From hill0093 at umn.edu  Tue Apr  1 00:25:17 2014
From: hill0093 at umn.edu (Hurr)
Date: Mon, 31 Mar 2014 15:25:17 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
Message-ID: <1396304717602-4687917.post@n4.nabble.com>

How can I label existing axis tick marks with a 
simple function of axis value like 1/AxisValue?
It seems like this should be an operation where
I just use the formula.




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917.html
Sent from the R help mailing list archive at Nabble.com.



From jim at bitwrit.com.au  Tue Apr  1 00:34:04 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 01 Apr 2014 09:34:04 +1100
Subject: [R] Setting Plot() Window Shape
In-Reply-To: <alpine.LNX.2.11.1403310839370.13719@localhost>
References: <alpine.LNX.2.11.1403310751350.13719@localhost>
	<alpine.LNX.2.11.1403310839370.13719@localhost>
Message-ID: <5339ED5C.80406@bitwrit.com.au>

On 04/01/2014 02:42 AM, Rich Shepard wrote:
> On Mon, 31 Mar 2014, Rich Shepard wrote:
>
>> I've read ?plot, ?plot.default, and ?plot.window to learn how to change
>> the shape of the plot from a square to a rectangle. plot.window suggests
>> that the aspect (asp) parameter is appropriate but that associates the x
>> axis size to the value of the y axis and, plot.window suggests that it is
>> better to make such adjustments with plot itself. My Web searches have
>> not
>> found examples of how to do this.
>
> Clarification:
>
> If I specify x11 <- (width = 6, height = 3) (as an example) then the
> display has that shape. However, when I want to redirect the output to a
> pdf
> file with the pdf() command, the resulting plot has reverted to a square
> rather than the specified width and height used to display it on the
> screen.
>
> What do I do to retain the specified width and height in the pdf output?
>
Hi Rich,
If you are starting a pdf device, you have to specify the width and 
height again - these don't carry over from the screen device.

Jim



From chris.barker at barkerstats.com  Tue Apr  1 00:41:00 2014
From: chris.barker at barkerstats.com (Chris)
Date: Mon, 31 Mar 2014 15:41:00 -0700 (PDT)
Subject: [R] labelling a plot in binom library  function call
Message-ID: <1396305660.70738.YahooMailNeo@web162504.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140331/958ce84c/attachment-0001.pl>

From jim at bitwrit.com.au  Tue Apr  1 00:36:40 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 01 Apr 2014 09:36:40 +1100
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1396304717602-4687917.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>
Message-ID: <5339EDF8.1070205@bitwrit.com.au>

On 04/01/2014 09:25 AM, Hurr wrote:
> How can I label existing axis tick marks with a
> simple function of axis value like 1/AxisValue?
> It seems like this should be an operation where
> I just use the formula.
>
Hi Hurr,
You can do this with boxed.labels (plotrix) if you know the position of 
the axis labels. If not, maybe axis.mult (also plotrix) will help.

Jim



From ii54250 at msn.com  Tue Apr  1 01:01:55 2014
From: ii54250 at msn.com (ioanna ioannou)
Date: Tue, 1 Apr 2014 00:01:55 +0100
Subject: [R] grf in geoR
Message-ID: <DUB126-DS11B397FA728ADCFCAA92EEF3630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/73c40c35/attachment-0001.pl>

From timyoo87 at gmail.com  Tue Apr  1 00:45:54 2014
From: timyoo87 at gmail.com (Timothy Yoo)
Date: Mon, 31 Mar 2014 15:45:54 -0700
Subject: [R] distribution modeling help
Message-ID: <CAENPigajE50qUzaRvr5ato=bD1AvbmmXB1un2jqmsi3pE2aSTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140331/f98a98db/attachment-0001.pl>

From ii54250 at msn.com  Tue Apr  1 01:04:00 2014
From: ii54250 at msn.com (ioanna ioannou)
Date: Tue, 1 Apr 2014 00:04:00 +0100
Subject: [R] grf in geoR
In-Reply-To: <024001cf4d35$37d75ca0$a78615e0$@msn.com>
References: <024001cf4d35$37d75ca0$a78615e0$@msn.com>
Message-ID: <DUB126-DS600EA98A82B14951C3E5EF3630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/669099bb/attachment-0001.pl>

From timyoo87 at gmail.com  Tue Apr  1 01:40:58 2014
From: timyoo87 at gmail.com (Timothy Yoo)
Date: Mon, 31 Mar 2014 16:40:58 -0700
Subject: [R] help with fitting a distribution
Message-ID: <CAENPigbOKRFck+irQGy1L=GNXWex=qRmKqv=bxVYhgOTQuiM+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140331/576d01f8/attachment-0001.pl>

From fisher at plessthan.com  Tue Apr  1 04:03:02 2014
From: fisher at plessthan.com (Dennis Fisher)
Date: Mon, 31 Mar 2014 19:03:02 -0700
Subject: [R] Getting rid of spaces in plot math
Message-ID: <E28D1BA8-597E-4BBE-BFDE-E8C208AD3E30@plessthan.com>

R 3.0.2
OS X

Colleagues

I am trying to label a graphic:
	Cortisol (?g/ml)
A simplified version of the code is:
	plot(1) ; mtext(bquote("Cortisol ("~mu~"g/ml)"))
This code inserts spaces around the mu:
	Cortisol ( ? g/ml)
How can I suppress those spaces?

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



From smartpink111 at yahoo.com  Tue Apr  1 04:12:46 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 31 Mar 2014 19:12:46 -0700
Subject: [R] Getting rid of spaces in plot math
In-Reply-To: <E28D1BA8-597E-4BBE-BFDE-E8C208AD3E30@plessthan.com>
References: <E28D1BA8-597E-4BBE-BFDE-E8C208AD3E30@plessthan.com>
Message-ID: <1396318366.59305.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
mtext(bquote(Cortisol~(mu*g/ml)))?
A.K.




On Monday, March 31, 2014 10:05 PM, Dennis Fisher <fisher at plessthan.com> wrote:
R 3.0.2
OS X

Colleagues

I am trying to label a graphic:
??? Cortisol (?g/ml)
A simplified version of the code is:
??? plot(1) ; mtext(bquote("Cortisol ("~mu~"g/ml)"))
This code inserts spaces around the mu:
??? Cortisol ( ? g/ml)
How can I suppress those spaces?

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pisicandru at hotmail.com  Tue Apr  1 04:43:15 2014
From: pisicandru at hotmail.com (Monica Pisica)
Date: Tue, 1 Apr 2014 02:43:15 +0000
Subject: [R] colors in violin plot, ggplot2
Message-ID: <BAY168-W383E9DDFDFAD9A3B868282C3620@phx.gbl>

Hi,



I am using ggplot and geom_violin to build a violin plot of some with only 2 categories. All is good except that I cannot set up the colors I want or the violin plots. Either I have same color for both my categories or colors from probably rainbow(2), which are red and blue. What if I want brown and forestgreen. How do I do it?



so my code follows:

 
p <- ggplot(x1, aes(Location, aer_m_GPS , fill=factor(Location), colour=factor(Location)))


p1 <- p+geom_violin(alpha=0.3, width=1, trim = FALSE, scale = "width", adjust = 0.5) + geom_boxplot(width=0.2, outlier.colour="red", notch = FALSE, notchwidth = .5, alpha = 0.5, colour = "grey50")


p1



This will plot the violin plot with boxplot superimposed on it, both with color red and blue. I hope to get brown and forestgreen.


Thanks for any advice,


Monica 		 	   		  


From luca.cerone at gmail.com  Tue Apr  1 10:41:44 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Tue, 1 Apr 2014 10:41:44 +0200
Subject: [R] Environment variable defined in .bashrc is not recognized by R
Message-ID: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>

Dear all,
in my .bashrc file I have set the environment variable R_HISTFILE like this:

 export R_HISTFILE="$HOME/.Rhistory"

I then use it in my .Rprofile to have R writing all the history in a
single file, rather than on a per directory basis.
However this doesn't work becaus R_HISTFILE is not recognized by R.

If I type: Sys.getenv("R_HISTFILE")
the output is: ""

How can I get R recognizing environment variables?

Best,
Luca

-- 
Luca Cerone

Skype: luca.cerone



From Rainer at krugs.de  Tue Apr  1 11:25:26 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 01 Apr 2014 11:25:26 +0200
Subject: [R] Environment variable defined in .bashrc is not recognized
	by R
In-Reply-To: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>
	(Luca Cerone's message of "Tue, 1 Apr 2014 10:41:44 +0200")
References: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>
Message-ID: <m2fvlxiepl.fsf@krugs.de>

Luca Cerone <luca.cerone at gmail.com> writes:

> Dear all,
> in my .bashrc file I have set the environment variable R_HISTFILE like this:
>
>  export R_HISTFILE="$HOME/.Rhistory"
>
> I then use it in my .Rprofile to have R writing all the history in a
> single file, rather than on a per directory basis.
> However this doesn't work becaus R_HISTFILE is not recognized by R.

Which OS? How do you start R?

There is a difference between login shell (executed when you log in) and
non-log in (I thik interactive shell? don't know the actual
name). .baschrc is only executed after you are logged in and start the
shell. So when you start R from the shell, it should work - you can
check by 
  
  echo $R_HISTFILE

which should show you the value of the variable.

If you are starting R the R gui (on Mac or RStudio) .bashrc is not
sourced. Checo online for the file which will be sourced by the login
shell - different between OS and distros.

Cheers,

Rainer


>
> If I type: Sys.getenv("R_HISTFILE")
> the output is: ""
>
> How can I get R recognizing environment variables?
>
> Best,
> Luca

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/374b9258/attachment-0002.bin>

From luca.cerone at gmail.com  Tue Apr  1 11:33:09 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Tue, 1 Apr 2014 11:33:09 +0200
Subject: [R] Environment variable defined in .bashrc is not recognized
	by R
In-Reply-To: <m2fvlxiepl.fsf@krugs.de>
References: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>
	<m2fvlxiepl.fsf@krugs.de>
Message-ID: <CAFnz2--Et7jkxn3_CALW3F5+rDWa9u2GSsGBoUYRLbY4_SmLuA@mail.gmail.com>

Thanks,
effectively I was using RStudio (on an Ubuntu 12.04 machine).

Is there any other way to make the variable available to Rstudio?
Now I have simply written the path manually, but I like the idea of
having a system-wide variable :)

Thanks for your help, Rainer!


On Tue, Apr 1, 2014 at 11:25 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Luca Cerone <luca.cerone at gmail.com> writes:
>
>> Dear all,
>> in my .bashrc file I have set the environment variable R_HISTFILE like this:
>>
>>  export R_HISTFILE="$HOME/.Rhistory"
>>
>> I then use it in my .Rprofile to have R writing all the history in a
>> single file, rather than on a per directory basis.
>> However this doesn't work becaus R_HISTFILE is not recognized by R.
>
> Which OS? How do you start R?
>
> There is a difference between login shell (executed when you log in) and
> non-log in (I thik interactive shell? don't know the actual
> name). .baschrc is only executed after you are logged in and start the
> shell. So when you start R from the shell, it should work - you can
> check by
>
>   echo $R_HISTFILE
>
> which should show you the value of the variable.
>
> If you are starting R the R gui (on Mac or RStudio) .bashrc is not
> sourced. Checo online for the file which will be sourced by the login
> shell - different between OS and distros.
>
> Cheers,
>
> Rainer
>
>
>>
>> If I type: Sys.getenv("R_HISTFILE")
>> the output is: ""
>>
>> How can I get R recognizing environment variables?
>>
>> Best,
>> Luca
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982



-- 
Luca Cerone

Tel: +34 692 06 71 28
Skype: luca.cerone



From Rainer at krugs.de  Tue Apr  1 11:57:25 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 01 Apr 2014 11:57:25 +0200
Subject: [R] Environment variable defined in .bashrc is not recognized
	by R
In-Reply-To: <CAFnz2--Et7jkxn3_CALW3F5+rDWa9u2GSsGBoUYRLbY4_SmLuA@mail.gmail.com>
	(Luca Cerone's message of "Tue, 1 Apr 2014 11:33:09 +0200")
References: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>
	<m2fvlxiepl.fsf@krugs.de>
	<CAFnz2--Et7jkxn3_CALW3F5+rDWa9u2GSsGBoUYRLbY4_SmLuA@mail.gmail.com>
Message-ID: <m2bnwlid8a.fsf@krugs.de>

Luca Cerone <luca.cerone at gmail.com> writes:

> Thanks,
> effectively I was using RStudio (on an Ubuntu 12.04 machine).
>
> Is there any other way to make the variable available to Rstudio?
> Now I have simply written the path manually, but I like the idea of
> having a system-wide variable :)

Check out 

  http://www.gnu.org/software/bash/manual/html_node/Bash-Startup-Files.html

and, specifically for Ubuntu:

  https://help.ubuntu.com/community/EnvironmentVariables

If you need more: just google for
  
  login shell variable Ubuntu

Cheers,

Rainer

>
> Thanks for your help, Rainer!
>
>
> On Tue, Apr 1, 2014 at 11:25 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Luca Cerone <luca.cerone at gmail.com> writes:
>>
>>> Dear all,
>>> in my .bashrc file I have set the environment variable R_HISTFILE like this:
>>>
>>>  export R_HISTFILE="$HOME/.Rhistory"
>>>
>>> I then use it in my .Rprofile to have R writing all the history in a
>>> single file, rather than on a per directory basis.
>>> However this doesn't work becaus R_HISTFILE is not recognized by R.
>>
>> Which OS? How do you start R?
>>
>> There is a difference between login shell (executed when you log in) and
>> non-log in (I thik interactive shell? don't know the actual
>> name). .baschrc is only executed after you are logged in and start the
>> shell. So when you start R from the shell, it should work - you can
>> check by
>>
>>   echo $R_HISTFILE
>>
>> which should show you the value of the variable.
>>
>> If you are starting R the R gui (on Mac or RStudio) .bashrc is not
>> sourced. Checo online for the file which will be sourced by the login
>> shell - different between OS and distros.
>>
>> Cheers,
>>
>> Rainer
>>
>>
>>>
>>> If I type: Sys.getenv("R_HISTFILE")
>>> the output is: ""
>>>
>>> How can I get R recognizing environment variables?
>>>
>>> Best,
>>> Luca
>>
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/4bc7d005/attachment-0002.bin>

From lebatsnok at gmail.com  Tue Apr  1 12:11:22 2014
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Tue, 1 Apr 2014 13:11:22 +0300
Subject: [R] Fwd: rbind error - duplicated row.names not allowed
In-Reply-To: <5339D5B9.40600@auckland.ac.nz>
References: <CAFFT+Y6nCMhOts9N=MXgWqtC69CJPyqX3YcYMTTxrHvRv88VOw@mail.gmail.com>
	<CAFFT+Y4bG2-e65kPaPCCgN+GrxPG=Ps=K6SNnm1W6jVAgNSY9A@mail.gmail.com>
	<5339D5B9.40600@auckland.ac.nz>
Message-ID: <CAH7sKSNtiZdMW_eAX1DgwQAbwYRV25CMjsEdtuS43UpVBODmxA@mail.gmail.com>

deleting the old rownames might help.

rownames(df1) <- rownames(df2) <- rownames(df3) <- NULL

But a reproducible example would be interestng. In simple cases there
is no problem with "duplicated" rownames as they are automatically
renamed:

> df1 <- data.frame(A=1, B=2, row.names="A")
> df2 <- data.frame(A=1, B=2, row.names="A")
> rbind(df1,df2)
   A B
A  1 2
A1 1 2
> df1 <- data.frame(A=1:2, B=2:3, row.names=c("A", "A1"))
> df2 <- data.frame(A=1, B=2, row.names="A")
> rbind(df1,df2)
   A B
A  1 2
A1 2 3
A2 1 2

On Mon, Mar 31, 2014 at 11:53 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 01/04/14 05:42, Jefferson Ferreira Ferreira wrote:
>>
>> There are other issues here addressing the same question, but I don't
>> realize how to solve my problem based on it. So, I have 5 data frames that
>> I want to merge rows in one unique data frame using rbind, but it returns
>> the error:
>>
>> "Error in row.names<-.data.frame(*tmp*, value = value) : 'row.names'
>> duplicated not allowed In addition: Warning message: non-unique values
>> when
>> setting 'row.names': '1', '10', '100', '1000', '10000', '100000',
>> '1000000', '1000001 [....]"
>>
>> The data frames have the same columns but different number of rows. I
>> thought the rbind command took the first column as row.names. So tried to
>> put a sequential id in the five data frames but it doesn't work. I've
>> tried
>> to specify a sequential row names among the data frames via row.names()
>> but
>> with no success too. The merge command is not an option I think because
>> are
>> 5 data frames and successive merges will overwrite precedents. I've
>> created
>> a new data frame only with ids and tried to join but the resulting data
>> frame don't append the columns of joined df.
>>
>> Follows an extract of df 1:
>>
>>    id    image     power     value pol class1  1 tsx_sm_hh 0.1834515
>> -7.364787  hh    FR2  2 tsx_sm_hh 0.1834515 -7.364787  hh    FR3  3
>> tsx_sm_hh 0.1991938 -7.007242  hh    FR4  4 tsx_sm_hh 0.1991938
>> -7.007242  hh    FR5  5 tsx_sm_hh 0.2079365 -6.820693  hh    FR6  6
>> tsx_sm_hh 0.2079365 -6.820693  hh    FR[...]1802124 1802124 tsx_sm_hh
>> 0.1991938 -7.007242  hh    FR
>>
>>   The four other df's are the same structure, except the 'id' columns that
>> don't have duplicated numbers among it. 'pol' and 'image' columns are
>> defined as levels. and all.pol <- rbind(df1,df2,df3,df4,df5) return the
>> this error of row.names duplicated.
>>
>> Any idea?
>
>
> Not without a reproducible example.  If you can create one, use dput() to
> include the necessary data in your posting.
>
> You *might* try something like:
>
>         e1 <- df1[1:5,1:2]
>         e2 <- df2[1:5,1:2]
>         ee <- rbind(e1,e2)
>
> If that throws the error, include dput(e1) and dput(e2) in your posting. If
> it *doesn't* then this might give you some insight into just what is
> triggering the error.
>
> Look at rownames(df1) and rownames(df2) as well as rownames(e1) and
> rownames(e2).
>
> cheers,
>
> Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From assymeon2 at hotmail.com  Tue Apr  1 10:37:14 2014
From: assymeon2 at hotmail.com (ANNA SIMEONIDOU)
Date: Tue, 1 Apr 2014 11:37:14 +0300
Subject: [R]  Please help! Matrices and parameter of time
Message-ID: <DUB128-W82F9618036F496A6784BF9EC620@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/492f90d8/attachment-0001.pl>

From rgenevest at free.fr  Tue Apr  1 11:26:45 2014
From: rgenevest at free.fr (remissssss)
Date: Tue, 1 Apr 2014 02:26:45 -0700 (PDT)
Subject: [R] trouble using readOGR() function
Message-ID: <1396344405775-4687937.post@n4.nabble.com>

Hi all,
I got some trouble trying to open a .kml file into R. Usually, the readOGR
package works great for it but here I get a message error that I can't
understand.

When I'm typing this :
myfile <-readOGR(dsn="/windows/landuse.kml",layer="agricultural use")

I get the following error :
Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv =
use_iconv) :
Multiple incompatible geometries: 6:7

It seems that the file is read, since I get different parameters on it while
using OGRSpatialRef() or ogrListLayers()

Someone would have any idea to solve the "incompatible geometry" error ?

Thanks for help!



--
View this message in context: http://r.789695.n4.nabble.com/trouble-using-readOGR-function-tp4687937.html
Sent from the R help mailing list archive at Nabble.com.



From Sonja.Schillo at uni-due.de  Tue Apr  1 10:27:54 2014
From: Sonja.Schillo at uni-due.de (Schillo, Sonja)
Date: Tue, 1 Apr 2014 08:27:54 +0000
Subject: [R] rpart and randomforest results
Message-ID: <F935BF3EEA79BF45901A755531026E8344F40E43@WIWINF-EXDAG03.wiwinf.uni-due.de>

Hi all,

I have a question on rpart and randomforest results:

We calculated a single regression tree using rpart and got a pseudo-r2 of roundabout 10% (which is not too bad compared to a linear regression on this data). Encouraged by this we grew a whole regression forest on the same data set using randomforest. But we got  pretty bad pseudo-r2 values for the randomforest (even sometimes negative values for some option settings).
We then thought that if we built only one single tree with the randomforest routine we should get a result similar to that of rpart. So we set the options for randomforest to only one single tree but the resulting pseudo-r2 value was negative aswell.

Does anyone have a clue as to why the randomforest results are so bad whereas the rpart result is quite ok?
Is our assumption that a single tree grown by randomforest should give similar results as a tree grown by rpart wrong?
What am I missing here? 

Thanks a lot for your help!
Sonja



From Yngvar.Nilssen at kreftregisteret.no  Tue Apr  1 10:37:09 2014
From: Yngvar.Nilssen at kreftregisteret.no (Yngvar Nilssen)
Date: Tue, 1 Apr 2014 10:37:09 +0200
Subject: [R] R rms package: nomogram using imported coefficients and linear
 predictor
Message-ID: <9D3AD053100C694F9C1906F8377AE808B626A05AA8@INT-MAIL-ALPHA.krg.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/5c26a8c6/attachment-0001.pl>

From mmalten at gmail.com  Tue Apr  1 13:31:57 2014
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Tue, 1 Apr 2014 07:31:57 -0400
Subject: [R] rpart and randomforest results
In-Reply-To: <F935BF3EEA79BF45901A755531026E8344F40E43@WIWINF-EXDAG03.wiwinf.uni-due.de>
References: <F935BF3EEA79BF45901A755531026E8344F40E43@WIWINF-EXDAG03.wiwinf.uni-due.de>
Message-ID: <CANOgrHaKRY+4ibQGisjRzmjpArMax6LPWDCL9JjhZ5TPYO98FQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/8d878eb5/attachment-0001.pl>

From pisicandru at hotmail.com  Tue Apr  1 14:19:39 2014
From: pisicandru at hotmail.com (Monica Pisica)
Date: Tue, 1 Apr 2014 12:19:39 +0000
Subject: [R] colors in violin plot, ggplot2
In-Reply-To: <CADv2QyGpXuD0SCuh3h+qQuk_pErvj1V0OewEUzHKyb3yTPQPvg@mail.gmail.com>
References: <BAY168-W383E9DDFDFAD9A3B868282C3620@phx.gbl>,
	<CADv2QyGpXuD0SCuh3h+qQuk_pErvj1V0OewEUzHKyb3yTPQPvg@mail.gmail.com>
Message-ID: <BAY168-W731BE46AE8DB58FE9F3CFAC3620@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/f82abafe/attachment-0001.pl>

From marceivissa at gmail.com  Tue Apr  1 14:56:24 2014
From: marceivissa at gmail.com (=?ISO-8859-1?Q?Marc_Mar=ED_Dell=27Olmo?=)
Date: Tue, 1 Apr 2014 14:56:24 +0200
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
Message-ID: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>

Dear all,

Anyone knows how to generate a vector of Normal distributed values
(for example N(0,0.5)), but with a sum-to-zero constraint??

The sum would be exactly zero, without decimals.

I made some attempts:

> l <- 1000000
> aux <- rnorm(l,0,0.5)
> s <- sum(aux)/l
> aux2 <- aux-s
> sum(aux2)
[1] -0.000000000006131392
>
> aux[1]<- -sum(aux[2:l])
> sum(aux)
[1] -0.00000000000003530422


but the sum is not exactly zero and not all parameters are N(0,0.5)
distributed...

Perhaps is obvious but I can't find the way to do it..

Thank you very much!

Marc



From jdnewmil at dcn.davis.CA.us  Tue Apr  1 15:27:03 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 01 Apr 2014 06:27:03 -0700
Subject: [R] A vector of normal distributed values with a
	sum-to-zero	constraint
In-Reply-To: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
Message-ID: <46516daa-dd8a-4e10-857c-a72ef306f2a6@email.android.com>

You are on a fool's errand. Read FAQ 7.31.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 1, 2014 5:56:24 AM PDT, "Marc Mar? Dell'Olmo" <marceivissa at gmail.com> wrote:
>Dear all,
>
>Anyone knows how to generate a vector of Normal distributed values
>(for example N(0,0.5)), but with a sum-to-zero constraint??
>
>The sum would be exactly zero, without decimals.
>
>I made some attempts:
>
>> l <- 1000000
>> aux <- rnorm(l,0,0.5)
>> s <- sum(aux)/l
>> aux2 <- aux-s
>> sum(aux2)
>[1] -0.000000000006131392
>>
>> aux[1]<- -sum(aux[2:l])
>> sum(aux)
>[1] -0.00000000000003530422
>
>
>but the sum is not exactly zero and not all parameters are N(0,0.5)
>distributed...
>
>Perhaps is obvious but I can't find the way to do it..
>
>Thank you very much!
>
>Marc
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Tue Apr  1 15:47:10 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 1 Apr 2014 08:47:10 -0500
Subject: [R] Please help! Matrices and parameter of time
In-Reply-To: <DUB128-W82F9618036F496A6784BF9EC620@phx.gbl>
References: <DUB128-W82F9618036F496A6784BF9EC620@phx.gbl>
Message-ID: <00ec01cf4db0$e1820090$a48601b0$@tamu.edu>

Use an 3-dimensional array.

?array

And any basic introduction to R.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of ANNA
SIMEONIDOU
Sent: Tuesday, April 1, 2014 3:37 AM
To: r-help at r-project.org
Subject: [R] Please help! Matrices and parameter of time

Hi, Well, the solution to my problem maybe is easy, but i have
really stuck with this.
I have a process which evolves in three times, so there is the
parameter of time (t=1,2,3).More particularly i have three 4*4
matrices, one for each time. In other words each element has
three cordinates: time, row and column.
The problems are these:i don't know how to express these
matrices.Also i don't know how can i extract each element, for
example, if i want the element from the matrix corresponding to
the 3d time, the  2nd row, the 3d column, how will i extract
this? 
I would appreciate any help and idea!Thank you!Anna S.
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From jdnewmil at dcn.davis.CA.us  Tue Apr  1 15:49:31 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 01 Apr 2014 06:49:31 -0700
Subject: [R] Please help! Matrices and parameter of time
In-Reply-To: <DUB128-W82F9618036F496A6784BF9EC620@phx.gbl>
References: <DUB128-W82F9618036F496A6784BF9EC620@phx.gbl>
Message-ID: <a6ba94b5-ebe8-4b51-a836-4e2d4ce7733f@email.android.com>

This mailing list has a no homework policy (read the Posting Guide, please, which also requests that you post in plain text format only). If this is not homework then you will have to be a bit more specific about what you know and what you don't in order to get useful help. Questions about why you should put certain values in particular locations in your array are not about R and are off topic here.

If you are having difficulty with R syntax for arrays, I recommend reading the Introduction to R document supplied with the software, and experimenting. If you are still having difficulty after doing that, then refer to where you get lost in that document when asking for more help. 

A word of advice: the least obvious thing about arrays to beginners is that they are constructed using one big vector rather than a bunch of little vectors, yet it is possible to extract or change little vectors or arrays from the larger array using indexing.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 1, 2014 1:37:14 AM PDT, ANNA SIMEONIDOU <assymeon2 at hotmail.com> wrote:
>Hi, Well, the solution to my problem maybe is easy, but i have really
>stuck with this.
>I have a process which evolves in three times, so there is the
>parameter of time (t=1,2,3).More particularly i have three 4*4 
>matrices, one for each time. In other words each element has three
>cordinates: time, row and column.
>The problems are these:i don't know how to express these matrices.Also
>i don't know how can i extract each element, for example, if i want the
>element from the matrix corresponding to the 3d time, the  2nd row, the
>3d column, how will i extract this? 
>I would appreciate any help and idea!Thank you!Anna S.
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Tue Apr  1 15:29:46 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 1 Apr 2014 09:29:46 -0400
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
Message-ID: <CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>

Make a copy with opposite sign. This is Normal, symmetric, but no longer random.

  set.seed(112358)
  x <- rnorm(5000, 0, 0.5)
  x <- c(x, -x)
  sum(x)
  hist(x)

B.

On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:

> Dear all,
> 
> Anyone knows how to generate a vector of Normal distributed values
> (for example N(0,0.5)), but with a sum-to-zero constraint??
> 
> The sum would be exactly zero, without decimals.
> 
> I made some attempts:
> 
>> l <- 1000000
>> aux <- rnorm(l,0,0.5)
>> s <- sum(aux)/l
>> aux2 <- aux-s
>> sum(aux2)
> [1] -0.000000000006131392
>> 
>> aux[1]<- -sum(aux[2:l])
>> sum(aux)
> [1] -0.00000000000003530422
> 
> 
> but the sum is not exactly zero and not all parameters are N(0,0.5)
> distributed...
> 
> Perhaps is obvious but I can't find the way to do it..
> 
> Thank you very much!
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From JLucke at ria.buffalo.edu  Tue Apr  1 16:14:08 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Tue, 1 Apr 2014 10:14:08 -0400
Subject: [R] A vector of normal distributed values with a
	sum-to-zero	constraint
In-Reply-To: <CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
Message-ID: <OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/7baddf93/attachment-0001.pl>

From boris.steipe at utoronto.ca  Tue Apr  1 16:25:06 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 1 Apr 2014 10:25:06 -0400
Subject: [R] A vector of normal distributed values with a
	sum-to-zero	constraint
In-Reply-To: <OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
Message-ID: <AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>

But the result is not Normal. Consider:

set.seed(112358)
N <- 100
x <- rnorm(N-1)
sum(x)

[1] 1.759446   !!!

i.e. you have an outlier at 1.7 sigma, and for larger N...

set.seed(112358)
N <- 10000
x <- rnorm(N-1)
sum(x)
[1] -91.19731

B.


On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:

> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of  N samples, only (N-1) can be random.   Thus the solution is 
> > N <- 100
> > x <- rnorm(N-1)
> > x <- c(x, -sum(x))
> > sum(x)
> [1] -7.199102e-17
> 
> >
> 
> 
> 
> 
> 
> 
> 
> 
> Boris Steipe <boris.steipe at utoronto.ca> 
> Sent by: r-help-bounces at r-project.org
> 04/01/2014 09:29 AM
> 
> To
> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
> cc
> "r-help at r-project.org" <r-help at r-project.org>
> Subject
> Re: [R] A vector of normal distributed values with a sum-to-zero        constraint
> 
> 
> 
> 
> 
> Make a copy with opposite sign. This is Normal, symmetric, but no longer random.
> 
>  set.seed(112358)
>  x <- rnorm(5000, 0, 0.5)
>  x <- c(x, -x)
>  sum(x)
>  hist(x)
> 
> B.
> 
> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
> 
> > Dear all,
> > 
> > Anyone knows how to generate a vector of Normal distributed values
> > (for example N(0,0.5)), but with a sum-to-zero constraint??
> > 
> > The sum would be exactly zero, without decimals.
> > 
> > I made some attempts:
> > 
> >> l <- 1000000
> >> aux <- rnorm(l,0,0.5)
> >> s <- sum(aux)/l
> >> aux2 <- aux-s
> >> sum(aux2)
> > [1] -0.000000000006131392
> >> 
> >> aux[1]<- -sum(aux[2:l])
> >> sum(aux)
> > [1] -0.00000000000003530422
> > 
> > 
> > but the sum is not exactly zero and not all parameters are N(0,0.5)
> > distributed...
> > 
> > Perhaps is obvious but I can't find the way to do it..
> > 
> > Thank you very much!
> > 
> > Marc
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



From marceivissa at gmail.com  Tue Apr  1 16:56:48 2014
From: marceivissa at gmail.com (=?ISO-8859-1?Q?Marc_Mar=ED_Dell=27Olmo?=)
Date: Tue, 1 Apr 2014 16:56:48 +0200
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
Message-ID: <CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>

Boris is right. I need this vector to include as initial values of a
MCMC process (with openbugs) and If I use this last approach sum(x)
could be a large (or extreme) value and can cause problems.

The other approach x <- c(x, -x) has the problem that only vectors
with even values are obtained.

Thank you!


2014-04-01 16:25 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
> But the result is not Normal. Consider:
>
> set.seed(112358)
> N <- 100
> x <- rnorm(N-1)
> sum(x)
>
> [1] 1.759446   !!!
>
> i.e. you have an outlier at 1.7 sigma, and for larger N...
>
> set.seed(112358)
> N <- 10000
> x <- rnorm(N-1)
> sum(x)
> [1] -91.19731
>
> B.
>
>
> On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:
>
>> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of  N samples, only (N-1) can be random.   Thus the solution is
>> > N <- 100
>> > x <- rnorm(N-1)
>> > x <- c(x, -sum(x))
>> > sum(x)
>> [1] -7.199102e-17
>>
>> >
>>
>>
>>
>>
>>
>>
>>
>>
>> Boris Steipe <boris.steipe at utoronto.ca>
>> Sent by: r-help-bounces at r-project.org
>> 04/01/2014 09:29 AM
>>
>> To
>> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
>> cc
>> "r-help at r-project.org" <r-help at r-project.org>
>> Subject
>> Re: [R] A vector of normal distributed values with a sum-to-zero        constraint
>>
>>
>>
>>
>>
>> Make a copy with opposite sign. This is Normal, symmetric, but no longer random.
>>
>>  set.seed(112358)
>>  x <- rnorm(5000, 0, 0.5)
>>  x <- c(x, -x)
>>  sum(x)
>>  hist(x)
>>
>> B.
>>
>> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
>>
>> > Dear all,
>> >
>> > Anyone knows how to generate a vector of Normal distributed values
>> > (for example N(0,0.5)), but with a sum-to-zero constraint??
>> >
>> > The sum would be exactly zero, without decimals.
>> >
>> > I made some attempts:
>> >
>> >> l <- 1000000
>> >> aux <- rnorm(l,0,0.5)
>> >> s <- sum(aux)/l
>> >> aux2 <- aux-s
>> >> sum(aux2)
>> > [1] -0.000000000006131392
>> >>
>> >> aux[1]<- -sum(aux[2:l])
>> >> sum(aux)
>> > [1] -0.00000000000003530422
>> >
>> >
>> > but the sum is not exactly zero and not all parameters are N(0,0.5)
>> > distributed...
>> >
>> > Perhaps is obvious but I can't find the way to do it..
>> >
>> > Thank you very much!
>> >
>> > Marc
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From Keith.Jewell at campdenbri.co.uk  Tue Apr  1 16:58:17 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Tue, 1 Apr 2014 15:58:17 +0100
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
Message-ID: <lhek68$5m8$1@ger.gmane.org>

It seems so simple to me, that I must be missing something.

Subject to Jeff Newmiller's reminder of FAQ 7.31; if the sum is zero 
then the mean is zero and vice versa.

The OP's original attempt of:
-------------
l <- 1000000
aux <- rnorm(l,0,0.5)
s <- sum(aux)/l
aux2 <- aux-s
sum(aux2)
-------------
is equivalent to

   aux2 <- rnorm(l,0,0.5)
   aux2 <- aux2-mean(aux2)

If calculations were exact then aux2 would have mean, and thus sum, 
equal to zero - any difference from zero is attributable entirely to 
machine precision.


On 01/04/2014 15:25, Boris Steipe wrote:
> But the result is not Normal. Consider:
>
> set.seed(112358)
> N <- 100
> x <- rnorm(N-1)
> sum(x)
>
> [1] 1.759446   !!!
>
> i.e. you have an outlier at 1.7 sigma, and for larger N...
>
> set.seed(112358)
> N <- 10000
> x <- rnorm(N-1)
> sum(x)
> [1] -91.19731
>
> B.
>
>
> On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:
>
>> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of  N samples, only (N-1) can be random.   Thus the solution is
>>> N <- 100
>>> x <- rnorm(N-1)
>>> x <- c(x, -sum(x))
>>> sum(x)
>> [1] -7.199102e-17
>>
>>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Boris Steipe <boris.steipe at utoronto.ca>
>> Sent by: r-help-bounces at r-project.org
>> 04/01/2014 09:29 AM
>>
>> To
>> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
>> cc
>> "r-help at r-project.org" <r-help at r-project.org>
>> Subject
>> Re: [R] A vector of normal distributed values with a sum-to-zero        constraint
>>
>>
>>
>>
>>
>> Make a copy with opposite sign. This is Normal, symmetric, but no longer random.
>>
>>   set.seed(112358)
>>   x <- rnorm(5000, 0, 0.5)
>>   x <- c(x, -x)
>>   sum(x)
>>   hist(x)
>>
>> B.
>>
>> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
>>
>>> Dear all,
>>>
>>> Anyone knows how to generate a vector of Normal distributed values
>>> (for example N(0,0.5)), but with a sum-to-zero constraint??
>>>
>>> The sum would be exactly zero, without decimals.
>>>
>>> I made some attempts:
>>>
>>>> l <- 1000000
>>>> aux <- rnorm(l,0,0.5)
>>>> s <- sum(aux)/l
>>>> aux2 <- aux-s
>>>> sum(aux2)
>>> [1] -0.000000000006131392
>>>>
>>>> aux[1]<- -sum(aux[2:l])
>>>> sum(aux)
>>> [1] -0.00000000000003530422
>>>
>>>
>>> but the sum is not exactly zero and not all parameters are N(0,0.5)
>>> distributed...
>>>
>>> Perhaps is obvious but I can't find the way to do it..
>>>
>>> Thank you very much!
>>>
>>> Marc
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



From JLucke at ria.buffalo.edu  Tue Apr  1 17:01:10 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Tue, 1 Apr 2014 11:01:10 -0400
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
	<CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
Message-ID: <OF9B2CAE81.FA80D99A-ON85257CAD.00526CD1-85257CAD.00528241@ria.buffalo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/c89d4107/attachment-0001.pl>

From ruipbarradas at sapo.pt  Tue Apr  1 17:22:52 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 01 Apr 2014 16:22:52 +0100
Subject: [R] A vector of normal distributed values with a sum-to-zero
 constraint
In-Reply-To: <OF9B2CAE81.FA80D99A-ON85257CAD.00526CD1-85257CAD.00528241@ria.buffalo.edu>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>	<CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
	<OF9B2CAE81.FA80D99A-ON85257CAD.00526CD1-85257CAD.00528241@ria.buffalo.edu>
Message-ID: <533AD9CC.9030505@sapo.pt>

Hello,

One way is to use ?scale.

set.seed(4867)
l <- 1000000
aux <- rnorm(l, 0, 0.5)
aux <- scale(aux, scale = FALSE)
sum(aux)

hist(aux, prob = TRUE)
curve(dnorm(x, 0, 0.5), from = -2, to = 2, add = TRUE)

Hope this helps,

Rui Barradas

Em 01-04-2014 16:01, JLucke at ria.buffalo.edu escreveu:
> Then what's wrong with centering your initial values around the mean?
>
>
>
> Marc Mar? Dell'Olmo <marceivissa at gmail.com>
> 04/01/2014 10:56 AM
>
> To
> Boris Steipe <boris.steipe at utoronto.ca>,
> cc
> JLucke at ria.buffalo.edu, "r-help at r-project.org" <r-help at r-project.org>
> Subject
> Re: [R] A vector of normal distributed values with a sum-to-zero
> constraint
>
>
>
>
>
>
> Boris is right. I need this vector to include as initial values of a
> MCMC process (with openbugs) and If I use this last approach sum(x)
> could be a large (or extreme) value and can cause problems.
>
> The other approach x <- c(x, -x) has the problem that only vectors
> with even values are obtained.
>
> Thank you!
>
>
> 2014-04-01 16:25 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> But the result is not Normal. Consider:
>>
>> set.seed(112358)
>> N <- 100
>> x <- rnorm(N-1)
>> sum(x)
>>
>> [1] 1.759446   !!!
>>
>> i.e. you have an outlier at 1.7 sigma, and for larger N...
>>
>> set.seed(112358)
>> N <- 10000
>> x <- rnorm(N-1)
>> sum(x)
>> [1] -91.19731
>>
>> B.
>>
>>
>> On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:
>>
>>> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of
>   N samples, only (N-1) can be random.   Thus the solution is
>>>> N <- 100
>>>> x <- rnorm(N-1)
>>>> x <- c(x, -sum(x))
>>>> sum(x)
>>> [1] -7.199102e-17
>>>
>>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Boris Steipe <boris.steipe at utoronto.ca>
>>> Sent by: r-help-bounces at r-project.org
>>> 04/01/2014 09:29 AM
>>>
>>> To
>>> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
>>> cc
>>> "r-help at r-project.org" <r-help at r-project.org>
>>> Subject
>>> Re: [R] A vector of normal distributed values with a sum-to-zero
> constraint
>>>
>>>
>>>
>>>
>>>
>>> Make a copy with opposite sign. This is Normal, symmetric, but no
> longer random.
>>>
>>>   set.seed(112358)
>>>   x <- rnorm(5000, 0, 0.5)
>>>   x <- c(x, -x)
>>>   sum(x)
>>>   hist(x)
>>>
>>> B.
>>>
>>> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
>>>
>>>> Dear all,
>>>>
>>>> Anyone knows how to generate a vector of Normal distributed values
>>>> (for example N(0,0.5)), but with a sum-to-zero constraint??
>>>>
>>>> The sum would be exactly zero, without decimals.
>>>>
>>>> I made some attempts:
>>>>
>>>>> l <- 1000000
>>>>> aux <- rnorm(l,0,0.5)
>>>>> s <- sum(aux)/l
>>>>> aux2 <- aux-s
>>>>> sum(aux2)
>>>> [1] -0.000000000006131392
>>>>>
>>>>> aux[1]<- -sum(aux[2:l])
>>>>> sum(aux)
>>>> [1] -0.00000000000003530422
>>>>
>>>>
>>>> but the sum is not exactly zero and not all parameters are N(0,0.5)
>>>> distributed...
>>>>
>>>> Perhaps is obvious but I can't find the way to do it..
>>>>
>>>> Thank you very much!
>>>>
>>>> Marc
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From waddeessa at gmail.com  Tue Apr  1 16:19:21 2014
From: waddeessa at gmail.com (Kumsa)
Date: Tue, 1 Apr 2014 16:19:21 +0200
Subject: [R] Remove part of a summary of a model in a regression output
Message-ID: <CALekQEu8GfMM+qQMoxmRsH9VxHr7ZsPQibrJWGdbzpgiA4-nmQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/6e09b0d5/attachment-0001.pl>

From eliza_botto at hotmail.com  Tue Apr  1 18:07:57 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 1 Apr 2014 16:07:57 +0000
Subject: [R] importing multiple text files in R
Message-ID: <BLU170-W131234E9C9D3CCE1AA6A1E589620@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/9adf50c7/attachment-0001.pl>

From frtog at vestas.com  Tue Apr  1 18:19:36 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 1 Apr 2014 18:19:36 +0200
Subject: [R] importing multiple text files in R
Message-ID: <0uy97ovvo7wheikj2wjcg06x.1396369173682@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/1ec50ef0/attachment-0001.pl>

From HDoran at air.org  Tue Apr  1 18:33:22 2014
From: HDoran at air.org (Doran, Harold)
Date: Tue, 1 Apr 2014 16:33:22 +0000
Subject: [R] Times and Dates
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6868A242FCA@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/2904f6e0/attachment-0001.pl>

From miguel.sanz.elvira at gmail.com  Tue Apr  1 18:18:47 2014
From: miguel.sanz.elvira at gmail.com (miguel sanz)
Date: Tue, 1 Apr 2014 18:18:47 +0200
Subject: [R]  jointprior in deal package
Message-ID: <CAPC-W7uDzW86afn9OgwBmerkVxCkneuAw-=0q8tYy5hwzXHfsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/fd641cfe/attachment-0001.pl>

From Zeef at gmx.de  Tue Apr  1 19:23:19 2014
From: Zeef at gmx.de (Dao_De)
Date: Tue, 1 Apr 2014 10:23:19 -0700 (PDT)
Subject: [R] Plotting Satellite
Message-ID: <1396372999202-4687971.post@n4.nabble.com>

I want to read the following file with and extract the longitude and latitude
for certain areas. 
The file is satellite data from topex and contains the monthly wave energy
fluxes around the worlds oceans.


For doing that i have the following loop that reads the specific data.

I then want to create a worldmap/the specific region for example the baltic
sea or whatever, that shows the the wave energy. Also i want to plot the
averages and the trend for the wave energy and eventually calcualte a slope
for the wave energy over time.




I got the following loop




library(sp)
library(maptools)
library(maps)
library(rgdal)
library(shape)
library(mapdata)

# "pow_sat_file.txt"

inputpath1<-"/Users/Sam/Desktop/MER/rem/" 
inputfile1<-paste(inputpath1,"pow_sat_file.txt",sep="") 

sat<-read.table("pow_sat_file.txt",header=TRUE, sep="",nrow=-1)
sat.mat<-as.data.frame(sat)

dims<-dim(sat.mat)
tempo<-matrix(0, nrow=dims[1], ncol=dims[2])
tempo<-data.frame(tempo)
date<-seq(as.Date("1993/1/1"), as.Date("2005/10/1"), by="month")

# France coordinates
long.min<--6
long.max<-10
lat.min<-40
lat.max<-52

#Loop on "pow_sat_file.txt" to only keep the interesting points
for (i in 1:dims[1]){
? long<-sat.mat[i,1]
? lat<-sat.mat[i,2]
? if (((long>=-6 && long<=10)==TRUE ) && ((lat>=40 && lat<=52))==TRUE){
? ? tempo[i,1]<-long
? ? tempo[i,2]<-lat
? ? for (j in 3:dims[2]){
? ? ? tempo[i,j]<-sat.mat[i,j]
? ? }
? }
}


How do i continue from here to get a map of the specific region and a slope?

Thx in advance



--
View this message in context: http://r.789695.n4.nabble.com/Plotting-Satellite-tp4687971.html
Sent from the R help mailing list archive at Nabble.com.



From murdoch.duncan at gmail.com  Tue Apr  1 19:58:23 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 01 Apr 2014 13:58:23 -0400
Subject: [R] Times and Dates
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6868A242FCA@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A242FCA@DC1VEX10MB001.air.org>
Message-ID: <533AFE3F.5070007@gmail.com>

On 01/04/2014 12:33 PM, Doran, Harold wrote:
> Is the time and date package the right one to convert a vector, such as the following, into a time format?
>
> "12:06" "11:51" "11:53" "12:27" "14:20" "12:27"
>
> The aim is to deal with a time variable numerically (find means, etc).

I don't know which package you were referring to.  You can convert 
strings to POSIXlt objects using the base package strptime function.  
Those aren't numbers, but if you further convert them to POSIXct 
objects, they are.  The mean() function works on either type.

For example,

 > x <- strptime( c("12:06", "11:51") , format="%H:%M")
 > x
[1] "2014-04-01 12:06:00 EDT" "2014-04-01 11:51:00 EDT"
 > mean(x)
[1] "2014-04-01 11:58:30 EDT"

You may get different results for the day and time zone.  If you don't 
want to see those, format the output:

 >  format(mean(x), format="%H:%M")
[1] "11:58"

Duncan Murdoch



From lebatsnok at gmail.com  Tue Apr  1 20:07:10 2014
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Tue, 1 Apr 2014 21:07:10 +0300
Subject: [R] importing multiple text files in R
In-Reply-To: <0uy97ovvo7wheikj2wjcg06x.1396369173682@email.android.com>
References: <0uy97ovvo7wheikj2wjcg06x.1396369173682@email.android.com>
Message-ID: <CAH7sKSO97DHBLTGmyKO4ScFNQF7RT-_S8-WW0Lcx7TifwZUXQQ@mail.gmail.com>

you can extract numbers from your file names and then sort them like this:

filelist = list.files(pattern = ".s*.txt")
filelist[order(as.integer(gsub("[^0-9]", "", filelist)))]
(cf with alphabetic order: filelist[order(gsub("[^0-9]", "", filelist))]

Or if you just have s1...s120 you can construct the names programmatically

filelist<-paste0("s", 1:120, ".txt")


On Tue, Apr 1, 2014 at 7:19 PM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:
> Try
> mixedsort  in gtools package
>
> Br. Frede
>
>
> Sendt fra Samsung mobil
>
>
> -------- Oprindelig meddelelse --------
> Fra: eliza botto
> Dato:01/04/2014 18.10 (GMT+01:00)
> Til: r-help at r-project.org
> Emne: [R] importing multiple text files in R
>
> Dear useRs,
> I have a number of text file located at a certain location with the following names.
> s1.txt,s2.txt,s3.txt,s4.txt,s5.txt...............s120.txt
> when i read them, before opening them, by using
> filelist = list.files(pattern = ".s*.txt")
> The are opened in the following order
> [1] "s1.txt"   "s10.txt"  "s100.txt" "s101.txt" "s102.txt" "s103.txt" "s104.txt" "s105.txt" "s106.txt" "s107.txt" "s108.txt" "s109.txt" "s11.txt"  "s110.txt" [15] "s111.txt" "s112.txt" "s113.txt" "s114.txt" "s115.txt" "s116.txt" "s117.txt" "s118.txt" "s119.txt" "s12.txt"  "s120.txt" "s13.txt"  "s14.txt"  "s15.txt"
>  [29] "s16.txt"  "s17.txt"  "s18.txt"  "s19.txt"  "s2.txt"   "s20.txt"  "s21.txt"  "s22.txt"  "s23.txt"  "s24.txt"  "s25.txt"  "s26.txt"  "s27.txt"  "s28.txt"
>  [43] "s29.txt"  "s3.txt"   "s30.txt"  "s31.txt"  "s32.txt"  "s33.txt"  "s34.txt"  "s35.txt"  "s36.txt"  "s37.txt"  "s38.txt"  "s39.txt"  "s4.txt"   "s40.txt"
>  [57] "s41.txt"  "s42.txt"  "s43.txt"  "s44.txt"  "s45.txt"  "s46.txt"  "s47.txt"  "s48.txt"  "s49.txt"  "s5.txt"   "s50.txt"  "s51.txt"  "s52.txt"  "s53.txt"
>  [71] "s54.txt"  "s55.txt"  "s56.txt"  "s57.txt"  "s58.txt"  "s59.txt"  "s6.txt"   "s60.txt"  "s61.txt"  "s62.txt"  "s63.txt"  "s64.txt"  "s65.txt"  "s66.txt"
>  [85] "s67.txt"  "s68.txt"  "s69.txt"  "s7.txt"   "s70.txt"  "s71.txt"  "s72.txt"  "s73.txt"  "s74.txt"  "s75.txt"  "s76.txt"  "s77.txt"  "s78.txt"  "s79.txt"
>  [99] "s8.txt"   "s80.txt"  "s81.txt"  "s82.txt"  "s83.txt"  "s84.txt"  "s85.txt"  "s86.txt"  "s87.txt"  "s88.txt"  "s89.txt"  "s9.txt"   "s90.txt"  "s91.txt"
> [113] "s92.txt"  "s93.txt"  "s94.txt"  "s95.txt"  "s96.txt"  "s97.txt"  "s98.txt"  "s99.txt"
>
> How can I open them systematically starting from s1,s2,s3 and all the way upto s120?
> Thankyou very much indeed in advance.
> Eliza
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From h.wickham at gmail.com  Tue Apr  1 20:29:24 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 1 Apr 2014 11:29:24 -0700
Subject: [R] Environment variable defined in .bashrc is not recognized
	by R
In-Reply-To: <CAFnz2--Et7jkxn3_CALW3F5+rDWa9u2GSsGBoUYRLbY4_SmLuA@mail.gmail.com>
References: <CAFnz2-98acBSm681s=t-ak5obsFyQBhR0qYoP0B8MkYOixwZuw@mail.gmail.com>
	<m2fvlxiepl.fsf@krugs.de>
	<CAFnz2--Et7jkxn3_CALW3F5+rDWa9u2GSsGBoUYRLbY4_SmLuA@mail.gmail.com>
Message-ID: <CABdHhvG2F7NoPyT2yjTE9WvRtOOudmBr4k=5mf3i4tbLuqPfnA@mail.gmail.com>

Use .Renviron

Hadley

On Tue, Apr 1, 2014 at 2:33 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
> Thanks,
> effectively I was using RStudio (on an Ubuntu 12.04 machine).
>
> Is there any other way to make the variable available to Rstudio?
> Now I have simply written the path manually, but I like the idea of
> having a system-wide variable :)
>
> Thanks for your help, Rainer!
>
>
> On Tue, Apr 1, 2014 at 11:25 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Luca Cerone <luca.cerone at gmail.com> writes:
>>
>>> Dear all,
>>> in my .bashrc file I have set the environment variable R_HISTFILE like this:
>>>
>>>  export R_HISTFILE="$HOME/.Rhistory"
>>>
>>> I then use it in my .Rprofile to have R writing all the history in a
>>> single file, rather than on a per directory basis.
>>> However this doesn't work becaus R_HISTFILE is not recognized by R.
>>
>> Which OS? How do you start R?
>>
>> There is a difference between login shell (executed when you log in) and
>> non-log in (I thik interactive shell? don't know the actual
>> name). .baschrc is only executed after you are logged in and start the
>> shell. So when you start R from the shell, it should work - you can
>> check by
>>
>>   echo $R_HISTFILE
>>
>> which should show you the value of the variable.
>>
>> If you are starting R the R gui (on Mac or RStudio) .bashrc is not
>> sourced. Checo online for the file which will be sourced by the login
>> shell - different between OS and distros.
>>
>> Cheers,
>>
>> Rainer
>>
>>
>>>
>>> If I type: Sys.getenv("R_HISTFILE")
>>> the output is: ""
>>>
>>> How can I get R recognizing environment variables?
>>>
>>> Best,
>>> Luca
>>
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>
>
>
> --
> Luca Cerone
>
> Tel: +34 692 06 71 28
> Skype: luca.cerone
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/



From smartpink111 at yahoo.com  Tue Apr  1 20:37:11 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 1 Apr 2014 11:37:11 -0700 (PDT)
Subject: [R] Remove part of a summary of a model in a regression output
In-Reply-To: <CALekQEu8GfMM+qQMoxmRsH9VxHr7ZsPQibrJWGdbzpgiA4-nmQ@mail.gmail.com>
References: <CALekQEu8GfMM+qQMoxmRsH9VxHr7ZsPQibrJWGdbzpgiA4-nmQ@mail.gmail.com>
Message-ID: <1396377431.19041.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could extract the part you wanted by:

indx <- grepl("as.factor",names(mod1$coefficients))
?coef(summary(mod1))[!indx,] 

A.K.


On Tuesday, April 1, 2014 1:03 PM, Kumsa <waddeessa at gmail.com> wrote:
I would like to drop the out put part of the output that begins with
"as.factor(stratadow) in the summary of a model shown below.How can I
accomplish this task? Thanks

summary(mod1)

Family: poisson
Link function: log

Formula:
death ~ hw + temp + as.factor(stratadow)

Parametric coefficients:
? ? ? ? ? ? ? ? ? ? ? ? ?  Estimate Std. Error z value Pr(>|z|)
(Intercept)? ? ? ? ? ? ?  1.4502766? 0.3855373?  3.762 0.000169 ***
hw? ? ? ? ? ? ? ? ? ? ? ?  0.0528747? 0.1387688?  0.381 0.703183
temp? ? ? ? ? ? ? ? ? ?  -0.0010948? 0.0209806? -0.052 0.958382
as.factor(stratadow)1101? 0.1240602? 0.3351163?  0.370 0.711233
as.factor(stratadow)1102? 0.1226159? 0.3352892?  0.366 0.714588
as.factor(stratadow)1103? 0.2711197? 0.3246650?  0.835 0.403675
as.factor(stratadow)1104? 0.1746700? 0.3309611?  0.528 0.597662
as.factor(stratadow)1105? 0.0677140? 0.3407435?  0.199 0.842478
as.factor(stratadow)1106 -0.0011192? 0.3436671? -0.003 0.997402
as.factor(stratadow)1360? 0.0117679? 0.3441415?  0.034 0.972722
as.factor(stratadow)1361 -0.0489304? 0.3494791? -0.140 0.888652
as.factor(stratadow)1362? 0.1235263? 0.3349138?  0.369 0.712254

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From 538280 at gmail.com  Tue Apr  1 20:55:50 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 1 Apr 2014 12:55:50 -0600
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
Message-ID: <CAFEqCdxD7ga3Tci1pTDLZ+z_H3zJrOM7GPa68VDg=fMvSsrvfg@mail.gmail.com>

Here is one approach to generating a set (or in this case multiple
sets) of normals that sum to 0 (with a little round off error) and
works for an odd number of points:

v <- matrix(-1/8, 9, 9)
diag(v) <- 1
eigen(v)
x <- mvrnorm(100,mu=rep(0,9), Sigma=v, empirical=TRUE)
rowSums(x)
range(.Last.value)
hist(x)
sd(x)
mean(x)
apply(x,2,sd)


the key is to find the value of the off diagonals in the covariance
matrix that gives you exactly one eigenvalue that is equal to 0 (or
close enough with rounding) and all the others are positive.  There is
probably a mathematical formula that gives the exact value to use, but
I found one that works with a little trial and error (it will change
for different sample sizes).

On Tue, Apr 1, 2014 at 6:56 AM, Marc Mar? Dell'Olmo
<marceivissa at gmail.com> wrote:
> Dear all,
>
> Anyone knows how to generate a vector of Normal distributed values
> (for example N(0,0.5)), but with a sum-to-zero constraint??
>
> The sum would be exactly zero, without decimals.
>
> I made some attempts:
>
>> l <- 1000000
>> aux <- rnorm(l,0,0.5)
>> s <- sum(aux)/l
>> aux2 <- aux-s
>> sum(aux2)
> [1] -0.000000000006131392
>>
>> aux[1]<- -sum(aux[2:l])
>> sum(aux)
> [1] -0.00000000000003530422
>
>
> but the sum is not exactly zero and not all parameters are N(0,0.5)
> distributed...
>
> Perhaps is obvious but I can't find the way to do it..
>
> Thank you very much!
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From smartpink111 at yahoo.com  Tue Apr  1 21:03:11 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 1 Apr 2014 12:03:11 -0700 (PDT)
Subject: [R] Create sequential vector for values in another column
Message-ID: <1396378991.39603.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(14)
dat1 <- data.frame(shell_ID= sample(c("0208A_47_33","0208A_47_34","0912C_13_3","1400C_2_48"),20,replace=TRUE),stringsAsFactors=FALSE)
dat2 <- dat1
ord1 <- order(as.numeric(gsub("[[:alpha:]]+.*","",dat1$shell_ID)),as.numeric(gsub(".*\\_","",dat1$shell_ID)) ) 

dat1 <-  dat1[ord1,,drop=FALSE]
row.names(dat1) <- 1:nrow(dat1)
#or
library(gtools)
dat2$shell_ID <- mixedsort(dat2$shell_ID) 

identical(dat1,dat2)
#[1] TRUE 

dat1$x <- as.numeric(factor(dat1$shell_ID))
dat1?
#or

dat2$x <- match(dat1$shell_ID,unique(dat1$shell_ID)) 

all.equal(dat1,dat2)
#[1] TRUE 

A.K. 


Hi all, I am trying to do a similar thing however I would like the second vector to read as follows. shell_ID                     X
0208A_47_33             1
0208A_47_33             1
0208A_47_33             1
0208A_47_34             2
0208A_47_34             2
0208A_47_34             2
0208A_47_34             2
0208A_47_34             2
0208A_47_34             2
0208A_47_34             2
0912C_13_3               3
0912C_13_3               3
0912C_13_3               3
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4
1400C_2_48               4 However the shell_ID's may not be in any particular order as I am already using a subset of data based on another variable in R I am not familiar with how to check that the shell_IDs are sorted. The subset contains 21,005 unique shell_ID's. Thanks
Helen 




From smartpink111 at yahoo.com  Tue Apr  1 21:18:13 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 1 Apr 2014 12:18:13 -0700 (PDT)
Subject: [R] Char to Numeric --- Type Conversion
Message-ID: <1396379893.74065.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(445) 

dat1 <- as.data.frame(matrix(sample(seq(2,4,by=0.5),80,replace=TRUE),ncol=20),stringsAsFactors=FALSE) dat1[dat1==2] <- ""
dat1[,sapply(dat1,is.character)] <- lapply(dat1[,sapply(dat1,is.character)] ,as.numeric)
identical(sum(sapply(dat1,is.numeric)), ncol(dat1))
#[1] TRUE?
A.K.


Hi All, I have a dataframe with 100 columns. In some of the columns, the values are of type CHAR.
I wanted to do type conversion for the whole table, wherever I find the values to be char into Num. Regards,
Praveen 




From c-w.hoffmann at sunrise.ch  Tue Apr  1 22:13:40 2014
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Tue, 01 Apr 2014 22:13:40 +0200
Subject: [R] 127.0.0.1:22381/doc/html/index.html  won't start
Message-ID: <533B1DF4.2030003@sunrise.ch>

Dear All,

Sorry to bother you.

I am using Aquamacs 3.0a (GNU Emacs 24.3.50.2), newly installed.

Somehow, on my mac even the newly installed R3.0.3 will mill endlessly 
after M-x R waiting for

127.0.0.1:22381/doc/html/index.html

to load. How can I find out, what is wrong with my configuration?

Thanks for considering.

Christian



From c-w.hoffmann at sunrise.ch  Tue Apr  1 22:17:15 2014
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Tue, 01 Apr 2014 22:17:15 +0200
Subject: [R] 127.0.0.1:22381/doc/html/index.html  won't start 2.
Message-ID: <533B1ECB.9020504@sunrise.ch>

Dear All,

Sorry to bother you.

I am using Aquamacs 3.0a (GNU Emacs 24.3.50.2), newly installed, on Mac 
OSX 10.7.5 .

Somehow, on my mac even the newly installed R3.0.3 will mill endlessly 
after M-x R waiting for

127.0.0.1:22381/doc/html/index.html

to load. How can I find out, what is wrong with my configuration?

Thanks for considering.

Christian



From mdsumner at gmail.com  Wed Apr  2 00:20:40 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 2 Apr 2014 09:20:40 +1100
Subject: [R] Plotting Satellite
In-Reply-To: <1396372999202-4687971.post@n4.nabble.com>
References: <1396372999202-4687971.post@n4.nabble.com>
Message-ID: <CAAcGz9_of_GS7YxMf_xca_7b79sUF3DE49S9MviDOfaTwPc59w@mail.gmail.com>

Hi,

What are the columns in sat.mat?

I can see that, sat.mat[,1:2] are longitude and latitude in some form
but we don't even know what dim(sat.mat)[2] is from what you've shown.

You can avoid the loops (untested):

asub <- sat.mat[,1] >= long.min & sat.mat[,1] <= long.max &
sat.mat[,2] >= lat.min & sat.mat[,2] <= lat.max
tempo <- sat.mat[asub, ]

Note that you don't need to equate to TRUE, and & is vectorized. Your
process would have needed to zap out rows with values of zero in
tempo[,1:2] but since your longitude range straddles longitude 0 you
might have a problem there.

## basic plot
plot(tempo[,1:2], pch = ".")

Using other columns you can control the plot colours and symbols, and
there is higher-level support for these idioms in the packages you
load but haven't use. Check out R-Sig-Geo in future as a list relevant
to this topic. When posting include examples relevant only to your
question, and recreate or point to example data.

Are the data gridded?  If so I'd be going to the provider for a
sensible format and avoid this raw table thing completely. If you
can't get that use the tools in the Spatial suite to sort it out and
streamline first.

Cheers, Mike.


On Wed, Apr 2, 2014 at 4:23 AM, Dao_De <Zeef at gmx.de> wrote:
> I want to read the following file with and extract the longitude and latitude
> for certain areas.
> The file is satellite data from topex and contains the monthly wave energy
> fluxes around the worlds oceans.
>
>
> For doing that i have the following loop that reads the specific data.
>
> I then want to create a worldmap/the specific region for example the baltic
> sea or whatever, that shows the the wave energy. Also i want to plot the
> averages and the trend for the wave energy and eventually calcualte a slope
> for the wave energy over time.
>
>
>
>
> I got the following loop
>
>
>
>
> library(sp)
> library(maptools)
> library(maps)
> library(rgdal)
> library(shape)
> library(mapdata)
>
> # "pow_sat_file.txt"
>
> inputpath1<-"/Users/Sam/Desktop/MER/rem/"
> inputfile1<-paste(inputpath1,"pow_sat_file.txt",sep="")
>
> sat<-read.table("pow_sat_file.txt",header=TRUE, sep="",nrow=-1)
> sat.mat<-as.data.frame(sat)
>
> dims<-dim(sat.mat)
> tempo<-matrix(0, nrow=dims[1], ncol=dims[2])
> tempo<-data.frame(tempo)
> date<-seq(as.Date("1993/1/1"), as.Date("2005/10/1"), by="month")
>
> # France coordinates
> long.min<--6
> long.max<-10
> lat.min<-40
> lat.max<-52
>
> #Loop on "pow_sat_file.txt" to only keep the interesting points
> for (i in 1:dims[1]){
>   long<-sat.mat[i,1]
>   lat<-sat.mat[i,2]
>   if (((long>=-6 && long<=10)==TRUE ) && ((lat>=40 && lat<=52))==TRUE){
>     tempo[i,1]<-long
>     tempo[i,2]<-lat
>     for (j in 3:dims[2]){
>       tempo[i,j]<-sat.mat[i,j]
>     }
>   }
> }
>
>
> How do i continue from here to get a map of the specific region and a slope?
>
> Thx in advance
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Plotting-Satellite-tp4687971.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com



From Zeef at gmx.de  Tue Apr  1 21:06:16 2014
From: Zeef at gmx.de (Dao_De)
Date: Tue, 1 Apr 2014 12:06:16 -0700 (PDT)
Subject: [R] Plotting Satellite
In-Reply-To: <1396372999202-4687971.post@n4.nabble.com>
References: <1396372999202-4687971.post@n4.nabble.com>
Message-ID: <1396379176096-4687981.post@n4.nabble.com>

sorry i forgot to put the file; Here it is
https://www.dropbox.com/s/paau32l6bth5t8r/pow_sat_file.txt



--
View this message in context: http://r.789695.n4.nabble.com/Plotting-Satellite-tp4687971p4687981.html
Sent from the R help mailing list archive at Nabble.com.



From mlavis at syr.edu  Tue Apr  1 20:34:34 2014
From: mlavis at syr.edu (elle)
Date: Tue, 1 Apr 2014 11:34:34 -0700 (PDT)
Subject: [R] MULTIPLE LEVELS for a SINGLE VALUE in a dataframe,
 how do I remove these?
Message-ID: <1396377274424-4687977.post@n4.nabble.com>

I have a series of dates and times in one column.  They are all in the format
"%m/%d/%Y %H:%M:%S"; however, they are character values.

I have a number of problems:
1) if I use antdist$ts[1] to just examine the FIRST value of the timestamp
(ts) column, it shows that there are 144873 Levels, and it should only have
1 Level with the first value of "6/1/2013 08:07:39"; how do I delete the
remaining levels?
2) I need to change this column to a factor, so that I can use it in
functions and graph it, etc.  It's useless in this format.  I think that
once I can remove the levels, I can use as.Date or as.POSIXct to do this,
but I need to figure out what's happening in the first part of the question.

Here's the R code for just looking at the first value of the timestamp
column:
> antdist$ts[1]
[1] 6/1/2013 08:07:39
144873 Levels: 6/1/2013 08:07:39 6/1/2013 08:07:41 6/1/2013 08:07:43
6/1/2013 08:07:45 ... 8/2/2013 11:47:51

Here's a photo of what the first few rows of the timestamp column look like
using View(antdist):
<http://r.789695.n4.nabble.com/file/n4687977/Capture.jpg> 

Thank you, thank you, thank you for your help!



--
View this message in context: http://r.789695.n4.nabble.com/MULTIPLE-LEVELS-for-a-SINGLE-VALUE-in-a-dataframe-how-do-I-remove-these-tp4687977.html
Sent from the R help mailing list archive at Nabble.com.



From romartin at vtr.net  Tue Apr  1 23:58:17 2014
From: romartin at vtr.net (Rodrigo Martinez Flores)
Date: Tue, 01 Apr 2014 18:58:17 -0300
Subject: [R] Process Forked at MAC
Message-ID: <web-12701505@b2.vtr.net>

Dear Guys..

Thank you very much for taking time to answer these questions.

I 'm running simple command directly on R console:

> corpus=tm_map(corpus,tolower)
giving this result:
The process has forked and you cannot use this CoreFoundation 
functionality safely. You MUST exec(). Once and again.

tm and SnowballC installed.
Runing: R 3.0.3 GUI 1.63 Snow Leopard build (6660)

I tried restarting system, deleting start-up sw, but nothing.   Your 
help will be much appreciated.

Thank you.   Rodrigo.

Hardware info:

   Nombre del modelo:	MacBook Air
   Identificador del modelo:	MacBookAir4,2
   Nombre del procesador:	Intel Core i5
   Velocidad del procesador:	1,7 GHz
   Cantidad de procesadores:	1
   Cantidad total de n?cleos:	2
   Cach? de nivel 2 (por n?cleo):	256 KB
   Cach? de nivel 3:	3 MB
   Memoria:	4 GB
   Versi?n de la ROM de arranque:	MBA41.0077.B0F
   Versi?n SMC (sistema):	1.73f66
   N?mero de serie (sistema):	C02GTG2WDJWT
   UUID de hardware:	96E5DEFD-3601-54ED-BB3B-4AF4DAC2F775

Software:

   Versi?n del sistema:	Mac OS X 10.7.5 (11G63b)
   Versi?n del kernel:	Darwin 11.4.2
   Volumen de arranque:	Macintosh HD
   Modo de arranque:	Normal
   Memoria virtual segura:	Activado
   Extensiones y kernel de 64 bits:	S?
   Tiempo desde el arranque:	1:24



From murdoch.duncan at gmail.com  Wed Apr  2 01:05:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 01 Apr 2014 19:05:37 -0400
Subject: [R] 127.0.0.1:22381/doc/html/index.html  won't start
In-Reply-To: <533B1DF4.2030003@sunrise.ch>
References: <533B1DF4.2030003@sunrise.ch>
Message-ID: <533B4641.6060009@gmail.com>

On 01/04/2014, 4:13 PM, Christian Hoffmann wrote:
> Dear All,
>
> Sorry to bother you.
>
> I am using Aquamacs 3.0a (GNU Emacs 24.3.50.2), newly installed.
>
> Somehow, on my mac even the newly installed R3.0.3 will mill endlessly
> after M-x R waiting for
>
> 127.0.0.1:22381/doc/html/index.html
>
> to load. How can I find out, what is wrong with my configuration?

There is an ESS-specific help list; you might have better luck there: 
https://stat.ethz.ch/mailman/listinfo/ess-help.

Duncan Murdoch
>
> Thanks for considering.
>
> Christian
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From kridox at ymail.com  Wed Apr  2 04:01:33 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 2 Apr 2014 11:01:33 +0900
Subject: [R] Centered difference operation on matrix with R
In-Reply-To: <CAAcyNCyGnV9djYpXJv6XS+dywqt3hF0=WThF+GJqsfWTq6Kd-Q@mail.gmail.com>
References: <CAAcyNCyGnV9djYpXJv6XS+dywqt3hF0=WThF+GJqsfWTq6Kd-Q@mail.gmail.com>
Message-ID: <CAAcyNCwgBLCunjVDOJp4rMBv6V+0aW27bis4ZnjN7_0-X1v4Fg@mail.gmail.com>

Dear list members,

The answer is in package "pracma", function "gradient".

Regards,
Pascal Oettli

On Fri, Mar 28, 2014 at 2:51 PM, Pascal Oettli <kridox at ymail.com> wrote:
> Dear list members,
>
> I am wondering whether there is any more efficient way to calculate
> centered difference on matrix in R? Please see herewith an example:
>
> lon <- matrix(rep(seq(0,2,length.out=1e3), 1e3), 1e3, 1e3)
> lat <- matrix(rep(seq(0,2,length.out=1e3), each=1e3), 1e3, 1e3)
> x <- matrix(rep(seq(0.01,2,length.out=1e3), 1e3), 1e3, 1e3)
> y <- matrix(rep(seq(0.01,2,length.out=1e3), each=1e3), 1e3, 1e3)
> u <- y * cos(x)
> v <- y * sin(x)
>
> to.rad <- pi/180
> dx <- diff(lon,2); dx <- rbind(NA,dx,NA); dx <- dx*to.rad
> dy <- t(diff(t(lat),2)); dy <- cbind(NA,dy,NA); dy <- dy*to.rad
>
> du <- t(diff(t(u * cos(lat*to.rad)),2)); du <- cbind(NA,du,NA)
> dv <- diff(v,2); dv <- rbind(NA,dv,NA)
>
> Best Regards,
> Pascal Oettli



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From kridox at ymail.com  Wed Apr  2 04:20:40 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 2 Apr 2014 11:20:40 +0900
Subject: [R] labelling a plot in binom library function call
In-Reply-To: <1396305660.70738.YahooMailNeo@web162504.mail.bf1.yahoo.com>
References: <1396305660.70738.YahooMailNeo@web162504.mail.bf1.yahoo.com>
Message-ID: <CAAcyNCwYJKH66y8c-Zc3zr=02TtH-JmVfakknZ7V41TL49rGcw@mail.gmail.com>

Hello,

The "binom" package is using "ggplot2" to plot the density. Thus, you
have to follow the "ggplot2" syntax:

R>  binom.bayes.densityplot(hpdc) + ggtitle("my plot")

HTH
Pascal

On Tue, Apr 1, 2014 at 7:41 AM, Chris <chris.barker at barkerstats.com> wrote:
> Hi, I'm using  a function in the binom library. I'd like to add a title(s) to the plot generated by "binom.bayes.densityplot".
>
> I get an error message when trying to use the title function
> The error message is: "Error in title(main = "my plot") : plot.new has not been called yet" occurs after running the title command".
>
> Example code:
>
> hpdc <- binom.bayes(
> x = 0:10, n = 10, type = "central", conf.level = 0.8, tol = 1e-9)
> print(hpdc)
> binom.bayes.densityplot(hpdc)
> title(main="my plot")
>
>
> I was also unsuccessful in passing a plot title to the function call.
>
> And issuing a "plot.new()" before the title command clears the plot.
>
> Thanks in advance for suggestions.
>
>
>
> Chris Barker, Ph.D.
> Adjunct Associate Professor of Biostatistics - UIC-SPH
> and
> President and Owner
> Statistical Planning and Analysis Services, Inc.
> www.barkerstats.com
> 415 609 7473415 609 7473
> skype: barkerstats
>
>
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From alj27 at georgetown.edu  Wed Apr  2 05:51:34 2014
From: alj27 at georgetown.edu (Aimee Kopolow)
Date: Tue, 1 Apr 2014 23:51:34 -0400
Subject: [R] Difficulty coding time-forced functions in deSolve
Message-ID: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>

Hi all,

I'm trying to use deSolve to solve a series of differential equations
with rk4 mimicking a SEIR model,  while including an event/function
that is not solely time-dependent.

Explicitly:
I want to introduce vaccination 7 days after the proportion of I2/N2
reaches 0.01.


Here is the code I am using:


require(deSolve)

require(sfsmisc)


SEIR <- function(t, x, p) {

with(as.list(c(x,p)),{





dS<-b*N-d*S-beta*S*I/N-V(I, N, t)*S


dE<- -d*E+beta*S*I/N -epsilon*E-V(I, N, t)*E


dI<- -d*I+epsilon*E-gamma*I-mu*I-V(I, N, t)*I


dR<--d*R+gamma*I+V(I, N, t)*S+V(I, N, t)*E+V(I, N, t)*I


dN<-dS+dE+dI+dR


list(c(dS, dE, dI, dR, dN))




})

}

V <-function(I, N, t) {ifelse(t >=8 & I[t-7]/N[t-7]>0.01, 0.25, 0)}

num_years <- 10.0

time_limit <-num_years*365.00


Ni <-1.0E3

b <-1/(10.0*365)

d <-b

beta <-0.48

epsilon <-1/4

gamma <-1/4

mu <--log(1-0.25)*gamma


parms <-c(Ni=Ni, b=b, d=d, beta=beta, epsilon=epsilon, gamma=gamma, mu=mu)

xstart <-c(S=999, E=0, I=1, R=0, N=1000)


 times   <- seq(0.0, time_limit, 1.0)

        tol <- 1e-16

        my.atol <- rep(tol,5)

        my.rtol <- 1e-12

 out_rk4 <-  as.data.frame(rk4(xstart, times, SEIR, parms))



  outfilename <- paste("Basic SEIR.csv")



   write.csv(out_rk4,file=outfilename,row.names=FALSE, col.names=FALSE)



If I remove function V and the associated parts within the
differential equations, the model runs just fine. If I define V as
V<-function(I, N) {ifelse(I/N >0.01, 0.25, 0)
the model functions just fine.

Any pointers as to how I can code a function that relies on solutions
from previous time steps?

thank you in advance,
Aimee.



From frtog at vestas.com  Wed Apr  2 07:29:21 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 2 Apr 2014 07:29:21 +0200
Subject: [R] MULTIPLE LEVELS for a SINGLE VALUE in a dataframe,
 how do I remove these?
In-Reply-To: <1396377274424-4687977.post@n4.nabble.com>
References: <1396377274424-4687977.post@n4.nabble.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C57B602C@DKRDSEXC016.vestas.net>

Hi 'What is your name?'

When you read the data into R the first column was interpreted as a factor where the levels are the timestamps. If you used read.table() there is the stringsAsFactor you can set to FALSE so that the first column will be read in as strings instead of a factor.

However you can now do this.

antdist$ts <- as.character(antdist$ts)

antdist$ts <- as.POSIXct(strptime(antdist$ts, format = "%m/%d/%Y %H:%M:%S"))


See ?factor, ?as.POSIXct, ?strptime


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of elle
> Sent: 1. april 2014 20:35
> To: r-help at r-project.org
> Subject: [R] MULTIPLE LEVELS for a SINGLE VALUE in a dataframe, how do I
> remove these?
> 
> I have a series of dates and times in one column.  They are all in the format
> "%m/%d/%Y %H:%M:%S"; however, they are character values.
> 
> I have a number of problems:
> 1) if I use antdist$ts[1] to just examine the FIRST value of the timestamp
> (ts) column, it shows that there are 144873 Levels, and it should only have
> 1 Level with the first value of "6/1/2013 08:07:39"; how do I delete the
> remaining levels?
> 2) I need to change this column to a factor, so that I can use it in
> functions and graph it, etc.  It's useless in this format.  I think that
> once I can remove the levels, I can use as.Date or as.POSIXct to do this,
> but I need to figure out what's happening in the first part of the question.
> 
> Here's the R code for just looking at the first value of the timestamp
> column:
> > antdist$ts[1]
> [1] 6/1/2013 08:07:39
> 144873 Levels: 6/1/2013 08:07:39 6/1/2013 08:07:41 6/1/2013 08:07:43
> 6/1/2013 08:07:45 ... 8/2/2013 11:47:51
> 
> Here's a photo of what the first few rows of the timestamp column look like
> using View(antdist):
> <http://r.789695.n4.nabble.com/file/n4687977/Capture.jpg>
> 
> Thank you, thank you, thank you for your help!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/MULTIPLE-
> LEVELS-for-a-SINGLE-VALUE-in-a-dataframe-how-do-I-remove-these-
> tp4687977.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From marlinkcox at gmail.com  Wed Apr  2 08:16:38 2014
From: marlinkcox at gmail.com (Marlin Keith Cox)
Date: Tue, 1 Apr 2014 22:16:38 -0800
Subject: [R] Time series
Message-ID: <CAHskWAU2CLXww+zN35CZfCibTfogQM9QWYpjaAbiifUSQfviRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140401/13b65c65/attachment-0001.pl>

From Achim.Zeileis at uibk.ac.at  Wed Apr  2 08:26:29 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 2 Apr 2014 08:26:29 +0200 (CEST)
Subject: [R] Time series
In-Reply-To: <CAHskWAU2CLXww+zN35CZfCibTfogQM9QWYpjaAbiifUSQfviRg@mail.gmail.com>
References: <CAHskWAU2CLXww+zN35CZfCibTfogQM9QWYpjaAbiifUSQfviRg@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1404020825001.29684@paninaro.uibk.ac.at>

On Tue, 1 Apr 2014, Marlin Keith Cox wrote:

> A simplified ask is:  when I use the time series plot function, R treats
> each time on 9/19/13 as an individual day, when clearly it isn't.

The "ts" class can handle only regular time series. See the "zoo" or "xts" 
packages for dealing with time series that have an irregular time index. 
Here, you could use POSIXct or chron time stamps.

> Thank you ahead of time.  Keith
>
> ts(chum)
> with(chum,plot.ts(Time,PA))
>
> Chum<-
>
>  Time PA  9/18/13 18:29 16  9/19/13 13:29 14  9/19/13 16:29 13.2  9/19/13
> 17:29 13.1  9/19/13 18:29 13  9/20/13 18:29 12  9/21/13 18:29 10  9/22/13
> 18:29 9  9/23/13 18:29 7  9/24/13 18:29 5  9/25/13 18:29 3  9/26/13
> 18:29 2  9/27/13
> 18:29 1
>
>
> M. Keith Cox, Ph.D.
> Principal
> MKConsulting
> 17105 Glacier Hwy
> Juneau, AK 99801
> U.S. 907.957.4606
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From kridox at ymail.com  Wed Apr  2 08:26:49 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 2 Apr 2014 15:26:49 +0900
Subject: [R] Time series
In-Reply-To: <CAHskWAU2CLXww+zN35CZfCibTfogQM9QWYpjaAbiifUSQfviRg@mail.gmail.com>
References: <CAHskWAU2CLXww+zN35CZfCibTfogQM9QWYpjaAbiifUSQfviRg@mail.gmail.com>
Message-ID: <CAAcyNCx2tEFYOx1NsrFMvi1AxjPTMRy=oj-3sqgw5uUufhJU4Q@mail.gmail.com>

Hello Keith,

Your example is clearly not reproducible and wrong (Chum and chum).
Please use dput() to attach sample dataset.
At first glance, you work with hourly data. Package such as "xts"
might be more useful.

Regards,
Pascal

On Wed, Apr 2, 2014 at 3:16 PM, Marlin Keith Cox <marlinkcox at gmail.com> wrote:
> A simplified ask is:  when I use the time series plot function, R treats
> each time on 9/19/13 as an individual day, when clearly it isn't.
>
> Thank you ahead of time.  Keith
>
> ts(chum)
> with(chum,plot.ts(Time,PA))
>
> Chum<-
>
>   Time PA  9/18/13 18:29 16  9/19/13 13:29 14  9/19/13 16:29 13.2  9/19/13
> 17:29 13.1  9/19/13 18:29 13  9/20/13 18:29 12  9/21/13 18:29 10  9/22/13
> 18:29 9  9/23/13 18:29 7  9/24/13 18:29 5  9/25/13 18:29 3  9/26/13
> 18:29 2  9/27/13
> 18:29 1
>
>
> M. Keith Cox, Ph.D.
> Principal
> MKConsulting
> 17105 Glacier Hwy
> Juneau, AK 99801
> U.S. 907.957.4606
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From hb at biostat.ucsf.edu  Wed Apr  2 08:45:48 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 1 Apr 2014 23:45:48 -0700
Subject: [R] pre-allocation not always a timesaver
In-Reply-To: <1393559600.27870.36.camel@localhost>
References: <1393559600.27870.36.camel@localhost>
Message-ID: <CAFDcVCQowWQDEnJk3h8Z-L+-M1kYR1QRTrO8GgPnh_w9GSw85Q@mail.gmail.com>

I don't think you got a response to this one;

    x <- array(dim=(c(j, n)))
    for (i in 1:n) {
        x[,i] <- rnorm(j)
    }

Note that array() allocates a logical array by default, which means
that in your first iteration (i==1) it has to be coerced to a double
array before assigning the value of rnorm(). That takes time. It also
takes time to garbage collect the "stray" logical array afterward.
Using,

    x <- array(NA_real_, dim=(c(j, n)))
    for (i in 1:n) {
        x[,i] <- rnorm(j)
    }

avoids this.

For updating list elements, you can avoid repetitive overhead from $<-
and $ by replacing:

   a$myx <- array(dim=c(j, n))
    for (i in 1:n) {
       a$myx[,i] <- rnorm(j)
    }
    a$myx

with

   myx <- array(NA_real, dim=c(j, n))
    for (i in 1:n) {
       myx[,i] <- rnorm(j)
    }
    a$myx <- myx
    myx

Similarly for S4 slots and @<- and @.

/Henrik

On Thu, Feb 27, 2014 at 7:53 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> The R Inferno advises that if you are building up results in pieces it's
> best to pre-allocate the result object and fill it in.  In some testing,
> I see a benefit with this strategy for regular variables.  However, when
> the results are held by a class, the opposite seems to be the case.
>
> Comments?  Explanations?
>
> Possibly for classes any update causes the entire object to be
> replaced--perhaps to trigger the validation machinery?--and so
> preallocation simply means on average a bigger object is being
> manipulated.
>
> Here is some test code, with CPU seconds given in the comments.  I tried
> everything twice in case there was some "first-time" overhead such as
> growing total memory in the image.  When the 2 times differed noticeably
> I reported both values.
>
> # class definitions
> refbase <- setRefClass("refBase", fields = list(dispatch="ANY", myx="ANY"),
>                        methods = list( initialize = function(x0=NULL, ...) {
>                            usingMethods("foo")
>                            dispatch <<- foo
>                            myx <<- x0
>                        }
> # some irrelevant methods edited out
>                        ))
>
> myclass <- setClass("simple", representation=list(myx="ANY"))
>
> ### Method 1: regular variables
> pre <- function(n, j=1000) {
>     x <- array(dim=(c(j, n)))
>     for (i in 1:n) {
>         x[,i] <- rnorm(j)
>     }
>     x
> }
> system.time(pre(1000)) #0.3s
>
> nopre <- function(n, j=1000) {
>     x <- numeric(0)
>     for (i in 1:n)
>         x <- c(x, rnorm(j))
>     x
> }
>
> system.time(nopre(1000))  # 2.0s, 2.7s
>
> # Method 2: with ref class
> pre2 <- function(n, j=1000) {
>     a <- refbase(x0=numeric(0))
>     a$myx <- array(dim=c(j, n))
>     for (i in 1:n) {
>         a$myx[,i] <- rnorm(j)
>     }
>     a$myx
> }
> system.time(pre2(1000)) # 4.0 s
>
> nopre2 <- function(n, j=1000) {
>     a <- refbase(x0=numeric(0))
>     for (i in 1:n)
>         a$myx <- c(a$myx, rnorm(j))
>     a$myx
> }
> system.time(nopre2(1000)) # 2.9s, 4.3
>
> # Method 3: with regular class
> pre3 <- function(n, j=1000) {
>     a <- myclass()
>     a at myx <- array(dim=c(j, n))
>     for (i in 1:n) {
>         a at myx[,i] <- rnorm(j)
>     }
>     a at myx
> }
> system.time(pre3(1000)) # 7.3 s
>
> nopre3 <- function(n, j=1000) {
>     a <- myclass(myx=numeric(0))
>     for (i in 1:n)
>         a at myx <- c(a at myx, rnorm(j))
>     a at myx
> }
> system.time(nopre3(1000))  # 4.2s
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From thpe at simecol.de  Wed Apr  2 08:47:32 2014
From: thpe at simecol.de (Thomas Petzoldt)
Date: Wed, 02 Apr 2014 08:47:32 +0200
Subject: [R] Difficulty coding time-forced functions in deSolve
In-Reply-To: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
Message-ID: <533BB284.4080801@simecol.de>

On 4/2/2014 5:51 AM, Aimee Kopolow wrote:

> Any pointers as to how I can code a function that relies on solutions
> from previous time steps?

Such a system would be called a delay differential equation (DDE). It 
can be solved with the dede function, see ?dede for details.

However if you want to model something like this:

 > Explicitly:
 > I want to introduce vaccination 7 days after the proportion of I2/N2
 > reaches 0.01.


Than this is called "root finding", that can be combined with events, 
see example "EVENTS triggered by a root function" in ?events.

More can be found in the papers listed at:

http://desolve.r-forge.r-project.org

... or you may consider to ask the R-sig-dynamic models mailing list:

https://stat.ethz.ch/mailman/listinfo/r-sig-dynamic-models

Hope it helps

Thomas Petzoldt

Dr. Thomas Petzoldt
Technische Universitaet Dresden
Faculty of Environmental Sciences
Institute of Hydrobiology
01062 Dresden, Germany

http://tu-dresden.de/Members/thomas.petzoldt



From frtog at vestas.com  Wed Apr  2 09:01:02 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 2 Apr 2014 09:01:02 +0200
Subject: [R] A vector of normal distributed values with a
	sum-to-zero	constraint
In-Reply-To: <CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>
	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>
	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>
	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>
	<CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C57B60A9@DKRDSEXC016.vestas.net>

Hi Marc

I think that we could help you better if we knew in which context you need sample from a sum constrained normal distribution. However this is more a question on probability theory than on how to do it in R.

The proposal so far has been linear transformation of multivariate normal distribution (Marc, Rui), mixture of normal and reflected normal distribution (Boris, try that with e.g. mu = 2), normal distribution mixed with single point with positive mass (Jlucke), degenerated normal distribution (Greg).

What you in fact want to do is to draw samples from a conditional distribution. The condition is the sum constraint so if we have x = (x1, x2, ..., xn) then sum_{i=1}^n xi = 0 or x1 + x2 + ... x{n-1} = xn so you want to draw samples from P(x given that x is normal distributed and sum(x)=0). The sum constraint gives in fact what is called distributions on the simplex. Google for "normal distribution simplex" and you will get almost 2 mill hits. The second shows how to sample using Gibbs sampling (http://dobigeon.perso.enseeiht.fr/papers/Dobigeon_TechReport_2007b.pdf).

However you can probably just use other distributions given sum constraint since you say that you only need the sample as initial values for a MCMC algorithm. Many methods are available from "compositional statistics" (google for that, Aitchison 1986 is the pioneer). 

At least two packages are available for R:"compositions" with the latest version from 2013 and can be found in the archives and "robComposition" still maintained.

Hope that helps, it is help for yourself to find a solution.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Marc Mar? Dell'Olmo
> Sent: 1. april 2014 16:57
> To: Boris Steipe
> Cc: r-help at r-project.org
> Subject: Re: [R] A vector of normal distributed values with a sum-to-zero
> constraint
> 
> Boris is right. I need this vector to include as initial values of a
> MCMC process (with openbugs) and If I use this last approach sum(x)
> could be a large (or extreme) value and can cause problems.
> 
> The other approach x <- c(x, -x) has the problem that only vectors
> with even values are obtained.
> 
> Thank you!
> 
> 
> 2014-04-01 16:25 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
> > But the result is not Normal. Consider:
> >
> > set.seed(112358)
> > N <- 100
> > x <- rnorm(N-1)
> > sum(x)
> >
> > [1] 1.759446   !!!
> >
> > i.e. you have an outlier at 1.7 sigma, and for larger N...
> >
> > set.seed(112358)
> > N <- 10000
> > x <- rnorm(N-1)
> > sum(x)
> > [1] -91.19731
> >
> > B.
> >
> >
> > On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:
> >
> >> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of
> N samples, only (N-1) can be random.   Thus the solution is
> >> > N <- 100
> >> > x <- rnorm(N-1)
> >> > x <- c(x, -sum(x))
> >> > sum(x)
> >> [1] -7.199102e-17
> >>
> >> >
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> Boris Steipe <boris.steipe at utoronto.ca>
> >> Sent by: r-help-bounces at r-project.org
> >> 04/01/2014 09:29 AM
> >>
> >> To
> >> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
> >> cc
> >> "r-help at r-project.org" <r-help at r-project.org>
> >> Subject
> >> Re: [R] A vector of normal distributed values with a sum-to-zero
> constraint
> >>
> >>
> >>
> >>
> >>
> >> Make a copy with opposite sign. This is Normal, symmetric, but no longer
> random.
> >>
> >>  set.seed(112358)
> >>  x <- rnorm(5000, 0, 0.5)
> >>  x <- c(x, -x)
> >>  sum(x)
> >>  hist(x)
> >>
> >> B.
> >>
> >> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
> >>
> >> > Dear all,
> >> >
> >> > Anyone knows how to generate a vector of Normal distributed values
> >> > (for example N(0,0.5)), but with a sum-to-zero constraint??
> >> >
> >> > The sum would be exactly zero, without decimals.
> >> >
> >> > I made some attempts:
> >> >
> >> >> l <- 1000000
> >> >> aux <- rnorm(l,0,0.5)
> >> >> s <- sum(aux)/l
> >> >> aux2 <- aux-s
> >> >> sum(aux2)
> >> > [1] -0.000000000006131392
> >> >>
> >> >> aux[1]<- -sum(aux[2:l])
> >> >> sum(aux)
> >> > [1] -0.00000000000003530422
> >> >
> >> >
> >> > but the sum is not exactly zero and not all parameters are N(0,0.5)
> >> > distributed...
> >> >
> >> > Perhaps is obvious but I can't find the way to do it..
> >> >
> >> > Thank you very much!
> >> >
> >> > Marc
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Wed Apr  2 09:54:07 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 2 Apr 2014 09:54:07 +0200
Subject: [R] A vector of normal distributed values with a sum-to-zero
	constraint
In-Reply-To: <533AD9CC.9030505@sapo.pt>
References: <CAAZSCQ7EYSK0rBni=io3h4tC9kh0mYWnvycpQSWSTDpBA+R+HQ@mail.gmail.com>	<CA8F8699-B734-47A5-AD25-6D830EFF72F2@utoronto.ca>	<OFF245067B.A0840EBA-ON85257CAD.004DAB1A-85257CAD.004E33D1@ria.buffalo.edu>	<AF9167BC-825F-4129-933E-4C70E1736D32@utoronto.ca>	<CAAZSCQ5BQnekPeg4i=nUVaOPHcTsdWE_nm_-t6AnVP1HcmaX4g@mail.gmail.com>
	<OF9B2CAE81.FA80D99A-ON85257CAD.00526CD1-85257CAD.00528241@ria.buffalo.edu>
	<533AD9CC.9030505@sapo.pt>
Message-ID: <9662FB54-0366-45B3-AA49-FB349308502B@gmail.com>


On 01 Apr 2014, at 17:22 , Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> One way is to use ?scale.
> 

...except that the sd will be less than 0.5 (not obvious at n=1e6, though). However, if you want

- normal distribution
- symmetry
- constant marginal variance of sigma^2
- fixed sum = 0 

I don't see any way more straightforward than generating n normal variates and subtracting the mean. The only snag is that the variance of a residual is sigma^2(1-1/n), so generate the original data with a variance of sigma^2/(1-1/n) = n/(n-1) sigma^2

I.e.

x <- rnorm(n,0,0.5*sqrt(n/(n-1)))
x <- x - mean(x) 

All of this applies within the boundaries of numerical precision. You're not going to beat the FPU:

> n <- 1e6
> x <- rnorm(n,0,0.5*sqrt(n/(n-1)))
> x <- x - mean(x) 
> sum(x)
[1] -1.625718e-11
> mean(x)
[1] -1.452682e-17

The problem of getting a sum or mean of _exactly_ 0 is just not well-defined, since sums and averages depend on the summation order:

> sum(x)
[1] -1.625718e-11
> sum(sample(x))
[1] -1.624851e-11
> sum(sort(x))
[1] -1.508771e-11
> sum(rev(sort(x)))
[1] -1.599831e-11


 


> set.seed(4867)
> l <- 1000000
> aux <- rnorm(l, 0, 0.5)
> aux <- scale(aux, scale = FALSE)
> sum(aux)
> 
> hist(aux, prob = TRUE)
> curve(dnorm(x, 0, 0.5), from = -2, to = 2, add = TRUE)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 01-04-2014 16:01, JLucke at ria.buffalo.edu escreveu:
>> Then what's wrong with centering your initial values around the mean?
>> 
>> 
>> 
>> Marc Mar? Dell'Olmo <marceivissa at gmail.com>
>> 04/01/2014 10:56 AM
>> 
>> To
>> Boris Steipe <boris.steipe at utoronto.ca>,
>> cc
>> JLucke at ria.buffalo.edu, "r-help at r-project.org" <r-help at r-project.org>
>> Subject
>> Re: [R] A vector of normal distributed values with a sum-to-zero
>> constraint
>> 
>> 
>> 
>> 
>> 
>> 
>> Boris is right. I need this vector to include as initial values of a
>> MCMC process (with openbugs) and If I use this last approach sum(x)
>> could be a large (or extreme) value and can cause problems.
>> 
>> The other approach x <- c(x, -x) has the problem that only vectors
>> with even values are obtained.
>> 
>> Thank you!
>> 
>> 
>> 2014-04-01 16:25 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>> But the result is not Normal. Consider:
>>> 
>>> set.seed(112358)
>>> N <- 100
>>> x <- rnorm(N-1)
>>> sum(x)
>>> 
>>> [1] 1.759446   !!!
>>> 
>>> i.e. you have an outlier at 1.7 sigma, and for larger N...
>>> 
>>> set.seed(112358)
>>> N <- 10000
>>> x <- rnorm(N-1)
>>> sum(x)
>>> [1] -91.19731
>>> 
>>> B.
>>> 
>>> 
>>> On 2014-04-01, at 10:14 AM, JLucke at ria.buffalo.edu wrote:
>>> 
>>>> The sum-to-zero constraint imposes a loss of one degree of freedom.  Of
>>  N samples, only (N-1) can be random.   Thus the solution is
>>>>> N <- 100
>>>>> x <- rnorm(N-1)
>>>>> x <- c(x, -sum(x))
>>>>> sum(x)
>>>> [1] -7.199102e-17
>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Boris Steipe <boris.steipe at utoronto.ca>
>>>> Sent by: r-help-bounces at r-project.org
>>>> 04/01/2014 09:29 AM
>>>> 
>>>> To
>>>> Marc Mar? Dell'Olmo <marceivissa at gmail.com>,
>>>> cc
>>>> "r-help at r-project.org" <r-help at r-project.org>
>>>> Subject
>>>> Re: [R] A vector of normal distributed values with a sum-to-zero
>> constraint
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Make a copy with opposite sign. This is Normal, symmetric, but no
>> longer random.
>>>> 
>>>>  set.seed(112358)
>>>>  x <- rnorm(5000, 0, 0.5)
>>>>  x <- c(x, -x)
>>>>  sum(x)
>>>>  hist(x)
>>>> 
>>>> B.
>>>> 
>>>> On 2014-04-01, at 8:56 AM, Marc Mar? Dell'Olmo wrote:
>>>> 
>>>>> Dear all,
>>>>> 
>>>>> Anyone knows how to generate a vector of Normal distributed values
>>>>> (for example N(0,0.5)), but with a sum-to-zero constraint??
>>>>> 
>>>>> The sum would be exactly zero, without decimals.
>>>>> 
>>>>> I made some attempts:
>>>>> 
>>>>>> l <- 1000000
>>>>>> aux <- rnorm(l,0,0.5)
>>>>>> s <- sum(aux)/l
>>>>>> aux2 <- aux-s
>>>>>> sum(aux2)
>>>>> [1] -0.000000000006131392
>>>>>> 
>>>>>> aux[1]<- -sum(aux[2:l])
>>>>>> sum(aux)
>>>>> [1] -0.00000000000003530422
>>>>> 
>>>>> 
>>>>> but the sum is not exactly zero and not all parameters are N(0,0.5)
>>>>> distributed...
>>>>> 
>>>>> Perhaps is obvious but I can't find the way to do it..
>>>>> 
>>>>> Thank you very much!
>>>>> 
>>>>> Marc
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From zsurzsalaszlo at gmail.com  Wed Apr  2 12:24:26 2014
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Wed, 2 Apr 2014 12:24:26 +0200
Subject: [R] mzR and Rcpp version bug
Message-ID: <CAF4U=VnFrAmDwN=_hy6BmRM+1Z4s0=nf4p3DS9mck0DzqEizeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/880393b3/attachment-0001.pl>

From my.r.help at gmail.com  Wed Apr  2 13:32:26 2014
From: my.r.help at gmail.com (Michael Smith)
Date: Wed, 02 Apr 2014 19:32:26 +0800
Subject: [R] Strange sprintf Behavior
In-Reply-To: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
Message-ID: <533BF54A.6090003@gmail.com>

All,

I'm getting this:

> sprintf("%.17f", 0.8)
[1] "0.80000000000000004"

Where does the `4` at the end come from? Shouldn't it be zero at the
end? Maybe I'm missing something.

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
LC_TIME=en_US.utf8
 [4] LC_COLLATE=en_US.utf8     LC_MONETARY=en_US.utf8
LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C                 LC_ADDRESS=C

[10] LC_TELEPHONE=C            LC_MEASUREMENT=en_US.utf8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Thanks,

M



From marc_schwartz at me.com  Wed Apr  2 14:17:11 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 02 Apr 2014 07:17:11 -0500
Subject: [R] Strange sprintf Behavior
In-Reply-To: <533BF54A.6090003@gmail.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
	<533BF54A.6090003@gmail.com>
Message-ID: <0844EE94-A3F9-4C65-8488-37F07EF325BB@me.com>


On Apr 2, 2014, at 6:32 AM, Michael Smith <my.r.help at gmail.com> wrote:

> All,
> 
> I'm getting this:
> 
>> sprintf("%.17f", 0.8)
> [1] "0.80000000000000004"
> 
> Where does the `4` at the end come from? Shouldn't it be zero at the
> end? Maybe I'm missing something.


Hi,

First, please start a new thread when posting, do not just reply to an existing thread and change the subject line. Your post gets lost in the archive and is improperly linked to other posts.

Second, see the Most Frequently Asked Question:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Regards,

Marc Schwartz



From sporter at ori.org.za  Wed Apr  2 14:21:20 2014
From: sporter at ori.org.za (Sean Porter)
Date: Wed, 2 Apr 2014 14:21:20 +0200
Subject: [R] gradientForest input data structure
Message-ID: <00e501cf4e6e$0e039a80$2a0acf80$@ori.org.za>

Dear All,

Following on from my last post (randomForest warning: The response has five
or fewer unique values. Are you sure you want to do regression?) which
presented two problems whilst trying to conduct a gradientForest regression,
the warning I got was not an issue as Andy kindly pointed out, but I still
have the second problem relating to the data structure of my input data and
I would really appreciate your help on this. I think this is simply a data
structure issue and nothing specific to gradientForest.

I am a relative beginner to R (also not a mathematician) and have tried to
figure out how the data is structured to get the analysis to work but to no
avail. I can run the analysis with the data provided within the
gradientForest package according to the instructions but when I try it with
my own data it doesn?t work and it does not consider all the response
variables (please see output in the previous post below). So my
understanding is that gradientForest regression requires a set of response
variables and a set of predictor variables which then need to be combined.
The structure of the predictor variables according to the example data
accompanying the gradientForest package is:

load("GZ.phys.site.Rdata")
> str(Phys_site)
'data.frame':   197 obs. of  28 variables:
 $ BATHY  : num  -16.7 -26.6 -32.8 -32.5 -29.7 ...
 $ SLOPE  : num  0.505 0.784 0.12 0.332 0.467 ...
 $ ASPECT : num  234 116 192 172 230 ...
 $ BSTRESS: num  0.218 0.248 0.322 0.374 0.425 ...
 $ CRBNT  : num  98.5 98 98.9 98.3 97.9 ...
 $ GRAVEL : num  39.3 39.2 30 42.4 38.8 ...
 $ SAND   : num  59.7 59.8 63.9 54.9 62.7 ...
 $ MUD    : num  3.16e-07 2.76e-02 5.17 9.22e-01 2.38 ...
 $ NO3_AV : num  0.24 0.3 0.24 0.26 0.3 0.24 0.25 0.24 0.23 0.25 ...
 $ NO3_SR : num  0.33 0.39 0.29 0.16 0.2 0.33 0.31 0.35 0.39 0.19 ...
 $ PO4_AV : num  0.15 0.15 0.15 0.15 0.16 0.16 0.16 0.16 0.15 0.15 ...
 $ PO4_SR : num  0.08 0.08 0.07 0.05 0.08 0.07 0.07 0.08 0.08 0.06 ...
 $ O2_AV  : num  4.42 4.44 4.39 4.35 4.33 4.38 4.34 4.37 4.4 4.34 ...
 $ O2_SR  : num  0.4 0.49 0.28 0.26 0.24 0.32 0.27 0.36 0.43 0.24 ...
 $ S_AV   : num  34.9 34.9 35 34.9 34.9 ...
 $ S_SR   : num  1.47 1.29 1.64 1.57 1.58 1.8 1.94 1.81 1.7 1.83 ...
 $ T_AV   : num  28.2 28 28.3 28.6 28.5 ...
 $ T_SR   : num  2.19 2.79 1.8 1.99 2.12 2.03 2.12 2.18 2.15 2.23 ...
 $ Si_AV  : num  2.33 2.67 2.25 1.26 1.21 2.39 2.34 2.46 2.6 1.6 ...
 $ Si_SR  : num  4.3 4.96 3.59 2.59 2.64 3.92 3.56 4.32 4.88 2.97 ...
 $ CHLA_AV: num  0.499 0.499 0.455 0.594 0.594 ...
 $ CHLA_SR: num  0.55 0.55 0.669 1.258 1.258 ...
 $ K490_AV: num  0.0726 0.0726 0.0672 0.075 0.075 ...
 $ K490_SR: num  0.0489 0.0489 0.0594 0.0732 0.0732 ...
 $ SST_AV : num  27 27 26.9 26.9 26.9 ...
 $ SST_SR : num  4.85 4.85 4.81 4.81 4.81 ...
 $ BIR_AV : num  0.1735 0.0688 0.2397 0.4476 0.5169 ...
 $ BIR_SR : num  0.1563 0.0885 0.2249 0.2667 0.256 ...

Which seems to correspond to the structure of my predictor variables, so I
don?t think this is the problem:

str(enviro)
'data.frame':   14 obs. of  8 variables:
 $ Temperature         : num  24.8 24.4 24.3 23 24.6 24.6 24.8 24.9 24.3
24.5 ...
 $ Turbidity           : num  0.047 0.046 0.052 0.058 0.049 0.047 0.047
0.049 0.049 0.051 ...
 $ Chlorophyll         : num  0.24 0.23 0.29 0.26 0.25 0.23 0.23 0.28 0.3
0.29 ...
 $ Waveheight          : num  2.14 2.13 2.12 2.12 2.12 2.12 2.11 2.12 2.11
2.12 ...
 $ nLw551              : num  0.231 0.228 0.228 0.236 0.226 ...
 $ nLw667              : num  1e-04 8e-04 1e-03 1e-03 1e-03 1e-04 1e-04
1e-03 1e-03 1e-04 ...
 $ Sediment.nlw551.667.: num  0.231 0.229 0.229 0.237 0.227 ...
 $ Depth               : num  4.8 4.1 5 4 6.2 7.7 10.1 4.3 5.1 7.9 ...

?BUT my set of response variables seems to be in the wrong structure and
this is I think the problem and where I need help. This is the structure of
the example data provided with gradientForest:

> load("GZ.sps.mat.Rdata")
> str(Sp_mat)
 num [1:197, 1:110] 1.04 -2.11 -3.43 -2.36 -1.15 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:197] "1" "2" "3" "4" ...
  ..$ : chr [1:110] "A1010102" "A1010113" "A1010206" "A1010209" ...????

And this is the structure that my response variables are currently in
(essentially a matrix created from Excel with rows indicating sites (14 of
them) and coloumns indicating species (100 hundred of them) abbundances
occuring at these sites (Header = TRUE):

> # data structure of biological data
> str(biological)
'data.frame':   14 obs. of  100 variables:
 $ a : num  0 0 0 0 0 0 0 0 0 0 ...
 $ b : num  0 0 0 0 257 ...
 $ c : int  0 0 0 0 0 0 441 0 0 0 ...
 $ d : num  179 0 1430 0 0 ...
 $ e : num  100 0 601 0 123 ...
 $ f : num  0 0 3 0 1.5 0 0 0 0 4.5 ...
 $ g : num  0 0 0 0 0 0 0 0 0 0 ...
 $ h : int  0 0 0 0 0 0 0 0 1 0 ...
 $ i : num  0 0 0 0 0 0 0 0 0 3.85 ...
 $ j : num  0 0 0 27.6 3.6 ...
 $ k : num  0 0 0 0 0 0 0 0 0 1.8 ...
 $ l : num  0 0 0 0 0 0 0 0 0 0 ...
 $ m : num  0 0 0 0 0 0 0 0 0 0 ...
 $ n : num  0 0 0 0 0 0 0 1.1 0 0 ...
 $ o : num  0 0 0 0 0 0.2 0 0 0 0 ...
 $ p : num  0 0.15 0 0 0.35 0.9 0 0 0 0 ...
 $ q : num  0 0 0 0 0 0 0 9.4 0 0 ...
 $ r : num  0 41 0 0 1.75 0 0 0 0 0 ...
 $ s : num  0 0 0 0 0 ...
 $ t : num  0 0 22.1 0 0 ...
 $ u : num  0 0 0 0 0 0 0 0 0 0 ...
 $ v : num  0 0 0 0 0.12 0 0 0 0 0 ...
 $ w : num  0 0 0 0 4.95 6.6 0 3.3 0 3.3 ...
 $ x : num  0 0 0 0 7.9 ...
 $ y : int  0 0 0 0 0 1 0 0 0 0 ...
 $ z : num  0 0 0 0 0 0 0 0 0 0.8 ...
 $ aa: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ab: num  0 47 0 136.3 9.4 ...
 $ ac: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ad: num  0 4.2 0 8.4 0 0 0 0.7 0 0 ...
 $ ae: int  0 0 0 2 0 1 0 0 0 0 ...
 $ af: num  0 92.4 720.7 0 554.4 ...
 $ ag: int  0 0 0 0 0 0 0 0 0 0 ...
 $ ah: int  0 0 0 0 0 0 0 0 0 0 ...
 $ ai: num  43.4 3.4 26.4 0 1.7 ...
 $ aj: num  0 0 0 0 0 ...
 $ ak: num  0 0 0.25 0 0 0 0 0 0 0 ...
 $ al: num  0 0 0 0 0 ...
 $ am: num  561.6 0 93.6 0 374.4 ...
 $ an: num  234 0 562 0 187 ...
 $ ao: num  15.92 2.16 0 0 1.08 ...
 $ ap: num  31.84 0 1.08 0 3.24 ...
 $ aq: num  0 0 0 37.8 29.4 0 92.4 0 0 0 ...
 $ ar: int  0 72 0 76 16 49 0 8 0 0 ...
 $ as: num  0 0 0 0 0 0 0 0 0 0 ...
 $ at: num  0 0 0 0 0 0 0 0 0 0 ...
 $ au: num  0 0 0 0 0 0 0 0 0 0 ...
 $ av: num  0 31.8 0 25.4 0 ...
 $ aw: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ax: num  0 2.7 0 0 0 0 0 2.7 2.7 0 ...
 $ ay: int  0 0 0 0 0 1 0 0 0 0 ...
 $ az: num  2.7 0 0 0 0 0 0 0 0 0 ...
 $ ba: num  7.72 0 0 0 0 0 0 0 0 0 ...
 $ bb: num  262 0 0 0 0 ...
 $ bc: num  0 1.6 0 13.6 0 ...
 $ bd: num  0 0 7.96 0 0 0 0 0 0 0 ...
 $ be: num  2493 0 1254 0 988 ...
 $ bf: num  0 46.4 0 72.5 45 ...
 $ bg: num  218 0 265 0 884 ...
 $ bh: num  0 0 0 0 0 0 0 2.8 0 0 ...
 $ bi: num  0 0 0 0 0 ...
 $ bj: num  0 0 0 0 0 0 0 0 0 0 ...
 $ bk: num  0 0 0 0 0 1.4 0 0 0 0 ...
 $ bl: num  0 0 0 0 0 0 3.2 0 0 0 ...
 $ bm: num  0 2.6 0 72.8 0 ...
 $ bn: num  0 0 82.8 0 0 0 0 0 0 0 ...
 $ bo: num  0 0 0 0 0 ...
 $ bp: int  0 0 0 0 0 0 0 288 0 0 ...
 $ bq: num  28.4 530.5 433.4 473.9 615.6 ...
 $ br: num  0 0 0 0 0 0 0 0 0 0 ...
 $ bs: num  0 0 0 0 0 0 0 0 0 14.5 ...
 $ bt: num  56.2 0 1125 0 78.8 ...
 $ bu: num  205.4 7.9 130.3 0 0 ...
 $ bv: num  1353.2 0 119.4 0 79.6 ...
 $ bw: num  0 0 0 2.45 0.7 2.1 0 0 0 0 ...
 $ bx: num  0 0 0 0 0 ...
 $ by: num  0 0 0 0 0 0 26.4 0 0 0 ...
 $ bz: num  208 1806 3727 208 8427 ...
 $ ca: num  49.2 0 32.8 0 57.4 ...
 $ cb: num  0 7.15 0 0 0 0 1.65 0 0 0 ...
 $ cc: num  0 590 0 419 0 ...
 $ cd: num  0 0 0 0 0 0 0 0 1.5 0 ...
 $ ce: num  1390 0 1394 0 552 ...
 $ cf: num  75.6 0 0 0 0 ...
 $ cg: num  3.86 0 0 0 0 0 0 0 0 0 ...
 $ ch: num  81.3 0 0 0 0 ...
 $ ci: num  0 0 0 0 12.2 ...
 $ cj: num  0 1.2 0 0.8 0 0.8 0.8 3.6 0 0 ...
 $ ck: num  0 0 0 0 0 17.4 0 0 0 0 ...
 $ cl: int  0 0 0 0 0 0 0 0 0 435 ...
 $ cm: num  0 0 0 0 0 0 31.2 0 0 0 ...
 $ cn: num  0 0 0 16.8 0 0 0 0 0 0 ...
 $ co: num  11.61 0 2.11 0 10.55 ...
 $ cp: num  15.05 1.4 0.35 0 0 ...
 $ cq: num  0 0 0 0 0 0 0 4.2 0 0 ...
 $ cr: int  0 0 0 0 1 0 0 0 0 0 ...
 $ cs: num  0 0 0 0 0 0 17.1 0 0 0 ...
 $ ct: num  2.7 0 0 0 0 0 0 0 0 0 ...
 $ cu: num  0 0 30.9 0 41.2 ...
  [list output truncated]
????
I thought it may be that some values are numbers and some are integers but I
tested this using only numbers and found that this is not the problem. How
do I get my response/species data into the correct structure such as in the
example (GZ.sps.mat.Rdata) ?

Thank you very much

Sean


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sean Porter
Sent: 25 March 2014 09:34 AM
To: 'Liaw, Andy'; r-help at r-project.org
Subject: Re: [R] randomForest warning: The response has five or fewer unique
values. Are you sure you want to do regression?

Dear Andy,

Thank you for your help! Below are the full details of what I am doing in R
along with the data structure, so hopefully this will help. Okay so the
warning is just a warning and nothing to worry about when doing regression.
But why is randomForest only producing regression trees for each of only 3
species when I have 100 species in the matrix, surely this is not correct,
what am I doing wrong? Also, what did you mean when you said by using the
code I am not using randomForest directly ? 

Many thanks, Sean 

> # For Andy
> # get biological data into R
>  biological <- read.table (file = "C:/bio1.txt", header = TRUE)
> dim(biological)
[1]  14 100
> # get environmental data into R
> enviro <- read.table (file = "C:/abio1.txt", header = TRUE)
> dim(enviro)
[1] 14  8
> # data structure of biological data
> str(biological)
'data.frame':   14 obs. of  100 variables:
 $ a : num  0 0 0 0 0 0 0 0 0 0 ...
 $ b : num  0 0 0 0 257 ...
 $ c : int  0 0 0 0 0 0 441 0 0 0 ...
 $ d : num  179 0 1430 0 0 ...
 $ e : num  100 0 601 0 123 ...
 $ f : num  0 0 3 0 1.5 0 0 0 0 4.5 ...
 $ g : num  0 0 0 0 0 0 0 0 0 0 ...
 $ h : int  0 0 0 0 0 0 0 0 1 0 ...
 $ i : num  0 0 0 0 0 0 0 0 0 3.85 ...
 $ j : num  0 0 0 27.6 3.6 ...
 $ k : num  0 0 0 0 0 0 0 0 0 1.8 ...
 $ l : num  0 0 0 0 0 0 0 0 0 0 ...
 $ m : num  0 0 0 0 0 0 0 0 0 0 ...
 $ n : num  0 0 0 0 0 0 0 1.1 0 0 ...
 $ o : num  0 0 0 0 0 0.2 0 0 0 0 ...
 $ p : num  0 0.15 0 0 0.35 0.9 0 0 0 0 ...
 $ q : num  0 0 0 0 0 0 0 9.4 0 0 ...
 $ r : num  0 41 0 0 1.75 0 0 0 0 0 ...
 $ s : num  0 0 0 0 0 ...
 $ t : num  0 0 22.1 0 0 ...
 $ u : num  0 0 0 0 0 0 0 0 0 0 ...
 $ v : num  0 0 0 0 0.12 0 0 0 0 0 ...
 $ w : num  0 0 0 0 4.95 6.6 0 3.3 0 3.3 ...
 $ x : num  0 0 0 0 7.9 ...
 $ y : int  0 0 0 0 0 1 0 0 0 0 ...
 $ z : num  0 0 0 0 0 0 0 0 0 0.8 ...
 $ aa: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ab: num  0 47 0 136.3 9.4 ...
 $ ac: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ad: num  0 4.2 0 8.4 0 0 0 0.7 0 0 ...
 $ ae: int  0 0 0 2 0 1 0 0 0 0 ...
 $ af: num  0 92.4 720.7 0 554.4 ...
 $ ag: int  0 0 0 0 0 0 0 0 0 0 ...
 $ ah: int  0 0 0 0 0 0 0 0 0 0 ...
 $ ai: num  43.4 3.4 26.4 0 1.7 ...
 $ aj: num  0 0 0 0 0 ...
 $ ak: num  0 0 0.25 0 0 0 0 0 0 0 ...
 $ al: num  0 0 0 0 0 ...
 $ am: num  561.6 0 93.6 0 374.4 ...
 $ an: num  234 0 562 0 187 ...
 $ ao: num  15.92 2.16 0 0 1.08 ...
 $ ap: num  31.84 0 1.08 0 3.24 ...
 $ aq: num  0 0 0 37.8 29.4 0 92.4 0 0 0 ...
 $ ar: int  0 72 0 76 16 49 0 8 0 0 ...
 $ as: num  0 0 0 0 0 0 0 0 0 0 ...
 $ at: num  0 0 0 0 0 0 0 0 0 0 ...
 $ au: num  0 0 0 0 0 0 0 0 0 0 ...
 $ av: num  0 31.8 0 25.4 0 ...
 $ aw: num  0 0 0 0 0 0 0 0 0 0 ...
 $ ax: num  0 2.7 0 0 0 0 0 2.7 2.7 0 ...
 $ ay: int  0 0 0 0 0 1 0 0 0 0 ...
 $ az: num  2.7 0 0 0 0 0 0 0 0 0 ...
 $ ba: num  7.72 0 0 0 0 0 0 0 0 0 ...
 $ bb: num  262 0 0 0 0 ...
 $ bc: num  0 1.6 0 13.6 0 ...
 $ bd: num  0 0 7.96 0 0 0 0 0 0 0 ...
 $ be: num  2493 0 1254 0 988 ...
 $ bf: num  0 46.4 0 72.5 45 ...
 $ bg: num  218 0 265 0 884 ...
 $ bh: num  0 0 0 0 0 0 0 2.8 0 0 ...
 $ bi: num  0 0 0 0 0 ...
 $ bj: num  0 0 0 0 0 0 0 0 0 0 ...
 $ bk: num  0 0 0 0 0 1.4 0 0 0 0 ...
 $ bl: num  0 0 0 0 0 0 3.2 0 0 0 ...
 $ bm: num  0 2.6 0 72.8 0 ...
 $ bn: num  0 0 82.8 0 0 0 0 0 0 0 ...
 $ bo: num  0 0 0 0 0 ...
 $ bp: int  0 0 0 0 0 0 0 288 0 0 ...
 $ bq: num  28.4 530.5 433.4 473.9 615.6 ...
 $ br: num  0 0 0 0 0 0 0 0 0 0 ...
 $ bs: num  0 0 0 0 0 0 0 0 0 14.5 ...
 $ bt: num  56.2 0 1125 0 78.8 ...
 $ bu: num  205.4 7.9 130.3 0 0 ...
 $ bv: num  1353.2 0 119.4 0 79.6 ...
 $ bw: num  0 0 0 2.45 0.7 2.1 0 0 0 0 ...
 $ bx: num  0 0 0 0 0 ...
 $ by: num  0 0 0 0 0 0 26.4 0 0 0 ...
 $ bz: num  208 1806 3727 208 8427 ...
 $ ca: num  49.2 0 32.8 0 57.4 ...
 $ cb: num  0 7.15 0 0 0 0 1.65 0 0 0 ...
 $ cc: num  0 590 0 419 0 ...
 $ cd: num  0 0 0 0 0 0 0 0 1.5 0 ...
 $ ce: num  1390 0 1394 0 552 ...
 $ cf: num  75.6 0 0 0 0 ...
 $ cg: num  3.86 0 0 0 0 0 0 0 0 0 ...
 $ ch: num  81.3 0 0 0 0 ...
 $ ci: num  0 0 0 0 12.2 ...
 $ cj: num  0 1.2 0 0.8 0 0.8 0.8 3.6 0 0 ...
 $ ck: num  0 0 0 0 0 17.4 0 0 0 0 ...
 $ cl: int  0 0 0 0 0 0 0 0 0 435 ...
 $ cm: num  0 0 0 0 0 0 31.2 0 0 0 ...
 $ cn: num  0 0 0 16.8 0 0 0 0 0 0 ...
 $ co: num  11.61 0 2.11 0 10.55 ...
 $ cp: num  15.05 1.4 0.35 0 0 ...
 $ cq: num  0 0 0 0 0 0 0 4.2 0 0 ...
 $ cr: int  0 0 0 0 1 0 0 0 0 0 ...
 $ cs: num  0 0 0 0 0 0 17.1 0 0 0 ...
 $ ct: num  2.7 0 0 0 0 0 0 0 0 0 ...
 $ cu: num  0 0 30.9 0 41.2 ...
  [list output truncated]
> # data structure of environmental data
> str(enviro)
'data.frame':   14 obs. of  8 variables:
 $ Temperature         : num  24.8 24.4 24.3 23 24.6 24.6 24.8 24.9 24.3
24.5 ...
 $ Turbidity           : num  0.047 0.046 0.052 0.058 0.049 0.047 0.047
0.049 0.049 0.051 ...
 $ Chlorophyll         : num  0.24 0.23 0.29 0.26 0.25 0.23 0.23 0.28 0.3
0.29 ...
 $ Waveheight          : num  2.14 2.13 2.12 2.12 2.12 2.12 2.11 2.12 2.11
2.12 ...
 $ nLw551              : num  0.231 0.228 0.228 0.236 0.226 ...
 $ nLw667              : num  1e-04 8e-04 1e-03 1e-03 1e-03 1e-04 1e-04
1e-03 1e-03 1e-04 ...
 $ Sediment.nlw551.667.: num  0.231 0.229 0.229 0.237 0.227 ...
 $ Depth               : num  4.8 4.1 5 4 6.2 7.7 10.1 4.3 5.1 7.9 ...
> # conduct randomForest regression
> gf <- gradientForest(cbind(enviro, biological), predictor.vars =
colnames(enviro), response.vars = colnames(biological), ntree = 500,
transform = NULL, compact = T, nbin = 201, maxLevel = 5, corr.threshold =
0.5)
There were 50 or more warnings (use warnings() to see the first 50)
> gf
A forest of 500 regression trees for each of 3 species

Call:

gradientForest(data = cbind(enviro, biological), predictor.vars =
colnames(enviro), 
    response.vars = colnames(biological), ntree = 500, transform = NULL, 
    maxLevel = 5, corr.threshold = 0.5, compact = T, nbin = 201)



Important variables:
[1] Sediment.nlw551.667. Depth                nLw551               nLw667
Chlorophyll         

> # End


?????????


-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com]
Sent: 25 March 2014 02:37 AM
To: Sean Porter; r-help at r-project.org
Subject: RE: [R] randomForest warning: The response has five or fewer unique
values. Are you sure you want to do regression?

If you are using the code, that's not really using randomForest directly.  I
don't understand the data structure you have (since you did not show
anything) so can't really tell you much.  In any case, that warning came
from randomForest() when it is run in regression mode but the response has
fewer than five distinct values.  It may be legitimate regression data, and
if so you can safely ignore the warning (that's why it's not an error).
It's there to catch the cases when people try to do classification with
class labels 1, 2, ..., k and forgot to make it a factor.

Best,
Andy Liaw

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sean Porter
Sent: Thursday, March 20, 2014 3:27 AM
To: r-help at r-project.org
Subject: [R] randomForest warning: The response has five or fewer unique
values. Are you sure you want to do regression?

Hello everyone,

 

Im relatively new to R and new to the randomForest package and have scoured
the archives for help with no luck. I am trying to perform a regression on a
set of predictors and response variables to determine the most important
predictors. I have 100 response variables collected from 14 sites and 8
predictor variables from the same 14 sites. I run the code to perform the
randomForest  regression given by Pitcher et al 2011   (
http://gradientforest.r-forge.r-project.org/biodiversity-survey.pdf ). 

 

However, after running the code I get the warning:

 

" In randomForest.default(m, y, ...) :

  The response has five or fewer unique values.  Are you sure you want to do
regression?"

 

And it produces a set of 500 regression trees for each of 3 species only
when the number of species in the response file is 100. I noticed that in
the example by Pitcher they get 500 trees from only 90 species even though
they input 110 species in the response data.

 

Why am I getting the warning/how do I solve it, and why is randomForest
producing trees for only 3 species when I am looking at 100 species
(response variables)?

 

Many thanks

 

Sean

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:15}}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From leandromarino at leandromarino.com.br  Wed Apr  2 15:37:47 2014
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Wed, 2 Apr 2014 10:37:47 -0300
Subject: [R] Survey
Message-ID: <CAKSaaF=+VT4uSwsa02XdFZ9c6eAN2e-1cyDE+_nrDSSZtummLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/7cd23531/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Wed Apr  2 16:14:40 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 02 Apr 2014 07:14:40 -0700
Subject: [R] Strange sprintf Behavior
In-Reply-To: <533BF54A.6090003@gmail.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
	<533BF54A.6090003@gmail.com>
Message-ID: <d722f647-a8bb-4f73-be20-95f568ed0bae@email.android.com>

It is poor netiquette to reply to a thread with a different subject. Please start a new thread for a new subject.

As for your question, see FAQ 7.31. This is standard floating point numerical limitations at work.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 2, 2014 4:32:26 AM PDT, Michael Smith <my.r.help at gmail.com> wrote:
>All,
>
>I'm getting this:
>
>> sprintf("%.17f", 0.8)
>[1] "0.80000000000000004"
>
>Where does the `4` at the end come from? Shouldn't it be zero at the
>end? Maybe I'm missing something.
>
>> sessionInfo()
>R version 3.0.2 (2013-09-25)
>Platform: x86_64-redhat-linux-gnu (64-bit)
>
>locale:
> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>LC_TIME=en_US.utf8
> [4] LC_COLLATE=en_US.utf8     LC_MONETARY=en_US.utf8
>LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=en_US.utf8       LC_NAME=C                 LC_ADDRESS=C
>
>[10] LC_TELEPHONE=C            LC_MEASUREMENT=en_US.utf8
>LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>Thanks,
>
>M
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From friendly at yorku.ca  Wed Apr  2 16:43:23 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 02 Apr 2014 10:43:23 -0400
Subject: [R] ggplot:  add points selectively to curves
Message-ID: <533C220B.5020408@yorku.ca>

I'm working on an example of plotting predicted probabilities from a 
proportional odds model.
The steps below generate a data frame, plotdat, that I want to plot with 
ggplot.

library(MASS)
data("Arthritis", package="vcd")
arth.polr <- polr(Improved ~ Sex + Treatment + Age, data=Arthritis, 
Hess=TRUE)

# get predicted probs for categories of Improve
arth.fitp <- cbind(Arthritis,
                   predict(arth.polr, type="probs"))
head(arth.fitp)

# reshape probs to long
library(reshape2)
plotdat <- melt(arth.fitp,
                 id.vars = c("Sex", "Treatment", "Age", "Improved"),
                 measure.vars=c("None", "Some", "Marked"),
                 variable.name = "Level",
                 value.name = "Probability")
## view first few rows
head(plotdat)

 > head(plotdat)
    Sex Treatment Age Improved Level Probability
1 Male   Treated  27     Some  None   0.7326185
2 Male   Treated  29     None  None   0.7174048
3 Male   Treated  30     None  None   0.7096042
4 Male   Treated  32   Marked  None   0.6936286
5 Male   Treated  46   Marked  None   0.5702499
6 Male   Treated  58   Marked  None   0.4563432

In the plot step, I am plotting Probability vs. Age, stratified by 
Level, and faceted by
Sex and Treatment.  My question concerns the use of geom_point().
The call below plots 3 points for each case, one on each Level curve.


ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) +
     geom_line(size=2.5) + theme_bw() + xlim(10,80) +
     geom_point(color="black", size=1.5) +
     facet_grid(Sex ~ Treatment,
                labeller = function(x, y) sprintf("%s = %s", x, y)
                )

Instead,
I want to plot only one point for each case, for the value of Level that 
corresponds
to the value of Improved in this data set.  Somehow, this involves something
like an aes() argument to geom_point(), with Level indexed by Improved, 
or some such.
How can I do this?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From phouliha at stevens.edu  Wed Apr  2 18:05:44 2014
From: phouliha at stevens.edu (PHOULIHAN)
Date: Wed, 2 Apr 2014 09:05:44 -0700 (PDT)
Subject: [R] Insert DateTime from R into MongoDB
Message-ID: <1396454744348-4688030.post@n4.nabble.com>

First time poster, for forgive if I'm not following the etiquette:

How does one properly insert a DateTime, from R, into mongoDB and have it
recognized as a DateTime in mongoDB in lieu of being recognized as a string?

I've tried a zillion things, and NOTHING works.  I'm using:
library('RMongo')
require(rmongodb)
require(RJSONIO)

With a variety of commands I found online, and it always passes from R into
mognoDB as a string no matter what I do. 



--
View this message in context: http://r.789695.n4.nabble.com/Insert-DateTime-from-R-into-MongoDB-tp4688030.html
Sent from the R help mailing list archive at Nabble.com.



From babeth_013 at icloud.com  Wed Apr  2 15:09:49 2014
From: babeth_013 at icloud.com (Elizabeth Caron-Gamache)
Date: Wed, 02 Apr 2014 09:09:49 -0400
Subject: [R] CORDIF test
Message-ID: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/09e5e81a/attachment-0001.pl>

From nhoughton01 at gmail.com  Wed Apr  2 16:12:16 2014
From: nhoughton01 at gmail.com (Natalie Houghton McNair)
Date: Wed, 2 Apr 2014 07:12:16 -0700
Subject: [R] Help with MANOVA
Message-ID: <CAJea-HbbhHGfER3qPfwpX7386XMtMivneifPWb44FvbH0xc_Vg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/d8dcf34b/attachment-0001.pl>

From nwf7 at scarletmail.rutgers.edu  Wed Apr  2 19:10:55 2014
From: nwf7 at scarletmail.rutgers.edu (zumacrume)
Date: Wed, 2 Apr 2014 10:10:55 -0700 (PDT)
Subject: [R] R2WinBUGS "expected collection operator c" error
Message-ID: <1396458655108-4688032.post@n4.nabble.com>

Hi all,
I am currently in a Bayesian Modeling course and am trying to implement an
analog representation model using R, WinBUGS, and R2WinBUGS.  I'm currently
stuck banging my head against an "expected collection operator c" error.  I
am working off of a template code, and I swear I haven't moved any
collection operators from the original code.
Here is what my script looks like in R:
########################################################

# clears workspace:  
rm(list=ls(all=TRUE)) 

# sets working directories:
setwd("C:\\Users\\Nick\\Desktop\\modeling")
library(R2WinBUGS)
bugsdir = "C:/Program Files/WinBUGS14"

# read the data

g   = matrix(scan("g.txt", sep=","), ncol=144, nrow=3, byrow=T)
q   = matrix(scan("q.txt", sep=","), ncol=144, nrow=3, byrow=T)
S   = 3         # number of subjects
Q   = 144 # number of questions for each child
N   = 9 # maximum numbers of item list

data  = list("g", "q", "S", "Q", "N") # to be passed on to WinBUGS
myinits =	list(
  list(sigma = rep(1,S), pitmp=rep(1/N, N)))  

# parameters to be monitored:	
parameters = c("pp","ppb","sigma")

# NB. even with only 1000 iterations, the sampling can take a long time! 
# The following command calls WinBUGS with specific options.
# For a detailed description see Sturtz, Ligges, & Gelman (2005).
samples = bugs(data, inits=myinits, parameters,
	 			model.file ="NumberConcept_2_data.txt",
	 			n.chains=1, n.iter=1000, n.burnin=100, n.thin=1,
	 			DIC=T, bugs.directory=bugsdir,
	 			codaPkg=F, debug=T)
# Now the values for the monitored parameters are in the "samples" object, 
# ready for inspection.

samples$summary

#######################################################

and here is the log file file from WinBUGS after R2WinBUGS passes it over:

#######################################################
display(log)
check(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/NumberConcept_2_data.txt)
model is syntactically correct
data(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/data.txt)
expected collection operator c
compile(1)
inits(1,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/inits1.txt)
command #Bugs:inits cannot be executed (is greyed out)
gen.inits()
command #Bugs:gen.inits cannot be executed (is greyed out)
thin.updater(1)
update(100)
command #Bugs:update cannot be executed (is greyed out)
set(pp)
command #Bugs:set cannot be executed (is greyed out)
set(ppb)
command #Bugs:set cannot be executed (is greyed out)
set(sigma)
command #Bugs:set cannot be executed (is greyed out)
set(deviance)
command #Bugs:set cannot be executed (is greyed out)
dic.set()
command #Bugs:dic.set cannot be executed (is greyed out)
update(900)
command #Bugs:update cannot be executed (is greyed out)
coda(*,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/coda)
command #Bugs:coda cannot be executed (is greyed out)
stats(*)
command #Bugs:stats cannot be executed (is greyed out)
dic.stats()

DIC
history(*,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/history.odc)
command #Bugs:history cannot be executed (is greyed out)
save(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/log.odc)
save(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/log.txt)

#################################################################
WinBUGS also opens up a data window that looks like this:
#################################################################

list(g= structure(.Data= c(1.00000E+00, 1.00000E+00, 1.00000E+00,
1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00), .Dim=c(3, 144)), q=
structure(.Data= c(4.00000E+00, 5.00000E+00, 3.00000E+00, 8.00000E+00,
1.00000E+00, 5.00000E+00, 4.00000E+00, 4.00000E+00, 3.00000E+00,
3.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 4.00000E+00,
5.00000E+00, 2.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 3.00000E+00, 7.00000E+00, 6.00000E+00,
5.00000E+00, 4.00000E+00, 7.00000E+00, 1.00000E+00, 1.00000E+00,
3.00000E+00, 6.00000E+00, 2.00000E+00, 6.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 3.00000E+00, 3.00000E+00, 4.00000E+00,
1.00000E+00, 7.00000E+00, 2.00000E+00, 2.00000E+00, 3.00000E+00,
4.00000E+00, 1.00000E+00, 3.00000E+00, 5.00000E+00, 6.00000E+00,
2.00000E+00, 6.00000E+00, 4.00000E+00, 2.00000E+00, 2.00000E+00,
5.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00, 4.00000E+00,
5.00000E+00, 3.00000E+00, 3.00000E+00, 1.00000E+00, 1.00000E+00,
7.00000E+00, 2.00000E+00, 1.00000E+00, 8.00000E+00, 4.00000E+00,
2.00000E+00, 1.00000E+00, 6.00000E+00, 4.00000E+00, 2.00000E+00,
3.00000E+00, 4.00000E+00, 2.00000E+00, 5.00000E+00, 1.00000E+00,
7.00000E+00, 2.00000E+00, 3.00000E+00, 5.00000E+00, 3.00000E+00,
6.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00, 3.00000E+00,
5.00000E+00, 1.00000E+00, 6.00000E+00, 2.00000E+00, 6.00000E+00,
4.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00, 1.00000E+00,
3.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
3.00000E+00, 2.00000E+00, 4.00000E+00, 8.00000E+00, 1.00000E+00,
1.00000E+00, 5.00000E+00, 6.00000E+00, 4.00000E+00, 7.00000E+00,
1.00000E+00, 6.00000E+00, 7.00000E+00, 5.00000E+00, 3.00000E+00,
3.00000E+00, 4.00000E+00, 4.00000E+00, 3.00000E+00, 3.00000E+00,
2.00000E+00, 5.00000E+00, 3.00000E+00, 2.00000E+00, 6.00000E+00,
1.00000E+00, 2.00000E+00, 3.00000E+00, 1.00000E+00, 5.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 4.00000E+00, 2.00000E+00,
8.00000E+00, 2.00000E+00, 4.00000E+00, 1.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 3.00000E+00, 7.00000E+00, 3.00000E+00,
1.00000E+00, 3.00000E+00, 2.00000E+00, 4.00000E+00, 7.00000E+00,
4.00000E+00, 1.00000E+00, 1.00000E+00, 5.00000E+00, 3.00000E+00,
6.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 2.00000E+00, 6.00000E+00, 5.00000E+00, 8.00000E+00,
4.00000E+00, 3.00000E+00, 5.00000E+00, 3.00000E+00, 4.00000E+00,
6.00000E+00, 4.00000E+00, 5.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 5.00000E+00,
5.00000E+00, 1.00000E+00, 4.00000E+00, 4.00000E+00, 1.00000E+00,
3.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 5.00000E+00,
3.00000E+00, 2.00000E+00, 1.00000E+00, 5.00000E+00, 6.00000E+00,
3.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 8.00000E+00,
2.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00, 1.00000E+00,
6.00000E+00, 7.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
6.00000E+00, 3.00000E+00, 2.00000E+00, 7.00000E+00, 3.00000E+00,
2.00000E+00, 3.00000E+00, 3.00000E+00, 7.00000E+00, 1.00000E+00,
3.00000E+00, 5.00000E+00, 5.00000E+00, 5.00000E+00, 6.00000E+00,
4.00000E+00, 6.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
4.00000E+00, 1.00000E+00, 8.00000E+00, 4.00000E+00, 5.00000E+00,
1.00000E+00, 4.00000E+00, 6.00000E+00, 2.00000E+00, 1.00000E+00,
3.00000E+00, 3.00000E+00, 1.00000E+00, 4.00000E+00, 2.00000E+00,
1.00000E+00, 2.00000E+00, 1.00000E+00, 3.00000E+00, 7.00000E+00,
8.00000E+00, 2.00000E+00, 2.00000E+00, 3.00000E+00, 2.00000E+00,
6.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 5.00000E+00,
4.00000E+00, 3.00000E+00, 3.00000E+00, 6.00000E+00, 2.00000E+00,
1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 5.00000E+00,
1.00000E+00, 4.00000E+00, 4.00000E+00, 6.00000E+00, 3.00000E+00,
2.00000E+00, 5.00000E+00, 7.00000E+00, 5.00000E+00, 4.00000E+00,
3.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
2.00000E+00, 3.00000E+00, 5.00000E+00, 1.00000E+00, 5.00000E+00,
1.00000E+00, 6.00000E+00, 6.00000E+00, 2.00000E+00, 2.00000E+00,
3.00000E+00, 3.00000E+00, 1.00000E+00, 3.00000E+00, 3.00000E+00,
4.00000E+00, 7.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00,
2.00000E+00, 1.00000E+00, 4.00000E+00, 4.00000E+00, 4.00000E+00,
2.00000E+00, 8.00000E+00, 7.00000E+00, 3.00000E+00, 5.00000E+00,
1.00000E+00, 6.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00,
1.00000E+00, 5.00000E+00, 3.00000E+00, 1.00000E+00, 4.00000E+00,
6.00000E+00, 3.00000E+00, 4.00000E+00, 7.00000E+00, 6.00000E+00,
1.00000E+00, 1.00000E+00, 8.00000E+00, 7.00000E+00, 6.00000E+00,
1.00000E+00, 4.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
2.00000E+00, 4.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
2.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 3.00000E+00,
4.00000E+00, 5.00000E+00, 5.00000E+00, 3.00000E+00, 5.00000E+00,
2.00000E+00, 6.00000E+00, 1.00000E+00, 5.00000E+00, 4.00000E+00,
4.00000E+00, 3.00000E+00, 5.00000E+00, 4.00000E+00, 1.00000E+00,
1.00000E+00, 2.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00,
5.00000E+00, 2.00000E+00, 6.00000E+00, 1.00000E+00, 6.00000E+00,
2.00000E+00, 3.00000E+00, 2.00000E+00, 3.00000E+00, 3.00000E+00,
4.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 3.00000E+00,
3.00000E+00, 7.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
5.00000E+00, 8.00000E+00, 4.00000E+00, 1.00000E+00, 8.00000E+00,
1.00000E+00, 5.00000E+00, 6.00000E+00, 3.00000E+00, 5.00000E+00,
4.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 5.00000E+00,
4.00000E+00, 3.00000E+00, 6.00000E+00, 1.00000E+00, 1.00000E+00,
7.00000E+00, 4.00000E+00, 2.00000E+00, 2.00000E+00, 4.00000E+00,
2.00000E+00, 1.00000E+00, 2.00000E+00, 5.00000E+00, 2.00000E+00,
3.00000E+00, 7.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
3.00000E+00, 6.00000E+00, 3.00000E+00), .Dim=c(3, 144)), S=3.00000E+00,
Q=1.44000E+02, N=9.00000E+00)

##################################################################

Which is my data from files g.txt and q.txt - I go looking for a missing
collection operator c but cannot find it anywhere, if anyone has a clue what
I could do to get past this point, I would be so grateful!

Best,
N





--
View this message in context: http://r.789695.n4.nabble.com/R2WinBUGS-expected-collection-operator-c-error-tp4688032.html
Sent from the R help mailing list archive at Nabble.com.



From gunter.berton at gene.com  Wed Apr  2 19:59:41 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 2 Apr 2014 10:59:41 -0700
Subject: [R] CORDIF test
In-Reply-To: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
References: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
Message-ID: <CACk-te3Zw7gZ2c3nQSpK29_9XBqLGj9qr59BURHUEN2Ua2nB=g@mail.gmail.com>

google is your friend!

google "r cordif test"

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Wed, Apr 2, 2014 at 6:09 AM, Elizabeth Caron-Gamache
<babeth_013 at icloud.com> wrote:
> Hi,
>
> I search on your website for a definition of the CORDIF test, but it wasn?t successful. I?m analyzing an article that use that test and it?s not really documented on the net. The article refers to your website, so I pretend that you will be able to give me a brief explanation of this test. Here is the cote that talk about this test in my article :
>
> ?' To compare these regressions and to see which?either body height or LLL?is best related to performance (Pearson correlation coefficients comparison), a CORDIF test (R software [www.r-project.org], multilevel package, ver- sion 2.12.1) was performed.
>
> Does it use parametric or non-parametric values ?
> Is it a test to compare 2 groups only or it can be used for a comparison of more than two groups ?
> Why is it so hard to find information on that test on the net ?
>
> Thanks for your time
> Have a nice day
>
> Elizabeth Caron
> Physical therapist student, Laval University, Qc, Canada
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From marc_schwartz at me.com  Wed Apr  2 20:03:35 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 02 Apr 2014 13:03:35 -0500
Subject: [R] CORDIF test
In-Reply-To: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
References: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
Message-ID: <E1AA307A-5C8F-4EF2-ABE0-6B51F131D843@me.com>

On Apr 2, 2014, at 8:09 AM, Elizabeth Caron-Gamache <babeth_013 at icloud.com> wrote:

> Hi, 
> 
> I search on your website for a definition of the CORDIF test, but it wasn?t successful. I?m analyzing an article that use that test and it?s not really documented on the net. The article refers to your website, so I pretend that you will be able to give me a brief explanation of this test. Here is the cote that talk about this test in my article : 
> 
> ?' To compare these regressions and to see which?either body height or LLL?is best related to performance (Pearson correlation coefficients comparison), a CORDIF test (R software [www.r-project.org], multilevel package, ver- sion 2.12.1) was performed.
> 
> Does it use parametric or non-parametric values ?
> Is it a test to compare 2 groups only or it can be used for a comparison of more than two groups ?
> Why is it so hard to find information on that test on the net ?
> 
> Thanks for your time
> Have a nice day 
> 
> Elizabeth Caron
> Physical therapist student, Laval University, Qc, Canada


Thanks for including the citation, which indicates that the CORDIF test is part of the 'multilevel' package, which is on CRAN:

  http://cran.r-project.org/web/packages/multilevel/index.html

The reason that it is likely difficult is that 'cordif' is an abbreviation for "correlation difference", not the proper name for a test.

If you review the provided documentation for the package:

  http://cran.r-project.org/web/packages/multilevel/multilevel.pdf

you will see that there is a description of the cordif() function and a reference given:

Cohen, J. & Cohen, P. (1983). Applied multiple regression/correlation analysis for the behavioral sciences (2nd Ed.). Hillsdale, NJ: Lawrence Erlbaum Associates.

I would review the package documentation and reference and if you have further questions, contact the authors of the paper.

Regards,

Marc Schwartz



From istazahn at gmail.com  Wed Apr  2 20:17:08 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 2 Apr 2014 14:17:08 -0400
Subject: [R] CORDIF test
In-Reply-To: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
References: <D6938EAA-C050-4B67-A70A-616959E9FC97@icloud.com>
Message-ID: <CA+vqiLGvBqew5krxEnNF-4=Kn=98GeAC_MXo2FQNaMqL3y0ykw@mail.gmail.com>

Hi Elizabeth,

In addition to the helpful suggestions you have already received, I
would add that for simple functions like this it can be very
instructive to just look at the function definition. Loading the
multilevel package and typing 'cordif' will show you

function (rvalue1, rvalue2, n1, n2)
{
    zvalue1 <- 0.5 * ((log(1 + rvalue1)) - (log(1 - rvalue1)))
    zvalue2 <- 0.5 * ((log(1 + rvalue2)) - (log(1 - rvalue2)))
    zest <- (zvalue1 - zvalue2)/sqrt(1/(n1 - 3) + 1/(n2 - 3))
    out <- list(`z value` = zest)
    return(out)
}


best.
Ista

On Wed, Apr 2, 2014 at 9:09 AM, Elizabeth Caron-Gamache
<babeth_013 at icloud.com> wrote:
> Hi,
>
> I search on your website for a definition of the CORDIF test, but it wasn?t successful. I?m analyzing an article that use that test and it?s not really documented on the net. The article refers to your website, so I pretend that you will be able to give me a brief explanation of this test. Here is the cote that talk about this test in my article :
>
> ?' To compare these regressions and to see which?either body height or LLL?is best related to performance (Pearson correlation coefficients comparison), a CORDIF test (R software [www.r-project.org], multilevel package, ver- sion 2.12.1) was performed.
>
> Does it use parametric or non-parametric values ?
> Is it a test to compare 2 groups only or it can be used for a comparison of more than two groups ?
> Why is it so hard to find information on that test on the net ?
>
> Thanks for your time
> Have a nice day
>
> Elizabeth Caron
> Physical therapist student, Laval University, Qc, Canada
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From smartpink111 at yahoo.com  Wed Apr  2 20:20:52 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Apr 2014 11:20:52 -0700 (PDT)
Subject: [R] Removing White spaces with NA
Message-ID: <1396462852.61193.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat <- data.frame(Col1=c("A", "", "B","C", "","","D"), stringsAsFactors=FALSE)
is.na(dat) <- dat==''
dat$Col1
#[1] "A" NA  "B" "C" NA  NA  "D" 
A.K.



Hi All, I have a table and a column with values as below Col1
A B
C D I need to replace the Empty cells with the value NA as below
Col1
A
NA
B
C
NA
NA
D I tried a code, which was not working.
Table.name$column.name <- gsub("","NA", table.name$column.name) Can anyone help me with this ?
Thanks and regards,
Praveen



From marc_grt at yahoo.fr  Wed Apr  2 20:24:42 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 02 Apr 2014 20:24:42 +0200
Subject: [R] Interpreting effect of ordered categorical predictor
Message-ID: <533C55EA.5050500@yahoo.fr>

(I posted this question in 
http://stackoverflow.com/questions/22781965/interpreting-effect-of-ordered-categorical-predictor 
without answer... I try here)

Thanks a lot
Marc

My question is very similar to this one 
(https://stat.ethz.ch/pipermail/r-help/2012-March/305357.html) but I 
fail to understand it fully. I would like to visualize the effect of an 
ordered categorical predictor after a glm.

First I generate some dummy data:

## data.frame with continuous values and 6 factors
datagenerate <- data.frame(measure=c(rnorm(20, 10, 2), rnorm(30, 15, 2), 
rnorm(20, 20, 2),
rnorm(20, 25, 2), rnorm(20, 30, 2), rnorm(20, 35, 2)), factor=c(rep("A", 
20), rep("B", 30),
rep("C", 20), rep("D", 20), rep("E", 20), rep("F", 20)), 
stringsAsFactors=FALSE)
nbfactors <- length(levels(datagenerate$factor))

Now I apply a glm with an unordered category:

## First factors are unordered
datagenerate$factor <- as.factor(datagenerate$factor)
essaiglm <- glm(measure ~ factor, datagenerate, family=gaussian())
coef_unordered <- coef(summary(essaiglm))[,1]
plot(1:nbfactors, c(0, coef_unordered[2:nbfactors]), type="h", bty="n", 
las=1,
xlab="Factors", ylab="Effect")

All is ok. But I would like to do the same with ordered category:

## Now factors are ordered
datagenerate$factor <- ordered(datagenerate$factor, levels=c("A", "B", 
"C", "D", "E", "F"))
essaiglm <- glm(measure ~ factor, datagenerate, family=gaussian())
coef_ordered <- coef(summary(essaiglm))[,1]

## I am not sure about this line. How the ordered factors are coded ?
x <- ((0:(nbfactors-1))-(nbfactors-1)/2)/(nbfactors-1)

y <- x*coef_ordered["factor.L"]+x^2*coef_ordered["factor.Q"]+
x^3*coef_ordered["factor.C"]+x^4*coef_ordered["factor^4"]+
x^5*coef_ordered["factor^5"]
y <- y-min(y)
plot(1:nbfactors, y, type="h", bty="n", las=1, xlab="Factors", 
ylab="Effect")
The result is highly dependent on the coding of the levels. Based on 
several tries, I propose

x <- ((0:(nbfactors-1))-(nbfactors-1)/2)/(nbfactors-1)
But I am not sure.

If someone has the answer, I will be very grateful.

Thanks a lot

Marc



From c-w.hoffmann at sunrise.ch  Wed Apr  2 20:58:14 2014
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Wed, 02 Apr 2014 20:58:14 +0200
Subject: [R] 127.0.0.1:22381/doc/html/index.html  hep.start won't start
Message-ID: <533C5DC6.4080908@sunrise.ch>

Dear All,

Sorry to bother you. I narrowed my problem to the function

help.start() which causes the freezing of R by

mill endlessly after M-x R waiting for

127.0.0.1:22381/doc/html/index.html

to load.

I am using Aquamacs 3.0a (GNU Emacs 24.3.50.2)with R3.0.3, newly 
installed: sessionInfo()
-----------
R version 3.0.3 (2014-03-06)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.0.3 tools_3.0.3
---------

The FIREWALL is responsible, deactivating will allow help.start()? Bur I 
don't want to work without the firewall!!
Settingthe firewall for  Firefox and Aquamacs to "allow incoming 
connections" (translated from German)will also not help.

Thanks for considering.

Christian



From jabugri at uds.edu.gh  Wed Apr  2 21:15:51 2014
From: jabugri at uds.edu.gh (Abugri James)
Date: Wed, 2 Apr 2014 20:15:51 +0100
Subject: [R] looping in R
Message-ID: <CA+Zx2AhcMwYYm2v4ekuZb-bRqtuK1P-8zjO=qCA=rR8YeU5ZKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/ac1ef4a6/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Wed Apr  2 22:21:34 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 02 Apr 2014 13:21:34 -0700
Subject: [R] looping in R
In-Reply-To: <CA+Zx2AhcMwYYm2v4ekuZb-bRqtuK1P-8zjO=qCA=rR8YeU5ZKw@mail.gmail.com>
References: <CA+Zx2AhcMwYYm2v4ekuZb-bRqtuK1P-8zjO=qCA=rR8YeU5ZKw@mail.gmail.com>
Message-ID: <331d86db-607f-4eb4-822f-b5eaecd5f537@email.android.com>

You desperately need to read the Posting Guide (mentioned in the footer of this email) which warns you not to post in HTML format, and learn how to make a reproducible example (e.g. http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example).

The problem lies in some interaction between your data and code, and without both we cannot help you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 2, 2014 12:15:51 PM PDT, Abugri James <jabugri at uds.edu.gh> wrote:
>I ran the following loop on my SNP data and got an error message as
>indicated
>for (i in genenames){
>+   current <- fst1[which(fst1$Gene == i),]
>+   num <- nrow(current)
>+   fst <- max(current$fst)
>+   position <- mean(current$pos)
>+   nposition <- mean(current$newpos)
>+   numhigh <- nrow(current[which(current$fst > threshold),])
>+   colors <- mean(current$colors)
>+   output <- matrix(NA,nrow=1,ncol=8)
>+   numthresh <- paste("# SNPs > Fst = ", threshold, sep="")
>+   colnames(output) <- c("gene", "gene_old", "pos", "newpos", "#
>Snps",
>numthresh, "Max.Fst", "colors")
>+   output[1,1] <- i
>+   output[1,2] <- as.character(current[1, "gene_old"])
>+   output[1,3] <- position
>+   output[1,4] <- nposition
>+   output[1,5] <- num
>+   output[1,6] <- numhigh
>+   output[1,7] <- fst
>+   output[1,8] <- colors
>+   maxfstgene <- rbind(maxfstgene, output)
>+ }
>Error in output[1, 2] <- as.character(current[1, "gene_old"]) :
>  replacement has length zero
>In addition: Warning message:
>In mean.default(current$pos) :
>  argument is not numeric or logical: returning NA
>--



From murdoch.duncan at gmail.com  Wed Apr  2 22:35:57 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Apr 2014 16:35:57 -0400
Subject: [R] looping in R
In-Reply-To: <CA+Zx2AhcMwYYm2v4ekuZb-bRqtuK1P-8zjO=qCA=rR8YeU5ZKw@mail.gmail.com>
References: <CA+Zx2AhcMwYYm2v4ekuZb-bRqtuK1P-8zjO=qCA=rR8YeU5ZKw@mail.gmail.com>
Message-ID: <533C74AD.6000207@gmail.com>

On 02/04/2014, 3:15 PM, Abugri James wrote:
> I ran the following loop on my SNP data and got an error message as
> indicated

I would assume that the error message is accurate: 
as.character(current[1, "gene_old"]) has length zero.  You'll need to 
debug why that happened.

Duncan Murdoch

> for (i in genenames){
> +   current <- fst1[which(fst1$Gene == i),]
> +   num <- nrow(current)
> +   fst <- max(current$fst)
> +   position <- mean(current$pos)
> +   nposition <- mean(current$newpos)
> +   numhigh <- nrow(current[which(current$fst > threshold),])
> +   colors <- mean(current$colors)
> +   output <- matrix(NA,nrow=1,ncol=8)
> +   numthresh <- paste("# SNPs > Fst = ", threshold, sep="")
> +   colnames(output) <- c("gene", "gene_old", "pos", "newpos", "# Snps",
> numthresh, "Max.Fst", "colors")
> +   output[1,1] <- i
> +   output[1,2] <- as.character(current[1, "gene_old"])
> +   output[1,3] <- position
> +   output[1,4] <- nposition
> +   output[1,5] <- num
> +   output[1,6] <- numhigh
> +   output[1,7] <- fst
> +   output[1,8] <- colors
> +   maxfstgene <- rbind(maxfstgene, output)
> + }
> Error in output[1, 2] <- as.character(current[1, "gene_old"]) :
>    replacement has length zero
> In addition: Warning message:
> In mean.default(current$pos) :
>    argument is not numeric or logical: returning NA
> --
>



From jvadams at usgs.gov  Wed Apr  2 22:55:26 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 2 Apr 2014 15:55:26 -0500
Subject: [R] ASA Conference on Statistical Practice - call for short courses
Message-ID: <CAN5YmCEQs8Lm2WyjL4GWNRdBhiNA-S=-zb8SCoahXvUU-MwZjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/cced147f/attachment-0001.pl>

From shj107 at gmail.com  Wed Apr  2 23:18:53 2014
From: shj107 at gmail.com (=?ISO-8859-1?Q?Stef=E1n_Hrafn_J=F3nsson?=)
Date: Wed, 2 Apr 2014 21:18:53 +0000
Subject: [R] Icelandic Characters in Mac
Message-ID: <CAMqewfLTJ1wYzvjR2WHKWqEOBufTRCj_+CYvo1sNmyakKw5Qig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140402/c1d29493/attachment-0001.pl>

From ingfimo at gmail.com  Wed Apr  2 23:30:13 2014
From: ingfimo at gmail.com (Filippo)
Date: Wed, 02 Apr 2014 22:30:13 +0100
Subject: [R] -fopenmp
Message-ID: <533C8165.7020906@gmail.com>

Hi everybody,
just wanted to know if it is possible to use the openmp library in 
Fortran code to be used within R.
I tried this simple thing:

subroutine test
!$OMP parallel
write(*,*) 'hello'
!$OMP end parallel
end subroutine test

and I compiled in the following way:

R CMD SHLIB test.f90 -fopenmp

but is seems not working.
The program correctly print me out four times 'hello' if I compile 
outside R simply using gfortran with the flag -fopenmp.
If someone can help me I would be very grateful.
Thanks in advance and regards
Filippo Monari



From ligges at statistik.tu-dortmund.de  Thu Apr  3 00:12:32 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 03 Apr 2014 00:12:32 +0200
Subject: [R] R2WinBUGS "expected collection operator c" error
In-Reply-To: <1396458655108-4688032.post@n4.nabble.com>
References: <1396458655108-4688032.post@n4.nabble.com>
Message-ID: <533C8B50.9000205@statistik.tu-dortmund.de>

This is probably a BUGS rather than an R problem, hence better for a 
BUGS mailing list. But if we should help, then we need at least the 
modelfile.

Best,
Uwe Ligges



On 02.04.2014 19:10, zumacrume wrote:
> Hi all,
> I am currently in a Bayesian Modeling course and am trying to implement an
> analog representation model using R, WinBUGS, and R2WinBUGS.  I'm currently
> stuck banging my head against an "expected collection operator c" error.  I
> am working off of a template code, and I swear I haven't moved any
> collection operators from the original code.
> Here is what my script looks like in R:
> ########################################################
>
> # clears workspace:
> rm(list=ls(all=TRUE))
>
> # sets working directories:
> setwd("C:\\Users\\Nick\\Desktop\\modeling")
> library(R2WinBUGS)
> bugsdir = "C:/Program Files/WinBUGS14"
>
> # read the data
>
> g   = matrix(scan("g.txt", sep=","), ncol=144, nrow=3, byrow=T)
> q   = matrix(scan("q.txt", sep=","), ncol=144, nrow=3, byrow=T)
> S   = 3         # number of subjects
> Q   = 144 # number of questions for each child
> N   = 9 # maximum numbers of item list
>
> data  = list("g", "q", "S", "Q", "N") # to be passed on to WinBUGS
> myinits =	list(
>    list(sigma = rep(1,S), pitmp=rep(1/N, N)))
>
> # parameters to be monitored:	
> parameters = c("pp","ppb","sigma")
>
> # NB. even with only 1000 iterations, the sampling can take a long time!
> # The following command calls WinBUGS with specific options.
> # For a detailed description see Sturtz, Ligges, & Gelman (2005).
> samples = bugs(data, inits=myinits, parameters,
> 	 			model.file ="NumberConcept_2_data.txt",
> 	 			n.chains=1, n.iter=1000, n.burnin=100, n.thin=1,
> 	 			DIC=T, bugs.directory=bugsdir,
> 	 			codaPkg=F, debug=T)
> # Now the values for the monitored parameters are in the "samples" object,
> # ready for inspection.
>
> samples$summary
>
> #######################################################
>
> and here is the log file file from WinBUGS after R2WinBUGS passes it over:
>
> #######################################################
> display(log)
> check(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/NumberConcept_2_data.txt)
> model is syntactically correct
> data(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/data.txt)
> expected collection operator c
> compile(1)
> inits(1,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/inits1.txt)
> command #Bugs:inits cannot be executed (is greyed out)
> gen.inits()
> command #Bugs:gen.inits cannot be executed (is greyed out)
> thin.updater(1)
> update(100)
> command #Bugs:update cannot be executed (is greyed out)
> set(pp)
> command #Bugs:set cannot be executed (is greyed out)
> set(ppb)
> command #Bugs:set cannot be executed (is greyed out)
> set(sigma)
> command #Bugs:set cannot be executed (is greyed out)
> set(deviance)
> command #Bugs:set cannot be executed (is greyed out)
> dic.set()
> command #Bugs:dic.set cannot be executed (is greyed out)
> update(900)
> command #Bugs:update cannot be executed (is greyed out)
> coda(*,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/coda)
> command #Bugs:coda cannot be executed (is greyed out)
> stats(*)
> command #Bugs:stats cannot be executed (is greyed out)
> dic.stats()
>
> DIC
> history(*,C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/history.odc)
> command #Bugs:history cannot be executed (is greyed out)
> save(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/log.odc)
> save(C:/Users/Nick/AppData/Local/Temp/RtmpIRZ1dh/log.txt)
>
> #################################################################
> WinBUGS also opens up a data window that looks like this:
> #################################################################
>
> list(g= structure(.Data= c(1.00000E+00, 1.00000E+00, 1.00000E+00,
> 1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 2.00000E+00, 2.00000E+00), .Dim=c(3, 144)), q=
> structure(.Data= c(4.00000E+00, 5.00000E+00, 3.00000E+00, 8.00000E+00,
> 1.00000E+00, 5.00000E+00, 4.00000E+00, 4.00000E+00, 3.00000E+00,
> 3.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 4.00000E+00,
> 5.00000E+00, 2.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 3.00000E+00, 7.00000E+00, 6.00000E+00,
> 5.00000E+00, 4.00000E+00, 7.00000E+00, 1.00000E+00, 1.00000E+00,
> 3.00000E+00, 6.00000E+00, 2.00000E+00, 6.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 3.00000E+00, 3.00000E+00, 4.00000E+00,
> 1.00000E+00, 7.00000E+00, 2.00000E+00, 2.00000E+00, 3.00000E+00,
> 4.00000E+00, 1.00000E+00, 3.00000E+00, 5.00000E+00, 6.00000E+00,
> 2.00000E+00, 6.00000E+00, 4.00000E+00, 2.00000E+00, 2.00000E+00,
> 5.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00, 4.00000E+00,
> 5.00000E+00, 3.00000E+00, 3.00000E+00, 1.00000E+00, 1.00000E+00,
> 7.00000E+00, 2.00000E+00, 1.00000E+00, 8.00000E+00, 4.00000E+00,
> 2.00000E+00, 1.00000E+00, 6.00000E+00, 4.00000E+00, 2.00000E+00,
> 3.00000E+00, 4.00000E+00, 2.00000E+00, 5.00000E+00, 1.00000E+00,
> 7.00000E+00, 2.00000E+00, 3.00000E+00, 5.00000E+00, 3.00000E+00,
> 6.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00, 3.00000E+00,
> 5.00000E+00, 1.00000E+00, 6.00000E+00, 2.00000E+00, 6.00000E+00,
> 4.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00, 1.00000E+00,
> 3.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00,
> 3.00000E+00, 2.00000E+00, 4.00000E+00, 8.00000E+00, 1.00000E+00,
> 1.00000E+00, 5.00000E+00, 6.00000E+00, 4.00000E+00, 7.00000E+00,
> 1.00000E+00, 6.00000E+00, 7.00000E+00, 5.00000E+00, 3.00000E+00,
> 3.00000E+00, 4.00000E+00, 4.00000E+00, 3.00000E+00, 3.00000E+00,
> 2.00000E+00, 5.00000E+00, 3.00000E+00, 2.00000E+00, 6.00000E+00,
> 1.00000E+00, 2.00000E+00, 3.00000E+00, 1.00000E+00, 5.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 4.00000E+00, 2.00000E+00,
> 8.00000E+00, 2.00000E+00, 4.00000E+00, 1.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 3.00000E+00, 7.00000E+00, 3.00000E+00,
> 1.00000E+00, 3.00000E+00, 2.00000E+00, 4.00000E+00, 7.00000E+00,
> 4.00000E+00, 1.00000E+00, 1.00000E+00, 5.00000E+00, 3.00000E+00,
> 6.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 2.00000E+00, 6.00000E+00, 5.00000E+00, 8.00000E+00,
> 4.00000E+00, 3.00000E+00, 5.00000E+00, 3.00000E+00, 4.00000E+00,
> 6.00000E+00, 4.00000E+00, 5.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 5.00000E+00,
> 5.00000E+00, 1.00000E+00, 4.00000E+00, 4.00000E+00, 1.00000E+00,
> 3.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 5.00000E+00,
> 3.00000E+00, 2.00000E+00, 1.00000E+00, 5.00000E+00, 6.00000E+00,
> 3.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 8.00000E+00,
> 2.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00, 1.00000E+00,
> 6.00000E+00, 7.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
> 6.00000E+00, 3.00000E+00, 2.00000E+00, 7.00000E+00, 3.00000E+00,
> 2.00000E+00, 3.00000E+00, 3.00000E+00, 7.00000E+00, 1.00000E+00,
> 3.00000E+00, 5.00000E+00, 5.00000E+00, 5.00000E+00, 6.00000E+00,
> 4.00000E+00, 6.00000E+00, 2.00000E+00, 2.00000E+00, 1.00000E+00,
> 4.00000E+00, 1.00000E+00, 8.00000E+00, 4.00000E+00, 5.00000E+00,
> 1.00000E+00, 4.00000E+00, 6.00000E+00, 2.00000E+00, 1.00000E+00,
> 3.00000E+00, 3.00000E+00, 1.00000E+00, 4.00000E+00, 2.00000E+00,
> 1.00000E+00, 2.00000E+00, 1.00000E+00, 3.00000E+00, 7.00000E+00,
> 8.00000E+00, 2.00000E+00, 2.00000E+00, 3.00000E+00, 2.00000E+00,
> 6.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00, 5.00000E+00,
> 4.00000E+00, 3.00000E+00, 3.00000E+00, 6.00000E+00, 2.00000E+00,
> 1.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00, 5.00000E+00,
> 1.00000E+00, 4.00000E+00, 4.00000E+00, 6.00000E+00, 3.00000E+00,
> 2.00000E+00, 5.00000E+00, 7.00000E+00, 5.00000E+00, 4.00000E+00,
> 3.00000E+00, 1.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00,
> 2.00000E+00, 3.00000E+00, 5.00000E+00, 1.00000E+00, 5.00000E+00,
> 1.00000E+00, 6.00000E+00, 6.00000E+00, 2.00000E+00, 2.00000E+00,
> 3.00000E+00, 3.00000E+00, 1.00000E+00, 3.00000E+00, 3.00000E+00,
> 4.00000E+00, 7.00000E+00, 5.00000E+00, 1.00000E+00, 1.00000E+00,
> 2.00000E+00, 1.00000E+00, 4.00000E+00, 4.00000E+00, 4.00000E+00,
> 2.00000E+00, 8.00000E+00, 7.00000E+00, 3.00000E+00, 5.00000E+00,
> 1.00000E+00, 6.00000E+00, 1.00000E+00, 2.00000E+00, 4.00000E+00,
> 1.00000E+00, 5.00000E+00, 3.00000E+00, 1.00000E+00, 4.00000E+00,
> 6.00000E+00, 3.00000E+00, 4.00000E+00, 7.00000E+00, 6.00000E+00,
> 1.00000E+00, 1.00000E+00, 8.00000E+00, 7.00000E+00, 6.00000E+00,
> 1.00000E+00, 4.00000E+00, 3.00000E+00, 2.00000E+00, 1.00000E+00,
> 2.00000E+00, 4.00000E+00, 1.00000E+00, 2.00000E+00, 2.00000E+00,
> 2.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 3.00000E+00,
> 4.00000E+00, 5.00000E+00, 5.00000E+00, 3.00000E+00, 5.00000E+00,
> 2.00000E+00, 6.00000E+00, 1.00000E+00, 5.00000E+00, 4.00000E+00,
> 4.00000E+00, 3.00000E+00, 5.00000E+00, 4.00000E+00, 1.00000E+00,
> 1.00000E+00, 2.00000E+00, 7.00000E+00, 4.00000E+00, 2.00000E+00,
> 5.00000E+00, 2.00000E+00, 6.00000E+00, 1.00000E+00, 6.00000E+00,
> 2.00000E+00, 3.00000E+00, 2.00000E+00, 3.00000E+00, 3.00000E+00,
> 4.00000E+00, 1.00000E+00, 1.00000E+00, 2.00000E+00, 3.00000E+00,
> 3.00000E+00, 7.00000E+00, 1.00000E+00, 2.00000E+00, 1.00000E+00,
> 5.00000E+00, 8.00000E+00, 4.00000E+00, 1.00000E+00, 8.00000E+00,
> 1.00000E+00, 5.00000E+00, 6.00000E+00, 3.00000E+00, 5.00000E+00,
> 4.00000E+00, 1.00000E+00, 3.00000E+00, 2.00000E+00, 5.00000E+00,
> 4.00000E+00, 3.00000E+00, 6.00000E+00, 1.00000E+00, 1.00000E+00,
> 7.00000E+00, 4.00000E+00, 2.00000E+00, 2.00000E+00, 4.00000E+00,
> 2.00000E+00, 1.00000E+00, 2.00000E+00, 5.00000E+00, 2.00000E+00,
> 3.00000E+00, 7.00000E+00, 2.00000E+00, 1.00000E+00, 1.00000E+00,
> 3.00000E+00, 6.00000E+00, 3.00000E+00), .Dim=c(3, 144)), S=3.00000E+00,
> Q=1.44000E+02, N=9.00000E+00)
>
> ##################################################################
>
> Which is my data from files g.txt and q.txt - I go looking for a missing
> collection operator c but cannot find it anywhere, if anyone has a clue what
> I could do to get past this point, I would be so grateful!
>
> Best,
> N
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/R2WinBUGS-expected-collection-operator-c-error-tp4688032.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From smartpink111 at yahoo.com  Thu Apr  3 00:41:01 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Apr 2014 15:41:01 -0700 (PDT)
Subject: [R] plotting several columns of matrix in one graph
Message-ID: <1396478461.5202.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
library(xts) 


library(xtsExtra)
data(sample_matrix)
plot(as.xts(sample_matrix),screens=1)
#or
library(zoo)
plot(as.zoo(sample_matrix), plot.type="single",col=1:ncol(sample_matrix))

You may also check ?matplot

A.K.


Hi everyone, I have started using R and although I am used to some other languages, I am struggling doing a plot that contains several lines which each correspond to a column of the Matrix which all my data. I tried to google it but unfortunately, it haven't found anything which helped me and also the description didn't really give me a hint what to do. Let's say I have Matrix calles Data_Set which consists of 6 columns and let's say 100 rows. in the first column, I have the date, which is also the x-axis of my plot. The next five column contain the time series, for each of them I want I line drawn in the plot. I have installed the lattice package and I tried several things using the xyplot command, but it didn't work. thanks so much for your help.



From james at crosb.ie  Thu Apr  3 00:35:49 2014
From: james at crosb.ie (jcrosbie)
Date: Wed, 2 Apr 2014 15:35:49 -0700 (PDT)
Subject: [R] Subset error on atomic vectors why?
Message-ID: <1396478149050-4688051.post@n4.nabble.com>

I'm getting this error: "Error in MOPrice$Date : $ operator is invalid for
atomic vectors"

The cost is: subset(MOPrice,
as.Date(MOPrice$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d")) 

The date column looks like:
"2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31"







--
View this message in context: http://r.789695.n4.nabble.com/Subset-error-on-atomic-vectors-why-tp4688051.html
Sent from the R help mailing list archive at Nabble.com.



From tlumley at uw.edu  Thu Apr  3 00:58:26 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 3 Apr 2014 11:58:26 +1300
Subject: [R] Survey
In-Reply-To: <CAKSaaF=+VT4uSwsa02XdFZ9c6eAN2e-1cyDE+_nrDSSZtummLA@mail.gmail.com>
References: <CAKSaaF=+VT4uSwsa02XdFZ9c6eAN2e-1cyDE+_nrDSSZtummLA@mail.gmail.com>
Message-ID: <CAJ55+dKcZaEcdBoOjYHe00_To8njJ-dzQCfeUiQN-nKdh5_vNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/b0f50d7e/attachment-0001.pl>

From dwinsemius at comcast.net  Thu Apr  3 00:59:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Apr 2014 15:59:49 -0700
Subject: [R] Icelandic Characters in Mac
In-Reply-To: <CAMqewfLTJ1wYzvjR2WHKWqEOBufTRCj_+CYvo1sNmyakKw5Qig@mail.gmail.com>
References: <CAMqewfLTJ1wYzvjR2WHKWqEOBufTRCj_+CYvo1sNmyakKw5Qig@mail.gmail.com>
Message-ID: <44B53F9D-8FAB-4FB1-8867-9790AF2FC54B@comcast.net>


On Apr 2, 2014, at 2:18 PM, Stef?n Hrafn J?nsson wrote:

> Dear R community
> 
> I have few students that use Mac. When creating graphs they inform me that
> when they use Icelandic characters in title or xlab they get some wrong
> results. In stead of
> 
> "?a? er s?tt" they get ".a. er s.tt" period in stead of the Icelandic
> character.
> 
> Any Icelandic Mac user that has a solution to this?  .
> 
> 
> The Icelandic characters follows.
> 
> ? ? ? ? ? ?,?  ? ? ? ? ? ? ?
> 
> http://en.wikipedia.org/wiki/Icelandic_alphabet

The default screen device is named quartz(). I'm not an Icelander, but in a US locale with the standard fonts I get faithful reproduction of those characters on a Mac running 10.7.5 with R 3.0.2

They need to be looking at:

?quartz

?quartzFonts

"sans" for a sans-serif font, 
"serif" for a serif font 
 "mono" for a monospaced font.

And they need to know what fonts would be appropriate to assign to the various families,s or they need to specify font families in their plotting calls. There may be a need to review how their locale settings are being specified.

-- 
David Winsemius
Alameda, CA, USA



From dwinsemius at comcast.net  Thu Apr  3 01:02:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Apr 2014 16:02:56 -0700
Subject: [R] Subset error on atomic vectors why?
In-Reply-To: <1396478149050-4688051.post@n4.nabble.com>
References: <1396478149050-4688051.post@n4.nabble.com>
Message-ID: <E1AE3537-E4BE-4338-A93B-1DCC96A502DF@comcast.net>


On Apr 2, 2014, at 3:35 PM, jcrosbie wrote:

> I'm getting this error: "Error in MOPrice$Date : $ operator is invalid for
> atomic vectors"
> 
> The cost is: subset(MOPrice,
> as.Date(MOPrice$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d")) 
> 
> The date column looks like:
> "2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31"
> 

What does str(MOPrice) return?


> View this message in context: http://r.789695.n4.nabble.com/Subset-error-on-atomic-vectors-why-tp4688051.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> 

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From smartpink111 at yahoo.com  Thu Apr  3 00:59:37 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Apr 2014 15:59:37 -0700 (PDT)
Subject: [R] Subset error on atomic vectors why?
In-Reply-To: <1396478149050-4688051.post@n4.nabble.com>
References: <1396478149050-4688051.post@n4.nabble.com>
Message-ID: <1396479577.68033.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
It is not mentioned whether your dataset is a matrix of data.frame.? Also, please use ?dput() to show the dataset.? I get similar errors with matrix.

MOPrice <- data.frame(Date=c("2013-12-31","2013-12-31","2013-12-31","2013-11-28"),stringsAsFactors=FALSE)
subset(MOPrice, as.Date(Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d"))
#        Date
#4 2013-11-28
MOPrice1 <- data.frame(Date=c("2013-12-31","2013-12-31","2013-12-31"),stringsAsFactors=FALSE)
subset(MOPrice1, as.Date(Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d"))
#[1] Date 

#<0 rows> (or 0-length row.names)

MOPrice2 <- data.frame(Date=c("2013-12-31","2013-12-31","2013-12-31"))
subset(MOPrice2, as.Date(MOPrice2$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d"))
#[1] Date
#<0 rows> (or 0-length row.names)
subset(MOPrice1, as.Date(MOPrice1$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d"))
#[1] Date
#<0 rows> (or 0-length row.names)
MOPrice3 <- as.matrix(MOPrice1)
subset(MOPrice3, as.Date(MOPrice3$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d"))
#Error in MOPrice3$Date : $ operator is invalid for atomic vectors 


A.K.


On Wednesday, April 2, 2014 6:49 PM, jcrosbie <james at crosb.ie> wrote:
I'm getting this error: "Error in MOPrice$Date : $ operator is invalid for
atomic vectors"

The cost is: subset(MOPrice,
as.Date(MOPrice$Date,"%Y-%m-%d")==as.Date("2013-11-28","%Y-%m-%d")) 

The date column looks like:
"2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31" "2013-12-31"







--
View this message in context: http://r.789695.n4.nabble.com/Subset-error-on-atomic-vectors-why-tp4688051.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From friendly at yorku.ca  Thu Apr  3 03:19:45 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 02 Apr 2014 21:19:45 -0400
Subject: [R] ggplot: add points selectively to curves
In-Reply-To: <CADv2QyHkR+w21usNfivB_kJmg_2hanJKnGrups3DW8TxHn27=A@mail.gmail.com>
References: <533C220B.5020408@yorku.ca>
	<CADv2QyHkR+w21usNfivB_kJmg_2hanJKnGrups3DW8TxHn27=A@mail.gmail.com>
Message-ID: <533CB731.8060604@yorku.ca>

Thanks, Dennis

Not quite.  I need to have the same lines as in the original, using 
plotdat, but then
add the points from your plotdat2

gg <- ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) +
     geom_line(size=2.5) + theme_bw() + xlim(10,80) +
#    geom_point(color="black", size=1.5) +         # not these points
     facet_grid(Sex ~ Treatment, # scales = "free",
                labeller = function(x, y) sprintf("%s = %s", x, y)
                )

# want these points, added to the above plot
plotdat2 <- subset(plotdat,
                      as.character(Improved) == as.character(Level))



On 02/04/2014 7:09 PM, Dennis Murphy wrote:
> Hi Michael:
>
> Does this work?
>
> plotdat2 <- subset(plotdat,
>                       as.character(Improved) == as.character(Level))
> ggplot(plotdat2, aes(x = Age, y = Probability, color = Level)) +
>      geom_line(size=2.5) + theme_bw() + xlim(10,80) +
>      geom_point(color="black", size=1.5) +
>      facet_grid(Sex ~ Treatment,
>                 labeller = function(x, y) sprintf("%s = %s", x, y)
>                 )
>
> Dennis
>
> On Wed, Apr 2, 2014 at 7:43 AM, Michael Friendly <friendly at yorku.ca> wrote:
>> I'm working on an example of plotting predicted probabilities from a
>> proportional odds model.
>> The steps below generate a data frame, plotdat, that I want to plot with
>> ggplot.
>>
>> library(MASS)
>> data("Arthritis", package="vcd")
>> arth.polr <- polr(Improved ~ Sex + Treatment + Age, data=Arthritis,
>> Hess=TRUE)
>>
>> # get predicted probs for categories of Improve
>> arth.fitp <- cbind(Arthritis,
>>                    predict(arth.polr, type="probs"))
>> head(arth.fitp)
>>
>> # reshape probs to long
>> library(reshape2)
>> plotdat <- melt(arth.fitp,
>>                  id.vars = c("Sex", "Treatment", "Age", "Improved"),
>>                  measure.vars=c("None", "Some", "Marked"),
>>                  variable.name = "Level",
>>                  value.name = "Probability")
>> ## view first few rows
>> head(plotdat)
>>
>>> head(plotdat)
>>     Sex Treatment Age Improved Level Probability
>> 1 Male   Treated  27     Some  None   0.7326185
>> 2 Male   Treated  29     None  None   0.7174048
>> 3 Male   Treated  30     None  None   0.7096042
>> 4 Male   Treated  32   Marked  None   0.6936286
>> 5 Male   Treated  46   Marked  None   0.5702499
>> 6 Male   Treated  58   Marked  None   0.4563432
>>
>> In the plot step, I am plotting Probability vs. Age, stratified by Level,
>> and faceted by
>> Sex and Treatment.  My question concerns the use of geom_point().
>> The call below plots 3 points for each case, one on each Level curve.
>>
>>
>> ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) +
>>      geom_line(size=2.5) + theme_bw() + xlim(10,80) +
>>      geom_point(color="black", size=1.5) +
>>      facet_grid(Sex ~ Treatment,
>>                 labeller = function(x, y) sprintf("%s = %s", x, y)
>>                 )
>>
>> Instead,
>> I want to plot only one point for each case, for the value of Level that
>> corresponds
>> to the value of Improved in this data set.  Somehow, this involves something
>> like an aes() argument to geom_point(), with Level indexed by Improved, or
>> some such.
>> How can I do this?
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From smartpink111 at yahoo.com  Thu Apr  3 04:25:32 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Apr 2014 19:25:32 -0700 (PDT)
Subject: [R] ggplot: add points selectively to curves
In-Reply-To: <533CB731.8060604@yorku.ca>
References: <533C220B.5020408@yorku.ca>	<CADv2QyHkR+w21usNfivB_kJmg_2hanJKnGrups3DW8TxHn27=A@mail.gmail.com>
	<533CB731.8060604@yorku.ca>
Message-ID: <1396491932.44608.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
gg <- ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) + geom_line(size=2.5) + theme_bw() + xlim(10,80) + facet_grid(Sex ~ Treatment, # scales = "free", labeller = function(x, y) sprintf("%s = %s", x, y) ) 

plotdat2 <- subset(plotdat,as.character(Improved)==as.character(Level)) 


gg+geom_point(data= plotdat2, aes(x=Age, y=Probability),color="black",size=1.5)


A.K.


On Wednesday, April 2, 2014 9:22 PM, Michael Friendly <friendly at yorku.ca> wrote:
Thanks, Dennis

Not quite.? I need to have the same lines as in the original, using 
plotdat, but then
add the points from your plotdat2

gg <- ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) +
? ?  geom_line(size=2.5) + theme_bw() + xlim(10,80) +
#? ? geom_point(color="black", size=1.5) +? ? ? ?  # not these points
? ?  facet_grid(Sex ~ Treatment, # scales = "free",
? ? ? ? ? ? ? ? labeller = function(x, y) sprintf("%s = %s", x, y)
? ? ? ? ? ? ? ? )

# want these points, added to the above plot
plotdat2 <- subset(plotdat,
? ? ? ? ? ? ? ? ? ? ? as.character(Improved) == as.character(Level))



On 02/04/2014 7:09 PM, Dennis Murphy wrote:
> Hi Michael:
>
> Does this work?
>
> plotdat2 <- subset(plotdat,
>? ? ? ? ? ? ? ? ? ? ?  as.character(Improved) == as.character(Level))
> ggplot(plotdat2, aes(x = Age, y = Probability, color = Level)) +
>? ? ? geom_line(size=2.5) + theme_bw() + xlim(10,80) +
>? ? ? geom_point(color="black", size=1.5) +
>? ? ? facet_grid(Sex ~ Treatment,
>? ? ? ? ? ? ? ?  labeller = function(x, y) sprintf("%s = %s", x, y)
>? ? ? ? ? ? ? ?  )
>
> Dennis
>
> On Wed, Apr 2, 2014 at 7:43 AM, Michael Friendly <friendly at yorku.ca> wrote:
>> I'm working on an example of plotting predicted probabilities from a
>> proportional odds model.
>> The steps below generate a data frame, plotdat, that I want to plot with
>> ggplot.
>>
>> library(MASS)
>> data("Arthritis", package="vcd")
>> arth.polr <- polr(Improved ~ Sex + Treatment + Age, data=Arthritis,
>> Hess=TRUE)
>>
>> # get predicted probs for categories of Improve
>> arth.fitp <- cbind(Arthritis,
>>? ? ? ? ? ? ? ? ? ? predict(arth.polr, type="probs"))
>> head(arth.fitp)
>>
>> # reshape probs to long
>> library(reshape2)
>> plotdat <- melt(arth.fitp,
>>? ? ? ? ? ? ? ? ? id.vars = c("Sex", "Treatment", "Age", "Improved"),
>>? ? ? ? ? ? ? ? ? measure.vars=c("None", "Some", "Marked"),
>>? ? ? ? ? ? ? ? ? variable.name = "Level",
>>? ? ? ? ? ? ? ? ? value.name = "Probability")
>> ## view first few rows
>> head(plotdat)
>>
>>> head(plotdat)
>>? ?  Sex Treatment Age Improved Level Probability
>> 1 Male?  Treated? 27? ?  Some? None?  0.7326185
>> 2 Male?  Treated? 29? ?  None? None?  0.7174048
>> 3 Male?  Treated? 30? ?  None? None?  0.7096042
>> 4 Male?  Treated? 32?  Marked? None?  0.6936286
>> 5 Male?  Treated? 46?  Marked? None?  0.5702499
>> 6 Male?  Treated? 58?  Marked? None?  0.4563432
>>
>> In the plot step, I am plotting Probability vs. Age, stratified by Level,
>> and faceted by
>> Sex and Treatment.? My question concerns the use of geom_point().
>> The call below plots 3 points for each case, one on each Level curve.
>>
>>
>> ggplot(plotdat, aes(x = Age, y = Probability, color = Level)) +
>>? ? ? geom_line(size=2.5) + theme_bw() + xlim(10,80) +
>>? ? ? geom_point(color="black", size=1.5) +
>>? ? ? facet_grid(Sex ~ Treatment,
>>? ? ? ? ? ? ? ?  labeller = function(x, y) sprintf("%s = %s", x, y)
>>? ? ? ? ? ? ? ?  )
>>
>> Instead,
>> I want to plot only one point for each case, for the value of Level that
>> corresponds
>> to the value of Improved in this data set.? Somehow, this involves something
>> like an aes() argument to geom_point(), with Level indexed by Improved, or
>> some such.
>> How can I do this?
>>
>> --
>> Michael Friendly? ?  Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University? ? ? Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street? ? Web:? http://www.datavis.ca
>> Toronto, ONT? M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Michael Friendly? ?  Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University? ? ? Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street? ? Web:? http://www.datavis.ca
Toronto, ONT? M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From smartpink111 at yahoo.com  Thu Apr  3 04:55:34 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Apr 2014 19:55:34 -0700 (PDT)
Subject: [R] plotting several columns of matrix in one graph
In-Reply-To: <1396478461.5202.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1396478461.5202.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1396493734.17599.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
It is better to show a reproducible example using ?dput().? May be this helps:
#vector

vec1 <- seq(as.Date("2002-01-01"), as.Date("2009-12-31"),by="1 day")
#Assuming that length of the vector is the same as ?nrow of matrix.

set.seed(532)
mat1 <- matrix(cumsum(rnorm(length(vec1)*5)),ncol=5, dimnames=list(NULL,LETTERS[1:5]))

library(xts) 

library(xtsExtra)
plot(as.xts(mat1,order.by=vec1),major.format="%Y",screens=1, main="Time series plot", auto.legend=TRUE,auto.grid=FALSE,col=5:1)

You should also check ?legend()

A.K.







thank you so much. it tried the 2nd way and it is working perfectly. could you also tell me how I can select a vector which is then used for the x axis? let's say I want some Dates 2002 to 2009, currently I have a vector called date which contains of every single day from 2002 to 2009, is there a way to get this on the x axis (just the year)? in Addition, is there some command to add a legend, titles, Change Color etc? From what I find on the Internet, I just don't understand how that is working. thanks again for the help! 


On Wednesday, April 2, 2014 6:41 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
May be this helps:
library(xts) 


library(xtsExtra)
data(sample_matrix)
plot(as.xts(sample_matrix),screens=1)
#or
library(zoo)
plot(as.zoo(sample_matrix), plot.type="single",col=1:ncol(sample_matrix))

You may also check ?matplot

A.K.


Hi everyone, I have started using R and although I am used to some other languages, I am struggling doing a plot that contains several lines which each correspond to a column of the Matrix which all my data. I tried to google it but unfortunately, it haven't found anything which helped me and also the description didn't really give me a hint what to do. Let's say I have Matrix calles Data_Set which consists of 6 columns and let's say 100 rows. in the first column, I have the date, which is also the x-axis of my plot. The next five column contain the time series, for each of them I want I line drawn in the plot. I have installed the lattice package and I tried several things using the xyplot command, but it didn't work. thanks so much for your help.



From ripley at stats.ox.ac.uk  Thu Apr  3 06:15:18 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 03 Apr 2014 05:15:18 +0100
Subject: [R] -fopenmp
In-Reply-To: <533C8165.7020906@gmail.com>
References: <533C8165.7020906@gmail.com>
Message-ID: <533CE056.40108@stats.ox.ac.uk>

On 02/04/2014 22:30, Filippo wrote:
> Hi everybody,
> just wanted to know if it is possible to use the openmp library in
> Fortran code to be used within R.

Yes, on a supported platform.  But

1) The posting guide tells you this is not the correct list for 
questions about compiled code.

2) 'Writing R Extensions' tells you how to do this.

3) ?SHLIB tells you about valid inputs, which do not include arbitrary 
flags.

> I tried this simple thing:
>
> subroutine test
> !$OMP parallel
> write(*,*) 'hello'
> !$OMP end parallel
> end subroutine test
>
> and I compiled in the following way:
>
> R CMD SHLIB test.f90 -fopenmp
>
> but is seems not working.
> The program correctly print me out four times 'hello' if I compile
> outside R simply using gfortran with the flag -fopenmp.
> If someone can help me I would be very grateful.
> Thanks in advance and regards
> Filippo Monari
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lucy.leigh at newcastle.edu.au  Thu Apr  3 04:29:13 2014
From: lucy.leigh at newcastle.edu.au (Lucy Leigh)
Date: Thu, 3 Apr 2014 02:29:13 +0000
Subject: [R] 'rms' package error
Message-ID: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/59291feb/attachment-0001.pl>

From my.r.help at gmail.com  Thu Apr  3 04:51:13 2014
From: my.r.help at gmail.com (Michael Smith)
Date: Thu, 03 Apr 2014 10:51:13 +0800
Subject: [R] Strange sprintf Behavior
In-Reply-To: <d722f647-a8bb-4f73-be20-95f568ed0bae@email.android.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
	<533BF54A.6090003@gmail.com>
	<d722f647-a8bb-4f73-be20-95f568ed0bae@email.android.com>
Message-ID: <533CCCA1.6080007@gmail.com>

All,

Apologies for the thread issue, and many thanks for the pointers to the
FAQs.

Thanks,
M

On 04/02/2014 10:14 PM, Jeff Newmiller wrote:
> It is poor netiquette to reply to a thread with a different subject. Please start a new thread for a new subject.
> 
> As for your question, see FAQ 7.31. This is standard floating point numerical limitations at work.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On April 2, 2014 4:32:26 AM PDT, Michael Smith <my.r.help at gmail.com> wrote:
>> All,
>>
>> I'm getting this:
>>
>>> sprintf("%.17f", 0.8)
>> [1] "0.80000000000000004"
>>
>> Where does the `4` at the end come from? Shouldn't it be zero at the
>> end? Maybe I'm missing something.
>>
>>> sessionInfo()
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>> LC_TIME=en_US.utf8
>> [4] LC_COLLATE=en_US.utf8     LC_MONETARY=en_US.utf8
>> LC_MESSAGES=en_US.utf8
>> [7] LC_PAPER=en_US.utf8       LC_NAME=C                 LC_ADDRESS=C
>>
>> [10] LC_TELEPHONE=C            LC_MEASUREMENT=en_US.utf8
>> LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> Thanks,
>>
>> M
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From kridox at ymail.com  Thu Apr  3 06:36:36 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 3 Apr 2014 13:36:36 +0900
Subject: [R] 'rms' package error
In-Reply-To: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <CAAcyNCy7C9TmrpSGTMPZmN23xWFvbj9MYcBBa-KH573tOMBThA@mail.gmail.com>

Hello Lucy,

If you carefully read, it is is not an error message, but a warning
message. It tells you that for the moment, if I am not mistaken,
"pphsm" does not return the correct covariance matrix, for any
fitting.

Regards,
Pascal

On Thu, Apr 3, 2014 at 11:29 AM, Lucy Leigh <lucy.leigh at newcastle.edu.au> wrote:
> Hi everyone,
> I am attempting to use the R package 'rms'
> http://biostat.mc.vanderbilt.edu/wiki/Main/Rrms
> to implement a PH weibull model, using the pphsm() function.
>
> However, I get the following error,
> f.ph <- pphsm(f)
> Warning message:
> In pphsm(f) :
>   at present, pphsm does not return the correct covariance matrix
>
> I tried simply running the example on page 117 of the manual, i.e.
> set.seed(1)
> S <- Surv(runif(100))
> x <- runif(100)
> dd <- datadist(x); options(datadist='dd')
> f <- psm(S ~ x, dist="exponential")
> summary(f) # effects on log(T) scale
> f.ph <- pphsm(f)
> ## Not run: summary(f.ph)
>
> But I still got the above error message.
> I have looked through the R help archives, and it appears that this question has been asked before in 2011, but
> there were no replies.
> http://r.789695.n4.nabble.com/HELP-td3494640.html
>
> Does anyone know how to get this function to work? Or if there is an alternative package that can implement
> a Weibull PH model?
> Cheers,
> Lucy
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From yczhang at nigpas.ac.cn  Thu Apr  3 07:32:03 2014
From: yczhang at nigpas.ac.cn (=?GBK?B?1cXS1LS6?=)
Date: Thu, 3 Apr 2014 13:32:03 +0800 (GMT+08:00)
Subject: [R] figure margins too large
Message-ID: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/c378fc4f/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Thu Apr  3 08:42:30 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 02 Apr 2014 23:42:30 -0700
Subject: [R] data.frame(1)*1:4 = 1?
Message-ID: <533D02D6.9060105@structuremonitoring.com>

Hello, All:


       What's the logic behind "data.frame(1)*1:4" producing a scalar 
1?  Or the following:


  data.frame(1:2, 3:4)*5:7
   X1.2 X3.4
1    5   21
2   12   20


       I stumbled over this, because I thought I was multiplying a 
scalar times a vector, and obtaining a scalar rather than the 
anticipated vector.  I learned that my "scalar" was in fact a data.frame 
with one row and one column.


       What am I missing?


       Thanks,
       Spencer



From fabian at tbi.univie.ac.at  Thu Apr  3 08:56:07 2014
From: fabian at tbi.univie.ac.at (fabian)
Date: Thu, 03 Apr 2014 08:56:07 +0200
Subject: [R] =?utf-8?b?ZGF0YS5mcmFtZSgxKSoxOjQgPSAxPw==?=
In-Reply-To: <533D02D6.9060105@structuremonitoring.com>
References: <533D02D6.9060105@structuremonitoring.com>
Message-ID: <f1f9186e709b9c8550d41e6ae71186f7@tbi.univie.ac.at>

This is because your vector is recycled:

data.frame(1)*1:4 = data.frame(1)*c(1,2,3,4)

only the first element is needed since the data frame has nothing else 
to multiply with c(2,3,4)


(x<-data.frame(1:2, 3:4))
   X1.2 X3.4
1    1    3
2    2    4

(y<-x*5:7)

y[1,1] = x[1,1] * 5
y[2,1] = x[2,1] * 6
y[1,2] = x[1,2] * 7
y[2,2] = x[2,2] * 5

since you have e vector with length 3, for the 4th entry in the 
data.frame the first element in the vector is recycled.

hope this helps



On 03-04-2014 08:42, Spencer Graves wrote:
> Hello, All:
> 
> 
>       What's the logic behind "data.frame(1)*1:4" producing a scalar
> 1?  Or the following:
> 
> 
>  data.frame(1:2, 3:4)*5:7
>   X1.2 X3.4
> 1    5   21
> 2   12   20
> 
> 
>       I stumbled over this, because I thought I was multiplying a
> scalar times a vector, and obtaining a scalar rather than the
> anticipated vector.  I learned that my "scalar" was in fact a
> data.frame with one row and one column.
> 
> 
>       What am I missing?
> 
> 
>       Thanks,
>       Spencer
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Thu Apr  3 09:02:47 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 03 Apr 2014 18:02:47 +1100
Subject: [R] figure margins too large
In-Reply-To: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>
References: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>
Message-ID: <533D0797.7030505@bitwrit.com.au>

On 04/03/2014 04:32 PM, ??? wrote:
> Dear R experts,
>
>
> I tried to plot some figures in R using postscript(), but it always shows that the fugures margin is too large. I don't know how to change it. The following is my example:
>
>
>> postscript("All.eps",width=3.27,height=1.416,pointsize=12,family="Arial")
>> par(mar=c(5.1,4.5,4.1,2.1));boxplot(All~Nameall,ylab= expression(Size~ (log [10]~mm ^2)), boxwex=0.3, main="All species",col=c("red","yellow","blue"),ylim=c(0,4.0))
>> Error: plot.new() : figure margins too large
>
>
> When I run the boxplot in R, it shows well, but once I run it in the postscript, it fails. Can someone help me on it?
> Note: my operational system is windows 7.
>
>
Hi Yichun,
It is probably because you are trying to set up a very small postscript 
device, and after the margins have been allocated, there is no room for 
the plot. Try doing the plot with a larger size (e.g. width=8, height=4) 
and see if you can scale it down afterward.

Jim



From ripley at stats.ox.ac.uk  Thu Apr  3 09:07:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 03 Apr 2014 08:07:51 +0100
Subject: [R] figure margins too large
In-Reply-To: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>
References: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>
Message-ID: <533D08C7.4040901@stats.ox.ac.uk>

On 03/04/2014 06:32, ??? wrote:
> Dear R experts,
>
>
> I tried to plot some figures in R using postscript(), but it always shows that the fugures margin is too large. I don't know how to change it. The following is my example:
>
>
>> postscript("All.eps",width=3.27,height=1.416,pointsize=12,family="Arial")
>> par(mar=c(5.1,4.5,4.1,2.1));boxplot(All~Nameall,ylab= expression(Size~ (log [10]~mm ^2)), boxwex=0.3, main="All species",col=c("red","yellow","blue"),ylim=c(0,4.0))
>> Error: plot.new() : figure margins too large
>
>
> When I run the boxplot in R, it shows well, but once I run it in the postscript, it fails. Can someone help me on it?
> Note: my operational system is windows 7.

Given your pointsize, the margins take up all the plot.  So do one of

- increase the device size (recommended)
- reduce the pointsize
- reduce the margins (the par(mar=) setting), carefully

Also, you have not shown us the 'at a minimum' information asked for in 
the posting guide, but family = "Arial" is unknown in current R (3.1.0 
RC has "ArialMT"), and that call will not produce an EPS file.

>
>
> Many thanks in advance
> Yichun
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jwiley.psych at gmail.com  Thu Apr  3 09:07:49 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 Apr 2014 00:07:49 -0700
Subject: [R] data.frame(1)*1:4 = 1?
In-Reply-To: <533D02D6.9060105@structuremonitoring.com>
References: <533D02D6.9060105@structuremonitoring.com>
Message-ID: <CANz9Z_JmtKdgH347gZ15owDaGSaHJyQceDhEPcDqfvXPKv661g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/5283c154/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Thu Apr  3 09:42:01 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 03 Apr 2014 00:42:01 -0700
Subject: [R] data.frame(1)*1:4 = 1?
In-Reply-To: <CANz9Z_JmtKdgH347gZ15owDaGSaHJyQceDhEPcDqfvXPKv661g@mail.gmail.com>
References: <533D02D6.9060105@structuremonitoring.com>
	<CANz9Z_JmtKdgH347gZ15owDaGSaHJyQceDhEPcDqfvXPKv661g@mail.gmail.com>
Message-ID: <533D10C9.5000106@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/1ad9d211/attachment-0001.pl>

From katherine_gobin at yahoo.com  Thu Apr  3 12:22:23 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 3 Apr 2014 18:22:23 +0800 (SGT)
Subject: [R] How to store interim print results
Message-ID: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/bb538fa6/attachment-0001.pl>

From srdjan.santic at gmail.com  Thu Apr  3 12:35:37 2014
From: srdjan.santic at gmail.com (Srdjan Santic)
Date: Thu, 3 Apr 2014 12:35:37 +0200
Subject: [R] ff package: problem with reading in numerical values
Message-ID: <CALe19-26rq1z+ykpjikuziUqCCScv8hUnnExLv4HV2u6+OVRFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/1dc9e299/attachment-0001.pl>

From kevin.thorpe at utoronto.ca  Thu Apr  3 14:17:03 2014
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 3 Apr 2014 08:17:03 -0400
Subject: [R] 'rms' package error
In-Reply-To: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <533D513F.4020701@utoronto.ca>

On 04/02/2014 10:29 PM, Lucy Leigh wrote:
> Hi everyone,
> I am attempting to use the R package 'rms'
> http://biostat.mc.vanderbilt.edu/wiki/Main/Rrms
> to implement a PH weibull model, using the pphsm() function.
>
> However, I get the following error,
> f.ph <- pphsm(f)
> Warning message:
> In pphsm(f) :
>    at present, pphsm does not return the correct covariance matrix
>
> I tried simply running the example on page 117 of the manual, i.e.
> set.seed(1)
> S <- Surv(runif(100))
> x <- runif(100)
> dd <- datadist(x); options(datadist='dd')
> f <- psm(S ~ x, dist="exponential")
> summary(f) # effects on log(T) scale
> f.ph <- pphsm(f)
> ## Not run: summary(f.ph)
>
> But I still got the above error message.
> I have looked through the R help archives, and it appears that this question has been asked before in 2011, but
> there were no replies.
> http://r.789695.n4.nabble.com/HELP-td3494640.html
>
> Does anyone know how to get this function to work? Or if there is an alternative package that can implement
> a Weibull PH model?
> Cheers,
> Lucy
>

Maybe I'm missing something, but since the AFT and PH models intersect 
in the weibull distribution, why not just use the psm() function to fit 
the parametric model. You can still obtain hazard ratio estimates from 
that model with a little bit of calculation (e.g. exp(-beta/scale)).


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From roger.bivand at nhh.no  Thu Apr  3 13:45:15 2014
From: roger.bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2014 11:45:15 +0000
Subject: [R] trouble using readOGR() function
References: <1396344405775-4687937.post@n4.nabble.com>
Message-ID: <loom.20140403T133621-477@post.gmane.org>

remissssss <rgenevest <at> free.fr> writes:

> 
> Hi all,
> I got some trouble trying to open a .kml file into R. Usually, the readOGR
> package works great for it but here I get a message error that I can't
> understand.
> 
> When I'm typing this :
> myfile <-readOGR(dsn="/windows/landuse.kml",layer="agricultural use")
> 
> I get the following error :
> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv =
> use_iconv) :
> Multiple incompatible geometries: 6:7
> 

readOGR is a function in the rgdal package. This is a specialised question
better asked on R-sig-geo. In addition, you have not provided the output of
sessionInfo() so that we know your platform and package versions, nor the
messages shown on the console when rgdal is loaded (versions of the external
libraries being interfaced.

The sp classes into which you are reading data can only hold points or lines
or polygons separately. I have revised ogrInfo so that instead of 6:7 it
will in the future show: MultiPolygon:GeometryCollection.

A geometry collection is a catch-all that your data source (the provider of
the KML file) hasn't managed to define in a simple way, and this is where
you need to go to resolve the problem. 

Hope this clarifies,

Roger

> It seems that the file is read, since I get different parameters on it while
> using OGRSpatialRef() or ogrListLayers()
> 
> Someone would have any idea to solve the "incompatible geometry" error ?
> 
> Thanks for help!
>



From mdsumner at gmail.com  Thu Apr  3 15:24:49 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 4 Apr 2014 00:24:49 +1100
Subject: [R] trouble using readOGR() function
In-Reply-To: <1396344405775-4687937.post@n4.nabble.com>
References: <1396344405775-4687937.post@n4.nabble.com>
Message-ID: <CAAcGz9_ajv-8nrVYtjMdJb=-QmRAnx+_Q7gquhLk1G643HjGjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/dd1296d3/attachment-0001.pl>

From jholtman at gmail.com  Thu Apr  3 15:25:52 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 3 Apr 2014 09:25:52 -0400
Subject: [R] How to store interim print results
In-Reply-To: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
References: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
Message-ID: <CAAxdm-66aoAkFiiyTKg7acf3xH4xTGP6KjwGYmvegJ=zW0XS_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/a74e6603/attachment-0001.pl>

From roger.bivand at nhh.no  Wed Apr  2 12:48:34 2014
From: roger.bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2014 10:48:34 +0000
Subject: [R] trouble using readOGR() function
References: <1396344405775-4687937.post@n4.nabble.com>
Message-ID: <loom.20140402T122849-233@post.gmane.org>

remissssss <rgenevest <at> free.fr> writes:

> 
> Hi all,
> I got some trouble trying to open a .kml file into R. Usually, the readOGR
> package works great for it but here I get a message error that I can't
> understand.
> 
> When I'm typing this :
> myfile <-readOGR(dsn="/windows/landuse.kml",layer="agricultural use")
> 
> I get the following error :
> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv =
> use_iconv) :
> Multiple incompatible geometries: 6:7
> 

Please consider using the R-sig-geo list, as this is a somewhat specialised
question not of interest to most R-help subscribers.

When posting questions, always report the output of sessionInfo(), so giving
your platform information (here probably Windows?) and package versions.

The problem is not that the file cannot be opened, but that it contains
multiple incompatible geometries, as the error message says. If you file
contains incompatible geometries, ones that cannot be read as points or
lines or polygons, the data can be read, but cannot be imported into sp
classes, which treat these geometry types separately. Here, type 6 is
wkbMultiPolygon, while type 7 is wkbGeometryCollection, which is not
acceptable under any circumstances. 

Consequently, the problem is in the software generating the file you are
trying to read, or your expectation of being able to read a file into sp
classes for which no provision is made. Most likely the upstream software is
passing on a geometry problem it hasn't resolved itself.

Hope this clarifies,

Roger

> 
> Someone would have any idea to solve the "incompatible geometry" error ?
> 
> Thanks for help!
>



From jvadams at usgs.gov  Thu Apr  3 15:28:06 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 3 Apr 2014 08:28:06 -0500
Subject: [R] How to store interim print results
In-Reply-To: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
References: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
Message-ID: <CAN5YmCE4K6HHMcsUuqy6w=o+osfZzqtpR4sXFQr8FeLAHQjrHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/d578e0ca/attachment-0001.pl>

From goran.brostrom at umu.se  Thu Apr  3 15:56:00 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 3 Apr 2014 15:56:00 +0200
Subject: [R] 'rms' package error
In-Reply-To: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <c75aea77f0dd48be9c956980d1151165@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <533D6870.5010108@umu.se>



On 04/03/2014 04:29 AM, Lucy Leigh wrote:
> Hi everyone,
> I am attempting to use the R package 'rms'
> http://biostat.mc.vanderbilt.edu/wiki/Main/Rrms
> to implement a PH weibull model, using the pphsm() function.
>
> However, I get the following error,
> f.ph <- pphsm(f)
> Warning message:
> In pphsm(f) :
>    at present, pphsm does not return the correct covariance matrix
>
> I tried simply running the example on page 117 of the manual, i.e.
> set.seed(1)
> S <- Surv(runif(100))
> x <- runif(100)
> dd <- datadist(x); options(datadist='dd')
> f <- psm(S ~ x, dist="exponential")
> summary(f) # effects on log(T) scale
> f.ph <- pphsm(f)
> ## Not run: summary(f.ph)
>
> But I still got the above error message.
> I have looked through the R help archives, and it appears that this question has been asked before in 2011, but
> there were no replies.
> http://r.789695.n4.nabble.com/HELP-td3494640.html
>
> Does anyone know how to get this function to work? Or if there is an alternative package that can implement
> a Weibull PH model?

The function 'phreg' in the package 'eha' fits parametric PH models to 
right-censored and left-truncated data for some baseline distributions, 
among them the Weibull.

G?ran Brostr?m

> Cheers,
> Lucy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From vikrant.shimpi at tcs.com  Thu Apr  3 11:17:50 2014
From: vikrant.shimpi at tcs.com (vikrant)
Date: Thu, 3 Apr 2014 02:17:50 -0700 (PDT)
Subject: [R] Converting corpus into dataframe in r tm package
Message-ID: <1396516670687-4688081.post@n4.nabble.com>

HI ,

I would like to do stemming operation on vector of words using tm package. I
am using R 2.8.1 and tm package for same. For doing any operations i tm
package the data first needs to be converted to corpus
and then use various commands in tm package. No problem is I am not able to
convert these processed corpus into a dataframe/ vector. I am using
following commands for the same.

library(tm)
docs <- c("mining","miners")
s = Corpus(VectorSource(docs))
b = tmMap(s, stemDoc)
inspect(b)

By inspect command I am able to view the desired output but cannot convert
it into dataframeor any other datastructure for further usage. Inspect
command produces following output :
A corpus with 2 text documents

The metadata consists of 2 tag-value pairs and a data frame
Available tags are:
  create_date creator 
Available variables in the data frame are:
  MetaID 

[[1]]
[1] mine

[[2]]
[1] miner

I need only results 'mine' , 'miner' in a vector. Please help



--
View this message in context: http://r.789695.n4.nabble.com/Converting-corpus-into-dataframe-in-r-tm-package-tp4688081.html
Sent from the R help mailing list archive at Nabble.com.



From monaly.mistry at gmail.com  Thu Apr  3 14:16:32 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Thu, 3 Apr 2014 13:16:32 +0100
Subject: [R] nearest neighbour
Message-ID: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/e47e8767/attachment-0001.pl>

From nj.negovetich at gmail.com  Thu Apr  3 15:29:15 2014
From: nj.negovetich at gmail.com (Nick Negovetich)
Date: Thu, 03 Apr 2014 08:29:15 -0500
Subject: [R] Mixed Effects MANOVA
Message-ID: <533D622B.7080502@gmail.com>

Greetings,

I have a question regarding data analysis of habitat use of animals.  
These animals were radio collared and tracked periodically throughout 
the year.  When they were sighted/detected, the habitat type was 
marked.  Our dataset recorded the sex of the animal, and we know the 
data when the surveys were performed.  The goal was to address the 
questions: does habitat use differ between the sexes, and does habitat 
use vary between seasons?  Below is a summary table, ignoring seasons.

dattab <- matrix(c(190,87,206,170,103,23,66,72,53,22),nrow=5,byrow=T)
rownames(dattab) <- c("Rock","Burrow","Cactus","Brushpile","Other")
colnames(dattab) <- c("Female","Male")
dattab
           Female Male
Rock         190   87
Burrow       206  170
Cactus       103   23
Brushpile     66   72
Other         53   22

We could perform a test of independence, but the problem lies with our 
assumptions.  Because individual animals were tracked through time, each 
animal give a different number of datapoints (min=1, max=126), which 
violates our assumption of independence.  Thus, our sampling unit should 
be at the level of the skunk and analysis should proceed from there.  
I'm familiar (theory and practice) with linear mixed effect models, but 
I believe that these data call for a mixed effects MANOVA.  Is there 
such a test in R?  Or, would it be better to analyze the data using a 
standard MANOVA where our y1, y2, ... are the percentage of data points 
within that various habitats? My problem with this last analysis is that 
each skunk will carry the same weight even though both could have a 
large difference in the number of data points.  Thanks...



From maria.kernecker at mail.mcgill.ca  Thu Apr  3 15:54:08 2014
From: maria.kernecker at mail.mcgill.ca (Maria Kernecker)
Date: Thu, 3 Apr 2014 13:54:08 +0000
Subject: [R] grouping explanatory variables into "sets" for GLMM
Message-ID: <F453AFCA-5A06-41A1-A209-BBEAEA374542@mail.mcgill.ca>

Dear all, 

I am trying to run a GLMM following the procedure described by Rhodes et al. (Ch. 21) in the Zuur book Mixed effects models and extensions in R . Like in his example, I have four "sets" of explanatory variables: 
1. Land use - 1 variable, factor (forest or agriculture)
2. Location - 1 variable, factor (riparian or upland)
3. Agricultural management - 3 variables that are binary (0 or 1 for till, manure, annual crop)
4. Vegetation patterns - 4 variables that are continuous (# of plant species in 4 different functional guilds)

How do I create these "sets"?  I would like to build my model with these "sets" only instead of listing every variable. 

Also: is there a way of running all possible models with the different combinations of these sets and/or variables, sort of like running ordistep for ordinations?

Thanks a bunch in advance for your help!
Maria  



From Zeef at gmx.de  Thu Apr  3 16:45:03 2014
From: Zeef at gmx.de (Dao_De)
Date: Thu, 3 Apr 2014 07:45:03 -0700 (PDT)
Subject: [R] Plotting Satellite
In-Reply-To: <1396372999202-4687971.post@n4.nabble.com>
References: <1396372999202-4687971.post@n4.nabble.com>
Message-ID: <1396536303698-4688104.post@n4.nabble.com>

Ok i figured it out.




Here is the script that gives you the map.

The second map should express with a two-color scale or code [indicating
significant/non significant] whether your trends are truly significant at a
95% confidence level.


All i got is this. And this time i am really stuck..



It always says "Indices out of boundaries" something.
Can anyone help here and fix the error?



--
View this message in context: http://r.789695.n4.nabble.com/Plotting-Satellite-tp4687971p4688104.html
Sent from the R help mailing list archive at Nabble.com.



From washirah at gmail.com  Thu Apr  3 12:17:37 2014
From: washirah at gmail.com (Andrew Wachira)
Date: Thu, 3 Apr 2014 13:17:37 +0300
Subject: [R] NHPP with Cyclic Rate
Message-ID: <CAP7SS_pcnNH89B+P6vAyz6+ju6CzHGUv1apt1_RSJkRAszjLMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/159b303d/attachment-0001.pl>

From gunter.berton at gene.com  Thu Apr  3 17:28:51 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 3 Apr 2014 08:28:51 -0700
Subject: [R] grouping explanatory variables into "sets" for GLMM
In-Reply-To: <F453AFCA-5A06-41A1-A209-BBEAEA374542@mail.mcgill.ca>
References: <F453AFCA-5A06-41A1-A209-BBEAEA374542@mail.mcgill.ca>
Message-ID: <CACk-te0Ub4p37iw1y2PGZpLWksimU=mHSBKWMFuY+OdGZy-CtQ@mail.gmail.com>

Have you read "An Introduction to R" (or other online tutorial)? If
not, please do so before posting further here. It sounds like you are
missing very basic knowledge -- on factors -- which you need to learn
about before proceeding.

?factor

gives you the answer you seek, I believe.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Thu, Apr 3, 2014 at 6:54 AM, Maria Kernecker
<maria.kernecker at mail.mcgill.ca> wrote:
> Dear all,
>
> I am trying to run a GLMM following the procedure described by Rhodes et al. (Ch. 21) in the Zuur book Mixed effects models and extensions in R . Like in his example, I have four "sets" of explanatory variables:
> 1. Land use - 1 variable, factor (forest or agriculture)
> 2. Location - 1 variable, factor (riparian or upland)
> 3. Agricultural management - 3 variables that are binary (0 or 1 for till, manure, annual crop)
> 4. Vegetation patterns - 4 variables that are continuous (# of plant species in 4 different functional guilds)
>
> How do I create these "sets"?  I would like to build my model with these "sets" only instead of listing every variable.
>
> Also: is there a way of running all possible models with the different combinations of these sets and/or variables, sort of like running ordistep for ordinations?
>
> Thanks a bunch in advance for your help!
> Maria
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Thu Apr  3 17:31:40 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 3 Apr 2014 08:31:40 -0700
Subject: [R] Mixed Effects MANOVA
In-Reply-To: <533D622B.7080502@gmail.com>
References: <533D622B.7080502@gmail.com>
Message-ID: <CACk-te0+Ag-P5noB=epUwMQ7sQ_pfZeUr6aq901wopHVAhYw9g@mail.gmail.com>

This is R-help, not a list that provides statistical help (primarily;
they do intersect at times). Post to the r-sig-mixed-models list
instead. You're likely to do better there anyway for this sort of
thing.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Thu, Apr 3, 2014 at 6:29 AM, Nick Negovetich <nj.negovetich at gmail.com> wrote:
> Greetings,
>
> I have a question regarding data analysis of habitat use of animals.  These
> animals were radio collared and tracked periodically throughout the year.
> When they were sighted/detected, the habitat type was marked.  Our dataset
> recorded the sex of the animal, and we know the data when the surveys were
> performed.  The goal was to address the questions: does habitat use differ
> between the sexes, and does habitat use vary between seasons?  Below is a
> summary table, ignoring seasons.
>
> dattab <- matrix(c(190,87,206,170,103,23,66,72,53,22),nrow=5,byrow=T)
> rownames(dattab) <- c("Rock","Burrow","Cactus","Brushpile","Other")
> colnames(dattab) <- c("Female","Male")
> dattab
>           Female Male
> Rock         190   87
> Burrow       206  170
> Cactus       103   23
> Brushpile     66   72
> Other         53   22
>
> We could perform a test of independence, but the problem lies with our
> assumptions.  Because individual animals were tracked through time, each
> animal give a different number of datapoints (min=1, max=126), which
> violates our assumption of independence.  Thus, our sampling unit should be
> at the level of the skunk and analysis should proceed from there.  I'm
> familiar (theory and practice) with linear mixed effect models, but I
> believe that these data call for a mixed effects MANOVA.  Is there such a
> test in R?  Or, would it be better to analyze the data using a standard
> MANOVA where our y1, y2, ... are the percentage of data points within that
> various habitats? My problem with this last analysis is that each skunk will
> carry the same weight even though both could have a large difference in the
> number of data points.  Thanks...
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From halabi.anan at gmail.com  Thu Apr  3 17:48:32 2014
From: halabi.anan at gmail.com (Anan Halabi)
Date: Thu, 3 Apr 2014 18:48:32 +0300
Subject: [R] text minning script
Message-ID: <CAN7nup4xn=VWXibsh1ovb6CQ+mE5eZeFBen++685QpdZLJtgJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/12ec6c90/attachment-0001.pl>

From qkou at umail.iu.edu  Thu Apr  3 17:54:31 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Thu, 3 Apr 2014 11:54:31 -0400
Subject: [R] mzR and Rcpp version bug
In-Reply-To: <CAF4U=VnFrAmDwN=_hy6BmRM+1Z4s0=nf4p3DS9mck0DzqEizeg@mail.gmail.com>
References: <CAF4U=VnFrAmDwN=_hy6BmRM+1Z4s0=nf4p3DS9mck0DzqEizeg@mail.gmail.com>
Message-ID: <CAJ_LAMBgyk_nXZK7efHtbVbLm6Hgy0h4pnoqoeUcrv7BET0LvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/3fbe3407/attachment-0001.pl>

From frtog at vestas.com  Thu Apr  3 18:26:40 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 3 Apr 2014 18:26:40 +0200
Subject: [R] text minning script
In-Reply-To: <CAN7nup4xn=VWXibsh1ovb6CQ+mE5eZeFBen++685QpdZLJtgJA@mail.gmail.com>
References: <CAN7nup4xn=VWXibsh1ovb6CQ+mE5eZeFBen++685QpdZLJtgJA@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5AD8FC1@DKRDSEXC016.vestas.net>

Hi Anan

Don't expect people on this list to do YOUR work. If you have some specific problems with R then perhaps some people are devoted to help you.

Now is the time when you help yourself. Google for "r text mining" or "r text mining example" and you will get some help. Certainly not any help to do YOUR work but it may lead you on your way to solve your own problems with text mining.

By the way, asking for help to people unknown to you on this list then it is very polite of you if you say please and many thankful beforehand and perhaps use a "Best regard" or something like that.   


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Anan Halabi
> Sent: 3. april 2014 17:49
> To: r-help at r-project.org
> Subject: [R] text minning script
> 
> I need simple script to work with  text minning
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From frtog at vestas.com  Thu Apr  3 18:52:50 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 3 Apr 2014 18:52:50 +0200
Subject: [R] text minning script
In-Reply-To: <CAN7nup67U-fzuQ_NEVWEMsVKBqkB9ki40OYDv8VO7RaJUZOa6Q@mail.gmail.com>
References: <CAN7nup4xn=VWXibsh1ovb6CQ+mE5eZeFBen++685QpdZLJtgJA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5AD8FC1@DKRDSEXC016.vestas.net>
	<CAN7nup67U-fzuQ_NEVWEMsVKBqkB9ki40OYDv8VO7RaJUZOa6Q@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5AD8FD1@DKRDSEXC016.vestas.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/3972676a/attachment-0001.pl>

From katherine_gobin at yahoo.com  Thu Apr  3 19:05:58 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 4 Apr 2014 01:05:58 +0800 (SGT)
Subject: [R] How to store interim print results
In-Reply-To: <CAN5YmCE4K6HHMcsUuqy6w=o+osfZzqtpR4sXFQr8FeLAHQjrHA@mail.gmail.com>
References: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
	<CAN5YmCE4K6HHMcsUuqy6w=o+osfZzqtpR4sXFQr8FeLAHQjrHA@mail.gmail.com>
Message-ID: <1396544758.47192.YahooMailNeo@web193301.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/ec22a590/attachment-0001.pl>

From fcheesman.fc at gmail.com  Thu Apr  3 17:26:10 2014
From: fcheesman.fc at gmail.com (Frances Cheesman)
Date: Thu, 3 Apr 2014 16:26:10 +0100
Subject: [R] Equation of a curve
Message-ID: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/89efca78/attachment-0001.pl>

From katherine_gobin at yahoo.com  Thu Apr  3 19:00:37 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 4 Apr 2014 01:00:37 +0800 (SGT)
Subject: [R] How to store interim print results
In-Reply-To: <CAAxdm-66aoAkFiiyTKg7acf3xH4xTGP6KjwGYmvegJ=zW0XS_w@mail.gmail.com>
References: <1396520543.8055.YahooMailNeo@web193305.mail.sg3.yahoo.com>
	<CAAxdm-66aoAkFiiyTKg7acf3xH4xTGP6KjwGYmvegJ=zW0XS_w@mail.gmail.com>
Message-ID: <1396544437.77261.YahooMailNeo@web193303.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/8bc258ad/attachment-0001.pl>

From frtog at vestas.com  Thu Apr  3 19:49:05 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 3 Apr 2014 19:49:05 +0200
Subject: [R] Equation of a curve
In-Reply-To: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
References: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5AD8FEB@DKRDSEXC016.vestas.net>

Hi Frances

The short answer is YES, you can do anything in R if you bother.

Do you have any figures of the growth curves (something close to exponential growth until they suddenly commit suicide or the environment kills)?.

We NEED more information, thank you please.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Frances Cheesman
> Sent: 3. april 2014 17:26
> To: R-help at r-project.org
> Subject: [R] Equation of a curve
> 
> Hi all,
> 
> I have a number of bacterial growth curves I would like to find the
> equations for these and then integrate them to find the area under the
> curves for me to do stats on later.
> 
> Is there any way I can do this in R?
> 
> Thanks,
> 
> Frances
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Thu Apr  3 20:09:50 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 3 Apr 2014 14:09:50 -0400
Subject: [R] Equation of a curve
In-Reply-To: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
References: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
Message-ID: <8E490768-CC4D-44FB-9993-928BBE63EC17@utoronto.ca>

You may have a different use in mind, but I think integration does not make sense for growth curves. And there is no simple, general equation that I'm aware of: 

When you determine the area under the curve (integration), you are essentially multiplying bacterial mass by time. Imagine that you would kill your bacteria and continue observing. Then the integral would just grow, and grow ... that's possibly not what you want. Bacterial growth parameters are often characterized by *doubling times*, or *growth rate* and these are essentially derived from *differentiating* the observed concentration (or absorbance) with respect to time - relative mass-increase per time unit.

That said, you will usually observe non ideal behaviour at the start of growth (lag phase), a phase of rapid growth (exponential phase) and slowing of growth as the culture conditions become nutrient limited (stationary phase) - possibly followed by a drop of absorbance when your bacteria die off. Modelling this with equations is not trivial, and the parameters you are fitting are usually not of interest anyway.

Probably the best approach is to focus on that part of your growth curve that actually shows the expected exponential growth. This part should be linear if you plot the log of your measurement.

1: Take the log of your measurement;
2: plot it and determine the time interval you should analyze;
3: perform a simple linear regression on the data points in that interval. See: ?lm in R.
4: Calculate your doubling time (or whatever number you need) from the slope.

Hope this helps,
B.


On 2014-04-03, at 11:26 AM, Frances Cheesman wrote:

> Hi all,
> 
> I have a number of bacterial growth curves I would like to find the
> equations for these and then integrate them to find the area under the
> curves for me to do stats on later.
> 
> Is there any way I can do this in R?
> 
> Thanks,
> 
> Frances
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From yuan.hypnos.luo at gmail.com  Thu Apr  3 20:48:41 2014
From: yuan.hypnos.luo at gmail.com (Yuan Luo)
Date: Thu, 3 Apr 2014 14:48:41 -0400
Subject: [R] A question on IRanges package
Message-ID: <CAMY509kBTyNdicD7udtXv+pLDDvbWhUHCmJ_VbUNCqsdTAhJ_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/12049c12/attachment-0001.pl>

From pdalgd at gmail.com  Thu Apr  3 21:24:09 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 3 Apr 2014 21:24:09 +0200
Subject: [R] Icelandic Characters in Mac
In-Reply-To: <44B53F9D-8FAB-4FB1-8867-9790AF2FC54B@comcast.net>
References: <CAMqewfLTJ1wYzvjR2WHKWqEOBufTRCj_+CYvo1sNmyakKw5Qig@mail.gmail.com>
	<44B53F9D-8FAB-4FB1-8867-9790AF2FC54B@comcast.net>
Message-ID: <7649FC04-8C3C-41B9-B116-DD619B8F441D@gmail.com>


On 03 Apr 2014, at 00:59 , David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Apr 2, 2014, at 2:18 PM, Stef?n Hrafn J?nsson wrote:
> 
>> Dear R community
>> 
>> I have few students that use Mac. When creating graphs they inform me that
>> when they use Icelandic characters in title or xlab they get some wrong
>> results. In stead of
>> 
>> "?a? er s?tt" they get ".a. er s.tt" period in stead of the Icelandic
>> character.
>> 
>> Any Icelandic Mac user that has a solution to this?  .
>> 
>> 
>> The Icelandic characters follows.
>> 
>> ? ? ? ? ? ?,?  ? ? ? ? ? ? ?
>> 
>> http://en.wikipedia.org/wiki/Icelandic_alphabet
> 
> The default screen device is named quartz(). I'm not an Icelander, but in a US locale with the standard fonts I get faithful reproduction of those characters on a Mac running 10.7.5 with R 3.0.2
> 

Rather amusingly, some of the Icelandic got mangled in your mail, though. 
I think I received them correctly in Stef?n's mail:

? ? ? ? ? ?,?  ? ? ? ? ? ? ?

(although thorn ?? seems missing from the list?) 

I too can use "?a? er s?tt" in plot labels, on 10.9.2 in en_US.UTF-8 locale.

I think we need more info about what setup the students have been using. Having the locale set to "C" might cause something like the described effect.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From Sonja.Schillo at uni-due.de  Thu Apr  3 21:58:26 2014
From: Sonja.Schillo at uni-due.de (Schillo, Sonja)
Date: Thu, 3 Apr 2014 19:58:26 +0000
Subject: [R] rpart and randomforest results
In-Reply-To: <CANOgrHaKRY+4ibQGisjRzmjpArMax6LPWDCL9JjhZ5TPYO98FQ@mail.gmail.com>
References: <F935BF3EEA79BF45901A755531026E8344F40E43@WIWINF-EXDAG03.wiwinf.uni-due.de>
	<CANOgrHaKRY+4ibQGisjRzmjpArMax6LPWDCL9JjhZ5TPYO98FQ@mail.gmail.com>
Message-ID: <F935BF3EEA79BF45901A755531026E8344F42E40@WIWINF-EXDAG03.wiwinf.uni-due.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/a7cda13b/attachment-0001.pl>

From highstat at highstat.com  Thu Apr  3 22:22:33 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 03 Apr 2014 21:22:33 +0100
Subject: [R] Stats courses in Australia
Message-ID: <533DC309.505@highstat.com>

We are planning to run a series of four courses in Australia (and/or New 
Zealand) in August 2014. Potential courses:

1. Data Exploration, Regression, GLM & GAM with introduction to R
2. Introduction to Linear Mixed Effects Models and GLMM with R
3. Zero Inflated Models & GLMM with R
4. Beginner?s Guide to GAM & GAMM with R

For flyers, see:
www.highstat.com/Courses/Flyer2014_08Australia1.pdf
www.highstat.com/Courses/Flyer2014_08Australia2.pdf
www.highstat.com/Courses/Flyer2014_08Australia3.pdf
www.highstat.com/Courses/Flyer2014_08Australia4.pdf

If you would like to participate, or organise a course at your 
institute, please contact us.

Kind regards,

Alain


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com



From r.turner at auckland.ac.nz  Thu Apr  3 22:23:29 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 04 Apr 2014 09:23:29 +1300
Subject: [R] nearest neighbour
In-Reply-To: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>
References: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>
Message-ID: <533DC341.7020505@auckland.ac.nz>

On 04/04/14 01:16, Monaly Mistry wrote:
> Hi,
>
> If I have a data frame of the location of individuals (x and y coordinate),
> how do I find the 5 nearest neighbours for each individual.

The nnwhich() function from the spatstat package will do this for you.

E.g.:

require(spatstat) # You need to have *installed* spatstat!
W <- ripras(ddd)  # Where "ddd" is the name of your data frame.
X <- ppp(x=ddd[,1],y=ddd[,2],window=W)
n5 <- nnwhich(X,k=1:5)

cheers,

Rolf Turner



From rshepard at appl-ecosys.com  Thu Apr  3 22:55:17 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 3 Apr 2014 13:55:17 -0700 (PDT)
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
Message-ID: <alpine.LNX.2.11.1404031340020.12013@localhost>

   I have irregular time series as zoo objects; one example:

structure(c(6, 5, 14, 9, 8, 9, 8, 5, 5, 5, 3, 3, 4, 3, 9, 6.94, 
7.44, 3.09, 0.84, 5.35, 4.76, 4.21, 1.58, 2.6, 3.41, 9.59, 7.1, 
5, 5, 5, 3, 1.5, 2.4, 3.9, 5.8, 2.3, 3.6, 4.1, 15.4, 7.8, 4.2, 
5.8, 3, 4.5, 8.1, 9.6, 9.3, 7.9, 3.8, 3.2, 3.6, 8.4, 10.5, 8.7, 
7.9, 3.1, 2.7, 3.7, 3.7, 2.9, 3.6, 2.3, 2, 1), index = structure(c(8147, 
8177, 8345, 8428, 8449, 8462, 8474, 8498, 8520, 8531, 8547, 8561, 
8576, 8590, 8612, 8852, 8862, 8881, 8912, 8939, 9231, 9249, 9280, 
9304, 9337, 9468, 9511, 9623, 9652, 9679, 9981, 9995, 10028, 
10071, 10371, 10374, 10434, 10484, 10520, 10554, 10721, 10736, 
10764, 10794, 10904, 10926, 11020, 11026, 11068, 11086, 11136, 
11288, 11298, 11369, 11388, 11442, 11453, 11498, 11811, 11859, 
12175, 12218, 12597, 12600), class = "Date"), class = "zoo")

   They appear to have seasonal variation and a trend. When I try to decompose
them using stl() I get an error about missing values:

s95so4.stl <- stl(s95so4.z)
Error in na.fail.default(as.ts(x)) : missing values in object

   The s.window option might be applicable, but it seems to me that
specifying 'periodic' for an irregular time series is inappropriate (in any
case, it still produces the same error message), and I don't know what would
be an appropriate span (in lags) for the loess window.

   I would like to learn how to decompose such irregular (zoo) time series
into seasonal variation, trend, and residual errors so I can apply
regressions (using lm()) to pairs that ought to be related.

   Would StructTS() be the appropriate function for these data?

Rich



From r.turner at auckland.ac.nz  Thu Apr  3 23:08:51 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 04 Apr 2014 10:08:51 +1300
Subject: [R] NHPP with Cyclic Rate
In-Reply-To: <CAP7SS_pcnNH89B+P6vAyz6+ju6CzHGUv1apt1_RSJkRAszjLMg@mail.gmail.com>
References: <CAP7SS_pcnNH89B+P6vAyz6+ju6CzHGUv1apt1_RSJkRAszjLMg@mail.gmail.com>
Message-ID: <533DCDE3.4070909@auckland.ac.nz>

On 03/04/14 23:17, Andrew Wachira wrote:
> Is there an R-package that computes the parameters of a nonhomogenous
> Poisson process with cyclic rate (the rate function has polynomial and
> trigonometric components)?
> Something more like NPPMLE (
> http://www.ise.ncsu.edu/jwilson/files/johnson94orl.pdf ) but in R?


Have you tried Google?  Have you tried RSiteSearch()?

These would have led you fairly quickly to the NHPoisson package which
*might* be able to accomplish what you want.

cheers,

Rolf Turner



From 538280 at gmail.com  Thu Apr  3 23:22:18 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 3 Apr 2014 15:22:18 -0600
Subject: [R] Equation of a curve
In-Reply-To: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
References: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
Message-ID: <CAFEqCdyp0=wpQBopSGkCpRrTU040+wztEK+oAVy3YBk2XScMPg@mail.gmail.com>

The mean value theorem of integration (I have a cross-stitch of this
theorem hanging on my wall (between cross-stitches of the central
limit theorem and Bayes theorem)) tells us that the area under a curve
is equal to the width of the area of interest times the average height
of the curve.  Often when we want to use the area under a curve in
statistics we can just use the average of the y-values generating the
curve and it is much simpler.

 If the x-coordinates of your points are evenly spaced or are random
with a fairly uniform distribution then the mean height of the points
will probably be as useful as any curve that you computed and then
integrated.

If the x-coordinates are not uniformly spread then you may benefit
from a weighted average.  One option for estimating the integral is to
use the trapezoidal rule or Simpson's rule, but if you look at those
formulas, they are just a weighted average of the heights again.

So, while Yes, R can estimate curves and compute numerical integrals
of the curves, there is a good chance that you don't really need to do
either.

On Thu, Apr 3, 2014 at 9:26 AM, Frances Cheesman <fcheesman.fc at gmail.com> wrote:
> Hi all,
>
> I have a number of bacterial growth curves I would like to find the
> equations for these and then integrate them to find the area under the
> curves for me to do stats on later.
>
> Is there any way I can do this in R?
>
> Thanks,
>
> Frances
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From rshepard at appl-ecosys.com  Thu Apr  3 23:25:48 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 3 Apr 2014 14:25:48 -0700 (PDT)
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
Message-ID: <alpine.LNX.2.11.1404031424540.12013@localhost>

On Thu, 3 Apr 2014, arun wrote:

> Not sure if this helps you.
> http://stackoverflow.com/questions/12623027/how-to-analyse-irregular-time-series-in-r

A.K.,

   Yes, it does. I've read all the zoo docs I can find and have been
searching for more information on irregular time series data. Environmental
data, unlike financial or economic data (or the examples in books and R help
pages) is always sloppy and irregular. Wish there was a book or monograph on
these data.

Thanks very much,

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
www.appl-ecosys.com      Voice: 503-667-4517         Fax: 503-667-8863



From qkou at umail.iu.edu  Thu Apr  3 23:28:58 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Thu, 3 Apr 2014 17:28:58 -0400
Subject: [R] A question on IRanges package
In-Reply-To: <CAMY509kBTyNdicD7udtXv+pLDDvbWhUHCmJ_VbUNCqsdTAhJ_w@mail.gmail.com>
References: <CAMY509kBTyNdicD7udtXv+pLDDvbWhUHCmJ_VbUNCqsdTAhJ_w@mail.gmail.com>
Message-ID: <CAJ_LAMAHsz4hfis=8=QdBEXDy7Y6KqirXRGO=2dTneN20ewJ7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/5632c742/attachment-0001.pl>

From qkou at umail.iu.edu  Thu Apr  3 23:33:21 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Thu, 3 Apr 2014 17:33:21 -0400
Subject: [R] ff package: problem with reading in numerical values
In-Reply-To: <CALe19-26rq1z+ykpjikuziUqCCScv8hUnnExLv4HV2u6+OVRFQ@mail.gmail.com>
References: <CALe19-26rq1z+ykpjikuziUqCCScv8hUnnExLv4HV2u6+OVRFQ@mail.gmail.com>
Message-ID: <CAJ_LAMByV+_bqBEV10mfQTOyeaP9GQaB85iW+DVzZXgiJhT1Gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/8ec99a83/attachment-0001.pl>

From roy.mendelssohn at noaa.gov  Thu Apr  3 23:34:15 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Thu, 3 Apr 2014 14:34:15 -0700
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
In-Reply-To: <alpine.LNX.2.11.1404031424540.12013@localhost>
References: <alpine.LNX.2.11.1404031424540.12013@localhost>
Message-ID: <DF4C02AB-85D9-4676-97DC-0BBAF0772029@noaa.gov>

HI Rich:

How irregular is irregular.  kalman filter based methods, such as those in KFAS and DLM, can handle missing data, and often "irregular" data can be thought of as regular data with missing values,  A lot depends on how irregular and how big the gaps, to the point where the analysis can be calculated but is not very meaningful.

Don't know if this helps.

-Roy M.

On Apr 3, 2014, at 2:25 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:

> On Thu, 3 Apr 2014, arun wrote:
> 
>> Not sure if this helps you.
>> http://stackoverflow.com/questions/12623027/how-to-analyse-irregular-time-series-in-r
> 
> A.K.,
> 
>  Yes, it does. I've read all the zoo docs I can find and have been
> searching for more information on irregular time series data. Environmental
> data, unlike financial or economic data (or the examples in books and R help
> pages) is always sloppy and irregular. Wish there was a book or monograph on
> these data.
> 
> Thanks very much,
> 
> Rich
> 
> -- 
> Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
> Applied Ecosystem Services, Inc.   |
> www.appl-ecosys.com      Voice: 503-667-4517         Fax: 503-667-8863
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From rshepard at appl-ecosys.com  Thu Apr  3 23:54:22 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 3 Apr 2014 14:54:22 -0700 (PDT)
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
In-Reply-To: <DF4C02AB-85D9-4676-97DC-0BBAF0772029@noaa.gov>
References: <alpine.LNX.2.11.1404031424540.12013@localhost>
	<DF4C02AB-85D9-4676-97DC-0BBAF0772029@noaa.gov>
Message-ID: <alpine.LNX.2.11.1404031448180.12013@localhost>

On Thu, 3 Apr 2014, Roy Mendelssohn wrote:

> How irregular is irregular. kalman filter based methods, such as those in
> KFAS and DLM, can handle missing data, and often "irregular" data can be
> thought of as regular data with missing values, A lot depends on how
> irregular and how big the gaps, to the point where the analysis can be
> calculated but is not very meaningful.

Roy,

   The degree of irregularity varies with the data set. It varies greatly.
Sometimes, monthly samples are missed because the streambed is dry, or
because there are several meters of snow on top of the channel. Sometimes
regulators have permit holders stop analyzing for a chemical constituent,
then there's an agency staff change and that constituent is back on the list
of chemicals to be monitored. Some times fish are present, other times
they're not.

> Don't know if this helps.

   Yes, it does. I'll read up on Kalman filters, on state-space models with
missing data modifications in Shumway & Stoffer (3rd Ed.), and on gamm.

Thanks,

Rich



From roy.mendelssohn at noaa.gov  Fri Apr  4 00:04:15 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Thu, 3 Apr 2014 15:04:15 -0700
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
In-Reply-To: <alpine.LNX.2.11.1404031448180.12013@localhost>
References: <alpine.LNX.2.11.1404031424540.12013@localhost>
	<DF4C02AB-85D9-4676-97DC-0BBAF0772029@noaa.gov>
	<alpine.LNX.2.11.1404031448180.12013@localhost>
Message-ID: <14A14AC3-65FD-4A8E-999A-9FB140A1BA5D@noaa.gov>

The state-space approach has the advantage in the appropriate situations that  you can model the trends and seasonals and cycles in a way that doesn't assume stationarity and provides a lot of flexibility.  To me a lot of it depends on if the nature of the irregularity is an inherent property of the data themselves or of the observation process - for example if it makes sense to say the physical observable is there every month but we just have not been able to observe.  I have fit state-space models to reasonably sparse data with what appear to be good results.  

If you want I can send you some examples off-line.

-Roy


On Apr 3, 2014, at 2:54 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:

> On Thu, 3 Apr 2014, Roy Mendelssohn wrote:
> 
>> How irregular is irregular. kalman filter based methods, such as those in
>> KFAS and DLM, can handle missing data, and often "irregular" data can be
>> thought of as regular data with missing values, A lot depends on how
>> irregular and how big the gaps, to the point where the analysis can be
>> calculated but is not very meaningful.
> 
> Roy,
> 
>  The degree of irregularity varies with the data set. It varies greatly.
> Sometimes, monthly samples are missed because the streambed is dry, or
> because there are several meters of snow on top of the channel. Sometimes
> regulators have permit holders stop analyzing for a chemical constituent,
> then there's an agency staff change and that constituent is back on the list
> of chemicals to be monitored. Some times fish are present, other times
> they're not.
> 
>> Don't know if this helps.
> 
>  Yes, it does. I'll read up on Kalman filters, on state-space models with
> missing data modifications in Shumway & Stoffer (3rd Ed.), and on gamm.
> 
> Thanks,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From rshepard at appl-ecosys.com  Fri Apr  4 00:11:20 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 3 Apr 2014 15:11:20 -0700 (PDT)
Subject: [R] Time Series Decomposition On Zoo Objects: Errors
In-Reply-To: <14A14AC3-65FD-4A8E-999A-9FB140A1BA5D@noaa.gov>
References: <alpine.LNX.2.11.1404031424540.12013@localhost>
	<DF4C02AB-85D9-4676-97DC-0BBAF0772029@noaa.gov>
	<alpine.LNX.2.11.1404031448180.12013@localhost>
	<14A14AC3-65FD-4A8E-999A-9FB140A1BA5D@noaa.gov>
Message-ID: <alpine.LNX.2.11.1404031507570.12013@localhost>

On Thu, 3 Apr 2014, Roy Mendelssohn wrote:

> The state-space approach has the advantage in the appropriate situations
> that you can model the trends and seasonals and cycles in a way that
> doesn't assume stationarity and provides a lot of flexibility. To me a lot
> of it depends on if the nature of the irregularity is an inherent property
> of the data themselves or of the observation process - for example if it
> makes sense to say the physical observable is there every month but we
> just have not been able to observe. I have fit state-space models to
> reasonably sparse data with what appear to be good results.

Roy,

   Hadn't thought about the nature of the irregularity. For all my data, the
nature is observational. Water and air chemistry (and physical parameters
such as flow and temperature) are always there. Biota might be different.
Plants tend to not move too quickly so they're always present ... or not.
But, animals (aquatic and terrestrial) may not be present or may be present
but not observed.

> If you want I can send you some examples off-line.

   That would be much appreciated.

Thanks,

Rich



From breakaway8 at gmail.com  Fri Apr  4 01:00:18 2014
From: breakaway8 at gmail.com (Ruijie)
Date: Fri, 4 Apr 2014 07:00:18 +0800
Subject: [R] Computing standardised beta in linear regression
Message-ID: <CA+o6KtU34vJbQsJY55eeWGckgXN+3KwQ4P+iECa44B7Cvi5p1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/26c6debe/attachment-0001.pl>

From timmarcella at gmail.com  Fri Apr  4 01:50:45 2014
From: timmarcella at gmail.com (Tim Marcella)
Date: Thu, 3 Apr 2014 16:50:45 -0700
Subject: [R] Nested Logit Model
Message-ID: <CAGbJzAJgTk3KaqbPWM_hKLtZ86cKRojD=p-0=cr2hf1maHi_qA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/13ee2f7c/attachment-0001.pl>

From dwinsemius at comcast.net  Fri Apr  4 03:20:29 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Apr 2014 18:20:29 -0700
Subject: [R] Icelandic Characters in Mac
In-Reply-To: <7649FC04-8C3C-41B9-B116-DD619B8F441D@gmail.com>
References: <CAMqewfLTJ1wYzvjR2WHKWqEOBufTRCj_+CYvo1sNmyakKw5Qig@mail.gmail.com>
	<44B53F9D-8FAB-4FB1-8867-9790AF2FC54B@comcast.net>
	<7649FC04-8C3C-41B9-B116-DD619B8F441D@gmail.com>
Message-ID: <53D77E7C-387A-42AA-8676-4E71992947DA@comcast.net>


On Apr 3, 2014, at 12:24 PM, peter dalgaard wrote:

> 
> On 03 Apr 2014, at 00:59 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Apr 2, 2014, at 2:18 PM, Stef?n Hrafn J?nsson wrote:
>> 
>>> Dear R community
>>> 
>>> I have few students that use Mac. When creating graphs they inform me that
>>> when they use Icelandic characters in title or xlab they get some wrong
>>> results. In stead of
>>> 
>>> "?a? er s?tt" they get ".a. er s.tt" period in stead of the Icelandic
>>> character.
>>> 
>>> Any Icelandic Mac user that has a solution to this?  .
>>> 
>>> 
>>> The Icelandic characters follows.
>>> 
>>> ? ? ? ? ? ?,?  ? ? ? ? ? ? ?
>>> 
>>> http://en.wikipedia.org/wiki/Icelandic_alphabet
>> 
>> The default screen device is named quartz(). I'm not an Icelander, but in a US locale with the standard fonts I get faithful reproduction of those characters on a Mac running 10.7.5 with R 3.0.2
>> 
> 
> Rather amusingly, some of the Icelandic got mangled in your mail, though. 
> I think I received them correctly in Stef?n's mail:
> 
> ? ? ? ? ? ?,?  ? ? ? ? ? ? ?
> 
> (although thorn ?? seems missing from the list?) 
> 

I'm admittedly not an Icelander, nor has my country ever claimed that island, so who knows if what I am seeing with your encoding (and I think you also use a Mac?) and the behavior of my mail-client (using Monaco for display) on this Mac is any more correct today. I also get what appears to be "faithful" transferal (in the sense of the mail version having sufficient similarity to the screen plot) of that set of characters in the title of a plot (attached):

png(); plot(1,1, main="? ? ? ? ? ?,?  ? ? ? ? ? ? ?" );dev.off()



Maybe Stef?n and his students can get further amusement and education with this exchange?


> I too can use "?a? er s?tt" in plot labels, on 10.9.2 in en_US.UTF-8 locale.
> 
> I think we need more info about what setup the students have been using.

I think that's what I said. If they want to see their locale settings, they can execute:

sessionInfo()
# or
Sys.getlocale()
#[1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"

And the help page for that function has this warning:
"Attempts to change the character set (by Sys.setlocale("LC_TYPE", ), if that implies a different character set) during a session may not work and are likely to lead to some confusion."


> Having the locale set to "C" might cause something like the described effect.

You are probably in a better position to tell them how to change the settings.

> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

David Winsemius
Alameda, CA, USA



From vk2toi at optusnet.com.au  Fri Apr  4 04:30:01 2014
From: vk2toi at optusnet.com.au (Bob Kelly)
Date: Fri, 04 Apr 2014 13:30:01 +1100
Subject: [R] unzip error with odfWeave and OpenOffice
Message-ID: <533E1929.1040004@optusnet.com.au>

Hello r-help mailing list readers,

I am trying to create a report with OpenOffice (ver 4.0.1) using the 
odfWeave (ver 0.8.4) package.
This is completely new to me so I am using part of an example from the 
book R in Action.
I have used 7-zip on the file and this opens it correctly, am I doing 
something wrong in setting up the process.

input to R (3.0.2)

> infile <- "example1.odt"
> outfile <- "example-out.odt"
> odfWeave(infile, outfile)

output from R

> odfWeave(infile, outfile)
   Creating  C:\Users\RFMOBI~1.INS\AppData\Local\Temp\Rtmp48EjRV/odfWeave04123430182
   Copying  example1.odt
   Setting wd to  C:\Users\rfmobile.INSTRUMENTS\AppData\Local\Temp\Rtmp48EjRV\odfWeave04123430182
   Unzipping ODF file using unzip -o "example1.odt"
Error in odfWeave(infile, outfile) : Error unzipping file

below is the file I am trying to open

My Sample Report

Robert I. Kabacoff, Ph.D.

<<echo=true, results=hide>>=
library(multcomp)
library(xtable)
attach(cholesterol)
@

1 Results



regards

Bob Kelly



From kridox at ymail.com  Fri Apr  4 05:07:41 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 4 Apr 2014 12:07:41 +0900
Subject: [R] unzip error with odfWeave and OpenOffice
In-Reply-To: <533E1929.1040004@optusnet.com.au>
References: <533E1929.1040004@optusnet.com.au>
Message-ID: <CAAcyNCw-wAuWMzJ9KWq46Dvp-b04ZxYJkMgvnNFXOVhDwW=C0A@mail.gmail.com>

Hello,

Probably a path problem:
https://stat.ethz.ch/pipermail/r-help/2010-March/232135.html

Regards,
Pascal

On Fri, Apr 4, 2014 at 11:30 AM, Bob Kelly <vk2toi at optusnet.com.au> wrote:
> Hello r-help mailing list readers,
>
> I am trying to create a report with OpenOffice (ver 4.0.1) using the
> odfWeave (ver 0.8.4) package.
> This is completely new to me so I am using part of an example from the book
> R in Action.
> I have used 7-zip on the file and this opens it correctly, am I doing
> something wrong in setting up the process.
>
> input to R (3.0.2)
>
>> infile <- "example1.odt"
>> outfile <- "example-out.odt"
>> odfWeave(infile, outfile)
>
>
> output from R
>
>> odfWeave(infile, outfile)
>
>   Creating
> C:\Users\RFMOBI~1.INS\AppData\Local\Temp\Rtmp48EjRV/odfWeave04123430182
>   Copying  example1.odt
>   Setting wd to
> C:\Users\rfmobile.INSTRUMENTS\AppData\Local\Temp\Rtmp48EjRV\odfWeave04123430182
>   Unzipping ODF file using unzip -o "example1.odt"
> Error in odfWeave(infile, outfile) : Error unzipping file
>
> below is the file I am trying to open
>
> My Sample Report
>
> Robert I. Kabacoff, Ph.D.
>
> <<echo=true, results=hide>>=
> library(multcomp)
> library(xtable)
> attach(cholesterol)
> @
>
> 1 Results
>
>
>
> regards
>
> Bob Kelly
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From kydaviddoyle at gmail.com  Fri Apr  4 05:20:34 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Thu, 3 Apr 2014 22:20:34 -0500
Subject: [R] Doing box plots for part of the data??
Message-ID: <CACftpvoh=rjJLOj-jxK_=rGY4AfNEn6U9pYSsK2+-fCmNreSHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140403/04ca0204/attachment-0001.pl>

From gunter.berton at gene.com  Fri Apr  4 05:55:06 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 3 Apr 2014 20:55:06 -0700
Subject: [R] grouping explanatory variables into "sets" for GLMM
In-Reply-To: <19142408-3257-4150-BD9B-76690E22F472@mail.mcgill.ca>
References: <F453AFCA-5A06-41A1-A209-BBEAEA374542@mail.mcgill.ca>
	<CACk-te0Ub4p37iw1y2PGZpLWksimU=mHSBKWMFuY+OdGZy-CtQ@mail.gmail.com>
	<19142408-3257-4150-BD9B-76690E22F472@mail.mcgill.ca>
Message-ID: <CACk-te3dfebFCG=zJJt7W33TVN=sja2vZyDFeddAbCALB87yLw@mail.gmail.com>

Unless there is reason to keep the conversation private, always reply
to the list. How will anyone else know that my answer wasn't
satisfactory?

1. I don't intend to go through your references. A minimal
reproducible example of what you wish to do and what you tried would
help.

2. Have you read An Intro to R?

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Thu, Apr 3, 2014 at 5:14 PM, Maria Kernecker, PhD
<mkernecker at gmail.com> wrote:
> Thanks for getting back to me.
>
> It seems I didn't write my question clearly and that it was misunderstood - even if it is easy to answer: I would like to reduce the number of explanatory variables in my model by using "sets" or categories that these variables belong to, like Rhodes et al. did in their chapter, or like Lentini et al. 2012 did in their paper.
>
> Factor is not the answer I am looking for, unfortunately.
>
> On Apr 3, 2014, at 11:28 AM, Bert Gunter wrote:
>
>> Have you read "An Introduction to R" (or other online tutorial)? If
>> not, please do so before posting further here. It sounds like you are
>> missing very basic knowledge -- on factors -- which you need to learn
>> about before proceeding.
>>
>> ?factor
>>
>> gives you the answer you seek, I believe.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> H. Gilbert Welch
>>
>>
>>
>>
>> On Thu, Apr 3, 2014 at 6:54 AM, Maria Kernecker
>> <maria.kernecker at mail.mcgill.ca> wrote:
>>> Dear all,
>>>
>>> I am trying to run a GLMM following the procedure described by Rhodes et al. (Ch. 21) in the Zuur book Mixed effects models and extensions in R . Like in his example, I have four "sets" of explanatory variables:
>>> 1. Land use - 1 variable, factor (forest or agriculture)
>>> 2. Location - 1 variable, factor (riparian or upland)
>>> 3. Agricultural management - 3 variables that are binary (0 or 1 for till, manure, annual crop)
>>> 4. Vegetation patterns - 4 variables that are continuous (# of plant species in 4 different functional guilds)
>>>
>>> How do I create these "sets"?  I would like to build my model with these "sets" only instead of listing every variable.
>>>
>>> Also: is there a way of running all possible models with the different combinations of these sets and/or variables, sort of like running ordistep for ordinations?
>>>
>>> Thanks a bunch in advance for your help!
>>> Maria
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>



From jim at bitwrit.com.au  Fri Apr  4 05:54:34 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 04 Apr 2014 14:54:34 +1100
Subject: [R] Doing box plots for part of the data??
In-Reply-To: <CACftpvoh=rjJLOj-jxK_=rGY4AfNEn6U9pYSsK2+-fCmNreSHg@mail.gmail.com>
References: <CACftpvoh=rjJLOj-jxK_=rGY4AfNEn6U9pYSsK2+-fCmNreSHg@mail.gmail.com>
Message-ID: <533E2CFA.8090205@bitwrit.com.au>

On 04/04/2014 02:20 PM, David Doyle wrote:
> HI folks
>
> I'm wanting to do box plots of just 2 of my wells.
>
> I can do it for all of them by using
>
> boxplot(Barium~Well.ID,data=mydata, main="Barium", ylab="mg/L")
>
> to do for all 4 wells
> Anyone have a sugestion on how to do it for only 2 wells like MW-1 and MW-2?
>
> The data can be found?
> http://www.doylesdartden.com/TEMP/mydata.csv
>

Hi David,
Try this:

dddf<-read.csv("mydata.csv")
dddf12<-dddf[dddf$Well.ID=="MW-1" | dddf$Well.ID=="MW-2",]
dddf12$Well.ID<-factor(dddf12$Well.ID,levels=c("MW-1","MW-2"))
boxplot(Barium~Well.ID,dddf12)

Jim



From dmck at u.washington.edu  Fri Apr  4 06:14:21 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 3 Apr 2014 21:14:21 -0700
Subject: [R] grouping explanatory variables into "sets" for GLMM
In-Reply-To: <CACk-te3dfebFCG=zJJt7W33TVN=sja2vZyDFeddAbCALB87yLw@mail.gmail.com>
References: <F453AFCA-5A06-41A1-A209-BBEAEA374542@mail.mcgill.ca>
	<CACk-te0Ub4p37iw1y2PGZpLWksimU=mHSBKWMFuY+OdGZy-CtQ@mail.gmail.com>
	<19142408-3257-4150-BD9B-76690E22F472@mail.mcgill.ca>
	<CACk-te3dfebFCG=zJJt7W33TVN=sja2vZyDFeddAbCALB87yLw@mail.gmail.com>
Message-ID: <61215A2F-7BA9-400D-BB29-09F2F2C6D83D@u.washington.edu>

Reading the Intro, as Bert suggests, would likely solve some of your problems. If you think about how many combinations it would take, using only one variable from each group in any one model, you would see that the number of individual models (12) is not so onerous that you couldn?t specify them one at a time.

On Apr 3, 2014, at 8:55 PM, Bert Gunter <gunter.berton at gene.com> wrote:

> Unless there is reason to keep the conversation private, always reply
> to the list. How will anyone else know that my answer wasn't
> satisfactory?
> 
> 1. I don't intend to go through your references. A minimal
> reproducible example of what you wish to do and what you tried would
> help.
> 
> 2. Have you read An Intro to R?
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
> On Thu, Apr 3, 2014 at 5:14 PM, Maria Kernecker, PhD
> <mkernecker at gmail.com> wrote:
>> Thanks for getting back to me.
>> 
>> It seems I didn't write my question clearly and that it was misunderstood - even if it is easy to answer: I would like to reduce the number of explanatory variables in my model by using "sets" or categories that these variables belong to, like Rhodes et al. did in their chapter, or like Lentini et al. 2012 did in their paper.
>> 
>> Factor is not the answer I am looking for, unfortunately.
>> 
>> On Apr 3, 2014, at 11:28 AM, Bert Gunter wrote:
>> 
>>> Have you read "An Introduction to R" (or other online tutorial)? If
>>> not, please do so before posting further here. It sounds like you are
>>> missing very basic knowledge -- on factors -- which you need to learn
>>> about before proceeding.
>>> 
>>> ?factor
>>> 
>>> gives you the answer you seek, I believe.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>> 
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> H. Gilbert Welch
>>> 
>>> 
>>> 
>>> 
>>> On Thu, Apr 3, 2014 at 6:54 AM, Maria Kernecker
>>> <maria.kernecker at mail.mcgill.ca> wrote:
>>>> Dear all,
>>>> 
>>>> I am trying to run a GLMM following the procedure described by Rhodes et al. (Ch. 21) in the Zuur book Mixed effects models and extensions in R . Like in his example, I have four "sets" of explanatory variables:
>>>> 1. Land use - 1 variable, factor (forest or agriculture)
>>>> 2. Location - 1 variable, factor (riparian or upland)
>>>> 3. Agricultural management - 3 variables that are binary (0 or 1 for till, manure, annual crop)
>>>> 4. Vegetation patterns - 4 variables that are continuous (# of plant species in 4 different functional guilds)
>>>> 
>>>> How do I create these "sets"?  I would like to build my model with these "sets" only instead of listing every variable.
>>>> 
>>>> Also: is there a way of running all possible models with the different combinations of these sets and/or variables, sort of like running ordistep for ordinations?
>>>> 
>>>> Thanks a bunch in advance for your help!
>>>> Maria
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences 
College of the Environment
University of Washington
dmck at uw.edu



From yczhang at nigpas.ac.cn  Fri Apr  4 06:20:59 2014
From: yczhang at nigpas.ac.cn (=?UTF-8?B?5byg5Lul5pil?=)
Date: Fri, 4 Apr 2014 12:20:59 +0800 (GMT+08:00)
Subject: [R] figure margins too large
In-Reply-To: <533D0797.7030505@bitwrit.com.au>
References: <dc52ec.b873.145261297da.Coremail.yczhang@nigpas.ac.cn>
	<533D0797.7030505@bitwrit.com.au>
Message-ID: <5d605f.e804.1452af7e065.Coremail.yczhang@nigpas.ac.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/0f56570a/attachment-0001.pl>

From Nicholas.Surawski at csiro.au  Fri Apr  4 06:59:09 2014
From: Nicholas.Surawski at csiro.au (Nicholas.Surawski at csiro.au)
Date: Fri, 4 Apr 2014 04:59:09 +0000
Subject: [R] MANOVA post hoc testing
Message-ID: <AB7C4CCDB3124840828A5050BD277EB41B12B995@exmbx03-cdc.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/0cd5fd93/attachment-0001.pl>

From washirah at gmail.com  Fri Apr  4 06:31:17 2014
From: washirah at gmail.com (Andrew Wachira)
Date: Fri, 4 Apr 2014 07:31:17 +0300
Subject: [R] NHPP with Cyclic Rate
In-Reply-To: <533DCDE3.4070909@auckland.ac.nz>
References: <CAP7SS_pcnNH89B+P6vAyz6+ju6CzHGUv1apt1_RSJkRAszjLMg@mail.gmail.com>
	<533DCDE3.4070909@auckland.ac.nz>
Message-ID: <CAP7SS_oLGRdCdA3oiHBP_TB_V93mR1bJLvnbbgnLZ6Emeza8xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/101b06e0/attachment-0001.pl>

From frtog at vestas.com  Fri Apr  4 07:37:51 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 4 Apr 2014 07:37:51 +0200
Subject: [R] Doing box plots for part of the data??
In-Reply-To: <533E2CFA.8090205@bitwrit.com.au>
References: <CACftpvoh=rjJLOj-jxK_=rGY4AfNEn6U9pYSsK2+-fCmNreSHg@mail.gmail.com>
	<533E2CFA.8090205@bitwrit.com.au>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5AD908F@DKRDSEXC016.vestas.net>

Or using the original data and the subset argument of boxplot:

boxplot(Barium~Well.ID,data=mydata, main="Barium", ylab="mg/L", subset = Well.ID %in% c("MW-1", "MW-2"))

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Jim Lemon
> Sent: 4. april 2014 05:55
> To: David Doyle
> Cc: r-help at r-project.org
> Subject: Re: [R] Doing box plots for part of the data??
> 
> On 04/04/2014 02:20 PM, David Doyle wrote:
> > HI folks
> >
> > I'm wanting to do box plots of just 2 of my wells.
> >
> > I can do it for all of them by using
> >
> > boxplot(Barium~Well.ID,data=mydata, main="Barium", ylab="mg/L")
> >
> > to do for all 4 wells
> > Anyone have a sugestion on how to do it for only 2 wells like MW-1 and
> MW-2?
> >
> > The data can be found?
> > http://www.doylesdartden.com/TEMP/mydata.csv
> >
> 
> Hi David,
> Try this:
> 
> dddf<-read.csv("mydata.csv")
> dddf12<-dddf[dddf$Well.ID=="MW-1" | dddf$Well.ID=="MW-2",]
> dddf12$Well.ID<-factor(dddf12$Well.ID,levels=c("MW-1","MW-2"))
> boxplot(Barium~Well.ID,dddf12)
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From teresamarso at hotmail.com  Fri Apr  4 08:36:32 2014
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Fri, 4 Apr 2014 06:36:32 +0000
Subject: [R] Box plot without original data
Message-ID: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>

Hi to everyone!

I need to plot a box plot but I don't have the original data, is it possible to make it just with the median, mean, sd and range of values?

Any idea is welcome.


Thanks in advance. 		 	   		  


From teresamarso at hotmail.com  Fri Apr  4 10:49:10 2014
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Fri, 4 Apr 2014 08:49:10 +0000
Subject: [R] Simulating data
In-Reply-To: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
Message-ID: <DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>

Hi to everyone


To simulate data I only know this command:

rnorm(n , mean, sd)
?
It exists another way to specify?Median and range as well?

The point is that?I have ?this information about the variable:


Median: 4.3
Mean: 4.2
SD: 1.8
Range: 0-8

and I need a boxplot, but I don't have the original data, simulating data?
looks?a good idea to solve it.

Thanks in advance. 		 	   		  


From jim at bitwrit.com.au  Fri Apr  4 10:56:12 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 04 Apr 2014 19:56:12 +1100
Subject: [R] Box plot without original data
In-Reply-To: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
Message-ID: <533E73AC.8010906@bitwrit.com.au>

On 04/04/2014 05:36 PM, M? Teresa Martinez Soriano wrote:
> Hi to everyone!
>
> I need to plot a box plot but I don't have the original data, is it possible to make it just with the median, mean, sd and range of values?
>
> Any idea is welcome.
>
Hi Teresa,
You can get the return value from the boxplot function and then 
substitute the values you want into the $stats component. Then pass that 
to the bxp function. See the help pages for boxplot and bxp.

Another option is to use the box.heresy function in the plotrix package, 
as that function does not assume that the box will be defined by the 
median and (approximate) quartiles.

Jim



From Keith.Jewell at campdenbri.co.uk  Fri Apr  4 10:11:26 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Fri, 4 Apr 2014 09:11:26 +0100
Subject: [R] Equation of a curve
In-Reply-To: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
References: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
Message-ID: <lhlpff$r79$1@ger.gmane.org>

On 03/04/2014 16:26, Frances Cheesman wrote:
> Hi all,
>
> I have a number of bacterial growth curves I would like to find the
> equations for these and then integrate them to find the area under the
> curves for me to do stats on later.
>
> Is there any way I can do this in R?
>
> Thanks,
>
> Frances
>
> 	[[alternative HTML version deleted]]
>
Responding to the curve fitting question and passing over the 
integration issue...

It is quite common to use nls to fit equations to log(count) v time 
data. You'll have to choose an appropriate model, ideally as a self 
starting nls model. Of those included in the stats package you might 
consider SSfpl, SSgompertz, SSlogis and SSweibull.

But choice of a model is really a microbiological issue and all those 
models might be considered a little passe. Fitting this kind of 
sigmoidal model can be difficult unless the data is good.



From johndharrison0 at gmail.com  Thu Apr  3 22:03:58 2014
From: johndharrison0 at gmail.com (John Harrison)
Date: Fri, 4 Apr 2014 03:03:58 +0700
Subject: [R] [R-pkgs] rDVR package
Message-ID: <CALVusX9Guch9jfqPL0+RkD=sd4mktNLVEGvsY87RoWjbqT21YQ@mail.gmail.com>

I would like to announce the release of version 0.1.1 of the rDVR package
on CRAN.  rDVR is an R package that allows cross Platform (Lin/Win/OSx)
video recording from R. It is light weight and allows up to 10 minutes of
recording by default.

rDVR has a project page at

http://johndharrison.github.io/rDVR/
http://cran.r-project.org/web/packages/rDVR/index.html

The package comes with a vignette which contain overviews on basic
operation and a few examples linking to projects such as Shiny and
RSelenium. rDVR uses include bug testing, project documentation and web
testing.

Comments and suggestions are greatly appreciated.

John Harrison

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages



From fcheesman.fc at gmail.com  Fri Apr  4 11:34:43 2014
From: fcheesman.fc at gmail.com (Frances Cheesman)
Date: Fri, 4 Apr 2014 10:34:43 +0100
Subject: [R] Equation of a curve
In-Reply-To: <lhlpff$r79$1@ger.gmane.org>
References: <CAGp8wPG99jZp-Bvs8Sr3M-KSDy9+-TyYNhPivAF197XcgX6o8w@mail.gmail.com>
	<lhlpff$r79$1@ger.gmane.org>
Message-ID: <CAGp8wPHD56_sSXmkM=5+v9hNJHL1hBgA_+r45uNRy7UuYKVvfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/77e0f9fa/attachment-0001.pl>

From frtog at vestas.com  Fri Apr  4 12:08:35 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 4 Apr 2014 12:08:35 +0200
Subject: [R] Simulating data
In-Reply-To: <DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
	<DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5AD92F1@DKRDSEXC016.vestas.net>

Hi Teresa

Try this:

Median <- 4.3
Mean <- 4.2
SD <- 1.8
RangeLower <- 0
RangeUpper <- 8

par(mfcol = c(1,2))

(bpstats <- boxplot(rnorm(100, mean = Mean, sd = SD), outl = FALSE))

## assuming normality of original data since we don't know the distribution
## get the 25% and 75% quantile
q25 <- qnorm(0.25, mean = Mean, sd = SD)
q75 <- qnorm(0.75, mean = Mean, sd = SD)

yourstats <- matrix(c(RangeLower, q25, Median, q75, RangeUpper), ncol = 1)

bpstats$stats <- yourstats 

bxp(bpstats, outl = FALSE)



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of M? Teresa Martinez Soriano
> Sent: 4. april 2014 10:49
> To: r-help at r-project.org
> Subject: [R] Simulating data
> 
> Hi to everyone
> 
> 
> To simulate data I only know this command:
> 
> rnorm(n , mean, sd)
> 
> It exists another way to specify?Median and range as well?
> 
> The point is that?I have ?this information about the variable:
> 
> 
> Median: 4.3
> Mean: 4.2
> SD: 1.8
> Range: 0-8
> 
> and I need a boxplot, but I don't have the original data, simulating data
> looks?a good idea to solve it.
> 
> Thanks in advance.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jfox at mcmaster.ca  Fri Apr  4 13:55:17 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 04 Apr 2014 07:55:17 -0400
Subject: [R] MANOVA post hoc testing
In-Reply-To: <AB7C4CCDB3124840828A5050BD277EB41B12B995@exmbx03-cdc.nexus.csiro.au>
References: <AB7C4CCDB3124840828A5050BD277EB41B12B995@exmbx03-cdc.nexus.csiro.au>
Message-ID: <web-504233814@cgpsrv2.cis.mcmaster.ca>

Dear Nicholas,

On Fri, 4 Apr 2014 04:59:09 +0000
 <Nicholas.Surawski at csiro.au> wrote:
> Greetings,
> 
> I'm interested in performing some post hoc tests after conducting a multivariate analysis of covariance (MANCOVA) which I performed using the Anova function in the car package. The covariate did not end up being statistically significant, but the single factor's effect on the multivariate response was statistically significant.  From here, I would like to use the linearHypothesis function in the car package to test for where significant differences are occurring.
> 
> Codewise, to fit the MANCOVA i've used:
> Model_1 <- Anova(lm((Y)~X+covariate))
> I've then tried to perform multiple comparisons using:
> linearHypothesis(Model_1,matchCoefs(Model_1,"X"),white.adjust=TRUE)

The argument white.adjust=TRUE isn't available for a multivariate linear model; see ?linearHypothesis. Also, the command (without the white.adjust argument) will give you the same test as Anova() did.

Best,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
> 
> After I run the 2nd bit of code I get the error message: " Error in vcov.default(model) :   there is no vcov() method for models of class Anova.mlm".
> 
> Presumably, this means that I've stuffed up in trying to estimate the variance-covariance matrix for the Anova function.
> 
> Any suggestions/help to resolve this problem would be greatly appreciated.
> 
> Cheers,
> 
> Nic Surawski
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From enrraco at fimif.upt.al  Fri Apr  4 11:42:18 2014
From: enrraco at fimif.upt.al (drunkenphd)
Date: Fri, 4 Apr 2014 02:42:18 -0700 (PDT)
Subject: [R] How to plot data using ggplot
Message-ID: <1396604538079-4688168.post@n4.nabble.com>

Hi,
I have a list of cities and their coordinates, and also for each city I have
a variable varA which I want to represent in a map using ggplot.
For example :

CityA	  lat 22.93977	lon 46.70663	varA 545

CityB	  lat 23.93977	lon 46.70663	varA 122

VarA values begin from 0 to 3000.
I want the color scale to represent  this range appropriately.
Can you help
Regards



--
View this message in context: http://r.789695.n4.nabble.com/How-to-plot-data-using-ggplot-tp4688168.html
Sent from the R help mailing list archive at Nabble.com.



From thanoon.younis80 at gmail.com  Fri Apr  4 14:10:21 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Fri, 4 Apr 2014 15:10:21 +0300
Subject: [R] simulation data
Message-ID: <CABLo8nEigJsdfZCB8hiGam87FirUh9twRMRWXNho+xW9S6hF_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/8134c804/attachment-0001.pl>

From chrisege at stud.ntnu.no  Fri Apr  4 14:33:57 2014
From: chrisege at stud.ntnu.no (Chris89)
Date: Fri, 4 Apr 2014 05:33:57 -0700 (PDT)
Subject: [R] Lognormal AR(0,1) model
Message-ID: <1396614837257-4688176.post@n4.nabble.com>

Hi everyone!

I am trying to make two log-normal AR(0,1) model using R with a given
correlation between them, \rho, on the form:

X_t = \alpha X_{t-1} + a_t
Y_t = \beta Y_{t-1} + b_t

At the moment I have been making n values of correlated log-normal data,
called a_t and b_t, and generated a starting value X[1] and Y[1] using the
rnorm() function. The rest of the n-1 values are calculated in a for() loop.
The data do get a lognormal "look", but it is obviously not a lognormal
distribution. 

As I am a novice to time-series, my question is simply: Are there any way to
make correlated log-normal distributed AR(0,1) models, and are there any
package in R that will help me?

sincerely
Chris

 





--
View this message in context: http://r.789695.n4.nabble.com/Lognormal-AR-0-1-model-tp4688176.html
Sent from the R help mailing list archive at Nabble.com.



From SchinasiL at fellows.iarc.fr  Fri Apr  4 15:49:30 2014
From: SchinasiL at fellows.iarc.fr (Leah Schinasi)
Date: Fri, 4 Apr 2014 13:49:30 +0000
Subject: [R] MICE, POST-PROCESSING imputations with two conditions
Message-ID: <6A11D680DC1B004BADA1D275B4D1903811BB99CC@exchange>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/e189ed87/attachment-0001.pl>

From matthias.winkler at ibp.fraunhofer.de  Fri Apr  4 16:55:07 2014
From: matthias.winkler at ibp.fraunhofer.de (Winkler, Matthias)
Date: Fri, 4 Apr 2014 14:55:07 +0000
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
Message-ID: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/cdf750c7/attachment-0001.pl>

From deter088 at umn.edu  Fri Apr  4 17:42:49 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 4 Apr 2014 10:42:49 -0500
Subject: [R] simulation data
In-Reply-To: <CABLo8nEigJsdfZCB8hiGam87FirUh9twRMRWXNho+xW9S6hF_g@mail.gmail.com>
References: <CABLo8nEigJsdfZCB8hiGam87FirUh9twRMRWXNho+xW9S6hF_g@mail.gmail.com>
Message-ID: <CAOLJph=a-BLPUvEwPrrOy0rnO83YZyV-u5x6NrAAD=bruLq6gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/bc404ee4/attachment-0001.pl>

From rmh at temple.edu  Fri Apr  4 17:50:11 2014
From: rmh at temple.edu (Rmh)
Date: Fri, 4 Apr 2014 11:50:11 -0400
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
In-Reply-To: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
References: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
Message-ID: <CB5F6A50-6A8E-46F0-825F-15225E806298@temple.edu>


high probability you are in a daylight savings time problem.  see the archives for repair strategies.  probably it will be enforcing standard time on all measurements.

Rich
Sent from my iPhone

> On Apr 4, 2014, at 10:55, "Winkler, Matthias" <matthias.winkler at ibp.fraunhofer.de> wrote:
> 
> Dear R-users,
> 
> I'm working on datasets which contain data from the years 1960 to 2100 with a timestep of one hour. Every year has 365 days, leap years are ignored.
> After reading the dataset with R I convert the column which contains date/time to POSIXct:
> 
> as.POSIXct(strptime(MyData [,1], format="%d.%m.%Y : %H"))
> 
> After that, I divide the data with split() into parts of one year each. Then I recognized, that the years for some rows are obviously converted wrong: They show years larger than 2100 (see example below).
> I've controlled my original dataset, but the dates are correct there.
> 
> I also produced a date/time-sequence in R, which showed the same mistakes (see example below). The mistakes occur at the same dates like in my datasets. It's always at the end of march.
> 
>> datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"), to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
>> levels(as.factor(strftime(datetimesequenz, format="%Y")))
>  [1] "1960" "1961" "1962" "1963" "1964" "1965" "1966" "1967" "1968" "1969" "1970" "1971" "1972" "1973" "1974" "1975" "1976" "1977"
> [19] "1978" "1979" "1980" "1981" "1982" "1983" "1984" "1985" "1986" "1987" "1988" "1989" "1990" "1991" "1992" "1993" "1994" "1995"
> [37] "1996" "1997" "1998" "1999" "2000" "2001" "2002" "2003" "2004" "2005" "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013"
> [55] "2014" "2015" "2016" "2017" "2018" "2019" "2020" "2021" "2022" "2023" "2024" "2025" "2026" "2027" "2028" "2029" "2030" "2031"
> [73] "2032" "2033" "2034" "2035" "2036" "2037" "2038" "2039" "2040" "2041" "2042" "2043" "2044" "2045" "2046" "2047" "2048" "2049"
> [91] "2050" "2051" "2052" "2053" "2054" "2055" "2056" "2057" "2058" "2059" "2060" "2061" "2062" "2063" "2064" "2065" "2066" "2067"
> [109] "2068" "2069" "2070" "2071" "2072" "2073" "2074" "2075" "2076" "2077" "2078" "2079" "2080" "2081" "2082" "2083" "2084" "2085"
> [127] "2086" "2087" "2088" "2089" "2090" "2091" "2092" "2093" "2094" "2095" "2096" "2097" "2098" "2099" "2100" "2101" "2102" "2103"
> [145] "2105" "2107" "2109" "2110" "2111" "2112" "2113" "2114" "2115" "2117" "2118" "2120" "2121" "2122" "2124" "2125" "2126" "2128"
> [163] "2129" "2130" "2131" "2132" "2133" "2135" "2137" "2138" "2139" "2140" "2141" "2142" "2143" "2145" "2146" "2148" "2149" "2150"
> [181] "2152" "2153" "2154" "2156" "2157" "2158" "2159" "2160" "2161" "2166"
> 
> Has anybody experienced the same problem and knows a workaround?
> 
> I'm using R 3.0.1 under Windows 7 64bit. I also tried this with R 3.0.3, it showed the same problem.
> Thank you for your help!
> 
> Kind regards,
> Matthias
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Fri Apr  4 18:54:26 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Apr 2014 12:54:26 -0400
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
In-Reply-To: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
References: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
Message-ID: <533EE3C2.8060808@gmail.com>

On 04/04/2014 10:55 AM, Winkler, Matthias wrote:
> Dear R-users,
>
> I'm working on datasets which contain data from the years 1960 to 2100 with a timestep of one hour. Every year has 365 days, leap years are ignored.
> After reading the dataset with R I convert the column which contains date/time to POSIXct:
>
> as.POSIXct(strptime(MyData [,1], format="%d.%m.%Y : %H"))
>
> After that, I divide the data with split() into parts of one year each. Then I recognized, that the years for some rows are obviously converted wrong: They show years larger than 2100 (see example below).
> I've controlled my original dataset, but the dates are correct there.
>
> I also produced a date/time-sequence in R, which showed the same mistakes (see example below). The mistakes occur at the same dates like in my datasets. It's always at the end of march.
>
> > datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"), to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
> > levels(as.factor(strftime(datetimesequenz, format="%Y")))
>    [1] "1960" "1961" "1962" "1963" "1964" "1965" "1966" "1967" "1968" "1969" "1970" "1971" "1972" "1973" "1974" "1975" "1976" "1977"
> [19] "1978" "1979" "1980" "1981" "1982" "1983" "1984" "1985" "1986" "1987" "1988" "1989" "1990" "1991" "1992" "1993" "1994" "1995"
> [37] "1996" "1997" "1998" "1999" "2000" "2001" "2002" "2003" "2004" "2005" "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013"
> [55] "2014" "2015" "2016" "2017" "2018" "2019" "2020" "2021" "2022" "2023" "2024" "2025" "2026" "2027" "2028" "2029" "2030" "2031"
> [73] "2032" "2033" "2034" "2035" "2036" "2037" "2038" "2039" "2040" "2041" "2042" "2043" "2044" "2045" "2046" "2047" "2048" "2049"
> [91] "2050" "2051" "2052" "2053" "2054" "2055" "2056" "2057" "2058" "2059" "2060" "2061" "2062" "2063" "2064" "2065" "2066" "2067"
> [109] "2068" "2069" "2070" "2071" "2072" "2073" "2074" "2075" "2076" "2077" "2078" "2079" "2080" "2081" "2082" "2083" "2084" "2085"
> [127] "2086" "2087" "2088" "2089" "2090" "2091" "2092" "2093" "2094" "2095" "2096" "2097" "2098" "2099" "2100" "2101" "2102" "2103"
> [145] "2105" "2107" "2109" "2110" "2111" "2112" "2113" "2114" "2115" "2117" "2118" "2120" "2121" "2122" "2124" "2125" "2126" "2128"
> [163] "2129" "2130" "2131" "2132" "2133" "2135" "2137" "2138" "2139" "2140" "2141" "2142" "2143" "2145" "2146" "2148" "2149" "2150"
> [181] "2152" "2153" "2154" "2156" "2157" "2158" "2159" "2160" "2161" "2166"
>
> Has anybody experienced the same problem and knows a workaround?
>
> I'm using R 3.0.1 under Windows 7 64bit. I also tried this with R 3.0.3, it showed the same problem.
> Thank you for your help!

I don't see this in 3.1.0 beta.  Do you?

Duncan Murdoch



From chiefmurphy at gmail.com  Fri Apr  4 19:32:08 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Fri, 4 Apr 2014 10:32:08 -0700
Subject: [R] Base within reverses column order
Message-ID: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>

I just noticed this annoyance, but I'm not the first one, apparently
-- see http://lists.r-forge.r-project.org/pipermail/datatable-help/2012-May/001176.html

The thread never answered the OP's question "Is this a bug?" so I
assume the answer, unfortunately, is No.

If not a bug, do users of within have a workaround to produce a result
with columns as ordered within 'within'? I can think of a way using
names and subset-with-select, but that seems unduly kludgy.

Thanks,
Dan



From murdoch.duncan at gmail.com  Fri Apr  4 19:55:22 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Apr 2014 13:55:22 -0400
Subject: [R] Base within reverses column order
In-Reply-To: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>
References: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>
Message-ID: <533EF20A.6010500@gmail.com>

On 04/04/2014 1:32 PM, Dan Murphy wrote:
> I just noticed this annoyance, but I'm not the first one, apparently
> -- see http://lists.r-forge.r-project.org/pipermail/datatable-help/2012-May/001176.html
>
> The thread never answered the OP's question "Is this a bug?" so I
> assume the answer, unfortunately, is No.
>
> If not a bug, do users of within have a workaround to produce a result
> with columns as ordered within 'within'? I can think of a way using
> names and subset-with-select, but that seems unduly kludgy.

I wouldn't be surprised if it is not consistent about that.  It uses 
as.list to convert an environment to a list, and that's where the 
reversal occurs:  but since environments are unordered collections of 
objects, you just happen to be seeing an undocumented and unpromised 
property of the internal implementation.

If the order matters to you, then create your initial dataframe with the 
new variables (set to NA, for example), or reorder it afterwards.  But 
generally speaking even in a dataframe (which is an ordered collection 
of objects), it's better to program in a way that doesn't make 
assumptions about the order.  Columns have names, and you should use those.

Duncan Murdoch



From ema.belli93 at gmail.com  Fri Apr  4 19:09:37 2014
From: ema.belli93 at gmail.com (Emanuele Belli)
Date: Fri, 4 Apr 2014 19:09:37 +0200
Subject: [R] par(mfrow)
Message-ID: <6412A024-80EE-46F5-9EA8-1BF30A9E0D6B@gmail.com>

Hi,
I have some problems using the par function: I want to split the screen into 2 rows and 4 col and I type " par(mfrow=c(2, 4)) " but when I do that, instead of setting a graphical parameter, it creates a white Quarz.
I'm currently using the R base version for Mac Os, 3.0.3 .
Could you give me an help?
Thank you very much, 

Emanuele


From eliza_botto at hotmail.com  Fri Apr  4 20:08:26 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 4 Apr 2014 18:08:26 +0000
Subject: [R] average of rows of each column
Message-ID: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/71586f87/attachment-0001.pl>

From djmuser at gmail.com  Fri Apr  4 20:46:06 2014
From: djmuser at gmail.com (Dennis Murphy)
Date: Fri, 4 Apr 2014 11:46:06 -0700
Subject: [R] How to plot data using ggplot
In-Reply-To: <1396604538079-4688168.post@n4.nabble.com>
References: <1396604538079-4688168.post@n4.nabble.com>
Message-ID: <CADv2QyHNMaUm4ZfpA-FurqEuLhckOjLz6ewyhXHFY+3B-s2JZw@mail.gmail.com>

1. Look into the ggmap package if you want to overlay your data onto a map.
2. Re your color scale representation, define 'appropriately'. Do you
mean a continuous range expressible in a colorbar or a discrete range,
and if the latter, what intervals did you have in mind?

Dennis

On Fri, Apr 4, 2014 at 2:42 AM, drunkenphd <enrraco at fimif.upt.al> wrote:
> Hi,
> I have a list of cities and their coordinates, and also for each city I have
> a variable varA which I want to represent in a map using ggplot.
> For example :
>
> CityA     lat 22.93977  lon 46.70663    varA 545
>
> CityB     lat 23.93977  lon 46.70663    varA 122
>
> VarA values begin from 0 to 3000.
> I want the color scale to represent  this range appropriately.
> Can you help
> Regards
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-plot-data-using-ggplot-tp4688168.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From david at revolutionanalytics.com  Fri Apr  4 21:38:15 2014
From: david at revolutionanalytics.com (David Smith)
Date: Fri, 4 Apr 2014 12:38:15 -0700
Subject: [R] Revolutions blog: March roundup
Message-ID: <CABgvEC_-of4xjPYunns-qu-GoDnJYgtcWs+-qoFKVkAgU-56vQ@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of March:

Francis Smart offers five excellent reasons to use R, and notes that R
is the top Google Search for statistical software:
http://bit.ly/1dYHrGv

Revolution Analytics is offering R training for SAS users in Singapore
and online: http://bit.ly/1dYHphT

The number of R user groups worldwide continues to grow, and there
have already been over 135 meetings in 2014: http://bit.ly/1dYHphV

Color palettes for R charts based on the production design of Wes
Anderson movies: http://bit.ly/1dYHrGu

A history of ensemble methods, by Mike Bowles: http://bit.ly/1dYHrGt

An eBook on Big Data and Data Science by the publishers of the Big
Data Journal includes articles based on R: http://bit.ly/1dYHphU

An in-depth tutorial by Gaston Sanchez on handling character data with
R: http://bit.ly/1dYHpi3

Joseph Rickert suggests several large, open data sets you can analyze
with R: http://bit.ly/1dYHrGz

Rodrigo Zamith updates his web-based application to compare NCAA
basketball team performance: http://bit.ly/1dYHpyg

Many R projects are under consideration for the 2014 Google Summer of
Code: http://bit.ly/1dYHpyh

Bob Muenchen shares his secrets of teaching with R: http://bit.ly/1dYHrGA

The Atlanta Big Data Analytics Team Challenge sponsored R users to
help CARE International: http://bit.ly/1dYHrGB

The Human Rights Data Analysis Group uses R and ensemble models to
quantify the impact of the war in Syria: http://bit.ly/1dYHrGD

An index of contributed R documentation, assembled into an R "meta"
book: http://bit.ly/1dYHrGF

The deadline for submitting tutorials to the useR! 2014 conference in
LA has been extended to April 10: http://bit.ly/1dYHpyk

Derek Norton describes how to do ridge regression using the rxCovCor
function of the RevoScaleR package: http://bit.ly/1dYHrGG

In an op-ed at RSS StatsLife, I review the role of statisticians in
data privacy: http://bit.ly/1dYHpyo

A brief summary of the improvements in R 3.0.3: http://bit.ly/1dYHpyr

Hidden Markov models in R, with application to detection
regime-switching events in financial markets: http://bit.ly/1dYHpys

Why automating data science is dangerous without human supervision and
statistical expertise: http://bit.ly/1dYHpyt

A history of Emacs and ESS-mode for R, by Rodney Sparapani:
http://bit.ly/1dYHpyv

Some news articles about R and Revolution Analytics in Wired,
ComputerWorld, Inside BigData and Datanami: http://bit.ly/1dYHpyu

Some non-R stories in the past month included: a real photo that looks
like Sim City (http://bit.ly/1dYHrWY), a video of Europe's
constantly-changing borders (http://bit.ly/1dYHpyw), the new
FiveThirtyEight data journalism site (http://bit.ly/1dYHrWZ),
bad-mannered cats (http://bit.ly/1dYHpOQ), and a surprising
demonstration of change blindness (http://bit.ly/1dYHpOS).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, via email using blogtrottr.com,
or by following me on Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid



From bretschr at xs4all.nl  Fri Apr  4 22:10:10 2014
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Fri, 4 Apr 2014 22:10:10 +0200
Subject: [R] par(mfrow)
In-Reply-To: <6412A024-80EE-46F5-9EA8-1BF30A9E0D6B@gmail.com>
References: <6412A024-80EE-46F5-9EA8-1BF30A9E0D6B@gmail.com>
Message-ID: <51C22D18-476C-4F61-93B1-AF50ACA6BA47@xs4all.nl>

Hi,


re:


> I have some problems using the par function: I want to split the screen into 2 rows and 4 col and I type " par(mfrow=c(2, 4)) " but when I do that, instead of setting a graphical parameter, it creates a white Quarz.
> I'm currently using the R base version for Mac Os, 3.0.3 .
> Could you give me an help?
> Thank you very much, 




But that's correct, if you don't plot something afterwards. Try plotting 8 x-y graphs, then you'll see that 8 small plot will appear (unless the margins will prove to be too large).

Good luck,


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl



From dcarlson at tamu.edu  Fri Apr  4 22:14:32 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 4 Apr 2014 15:14:32 -0500
Subject: [R] average of rows of each column
In-Reply-To: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
References: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
Message-ID: <002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>

Something like (only 20 columns here):

x <- matrix(rnorm(120*20), 120, 20)
xagg <- aggregate(x, list(rep(1:12, each=10)), mean)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of eliza botto
Sent: Friday, April 4, 2014 1:08 PM
To: r-help at r-project.org
Subject: [R] average of rows of each column


Dear useRs,
I have a matrix of 120 row and 1000 columns.What I want is to
get an average of a set of 12 rows starting from 1 till 120 for
each column. Precisely, for column 1 the average of 1:10 rows,
11:20 rows.... 111:120. similarly for column 2, 3, 4.... 1000.
So in the end i should have a matrix with 12 rows and 1000
columns.
Thankyou very much in advance.

Eliza
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From waverley.paloalto at gmail.com  Fri Apr  4 22:27:53 2014
From: waverley.paloalto at gmail.com (Waverley @ Palo Alto)
Date: Fri, 4 Apr 2014 13:27:53 -0700
Subject: [R] solicit help to read in 384 plate color image
Message-ID: <CADiQnYiwguMYBE3HQFeKFK+miYmxpmmnVanOLiqHtadhRePMqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/d0e68625/attachment-0001.pl>

From ruipbarradas at sapo.pt  Fri Apr  4 21:23:57 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 04 Apr 2014 20:23:57 +0100
Subject: [R] average of rows of each column
In-Reply-To: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
References: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
Message-ID: <533F06CD.8040108@sapo.pt>

Hello,

Try the following.

m <- 120
n <- 10  # in your case this is 1000
mat <- matrix(rnorm(n*m), nrow = m)

fun <- function(x, na.rm = TRUE){
	tapply(x, rep(1:12, each = 10), mean, na.rm = na.rm)
}

apply(mat, 2, fun)
apply(mat, 2, fun, na.rm = FALSE) # alternative



Hope this helps,

Rui Barradas

Em 04-04-2014 19:08, eliza botto escreveu:
>
> Dear useRs,
> I have a matrix of 120 row and 1000 columns.What I want is to get an average of a set of 12 rows starting from 1 till 120 for each column. Precisely, for column 1 the average of 1:10 rows, 11:20 rows.... 111:120. similarly for column 2, 3, 4.... 1000. So in the end i should have a matrix with 12 rows and 1000 columns.
> Thankyou very much in advance.
>
> Eliza
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From zmring at gmail.com  Fri Apr  4 23:06:15 2014
From: zmring at gmail.com (John Smith)
Date: Fri, 4 Apr 2014 17:06:15 -0400
Subject: [R] how to change annotations in contour function from rsm package
Message-ID: <CAPy-LLawsKXGTiRMyESiQGTh57tVj1KSgW0JMPC-31_zo5z15g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/96802595/attachment-0001.pl>

From dwinsemius at comcast.net  Fri Apr  4 23:19:09 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 4 Apr 2014 14:19:09 -0700
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
In-Reply-To: <533EE3C2.8060808@gmail.com>
References: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
	<533EE3C2.8060808@gmail.com>
Message-ID: <C67C1881-1105-4C40-B2A3-EA9FFE10C4C4@comcast.net>


On Apr 4, 2014, at 9:54 AM, Duncan Murdoch wrote:

> On 04/04/2014 10:55 AM, Winkler, Matthias wrote:
>> Dear R-users,
>> 
>> I'm working on datasets which contain data from the years 1960 to 2100 with a timestep of one hour. Every year has 365 days, leap years are ignored.
>> After reading the dataset with R I convert the column which contains date/time to POSIXct:
>> 
>> as.POSIXct(strptime(MyData [,1], format="%d.%m.%Y : %H"))
>> 
>> After that, I divide the data with split() into parts of one year each. Then I recognized, that the years for some rows are obviously converted wrong: They show years larger than 2100 (see example below).
>> I've controlled my original dataset, but the dates are correct there.
>> 
>> I also produced a date/time-sequence in R, which showed the same mistakes (see example below). The mistakes occur at the same dates like in my datasets. It's always at the end of march.
>> 
>> > datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"), to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
>> > levels(as.factor(strftime(datetimesequenz, format="%Y")))
>>   [1] "1960" "1961" "1962" "1963" "1964" "1965" "1966" "1967" "1968" "1969" "1970" "1971" "1972" "1973" "1974" "1975" "1976" "1977"
>> [19] "1978" "1979" "1980" "1981" "1982" "1983" "1984" "1985" "1986" "1987" "1988" "1989" "1990" "1991" "1992" "1993" "1994" "1995"
>> [37] "1996" "1997" "1998" "1999" "2000" "2001" "2002" "2003" "2004" "2005" "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013"
>> [55] "2014" "2015" "2016" "2017" "2018" "2019" "2020" "2021" "2022" "2023" "2024" "2025" "2026" "2027" "2028" "2029" "2030" "2031"
>> [73] "2032" "2033" "2034" "2035" "2036" "2037" "2038" "2039" "2040" "2041" "2042" "2043" "2044" "2045" "2046" "2047" "2048" "2049"
>> [91] "2050" "2051" "2052" "2053" "2054" "2055" "2056" "2057" "2058" "2059" "2060" "2061" "2062" "2063" "2064" "2065" "2066" "2067"
>> [109] "2068" "2069" "2070" "2071" "2072" "2073" "2074" "2075" "2076" "2077" "2078" "2079" "2080" "2081" "2082" "2083" "2084" "2085"
>> [127] "2086" "2087" "2088" "2089" "2090" "2091" "2092" "2093" "2094" "2095" "2096" "2097" "2098" "2099" "2100" "2101" "2102" "2103"
>> [145] "2105" "2107" "2109" "2110" "2111" "2112" "2113" "2114" "2115" "2117" "2118" "2120" "2121" "2122" "2124" "2125" "2126" "2128"
>> [163] "2129" "2130" "2131" "2132" "2133" "2135" "2137" "2138" "2139" "2140" "2141" "2142" "2143" "2145" "2146" "2148" "2149" "2150"
>> [181] "2152" "2153" "2154" "2156" "2157" "2158" "2159" "2160" "2161" "2166"
>> 
>> Has anybody experienced the same problem and knows a workaround?
>> 
>> I'm using R 3.0.1 under Windows 7 64bit. I also tried this with R 3.0.3, it showed the same problem.
>> Thank you for your help!
> 
> I don't see this in 3.1.0 beta.  Do you?

I'm not seeing it on a Mac in 3.0.2 either.

> max(datetimesequenz)
[1] "2100-01-01 PST"
> length(datetimesequenz)
[1] 1227241

> 
> Duncan Murdoch

David Winsemius
Alameda, CA, USA



From eliza_botto at hotmail.com  Fri Apr  4 23:46:16 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 4 Apr 2014 21:46:16 +0000
Subject: [R] average of rows of each column
In-Reply-To: <002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>
References: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>,
	<002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>
Message-ID: <BLU170-W7435881A2743C3961133EB896F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/8e9ac482/attachment-0001.pl>

From axel.urbiz at gmail.com  Sat Apr  5 01:10:35 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 4 Apr 2014 19:10:35 -0400
Subject: [R] Sweave files into LaTex
Message-ID: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/ee12a6e5/attachment-0001.pl>

From murdoch.duncan at gmail.com  Sat Apr  5 02:25:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Apr 2014 20:25:52 -0400
Subject: [R] Sweave files into LaTex
In-Reply-To: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
References: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
Message-ID: <533F4D90.7000208@gmail.com>

On 04/04/2014, 7:10 PM, Axel Urbiz wrote:
> Hi,
>
> I'm writing a thesis in Latex (say master.tex). I'd like to include R
> code/results from an .Rwd file. I've naively tried:
>
> 1) Add ONLY the code below in Rcode.Rnw file:
>
> \section{Exploratory data analysis}
> <<eval=TRUE, echo=FALSE>>=
> library(ggplot2)
> data(diamonds)
> head(diamonds)
> @
>
> 2) Then, in the master.tex file add the following line:
>
> \include{Rcode.Rnw}
>
> But of course, that didn't work.Any help would be much appreciated.

You want

\include{Rcode.tex}

But you have to run Sweave to produce Rcode.tex from Rcode.Rnw.  The 
patchDVI package has functions to make this easy if you're using 
TeXWorks or some other LaTeX editors -- see the vignette.

Duncan Murdoch



From enrraco at fimif.upt.al  Fri Apr  4 20:53:16 2014
From: enrraco at fimif.upt.al (drunkenphd)
Date: Fri, 4 Apr 2014 11:53:16 -0700 (PDT)
Subject: [R] How to plot data using ggplot
In-Reply-To: <CADv2QyHNMaUm4ZfpA-FurqEuLhckOjLz6ewyhXHFY+3B-s2JZw@mail.gmail.com>
References: <1396604538079-4688168.post@n4.nabble.com>
	<CADv2QyHNMaUm4ZfpA-FurqEuLhckOjLz6ewyhXHFY+3B-s2JZw@mail.gmail.com>
Message-ID: <1396637596602-4688191.post@n4.nabble.com>

djmuseR wrote
> Do you mean a continuous range expressible in a colorbar or a discrete
> range,
> and if the latter, what intervals did you have in mind? 

I mean diskrete values like : 545    0    8   25  101  420   95  928   24 
165    6  108   18  213   70.
The problem is that range is from 0-4000 while only one value is near 4000
and all the others are below 1000.
Please advice..
Regards




--
View this message in context: http://r.789695.n4.nabble.com/How-to-plot-data-using-ggplot-tp4688168p4688191.html
Sent from the R help mailing list archive at Nabble.com.



From jabugri at uds.edu.gh  Sat Apr  5 08:46:53 2014
From: jabugri at uds.edu.gh (James Abugri)
Date: Sat, 5 Apr 2014 07:46:53 +0100
Subject: [R] rehh package for iHS and Rsb on NGS data
Message-ID: <533f0c49.c5030e0a.2cd5.ffffc500@mx.google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140405/f120fe66/attachment-0001.pl>

From libgray3827 at gmail.com  Sat Apr  5 00:17:29 2014
From: libgray3827 at gmail.com (Lib Gray)
Date: Fri, 4 Apr 2014 17:17:29 -0500
Subject: [R] Subsetting data by ID with different constraints
Message-ID: <CAHaLxz0ZsMHAQ1=2ZsGgS04O4rMg4PP2GPfg7SjF=Vvpjyy44A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/ced6ffc0/attachment-0001.pl>

From dwinsemius at comcast.net  Sat Apr  5 03:15:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 4 Apr 2014 18:15:45 -0700
Subject: [R] rehh package for iHS and Rsb on NGS data
In-Reply-To: <533f0c49.c5030e0a.2cd5.ffffc500@mx.google.com>
References: <533f0c49.c5030e0a.2cd5.ffffc500@mx.google.com>
Message-ID: <2A4A346C-E5A9-4325-99BD-7A6332BD4C9D@comcast.net>


On Apr 4, 2014, at 11:46 PM, James Abugri wrote:

> Hello expert community.
> Is there anybody whose used rehh package for iHS and rsb. I have gone through the tutorial a dozen times, I need expert help to enable me apply it to my p.falciparum snp data from the illumina platform.
> 

This sounds like it would be more appropriate on the BioConductor forum.

> Thanks
> James Abugri
> -- 
> * "The information contained in this email and any attachments may be 
> legally privileged and confidential. If you are not an intended recipient, 
> you are hereby notified that any dissemination, distribution, or copying of 
> this e-mail is strictly prohibited. If you have received this e-mail in 
> error, please notify the sender and permanently delete the e-mail and any 
> attachments immediately. You should not retain, copy or use this e-mail or 
> any attachments for any purpose, nor disclose all or any part of the 
> contents to any other person."*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From smartpink111 at yahoo.com  Sat Apr  5 05:21:57 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Apr 2014 20:21:57 -0700 (PDT)
Subject: [R] Removing White spaces with NA
In-Reply-To: <1396462852.61193.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1396462852.61193.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1396668117.79190.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Check if this works:
n <- 1e7
dat <- data.frame(Col1=c("A", "", "B","C", "","","D",rep('',n)), stringsAsFactors=FALSE) 

dat2 <- dat

dat[dat==''] <- NA 

which(dat$Col1=='')
#integer(0) 


#or 
dat2$Col1[dat2$Col1==''] <- NA 
?which(dat2$Col1=='') 
#integer(0) 

A.K.


On Wednesday, April 2, 2014 2:20 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
May be this helps:
dat <- data.frame(Col1=c("A", "", "B","C", "","","D"), stringsAsFactors=FALSE)
is.na(dat) <- dat==''
dat$Col1
#[1] "A" NA? "B" "C" NA? NA? "D" 
A.K.



Hi All, I have a table and a column with values as below Col1
A B
C D I need to replace the Empty cells with the value NA as below
Col1
A
NA
B
C
NA
NA
D I tried a code, which was not working.
Table.name$column.name <- gsub("","NA", table.name$column.name) Can anyone help me with this ?
Thanks and regards,
Praveen



From zilefacelvis at yahoo.com  Sat Apr  5 06:02:03 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 4 Apr 2014 21:02:03 -0700 (PDT)
Subject: [R] Aggregate time series from daily to monthly by date and site
Message-ID: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>

Hi,
I have daily data arranged by date and site. Keeping the number of columns as there are, I will like to aggregate (FUN=mean) from daily to monthly the following data (only part is shown here) which starts in 1971 and ends in 1980.

? ? Year Month Day Site Sim001 Sim002 Sim003 Sim004
1 ? 1971 ? ? 1 ? 1 GGG1 ? 8.58 -12.67 ? 4.45 ?-1.31
2 ? 1971 ? ? 1 ? 1 GGG2 ?11.82 ?-9.94 ?-3.37 ? 4.94
3 ? 1971 ? ? 1 ? 1 GGG3 ? 7.72 -11.94 ?-1.17 ? 4.70
4 ? 1971 ? ? 1 ? 1 GGG4 ? 8.93 -10.81 ? 4.66 ? 2.88
5 ? 1971 ? ? 1 ? 1 GGG5 ? 9.82 ?-6.78 ?-4.19 ?-0.01
6 ? 1971 ? ? 1 ? 1 GGG6 ?13.93 ?-3.39 ?-3.84 ? 1.83
7 ? 1971 ? ? 1 ? 1 GGG7 ?10.94 ?-7.58 ? 1.74 ?-7.51
8 ? 1971 ? ? 1 ? 1 GGG8 ? 5.07 -16.09 ? 1.26 ? 1.12
9 ? 1971 ? ? 1 ? 1 GGG9 ?11.13 ?-9.96 ?-7.06 ? 5.25
10 ?1971 ? ? 1 ? 1 GG10 ? 7.66 ?-8.68 ?-2.65 ? 5.25
11 ?1971 ? ? 1 ? 1 GG11 ? 1.06 ? 6.14 ?-4.88 ? 3.78
12 ?1971 ? ? 1 ? 1 GG12 ?14.93 -12.43 ?-4.06 ? 4.94
13 ?1971 ? ? 1 ? 1 GG13 ? 7.56 -10.81 ?-2.32 ? 2.32
14 ?1971 ? ? 1 ? 1 GG14 ? 6.18 ?-7.58 ?-1.64 ? 9.83
15 ?1971 ? ? 1 ? 1 GG15 ?10.96 ?-0.62 ? 0.56 ?-1.59
16 ?1971 ? ? 1 ? 1 GG16 ? 4.94 ? 1.52 ? 0.31 ? 6.45
17 ?1971 ? ? 1 ? 1 GG17 ? 0.79 ? 0.83 ?-0.35 ? 4.26
18 ?1971 ? ? 1 ? 1 GG18 ? 4.91 ?-3.29 ?-5.69 ? 3.10
19 ?1971 ? ? 1 ? 1 GG19 ? 0.68 ?-0.50 ? 3.35 ? 5.50
20 ?1971 ? ? 1 ? 1 GG20 ? 4.50 ? 1.14 ? 4.84 ? 6.94
21 ?1971 ? ? 1 ? 1 GG21 ? 3.13 ? 3.35 ? 3.62 ? 2.76
22 ?1971 ? ? 1 ? 1 GG22 ? 2.91 ? 1.10 ? 0.77 ? 5.10
23 ?1971 ? ? 1 ? 1 GG23 ?-2.27 ?-5.25 ?-3.05 ? 1.95
24 ?1971 ? ? 1 ? 1 GG24 ? 8.18 ? 2.00 ?-0.42 ?15.13
25 ?1971 ? ? 1 ? 1 GG25 ? 3.87 ?-4.09 ?-2.55 ?-9.18
26 ?1971 ? ? 1 ? 1 GG26 ? 5.10 ? 2.28 ? 1.34 ? 2.88
27 ?1971 ? ? 1 ? 1 GG27 ? 7.23 ? 2.46 ? 2.89 ? 4.28
28 ?1971 ? ? 1 ? 1 GG28 ? 8.55 ? 5.64 ? 3.09 ?-5.01
29 ?1971 ? ? 1 ? 1 GG29 ? 1.39 ? 4.64 ? 9.79 ?-0.27
30 ?1971 ? ? 1 ? 1 GG30 ? 6.85 -12.11 ? 4.98 ? 1.91
31 ?1971 ? ? 1 ? 1 GG31 ? 4.25 ?-2.21 ? 9.59 ?-1.46
32 ?1971 ? ? 1 ? 1 GG32 ?-0.24 -16.54 ? 4.99 ?-0.60
33 ?1971 ? ? 1 ? 1 GG33 ? 9.86 ?-7.38 ?11.77 ?-8.99
34 ?1971 ? ? 1 ? 1 GG34 ? 9.92 -16.33 ?13.07 ?-8.79
35 ?1971 ? ? 1 ? 1 GG35 ? 5.11 ?-7.63 ? 0.41 ?-3.09
36 ?1971 ? ? 1 ? 1 GG36 ? 6.14 -11.61 ?10.38 ?-7.09
37 ?1971 ? ? 1 ? 1 GG37 ? 8.14 -12.78 ?11.01 ?-5.20
38 ?1971 ? ? 1 ? 1 GG38 ? 7.52 -12.86 ? 3.43 ?-7.55
39 ?1971 ? ? 1 ? 1 GG39 ? 4.19 ?-9.99 ? 6.08 ?-4.04
40 ?1971 ? ? 1 ? 1 GG40 ? 1.02 ? 4.84 ? 0.55 ?-3.80
41 ?1971 ? ? 1 ? 1 GG41 ?-2.43 -13.75 ? 6.49 -10.66
42 ?1971 ? ? 1 ? 1 GG42 ? 6.85 -12.33 ? 2.85 ?-6.34
43 ?1971 ? ? 1 ? 1 GG43 ? 4.94 -13.43 ?11.17 ?-3.62
44 ?1971 ? ? 1 ? 1 GG44 ? 8.11 -21.13 ?11.32 ?-8.49
45 ?1971 ? ? 1 ? 1 GG45 ? 7.34 -12.63 ?-0.89 ?-2.29
46 ?1971 ? ? 1 ? 1 GG46 ?10.56 ?-3.16 ?-0.48 ? 0.38
47 ?1971 ? ? 1 ? 1 GG47 ?-6.52 ? 1.61 ?10.80 ? 5.25
48 ?1971 ? ? 1 ? 1 GG48 ? 2.66 ?-2.36 ? 1.86 ? 8.60
49 ?1971 ? ? 1 ? 1 GG49 ?-4.89 ? 5.54 ? 6.63 ? 5.83
50 ?1971 ? ? 1 ? 1 GG50 ? 0.11 ? 3.59 ? 5.14 ? 8.94
51 ?1971 ? ? 1 ? 1 GG51 ? 3.90 ? 1.23 ? 4.13 ? 9.86
52 ?1971 ? ? 1 ? 1 GG52 ? 3.87 ?-0.25 ? 8.72 ? 4.62
53 ?1971 ? ? 1 ? 1 GG53 ? 2.55 ?-1.49 ?15.01 ? 4.33
54 ?1971 ? ? 1 ? 1 GG54 ?-0.20 ?-1.65 ? 4.78 ?10.15
55 ?1971 ? ? 1 ? 1 GG55 ? 5.09 ? 0.90 ? 5.56 ? 7.87
56 ?1971 ? ? 1 ? 1 GG56 ?-2.40 ?-2.29 ? 5.69 ? 9.07
57 ?1971 ? ? 1 ? 1 GG57 ? 1.32 ?-2.35 ?10.39 ? 0.04
58 ?1971 ? ? 1 ? 1 GG58 ? 3.49 ?-2.01 ? 8.99 ? 2.85
59 ?1971 ? ? 1 ? 1 GG59 ? 4.93 ?-2.07 ? 6.95 ? 6.00
60 ?1971 ? ? 1 ? 1 GG60 ?-9.58 ? 1.37 ?10.59 ? 4.54
61 ?1971 ? ? 1 ? 1 GG61 ? 9.08 ?-0.64 ? 3.92 ?13.50
62 ?1971 ? ? 1 ? 1 GG62 ? 2.85 ? 4.75 ? 3.40 ?12.39
63 ?1971 ? ? 1 ? 1 GG63 ? 7.71 ? 3.02 ? 3.95 ?11.79
64 ?1971 ? ? 1 ? 1 GG64 ? 4.50 ? 5.44 ? 0.87 ? 6.29
65 ?1971 ? ? 1 ? 1 GG65 ? 0.99 ? 3.76 ? 2.28 ?15.45
66 ?1971 ? ? 1 ? 1 GG66 ? 8.72 ? 5.16 ? 1.11 ?15.82
67 ?1971 ? ? 1 ? 1 GG67 ?12.45 ? 2.54 ? 4.36 ?19.79
68 ?1971 ? ? 1 ? 1 GG68 ? 8.83 ? 4.11 ? 6.21 ?13.12
69 ?1971 ? ? 1 ? 1 GG69 ? 8.94 ? 5.03 ? 1.73 ? 6.50
70 ?1971 ? ? 1 ? 1 GG70 ? 5.05 ?-1.12 ? 2.50 ?-4.63
71 ?1971 ? ? 1 ? 1 GG71 ? 9.82 ? 4.53 ? 4.19 ? 1.79
72 ?1971 ? ? 1 ? 1 GG72 ?11.72 ?-0.15 ? 1.85 ?-0.80
73 ?1971 ? ? 1 ? 1 GG73 ? 1.21 ?-4.98 ? 8.65 ? 1.29
74 ?1971 ? ? 1 ? 1 GG74 ? 7.92 ? 0.85 ? 6.24 ? 8.88
75 ?1971 ? ? 1 ? 1 GG75 ? 3.45 ?-3.04 ? 7.82 ? 1.28
76 ?1971 ? ? 1 ? 1 GG76 ? 1.34 ?-0.06 ? 7.43 ? 6.55
77 ?1971 ? ? 1 ? 1 GG77 ? 8.25 ?-3.01 ? 5.19 ? 5.78
78 ?1971 ? ? 1 ? 1 GG78 ? 2.92 ?-1.10 ?-1.71 ? 5.46
79 ?1971 ? ? 1 ? 1 GG79 ? 2.10 ? 4.02 ?-3.16 ? 2.83
80 ?1971 ? ? 1 ? 1 GG80 ?-3.19 ? 1.77 ?-2.66 ? 8.00
81 ?1971 ? ? 1 ? 1 GG81 ? 4.75 ?-3.36 ?-7.00 ? 6.25
82 ?1971 ? ? 1 ? 1 GG82 ?-0.30 ? 1.56 ?-2.08 ? 4.94
83 ?1971 ? ? 1 ? 1 GG83 ? 1.69 ?-1.63 ? 0.36 ? 5.01
84 ?1971 ? ? 1 ? 1 GG84 ? 3.31 ? 1.12 ? 8.61 ? 5.32
85 ?1971 ? ? 1 ? 1 GG85 ? 5.18 ?-2.39 ? 3.22 ? 2.95
86 ?1971 ? ? 1 ? 1 GG86 ? 2.43 ?-2.05 ? 7.99 ? 7.46
87 ?1971 ? ? 1 ? 1 GG87 ? 3.02 ? 4.51 ?-1.19 ? 5.71
88 ?1971 ? ? 1 ? 1 GG88 ?-5.31 ? 1.52 ?11.38 ?-3.51
89 ?1971 ? ? 1 ? 1 GG89 ?-6.70 ?-0.61 ?10.20 ? 3.51
90 ?1971 ? ? 1 ? 1 GG90 ?-5.90 ? 2.54 ? 8.87 ? 9.46
91 ?1971 ? ? 1 ? 1 GG91 ?-4.73 ? 2.88 ? 7.23 ? 8.55
92 ?1971 ? ? 1 ? 1 GG92 ?-8.13 ? 6.79 ? 8.07 ? 6.71
93 ?1971 ? ? 1 ? 1 GG93 ?-7.67 ? 5.50 ? 2.77 ? 7.36
94 ?1971 ? ? 1 ? 1 GG94 ? 3.73 ?-2.36 ? 9.61 ?10.96
95 ?1971 ? ? 1 ? 1 GG95 ?-2.40 ? 4.18 ?-1.10 ? 3.47
96 ?1971 ? ? 1 ? 1 GG96 ? 1.46 ?-0.13 ?-2.05 ?-1.99
97 ?1971 ? ? 1 ? 1 GG97 ?-4.71 ? 5.68 ? 6.39 ? 5.75
98 ?1971 ? ? 1 ? 1 GG98 ? 0.33 ? 1.82 ? 6.60 ? 1.56
99 ?1971 ? ? 1 ? 1 GG99 ?-3.11 ? 3.21 ?-2.89 ?-4.38
100 1971 ? ? 1 ? 1 G100 ? 2.45 ? 0.21 ?-6.41 ? 0.67



Thanks for your useful solution.
Atem.



From jdnewmil at dcn.davis.CA.us  Sat Apr  5 06:53:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 04 Apr 2014 21:53:55 -0700
Subject: [R] Aggregate time series from daily to monthly by date and site
In-Reply-To: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <01d93ba2-5caf-4e99-99bc-6a818e16ab1d@email.android.com>

You have been around long enough that we should not have to tell you how to provide data in a reproducible manner... read ?dput.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 4, 2014 9:02:03 PM PDT, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
>Hi,
>I have daily data arranged by date and site. Keeping the number of
>columns as there are, I will like to aggregate (FUN=mean) from daily to
>monthly the following data (only part is shown here) which starts in
>1971 and ends in 1980.
>
>? ? Year Month Day Site Sim001 Sim002 Sim003 Sim004
>1 ? 1971 ? ? 1 ? 1 GGG1 ? 8.58 -12.67 ? 4.45 ?-1.31
>2 ? 1971 ? ? 1 ? 1 GGG2 ?11.82 ?-9.94 ?-3.37 ? 4.94
>3 ? 1971 ? ? 1 ? 1 GGG3 ? 7.72 -11.94 ?-1.17 ? 4.70
>4 ? 1971 ? ? 1 ? 1 GGG4 ? 8.93 -10.81 ? 4.66 ? 2.88
>5 ? 1971 ? ? 1 ? 1 GGG5 ? 9.82 ?-6.78 ?-4.19 ?-0.01
>6 ? 1971 ? ? 1 ? 1 GGG6 ?13.93 ?-3.39 ?-3.84 ? 1.83
>7 ? 1971 ? ? 1 ? 1 GGG7 ?10.94 ?-7.58 ? 1.74 ?-7.51
>8 ? 1971 ? ? 1 ? 1 GGG8 ? 5.07 -16.09 ? 1.26 ? 1.12
>9 ? 1971 ? ? 1 ? 1 GGG9 ?11.13 ?-9.96 ?-7.06 ? 5.25
>10 ?1971 ? ? 1 ? 1 GG10 ? 7.66 ?-8.68 ?-2.65 ? 5.25
>11 ?1971 ? ? 1 ? 1 GG11 ? 1.06 ? 6.14 ?-4.88 ? 3.78
>12 ?1971 ? ? 1 ? 1 GG12 ?14.93 -12.43 ?-4.06 ? 4.94
>13 ?1971 ? ? 1 ? 1 GG13 ? 7.56 -10.81 ?-2.32 ? 2.32
>14 ?1971 ? ? 1 ? 1 GG14 ? 6.18 ?-7.58 ?-1.64 ? 9.83
>15 ?1971 ? ? 1 ? 1 GG15 ?10.96 ?-0.62 ? 0.56 ?-1.59
>16 ?1971 ? ? 1 ? 1 GG16 ? 4.94 ? 1.52 ? 0.31 ? 6.45
>17 ?1971 ? ? 1 ? 1 GG17 ? 0.79 ? 0.83 ?-0.35 ? 4.26
>18 ?1971 ? ? 1 ? 1 GG18 ? 4.91 ?-3.29 ?-5.69 ? 3.10
>19 ?1971 ? ? 1 ? 1 GG19 ? 0.68 ?-0.50 ? 3.35 ? 5.50
>20 ?1971 ? ? 1 ? 1 GG20 ? 4.50 ? 1.14 ? 4.84 ? 6.94
>21 ?1971 ? ? 1 ? 1 GG21 ? 3.13 ? 3.35 ? 3.62 ? 2.76
>22 ?1971 ? ? 1 ? 1 GG22 ? 2.91 ? 1.10 ? 0.77 ? 5.10
>23 ?1971 ? ? 1 ? 1 GG23 ?-2.27 ?-5.25 ?-3.05 ? 1.95
>24 ?1971 ? ? 1 ? 1 GG24 ? 8.18 ? 2.00 ?-0.42 ?15.13
>25 ?1971 ? ? 1 ? 1 GG25 ? 3.87 ?-4.09 ?-2.55 ?-9.18
>26 ?1971 ? ? 1 ? 1 GG26 ? 5.10 ? 2.28 ? 1.34 ? 2.88
>27 ?1971 ? ? 1 ? 1 GG27 ? 7.23 ? 2.46 ? 2.89 ? 4.28
>28 ?1971 ? ? 1 ? 1 GG28 ? 8.55 ? 5.64 ? 3.09 ?-5.01
>29 ?1971 ? ? 1 ? 1 GG29 ? 1.39 ? 4.64 ? 9.79 ?-0.27
>30 ?1971 ? ? 1 ? 1 GG30 ? 6.85 -12.11 ? 4.98 ? 1.91
>31 ?1971 ? ? 1 ? 1 GG31 ? 4.25 ?-2.21 ? 9.59 ?-1.46
>32 ?1971 ? ? 1 ? 1 GG32 ?-0.24 -16.54 ? 4.99 ?-0.60
>33 ?1971 ? ? 1 ? 1 GG33 ? 9.86 ?-7.38 ?11.77 ?-8.99
>34 ?1971 ? ? 1 ? 1 GG34 ? 9.92 -16.33 ?13.07 ?-8.79
>35 ?1971 ? ? 1 ? 1 GG35 ? 5.11 ?-7.63 ? 0.41 ?-3.09
>36 ?1971 ? ? 1 ? 1 GG36 ? 6.14 -11.61 ?10.38 ?-7.09
>37 ?1971 ? ? 1 ? 1 GG37 ? 8.14 -12.78 ?11.01 ?-5.20
>38 ?1971 ? ? 1 ? 1 GG38 ? 7.52 -12.86 ? 3.43 ?-7.55
>39 ?1971 ? ? 1 ? 1 GG39 ? 4.19 ?-9.99 ? 6.08 ?-4.04
>40 ?1971 ? ? 1 ? 1 GG40 ? 1.02 ? 4.84 ? 0.55 ?-3.80
>41 ?1971 ? ? 1 ? 1 GG41 ?-2.43 -13.75 ? 6.49 -10.66
>42 ?1971 ? ? 1 ? 1 GG42 ? 6.85 -12.33 ? 2.85 ?-6.34
>43 ?1971 ? ? 1 ? 1 GG43 ? 4.94 -13.43 ?11.17 ?-3.62
>44 ?1971 ? ? 1 ? 1 GG44 ? 8.11 -21.13 ?11.32 ?-8.49
>45 ?1971 ? ? 1 ? 1 GG45 ? 7.34 -12.63 ?-0.89 ?-2.29
>46 ?1971 ? ? 1 ? 1 GG46 ?10.56 ?-3.16 ?-0.48 ? 0.38
>47 ?1971 ? ? 1 ? 1 GG47 ?-6.52 ? 1.61 ?10.80 ? 5.25
>48 ?1971 ? ? 1 ? 1 GG48 ? 2.66 ?-2.36 ? 1.86 ? 8.60
>49 ?1971 ? ? 1 ? 1 GG49 ?-4.89 ? 5.54 ? 6.63 ? 5.83
>50 ?1971 ? ? 1 ? 1 GG50 ? 0.11 ? 3.59 ? 5.14 ? 8.94
>51 ?1971 ? ? 1 ? 1 GG51 ? 3.90 ? 1.23 ? 4.13 ? 9.86
>52 ?1971 ? ? 1 ? 1 GG52 ? 3.87 ?-0.25 ? 8.72 ? 4.62
>53 ?1971 ? ? 1 ? 1 GG53 ? 2.55 ?-1.49 ?15.01 ? 4.33
>54 ?1971 ? ? 1 ? 1 GG54 ?-0.20 ?-1.65 ? 4.78 ?10.15
>55 ?1971 ? ? 1 ? 1 GG55 ? 5.09 ? 0.90 ? 5.56 ? 7.87
>56 ?1971 ? ? 1 ? 1 GG56 ?-2.40 ?-2.29 ? 5.69 ? 9.07
>57 ?1971 ? ? 1 ? 1 GG57 ? 1.32 ?-2.35 ?10.39 ? 0.04
>58 ?1971 ? ? 1 ? 1 GG58 ? 3.49 ?-2.01 ? 8.99 ? 2.85
>59 ?1971 ? ? 1 ? 1 GG59 ? 4.93 ?-2.07 ? 6.95 ? 6.00
>60 ?1971 ? ? 1 ? 1 GG60 ?-9.58 ? 1.37 ?10.59 ? 4.54
>61 ?1971 ? ? 1 ? 1 GG61 ? 9.08 ?-0.64 ? 3.92 ?13.50
>62 ?1971 ? ? 1 ? 1 GG62 ? 2.85 ? 4.75 ? 3.40 ?12.39
>63 ?1971 ? ? 1 ? 1 GG63 ? 7.71 ? 3.02 ? 3.95 ?11.79
>64 ?1971 ? ? 1 ? 1 GG64 ? 4.50 ? 5.44 ? 0.87 ? 6.29
>65 ?1971 ? ? 1 ? 1 GG65 ? 0.99 ? 3.76 ? 2.28 ?15.45
>66 ?1971 ? ? 1 ? 1 GG66 ? 8.72 ? 5.16 ? 1.11 ?15.82
>67 ?1971 ? ? 1 ? 1 GG67 ?12.45 ? 2.54 ? 4.36 ?19.79
>68 ?1971 ? ? 1 ? 1 GG68 ? 8.83 ? 4.11 ? 6.21 ?13.12
>69 ?1971 ? ? 1 ? 1 GG69 ? 8.94 ? 5.03 ? 1.73 ? 6.50
>70 ?1971 ? ? 1 ? 1 GG70 ? 5.05 ?-1.12 ? 2.50 ?-4.63
>71 ?1971 ? ? 1 ? 1 GG71 ? 9.82 ? 4.53 ? 4.19 ? 1.79
>72 ?1971 ? ? 1 ? 1 GG72 ?11.72 ?-0.15 ? 1.85 ?-0.80
>73 ?1971 ? ? 1 ? 1 GG73 ? 1.21 ?-4.98 ? 8.65 ? 1.29
>74 ?1971 ? ? 1 ? 1 GG74 ? 7.92 ? 0.85 ? 6.24 ? 8.88
>75 ?1971 ? ? 1 ? 1 GG75 ? 3.45 ?-3.04 ? 7.82 ? 1.28
>76 ?1971 ? ? 1 ? 1 GG76 ? 1.34 ?-0.06 ? 7.43 ? 6.55
>77 ?1971 ? ? 1 ? 1 GG77 ? 8.25 ?-3.01 ? 5.19 ? 5.78
>78 ?1971 ? ? 1 ? 1 GG78 ? 2.92 ?-1.10 ?-1.71 ? 5.46
>79 ?1971 ? ? 1 ? 1 GG79 ? 2.10 ? 4.02 ?-3.16 ? 2.83
>80 ?1971 ? ? 1 ? 1 GG80 ?-3.19 ? 1.77 ?-2.66 ? 8.00
>81 ?1971 ? ? 1 ? 1 GG81 ? 4.75 ?-3.36 ?-7.00 ? 6.25
>82 ?1971 ? ? 1 ? 1 GG82 ?-0.30 ? 1.56 ?-2.08 ? 4.94
>83 ?1971 ? ? 1 ? 1 GG83 ? 1.69 ?-1.63 ? 0.36 ? 5.01
>84 ?1971 ? ? 1 ? 1 GG84 ? 3.31 ? 1.12 ? 8.61 ? 5.32
>85 ?1971 ? ? 1 ? 1 GG85 ? 5.18 ?-2.39 ? 3.22 ? 2.95
>86 ?1971 ? ? 1 ? 1 GG86 ? 2.43 ?-2.05 ? 7.99 ? 7.46
>87 ?1971 ? ? 1 ? 1 GG87 ? 3.02 ? 4.51 ?-1.19 ? 5.71
>88 ?1971 ? ? 1 ? 1 GG88 ?-5.31 ? 1.52 ?11.38 ?-3.51
>89 ?1971 ? ? 1 ? 1 GG89 ?-6.70 ?-0.61 ?10.20 ? 3.51
>90 ?1971 ? ? 1 ? 1 GG90 ?-5.90 ? 2.54 ? 8.87 ? 9.46
>91 ?1971 ? ? 1 ? 1 GG91 ?-4.73 ? 2.88 ? 7.23 ? 8.55
>92 ?1971 ? ? 1 ? 1 GG92 ?-8.13 ? 6.79 ? 8.07 ? 6.71
>93 ?1971 ? ? 1 ? 1 GG93 ?-7.67 ? 5.50 ? 2.77 ? 7.36
>94 ?1971 ? ? 1 ? 1 GG94 ? 3.73 ?-2.36 ? 9.61 ?10.96
>95 ?1971 ? ? 1 ? 1 GG95 ?-2.40 ? 4.18 ?-1.10 ? 3.47
>96 ?1971 ? ? 1 ? 1 GG96 ? 1.46 ?-0.13 ?-2.05 ?-1.99
>97 ?1971 ? ? 1 ? 1 GG97 ?-4.71 ? 5.68 ? 6.39 ? 5.75
>98 ?1971 ? ? 1 ? 1 GG98 ? 0.33 ? 1.82 ? 6.60 ? 1.56
>99 ?1971 ? ? 1 ? 1 GG99 ?-3.11 ? 3.21 ?-2.89 ?-4.38
>100 1971 ? ? 1 ? 1 G100 ? 2.45 ? 0.21 ?-6.41 ? 0.67
>
>
>
>Thanks for your useful solution.
>Atem.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From zilefacelvis at yahoo.com  Sat Apr  5 07:37:16 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 4 Apr 2014 22:37:16 -0700 (PDT)
Subject: [R] Aggregate time series from daily to monthly by date and site
In-Reply-To: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <1396676236.10755.YahooMailNeo@web160603.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140404/a6eb0ab3/attachment-0001.pl>

From ruipbarradas at sapo.pt  Sat Apr  5 12:46:46 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 05 Apr 2014 11:46:46 +0100
Subject: [R] Aggregate time series from daily to monthly by date and site
In-Reply-To: <1396676236.10755.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1396676236.10755.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <533FDF16.5060209@sapo.pt>

Hello,

Maybe the following will do.

dat <- structure(...)

aggregate(dat[5:8], dat[c(1, 2, 4)], FUN = mean)


Hope this helps,

Rui Barradas

Em 05-04-2014 06:37, Zilefac Elvis escreveu:
> Hi,
>
> I have daily data arranged by date and site. Keeping the number of columns as there are, I will like to aggregate (FUN=mean) from daily to monthly the following data (only part is shown here) which starts in 1971 and ends in 1980.
>
>
> structure(list(Year = c(1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971, 1971,
> 1971, 1971, 1971, 1971, 1971), Month = c(1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1), Day = c(1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1), Site = c("GGG1", "GGG2", "GGG3", "GGG4",
> "GGG5", "GGG6", "GGG7", "GGG8", "GGG9", "GG10", "GG11", "GG12",
> "GG13", "GG14", "GG15", "GG16", "GG17", "GG18", "GG19", "GG20",
> "GG21", "GG22", "GG23", "GG24", "GG25", "GG26", "GG27", "GG28",
> "GG29", "GG30", "GG31", "GG32", "GG33", "GG34", "GG35", "GG36",
> "GG37", "GG38", "GG39", "GG40", "GG41", "GG42", "GG43", "GG44",
> "GG45", "GG46", "GG47", "GG48", "GG49", "GG50", "GG51", "GG52",
> "GG53", "GG54", "GG55", "GG56", "GG57", "GG58", "GG59", "GG60",
> "GG61", "GG62", "GG63", "GG64", "GG65", "GG66", "GG67", "GG68",
> "GG69", "GG70", "GG71", "GG72", "GG73", "GG74", "GG75", "GG76",
> "GG77", "GG78", "GG79", "GG80", "GG81", "GG82", "GG83", "GG84",
> "GG85", "GG86", "GG87", "GG88", "GG89", "GG90", "GG91", "GG92",
> "GG93", "GG94", "GG95", "GG96", "GG97", "GG98", "GG99", "G100"
> ), Sim001 = c(8.58, 11.82, 7.72, 8.93, 9.82, 13.93, 10.94, 5.07,
> 11.13, 7.66, 1.06, 14.93, 7.56, 6.18, 10.96, 4.94, 0.79, 4.91,
> 0.68, 4.5, 3.13, 2.91, -2.27, 8.18, 3.87, 5.1, 7.23, 8.55, 1.39,
> 6.85, 4.25, -0.24, 9.86, 9.92, 5.11, 6.14, 8.14, 7.52, 4.19,
> 1.02, -2.43, 6.85, 4.94, 8.11, 7.34, 10.56, -6.52, 2.66, -4.89,
> 0.11, 3.9, 3.87, 2.55, -0.2, 5.09, -2.4, 1.32, 3.49, 4.93, -9.58,
> 9.08, 2.85, 7.71, 4.5, 0.99, 8.72, 12.45, 8.83, 8.94, 5.05, 9.82,
> 11.72, 1.21, 7.92, 3.45, 1.34, 8.25, 2.92, 2.1, -3.19, 4.75,
> -0.3, 1.69, 3.31, 5.18, 2.43, 3.02, -5.31, -6.7, -5.9, -4.73,
> -8.13, -7.67, 3.73, -2.4, 1.46, -4.71, 0.33, -3.11, 2.45), Sim002 = c(-12.67,
> -9.94, -11.94, -10.81, -6.78, -3.39, -7.58, -16.09, -9.96, -8.68,
> 6.14, -12.43, -10.81, -7.58, -0.62, 1.52, 0.83, -3.29, -0.5,
> 1.14, 3.35, 1.1, -5.25, 2, -4.09, 2.28, 2.46, 5.64, 4.64, -12.11,
> -2.21, -16.54, -7.38, -16.33, -7.63, -11.61, -12.78, -12.86,
> -9.99, 4.84, -13.75, -12.33, -13.43, -21.13, -12.63, -3.16, 1.61,
> -2.36, 5.54, 3.59, 1.23, -0.25, -1.49, -1.65, 0.9, -2.29, -2.35,
> -2.01, -2.07, 1.37, -0.64, 4.75, 3.02, 5.44, 3.76, 5.16, 2.54,
> 4.11, 5.03, -1.12, 4.53, -0.15, -4.98, 0.85, -3.04, -0.06, -3.01,
> -1.1, 4.02, 1.77, -3.36, 1.56, -1.63, 1.12, -2.39, -2.05, 4.51,
> 1.52, -0.61, 2.54, 2.88, 6.79, 5.5, -2.36, 4.18, -0.13, 5.68,
> 1.82, 3.21, 0.21), Sim003 = c(4.45, -3.37, -1.17, 4.66, -4.19,
> -3.84, 1.74, 1.26, -7.06, -2.65, -4.88, -4.06, -2.32, -1.64,
> 0.56, 0.31, -0.35, -5.69, 3.35, 4.84, 3.62, 0.77, -3.05, -0.42,
> -2.55, 1.34, 2.89, 3.09, 9.79, 4.98, 9.59, 4.99, 11.77, 13.07,
> 0.41, 10.38, 11.01, 3.43, 6.08, 0.55, 6.49, 2.85, 11.17, 11.32,
> -0.89, -0.48, 10.8, 1.86, 6.63, 5.14, 4.13, 8.72, 15.01, 4.78,
> 5.56, 5.69, 10.39, 8.99, 6.95, 10.59, 3.92, 3.4, 3.95, 0.87,
> 2.28, 1.11, 4.36, 6.21, 1.73, 2.5, 4.19, 1.85, 8.65, 6.24, 7.82,
> 7.43, 5.19, -1.71, -3.16, -2.66, -7, -2.08, 0.36, 8.61, 3.22,
> 7.99, -1.19, 11.38, 10.2, 8.87, 7.23, 8.07, 2.77, 9.61, -1.1,
> -2.05, 6.39, 6.6, -2.89, -6.41), Sim004 = c(-1.31, 4.94, 4.7,
> 2.88, -0.01, 1.83, -7.51, 1.12, 5.25, 5.25, 3.78, 4.94, 2.32,
> 9.83, -1.59, 6.45, 4.26, 3.1, 5.5, 6.94, 2.76, 5.1, 1.95, 15.13,
> -9.18, 2.88, 4.28, -5.01, -0.27, 1.91, -1.46, -0.6, -8.99, -8.79,
> -3.09, -7.09, -5.2, -7.55, -4.04, -3.8, -10.66, -6.34, -3.62,
> -8.49, -2.29, 0.38, 5.25, 8.6, 5.83, 8.94, 9.86, 4.62, 4.33,
> 10.15, 7.87, 9.07, 0.04, 2.85, 6, 4.54, 13.5, 12.39, 11.79, 6.29,
> 15.45, 15.82, 19.79, 13.12, 6.5, -4.63, 1.79, -0.8, 1.29, 8.88,
> 1.28, 6.55, 5.78, 5.46, 2.83, 8, 6.25, 4.94, 5.01, 5.32, 2.95,
> 7.46, 5.71, -3.51, 3.51, 9.46, 8.55, 6.71, 7.36, 10.96, 3.47,
> -1.99, 5.75, 1.56, -4.38, 0.67)), .Names = c("Year", "Month",
> "Day", "Site", "Sim001", "Sim002", "Sim003", "Sim004"), row.names = c(NA,
> 100L), class = "data.frame")
>
> Thanks for your useful solution.
> Atem.
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From nalimilan at club.fr  Sat Apr  5 12:54:14 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 5 Apr 2014 12:54:14 +0200
Subject: [R] Purpose of readLines(..., encoding=)?
Message-ID: <1396695254.14044.12.camel@milan>

Hi!

I'm wondering what's the use of the 'encoding' argument to readLines(x),
as opposed to readLines(file(x, encoding=)). The same question applies
to read.table()'s 'encoding' vs 'fileEncoding' arguments. AFAIK only the
latter is able to re-encode the read text into the internal
representation used by R (let's say when reading files in encodings
other than latin1 and UTF-8). But then what's the purpose of the former?

?readLines says:
encoding: encoding to be assumed for input strings.  It is used to mark
          character strings as known to be in Latin-1 or UTF-8: it is
          not used to re-encode the input.  To do the latter, specify
          the encoding as part of the connection ?con? or via
          ?options(encoding=)?: see the example under ?file?.

But if I have a UTF-8 text file to read, couldn't I use
readLines(file(x, encoding="UTF-8"))
instead of
readLines(x, encoding="UTF-8")

In my experience resulting character strings are marked as UTF-8 where
needed as well.

The reason I'm asking this is because I need to decide whether I should
allow users of a tm source plug-in to pass both (? la 'encoding' vs
'fileEncoding') or whether I could safely skip the first one.


Thanks for your help



From ripley at stats.ox.ac.uk  Sat Apr  5 15:16:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 5 Apr 2014 14:16:51 +0100
Subject: [R] Purpose of readLines(..., encoding=)?
In-Reply-To: <1396695254.14044.12.camel@milan>
References: <1396695254.14044.12.camel@milan>
Message-ID: <53400243.5010906@stats.ox.ac.uk>

UTF-8 is treated specially by readLines(), originally to allow for UTF-8 
strings on Windows.  See the NEWS for 2.12.0.

That is not the case for encoding = "latin1".

If you have a Latin-1 file in a UTF-8 locale, then

readLines(x, encoding = "latin1")

stores the strings in Latin-1 and marks them, and

readLines(file(x, encoding = "latin1"))

translates the strings to UTF-8 and marks them as such.

There can be advantages to the first, including speed and less storage 
space.  Also to the second (e.g. translating once may be better if the 
strings are to be manipulated by character-level functions).

Prior to 2.12.0 there were differences for UTF-8 files, and even now
readLines(x, encoding="UTF-8") is more convenient (no encoding left open 
as your first example will).

On 05/04/2014 11:54, Milan Bouchet-Valat wrote:
> Hi!
>
> I'm wondering what's the use of the 'encoding' argument to readLines(x),
> as opposed to readLines(file(x, encoding=)). The same question applies
> to read.table()'s 'encoding' vs 'fileEncoding' arguments. AFAIK only the
> latter is able to re-encode the read text into the internal
> representation used by R (let's say when reading files in encodings
> other than latin1 and UTF-8). But then what's the purpose of the former?
>
> ?readLines says:
> encoding: encoding to be assumed for input strings.  It is used to mark
>            character strings as known to be in Latin-1 or UTF-8: it is
>            not used to re-encode the input.  To do the latter, specify
>            the encoding as part of the connection ?con? or via
>            ?options(encoding=)?: see the example under ?file?.
>
> But if I have a UTF-8 text file to read, couldn't I use
> readLines(file(x, encoding="UTF-8"))
> instead of
> readLines(x, encoding="UTF-8")
>
> In my experience resulting character strings are marked as UTF-8 where
> needed as well.
>
> The reason I'm asking this is because I need to decide whether I should
> allow users of a tm source plug-in to pass both (? la 'encoding' vs
> 'fileEncoding') or whether I could safely skip the first one.
>
>
> Thanks for your help
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nalimilan at club.fr  Sat Apr  5 17:15:36 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 5 Apr 2014 17:15:36 +0200
Subject: [R] Purpose of readLines(..., encoding=)?
In-Reply-To: <53400243.5010906@stats.ox.ac.uk>
References: <1396695254.14044.12.camel@milan> <53400243.5010906@stats.ox.ac.uk>
Message-ID: <1396710936.6534.9.camel@milan>

Le samedi 05 avril 2014 ? 14:16 +0100, Prof Brian Ripley a ?crit :
> UTF-8 is treated specially by readLines(), originally to allow for UTF-8 
> strings on Windows.  See the NEWS for 2.12.0.
> 
> That is not the case for encoding = "latin1".
> 
> If you have a Latin-1 file in a UTF-8 locale, then
> 
> readLines(x, encoding = "latin1")
> 
> stores the strings in Latin-1 and marks them, and
> 
> readLines(file(x, encoding = "latin1"))
> 
> translates the strings to UTF-8 and marks them as such.
> 
> There can be advantages to the first, including speed and less storage 
> space.  Also to the second (e.g. translating once may be better if the 
> strings are to be manipulated by character-level functions).
Thanks for the detailed explanation. So in the case at hand I will only
retain 'fileEncoding', as tm corpora are expected to be converted to
UTF-8 (anything other than that is asking for trouble anyway).

> Prior to 2.12.0 there were differences for UTF-8 files, and even now
> readLines(x, encoding="UTF-8") is more convenient (no encoding left open 
> as your first example will).
I guess you meant "no connection left open"?

Indeed. I think it would be nice to add a 'fileEncoding' argument to
readLines(), just like the one passed to read.table(). This would be
more convenient than creating the connection and closing it after you're
done, and it would reduce the confusion for newcomers who try using
'encoding' when they really need the other solution. I could prepare a
patch to do this if you want.


Regards



From zilefacelvis at yahoo.com  Sat Apr  5 18:00:35 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sat, 5 Apr 2014 09:00:35 -0700 (PDT)
Subject: [R] Aggregate time series from daily to monthly by date and site
In-Reply-To: <533FDF16.5060209@sapo.pt>
References: <1396670523.32798.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1396676236.10755.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<533FDF16.5060209@sapo.pt>
Message-ID: <1396713635.48069.YahooMailNeo@web160602.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140405/14648c72/attachment-0001.pl>

From SSrinivasan at med.miami.edu  Sat Apr  5 10:50:39 2014
From: SSrinivasan at med.miami.edu (Srinivasan, Sathish  K)
Date: Sat, 5 Apr 2014 04:50:39 -0400
Subject: [R] Multic for windows 7 and Ubuntu
Message-ID: <4EB41664F8279A4CA870A740E038CFEA4A7B319F80@MEDEXMB05.ad.med.miami.edu>

Hi all,
Does anyone have issues installing multic package (http://cran.r-project.org/web/packages/multic/index.html) on ubuntu. Also, there is no active support for windows binary version. Could any one please help me install multic package on ubuntu 12.04, 64 bit system running with R 2.14.2 version.

Thanks
Sathish


From chiefmurphy at gmail.com  Sat Apr  5 19:10:05 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Sat, 5 Apr 2014 10:10:05 -0700
Subject: [R] Base within reverses column order
In-Reply-To: <533EF20A.6010500@gmail.com>
References: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>
	<533EF20A.6010500@gmail.com>
Message-ID: <CAHgH9_GLNVC-3h7=GMUX2GnF0c=1wsSijFrPEicvOTAW+TAAfw@mail.gmail.com>

Thanks, Duncan. Using names is certainly the most reliable solution,
but requires remembering to modify the "surrounding code" when
enhancing what's within -- a bug risk source when passing on the code.
Are you saying that an automatic reversal as follows may break in the
future because R-devel may change the current behavior of 'within'?
(If so, then that's the greater source of bug risk .. so back to
'names'.)

ln <- length(foo)
foo <- within(foo, {
  bar <- whatever
  other()
  })
foo <- foo[c(1:ln, length(foo):(ln+1))] # to reverse within's assumed
backwards column order

Is there a way to capture the names of new objects created within?


On Fri, Apr 4, 2014 at 10:55 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 04/04/2014 1:32 PM, Dan Murphy wrote:
>>
>> I just noticed this annoyance, but I'm not the first one, apparently
>> -- see
>> http://lists.r-forge.r-project.org/pipermail/datatable-help/2012-May/001176.html
>>
>> The thread never answered the OP's question "Is this a bug?" so I
>> assume the answer, unfortunately, is No.
>>
>> If not a bug, do users of within have a workaround to produce a result
>> with columns as ordered within 'within'? I can think of a way using
>> names and subset-with-select, but that seems unduly kludgy.
>
>
> I wouldn't be surprised if it is not consistent about that.  It uses as.list
> to convert an environment to a list, and that's where the reversal occurs:
> but since environments are unordered collections of objects, you just happen
> to be seeing an undocumented and unpromised property of the internal
> implementation.
>
> If the order matters to you, then create your initial dataframe with the new
> variables (set to NA, for example), or reorder it afterwards.  But generally
> speaking even in a dataframe (which is an ordered collection of objects),
> it's better to program in a way that doesn't make assumptions about the
> order.  Columns have names, and you should use those.
>
> Duncan Murdoch



From deter088 at umn.edu  Sat Apr  5 19:47:57 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Sat, 5 Apr 2014 12:47:57 -0500
Subject: [R] simulation data
In-Reply-To: <CABLo8nGEA6=9m46U9+=QobKs4aSgpGK19AphD16hjmcGRQOnBw@mail.gmail.com>
References: <CABLo8nEigJsdfZCB8hiGam87FirUh9twRMRWXNho+xW9S6hF_g@mail.gmail.com>
	<CAOLJph=a-BLPUvEwPrrOy0rnO83YZyV-u5x6NrAAD=bruLq6gw@mail.gmail.com>
	<CABLo8nGEA6=9m46U9+=QobKs4aSgpGK19AphD16hjmcGRQOnBw@mail.gmail.com>
Message-ID: <CAOLJphm8qu_YDMeWDVzOtTGaj6FfrcbCMSRmhXYzuCKZxPH_hw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140405/82fbb29d/attachment-0001.pl>

From friendly at yorku.ca  Sat Apr  5 20:13:53 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 05 Apr 2014 14:13:53 -0400
Subject: [R] Sweave files into LaTex
In-Reply-To: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
References: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
Message-ID: <534047E1.5090803@yorku.ca>

If you use knitr, you can do, in master.Rnw

<<Rcode, child="Rcode.Rnw">>=
@
This is the equivalent of \input{} (but not \include{}) at the .Rnw level.

At any rate, if you have more than just a few code chunks, you should
do your work in master.Rnw and produce master.tex from that using
either sweave() or knitr()

-M

On 4/4/2014 7:10 PM, Axel Urbiz wrote:
> Hi,
>
> I'm writing a thesis in Latex (say master.tex). I'd like to include R
> code/results from an .Rwd file. I've naively tried:
>
> 1) Add ONLY the code below in Rcode.Rnw file:
>
> \section{Exploratory data analysis}
> <<eval=TRUE, echo=FALSE>>=
> library(ggplot2)
> data(diamonds)
> head(diamonds)
> @
>
> 2) Then, in the master.tex file add the following line:
>
> \include{Rcode.Rnw}
>
> But of course, that didn't work.Any help would be much appreciated.
>
> Best,
> Axel.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From friendly at yorku.ca  Sat Apr  5 20:13:53 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 5 Apr 2014 14:13:53 -0400
Subject: [R] Sweave files into LaTex
In-Reply-To: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
References: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
Message-ID: <534047E1.5090803@yorku.ca>

If you use knitr, you can do, in master.Rnw

<<Rcode, child="Rcode.Rnw">>=
@
This is the equivalent of \input{} (but not \include{}) at the .Rnw level.

At any rate, if you have more than just a few code chunks, you should
do your work in master.Rnw and produce master.tex from that using
either sweave() or knitr()

-M

On 4/4/2014 7:10 PM, Axel Urbiz wrote:
> Hi,
>
> I'm writing a thesis in Latex (say master.tex). I'd like to include R
> code/results from an .Rwd file. I've naively tried:
>
> 1) Add ONLY the code below in Rcode.Rnw file:
>
> \section{Exploratory data analysis}
> <<eval=TRUE, echo=FALSE>>=
> library(ggplot2)
> data(diamonds)
> head(diamonds)
> @
>
> 2) Then, in the master.tex file add the following line:
>
> \include{Rcode.Rnw}
>
> But of course, that didn't work.Any help would be much appreciated.
>
> Best,
> Axel.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From kate.ignatius at gmail.com  Sat Apr  5 18:49:25 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 5 Apr 2014 12:49:25 -0400
Subject: [R] Setting alternative x-axis breaks using gglpot2
Message-ID: <CAE6QMsbWPN2c1YEHHxumNcDXP4s8nJ9Z6pksHR5qjFZvB=-Ncg@mail.gmail.com>

I'm not doing a Manhattan plot, but plotting AD (coloured by DP) along
the genome:

 points <- ggplot(sam,aes(x = midpoint,y = ad, colour = dp, size = 3)) +
  geom_point() +
  scale_y_continuous(breaks=c(0,20,30,40)) +
  labs(x = "chr",y = "ad") +
  scale_colour_gradient2(high="red", mid="green")

However, instead of having the BP position along the bottom, I was
wondering whether its possible to have the chromosome instead.  Is
there an easier way to do this?

I'm also trying to reduce the size of the points on the "Manhattan"
plot but changing the size in the code does not work.

Thanks!



From kate.ignatius at gmail.com  Sat Apr  5 18:51:30 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 5 Apr 2014 12:51:30 -0400
Subject: [R] Recoding in R conditioned on a certain value.
Message-ID: <CAE6QMsb_tMLUkObgv7fKkrAfz19BbCTJgN-u3h+4Q6mdLTbLdw@mail.gmail.com>

I'm trying to work out the average of a certain value by chromosome.
I've done the following, but it doesn't seem to work:

Say, I want to find average AD for chromosome 1 only and paste the
value next to all the positions on chromosome 1:

sam$mmad[sam$chrom == '1'] <-
(sam$ad)/(colSums(sam[c(1:nrow(sam$chrom=='1'))],))

I know this is convoluted and possible wrong... but I would like to do
this for all chromosomes.

Thanks!



From thpe at simecol.de  Sat Apr  5 21:52:13 2014
From: thpe at simecol.de (Thomas Petzoldt)
Date: Sat, 05 Apr 2014 21:52:13 +0200
Subject: [R] Difficulty coding time-forced functions in deSolve
In-Reply-To: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
References: <CALcwsApHnog3ZzSM1oKBADggOkN0DDzTh=n6OMWa9gQVMKaXFA@mail.gmail.com>
Message-ID: <53405EED.2000008@simecol.de>

Hi,

does the following help you?

Thomas


require(deSolve)

SEIR <- function(t, x, p) {

   if (t < 7)
     xlag <- x
   else
     xlag <- lagvalue(t - 7)

   V <- ifelse(xlag[3]/sum(xlag) > 0.01, 0.25, 0)

   ## uncomment the following for printing some internal information
   #cat("t=", t, " -- ")
   #cat(xlag, " -- ", V, "\n")

   N <- sum(x)
   with(as.list(c(x,p)),{
     dS<-  b*N - d*S - beta*S*I/N - V*S
     dE<- -d*E+beta*S*I/N - epsilon*E - V*E
     dI<- -d*I + epsilon*E - gamma*I - mu*I - V*I
     dR<- -d*R + gamma*I + V*S + V*E + V*I
     list(c(dS, dE, dI, dR), N = unname(N), V = unname(V))
   })
}

num_years  <- 1
time_limit <- num_years*365.00

b       <- 1/(10.0*365)
d       <- b
beta    <- 0.48
epsilon <- 1/4
gamma   <- 1/4
mu      <- -log(1-0.25)*gamma
parms   <- c(b=b, d=d, beta=beta, epsilon=epsilon, gamma=gamma, mu=mu)

xstart <-c(S=999, E=0, I=1, R=0)
times   <- seq(0.0, time_limit, 1.0)

out <-  dede(xstart, times, SEIR, parms, rtol=1e-8, atol=1e-8)

plot(out)



From dwinsemius at comcast.net  Sat Apr  5 22:18:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Apr 2014 13:18:44 -0700
Subject: [R] Recoding in R conditioned on a certain value.
In-Reply-To: <CAE6QMsb_tMLUkObgv7fKkrAfz19BbCTJgN-u3h+4Q6mdLTbLdw@mail.gmail.com>
References: <CAE6QMsb_tMLUkObgv7fKkrAfz19BbCTJgN-u3h+4Q6mdLTbLdw@mail.gmail.com>
Message-ID: <D005C94F-A4D5-46EB-BB0E-54D428833684@comcast.net>


On Apr 5, 2014, at 9:51 AM, Kate Ignatius wrote:

> I'm trying to work out the average of a certain value by chromosome.
> I've done the following, but it doesn't seem to work:
> 
> Say, I want to find average AD for chromosome 1 only and paste the
> value next to all the positions on chromosome 1:
> 
> [sam$chrom == '1'] <-
> (sam$ad)/(colSums(sam[c(1:nrow(sam$chrom=='1'))],))

It "looks" wrong to me because of the mismatching lengths of the lhs and rhs but since you have not provided a test dataset that's all I will say.

The usual way to calculate a function within categorical groupings that will be "re-inserted" alongside the original dataframe is to use `ave`:

sam$mmad <- with( sam, ave(ad, chrom, FUN=mean) )


> 
> I know this is convoluted and possible wrong... but I would like to do
> this for all chromosomes.
> 
> Thanks!
-- 
David Winsemius
Alameda, CA, USA



From dwinsemius at comcast.net  Sun Apr  6 03:02:04 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Apr 2014 18:02:04 -0700
Subject: [R] Multic for windows 7 and Ubuntu
In-Reply-To: <4EB41664F8279A4CA870A740E038CFEA4A7B319F80@MEDEXMB05.ad.med.miami.edu>
References: <4EB41664F8279A4CA870A740E038CFEA4A7B319F80@MEDEXMB05.ad.med.miami.edu>
Message-ID: <A0F31970-2F55-4DA0-BB4D-D03F76DB7276@comcast.net>


On Apr 5, 2014, at 1:50 AM, Srinivasan, Sathish K wrote:

> Hi all,
> Does anyone have issues installing multic package (http://cran.r-project.org/web/packages/multic/index.html) on ubuntu.

After doing a search on rhelp and r-sig-debian yours seems to be the first. Shouldn't you be providing much more detail regarding your current setup and versions of R and compilers, methods you are using, and the errors you are getting? Review the Posting Guide for a checklist. (And : You are mentioning both Windows7 and Linux distro which adds to the ambiguity and lack of clarity.). The README says the package needs compilation and provided details about how to go about that and who to contact with specific requests for information about your setup:

http://cran.r-project.org/web/packages/multic/README

> Also, there is no active support for windows binary version.

Yes? The message linked to is a generic CRAN message. What is the point of mentioning this?

> Could any one please help me install multic package on ubuntu 12.04, 64 bit system running with R 2.14.2 version.

I'm not a Linux user so probably am speaking out of place and only doing so because it is the weekend and I've noticed that the traffic is slow on the mailing list on weekends. I believe Ubuntu is a fork of Debian so you may want to pay particular attention to mentions of Debian specific instructions in the links below. Many of the questions I have seen on R help from ubuntu users who have difficulties with installing packages get resolved by re-installing R using the development version of R. I have seen the use of r-base-dev as a target.

http://cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-other-programs-under-a-Unix_002dalike

http://cran.r-project.org/doc/manuals/R-admin.html#Installing-R-under-Unix_002dalikes

There is also a Debian R mailing list and the archives are at markmail (although I suspect those are not he official ones.)

http://markmail.org/search/+list:org%2Er-project%2Er-sig-debian


> 
> Thanks
> Sathish
> 
Please ... read.
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--  

David Winsemius
Alameda, CA, USA



From smartpink111 at yahoo.com  Sun Apr  6 03:15:26 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 5 Apr 2014 18:15:26 -0700 (PDT)
Subject: [R] plotting several columns of matrix in one graph
In-Reply-To: <1396493734.17599.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1396478461.5202.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1396493734.17599.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1396746926.14674.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,

Your statement is not clear:
"that does not give me a vector with several elements but just one"

library(xts)
library(xtsExtra)
vec1 <- seq(as.Date("2002-01-01"), as.Date("2009-12-31"),by="1 day") 

length(vec1)
#[1] 2922 

head(vec1) 

#[1] "2002-01-01" "2002-01-02" "2002-01-03" "2002-01-04" "2002-01-05"
[6] "2002-01-06" 

set.seed(532)

mat1 <- matrix(cumsum(rnorm(length(vec1)*5)),ncol=5, dimnames=list(NULL,LETTERS[1:5]))
plot(as.xts(mat1,order.by=vec1),major.format="%Y",screens=1, main="Time series plot", auto.legend=TRUE,auto.grid=FALSE,col=5:1)

#I am attaching the pdf generated by the above command.

A.K.





hi, thanks for your answer. when I run this: vec1 <- seq(as.Date("2002-01-01"), as.Date("2009-12-31"),by="1 day") that does not give me a vector with several elements but just one. I tried several of your proposed methods, but to be honest nothing really worked out as it should including titles, colour etc. Not I tried to use matplot as proposed but the plots I get are really strange, the code is the following: x <- Data_Prices[,"Date"]
y<- cbind(Data_Used[,"Column2"],Data_Used[,"Column3"],Data_Used[,"Column4"] ) matlines (x, y, type = "l", lty = 1:2, lwd = 1, pch = NULL, col = 1:2) In the end, I Need a plot with the Dates (x) on the xaxis and 3 lines In Addition, I would like to manipulate colours of the lines, legend etc. 


On Wednesday, April 2, 2014 10:55 PM, arun <smartpink111 at yahoo.com> wrote:
HI,
It is better to show a reproducible example using ?dput().? May be this helps:
#vector

vec1 <- seq(as.Date("2002-01-01"), as.Date("2009-12-31"),by="1 day")
#Assuming that length of the vector is the same as ?nrow of matrix.

set.seed(532)
mat1 <- matrix(cumsum(rnorm(length(vec1)*5)),ncol=5, dimnames=list(NULL,LETTERS[1:5]))

library(xts) 

library(xtsExtra)
plot(as.xts(mat1,order.by=vec1),major.format="%Y",screens=1, main="Time series plot", auto.legend=TRUE,auto.grid=FALSE,col=5:1)

You should also check ?legend()

A.K.







thank you so much. it tried the 2nd way and it is working perfectly. could you also tell me how I can select a vector which is then used for the x axis? let's say I want some Dates 2002 to 2009, currently I have a vector called date which contains of every single day from 2002 to 2009, is there a way to get this on the x axis (just the year)? in Addition, is there some command to add a legend, titles, Change Color etc? From what I find on the Internet, I just don't understand how that is working. thanks again for the help! 



On Wednesday, April 2, 2014 6:41 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
May be this helps:
library(xts) 


library(xtsExtra)
data(sample_matrix)
plot(as.xts(sample_matrix),screens=1)
#or
library(zoo)
plot(as.zoo(sample_matrix), plot.type="single",col=1:ncol(sample_matrix))

You may also check ?matplot

A.K.


Hi everyone, I have started using R and although I am used to some other languages, I am struggling doing a plot that contains several lines which each correspond to a column of the Matrix which all my data. I tried to google it but unfortunately, it haven't found anything which helped me and also the description didn't really give me a hint what to do. Let's say I have Matrix calles Data_Set which consists of 6 columns and let's say 100 rows. in the first column, I have the date, which is also the x-axis of my plot. The next five column contain the time series, for each of them I want I line drawn in the plot. I have installed the lattice package and I tried several things using the xyplot command, but it didn't work. thanks so much for your help.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plotseveralcolumns.pdf
Type: application/pdf
Size: 99164 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140405/b9d7f2d2/attachment-0002.pdf>

From qkou at umail.iu.edu  Sun Apr  6 03:23:16 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Sat, 5 Apr 2014 21:23:16 -0400
Subject: [R] Multic for windows 7 and Ubuntu
In-Reply-To: <A0F31970-2F55-4DA0-BB4D-D03F76DB7276@comcast.net>
References: <4EB41664F8279A4CA870A740E038CFEA4A7B319F80@MEDEXMB05.ad.med.miami.edu>
	<A0F31970-2F55-4DA0-BB4D-D03F76DB7276@comcast.net>
Message-ID: <CAJ_LAMCuqCahWudCOcaqp8msHGFYmiuxsoLcTYbmg=8pUzjQ8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140405/9cd79906/attachment-0001.pl>

From smartpink111 at yahoo.com  Sun Apr  6 08:14:40 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 5 Apr 2014 23:14:40 -0700 (PDT)
Subject: [R] Error Message using xyplot of lattice
Message-ID: <1396764880.77673.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You didn't provide a reproducible example.? If your dataset is something like this:
set.seed(495)
DataSeries <- data.frame(Date=seq(as.Date("2001-01-01"),by="1 day", length.out=20), A= sample(10,20,replace=TRUE), B= rnorm(20))


###Using your codes:

Matrix_New1 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"A"]),colnames(DataSeries)[2])

Matrix_New2 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"B"]),colnames(DataSeries)[3])

str(Matrix_New1)
#List of 60
str(Matrix_New2) 

#List of 60 

Matrix_Complete<- rbind(Matrix_New1,Matrix_New2)
str(Matrix_Complete)
#List of 120
Col_Names_MC<-c("X","Y", "Z")
colnames(Matrix_Complete)<-Col_Names_MC 

library(lattice) 

Plot_AB<-xyplot(Y~ X, data =Matrix_Complete, type =c("l"), groups=Z, as.table=TRUE, main="Development over time")
#Error in eval(expr, envir, enclos) : object 'Z' not found 

#You could try:
library(reshape2)
?DataSeriesM <- setNames(melt(DataSeries,id.var="Date"),LETTERS[c(24,26,25)])
 xyplot(Y~X,data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time")
?#for a numeric X axis
 xyplot(Y~as.numeric(X),data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time") 
# with legends
 xyplot(Y~as.numeric(X),xlab="X",data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time",auto.key=list(x=.85, y=.95, border=TRUE,lines=TRUE)) 


Hope it helps.

A.K.


Hi everbody, I have the following error message occuring when I run my code:
"Error in eval(expr, envir, enclos) : object 'Series' not found" The code I am using is the following: Matrix_New1 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"A"]),colnames(DataSeries)[2] )
Matrix_New2 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"B"]),colnames(DataSeries)[3] ) #whereas first and second columns should be numbers, third column is "A" and "B" respectively Matrix_Complete<- rbind(Matrix_New1,Matrix_New2) Col_Names_MC<-c("X","Y", "Z")
colnames(Matrix_Complete)<-Col_Names_MC Plot_AB<-xyplot(Y~ X, data =Matrix_Complete, type =c("l"), groups=Z, as.table=TRUE, main="Development over time") print(Plot_AB) Can you explain me why this way of creating a plot is not working and what I Need to Change in order to be able to plot it? 




From ajdamico at gmail.com  Sun Apr  6 11:36:59 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 6 Apr 2014 05:36:59 -0400
Subject: [R] Survey
In-Reply-To: <CAJ55+dKcZaEcdBoOjYHe00_To8njJ-dzQCfeUiQN-nKdh5_vNA@mail.gmail.com>
References: <CAKSaaF=+VT4uSwsa02XdFZ9c6eAN2e-1cyDE+_nrDSSZtummLA@mail.gmail.com>
	<CAJ55+dKcZaEcdBoOjYHe00_To8njJ-dzQCfeUiQN-nKdh5_vNA@mail.gmail.com>
Message-ID: <CAOwvMDxfwoCNYDF388ZVWy1j6MR6Xc8YMKJqTvK-XkHuPWPHdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/4c0e471a/attachment-0001.pl>

From dmcp at webmail.co.za  Sun Apr  6 12:18:53 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Sun, 06 Apr 2014 12:18:53 +0200
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
In-Reply-To: <C67C1881-1105-4C40-B2A3-EA9FFE10C4C4@comcast.net>
References: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
	<533EE3C2.8060808@gmail.com>,
	<C67C1881-1105-4C40-B2A3-EA9FFE10C4C4@comcast.net>
Message-ID: <04ca3991741eafcd7fb2c1025c9a0186@www.webmail.co.za>

I _do_ see this error - on R 3.0.3 / Win XP
however, not on R 2.11.1 / Linux.
(Same hardware, 2 x OS, 2 x R versions)

Maybe it's peculiar to to 'doze...

datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"),
to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
levels(as.factor(strftime(datetimesequenz, format="%Y")))
[1] "1960" "1961" "1962" "1963" "1964" "1965" "1966" "1967" "1968" "1969"
"1970" "1971" "1972"
 [14] "1973" "1974" ...
 ...
[183] "2154" "2155" "2157" "2158" "2159" "2160" "2161" "2162" "2167"

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
[5] LC_TIME=English_Australia.1252    

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils    
methods   base     

other attached packages:
[1] svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.2.1    Hmisc_3.12-2   
Formula_1.1-1  
[6] survival_2.37-4

loaded via a namespace (and not attached):
[1] cluster_1.14.4  fortunes_1.5-0  grid_3.0.2      lattice_0.20-23
rpart_4.1-3    
[6] svMisc_0.9-69   tools_3.0.2  


Cheers,
D.

On Fri, 4 Apr 2014 14:19:09 -0700 David Winsemius <dwinsemius at comcast.net>
wrote

> On Apr 4, 2014, at 9:54 AM, Duncan Murdoch wrote:
> 
> > On 04/04/2014 10:55 AM, Winkler, Matthias wrote:
> >> Dear R-users,
> >> 
> >> I'm working on datasets which contain data from the years 1960 to 2100
..
> >> I also produced a date/time-sequence in R, which showed the same mistakes
> >> (see example below). The mistakes occur at the same dates like in my
> >> datasets. It's always at the end of march. 
> >> > datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"),
> >> > to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
> >> > levels(as.factor(strftime(datetimesequenz, format="%Y"))) >>   [1]
> >> > "1960" "1961" "1962" ...
> >> [181] "2152" "2153" "2154" "2156" "2157" "2158" "2159" "2160" "2161"
> >> "2166" 
> >> Has anybody experienced the same problem and knows a workaround?
> >> 
> >> I'm using R 3.0.1 under Windows 7 64bit. I also tried this with R 3.0.3,
> >> it showed the same problem. Thank you for your help!
> > 
> > I don't see this in 3.1.0 beta.  Do you?
> 
> I'm not seeing it on a Mac in 3.0.2 either.
> 
> > max(datetimesequenz)
> [1] "2100-01-01 PST"
> > length(datetimesequenz)
> [1] 1227241
> 
> > 
> > Duncan Murdoch
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Fight Crime And Corruption! http://www.anc.org.za/2014/manifesto/



From phil at pricom.com.au  Sun Apr  6 14:03:38 2014
From: phil at pricom.com.au (Philip Rhoades)
Date: Sun, 6 Apr 2014 22:03:38 +1000
Subject: [R] GGPLOT Question
Message-ID: <221ade1a793af12f4843c4381d5b8a45@localhost>

People,

I have this script:

library(ggplot2)

df <- read.table(text = " id min max
  Sp1 8.5 13.2
  Sp2 11.7 14.5
  Sp3 14.7 17.7 ", header=TRUE)

ggplot(df) +
  geom_crossbar(aes(ymin = min, ymax = max, x = id, y = min),
  fill = "blue", fatten = 0)

- is there some way to get geom_crossbar to print horizontally? - I 
couldn't find it . . and there doesn't seem to be a horizontal 
equivalent?

Thanks,

Phil.
-- 
Philip Rhoades

GPO Box 3411
Sydney NSW	2001
Australia
E-mail:  phil at pricom.com.au



From ssefick at gmail.com  Sun Apr  6 14:09:35 2014
From: ssefick at gmail.com (stephen sefick)
Date: Sun, 6 Apr 2014 07:09:35 -0500
Subject: [R] GGPLOT Question
In-Reply-To: <221ade1a793af12f4843c4381d5b8a45@localhost>
References: <221ade1a793af12f4843c4381d5b8a45@localhost>
Message-ID: <CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/ce0e488e/attachment-0001.pl>

From phil at pricom.com.au  Sun Apr  6 14:23:34 2014
From: phil at pricom.com.au (Philip Rhoades)
Date: Sun, 06 Apr 2014 22:23:34 +1000
Subject: [R] GGPLOT Question
In-Reply-To: <CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>
References: <221ade1a793af12f4843c4381d5b8a45@localhost>
	<CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>
Message-ID: <a4689bc1ccfe1056096e52e2f7cdb591@localhost>

Stephen,


On 2014-04-06 22:09, stephen sefick wrote:
> add +coord_flip() at the end. Does that do it?


Wow! - that was a fast response! - yes that works - thanks a lot!

Regards,

Phil.


> On Sun, Apr 6, 2014 at 7:03 AM, Philip Rhoades <phil at pricom.com.au> 
> wrote:
> 
>> People,
>> 
>> I have this script:
>> 
>> library(ggplot2)
>> 
>> df <- read.table(text = " id min max
>>  Sp1 8.5 13.2
>>  Sp2 11.7 14.5
>>  Sp3 14.7 17.7 ", header=TRUE)
>> 
>> ggplot(df) +
>>  geom_crossbar(aes(ymin = min, ymax = max, x = id, y = min),
>>  fill = "blue", fatten = 0)
>> 
>> - is there some way to get geom_crossbar to print horizontally? - I
>> couldn't find it . . and there doesn't seem to be a horizontal 
>> equivalent?
>> 
>> Thanks,
>> 
>> Phil.
>> --
>> Philip Rhoades
>> 
>> GPO Box 3411
>> Sydney NSW      2001
>> Australia
>> E-mail:  phil at pricom.com.au
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
> 
> Let's not spend our time and resources thinking about things that are 
> so
> little or so large that all they really do for us is puff us up and 
> make us
> feel like gods.  We are mammals, and have not exhausted the annoying 
> little
> problems of being mammals.
> 
>                                 -K. Mullis
> 
> "A big computer, a complex algorithm and a long time does not equal
> science."
> 
>                               -Robert Gentleman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Philip Rhoades

GPO Box 3411
Sydney NSW	2001
Australia
E-mail:  phil at pricom.com.au



From phil at pricom.com.au  Sun Apr  6 14:31:11 2014
From: phil at pricom.com.au (Philip Rhoades)
Date: Sun, 06 Apr 2014 22:31:11 +1000
Subject: [R] GGPLOT Question - #2
In-Reply-To: <a4689bc1ccfe1056096e52e2f7cdb591@localhost>
References: <221ade1a793af12f4843c4381d5b8a45@localhost>
	<CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>
	<a4689bc1ccfe1056096e52e2f7cdb591@localhost>
Message-ID: <bc9238b360bbefa1cc15a152a9fe68a1@localhost>

People,

OK, the last two bits of the puzzle - can I colour the bars 
independently and change the scale from linear to logarithmic?

Thanks,

Phil.


On 2014-04-06 22:23, Philip Rhoades wrote:
> Stephen,
> 
> 
> On 2014-04-06 22:09, stephen sefick wrote:
>> add +coord_flip() at the end. Does that do it?
> 
> 
> Wow! - that was a fast response! - yes that works - thanks a lot!
> 
> Regards,
> 
> Phil.
> 
> 
>> On Sun, Apr 6, 2014 at 7:03 AM, Philip Rhoades <phil at pricom.com.au> 
>> wrote:
>> 
>>> People,
>>> 
>>> I have this script:
>>> 
>>> library(ggplot2)
>>> 
>>> df <- read.table(text = " id min max
>>>  Sp1 8.5 13.2
>>>  Sp2 11.7 14.5
>>>  Sp3 14.7 17.7 ", header=TRUE)
>>> 
>>> ggplot(df) +
>>>  geom_crossbar(aes(ymin = min, ymax = max, x = id, y = min),
>>>  fill = "blue", fatten = 0)
>>> 
>>> - is there some way to get geom_crossbar to print horizontally? - I
>>> couldn't find it . . and there doesn't seem to be a horizontal 
>>> equivalent?
>>> 
>>> Thanks,
>>> 
>>> Phil.
>>> --
>>> Philip Rhoades
>>> 
>>> GPO Box 3411
>>> Sydney NSW      2001
>>> Australia
>>> E-mail:  phil at pricom.com.au
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>> 
>> Let's not spend our time and resources thinking about things that are 
>> so
>> little or so large that all they really do for us is puff us up and 
>> make us
>> feel like gods.  We are mammals, and have not exhausted the annoying 
>> little
>> problems of being mammals.
>> 
>>                                 -K. Mullis
>> 
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>> 
>>                               -Robert Gentleman
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Philip Rhoades

GPO Box 3411
Sydney NSW	2001
Australia
E-mail:  phil at pricom.com.au



From nicomet80 at gmail.com  Sun Apr  6 16:23:56 2014
From: nicomet80 at gmail.com (Nico Met)
Date: Sun, 6 Apr 2014 15:23:56 +0100
Subject: [R] Column value comparison and colouring
Message-ID: <CAMMD=S6Ub5BnzATQ5b0Q4TfaS4NzTC5GAexW+Cr8NCEqma+C-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/8210ff56/attachment-0001.pl>

From marc_grt at yahoo.fr  Sun Apr  6 16:26:12 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 06 Apr 2014 16:26:12 +0200
Subject: [R] Any solution to have RnetCDF, ncdf or ncdf4 in R 3.1 ?
Message-ID: <53416404.80004@yahoo.fr>

I just have installed the last RC of R 3.1. All is ok except for 3 
packages that I was not able to compile and they do not exist as 
precompiled package for MacOSX (Marverick):

These packages are RnetCDF, ncdf or ncdf4. For all, I get error when I 
try to install them:
install.packages("RNetCDF", type="source")
....
checking for nc_create in -lnetcdf... no
configure: error: netcdf library not found
ERROR: configuration failed for package ?RNetCDF?
* removing 
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/RNetCDF?

install.packages("ncdf", type="source")
....
configure: error: netcdf header netcdf.h not found
ERROR: configuration failed for package ?ncdf?
* removing 
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/ncdf?
Warning in install.packages :
installation of package ?ncdf? had non-zero exit status

install.packages("ncdf4", type="source")
....
ERROR: configuration failed for package ?ncdf4?
* removing 
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/ncdf4?
Warning in install.packages :
installation of package ?ncdf4? had non-zero exit status

Sincerely,

Marc Girondot



From gunter.berton at gene.com  Sun Apr  6 16:40:40 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 6 Apr 2014 07:40:40 -0700
Subject: [R] Column value comparison and colouring
In-Reply-To: <CAMMD=S6Ub5BnzATQ5b0Q4TfaS4NzTC5GAexW+Cr8NCEqma+C-w@mail.gmail.com>
References: <CAMMD=S6Ub5BnzATQ5b0Q4TfaS4NzTC5GAexW+Cr8NCEqma+C-w@mail.gmail.com>
Message-ID: <CACk-te28n3CBMYBUedoJR6RUhVOYrCEkgpvBmmv6rcvN3ON7KQ@mail.gmail.com>

Post in plain text, not HTML.

I would suggest that R is not Excel, and that you do not (shudder)
treat it as such. Learn R and use it sensibly.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sun, Apr 6, 2014 at 7:23 AM, Nico Met <nicomet80 at gmail.com> wrote:
> Dear all,
>
> I have a big matrix,  where I want to compare, one element of a vector with
> many others and clear them.
>
> For example:
>
> In column sil compare elements with other columns (0.734)>-1.0770 in 3rd
> column, so, color them bold else color them bold red
> For example:
>
>> dput(test)
> structure(list(Class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L), sil = c(0.734,
> 0.734, 0.734, 0.734, 0.734, -0.03, -0.03, -0.03), M201.1637T.1 =
> c(-1.077019059,
> -1.025923945, -2.025907674, -1.223001413, -1.547348898, -0.376842603,
> -1.33495095, -0.486811653), M203.1794T.1 = c(-0.884899777, -0.878305283,
> -1.910526051, -1.446826543, -1.950515819, -0.192865129, -1.669691644,
> -0.636095942), M205.1950T.1 = c(-1.307163965, -1.022407192, -2.050283307,
> -1.508604131, -1.710170605, -0.197410826, -1.547129558, -0.780189201
> ), M207.2107T.1 = c(-1.378614081, -0.950293267, -1.714837198,
> -1.827195011, -1.629677288, -0.064343778, -1.598304259, -0.502002575
> )), .Names = c("Class", "sil", "M201.1637T.1", "M203.1794T.1",
> "M205.1950T.1", "M207.2107T.1"), class = "data.frame", row.names =
> c("500002T_D06_19_42",
> "500030X_B03_19_15", "500059R_G09_19_81", "500061V_H02_13_86",
> "500078W_D10_6_46", "500082M_D05_18_41", "500105S_B09_15_21",
> "500120W_B04_19_16")
>
> Thanks in advance
>
> Nico
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From kridox at ymail.com  Sun Apr  6 16:45:03 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Sun, 6 Apr 2014 23:45:03 +0900
Subject: [R] Any solution to have RnetCDF, ncdf or ncdf4 in R 3.1 ?
In-Reply-To: <53416404.80004@yahoo.fr>
References: <53416404.80004@yahoo.fr>
Message-ID: <CAAcyNCxhgUVegXN+of_Ao9aMEQw7cGg7SGLXLQ0zm3WiaztsQw@mail.gmail.com>

Hello,

Do you have NetCDF library correctly installed (with headers)?

Regards,
Pascal

On Sun, Apr 6, 2014 at 11:26 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> I just have installed the last RC of R 3.1. All is ok except for 3 packages
> that I was not able to compile and they do not exist as precompiled package
> for MacOSX (Marverick):
>
> These packages are RnetCDF, ncdf or ncdf4. For all, I get error when I try
> to install them:
> install.packages("RNetCDF", type="source")
> ....
> checking for nc_create in -lnetcdf... no
> configure: error: netcdf library not found
> ERROR: configuration failed for package ?RNetCDF?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/RNetCDF?
>
> install.packages("ncdf", type="source")
> ....
> configure: error: netcdf header netcdf.h not found
> ERROR: configuration failed for package ?ncdf?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/ncdf?
> Warning in install.packages :
> installation of package ?ncdf? had non-zero exit status
>
> install.packages("ncdf4", type="source")
> ....
> ERROR: configuration failed for package ?ncdf4?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/ncdf4?
> Warning in install.packages :
> installation of package ?ncdf4? had non-zero exit status
>
> Sincerely,
>
> Marc Girondot
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From dpierce at ucsd.edu  Sun Apr  6 16:47:41 2014
From: dpierce at ucsd.edu (David W. Pierce)
Date: Sun, 6 Apr 2014 07:47:41 -0700
Subject: [R] Any solution to have RnetCDF, ncdf or ncdf4 in R 3.1 ?
In-Reply-To: <53416404.80004@yahoo.fr>
References: <53416404.80004@yahoo.fr>
Message-ID: <CAL+Zad-069tpdYf9nRJncR15C-SzbSS_UHj2+09bn42cPZ8MtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/bbe754ce/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Sun Apr  6 17:26:19 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 06 Apr 2014 08:26:19 -0700
Subject: [R] Column value comparison and colouring
In-Reply-To: <CAMMD=S6Ub5BnzATQ5b0Q4TfaS4NzTC5GAexW+Cr8NCEqma+C-w@mail.gmail.com>
References: <CAMMD=S6Ub5BnzATQ5b0Q4TfaS4NzTC5GAexW+Cr8NCEqma+C-w@mail.gmail.com>
Message-ID: <6779e56f-eaf6-454d-82b3-66213381fd57@email.android.com>

Your question confuses me. Perhaps you are still thinking as though this were Excel?

You refer to "a big matrix", but your dput (thank you for that) is actually a data frame. Data frames are a list of columns, each of which can have a different type.

"Clear them"? I think set them to NA. You later talk about coloring and formatting... are you printing the matrix using Markdown or LaTeX? You cannot color data directly in R, only upon output. Are you plotting using a heatmap?

You also mention comparing one column with multiple other columns. Regardless if this were Excel or not, that would be unclear. Do you want to compare sil with each column separately and create a whole new set of columns containing color names, or compare to the minimum of all columns and make a single column of color names for sil?

I think you need to clarify your intent a bit more before I can help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 6, 2014 7:23:56 AM PDT, Nico Met <nicomet80 at gmail.com> wrote:
>Dear all,
>
>I have a big matrix,  where I want to compare, one element of a vector
>with
>many others and clear them.
>
>For example:
>
>In column sil compare elements with other columns (0.734)>-1.0770 in
>3rd
>column, so, color them bold else color them bold red
>For example:
>
>> dput(test)
>structure(list(Class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L), sil =
>c(0.734,
>0.734, 0.734, 0.734, 0.734, -0.03, -0.03, -0.03), M201.1637T.1 =
>c(-1.077019059,
>-1.025923945, -2.025907674, -1.223001413, -1.547348898, -0.376842603,
>-1.33495095, -0.486811653), M203.1794T.1 = c(-0.884899777,
>-0.878305283,
>-1.910526051, -1.446826543, -1.950515819, -0.192865129, -1.669691644,
>-0.636095942), M205.1950T.1 = c(-1.307163965, -1.022407192,
>-2.050283307,
>-1.508604131, -1.710170605, -0.197410826, -1.547129558, -0.780189201
>), M207.2107T.1 = c(-1.378614081, -0.950293267, -1.714837198,
>-1.827195011, -1.629677288, -0.064343778, -1.598304259, -0.502002575
>)), .Names = c("Class", "sil", "M201.1637T.1", "M203.1794T.1",
>"M205.1950T.1", "M207.2107T.1"), class = "data.frame", row.names =
>c("500002T_D06_19_42",
>"500030X_B03_19_15", "500059R_G09_19_81", "500061V_H02_13_86",
>"500078W_D10_6_46", "500082M_D05_18_41", "500105S_B09_15_21",
>"500120W_B04_19_16")
>
>Thanks in advance
>
>Nico
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sun Apr  6 19:06:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Apr 2014 10:06:13 -0700
Subject: [R] Survey
In-Reply-To: <CAOwvMDxfwoCNYDF388ZVWy1j6MR6Xc8YMKJqTvK-XkHuPWPHdA@mail.gmail.com>
References: <CAKSaaF=+VT4uSwsa02XdFZ9c6eAN2e-1cyDE+_nrDSSZtummLA@mail.gmail.com>
	<CAJ55+dKcZaEcdBoOjYHe00_To8njJ-dzQCfeUiQN-nKdh5_vNA@mail.gmail.com>
	<CAOwvMDxfwoCNYDF388ZVWy1j6MR6Xc8YMKJqTvK-XkHuPWPHdA@mail.gmail.com>
Message-ID: <7BB28789-CC3C-4E5C-BC70-07E03C67DDCC@comcast.net>


On Apr 6, 2014, at 2:36 AM, Anthony Damico wrote:

> hi leandro, in case you're already familiar with ibge's pnad, you  
> might
> find these examples useful--
>
> http://www.asdfree.com/search/label/pesquisa%20nacional%20por%20amostra%20de%20domicilios%20%28pnad%29
>
> https://github.com/ajdamico/usgsd/tree/master/Pesquisa%20Nacional%20por%20Amostra%20de%20Domicilios
>
> --they construct and analyze the sqlite-backed survey design that dr.
> lumley is referring to

Thank you for this and all of your other work aimed at improving  
access to governmental data resource. The script for importation of  
the SEER text data ran flawlessly.

The link at the bottom of the page in the first link to Lumley's old  
page on database backed svy objects at UW is now at an r-forge hosted  
page:

http://r-survey.r-forge.r-project.org/survey/svy-dbi.html

-- 

David.
>
>
>
> On Wed, Apr 2, 2014 at 6:58 PM, Thomas Lumley <tlumley at uw.edu> wrote:
>
>> On Thu, Apr 3, 2014 at 2:37 AM, Leandro Marino <
>> leandromarino at leandromarino.com.br> wrote:
>>
>>> Dear R-Users,
>>>
>>> I was using survey for the past years and now I am experiencing some
>>> problems with scripts that was working in the past.
>>>
>>> We are working with big data bases so I can't put all variables  
>>> that I
>> will
>>> use in the svydesign.
>>>
>>
>> This was never supposed to work.
>>
>> The variables shouldn't take up any more room in the survey design  
>> object
>> than they do anywhere else, but in any case the right solution when  
>> you
>> have enough memory for the variables in a given analysis but not  
>> for all
>> the variables in your dataset is to use the database-backed designs  
>> and put
>> the data in something like SQLite.
>>
>>  -thomas
>>
>> --
>> Thomas Lumley
>> Professor of Biostatistics
>> University of Auckland
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA



From rguy at 123mail.org  Sun Apr  6 16:00:05 2014
From: rguy at 123mail.org (Rguy)
Date: Sun, 6 Apr 2014 15:00:05 +0100
Subject: [R] identical applied to data frames
Message-ID: <CAEorq2MMg0xACg8Nxb7f4aBbMG3XFty+r4JxovQvCavJ-WmO=g@mail.gmail.com>

I have two data frames that I believe are identical, yet checking them with
identical() fails.

Each data frame has two columns named 'pk' and 'newv_f13__bool'. As shown
below, the columns of the data frames are identical, according to the
identical() function, yet the data frames themselves are not. How can this
be?

Browse[1]> identical(shft$pk, shft_mat$pk)
[1] TRUE
Browse[1]> identical(shft$newv_f13__bool, shft_mat$newv_f13__bool)
[1] TRUE
Browse[1]> identical(shft, shft_mat)
[1] FALSE

I have attached a file in which the two data frames are saved (using the
save() function).

From jamilnaser79 at gmail.com  Sun Apr  6 12:21:25 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Sun, 6 Apr 2014 11:21:25 +0100
Subject: [R] skipping an error message
Message-ID: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/32942fdb/attachment-0001.pl>

From christianvanbrauner at gmail.com  Sun Apr  6 12:29:47 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Sun, 6 Apr 2014 12:29:47 +0200
Subject: [R] Question: Do I need to set refit=FALSE when testing for random
 effects with anova()?
Message-ID: <CALNVzyBfMvZADP4=FGRWs5uizwiyf=sRRZ=uqtAojZmWsTg9bw@mail.gmail.com>

Hello,

I am currently testing whether I should include certain random effects
in my lmer model or not. I use the anova function for that. My
procedure so far is to fit the model with a function call to lmer()
with REML=TRUE (the default option). Then I call anova() on the two
models where one of them does include the random effect to be tested
and the other one does not. However, it is well known that the anova()
function refits the models with ML (new versions also output a warning
that they do so). But in the new version of anova() you can prevent
anova() from doing so by setting the option refit=FALSE. In order to
test for random effects should I set refit=FALSE in my call to anova()
or not? If I do set refit=FALSE the p-values tend to be lower.
(Additional question: Are the p-values calculated by anova()
anti-conservative when I set refit=FALSE?)

Thanks for any help



From thanoon.younis80 at gmail.com  Sun Apr  6 14:26:10 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sun, 6 Apr 2014 15:26:10 +0300
Subject: [R] structural equation models in R
Message-ID: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/75633db8/attachment-0001.pl>

From phil at pricom.com.au  Sun Apr  6 17:38:22 2014
From: phil at pricom.com.au (Philip Rhoades)
Date: Mon, 07 Apr 2014 01:38:22 +1000
Subject: [R] GGPLOT Question - #2
In-Reply-To: <bc9238b360bbefa1cc15a152a9fe68a1@localhost>
References: <221ade1a793af12f4843c4381d5b8a45@localhost>
	<CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>
	<a4689bc1ccfe1056096e52e2f7cdb591@localhost>
	<bc9238b360bbefa1cc15a152a9fe68a1@localhost>
Message-ID: <771e42f513dc8f24e3397028a3d9321d@localhost>

People,


On 2014-04-06 22:31, Philip Rhoades wrote:
> People,
> 
> OK, the last two bits of the puzzle - can I colour the bars
> independently and change the scale from linear to logarithmic?


To answer my own question - the attached file works for me but I guess 
could be improved?

Thanks,

Phil.



> On 2014-04-06 22:23, Philip Rhoades wrote:
>> Stephen,
>> 
>> 
>> On 2014-04-06 22:09, stephen sefick wrote:
>>> add +coord_flip() at the end. Does that do it?
>> 
>> 
>> Wow! - that was a fast response! - yes that works - thanks a lot!
>> 
>> Regards,
>> 
>> Phil.
>> 
>> 
>>> On Sun, Apr 6, 2014 at 7:03 AM, Philip Rhoades <phil at pricom.com.au> 
>>> wrote:
>>> 
>>>> People,
>>>> 
>>>> I have this script:
>>>> 
>>>> library(ggplot2)
>>>> 
>>>> df <- read.table(text = " id min max
>>>>  Sp1 8.5 13.2
>>>>  Sp2 11.7 14.5
>>>>  Sp3 14.7 17.7 ", header=TRUE)
>>>> 
>>>> ggplot(df) +
>>>>  geom_crossbar(aes(ymin = min, ymax = max, x = id, y = min),
>>>>  fill = "blue", fatten = 0)
>>>> 
>>>> - is there some way to get geom_crossbar to print horizontally? - I
>>>> couldn't find it . . and there doesn't seem to be a horizontal 
>>>> equivalent?
>>>> 
>>>> Thanks,
>>>> 
>>>> Phil.
>>>> --
>>>> Philip Rhoades
>>>> 
>>>> GPO Box 3411
>>>> Sydney NSW      2001
>>>> Australia
>>>> E-mail:  phil at pricom.com.au
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> Stephen Sefick
>>> **************************************************
>>> Auburn University
>>> Biological Sciences
>>> 331 Funchess Hall
>>> Auburn, Alabama
>>> 36849
>>> **************************************************
>>> sas0025 at auburn.edu
>>> http://www.auburn.edu/~sas0025
>>> **************************************************
>>> 
>>> Let's not spend our time and resources thinking about things that are 
>>> so
>>> little or so large that all they really do for us is puff us up and 
>>> make us
>>> feel like gods.  We are mammals, and have not exhausted the annoying 
>>> little
>>> problems of being mammals.
>>> 
>>>                                 -K. Mullis
>>> 
>>> "A big computer, a complex algorithm and a long time does not equal
>>> science."
>>> 
>>>                               -Robert Gentleman
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Philip Rhoades

GPO Box 3411
Sydney NSW	2001
Australia
E-mail:  phil at pricom.com.au
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: TechComparison.r
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/6e256efe/attachment-0001.pl>

From dwinsemius at comcast.net  Sun Apr  6 19:13:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Apr 2014 10:13:23 -0700
Subject: [R] Fwd:  Recoding in R conditioned on a certain value.
References: <DBD3C8C8-7212-4004-ABEB-2A0C647D8905@comcast.net>
Message-ID: <5C884966-E1E8-4101-996E-BACC3279C6B0@comcast.net>


On Apr 5, 2014, at 8:37 PM, Kate Ignatius wrote:

> Thanks,
>
> I ended up using this.  I was curious how to get the mean of multiple
> columns by chrom (or Plan with the example below).  Using this data
> for example:
>
> Plan   X       mm  mm2
> 1  95 0.323000 0.400303
> 1 275 0.341818 0.400303
> 1   2 0.618000 0.400303
> 1  75 0.320000 0.400303
> 1  13 0.399000 0.400303
> 1  20 0.400000 0.400303
> 2 219 0.393000 0.353350
> 2  50 0.060000 0.353350
> 2 213 0.390000 0.353350
> 2 204 0.496100 0.353350
> 2  19 0.393000 0.353350
> 2 201 0.388000 0.353350
>
> I've tried:
>
> pp$meanmm <- with(pp, ave(pp[,3:4], Plan, FUN = mean))

People should do some 'dimensional analysis' when they get errors.  
(And they should report the text of the errors.) The length and width  
of what is specified on the LHS should be the same as what would be  
produced on the RHS of hte assignment. But that would not have been  
the first error that was encountered. You tried to pass two columns as  
the first argument to a function that expected one, and then you tried  
to assign the result to one column. This might have a better chance.

pp[ c('mean.m1' , 'mean.m2') ] <- lapply( pp[ , 3:4] , function(x)  
ave(x, pp$Plan, FUN=mean) )


 > pp
    Plan   X       mm      mm2  mean.m1  mean.m2
1     1  95 0.323000 0.400303 0.400303 0.400303
2     1 275 0.341818 0.400303 0.400303 0.400303
3     1   2 0.618000 0.400303 0.400303 0.400303
snipped

-- 
David.

>
> But that doesn't seem to work.
>
> On Sat, Apr 5, 2014 at 4:18 PM, David Winsemius <dwinsemius at comcast.net 
> > wrote:
>>
>> On Apr 5, 2014, at 9:51 AM, Kate Ignatius wrote:
>>
>>> I'm trying to work out the average of a certain value by chromosome.
>>> I've done the following, but it doesn't seem to work:
>>>
>>> Say, I want to find average AD for chromosome 1 only and paste the
>>> value next to all the positions on chromosome 1:
>>>
>>> [sam$chrom == '1'] <-
>>> (sam$ad)/(colSums(sam[c(1:nrow(sam$chrom=='1'))],))
>>
>> It "looks" wrong to me because of the mismatching lengths of the  
>> lhs and rhs but since you have not provided a test dataset that's  
>> all I will say.
>>
>> The usual way to calculate a function within categorical groupings  
>> that will be "re-inserted" alongside the original dataframe is to  
>> use `ave`:
>>
>> sam$mmad <- with( sam, ave(ad, chrom, FUN=mean) )
>>
>>
>>>
>>> I know this is convoluted and possible wrong... but I would like  
>>> to do
>>> this for all chromosomes.
>>>
>>> Thanks!
>> --
>> David Winsemius
>> Alameda, CA, USA
>>

David Winsemius, MD
Alameda, CA, USA


David Winsemius, MD
Alameda, CA, USA



From dwinsemius at comcast.net  Sun Apr  6 19:23:21 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Apr 2014 10:23:21 -0700
Subject: [R] identical applied to data frames
In-Reply-To: <CAEorq2MMg0xACg8Nxb7f4aBbMG3XFty+r4JxovQvCavJ-WmO=g@mail.gmail.com>
References: <CAEorq2MMg0xACg8Nxb7f4aBbMG3XFty+r4JxovQvCavJ-WmO=g@mail.gmail.com>
Message-ID: <02B4EFDE-BA23-4C16-8B54-4F105C70B649@comcast.net>


On Apr 6, 2014, at 7:00 AM, Rguy wrote:

> I have two data frames that I believe are identical, yet checking  
> them with
> identical() fails.
>
> Each data frame has two columns named 'pk' and 'newv_f13__bool'. As  
> shown
> below, the columns of the data frames are identical, according to the
> identical() function, yet the data frames themselves are not. How  
> can this
> be?
>
> Browse[1]> identical(shft$pk, shft_mat$pk)
> [1] TRUE
> Browse[1]> identical(shft$newv_f13__bool, shft_mat$newv_f13__bool)
> [1] TRUE
> Browse[1]> identical(shft, shft_mat)
> [1] FALSE

  It could be as simple as having a different column order:

 > df1 <- df4
 > identical(df1,df4)
[1] TRUE
 > df1[] <- df1[rev(names(df1))]
 > identical(df1,df4)
[1] FALSE

>
> I have attached a file in which the two data frames are saved (using  
> the
> save() function).

No attachment. Probably not a text file. Read the general instructions  
page more carefully.

-- 

David Winsemius, MD
Alameda, CA, USA



From patrick.coulombe at gmail.com  Sun Apr  6 20:17:32 2014
From: patrick.coulombe at gmail.com (Patrick Coulombe)
Date: Sun, 6 Apr 2014 12:17:32 -0600
Subject: [R] structural equation models in R
In-Reply-To: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
References: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
Message-ID: <CAPy1FZ7z0bHp_C5-GApCVDm_cQDn0t3UakxT2t1K+a+4Rpb69Q@mail.gmail.com>

Hi Thanoon,

Not sure how we can help when you ask such a vague, broad question.
But in any case, I would recommend using the package "lavaan" in R.
Look it up: http://lavaan.ugent.be/

Patrick

2014-04-06 6:26 GMT-06:00 thanoon younis <thanoon.younis80 at gmail.com>:
> hi
> i need your help to know how can i analysis structural equation models in R.
>
> thanks alot
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dmck at u.washington.edu  Sun Apr  6 20:50:13 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 6 Apr 2014 11:50:13 -0700
Subject: [R] structural equation models in R
In-Reply-To: <CAPy1FZ7z0bHp_C5-GApCVDm_cQDn0t3UakxT2t1K+a+4Rpb69Q@mail.gmail.com>
References: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
	<CAPy1FZ7z0bHp_C5-GApCVDm_cQDn0t3UakxT2t1K+a+4Rpb69Q@mail.gmail.com>
Message-ID: <01EE2653-3105-4049-A186-68EF2B155D54@u.washington.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/9d676417/attachment-0001.pl>

From rshepard at appl-ecosys.com  Sun Apr  6 20:54:31 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 6 Apr 2014 11:54:31 -0700 (PDT)
Subject: [R] structural equation models in R
In-Reply-To: <CAPy1FZ7z0bHp_C5-GApCVDm_cQDn0t3UakxT2t1K+a+4Rpb69Q@mail.gmail.com>
References: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
	<CAPy1FZ7z0bHp_C5-GApCVDm_cQDn0t3UakxT2t1K+a+4Rpb69Q@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1404061153381.3451@localhost>

On Sun, 6 Apr 2014, Patrick Coulombe wrote:

> Not sure how we can help when you ask such a vague, broad question. But in
> any case, I would recommend using the package "lavaan" in R. Look it up:
> http://lavaan.ugent.be/

   There's also plspm for Partial Least Squares -- Path Modeling.

Rich



From smartpink111 at yahoo.com  Sun Apr  6 21:07:24 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Apr 2014 12:07:24 -0700 (PDT)
Subject: [R] Error Message using xyplot of lattice
In-Reply-To: <1396764880.77673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1396764880.77673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1396811244.3879.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Check the output of:
datM <- melt(DataSeries,id.var="Date")
head(datM,2)# 3 columns
# Date variable value 

#1 2001-01-01 A 4
#2 2001-01-02 A 1
datM1 <- setNames(datM,LETTERS[c(24,26,25)])
library(lattice)
xyplot(Y~as.numeric(X),data=datM1,groups=Z,type="l") 


A.K.

hi, thank you for the help. doing this looks good, however I tried to adapt to code in order to be able to plot more than just 2 time series and I again get some Errors. using this: DataSeriesM <- setNames(melt(DataSeries,id.var="Date"),LETTERS[c(24,18,19,20,21,22,23,26,25)]) where DataSeries has 5000 observations of 9 variables, I get the error message: "Error in setNames(melt(DataSeries, id.var = "Date"), LETTERS[c(24, 18,  : 'names' attribute [9] must be the same length as the vector [3]" If I run this: length(LETTERS[c(24,18,19,20,21,22,23,26,25)])
length(DataSeries) I get 9 for both. I don't really understand why it is not working, is there anything you see? Using your example, I tried this: set.seed(495)
DataSeries <- data.frame(Date=seq(as.Date("2001-01-01"),by="1 day", length.out=20), A= sample(10,20,replace=TRUE), B= rnorm(20),C= rnorm(20)-1) DataSeriesM <- setNames(melt(DataSeries,id.var="Date"),LETTERS[c(24,26,25,22)]) which dives me the same error message. How do I Need to adapt this part as well as the code below to plot more than 2 lines? # with legends
xyplot(Y~as.numeric(X),xlab="X",data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time",auto.key=list(x=.85, y=.95, border=TRUE,lines=TRUE)) 


On Sunday, April 6, 2014 2:14 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
You didn't provide a reproducible example.? If your dataset is something like this:
set.seed(495)
DataSeries <- data.frame(Date=seq(as.Date("2001-01-01"),by="1 day", length.out=20), A= sample(10,20,replace=TRUE), B= rnorm(20))


###Using your codes:

Matrix_New1 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"A"]),colnames(DataSeries)[2])

Matrix_New2 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"B"]),colnames(DataSeries)[3])

str(Matrix_New1)
#List of 60
str(Matrix_New2) 

#List of 60 

Matrix_Complete<- rbind(Matrix_New1,Matrix_New2)
str(Matrix_Complete)
#List of 120
Col_Names_MC<-c("X","Y", "Z")
colnames(Matrix_Complete)<-Col_Names_MC 

library(lattice) 

Plot_AB<-xyplot(Y~ X, data =Matrix_Complete, type =c("l"), groups=Z, as.table=TRUE, main="Development over time")
#Error in eval(expr, envir, enclos) : object 'Z' not found 

#You could try:
library(reshape2)
?DataSeriesM <- setNames(melt(DataSeries,id.var="Date"),LETTERS[c(24,26,25)])
xyplot(Y~X,data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time")
?#for a numeric X axis
xyplot(Y~as.numeric(X),data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time") 
# with legends
xyplot(Y~as.numeric(X),xlab="X",data=DataSeriesM,type="l",groups=Z,as.table=TRUE,main="Development over time",auto.key=list(x=.85, y=.95, border=TRUE,lines=TRUE)) 


Hope it helps.

A.K.


Hi everbody, I have the following error message occuring when I run my code:
"Error in eval(expr, envir, enclos) : object 'Series' not found" The code I am using is the following: Matrix_New1 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"A"]),colnames(DataSeries)[2] )
Matrix_New2 <- cbind(as.list(DataSeries[,"Date"]),as.list(DataSeries[,"B"]),colnames(DataSeries)[3] ) #whereas first and second columns should be numbers, third column is "A" and "B" respectively Matrix_Complete<- rbind(Matrix_New1,Matrix_New2) Col_Names_MC<-c("X","Y", "Z")
colnames(Matrix_Complete)<-Col_Names_MC Plot_AB<-xyplot(Y~ X, data =Matrix_Complete, type =c("l"), groups=Z, as.table=TRUE, main="Development over time") print(Plot_AB) Can you explain me why this way of creating a plot is not working and what I Need to Change in order to be able to plot it? 




From kate.ignatius at gmail.com  Sun Apr  6 21:29:04 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 6 Apr 2014 15:29:04 -0400
Subject: [R] Colour of geom_hline is not correct in legend
Message-ID: <CAE6QMsaM2rnnRU=jaAcZXYomggx_8CVcb-09q_rR_xQReZUpZQ@mail.gmail.com>

I've used geom_point and geom_hline in ggplot2 and have gotten
satisfactory legends for both.  However, I have one black line and one
blue line in the figure but in the legend they are both black - how
can I correct this in the legend to be the right colors?

    mcgc <- ggplot(sam, aes(x = m,y = ad, colour = X)) +
                      geom_point(size = 0.75) +
                      scale_colour_gradient2(high="red", mid="green",
limits=c(0,1), guide = "colourbar") +
                      geom_hline(aes(yintercept = mad, linetype =
"mad"), colour = "blue", size=0.75, show_guide = TRUE) +
                      geom_hline(aes(yintercept = mmad, linetype =
"mmad"), colour = "black", size=0.75, show_guide = TRUE)  +
                      facet_wrap(~ Plan, scales = "free", ncol = 4) +
                      scale_linetype_manual(name = "Plan of Health
Care", values = c("mad" = 1, "mmad" = 1),guide = "legend")

I'm sure I've over written something here... just not sure where (am
new to ggplot)

Data:

    Plan  ad X       m  mad  mmad
    1  1 95 0.323000 0.400303 0.12
    1  2 275 0.341818 0.400303 0.12
    1  3  2 0.618000 0.400303 0.12
    1  4 75 0.320000 0.400303 0.12
    1  5 13 0.399000 0.400303 0.12
    1  6 20 0.400000 0.400303 0.12
    2  1 219 0.393000 0.353350 0.45
    2  2 50 0.060000 0.353350 0.45
    2  3 213 0.390000 0.353350 0.45
    2  4 204 0.496100 0.353350 0.45
    2  5 19 0.393000 0.353350 0.45
    2  6 201 0.388000 0.353350 0.45

Plan goes up to 40, but I've only included a snippet of data here...



From jfox at mcmaster.ca  Sun Apr  6 21:42:43 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 6 Apr 2014 15:42:43 -0400
Subject: [R] structural equation models in R
In-Reply-To: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
References: <CABLo8nFoAUgXVt=PNwNxaUOvG91zo5X+=dCqS9-crpWsKuftZg@mail.gmail.com>
Message-ID: <004501cf51d0$610d4220$2327c660$@mcmaster.ca>

Dear thanoon younis,

RSiteSearch("structural equation model", "functions") turns up a number of
relevant packages.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of thanoon younis
> Sent: Sunday, April 06, 2014 8:26 AM
> To: r-help at r-project.org
> Subject: [R] structural equation models in R
> 
> hi
> i need your help to know how can i analysis structural equation models
> in R.
> 
> thanks alot
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r.turner at auckland.ac.nz  Sun Apr  6 22:56:48 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 07 Apr 2014 08:56:48 +1200
Subject: [R] identical applied to data frames
In-Reply-To: <CAEorq2MMg0xACg8Nxb7f4aBbMG3XFty+r4JxovQvCavJ-WmO=g@mail.gmail.com>
References: <CAEorq2MMg0xACg8Nxb7f4aBbMG3XFty+r4JxovQvCavJ-WmO=g@mail.gmail.com>
Message-ID: <5341BF90.6020005@auckland.ac.nz>

On 07/04/14 02:00, Rguy wrote:
> I have two data frames that I believe are identical, yet checking them with
> identical() fails.
>
> Each data frame has two columns named 'pk' and 'newv_f13__bool'. As shown
> below, the columns of the data frames are identical, according to the
> identical() function, yet the data frames themselves are not. How can this
> be?
>
> Browse[1]> identical(shft$pk, shft_mat$pk)
> [1] TRUE
> Browse[1]> identical(shft$newv_f13__bool, shft_mat$newv_f13__bool)
> [1] TRUE
> Browse[1]> identical(shft, shft_mat)
> [1] FALSE
>
> I have attached a file in which the two data frames are saved (using the
> save() function).

Attachment did not come through.

What does all.equal() say about your two data frames?

cheers,

Rolf Turner



From yvan at dragonfly.co.nz  Mon Apr  7 00:02:14 2014
From: yvan at dragonfly.co.nz (Yvan Richard)
Date: Mon, 7 Apr 2014 10:02:14 +1200
Subject: [R] GGPLOT Question - #2
In-Reply-To: <771e42f513dc8f24e3397028a3d9321d@localhost>
References: <221ade1a793af12f4843c4381d5b8a45@localhost>
	<CADKEMqj=hDfMqMCN3CzKgRWr2T4H8ZuefmUAJcT1wyOqNEreVg@mail.gmail.com>
	<a4689bc1ccfe1056096e52e2f7cdb591@localhost>
	<bc9238b360bbefa1cc15a152a9fe68a1@localhost>
	<771e42f513dc8f24e3397028a3d9321d@localhost>
Message-ID: <CAMrYPbELywnB5b_YTPit3YpYOoSpLOyV65Jxe0g9z5ocU8_+Nw@mail.gmail.com>

Hi Phil,
You don't need multiple data frames. A single one will do. Try that.

df <- rbind(df1, df2, df3, df4, df5, df6)
df$type <- c('a','a','b','b','c','c')
ggplot() +
    geom_crossbar(data = df, aes(ymin=min, ymax=max, x=Treatment,
y=min, fill=type, fatten=0)) +
    scale_fill_manual(values=c(a='red', b='orange', c='green'), guid='none') +
    ylab( "Days" ) +
    scale_y_log10( breaks=c( 0.01, 0.1, 1.0, 10.0, 100.1, 1000.0,
10000.0, 100000.0 ), labels=c( "0.01", "0.1", "1.0", "10", "100",
"1,000", "10,000", "100,000" ) ) +
    coord_flip() +
    ggtitle( "Comparison of Medical Temperature Reduction Treatments" )


On 7 April 2014 03:38, Philip Rhoades <phil at pricom.com.au> wrote:
> People,
>
>
>
> On 2014-04-06 22:31, Philip Rhoades wrote:
>>
>> People,
>>
>> OK, the last two bits of the puzzle - can I colour the bars
>> independently and change the scale from linear to logarithmic?
>
>
>
> To answer my own question - the attached file works for me but I guess could
> be improved?
>
>
> Thanks,
>
> Phil.
>
>
>
>> On 2014-04-06 22:23, Philip Rhoades wrote:
>>>
>>> Stephen,
>>>
>>>
>>> On 2014-04-06 22:09, stephen sefick wrote:
>>>>
>>>> add +coord_flip() at the end. Does that do it?
>>>
>>>
>>>
>>> Wow! - that was a fast response! - yes that works - thanks a lot!
>>>
>>> Regards,
>>>
>>> Phil.
>>>
>>>
>>>> On Sun, Apr 6, 2014 at 7:03 AM, Philip Rhoades <phil at pricom.com.au>
>>>> wrote:
>>>>
>>>>> People,
>>>>>
>>>>> I have this script:
>>>>>
>>>>> library(ggplot2)
>>>>>
>>>>> df <- read.table(text = " id min max
>>>>>  Sp1 8.5 13.2
>>>>>  Sp2 11.7 14.5
>>>>>  Sp3 14.7 17.7 ", header=TRUE)
>>>>>
>>>>> ggplot(df) +
>>>>>  geom_crossbar(aes(ymin = min, ymax = max, x = id, y = min),
>>>>>  fill = "blue", fatten = 0)
>>>>>
>>>>> - is there some way to get geom_crossbar to print horizontally? - I
>>>>> couldn't find it . . and there doesn't seem to be a horizontal
>>>>> equivalent?
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Phil.
>>>>> --
>>>>> Philip Rhoades
>>>>>
>>>>> GPO Box 3411
>>>>> Sydney NSW      2001
>>>>> Australia
>>>>> E-mail:  phil at pricom.com.au
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Stephen Sefick
>>>> **************************************************
>>>> Auburn University
>>>> Biological Sciences
>>>> 331 Funchess Hall
>>>> Auburn, Alabama
>>>> 36849
>>>> **************************************************
>>>> sas0025 at auburn.edu
>>>> http://www.auburn.edu/~sas0025
>>>> **************************************************
>>>>
>>>> Let's not spend our time and resources thinking about things that are so
>>>> little or so large that all they really do for us is puff us up and make
>>>> us
>>>> feel like gods.  We are mammals, and have not exhausted the annoying
>>>> little
>>>> problems of being mammals.
>>>>
>>>>                                 -K. Mullis
>>>>
>>>> "A big computer, a complex algorithm and a long time does not equal
>>>> science."
>>>>
>>>>                               -Robert Gentleman
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Philip Rhoades
>
> GPO Box 3411
> Sydney NSW      2001
> Australia
> E-mail:  phil at pricom.com.au
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Yvan Richard

      DRAGONFLY Science

Physical address: Level 5, 158 Victoria St, Te Aro, Wellington
Postal address: PO Box 27535, Wellington 6141
New Zealand
Ph: 04.385.9285
web page



From kate.ignatius at gmail.com  Mon Apr  7 00:31:43 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 6 Apr 2014 18:31:43 -0400
Subject: [R] Manipulating x axis using scale_x_continuous (but a factor is
 used). Is there a work around?
Message-ID: <CAE6QMsa+mYmuwTCH4i-5Zj008Ci4EzEZS0SryBpfY6nUNE30GQ@mail.gmail.com>

My code that I've used is:

    mcgc <- ggplot(sam, aes(x = person,y = m, colour = X)) +
                  geom_point(size = 0.75) +
                  scale_colour_gradient2(high="red", mid="green",
limits=c(0,1), guide = "colourbar") +
                  geom_hline(aes(yintercept = mad, linetype = "mad"),
colour = "blue", size=0.75, show_guide = TRUE) +
                  geom_hline(aes(yintercept = mmad, linetype =
"mmad"), colour = "black", size=0.75, show_guide = TRUE)  +
                  facet_wrap(~ Plan, scales = "free", ncol = 4) +
                  scale_linetype_manual(name = "Plan of Health Care",
values = c("mad" = 1, "mmad" = 1),guide = "legend")

For this data:

Data:

    Plan  Person X       m  mad  mmad
    1  1 95 0.323000 0.400303 0.12
    1  2 275 0.341818 0.400303 0.12
    1  3  2 0.618000 0.400303 0.12
    1  4 75 0.320000 0.400303 0.12
    1  5 13 0.399000 0.400303 0.12
    1  6 20 0.400000 0.400303 0.12
    2  7 219 0.393000 0.353350 0.45
    2  8 50 0.060000 0.353350 0.45
    2  9 213 0.390000 0.353350 0.45
    2  15 204 0.496100 0.353350 0.45
    2  19 19 0.393000 0.353350 0.45
    2  24 201 0.388000 0.353350 0.45
    3  30 219 0.567 0.1254 0.89
    3  14 50 0.679 0.1254 0.89
    3  55 213 0.1234 0.1254 0.89
    3  18 204 0.6135 0.1254 0.89
    3  59 19 0.39356 0.1254 0.89
    3  101 201 0.300 0.1254 0.89

I'm trying to manipulate the x axis using the following, only because
the data can get very large and there is just way too many Persons to
fit on the x-axis and I need to reduce it so its legible:

    scale_x_continuous(breaks = c(min(person), median(person),
max(person)), labels = c(min(person), median(person), max(person)))

However, given that I had to change `person` into a factor to order
the data properly, the above code does not work.  I get the errors,
depending on how I fiddle around with the code:

    Error: Discrete value supplied to continuous scale
    Error in Summary.factor(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,  :
      min not meaningful for factors

Changing `person` to numeric does not work, as the accumulated
`person` for the entire dataset will then be on each Plan figure
panel, as opposed to the scale specific for each Plan. That is, the
x-axis for each panel (Plan) should have a scale beginning from its
lowest Person to its highest Person (ie Plan 1 should have an x-axis
that goes from 1 to 6 but Plan 3 has one that goes from 14 to 101).
Changing the Person to numeric, the x-axis for all panels starts at 1
and goes to 101.

Is there a work around for this?



From jim at bitwrit.com.au  Mon Apr  7 00:51:54 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 07 Apr 2014 08:51:54 +1000
Subject: [R] skipping an error message
In-Reply-To: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>
References: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>
Message-ID: <5341DA8A.1080602@bitwrit.com.au>

On 04/06/2014 08:21 PM, Naser Jamil wrote:
> Dear R-user,
> May I seek your suggestion on an issue. I'm fitting non-linear mixed effects
> model as a part of my large R program. But sometimes I get error messages
> from it and the code stops working. In such cases, I want to skip the
> iterations and
> want to move to the next iteration ignoring all the subsequent
> computations.
>
> The following is only that part of the code which fits the mixed effects
> model. I tried with "tryCatch" as shown below, but it's not serving my
> purpose. I guess something is wrong in my approach.
>
> ###########################################################
>
> grouped.data<-groupedData(formula = conc ~ t | subject,
> data = data.d)
> model.d<-nlme(conc~f2(dose,Theta1,Theta2,Theta3,t),
> fixed=Theta1+Theta2+Theta3~1,
> data=grouped.data,
> random=Theta1+Theta2+Theta3~1,
> start=list(fixed=ini.pkpara))
> summ<-summary(model.d) # summary of the model
>
> tryCatch(summ, error = function() next)
>
> ###########################################################
>
Hi Jamil,
I think you have to pass the expression:

nlme(conc~f2(dose,Theta1,Theta2,Theta3,t),
  fixed=Theta1+Theta2+Theta3~1,
  data=grouped.data,
  random=Theta1+Theta2+Theta3~1,
  start=list(fixed=ini.pkpara))

not the result of the expression.

Jim



From marc_grt at yahoo.fr  Mon Apr  7 01:21:59 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 07 Apr 2014 01:21:59 +0200
Subject: [R] Any solution to have RnetCDF, ncdf or ncdf4 in R 3.1 ?
In-Reply-To: <CAL+Zad-069tpdYf9nRJncR15C-SzbSS_UHj2+09bn42cPZ8MtA@mail.gmail.com>
References: <53416404.80004@yahoo.fr>
	<CAL+Zad-069tpdYf9nRJncR15C-SzbSS_UHj2+09bn42cPZ8MtA@mail.gmail.com>
Message-ID: <5341E197.1070008@yahoo.fr>

Le 06/04/2014 16:47, David W. Pierce a ?crit :
> Hi Marc,
>
> those packages are just interfaces to the netcdf library that must 
> already exist on your machine. Try installing the netcdf library 
> first, and then installing the R package.
>
> You will need the development version of the netcdf library installed 
> in order to compile the R packages. Hopefully the exact package name 
> will be obvious in the package manager on your system.
>
>
Thanks a lot for these infos.
Here are the last news for my problem of installation package in 3.1:

I have installed macport and then I have tried to install development 
version of netcdf library:
sudo port install netcdf-devel
Error: Port netcdf-devel not found

The netcdf library is available in macport but not the development one.

In the meantime, I have tried to install ncdf and ncdf4 package after 
downloading the MacosX binary versions at:
http://cran.r-project.org/bin/macosx/contrib/r-release/ncdf_1.6.6.tgz
http://cran.r-project.org/bin/macosx/contrib/r-release/ncdf4_1.10.tgz

I have installed both using the install_local() function of the package 
devtools.
Both install and run correctly.

The same procedure applied to RNetCDF 
(http://cran.r-project.org/web/packages/RNetCDF/index.html) has produced 
an error during installation.

I have installed other packages in 3.1, or directly using 
install.packages() or loading the MacosX binary and using 
install_local(). I have still a problem with rgdal 
(http://cran.r-project.org/web/packages/rgdal/index.html). Probably 
again it is a problem of library (gdal) that is not present. I will wait 
that binary library is available in CRAN.

Marc



From kristi.glover at hotmail.com  Mon Apr  7 03:07:13 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 6 Apr 2014 22:07:13 -0300
Subject: [R] simple linear plots with a loop
Message-ID: <COL130-W4477F434D9E03F07BB6C13FA680@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140406/682a06e3/attachment-0001.pl>

From dwinsemius at comcast.net  Mon Apr  7 03:17:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Apr 2014 18:17:02 -0700
Subject: [R] Any solution to have RnetCDF, ncdf or ncdf4 in R 3.1 ?
In-Reply-To: <5341E197.1070008@yahoo.fr>
References: <53416404.80004@yahoo.fr>
	<CAL+Zad-069tpdYf9nRJncR15C-SzbSS_UHj2+09bn42cPZ8MtA@mail.gmail.com>
	<5341E197.1070008@yahoo.fr>
Message-ID: <FF8E2BFB-4E97-4A32-896D-6200D3E93556@comcast.net>


On Apr 6, 2014, at 4:21 PM, Marc Girondot wrote:

> Le 06/04/2014 16:47, David W. Pierce a ?crit :
>> Hi Marc,
>>
>> those packages are just interfaces to the netcdf library that must  
>> already exist on your machine. Try installing the netcdf library  
>> first, and then installing the R package.
>>
>> You will need the development version of the netcdf library  
>> installed in order to compile the R packages. Hopefully the exact  
>> package name will be obvious in the package manager on your system.
>>
>>
> Thanks a lot for these infos.
> Here are the last news for my problem of installation package in 3.1:
>
> I have installed macport and then I have tried to install  
> development version of netcdf library:
> sudo port install netcdf-devel
> Error: Port netcdf-devel not found

Macports installs its packages in folders that are not standard and  
then R packages don't find them (at least that's my understanding of  
the reason Macports causes troubles with R packages.) You are asked  
not to use it for packages that R will be linking to. So maybe that  
error will be a boon rather than a bane. Doing a search on: [ macports  
Urbanek]  in the archive of r-sig-mac should provide further details.  
This really should have been posted there.

>
> The netcdf library is available in macport but not the development  
> one.
>
> In the meantime, I have tried to install ncdf and ncdf4 package  
> after downloading the MacosX binary versions at:
> http://cran.r-project.org/bin/macosx/contrib/r-release/ncdf_1.6.6.tgz
> http://cran.r-project.org/bin/macosx/contrib/r-release/ncdf4_1.10.tgz
>
> I have installed both using the install_local() function of the  
> package devtools.
> Both install and run correctly.
>
> The same procedure applied to RNetCDF (http://cran.r-project.org/web/packages/RNetCDF/index.html 
> ) has produced an error during installation.
>
> I have installed other packages in 3.1, or directly using  
> install.packages() or loading the MacosX binary and using  
> install_local(). I have still a problem with rgdal (http://cran.r-project.org/web/packages/rgdal/index.html 
> ). Probably again it is a problem of library (gdal) that is not  
> present. I will wait that binary library is available in CRAN.

GDAL is an external package. http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries

rgdal is the R interface package that you would use to get GDAL  
functionality.

-- 

David Winsemius, MD
Alameda, CA, USA



From SSrinivasan at med.miami.edu  Mon Apr  7 02:44:53 2014
From: SSrinivasan at med.miami.edu (Srinivasan, Sathish  K)
Date: Sun, 6 Apr 2014 20:44:53 -0400
Subject: [R] Multic for windows 7 and Ubuntu
In-Reply-To: <CAJ_LAMCuqCahWudCOcaqp8msHGFYmiuxsoLcTYbmg=8pUzjQ8g@mail.gmail.com>
References: <4EB41664F8279A4CA870A740E038CFEA4A7B319F80@MEDEXMB05.ad.med.miami.edu>
	<A0F31970-2F55-4DA0-BB4D-D03F76DB7276@comcast.net>,
	<CAJ_LAMCuqCahWudCOcaqp8msHGFYmiuxsoLcTYbmg=8pUzjQ8g@mail.gmail.com>
Message-ID: <4EB41664F8279A4CA870A740E038CFEA4A7B319F82@MEDEXMB05.ad.med.miami.edu>

Thanks  for your replies.

> After doing a search on rhelp and r-sig-debian yours seems to be the first. Shouldn't you be providing much more detail regarding your current setup and versions of R and compilers, methods you are using, and the errors you are getting? Review the Posting Guide for a checklist. (And : You are mentioning both Windows7 and Linux distro which adds to the ambiguity and lack of clarity.). The README says the package needs compilation and provided details about how to go about that and who to contact with specific requests for information about your setup:
http://cran.r-project.org/web/packages/multic/README

Installation Error is related to "Segmentation Fault". I did not save the error message, I wish I could post it here.
gcc compiler version is 4.6.3

> Also, there is no active support for windows binary version.
>Yes? The message linked to is a generic CRAN message. What is the point of mentioning this?

I mentioned it, because the multic package is a unix/linux library. There is no support for Windows PC. I thought any one might provide support for multic package on windows PC.

> Could any one please help me install multic package on ubuntu 12.04, 64 bit system running with R 2.14.2 version.
>I'm not a Linux user so probably am speaking out of place and only doing so because it is the weekend and I've noticed that the traffic is slow on the mailing list on weekends. I believe Ubuntu is a fork of Debian so you may want to pay particular attention to mentions of Debian specific instructions in the links below. Many of the questions I have seen on R help from ubuntu users who have difficulties with installing packages get resolved by re-installing R using the development version of R. I have seen the use of r-base-dev as a target.
http://cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-other-programs-under-a-Unix_002dalike
http://cran.r-project.org/doc/manuals/R-admin.html#Installing-R-under-Unix_002daikes
There is also a Debian R mailing list and the archives are at markmail (although I suspect those are not he official ones.)
http://markmail.org/search/+list:org%2Er-project%2Er-sig-debian

 I fixed the installation issue on ubuntu 12.04, by rebooting my system and installed multic on  a fresh R (2.14.1) session. It works well!


Thanks
 Sathish
________________________________________
From: Qiang Kou [qkou at umail.iu.edu]
Sent: Saturday, April 05, 2014 9:23 PM
To: David Winsemius
Cc: Srinivasan, Sathish  K; r-help at r-project.org
Subject: Re: [R] Multic for windows 7 and Ubuntu

I have just test the package on Ubuntu 12.04, everything is OK.

So please provide the error message on your computer.

Best,

KK


On Sat, Apr 5, 2014 at 9:02 PM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:

On Apr 5, 2014, at 1:50 AM, Srinivasan, Sathish K wrote:

> Hi all,
> Does anyone have issues installing multic package (http://cran.r-project.org/web/packages/multic/index.html) on ubuntu.

After doing a search on rhelp and r-sig-debian yours seems to be the first. Shouldn't you be providing much more detail regarding your current setup and versions of R and compilers, methods you are using, and the errors you are getting? Review the Posting Guide for a checklist. (And : You are mentioning both Windows7 and Linux distro which adds to the ambiguity and lack of clarity.). The README says the package needs compilation and provided details about how to go about that and who to contact with specific requests for information about your setup:

http://cran.r-project.org/web/packages/multic/README

> Also, there is no active support for windows binary version.

Yes? The message linked to is a generic CRAN message. What is the point of mentioning this?

> Could any one please help me install multic package on ubuntu 12.04, 64 bit system running with R 2.14.2 version.

I'm not a Linux user so probably am speaking out of place and only doing so because it is the weekend and I've noticed that the traffic is slow on the mailing list on weekends. I believe Ubuntu is a fork of Debian so you may want to pay particular attention to mentions of Debian specific instructions in the links below. Many of the questions I have seen on R help from ubuntu users who have difficulties with installing packages get resolved by re-installing R using the development version of R. I have seen the use of r-base-dev as a target.

http://cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-other-programs-under-a-Unix_002dalike

http://cran.r-project.org/doc/manuals/R-admin.html#Installing-R-under-Unix_002dalikes

There is also a Debian R mailing list and the archives are at markmail (although I suspect those are not he official ones.)

http://markmail.org/search/+list:org%2Er-project%2Er-sig-debian


>
> Thanks
> Sathish
>
Please ... read.
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Qiang Kou
qkou at umail.iu.edu<mailto:qkou at umail.iu.edu>
School of Informatics and Computing, Indiana University



From dwinsemius at comcast.net  Mon Apr  7 03:34:53 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Apr 2014 18:34:53 -0700
Subject: [R] simple linear plots with a loop
In-Reply-To: <COL130-W4477F434D9E03F07BB6C13FA680@phx.gbl>
References: <COL130-W4477F434D9E03F07BB6C13FA680@phx.gbl>
Message-ID: <CB63C864-4AC7-44F7-8DFB-BC83B8B247F7@comcast.net>


On Apr 6, 2014, at 6:07 PM, Kristi Glover wrote:

> Hi R users,
> I was trying to plot with  a fixed y with many independet variables.

It looks like you are plotting with a fixed x.

> I tried this loop but it did not work. any suggestions?

Yes. Explain what "did not work" means. Error? Then post the error  
message. Different results than expected? Then describe.


> I wanted to make 9 plots. This is a just an example data.
>
> dat1<- as.data.frame(matrix(sample(1:20,100,replace=TRUE),ncol=10))
> lapply(seq_len(ncol(dat1)),function(i)
> {
> par(mfrow=c(3,3)),
> plot(dat1[,1],dat1[,i+1],
> z[,i]<-lm(dat1[,1]~dat1[,i+1]),

What were you expecting to happen to "dat1[,i+1]" when "i" was at its  
max?

> abline(z),
> summary(z[,i])
> }
> here first column is dependent variable and other V2 to V10s are  
> independent variables. Also wanted look the summary (linear model)  
> with each variable.
> Thanks for your suggestions
> KG
> ===

Please post in plain text.

> 		 	   		
> 	[[alternative HTML version deleted]]

-- 

David Winsemius, MD
Alameda, CA, USA



From jim at bitwrit.com.au  Mon Apr  7 04:00:46 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 07 Apr 2014 12:00:46 +1000
Subject: [R] simple linear plots with a loop
In-Reply-To: <COL130-W4477F434D9E03F07BB6C13FA680@phx.gbl>
References: <COL130-W4477F434D9E03F07BB6C13FA680@phx.gbl>
Message-ID: <534206CE.7010905@bitwrit.com.au>

On 04/07/2014 11:07 AM, Kristi Glover wrote:
> Hi R users,
> I was trying to plot with  a fixed y with many independet variables. I tried this loop but it did not work. any suggestions? I wanted to make 9 plots. This is a just an example data.
>
> dat1<- as.data.frame(matrix(sample(1:20,100,replace=TRUE),ncol=10))
> lapply(seq_len(ncol(dat1)),function(i)
> {
> par(mfrow=c(3,3)),
> plot(dat1[,1],dat1[,i+1],
> z[,i]<-lm(dat1[,1]~dat1[,i+1]),
> abline(z),
> summary(z[,i])
> }
>   here first column is dependent variable and other V2 to V10s are independent variables. Also wanted look the summary (linear model) with each variable.
> Thanks for your suggestions
> KG

Hi Kristi,
You can get your plots like this:

for(i in 2:10) {
  plot(dat1[,1],dat1[,i],ylab=paste("dat1[,",i,"]",sep=""))
  z<-lm(dat1[,1]~dat1[,i])
  abline(z)
  print(summary(z))
}

This prints the summaries on the console. If you want to get a listing 
with plots and summaries together, there are a number of ways, one of 
which is the htmlize function in the prettyR package. Save the following 
to a file named kg.R:

#title~Example listing with htmlize
z[[1]]<-NULL
png("kg.png",width=600,height=600)
par(mfrow=c(3,3))
for(i in 2:10) {
  plot(dat1[,1],dat1[,i],ylab=paste("dat1[,",i,"]",sep=""))
  z[[i]]<-lm(dat1[,1]~dat1[,i])
  abline(z[[i]])
}
dev.off()
for(i in 1:9) print(summary(z[[i]]))

then:

library(prettyR)
htmlize("kg.R")

Jim



From catagui at gmail.com  Mon Apr  7 07:41:43 2014
From: catagui at gmail.com (Catalina Aguilar Hurtado)
Date: Mon, 7 Apr 2014 15:41:43 +1000
Subject: [R] How to make a proper use of blocking in limma using voom
Message-ID: <CAAHBMXa7ns-iZgrCxqUsYW40ety3dNmuvZj+e7B4v4d=US_0CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/276e575a/attachment-0001.pl>

From petr.pikal at precheza.cz  Mon Apr  7 08:44:58 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 7 Apr 2014 06:44:58 +0000
Subject: [R] How to plot data using ggplot
In-Reply-To: <1396637596602-4688191.post@n4.nabble.com>
References: <1396604538079-4688168.post@n4.nabble.com>
	<CADv2QyHNMaUm4ZfpA-FurqEuLhckOjLz6ewyhXHFY+3B-s2JZw@mail.gmail.com>
	<1396637596602-4688191.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC815A@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of drunkenphd
> Sent: Friday, April 04, 2014 8:53 PM
> To: r-help at r-project.org
> Subject: Re: [R] How to plot data using ggplot
>
> djmuseR wrote
> > Do you mean a continuous range expressible in a colorbar or a
> discrete
> > range, and if the latter, what intervals did you have in mind?
>
> I mean diskrete values like : 545    0    8   25  101  420   95  928
> 24
> 165    6  108   18  213   70.
> The problem is that range is from 0-4000 while only one value is near
> 4000 and all the others are below 1000.

Maybe using logarithmic scale?

Petr

> Please advice..
> Regards
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> plot-data-using-ggplot-tp4688168p4688191.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Apr  7 08:56:05 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 7 Apr 2014 06:56:05 +0000
Subject: [R] solicit help to read in 384 plate color image
In-Reply-To: <CADiQnYiwguMYBE3HQFeKFK+miYmxpmmnVanOLiqHtadhRePMqg@mail.gmail.com>
References: <CADiQnYiwguMYBE3HQFeKFK+miYmxpmmnVanOLiqHtadhRePMqg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC8173@SRVEXCHMBX.precheza.cz>

Hi

There was package rimage which could read jpeg file in colours and manipulate with it. However it is not actively maintained and therefore it does not work in recent versions of R. I believe that R 2.14.0 is the last version able to use rimage. It was quite simple and I was tempted to start its maintenance but I do not use it often and so my interest ceased. If you wanted to try it you need to install this old version, install rimage. After that you can read your images in this old version, preprocess it with rimage and save result for use in new R version.

Regards
Petr

PS. If you do not find rimage in CRAN I can send you a zip file.



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Waverley @ Palo Alto
> Sent: Friday, April 04, 2014 10:28 PM
> To: r-help
> Subject: [R] solicit help to read in 384 plate color image
>
> Hi,
>
> I am doing an experiment which results different colors of different
> intensities in the 384 micro titer plate.
>
> I took a picture of the plate by scanning in the image as a jpeg file
> and now I want to
>
> 1. read in the image file
> 2. grid the content
> 3. need to extract the intensity and color of each well.
>
> Is there a R package I can use for that? there is a package called
> "gitter"
> which is almost satisfying my needs. However, it can only read in grey
> values and no colors.
>
> If someone has the code, please share.
>
> --
>
> Thanks.
>
> waverley
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From paramon at acdlabs.ru  Mon Apr  7 08:33:50 2014
From: paramon at acdlabs.ru (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Mon, 07 Apr 2014 10:33:50 +0400
Subject: [R] Micro-point with pch=16?
Message-ID: <534246CE.9050606@acdlabs.ru>

Hello!

I'm trying to plot a 3D dataset as a scatter-plot, coding Z-axis values 
with point size. I pass the following parameters to "plot" function:

type = 'p',
pch = 16,
cex = intensity/max(intensity)

In my dataset, max(intensity)/min(intensity) is ~4000. However, visual 
points vary in radius by no more then 100 probably. Albeit default 
device isn't good at displaying micro-points, other devices (pdf, svg) 
can display such points just fine.

Is there a way to produce micro-points with cex=0.001 and less?

Best wishes,
Andrey Paramonov

-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From lianoglou.steve at gene.com  Mon Apr  7 09:09:02 2014
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Mon, 7 Apr 2014 00:09:02 -0700
Subject: [R] How to make a proper use of blocking in limma using voom
In-Reply-To: <CAAHBMXa7ns-iZgrCxqUsYW40ety3dNmuvZj+e7B4v4d=US_0CA@mail.gmail.com>
References: <CAAHBMXa7ns-iZgrCxqUsYW40ety3dNmuvZj+e7B4v4d=US_0CA@mail.gmail.com>
Message-ID: <CAHA9McMtPPq9x019jySofvbUybXc8MxdOWXEdUJc080B1Faq2A@mail.gmail.com>

Hi,

This is a bioconductor-related question so please post any follow up
questions on that mailing list. You can sign up to that list here:

https://stat.ethz.ch/mailman/listinfo/bioconductor

Comments in line:


On Sun, Apr 6, 2014 at 10:41 PM, Catalina Aguilar Hurtado
<catagui at gmail.com> wrote:
> Hi all,
>
> I have a RNAseq data to analyse were I have a control and a one treatment
> for different individuals. I need to block the effects of the individual,
> but I am having several troubles to get the data that I need. I am using
> voom because my data is very heterogeneous and voom seams to do a good job
> normalising my reads.
>
> I am having the following issues:
>
>    1.
>
>    I want to get the differentially expressed genes (DEGs) of my treatment
>    not of my control. I don't understand after the eBayes analysis why I get
>    the coefficients for both. I have tried a > makeContrasts (TreatvsCont=
>    c2-co, levels = design) to subtract the control effect but then I get 0
>    DEGs.
>    2.
>
>    I am not sure when to include the 0 (null model) in the model formula, I
>    have read examples for both types of models.
>
> This are my targets, with my column names of my counts, individual and
> condition
>
>>targets
>
> Individual condition
>
> A1 1 co
>
> A2 3 co
>
> A4 4 co
>
> A5 5 co
>
> E1 1 c2
>
> E2 2 c2
>
> E3 3 c2
>
> E4 4 c2
>
> E5 5 c2
>
> This is the code I have been trying:
>
>>co2=as.matrix(read.table("2014_04_02_1h_PB.csv",header=T, sep=",",
> row.names=1))
>
>>nf = calcNormFactors (co2)
>
>>targets= read.table ("targets.csv", header = T, sep=",",row.names=1)
>
>>treat <- factor (targets$condition, levels= c("co", "c2"))
>
>>design <- model.matrix(~0+treat)
>
>>colnames (design) <- levels (treat)
>
>>y <- voom(co2,design,lib.size=colSums(co2)*nf)
>
>>corfit <- duplicateCorrelation(y,design,block=targets$Individual)
>
>>fit <-
> lmFit(y,design,block=targets$Individual,correlation=corfit$consensus)
>
>>fit2<- eBayes (fit)
>
>>results_trt <- topTable (fit2, coef="c2", n=nrow (y), sort.by="none")
>
> >From which gives me 18,000 genes with adj.P.Val < 0.01 out of 22,000 genes
> that I have in total. Which makes no sense..

This is because you defined your model matrix to have no intercept
term (that's what the 0 in `~ 0 + treat` is doing).

You will have to test for a particular contrast (not just a coeficient
in your design) in order to get what you are after. Sections 9.7 (
Multi-level Experiments) and 16.3 (
Comparing Mammary Progenitor Cell Populations with Illumina BeadChips)
in the lima user's guide may be the most useful for you to follow
along at this point:

http://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf

(look for the `makeContrasts` call)

After you call `fit <- lmFit( ... )` in your code above you might do
something like:

R> cm <- makeContrasts(co2Vsco=treatco2 - treatco0, levels=design)
R> fit2 <- eBayes(contrasts.fit(fit, cm))
R> res <- topTable(fit2, coef='co2Vsco')

Note that the `treatco2` and `treatco` are only correct if these are
the column names of your design matrix -- substitute with the
appropriate names for your example, if necessary.

> Thanks in advance for the help.

Noodle on that a bit and if you still have questions, please do post a
follow up question on the bioconductor list.

Btw, to help make your question more interpretable, since we don't
have your targets file, I think it would be easier for us if you
copy/paste the output of `dput(targets)` and `dput(design)` after you
create those object in a follow up email if it's necessary to write
one.

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech



From spencer.graves at structuremonitoring.com  Mon Apr  7 09:11:32 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 7 Apr 2014 00:11:32 -0700
Subject: [R] solicit help to read in 384 plate color image
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC8173@SRVEXCHMBX.precheza.cz>
References: <CADiQnYiwguMYBE3HQFeKFK+miYmxpmmnVanOLiqHtadhRePMqg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC8173@SRVEXCHMBX.precheza.cz>
Message-ID: <53424FA4.9040501@structuremonitoring.com>

       Have you considered the Bioconductor package "EBImage"?  See 
"www.bioconductor.org/packages/release/bioc/html/EBImage.html".


       I found it using findFn{sos}.  It seems well developed, well 
maintained AND includes a vignette that simplifies the job of learning 
how to use it.


       Hope this helps.
       Spencer


On 4/6/2014 11:56 PM, PIKAL Petr wrote:
> Hi
>
> There was package rimage which could read jpeg file in colours and manipulate with it. However it is not actively maintained and therefore it does not work in recent versions of R. I believe that R 2.14.0 is the last version able to use rimage. It was quite simple and I was tempted to start its maintenance but I do not use it often and so my interest ceased. If you wanted to try it you need to install this old version, install rimage. After that you can read your images in this old version, preprocess it with rimage and save result for use in new R version.
>
> Regards
> Petr
>
> PS. If you do not find rimage in CRAN I can send you a zip file.
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Waverley @ Palo Alto
>> Sent: Friday, April 04, 2014 10:28 PM
>> To: r-help
>> Subject: [R] solicit help to read in 384 plate color image
>>
>> Hi,
>>
>> I am doing an experiment which results different colors of different
>> intensities in the 384 micro titer plate.
>>
>> I took a picture of the plate by scanning in the image as a jpeg file
>> and now I want to
>>
>> 1. read in the image file
>> 2. grid the content
>> 3. need to extract the intensity and color of each well.
>>
>> Is there a R package I can use for that? there is a package called
>> "gitter"
>> which is almost satisfying my needs. However, it can only read in grey
>> values and no colors.
>>
>> If someone has the code, please share.
>>
>> --
>>
>> Thanks.
>>
>> waverley
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Mon Apr  7 10:00:00 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 7 Apr 2014 08:00:00 +0000
Subject: [R] solicit help to read in 384 plate color image
In-Reply-To: <53424FA4.9040501@structuremonitoring.com>
References: <CADiQnYiwguMYBE3HQFeKFK+miYmxpmmnVanOLiqHtadhRePMqg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC8173@SRVEXCHMBX.precheza.cz>
	<53424FA4.9040501@structuremonitoring.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC823E@SRVEXCHMBX.precheza.cz>

Hi

Yes I know about EBImage. It was rather too complicated for some simple tasks reading image, performing rowwise/colwise computations and summing or averaging of rows or columns which was my task (and I had some code from ancient times which used rimage :). However when I read introduction to EBImage it seems that it can do the same job (after some learning from my side :).

Thanks
Petr

> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at structuremonitoring.com]
> Sent: Monday, April 07, 2014 9:12 AM
> To: PIKAL Petr; Waverley @ Palo Alto; r-help
> Subject: Re: [R] solicit help to read in 384 plate color image
>
>        Have you considered the Bioconductor package "EBImage"?  See
> "www.bioconductor.org/packages/release/bioc/html/EBImage.html".
>
>
>        I found it using findFn{sos}.  It seems well developed, well
> maintained AND includes a vignette that simplifies the job of learning
> how to use it.
>
>
>        Hope this helps.
>        Spencer
>
>
> On 4/6/2014 11:56 PM, PIKAL Petr wrote:
> > Hi
> >
> > There was package rimage which could read jpeg file in colours and
> manipulate with it. However it is not actively maintained and therefore
> it does not work in recent versions of R. I believe that R 2.14.0 is
> the last version able to use rimage. It was quite simple and I was
> tempted to start its maintenance but I do not use it often and so my
> interest ceased. If you wanted to try it you need to install this old
> version, install rimage. After that you can read your images in this
> old version, preprocess it with rimage and save result for use in new R
> version.
> >
> > Regards
> > Petr
> >
> > PS. If you do not find rimage in CRAN I can send you a zip file.
> >
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Waverley @ Palo Alto
> >> Sent: Friday, April 04, 2014 10:28 PM
> >> To: r-help
> >> Subject: [R] solicit help to read in 384 plate color image
> >>
> >> Hi,
> >>
> >> I am doing an experiment which results different colors of different
> >> intensities in the 384 micro titer plate.
> >>
> >> I took a picture of the plate by scanning in the image as a jpeg
> file
> >> and now I want to
> >>
> >> 1. read in the image file
> >> 2. grid the content
> >> 3. need to extract the intensity and color of each well.
> >>
> >> Is there a R package I can use for that? there is a package called
> >> "gitter"
> >> which is almost satisfying my needs. However, it can only read in
> grey
> >> values and no colors.
> >>
> >> If someone has the code, please share.
> >>
> >> --
> >>
> >> Thanks.
> >>
> >> waverley
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From matthias.winkler at ibp.fraunhofer.de  Mon Apr  7 09:52:57 2014
From: matthias.winkler at ibp.fraunhofer.de (Winkler, Matthias)
Date: Mon, 7 Apr 2014 07:52:57 +0000
Subject: [R] Mistakes in date conversion for future date/time (POSIXct)
In-Reply-To: <04ca3991741eafcd7fb2c1025c9a0186@www.webmail.co.za>
References: <C08EE413F100F8429FCD8758D566EE960E57F71C@fgdemucimp02exc.ads.fraunhofer.de>
	<533EE3C2.8060808@gmail.com>,
	<C67C1881-1105-4C40-B2A3-EA9FFE10C4C4@comcast.net>
	<04ca3991741eafcd7fb2c1025c9a0186@www.webmail.co.za>
Message-ID: <C08EE413F100F8429FCD8758D566EE960E57FC97@fgdemucimp02exc.ads.fraunhofer.de>

Thank you for your answers. They helped me a lot!

I used R 3.1.0 RC and the mistake didn't show up. 

I also made an additional test, the same as David McPearson did: I tried it again with R 3.0.3 on a pc with 2 OS (Windows 7 and Linux). The error showed up at the windows system but not in Linux. So this seems to be a problem related to Windows.

Kind regards
Matthias

?


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von David McPearson
Gesendet: Sonntag, 6. April 2014 12:19
An: r-help at r-project.org
Betreff: Re: [R] Mistakes in date conversion for future date/time (POSIXct)

I _do_ see this error - on R 3.0.3 / Win XP however, not on R 2.11.1 / Linux.
(Same hardware, 2 x OS, 2 x R versions)

Maybe it's peculiar to to 'doze...

datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 00:00"),
to=as.POSIXct("2100-01-01 00:00"), by="1 hour") levels(as.factor(strftime(datetimesequenz, format="%Y"))) [1] "1960" "1961" "1962" "1963" "1964" "1965" "1966" "1967" "1968" "1969"
"1970" "1971" "1972"
 [14] "1973" "1974" ...
 ...
[183] "2154" "2155" "2157" "2158" "2159" "2160" "2161" "2162" "2167"

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
[5] LC_TIME=English_Australia.1252    

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils    
methods   base     

other attached packages:
[1] svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.2.1    Hmisc_3.12-2   
Formula_1.1-1
[6] survival_2.37-4

loaded via a namespace (and not attached):
[1] cluster_1.14.4  fortunes_1.5-0  grid_3.0.2      lattice_0.20-23
rpart_4.1-3    
[6] svMisc_0.9-69   tools_3.0.2  


Cheers,
D.

On Fri, 4 Apr 2014 14:19:09 -0700 David Winsemius <dwinsemius at comcast.net> wrote

> On Apr 4, 2014, at 9:54 AM, Duncan Murdoch wrote:
> 
> > On 04/04/2014 10:55 AM, Winkler, Matthias wrote:
> >> Dear R-users,
> >> 
> >> I'm working on datasets which contain data from the years 1960 to 
> >> 2100
..
> >> I also produced a date/time-sequence in R, which showed the same 
> >> mistakes (see example below). The mistakes occur at the same dates 
> >> like in my datasets. It's always at the end of march.
> >> > datetimesequenz <- seq.POSIXt(from=as.POSIXct("1960-01-01 
> >> > 00:00"),
> >> > to=as.POSIXct("2100-01-01 00:00"), by="1 hour")
> >> > levels(as.factor(strftime(datetimesequenz, format="%Y"))) >>   [1]
> >> > "1960" "1961" "1962" ...
> >> [181] "2152" "2153" "2154" "2156" "2157" "2158" "2159" "2160" "2161"
> >> "2166" 
> >> Has anybody experienced the same problem and knows a workaround?
> >> 
> >> I'm using R 3.0.1 under Windows 7 64bit. I also tried this with R 
> >> 3.0.3, it showed the same problem. Thank you for your help!
> > 
> > I don't see this in 3.1.0 beta.  Do you?
> 
> I'm not seeing it on a Mac in 3.0.2 either.
> 
> > max(datetimesequenz)
> [1] "2100-01-01 PST"
> > length(datetimesequenz)
> [1] 1227241
> 
> > 
> > Duncan Murdoch
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Fight Crime And Corruption! http://www.anc.org.za/2014/manifesto/

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From studenttbal at gmail.com  Mon Apr  7 09:01:49 2014
From: studenttbal at gmail.com (T Bal)
Date: Mon, 7 Apr 2014 09:01:49 +0200
Subject: [R] R script on Rstudio server
Message-ID: <CAOeUc7s4se90j=2RjU7jomCjfxTEXkFXrLjPXjU383k63_NDcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/baff6c80/attachment-0001.pl>

From jim at bitwrit.com.au  Mon Apr  7 10:49:38 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 07 Apr 2014 18:49:38 +1000
Subject: [R] skipping an error message
In-Reply-To: <CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>
References: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>	<5341DA8A.1080602@bitwrit.com.au>
	<CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>
Message-ID: <534266A2.3050004@bitwrit.com.au>

On 04/07/2014 06:46 PM, Naser Jamil wrote:
> Hi Jim,
> Thanks for the suggestion. What I understand is trying something like
>
> tryCatch(nlme(conc~f2(dose,Theta1,Theta
> 2,Theta3,t),
>   fixed=Theta1+Theta2+Theta3~1,
>   data=grouped.data,
>   random=Theta1+Theta2+Theta3~1,
>   start=list(fixed=ini.pkpara))
>              )
>
> Is that correct?
>
> Once again thanks.
>
> Regards,
> Jamil.
>
Yes, I think that will do what you want.

Jim



From jim at bitwrit.com.au  Mon Apr  7 10:51:06 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 07 Apr 2014 18:51:06 +1000
Subject: [R] Micro-point with pch=16?
In-Reply-To: <534246CE.9050606@acdlabs.ru>
References: <534246CE.9050606@acdlabs.ru>
Message-ID: <534266FA.5000707@bitwrit.com.au>

On 04/07/2014 04:33 PM, ?????? ????????? wrote:
> Hello!
>
> I'm trying to plot a 3D dataset as a scatter-plot, coding Z-axis values
> with point size. I pass the following parameters to "plot" function:
>
> type = 'p',
> pch = 16,
> cex = intensity/max(intensity)
>
> In my dataset, max(intensity)/min(intensity) is ~4000. However, visual
> points vary in radius by no more then 100 probably. Albeit default
> device isn't good at displaying micro-points, other devices (pdf, svg)
> can display such points just fine.
>
> Is there a way to produce micro-points with cex=0.001 and less?
>
Hi Andrey,
As the points help page says:

What happens for very small or zero values of cex is device-dependent: 
symbols or characters may become invisible or they may be plotted at a 
fixed minimum size.

Jim



From smartpink111 at yahoo.com  Mon Apr  7 12:59:04 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Apr 2014 03:59:04 -0700 (PDT)
Subject: [R] How to use an elements' name when creating a data frame via
	a for loop
Message-ID: <1396868344.64268.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

May be this helps:
stations <- LETTERS[1:4]
set.seed(42)
PM2.5 <- data.frame(DateTime=seq(as.POSIXct("2010-01-10 01:00:00"),length.out=10,by= "1 day"), station= sample(LETTERS[1:4],10,replace=TRUE))
for(i in 1:length(stations))
assign(paste(stations[i],"PM",sep="_"),subset(PM2.5,station==stations[i])) 

A_PM 

#             DateTime station
#8 2010-01-17 01:00:00 A

D_PM
#             DateTime station
#1 2010-01-10 01:00:00 D 

#2 2010-01-11 01:00:00       D
#4 2010-01-13 01:00:00       D 


A.K.

Hey, I got a question that bugs me for a longer time now.  I want to create several data.frames via a for loop that is applied to the elements of a vector.
And I want to use the names of the elements in the name of the created data.frames. Is that possible?
Im confused with the coding there ... Should look something like this:   for (i in 1:length(stations)) {stations[i]_PM <- data.frame(PM2.5$DateTime,PM2.5$stations[i])} The result should be several dataframes (length of stations) with the name StationID_PM.
Should I use the paste function?? Thank you very much. Hopefuly, I explained myself well enough. Dolby



From katherine_gobin at yahoo.com  Mon Apr  7 13:12:16 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Mon, 7 Apr 2014 19:12:16 +0800 (SGT)
Subject: [R] Conditional subtraction
Message-ID: <1396869136.85951.YahooMailNeo@web193305.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/6a4799dc/attachment-0001.pl>

From smartpink111 at yahoo.com  Mon Apr  7 13:33:44 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Apr 2014 04:33:44 -0700 (PDT)
Subject: [R] "invalid factor level, NA generated" error message help
Message-ID: <1396870424.94401.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:
number_of_stations <- 3
label <- c("s1","s2","s3","s4")
label1 <- combn(label[1:number_of_stations],2)
label.i <- character(0)calc_distances <- function(z,a){ for(i in 1:z){lab.i <- paste(a[1,i],a[2,i],sep="-") 

label.i <- c(label.i,lab.i)} 

data.frame(label=label.i,stringsAsFactors=FALSE) }


calc_distances(number_of_stations,label1)
#  label 

#1 s1-s2 

#2 s1-s3
#3 s2-s3 

number_of_stations <- 5 

label <- c("s1","s2","s3","s4" ,"s5")
label1 <- combn(label[1:number_of_stations],2 ) 

calc_distances(number_of_stations,label1)
#label 

#1 s1-s2 

#2 s1-s3 

#3 s1-s4
#4 s1-s5 

#5 s2-s3?
#or
data.frame(label=apply(label1[,1:number_of_stations],2,paste,collapse="-"),stringsAsFactors=FALSE) 
A.K.


Hi, I have read several pages and threads on this error message, but I haven't found one that solved my problem, so any help would be appreciated. As part of a much larger script, I am trying to generate a label column that has all possible combinations from a vector, such that for the vector c("s1","s2","s3") I would get a column
"s1-s2"
"s1-s3"
"s2-s3" I need the script to be imbedded within a for loop that is carrying out other functions, so here is the snip it of code that is relevant to this column number_of_stations <- 3
label <- c("s1","s2","s3","s4")
label <- combn(label[1:number_of_stations],2) #this script is designed to be run using various numbers of stations which will not always be the same as the number of labels
lable.i <- as.data.frame(NULL)
calc_distances <- function(z,a){ for(i in 1:z){lab.i <- gsub(" ","",paste(a[1,i],"-",a[2,i])) label.i <- as.data.frame(rbind(label.i,lab.i))} print(lable.i)}
calc_distances(number_of_stations,label) When I run that script, I get the following X.s1.s2.
1    s1-s2
2 3 Warning messages:
1: In `[<-.factor`(`*tmp*`, ri, value = "s1-s3") : invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, ri, value = "s2-s3") : invalid factor level, NA generated So, my question is, why does it run on the first set, but have issues with the other sets? Also, If I extract this code from the for loop and run the gsub line separately for each combination, it works fine (e.g. gsub(" ","",paste(label[1,2],"-",label[2,2])) doesn't give me that error message). How do I solve this error? Thanks for the help



From smartpink111 at yahoo.com  Mon Apr  7 13:53:16 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Apr 2014 04:53:16 -0700 (PDT)
Subject: [R] Conditional subtraction
Message-ID: <1396871596.73142.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
indx <- as.vector(with(dat,tapply(seq_along(price), list(id), FUN= head,1)))
dat$adjusted_price <- dat$price
dat$adjusted_price[indx] <- with(dat, price[indx]-adj_factor[indx])
dat 

#  key       id    price adj_factor adjusted_price
#1   A instru_A 101.3800     2.0800        99.3000 

#2   B instru_B   3.9306     2.5217         1.4089 

#3   C instru_B   3.7488     2.5217         3.7488 

#4   D instru_B  92.9624     2.5217        92.9624 

#5   E instru_C   5.1500     3.0800         2.0700 

#6   E instru_C  96.1908     3.0800        96.1908
A.K.

Dear R forum I have following data.frame dat = data.frame(key = c("A", "B", "C", "D", "E", "E"), id = c("instru_A", "instru_B", "instru_B", "instru_B", "instru_C", "instru_C"), price = c(101.38, 3.9306, 3.7488, 92.9624, 5.15, 96.1908), adj_factor = c(2.08, 2.5217, 2.5217, 2.5217, 3.08, 3.08)) > dat key       id     price         adj_factor
1   A instru_A 101.3800   2.0800
2   B instru_B   3.9306     2.5217
3   C instru_B   3.7488     2.5217
4   D instru_B  92.9624    2.5217
5   E instru_C   5.1500     3.0800
6   E instru_C  96.1908    3.0800 This is just a part of big database and ids can appear any no of times. # MY PROBLEM I need to subtract adj_factor from the price, however only from the first id only. In case of instru_A, there is only 1 id, so 2.08 should be subtracted from 101.38. The id "instru_B" is appearing 3 times. So in this case, adj_factor = 2.5217 should be subtracted from 3.9306 and rest should remain same. Similarly, id "instru_C" is appearing 2 times, hence the adj_factor = 3.08 should be subtracted from 5.15. Effectively I am looking for  > dat_new key       id     price         adj_factor   adjusted_price
1   A instru_A 101.3800   2.0800        99.3000      # price adjusted
2   B instru_B   3.9306     2.5217         1.4089      # price adjusted
3   C instru_B   3.7488     2.5217         3.7488
4   D instru_B  92.9624    2.5217        92.9624
5   E instru_C   5.1500     3.0800         2.0700      # price adjusted
6   E instru_C  96.1908    3.0800        96.1908 I tried something like adj_price = function(id, price, adj_factor)
{
id_length = length(id) if(id_length == 1) {
(adjusted_price = price-adj_factor)
} if(id_length == 2) {
(adjusted_price = c(price[1]-adj_factor[1], price[2]))
} if(id_length > 2) {
(adjusted_price = c(price[1]-adj_factor[1],price[2:id_length]))
} return(adjusted_price) } (final_price = adj_price(dat$id, dat$price, dat$adj_factor)) > (final_price = adj_price(dat$id, dat$price, dat$adj_factor))
[1] 99.3000  3.9306  3.7488 92.9624  5.1500 96.1908 Kindly advise Regards Katherine



From ruipbarradas at sapo.pt  Mon Apr  7 13:36:29 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 07 Apr 2014 12:36:29 +0100
Subject: [R] Conditional subtraction
In-Reply-To: <1396869136.85951.YahooMailNeo@web193305.mail.sg3.yahoo.com>
References: <1396869136.85951.YahooMailNeo@web193305.mail.sg3.yahoo.com>
Message-ID: <53428DBD.2080804@sapo.pt>

Hello,

Try the following.



fun <- function(x){
	x[["adjusted_price"]] <- x[["price"]]
	x[["adjusted_price"]][1] <- x[["price"]][1] - x[["adj_factor"]][1]
	x
}

res <- do.call(rbind, lapply(split(dat, dat$id), fun))
rownames(res) <- NULL
res


Hope this helps,

Rui Barradas

Em 07-04-2014 12:12, Katherine Gobin escreveu:
> Dear R forum
>
> I have following data.frame
>
> dat = data.frame(key = c("A", "B", "C", "D", "E", "E"), id = c("instru_A", "instru_B", "instru_B", "instru_B", "instru_C", "instru_C"), price = c(101.38, 3.9306, 3.7488, 92.9624, 5.15, 96.1908), adj_factor = c(2.08, 2.5217, 2.5217, 2.5217, 3.08, 3.08))
>
>> dat
>    key       id     price         adj_factor
> 1   A instru_A 101.3800   2.0800
> 2   B instru_B   3.9306     2.5217
> 3   C instru_B   3.7488     2.5217
> 4   D instru_B  92.9624    2.5217
> 5   E instru_C   5.1500     3.0800
> 6   E instru_C  96.1908    3.0800
>
> This is just a part of big database and ids can appear any no of times.
>
> # MY PROBLEM
>
>
> I need to subtract adj_factor from the price, however only from the first id only.
>
> In case of instru_A, there is only 1 id, so 2.08 should be subtracted from 101.38.
>
> The id "instru_B" is appearing 3 times. So in this case, adj_factor = 2.5217 should be subtracted from 3.9306 and rest should remain same.
>
> Similarly, id "instru_C" is appearing 2 times, hence the adj_factor = 3.08 should be subtracted from 5.15.
>
>
> Effectively I am looking for
>
>> dat_new
>
>    key       id     price         adj_factor   adjusted_price
> 1   A instru_A 101.3800   2.0800        99.3000      # price adjusted
> 2   B instru_B   3.9306     2.5217         1.4089      # price adjusted
> 3   C instru_B   3.7488     2.5217         3.7488
> 4   D instru_B  92.9624    2.5217        92.9624
> 5   E instru_C   5.1500     3.0800         2.0700      # price adjusted
> 6   E instru_C  96.1908    3.0800        96.1908
>
>
>
>
> I tried something like
>
> adj_price = function(id, price, adj_factor)
> {
> id_length = length(id)
>
> if(id_length == 1)
>
> {
> (adjusted_price = price-adj_factor)
> }
>
> if(id_length == 2)
>
> {
> (adjusted_price = c(price[1]-adj_factor[1], price[2]))
> }
>
> if(id_length > 2)
>
> {
> (adjusted_price = c(price[1]-adj_factor[1],price[2:id_length]))
> }
>
> return(adjusted_price)
>
> }
>
> (final_price = adj_price(dat$id, dat$price, dat$adj_factor))
>
>> (final_price = adj_price(dat$id, dat$price, dat$adj_factor))
> [1] 99.3000  3.9306  3.7488 92.9624  5.1500 96.1908
>
>
> Kindly advise
>
> Regards
>
> Katherine
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From qkou at umail.iu.edu  Mon Apr  7 16:07:01 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Mon, 7 Apr 2014 10:07:01 -0400
Subject: [R] R script on Rstudio server
In-Reply-To: <CAOeUc7s4se90j=2RjU7jomCjfxTEXkFXrLjPXjU383k63_NDcQ@mail.gmail.com>
References: <CAOeUc7s4se90j=2RjU7jomCjfxTEXkFXrLjPXjU383k63_NDcQ@mail.gmail.com>
Message-ID: <CAJ_LAMDz1eqnzcauZbDf6_HOK=PbnduLYeZhyKwAuZgETEAemw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/42f552a7/attachment-0001.pl>

From jamilnaser79 at gmail.com  Mon Apr  7 10:46:05 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Mon, 7 Apr 2014 09:46:05 +0100
Subject: [R] skipping an error message
In-Reply-To: <5341DA8A.1080602@bitwrit.com.au>
References: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>
	<5341DA8A.1080602@bitwrit.com.au>
Message-ID: <CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/f2e025da/attachment-0001.pl>

From paramon at acdlabs.ru  Mon Apr  7 13:07:26 2014
From: paramon at acdlabs.ru (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Mon, 07 Apr 2014 15:07:26 +0400
Subject: [R] Micro-point with pch=16?
In-Reply-To: <534266FA.5000707@bitwrit.com.au>
References: <534246CE.9050606@acdlabs.ru> <534266FA.5000707@bitwrit.com.au>
Message-ID: <534286EE.1040300@acdlabs.ru>

07.04.2014 12:51, Jim Lemon ?????:
> On 04/07/2014 04:33 PM, ?????? ????????? wrote:
>> Hello!
>>
>> I'm trying to plot a 3D dataset as a scatter-plot, coding Z-axis values
>> with point size. I pass the following parameters to "plot" function:
>>
>> type = 'p',
>> pch = 16,
>> cex = intensity/max(intensity)
>>
>> In my dataset, max(intensity)/min(intensity) is ~4000. However, visual
>> points vary in radius by no more then 100 probably. Albeit default
>> device isn't good at displaying micro-points, other devices (pdf, svg)
>> can display such points just fine.
>>
>> Is there a way to produce micro-points with cex=0.001 and less?
>>
> Hi Andrey,
> As the points help page says:
>
> What happens for very small or zero values of cex is device-dependent:
> symbols or characters may become invisible or they may be plotted at a
> fixed minimum size.

Indeed, for svg device micro-points are plotted at fixed minimal size.
But is there a way to work-around this limitation, for svg device?

Best wishes,
Andrey Paramonov


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From boris.steipe at utoronto.ca  Mon Apr  7 16:53:09 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 7 Apr 2014 10:53:09 -0400
Subject: [R] Micro-point with pch=16?
In-Reply-To: <534286EE.1040300@acdlabs.ru>
References: <534246CE.9050606@acdlabs.ru> <534266FA.5000707@bitwrit.com.au>
	<534286EE.1040300@acdlabs.ru>
Message-ID: <E325AD02-441F-4776-9B71-516EAD15A797@utoronto.ca>

Since you won't be able to see the effect on-screen, how about a little script that post-processes the SVG?
B.


On 2014-04-07, at 7:07 AM, ?????? ????????? wrote:

> 07.04.2014 12:51, Jim Lemon ?????:
>> On 04/07/2014 04:33 PM, ?????? ????????? wrote:
>>> Hello!
>>> 
>>> I'm trying to plot a 3D dataset as a scatter-plot, coding Z-axis values
>>> with point size. I pass the following parameters to "plot" function:
>>> 
>>> type = 'p',
>>> pch = 16,
>>> cex = intensity/max(intensity)
>>> 
>>> In my dataset, max(intensity)/min(intensity) is ~4000. However, visual
>>> points vary in radius by no more then 100 probably. Albeit default
>>> device isn't good at displaying micro-points, other devices (pdf, svg)
>>> can display such points just fine.
>>> 
>>> Is there a way to produce micro-points with cex=0.001 and less?
>>> 
>> Hi Andrey,
>> As the points help page says:
>> 
>> What happens for very small or zero values of cex is device-dependent:
>> symbols or characters may become invisible or they may be plotted at a
>> fixed minimum size.
> 
> Indeed, for svg device micro-points are plotted at fixed minimal size.
> But is there a way to work-around this limitation, for svg device?
> 
> Best wishes,
> Andrey Paramonov
> 
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From wewolski at gmail.com  Mon Apr  7 17:05:00 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 7 Apr 2014 17:05:00 +0200
Subject: [R] installing r on ubuntu ?
Message-ID: <CAAjnpdhmrEcOLWcPyOZ8SG_V5RH4qC+xNQtFWd5ESpWqFpok_w@mail.gmail.com>

Hi,

trying to install newest R on ubuntu

I follow the instructions at:
 http://cran.at.r-project.org/bin/linux/ubuntu/


I added:

deb http://cran.r-mirror.de/bin/linux/ubuntu saucy/

to:
/etc/apt/sources.list


running :

sudo apt-get update

produces :
W: GPG error: http://cran.r-mirror.de saucy/ Release: The following
signatures couldn't be verified because the public key is not
available: NO_PUBKEY 51716619E084DAB9

??


regards
Witold


-- 
Witold Eryk Wolski



From qkou at umail.iu.edu  Mon Apr  7 17:10:38 2014
From: qkou at umail.iu.edu (Qiang Kou)
Date: Mon, 7 Apr 2014 11:10:38 -0400
Subject: [R] installing r on ubuntu ?
In-Reply-To: <CAAjnpdhmrEcOLWcPyOZ8SG_V5RH4qC+xNQtFWd5ESpWqFpok_w@mail.gmail.com>
References: <CAAjnpdhmrEcOLWcPyOZ8SG_V5RH4qC+xNQtFWd5ESpWqFpok_w@mail.gmail.com>
Message-ID: <CAJ_LAMBvm44WWw9rbGyg6pgSEqTWL0z_MnX0usEAOwQ_+7vC9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/89613b2f/attachment-0001.pl>

From andy_liaw at merck.com  Mon Apr  7 17:23:36 2014
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 7 Apr 2014 11:23:36 -0400
Subject: [R] rpart and randomforest results
In-Reply-To: <F935BF3EEA79BF45901A755531026E8344F42E40@WIWINF-EXDAG03.wiwinf.uni-due.de>
References: <F935BF3EEA79BF45901A755531026E8344F40E43@WIWINF-EXDAG03.wiwinf.uni-due.de>
	<CANOgrHaKRY+4ibQGisjRzmjpArMax6LPWDCL9JjhZ5TPYO98FQ@mail.gmail.com>
	<F935BF3EEA79BF45901A755531026E8344F42E40@WIWINF-EXDAG03.wiwinf.uni-due.de>
Message-ID: <D5FA03935F7418419332B61CA255F65FB4B5831996@USCTMXP51012.merck.com>

Hi Sonja,

How did you build the rpart tree (i.e., what settings did you use in rpart.control)?  Rpart by default will use cross validation to prune back the tree, whereas RF doesn't need that.  There are other more subtle differences as well.  If you want to compare single tree results, you really want to make sure the settings in the two are as close as possible.  Also, how did you compute the pseudo R2, on test set, or some other way?

Best,
Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Schillo, Sonja
Sent: Thursday, April 03, 2014 3:58 PM
To: Mitchell Maltenfort
Cc: r-help at r-project.org
Subject: Re: [R] rpart and randomforest results

Hi,

the random forest should do that, you're totally right. As far as I know it does so by randomly selecting the variables considered for a split (but here we set the option for how many variables to consider at each split to the number of variables available so that I thought that the random forest does not have the chance to randomly select the variables). The next thing that randomforest does is bootstrapping. But here again we set the option to the number of cases we have in the data set so that no bootstrapping should be done.
We tried to take all the "randomness" from the randomforest away.

Is that plausible and does anyone have another idea?

Thanks
Sonja


Von: Mitchell Maltenfort [mailto:mmalten at gmail.com]
Gesendet: Dienstag, 1. April 2014 13:32
An: Schillo, Sonja
Cc: r-help at r-project.org
Betreff: Re: [R] rpart and randomforest results


Is it possible that the random forest is somehow adjusting for optimism or overfitting?
On Apr 1, 2014 7:27 AM, "Schillo, Sonja" <Sonja.Schillo at uni-due.de<mailto:Sonja.Schillo at uni-due.de>> wrote:
Hi all,

I have a question on rpart and randomforest results:

We calculated a single regression tree using rpart and got a pseudo-r2 of roundabout 10% (which is not too bad compared to a linear regression on this data). Encouraged by this we grew a whole regression forest on the same data set using randomforest. But we got  pretty bad pseudo-r2 values for the randomforest (even sometimes negative values for some option settings).
We then thought that if we built only one single tree with the randomforest routine we should get a result similar to that of rpart. So we set the options for randomforest to only one single tree but the resulting pseudo-r2 value was negative aswell.

Does anyone have a clue as to why the randomforest results are so bad whereas the rpart result is quite ok?
Is our assumption that a single tree grown by randomforest should give similar results as a tree grown by rpart wrong?
What am I missing here?

Thanks a lot for your help!
Sonja

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}



From wdunlap at tibco.com  Mon Apr  7 17:35:53 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 7 Apr 2014 15:35:53 +0000
Subject: [R] skipping an error message
In-Reply-To: <CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>
References: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>
	<5341DA8A.1080602@bitwrit.com.au>
	<CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FABE8DC@PA-MBX01.na.tibco.com>

> Thanks for the suggestion. What I understand is trying something like
> 
> tryCatch(nlme(conc~f2(dose,Theta1,Theta
> 2,Theta3,t),
>  fixed=Theta1+Theta2+Theta3~1,
>  data=grouped.data,
>  random=Theta1+Theta2+Theta3~1,
>  start=list(fixed=ini.pkpara))
>             )
> 
> Is that correct?

No.

Executing tryCatch(someExpression) is equivalent to executing just
someExpression because you haven't set up any condition handlers.

If you did something like
   model.d <- tryCatch(nlme(blah blah blah), error=function(e)NULL)
then model.d would contain the return value of the call to nlme if
all went well and NULL otherwise.  You could then use
   if(!is.null(model.d)) {
       furtherProcessTheModel(model.d)
   }
to do things that only make sense when the model could  be fitted.

Now NULL may be a legitimate return value from a function and
it also doesn't give you any hint about what went wrong, so you could
have the error handler return an object of a class that no normal
function would return and have it contain the error message.  E.g.,
   model.d <- tryCatch(nlme(notAFormula),
                             error=function(e)structure(conditionMessage(e),class="ERROR"))
and then you can test for errors with
   if (inherits(model.d, "ERROR")) {
       message("Iteration ", i, "failed with error: ", model.d)
   } else {
       furtherProcessTheModel(model.d)
   }
You could also look at the error message that model.d contains in that case.

The try() function is essentially that call to tryCatch: it gives its error output
the class 'try-error'.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Naser Jamil
> Sent: Monday, April 07, 2014 1:46 AM
> To: Jim Lemon
> Cc: R help
> Subject: Re: [R] skipping an error message
> 
> Hi Jim,
> Thanks for the suggestion. What I understand is trying something like
> 
> tryCatch(nlme(conc~f2(dose,Theta1,Theta
> 2,Theta3,t),
>  fixed=Theta1+Theta2+Theta3~1,
>  data=grouped.data,
>  random=Theta1+Theta2+Theta3~1,
>  start=list(fixed=ini.pkpara))
>             )
> 
> Is that correct?
> 
> Once again thanks.
> 
> Regards,
> Jamil.
> 
> 
> On 6 April 2014 23:51, Jim Lemon <jim at bitwrit.com.au> wrote:
> 
> > On 04/06/2014 08:21 PM, Naser Jamil wrote:
> >
> >> Dear R-user,
> >> May I seek your suggestion on an issue. I'm fitting non-linear mixed
> >> effects
> >> model as a part of my large R program. But sometimes I get error messages
> >> from it and the code stops working. In such cases, I want to skip the
> >> iterations and
> >> want to move to the next iteration ignoring all the subsequent
> >> computations.
> >>
> >> The following is only that part of the code which fits the mixed effects
> >> model. I tried with "tryCatch" as shown below, but it's not serving my
> >> purpose. I guess something is wrong in my approach.
> >>
> >> ###########################################################
> >>
> >> grouped.data<-groupedData(formula = conc ~ t | subject,
> >> data = data.d)
> >> model.d<-nlme(conc~f2(dose,Theta1,Theta2,Theta3,t),
> >> fixed=Theta1+Theta2+Theta3~1,
> >> data=grouped.data,
> >> random=Theta1+Theta2+Theta3~1,
> >> start=list(fixed=ini.pkpara))
> >> summ<-summary(model.d) # summary of the model
> >>
> >> tryCatch(summ, error = function() next)
> >>
> >> ###########################################################
> >>
> >>  Hi Jamil,
> > I think you have to pass the expression:
> >
> > nlme(conc~f2(dose,Theta1,Theta2,Theta3,t),
> >  fixed=Theta1+Theta2+Theta3~1,
> >  data=grouped.data,
> >  random=Theta1+Theta2+Theta3~1,
> >  start=list(fixed=ini.pkpara))
> >
> > not the result of the expression.
> >
> > Jim
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Mon Apr  7 17:51:10 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 07 Apr 2014 08:51:10 -0700
Subject: [R] R script on Rstudio server
In-Reply-To: <CAOeUc7s4se90j=2RjU7jomCjfxTEXkFXrLjPXjU383k63_NDcQ@mail.gmail.com>
References: <CAOeUc7s4se90j=2RjU7jomCjfxTEXkFXrLjPXjU383k63_NDcQ@mail.gmail.com>
Message-ID: <4c7da938-27bc-4413-a04f-1e6a015545f1@email.android.com>

Please read the Posting Guide. RStudio has a support forum of their own, and you should post in plain text.

That said, RStudio Server is just a user interface for the R software installed on the server it runs on. This is a great place to ask questions about R, but not about how to add memory to a server. You should try some smaller data sets to get an idea of how much memory you need, and if it is not practical then there are database approaches that can use more disk and less RAM. The drawback is that you usually have to adapt your algorithms to those approaches.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 7, 2014 12:01:49 AM PDT, T Bal <studenttbal at gmail.com> wrote:
>Hi,
>I want to install Rstudio server. The reason for that is that I want to
>run
>R script on this server. In this R script I am loading (working with)
>very
>large data with size 1000 Mb. When I run this R script I get memory
>error.
>If I run this script on Rstudio server, will I not have this problem?
>Can
>Rstudio Serve solve this (memory, size) problem?
>Thanks!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From sdurier.stat at gmail.com  Mon Apr  7 17:56:35 2014
From: sdurier.stat at gmail.com (=?ISO-8859-1?Q?S=E9bastien_Durier?=)
Date: Mon, 7 Apr 2014 17:56:35 +0200
Subject: [R] average of rows of each column
In-Reply-To: <BLU170-W7435881A2743C3961133EB896F0@phx.gbl>
References: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
	<002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>
	<BLU170-W7435881A2743C3961133EB896F0@phx.gbl>
Message-ID: <CAOQbXv7pj52AA6PD4tymh_FxmA_2YJrqmQvvV71e8CPc+1p-kA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/301accca/attachment-0001.pl>

From dwinsemius at comcast.net  Mon Apr  7 18:09:41 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 7 Apr 2014 09:09:41 -0700
Subject: [R] Base within reverses column order
In-Reply-To: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>
References: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>
Message-ID: <070427D2-6791-4470-9A56-8EE1EFB6B615@comcast.net>


On Apr 4, 2014, at 10:32 AM, Dan Murphy wrote:

> I just noticed this annoyance, but I'm not the first one, apparently
> -- see http://lists.r-forge.r-project.org/pipermail/datatable-help/2012-May/001176.html
> 
> The thread never answered the OP's question "Is this a bug?" so I
> assume the answer, unfortunately, is No.
> 

Well, using `within` outside of data,table objects is not really the "true" data-table way, is it?

DT= data.table(a=1:10, b=2:11)
> DT[ , ( c("c","d") ) := .SD[, list(a+b,a*b)] ]
> DT
     a  b  c   d
 1:  1  2  3   2
 2:  2  3  5   6
 3:  3  4  7  12
 4:  4  5  9  20
 5:  5  6 11  30
 6:  6  7 13  42
 7:  7  8 15  56
 8:  8  9 17  72
 9:  9 10 19  90
10: 10 11 21 110

(This answer was from Simon O'Hanlon on SO: http://stackoverflow.com/questions/16943939/elegantly-assigning-multiple-columns-in-data-table-with-lapply/16944343#16944343

Inside `[.data.table` expressions are handled without initial evaluation and sometimes `eval` needs to be called directly. Evaluation is deferred in many instances, but arguably closer to "computing on the language" than when using interactive R. The .SD object is the data.table self-reference mechanism so the `a+b` and the `a*b` are evaluated in the context of the column names of DT. And `:=` is a special data.table assignment function that avoids constructing multiple copies of data.table objects during column binding.


> If not a bug, do users of within have a workaround to produce a result
> with columns as ordered within 'within'? I can think of a way using
> names and subset-with-select, but that seems unduly kludgy.

data.table users would think your `within` approach was suspicious if not also kludgey. It would be an end run around the package's syntacical modifications and it may lose the space efficiencies that data.table offers.

-- 

David Winsemius
Alameda, CA, USA



From dcarlson at tamu.edu  Mon Apr  7 18:10:16 2014
From: dcarlson at tamu.edu (dcarlson at tamu.edu)
Date: Mon, 7 Apr 2014 11:10:16 -0500
Subject: [R] average of rows of each column
In-Reply-To: <002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>
References: <BLU170-W13722AA8070BCB400A08A29896F0@phx.gbl>
	<002801cf5042$7e06eb40$7a14c1c0$@tamu.edu>
Message-ID: <01ae01cf527b$dd2c3270$97849750$@tamu.edu>

Actually how about 1:30pm today. I'm on Alvard's Jobinar panel
from 12:30-1:30pm.

David

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David Carlson
Sent: Friday, April 4, 2014 3:15 PM
To: 'eliza botto'; r-help at r-project.org
Subject: Re: [R] average of rows of each column

Something like (only 20 columns here):

x <- matrix(rnorm(120*20), 120, 20)
xagg <- aggregate(x, list(rep(1:12, each=10)), mean)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of eliza botto
Sent: Friday, April 4, 2014 1:08 PM
To: r-help at r-project.org
Subject: [R] average of rows of each column


Dear useRs,
I have a matrix of 120 row and 1000 columns.What I want is to
get an average of a set of 12 rows starting from 1 till 120 for
each column. Precisely, for column 1 the average of 1:10 rows,
11:20 rows.... 111:120. similarly for column 2, 3, 4.... 1000.
So in the end i should have a matrix with 12 rows and 1000
columns.
Thankyou very much in advance.

Eliza
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From boris.steipe at utoronto.ca  Mon Apr  7 18:14:08 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 7 Apr 2014 12:14:08 -0400
Subject: [R] Micro-point with pch=16?
In-Reply-To: <5342BDA7.5030601@acdlabs.ru>
References: <534246CE.9050606@acdlabs.ru> <534266FA.5000707@bitwrit.com.au>
	<534286EE.1040300@acdlabs.ru>
	<E325AD02-441F-4776-9B71-516EAD15A797@utoronto.ca>
	<5342BDA7.5030601@acdlabs.ru>
Message-ID: <61F29C65-FDC5-4221-94A4-AB32F31A9EE8@utoronto.ca>

The semantics of R svg output are quite simple. The points (drawn as pch=16) are each in a single <path ... /> element in one line, drawn as two cubic Bezier curves with absolute coordinates (cf. http://www.w3.org/TR/SVG11/paths.html#PathDataCubicBezierCommands).

(example: linebreaks and indents for clarity)
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;" 
  d="
    M 397.640625 528.933594 
    C 397.640625 532.53125 392.238281 532.53125 392.238281 528.933594 
    C 392.238281 525.332031 397.640625 525.332031 397.640625 528.933594
    "
/>

Every C element specifies a curve going from the last previous point to a next point, subject to two control points. Here, the first point is (397.640625, 528.933594) and the second point is (392.238281, 528.933594). Therefore ((397.640625 + 392.238281)/2, (528.933594 + 528.933594/2)) is the centre of the circle and abs(397.640625 - 392.238281) is its diameter.

You could:
 - encode the range of properties you want in some way in the plot symbol 
   e.g. size as the log of the ratio, or encoding it into the color
 - process the svg file, identify the path elements
 - calculate center and desired size
 - replace the path element of the svg with an appropriate circle 
   (see http://www.w3.org/TR/SVG11/shapes.html#CircleElement)

---
Perhaps though, since all you want to do is to encode Z distance, applying transparency would achieve a comparable effect (see: ?rgb ).

Cheers,
B.






On 2014-04-07, at 11:00 AM, ?????? ????????? wrote:

> 07.04.2014 18:53, Boris Steipe ?????:
>> Since you won't be able to see the effect on-screen, how about a little script that post-processes the SVG?
>> B.
> 
> It would be the way-to-go, but I'm not sure how to
> 1) determine which point corresponds to which element in svg file,
> 2) modify those mysterious path elements.
> 
> Probably there is a way to monkey-patch some internal procedure?
> 
> Best wishes,
> Andrey Paramonov
> 
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 



From lmramba at ufl.edu  Mon Apr  7 18:12:54 2014
From: lmramba at ufl.edu (Laz)
Date: Mon, 07 Apr 2014 12:12:54 -0400
Subject: [R] Adding correlation and or variance structure in mixed models
Message-ID: <5342CE86.5080007@ufl.edu>

Dear R users,

I am using mixed models to analyze genetic experiments. I have tried to 
use R packages such as lme4, nlme. I am looking for a model that can 
allow me to specify my correlation structure and the same time allow to 
have more than 2 random effects in the model. None of the above packages 
fully answer  my question and some results obtained have incorrect  
degrees of freedom at some point.

For example: Y = XB + Z1g + Z2f + e
where X is the design matrix of fixed effect, B is the vector of fixed 
effect, Z1 is a random design matrix of the first random variable,g,  
and g is the vector of the random effect g, Z2 is random design matrix 
of the second random variable,  and f is a vector of the random effect 
f., e is the residual error.
If I need to specify an autocorrelation structure such as AR1 
(autocorrelation 1st order) or CORG (general correlation) how would I do 
that in R? the functions provided do not allow to specify this term 
except the gls but it does not take random effects.


I am interested in specifying variance structures such as AR1V 
(autocorrelation 1st order), diagonal, uniform heterogeneous, uniform 
correlation, Unstrustured etc in my model that has both fixed and 
several random effects. Which R packages or functions will help me to 
accomplish this?


Thanks.
Laz



From macqueen1 at llnl.gov  Mon Apr  7 18:30:41 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 7 Apr 2014 16:30:41 +0000
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1396304717602-4687917.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>
Message-ID: <CF682023.F262C%macqueen1@llnl.gov>

If you want to customize tick mark labels, use the axis() function.

Something along the lines of

plot(x,y, xaxt='n')
xat <- pretty(x)
axis(1, at=xat, labels=1/xat)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/31/14 3:25 PM, "Hurr" <hill0093 at umn.edu> wrote:

>How can I label existing axis tick marks with a
>simple function of axis value like 1/AxisValue?
>It seems like this should be an operation where
>I just use the formula.
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function
>-of-axis-value-tp4687917.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From timmarcella at gmail.com  Mon Apr  7 18:36:02 2014
From: timmarcella at gmail.com (Tim Marcella)
Date: Mon, 7 Apr 2014 09:36:02 -0700
Subject: [R] Time interactions for coxph object
Message-ID: <CAGbJzAL295uHvywfn+NAgak9ZeeE=tDwwu4mD_GZvg8tbev1DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/e4bf5329/attachment-0001.pl>

From paramon at acdlabs.ru  Mon Apr  7 17:00:55 2014
From: paramon at acdlabs.ru (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Mon, 07 Apr 2014 19:00:55 +0400
Subject: [R] Micro-point with pch=16?
In-Reply-To: <E325AD02-441F-4776-9B71-516EAD15A797@utoronto.ca>
References: <534246CE.9050606@acdlabs.ru> <534266FA.5000707@bitwrit.com.au>
	<534286EE.1040300@acdlabs.ru>
	<E325AD02-441F-4776-9B71-516EAD15A797@utoronto.ca>
Message-ID: <5342BDA7.5030601@acdlabs.ru>

07.04.2014 18:53, Boris Steipe ?????:
> Since you won't be able to see the effect on-screen, how about a little script that post-processes the SVG?
> B.

It would be the way-to-go, but I'm not sure how to
1) determine which point corresponds to which element in svg file,
2) modify those mysterious path elements.

Probably there is a way to monkey-patch some internal procedure?

Best wishes,
Andrey Paramonov


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From marc_grt at yahoo.fr  Mon Apr  7 19:22:17 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 07 Apr 2014 19:22:17 +0200
Subject: [R] Changes between R 3.1 vs 3.0.3
Message-ID: <5342DEC9.6010501@yahoo.fr>

If there a list of changes between 3.1 and 3.0.3 ?

For example, when using levels(xxxx), if xxxx was not a factor, in 3.0.3 
it was changed as a factor but in 3.1 RC it returns NULL.
Same for automatic conversion in numeric for characters used in algebric 
operations.

New way is more strict and is better in my point of view. It will 
prevent unwanted side effect in code.

Thanks a lot

Marc Girondot



From bogaso.christofer at gmail.com  Mon Apr  7 19:49:09 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 7 Apr 2014 23:34:09 +0545
Subject: [R] Getting a particular weekday for a given month
Message-ID: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/8cdbedc4/attachment-0001.pl>

From istazahn at gmail.com  Mon Apr  7 19:58:17 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 7 Apr 2014 13:58:17 -0400
Subject: [R] Changes between R 3.1 vs 3.0.3
In-Reply-To: <5342DEC9.6010501@yahoo.fr>
References: <5342DEC9.6010501@yahoo.fr>
Message-ID: <CA+vqiLHH11Kn6Nw_0WoD=Pv_0WW8v4EwA3YDSDf55FOuzNMHAw@mail.gmail.com>

I would have thought a web search for "R devel changelog" would get
you to the right place... Google gives me
developer.r-project.org/blosxom.cgi/R-devel/NEWS as the first hit,
which looks about right.

best,
Ista

On Mon, Apr 7, 2014 at 1:22 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> If there a list of changes between 3.1 and 3.0.3 ?
>
> For example, when using levels(xxxx), if xxxx was not a factor, in 3.0.3 it
> was changed as a factor but in 3.1 RC it returns NULL.
> Same for automatic conversion in numeric for characters used in algebric
> operations.
>
> New way is more strict and is better in my point of view. It will prevent
> unwanted side effect in code.
>
> Thanks a lot
>
> Marc Girondot
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Mon Apr  7 20:23:55 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 7 Apr 2014 14:23:55 -0400
Subject: [R] Getting a particular weekday for a given month
In-Reply-To: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
References: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
Message-ID: <20EC3EBD-51F3-49A1-A8D5-CBAEFFC299DE@utoronto.ca>

Something like:

# the third Wednesday
m <- as.Date("2014-04-01")
format(m+which(format(m+0:30,"%a") == "Wed")[3]-1, "%a %b %d")

# or eg. all Tuesdays
format(m+which(format(m+0:30,"%a") == "Tue")-1, "%a %b %d")

# or eg. the last Friday
wd <- which(format(m+0:30,"%a") == "Fri")-1
format(m+wd[length(wd)], "%a %b %d")



Note: adding integers to your "Month" increments months, not days
Cheers,
B.





On 2014-04-07, at 1:49 PM, Christofer Bogaso wrote:

> Hi,
> 
> Given a month name, I am looking for some script to figure out, what is the
> date for 3rd Wednesday. For example let say I have following month:
> 
> library(zoo)
> Month <- as.yearmon(as.Date(Sys.time()))
> 
> I need to answer: What is the date for 3rd Wednesday of 'Month'?
> 
> Really appreciate for any pointer.
> 
> Thanks for your time.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Mon Apr  7 20:28:30 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Apr 2014 14:28:30 -0400
Subject: [R] Changes between R 3.1 vs 3.0.3
In-Reply-To: <5342DEC9.6010501@yahoo.fr>
References: <5342DEC9.6010501@yahoo.fr>
Message-ID: <5342EE4E.2090101@gmail.com>

On 07/04/2014 1:22 PM, Marc Girondot wrote:
> If there a list of changes between 3.1 and 3.0.3 ?

If you have 3.1.0rc installed, look in the HTML help system for the NEWS 
item.  If you don't have it installed, a copy of the nightly news is on 
CRAN under "new features in this version" on 
<http://cran.r-project.org/bin/windows/base/rtest.html>.  (The actual 
URL changes sometimes; currently it is 
<http://cran.r-project.org/bin/windows/base/NEWS.R-3.1.0rc.html>.)

The RSS feed that Ista pointed you to will tell you about changes to 
that file (i.e. sort of second differences to R).

Duncan Murdoch

>
> For example, when using levels(xxxx), if xxxx was not a factor, in 3.0.3
> it was changed as a factor but in 3.1 RC it returns NULL.
> Same for automatic conversion in numeric for characters used in algebric
> operations.
>
> New way is more strict and is better in my point of view. It will
> prevent unwanted side effect in code.
>
> Thanks a lot
>
> Marc Girondot
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From Ted.Harding at wlandres.net  Mon Apr  7 20:29:45 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Mon, 07 Apr 2014 19:29:45 +0100 (BST)
Subject: [R] Getting a particular weekday for a given month
In-Reply-To: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
Message-ID: <XFMail.20140407192945.Ted.Harding@wlandres.net>

On 07-Apr-2014 17:49:09 Christofer Bogaso wrote:
> Hi,
> Given a month name, I am looking for some script to figure out,
> what is the date for 3rd Wednesday. For example let say I have
> following month:
> 
> library(zoo)
> Month <- as.yearmon(as.Date(Sys.time()))
> 
> I need to answer: What is the date for 3rd Wednesday of 'Month'?
> 
> Really appreciate for any pointer.
> 
> Thanks for your time.

The following may not suit you, but it the sort of approach I tend
to adopt myself, using things I know about rather than getting lost
in R documentation! (Outline of general method, not details). And it
also assumes you are using a Unixoid system (e.g. Linux or Mac OS2).

Your two commands currently give:

  library(zoo)
  Month <- as.yearmon(as.Date(Sys.time()))
  Month
  # [1] "Apr 2014"

and it is straightforward to extract "Apr" and "2014" from Month.

This is the point at which I attach my horses to my wooden plough ...

In Unixoid systems there is a command 'cal' which, for "2014",
yields output:

$ cal 2014
                             2014                              

      January               February               March        
Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su
       1  2  3  4  5                  1  2                  1  2
 6  7  8  9 10 11 12   3  4  5  6  7  8  9   3  4  5  6  7  8  9
13 14 15 16 17 18 19  10 11 12 13 14 15 16  10 11 12 13 14 15 16
20 21 22 23 24 25 26  17 18 19 20 21 22 23  17 18 19 20 21 22 23
27 28 29 30 31        24 25 26 27 28        24 25 26 27 28 29 30
                                            31                  
       April                  May                   June        
Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su
    1  2  3  4  5  6            1  2  3  4                     1
 7  8  9 10 11 12 13   5  6  7  8  9 10 11   2  3  4  5  6  7  8
14 15 16 17 18 19 20  12 13 14 15 16 17 18   9 10 11 12 13 14 15
21 22 23 24 25 26 27  19 20 21 22 23 24 25  16 17 18 19 20 21 22
28 29 30              26 27 28 29 30 31     23 24 25 26 27 28 29
                                            30                  
        July                 August              September      
Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su
    1  2  3  4  5  6               1  2  3   1  2  3  4  5  6  7
 7  8  9 10 11 12 13   4  5  6  7  8  9 10   8  9 10 11 12 13 14
14 15 16 17 18 19 20  11 12 13 14 15 16 17  15 16 17 18 19 20 21
21 22 23 24 25 26 27  18 19 20 21 22 23 24  22 23 24 25 26 27 28
28 29 30 31           25 26 27 28 29 30 31  29 30               
                                                                
      October               November              December      
Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su
       1  2  3  4  5                  1  2   1  2  3  4  5  6  7
 6  7  8  9 10 11 12   3  4  5  6  7  8  9   8  9 10 11 12 13 14
13 14 15 16 17 18 19  10 11 12 13 14 15 16  15 16 17 18 19 20 21
20 21 22 23 24 25 26  17 18 19 20 21 22 23  22 23 24 25 26 27 28
27 28 29 30 31        24 25 26 27 28 29 30  29 30 31            

After the first two lines, this consists of 4 blocks, each with 8 rows,
each covering 3 months where each month consists of 7 columns, one
for each day of the week (Mo - Su). Each column occupies 3 character
spaces (excpet for the last -- only 2).

>From "April" you can readily identify that this is the 4th month,
so you need to go to Month 1 of the 2nd block of rows. The "We"
column is the 3rd in that month, and you are looking for the
date of the 3rd Wednesday. So count down to the 3rd non-blank
entry[*] in this 3rd column, and you will find "16". Done.

[*] Some months, e.g. November above, have an initial blank
entry because this day belongs to the previous month.

Quite how you would program this efficiently in R is another matter!
But the principle is simple. To give R a text file to work on, at the
shell prompt use a command like:

$ cal 2014 > cal2014.txt

and then "cal2014.txt" is accessible as a plain text file.

Even simpler (if it is only one particular month you want,
as in your example) is:

$ cal April 2014

which yields:

     April 2014     
Mo Tu We Th Fr Sa Su
    1  2  3  4  5  6
 7  8  9 10 11 12 13
14 15 16 17 18 19 20
21 22 23 24 25 26 27
28 29 30            

and now just count down the 3rd column (as before).

Maybe this helps ...
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 07-Apr-2014  Time: 19:29:41
This message was sent by XFMail



From murdoch.duncan at gmail.com  Mon Apr  7 20:33:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Apr 2014 14:33:08 -0400
Subject: [R] Base within reverses column order
In-Reply-To: <CAHgH9_GLNVC-3h7=GMUX2GnF0c=1wsSijFrPEicvOTAW+TAAfw@mail.gmail.com>
References: <CAHgH9_ECDDaRYbuSDnz+kRX_nzNRE4zd3G7oRU87NcZGvGTCEQ@mail.gmail.com>	<533EF20A.6010500@gmail.com>
	<CAHgH9_GLNVC-3h7=GMUX2GnF0c=1wsSijFrPEicvOTAW+TAAfw@mail.gmail.com>
Message-ID: <5342EF64.8030501@gmail.com>

On 05/04/2014 1:10 PM, Dan Murphy wrote:
> Thanks, Duncan. Using names is certainly the most reliable solution,
> but requires remembering to modify the "surrounding code" when
> enhancing what's within -- a bug risk source when passing on the code.
> Are you saying that an automatic reversal as follows may break in the
> future because R-devel may change the current behavior of 'within'?

I'm saying that there might already be cases where that code breaks.
> (If so, then that's the greater source of bug risk .. so back to
> 'names'.)
>
> ln <- length(foo)
> foo <- within(foo, {
>    bar <- whatever
>    other()
>    })
> foo <- foo[c(1:ln, length(foo):(ln+1))] # to reverse within's assumed
> backwards column order
>
> Is there a way to capture the names of new objects created within?

Sure, something ike this should work:

oldvars <- names(foo)
foo <- within(foo, {...})
newvars <- setdiff(names(foo), oldvars)

There might also be changes to the oldvars; within doesn't just add 
columns, it can modify existing ones.

Duncan Murdoch

>
>
> On Fri, Apr 4, 2014 at 10:55 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 04/04/2014 1:32 PM, Dan Murphy wrote:
> >>
> >> I just noticed this annoyance, but I'm not the first one, apparently
> >> -- see
> >> http://lists.r-forge.r-project.org/pipermail/datatable-help/2012-May/001176.html
> >>
> >> The thread never answered the OP's question "Is this a bug?" so I
> >> assume the answer, unfortunately, is No.
> >>
> >> If not a bug, do users of within have a workaround to produce a result
> >> with columns as ordered within 'within'? I can think of a way using
> >> names and subset-with-select, but that seems unduly kludgy.
> >
> >
> > I wouldn't be surprised if it is not consistent about that.  It uses as.list
> > to convert an environment to a list, and that's where the reversal occurs:
> > but since environments are unordered collections of objects, you just happen
> > to be seeing an undocumented and unpromised property of the internal
> > implementation.
> >
> > If the order matters to you, then create your initial dataframe with the new
> > variables (set to NA, for example), or reorder it afterwards.  But generally
> > speaking even in a dataframe (which is an ordered collection of objects),
> > it's better to program in a way that doesn't make assumptions about the
> > order.  Columns have names, and you should use those.
> >
> > Duncan Murdoch



From ggrothendieck at gmail.com  Mon Apr  7 20:45:30 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 7 Apr 2014 14:45:30 -0400
Subject: [R] Getting a particular weekday for a given month
In-Reply-To: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
References: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
Message-ID: <CAP01uR=Vx1KeRxA-kWxSZHK4Je3dfHaOmfXKhYxE7+j3bG8MPg@mail.gmail.com>

On Mon, Apr 7, 2014 at 1:49 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi,
>
> Given a month name, I am looking for some script to figure out, what is the
> date for 3rd Wednesday. For example let say I have following month:
>
> library(zoo)
> Month <- as.yearmon(as.Date(Sys.time()))
>
> I need to answer: What is the date for 3rd Wednesday of 'Month'?
>
> Really appreciate for any pointer.
>

In the zoo quickref vignette is a one line nextfri function which can
easily be converted to a nextwed function.  Note that the code below
requires zoo to be loaded as in the first line:

library(zoo)
d <- Sys.Date()
d <- as.Date(cut(d, "month")) # can omit if d is already 1st of month
nextwed <- function(x) 7 * ceiling(as.numeric(x-3+4) / 7) + as.Date(3-4)
nextwed(d) + 14

The last line gives:

[1] "2014-04-16"

Note that this approach is vectorized and continues to work if d is a
Date class vector.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From jamilnaser79 at gmail.com  Mon Apr  7 23:21:42 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Mon, 7 Apr 2014 22:21:42 +0100
Subject: [R] skipping an error message
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FABE8DC@PA-MBX01.na.tibco.com>
References: <CAJK=5YmKqk1nTV2b7EUgzBcb+_dhv0YNrXE5QNkN0V_7hRJWoQ@mail.gmail.com>
	<5341DA8A.1080602@bitwrit.com.au>
	<CAJK=5Ym-gQLr0YJi+Dm6787hoSKnMuQds2Trfdk_BwB9u3SgXg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FABE8DC@PA-MBX01.na.tibco.com>
Message-ID: <CAJK=5YkCYK3iQt49TBzBhUmG2NN_fbR36j4=_SjHRZnOKPXPBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/cfaa428d/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Tue Apr  8 00:05:20 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 07 Apr 2014 15:05:20 -0700
Subject: [R] getting arg names in function calls?
Message-ID: <53432120.9050500@structuremonitoring.com>

       How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?


       More generally, how can I get argument names assigned to function 
calls in "language" objects?


       Example:


tstFn <- function()plot(0, 1)
bo <- body(tstFn)


tstFnxy <- function()plot(x=0, y=1)
boxy <- body(tstFnxy)


       Is there a function that will modify "bo" to match "boxy"?


       My current solution requires me to know the names of the 
arguments for "plot" (in this example).  I'd prefer a more general 
solution.


       Thanks,
       Spencer


p.s.  I'm trying to create an animation by repeatedly calling a function 
that contains something like text(0, 1, "abc").  By computing on the 
language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the 
first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the 
third.  The function will be more general if I can get the names of the 
arguments as just described.



From wdunlap at tibco.com  Tue Apr  8 00:18:43 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 7 Apr 2014 22:18:43 +0000
Subject: [R] getting arg names in function calls?
In-Reply-To: <53432120.9050500@structuremonitoring.com>
References: <53432120.9050500@structuremonitoring.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>

Look at match.call().  E.g.,
  > f <- function(x, y = log2(x), ...) match.call()
  > f()
  f()
  > f(1, x=2, anotherArg=3, 4)
  f(x = 2, y = 1, anotherArg = 3, 4)
or, using its 'definition' and 'call' arguments directly
  > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)))
  foo(x = 2, y = 1, extraArg = 3, 4)
  > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)), expand.dots=FALSE)
  foo(x = 2, y = 1, ... = list(extraArg = 3, 4))

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Spencer Graves
> Sent: Monday, April 07, 2014 3:05 PM
> To: R list
> Subject: [R] getting arg names in function calls?
> 
>        How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?
> 
> 
>        More generally, how can I get argument names assigned to function
> calls in "language" objects?
> 
> 
>        Example:
> 
> 
> tstFn <- function()plot(0, 1)
> bo <- body(tstFn)
> 
> 
> tstFnxy <- function()plot(x=0, y=1)
> boxy <- body(tstFnxy)
> 
> 
>        Is there a function that will modify "bo" to match "boxy"?
> 
> 
>        My current solution requires me to know the names of the
> arguments for "plot" (in this example).  I'd prefer a more general
> solution.
> 
> 
>        Thanks,
>        Spencer
> 
> 
> p.s.  I'm trying to create an animation by repeatedly calling a function
> that contains something like text(0, 1, "abc").  By computing on the
> language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the
> first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the
> third.  The function will be more general if I can get the names of the
> arguments as just described.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bbolker at gmail.com  Tue Apr  8 00:31:00 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 Apr 2014 22:31:00 +0000
Subject: [R] Adding correlation and or variance structure in mixed models
References: <5342CE86.5080007@ufl.edu>
Message-ID: <loom.20140408T002742-450@post.gmane.org>

Laz <lmramba <at> ufl.edu> writes:

> 
> Dear R users,
> 
> I am using mixed models to analyze genetic experiments. I have tried to 
> use R packages such as lme4, nlme. I am looking for a model that can 
> allow me to specify my correlation structure and the same time allow to 
> have more than 2 random effects in the model. None of the above packages 
> fully answer  my question and some results obtained have incorrect  
> degrees of freedom at some point.
> 
> For example: Y = XB + Z1g + Z2f + e
> where X is the design matrix of fixed effect, B is the vector of fixed 
> effect, Z1 is a random design matrix of the first random variable,g,  
> and g is the vector of the random effect g, Z2 is random design matrix 
> of the second random variable,  and f is a vector of the random effect 
> f., e is the residual error.
> If I need to specify an autocorrelation structure such as AR1 
> (autocorrelation 1st order) or CORG (general correlation) how would I do 
> that in R? the functions provided do not allow to specify this term 
> except the gls but it does not take random effects.
> 
> I am interested in specifying variance structures such as AR1V 
> (autocorrelation 1st order), diagonal, uniform heterogeneous, uniform 
> correlation, Unstrustured etc in my model that has both fixed and 
> several random effects. Which R packages or functions will help me to 
> accomplish this?
> 
> Thanks.
> Laz

   The lme() function in the nlme package allows you to do some but
not necessarily all of this, and is I think the closest you will get.
If by "more than one random effect" you mean *crossed* (as opposed to
nested) random effects, that will be a little more difficult, but it
is possible in lme: see Pinheiro and Bates 2000 p. 163.  

  For more information/detail you should ask this question at
r-sig-mixed-models at r-project.org , but it would be a good idea to
invest in a copy of Pinheiro and Bates 2000 and find out as much
as you can for yourself first.

  Ben Bolker



From christianvanbrauner at gmail.com  Tue Apr  8 00:59:43 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Tue, 8 Apr 2014 00:59:43 +0200
Subject: [R] Question: Do I need to set refit=FALSE when testing for
 random effects with anova()?
Message-ID: <CALNVzyB1mMpqc=M0-L8inoRR3rf9LBHhiw=7fqUiCayaCkSdLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/9dc48f3e/attachment-0001.pl>

From smartpink111 at yahoo.com  Tue Apr  8 02:16:44 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Apr 2014 17:16:44 -0700 (PDT)
Subject: [R] How to use an elements' name when creating a data frame via
	a for loop
In-Reply-To: <1396881718.12551.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1396868344.64268.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1396881718.12551.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1396916204.63229.YahooMailNeo@web142602.mail.bf1.yahoo.com>





Hi,

It is not clear what you really want.? Now, you mentions ?merge() etc.? If you don't want to use ?assign(),

lst <- list(as.data.frame(matrix(1:40,ncol=5)), as.data.frame(matrix(1:20,ncol=4)), as.data.frame(matrix(1:25,ncol=5)),as.data.frame(matrix(21:30,ncol=2)))

?stations <- c("BETB011", "BETM204", "BETN029","BETN043")
?names(lst) <- paste(stations, "PM",sep="_") 
head(lst$BETB011_PM,2)
# V1 V2 V3 V4 V5
# 1  1  9 17 25 33
# 2  2 10 18 26 34 

#or
attach(lst) #not recommended.? 


head(BETB011_PM,2)
# V1 V2 V3 V4 V5?
#1? 1? 9 17 25 33?
#2? 2 10 18 26 34 


A.K.


Hello, 
thank you for your answer. I think its already a little too advanced for me. 
I would appreciate if you would just give me a hint to the construction of the several data frames (so maybe without the assign function). 
i can merge the other data frames via the merge function, so thats not an issue for me at the moment. 
But in order to merge the data it would be handy to create the data frames upfront. 
Therefore, a for loop would be nice that simply creates data frames for every station in the station data frame and names them accordingly. 
I assume its sth like? stations <- c("BETB011", "BETM204", "BETN029","BETN043") 
for (i in 1:length(stations) 
{[i] <- data.frame(stations[i])}? Would be nice then to have 4 data.frames named BETB011, BETM204, BETN29, BETN043 or even better 
BETB011_PM, BETM204_PM, ... 
But unfortunately this does not work.





On Monday, April 7, 2014 6:59 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

May be this helps:
stations <- LETTERS[1:4]
set.seed(42)
PM2.5 <- data.frame(DateTime=seq(as.POSIXct("2010-01-10 01:00:00"),length.out=10,by= "1 day"), station= sample(LETTERS[1:4],10,replace=TRUE))
for(i in 1:length(stations))
assign(paste(stations[i],"PM",sep="_"),subset(PM2.5,station==stations[i])) 

A_PM 

#? ? ? ? ? ?? DateTime station
#8 2010-01-17 01:00:00 A

D_PM
#? ? ? ? ? ?? DateTime station
#1 2010-01-10 01:00:00 D 

#2 2010-01-11 01:00:00? ? ?? D
#4 2010-01-13 01:00:00? ? ?? D 


A.K.

Hey, I got a question that bugs me for a longer time now.? I want to create several data.frames via a for loop that is applied to the elements of a vector.
And I want to use the names of the elements in the name of the created data.frames. Is that possible?
Im confused with the coding there ... Should look something like this:?? for (i in 1:length(stations)) {stations[i]_PM <- data.frame(PM2.5$DateTime,PM2.5$stations[i])} The result should be several dataframes (length of stations) with the name StationID_PM.
Should I use the paste function?? Thank you very much. Hopefuly, I explained myself well enough. Dolby



From johnwilliams at fas.harvard.edu  Tue Apr  8 02:29:59 2014
From: johnwilliams at fas.harvard.edu (John Williams)
Date: Mon, 7 Apr 2014 17:29:59 -0700 (PDT)
Subject: [R] {metafor} variance explaination for paired pre-test/posttest
Message-ID: <1396916999280-4688365.post@n4.nabble.com>

In a previous post
https://stat.ethz.ch/pipermail/r-help/2012-April/308946.html
<https://stat.ethz.ch/pipermail/r-help/2012-April/308946.html>  , the
following calculation was given for imputing the variance of change scores
for paired studies:

// begin quote

2) Often, the dependent variable is not the same in each study. Then you
will have to resort to a standardized outcome measure. There are two
options:

a) standardization based on the change score standard deviation

Then yi = (m1i - m2i) / sdi with sampling variance vi = 1/ni + yi^2 /
(2*ni).

// end quote

I used the sampling variance equation above in a paper that is being
reviewed by a coauthor, who is a biostatistician. 

He commented that he has never seen this equation for variance before, and
it looks strange to him. To put my knowledge into perspective, I am an
undergraduate taking my first statistics course. I imputed the t-statistic
from two-sided p-values reported in the paper, and used that to get the sdi
(as in the previous post). 

I consulted the Cochrane Handbook and The Handbook of Research Syntheses and
Meta-analysis 2nd Ed (Cooper, Hedges, Valentine 2009) and couldn't find that
equation anywhere. 

Would Prof. Viechtbauer, or anyone else knowledgeable, mind explaining the
sample variance above? I need to be able to defend my choice of equation.
Since it's the only method that I found that doesn't rely on a correlation
coefficient (which are not included in the papers), I'd like to be able to
justify it and not redo calculations for 23 studies if possible.

Thank you very much,

John

~~~~
John Williams
ALB Candidate, Harvard University (Expected May 2014)
johnwilliams at fas.harvard.edu
jawilliamsjr at gmail.com



--
View this message in context: http://r.789695.n4.nabble.com/metafor-variance-explaination-for-paired-pre-test-posttest-tp4688365.html
Sent from the R help mailing list archive at Nabble.com.



From rshepard at appl-ecosys.com  Tue Apr  8 02:50:49 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 7 Apr 2014 17:50:49 -0700 (PDT)
Subject: [R] What Directs R to Executable Directory?
Message-ID: <alpine.LNX.2.11.1404071748010.24159@localhost>

   I apparently had a prior version of R in /usr/local/, but deleted all
R files in that subdirectory. Rebuilt R-3.0.3 and installed it in /usr/.
However, when I try to start R as either a user or as root it aborts because
it cannot find /usr/local/bin/R.

   Where is this information stored? I need to either edit that file or
remove it so R can happily find all it wants in /usr/.

Thanks,

Rich



From wdunlap at tibco.com  Tue Apr  8 03:22:00 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 8 Apr 2014 01:22:00 +0000
Subject: [R] What Directs R to Executable Directory?
In-Reply-To: <alpine.LNX.2.11.1404071748010.24159@localhost>
References: <alpine.LNX.2.11.1404071748010.24159@localhost>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC205E@PA-MBX01.na.tibco.com>

Running the Linux commands
   which R
and
   echo $PATH | sed -e 's/:/\n/g'
might give you a hint.

(Exactly what did you install in /usr?)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rich Shepard
> Sent: Monday, April 07, 2014 5:51 PM
> To: r-help at r-project.org
> Subject: [R] What Directs R to Executable Directory?
> 
>    I apparently had a prior version of R in /usr/local/, but deleted all
> R files in that subdirectory. Rebuilt R-3.0.3 and installed it in /usr/.
> However, when I try to start R as either a user or as root it aborts because
> it cannot find /usr/local/bin/R.
> 
>    Where is this information stored? I need to either edit that file or
> remove it so R can happily find all it wants in /usr/.
> 
> Thanks,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From rshepard at appl-ecosys.com  Tue Apr  8 03:36:19 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 7 Apr 2014 18:36:19 -0700 (PDT)
Subject: [R] What Directs R to Executable Directory?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FAC205E@PA-MBX01.na.tibco.com>
References: <alpine.LNX.2.11.1404071748010.24159@localhost>
	<E66794E69CFDE04D9A70842786030B933FAC205E@PA-MBX01.na.tibco.com>
Message-ID: <alpine.LNX.2.11.1404071833070.24159@localhost>

On Tue, 8 Apr 2014, William Dunlap wrote:

> Running the Linux commands
>   which R

Bill,

   That's how I found the installation in /usr/local/. After removing
everything there and re-installing -3.0.3 with the /usr/ directory as the
PREFIX, R is in /usr/bin/ and the libraries are in /usr/lib64/

> (Exactly what did you install in /usr?)

   Everything. That's the default for all SlackBuild.org scripts.

   I'll look more tomorrow. There's no R_ENVIRON, R_PROFILE, Renviron.site,
or Rprofile.site on the system.

Thanks,

Rich



From axel.urbiz at gmail.com  Tue Apr  8 03:54:41 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 7 Apr 2014 21:54:41 -0400
Subject: [R] Sweave files into LaTex
In-Reply-To: <534047E1.5090803@yorku.ca>
References: <CAAyVsXJw1OO8C66YnQumyPUz1LFju49=5MsgGfDHekLkDCYyBw@mail.gmail.com>
	<534047E1.5090803@yorku.ca>
Message-ID: <CAAyVsXJBJigLRLYS8r8Kj+te=KmnAqZZxe0NB3FmLDQK7tA7ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/a579f398/attachment-0001.pl>

From kydaviddoyle at gmail.com  Tue Apr  8 04:20:35 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Mon, 7 Apr 2014 21:20:35 -0500
Subject: [R] Plotting does odd line thing
Message-ID: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/5a3a234c/attachment-0001.pl>

From marc_grt at yahoo.fr  Tue Apr  8 04:53:22 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 08 Apr 2014 04:53:22 +0200
Subject: [R] Plotting does odd line thing
In-Reply-To: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
References: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
Message-ID: <534364A2.6030103@yahoo.fr>

Le 08/04/2014 04:20, David Doyle a ?crit :
> Hello folks,
>
> When I use the lines function below it connects all my points but then
> draws a line back to the start point.  Any suggestions on what is going on??
>
> mydata <-read.csv("http://doylesdartden.com/R/test_data.csv", sep=",")
>
> attach(mydata)
>
> plot(EMD~Year,data=mydata, subset = Well.ID %in% c("MW-1", "D_EMD"),
> col=ifelse(D_EMD, "black", "red"), pch=ifelse(D_EDM, 19, 17), cex = 1.5)
>
> lines(EMD~Year)
>
> Thank you for your time.
>
> David
>
>
First, there is a typo error here:

pch=ifelse(D_EMD, 19, 17)

Second try this to see that year data are not monotonically increasing. 
Then it produces the zig-zag effect that you observe:
plot(1990:2000, c(rep(0, 10), 10), type="n")
lines(EMD~Year)
It can be seen here also:
diff(Year)
or
diff(Year)<0

Sincerely,

Marc



From jim at bitwrit.com.au  Tue Apr  8 04:52:30 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 08 Apr 2014 12:52:30 +1000
Subject: [R] Plotting does odd line thing
In-Reply-To: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
References: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
Message-ID: <5343646E.9060807@bitwrit.com.au>

On 04/08/2014 12:20 PM, David Doyle wrote:
> Hello folks,
>
> When I use the lines function below it connects all my points but then
> draws a line back to the start point.  Any suggestions on what is going on??
>
> mydata<-read.csv("http://doylesdartden.com/R/test_data.csv", sep=",")
>
> attach(mydata)
>
> plot(EMD~Year,data=mydata, subset = Well.ID %in% c("MW-1", "D_EMD"),
> col=ifelse(D_EMD, "black", "red"), pch=ifelse(D_EDM, 19, 17), cex = 1.5)
>
> lines(EMD~Year)
>
Hi David,
While you will get what you expect with:

lines(EMD[1:39]~Year[1:39])

I would be unnecessarily obscure in suggesting it. Try this:

subset<-Well.ID %in% c("MW-1", "D_EMD")
lines(EMD[subset]~Year[subset])

You haven't selected the same points for the lines function as you have 
for the plot function.

Jim



From dwinsemius at comcast.net  Tue Apr  8 05:41:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 7 Apr 2014 20:41:25 -0700
Subject: [R] Time interactions for coxph object
In-Reply-To: <CAGbJzAL295uHvywfn+NAgak9ZeeE=tDwwu4mD_GZvg8tbev1DA@mail.gmail.com>
References: <CAGbJzAL295uHvywfn+NAgak9ZeeE=tDwwu4mD_GZvg8tbev1DA@mail.gmail.com>
Message-ID: <31D9CC9C-2765-4BCF-8CA0-80D75DFF6501@comcast.net>


On Apr 7, 2014, at 9:36 AM, Tim Marcella wrote:

> Hi All,
>
> I am working in the 'survival' library and need to know how to code a
> variable time interaction for left truncated data (not all subjects
> followed from the start of the study). I therefor add in the entry  
> time and
> exit time variables into the formula.
>
> Here is my basic formula
>
>    CSHR.shore.fly <- coxph(Surv(entry, exit, to == 1) ~ shore.cat,  
> data
>      glba.mod)
>
> My variable shore.cat is violating the proportional hazards  
> assumption so I
> am trying to add in an interaction with time. Do I interact exit?  
> entry? or
> the range of the two?

If you believe there is a trend in risk then there is the 'tt'  
argument which takes a function.

-- 
David Winsemius, MD
Alameda, CA, USA



From dilaradi21 at gmail.com  Tue Apr  8 05:46:02 2014
From: dilaradi21 at gmail.com (dila radi)
Date: Mon, 7 Apr 2014 20:46:02 -0700
Subject: [R] Replacement Value
Message-ID: <CAMgoKB+jt61mVjAz5YZohWinTj3MtgadOwLhB_DQJXYk_z9AzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140407/0818183b/attachment-0001.pl>

From jim at bitwrit.com.au  Tue Apr  8 06:45:42 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 08 Apr 2014 14:45:42 +1000
Subject: [R] Replacement Value
In-Reply-To: <CAMgoKB+jt61mVjAz5YZohWinTj3MtgadOwLhB_DQJXYk_z9AzA@mail.gmail.com>
References: <CAMgoKB+jt61mVjAz5YZohWinTj3MtgadOwLhB_DQJXYk_z9AzA@mail.gmail.com>
Message-ID: <53437EF6.3050301@bitwrit.com.au>

On 04/08/2014 01:46 PM, dila radi wrote:
> Hi all,
>
> I have problem on how to replace value. I have this kind of data set:
>
> structure(list(A = c(0, 12.6, 10.1, 8.1, 14.4, 0, 0, 0, 0, 0.5,
> 12.9, 25.9, 49, 0, 0, 0, 0, 0, 7.8), B = c(0, 0, 9.1, 9.3, 1.5,
> 1, 1, 1, 1.7, 6, 0, 0, 0, 1.7, 3.8, 0, 0, 0, 1), C = c(1, 1,
> 9.100000004, 9.299999999, 1.5, 1, 1, 1, 1.7, 5.999999999, 1,
> 1, 1, 1.7, 3.800000001, 1, 1, 1, 1)), .Names = c("A", "B", "C"
> ), row.names = c(NA, 19L), class = "data.frame")
>
> The problem is the value under variable 'C'.   It supposed to be like this:
>
> 1) When value is '0' under variable 'B', the next value under variable 'C'
> also should be '0'.
>
> 2) When value is '1' under variable 'B', there is no changes for values
> under variable 'C'.
>
> How do I achieved this by fulfill these two conditions? Thank you so much.
>
Hi Dila,
The answer to the above is fairly simple (data frame is named drdf):

drdf$C[which(drdf$B==0)+1]<-0

The second condition does nothing. However, I think that you may want 
something more complicated as there are values other than 0 or 1 in drdf.

Jim



From es at enricoschumann.net  Tue Apr  8 07:48:49 2014
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 08 Apr 2014 07:48:49 +0200
Subject: [R] Getting a particular weekday for a given month
In-Reply-To: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
	(Christofer Bogaso's message of "Mon, 7 Apr 2014 23:34:09 +0545")
References: <CA+dpOJnfDqRHONrXmq78aKC30WSheAYex=yAUFPSV9vfU9UYeA@mail.gmail.com>
Message-ID: <874n24nzge.fsf@enricoschumann.net>

On Mon, 07 Apr 2014, Christofer Bogaso <bogaso.christofer at gmail.com> writes:

> Hi,
>
> Given a month name, I am looking for some script to figure out, what is the
> date for 3rd Wednesday. For example let say I have following month:
>
> library(zoo)
> Month <- as.yearmon(as.Date(Sys.time()))
>
> I need to answer: What is the date for 3rd Wednesday of 'Month'?
>
> Really appreciate for any pointer.
>
> Thanks for your time.
>

There is a function 'lastWeekday' in the PMwR package, which will
compute the last weekday -- Wednesday, say -- in a given month.
(Disclosure: I am the package author.) For example

  lastWeekday(3, Sys.Date()) 

produces "2014-04-30", which is the last Wednesday of the current month.
To get the third Wednesday of a given month, you can do this:

  lastWeekday(3, endOfPreviousMonth(Sys.Date()), shift = 3)

or, for example, for the third Friday of September 2012:

  lastWeekday(5, endOfPreviousMonth(as.Date("2012-09-01")), shift = 3)

  ##"2012-09-21"

That is, you first find the last particular weekday of the previous
month, and then shift forward 3 weeks.

However, PMwR is not on CRAN; it's available from here

  http://enricoschumann.net/R/packages/PMwR/index.htm

If you are on a Unix-type system (or have Rtools installed on Windows),
you can directly install the package from source:

  install.packages('PMwR',
                   repos = 'http://enricoschumann.net/R', 
                   type = 'source')

Regards,
        Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net



From frtog at vestas.com  Tue Apr  8 07:52:57 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Apr 2014 07:52:57 +0200
Subject: [R] Plotting does odd line thing
In-Reply-To: <5343646E.9060807@bitwrit.com.au>
References: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
	<5343646E.9060807@bitwrit.com.au>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF21B7@DKRDSEXC016.vestas.net>

Well the lines() function has a subset argument as does plot() so why not do this?

lines(EMD ~ Year, data = mydata, subset = Well.ID %in% c("MW-1", "D_EMD"))

And yes lines() also have a data argument so why do you not use that (as you do with plot()) instead of attaching.

Attaching dataframes may be a potential danger when some time in the future you have forgot that you attached the dataframe and you have forgot the warnings you get when attaching (making debugging difficult).

Try this:

> ## Define an object named Year
> ## in which case call to lines do not what you think it will do
> Year <- 1:nrow(mydata) 
>
> ## or Year <- 'foo' in which case one gets an error later
>
> ## attach the dataframe
>  attach(mydata)

The following object is masked _by_ .GlobalEnv:

    Year

Now what will happen if you do lines(EMD ~ Year)?????  

Here is the search path in my session:

> search()
 [1] ".GlobalEnv"        "mydata"            "package:lattice"  
 [4] "package:RODBC"     "package:stats"     "package:graphics" 
 [7] "package:grDevices" "ESSR"              "package:utils"    
[10] "package:datasets"  "package:methods"   "Autoloads"        
[13] "package:base"     


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Jim Lemon
> Sent: 8. april 2014 04:53
> To: David Doyle
> Cc: r-help at r-project.org
> Subject: Re: [R] Plotting does odd line thing
> 
> On 04/08/2014 12:20 PM, David Doyle wrote:
> > Hello folks,
> >
> > When I use the lines function below it connects all my points but then
> > draws a line back to the start point.  Any suggestions on what is going on??
> >
> > mydata<-read.csv("http://doylesdartden.com/R/test_data.csv", sep=",")
> >
> > attach(mydata)
> >
> > plot(EMD~Year,data=mydata, subset = Well.ID %in% c("MW-1", "D_EMD"),
> > col=ifelse(D_EMD, "black", "red"), pch=ifelse(D_EDM, 19, 17), cex = 1.5)
> >
> > lines(EMD~Year)
> >
> Hi David,
> While you will get what you expect with:
> 
> lines(EMD[1:39]~Year[1:39])
> 
> I would be unnecessarily obscure in suggesting it. Try this:
> 
> subset<-Well.ID %in% c("MW-1", "D_EMD")
> lines(EMD[subset]~Year[subset])
> 
> You haven't selected the same points for the lines function as you have
> for the plot function.
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From sagnik.stats at gmail.com  Tue Apr  8 08:13:27 2014
From: sagnik.stats at gmail.com (sagnik chakravarty)
Date: Tue, 8 Apr 2014 11:43:27 +0530
Subject: [R] Issues with fa() function in "psych"
Message-ID: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/9154eb7a/attachment-0001.pl>

From kridox at ymail.com  Tue Apr  8 09:28:46 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 8 Apr 2014 16:28:46 +0900
Subject: [R] Issues with fa() function in "psych"
In-Reply-To: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
References: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
Message-ID: <CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>

Hello,

And what about submitting your suggestions directly to the package
author/maintainer?

And please don't post in HTML.

Regards,
Pascal

On Tue, Apr 8, 2014 at 3:13 PM, sagnik chakravarty
<sagnik.stats at gmail.com> wrote:
> Hi Team,
>
> I was using your "psych" package for factor analysis and was also comparing
> the results with SAS results. I have some suggestions and/or confusions
> regarding the fa() function in the package:
>
>    - The fa() function *doesn't account for Heywood cases* (communality
>    greater than 1) and never ever throws out any error related to that which
>    other softwares do. This is a serious and common issue in iterative factor
>    analysis and hence should have been accounted for.
>
>
>    - The fa() function doesn't provide "equamax" rotation in its rotation
>    list and still if you specify "*rotation=equamax*", it will run without
>    throwing out any error and even mentioning in the result that "equamax" has
>    been applied. But I have thoroughly compared results from "
>    *rotation=none*" and "*rotation=equamax*" options and they are exactly
>    same. *That means fa() is not doing the rotation at all and yet telling
>    that it is doing that!!* I have even mentioned "*rotation=crap*" option
>    just to check and surprisingly it ran(without any error) with the result
>    showing:
>
>            *Factor Analysis using method =  gls*
> *           Call: fa(r = cor_mat, nfactors = 4, n.obs = 69576, rotate =
> "crap", fm = "gls")*
>
>             I hope you understand the severity of this bug and hence
> request you to correct this.
>
>    - To my sense, there might be some problem with "fm=ml" and "fm=pa"
>    options since the convergence issue should be with MLE method and not PA
>    method but while running factor analysis with PA, I am getting the
>    following warning:
>
>             *maximum iteration exceeded*
> *            The estimated weights for the factor scores are probably
> incorrect.  Try a different factor extraction method.*
>
>              If I compare the results of R and SAS,* I am getting
> convergence error for MLE in SAS whereas I am getting the same error for PA
> in R *!! I am not being able to understand this mismatch.
>
>    - If I call the *loading matrix like efa_pa$loadings, the matrix shown
>    has many blank cells whereas the final result showing the loadings doesn't
>    have so* !!
>
> *Loadings:*
> *             PA1    PA2    PA3    PA4   *
> *Var1    0.401                       -0.243*
> *Var2    0.336 -0.104            0.710*
> *Var3    0.624  0.123 0.170      *
>
>
>    - Could you please explain* what the "com" column means* in the output:?
>
>
> *           PA1   PA3   PA2   PA4     h2          u2      com*
> *Var1  0.44  0.14 -0.03  -0.10 0.22665  0.773  1.3*
> *Var2  0.08  0.11  0.02   0.78  0.62951  0.370  1.1*
> *Var3  0.62  0.12  0.15   0.14  0.43578  0.564  1.3*
>
>    - Request you to add option for *"equamax" rotation* also if possible.
>
>
> I have come across the above issues until now. Please do correct me if I am
> wrong.
>
> Awaiting your revert which would clear out my confusions,
>
> Thanks for your valuable time,
>
> Sagnik
>
> --
> Regards,
>
> *SAGNIK CHAKRAVARTY*
>
> *Mob:*  +919972865435
> *Email:* sagnik.stats at gmail.com
>            sagnik.739 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr  8 09:54:25 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 8 Apr 2014 09:54:25 +0200
Subject: [R] {metafor} variance explaination for paired pre-test/posttest
In-Reply-To: <1396916999280-4688365.post@n4.nabble.com>
References: <1396916999280-4688365.post@n4.nabble.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DA800805A@UM-MAIL4112.unimaas.nl>

The standardized mean change using 'change score standardization' is described in this article:

Gibbons, R. D., Hedeker, D. R., & Davis, J. M. (1993). Estimation of effect size from a series of experiments involving paired comparisons. Journal of Educational Statistics, 18(3), 271-279.

For a comparison of the standardized mean change using change versus raw score standardization, see:

Morris, S. B., & DeShon, R. P. (2002). Combining effect size estimates in meta-analysis with repeated measures and independent-groups designs. Psychological Methods, 7(1), 105-125.

Viechtbauer, W. (2007). Approximate confidence intervals for standardized effect sizes in the two-independent and two-dependent samples design. Journal of Educational and Behavioral Statistics, 32(1), 39-60.

These articles also provide equations for the sampling variance of the standardized mean change. The equation 1/ni + yi^2/(2*ni) is the estimate based on the asymptotic variance of the standardized mean change using change score standardization. 

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of John Williams
> Sent: Tuesday, April 08, 2014 02:30
> To: r-help at r-project.org
> Subject: [R] {metafor} variance explaination for paired pre-test/posttest
> 
> In a previous post
> https://stat.ethz.ch/pipermail/r-help/2012-April/308946.html
> <https://stat.ethz.ch/pipermail/r-help/2012-April/308946.html>  , the
> following calculation was given for imputing the variance of change
> scores
> for paired studies:
> 
> // begin quote
> 
> 2) Often, the dependent variable is not the same in each study. Then you
> will have to resort to a standardized outcome measure. There are two
> options:
> 
> a) standardization based on the change score standard deviation
> 
> Then yi = (m1i - m2i) / sdi with sampling variance vi = 1/ni + yi^2 /
> (2*ni).
> 
> // end quote
> 
> I used the sampling variance equation above in a paper that is being
> reviewed by a coauthor, who is a biostatistician.
> 
> He commented that he has never seen this equation for variance before,
> and
> it looks strange to him. To put my knowledge into perspective, I am an
> undergraduate taking my first statistics course. I imputed the t-
> statistic
> from two-sided p-values reported in the paper, and used that to get the
> sdi
> (as in the previous post).
> 
> I consulted the Cochrane Handbook and The Handbook of Research Syntheses
> and
> Meta-analysis 2nd Ed (Cooper, Hedges, Valentine 2009) and couldn't find
> that
> equation anywhere.
> 
> Would Prof. Viechtbauer, or anyone else knowledgeable, mind explaining
> the
> sample variance above? I need to be able to defend my choice of equation.
> Since it's the only method that I found that doesn't rely on a
> correlation
> coefficient (which are not included in the papers), I'd like to be able
> to
> justify it and not redo calculations for 23 studies if possible.
> 
> Thank you very much,
> 
> John
> 
> ~~~~
> John Williams
> ALB Candidate, Harvard University (Expected May 2014)
> johnwilliams at fas.harvard.edu
> jawilliamsjr at gmail.com



From johnwilliams at fas.harvard.edu  Tue Apr  8 10:43:45 2014
From: johnwilliams at fas.harvard.edu (John Williams)
Date: Tue, 8 Apr 2014 01:43:45 -0700 (PDT)
Subject: [R] {metafor} variance explaination for paired pre-test/posttest
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DA800805A@UM-MAIL4112.unimaas.nl>
References: <1396916999280-4688365.post@n4.nabble.com>
	<077E31A57DA26E46AB0D493C9966AC730DA800805A@UM-MAIL4112.unimaas.nl>
Message-ID: <1396946625883-4688382.post@n4.nabble.com>

Prof. Viechtbauer, thanks for the articles. I appreciate your help.

Yours,

John 
 
~~~~ 
John Williams 
ALB Candidate, Harvard University (Expected May 2014) 
johnwilliams at fas.harvard.edu
jawilliamsjr at gmail.com



--
View this message in context: http://r.789695.n4.nabble.com/metafor-variance-explaination-for-paired-pre-test-posttest-tp4688365p4688382.html
Sent from the R help mailing list archive at Nabble.com.



From john.maindonald at anu.edu.au  Tue Apr  8 13:00:03 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 8 Apr 2014 11:00:03 +0000
Subject: [R] rpart and randomforest results
In-Reply-To: <mailman.26.1396951209.31834.r-help@r-project.org>
References: <mailman.26.1396951209.31834.r-help@r-project.org>
Message-ID: <54017DE5-AE46-4AF6-8210-37CE7DE6F6D1@anu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/41893ebb/attachment-0001.pl>

From therneau at mayo.edu  Tue Apr  8 14:59:57 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 08 Apr 2014 07:59:57 -0500
Subject: [R] Time interactions for coxph object
Message-ID: <6e55ab$8kha94@ironport10.mayo.edu>

  The very first step is to understand the possible nature of proportional hazards.  This 
is parallel to the usual advice in linear models to graph the data before you start 
fitting complicated non-linear models.
  zp <- cox.zph(CSHR.shore.fly, transform="identity")
  plot(zp)    # or plot(zp[3]) for the third variable of a model, but you have only 1
  print(zp)

This looks at the working model hazard = exp( beta(t) * x); a time dependent coefficient.
Propoprtional hazards corresponds to a horizontal line, i.e., beta(t) = constant.

The steps are
   1. Visualize
   2. THINK
   3. Act appropriately

The tt addition to coxph allows complex time-dependent coefficients and is explained in a 
vignette. (See ?vignette). I've seen scores of data sets with non-proportional hazards, 
and used the tt functionality perhaps 3 times.  Don't jump too quickly into complexity.

Terry Therneau

-----  begin included message ---------




Hi All,

I am working in the 'survival' library and need to know how to code a
variable time interaction for left truncated data (not all subjects
followed from the start of the study). I therefor add in the entry time and
exit time variables into the formula.

Here is my basic formula

     CSHR.shore.fly <- coxph(Surv(entry, exit, to == 1) ~ shore.cat, data
       glba.mod)

My variable shore.cat is violating the proportional hazards assumption so I
am trying to add in an interaction with time. Do I interact exit? entry? or
the range of the two?



From rshepard at appl-ecosys.com  Tue Apr  8 15:34:25 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 8 Apr 2014 06:34:25 -0700 (PDT)
Subject: [R] What Directs R to Executable Directory? [RESOLVED]
In-Reply-To: <alpine.LNX.2.11.1404071748010.24159@localhost>
References: <alpine.LNX.2.11.1404071748010.24159@localhost>
Message-ID: <alpine.LNX.2.11.1404080632300.11971@localhost>

On Mon, 7 Apr 2014, Rich Shepard wrote:

> However, when I try to start R as either a user or as root it aborts because
> it cannot find /usr/local/bin/R.

   When I stepped back from the problem, but shutting down the laptop for the
evening, it occurred to me that the system needed to be rebooted to see the
new installation and forget about the older one. Sure enough, when I booted
the laptop this morning, R worked as expected.

Thanks very much, Bill,

Rich



From mamushbukana at gmail.com  Tue Apr  8 15:50:40 2014
From: mamushbukana at gmail.com (mamuash bukana)
Date: Tue, 8 Apr 2014 10:50:40 -0300
Subject: [R] locating a data value in 3-dimensional data set
Message-ID: <CAFxDEqL8WCXuRVr4=8RShYG5yEcyOsV7AqvJw_YDjoUYe_+tkg@mail.gmail.com>

I have a 3-dimentional data set with dimensions "longitude",
"latitude", and "time". Unfortunately, when I look at the range of
values in the data set, I noticed some very extremely large(positive
and negative) values which are unexpected to be there. So I wanted to
point-out the location (lon, lat and time) which these extreme values
correspond to in order to see what is happening there. But I could not
point-out these grid points and time.

I tried:
which(3ddata==x) # 3ddata is name of data set, x is the observed extreme value
But this couldn't help me.

Any suggestion please?

Thanks

B



From S.Ellison at LGCGroup.com  Tue Apr  8 16:04:37 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 8 Apr 2014 15:04:37 +0100
Subject: [R] locating a data value in 3-dimensional data set
In-Reply-To: <CAFxDEqL8WCXuRVr4=8RShYG5yEcyOsV7AqvJw_YDjoUYe_+tkg@mail.gmail.com>
References: <CAFxDEqL8WCXuRVr4=8RShYG5yEcyOsV7AqvJw_YDjoUYe_+tkg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E8D0A845F@GOLD.corp.lgc-group.com>

> I tried:
> which(3ddata==x) # 3ddata is name of data set, x is the observed extreme
> value But this couldn't help me.

You'll need which(3ddata$long==x) if 3ddata is a data frame* with columns long, lat, time, or something like 3ddata[ ,'long'] if it's a matrix with dimnames or [,1] if just a matrix.

But you'll be better off with >=x if the values are floating point; see R FAQ 7.31

*clearly, '3ddata' cannot be a data frame name - it's not legal R. I assume you have some legal name for it.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From kehld at ktk.pte.hu  Tue Apr  8 16:15:02 2014
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Tue, 8 Apr 2014 14:15:02 +0000
Subject: [R] locating a data value in 3-dimensional data set
In-Reply-To: <CAFxDEqL8WCXuRVr4=8RShYG5yEcyOsV7AqvJw_YDjoUYe_+tkg@mail.gmail.com>
References: <CAFxDEqL8WCXuRVr4=8RShYG5yEcyOsV7AqvJw_YDjoUYe_+tkg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B9AE144@EMAIL.ktkdom.pte.hu>

Dear Mamuash Bukana,

is this a data frame with variable names you indicated?

you will need something like which(dataframename$variablename == x) 
but if you have more you might use >

HTH
kd
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: mamuash bukana [mamushbukana at gmail.com]
K?ldve: 2014. ?prilis 8. 15:50
To: r-help at r-project.org
T?rgy: [R] locating a data value in 3-dimensional data set

I have a 3-dimentional data set with dimensions "longitude",
"latitude", and "time". Unfortunately, when I look at the range of
values in the data set, I noticed some very extremely large(positive
and negative) values which are unexpected to be there. So I wanted to
point-out the location (lon, lat and time) which these extreme values
correspond to in order to see what is happening there. But I could not
point-out these grid points and time.

I tried:
which(3ddata==x) # 3ddata is name of data set, x is the observed extreme value
But this couldn't help me.

Any suggestion please?

Thanks

B

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From frtog at vestas.com  Tue Apr  8 16:33:44 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Apr 2014 16:33:44 +0200
Subject: [R] locating a data value in 3-dimensional data set
Message-ID: <4fmyl0kui3d9gwhlxhpkqlxw.1396967620765@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/d1d723dc/attachment-0001.pl>

From frtog at vestas.com  Tue Apr  8 16:36:36 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Apr 2014 16:36:36 +0200
Subject: [R] locating a data value in 3-dimensional data set
Message-ID: <uxp3rat9qm8oihydi3at462x.1396967792657@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/c368a8c2/attachment-0001.pl>

From jgrn at illinois.edu  Tue Apr  8 17:00:03 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 8 Apr 2014 10:00:03 -0500
Subject: [R] Ignore escape characters in a string...
Message-ID: <CABG0rftuobmpdRUs7mMtvZVBBm-AttKOs3okWVobKfSoiB1w_w@mail.gmail.com>

R-helpers:

One of the minor irritations I have is copying paths from Windows
explorer, which look like:

C:\Program Files\R\R-3.0.3

and using them in a setwd() statement, since the "\" is, of course,
interpreted as an escape character.  I have to, at present, manually
add in the double slashes or reverse them.

So, I'd like to write a quick function that takes this path:

winpath <- "C:\Program Files\R\R-3.0.3"

and converts it to a ready-to-go R path -- is there a way to have R
IGNORE escape characters in a character vector?

Alternatively, is there some trick to using a copy/paste from Windows
explorer I'm not aware of?

--j



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007



From b.rowlingson at lancaster.ac.uk  Tue Apr  8 17:17:53 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 8 Apr 2014 16:17:53 +0100
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <20cc49e752494b56abc577785c7cc97f@EX-0-HT0.lancs.local>
References: <20cc49e752494b56abc577785c7cc97f@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMkqFGv2Td3fYNuqyktaNWXSSYCh4owL1O_HMms2QV98w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/16d04887/attachment-0001.pl>

From frtog at vestas.com  Tue Apr  8 17:30:38 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Apr 2014 17:30:38 +0200
Subject: [R] Ignore escape characters in a string...
Message-ID: <f2l3b2axf9m6dsj9c0u2qc6w.1396971036063@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/aa912f57/attachment-0001.pl>

From ruipbarradas at sapo.pt  Tue Apr  8 17:35:17 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 08 Apr 2014 16:35:17 +0100
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <CANVKczMkqFGv2Td3fYNuqyktaNWXSSYCh4owL1O_HMms2QV98w@mail.gmail.com>
References: <20cc49e752494b56abc577785c7cc97f@EX-0-HT0.lancs.local>
	<CANVKczMkqFGv2Td3fYNuqyktaNWXSSYCh4owL1O_HMms2QV98w@mail.gmail.com>
Message-ID: <53441735.2050003@sapo.pt>

Hello,

There is support for the clipboard on Windows 7.
Also, note that on Windows your solution leaves a connection open so 
maybe the following is better.

# copy the next line
C:\Program Files\R\R-3.0.3

clipb <- file("clipboard")
winpath <- readLines(clipb)
close(clipb)


And, just to avoid backslashes altogether,

fun <- function(x) gsub("\\\\", "/", x)
fun(winpath)

Hope this helps,

Rui Barradas

Em 08-04-2014 16:17, Barry Rowlingson escreveu:
> On Tue, Apr 8, 2014 at 4:00 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>
>> C:\Program Files\R\R-3.0.3
>
>
> Does R on windows have clipboard support? I can do this on Linux:
>
>   > readLines(file("clipboard"))
> [1] "C:\\Program Files\\R\\R-3.0.3"
>
> - that's from a copy of a path with only single slashes in. But
> help(connections) on my linux system doesn't mention the Windows
> clipboard....
>
> Some ppl on SO have assorted solutions involving Windows scripting tools
> that tweak the clipboard so you can Ctrl-V a modified value:
>
> http://stackoverflow.com/questions/1407238/relief-from-backslash-irritation-in-r-for-windows
>
> Barry
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From b.rowlingson at lancaster.ac.uk  Tue Apr  8 17:40:16 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 8 Apr 2014 16:40:16 +0100
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <fb3e20bb4354472193563413f4a8252e@EX-1-HT0.lancs.local>
References: <fb3e20bb4354472193563413f4a8252e@EX-1-HT0.lancs.local>
Message-ID: <CANVKczNTPSt4o7Z_1NGC8465dmpe+bcCTcVt6H8cpkWGoitVfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/009fb42f/attachment-0001.pl>

From hill0093 at umn.edu  Tue Apr  8 18:06:09 2014
From: hill0093 at umn.edu (Hurr)
Date: Tue, 8 Apr 2014 09:06:09 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <CF682023.F262C%macqueen1@llnl.gov>
References: <1396304717602-4687917.post@n4.nabble.com>
	<CF682023.F262C%macqueen1@llnl.gov>
Message-ID: <1396973169170-4688399.post@n4.nabble.com>

Don suggested something like this:
h=c(1,2,3,4,5,6,7,8,9)
v=c(9,8,7,6,5,4,3,2,1)
plot(h,v,xaxt='n')
xat=pretty(h)
axis(1,at=xat,labels=1/xat)
But it puts the tick marks at the data-x-locations.
If the tick locations are not automatic or
automatically separate from the data locations, then
I want to tell it where to put them using 
a separate indicator. I am not familiar enough with
R to find the answer.
But if it would work, it would be valuable.




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917p4688399.html
Sent from the R help mailing list archive at Nabble.com.



From frtog at vestas.com  Tue Apr  8 18:10:33 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Apr 2014 18:10:33 +0200
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <CANVKczNTPSt4o7Z_1NGC8465dmpe+bcCTcVt6H8cpkWGoitVfg@mail.gmail.com>
References: <fb3e20bb4354472193563413f4a8252e@EX-1-HT0.lancs.local>
	<CANVKczNTPSt4o7Z_1NGC8465dmpe+bcCTcVt6H8cpkWGoitVfg@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF26BD@DKRDSEXC016.vestas.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/d093f3c5/attachment-0001.pl>

From kydaviddoyle at gmail.com  Tue Apr  8 18:51:41 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Tue, 8 Apr 2014 11:51:41 -0500
Subject: [R] Plotting does odd line thing
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF21B7@DKRDSEXC016.vestas.net>
References: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
	<5343646E.9060807@bitwrit.com.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF21B7@DKRDSEXC016.vestas.net>
Message-ID: <CACftpvorAvrW6scQs=1Js4fXGYm49_zOBgdZqsFEx1Z-mdgmJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/40444154/attachment-0001.pl>

From mamushbukana at gmail.com  Tue Apr  8 18:54:54 2014
From: mamushbukana at gmail.com (mamuash bukana)
Date: Tue, 8 Apr 2014 13:54:54 -0300
Subject: [R] locating a data value in 3-dimensional data set
In-Reply-To: <4fmyl0kui3d9gwhlxhpkqlxw.1396967620765@email.android.com>
References: <4fmyl0kui3d9gwhlxhpkqlxw.1396967620765@email.android.com>
Message-ID: <CAFxDEqLO5or2gDNHaLPoPHiWW7iD9d7ex7XjiFmb6R+pqgR-Wg@mail.gmail.com>

Many thanks to you all; specially to Frede.
which(3ddata$variablename>=x,arr.ind=TRUE) answers my question
perfectly.

Cheers!

Bukana

On Tue, Apr 8, 2014 at 11:33 AM, Frede Aakmann T?gersen
<frtog at vestas.com> wrote:
> Hi
>
> I know there is a arr.index (or something like that,  I'm not near my R
> right now) argument to which (). I have used it for 2-dim arrays and never
> for higher dimensions. But try it out by setting the argument to TRUE.
>
> Br. Frede
>
>
> Sendt fra Samsung mobil
>
>
> -------- Oprindelig meddelelse --------
> Fra: mamuash bukana
> Dato:08/04/2014 15.51 (GMT+01:00)
> Til: r-help at r-project.org
> Emne: [R] locating a data value in 3-dimensional data set
>
> I have a 3-dimentional data set with dimensions "longitude",
> "latitude", and "time". Unfortunately, when I look at the range of
> values in the data set, I noticed some very extremely large(positive
> and negative) values which are unexpected to be there. So I wanted to
> point-out the location (lon, lat and time) which these extreme values
> correspond to in order to see what is happening there. But I could not
> point-out these grid points and time.
>
> I tried:
> which(3ddata==x) # 3ddata is name of data set, x is the observed extreme
> value
> But this couldn't help me.
>
> Any suggestion please?
>
> Thanks
>
> B
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From julien.riou.k at gmail.com  Tue Apr  8 10:31:32 2014
From: julien.riou.k at gmail.com (Julien Riou)
Date: Tue, 8 Apr 2014 10:31:32 +0200
Subject: [R] Meta-analysis of prevalence at the country level with mgcv/gamm4
Message-ID: <CAL49zWNRgYHFvUXdfoTuD8ixaewAS7iE4r3tP3p5K4dZha8Nuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/e488ba9a/attachment-0001.pl>

From smartpink111 at yahoo.com  Tue Apr  8 15:46:24 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Apr 2014 06:46:24 -0700 (PDT)
Subject: [R] Splitting columns  and forming new data files in R
In-Reply-To: <1396934226.74413.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1396934226.74413.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <1396964784.23082.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
#Tmin,Tmax,Tmean,Precip 

#"Tmean" -999.9 in all files
#working directory is "sample" 

#created folder "final"
list.files()
#[1] "coordinates.csv" "final"           "Precip"          "Tmax
"           
#[5] "Tmin"
Coord <- read.csv(list.files(pattern=".csv"),header=TRUE,stringsAsFactors=FALSE)
lfile <- list.files()[!grepl(".csv|final",list.files())]
files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")
lst1 <- split(files,gsub(".*\\/(.*)\\.csv","\\1",files)) 

names1 <- gsub(".*\\/(.*)\\/.*\\.csv","\\1",lst1[[1]])
lst1New <-   lapply(lst1,function(x) {lst2 <- setNames(lapply(x,function(y) {dat <- read.table(y,sep=" ",header=TRUE, stringsAsFactors=FALSE); dat[,1:104]} ), names1); dat2 <- do.call(cbind,lst2); indx <- grepl("Sim",names(dat2)); dat3 <- dat2[indx];dat4 <- dat2[!indx][,1:4]; names(dat4) <- gsub(".*\\.","",names(dat4)); lapply(split(names(dat3),gsub(".*\\.","",names(dat3))),function(x)  {dat5 <- cbind(dat4,dat3[,x]); dat5$Tmean <- -999.9; dat6 <- dat5[,c(1:4,7:6,8,5)];colnames(dat6)[2:3] <- Coord[match(unique(dat6$Site), Coord$Site),3:2];dat7 <- dat6[,-4]; dat7; colnames(dat7)[-(2:3)] <- NA; dat7})})

sapply(lst1New,length) 

#G100 G101 G102 G103 

# 100  100  100  100
lapply(names(lst1New),function(x) {nm1 <- paste(x, names(lst1New[[x]]),sep="_"); nm2 <- paste0(paste(paste0(getwd(),"/final"),nm1,sep="/"),".csv");lapply(seq_along(lst1New[[x]]),function(i) {x1 <- lst1New[[x]][i]; write.table(x1, nm2[i],quote=FALSE,row.names=FALSE)})})

length(list.files(paste0(getwd(),"/final")))
#[1] 400 


A.K.

On Tuesday, April 8, 2014 1:17 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
Please I need your help. I finally solved the previous task I sent to you.
I have Precip,Tmin and Tmax in three different folders (attached).
Each folder has 4 files with identical names in all folders (we can match case).

Within each file are [,YYY MM DD sim001...sim100] (some files may have more than 100 simulations. Use only the first 100).

Q1) Open all three folders, go to file 1 (e.g G100), copy column 1 (sim001, do not copy date) and paste it in a new folder called?"final". Do so for column 2 (sim002),...,column 100 (sim100). So from file 1 alone with 100 sims, you will have 100 files in "final". The files in "final" should be labelled for example as G100_sim001, G100_sim002,...,G100_sim100; G101_sim001,G101_sim002 etc.

The format of all files in "final" is similar to:

50-110.7
196111-999.9-999.9-999.90
196112-999.9-999.9-999.92.38
196113-999.9-999.9-999.90
196114-999.9-999.9-999.90
196115-999.9-999.9-999.90
196116-999.9-999.9-999.90
196117-999.9-999.9-999.90
196118-999.9-999.9-999.90
196119-999.9-999.9-999.95.19
1961110-999.9-999.9-999.90
1961111-999.9-999.9-999.90
1961112-999.9-999.9-999.90
1961113-999.9-999.9-999.90
1961114-999.9-999.9-999.90
1961115-999.9-999.9-999.90


The columns after the date should be [Tmin,Tmax,Tmean,Precip]. Please do not include column names in output. Output files are .csv.

*Fill column "Tmean" with?-999.9 in all files.

Therefore, using the sample I have provided, you will have 4sites*100 sims = 400 files in folder "final".



Q2) From the attached coordinates file, please copy Lat andLong corresponding to the Site and past it in the first row of every file starting with that site code.

For example, all files beginning with G100_sim... will have their first row similar to:

? ? ? ?49.53-96.7
196111-999.9-999.9-999.90


This looks very cumbersome for me to handle.?

Thanks very much.
Atem.



From lise.hanssens at ugent.be  Tue Apr  8 14:20:56 2014
From: lise.hanssens at ugent.be (lghansse)
Date: Tue, 8 Apr 2014 05:20:56 -0700 (PDT)
Subject: [R] Error logistic analysis
Message-ID: <1396959656546-4688385.post@n4.nabble.com>

I'm trying to conduct a single level logistic analysis (as a beginning step
for a more advanced Multi-level analysis). However, when I try to run it, I
get following error:

Warning messages:
1: In model.response(mf, "numeric") :
  using type = "numeric" with a factor response will be ignored
2: In Ops.factor(y, z$residuals) : - not meaningful for factors

I haven't got a clue why I'm getting this because I used the exact same
syntax (same data preparation etc...) for a similar analysis (same
datastructure, different country). 

Syntax: 
Single_model1 <- lm(openhrs1 ~ genhealt1 + age + sexpat1 + hhincome1 +
edupat1 
+ etniciteit1, data=Slovakije)

My Missing data are coded as such, I already tried to run the analysis in a
data frame without the missing cases, but that didn't work either. 



--
View this message in context: http://r.789695.n4.nabble.com/Error-logistic-analysis-tp4688385.html
Sent from the R help mailing list archive at Nabble.com.



From marc_schwartz at me.com  Tue Apr  8 19:29:30 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 08 Apr 2014 12:29:30 -0500
Subject: [R] Error logistic analysis
In-Reply-To: <1396959656546-4688385.post@n4.nabble.com>
References: <1396959656546-4688385.post@n4.nabble.com>
Message-ID: <64A8BD9B-EBA1-41EB-B5D6-68505C51BA7D@me.com>


On Apr 8, 2014, at 7:20 AM, lghansse <lise.hanssens at ugent.be> wrote:

> I'm trying to conduct a single level logistic analysis (as a beginning step
> for a more advanced Multi-level analysis). However, when I try to run it, I
> get following error:
> 
> Warning messages:
> 1: In model.response(mf, "numeric") :
>  using type = "numeric" with a factor response will be ignored
> 2: In Ops.factor(y, z$residuals) : - not meaningful for factors
> 
> I haven't got a clue why I'm getting this because I used the exact same
> syntax (same data preparation etc...) for a similar analysis (same
> datastructure, different country). 
> 
> Syntax: 
> Single_model1 <- lm(openhrs1 ~ genhealt1 + age + sexpat1 + hhincome1 +
> edupat1 
> + etniciteit1, data=Slovakije)
> 
> My Missing data are coded as such, I already tried to run the analysis in a
> data frame without the missing cases, but that didn't work either. 


You are using the lm() function above, which is a regular least squares linear regression for a continuous response variable.

If you want to run a logistic regression, you need to use glm() with 'family = binomial':

Single_model1 <- glm(openhrs1 ~ genhealt1 + age + sexpat1 + hhincome1 +
                     edupat1 + etniciteit1, family = binomial, data = Slovakije)


Regards,

Marc Schwartz



From trujillo at unex.es  Tue Apr  8 19:37:07 2014
From: trujillo at unex.es (=?ISO-8859-1?Q?Jos=E9_Trujillo_Carmona?=)
Date: Tue, 08 Apr 2014 19:37:07 +0200
Subject: [R] moses extreme reaction test
Message-ID: <534433C3.8060703@unex.es>

Is there a package that contains "moses extreme reaction test"?

Thank's



From marc_schwartz at me.com  Tue Apr  8 19:42:32 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 08 Apr 2014 12:42:32 -0500
Subject: [R] moses extreme reaction test
In-Reply-To: <534433C3.8060703@unex.es>
References: <534433C3.8060703@unex.es>
Message-ID: <5B7D07E2-30CC-468C-A6DA-1F247BB0A3E1@me.com>


On Apr 8, 2014, at 12:37 PM, Jos? Trujillo Carmona <trujillo at unex.es> wrote:

> Is there a package that contains "moses extreme reaction test"?
> 
> Thank's


A search using rseek.org indicates that the DescTools package on CRAN contains a function called  
MosesTest() that appears to implement it.

  http://cran.r-project.org/web/packages/DescTools/

Regards,

Marc Schwartz



From dwinsemius at comcast.net  Tue Apr  8 19:43:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Apr 2014 10:43:42 -0700
Subject: [R] moses extreme reaction test
In-Reply-To: <534433C3.8060703@unex.es>
References: <534433C3.8060703@unex.es>
Message-ID: <97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>


On Apr 8, 2014, at 10:37 AM, Jos? Trujillo Carmona wrote:

> Is there a package that contains "moses extreme reaction test"?

Learn to search.

install.packages("sos")
library(sos)
findFn("moses extreme")


found 5 matches;  retrieving 1 page

Downloaded 3 links in 1 packages

-- 

David Winsemius
Alameda, CA, USA



From jdnewmil at dcn.davis.CA.us  Tue Apr  8 20:23:30 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 08 Apr 2014 11:23:30 -0700
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <CABG0rftuobmpdRUs7mMtvZVBBm-AttKOs3okWVobKfSoiB1w_w@mail.gmail.com>
References: <CABG0rftuobmpdRUs7mMtvZVBBm-AttKOs3okWVobKfSoiB1w_w@mail.gmail.com>
Message-ID: <aa655752-35f1-41b9-abbf-d2ec31f56e2c@email.android.com>

What is wrong with

winpath <- readLines("clipboard ")

?

If you want to show that as a literal in your code, then don't bother assigning it to a variable, but let it echo to output and copy THAT and put it in your source code.

There is also file.choose()...

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 8, 2014 8:00:03 AM PDT, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>R-helpers:
>
>One of the minor irritations I have is copying paths from Windows
>explorer, which look like:
>
>C:\Program Files\R\R-3.0.3
>
>and using them in a setwd() statement, since the "\" is, of course,
>interpreted as an escape character.  I have to, at present, manually
>add in the double slashes or reverse them.
>
>So, I'd like to write a quick function that takes this path:
>
>winpath <- "C:\Program Files\R\R-3.0.3"
>
>and converts it to a ready-to-go R path -- is there a way to have R
>IGNORE escape characters in a character vector?
>
>Alternatively, is there some trick to using a copy/paste from Windows
>explorer I'm not aware of?
>
>--j



From jspark4 at uic.edu  Tue Apr  8 20:29:23 2014
From: jspark4 at uic.edu (Sparks, John James)
Date: Tue, 8 Apr 2014 13:29:23 -0500
Subject: [R] Pull Stock Symbol Out of String
Message-ID: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>

Dear R Helpers,

My regex skills are beginner to intermediate and banging around the web
has not resulted in a solution to the problem below so I hope that one of
you who has mad skills can help me out.

I want to extract the stock ticker--AMT-- out of the string

American Tower Corporation (REIT)??(AMT)

The presence of the other parenthetical text (REIT) makes this difficult. 
Please note that the string may or may not have a interfering set of
characters such as the (REIT) so the solution needs to be generalizable to
the last set of characters that are contained in parentheses in the larger
string.  So an example of a string without the interfering (REIT) would be

Aetna Inc.??(AET)


Your assistance would be very much appreciated.

--John Sparks



From o.godoy at met.no  Tue Apr  8 20:39:54 2014
From: o.godoy at met.no (=?ISO-8859-1?Q?=D8ystein_God=F8y?=)
Date: Tue, 8 Apr 2014 20:39:54 +0200
Subject: [R] ggplot2 and geom_tile
Message-ID: <2162533.O1G9xPTqRE@pc4394>

Dear community,

I have been using ggplot2 for visualisation and I am really impressed by this. 
I do however have a problem that returns when plotting various types of 
spatial datasets as raster images. This is probably due to me not fully 
understanding the package.

When I am plotting images using geom_tile, I sometimes only have small dots in 
the image and at other times I have apparently blank images. On other 
occasions it works nicely without me being able to spot the differences 
between these plot requests nor the underlying data. I am usually plotting 
geophysical information either on a geographical grid (latitude/longitude) or 
on a map projection (normally using proj4 for the projection of data). 

I have tried to play with the position attribute, but without success so far, 
but believe that I suffer from some form of effect from this. I have tried to 
google for information and I have read the manual pages but so far without 
success. Do you have some suggested reading for problems like this? Is the 
problem likely to be related to position?

I apologise for the vague description of the problem.

All the best
?ystein
-- 
Dr. Oystein Godoy
Norwegian Meteorological Institute 
P.O.BOX 43, Blindern, N-0313 OSLO, Norway
Ph: (+47) 2296 3000 (switchb) 2296 3334 (direct line)
Fax:(+47) 2296 3050 Institute home page: http://met.no/



From wdunlap at tibco.com  Tue Apr  8 20:47:47 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 8 Apr 2014 18:47:47 +0000
Subject: [R] Pull Stock Symbol Out of String
In-Reply-To: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
References: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC2364@PA-MBX01.na.tibco.com>

The following gets the last parenthesized sequence of non-parentheses
  > sub(".*(\\([^()]+\\))([^()]*)$", "\\1", 
          c("Aetna(AET)",
             "American Tower Corp(REIT)(ATC)",
             "No Parens",
             "Qwerty Corp (ASD)(ZXC)(123) extra stuff"))
  [1] "(AET)"     "(ATC)"     "No Parens" "(123)"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Sparks, John James
> Sent: Tuesday, April 08, 2014 11:29 AM
> To: r-help at r-project.org
> Subject: [R] Pull Stock Symbol Out of String
> 
> Dear R Helpers,
> 
> My regex skills are beginner to intermediate and banging around the web
> has not resulted in a solution to the problem below so I hope that one of
> you who has mad skills can help me out.
> 
> I want to extract the stock ticker--AMT-- out of the string
> 
> American Tower Corporation (REIT)??(AMT)
> 
> The presence of the other parenthetical text (REIT) makes this difficult.
> Please note that the string may or may not have a interfering set of
> characters such as the (REIT) so the solution needs to be generalizable to
> the last set of characters that are contained in parentheses in the larger
> string.  So an example of a string without the interfering (REIT) would be
> 
> Aetna Inc.??(AET)
> 
> 
> Your assistance would be very much appreciated.
> 
> --John Sparks
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From trujillo at unex.es  Tue Apr  8 21:01:25 2014
From: trujillo at unex.es (=?ISO-8859-1?Q?Jos=E9_Trujillo?=)
Date: Tue, 08 Apr 2014 21:01:25 +0200
Subject: [R] moses extreme reaction test
In-Reply-To: <97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
References: <534433C3.8060703@unex.es>
	<97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
Message-ID: <53444785.8090709@unex.es>

Very useful.

Very Thanks.

El 08/04/14 19:43, David Winsemius escribi?:
> On Apr 8, 2014, at 10:37 AM, Jos? Trujillo Carmona wrote:
>
>> Is there a package that contains "moses extreme reaction test"?
> Learn to search.
>
> install.packages("sos")
> library(sos)
> findFn("moses extreme")
>
>
> found 5 matches;  retrieving 1 page
>
> Downloaded 3 links in 1 packages
>



From trujillo at unex.es  Tue Apr  8 21:13:03 2014
From: trujillo at unex.es (=?windows-1252?Q?Jos=E9_Trujillo?=)
Date: Tue, 08 Apr 2014 21:13:03 +0200
Subject: [R] moses extreme reaction test
In-Reply-To: <5B7D07E2-30CC-468C-A6DA-1F247BB0A3E1@me.com>
References: <534433C3.8060703@unex.es>
	<5B7D07E2-30CC-468C-A6DA-1F247BB0A3E1@me.com>
Message-ID: <53444A3F.8010905@unex.es>

What's the problem with this:?

package ?DscTools? is not available (for R version 3.1.0 beta)



El 08/04/14 19:42, Marc Schwartz escribi?:
> On Apr 8, 2014, at 12:37 PM, Jos? Trujillo Carmona <trujillo at unex.es> wrote:
>
>> Is there a package that contains "moses extreme reaction test"?
>>
>> Thank's
>
> A search using rseek.org indicates that the DescTools package on CRAN contains a function called
> MosesTest() that appears to implement it.
>
>    http://cran.r-project.org/web/packages/DescTools/
>
> Regards,
>
> Marc Schwartz



From erinm.hodgess at gmail.com  Tue Apr  8 21:15:35 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 8 Apr 2014 14:15:35 -0500
Subject: [R] xts Annual series
Message-ID: <CACxE24mO9-7EE5XNhetnj6BCwWgHuxGZj63w3KdPrzRXiz4OzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/f7793488/attachment-0001.pl>

From boris.steipe at utoronto.ca  Tue Apr  8 21:33:55 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 8 Apr 2014 15:33:55 -0400
Subject: [R] moses extreme reaction test
In-Reply-To: <53444A3F.8010905@unex.es>
References: <534433C3.8060703@unex.es>
	<5B7D07E2-30CC-468C-A6DA-1F247BB0A3E1@me.com>
	<53444A3F.8010905@unex.es>
Message-ID: <598D96E4-7212-4795-B75A-337A23D73EA7@utoronto.ca>

Typo: "DescTools" ?


On 2014-04-08, at 3:13 PM, Jos? Trujillo wrote:

> What's the problem with this:?
> 
> package ?DscTools? is not available (for R version 3.1.0 beta)
> 
> 
> 
> El 08/04/14 19:42, Marc Schwartz escribi?:
>> On Apr 8, 2014, at 12:37 PM, Jos? Trujillo Carmona <trujillo at unex.es> wrote:
>> 
>>> Is there a package that contains "moses extreme reaction test"?
>>> 
>>> Thank's
>> 
>> A search using rseek.org indicates that the DescTools package on CRAN contains a function called
>> MosesTest() that appears to implement it.
>> 
>>   http://cran.r-project.org/web/packages/DescTools/
>> 
>> Regards,
>> 
>> Marc Schwartz
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bogaso.christofer at gmail.com  Tue Apr  8 21:40:24 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 9 Apr 2014 01:25:24 +0545
Subject: [R] Need to download this data... can someone help?
Message-ID: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/b930a748/attachment-0001.pl>

From murtaugh at stat.oregonstate.edu  Tue Apr  8 21:34:18 2014
From: murtaugh at stat.oregonstate.edu (Paul Murtaugh)
Date: Tue, 08 Apr 2014 12:34:18 -0700
Subject: [R] browser always enters debug mode
Message-ID: <53444F3A.4050509@stat.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/c86e5188/attachment-0001.pl>

From ruipbarradas at sapo.pt  Tue Apr  8 21:49:14 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 08 Apr 2014 20:49:14 +0100
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>
Message-ID: <534452BA.4050605@sapo.pt>

Hello,

Try the following.

library(XML)
URL <- 
"http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html"

dat <- readHTMLTable(readLines(URL), which=1, header=TRUE, na.strings = "-")

str(dat)
dat[4:10] <- lapply(dat[4:10], function(x) as.numeric(as.character(x)))
head(dat)


Hope this helps,

Rui Barradas

Em 08-04-2014 20:40, Christofer Bogaso escreveu:
> Hi again,
>
> I am looking some way to download this data:
>
> http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html
>
> So far I have tried following code:
>
> library(XML)
> data <- xmlParse("
> http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html
> ")
>
> However not be able to get in right way.
>
> Really appreciate if someone point me on right approach.
>
> Thanks for your time.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From murdoch.duncan at gmail.com  Tue Apr  8 22:25:05 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Apr 2014 16:25:05 -0400
Subject: [R] browser always enters debug mode
In-Reply-To: <53444F3A.4050509@stat.oregonstate.edu>
References: <53444F3A.4050509@stat.oregonstate.edu>
Message-ID: <53445B21.7030700@gmail.com>

On 08/04/2014 3:34 PM, Paul Murtaugh wrote:
> This is something peculiar about the environment on one particular linux
> box, because it doesn't happen on other computers.  Whenever I invoke
> browser() inside a function, it automatically enters debugging mode,
> with line-by-line execution of code:
>
>   > dum <- function() { browser(); x <- rnorm(10); print(x) }
>   > dum()
> Called from: dum()
> Browse[1]>
> debug at #1: x <- rnorm(10)
> Browse[2]>
> debug at #1: print(x)
> Browse[2]>
>    [1] -0.41466890  0.02276493  1.01332894 -2.72784447  0.73471652 0.41360718
>    [7]  1.67942142 -1.47384724  1.12129541 -1.13447881
>   > isdebugged(dum)
> [1] FALSE
>
> Thanks in advance for any tips on how to revert to the normal browser()
> behavior.
> -Paul

That looks like the normal browser() behaviour to me.  What do you see 
elsewhere?

Duncan Murdoch



From michael.weylandt at gmail.com  Tue Apr  8 22:27:02 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 8 Apr 2014 16:27:02 -0400
Subject: [R] xts Annual series
In-Reply-To: <CACxE24mO9-7EE5XNhetnj6BCwWgHuxGZj63w3KdPrzRXiz4OzQ@mail.gmail.com>
References: <CACxE24mO9-7EE5XNhetnj6BCwWgHuxGZj63w3KdPrzRXiz4OzQ@mail.gmail.com>
Message-ID: <C058B703-038E-4069-B965-27240DE22ACF@gmail.com>



On Apr 8, 2014, at 15:15, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
> 
> If I have the following:
> 
> x <- as.yearqtr(2000 + seq(0,7)/4)
> x
> [1] "2000 Q1" "2000 Q2" ...
> 
> which is as it should be.
> Then if I set up time as
> time <- xts(1:8,x)
> time
> 2000 Q1   1
> 2000 Q2   2
> 2000 Q3  3
> .
> .
> 
> Also fine
> Now suppose I want to have an annual xts object.  How do I go about setting
> that up, please?

Not quite as transparently. R does not (to my knowledge) have a commonly used 'year' class. 

You can of course use yearqtr objects and skip 3/4 per year. 

> 
> Thanks,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From john.laing at gmail.com  Tue Apr  8 23:32:16 2014
From: john.laing at gmail.com (John Laing)
Date: Tue, 8 Apr 2014 17:32:16 -0400
Subject: [R] xts Annual series
In-Reply-To: <C058B703-038E-4069-B965-27240DE22ACF@gmail.com>
References: <CACxE24mO9-7EE5XNhetnj6BCwWgHuxGZj63w3KdPrzRXiz4OzQ@mail.gmail.com>
	<C058B703-038E-4069-B965-27240DE22ACF@gmail.com>
Message-ID: <CAA3Wa=uajAAGo=dGHbe+V8BuKmbVkgqmDXExDZqqM9qs9Y_Ygg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/d5290056/attachment-0001.pl>

From gunter.berton at gene.com  Tue Apr  8 23:41:01 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 8 Apr 2014 14:41:01 -0700
Subject: [R] moses extreme reaction test
In-Reply-To: <97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
References: <534433C3.8060703@unex.es>
	<97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
Message-ID: <CACk-te2AALtxhxmFkM7Gvk95z2s5Wq9MGVVN1=k_LwwuRxRk3g@mail.gmail.com>

Just for the fun of it, I searched for "R package moses extreme
reaction test"  on google. The 8th hit was the package DescTools, but
that included the 3 earlier hits and responses from r-help.

So I guess the point is that "Learn to Search" may even be a bit over
the top -- is there anyone on the internet who does not use standard
search engines like google, bing, and yahoo?

Best,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Apr 8, 2014 at 10:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Apr 8, 2014, at 10:37 AM, Jos? Trujillo Carmona wrote:
>
>> Is there a package that contains "moses extreme reaction test"?
>
> Learn to search.
>
> install.packages("sos")
> library(sos)
> findFn("moses extreme")
>
>
> found 5 matches;  retrieving 1 page
>
> Downloaded 3 links in 1 packages
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Tue Apr  8 23:45:42 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 8 Apr 2014 17:45:42 -0400
Subject: [R] Pull Stock Symbol Out of String
In-Reply-To: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
References: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
Message-ID: <C3F854CF-75BE-4F22-BC8C-64D23FBBEFDA@utoronto.ca>

You could try:

# Use ?regexec and ?regmatches to return a list of grouped matches.
# Use \\(  and \\) to match literal parentheses.
# Use ... to match three characters.
# Use $ to match at end of string.

s1 <- "American Tower Corporation (REIT)? (AMT)"
s2 <- "Aetna Inc.? (AET)"
getSym <- function(s) {regmatches(s, regexec("\\((...)\\)$", s))[[1]][2]}

getSym(s1) # [1] "AMT"
getSym(s2) # [1] "AET"

Cheers,
B.




On 2014-04-08, at 2:29 PM, Sparks, John James wrote:

> Dear R Helpers,
> 
> My regex skills are beginner to intermediate and banging around the web
> has not resulted in a solution to the problem below so I hope that one of
> you who has mad skills can help me out.
> 
> I want to extract the stock ticker--AMT-- out of the string
> 
> American Tower Corporation (REIT)? (AMT)
> 
> The presence of the other parenthetical text (REIT) makes this difficult. 
> Please note that the string may or may not have a interfering set of
> characters such as the (REIT) so the solution needs to be generalizable to
> the last set of characters that are contained in parentheses in the larger
> string.  So an example of a string without the interfering (REIT) would be
> 
> Aetna Inc.? (AET)
> 
> 
> Your assistance would be very much appreciated.
> 
> --John Sparks
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From michael.weylandt at gmail.com  Wed Apr  9 00:10:37 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 8 Apr 2014 18:10:37 -0400
Subject: [R] xts Annual series
In-Reply-To: <CAA3Wa=uajAAGo=dGHbe+V8BuKmbVkgqmDXExDZqqM9qs9Y_Ygg@mail.gmail.com>
References: <CACxE24mO9-7EE5XNhetnj6BCwWgHuxGZj63w3KdPrzRXiz4OzQ@mail.gmail.com>
	<C058B703-038E-4069-B965-27240DE22ACF@gmail.com>
	<CAA3Wa=uajAAGo=dGHbe+V8BuKmbVkgqmDXExDZqqM9qs9Y_Ygg@mail.gmail.com>
Message-ID: <760185CD-02D0-44EE-9C51-23A2DD136246@gmail.com>



On Apr 8, 2014, at 17:32, John Laing <john.laing at gmail.com> wrote:

> 
> That doesn't feel very eXtensible to me.
> 

xts is quite obviously past tense. ;-)

The list of allowable index classes is found in is.timeBased IIRC and the exclusion of integers is because there's no obvious way to have them play nice with other index classes. 

M


From jim at bitwrit.com.au  Wed Apr  9 00:24:30 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 09 Apr 2014 08:24:30 +1000
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1396973169170-4688399.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>	<CF682023.F262C%macqueen1@llnl.gov>
	<1396973169170-4688399.post@n4.nabble.com>
Message-ID: <5344771E.1000708@bitwrit.com.au>

On 04/09/2014 02:06 AM, Hurr wrote:
> Don suggested something like this:
> h=c(1,2,3,4,5,6,7,8,9)
> v=c(9,8,7,6,5,4,3,2,1)
> plot(h,v,xaxt='n')
> xat=pretty(h)
> axis(1,at=xat,labels=1/xat)
> But it puts the tick marks at the data-x-locations.
> If the tick locations are not automatic or
> automatically separate from the data locations, then
> I want to tell it where to put them using
> a separate indicator. I am not familiar enough with
> R to find the answer.
> But if it would work, it would be valuable.
>
>
Hi Hurr,
If you want to use pretty:

pretty(1:9)
[1]  0  2  4  6  8 10

you don't necessarily get axis ticks at the same locations as the data 
points. Maybe you want to specify your own axis ticks and use those:

axis_ticks<-c(1,4,7,10)
axis(1,at=axis_ticks,labels=1/axis_ticks)

but that seems too obvious. Could you supply an example of what you want 
to do?

Jim



From o.godoy at met.no  Tue Apr  8 21:55:24 2014
From: o.godoy at met.no (=?ISO-8859-1?Q?=D8ystein_God=F8y?=)
Date: Tue, 8 Apr 2014 21:55:24 +0200
Subject: [R] ggplot2 and geom_tile
In-Reply-To: <2162533.O1G9xPTqRE@pc4394>
References: <2162533.O1G9xPTqRE@pc4394>
Message-ID: <3669996.EXM7ZPfNyg@pc4394>

Dear community,

Please find two sample plots illustrating the problem attached (one 
problematic and one succesful). The commands used to create these are along 
with head of each dataset is provided below:

1. 
ggplot()+geom_tile(data=uvi1$data,aes(x=lon,y=lat,fill=uvic))+scale_x_continuous()+scale_y_continuous()+geom_path(data=norway,aes(x=lon,y=lat,group=group))+coord_equal()
> head(uvi1$data)
    lat   lon uvic uvipoc uvioc uvifcc       ozone snow cloud albedo altitude   
soz         x         y
1 62.50 10.75 2.94   2.50  0.76   1.82 0.007646222  100     6   0.70     0.90 
55.33  542.6142 -2858.031
2 64.75 21.00 2.14   1.82  0.56   0.97 0.008883495  100     7   0.70     0.07 
57.58  954.2729 -2485.966
3 68.00 17.25 2.06   1.75  0.54   0.54 0.007629234  100     8   0.70     0.86 
60.83  685.2720 -2206.937
4 60.00 26.50 3.11   2.65  0.81   0.81 0.008151490  100     8   0.70     0.00 
52.83 1421.3631 -2850.813
5 57.00 12.75 3.57   3.03  0.93   3.57 0.006526370    0     0   0.05     0.04 
49.83  777.1901 -3434.686
6 67.75 15.75 1.99   1.69  0.52   1.93 0.007863361  100     2   0.70     0.25 
60.58  634.5757 -2250.036

2. 
ggplot(data=dailyssi,aes(x=x,y=y,fill=DAILY_SSI))+geom_tile()+geom_path(data=northatlantic,aes(x=x,y=y,group=group,fill=NULL))+coord_equal(xlim=range(tmp2$x),ylim=range(tmp2$y))+scale_fill_gradientn(colours=mycolours(500),breaks=seq(0,max(dailyssi$DAILY_SSI,na.rm=T),50),guide=guide_colorbar(barheight=20))+xlab("Eastings")+ylab("Northings")+ggtitle("Daily 
SSI 2014-04-03 
[W/m?]")+geom_path(data=tmp$latg,aes(x=x,y=y,fill=NULL))+geom_path(data=tmp$long,aes(x=x,y=y,fill=NULL))
> head(dailyssi)
       lat       lon       x   y DAILY_SSI
1 54.57014 -90.03772 -3797.5 2.5  67.63009
2 54.61388 -90.03777 -3792.5 2.5  72.29466
3 54.65763 -90.03782 -3787.5 2.5  61.72242
4 54.70139 -90.03787 -3782.5 2.5  56.26741
5 54.74516 -90.03792 -3777.5 2.5  48.78071
6 54.78894 -90.03797 -3772.5 2.5  46.15528

If I plot the first sample in map projected version only land contours are 
shown.

All the best
?ystein

On Tuesday April 8 2014 20.39.54 ?ystein God?y wrote:
> Dear community,
> 
> I have been using ggplot2 for visualisation and I am really impressed by
> this. I do however have a problem that returns when plotting various types
> of spatial datasets as raster images. This is probably due to me not fully
> understanding the package.
> 
> When I am plotting images using geom_tile, I sometimes only have small dots
> in the image and at other times I have apparently blank images. On other
> occasions it works nicely without me being able to spot the differences
> between these plot requests nor the underlying data. I am usually plotting
> geophysical information either on a geographical grid (latitude/longitude)
> or on a map projection (normally using proj4 for the projection of data).
> 
> I have tried to play with the position attribute, but without success so
> far, but believe that I suffer from some form of effect from this. I have
> tried to google for information and I have read the manual pages but so far
> without success. Do you have some suggested reading for problems like this?
> Is the problem likely to be related to position?
> 
> I apologise for the vague description of the problem.
> 
> All the best
> ?ystein
-- 
Dr. Oystein Godoy
Norwegian Meteorological Institute 
P.O.BOX 43, Blindern, N-0313 OSLO, Norway
Ph: (+47) 2296 3000 (switchb) 2296 3334 (direct line)
Fax:(+47) 2296 3050 Institute home page: http://met.no/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: geom_tile_1.png
Type: image/png
Size: 9632 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/bd5ab3ad/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: geom_tile_2.png
Type: image/png
Size: 203419 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/bd5ab3ad/attachment-0005.png>

From kishan.lachhani at gmail.com  Tue Apr  8 22:22:14 2014
From: kishan.lachhani at gmail.com (Kishan Lachhani)
Date: Tue, 8 Apr 2014 21:22:14 +0100
Subject: [R]  rJava not loading on Windows
Message-ID: <CAHdXaqO3ZpBX=+czBadvuaPSaTbgM6o6TTUYKzhMurXB3666GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140408/5c53e428/attachment-0001.pl>

From murtaugh at stat.oregonstate.edu  Wed Apr  9 00:05:36 2014
From: murtaugh at stat.oregonstate.edu (Paul Murtaugh)
Date: Tue, 08 Apr 2014 15:05:36 -0700
Subject: [R] browser always enters debug mode
In-Reply-To: <53444F3A.4050509@stat.oregonstate.edu>
References: <53444F3A.4050509@stat.oregonstate.edu>
Message-ID: <534472B0.8020104@stat.oregonstate.edu>

It appears to be a difference between versions 2.* and 3.* in the way 
that a newline ('enter') is handled at the browser prompt. Formerly, it 
would continue execution of the function; now it kicks you into 
debugging mode.  To get the old behavior, you need to enter 'c' at the 
browser prompt.

On 04/08/2014 12:34 PM, I wrote:
> This is something peculiar about the environment on one particular linux
> box, because it doesn't happen on other computers.  Whenever I invoke
> browser() inside a function, it automatically enters debugging mode,
> with line-by-line execution of code:
>
>   > dum <- function() { browser(); x <- rnorm(10); print(x) }
>   > dum()
> Called from: dum()
> Browse[1]>
> debug at #1: x <- rnorm(10)
> Browse[2]>
> debug at #1: print(x)
> Browse[2]>
>    [1] -0.41466890  0.02276493  1.01332894 -2.72784447  0.73471652 0.41360718
>    [7]  1.67942142 -1.47384724  1.12129541 -1.13447881
>   > isdebugged(dum)
> [1] FALSE
>
> Thanks in advance for any tips on how to revert to the normal browser()
> behavior.
> -Paul
>



From dwinsemius at comcast.net  Wed Apr  9 00:56:09 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Apr 2014 15:56:09 -0700
Subject: [R] moses extreme reaction test
In-Reply-To: <CACk-te2AALtxhxmFkM7Gvk95z2s5Wq9MGVVN1=k_LwwuRxRk3g@mail.gmail.com>
References: <534433C3.8060703@unex.es>
	<97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
	<CACk-te2AALtxhxmFkM7Gvk95z2s5Wq9MGVVN1=k_LwwuRxRk3g@mail.gmail.com>
Message-ID: <530746B2-9494-4624-93E1-4D3758E476B3@comcast.net>


On Apr 8, 2014, at 2:41 PM, Bert Gunter wrote:

> Just for the fun of it, I searched for "R package moses extreme
> reaction test"  on google. The 8th hit was the package DescTools, but
> that included the 3 earlier hits and responses from r-help.
> 
> So I guess the point is that "Learn to Search" may even be a bit over
> the top -- is there anyone on the internet who does not use standard
> search engines like google, bing, and yahoo?

I don't think I'm the only one. Using Spencer Graves' excellent package is very convenient and has delivered many answers to questions posed on R help. It pops up a browser window directly from an R console command. I like the fact that I get an R help page with `findFn`. I suspect it has prevented many more questions that we never see. 

The other search tool I have used in preference to Google is Markmail. I find Google to be sometimes non-specific and possesses an very annoying tendency to give priority to Nabble citations. None of the first page Google citations actually answered the question when I tried. Rseek was much better, but I have found it to be less focused than sos::findFn.  De gustibus non disputandem, I suppose.

I suppose I should crack open Spencer's code and learn how to call Markmail and Rseek from my console session, that is unless he accepts this feature request and beats me to it.  

-- 
David.

> 
> Best,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
> On Tue, Apr 8, 2014 at 10:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Apr 8, 2014, at 10:37 AM, Jos? Trujillo Carmona wrote:
>> 
>>> Is there a package that contains "moses extreme reaction test"?
>> 
>> Learn to search.
>> 
>> install.packages("sos")
>> library(sos)
>> findFn("moses extreme")
>> 
>> 
>> found 5 matches;  retrieving 1 page
>> 
>> Downloaded 3 links in 1 packages
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From murdoch.duncan at gmail.com  Wed Apr  9 01:45:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Apr 2014 19:45:17 -0400
Subject: [R] browser always enters debug mode
In-Reply-To: <534472B0.8020104@stat.oregonstate.edu>
References: <53444F3A.4050509@stat.oregonstate.edu>
	<534472B0.8020104@stat.oregonstate.edu>
Message-ID: <53448A0D.8060402@gmail.com>

On 08/04/2014, 6:05 PM, Paul Murtaugh wrote:
> It appears to be a difference between versions 2.* and 3.* in the way
> that a newline ('enter') is handled at the browser prompt. Formerly, it
> would continue execution of the function; now it kicks you into
> debugging mode.  To get the old behavior, you need to enter 'c' at the
> browser prompt.

Right, I didn't realize you were using old versions on those other 
machines. Things are more consistent now (though I imagine there are 
still inconsistencies, depending on how you enter the debugging system).

Duncan Murdoch

>
> On 04/08/2014 12:34 PM, I wrote:
>> This is something peculiar about the environment on one particular linux
>> box, because it doesn't happen on other computers.  Whenever I invoke
>> browser() inside a function, it automatically enters debugging mode,
>> with line-by-line execution of code:
>>
>>    > dum <- function() { browser(); x <- rnorm(10); print(x) }
>>    > dum()
>> Called from: dum()
>> Browse[1]>
>> debug at #1: x <- rnorm(10)
>> Browse[2]>
>> debug at #1: print(x)
>> Browse[2]>
>>     [1] -0.41466890  0.02276493  1.01332894 -2.72784447  0.73471652 0.41360718
>>     [7]  1.67942142 -1.47384724  1.12129541 -1.13447881
>>    > isdebugged(dum)
>> [1] FALSE
>>
>> Thanks in advance for any tips on how to revert to the normal browser()
>> behavior.
>> -Paul
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From spencer.graves at structuremonitoring.com  Wed Apr  9 01:52:48 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 08 Apr 2014 16:52:48 -0700
Subject: [R] getting arg names in function calls?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>
References: <53432120.9050500@structuremonitoring.com>
	<E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>
Message-ID: <53448BD0.7080201@structuremonitoring.com>

Hi, Bill:


       Thanks for the reply.  Unfortunately, I don't see how that solves 
the example I gave of extracting "plot(x=0, y=1)" from tstFn <- 
function()plot(0, 1).


       As I noted, body(tstFn) returns "plot(0, 1)" as an "language" 
object of class "call".  My challenge is to convert that into something 
similar, with explicit names for the arguments.


       Any thoughts?
       Spencer


On 4/7/2014 3:18 PM, William Dunlap wrote:
> Look at match.call().  E.g.,
>    > f <- function(x, y = log2(x), ...) match.call()
>    > f()
>    f()
>    > f(1, x=2, anotherArg=3, 4)
>    f(x = 2, y = 1, anotherArg = 3, 4)
> or, using its 'definition' and 'call' arguments directly
>    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)))
>    foo(x = 2, y = 1, extraArg = 3, 4)
>    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)), expand.dots=FALSE)
>    foo(x = 2, y = 1, ... = list(extraArg = 3, 4))
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Spencer Graves
>> Sent: Monday, April 07, 2014 3:05 PM
>> To: R list
>> Subject: [R] getting arg names in function calls?
>>
>>         How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?
>>
>>
>>         More generally, how can I get argument names assigned to function
>> calls in "language" objects?
>>
>>
>>         Example:
>>
>>
>> tstFn <- function()plot(0, 1)
>> bo <- body(tstFn)
>>
>>
>> tstFnxy <- function()plot(x=0, y=1)
>> boxy <- body(tstFnxy)
>>
>>
>>         Is there a function that will modify "bo" to match "boxy"?
>>
>>
>>         My current solution requires me to know the names of the
>> arguments for "plot" (in this example).  I'd prefer a more general
>> solution.
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> p.s.  I'm trying to create an animation by repeatedly calling a function
>> that contains something like text(0, 1, "abc").  By computing on the
>> language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the
>> first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the
>> third.  The function will be more general if I can get the names of the
>> arguments as just described.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From spencer.graves at structuremonitoring.com  Wed Apr  9 02:57:39 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 08 Apr 2014 17:57:39 -0700
Subject: [R] moses extreme reaction test
In-Reply-To: <530746B2-9494-4624-93E1-4D3758E476B3@comcast.net>
References: <534433C3.8060703@unex.es>
	<97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
	<CACk-te2AALtxhxmFkM7Gvk95z2s5Wq9MGVVN1=k_LwwuRxRk3g@mail.gmail.com>
	<530746B2-9494-4624-93E1-4D3758E476B3@comcast.net>
Message-ID: <53449B03.2020201@structuremonitoring.com>

On 4/8/2014 3:56 PM, David Winsemius wrote:
> On Apr 8, 2014, at 2:41 PM, Bert Gunter wrote:
>
>> Just for the fun of it, I searched for "R package moses extreme
>> reaction test"  on google. The 8th hit was the package DescTools, but
>> that included the 3 earlier hits and responses from r-help.
>>
>> So I guess the point is that "Learn to Search" may even be a bit over
>> the top -- is there anyone on the internet who does not use standard
>> search engines like google, bing, and yahoo?
> I don't think I'm the only one. Using Spencer Graves' excellent package is very convenient and has delivered many answers to questions posed on R help. It pops up a browser window directly from an R console command. I like the fact that I get an R help page with `findFn`. I suspect it has prevented many more questions that we never see.
>
> The other search tool I have used in preference to Google is Markmail. I find Google to be sometimes non-specific and possesses an very annoying tendency to give priority to Nabble citations. None of the first page Google citations actually answered the question when I tried. Rseek was much better, but I have found it to be less focused than sos::findFn.  De gustibus non disputandem, I suppose.
>
> I suppose I should crack open Spencer's code and learn how to call Markmail and Rseek from my console session, that is unless he accepts this feature request and beats me to it.


       1.  I would happily accept code to generalize findFn{sos} to use 
another search capability like Google, Markmail, Nabble or Rseek. 
However, that might not be feasible, because the current code rests on a 
database of R packages (CRAN, Bioconductor, plus a few others) 
maintained by Jonathan Baron.  When Jonathan stops maintaining that 
database, that will be the end of findFn, unless someone else takes over 
that maintenance.


       2.  Do you also use writeFindFn2xls{sos}?  That produces an Excel 
file with 3 sheets, the first of which is a summary by package.  In 
addition to the sort by count, maxScore and totalScore, I get the date 
of the latest update, whether the package has a vignette, and the names 
of author(s) and maintainer.  That tells me whether the package is being 
maintained and how easy it might be to learn.  It is by far the fastest 
literature search I know for anything statistical.  In seconds, I can 
have the outline for a talk on "R capabilities for ______________" (as 
mentioned in the sos vignette ;-)


       3.  Thanks for the kind words about findFn.


       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From h.wickham at gmail.com  Wed Apr  9 04:18:14 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 8 Apr 2014 21:18:14 -0500
Subject: [R] getting arg names in function calls?
In-Reply-To: <53448BD0.7080201@structuremonitoring.com>
References: <53432120.9050500@structuremonitoring.com>
	<E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>
	<53448BD0.7080201@structuremonitoring.com>
Message-ID: <CABdHhvGmWFO8wcYkzYr4Mb-ZLLMVkvPFSCmW1HKaghhU-5_JxA@mail.gmail.com>

You might find it helpful to read
http://adv-r.had.co.nz/Expressions.html, and look at pryr::
standardise_call().

Hadley

On Tue, Apr 8, 2014 at 6:52 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hi, Bill:
>
>
>       Thanks for the reply.  Unfortunately, I don't see how that solves the
> example I gave of extracting "plot(x=0, y=1)" from tstFn <-
> function()plot(0, 1).
>
>
>       As I noted, body(tstFn) returns "plot(0, 1)" as an "language" object
> of class "call".  My challenge is to convert that into something similar,
> with explicit names for the arguments.
>
>
>       Any thoughts?
>       Spencer
>
>
>
> On 4/7/2014 3:18 PM, William Dunlap wrote:
>>
>> Look at match.call().  E.g.,
>>    > f <- function(x, y = log2(x), ...) match.call()
>>    > f()
>>    f()
>>    > f(1, x=2, anotherArg=3, 4)
>>    f(x = 2, y = 1, anotherArg = 3, 4)
>> or, using its 'definition' and 'call' arguments directly
>>    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3,
>> 4)))
>>    foo(x = 2, y = 1, extraArg = 3, 4)
>>    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3,
>> 4)), expand.dots=FALSE)
>>    foo(x = 2, y = 1, ... = list(extraArg = 3, 4))
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On Behalf
>>> Of Spencer Graves
>>> Sent: Monday, April 07, 2014 3:05 PM
>>> To: R list
>>> Subject: [R] getting arg names in function calls?
>>>
>>>         How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?
>>>
>>>
>>>         More generally, how can I get argument names assigned to function
>>> calls in "language" objects?
>>>
>>>
>>>         Example:
>>>
>>>
>>> tstFn <- function()plot(0, 1)
>>> bo <- body(tstFn)
>>>
>>>
>>> tstFnxy <- function()plot(x=0, y=1)
>>> boxy <- body(tstFnxy)
>>>
>>>
>>>         Is there a function that will modify "bo" to match "boxy"?
>>>
>>>
>>>         My current solution requires me to know the names of the
>>> arguments for "plot" (in this example).  I'd prefer a more general
>>> solution.
>>>
>>>
>>>         Thanks,
>>>         Spencer
>>>
>>>
>>> p.s.  I'm trying to create an animation by repeatedly calling a function
>>> that contains something like text(0, 1, "abc").  By computing on the
>>> language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the
>>> first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the
>>> third.  The function will be more general if I can get the names of the
>>> arguments as just described.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/



From wdunlap at tibco.com  Wed Apr  9 04:49:00 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 9 Apr 2014 02:49:00 +0000
Subject: [R] getting arg names in function calls?
In-Reply-To: <53448BD0.7080201@structuremonitoring.com>
References: <53432120.9050500@structuremonitoring.com>
	<E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>
	<53448BD0.7080201@structuremonitoring.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC26CA@PA-MBX01.na.tibco.com>

> I don't see how that solves
> the example I gave of extracting "plot(x=0, y=1)" from tstFn <-
> function()plot(0, 1).

Try
    > match.call(definition=plot, call=body(tstFn))
    plot(x = 0, y = 1)

plot() is not a great example, since some of its methods do not have an
argument called 'y' (e.g., plot.stepfun) and it has a lot of ... arguments which
you need to go to the help file for.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at structuremonitoring.com]
> Sent: Tuesday, April 08, 2014 4:53 PM
> To: William Dunlap; R list
> Subject: Re: [R] getting arg names in function calls?
> 
> Hi, Bill:
> 
> 
>        Thanks for the reply.  Unfortunately, I don't see how that solves
> the example I gave of extracting "plot(x=0, y=1)" from tstFn <-
> function()plot(0, 1).
> 
> 
>        As I noted, body(tstFn) returns "plot(0, 1)" as an "language"
> object of class "call".  My challenge is to convert that into something
> similar, with explicit names for the arguments.
> 
> 
>        Any thoughts?
>        Spencer
> 
> 
> On 4/7/2014 3:18 PM, William Dunlap wrote:
> > Look at match.call().  E.g.,
> >    > f <- function(x, y = log2(x), ...) match.call()
> >    > f()
> >    f()
> >    > f(1, x=2, anotherArg=3, 4)
> >    f(x = 2, y = 1, anotherArg = 3, 4)
> > or, using its 'definition' and 'call' arguments directly
> >    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)))
> >    foo(x = 2, y = 1, extraArg = 3, 4)
> >    > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)),
> expand.dots=FALSE)
> >    foo(x = 2, y = 1, ... = list(extraArg = 3, 4))
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of Spencer Graves
> >> Sent: Monday, April 07, 2014 3:05 PM
> >> To: R list
> >> Subject: [R] getting arg names in function calls?
> >>
> >>         How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?
> >>
> >>
> >>         More generally, how can I get argument names assigned to function
> >> calls in "language" objects?
> >>
> >>
> >>         Example:
> >>
> >>
> >> tstFn <- function()plot(0, 1)
> >> bo <- body(tstFn)
> >>
> >>
> >> tstFnxy <- function()plot(x=0, y=1)
> >> boxy <- body(tstFnxy)
> >>
> >>
> >>         Is there a function that will modify "bo" to match "boxy"?
> >>
> >>
> >>         My current solution requires me to know the names of the
> >> arguments for "plot" (in this example).  I'd prefer a more general
> >> solution.
> >>
> >>
> >>         Thanks,
> >>         Spencer
> >>
> >>
> >> p.s.  I'm trying to create an animation by repeatedly calling a function
> >> that contains something like text(0, 1, "abc").  By computing on the
> >> language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the
> >> first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the
> >> third.  The function will be more general if I can get the names of the
> >> arguments as just described.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com



From hill0093 at umn.edu  Wed Apr  9 05:12:52 2014
From: hill0093 at umn.edu (Hurr)
Date: Tue, 8 Apr 2014 20:12:52 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <5339EDF8.1070205@bitwrit.com.au>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
Message-ID: <1397013172001-4688443.post@n4.nabble.com>


This still puts tick marks at data points:
h=c(1,2,3,4,5,6,7,8,9)
v=c(9,8,7,6,5,4,3,2,1)
plot(h,v,xaxt='n')
x<-c(1.6,2.6,6.6,9.6,12.9)
axis_labels<-1/pretty(x)
axis(1,at=pretty(x),labels=axis_labels)
How do I get the axis to approx 13 ?




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917p4688443.html
Sent from the R help mailing list archive at Nabble.com.



From smartpink111 at yahoo.com  Wed Apr  9 03:17:55 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Apr 2014 18:17:55 -0700 (PDT)
Subject: [R] Pull Stock Symbol Out of String
In-Reply-To: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
References: <7f7e7c7ca8bc7ea027b9c7aff3affe27.squirrel@webmail.uic.edu>
Message-ID: <1397006275.12869.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You may try:
library(qdap)
str1 <- c("American Tower Corporation (REIT)? (AMT)", "Aetna Inc.? (AET)")
unlist(lapply(bracketXtract(str1,"round"),tail,1),use.names=F)
#[1] "AMT" "AET" 

A.K.


On Tuesday, April 8, 2014 7:48 PM, "Sparks, John James" <jspark4 at uic.edu> wrote:
Dear R Helpers,

My regex skills are beginner to intermediate and banging around the web
has not resulted in a solution to the problem below so I hope that one of
you who has mad skills can help me out.

I want to extract the stock ticker--AMT-- out of the string

American Tower Corporation (REIT)??(AMT)

The presence of the other parenthetical text (REIT) makes this difficult. 
Please note that the string may or may not have a interfering set of
characters such as the (REIT) so the solution needs to be generalizable to
the last set of characters that are contained in parentheses in the larger
string.? So an example of a string without the interfering (REIT) would be

Aetna Inc.??(AET)


Your assistance would be very much appreciated.

--John Sparks

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From frtog at vestas.com  Wed Apr  9 07:23:34 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 9 Apr 2014 07:23:34 +0200
Subject: [R] Plotting does odd line thing
In-Reply-To: <CACftpvorAvrW6scQs=1Js4fXGYm49_zOBgdZqsFEx1Z-mdgmJQ@mail.gmail.com>
References: <CACftpvqydC1KcVGfs7CCAvmGyMcgbDEj8fUYgcLvBAi02rVN9w@mail.gmail.com>
	<5343646E.9060807@bitwrit.com.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF21B7@DKRDSEXC016.vestas.net>
	<CACftpvorAvrW6scQs=1Js4fXGYm49_zOBgdZqsFEx1Z-mdgmJQ@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF2759@DKRDSEXC016.vestas.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/65a9855c/attachment-0001.pl>

From sachin.abeywardana at gmail.com  Wed Apr  9 08:11:26 2014
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Wed, 9 Apr 2014 16:11:26 +1000
Subject: [R] Not able to convert data.frame to numeric properly
Message-ID: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>

I have the following:


>a #note that the 28 is a row.name

        GHP     GP      T     Tn
28   2.2194 2.6561 2.9007 3.2988

>min(as.numeric(a))
2.9007
>min(as.numeric(as.character(a)))
2.9007
>as.numeric(as.character(a))                 #What's going on here???
[1] 33.0000 29.0000  2.9007  3.2988

So basically how do I get this to show the correct value of 2.21 as my
minimum value?

Thanks,
Sachin



From frtog at vestas.com  Wed Apr  9 08:17:18 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 9 Apr 2014 08:17:18 +0200
Subject: [R] Not able to convert data.frame to numeric properly
In-Reply-To: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>
References: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>

We can't say because we don't know how a was created.

Please email the output from 

str(a)

and

dput(a)



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Sachinthaka Abeywardana
> Sent: 9. april 2014 08:11
> To: r-help at r-project.org
> Subject: [R] Not able to convert data.frame to numeric properly
> 
> I have the following:
> 
> 
> >a #note that the 28 is a row.name
> 
>         GHP     GP      T     Tn
> 28   2.2194 2.6561 2.9007 3.2988
> 
> >min(as.numeric(a))
> 2.9007
> >min(as.numeric(as.character(a)))
> 2.9007
> >as.numeric(as.character(a))                 #What's going on here???
> [1] 33.0000 29.0000  2.9007  3.2988
> 
> So basically how do I get this to show the correct value of 2.21 as my
> minimum value?
> 
> Thanks,
> Sachin
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From sachin.abeywardana at gmail.com  Wed Apr  9 08:25:30 2014
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Wed, 9 Apr 2014 16:25:30 +1000
Subject: [R] Not able to convert data.frame to numeric properly
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>
References: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>
Message-ID: <CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>

a is ofcourse a subset of data.frame, a ROW of the original table specifically.

> str(a)
'data.frame': 1 obs. of  4 variables:
 $ GHP: Factor w/ 51 levels "0.0944","0.1446",..: 33
 $ GP : Factor w/ 51 levels "0.1755","0.3582",..: 29
 $ T  : num 2.9
 $ Tn : num 3.3
> dput(a)
structure(list(GHP = structure(33L, .Label = c("0.0944", "0.1446",
"0.2", "0.4124", "0.7601", "0.871", "0.8849", "0.9176", "1.0168",
"1.0663", "1.0947", "1.1823", "1.1831", "1.2418", "1.2542", "1.3082",
"1.3283", "1.3758", "1.4437", "1.4621", "1.5769", "1.6699", "1.7306",
"1.8366", "1.8456", "1.8651", "1.8972", "1.9595", "2.0781", "2.0802",
"2.1553", "2.2097", "2.2194", "2.3669", "2.3935", "2.5351", "2.5374",
"2.5966", "2.6934", "2.7764", "2.9073", "6.003", "6.0825", "6.1013",
"6.1068", "6.1675", "6.2401", "6.6001", "6.6047", "7.8665", "+AC0-27.0565"
), class = "factor"), GP = structure(29L, .Label = c("0.1755",
"0.3582", "0.4155", "0.4208", "0.7388", "0.8394", "0.8853", "0.9254",
"0.9423", "0.9695", "0.9757", "0.9793", "0.9896", "1.0422", "1.0519",
"1.116", "1.2482", "1.2691", "1.2735", "1.2788", "1.2948", "1.3141",
"1.3204", "1.4006", "1.5333", "1.6157", "1.9003", "2.6024", "2.6561",
"2.7466", "2.7572", "2.8108", "2.8256", "2.9565", "2.978", "3.0665",
"3.1155", "3.2027", "3.2123", "3.257", "3.4055", "6.0616", "6.0671",
"6.1166", "6.2053", "6.592", "6.6734", "7.005", "7.3159", "8.5777",
"+AC0-20.3347"), class = "factor"), T = 2.9007, Tn = 3.2988), .Names = c("GHP",
"GP", "T", "Tn"), row.names = 28L, class = "data.frame")

On Wed, Apr 9, 2014 at 4:17 PM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:
> We can't say because we don't know how a was created.
>
> Please email the output from
>
> str(a)
>
> and
>
> dput(a)
>
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Sachinthaka Abeywardana
>> Sent: 9. april 2014 08:11
>> To: r-help at r-project.org
>> Subject: [R] Not able to convert data.frame to numeric properly
>>
>> I have the following:
>>
>>
>> >a #note that the 28 is a row.name
>>
>>         GHP     GP      T     Tn
>> 28   2.2194 2.6561 2.9007 3.2988
>>
>> >min(as.numeric(a))
>> 2.9007
>> >min(as.numeric(as.character(a)))
>> 2.9007
>> >as.numeric(as.character(a))                 #What's going on here???
>> [1] 33.0000 29.0000  2.9007  3.2988
>>
>> So basically how do I get this to show the correct value of 2.21 as my
>> minimum value?
>>
>> Thanks,
>> Sachin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Wed Apr  9 08:48:29 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 9 Apr 2014 08:48:29 +0200
Subject: [R] moses extreme reaction test
In-Reply-To: <530746B2-9494-4624-93E1-4D3758E476B3@comcast.net>
References: <534433C3.8060703@unex.es>
	<97E6A513-B728-4EEA-B732-988FC78DAC11@comcast.net>
	<CACk-te2AALtxhxmFkM7Gvk95z2s5Wq9MGVVN1=k_LwwuRxRk3g@mail.gmail.com>
	<530746B2-9494-4624-93E1-4D3758E476B3@comcast.net>
Message-ID: <18873F2A-E829-488E-BF27-DC20E64CB6D0@xs4all.nl>


On 09-04-2014, at 00:56, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Apr 8, 2014, at 2:41 PM, Bert Gunter wrote:
> 
>> Just for the fun of it, I searched for "R package moses extreme
>> reaction test"  on google. The 8th hit was the package DescTools, but
>> that included the 3 earlier hits and responses from r-help.
>> 
>> So I guess the point is that "Learn to Search" may even be a bit over
>> the top -- is there anyone on the internet who does not use standard
>> search engines like google, bing, and yahoo?
> 
> I don't think I'm the only one. Using Spencer Graves' excellent package is very convenient and has delivered many answers to questions posed on R help. It pops up a browser window directly from an R console command. I like the fact that I get an R help page with `findFn`. I suspect it has prevented many more questions that we never see. 
> 
> The other search tool I have used in preference to Google is Markmail. I find Google to be sometimes non-specific and possesses an very annoying tendency to give priority to Nabble citations. None of the first page Google citations actually answered the question when I tried. Rseek was much better, but I have found it to be less focused than sos::findFn.  De gustibus non disputandem, I suppose.
> 

For the record:  De gustibus non est disputandum

See http://en.wikipedia.org/wiki/De_gustibus_non_est_disputandum

Berend



From frtog at vestas.com  Wed Apr  9 08:50:10 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 9 Apr 2014 08:50:10 +0200
Subject: [R] Not able to convert data.frame to numeric properly
In-Reply-To: <CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>
References: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>
	<CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5BF27D1@DKRDSEXC016.vestas.net>

Now we are able to help you. What you see is an artefact of an object in T of class 'factor'

 
> ## So please, see ?factor
> ## first 2 columns subset of a factor
> str(a)
'data.frame':	1 obs. of  4 variables:
 $ GHP: Factor w/ 51 levels "0.0944","0.1446",..: 33
 $ GP : Factor w/ 51 levels "0.1755","0.3582",..: 29
 $ T  : num 2.9
 $ Tn : num 3.3
> 
> ## you can't do this for a dataframe with columns of factors
> ## it doesn't give you the labels of the levels as one would expect
> ## but for some reason the number of levels
> as.character(a)
[1] "33"     "29"     "2.9007" "3.2988"
> 
> ## gets the number of level (33)
> as.numeric(a[,1])
[1] 33
> ## gets the label of level number 33
> as.character(a[,1])
[1] "2.2194"
> ## gets the label as a numeric
> as.numeric(as.character(a[,1]))
[1] 2.2194
> 
> ## do this for the first 2 columns
> for (i in 1:2) a[,i] <- as.numeric(as.character(a[,i]))
> 
> ## the structure of a
> str(a)
'data.frame':	1 obs. of  4 variables:
 $ GHP: num 2.22
 $ GP : num 2.66
 $ T  : num 2.9
 $ Tn : num 3.3
>
> ## now
> min(a)
[1] 2.2194
>

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: Sachinthaka Abeywardana [mailto:sachin.abeywardana at gmail.com]
> Sent: 9. april 2014 08:26
> To: Frede Aakmann T?gersen; r-help at r-project.org
> Subject: Re: [R] Not able to convert data.frame to numeric properly
> 
> a is ofcourse a subset of data.frame, a ROW of the original table specifically.
> 
> > str(a)
> 'data.frame': 1 obs. of  4 variables:
>  $ GHP: Factor w/ 51 levels "0.0944","0.1446",..: 33
>  $ GP : Factor w/ 51 levels "0.1755","0.3582",..: 29
>  $ T  : num 2.9
>  $ Tn : num 3.3
> > dput(a)
> structure(list(GHP = structure(33L, .Label = c("0.0944", "0.1446",
> "0.2", "0.4124", "0.7601", "0.871", "0.8849", "0.9176", "1.0168",
> "1.0663", "1.0947", "1.1823", "1.1831", "1.2418", "1.2542", "1.3082",
> "1.3283", "1.3758", "1.4437", "1.4621", "1.5769", "1.6699", "1.7306",
> "1.8366", "1.8456", "1.8651", "1.8972", "1.9595", "2.0781", "2.0802",
> "2.1553", "2.2097", "2.2194", "2.3669", "2.3935", "2.5351", "2.5374",
> "2.5966", "2.6934", "2.7764", "2.9073", "6.003", "6.0825", "6.1013",
> "6.1068", "6.1675", "6.2401", "6.6001", "6.6047", "7.8665", "+AC0-27.0565"
> ), class = "factor"), GP = structure(29L, .Label = c("0.1755",
> "0.3582", "0.4155", "0.4208", "0.7388", "0.8394", "0.8853", "0.9254",
> "0.9423", "0.9695", "0.9757", "0.9793", "0.9896", "1.0422", "1.0519",
> "1.116", "1.2482", "1.2691", "1.2735", "1.2788", "1.2948", "1.3141",
> "1.3204", "1.4006", "1.5333", "1.6157", "1.9003", "2.6024", "2.6561",
> "2.7466", "2.7572", "2.8108", "2.8256", "2.9565", "2.978", "3.0665",
> "3.1155", "3.2027", "3.2123", "3.257", "3.4055", "6.0616", "6.0671",
> "6.1166", "6.2053", "6.592", "6.6734", "7.005", "7.3159", "8.5777",
> "+AC0-20.3347"), class = "factor"), T = 2.9007, Tn = 3.2988), .Names =
> c("GHP",
> "GP", "T", "Tn"), row.names = 28L, class = "data.frame")
> 
> On Wed, Apr 9, 2014 at 4:17 PM, Frede Aakmann T?gersen
> <frtog at vestas.com> wrote:
> > We can't say because we don't know how a was created.
> >
> > Please email the output from
> >
> > str(a)
> >
> > and
> >
> > dput(a)
> >
> >
> >
> > Yours sincerely / Med venlig hilsen
> >
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org]
> >> On Behalf Of Sachinthaka Abeywardana
> >> Sent: 9. april 2014 08:11
> >> To: r-help at r-project.org
> >> Subject: [R] Not able to convert data.frame to numeric properly
> >>
> >> I have the following:
> >>
> >>
> >> >a #note that the 28 is a row.name
> >>
> >>         GHP     GP      T     Tn
> >> 28   2.2194 2.6561 2.9007 3.2988
> >>
> >> >min(as.numeric(a))
> >> 2.9007
> >> >min(as.numeric(as.character(a)))
> >> 2.9007
> >> >as.numeric(as.character(a))                 #What's going on here???
> >> [1] 33.0000 29.0000  2.9007  3.2988
> >>
> >> So basically how do I get this to show the correct value of 2.21 as my
> >> minimum value?
> >>
> >> Thanks,
> >> Sachin
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Apr  9 09:10:29 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 00:10:29 -0700 (PDT)
Subject: [R] Replacement Value
In-Reply-To: <CAMgoKB+hfsXyMCmSH2J1VqAzacxGbo8zaSZVwR7ioFhNW-9FrA@mail.gmail.com>
References: <CAMgoKB+jt61mVjAz5YZohWinTj3MtgadOwLhB_DQJXYk_z9AzA@mail.gmail.com>	<1396949139.13538.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAMgoKBJJ9y9BmDvT-FT9_7-ga0hGxDMq_+9fbvPwRWQbtZC0oQ@mail.gmail.com>	<1397018888.11128.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAMgoKB+hfsXyMCmSH2J1VqAzacxGbo8zaSZVwR7ioFhNW-9FrA@mail.gmail.com>
Message-ID: <1397027429.34991.YahooMailNeo@web142604.mail.bf1.yahoo.com>


Hi Dila,

If 'dat' is the dataset:
dat$C[dat$B==0] <- 0?

A.K.
On Wednesday, April 9, 2014 1:30 AM, dila radi <dilaradi21 at gmail.com> wrote:

Dear arun
Yes indeed..if the value in B is O..next value in the same row also 0..
other value than 0 remains unchanged.
On Apr 9, 2014 12:48 PM, "arun" <smartpink111 at yahoo.com> wrote:

Dear Dila,
>
>What I understand from your two rules are that there is only one rule and that is concerning with '0' for B.? All other values are left without any change.
>
>
>
>
>
>On Wednesday, April 9, 2014 12:45 AM, dila radi <dilaradi21 at gmail.com> wrote:
>
>Dear Arun
>I just concern on values 1 and 0 only. Other values did not follow the rules I mention before. Thank you.
>Dila
>On Apr 8, 2014 5:28 PM, "arun" <smartpink111 at yahoo.com> wrote:
>
>HI,
>>What about values >1.0 for B?? Does it also follow the same rule as your second rule.
>>A.K.
>>
>>
>>
>>
>>
>>On Tuesday, April 8, 2014 12:11 AM, dila radi <dilaradi21 at gmail.com> wrote:
>>Hi all,
>>
>>I have problem on how to replace value. I have this kind of data set:
>>
>>structure(list(A = c(0, 12.6, 10.1, 8.1, 14.4, 0, 0, 0, 0, 0.5,
>>12.9, 25.9, 49, 0, 0, 0, 0, 0, 7.8), B = c(0, 0, 9.1, 9.3, 1.5,
>>1, 1, 1, 1.7, 6, 0, 0, 0, 1.7, 3.8, 0, 0, 0, 1), C = c(1, 1,
>>9.100000004, 9.299999999, 1.5, 1, 1, 1, 1.7, 5.999999999, 1,
>>1, 1, 1.7, 3.800000001, 1, 1, 1, 1)), .Names = c("A", "B", "C"
>>), row.names = c(NA, 19L), class = "data.frame")
>>
>>The problem is the value under variable 'C'.? ?It supposed to be like this:
>>
>>1) When value is '0' under variable 'B', the next value under variable 'C'
>>also should be '0'.
>>
>>2) When value is '1' under variable 'B', there is no changes for values
>>under variable 'C'.
>>
>>How do I achieved this by fulfill these two conditions? Thank you so much.
>>
>>
>>Regards,
>>Dila
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>



From smartpink111 at yahoo.com  Wed Apr  9 09:21:29 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 00:21:29 -0700 (PDT)
Subject: [R] Not able to convert data.frame to numeric properly
In-Reply-To: <CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>
References: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>
	<CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>
Message-ID: <1397028089.37827.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
min(sapply(lapply(a,as.character),as.numeric))?
#[1] 2.2194 


A.K.

On Wednesday, April 9, 2014 2:27 AM, Sachinthaka Abeywardana <sachin.abeywardana at gmail.com> wrote:

a is ofcourse a subset of data.frame, a ROW of the original table specifically.

> str(a)
'data.frame': 1 obs. of? 4 variables:
$ GHP: Factor w/ 51 levels "0.0944","0.1446",..: 33
$ GP : Factor w/ 51 levels "0.1755","0.3582",..: 29
$ T? : num 2.9
$ Tn : num 3.3
> dput(a)
structure(list(GHP = structure(33L, .Label = c("0.0944", "0.1446",
"0.2", "0.4124", "0.7601", "0.871", "0.8849", "0.9176", "1.0168",
"1.0663", "1.0947", "1.1823", "1.1831", "1.2418", "1.2542", "1.3082",
"1.3283", "1.3758", "1.4437", "1.4621", "1.5769", "1.6699", "1.7306",
"1.8366", "1.8456", "1.8651", "1.8972", "1.9595", "2.0781", "2.0802",
"2.1553", "2.2097", "2.2194", "2.3669", "2.3935", "2.5351", "2.5374",
"2.5966", "2.6934", "2.7764", "2.9073", "6.003", "6.0825", "6.1013",
"6.1068", "6.1675", "6.2401", "6.6001", "6.6047", "7.8665", "+AC0-27.0565"
), class = "factor"), GP = structure(29L, .Label = c("0.1755",
"0.3582", "0.4155", "0.4208", "0.7388", "0.8394", "0.8853", "0.9254",
"0.9423", "0.9695", "0.9757", "0.9793", "0.9896", "1.0422", "1.0519",
"1.116", "1.2482", "1.2691", "1.2735", "1.2788", "1.2948", "1.3141",
"1.3204", "1.4006", "1.5333", "1.6157", "1.9003", "2.6024", "2.6561",
"2.7466", "2.7572", "2.8108", "2.8256", "2.9565", "2.978", "3.0665",
"3.1155", "3.2027", "3.2123", "3.257", "3.4055", "6.0616", "6.0671",
"6.1166", "6.2053", "6.592", "6.6734", "7.005", "7.3159", "8.5777",
"+AC0-20.3347"), class = "factor"), T = 2.9007, Tn = 3.2988), .Names = c("GHP",
"GP", "T", "Tn"), row.names = 28L, class = "data.frame")


On Wed, Apr 9, 2014 at 4:17 PM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:
> We can't say because we don't know how a was created.
>
> Please email the output from
>
> str(a)
>
> and
>
> dput(a)
>
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Sachinthaka Abeywardana
>> Sent: 9. april 2014 08:11
>> To: r-help at r-project.org
>> Subject: [R] Not able to convert data.frame to numeric properly
>>
>> I have the following:
>>
>>
>> >a #note that the 28 is a row.name
>>
>>? ? ? ???GHP? ???GP? ? ? T? ???Tn
>> 28???2.2194 2.6561 2.9007 3.2988
>>
>> >min(as.numeric(a))
>> 2.9007
>> >min(as.numeric(as.character(a)))
>> 2.9007
>> >as.numeric(as.character(a))? ? ? ? ? ? ? ???#What's going on here???
>> [1] 33.0000 29.0000? 2.9007? 3.2988
>>
>> So basically how do I get this to show the correct value of 2.21 as my
>> minimum value?
>>
>> Thanks,
>> Sachin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Wed Apr  9 09:27:05 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 09 Apr 2014 17:27:05 +1000
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1397013172001-4688443.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
Message-ID: <5344F649.1020907@bitwrit.com.au>

On 04/09/2014 01:12 PM, Hurr wrote:
>
> This still puts tick marks at data points:
> h=c(1,2,3,4,5,6,7,8,9)
> v=c(9,8,7,6,5,4,3,2,1)
> plot(h,v,xaxt='n')
> x<-c(1.6,2.6,6.6,9.6,12.9)
> axis_labels<-1/pretty(x)
> axis(1,at=pretty(x),labels=axis_labels)
> How do I get the axis to approx 13 ?
>
>
plot(x,xaxt="n",xlim=c(1,13))

Jim



From hill0093 at umn.edu  Wed Apr  9 10:17:47 2014
From: hill0093 at umn.edu (Hurr)
Date: Wed, 9 Apr 2014 01:17:47 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <5344F649.1020907@bitwrit.com.au>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
	<5344F649.1020907@bitwrit.com.au>
Message-ID: <1397031467054-4688456.post@n4.nabble.com>

Thanks Jim, Labels for the following are at 0,2,4,6,8,10,12, not data, good.
and omitted where lack of room.

h=c(1.2,2.4,3.1,4.7,5.3,6.2,7.6,8.8,9.7)
v=c(9,8,7,6,5,4,3,2,1)
plot(h,v,xaxt='n',xlim=c(-1,13))
x<-c(1.6,2.6,6.6,9.6,12.9)
axis_labels<-1/pretty(x)
axis(1,at=pretty(x),labels=axis_labels)

Suppose I really did want more control, like where and what exactly




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917p4688456.html
Sent from the R help mailing list archive at Nabble.com.



From jim at bitwrit.com.au  Wed Apr  9 10:22:20 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 09 Apr 2014 18:22:20 +1000
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1397031467054-4688456.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>	<5339EDF8.1070205@bitwrit.com.au>	<1397013172001-4688443.post@n4.nabble.com>	<5344F649.1020907@bitwrit.com.au>
	<1397031467054-4688456.post@n4.nabble.com>
Message-ID: <5345033C.6080701@bitwrit.com.au>

On 04/09/2014 06:17 PM, Hurr wrote:
> Thanks Jim, Labels for the following are at 0,2,4,6,8,10,12, not data, good.
> and omitted where lack of room.
>
> h=c(1.2,2.4,3.1,4.7,5.3,6.2,7.6,8.8,9.7)
> v=c(9,8,7,6,5,4,3,2,1)
> plot(h,v,xaxt='n',xlim=c(-1,13))
> x<-c(1.6,2.6,6.6,9.6,12.9)
> axis_labels<-1/pretty(x)
> axis(1,at=pretty(x),labels=axis_labels)
>
> Suppose I really did want more control, like where and what exactly
>
If you want to specify the exact values of the ticks for the "at" 
argument, just remember to extend the x axis on the initial plot to 
include all x values. If you want to get the missing labels, look at the 
staxlab function in the plotrix package.

Jim



From smartpink111 at yahoo.com  Wed Apr  9 09:11:17 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 00:11:17 -0700 (PDT)
Subject: [R] Fw: Re: Splitting columns  and forming new data files in R
In-Reply-To: <1397021212.63742.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <333186.94996.bm@smtp212.mail.bf1.yahoo.com>
	<1397004647.27077.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397006020.88635.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397006352.78931.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1397006881.31441.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397020015.75948.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397021212.63742.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1397027477.77887.YahooMailNeo@web142603.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/fc2a0a06/attachment-0001.pl>

From tal.galili at gmail.com  Wed Apr  9 14:02:39 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Wed, 9 Apr 2014 15:02:39 +0300
Subject: [R] How to implement a recurring "check for updates" for R and
	packages?
Message-ID: <CANdJ3dUmbtTpcNtCjL_-4C5UJOSJVJrJQJ6g3XMmbZVJk5a0sQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/68a6a58f/attachment-0001.pl>

From gunter.berton at gene.com  Wed Apr  9 15:25:01 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 9 Apr 2014 06:25:01 -0700
Subject: [R] Not able to convert data.frame to numeric properly
In-Reply-To: <1397028089.37827.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAGuusR8gL_fxeyjYFeVjxZDB2+OKZgvUTYom1656GUO+g92NOg@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5BF279C@DKRDSEXC016.vestas.net>
	<CAGuusR9W4BWsMsbEzycrLFfELr0S-3-Vo0T4=yj5CUhzbMWbFg@mail.gmail.com>
	<1397028089.37827.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CACk-te3W8aOmdJU02ezTg3o2o35s6b5HyysczUWsvPDr7wgssA@mail.gmail.com>

I would suggest that unlist(lapply(... should always be preferable to
sapply(lapply... if you want to convert data in a data frame to a
vector. I can't see any reason to run the same loop twice. But check
timings -- maybe I'm overly sensitive to unimportant aesthetics.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Wed, Apr 9, 2014 at 12:21 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> Try:
> min(sapply(lapply(a,as.character),as.numeric))
> #[1] 2.2194
>
>
> A.K.
>
> On Wednesday, April 9, 2014 2:27 AM, Sachinthaka Abeywardana <sachin.abeywardana at gmail.com> wrote:
>
> a is ofcourse a subset of data.frame, a ROW of the original table specifically.
>
>> str(a)
> 'data.frame': 1 obs. of  4 variables:
> $ GHP: Factor w/ 51 levels "0.0944","0.1446",..: 33
> $ GP : Factor w/ 51 levels "0.1755","0.3582",..: 29
> $ T  : num 2.9
> $ Tn : num 3.3
>> dput(a)
> structure(list(GHP = structure(33L, .Label = c("0.0944", "0.1446",
> "0.2", "0.4124", "0.7601", "0.871", "0.8849", "0.9176", "1.0168",
> "1.0663", "1.0947", "1.1823", "1.1831", "1.2418", "1.2542", "1.3082",
> "1.3283", "1.3758", "1.4437", "1.4621", "1.5769", "1.6699", "1.7306",
> "1.8366", "1.8456", "1.8651", "1.8972", "1.9595", "2.0781", "2.0802",
> "2.1553", "2.2097", "2.2194", "2.3669", "2.3935", "2.5351", "2.5374",
> "2.5966", "2.6934", "2.7764", "2.9073", "6.003", "6.0825", "6.1013",
> "6.1068", "6.1675", "6.2401", "6.6001", "6.6047", "7.8665", "+AC0-27.0565"
> ), class = "factor"), GP = structure(29L, .Label = c("0.1755",
> "0.3582", "0.4155", "0.4208", "0.7388", "0.8394", "0.8853", "0.9254",
> "0.9423", "0.9695", "0.9757", "0.9793", "0.9896", "1.0422", "1.0519",
> "1.116", "1.2482", "1.2691", "1.2735", "1.2788", "1.2948", "1.3141",
> "1.3204", "1.4006", "1.5333", "1.6157", "1.9003", "2.6024", "2.6561",
> "2.7466", "2.7572", "2.8108", "2.8256", "2.9565", "2.978", "3.0665",
> "3.1155", "3.2027", "3.2123", "3.257", "3.4055", "6.0616", "6.0671",
> "6.1166", "6.2053", "6.592", "6.6734", "7.005", "7.3159", "8.5777",
> "+AC0-20.3347"), class = "factor"), T = 2.9007, Tn = 3.2988), .Names = c("GHP",
> "GP", "T", "Tn"), row.names = 28L, class = "data.frame")
>
>
> On Wed, Apr 9, 2014 at 4:17 PM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:
>> We can't say because we don't know how a was created.
>>
>> Please email the output from
>>
>> str(a)
>>
>> and
>>
>> dput(a)
>>
>>
>>
>> Yours sincerely / Med venlig hilsen
>>
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On Behalf Of Sachinthaka Abeywardana
>>> Sent: 9. april 2014 08:11
>>> To: r-help at r-project.org
>>> Subject: [R] Not able to convert data.frame to numeric properly
>>>
>>> I have the following:
>>>
>>>
>>> >a #note that the 28 is a row.name
>>>
>>>         GHP     GP      T     Tn
>>> 28   2.2194 2.6561 2.9007 3.2988
>>>
>>> >min(as.numeric(a))
>>> 2.9007
>>> >min(as.numeric(as.character(a)))
>>> 2.9007
>>> >as.numeric(as.character(a))                 #What's going on here???
>>> [1] 33.0000 29.0000  2.9007  3.2988
>>>
>>> So basically how do I get this to show the correct value of 2.21 as my
>>> minimum value?
>>>
>>> Thanks,
>>> Sachin
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From lists at revelle.net  Wed Apr  9 16:35:07 2014
From: lists at revelle.net (William Revelle)
Date: Wed, 9 Apr 2014 09:35:07 -0500
Subject: [R] Issues with fa() function in "psych"
In-Reply-To: <CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>
References: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
	<CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>
Message-ID: <85300B76-7E05-4663-8D3A-E8C3FCE7DB15@revelle.net>

Sagnik raises the question as to why the psych package does not offer the ?equamax? rotation.
It is because all rotations are handled through the GPArotation package which does not offer equamax.

Sagnik also points out that if the requested rotation is not available, fa defaults to rotate=?none? without any warning.  I have fixed that for the  next release (1.4.4).
(1.4.4 also will fix a bug in corr.test introduced into 1.4.3).


The question about why printing just the loadings matrix leaves blank cells?  That is because the loadings matrix of class ?loadings? which the default print function prints with a cut = .3.
Using the example from Sagnik, print(efa_pa$loadings,cut=0) will match the output of efa_pa.

The fm=?pa? option runs conventional principal axis factor analysis (ala SPSS).  As documented, this iterates max.iter times

"Not all factor programs that do principal axes do iterative solutions. The example from the SAS manual (Chapter 26) is such a case. To achieve that solution, it is necessary to specify that the max.iterations = 1. Comparing that solution to an iterated one (the default) shows that iterations improve the solution. In addition, fm="minres" or fm="mle" produces even better solutions for this example.?

The com column is factor complexity using the index developed by Hofmann (1978).  It is a row wise measure of item complexity.
I have added more documentation to this in 1.4.4

Bill


On Apr 8, 2014, at 2:28 AM, Pascal Oettli <kridox at ymail.com> wrote:

> Hello,
> 
> And what about submitting your suggestions directly to the package
> author/maintainer?
> 
> And please don't post in HTML.
> 
> Regards,
> Pascal
> 
> On Tue, Apr 8, 2014 at 3:13 PM, sagnik chakravarty
> <sagnik.stats at gmail.com> wrote:
>> Hi Team,
>> 
>> I was using your "psych" package for factor analysis and was also comparing
>> the results with SAS results. I have some suggestions and/or confusions
>> regarding the fa() function in the package:
>> 
>>   - The fa() function *doesn't account for Heywood cases* (communality
>>   greater than 1) and never ever throws out any error related to that which
>>   other softwares do. This is a serious and common issue in iterative factor
>>   analysis and hence should have been accounted for.
>> 
>> 
>>   - The fa() function doesn't provide "equamax" rotation in its rotation
>>   list and still if you specify "*rotation=equamax*", it will run without
>>   throwing out any error and even mentioning in the result that "equamax" has
>>   been applied. But I have thoroughly compared results from "
>>   *rotation=none*" and "*rotation=equamax*" options and they are exactly
>>   same. *That means fa() is not doing the rotation at all and yet telling
>>   that it is doing that!!* I have even mentioned "*rotation=crap*" option
>>   just to check and surprisingly it ran(without any error) with the result
>>   showing:
>> 
>>           *Factor Analysis using method =  gls*
>> *           Call: fa(r = cor_mat, nfactors = 4, n.obs = 69576, rotate =
>> "crap", fm = "gls")*
>> 
>>            I hope you understand the severity of this bug and hence
>> request you to correct this.
>> 
>>   - To my sense, there might be some problem with "fm=ml" and "fm=pa"
>>   options since the convergence issue should be with MLE method and not PA
>>   method but while running factor analysis with PA, I am getting the
>>   following warning:
>> 
>>            *maximum iteration exceeded*
>> *            The estimated weights for the factor scores are probably
>> incorrect.  Try a different factor extraction method.*
>> 
>>             If I compare the results of R and SAS,* I am getting
>> convergence error for MLE in SAS whereas I am getting the same error for PA
>> in R *!! I am not being able to understand this mismatch.
>> 
>>   - If I call the *loading matrix like efa_pa$loadings, the matrix shown
>>   has many blank cells whereas the final result showing the loadings doesn't
>>   have so* !!
>> 
>> *Loadings:*
>> *             PA1    PA2    PA3    PA4   *
>> *Var1    0.401                       -0.243*
>> *Var2    0.336 -0.104            0.710*
>> *Var3    0.624  0.123 0.170      *
>> 
>> 
>>   - Could you please explain* what the "com" column means* in the output:?
>> 
>> 
>> *           PA1   PA3   PA2   PA4     h2          u2      com*
>> *Var1  0.44  0.14 -0.03  -0.10 0.22665  0.773  1.3*
>> *Var2  0.08  0.11  0.02   0.78  0.62951  0.370  1.1*
>> *Var3  0.62  0.12  0.15   0.14  0.43578  0.564  1.3*
>> 
>>   - Request you to add option for *"equamax" rotation* also if possible.
>> 
>> 
>> I have come across the above issues until now. Please do correct me if I am
>> wrong.
>> 
>> Awaiting your revert which would clear out my confusions,
>> 
>> Thanks for your valuable time,
>> 
>> Sagnik
>> 
>> --
>> Regards,
>> 
>> *SAGNIK CHAKRAVARTY*
>> 
>> *Mob:*  +919972865435
>> *Email:* sagnik.stats at gmail.com
>>           sagnik.739 at gmail.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org



From smartpink111 at yahoo.com  Wed Apr  9 18:18:11 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 09:18:11 -0700 (PDT)
Subject: [R] Generate Crosstab in R
Message-ID: <1397060291.84618.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:

dat <- structure(list(Custom = c("Judi", "Judi", "Ben", "Tom", "Tom", 
"Bill", "Lindy", "Shary", "Judu", "Judu", "Billy", "Tommy", "Tommy", 
"Benjum", "Linda", "Shiry"), Gender = c("Female", "Female", "Male", 
"Male", "Male", "Male", "Female", "Female", "Female", "Female", 
"Male", "Male", "Male", "Male", "Female", "Female"), Product = c("A", 
"B", "A", "A", "B", "B", "A", "B", "A", "B", "A", "A", "B", "B", 
"A", "B"), Payment = c("Credit Card", "Credit Card", "Cash", 
"Cash", "Cash", "Credit Card", "Cash", "Credit Card", "Credit Card", 
"Credit Card", "Cash", "Cash", "Cash", "Credit Card", "Cash", 
"Credit Card")), .Names = c("Custom", "Gender", "Product", "Payment"
), class = "data.frame", row.names = c(NA, -16L))

?dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x))

?library(reshape2)
?res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ") #or dcast()

res[2,] <- res[2,]/2?
res 


A.K.


Hello experts, I am a beginner of R and need your kind help for a R question. Any advice will be greatly appreciated. I have a sample data set like below: Customs purchase either product A or B or both using either Credit card or Cash. I would like to summarize the data as a crosstab in R ---- show how many customs purchase product A only or product B only or product A and B using either credit card or cash. Is that possible in R? Thank you very much for your time and help. Customer_Sample.xlsx



From eraghu at mpi-muenster.mpg.de  Wed Apr  9 16:23:58 2014
From: eraghu at mpi-muenster.mpg.de (Raghu)
Date: Wed, 09 Apr 2014 16:23:58 +0200
Subject: [R] flowDensity package
Message-ID: <534557FE.7020405@mpi-muenster.mpg.de>

I am unable to install flowDensity package from bioconductor in R 
version 3.0 or 3.1.
did anyone have the same problems with this.

Thanks,
Raghu



From brianjamesarb at gmail.com  Wed Apr  9 15:18:24 2014
From: brianjamesarb at gmail.com (brian arb)
Date: Wed, 9 Apr 2014 09:18:24 -0400
Subject: [R] Error object .Source not found when using package
	tm.plugin.webmining
Message-ID: <CABYizFLbzNQTs3Hi2MGAVQ6NgTZ-hsa3ugrv1OZc-P-3+uGnpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/11db07ba/attachment-0001.pl>

From anto.rajaa at gmail.com  Wed Apr  9 15:25:41 2014
From: anto.rajaa at gmail.com (anto.r)
Date: Wed, 9 Apr 2014 06:25:41 -0700 (PDT)
Subject: [R] glmulti wrapper for lmer does not produce results
Message-ID: <53454A38.1080500@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/52a66a1e/attachment-0001.pl>

From jgrn at illinois.edu  Wed Apr  9 18:32:34 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Wed, 9 Apr 2014 11:32:34 -0500
Subject: [R] Ignore escape characters in a string...
In-Reply-To: <aa655752-35f1-41b9-abbf-d2ec31f56e2c@email.android.com>
References: <CABG0rftuobmpdRUs7mMtvZVBBm-AttKOs3okWVobKfSoiB1w_w@mail.gmail.com>
	<aa655752-35f1-41b9-abbf-d2ec31f56e2c@email.android.com>
Message-ID: <CABG0rfsLhBM2eYk4Y9eLT8Mp=OPAeyAcYr=uHyr7n45RaqZ9-w@mail.gmail.com>

Thanks all, I'll try some of these suggestions out but it seems like a
raw string ability could come in helpful -- there aren't any packages
out there that have this capability?

--j

On Tue, Apr 8, 2014 at 1:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> What is wrong with
>
> winpath <- readLines("clipboard ")
>
> ?
>
> If you want to show that as a literal in your code, then don't bother assigning it to a variable, but let it echo to output and copy THAT and put it in your source code.
>
> There is also file.choose()...
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 8, 2014 8:00:03 AM PDT, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>>R-helpers:
>>
>>One of the minor irritations I have is copying paths from Windows
>>explorer, which look like:
>>
>>C:\Program Files\R\R-3.0.3
>>
>>and using them in a setwd() statement, since the "\" is, of course,
>>interpreted as an escape character.  I have to, at present, manually
>>add in the double slashes or reverse them.
>>
>>So, I'd like to write a quick function that takes this path:
>>
>>winpath <- "C:\Program Files\R\R-3.0.3"
>>
>>and converts it to a ready-to-go R path -- is there a way to have R
>>IGNORE escape characters in a character vector?
>>
>>Alternatively, is there some trick to using a copy/paste from Windows
>>explorer I'm not aware of?
>>
>>--j
>



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007



From hb at biostat.ucsf.edu  Wed Apr  9 18:41:26 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 9 Apr 2014 09:41:26 -0700
Subject: [R] How to implement a recurring "check for updates" for R and
	packages?
In-Reply-To: <CANdJ3dUmbtTpcNtCjL_-4C5UJOSJVJrJQJ6g3XMmbZVJk5a0sQ@mail.gmail.com>
References: <CANdJ3dUmbtTpcNtCjL_-4C5UJOSJVJrJQJ6g3XMmbZVJk5a0sQ@mail.gmail.com>
Message-ID: <CAFDcVCT6k538XvJ8mSAiYDhs8Hw9Euj2RCT2faGPvRxdtXQkQw@mail.gmail.com>

[Sounds like a question for R-devel]

On Wed, Apr 9, 2014 at 5:02 AM, Tal Galili <tal.galili at gmail.com> wrote:
> Hello all,
>
>
> I wish to add to the
> installr<http://cran.r-project.org/web/packages/installr/>package the
> ability to check for new versions of R once every X units of
> time (maybe once every two weeks).
>
> I would like to keep a time stamp somewhere, that would stay persistent
> across R sessions (i.e.: that if I turn R off and then back on, it would
> keep track of the last time it checked for a new R version).
> It would be best if I could save some file, maybe in the installr package
> folder, that would keep track of that.
>
> Any suggestions or "best practice" on how to implement something like that?

I'm not aware of any standards for where to store site- and/or
user-specific R settings that are persistent across session.  It would
certainly nice to have a standard, instead of everyone inventing their
own.

Either way, before starting it is useful (even if you don't distribute
via CRAN) if you're aware of the following passage from
http://cran.r-project.org/web/packages/policies.html provides a fair
guideline:

"- Packages should not write in the users? home filespace, nor
anywhere else on the file system apart from the R session?s temporary
directory (or during installation in the location pointed to by
TMPDIR: and such usage should be cleaned up). Installing into the
system?s R installation (e.g., scripts to its bin directory) is not
allowed.
Limited exceptions may be allowed in interactive sessions if the
package obtains confirmation from the user."

Then have a look the R.cache package.  It is used for caching objects
to file, e.g. memoization of computational expensive results.  It
addresses the above policy in the following way:

1. It checks whether ~/.Rcache/ exists or not.  If it exists, it is
assumed that it already has the user's permission.

2  Otherwise, if in an interactive R session, it asks the user for
permission to create that directory.  If successful it is created (and
it drops an informative README.txt file in there too), otherwise it
uses a temporary directory.

Here is what it looks like to first time you load R.cache:

> library(R.cache)
The R.cache package needs to create a directory that will hold cache
files. It is convenient to use one in the user's home directory,
because it remains also after restarting R. Do you wish to create the
'~/.Rcache/' directory? If not, a temporary directory
(C:\Users\hb\AppData\Local\Temp\Rtmp61upx7/.Rcache) that is specific
to this R session will be used. [Y/n]:

You can use a similar strategy.  You could also use R.cache for you
own purposes, e.g.

readURL <- function(url, maxAge=10*24*3600, force=FALSE, ...) {
  library("R.cache")
  dirs <- "installr"  # => Caching to ~/.Rcache/installr/
  key <- list(method="readURL", url=url)

  # Check for cached results
  bfr <- loadCache(key=key, dirs=dirs)
  when <- attr(bfr, "when")

  # Recent enough results already available?
  if (!force && !is.null(when) && (Sys.time()-maxAge <= when))
    return(bfr);

  # Download and memoize
  bfr <- readLines(url)
  attr(bfr, "when") <- Sys.time()
  saveCache(bfr, key=key, dirs=dirs)

  bfr
} # readURL()

That would memoize the results from CRAN (for 10 days by default); you
can of course cache the parsed R version etc, but I leave that to you.

/Henrik
(author of R.cache)

>
> Thanks,
> Tal
>
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From mtmorgan at fhcrc.org  Wed Apr  9 18:53:41 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 09 Apr 2014 09:53:41 -0700
Subject: [R] flowDensity package
In-Reply-To: <534557FE.7020405@mpi-muenster.mpg.de>
References: <534557FE.7020405@mpi-muenster.mpg.de>
Message-ID: <53457B15.3030406@fhcrc.org>

On 04/09/2014 07:23 AM, Raghu wrote:
> I am unable to install flowDensity package from bioconductor in R version 3.0 or
> 3.1.
> did anyone have the same problems with this.

Please ask questions about Bioconductor packages on the Bioconductor mailing list

   http://bioconductor.org/help/mailing-list/

but as far as I can tell flowDensity is not a Bioconductor package!

   http://bioconductor.org/packages/release/BiocViews.html#___Software

Don't forget to provide the output of the R command

   sessionInfo()

to let us know about your operating system and R version.

Martin

>
> Thanks,
> Raghu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793



From info at aghmed.fsnet.co.uk  Wed Apr  9 19:39:30 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 09 Apr 2014 18:39:30 +0100
Subject: [R] Meta-analysis of prevalence at the country level with
 mgcv/gamm4
In-Reply-To: <CAL49zWNRgYHFvUXdfoTuD8ixaewAS7iE4r3tP3p5K4dZha8Nuw@mail.g
	mail.com>
References: <CAL49zWNRgYHFvUXdfoTuD8ixaewAS7iE4r3tP3p5K4dZha8Nuw@mail.gmail.com>
Message-ID: <Zen-1WXwTL-0005q4-0V@smarthost01a.mail.zen.net.uk>

At 09:31 08/04/2014, Julien Riou wrote:
>Dear R community,

Comments in line below

>I'm working on a meta-analysis of prevalence data. The aim is to get
>estimates of prevalence at the country level. The main issue is that the
>disease is highly correlated with age, and the sample ages of included
>studies are highly heterogeneous. Only median age is available for most
>studies, so I can't use SMR-like tricks. I figured I could use
>meta-regression to solve this, including age as a fixed-effect and
>introducing study-level and country-level random-effects.
>
>The idea (that I took from Fowkes et
>al<http://www.thelancet.com/journals/lancet/article/PIIS0140-6736%2813%2961249-0/abstract>)
>was to use this model to make country-specific predictions of prevalence
>for each 5-year age group from 15 to 60 (using the median age of the
>group), and to apply these predictions to the actual population size of
>each of those groups in the selected country, in order to obtain total
>infected population and to calculate age-adjusted prevalence in the 15-60
>population from that.
>
>I tried several ways to do this using R with packages meta and mgcv. I got
>some satisfying results, but I'm not that confident with my results and
>would appreciate some feedback.
>
>First is some simulated data, then the description of my different
>approaches:
>
>data<-data.frame(id_study=c("UK1","UK2","UK3","FRA1","FRA2","BEL1","GER1","GER2","GER3"),
>
>country=c("UK","UK","UK","FRANCE","FRANCE","BELGIUM","GERMANY","GERMANY","GERMANY"),
>                  n_events=c(91,49,18,10,50,6,9,10,22),
>                  n_total=c(3041,580,252,480,887,256,400,206,300),
>                  study_median_age=c(25,50,58,30,42,26,27,28,36))

So the first UK study with a median age of 25 is going to be used to 
estimate prevalence over a range of ages? You are going to have to 
make some very strong assumptions here which I personally would not 
want to make.

Is there any possibility that in the real dataset you can fit your 
model to those studies which do provide age-specific prevalences and 
then use that to impute?

You do not say when these studies were published but I would ask the 
authors of the primary studies if they can make the information 
available to you. You may have already done that of course. I referee 
quite a few papers on systematic reviews and my impression is that 
some authors are amenable to doing the work for you. You mileage may 
vary of course.

>*Standard random-effect meta-analysis* with package meta.
>
>I used metaprop() to get a first estimate of the prevalence in each country
>without taking age into account, and to obtain weights. As expected,
>heterogeneity was very high, so I used weights from the random-effects
>model.

Which will be nearly equal and so hardly worth using in my opinion 
but again your mileage may vary.

>  meta <- 
> metaprop(event=n_events,n=n_total,byvar=country,sm="PLOGIT",method.tau="REML",data=data)
>  summary(meta)
>  data$weight<-meta$w.random
>
>I used meta to get a first estimate of the prevalence without taking age
>into account, and to obtain weights. As expected, heterogeneity was very
>high, so I used weights from the random-effects model.
>
>*Generalized additive model* to include age with package mgcv.
>
>The gam() model parameters (k and sp) were chosen using BIC and GCV number
>(not shown here).
>
>  model <- gam( cbind(n_events,n_total-n_events) ~
>s(study_median_age,bs="cr",k=4,sp=2) + s(country,bs="re"),
>weights=weight, data=data, family="binomial"(link=logit),
>method="REML")
>  plot(model,pages=1,residuals=T, all.terms=T, shade=T)
>
>Predictions for each age group were obtained from this model as explained
>earlier. CI were obtained directly using predict.gam(), that uses the
>Bayesian posterior covariance matrix of the parameters. For exemple
>considering UK:
>
>  newdat<-data.frame(country="UK",study_median_age=seq(17,57,5))
>  link<-predict(model,newdat,type="link",se.fit=T)$fit
>  linkse<-predict(model,newdat,type="link",se.fit=T)$se
>  newdat$prev<-model$family$linkinv(link)
>  newdat$CIinf<-model$family$linkinv(link-1.96*linkse)
>  newdat$CIsup<-model$family$linkinv(link+1.96*linkse)
>  plot(newdat$prev~newdat$study_median_age, type="l",ylim=c(0,.12))
>  lines(newdat$CIinf~newdat$study_median_age, lty=2)
>  lines(newdat$CIsup~newdat$study_median_age, lty=2)
>
>The results were satisfying, representing the augmentation of the
>prevalence with advanced age, with coherent confidence intervals. I
>obtained a total prevalence for the country using the country population
>structure (not shown, I hope it is clear enough).
>
>However, I figured I needed to include study-level random-effects since
>there was a high heterogeneity (even though I did not calculate
>heterogeneity after the meta-regression).
>
>*Introducing study-level random-effect* with package gamm4.
>
>Since mgcv models can't handle that much random-effect parameters, I had to
>switch to gamm4.
>
>  model2 <- gamm4(cbind(n_events,n_total-n_events) ~
>s(study_median_age,bs="cr",k=4) + s(country,bs="re"),
>random=~(1|id_study), data=data, weights=weight,
>family="binomial"(link=logit))
>  plot(model2$gam,pages=1,residuals=T, all.terms=T, shade=T)
>
>  link<-predict(model2$gam,newdat,type="link",se.fit=T)$fit
>  linkse<-predict(model2$gam,newdat,type="link",se.fit=T)$se
>  newdat$prev2<-model$family$linkinv(link)
>  newdat$CIinf2<-model$family$linkinv(link-1.96*linkse)
>  newdat$CIsup2<-model$family$linkinv(link+1.96*linkse)
>  plot(newdat$prev2~newdat$study_median_age, 
> type="l",col="red",ylim=c(0,0.11))
>  lines(newdat$CIinf2~newdat$study_median_age, lty=2,col="red")
>  lines(newdat$CIsup2~newdat$study_median_age, lty=2,col="red")
>  lines(newdat$prev~newdat$study_median_age, type="l",ylim=c(0,.12))
>  lines(newdat$CIinf~newdat$study_median_age, lty=2)
>  lines(newdat$CIsup~newdat$study_median_age, lty=2)
>
>Since the study-level random effect was in the mer part of the fit, I
>didn't have to handle it.
>
>As you can see, I obtain rather different results, with a much smoother
>relation between age and prevalence, and quite different confidence
>intervals. It is even more different in the full-data analysis, where the
>CI are much wider in the model including study-level RE, to the point it is
>sometimes almost uninformative (prevalence between 0 and 15%, but if it is
>the way it is...). Moreover, the study-level RE model seems to be more
>stable when outliers are excluded.
>
>*So, my questions are:*
>
>    - Did I properly extract the weights from the metaprop() function and
>    used them further?
>    - Did I properly built my gam() and gamm4() models? I read a lot about
>    this, but I'm not used to this king of models.
>    - Which of these models should I use?
>
>I would really appreciate some help, since neither my teachers nor my
>colleagues could. It was a really harsh to conduct the systematic review,
>and very frustrating to struggle with the analysis... Thank you in advance!

I am afraid that is the way with systematic reviews, you can only 
synthesise what you find, not what you would like to have found. 
Anyone who has done a review will sympathise with you, not that that 
is any consolation.


>Julien
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From emorway at usgs.gov  Wed Apr  9 20:09:35 2014
From: emorway at usgs.gov (Morway, Eric)
Date: Wed, 9 Apr 2014 11:09:35 -0700
Subject: [R] Summing up realizations
Message-ID: <CAPoqHzosx_+N7YK19OvtV7qwfNtxD0PGyY5_jZvHzU2+WOukOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/bc6aa8c6/attachment-0001.pl>

From liusiqi.nine at gmail.com  Wed Apr  9 20:15:46 2014
From: liusiqi.nine at gmail.com (Si Qi L.)
Date: Wed, 9 Apr 2014 19:15:46 +0100
Subject: [R] logistical indexing in R
Message-ID: <CABmq+QUg9=H3=xj0WLGVDBQXvRZCxaWtTkmM22f231BqXTFApQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/993b6868/attachment-0001.pl>

From gunter.berton at gene.com  Wed Apr  9 21:12:20 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 9 Apr 2014 12:12:20 -0700
Subject: [R] Summing up realizations
In-Reply-To: <CAPoqHzosx_+N7YK19OvtV7qwfNtxD0PGyY5_jZvHzU2+WOukOQ@mail.gmail.com>
References: <CAPoqHzosx_+N7YK19OvtV7qwfNtxD0PGyY5_jZvHzU2+WOukOQ@mail.gmail.com>
Message-ID: <CACk-te0X_oq4F1-KurU-A=Fh9DRhAqREHrr9WwpwAso0SA+4cg@mail.gmail.com>

Have you read "An Introduction to R" (or a web tutorial) to learn R?
This looks straightforward, if I understand you correctly.

?sample
and indexing operations might be all you need.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Wed, Apr 9, 2014 at 11:09 AM, Morway, Eric <emorway at usgs.gov> wrote:
> Due in large part to my nonexistent statistics vocabulary, I'm not sure
> what the name is for the type of analysis I'm trying to do.  I have,
> however, started to cobble something together (below) that is undoubtedly
> reinventing the wheel (i.e., someone has probably already written something
> to do this type of analysis, especially within R).  I've compiled 1-year's
> worth of data (which is a subset of a much larger dataset, but extends from
> 10/1/97 to 9/30/98), that includes daily mean and standard deviations for
> flow (Q, Qsd) and specific conductance (EC, ECsd).  My goal is to calculate
> total load for the year and include a 95% CI on that value.  The load is
> calculated by multiplying each day's Q and EC and summing over the year.
>  Assuming normally-distributed errors, the calculated load for this data
> set is 565,240 tons/yr.  The last line of code below is where I have left
> off.  For each day in the full 25 year data set, I want to generate ~500
> realizations of each day's load (Q*SC), sum over the daily realization
> values to arrive at 500 realizations of total annual load.  So, my question
> is, what is the package that already does this? or, alternatively, could
> someone help me complete the code below based on what I just described?
> -Eric
>
>
> a <- read.csv(textConnection("date,Q,QAcc,Qsd,SC,SCAcc,SCsd
> 10/1/1997,654,0.15,50.05,1020.00,0.15,78.06
> 10/2/1997,592,0.15,45.31,1070.00,0.15,81.89
> 10/3/1997,560,0.15,42.86,1100.00,0.15,84.18
> 10/4/1997,541,0.15,41.40,1110.00,0.15,84.95
> 10/5/1997,545,0.15,41.71,1100.00,0.15,84.18
> 10/6/1997,528,0.15,40.41,1110.00,0.15,84.95
> 10/7/1997,452,0.15,34.59,1120.00,0.15,85.71
> 10/8/1997,458,0.15,35.05,NA,0.15,NA
> 10/9/1997,524,0.15,40.10,NA,0.15,NA
> 10/10/1997,580,0.15,44.39,NA,0.15,NA
> 10/11/1997,600,0.15,45.92,NA,0.15,NA
> 10/12/1997,716,0.15,54.80,NA,0.15,NA
> 10/13/1997,731,0.15,55.94,NA,0.15,NA
> 10/14/1997,550,0.15,42.09,NA,0.15,NA
> 10/15/1997,400,0.15,30.61,NA,0.15,NA
> 10/16/1997,413,0.15,31.61,NA,0.15,NA
> 10/17/1997,403,0.15,30.84,1050.00,0.15,80.36
> 10/18/1997,330,0.15,25.26,1100.00,0.15,84.18
> 10/19/1997,222,0.15,16.99,1210.00,0.15,92.60
> 10/20/1997,198,0.15,15.15,NA,0.15,NA
> 10/21/1997,197,0.15,15.08,NA,0.15,NA
> 10/22/1997,204,0.15,15.61,1400.00,0.15,107.14
> 10/23/1997,204,0.15,15.61,1410.00,0.15,107.91
> 10/24/1997,229,0.15,17.53,1390.00,0.15,106.38
> 10/25/1997,162,0.15,12.40,1220.00,0.15,93.37
> 10/26/1997,313,0.15,23.95,1230.00,0.15,94.13
> 10/27/1997,784,0.15,60.00,987.00,0.15,75.54
> 10/28/1997,691,0.15,52.88,1010.00,0.15,77.30
> 10/29/1997,939,0.15,71.86,974.00,0.15,74.54
> 10/30/1997,953,0.15,72.93,966.00,0.15,73.93
> 10/31/1997,1020,0.15,78.06,NA,0.15,NA
> 11/1/1997,1090,0.15,83.42,1000.00,0.15,76.53
> 11/2/1997,1070,0.15,81.89,991.00,0.15,75.84
> 11/3/1997,963,0.15,73.70,958.00,0.15,73.32
> 11/4/1997,896,0.15,68.57,984.00,0.15,75.31
> 11/5/1997,823,0.15,62.98,1020.00,0.15,78.06
> 11/6/1997,749,0.15,57.32,1070.00,0.15,81.89
> 11/7/1997,698,0.15,53.42,1100.00,0.15,84.18
> 11/8/1997,704,0.15,53.88,1140.00,0.15,87.24
> 11/9/1997,752,0.15,57.55,1100.00,0.15,84.18
> 11/10/1997,793,0.15,60.69,1080.00,0.15,82.65
> 11/11/1997,821,0.15,62.83,1070.00,0.15,81.89
> 11/12/1997,822,0.15,62.91,1080.00,0.15,82.65
> 11/13/1997,931,0.15,71.25,1040.00,0.15,79.59
> 11/14/1997,923,0.15,70.64,1020.00,0.15,78.06
> 11/15/1997,932,0.15,71.33,1010.00,0.15,77.30
> 11/16/1997,924,0.15,70.71,987.00,0.15,75.54
> 11/17/1997,928,0.15,71.02,984.00,0.15,75.31
> 11/18/1997,947,0.15,72.47,982.00,0.15,75.15
> 11/19/1997,786,0.15,60.15,1020.00,0.15,78.06
> 11/20/1997,729,0.15,55.79,1050.00,0.15,80.36
> 11/21/1997,771,0.15,59.01,1040.00,0.15,79.59
> 11/22/1997,745,0.15,57.02,1060.00,0.15,81.12
> 11/23/1997,463,0.15,35.43,1160.00,0.15,88.78
> 11/24/1997,397,0.15,30.38,1220.00,0.15,93.37
> 11/25/1997,848,0.15,64.90,1030.00,0.15,78.83
> 11/26/1997,878,0.15,67.19,971.00,0.15,74.31
> 11/27/1997,857,0.15,65.59,969.00,0.15,74.16
> 11/28/1997,939,0.15,71.86,965.00,0.15,73.85
> 11/29/1997,1130,0.15,86.48,958.00,0.15,73.32
> 11/30/1997,1040,0.15,79.59,1080.00,0.15,82.65
> 12/1/1997,956,0.15,73.16,1060.00,0.15,81.12
> 12/2/1997,1020,0.15,78.06,1040.00,0.15,79.59
> 12/3/1997,1150,0.15,88.01,944.00,0.15,72.24
> 12/4/1997,1120,0.15,85.71,933.00,0.15,71.40
> 12/5/1997,1040,0.15,79.59,928.00,0.15,71.02
> 12/6/1997,816,0.15,62.45,1020.00,0.15,78.06
> 12/7/1997,797,0.15,60.99,1060.00,0.15,81.12
> 12/8/1997,835,0.15,63.90,1070.00,0.15,81.89
> 12/9/1997,980,0.15,75.00,1020.00,0.15,78.06
> 12/10/1997,971,0.15,74.31,1020.00,0.15,78.06
> 12/11/1997,937,0.15,71.71,1030.00,0.15,78.83
> 12/12/1997,880,0.15,67.35,1010.00,0.15,77.30
> 12/13/1997,895,0.15,68.49,1050.00,0.15,80.36
> 12/14/1997,914,0.15,69.95,1030.00,0.15,78.83
> 12/15/1997,966,0.15,73.93,1020.00,0.15,78.06
> 12/16/1997,913,0.15,69.87,1010.00,0.15,77.30
> 12/17/1997,730,0.15,55.87,1160.00,0.15,88.78
> 12/18/1997,610,0.15,46.68,1290.00,0.15,98.72
> 12/19/1997,591,0.15,45.23,1350.00,0.15,103.32
> 12/20/1997,589,0.15,45.08,1360.00,0.15,104.08
> 12/21/1997,560,0.15,42.86,1370.00,0.15,104.85
> 12/22/1997,527,0.15,40.33,1380.00,0.15,105.61
> 12/23/1997,532,0.15,40.71,1390.00,0.15,106.38
> 12/24/1997,535,0.15,40.94,1400.00,0.15,107.14
> 12/25/1997,558,0.15,42.70,1390.00,0.15,106.38
> 12/26/1997,535,0.15,40.94,1380.00,0.15,105.61
> 12/27/1997,504,0.15,38.57,1410.00,0.15,107.91
> 12/28/1997,476,0.15,36.43,1400.00,0.15,107.14
> 12/29/1997,484,0.15,37.04,1410.00,0.15,107.91
> 12/30/1997,519,0.15,39.72,1400.00,0.15,107.14
> 12/31/1997,539,0.15,41.25,1410.00,0.15,107.91
> 1/1/1998,552,0.15,42.24,1400.00,0.15,107.14
> 1/2/1998,570,0.15,43.62,1400.00,0.15,107.14
> 1/3/1998,597,0.15,45.69,1420.00,0.15,108.67
> 1/4/1998,630,0.15,48.21,1400.00,0.15,107.14
> 1/5/1998,633,0.15,48.44,1390.00,0.15,106.38
> 1/6/1998,632,0.15,48.37,1390.00,0.15,106.38
> 1/7/1998,601,0.15,45.99,1390.00,0.15,106.38
> 1/8/1998,553,0.15,42.32,1430.00,0.15,109.44
> 1/9/1998,531,0.15,40.64,1440.00,0.15,110.20
> 1/10/1998,538,0.15,41.17,1430.00,0.15,109.44
> 1/11/1998,581,0.15,44.46,1400.00,0.15,107.14
> 1/12/1998,597,0.15,45.69,1400.00,0.15,107.14
> 1/13/1998,602,0.15,46.07,1390.00,0.15,106.38
> 1/14/1998,596,0.15,45.61,1390.00,0.15,106.38
> 1/15/1998,596,0.15,45.61,1380.00,0.15,105.61
> 1/16/1998,632,0.15,48.37,1390.00,0.15,106.38
> 1/17/1998,597,0.15,45.69,1390.00,0.15,106.38
> 1/18/1998,609,0.15,46.61,1400.00,0.15,107.14
> 1/19/1998,593,0.15,45.38,1400.00,0.15,107.14
> 1/20/1998,547,0.15,41.86,1410.00,0.15,107.91
> 1/21/1998,547,0.15,41.86,1400.00,0.15,107.14
> 1/22/1998,478,0.15,36.58,1400.00,0.15,107.14
> 1/23/1998,497,0.15,38.04,1400.00,0.15,107.14
> 1/24/1998,503,0.15,38.49,1390.00,0.15,106.38
> 1/25/1998,515,0.15,39.41,1370.00,0.15,104.85
> 1/26/1998,508,0.15,38.88,1370.00,0.15,104.85
> 1/27/1998,520,0.15,39.80,1350.00,0.15,103.32
> 1/28/1998,530,0.15,40.56,1340.00,0.15,102.55
> 1/29/1998,490,0.15,37.50,1320.00,0.15,101.02
> 1/30/1998,567,0.15,43.39,1320.00,0.15,101.02
> 1/31/1998,558,0.15,42.70,1340.00,0.15,102.55
> 2/1/1998,505,0.15,38.65,1340.00,0.15,102.55
> 2/2/1998,523,0.15,40.03,1370.00,0.15,104.85
> 2/3/1998,558,0.15,42.70,1380.00,0.15,105.61
> 2/4/1998,536,0.15,41.02,1400.00,0.15,107.14
> 2/5/1998,521,0.15,39.87,1400.00,0.15,107.14
> 2/6/1998,507,0.15,38.80,1400.00,0.15,107.14
> 2/7/1998,488,0.15,37.35,1390.00,0.15,106.38
> 2/8/1998,489,0.15,37.42,1390.00,0.15,106.38
> 2/9/1998,498,0.15,38.11,1390.00,0.15,106.38
> 2/10/1998,492,0.15,37.65,1390.00,0.15,106.38
> 2/11/1998,499,0.15,38.19,1380.00,0.15,105.61
> 2/12/1998,494,0.15,37.81,1380.00,0.15,105.61
> 2/13/1998,488,0.15,37.35,1390.00,0.15,106.38
> 2/14/1998,563,0.15,43.09,1380.00,0.15,105.61
> 2/15/1998,525,0.15,40.18,1300.00,0.15,99.49
> 2/16/1998,470,0.15,35.97,1360.00,0.15,104.08
> 2/17/1998,470,0.15,35.97,1380.00,0.15,105.61
> 2/18/1998,525,0.15,40.18,1380.00,0.15,105.61
> 2/19/1998,489,0.15,37.42,1370.00,0.15,104.85
> 2/20/1998,525,0.15,40.18,1370.00,0.15,104.85
> 2/21/1998,501,0.15,38.34,1380.00,0.15,105.61
> 2/22/1998,491,0.15,37.58,1390.00,0.15,106.38
> 2/23/1998,476,0.15,36.43,1400.00,0.15,107.14
> 2/24/1998,324,0.15,24.80,1460.00,0.15,111.73
> 2/25/1998,303,0.15,23.19,1520.00,0.15,116.33
> 2/26/1998,324,0.15,24.80,1500.00,0.15,114.80
> 2/27/1998,380,0.15,29.08,1350.00,0.15,103.32
> 2/28/1998,436,0.15,33.37,1240.00,0.15,94.90
> 3/1/1998,440,0.15,33.67,1230.00,0.15,94.13
> 3/2/1998,433,0.15,33.14,1220.00,0.15,93.37
> 3/3/1998,460,0.15,35.20,1220.00,0.15,93.37
> 3/4/1998,654,0.15,50.05,1180.00,0.15,90.31
> 3/5/1998,600,0.15,45.92,1190.00,0.15,91.07
> 3/6/1998,579,0.15,44.31,1250.00,0.15,95.66
> 3/7/1998,544,0.15,41.63,1280.00,0.15,97.96
> 3/8/1998,536,0.15,41.02,1280.00,0.15,97.96
> 3/9/1998,536,0.15,41.02,1270.00,0.15,97.19
> 3/10/1998,547,0.15,41.86,1270.00,0.15,97.19
> 3/11/1998,638,0.15,48.83,1210.00,0.15,92.60
> 3/12/1998,680,0.15,52.04,1130.00,0.15,86.48
> 3/13/1998,704,0.15,53.88,1100.00,0.15,84.18
> 3/14/1998,663,0.15,50.74,1100.00,0.15,84.18
> 3/15/1998,684,0.15,52.35,1090.00,0.15,83.42
> 3/16/1998,712,0.15,54.49,1080.00,0.15,82.65
> 3/17/1998,804,0.15,61.53,1050.00,0.15,80.36
> 3/18/1998,843,0.15,64.52,1040.00,0.15,79.59
> 3/19/1998,982,0.15,75.15,968.00,0.15,74.08
> 3/20/1998,1130,0.15,86.48,973.00,0.15,74.46
> 3/21/1998,1340,0.15,102.55,973.00,0.15,74.46
> 3/22/1998,1300,0.15,99.49,959.00,0.15,73.39
> 3/23/1998,1140,0.15,87.24,1010.00,0.15,77.30
> 3/24/1998,1060,0.15,81.12,1010.00,0.15,77.30
> 3/25/1998,791,0.15,60.54,1090.00,0.15,83.42
> 3/26/1998,934,0.15,71.48,1060.00,0.15,81.12
> 3/27/1998,1070,0.15,81.89,963.00,0.15,73.70
> 3/28/1998,2140,0.15,163.78,NA,0.15,NA
> 3/29/1998,1940,0.15,148.47,765.00,0.15,58.55
> 3/30/1998,1810,0.15,138.52,766.00,0.15,58.62
> 3/31/1998,1570,0.15,120.15,788.00,0.15,60.31
> 4/1/1998,1350,0.15,103.32,866.00,0.15,66.28
> 4/2/1998,1250,0.15,95.66,NA,0.15,NA
> 4/3/1998,1240,0.15,94.90,NA,0.15,NA
> 4/4/1998,1260,0.15,96.43,NA,0.15,NA
> 4/5/1998,1180,0.15,90.31,NA,0.15,NA
> 4/6/1998,1050,0.15,80.36,1000.00,0.15,76.53
> 4/7/1998,818,0.15,62.60,1040.00,0.15,79.59
> 4/8/1998,865,0.15,66.20,NA,0.15,NA
> 4/9/1998,1010,0.15,77.30,NA,0.15,NA
> 4/10/1998,1050,0.15,80.36,NA,0.15,NA
> 4/11/1998,2010,0.15,153.83,NA,0.15,NA
> 4/12/1998,2720,0.15,208.16,NA,0.15,NA
> 4/13/1998,2680,0.15,205.10,NA,0.15,NA
> 4/14/1998,2610,0.15,199.74,704.00,0.15,53.88
> 4/15/1998,1290,0.15,98.72,768.00,0.15,58.78
> 4/16/1998,825,0.15,63.14,962.00,0.15,73.62
> 4/17/1998,1120,0.15,85.71,937.00,0.15,71.71
> 4/18/1998,984,0.15,75.31,963.00,0.15,73.70
> 4/19/1998,1040,0.15,79.59,969.00,0.15,74.16
> 4/20/1998,1110,0.15,84.95,947.00,0.15,72.47
> 4/21/1998,1100,0.15,84.18,949.00,0.15,72.63
> 4/22/1998,1040,0.15,79.59,949.00,0.15,72.63
> 4/23/1998,964,0.15,73.78,950.00,0.15,72.70
> 4/24/1998,1010,0.15,77.30,933.00,0.15,71.40
> 4/25/1998,1210,0.15,92.60,859.00,0.15,65.74
> 4/26/1998,1850,0.15,141.58,780.00,0.15,59.69
> 4/27/1998,2740,0.15,209.69,749.00,0.15,57.32
> 4/28/1998,2780,0.15,212.76,780.00,0.15,59.69
> 4/29/1998,2850,0.15,218.11,761.00,0.15,58.24
> 4/30/1998,2650,0.15,202.81,729.00,0.15,55.79
> 5/1/1998,1920,0.15,146.94,736.00,0.15,56.33
> 5/2/1998,1290,0.15,98.72,825.00,0.15,63.14
> 5/3/1998,1220,0.15,93.37,832.00,0.15,63.67
> 5/4/1998,1330,0.15,101.79,832.00,0.15,63.67
> 5/5/1998,1470,0.15,112.50,818.00,0.15,62.60
> 5/6/1998,1820,0.15,139.29,824.00,0.15,63.06
> 5/7/1998,2200,0.15,168.37,795.00,0.15,60.84
> 5/8/1998,2250,0.15,172.19,796.00,0.15,60.92
> 5/9/1998,2360,0.15,180.61,830.00,0.15,63.52
> 5/10/1998,2380,0.15,182.14,815.00,0.15,62.37
> 5/11/1998,2090,0.15,159.95,831.00,0.15,63.60
> 5/12/1998,1980,0.15,151.53,863.00,0.15,66.05
> 5/13/1998,1800,0.15,137.76,874.00,0.15,66.89
> 5/14/1998,1400,0.15,107.14,849.00,0.15,64.97
> 5/15/1998,1400,0.15,107.14,807.00,0.15,61.76
> 5/16/1998,1380,0.15,105.61,801.00,0.15,61.30
> 5/17/1998,1410,0.15,107.91,782.00,0.15,59.85
> 5/18/1998,1280,0.15,97.96,789.00,0.15,60.38
> 5/19/1998,1250,0.15,95.66,786.00,0.15,60.15
> 5/20/1998,1390,0.15,106.38,761.00,0.15,58.24
> 5/21/1998,1490,0.15,114.03,764.00,0.15,58.47
> 5/22/1998,1570,0.15,120.15,745.00,0.15,57.02
> 5/23/1998,1680,0.15,128.57,721.00,0.15,55.18
> 5/24/1998,1610,0.15,123.21,727.00,0.15,55.64
> 5/25/1998,1640,0.15,125.51,753.00,0.15,57.63
> 5/26/1998,1380,0.15,105.61,802.00,0.15,61.38
> 5/27/1998,1180,0.15,90.31,795.00,0.15,60.84
> 5/28/1998,1180,0.15,90.31,792.00,0.15,60.61
> 5/29/1998,1020,0.15,78.06,811.00,0.15,62.07
> 5/30/1998,923,0.15,70.64,840.00,0.15,64.29
> 5/31/1998,1000,0.15,76.53,814.00,0.15,62.30
> 6/1/1998,1170,0.15,89.54,786.00,0.15,60.15
> 6/2/1998,1370,0.15,104.85,765.00,0.15,58.55
> 6/3/1998,1660,0.15,127.04,735.00,0.15,56.25
> 6/4/1998,1790,0.15,136.99,727.00,0.15,55.64
> 6/5/1998,2120,0.15,162.24,713.00,0.15,54.57
> 6/6/1998,2880,0.15,220.41,700.00,0.15,53.57
> 6/7/1998,3170,0.15,242.60,693.00,0.15,53.04
> 6/8/1998,2550,0.15,195.15,712.00,0.15,54.49
> 6/9/1998,1250,0.15,95.66,773.00,0.15,59.16
> 6/10/1998,595,0.15,45.54,964.00,0.15,73.78
> 6/11/1998,559,0.15,42.78,1040.00,0.15,79.59
> 6/12/1998,612,0.15,46.84,1060.00,0.15,81.12
> 6/13/1998,563,0.15,43.09,1090.00,0.15,83.42
> 6/14/1998,616,0.15,47.14,998.00,0.15,76.38
> 6/15/1998,679,0.15,51.96,942.00,0.15,72.09
> 6/16/1998,1040,0.15,79.59,868.00,0.15,66.43
> 6/17/1998,1020,0.15,78.06,847.00,0.15,64.82
> 6/18/1998,889,0.15,68.04,860.00,0.15,65.82
> 6/19/1998,792,0.15,60.61,886.00,0.15,67.81
> 6/20/1998,744,0.15,56.94,913.00,0.15,69.87
> 6/21/1998,680,0.15,52.04,927.00,0.15,70.94
> 6/22/1998,664,0.15,50.82,930.00,0.15,71.17
> 6/23/1998,703,0.15,53.80,929.00,0.15,71.10
> 6/24/1998,699,0.15,53.49,879.00,0.15,67.27
> 6/25/1998,682,0.15,52.19,867.00,0.15,66.35
> 6/26/1998,856,0.15,65.51,816.00,0.15,62.45
> 6/27/1998,993,0.15,75.99,777.00,0.15,59.46
> 6/28/1998,1130,0.15,86.48,709.00,0.15,54.26
> 6/29/1998,1290,0.15,98.72,671.00,0.15,51.35
> 6/30/1998,1290,0.15,98.72,653.00,0.15,49.97
> 7/1/1998,1370,0.15,104.85,651.00,0.15,49.82
> 7/2/1998,1460,0.15,111.73,731.00,0.15,55.94
> 7/3/1998,1540,0.15,117.86,687.00,0.15,52.58
> 7/4/1998,1520,0.15,116.33,632.00,0.15,48.37
> 7/5/1998,1450,0.15,110.97,647.00,0.15,49.52
> 7/6/1998,1070,0.15,81.89,673.00,0.15,51.51
> 7/7/1998,1160,0.15,88.78,653.00,0.15,49.97
> 7/8/1998,1360,0.15,104.08,642.00,0.15,49.13
> 7/9/1998,1190,0.15,91.07,660.00,0.15,50.51
> 7/10/1998,1140,0.15,87.24,681.00,0.15,52.12
> 7/11/1998,1380,0.15,105.61,663.00,0.15,50.74
> 7/12/1998,1550,0.15,118.62,638.00,0.15,48.83
> 7/13/1998,1020,0.15,78.06,640.00,0.15,48.98
> 7/14/1998,912,0.15,69.80,655.00,0.15,50.13
> 7/15/1998,995,0.15,76.15,636.00,0.15,48.67
> 7/16/1998,955,0.15,73.09,641.00,0.15,49.06
> 7/17/1998,924,0.15,70.71,635.00,0.15,48.60
> 7/18/1998,961,0.15,73.55,663.00,0.15,50.74
> 7/19/1998,824,0.15,63.06,695.00,0.15,53.19
> 7/20/1998,656,0.15,50.20,768.00,0.15,58.78
> 7/21/1998,596,0.15,45.61,746.00,0.15,57.09
> 7/22/1998,535,0.15,40.94,777.00,0.15,59.46
> 7/23/1998,579,0.15,44.31,763.00,0.15,58.39
> 7/24/1998,938,0.15,71.79,719.00,0.15,55.03
> 7/25/1998,993,0.15,75.99,704.00,0.15,53.88
> 7/26/1998,1220,0.15,93.37,711.00,0.15,54.41
> 7/27/1998,1360,0.15,104.08,681.00,0.15,52.12
> 7/28/1998,1200,0.15,91.84,697.00,0.15,53.34
> 7/29/1998,1340,0.15,102.55,630.00,0.15,48.21
> 7/30/1998,3200,0.15,244.90,602.00,0.15,46.07
> 7/31/1998,2850,0.15,218.11,628.00,0.15,48.06
> 8/1/1998,2570,0.15,196.68,684.00,0.15,52.35
> 8/2/1998,1880,0.15,143.88,710.00,0.15,54.34
> 8/3/1998,1900,0.15,145.41,684.00,0.15,52.35
> 8/4/1998,2450,0.15,187.50,756.00,0.15,57.86
> 8/5/1998,2760,0.15,211.22,717.00,0.15,54.87
> 8/6/1998,1320,0.15,101.02,837.00,0.15,64.06
> 8/7/1998,1030,0.15,78.83,934.00,0.15,71.48
> 8/8/1998,1080,0.15,82.65,883.00,0.15,67.58
> 8/9/1998,744,0.15,56.94,1010.00,0.15,77.30
> 8/10/1998,1250,0.15,95.66,910.00,0.15,69.64
> 8/11/1998,1360,0.15,104.08,927.00,0.15,70.94
> 8/12/1998,1670,0.15,127.81,889.00,0.15,68.04
> 8/13/1998,1210,0.15,92.60,1010.00,0.15,77.30
> 8/14/1998,668,0.15,51.12,1010.00,0.15,77.30
> 8/15/1998,1180,0.15,90.31,911.00,0.15,69.72
> 8/16/1998,1450,0.15,110.97,871.00,0.15,66.66
> 8/17/1998,1350,0.15,103.32,843.00,0.15,64.52
> 8/18/1998,1260,0.15,96.43,853.00,0.15,65.28
> 8/19/1998,936,0.15,71.63,897.00,0.15,68.65
> 8/20/1998,672,0.15,51.43,1000.00,0.15,76.53
> 8/21/1998,714,0.15,54.64,982.00,0.15,75.15
> 8/22/1998,771,0.15,59.01,974.00,0.15,74.54
> 8/23/1998,598,0.15,45.77,1000.00,0.15,76.53
> 8/24/1998,488,0.15,37.35,NA,0.15,NA
> 8/25/1998,528,0.15,40.41,NA,0.15,NA
> 8/26/1998,812,0.15,62.14,936.00,0.15,71.63
> 8/27/1998,720,0.15,55.10,993.00,0.15,75.99
> 8/28/1998,653,0.15,49.97,944.00,0.15,72.24
> 8/29/1998,796,0.15,60.92,892.00,0.15,68.27
> 8/30/1998,689,0.15,52.73,901.00,0.15,68.95
> 8/31/1998,511,0.15,39.11,1020.00,0.15,78.06
> 9/1/1998,410,0.15,31.38,1150.00,0.15,88.01
> 9/2/1998,374,0.15,28.62,1180.00,0.15,90.31
> 9/3/1998,444,0.15,33.98,1170.00,0.15,89.54
> 9/4/1998,473,0.15,36.20,1150.00,0.15,88.01
> 9/5/1998,727,0.15,55.64,951.00,0.15,72.78
> 9/6/1998,1130,0.15,86.48,735.00,0.15,56.25
> 9/7/1998,1090,0.15,83.42,737.00,0.15,56.40
> 9/8/1998,1020,0.15,78.06,773.00,0.15,59.16
> 9/9/1998,916,0.15,70.10,793.00,0.15,60.69
> 9/10/1998,859,0.15,65.74,820.00,0.15,62.76
> 9/11/1998,595,0.15,45.54,900.00,0.15,68.88
> 9/12/1998,458,0.15,35.05,1060.00,0.15,81.12
> 9/13/1998,429,0.15,32.83,1160.00,0.15,88.78
> 9/14/1998,418,0.15,31.99,1110.00,0.15,84.95
> 9/15/1998,493,0.15,37.73,1150.00,0.15,88.01
> 9/16/1998,438,0.15,33.52,1170.00,0.15,89.54
> 9/17/1998,406,0.15,31.07,1150.00,0.15,88.01
> 9/18/1998,397,0.15,30.38,1140.00,0.15,87.24
> 9/19/1998,429,0.15,32.83,1110.00,0.15,84.95
> 9/20/1998,450,0.15,34.44,1080.00,0.15,82.65
> 9/21/1998,449,0.15,34.36,1060.00,0.15,81.12
> 9/22/1998,450,0.15,34.44,1090.00,0.15,83.42
> 9/23/1998,478,0.15,36.58,1060.00,0.15,81.12
> 9/24/1998,531,0.15,40.64,1030.00,0.15,78.83
> 9/25/1998,573,0.15,43.85,999.00,0.15,76.45
> 9/26/1998,533,0.15,40.79,1040.00,0.15,79.59
> 9/27/1998,564,0.15,43.16,1020.00,0.15,78.06
> 9/28/1998,434,0.15,33.21,1130.00,0.15,86.48
> 9/29/1998,399,0.15,30.54,1180.00,0.15,90.31
> 9/30/1998,359,0.15,27.47,1230.00,0.15,94.13"),header=T)
> closeAllConnections()
> a[,1] <- transform(a$date,as.Date(a[,1],"%m/%d/%Y"))
>
> #convert cfs to cfd
> Cat.Dam.ConvertQ <- function(Q) (Q * 86400)
> #convert SC to TDS using locally regressed data (and do unit conversion)
> Cat.Dam.ConvertSC <- function(SC) ((0.8652 * SC - 145.43) *
> (28.3168/1000000/907.185))
>
> # estimated annul load, omits missing days
> sum(Cat.Dam.ConvertQ(a$Q) * Cat.Dam.Convert(a$SC), na.rm=TRUE)
> # 565239.3
>
> # 10 realizations for the first day
> Cat.Dam.ConvertQ(rnorm(10,a$Q[1],a$Qsd[1])) *
> Cat.Dam.ConvertSC(rnorm(10,a$SC[1],a$SCsd[1]))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Apr  9 21:47:06 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 12:47:06 -0700 (PDT)
Subject: [R] Generate Crosstab in R
In-Reply-To: <1397060291.84618.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1397060291.84618.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1397072826.74528.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
Try:
datNew <- read.csv("customer_samples.csv",stringsAsFactors=FALSE)

#I could reproduce similar error message with:
dat[] <- lapply(dat,as.factor)?

dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x)) 


#Warning messages:
1: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
3: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
4: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated 

A.K.


Hello A.K. ,  Thank you very much for your reply.  I tried the following codes but got some warning messages:  ------------------------- Codes I tried -------------- 
dat <- read.csv ("customer samples.csv")  dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x))  library(reshape2)  res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ") #or dcast()  res[2,] <- res[2,]/2 
res  ---------------------------------  Waring messages I got:  1: In '[<-.factor' ('*tmp*', i, value = "A and B"):  invalid factor level, NA generated  2: In '[<-.factor' ('*tmp*', i, value = "A and B"):  invalid factor level, NA generated  3: In '[<-.factor' ('*tmp*', i, value = "A and B"):  invalid factor level, NA generated  4: In '[<-.factor' ('*tmp*', i, value = "A and B"):  invalid factor level, NA generated  -------------------------------------------------  Could you please help me out?  Thanks a lot! 


On Wednesday, April 9, 2014 12:18 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:

dat <- structure(list(Custom = c("Judi", "Judi", "Ben", "Tom", "Tom", 
"Bill", "Lindy", "Shary", "Judu", "Judu", "Billy", "Tommy", "Tommy", 
"Benjum", "Linda", "Shiry"), Gender = c("Female", "Female", "Male", 
"Male", "Male", "Male", "Female", "Female", "Female", "Female", 
"Male", "Male", "Male", "Male", "Female", "Female"), Product = c("A", 
"B", "A", "A", "B", "B", "A", "B", "A", "B", "A", "A", "B", "B", 
"A", "B"), Payment = c("Credit Card", "Credit Card", "Cash", 
"Cash", "Cash", "Credit Card", "Cash", "Credit Card", "Credit Card", 
"Credit Card", "Cash", "Cash", "Cash", "Credit Card", "Cash", 
"Credit Card")), .Names = c("Custom", "Gender", "Product", "Payment"
), class = "data.frame", row.names = c(NA, -16L))

?dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x))

?library(reshape2)
?res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ") #or dcast()

res[2,] <- res[2,]/2?
res 


A.K.


Hello experts, I am a beginner of R and need your kind help for a R question. Any advice will be greatly appreciated. I have a sample data set like below: Customs purchase either product A or B or both using either Credit card or Cash. I would like to summarize the data as a crosstab in R ---- show how many customs purchase product A only or product B only or product A and B using either credit card or cash. Is that possible in R? Thank you very much for your time and help. Customer_Sample.xlsx



From brian.battaile at gmail.com  Wed Apr  9 19:25:02 2014
From: brian.battaile at gmail.com (Brian Battaile)
Date: Wed, 9 Apr 2014 09:25:02 -0800
Subject: [R] Fractional multinomial logit model or similar in R for analysis
	of behavior?
Message-ID: <CAEK1sx6JTWbTabCBBrRhZH31Qumash=0h8vtO=8Mkg-13CVKig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/2f93054d/attachment-0001.pl>

From crns13 at gmail.com  Wed Apr  9 20:27:44 2014
From: crns13 at gmail.com (Cassiano dos Santos)
Date: Wed, 9 Apr 2014 15:27:44 -0300
Subject: [R] Memory allocation using .C interface
Message-ID: <CACyCQc+UbURQY2G7HFC9h7PVpJbVd15ju0ygyi6BWod2O01Hig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/0f7ce2ae/attachment-0001.pl>

From kripa777 at hotmail.com  Wed Apr  9 22:06:35 2014
From: kripa777 at hotmail.com (Kripa R)
Date: Wed, 9 Apr 2014 20:06:35 +0000
Subject: [R] illumina probeID to entrezID
Message-ID: <BAY179-W8949005F1C86DCB080FF6A996A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/e897fc31/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Wed Apr  9 22:29:13 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 09 Apr 2014 13:29:13 -0700
Subject: [R] Summing up realizations
In-Reply-To: <CAPoqHzosx_+N7YK19OvtV7qwfNtxD0PGyY5_jZvHzU2+WOukOQ@mail.gmail.com>
References: <CAPoqHzosx_+N7YK19OvtV7qwfNtxD0PGyY5_jZvHzU2+WOukOQ@mail.gmail.com>
Message-ID: <2ac3e582-0223-472d-9229-23b43ca58d7b@email.android.com>

You might be thinking of bootstrap analysis. Note that measures are often correlated, so beware of just introducing randomness one measure at a time. Discussions about background theory are not really R-specific, so further chatter about this would not be on topic here, but the term "bootstrap" should get you started.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 9, 2014 11:09:35 AM PDT, "Morway, Eric" <emorway at usgs.gov> wrote:
>Due in large part to my nonexistent statistics vocabulary, I'm not sure
>what the name is for the type of analysis I'm trying to do.  I have,
>however, started to cobble something together (below) that is
>undoubtedly
>reinventing the wheel (i.e., someone has probably already written
>something
>to do this type of analysis, especially within R).  I've compiled
>1-year's
>worth of data (which is a subset of a much larger dataset, but extends
>from
>10/1/97 to 9/30/98), that includes daily mean and standard deviations
>for
>flow (Q, Qsd) and specific conductance (EC, ECsd).  My goal is to
>calculate
>total load for the year and include a 95% CI on that value.  The load
>is
>calculated by multiplying each day's Q and EC and summing over the
>year.
>Assuming normally-distributed errors, the calculated load for this data
>set is 565,240 tons/yr.  The last line of code below is where I have
>left
>off.  For each day in the full 25 year data set, I want to generate
>~500
>realizations of each day's load (Q*SC), sum over the daily realization
>values to arrive at 500 realizations of total annual load.  So, my
>question
>is, what is the package that already does this? or, alternatively,
>could
>someone help me complete the code below based on what I just described?
>-Eric
>
>
>a <- read.csv(textConnection("date,Q,QAcc,Qsd,SC,SCAcc,SCsd
>10/1/1997,654,0.15,50.05,1020.00,0.15,78.06
>10/2/1997,592,0.15,45.31,1070.00,0.15,81.89
>10/3/1997,560,0.15,42.86,1100.00,0.15,84.18
>10/4/1997,541,0.15,41.40,1110.00,0.15,84.95
>10/5/1997,545,0.15,41.71,1100.00,0.15,84.18
>10/6/1997,528,0.15,40.41,1110.00,0.15,84.95
>10/7/1997,452,0.15,34.59,1120.00,0.15,85.71
>10/8/1997,458,0.15,35.05,NA,0.15,NA
>10/9/1997,524,0.15,40.10,NA,0.15,NA
>10/10/1997,580,0.15,44.39,NA,0.15,NA
>10/11/1997,600,0.15,45.92,NA,0.15,NA
>10/12/1997,716,0.15,54.80,NA,0.15,NA
>10/13/1997,731,0.15,55.94,NA,0.15,NA
>10/14/1997,550,0.15,42.09,NA,0.15,NA
>10/15/1997,400,0.15,30.61,NA,0.15,NA
>10/16/1997,413,0.15,31.61,NA,0.15,NA
>10/17/1997,403,0.15,30.84,1050.00,0.15,80.36
>10/18/1997,330,0.15,25.26,1100.00,0.15,84.18
>10/19/1997,222,0.15,16.99,1210.00,0.15,92.60
>10/20/1997,198,0.15,15.15,NA,0.15,NA
>10/21/1997,197,0.15,15.08,NA,0.15,NA
>10/22/1997,204,0.15,15.61,1400.00,0.15,107.14
>10/23/1997,204,0.15,15.61,1410.00,0.15,107.91
>10/24/1997,229,0.15,17.53,1390.00,0.15,106.38
>10/25/1997,162,0.15,12.40,1220.00,0.15,93.37
>10/26/1997,313,0.15,23.95,1230.00,0.15,94.13
>10/27/1997,784,0.15,60.00,987.00,0.15,75.54
>10/28/1997,691,0.15,52.88,1010.00,0.15,77.30
>10/29/1997,939,0.15,71.86,974.00,0.15,74.54
>10/30/1997,953,0.15,72.93,966.00,0.15,73.93
>10/31/1997,1020,0.15,78.06,NA,0.15,NA
>11/1/1997,1090,0.15,83.42,1000.00,0.15,76.53
>11/2/1997,1070,0.15,81.89,991.00,0.15,75.84
>11/3/1997,963,0.15,73.70,958.00,0.15,73.32
>11/4/1997,896,0.15,68.57,984.00,0.15,75.31
>11/5/1997,823,0.15,62.98,1020.00,0.15,78.06
>11/6/1997,749,0.15,57.32,1070.00,0.15,81.89
>11/7/1997,698,0.15,53.42,1100.00,0.15,84.18
>11/8/1997,704,0.15,53.88,1140.00,0.15,87.24
>11/9/1997,752,0.15,57.55,1100.00,0.15,84.18
>11/10/1997,793,0.15,60.69,1080.00,0.15,82.65
>11/11/1997,821,0.15,62.83,1070.00,0.15,81.89
>11/12/1997,822,0.15,62.91,1080.00,0.15,82.65
>11/13/1997,931,0.15,71.25,1040.00,0.15,79.59
>11/14/1997,923,0.15,70.64,1020.00,0.15,78.06
>11/15/1997,932,0.15,71.33,1010.00,0.15,77.30
>11/16/1997,924,0.15,70.71,987.00,0.15,75.54
>11/17/1997,928,0.15,71.02,984.00,0.15,75.31
>11/18/1997,947,0.15,72.47,982.00,0.15,75.15
>11/19/1997,786,0.15,60.15,1020.00,0.15,78.06
>11/20/1997,729,0.15,55.79,1050.00,0.15,80.36
>11/21/1997,771,0.15,59.01,1040.00,0.15,79.59
>11/22/1997,745,0.15,57.02,1060.00,0.15,81.12
>11/23/1997,463,0.15,35.43,1160.00,0.15,88.78
>11/24/1997,397,0.15,30.38,1220.00,0.15,93.37
>11/25/1997,848,0.15,64.90,1030.00,0.15,78.83
>11/26/1997,878,0.15,67.19,971.00,0.15,74.31
>11/27/1997,857,0.15,65.59,969.00,0.15,74.16
>11/28/1997,939,0.15,71.86,965.00,0.15,73.85
>11/29/1997,1130,0.15,86.48,958.00,0.15,73.32
>11/30/1997,1040,0.15,79.59,1080.00,0.15,82.65
>12/1/1997,956,0.15,73.16,1060.00,0.15,81.12
>12/2/1997,1020,0.15,78.06,1040.00,0.15,79.59
>12/3/1997,1150,0.15,88.01,944.00,0.15,72.24
>12/4/1997,1120,0.15,85.71,933.00,0.15,71.40
>12/5/1997,1040,0.15,79.59,928.00,0.15,71.02
>12/6/1997,816,0.15,62.45,1020.00,0.15,78.06
>12/7/1997,797,0.15,60.99,1060.00,0.15,81.12
>12/8/1997,835,0.15,63.90,1070.00,0.15,81.89
>12/9/1997,980,0.15,75.00,1020.00,0.15,78.06
>12/10/1997,971,0.15,74.31,1020.00,0.15,78.06
>12/11/1997,937,0.15,71.71,1030.00,0.15,78.83
>12/12/1997,880,0.15,67.35,1010.00,0.15,77.30
>12/13/1997,895,0.15,68.49,1050.00,0.15,80.36
>12/14/1997,914,0.15,69.95,1030.00,0.15,78.83
>12/15/1997,966,0.15,73.93,1020.00,0.15,78.06
>12/16/1997,913,0.15,69.87,1010.00,0.15,77.30
>12/17/1997,730,0.15,55.87,1160.00,0.15,88.78
>12/18/1997,610,0.15,46.68,1290.00,0.15,98.72
>12/19/1997,591,0.15,45.23,1350.00,0.15,103.32
>12/20/1997,589,0.15,45.08,1360.00,0.15,104.08
>12/21/1997,560,0.15,42.86,1370.00,0.15,104.85
>12/22/1997,527,0.15,40.33,1380.00,0.15,105.61
>12/23/1997,532,0.15,40.71,1390.00,0.15,106.38
>12/24/1997,535,0.15,40.94,1400.00,0.15,107.14
>12/25/1997,558,0.15,42.70,1390.00,0.15,106.38
>12/26/1997,535,0.15,40.94,1380.00,0.15,105.61
>12/27/1997,504,0.15,38.57,1410.00,0.15,107.91
>12/28/1997,476,0.15,36.43,1400.00,0.15,107.14
>12/29/1997,484,0.15,37.04,1410.00,0.15,107.91
>12/30/1997,519,0.15,39.72,1400.00,0.15,107.14
>12/31/1997,539,0.15,41.25,1410.00,0.15,107.91
>1/1/1998,552,0.15,42.24,1400.00,0.15,107.14
>1/2/1998,570,0.15,43.62,1400.00,0.15,107.14
>1/3/1998,597,0.15,45.69,1420.00,0.15,108.67
>1/4/1998,630,0.15,48.21,1400.00,0.15,107.14
>1/5/1998,633,0.15,48.44,1390.00,0.15,106.38
>1/6/1998,632,0.15,48.37,1390.00,0.15,106.38
>1/7/1998,601,0.15,45.99,1390.00,0.15,106.38
>1/8/1998,553,0.15,42.32,1430.00,0.15,109.44
>1/9/1998,531,0.15,40.64,1440.00,0.15,110.20
>1/10/1998,538,0.15,41.17,1430.00,0.15,109.44
>1/11/1998,581,0.15,44.46,1400.00,0.15,107.14
>1/12/1998,597,0.15,45.69,1400.00,0.15,107.14
>1/13/1998,602,0.15,46.07,1390.00,0.15,106.38
>1/14/1998,596,0.15,45.61,1390.00,0.15,106.38
>1/15/1998,596,0.15,45.61,1380.00,0.15,105.61
>1/16/1998,632,0.15,48.37,1390.00,0.15,106.38
>1/17/1998,597,0.15,45.69,1390.00,0.15,106.38
>1/18/1998,609,0.15,46.61,1400.00,0.15,107.14
>1/19/1998,593,0.15,45.38,1400.00,0.15,107.14
>1/20/1998,547,0.15,41.86,1410.00,0.15,107.91
>1/21/1998,547,0.15,41.86,1400.00,0.15,107.14
>1/22/1998,478,0.15,36.58,1400.00,0.15,107.14
>1/23/1998,497,0.15,38.04,1400.00,0.15,107.14
>1/24/1998,503,0.15,38.49,1390.00,0.15,106.38
>1/25/1998,515,0.15,39.41,1370.00,0.15,104.85
>1/26/1998,508,0.15,38.88,1370.00,0.15,104.85
>1/27/1998,520,0.15,39.80,1350.00,0.15,103.32
>1/28/1998,530,0.15,40.56,1340.00,0.15,102.55
>1/29/1998,490,0.15,37.50,1320.00,0.15,101.02
>1/30/1998,567,0.15,43.39,1320.00,0.15,101.02
>1/31/1998,558,0.15,42.70,1340.00,0.15,102.55
>2/1/1998,505,0.15,38.65,1340.00,0.15,102.55
>2/2/1998,523,0.15,40.03,1370.00,0.15,104.85
>2/3/1998,558,0.15,42.70,1380.00,0.15,105.61
>2/4/1998,536,0.15,41.02,1400.00,0.15,107.14
>2/5/1998,521,0.15,39.87,1400.00,0.15,107.14
>2/6/1998,507,0.15,38.80,1400.00,0.15,107.14
>2/7/1998,488,0.15,37.35,1390.00,0.15,106.38
>2/8/1998,489,0.15,37.42,1390.00,0.15,106.38
>2/9/1998,498,0.15,38.11,1390.00,0.15,106.38
>2/10/1998,492,0.15,37.65,1390.00,0.15,106.38
>2/11/1998,499,0.15,38.19,1380.00,0.15,105.61
>2/12/1998,494,0.15,37.81,1380.00,0.15,105.61
>2/13/1998,488,0.15,37.35,1390.00,0.15,106.38
>2/14/1998,563,0.15,43.09,1380.00,0.15,105.61
>2/15/1998,525,0.15,40.18,1300.00,0.15,99.49
>2/16/1998,470,0.15,35.97,1360.00,0.15,104.08
>2/17/1998,470,0.15,35.97,1380.00,0.15,105.61
>2/18/1998,525,0.15,40.18,1380.00,0.15,105.61
>2/19/1998,489,0.15,37.42,1370.00,0.15,104.85
>2/20/1998,525,0.15,40.18,1370.00,0.15,104.85
>2/21/1998,501,0.15,38.34,1380.00,0.15,105.61
>2/22/1998,491,0.15,37.58,1390.00,0.15,106.38
>2/23/1998,476,0.15,36.43,1400.00,0.15,107.14
>2/24/1998,324,0.15,24.80,1460.00,0.15,111.73
>2/25/1998,303,0.15,23.19,1520.00,0.15,116.33
>2/26/1998,324,0.15,24.80,1500.00,0.15,114.80
>2/27/1998,380,0.15,29.08,1350.00,0.15,103.32
>2/28/1998,436,0.15,33.37,1240.00,0.15,94.90
>3/1/1998,440,0.15,33.67,1230.00,0.15,94.13
>3/2/1998,433,0.15,33.14,1220.00,0.15,93.37
>3/3/1998,460,0.15,35.20,1220.00,0.15,93.37
>3/4/1998,654,0.15,50.05,1180.00,0.15,90.31
>3/5/1998,600,0.15,45.92,1190.00,0.15,91.07
>3/6/1998,579,0.15,44.31,1250.00,0.15,95.66
>3/7/1998,544,0.15,41.63,1280.00,0.15,97.96
>3/8/1998,536,0.15,41.02,1280.00,0.15,97.96
>3/9/1998,536,0.15,41.02,1270.00,0.15,97.19
>3/10/1998,547,0.15,41.86,1270.00,0.15,97.19
>3/11/1998,638,0.15,48.83,1210.00,0.15,92.60
>3/12/1998,680,0.15,52.04,1130.00,0.15,86.48
>3/13/1998,704,0.15,53.88,1100.00,0.15,84.18
>3/14/1998,663,0.15,50.74,1100.00,0.15,84.18
>3/15/1998,684,0.15,52.35,1090.00,0.15,83.42
>3/16/1998,712,0.15,54.49,1080.00,0.15,82.65
>3/17/1998,804,0.15,61.53,1050.00,0.15,80.36
>3/18/1998,843,0.15,64.52,1040.00,0.15,79.59
>3/19/1998,982,0.15,75.15,968.00,0.15,74.08
>3/20/1998,1130,0.15,86.48,973.00,0.15,74.46
>3/21/1998,1340,0.15,102.55,973.00,0.15,74.46
>3/22/1998,1300,0.15,99.49,959.00,0.15,73.39
>3/23/1998,1140,0.15,87.24,1010.00,0.15,77.30
>3/24/1998,1060,0.15,81.12,1010.00,0.15,77.30
>3/25/1998,791,0.15,60.54,1090.00,0.15,83.42
>3/26/1998,934,0.15,71.48,1060.00,0.15,81.12
>3/27/1998,1070,0.15,81.89,963.00,0.15,73.70
>3/28/1998,2140,0.15,163.78,NA,0.15,NA
>3/29/1998,1940,0.15,148.47,765.00,0.15,58.55
>3/30/1998,1810,0.15,138.52,766.00,0.15,58.62
>3/31/1998,1570,0.15,120.15,788.00,0.15,60.31
>4/1/1998,1350,0.15,103.32,866.00,0.15,66.28
>4/2/1998,1250,0.15,95.66,NA,0.15,NA
>4/3/1998,1240,0.15,94.90,NA,0.15,NA
>4/4/1998,1260,0.15,96.43,NA,0.15,NA
>4/5/1998,1180,0.15,90.31,NA,0.15,NA
>4/6/1998,1050,0.15,80.36,1000.00,0.15,76.53
>4/7/1998,818,0.15,62.60,1040.00,0.15,79.59
>4/8/1998,865,0.15,66.20,NA,0.15,NA
>4/9/1998,1010,0.15,77.30,NA,0.15,NA
>4/10/1998,1050,0.15,80.36,NA,0.15,NA
>4/11/1998,2010,0.15,153.83,NA,0.15,NA
>4/12/1998,2720,0.15,208.16,NA,0.15,NA
>4/13/1998,2680,0.15,205.10,NA,0.15,NA
>4/14/1998,2610,0.15,199.74,704.00,0.15,53.88
>4/15/1998,1290,0.15,98.72,768.00,0.15,58.78
>4/16/1998,825,0.15,63.14,962.00,0.15,73.62
>4/17/1998,1120,0.15,85.71,937.00,0.15,71.71
>4/18/1998,984,0.15,75.31,963.00,0.15,73.70
>4/19/1998,1040,0.15,79.59,969.00,0.15,74.16
>4/20/1998,1110,0.15,84.95,947.00,0.15,72.47
>4/21/1998,1100,0.15,84.18,949.00,0.15,72.63
>4/22/1998,1040,0.15,79.59,949.00,0.15,72.63
>4/23/1998,964,0.15,73.78,950.00,0.15,72.70
>4/24/1998,1010,0.15,77.30,933.00,0.15,71.40
>4/25/1998,1210,0.15,92.60,859.00,0.15,65.74
>4/26/1998,1850,0.15,141.58,780.00,0.15,59.69
>4/27/1998,2740,0.15,209.69,749.00,0.15,57.32
>4/28/1998,2780,0.15,212.76,780.00,0.15,59.69
>4/29/1998,2850,0.15,218.11,761.00,0.15,58.24
>4/30/1998,2650,0.15,202.81,729.00,0.15,55.79
>5/1/1998,1920,0.15,146.94,736.00,0.15,56.33
>5/2/1998,1290,0.15,98.72,825.00,0.15,63.14
>5/3/1998,1220,0.15,93.37,832.00,0.15,63.67
>5/4/1998,1330,0.15,101.79,832.00,0.15,63.67
>5/5/1998,1470,0.15,112.50,818.00,0.15,62.60
>5/6/1998,1820,0.15,139.29,824.00,0.15,63.06
>5/7/1998,2200,0.15,168.37,795.00,0.15,60.84
>5/8/1998,2250,0.15,172.19,796.00,0.15,60.92
>5/9/1998,2360,0.15,180.61,830.00,0.15,63.52
>5/10/1998,2380,0.15,182.14,815.00,0.15,62.37
>5/11/1998,2090,0.15,159.95,831.00,0.15,63.60
>5/12/1998,1980,0.15,151.53,863.00,0.15,66.05
>5/13/1998,1800,0.15,137.76,874.00,0.15,66.89
>5/14/1998,1400,0.15,107.14,849.00,0.15,64.97
>5/15/1998,1400,0.15,107.14,807.00,0.15,61.76
>5/16/1998,1380,0.15,105.61,801.00,0.15,61.30
>5/17/1998,1410,0.15,107.91,782.00,0.15,59.85
>5/18/1998,1280,0.15,97.96,789.00,0.15,60.38
>5/19/1998,1250,0.15,95.66,786.00,0.15,60.15
>5/20/1998,1390,0.15,106.38,761.00,0.15,58.24
>5/21/1998,1490,0.15,114.03,764.00,0.15,58.47
>5/22/1998,1570,0.15,120.15,745.00,0.15,57.02
>5/23/1998,1680,0.15,128.57,721.00,0.15,55.18
>5/24/1998,1610,0.15,123.21,727.00,0.15,55.64
>5/25/1998,1640,0.15,125.51,753.00,0.15,57.63
>5/26/1998,1380,0.15,105.61,802.00,0.15,61.38
>5/27/1998,1180,0.15,90.31,795.00,0.15,60.84
>5/28/1998,1180,0.15,90.31,792.00,0.15,60.61
>5/29/1998,1020,0.15,78.06,811.00,0.15,62.07
>5/30/1998,923,0.15,70.64,840.00,0.15,64.29
>5/31/1998,1000,0.15,76.53,814.00,0.15,62.30
>6/1/1998,1170,0.15,89.54,786.00,0.15,60.15
>6/2/1998,1370,0.15,104.85,765.00,0.15,58.55
>6/3/1998,1660,0.15,127.04,735.00,0.15,56.25
>6/4/1998,1790,0.15,136.99,727.00,0.15,55.64
>6/5/1998,2120,0.15,162.24,713.00,0.15,54.57
>6/6/1998,2880,0.15,220.41,700.00,0.15,53.57
>6/7/1998,3170,0.15,242.60,693.00,0.15,53.04
>6/8/1998,2550,0.15,195.15,712.00,0.15,54.49
>6/9/1998,1250,0.15,95.66,773.00,0.15,59.16
>6/10/1998,595,0.15,45.54,964.00,0.15,73.78
>6/11/1998,559,0.15,42.78,1040.00,0.15,79.59
>6/12/1998,612,0.15,46.84,1060.00,0.15,81.12
>6/13/1998,563,0.15,43.09,1090.00,0.15,83.42
>6/14/1998,616,0.15,47.14,998.00,0.15,76.38
>6/15/1998,679,0.15,51.96,942.00,0.15,72.09
>6/16/1998,1040,0.15,79.59,868.00,0.15,66.43
>6/17/1998,1020,0.15,78.06,847.00,0.15,64.82
>6/18/1998,889,0.15,68.04,860.00,0.15,65.82
>6/19/1998,792,0.15,60.61,886.00,0.15,67.81
>6/20/1998,744,0.15,56.94,913.00,0.15,69.87
>6/21/1998,680,0.15,52.04,927.00,0.15,70.94
>6/22/1998,664,0.15,50.82,930.00,0.15,71.17
>6/23/1998,703,0.15,53.80,929.00,0.15,71.10
>6/24/1998,699,0.15,53.49,879.00,0.15,67.27
>6/25/1998,682,0.15,52.19,867.00,0.15,66.35
>6/26/1998,856,0.15,65.51,816.00,0.15,62.45
>6/27/1998,993,0.15,75.99,777.00,0.15,59.46
>6/28/1998,1130,0.15,86.48,709.00,0.15,54.26
>6/29/1998,1290,0.15,98.72,671.00,0.15,51.35
>6/30/1998,1290,0.15,98.72,653.00,0.15,49.97
>7/1/1998,1370,0.15,104.85,651.00,0.15,49.82
>7/2/1998,1460,0.15,111.73,731.00,0.15,55.94
>7/3/1998,1540,0.15,117.86,687.00,0.15,52.58
>7/4/1998,1520,0.15,116.33,632.00,0.15,48.37
>7/5/1998,1450,0.15,110.97,647.00,0.15,49.52
>7/6/1998,1070,0.15,81.89,673.00,0.15,51.51
>7/7/1998,1160,0.15,88.78,653.00,0.15,49.97
>7/8/1998,1360,0.15,104.08,642.00,0.15,49.13
>7/9/1998,1190,0.15,91.07,660.00,0.15,50.51
>7/10/1998,1140,0.15,87.24,681.00,0.15,52.12
>7/11/1998,1380,0.15,105.61,663.00,0.15,50.74
>7/12/1998,1550,0.15,118.62,638.00,0.15,48.83
>7/13/1998,1020,0.15,78.06,640.00,0.15,48.98
>7/14/1998,912,0.15,69.80,655.00,0.15,50.13
>7/15/1998,995,0.15,76.15,636.00,0.15,48.67
>7/16/1998,955,0.15,73.09,641.00,0.15,49.06
>7/17/1998,924,0.15,70.71,635.00,0.15,48.60
>7/18/1998,961,0.15,73.55,663.00,0.15,50.74
>7/19/1998,824,0.15,63.06,695.00,0.15,53.19
>7/20/1998,656,0.15,50.20,768.00,0.15,58.78
>7/21/1998,596,0.15,45.61,746.00,0.15,57.09
>7/22/1998,535,0.15,40.94,777.00,0.15,59.46
>7/23/1998,579,0.15,44.31,763.00,0.15,58.39
>7/24/1998,938,0.15,71.79,719.00,0.15,55.03
>7/25/1998,993,0.15,75.99,704.00,0.15,53.88
>7/26/1998,1220,0.15,93.37,711.00,0.15,54.41
>7/27/1998,1360,0.15,104.08,681.00,0.15,52.12
>7/28/1998,1200,0.15,91.84,697.00,0.15,53.34
>7/29/1998,1340,0.15,102.55,630.00,0.15,48.21
>7/30/1998,3200,0.15,244.90,602.00,0.15,46.07
>7/31/1998,2850,0.15,218.11,628.00,0.15,48.06
>8/1/1998,2570,0.15,196.68,684.00,0.15,52.35
>8/2/1998,1880,0.15,143.88,710.00,0.15,54.34
>8/3/1998,1900,0.15,145.41,684.00,0.15,52.35
>8/4/1998,2450,0.15,187.50,756.00,0.15,57.86
>8/5/1998,2760,0.15,211.22,717.00,0.15,54.87
>8/6/1998,1320,0.15,101.02,837.00,0.15,64.06
>8/7/1998,1030,0.15,78.83,934.00,0.15,71.48
>8/8/1998,1080,0.15,82.65,883.00,0.15,67.58
>8/9/1998,744,0.15,56.94,1010.00,0.15,77.30
>8/10/1998,1250,0.15,95.66,910.00,0.15,69.64
>8/11/1998,1360,0.15,104.08,927.00,0.15,70.94
>8/12/1998,1670,0.15,127.81,889.00,0.15,68.04
>8/13/1998,1210,0.15,92.60,1010.00,0.15,77.30
>8/14/1998,668,0.15,51.12,1010.00,0.15,77.30
>8/15/1998,1180,0.15,90.31,911.00,0.15,69.72
>8/16/1998,1450,0.15,110.97,871.00,0.15,66.66
>8/17/1998,1350,0.15,103.32,843.00,0.15,64.52
>8/18/1998,1260,0.15,96.43,853.00,0.15,65.28
>8/19/1998,936,0.15,71.63,897.00,0.15,68.65
>8/20/1998,672,0.15,51.43,1000.00,0.15,76.53
>8/21/1998,714,0.15,54.64,982.00,0.15,75.15
>8/22/1998,771,0.15,59.01,974.00,0.15,74.54
>8/23/1998,598,0.15,45.77,1000.00,0.15,76.53
>8/24/1998,488,0.15,37.35,NA,0.15,NA
>8/25/1998,528,0.15,40.41,NA,0.15,NA
>8/26/1998,812,0.15,62.14,936.00,0.15,71.63
>8/27/1998,720,0.15,55.10,993.00,0.15,75.99
>8/28/1998,653,0.15,49.97,944.00,0.15,72.24
>8/29/1998,796,0.15,60.92,892.00,0.15,68.27
>8/30/1998,689,0.15,52.73,901.00,0.15,68.95
>8/31/1998,511,0.15,39.11,1020.00,0.15,78.06
>9/1/1998,410,0.15,31.38,1150.00,0.15,88.01
>9/2/1998,374,0.15,28.62,1180.00,0.15,90.31
>9/3/1998,444,0.15,33.98,1170.00,0.15,89.54
>9/4/1998,473,0.15,36.20,1150.00,0.15,88.01
>9/5/1998,727,0.15,55.64,951.00,0.15,72.78
>9/6/1998,1130,0.15,86.48,735.00,0.15,56.25
>9/7/1998,1090,0.15,83.42,737.00,0.15,56.40
>9/8/1998,1020,0.15,78.06,773.00,0.15,59.16
>9/9/1998,916,0.15,70.10,793.00,0.15,60.69
>9/10/1998,859,0.15,65.74,820.00,0.15,62.76
>9/11/1998,595,0.15,45.54,900.00,0.15,68.88
>9/12/1998,458,0.15,35.05,1060.00,0.15,81.12
>9/13/1998,429,0.15,32.83,1160.00,0.15,88.78
>9/14/1998,418,0.15,31.99,1110.00,0.15,84.95
>9/15/1998,493,0.15,37.73,1150.00,0.15,88.01
>9/16/1998,438,0.15,33.52,1170.00,0.15,89.54
>9/17/1998,406,0.15,31.07,1150.00,0.15,88.01
>9/18/1998,397,0.15,30.38,1140.00,0.15,87.24
>9/19/1998,429,0.15,32.83,1110.00,0.15,84.95
>9/20/1998,450,0.15,34.44,1080.00,0.15,82.65
>9/21/1998,449,0.15,34.36,1060.00,0.15,81.12
>9/22/1998,450,0.15,34.44,1090.00,0.15,83.42
>9/23/1998,478,0.15,36.58,1060.00,0.15,81.12
>9/24/1998,531,0.15,40.64,1030.00,0.15,78.83
>9/25/1998,573,0.15,43.85,999.00,0.15,76.45
>9/26/1998,533,0.15,40.79,1040.00,0.15,79.59
>9/27/1998,564,0.15,43.16,1020.00,0.15,78.06
>9/28/1998,434,0.15,33.21,1130.00,0.15,86.48
>9/29/1998,399,0.15,30.54,1180.00,0.15,90.31
>9/30/1998,359,0.15,27.47,1230.00,0.15,94.13"),header=T)
>closeAllConnections()
>a[,1] <- transform(a$date,as.Date(a[,1],"%m/%d/%Y"))
>
>#convert cfs to cfd
>Cat.Dam.ConvertQ <- function(Q) (Q * 86400)
>#convert SC to TDS using locally regressed data (and do unit
>conversion)
>Cat.Dam.ConvertSC <- function(SC) ((0.8652 * SC - 145.43) *
>(28.3168/1000000/907.185))
>
># estimated annul load, omits missing days
>sum(Cat.Dam.ConvertQ(a$Q) * Cat.Dam.Convert(a$SC), na.rm=TRUE)
># 565239.3
>
># 10 realizations for the first day
>Cat.Dam.ConvertQ(rnorm(10,a$Q[1],a$Qsd[1])) *
>Cat.Dam.ConvertSC(rnorm(10,a$SC[1],a$SCsd[1]))
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From HDoran at air.org  Wed Apr  9 22:56:05 2014
From: HDoran at air.org (Doran, Harold)
Date: Wed, 9 Apr 2014 20:56:05 +0000
Subject: [R] Generate Binary Matrix
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6868A24FCDA@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/6f409241/attachment-0001.pl>

From ken.knoblauch at inserm.fr  Wed Apr  9 23:16:31 2014
From: ken.knoblauch at inserm.fr (ken knoblauch)
Date: Wed, 9 Apr 2014 21:16:31 +0000
Subject: [R] Generate Binary Matrix
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A24FCDA@DC1VEX10MB001.air.org>
Message-ID: <loom.20140409T230844-248@post.gmane.org>

Doran, Harold <HDoran <at> air.org> writes:
> I am trying to generate a binary matrix where 
 row 
in the matrix is guaranteed to have at 
least one 1.
> Ideally, I would like most rowSums  to be equal 
 2 or 3 
with some 1s and some 4s. But, 
rowSums cannot be equal
> to 0.
> 
> I can tinker with the vector of probability weights, 
but in 
 so (in the way I am doing it) this 
causes for
> more rowSums to be equal to 4 than I ideally would 
, but this never helps to guarantee a 
rowSum will not be
> equal to 0. I could post-hoc tinker with any rows 
 are all 
0, but seems like that may be just 
inefficient.
> 
> Below is sample code, any ideas on how to best 
tackle this?
> 
> Harold
> 
> dimMat <- matrix(0, 1000, 4)
> for(i in 1:1000){
>     dimMat[i, ] <- sample(c(0,1), 4, replace = TRUE, prob = c(.3, .7))
>                 }
> 
> table(rowSums(dimMat))


Wht don't you sample from the distribution of row sums 
for each row and then distribute that many 1's randomly
among the columns.

Ken



From spencer.graves at structuremonitoring.com  Wed Apr  9 23:29:24 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 09 Apr 2014 14:29:24 -0700
Subject: [R] getting arg names in function calls?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FAC26CA@PA-MBX01.na.tibco.com>
References: <53432120.9050500@structuremonitoring.com>
	<E66794E69CFDE04D9A70842786030B933FAC1B51@PA-MBX01.na.tibco.com>
	<53448BD0.7080201@structuremonitoring.com>
	<E66794E69CFDE04D9A70842786030B933FAC26CA@PA-MBX01.na.tibco.com>
Message-ID: <5345BBB4.4090003@structuremonitoring.com>

       Thanks very much to both Bill Dunlap and Hadley Wickham.


       Per Bill's second suggestion, "match.call(eval(bo[[1]]), bo)" 
returned the desired "plot(x = 0, y = 1)" [with bo <- 
body(function()plot(0, 1)].


       Hadley's "standardise_call(bo)" [from library(pryr)] is much 
simpler.


       Thanks again,
       Spencer


On 4/8/2014 7:49 PM, William Dunlap wrote:
>> I don't see how that solves
>> the example I gave of extracting "plot(x=0, y=1)" from tstFn <-
>> function()plot(0, 1).
> Try
>      > match.call(definition=plot, call=body(tstFn))
>      plot(x = 0, y = 1)
>
> plot() is not a great example, since some of its methods do not have an
> argument called 'y' (e.g., plot.stepfun) and it has a lot of ... arguments which
> you need to go to the help file for.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: Spencer Graves [mailto:spencer.graves at structuremonitoring.com]
>> Sent: Tuesday, April 08, 2014 4:53 PM
>> To: William Dunlap; R list
>> Subject: Re: [R] getting arg names in function calls?
>>
>> Hi, Bill:
>>
>>
>>         Thanks for the reply.  Unfortunately, I don't see how that solves
>> the example I gave of extracting "plot(x=0, y=1)" from tstFn <-
>> function()plot(0, 1).
>>
>>
>>         As I noted, body(tstFn) returns "plot(0, 1)" as an "language"
>> object of class "call".  My challenge is to convert that into something
>> similar, with explicit names for the arguments.
>>
>>
>>         Any thoughts?
>>         Spencer
>>
>>
>> On 4/7/2014 3:18 PM, William Dunlap wrote:
>>> Look at match.call().  E.g.,
>>>     > f <- function(x, y = log2(x), ...) match.call()
>>>     > f()
>>>     f()
>>>     > f(1, x=2, anotherArg=3, 4)
>>>     f(x = 2, y = 1, anotherArg = 3, 4)
>>> or, using its 'definition' and 'call' arguments directly
>>>     > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)))
>>>     foo(x = 2, y = 1, extraArg = 3, 4)
>>>     > match.call(function(x, y, ...)NULL, quote(foo(1, x=2, extraArg=3, 4)),
>> expand.dots=FALSE)
>>>     foo(x = 2, y = 1, ... = list(extraArg = 3, 4))
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf
>>>> Of Spencer Graves
>>>> Sent: Monday, April 07, 2014 3:05 PM
>>>> To: R list
>>>> Subject: [R] getting arg names in function calls?
>>>>
>>>>          How can I convert "plot(0, 1)" into "plot(x=0, y=1)"?
>>>>
>>>>
>>>>          More generally, how can I get argument names assigned to function
>>>> calls in "language" objects?
>>>>
>>>>
>>>>          Example:
>>>>
>>>>
>>>> tstFn <- function()plot(0, 1)
>>>> bo <- body(tstFn)
>>>>
>>>>
>>>> tstFnxy <- function()plot(x=0, y=1)
>>>> boxy <- body(tstFnxy)
>>>>
>>>>
>>>>          Is there a function that will modify "bo" to match "boxy"?
>>>>
>>>>
>>>>          My current solution requires me to know the names of the
>>>> arguments for "plot" (in this example).  I'd prefer a more general
>>>> solution.
>>>>
>>>>
>>>>          Thanks,
>>>>          Spencer
>>>>
>>>>
>>>> p.s.  I'm trying to create an animation by repeatedly calling a function
>>>> that contains something like text(0, 1, "abc").  By computing on the
>>>> language object 'text(0, 1, "abc")', I can call text(0, 1, 'a') the
>>>> first time, text(0, 1, 'ab') the second, and text(0, 1, 'abc') the
>>>> third.  The function will be more general if I can get the names of the
>>>> arguments as just described.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>



From clint at ecy.wa.gov  Wed Apr  9 23:29:35 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 9 Apr 2014 14:29:35 -0700
Subject: [R] Generate Binary Matrix
In-Reply-To: <loom.20140409T230844-248@post.gmane.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A24FCDA@DC1VEX10MB001.air.org>
	<loom.20140409T230844-248@post.gmane.org>
Message-ID: <alpine.LRH.2.11.1404091428160.5559@aeolus.ecy.wa.gov>

A bit kludgey but how about:

dimMat <- matrix(0, 1000, 4)
for(i in 1:1000){
while(sum(dimMat[i, ] <- sample(c(0,1), 4, replace = TRUE, prob = c(.3, .7)))==0) dimMat[i, ] <- sample(c(0,1), 4, replace = TRUE, prob = c(.3, .7))
}
table(rowSums(dimMat))


Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 9 Apr 2014, ken knoblauch wrote:

> Doran, Harold <HDoran <at> air.org> writes:
>> I am trying to generate a binary matrix where
> row
> in the matrix is guaranteed to have at
> least one 1.
>> Ideally, I would like most rowSums  to be equal
> 2 or 3
> with some 1s and some 4s. But,
> rowSums cannot be equal
>> to 0.
>>
>> I can tinker with the vector of probability weights,
> but in
> so (in the way I am doing it) this
> causes for
>> more rowSums to be equal to 4 than I ideally would
> , but this never helps to guarantee a
> rowSum will not be
>> equal to 0. I could post-hoc tinker with any rows
> are all
> 0, but seems like that may be just
> inefficient.
>>
>> Below is sample code, any ideas on how to best
> tackle this?
>>
>> Harold
>>
>> dimMat <- matrix(0, 1000, 4)
>> for(i in 1:1000){
>>     dimMat[i, ] <- sample(c(0,1), 4, replace = TRUE, prob = c(.3, .7))
>>                 }
>>
>> table(rowSums(dimMat))
>
>
> Wht don't you sample from the distribution of row sums
> for each row and then distribute that many 1's randomly
> among the columns.
>
> Ken
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From dcarlson at tamu.edu  Wed Apr  9 23:33:10 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 9 Apr 2014 16:33:10 -0500
Subject: [R] Generate Binary Matrix
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6868A24FCDA@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A24FCDA@DC1VEX10MB001.air.org>
Message-ID: <05da01cf543b$4defab70$e9cf0250$@tamu.edu>

You could randomly assign 1 to a single column in each row and
then use binomial draws on the remaining 0's:

> set.seed(42)
> dimMat <- matrix(0, 1000, 4)
> dimMat[cbind(1:1000, sample.int(4, 1000, replace=TRUE))] <- 1
> dimMat[dimMat<1] <- sample(0:1, 3000, replace=TRUE, prob=c(.6,
.4))
> table(rowSums(dimMat))

  1   2   3   4 
217 402 310  71 
> colSums(dimMat)
[1] 551 586 533 565
> sum(dimMat)
[1] 2235

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Wednesday, April 9, 2014 3:56 PM
To: r-help at r-project.org
Subject: [R] Generate Binary Matrix

I am trying to generate a binary matrix where every row in the
matrix is guaranteed to have at least one 1. Ideally, I would
like most rowSums  to be equal to 2 or 3 with some 1s and some
4s. But, rowSums cannot be equal to 0.

I can tinker with the vector of probability weights, but in
doing so (in the way I am doing it) this causes for more rowSums
to be equal to 4 than I ideally would like, but this never helps
to guarantee a rowSum will not be equal to 0. I could post-hoc
tinker with any rows that are all 0, but seems like that may be
just inefficient.

Below is sample code, any ideas on how to best tackle this?

Harold



dimMat <- matrix(0, 1000, 4)
for(i in 1:1000){
                dimMat[i, ] <- sample(c(0,1), 4, replace = TRUE,
prob = c(.3, .7))
                }

table(rowSums(dimMat))

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From tal.galili at gmail.com  Wed Apr  9 23:35:50 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Thu, 10 Apr 2014 00:35:50 +0300
Subject: [R] How to implement a recurring "check for updates" for R and
	packages?
In-Reply-To: <CAFDcVCT6k538XvJ8mSAiYDhs8Hw9Euj2RCT2faGPvRxdtXQkQw@mail.gmail.com>
References: <CANdJ3dUmbtTpcNtCjL_-4C5UJOSJVJrJQJ6g3XMmbZVJk5a0sQ@mail.gmail.com>
	<CAFDcVCT6k538XvJ8mSAiYDhs8Hw9Euj2RCT2faGPvRxdtXQkQw@mail.gmail.com>
Message-ID: <CANdJ3dUqMYNQ7ADmzNDcxEXjHTK6V=7zFkAE6m0h4+p=PQcvOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/3ce8c91a/attachment-0001.pl>

From peter.langfelder at gmail.com  Wed Apr  9 23:37:11 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 9 Apr 2014 14:37:11 -0700
Subject: [R] Memory allocation using .C interface
In-Reply-To: <CACyCQc+UbURQY2G7HFC9h7PVpJbVd15ju0ygyi6BWod2O01Hig@mail.gmail.com>
References: <CACyCQc+UbURQY2G7HFC9h7PVpJbVd15ju0ygyi6BWod2O01Hig@mail.gmail.com>
Message-ID: <CA+hbrhXMphxKy2v2je-L2nMVWJ7U0zLhL+6xirxa7+5Aj9P5GA@mail.gmail.com>

On Wed, Apr 9, 2014 at 11:27 AM, Cassiano dos Santos <crns13 at gmail.com> wrote:
> I am testing a call to a C function from R, using .C interface. The test
> consists in passing a numeric vector to the C function with no entries,
> dynamically allocates n positions, makes attributions and return the vector
> to R.

When execution enters your C function, the pointer x points to the
content (numerical values) of the R object known as 'x' to R code.
However, the content has length 0 and the value of the pointer may be
undefined (not sure about how R handles empty vectors).

You then change the C pointer x to point to the memory you allocated.
This memory has no relation to the R object 'x', so any changes you
make cannot be reflected in the R object x.

Further, when execution exits your function, the pointer to your
allocated memory is lost and your memory is not de-allocated (that is,
returned to the system). You should call the Free function on exit
from your function.

So the answer is that you cannot use the .C interface for this. You
could achieve your goal via the .Call interface but you have to read
up about how to work with R objects in C code.

HTH,

Peter

>
> I'm using Calloc from R.h. The prototype of the function is
>
> type* Calloc(size_t n, type)
>
> as noted in Writing R Extensions.
>
> The problem is that I don't get the new vector with the allocated positions
> in R. The vector continues to have no entries.
>
> *The code in R*
>
> fooR <- function(x) {
>   if (!is.numeric(x))
>     stop("argument x must be numeric")
>   out <- .C("foo",
>             x=as.double(x))
>   return(out$x)}
>
> x <- numeric()
>
> result <- myfooR(x)
>
> *The function in C*
>
> #include <R.h>
> void myfooRealloc(double *x){
>   int i, n;
>
>   n = 4;
>   x = Calloc(n, double);
>
>   for (i = 0; i < n; i++) {
>     x[i] = i;
>     printf("%f\n", x[i]); //just to check
>   }}
>
> The question is: Can .C inteface handle with such memory allocation?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From edd at debian.org  Wed Apr  9 22:14:55 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 9 Apr 2014 20:14:55 +0000
Subject: [R] Memory allocation using .C interface
References: <CACyCQc+UbURQY2G7HFC9h7PVpJbVd15ju0ygyi6BWod2O01Hig@mail.gmail.com>
Message-ID: <loom.20140409T221355-668@post.gmane.org>

Cassiano dos Santos <crns13 <at> gmail.com> writes:
> I am testing a call to a C function from R, using .C interface. The test
> consists in passing a numeric vector to the C function with no entries,
> dynamically allocates n positions, makes attributions and return the 
> vector to R.

Asking on StackOverflow *and* here is considered rude.  

I have tried to answer your question on StackOverflow.

Dirk



From paola.tellaroli at gmail.com  Fri Apr 11 00:04:48 2014
From: paola.tellaroli at gmail.com (Paola Tellaroli)
Date: Thu, 10 Apr 2014 18:04:48 -0400
Subject: [R] intCriteria function in clusterCrit produces Nan
Message-ID: <EA9EC1AA-63E6-4ADF-8294-95AC329DE180@gmail.com>

I'm trying to compute the Silhouette value with the intCriteria function of clusterCrit package, but if I write:

intCriteria(my.data,members,"Silhouette")

but I get a Nan and I can't understand why!

my.data is attached and

members=c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 1L, 4L, 
10L, 6L, 11L, 12L, 13L, 14L, 15L, 16L, 12L, 1L, 8L, 17L, 18L, 
14L, 18L, 14L, 12L, 12L, 16L, 4L, 8L, 18L, 19L, 12L, 6L, 17L, 
18L, 18L, 18L, 19L, 12L, 4L, 1L, 19L, 15L, 1L, 13L, 7L, 4L, 1L, 
14L, 15L, 4L, 18L, 13L, 12L, 1L, 8L, 4L, 10L, 16L, 9L, 7L, 1L, 
14L, 4L, 14L, 12L, 14L, 18L, 7L, 4L, 14L, 14L, 18L, 6L, 12L, 
15L, 8L, 1L, 18L, 8L, 15L, 12L, 6L, 12L, 19L, 7L, 17L, 7L, 1L, 
12L, 19L, 18L, 8L, 9L, 19L, 13L, 9L, 7L, 16L, 1L, 8L, 18L, 14L, 
4L, 8L, 18L, 18L, 15L, 10L, 8L, 1L, 20L, 12L, 18L, 14L, 1L, 16L, 
12L, 19L, 1L, 4L, 12L, 18L, 1L, 5L, 13L, 17L, 14L, 15L, 5L, 11L, 
17L, 13L, 12L, 7L, 14L, 14L, 8L, 5L, 12L, 19L, 14L, 9L, 16L, 
8L, 8L, 18L, 17L, 7L, 11L, 12L, 10L, 1L)

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: my.data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/f81f6181/attachment-0002.txt>
-------------- next part --------------


Paola

From hill0093 at umn.edu  Thu Apr 10 03:17:22 2014
From: hill0093 at umn.edu (Hurr)
Date: Wed, 9 Apr 2014 18:17:22 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <5345033C.6080701@bitwrit.com.au>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
	<5344F649.1020907@bitwrit.com.au>
	<1397031467054-4688456.post@n4.nabble.com>
	<5345033C.6080701@bitwrit.com.au>
Message-ID: <1397092642268-4688498.post@n4.nabble.com>

What we've covered so far is of great value.
For a neater plot,
the next step will be to learn how to put
numbers with units at each tick mark.
I suppose I can form the number-unit string myself in
separate code and put the tickmark in a place that
I calculate in separate code. 
But I need to learn the plotting code.




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917p4688498.html
Sent from the R help mailing list archive at Nabble.com.



From thanoon.younis80 at gmail.com  Thu Apr 10 03:28:36 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Thu, 10 Apr 2014 04:28:36 +0300
Subject: [R] simulation data
Message-ID: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/779d325c/attachment-0001.pl>

From smartpink111 at yahoo.com  Thu Apr 10 03:34:33 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Apr 2014 18:34:33 -0700 (PDT)
Subject: [R] Generate Crosstab in R
In-Reply-To: <1397072826.74528.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1397060291.84618.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397072826.74528.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1397093673.65916.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Suppose your data is similar to below:
dat <- structure(list(Custom = c("Judi", "Judi", "Ben", "Tom", "Tom", 
"Bill", "Lindy", "Shary", "Judu", "Judu", "Billy", "Tommy", "Tommy", 
"Benjum", "Linda", "Shiry", "Shiry", "Shiry", "Judu", "Billy", 
"Tommy", "Lindy"), Gender = c("Female", "Female", "Male", "Male", 
"Male", "Male", "Female", "Female", "Female", "Female", "Male", 
"Male", "Male", "Male", "Female", "Female", "Female", "Female", 
"Female", "Male", "Male", "Female"), Product = c("A", "B", "A", 
"A", "B", "B", "A", "B", "A", "B", "A", "A", "B", "B", "A", "B", 
"A", "C", "D", "E", "D", "C"), Payment = c("Credit Card", "Credit Card", 
"Cash", "Cash", "Cash", "Credit Card", "Cash", "Credit Card", 
"Credit Card", "Credit Card", "Cash", "Cash", "Cash", "Credit Card", 
"Cash", "Credit Card", "Credit Card", "Credit Card", "Credit Card", 
"Cash", "Cash", "Cash")), .Names = c("Custom", "Gender", "Product", 
"Payment"), class = "data.frame", row.names = c("1", "2", "3", 
"4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", 
"16", "17", "18", "19", "20", "21", "22"))

dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1)  paste("Purchase", gsub("(.*)\\,(.*)$","\\1 and \\2",paste(sort(unique(x)),collapse = ","))) else paste("Purchase", x, "only"))) 

library(reshape2)
res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ")

library(stringr)
res1 <- res/str_count(gsub("Purchase|and|only|\\,"," ",rownames(res)),"\\w+")
res1
#Female_Cash Female_Credit Card Male_Cash Male_Credit Card
# Purchase A and B             0                  1         1                0
# Purchase A and C             1                  0         0                0 
#Purchase A and E             0                  0         1                0 
#Purchase A,B and C           0                  1         0                0 
#Purchase A,B and D           0                  1         1                0 
#Purchase A only              1                  0         1                0 
#Purchase B only              0                  1         0                2
?
A.K.


Hello A.K. ,

Thank you so much for your reply.  The error message was fixed.   One more thing I would like to get your kind instruction.

For "res[2,] <- res[2,]/2", I think you divide the count of customers who purchase both product A and B by 2.  If there are more than two products or more ways of payments, how can R handle?

Is there any other way to run distinct count of customers directly (count customers who purchase product both A and B only one time but not two times)?    Thank you so much for your time and help.

Best,
Tom 




On Wednesday, April 9, 2014 3:47 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Try:
datNew <- read.csv("customer_samples.csv",stringsAsFactors=FALSE)

#I could reproduce similar error message with:
dat[] <- lapply(dat,as.factor)?

dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x)) 


#Warning messages:
1: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
3: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated
4: In `[<-.factor`(`*tmp*`, i, value = "A and B") : invalid factor level, NA generated 

A.K.


Hello A.K. ,? Thank you very much for your reply.? I tried the following codes but got some warning messages:? ------------------------- Codes I tried -------------- 
dat <- read.csv ("customer samples.csv")? dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x))? library(reshape2)? res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ") #or dcast()? res[2,] <- res[2,]/2 
res? ---------------------------------? Waring messages I got:? 1: In '[<-.factor' ('*tmp*', i, value = "A and B"):? invalid factor level, NA generated? 2: In '[<-.factor' ('*tmp*', i, value = "A and B"):? invalid factor level, NA generated? 3: In '[<-.factor' ('*tmp*', i, value = "A and B"):? invalid factor level, NA generated? 4: In '[<-.factor' ('*tmp*', i, value = "A and B"):? invalid factor level, NA generated? -------------------------------------------------? Could you please help me out?? Thanks a lot! 



On Wednesday, April 9, 2014 12:18 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:

dat <- structure(list(Custom = c("Judi", "Judi", "Ben", "Tom", "Tom", 
"Bill", "Lindy", "Shary", "Judu", "Judu", "Billy", "Tommy", "Tommy", 
"Benjum", "Linda", "Shiry"), Gender = c("Female", "Female", "Male", 
"Male", "Male", "Male", "Female", "Female", "Female", "Female", 
"Male", "Male", "Male", "Male", "Female", "Female"), Product = c("A", 
"B", "A", "A", "B", "B", "A", "B", "A", "B", "A", "A", "B", "B", 
"A", "B"), Payment = c("Credit Card", "Credit Card", "Cash", 
"Cash", "Cash", "Credit Card", "Cash", "Credit Card", "Credit Card", 
"Credit Card", "Cash", "Cash", "Cash", "Credit Card", "Cash", 
"Credit Card")), .Names = c("Custom", "Gender", "Product", "Payment"
), class = "data.frame", row.names = c(NA, -16L))

?dat1 <- within(dat, Categ <- ave(Product, Custom, FUN= function(x) if(length(x)>1) "A and B" else x))

?library(reshape2)
?res <- acast(dat1,Categ~Gender+Payment,length,value.var="Categ") #or dcast()

res[2,] <- res[2,]/2?
res 


A.K.


Hello experts, I am a beginner of R and need your kind help for a R question. Any advice will be greatly appreciated. I have a sample data set like below: Customs purchase either product A or B or both using either Credit card or Cash. I would like to summarize the data as a crosstab in R ---- show how many customs purchase product A only or product B only or product A and B using either credit card or cash. Is that possible in R? Thank you very much for your time and help. Customer_Sample.xlsx



From dwinsemius at comcast.net  Thu Apr 10 04:02:52 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Apr 2014 19:02:52 -0700
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1397092642268-4688498.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
	<5344F649.1020907@bitwrit.com.au>
	<1397031467054-4688456.post@n4.nabble.com>
	<5345033C.6080701@bitwrit.com.au>
	<1397092642268-4688498.post@n4.nabble.com>
Message-ID: <A9E74082-623B-4AB4-B7B6-2A028C3A7D77@comcast.net>


On Apr 9, 2014, at 6:17 PM, Hurr wrote:

> What we've covered so far is of great value.
> For a neater plot,
> the next step will be to learn how to put
> numbers with units at each tick mark.
> I suppose I can form the number-unit string myself in
> separate code and put the tickmark in a place that
> I calculate in separate code. 
> But I need to learn the plotting code.

It appears that this question has already been answered by Jim Lemon multiple ways. Have you tried his code? Have you followed the various links from the help page of `plot`? Have you constructed a test case and tried to solve this yourself? (He is a much more patient person than I am, but I'm sure he has some minimal expectation of the level of effort he expects from his correspondents.)


PLEASE (read more thoroughly?):  (the material at the bottom of every regularly posted item on the list but not seen by Nabble users.)

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA



From dwinsemius at comcast.net  Thu Apr 10 04:11:41 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Apr 2014 19:11:41 -0700
Subject: [R] Fractional multinomial logit model or similar in R for
	analysis of behavior?
In-Reply-To: <CAEK1sx6JTWbTabCBBrRhZH31Qumash=0h8vtO=8Mkg-13CVKig@mail.gmail.com>
References: <CAEK1sx6JTWbTabCBBrRhZH31Qumash=0h8vtO=8Mkg-13CVKig@mail.gmail.com>
Message-ID: <76FE5D0E-BB8E-4B6C-AE5A-1AD1E9A8CA93@comcast.net>


On Apr 9, 2014, at 10:25 AM, Brian Battaile wrote:

> I'm looking for a method to analyse behavior data that can be assigned to
> multiple categories
> as a proportion with all the categories adding to 1 and some explanatory
> variables and repeated measures on some individuals.

Maybe expanding your search strategy would help. What you are describing sounds like a Dirichlet problem. Consider searching on "dirichlet regression".

I got 325 links in 100 packages with sos::findFn("dirichlet regression"), but it's not my field so you need to judge suitability.


And ... this mailing list requests postings to be plain text.
-- 
David.
> 
> Data would look something like this
> 
> AnimalID Behavior1 Behavior2 Behavior3 Covariate1 Covariate2
> 1 0.75 0.2 0.05 1 0
> 2 0.5 0.25 0.25 0 0
> 2 0.6 0.3 0.1 0 0
> 3 0.7 0.25 0.05 1 1
> ....
> 
> There is a fractional multinomial logit model (fmlogit) in Stata that is
> designed to do this
> analysis ala
> Papke, Leslie E. and Jeffrey M. Wooldridge. 1996.  Econometric Methods for
> Fractional Response Variables with     an Application to 401(k) Plan
> Participation Rates. Journal of Applied Econometrics 11(6):619-632.
> 
> but I have not found anything in R.  If anyone knows of something similar
> in R or perhaps a different approach I would be grateful to hear about it.
> 
> Thank you
> Brian Battaile
> University of British Columbia
> US Geological Survey
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From davies.trevor at gmail.com  Thu Apr 10 05:27:29 2014
From: davies.trevor at gmail.com (Trevor Davies)
Date: Wed, 9 Apr 2014 20:27:29 -0700
Subject: [R] ggplot / ggmap: fixing geom_point size to break bins
Message-ID: <CAJhyqVgovY-y_qaEPQgboE=Lm9sRptzL+NDesWU=tbz4UhXnrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140409/1fb5bec1/attachment-0001.pl>

From r.turner at auckland.ac.nz  Thu Apr 10 05:55:32 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 10 Apr 2014 11:55:32 +0800
Subject: [R] simulation data
In-Reply-To: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
References: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
Message-ID: <53461634.2070404@auckland.ac.nz>

On 10/04/14 09:28, thanoon younis wrote:
> hi
>
> i want to simulate multivariate dichotomous data matrix with categories
> (0,1) and n=1000 and p=10.

Nobody's stopping you! :-)

cheers,

Rolf Turner



From sagnik.stats at gmail.com  Thu Apr 10 08:22:55 2014
From: sagnik.stats at gmail.com (sagnik chakravarty)
Date: Thu, 10 Apr 2014 11:52:55 +0530
Subject: [R] Issues with fa() function in "psych"
In-Reply-To: <85300B76-7E05-4663-8D3A-E8C3FCE7DB15@revelle.net>
References: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
	<CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>
	<85300B76-7E05-4663-8D3A-E8C3FCE7DB15@revelle.net>
Message-ID: <CAMwbFxjcsExo4XZUi3pCot5efYkK5U=NcMdxbkyqf20c9wabdg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/1c33652a/attachment-0001.pl>

From tyler_benster at brown.edu  Thu Apr 10 06:44:40 2014
From: tyler_benster at brown.edu (Benster, Tyler)
Date: Thu, 10 Apr 2014 00:44:40 -0400
Subject: [R] Major discrepancy between R and Stata for ARIMA
Message-ID: <CAEtgbp36d_Dmd5yQ0LQbwYoE4VGN3JMbJt6mVSgJv=uMnnJR2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/bebf8f79/attachment-0001.pl>

From revelle at northwestern.edu  Thu Apr 10 05:00:34 2014
From: revelle at northwestern.edu (William R Revelle)
Date: Thu, 10 Apr 2014 03:00:34 +0000
Subject: [R] Polychoric Principal Component Analysis (pPCA)
In-Reply-To: <1387311511.22377.YahooMailNeo@web121705.mail.ne1.yahoo.com>
References: <1387311511.22377.YahooMailNeo@web121705.mail.ne1.yahoo.com>
Message-ID: <67CEFE69-B495-4AA2-B990-12B7579A0E4C@northwestern.edu>

Peter,
I am not sure if anyone answered your question about doing biplots using polychoric output and PCA.

The biplot.psych  example # 3 shows how to do this

library(psych)
> responses <- table2df(bock.table[,2:6],count=bock.table[,7],
>                 labs= paste ("lsat6.",1:5,sep="?))

> W <- polychoric(responses, smooth=TRUE,global=TRUE,polycor=F, 
>             ML = FALSE,  std.err=FALSE,progress=TRUE) 
#this returns an object with both the correlations and the difficulties

#get the object returned by principal  (see biplot.psych  example 3)

p3 <- principal(r = W$rho, nfactors = 3, rotate = "Promax") # works if you actually give it the matrix

p3$scores <- factor.scores(responses,p3)   #find the scores from the response data set with the p3 pca solution
 biplot.psych(p3)

Bill




On Dec 17, 2013, at 2:18 PM, Peter Maclean <pmaclean2011 at yahoo.com> wrote:

> I have data set with binary responses. I would like to
> conduct polychoric principal component analysis (pPCA). I know there are several packages used in PCA but I could not find one that directly estimate pPCA and graph the individuals and variables maps. I will appreciate any help that expand these reproducible scripts.
> #How to conduct polychoric principal component analysis pPCA using 
> #either of these packages
> library(psych) 
> library(FactoMineR)
> library(nsprcomp)
> 
> #Bock and Liberman (1970) data set of 1000 observations of the LSAT
> #from psych
> 
> data(bock)
> responses <- table2df(bock.table[,2:6],count=bock.table[,7],
>                 labs= paste ("lsat6.",1:5,sep=""))
> fix(responses) 
> describe(responses)
> #Estimate the polychoric correlation matrix to be used in 
> #PCA using psych 
> W <- polychoric(responses, smooth=TRUE,global=TRUE,polycor=F, 
>             ML = FALSE,  std.err=FALSE,progress=TRUE) 
> #Regular PCA using stat, psych and FactoMiner, respectively
> #There is no option for including the matrix
> princomp(responses, cor=TRUE) #What kind of correlation is used here?
>  
> principal(r = responses, nfactors = 3, rotate = "Promax")
> principal(r = W, nfactors = 3, rotate = "Promax") #Do not work
> 
> PCA(responses, scale.unit=TRUE, ncp=3, graph=T) 
> #How to conduct polychoric principal component analysis using either of #the above package and producing individual and variable factor maps as #above
> 
> Peter Maclean
> Department of Economics
> UDSM
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org



From petr.pikal at precheza.cz  Thu Apr 10 09:41:15 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 10 Apr 2014 07:41:15 +0000
Subject: [R] logistical indexing in R
In-Reply-To: <CABmq+QUg9=H3=xj0WLGVDBQXvRZCxaWtTkmM22f231BqXTFApQ@mail.gmail.com>
References: <CABmq+QUg9=H3=xj0WLGVDBQXvRZCxaWtTkmM22f231BqXTFApQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BC8BE7@SRVEXCHMBX.precheza.cz>

Hi

Your approach seems to be rather complicated. Just change your values into NA.

data$ej[data$ej=="-999997"] <- NA

Then you can use is.na function to select and replace na values. However it seems to me that your data are not numeric and I am not sure if it is intended or not.

If you want more help you need to provide more detailed info what do you have and what shall be the result.

see

?str, ?dput

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Si Qi L.
> Sent: Wednesday, April 09, 2014 8:16 PM
> To: r-help at r-project.org
> Subject: [R] logistical indexing in R
>
> Dear mates,
>
> I am bit of stuck with a coding, all I have to do is to clean and
> tranform the missing data "-999997" of the attribute "ej" into a normal
> number value in a range from 0 to 22. My steps are :
>
> 1) first return the subsets, as check, they do sum to original
> 2) manipulate the attribute "ej" separately and replace them
>
> # assuming you have done one round of cleaning now and saved the result
> in  a file called test.csv.
>
> data<-read.csv("test.csv", header=T)
>  data1 <- subset(data, ej=="-999997")
> summary(data1)
>
> # ND now listed as an Other field
> data2 <- subset(data, ej!="-999997")
> summary(data2)
> # can store the contents of ej and copy them back into data1 and data2.
> # or just operate on them directly;
> vector_with_ej <- data1$ej
> vector_without_ej <- data2$ej
>
> So, How to do next? can anyone please give me some comments? Many
> thanks!
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ruipbarradas at sapo.pt  Thu Apr 10 12:15:00 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 10 Apr 2014 11:15:00 +0100
Subject: [R] simulation data
In-Reply-To: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
References: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
Message-ID: <53466F24.5050204@sapo.pt>

Hello,

At an R prompt type

?rbinom
?replicate

Hope this helps,

Rui Barradas

Em 10-04-2014 02:28, thanoon younis escreveu:
> hi
>
> i want to simulate multivariate dichotomous data matrix with categories
> (0,1) and n=1000 and p=10.
>
> thanks alot in advance
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pd.mes at cbs.dk  Thu Apr 10 12:05:40 2014
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 10 Apr 2014 12:05:40 +0200
Subject: [R]  R 3.0.3 is released
Message-ID: <532362AE-0B84-4B24-AFA0-9F5CAD222EC4@cbs.dk>

The build system rolled up R-3.1.0.tar.gz (codename "Spring Dance") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.1.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.

(There seems to be a minor mishap with the NEWS file not getting copied to CRAN. I'll attend to that shortly.)


For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = cbf6da8f886ccd8d0dda0cc7ffd1b8ec
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 2978039f3d69bde1d31c5a3699dbe88a
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS.html) = d88192d6e47eec39df1fe6ba3d673ae0
MD5 (R-latest.tar.gz) = a1ee52446bee81820409661e6d114ab1
MD5 (README) = e259ae5dd943b8547f0b7719664e815b
MD5 (RESOURCES) = c7cb32499ebbf85deb064aab282f93a4
MD5 (THANKS) = d4b45e302b7cad0fc4bb50d2cfe69649
MD5 (R-3/R-3.1.0.tar.gz) = a1ee52446bee81820409661e6d114ab1



This is the relevant part of the NEWS file


CHANGES IN R 3.1.0:

  NEW FEATURES:

    * type.convert() (and hence by default read.table()) returns a
      character vector or factor when representing a numeric input as a
      double would lose accuracy.  Similarly for complex inputs.

      If a file contains numeric data with unrepresentable numbers of
      decimal places that are intended to be read as numeric, specify
      colClasses in read.table() to be "numeric".

    * tools::Rdiff(useDiff = FALSE) is closer to the POSIX definition
      of diff -b (as distinct from the description in the man pages of
      most systems).

    * New function anyNA(), a version of any(is.na(.)) which is fast
      for atomic vectors, based on a proposal by Tim Hesterberg. (Wish
      of PR#15239.)

    * arrayInd(*, useNames = TRUE) and, analogously, which(*, arr.ind =
      TRUE) now make use of names(.dimnames) when available.

    * is.unsorted() now also works for raw vectors.

    * The "table" method for as.data.frame() (also useful as
      as.data.frame.table()) now passes sep and base arguments to
      provideDimnames().

    * uniroot() gets new optional arguments, notably extendInt,
      allowing to auto-extend the search interval when needed.  The
      return value has an extra component, init.it.

    * switch(f, ...) now warns when f is a factor, as this typically
      happens accidentally where the useR meant to pass a character
      string, but f is treated as integer (as always documented).

    * The parser has been modified to use less memory.

    * The way the unary operators (+ - !) handle attributes is now more
      consistent.  If there is no coercion, all attributes (including
      class) are copied from the input to the result: otherwise only
      names, dims and dimnames are.

    * colorRamp() and colorRampPalette() now allow non-opaque colours
      and a ramp in opacity via the new argument alpha = TRUE.
      (Suggested by Alberto Krone-Martins, but optionally as there are
      existing uses which expect only RGB values.)

    * grid.show.layout() and grid.show.viewport() get an optional vp.ex
      argument.

    * There is a new function find_gs_cmd() in the tools package to
      locate a GhostScript executable.  (This is an enhanced version of
      a previously internal function there.)

    * object.size() gains a format() method.

    * There is a new family, "ArialMT", for the pdf() and postscript()
      devices.  This will only be rendered correctly on viewers which
      have access to Monotype TrueType fonts (which are sometimes
      requested by journals).

    * The text and PDF news files, including NEWS and NEWS.2, have been
      moved to the doc directory.

    * combn(x, simplify = TRUE) now gives a factor result for factor
      input x (previously user error).  (Related to PR#15442.)

    * Added utils::fileSnapshot() and utils::changedFiles() functions
      to allow snapshots and comparison of directories of files.

    * make.names(names, unique=TRUE) now tries to preserve existing
      names. (Suggestion of PR#15452.)

    * New functions cospi(x), sinpi(x), and tanpi(x), for more accurate
      computation of cos(pi*x), etc, both in R and the C API.  Using
      these gains accuracy in some cases, e.g., inside lgamma() or
      besselI().  (Suggested by Morten Welinder in PR#15529.)

    * print.table(x, zero.print = ".") now also has an effect when x is
      not integer-valued.

    * There is more support to explore the system's idea of time-zone
      names.  Sys.timezone() tries to give the current system setting
      by name (and succeeds at least on Linux, OS X, Solaris and
      Windows), and OlsonNames() lists the names in the system's Olson
      database. Sys.timezone(location = FALSE) gives the previous
      behaviour.

    * Platforms with a 64-bit time_t type are allowed to handle
      conversions between the "POSIXct" and "POSIXlt" classes for
      date-times outside the 32-bit range (before 1902 or after 2037):
      the existing workarounds are used on other platforms.  (Note that
      time-zone information for post-2037 is speculative at best, and
      the OS services are tested for known errors and so not used on OS
      X.)

      Currently time_t is usually long and hence 64-bit on Unix-alike
      64-bit platforms: however it several cases the time-zone database
      is 32-bit.  On R for Windows it is 64-bit (for both architectures
      as from this version).

    * The "save.defaults" option can include a value for
      compression_level.  (Wish of PR#15579.)

    * colSums() and friends now have support for arrays and data-frame
      columns with 2^31 or more elements.

    * as.factor() is faster when f is an unclassed integer vector (for
      example, when called from tapply()).

    * fft() now works with longer inputs, from the 12 million
      previously supported up to 2 billion.  (PR#15593)

    * Complex svd() now uses LAPACK subroutine ZGESDD, the complex
      analogue of the routine used for the real case.

    * Sweave now outputs .tex files in UTF-8 if the input encoding is
      declared to be UTF-8, regardless of the local encoding.  The
      UTF-8 encoding may now be declared using a LaTeX comment
      containing the string %\SweaveUTF8 on a line by itself.

    * file.copy() gains a copy.date argument.

    * Printing of date-times will make use of the time-zone
      abbreviation in use at the time, if known.  For example, for
      Paris pre-1940 this could be LMT, PMT, WET or WEST.  To enable
      this, the "POSIXlt" class has an optional component "zone"
      recording the abbreviation for each element.

      For platforms which support it, there is also a component
      "gmtoff" recording the offset from GMT where known.

    * (On Windows, by default on OS X and optionally elsewhere.)  The
      system C function strftime has been replaced by a more
      comprehensive version with closer conformance to the POSIX 2008
      standard.

    * dnorm(x, log = FALSE) is more accurate (but somewhat slower) for
      |x| > 5; as suggested in PR#15620.

    * Some versions of the tiff() device have further compression
      options.

    * read.table(), readLines() and scan() have a new argument to
      influence the treatment of embedded nuls.

    * Avoid duplicating the right hand side values in complex
      assignments when possible.  This reduces copying of replacement
      values in expressions such as Z$a <- a0 and ans[[i]] <- tmp: some
      package code has relied on there being copies.

      Also, a number of other changes to reduce copying of objects; all
      contributed by or based on suggestions by Michael Lawrence.

    * The fast argument of KalmanLike(), KalmanRun() and
      KalmanForecast() has been replaced by update, which instead of
      updating mod in place, optionally returns the updated model in an
      attribute "mod" of the return value.

    * arima() and makeARIMA() get a new optional argument SSinit,
      allowing the choice of a different *s*tate *s*pace initialization
      which has been observed to be more reliable close to
      non-stationarity: see PR#14682.

    * warning() has a new argument noBreaks., to simplify
      post-processing of output with options(warn = 1).

    * pushBack() gains an argument encoding, to support reading of
      UTF-8 characters using scan(), read.table() and related functions
      in a non-UTF-8 locale.

    * all.equal.list() gets a new argument use.names which by default
      labels differing components by names (if they match) rather than
      by integer index.  Saved R output in packages may need to be
      updated.

    * The methods for all.equal() and attr.all.equal() now have
      argument check.attributes after ... so it cannot be partially nor
      positionally matched (as it has been, unintentionally).

      A side effect is that some previously undetected errors of
      passing empty arguments (no object between commas) to all.equal()
      are detected and reported.

      There are explicit checks that check.attributes is logical,
      tolerance is numeric and scale is NULL or numeric.  This catches
      some unintended positional matching.

      The message for all.equal.numeric() reports a "scaled difference"
      only for scale != 1.

    * all.equal() now has a "POSIXt" method replacing the "POSIXct"
      method.

    * The "Date" and "POSIXt" methods of seq() allows by = "quarter"
      for completeness (by = "3 months" always worked).

    * file.path() removes any trailing separator on Windows, where they
      are invalid (although sometimes accepted).  This is intended to
      enhance the portability of code written by those using POSIX file
      systems (where a trailing / can be used to confine path matching
      to directories).

    * New function agrepl() which like grepl() returns a logical
      vector.

    * fifo() is now supported on Windows. (PR#15600)

    * sort.list(method = "radix") now allows negative integers (wish of
      PR#15644).

    * Some functionality of print.ts() is now available in
      .preformat.ts() for more modularity.

    * mcparallel() gains an option detach = TRUE which allows execution
      of code independently of the current session.  It is based on a
      new estranged = TRUE argument to mcfork() which forks child
      processes such that they become independent of the parent
      process.

    * The pdf() device omits circles and text at extremely small sizes,
      since some viewers were failing on such files.

    * The rightmost break for the "months", "quarters" and "years"
      cases of hist.POSIXlt() has been increased by a day.  (Inter
      alia, fixes PR#15717.)

    * The handling of DF[i,] <- a where i is of length 0 is improved.
      (Inter alia, fixes PR#15718.)

    * hclust() gains a new method "ward.D2" which implements Ward's
      method correctly.  The previous "ward" method is "ward.D" now,
      with the old name still working.  Thanks to research and
      proposals by Pierre Legendre.

    * The sunspot.month dataset has been amended and updated from the
      official source, whereas the sunspots and sunspot.year datasets
      will remain immutable. The documentation and source links have
      been updated correspondingly.

    * The summary() method for "lm" fits warns if the fit is
      essentially perfect, as most of the summary may be computed
      inaccurately (and with platform-dependent values).

      Programmers who use summary() in order to extract just a
      component which will be reliable (e.g. $cov.unscaled) should wrap
      their calls in suppressWarnings().

  INSTALLATION and INCLUDED SOFTWARE:

    * The included version of LAPACK has been updated to 3.5.0.

    * There is some support for parallel testing of an installation, by
      setting TEST_MC_CORES to an integer greater than one to indicate
      the maximum number of cores to be used in parallel. (It is worth
      specifying at least 8 cores if available.)  Most of these require
      a make program (such as GNU make and dmake) which supports the
      $MAKE -j nproc syntax.

      Except on Windows: the tests of standard package examples in make
      check are done in parallel.  This also applies to running
      tools::testInstalledPackages().

      The more time-consuming regression tests are done in parallel.

      The package checks in make check-devel and make check-recommended
      are done in parallel.

    * More of make check will work if recommended packages are not
      installed: but recommended packages remain needed for thorough
      checking of an R build.

    * The version of tzcode included in src/extra/tzone has been
      updated.  (Formerly used only on Windows.)

    * The included (64-bit) time-zone conversion code and Olson
      time-zone database can be used instead of the system version: use
      configure option --with-internal-tzcode.  This is the default on
      Windows and OS X.  (Note that this does not currently work if a
      non-default rsharedir configure variable is used.)

      (It might be necessary to set environment variable TZ on OSes
      where this is not already set, although the system timezone is
      deduced correctly on at least Linux, OS X and Windows.)

      This option also switches to the version of strftime included in
      directory src/extra/tzone.

    * configure now tests for a C++11-compliant compiler by testing
      some basic features.  This by default tries flags for the
      compiler specified by CXX, but an alternative compiler, options
      and standard can be specified by variables CXX1X, CXX1XFLAGS and
      CXX1XSTD (e.g. -std=gnu++11).

    * R can now optionally be compiled to use reference counting
      instead of the NAMED mechanism by defining SWITCH_TO_REFCNT in
      Rinternals.h. This may become the default in the future.

    * There is a new option --use-system-tre to use a suitable system
      tre library: at present this means a version from their git
      repository, after corrections.  (Wish of PR#15660.)

  PACKAGE INSTALLATION:

    * The CRANextra repository is no longer a default repository on
      Windows: all the binary versions of packages from CRAN are now on
      CRAN, although CRANextra contains packages from Omegahat and
      elsewhere used by CRAN packages.

    * Only vignettes sources in directory vignettes are considered to
      be vignettes and hence indexed as such.

    * In the DESCRIPTION file,

          License: X11

      is no longer recognized as valid.  Use MIT or BSD_2_clause
      instead, both of which need + file LICENSE.

    * For consistency, entries in .Rinstignore are now matched
      case-insensitively on all platforms.

    * Help for S4 methods with very long signatures now tries harder to
      split the description in the Usage field to no more than 80
      characters per line (some packages had over 120 characters).

    * R CMD INSTALL --build (not Windows) now defaults to the internal
      tar() unless R_INSTALL_TAR is set.

    * There is support for compiling C++11 code in packages on suitable
      platforms: see 'Writing R Extensions'.

    * Fake installs now install the contents of directory inst: some
      packages use this to install e.g. C++ headers for use by other
      packages that are independent of the package itself.  Option
      --no-inst can be used to get the previous behaviour.

  DEBUGGING:

    * The behaviour of the code browser has been made more consistent,
      in part following the suggestions in PR#14985.

    * Calls to browser() are now consistent with calls to the browser
      triggered by debug(), in that Enter will default to n rather than
      c.

    * A new browser command s has been added, to "step into" function
      calls.

    * A new browser command f has been added, to "finish" the current
      loop or function.

    * Within the browser, the command help will display a short list of
      available commands.

  UTILITIES:

    * Only vignettes sources in directory vignettes are considered to
      be vignettes by R CMD check.  That has been the preferred
      location since R 2.14.0 and is now obligatory.

    * For consistency, R CMD build now matches entries in .Rbuildignore
      and vignettes/.install_extras case-insensitively on all platforms
      (not just on Windows).

    * checkFF() (called by R CMD check by default) can optionally check
      foreign function calls for consistency with the registered type
      and argument count.  This is the default for R CMD check
      --as-cran or can be enabled by setting environment variable
      _R_CHECK_FF_CALLS_ to registration (but is in any case suppressed
      by --install=no).  Because this checks calls in which .NAME is an
      R object and not just a literal character string, some other
      problems are detected for such calls.

      Functions suppressForeignCheck() and dontCheck() have been added
      to allow package authors to suppress false positive reports.

    * R CMD check --as-cran warns about a false value of the
      DESCRIPTION field BuildVignettes for Open Source packages, and
      ignores it.  (An Open Source package needs to have complete
      sources for its vignettes which should be usable on a suitably
      well-equipped system).

    * R CMD check --no-rebuild-vignettes is defunct:
      R CMD check --no-build-vignettes has been preferred since R
      3.0.0.

    * R CMD build --no-vignettes is defunct:
      R CMD build --no-build-vignettes has been preferred since R
      3.0.0.

    * R CMD Sweave and R CMD Stangle now process both Sweave and
      non-Sweave vignettes.  The tools::buildVignette() function has
      been added to do the same tasks from within R.

    * The flags returned by R CMD config --ldflags and (where
      installed) pkg-config --libs libR are now those needed to link a
      front-end against the (shared or static) R library.

    * Sweave.sty has a new option [inconsolata].

    * R CMD check customizations such as _R_CHECK_DEPENDS_ONLY_ make
      available packages only in LinkingTo only for installation, and
      not for loading/runtime tests.

    * tools::checkFF() reports on .C and .Fortran calls with DUP =
      FALSE if argument check_DUP is true.  This is selected by R CMD
      check by default.

    * R CMD check --use-gct can be tuned to garbage-collect less
      frequently using gctorture2() _via_ the setting of environment
      variable _R_CHECK_GCT_N_.

    * Where supported, tools::texi2dvi() limits the number of passes
      tried to 20.

  C-LEVEL FACILITIES:

    * (Windows only) A function R_WaitEvent() has been added (with
      declaration in headerR.h) to block execution until the next event
      is received by R.

    * Remapping in the Rmath.h header can be suppressed by defining
      R_NO_REMAP_RMATH.

    * The remapping of rround() in header Rmath.h has been removed: use
      fround() instead.

    * ftrunc() in header Rmath.h is now a wrapper for the C99 function
      trunc(), which might as well be used in C code: ftrunc() is still
      needed for portable C++ code.

    * The never-documented remapping of prec() to fprec() in header
      Rmath.h has been removed.

    * The included LAPACK subset now contains ZGESDD and ZGELSD.

    * The function LENGTH() now checks that it is only applied to
      vector arguments.  However, in packages length() should be used.
      (In R itself LENGTH() is a macro without the function overhead of
      length().)

    * Calls to SET_VECTOR_ELT() and SET_STRING_ELT() are now checked
      for indices which are in-range: several packages were writing one
      element beyond the allocated length.

    * allocVector3 has been added which allows custom allocators to be
      used for individual vector allocations.

  DEPRECATED AND DEFUNCT:

    * chol(pivot = TRUE, LINPACK = TRUE) is defunct.

      Arguments EISPACK for eigen() and LINPACK for chol(), chol2inv(),
      solve() and svd() are ignored: LAPACK is always used.

    * .find.package() and .path.package() are defunct: only the
      versions without the initial dot introduced in R 2.13.0 have ever
      been in the API.

    * Partial matching when using the $ operator _on data frames_ now
      throws a warning and may become defunct in the future. If partial
      matching is intended, replace foo$bar by foo[["bar", exact =
      FALSE]].

    * The long-deprecated use of \synopsis in the Usage section of .Rd
      files has been removed: such sections are now ignored (with a
      warning).

    * package.skeleton()'s deprecated argument namespace has been
      removed.

    * Many methods are no longer exported by package stats.  They are
      all registered on their generic, which should be called rather
      than calling a method directly.

    * Functions readNEWS() and checkNEWS() in package tools are
      defunct.

    * download.file(method = "lynx") is deprecated.

    * .C(DUP = FALSE) and .Fortran(DUP = FALSE) are now deprecated, and
      may be disabled in future versions of R.  As their help has long
      said, .Call() is much preferred.

      R CMD check notes such usages (by default).

    * The workaround of setting R_OSX_VALGRIND has been removed: it is
      not needed in current valgrind.

  BUG FIXES:

    * Calling lm.wfit() with no non-zero weights gave an array-overrun
      in the Fortran code and a not very sensible answer.  It is now
      special-cased with a simpler answer (no qr component).

    * Error messages involving non-syntactic names (e.g. as produced by
      `\r` when that object does not exist) now encode the control
      characters.  (Reported by Hadley Wickham.)

    * getGraphicsEvent() caused 100% usage of one CPU in Windows.
      (PR#15500)

    * nls() with no start argument may now work inside another function
      (scoping issue).

    * pbeta() and similar work better for very large (billions) ncp.

    * Where time zones have changed abbreviations over the years, the
      software tries to more consistently use the abbreviation
      appropriate to the time or if that is unknown, the current
      abbreviation.  On some platforms where the C function localtime
      changed the tzname variables the reported abbreviation could have
      been that of the last time converted.

    * all.equal(list(1), identity) now works.

    * Bug fix for pushing viewports in grid (reported by JJ Allaire and
      Kevin Ushey).

      NOTE for anyone poking around within the graphics engine display
      list (despite the warnings not to) that this changes what is
      recorded by grid on the graphics engine display list.

    * Extra checks have been added for unit resolution and conversion
      in grid, to catch instances of division-by-zero.  This may
      introduce error messages in existing code and/or produce a
      different result in existing code (but only where a non-finite
      location or dimension may now become zero).

    * Some bugs in TRE have been corrected by updating from the git
      repository.  This allows R to be installed on some platforms for
      which this was a blocker (PR#15087 suggests Linux on ARM and
      HP-UX).

    * ? applied to a call to an S4 generic failed in several cases.
      (PR#15680)
      which this was a blocker (PR#15087 suggests Linux on ARM and
      HP-UX).

    * ? applied to a call to an S4 generic failed in several cases.
      (PR#15680)

    * The implicit S4 generics for primitives with ... in their
      argument list were incorrect. (PR#15690)

    * Bug fixes to methods::callGeneric(). (PR#15691)

    * The bug fix to aggregrate() in PR#15004 introduced a new bug in
      the case of no grouping variables. (PR#15699)

    * In rare cases printing deeply nested lists overran a buffer by
      one byte and on a few platforms segfaulted. (PR#15679)

    * The dendrogram method of as.dendrogram() was hidden accidentally,
      (PR#15703), and order.dendrogram(d) gave too much for a leaf d.
      (PR#15702)

    * R would try to kill processes on exit that have pids ever used by
      a child process spawned by mcparallel even though the current
      process with that pid was not actually its child.

    * cophenetic() applied to a "dendrogram" object sometimes
      incorrectly returned a "Labels" attribute with dimensions.
      (PR#15706)

    * printCoefmat() called from quite a few print() methods now obeys
      small getOption("width") settings, line wrapping the "signif.
      codes" legend appropriately.  (PR#15708)

    * model.matrix() assumed that the stored dimnames for a matrix was
      NULL or length 2, but length 1 occurred.

    * The clipping region for a device was sometimes used in base
      graphics before it was set.



--
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce



From pd.mes at cbs.dk  Thu Apr 10 12:07:38 2014
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 10 Apr 2014 12:07:38 +0200
Subject: [R]  R 3.1.0 is released
Message-ID: <4415F313-1667-4A20-9005-CB3518BCA43E@cbs.dk>

(Resend with correct Subject field.)

The build system rolled up R-3.1.0.tar.gz (codename "Spring Dance") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.1.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.

(There seems to be a minor mishap with the NEWS file not getting copied to CRAN. I'll attend to that shortly.)


For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = cbf6da8f886ccd8d0dda0cc7ffd1b8ec
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 2978039f3d69bde1d31c5a3699dbe88a
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS.html) = d88192d6e47eec39df1fe6ba3d673ae0
MD5 (R-latest.tar.gz) = a1ee52446bee81820409661e6d114ab1
MD5 (README) = e259ae5dd943b8547f0b7719664e815b
MD5 (RESOURCES) = c7cb32499ebbf85deb064aab282f93a4
MD5 (THANKS) = d4b45e302b7cad0fc4bb50d2cfe69649
MD5 (R-3/R-3.1.0.tar.gz) = a1ee52446bee81820409661e6d114ab1



This is the relevant part of the NEWS file


CHANGES IN R 3.1.0:

 NEW FEATURES:

   * type.convert() (and hence by default read.table()) returns a
     character vector or factor when representing a numeric input as a
     double would lose accuracy.  Similarly for complex inputs.

     If a file contains numeric data with unrepresentable numbers of
     decimal places that are intended to be read as numeric, specify
     colClasses in read.table() to be "numeric".

   * tools::Rdiff(useDiff = FALSE) is closer to the POSIX definition
     of diff -b (as distinct from the description in the man pages of
     most systems).

   * New function anyNA(), a version of any(is.na(.)) which is fast
     for atomic vectors, based on a proposal by Tim Hesterberg. (Wish
     of PR#15239.)

   * arrayInd(*, useNames = TRUE) and, analogously, which(*, arr.ind =
     TRUE) now make use of names(.dimnames) when available.

   * is.unsorted() now also works for raw vectors.

   * The "table" method for as.data.frame() (also useful as
     as.data.frame.table()) now passes sep and base arguments to
     provideDimnames().

   * uniroot() gets new optional arguments, notably extendInt,
     allowing to auto-extend the search interval when needed.  The
     return value has an extra component, init.it.

   * switch(f, ...) now warns when f is a factor, as this typically
     happens accidentally where the useR meant to pass a character
     string, but f is treated as integer (as always documented).

   * The parser has been modified to use less memory.

   * The way the unary operators (+ - !) handle attributes is now more
     consistent.  If there is no coercion, all attributes (including
     class) are copied from the input to the result: otherwise only
     names, dims and dimnames are.

   * colorRamp() and colorRampPalette() now allow non-opaque colours
     and a ramp in opacity via the new argument alpha = TRUE.
     (Suggested by Alberto Krone-Martins, but optionally as there are
     existing uses which expect only RGB values.)

   * grid.show.layout() and grid.show.viewport() get an optional vp.ex
     argument.

   * There is a new function find_gs_cmd() in the tools package to
     locate a GhostScript executable.  (This is an enhanced version of
     a previously internal function there.)

   * object.size() gains a format() method.

   * There is a new family, "ArialMT", for the pdf() and postscript()
     devices.  This will only be rendered correctly on viewers which
     have access to Monotype TrueType fonts (which are sometimes
     requested by journals).

   * The text and PDF news files, including NEWS and NEWS.2, have been
     moved to the doc directory.

   * combn(x, simplify = TRUE) now gives a factor result for factor
     input x (previously user error).  (Related to PR#15442.)

   * Added utils::fileSnapshot() and utils::changedFiles() functions
     to allow snapshots and comparison of directories of files.

   * make.names(names, unique=TRUE) now tries to preserve existing
     names. (Suggestion of PR#15452.)

   * New functions cospi(x), sinpi(x), and tanpi(x), for more accurate
     computation of cos(pi*x), etc, both in R and the C API.  Using
     these gains accuracy in some cases, e.g., inside lgamma() or
     besselI().  (Suggested by Morten Welinder in PR#15529.)

   * print.table(x, zero.print = ".") now also has an effect when x is
     not integer-valued.

   * There is more support to explore the system's idea of time-zone
     names.  Sys.timezone() tries to give the current system setting
     by name (and succeeds at least on Linux, OS X, Solaris and
     Windows), and OlsonNames() lists the names in the system's Olson
     database. Sys.timezone(location = FALSE) gives the previous
     behaviour.

   * Platforms with a 64-bit time_t type are allowed to handle
     conversions between the "POSIXct" and "POSIXlt" classes for
     date-times outside the 32-bit range (before 1902 or after 2037):
     the existing workarounds are used on other platforms.  (Note that
     time-zone information for post-2037 is speculative at best, and
     the OS services are tested for known errors and so not used on OS
     X.)

     Currently time_t is usually long and hence 64-bit on Unix-alike
     64-bit platforms: however it several cases the time-zone database
     is 32-bit.  On R for Windows it is 64-bit (for both architectures
     as from this version).

   * The "save.defaults" option can include a value for
     compression_level.  (Wish of PR#15579.)

   * colSums() and friends now have support for arrays and data-frame
     columns with 2^31 or more elements.

   * as.factor() is faster when f is an unclassed integer vector (for
     example, when called from tapply()).

   * fft() now works with longer inputs, from the 12 million
     previously supported up to 2 billion.  (PR#15593)

   * Complex svd() now uses LAPACK subroutine ZGESDD, the complex
     analogue of the routine used for the real case.

   * Sweave now outputs .tex files in UTF-8 if the input encoding is
     declared to be UTF-8, regardless of the local encoding.  The
     UTF-8 encoding may now be declared using a LaTeX comment
     containing the string %\SweaveUTF8 on a line by itself.

   * file.copy() gains a copy.date argument.

   * Printing of date-times will make use of the time-zone
     abbreviation in use at the time, if known.  For example, for
     Paris pre-1940 this could be LMT, PMT, WET or WEST.  To enable
     this, the "POSIXlt" class has an optional component "zone"
     recording the abbreviation for each element.

     For platforms which support it, there is also a component
     "gmtoff" recording the offset from GMT where known.

   * (On Windows, by default on OS X and optionally elsewhere.)  The
     system C function strftime has been replaced by a more
     comprehensive version with closer conformance to the POSIX 2008
     standard.

   * dnorm(x, log = FALSE) is more accurate (but somewhat slower) for
     |x| > 5; as suggested in PR#15620.

   * Some versions of the tiff() device have further compression
     options.

   * read.table(), readLines() and scan() have a new argument to
     influence the treatment of embedded nuls.

   * Avoid duplicating the right hand side values in complex
     assignments when possible.  This reduces copying of replacement
     values in expressions such as Z$a <- a0 and ans[[i]] <- tmp: some
     package code has relied on there being copies.

     Also, a number of other changes to reduce copying of objects; all
     contributed by or based on suggestions by Michael Lawrence.

   * The fast argument of KalmanLike(), KalmanRun() and
     KalmanForecast() has been replaced by update, which instead of
     updating mod in place, optionally returns the updated model in an
     attribute "mod" of the return value.

   * arima() and makeARIMA() get a new optional argument SSinit,
     allowing the choice of a different *s*tate *s*pace initialization
     which has been observed to be more reliable close to
     non-stationarity: see PR#14682.

   * warning() has a new argument noBreaks., to simplify
     post-processing of output with options(warn = 1).

   * pushBack() gains an argument encoding, to support reading of
     UTF-8 characters using scan(), read.table() and related functions
     in a non-UTF-8 locale.

   * all.equal.list() gets a new argument use.names which by default
     labels differing components by names (if they match) rather than
     by integer index.  Saved R output in packages may need to be
     updated.

   * The methods for all.equal() and attr.all.equal() now have
     argument check.attributes after ... so it cannot be partially nor
     positionally matched (as it has been, unintentionally).

     A side effect is that some previously undetected errors of
     passing empty arguments (no object between commas) to all.equal()
     are detected and reported.

     There are explicit checks that check.attributes is logical,
     tolerance is numeric and scale is NULL or numeric.  This catches
     some unintended positional matching.

     The message for all.equal.numeric() reports a "scaled difference"
     only for scale != 1.

   * all.equal() now has a "POSIXt" method replacing the "POSIXct"
     method.

   * The "Date" and "POSIXt" methods of seq() allows by = "quarter"
     for completeness (by = "3 months" always worked).

   * file.path() removes any trailing separator on Windows, where they
     are invalid (although sometimes accepted).  This is intended to
     enhance the portability of code written by those using POSIX file
     systems (where a trailing / can be used to confine path matching
     to directories).

   * New function agrepl() which like grepl() returns a logical
     vector.

   * fifo() is now supported on Windows. (PR#15600)

   * sort.list(method = "radix") now allows negative integers (wish of
     PR#15644).

   * Some functionality of print.ts() is now available in
     .preformat.ts() for more modularity.

   * mcparallel() gains an option detach = TRUE which allows execution
     of code independently of the current session.  It is based on a
     new estranged = TRUE argument to mcfork() which forks child
     processes such that they become independent of the parent
     process.

   * The pdf() device omits circles and text at extremely small sizes,
     since some viewers were failing on such files.

   * The rightmost break for the "months", "quarters" and "years"
     cases of hist.POSIXlt() has been increased by a day.  (Inter
     alia, fixes PR#15717.)

   * The handling of DF[i,] <- a where i is of length 0 is improved.
     (Inter alia, fixes PR#15718.)

   * hclust() gains a new method "ward.D2" which implements Ward's
     method correctly.  The previous "ward" method is "ward.D" now,
     with the old name still working.  Thanks to research and
     proposals by Pierre Legendre.

   * The sunspot.month dataset has been amended and updated from the
     official source, whereas the sunspots and sunspot.year datasets
     will remain immutable. The documentation and source links have
     been updated correspondingly.

   * The summary() method for "lm" fits warns if the fit is
     essentially perfect, as most of the summary may be computed
     inaccurately (and with platform-dependent values).

     Programmers who use summary() in order to extract just a
     component which will be reliable (e.g. $cov.unscaled) should wrap
     their calls in suppressWarnings().

 INSTALLATION and INCLUDED SOFTWARE:

   * The included version of LAPACK has been updated to 3.5.0.

   * There is some support for parallel testing of an installation, by
     setting TEST_MC_CORES to an integer greater than one to indicate
     the maximum number of cores to be used in parallel. (It is worth
     specifying at least 8 cores if available.)  Most of these require
     a make program (such as GNU make and dmake) which supports the
     $MAKE -j nproc syntax.

     Except on Windows: the tests of standard package examples in make
     check are done in parallel.  This also applies to running
     tools::testInstalledPackages().

     The more time-consuming regression tests are done in parallel.

     The package checks in make check-devel and make check-recommended
     are done in parallel.

   * More of make check will work if recommended packages are not
     installed: but recommended packages remain needed for thorough
     checking of an R build.

   * The version of tzcode included in src/extra/tzone has been
     updated.  (Formerly used only on Windows.)

   * The included (64-bit) time-zone conversion code and Olson
     time-zone database can be used instead of the system version: use
     configure option --with-internal-tzcode.  This is the default on
     Windows and OS X.  (Note that this does not currently work if a
     non-default rsharedir configure variable is used.)

     (It might be necessary to set environment variable TZ on OSes
     where this is not already set, although the system timezone is
     deduced correctly on at least Linux, OS X and Windows.)

     This option also switches to the version of strftime included in
     directory src/extra/tzone.

   * configure now tests for a C++11-compliant compiler by testing
     some basic features.  This by default tries flags for the
     compiler specified by CXX, but an alternative compiler, options
     and standard can be specified by variables CXX1X, CXX1XFLAGS and
     CXX1XSTD (e.g. -std=gnu++11).

   * R can now optionally be compiled to use reference counting
     instead of the NAMED mechanism by defining SWITCH_TO_REFCNT in
     Rinternals.h. This may become the default in the future.

   * There is a new option --use-system-tre to use a suitable system
     tre library: at present this means a version from their git
     repository, after corrections.  (Wish of PR#15660.)

 PACKAGE INSTALLATION:

   * The CRANextra repository is no longer a default repository on
     Windows: all the binary versions of packages from CRAN are now on
     CRAN, although CRANextra contains packages from Omegahat and
     elsewhere used by CRAN packages.

   * Only vignettes sources in directory vignettes are considered to
     be vignettes and hence indexed as such.

   * In the DESCRIPTION file,

         License: X11

     is no longer recognized as valid.  Use MIT or BSD_2_clause
     instead, both of which need + file LICENSE.

   * For consistency, entries in .Rinstignore are now matched
     case-insensitively on all platforms.

   * Help for S4 methods with very long signatures now tries harder to
     split the description in the Usage field to no more than 80
     characters per line (some packages had over 120 characters).

   * R CMD INSTALL --build (not Windows) now defaults to the internal
     tar() unless R_INSTALL_TAR is set.

   * There is support for compiling C++11 code in packages on suitable
     platforms: see 'Writing R Extensions'.

   * Fake installs now install the contents of directory inst: some
     packages use this to install e.g. C++ headers for use by other
     packages that are independent of the package itself.  Option
     --no-inst can be used to get the previous behaviour.

 DEBUGGING:

   * The behaviour of the code browser has been made more consistent,
     in part following the suggestions in PR#14985.

   * Calls to browser() are now consistent with calls to the browser
     triggered by debug(), in that Enter will default to n rather than
     c.

   * A new browser command s has been added, to "step into" function
     calls.

   * A new browser command f has been added, to "finish" the current
     loop or function.

   * Within the browser, the command help will display a short list of
     available commands.

 UTILITIES:

   * Only vignettes sources in directory vignettes are considered to
     be vignettes by R CMD check.  That has been the preferred
     location since R 2.14.0 and is now obligatory.

   * For consistency, R CMD build now matches entries in .Rbuildignore
     and vignettes/.install_extras case-insensitively on all platforms
     (not just on Windows).

   * checkFF() (called by R CMD check by default) can optionally check
     foreign function calls for consistency with the registered type
     and argument count.  This is the default for R CMD check
     --as-cran or can be enabled by setting environment variable
     _R_CHECK_FF_CALLS_ to registration (but is in any case suppressed
     by --install=no).  Because this checks calls in which .NAME is an
     R object and not just a literal character string, some other
     problems are detected for such calls.

     Functions suppressForeignCheck() and dontCheck() have been added
     to allow package authors to suppress false positive reports.

   * R CMD check --as-cran warns about a false value of the
     DESCRIPTION field BuildVignettes for Open Source packages, and
     ignores it.  (An Open Source package needs to have complete
     sources for its vignettes which should be usable on a suitably
     well-equipped system).

   * R CMD check --no-rebuild-vignettes is defunct:
     R CMD check --no-build-vignettes has been preferred since R
     3.0.0.

   * R CMD build --no-vignettes is defunct:
     R CMD build --no-build-vignettes has been preferred since R
     3.0.0.

   * R CMD Sweave and R CMD Stangle now process both Sweave and
     non-Sweave vignettes.  The tools::buildVignette() function has
     been added to do the same tasks from within R.

   * The flags returned by R CMD config --ldflags and (where
     installed) pkg-config --libs libR are now those needed to link a
     front-end against the (shared or static) R library.

   * Sweave.sty has a new option [inconsolata].

   * R CMD check customizations such as _R_CHECK_DEPENDS_ONLY_ make
     available packages only in LinkingTo only for installation, and
     not for loading/runtime tests.

   * tools::checkFF() reports on .C and .Fortran calls with DUP =
     FALSE if argument check_DUP is true.  This is selected by R CMD
     check by default.

   * R CMD check --use-gct can be tuned to garbage-collect less
     frequently using gctorture2() _via_ the setting of environment
     variable _R_CHECK_GCT_N_.

   * Where supported, tools::texi2dvi() limits the number of passes
     tried to 20.

 C-LEVEL FACILITIES:

   * (Windows only) A function R_WaitEvent() has been added (with
     declaration in headerR.h) to block execution until the next event
     is received by R.

   * Remapping in the Rmath.h header can be suppressed by defining
     R_NO_REMAP_RMATH.

   * The remapping of rround() in header Rmath.h has been removed: use
     fround() instead.

   * ftrunc() in header Rmath.h is now a wrapper for the C99 function
     trunc(), which might as well be used in C code: ftrunc() is still
     needed for portable C++ code.

   * The never-documented remapping of prec() to fprec() in header
     Rmath.h has been removed.

   * The included LAPACK subset now contains ZGESDD and ZGELSD.

   * The function LENGTH() now checks that it is only applied to
     vector arguments.  However, in packages length() should be used.
     (In R itself LENGTH() is a macro without the function overhead of
     length().)

   * Calls to SET_VECTOR_ELT() and SET_STRING_ELT() are now checked
     for indices which are in-range: several packages were writing one
     element beyond the allocated length.

   * allocVector3 has been added which allows custom allocators to be
     used for individual vector allocations.

 DEPRECATED AND DEFUNCT:

   * chol(pivot = TRUE, LINPACK = TRUE) is defunct.

     Arguments EISPACK for eigen() and LINPACK for chol(), chol2inv(),
     solve() and svd() are ignored: LAPACK is always used.

   * .find.package() and .path.package() are defunct: only the
     versions without the initial dot introduced in R 2.13.0 have ever
     been in the API.

   * Partial matching when using the $ operator _on data frames_ now
     throws a warning and may become defunct in the future. If partial
     matching is intended, replace foo$bar by foo[["bar", exact =
     FALSE]].

   * The long-deprecated use of \synopsis in the Usage section of .Rd
     files has been removed: such sections are now ignored (with a
     warning).

   * package.skeleton()'s deprecated argument namespace has been
     removed.

   * Many methods are no longer exported by package stats.  They are
     all registered on their generic, which should be called rather
     than calling a method directly.

   * Functions readNEWS() and checkNEWS() in package tools are
     defunct.

   * download.file(method = "lynx") is deprecated.

   * .C(DUP = FALSE) and .Fortran(DUP = FALSE) are now deprecated, and
     may be disabled in future versions of R.  As their help has long
     said, .Call() is much preferred.

     R CMD check notes such usages (by default).

   * The workaround of setting R_OSX_VALGRIND has been removed: it is
     not needed in current valgrind.

 BUG FIXES:

   * Calling lm.wfit() with no non-zero weights gave an array-overrun
     in the Fortran code and a not very sensible answer.  It is now
     special-cased with a simpler answer (no qr component).

   * Error messages involving non-syntactic names (e.g. as produced by
     `\r` when that object does not exist) now encode the control
     characters.  (Reported by Hadley Wickham.)

   * getGraphicsEvent() caused 100% usage of one CPU in Windows.
     (PR#15500)

   * nls() with no start argument may now work inside another function
     (scoping issue).

   * pbeta() and similar work better for very large (billions) ncp.

   * Where time zones have changed abbreviations over the years, the
     software tries to more consistently use the abbreviation
     appropriate to the time or if that is unknown, the current
     abbreviation.  On some platforms where the C function localtime
     changed the tzname variables the reported abbreviation could have
     been that of the last time converted.

   * all.equal(list(1), identity) now works.

   * Bug fix for pushing viewports in grid (reported by JJ Allaire and
     Kevin Ushey).

     NOTE for anyone poking around within the graphics engine display
     list (despite the warnings not to) that this changes what is
     recorded by grid on the graphics engine display list.

   * Extra checks have been added for unit resolution and conversion
     in grid, to catch instances of division-by-zero.  This may
     introduce error messages in existing code and/or produce a
     different result in existing code (but only where a non-finite
     location or dimension may now become zero).

   * Some bugs in TRE have been corrected by updating from the git
     repository.  This allows R to be installed on some platforms for
     which this was a blocker (PR#15087 suggests Linux on ARM and
     HP-UX).

   * ? applied to a call to an S4 generic failed in several cases.
     (PR#15680)
     which this was a blocker (PR#15087 suggests Linux on ARM and
     HP-UX).

   * ? applied to a call to an S4 generic failed in several cases.
     (PR#15680)

   * The implicit S4 generics for primitives with ... in their
     argument list were incorrect. (PR#15690)

   * Bug fixes to methods::callGeneric(). (PR#15691)

   * The bug fix to aggregrate() in PR#15004 introduced a new bug in
     the case of no grouping variables. (PR#15699)

   * In rare cases printing deeply nested lists overran a buffer by
     one byte and on a few platforms segfaulted. (PR#15679)

   * The dendrogram method of as.dendrogram() was hidden accidentally,
     (PR#15703), and order.dendrogram(d) gave too much for a leaf d.
     (PR#15702)

   * R would try to kill processes on exit that have pids ever used by
     a child process spawned by mcparallel even though the current
     process with that pid was not actually its child.

   * cophenetic() applied to a "dendrogram" object sometimes
     incorrectly returned a "Labels" attribute with dimensions.
     (PR#15706)

   * printCoefmat() called from quite a few print() methods now obeys
     small getOption("width") settings, line wrapping the "signif.
     codes" legend appropriately.  (PR#15708)

   * model.matrix() assumed that the stored dimnames for a matrix was
     NULL or length 2, but length 1 occurred.

   * The clipping region for a device was sometimes used in base
     graphics before it was set.



--
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce



From dimitri.liakhovitski at gmail.com  Thu Apr 10 13:52:48 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 10 Apr 2014 07:52:48 -0400
Subject: [R] R speed test - for processor and for RAM size
Message-ID: <CAN2xGJZLQuGUGLLHeuaUVGUrEG7qq01_4gvx5bAtE4MTyTx-ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/165e38bf/attachment-0001.pl>

From julien.riou.k at gmail.com  Thu Apr 10 14:17:54 2014
From: julien.riou.k at gmail.com (Julien Riou)
Date: Thu, 10 Apr 2014 14:17:54 +0200
Subject: [R] Meta-analysis of prevalence at the country level with
	mgcv/gamm4
Message-ID: <CAL49zWPSEFD_sB6VJUr7V_whijSa3TMHTAh5jn9e1SN_vL2Hig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/30874783/attachment-0001.pl>

From dan.abner99 at gmail.com  Thu Apr 10 14:49:41 2014
From: dan.abner99 at gmail.com (Dan Abner)
Date: Thu, 10 Apr 2014 08:49:41 -0400
Subject: [R] mean fn in combination with by() XXXX
Message-ID: <CAPRGo-=+QZdqEPg5fa9RGtHuMkTfpEue2+0aYiMLKJY9gi0aoQ@mail.gmail.com>

 Hi all,

Can anyone please explain the following results (why does median()
work here but not mean())? Is there a fix or work around for this?

Thanks,

Dan


> by(urpdata[,2],urpdata[,12],mean,na.rm=TRUE)
Error in FUN(X[[1L]], ...) : could not find function "FUN"
> by(urpdata[,2],urpdata[,12],median,na.rm=TRUE)
urpdata[, 12]: post
[1] 64
------------------------------------------------------------------------------------------------------------------------------------
urpdata[, 12]: pre
[1] 83



From rguy at 123mail.org  Thu Apr 10 14:53:41 2014
From: rguy at 123mail.org (Rguy)
Date: Thu, 10 Apr 2014 13:53:41 +0100
Subject: [R] ggplot: vertical text annotation, outside plot region
Message-ID: <CAEorq2PC_MRcwyRpmF5hcx9_adWkB_uKqTYdvyO+6w+uZ4cMeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/80ffa359/attachment-0001.pl>

From deter088 at umn.edu  Thu Apr 10 14:55:24 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 Apr 2014 07:55:24 -0500
Subject: [R] simulation data
In-Reply-To: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
References: <CABLo8nHWmkdTZRj41m1FBCT-XQrn81bk5W-CLSEvv7DoF1-23w@mail.gmail.com>
Message-ID: <CAOLJphkLFL+_ntqhQx=rwTem=G=zqz6psbnC5CV98MpFVcQG4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/0d6b180b/attachment-0001.pl>

From lists at revelle.net  Thu Apr 10 16:38:13 2014
From: lists at revelle.net (William Revelle)
Date: Thu, 10 Apr 2014 09:38:13 -0500
Subject: [R] Issues with fa() function in "psych"
In-Reply-To: <CAMwbFxjcsExo4XZUi3pCot5efYkK5U=NcMdxbkyqf20c9wabdg@mail.gmail.com>
References: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
	<CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>
	<85300B76-7E05-4663-8D3A-E8C3FCE7DB15@revelle.net>
	<CAMwbFxjcsExo4XZUi3pCot5efYkK5U=NcMdxbkyqf20c9wabdg@mail.gmail.com>
Message-ID: <DD637DF7-8CA6-4422-9CA2-B3D8FE98917E@revelle.net>

I am probably going to push it to CRAN today or tomorrow.

Bill

On Apr 10, 2014, at 1:22 AM, sagnik chakravarty <sagnik.stats at gmail.com> wrote:

> Thanks a lot Bill and Revelle for your helpful response.
> It would have been great if I could know when we can expect the release of the edited version 1.4.4. 
> 
> Sagnik
> 
> 
> On Wed, Apr 9, 2014 at 8:05 PM, William Revelle <lists at revelle.net> wrote:
> Sagnik raises the question as to why the psych package does not offer the ?equamax? rotation.
> It is because all rotations are handled through the GPArotation package which does not offer equamax.
> 
> Sagnik also points out that if the requested rotation is not available, fa defaults to rotate=?none? without any warning.  I have fixed that for the  next release (1.4.4).
> (1.4.4 also will fix a bug in corr.test introduced into 1.4.3).
> 
> 
> The question about why printing just the loadings matrix leaves blank cells?  That is because the loadings matrix of class ?loadings? which the default print function prints with a cut = .3.
> Using the example from Sagnik, print(efa_pa$loadings,cut=0) will match the output of efa_pa.
> 
> The fm=?pa? option runs conventional principal axis factor analysis (ala SPSS).  As documented, this iterates max.iter times
> 
> "Not all factor programs that do principal axes do iterative solutions. The example from the SAS manual (Chapter 26) is such a case. To achieve that solution, it is necessary to specify that the max.iterations = 1. Comparing that solution to an iterated one (the default) shows that iterations improve the solution. In addition, fm="minres" or fm="mle" produces even better solutions for this example.?
> 
> The com column is factor complexity using the index developed by Hofmann (1978).  It is a row wise measure of item complexity.
> I have added more documentation to this in 1.4.4
> 
> Bill
> 
> 
> On Apr 8, 2014, at 2:28 AM, Pascal Oettli <kridox at ymail.com> wrote:
> 
> > Hello,
> >
> > And what about submitting your suggestions directly to the package
> > author/maintainer?
> >
> > And please don't post in HTML.
> >
> > Regards,
> > Pascal
> >
> > On Tue, Apr 8, 2014 at 3:13 PM, sagnik chakravarty
> > <sagnik.stats at gmail.com> wrote:
> >> Hi Team,
> >>
> >> I was using your "psych" package for factor analysis and was also comparing
> >> the results with SAS results. I have some suggestions and/or confusions
> >> regarding the fa() function in the package:
> >>
> >>   - The fa() function *doesn't account for Heywood cases* (communality
> >>   greater than 1) and never ever throws out any error related to that which
> >>   other softwares do. This is a serious and common issue in iterative factor
> >>   analysis and hence should have been accounted for.
> >>
> >>
> >>   - The fa() function doesn't provide "equamax" rotation in its rotation
> >>   list and still if you specify "*rotation=equamax*", it will run without
> >>   throwing out any error and even mentioning in the result that "equamax" has
> >>   been applied. But I have thoroughly compared results from "
> >>   *rotation=none*" and "*rotation=equamax*" options and they are exactly
> >>   same. *That means fa() is not doing the rotation at all and yet telling
> >>   that it is doing that!!* I have even mentioned "*rotation=crap*" option
> >>   just to check and surprisingly it ran(without any error) with the result
> >>   showing:
> >>
> >>           *Factor Analysis using method =  gls*
> >> *           Call: fa(r = cor_mat, nfactors = 4, n.obs = 69576, rotate =
> >> "crap", fm = "gls")*
> >>
> >>            I hope you understand the severity of this bug and hence
> >> request you to correct this.
> >>
> >>   - To my sense, there might be some problem with "fm=ml" and "fm=pa"
> >>   options since the convergence issue should be with MLE method and not PA
> >>   method but while running factor analysis with PA, I am getting the
> >>   following warning:
> >>
> >>            *maximum iteration exceeded*
> >> *            The estimated weights for the factor scores are probably
> >> incorrect.  Try a different factor extraction method.*
> >>
> >>             If I compare the results of R and SAS,* I am getting
> >> convergence error for MLE in SAS whereas I am getting the same error for PA
> >> in R *!! I am not being able to understand this mismatch.
> >>
> >>   - If I call the *loading matrix like efa_pa$loadings, the matrix shown
> >>   has many blank cells whereas the final result showing the loadings doesn't
> >>   have so* !!
> >>
> >> *Loadings:*
> >> *             PA1    PA2    PA3    PA4   *
> >> *Var1    0.401                       -0.243*
> >> *Var2    0.336 -0.104            0.710*
> >> *Var3    0.624  0.123 0.170      *
> >>
> >>
> >>   - Could you please explain* what the "com" column means* in the output:?
> >>
> >>
> >> *           PA1   PA3   PA2   PA4     h2          u2      com*
> >> *Var1  0.44  0.14 -0.03  -0.10 0.22665  0.773  1.3*
> >> *Var2  0.08  0.11  0.02   0.78  0.62951  0.370  1.1*
> >> *Var3  0.62  0.12  0.15   0.14  0.43578  0.564  1.3*
> >>
> >>   - Request you to add option for *"equamax" rotation* also if possible.
> >>
> >>
> >> I have come across the above issues until now. Please do correct me if I am
> >> wrong.
> >>
> >> Awaiting your revert which would clear out my confusions,
> >>
> >> Thanks for your valuable time,
> >>
> >> Sagnik
> >>
> >> --
> >> Regards,
> >>
> >> *SAGNIK CHAKRAVARTY*
> >>
> >> *Mob:*  +919972865435
> >> *Email:* sagnik.stats at gmail.com
> >>           sagnik.739 at gmail.com
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Pascal Oettli
> > Project Scientist
> > JAMSTEC
> > Yokohama, Japan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> William Revelle                    http://personality-project.org/revelle.html
> Professor                                  http://personality-project.org
> Department of Psychology   http://www.wcas.northwestern.edu/psych/
> Northwestern University    http://www.northwestern.edu/
> Use R for psychology             http://personality-project.org/r
> It is 5 minutes to midnight        http://www.thebulletin.org
> 
> 
> 
> 
> 
> 
> 
> -- 
> Regards,
> 
> SAGNIK CHAKRAVARTY
> 
> Mob:  +919972865435      
> Email: sagnik.stats at gmail.com
>            sagnik.739 at gmail.com

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org



From crns13 at gmail.com  Thu Apr 10 16:49:18 2014
From: crns13 at gmail.com (Cassiano dos Santos)
Date: Thu, 10 Apr 2014 11:49:18 -0300
Subject: [R] Memory allocation using .C interface
In-Reply-To: <CA+hbrhXMphxKy2v2je-L2nMVWJ7U0zLhL+6xirxa7+5Aj9P5GA@mail.gmail.com>
References: <CACyCQc+UbURQY2G7HFC9h7PVpJbVd15ju0ygyi6BWod2O01Hig@mail.gmail.com>
	<CA+hbrhXMphxKy2v2je-L2nMVWJ7U0zLhL+6xirxa7+5Aj9P5GA@mail.gmail.com>
Message-ID: <CACyCQcJ=AmtaXVODa9PSOtoGLcex6f6OvkD=G0Zt4+AitrUv2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/0e43d09b/attachment-0001.pl>

From pauljohn32 at gmail.com  Thu Apr 10 16:59:47 2014
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 10 Apr 2014 09:59:47 -0500
Subject: [R] premature evaluation of symbols. Is that the way to describe
	this problem?
Message-ID: <CAErODj-vSeWjLYQL1d2eE9PGzu5xk8HNKZmyKp-144rFODf79A@mail.gmail.com>

Dear eveRybody

In the package rockchalk, I have functions that take regressions and
make tables and plots.  Sometimes I'll combine a model with various
arguments and pass the resulting list around to be executed, usually
using do.call.  While debugging a function on a particularly large
dataset, I noticed that I've caused inconvenience for myself. I get
the correct calculations, but the arguments into functions are not
symbols when the function call happens. They are fully "written out".

So the debugger does not see function(x), it sees
function(c(1,3,1,3,45,2,4,2....).  Debugging begins with a
comprehensive listing of the elements in every object, which freezes
Emacs/ESS and generally ruins my quality of life.

I don't know the right words for this, but it seems to me object names
are parsed and evaluated before they need to be. Function calls
include the evaluated arguments in them, not just the symbols for
them.  I have some guesses on fixes, wonder what you think. And I
wonder if fixing this problem might generally make my functions faster
and more efficient because I'm not passing gigantic collections of
numbers through the function call.  I know, I don't have all the right
words here.

I've built a toy example that will illustrate the problem, you tell me
the words for it.

## Paul Johnson 2014-04-10
dat <- data.frame(x = rnorm(50),y = rnorm(50))
m1 <- lm(y ~ x, dat)

myRegFit <- function(model, nd) predict(model, nd)

mySpecialFeature <- function(model, ci){
    pargs <- list(model, model.frame(model)[1:3, ])
    res <- do.call(myRegFit, pargs)
    print(res)
}

mySpecialFeature (m1)

debug(myRegFit)

mySpecialFeature (m1)

Note when the debugger enters, it has the whole model's structure
"splatted" into the function call.

> dat <- data.frame(x = rnorm(50),y = rnorm(50))
> m1 <- lm(y ~ x, dat)
> myRegFit <-function(model, nd) predict(model, nd)
> mySpecialFeature <- function(model, ci){
+     pargs <- list(model, model.frame(model)[1:3, ])
+     res <- do.call(myRegFit, pargs)
+     print(res)
+ }
> mySpecialFeature (m1)
          1           2           3
-0.04755431  0.35162844 -0.11715522
> debug(myRegFit)
> mySpecialFeature (m1)
debugging in: (function (model, nd)
predict(model, nd))(list(coefficients = c(0.0636305741709566,
-0.177786836929453), residuals = c(-0.0152803151982162, -0.885875162659858,
-1.23645319405006, -1.77900639571943, -1.9952045397527, 1.38150266407176,
-2.27403449262599, 0.0367524776530579, -0.881037818467492, -1.10816713568432,
-0.55749829201921, -0.372526253742828, -0.353208893775679, 0.531708523456415,
-0.43187124865558, 1.03973431972897, 0.849170115617157, 1.11227803262189,
0.47216440383252, 0.920060697785203, -0.374672861268964, 2.94683565121636,
0.514112041811711, -0.52321362055969, -0.0412387814196237, 0.983863448669766,
0.534230127442599, -0.869960511196742, 1.90586406082412, -1.84705932449576,
0.806425475391075, 1.90939977897903, 0.41030042787483, 0.994503041407507,
0.715719209301158, -0.538096591457249, -0.482411304681239, 0.0323998214753804,
0.551162374882342, -0.618989357027834, 1.08996565055366, -0.697423620816604,
1.38170655971013, 1.55752893685726, -0.0929258405664267, -1.00210610433922,
-1.51879925258188, -1.57050250989563, -1.06868502360026, 0.458860605094578
), effects = c(-0.661274203468574, -1.07255577360914, -1.36123824096605,
-1.71875465303308, -1.8806486154155, 1.38636416232103, -2.29259163100096,
0.153263315278269, -0.950879523052079, -0.963705724647863, -0.62175976245114,
-0.423965256680951, -0.350662885659068, 0.469175412149025, -0.400505083448679,
1.03440116252973, 0.878739280288923, 1.16574672001397, 0.358222935858666,
1.00514946836967, -0.316592303881481, 2.8507611924072, 0.573209391002668,
-0.393720180068215, 0.0971873363200073, 1.23818281311352, 0.449576129222722,
-0.929511151618747, 1.97922180250824, -1.80820009744905, 0.877996855335966,
1.86871623414376, 0.226023354471842, 0.814892815951223, 0.821400980265047,
-0.536299037896556, -0.358703204255386, 0.105714598012197, 0.543301738010905,
-0.643659132172249, 1.26412624281219, -0.808498804261978, 1.32273956796476,
1.57655585529458, 0.022266343917185, -1.20958321975888, -1.52288584310647,
-1.60904879400386, -1.08384090772898, 0.567729611277337), rank = 2L,
    fitted.values = c(-0.0475543078742839, 0.351628437239565,
    -0.117155221544445, 0.165041007767092, 0.247859323684996,
    0.0805663573239046, 0.0448510221995737, 0.250840726246576,
    -0.0333621333428176, 0.293467635417987, -0.0248518201238109,
    -0.00529650906918994, 0.0770350456001708, -0.0222159311803766,
    0.120988140963125, 0.0650186744394092, 0.118247568257686,
    0.154696293986828, -0.100617877288265, 0.202919505525394,
    0.161729772710581, -0.0733692278375946, 0.163280463324874,
    0.270640256833884, 0.284263319806951, 0.461009994308065,
    -0.0559520919143943, -0.0176674192887905, 0.185028727541523,
    0.132415672762266, 0.182304379869478, 0.011106443703975,
    -0.207885424899216, -0.200768100305762, 0.234325514404888,
    0.0758935912226656, 0.261817140331961, 0.184963202179859,
    0.0611640613395693, 0.0355287514706238, 0.338761314434586,
    -0.0962465590881959, -0.0167773073486601, 0.102169781012095,
    0.248829672417071, -0.243267385378769, 0.0669197905143708,
    0.0143659410153998, 0.0500382129484238, 0.239186308642765
    ), assign = 0:1, qr = list(qr = c(-7.07106781186548, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    0.14142135623731, 0.14142135623731, 0.14142135623731, 0.14142135623731,
    1.18871623033411, 6.0328188078105, -0.18012556382541, 0.0829807810893617,
    0.160196640586552, 0.00422063404457838, -0.0290786460517367,
    0.162976358560143, -0.102000873004284, 0.202719661631434,
    -0.0940662616503503, -0.0758338195379766, 0.000928206918060759,
    -0.0916086841440873, 0.0419079829301299, -0.0102752861369684,
    0.0393528032622073, 0.0733358618834786, -0.164706930442335,
    0.118296891160581, 0.0798935429820433, -0.139301585451296,
    0.0813393331707195, 0.181436499351408, 0.194137995449112,
    0.358928189908056, -0.123062676154681, -0.0873678679520487,
    0.101616380529727, 0.0525624701654998, 0.0990763283113914,
    -0.0605404863829379, -0.264718090934247, -0.258082235933901,
    0.147578360387876, -0.000136030863872082, 0.173210245091236,
    0.101555287798443, -0.0138691440925964, -0.0377702879768747,
    0.244949334093302, -0.160631321222164, -0.0865379699066212,
    0.0243626389824618, 0.161101347601284, -0.297706548364757,
    -0.0085027759125684, -0.0575014860888491, -0.0242423560643218,
    0.152110333789614), qraux = c(1.14142135623731, 1.25694602752555
    ), pivot = 1:2, tol = 1e-07, rank = 2L), df.residual = 48L,
    xlevels = list(), call = lm(formula = y ~ x, data = dat),
    terms = y ~ x, model = list(y = c(-0.0628346230725001, -0.534246725420292,
    -1.3536084155945, -1.61396538795233, -1.7473452160677, 1.46206902139567,
    -2.22918347042642, 0.287593203899634, -0.91439995181031,
    -0.81469950026633, -0.582350112143021, -0.377822762812018,
    -0.276173848175508, 0.509492592276038, -0.310883107692455,
    1.10475299416838, 0.967417683874843, 1.26697432660872, 0.371546526544255,
    1.1229802033106, -0.212943088558383, 2.87346642337877, 0.677392505136584,
    -0.252573363725805, 0.243024538387328, 1.44487344297783,
    0.478278035528205, -0.887627930485533, 2.09089278836564,
    -1.71464365173349, 0.988729855260553, 1.920506222683, 0.202415002975614,
    0.793734941101744, 0.950044723706047, -0.462203000234584,
    -0.220594164349278, 0.21736302365524, 0.612326436221911,
    -0.58346060555721, 1.42872696498824, -0.793670179904799,
    1.36492925236147, 1.65969871786935, 0.155903831850644, -1.24537348971799,
    -1.45187946206751, -1.55613656888023, -1.01864681065184,
    0.698046913737343), x = c(0.6253830934028, -1.6199054330602,
    1.01686828360155, -0.570404622454562, -1.03623391189047,
    -0.0952589260568722, 0.105629597194727, -1.05300344676195,
    0.545556179461482, -1.29276759301495, 0.497688106852802,
    0.387695087164958, -0.0753963097646713, 0.482861987051367,
    -0.322619873230144, -0.00780766614911678, -0.307204937272165,
    -0.512218572469498, 0.9238504621374, -0.783460315510917,
    -0.551779874336542, 0.770584619056546, -0.560502064578936,
    -1.16437013132232, -1.24099595586789, -2.23514534034255,
    0.672618221633596, 0.457277911367569, -0.682829817253222,
    -0.38689646421126, -0.667506142457625, 0.295433179273129,
    1.52719967214396, 1.48716676129197, -0.960110113785672, -0.0689759560578443,
    -1.11474262990373, -0.682461255874912, 0.0138734277181953,
    0.158064698071454, -1.54753155529058, 0.899263050180665,
    0.452271286830549, -0.216771992273148, -1.0416918453845,
    1.7262130585714, -0.0185008991679137, 0.277099441142009,
    0.0764531359986249, -0.987450688160168))), list(y = c(-0.0628346230725001,
-0.534246725420292, -1.3536084155945), x = c(0.6253830934028,
-1.6199054330602, 1.01686828360155)))
debug: predict(model, nd)
Browse[2]>


I wish the debug output would look more like R's own lm, Note the
contents of "dat" are not splatted into the middle of the function
call.

> m1 <- lm(y ~ x, dat)
debugging in: lm(y ~ x, dat)
debug: {
    ret.x <- x
    ret.y <- y
    cl <- match.call()
    mf <- match.call(expand.dots = FALSE)
    m <- match(c("formula", "data", "subset",


I've been reading quite a while on this question, testing lots of
ideas. The quote function seems to work, but I worry about how the R
runtime environment finds all the pieces if I pass them through this
way.

mySpecialFeature <- function(model, ci){
    pargs <- list(quote(model), quote(model.frame(model)[1:3, ]))
    res <- do.call(myRegFit, pargs)
    print(res)
}

See, that fixes it:

> mySpecialFeature (m1)
debugging in: (function (model, nd)
predict(model, nd))(model, model.frame(model)[1:3, ])
debug: predict(model, nd)
Browse[2]> c
exiting from: (function (model, nd)
predict(model, nd))(model, model.frame(model)[1:3, ])
          1           2           3
-0.04755431  0.35162844 -0.11715522
>

Are there dangers in this I don't know about?




-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu



From PDalgd at gmail.com  Thu Apr 10 17:36:17 2014
From: PDalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Apr 2014 17:36:17 +0200
Subject: [R] premature evaluation of symbols. Is that the way to
	describe this problem?
In-Reply-To: <CAErODj-vSeWjLYQL1d2eE9PGzu5xk8HNKZmyKp-144rFODf79A@mail.gmail.com>
References: <CAErODj-vSeWjLYQL1d2eE9PGzu5xk8HNKZmyKp-144rFODf79A@mail.gmail.com>
Message-ID: <FFEA2AE4-524C-4264-B179-08AF78BE1D0F@gmail.com>


On 10 Apr 2014, at 16:59 , Paul Johnson <pauljohn32 at gmail.com> wrote:

> I've been reading quite a while on this question, testing lots of
> ideas. The quote function seems to work, but I worry about how the R
> runtime environment finds all the pieces if I pass them through this
> way.
> 
> mySpecialFeature <- function(model, ci){
>    pargs <- list(quote(model), quote(model.frame(model)[1:3, ]))
>    res <- do.call(myRegFit, pargs)
>    print(res)
> }
> 
> See, that fixes it:
> 
>> mySpecialFeature (m1)
> debugging in: (function (model, nd)
> predict(model, nd))(model, model.frame(model)[1:3, ])
> debug: predict(model, nd)
> Browse[2]> c
> exiting from: (function (model, nd)
> predict(model, nd))(model, model.frame(model)[1:3, ])
>          1           2           3
> -0.04755431  0.35162844 -0.11715522
>> 
> 
> Are there dangers in this I don't know about?
> 

I don't think so. A similar issue made the rounds quite recently over on R-devel ("Problem with do.call()") and the quote() trick was mentioned as a fix. 

The only potential issue that I can see is the fairly obvious one that the quoted arguments are evaluated later than unquoted ones, and possibly not at all due to lazy evaluation. This is of course largely the point of the maneuver, but there is also a slight risk that the object could change or disappear due to side effects when evaluating other arguments. This isn't different from the usual perils of lazy evaluation, though.

-pd


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From mbressan at arpa.veneto.it  Thu Apr 10 18:40:34 2014
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 10 Apr 2014 18:40:34 +0200
Subject: [R] print(cenfit object) to a data.frame
Message-ID: <5346C982.20103@arpa.veneto.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/2238d75e/attachment-0001.pl>

From ruipbarradas at sapo.pt  Thu Apr 10 19:00:10 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 10 Apr 2014 18:00:10 +0100
Subject: [R] print(cenfit object) to a data.frame
In-Reply-To: <5346C982.20103@arpa.veneto.it>
References: <5346C982.20103@arpa.veneto.it>
Message-ID: <5346CE1A.8010600@sapo.pt>

Hello,

Perhaps the easiest way is with ?capture.output:

dat <- read.table(text = capture.output(print(mycenfit)), 
stringsAsFactors = FALSE)

  str(dat)
'data.frame':   3 obs. of  5 variables:
  $ n     : int  3 3 3
  $ n.cen : int  1 1 2
  $ median: int  2 2 NA
  $ mean  : num  2.33 2.33 2
  $ sd    : num  0.667 0.667 NaN


Hope this helps,

Rui Barradas

Em 10-04-2014 17:40, Massimo Bressan escreveu:
> given this reproducible example:
>
> #start code
>
> df<-structure(list(lq = c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE,
> FALSE, FALSE), value = c(1, 3, 1, 2, 0.5, 2, 1, 2, 3), group =
> structure(c(1L, 1L, 2L, 2L, 3L, 3L, 3L, 1L, 2L), .Label = c("A", "B",
> "C"), class = "factor")), .Names = c("lq", "value", "group"), row.names
> = c(NA, -9L), class = "data.frame")
>
> library(NADA)
>
> mycenfit<-with(df, cenfit(value,lq,group))
>
> print(mycenfit)
>
> #end code
>
> does anybody knows how to convert the print() of the cenfit object (S4)
> "mycenfit" to a data frame?
>
> sorry, this might be a trivial question but for some reasons I do not
> understand I got completely stuck on this...
> I've seen similar questions pointed out in the mailing list but for a
> "surfit" object which do not seem to properly apply in my specific case
>
> any help much appreciated, thank you
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pertsou at gmail.com  Thu Apr 10 20:21:07 2014
From: pertsou at gmail.com (Endy BlackEndy)
Date: Thu, 10 Apr 2014 21:21:07 +0300
Subject: [R] How I can program comp() routine
Message-ID: <CAGpBJKR5+D5cDW-MO5f7u2P1uSAfqmpq_wcesBey9DWBdxUMDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/b6f8a982/attachment-0001.pl>

From simone.gabbriellini at gmail.com  Thu Apr 10 20:49:51 2014
From: simone.gabbriellini at gmail.com (Simone Gabbriellini)
Date: Thu, 10 Apr 2014 20:49:51 +0200
Subject: [R] how to select an element from a vector based on a probability
Message-ID: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>

Hello List,

I have an array like:

c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)

I would like to pick up an element with a probability proportional to
the element value, thus higher values should be picked up more often
than small values (i.e., picking up 38 should be more probable than
picking up 3)

Do you have any idea on how to code such a rich-get-richer mechanism?

Best regards,
Simone

-- 
-----------------------------------------------------------------

Simone Gabbriellini, PhD

Post-doctoral Researcher
ANR founded research project "DIFFCERAM"
GEMASS, CNRS & Paris-Sorbonne.

mobile: +39 340 39 75 626
email: simone.gabbriellini at cnrs.fr



From ruipbarradas at sapo.pt  Thu Apr 10 20:55:39 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 10 Apr 2014 19:55:39 +0100
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
Message-ID: <5346E92B.9000000@sapo.pt>

Hello,

Use ?sample.

sample(x, 1, prob = x)

Hope this helps,

Rui Barradas

Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
> Hello List,
>
> I have an array like:
>
> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>
> I would like to pick up an element with a probability proportional to
> the element value, thus higher values should be picked up more often
> than small values (i.e., picking up 38 should be more probable than
> picking up 3)
>
> Do you have any idea on how to code such a rich-get-richer mechanism?
>
> Best regards,
> Simone
>



From simone.gabbriellini at gmail.com  Thu Apr 10 20:58:46 2014
From: simone.gabbriellini at gmail.com (Simone Gabbriellini)
Date: Thu, 10 Apr 2014 20:58:46 +0200
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <5346E92B.9000000@sapo.pt>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
	<5346E92B.9000000@sapo.pt>
Message-ID: <CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>

Hello, Rui,

it does, indeed!

thanks,
Simone

2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
> Hello,
>
> Use ?sample.
>
> sample(x, 1, prob = x)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
>
>> Hello List,
>>
>> I have an array like:
>>
>> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
>> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
>> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
>> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
>> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
>> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
>> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
>> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>>
>> I would like to pick up an element with a probability proportional to
>> the element value, thus higher values should be picked up more often
>> than small values (i.e., picking up 38 should be more probable than
>> picking up 3)
>>
>> Do you have any idea on how to code such a rich-get-richer mechanism?
>>
>> Best regards,
>> Simone
>>
>



-- 
-----------------------------------------------------------------

Simone Gabbriellini, PhD

Post-doctoral Researcher
ANR founded research project "DIFFCERAM"
GEMASS, CNRS & Paris-Sorbonne.

mobile: +39 340 39 75 626
email: simone.gabbriellini at cnrs.fr



From alwina.hermann at 1plusi.de  Thu Apr 10 16:49:10 2014
From: alwina.hermann at 1plusi.de (Alwina Hermann)
Date: Thu, 10 Apr 2014 16:49:10 +0200
Subject: [R] Binom.test - hudge difference in p-value for little differences
	in PD forecast
Message-ID: <000b01cf54cc$0b9ffe50$22dffaf0$@1plusi.de>

Dear R team,
?
I'm not sure if I use the right distribution list, but I hope in case if
not, you will forward it to the reference person.
?
Following problem occured:
I used R to calculate the p-value for the two sided binomial test (exact -
Pearson).
For a very little difference for my forecast I get a very big difference in
my p-value
?
?>? binom.test(1,101, 0.02402)

??????? Exact binomial test

data:? 1 and 101
number of successes = 1, number of trials = 101, p-value = 0.7375
alternative hypothesis: true probability of success is not equal to 0.02402
95 percent confidence interval:
0.00025064 0.05393235
sample estimates:
probability of success 
????????????0.00990099

> binom.test(1,101, 0.02403)

??????? Exact binomial test

data:? 1 and 101
number of successes = 1, number of trials = 101, p-value = 0.5243
alternative hypothesis: true probability of success is not equal to 0.02403
95 percent confidence interval:
0.00025064 0.05393235
sample estimates:
probability of success 
????????????0.00990099


Can you please explain where this huge difference come from?
Which mathematical explanation is given for this topic?

Please help.

I hope for your soon feedback.

Kind Regards,
Alwina
?



From jlrenteriab at gmail.com  Thu Apr 10 18:27:15 2014
From: jlrenteriab at gmail.com (Jorge Luis Renteria)
Date: Thu, 10 Apr 2014 09:27:15 -0700 (PDT)
Subject: [R] Modeling presence only data in R
In-Reply-To: <480F428F.3080504@rjb.csic.es>
References: <mailman.19.1208944804.17847.r-help@r-project.org>
	<480F428F.3080504@rjb.csic.es>
Message-ID: <7e68d528-6a57-4c4d-99b0-4a4cd4e43544@googlegroups.com>



Dear Friends

I am running some SDM to assess the potential distribution of some plant 
species. We want to run 3 models using presence data only (BIOBLIM, DOMIAN, 
MAHAL). I am using the Dismo library for R.

We would like to evaluate the three models using the AUC the Kappa COR 
(Pearson correlation). When I run the evaluate function ?e<-evaluate (p,a, 
model,predictors)?from the Dismo package I get only the AUC>

Can someone advice or provide the scripts/ package to get the Kappa and COR 
of the models?

Thank you very much for your help

Cheers

jorge

On Wednesday, 23 April 2008 16:07:11 UTC+2, Alejandro Gonz?lez wrote:
>
> Dear Milton, you have 2 packages for modelling species distribution in 
> R: grasper and Biomod (by Wilfried Thuiller), but they are all 
> presence-absence models, so you must generate pseudoabsences for each 
> species, following recommendations in papers (see Lobo 2007). On the 
> other side, there are free gis tools to perform presence-only models 
> (Biomapper, GARP, Openmodeller). Write me if you need if you want some 
> advice.
>
>
> -- 
> Alejandro Gonz?lez Fern?ndez de Castro
>
> Departamento de Biodiversidad y Conservaci?n
> Real Jard?n Bot?nico (Consejo Superior de Investigaciones Cient?ficas)
>
> Plaza de Murillo, 2
> 28014 Madrid - Spain
> 00 34 91 4203017
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From patzelt at g.harvard.edu  Thu Apr 10 16:48:36 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Thu, 10 Apr 2014 10:48:36 -0400
Subject: [R] Plotting Simple Slopes with Multilevel Categorical Moderator
Message-ID: <CAB9UfhQQf3rtJe=N-sTh-o0D=i4n++stvBGWcL2quYa4gaWczA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/aeb1fe74/attachment-0001.pl>

From Vijayakumar_C02 at infosys.com  Thu Apr 10 14:59:14 2014
From: Vijayakumar_C02 at infosys.com (Vijayakumar Chinnamuthu)
Date: Thu, 10 Apr 2014 12:59:14 +0000
Subject: [R] Regarding the DLL creation in R
Message-ID: <A412559CCAF16D4AA192568EF14657B257B26F6F@BLRKECMBX21.ad.infosys.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/50afac0e/attachment-0001.pl>

From violette.bertrand at yahoo.fr  Thu Apr 10 16:05:09 2014
From: violette.bertrand at yahoo.fr (Violette Bertrand)
Date: Thu, 10 Apr 2014 15:05:09 +0100 (BST)
Subject: [R] Elliptic Fourier Analysis and PCA
Message-ID: <1397138709.19829.YahooMailNeo@web28902.mail.ir2.yahoo.com>

Hi, 

I use packages "momocs" and "ade4" to dertermine morphometry of 
woodpeckers'
cavities entrances. 
I have few questions about the PCA 
(non-normalized) (see image enclosed) :

? 1) *What do show the confidence 
ellipses ?*? Some papers say that ellipses
include 95 % of the data, but it 
seems to be less here... Moreover, I can choose the size of the ellipses with "cellipse" (ex : cellipse=1), but what does it means ?

? 2) What does mean "d=50" (in the top-right corner) ?

? 3) What 
do mean each axis of the PCA ? Wikipedia say "Each axis on a PCA
plot is an 
eigenvector of the covariance matrix of shape variables." But
it's not really 
clear for me... What is the axis units ?



Thanks for your help :-)

VB

From waddeessa at gmail.com  Thu Apr 10 14:58:56 2014
From: waddeessa at gmail.com (Kumsa)
Date: Thu, 10 Apr 2014 14:58:56 +0200
Subject: [R] Plotting a 3D surface from three variables
Message-ID: <CALekQEu-E-pdTbiOCCzA+sZU_R48aiuguccMtJ6eTOQ62j5ZfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/6c6fa829/attachment-0001.pl>

From fisher at plessthan.com  Thu Apr 10 21:48:08 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Thu, 10 Apr 2014 12:48:08 -0700
Subject: [R] Determining 32- vs. 64-bit Windows
Message-ID: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/d0b0abfa/attachment-0001.pl>

From rmh at temple.edu  Thu Apr 10 21:51:07 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 10 Apr 2014 15:51:07 -0400
Subject: [R] Plotting Simple Slopes with Multilevel Categorical Moderator
In-Reply-To: <CAB9UfhQQf3rtJe=N-sTh-o0D=i4n++stvBGWcL2quYa4gaWczA@mail.gmail.com>
References: <CAB9UfhQQf3rtJe=N-sTh-o0D=i4n++stvBGWcL2quYa4gaWczA@mail.gmail.com>
Message-ID: <CAGx1TMCu1AOE3+F+F7zG-X4ortRi68qLvZyBQuZFmL3mEAbmUA@mail.gmail.com>

I think you are looking for analysis of covariance.
Try the ancova function in the HH package.

install.packages("HH")
library(HH)
?ancova
demo("ancova")

On Thu, Apr 10, 2014 at 10:48 AM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> R -
>
> I've got a DV with 2 IVs one of which has 5 levels. I tried using the
> "pequod" package; however found that it is not able to graph/simple slope a
> moderator with multiple levels. Is there a package available to do this?
> (data below)
>
> dat$gpa <- as.factor(dat$gpa)
>
> mod1 <- lmres(item25 ~ psd * gpa, centered = c("psd", "gpa"), data = dat)
>
> sSlopes <- simpleSlope(mod1, pred = "psd", mod1 = "gpa")
>
> PlotSlope(sSlopes, namey = "Affirmative Action", namex = "Political
> Conservatism")
>
> structure(list(item25 = c(3L, 2L, 2L, 4L, 2L, 1L, 2L, 3L, 3L,
>
> 2L, 5L, 2L, 2L, 0L, 2L, 5L, 5L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 4L, 3L, 3L, 2L, 2L, 3L, 3L, 2L, 2L, 4L, 1L, 2L, 0L,
>
> 1L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 2L,
>
> 2L, 1L, 3L, 2L, 3L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 2L, 1L, 5L, 2L,
>
> 3L, 2L, 0L, 5L, 1L, 1L, 3L, 3L, 1L, 1L, 2L, 0L, 2L, 4L, 5L, 2L,
>
> 1L, 4L, 4L, 1L, 3L, 2L, 2L, 3L, 2L, 4L, 3L, 3L, 3L, 1L, 3L, 1L,
>
> 3L, 2L, 3L, 2L, 3L, 3L, 2L, 1L, 5L, 3L, 2L, 2L, 3L, 1L, 2L, 3L,
>
> 3L, 1L, 2L, 3L, 1L, 1L, 3L, 2L, 1L, 3L, 0L, 2L, 2L, 1L, 3L, 2L,
>
> 3L, 2L, 3L, 3L, 1L, 3L, 1L, 2L, 3L, 3L, 3L, 2L, 3L, 3L, 2L, 3L,
>
> 3L, 3L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 1L, 4L, 1L, 1L, 2L, 1L, 4L,
>
> 3L, 1L, 2L, 4L, 3L, 1L, 1L, 2L, 3L, 1L, 1L, 2L, 1L, 3L, 2L, 2L,
>
> 1L, 4L, 1L, 2L, 3L, 3L, 3L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 2L,
>
> 3L, 3L, 2L, 2L, 2L, 3L, 1L, 2L, 1L, 2L, 2L, 3L, 2L, 4L, 2L, 3L,
>
> 2L, 3L, 4L, 3L, 2L, 2L, 1L, 3L, 2L, 3L, 2L, 3L, 4L, 1L, 4L, 3L,
>
> 1L, 1L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 3L, 1L, 2L, 2L, 4L, 1L,
>
> 3L, 3L, 1L, 3L, 2L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 3L, 2L, 2L, 3L,
>
> 2L, 1L, 2L, 2L, 3L, 1L, 2L, 1L, 0L, 2L, 2L, 3L, 3L, 3L, 1L, 4L,
>
> 2L, 2L, 3L, 1L, 3L, 2L, 2L, 3L, 2L, 2L, 3L, 3L, 1L, 1L, 1L, 2L,
>
> 0L, 1L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 3L, 1L,
>
> 2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 5L, 3L, 2L, 1L,
>
> 0L, 1L, 3L, 2L, 2L, 2L, 3L, 2L, 3L, 4L, 2L, 4L, 2L, 3L, 2L, 1L,
>
> 2L, 3L, 1L, 2L, 2L, 2L, 3L, 3L, 2L, 5L, 4L, 4L, 3L, 2L, 3L, 3L,
>
> 1L, 1L, 1L, 1L, 3L, 2L, 1L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 4L, 0L,
>
> 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 1L, 3L, 1L, 2L, 1L, 3L, 3L, 3L,
>
> 2L, 2L, 5L, 3L, 4L, 3L, 3L, 1L, 2L, 1L, 2L, 2L, 3L, 2L, 1L, 2L,
>
> 2L, 2L, 2L, 3L, 2L, 1L, 2L, 1L, 2L, 2L, 4L, 3L, 2L, 4L, 3L, 1L,
>
> 1L, 3L, 2L, 1L, 2L, 4L, 2L, 2L, 5L, 3L, 2L, 4L, 5L, 2L, 3L, 4L,
>
> 1L, 1L, 1L, 3L, 3L, 2L, 3L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 3L, 4L, 3L, 3L, 2L, 2L, 3L, 2L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 4L,
>
> 1L, 1L, 3L, 5L, 0L, 0L, 2L, 2L, 4L, 2L, 2L, 1L, 3L, 2L, 1L, 2L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 4L, 1L, 3L, 4L, 4L, 3L, 4L, 1L, 1L, 2L,
>
> 3L, 3L, 5L, 2L, 1L, 2L, 2L, 3L, 3L, 1L, 2L, 2L, 1L, 3L, 4L, 3L,
>
> 1L, 4L, 3L, 2L, 3L, 2L, 5L, 4L, 2L, 4L, 3L, 3L, 2L, 1L, 3L, 2L,
>
> 2L, 3L, 1L, 1L, 2L, 1L, 2L, 3L, 4L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>
> 3L, 2L, 1L, 3L, 5L, 2L, 3L, 5L, 2L, 4L, 2L, 2L, 4L, 2L, 2L, 2L,
>
> 3L, 3L, 3L, 3L, 2L, 5L, 2L, 3L, 2L, 0L, 1L, 0L, 2L, 3L, 4L, 2L,
>
> 2L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 3L, 2L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 1L, 3L, 3L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 2L, 3L, 5L, 3L, 1L,
>
> 2L, 2L, 3L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 1L, 3L, 2L,
>
> 3L, 1L, 3L, 2L, 4L, 2L, 3L, 2L, 3L, 1L, 1L, 2L, 2L, 2L, 0L, 3L,
>
> 3L, 1L, 1L, 2L, 1L, 4L, 2L, 2L, 1L, 4L, 5L, 5L, 1L, 3L, 3L, 1L,
>
> 2L, 4L, 2L, 4L, 3L, 4L, 2L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 2L, 3L,
>
> 2L, 1L, 2L, 2L, 2L, 2L, 3L, 1L, 2L, 4L, 3L, 4L, 3L, 2L, 3L, 3L,
>
> 3L, 3L, 3L, 2L, 2L, 3L, 4L, 4L, 2L, 2L, 2L, 5L, 3L, 3L, 5L, 2L,
>
> 3L, 2L, 1L, 1L, 4L, 2L, 2L, 2L, 1L, 4L, 0L, 2L, 3L, 1L, 3L, 3L,
>
> 2L, 3L, 2L, 3L, 1L, 2L, 1L, 4L, 2L, 2L, 4L, 3L, 3L, 2L, 3L, 3L,
>
> 2L, 4L, 3L, 2L, 2L, 3L, 1L, 2L, 2L, 2L, 2L, 4L, 4L, 3L, 2L, 3L,
>
> 5L, 3L, 1L, 2L, 2L, 3L, 3L, 1L, 2L, 3L, 3L, 3L, 1L, 1L, 1L, 2L,
>
> 2L, 3L, 1L, 1L, 3L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 3L, 3L,
>
> 1L, 3L, 2L, 1L, 1L, 2L, 3L, 2L, 2L, 1L, 4L, 2L, 3L, 2L, 2L, 0L,
>
> 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 3L, 4L, 2L, 2L, 1L, 3L,
>
> 3L, 4L, 3L, 3L, 2L, 2L, 2L, 1L, 1L, 5L, 3L, 4L, 2L, 2L, 2L, 2L,
>
> 3L, 3L, 2L, 3L, 3L, 3L, 4L, 2L, 3L, 2L, 3L, 1L, 3L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 1L, 1L, 5L, 2L, 2L, 3L, 1L, 3L, 3L, 1L, 2L, 1L, 4L,
>
> 2L, 2L, 2L, 3L, 4L, 2L, 0L, 2L, 3L, 2L, 3L, 3L, 3L, 3L, 2L, 2L,
>
> 3L, 2L, 1L, 3L, 3L, 2L, 3L, 2L, 3L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>
> 2L, 3L, 3L, 2L, 2L, 3L, 1L, 3L, 4L, 3L, 2L, 2L, 2L, 1L, 4L, 2L,
>
> 3L, 3L, 2L, 2L, 4L, 3L, 4L, 2L, 2L, 1L, 3L, 2L, 2L, 0L, 2L, 2L,
>
> 4L, 1L, 3L, 1L, 2L, 2L, 1L, 2L, 3L, 2L, 1L, 1L, 2L, 2L, 2L, 1L,
>
> 3L, 1L, 2L, 2L, 2L, 2L, 5L, 0L, 3L, 5L, 2L, 2L, 0L, 2L, 4L, 2L,
>
> 0L, 1L, 2L, 2L, 1L, 2L, 3L, 3L, 2L, 4L, 2L, 2L, 3L, 2L, 3L, 4L,
>
> 3L, 2L, 2L, 3L, 4L, 2L, 1L, 3L, 3L, 2L, 2L, 3L, 5L, 1L, 2L, 2L,
>
> 2L, 1L, 1L, 2L, 3L, 3L, 2L, 2L, 2L, 3L, 1L, 2L, 1L, 2L, 1L, 5L,
>
> 3L, 5L, 2L, 1L, 2L, 1L, 1L, 0L, 0L, 2L, 1L, 2L, 2L, 2L, 1L, 3L,
>
> 1L, 1L, 2L, 1L, 2L, 1L, 2L, 3L, 2L, 3L, 1L, 1L, 1L, 1L, 3L, 2L,
>
> 2L, 2L, 4L, 2L, 3L, 1L, 2L, 2L, 1L, 1L, 4L, 2L, 3L, 2L, 2L, 2L,
>
> 1L, 1L, 1L, 2L, 1L, 5L, 4L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 1L, 1L,
>
> 3L, 2L, 2L, 3L, 1L, 2L, 3L, 4L, 2L, 1L, 5L, 3L, 4L, 1L, 2L, 3L,
>
> 3L, 2L, 4L, 1L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 4L, 1L, 4L, 2L,
>
> 3L, 1L, 1L, 2L, 1L, 3L, 3L, 2L, 1L, 2L, 1L, 2L, 3L, 2L, 3L, 2L,
>
> 2L, 1L, 2L, 2L, 1L, 0L, 3L, 1L, 4L, 2L, 2L, 1L, 2L, 2L, 3L, 2L,
>
> 2L, 4L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>
> 2L, 1L, 2L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 3L, 2L, 0L, 3L, 3L, 2L,
>
> 3L, 2L, 3L, 3L, 1L, 3L, 3L, 3L, 4L, 2L, 2L, 1L, 2L, 4L, 4L, 1L,
>
> 4L, 3L, 2L, 1L, 1L, 2L, 2L, 3L, 5L, 2L, 2L, 1L, 1L, 1L, 2L, 3L,
>
> 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 0L, 2L, 2L, 1L, 3L, 3L, 3L, 2L,
>
> 3L, 2L, 2L, 2L, 3L, 3L, 2L, 3L, 2L, 2L, 1L, 3L, 3L, 2L, 0L, 1L,
>
> 1L, 2L, 0L, 1L, 2L, 2L, 1L, 3L, 2L, 3L, 3L, 1L, 3L, 2L, 2L, 2L,
>
> 1L, 3L, 2L, 3L, 3L, 3L, 5L, 2L, 3L, 4L, 4L, 2L, 4L, 2L, 2L, 5L,
>
> 1L, 4L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 1L, 2L, 2L, 1L, 1L,
>
> 5L, 1L, 1L, 3L, 2L, 2L, 1L, 1L, 4L, 2L, 3L, 3L, 4L, 1L, 1L, 2L,
>
> 5L, 1L, 2L, 2L, 2L, 2L, 3L, 1L, 3L, 1L, 2L, 5L, 3L, 3L, 2L, 2L,
>
> 3L, 1L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 3L,
>
> 3L, 3L, 1L, 1L, 3L, 3L, 1L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 1L, 2L,
>
> 1L, 3L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 3L, 1L, 3L, 1L,
>
> 1L, 3L, 3L, 0L, 2L, 2L, 2L, 3L, 1L, 3L, 1L, 1L, 1L, 2L, 1L, 1L,
>
> 4L, 2L, 2L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 2L, 3L, 1L, 1L, 1L, 3L,
>
> 2L, 1L, 1L, 1L, 3L, 3L, 4L, 3L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 5L,
>
> 3L, 0L, 3L, 2L, 2L, 3L, 2L, 1L, 1L, 1L, 3L), psd = c(4L, 2L,
>
> 4L, 2L, 2L, 3L, 5L, 4L, 3L, 3L, 5L, 4L, 5L, 4L, 2L, 4L, 4L, 2L,
>
> 3L, 3L, 3L, 1L, 3L, 4L, 3L, 4L, 3L, 0L, 4L, 4L, 4L, 4L, 4L, 1L,
>
> 3L, 4L, 4L, 3L, 2L, 2L, 2L, 4L, 2L, 3L, 4L, 0L, 2L, 3L, 5L, 4L,
>
> 4L, 3L, 4L, 4L, 2L, 4L, 4L, 3L, 2L, 4L, 4L, 3L, 3L, 5L, 2L, 3L,
>
> 4L, 3L, 4L, 3L, 3L, 1L, 2L, 2L, 2L, 0L, 3L, 1L, 2L, 3L, 3L, 3L,
>
> 0L, 2L, 4L, 3L, 3L, 1L, 3L, 4L, 4L, 4L, 3L, 3L, 4L, 4L, 4L, 1L,
>
> 4L, 3L, 2L, 3L, 1L, 5L, 1L, 4L, 4L, 3L, 2L, 4L, 3L, 3L, 3L, 2L,
>
> 4L, 2L, 4L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 2L, 3L,
>
> 3L, 3L, 2L, 3L, 3L, 4L, 4L, 3L, 2L, 3L, 3L, 2L, 3L, 2L, 4L, 4L,
>
> 0L, 3L, 4L, 3L, 2L, 3L, 2L, 3L, 4L, 3L, 3L, 4L, 2L, 3L, 3L, 1L,
>
> 0L, 4L, 4L, 2L, 3L, 4L, 4L, 4L, 2L, 3L, 3L, 3L, 2L, 1L, 3L, 4L,
>
> 4L, 4L, 4L, 4L, 2L, 3L, 2L, 4L, 4L, 2L, 3L, 3L, 4L, 3L, 3L, 2L,
>
> 3L, 3L, 3L, 0L, 2L, 4L, 2L, 4L, 4L, 4L, 3L, 4L, 3L, 3L, 4L, 2L,
>
> 4L, 3L, 4L, 0L, 4L, 4L, 4L, 4L, 3L, 4L, 4L, 4L, 4L, 4L, 3L, 4L,
>
> 5L, 4L, 3L, 4L, 3L, 2L, 3L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>
> 4L, 4L, 3L, 4L, 3L, 4L, 4L, 4L, 3L, 3L, 2L, 3L, 4L, 3L, 1L, 4L,
>
> 3L, 1L, 4L, 3L, 0L, 1L, 5L, 3L, 1L, 3L, 4L, 4L, 5L, 4L, 2L, 2L,
>
> 2L, 3L, 3L, 4L, 5L, 4L, 3L, 3L, 4L, 3L, 5L, 4L, 3L, 2L, 4L, 1L,
>
> 4L, 3L, 2L, 3L, 3L, 3L, 0L, 4L, 1L, 3L, 3L, 3L, 4L, 4L, 2L, 4L,
>
> 3L, 4L, 4L, 4L, 2L, 2L, 2L, 3L, 3L, 2L, 3L, 2L, 4L, 3L, 5L, 2L,
>
> 4L, 4L, 2L, 5L, 2L, 3L, 4L, 2L, 4L, 3L, 5L, 4L, 2L, 3L, 3L, 3L,
>
> 3L, 3L, 3L, 2L, 2L, 4L, 4L, 1L, 5L, 3L, 4L, 4L, 1L, 4L, 3L, 3L,
>
> 4L, 4L, 2L, 3L, 2L, 0L, 4L, 2L, 1L, 3L, 4L, 4L, 3L, 3L, 3L, 2L,
>
> 4L, 4L, 5L, 3L, 2L, 4L, 4L, 3L, 4L, 3L, 3L, 0L, 2L, 3L, 2L, 0L,
>
> 4L, 3L, 3L, 2L, 3L, 2L, 3L, 4L, 2L, 5L, 4L, 3L, 4L, 3L, 1L, 3L,
>
> 4L, 5L, 3L, 4L, 3L, 4L, 2L, 3L, 2L, 4L, 3L, 0L, 3L, 4L, 4L, 1L,
>
> 2L, 3L, 3L, 3L, 3L, 4L, 3L, 2L, 2L, 3L, 4L, 2L, 3L, 2L, 4L, 2L,
>
> 4L, 1L, 4L, 5L, 3L, 4L, 3L, 0L, 3L, 4L, 3L, 2L, 4L, 3L, 3L, 1L,
>
> 4L, 2L, 2L, 4L, 3L, 2L, 3L, 4L, 5L, 2L, 4L, 2L, 2L, 2L, 2L, 3L,
>
> 3L, 3L, 3L, 3L, 3L, 3L, 1L, 2L, 4L, 3L, 4L, 2L, 4L, 2L, 3L, 4L,
>
> 2L, 3L, 2L, 3L, 4L, 3L, 2L, 1L, 2L, 3L, 4L, 3L, 2L, 4L, 1L, 1L,
>
> 4L, 4L, 2L, 3L, 2L, 3L, 2L, 2L, 4L, 2L, 4L, 3L, 2L, 4L, 3L, 4L,
>
> 4L, 2L, 3L, 2L, 4L, 2L, 1L, 3L, 1L, 2L, 2L, 4L, 3L, 2L, 4L, 2L,
>
> 3L, 4L, 3L, 3L, 5L, 4L, 2L, 4L, 1L, 3L, 2L, 3L, 2L, 2L, 2L, 3L,
>
> 4L, 2L, 0L, 2L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 4L, 3L, 3L, 3L, 1L,
>
> 4L, 3L, 1L, 3L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 3L, 4L, 4L, 3L,
>
> 1L, 3L, 4L, 2L, 3L, 4L, 5L, 4L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>
> 2L, 3L, 3L, 2L, 3L, 3L, 1L, 2L, 3L, 3L, 3L, 2L, 4L, 0L, 3L, 3L,
>
> 2L, 5L, 3L, 4L, 5L, 4L, 1L, 2L, 3L, 4L, 2L, 2L, 5L, 3L, 4L, 3L,
>
> 2L, 4L, 3L, 3L, 3L, 4L, 3L, 4L, 1L, 2L, 4L, 3L, 3L, 3L, 3L, 4L,
>
> 2L, 2L, 3L, 4L, 1L, 3L, 5L, 3L, 2L, 3L, 2L, 4L, 4L, 3L, 3L, 3L,
>
> 4L, 1L, 4L, 2L, 3L, 4L, 4L, 2L, 4L, 3L, 4L, 2L, 4L, 3L, 3L, 3L,
>
> 2L, 3L, 3L, 3L, 3L, 2L, 3L, 4L, 2L, 2L, 2L, 4L, 3L, 2L, 2L, 2L,
>
> 5L, 4L, 4L, 4L, 5L, 3L, 4L, 2L, 4L, 3L, 0L, 4L, 4L, 5L, 4L, 4L,
>
> 4L, 4L, 5L, 2L, 4L, 3L, 2L, 4L, 3L, 2L, 1L, 4L, 0L, 4L, 3L, 5L,
>
> 4L, 4L, 1L, 3L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>
> 2L, 3L, 3L, 3L, 4L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 2L,
>
> 4L, 1L, 1L, 1L, 2L, 3L, 0L, 4L, 5L, 1L, 3L, 3L, 2L, 3L, 2L, 2L,
>
> 4L, 2L, 2L, 4L, 2L, 1L, 3L, 3L, 2L, 3L, 1L, 3L, 2L, 0L, 3L, 1L,
>
> 2L, 2L, 3L, 2L, 3L, 2L, 3L, 1L, 4L, 3L, 1L, 1L, 2L, 5L, 1L, 3L,
>
> 3L, 3L, 2L, 1L, 2L, 0L, 4L, 5L, 2L, 3L, 2L, 3L, 4L, 1L, 4L, 3L,
>
> 2L, 4L, 0L, 1L, 4L, 2L, 4L, 4L, 3L, 3L, 4L, 1L, 3L, 3L, 2L, 2L,
>
> 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L, 3L, 4L, 3L, 5L, 2L, 2L, 2L, 3L,
>
> 2L, 3L, 4L, 3L, 3L, 4L, 3L, 4L, 3L, 3L, 1L, 3L, 4L, 4L, 1L, 3L,
>
> 2L, 2L, 4L, 4L, 4L, 0L, 4L, 2L, 2L, 3L, 3L, 4L, 3L, 5L, 2L, 3L,
>
> 2L, 4L, 2L, 4L, 4L, 1L, 4L, 4L, 0L, 4L, 3L, 4L, 3L, 4L, 2L, 3L,
>
> 4L, 3L, 3L, 3L, 5L, 3L, 0L, 2L, 4L, 2L, 3L, 4L, 2L, 4L, 3L, 3L,
>
> 3L, 3L, 3L, 2L, 3L, 4L, 3L, 4L, 4L, 3L, 4L, 4L, 4L, 4L, 5L, 2L,
>
> 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 2L, 3L, 4L, 4L, 3L, 3L, 3L, 4L,
>
> 2L, 3L, 0L, 3L, 4L, 4L, 1L, 2L, 1L, 2L, 2L, 2L, 3L, 5L, 3L, 4L,
>
> 1L, 0L, 4L, 3L, 3L, 4L, 3L, 3L, 2L, 3L, 3L, 2L, 1L, 2L, 2L, 3L,
>
> 4L, 3L, 4L, 4L, 3L, 3L, 4L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 3L, 4L,
>
> 2L, 3L, 3L, 5L, 3L, 2L, 4L, 3L, 4L, 1L, 2L, 3L, 2L, 2L, 4L, 4L,
>
> 3L, 4L, 4L, 3L, 3L, 4L, 4L, 2L, 4L, 3L, 4L, 3L, 4L, 3L, 4L, 3L,
>
> 4L, 1L, 2L, 3L, 4L, 2L, 3L, 3L, 3L, 3L, 1L, 4L, 5L, 4L, 2L, 3L,
>
> 3L, 2L, 2L, 1L, 2L, 4L, 3L, 4L, 4L, 4L, 3L, 2L, 1L, 1L, 2L, 2L,
>
> 2L, 3L, 1L, 2L, 4L, 4L, 4L, 4L, 1L, 2L, 2L, 2L, 4L, 0L, 3L, 3L,
>
> 4L, 4L, 2L, 3L, 0L, 3L, 3L, 2L, 4L, 2L, 2L, 4L, 3L, 2L, 3L, 3L,
>
> 1L, 4L, 3L, 2L, 4L, 2L, 4L, 3L, 3L, 4L, 3L, 4L, 3L, 4L, 5L, 3L,
>
> 4L, 0L, 3L, 4L, 2L, 3L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 2L, 1L, 1L,
>
> 2L, 3L, 4L, 4L, 2L, 3L, 3L, 4L, 2L, 4L, 1L, 2L, 4L, 2L, 2L, 3L,
>
> 4L, 3L, 1L, 2L, 2L, 3L, 4L, 3L, 4L, 4L, 4L, 2L, 3L, 4L, 2L, 2L,
>
> 3L, 3L, 3L, 4L, 3L, 1L, 0L, 3L, 2L, 2L, 3L, 3L, 4L, 3L, 4L, 1L,
>
> 2L, 4L, 0L, 3L, 3L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 0L, 4L, 2L, 3L,
>
> 2L, 4L, 2L, 4L, 3L, 3L, 1L, 4L, 2L, 3L, 2L, 3L, 2L, 4L, 2L, 4L,
>
> 4L, 2L, 1L, 2L, 2L, 4L, 3L, 2L, 3L, 3L, 2L, 3L, 4L, 4L, 3L, 2L,
>
> 3L, 3L, 2L, 4L, 3L, 3L, 2L, 3L, 4L, 4L, 2L, 3L, 3L, 3L, 4L, 2L,
>
> 2L, 1L, 4L, 2L, 3L, 2L, 2L, 3L, 2L, 0L, 3L, 2L, 2L, 2L, 2L, 3L,
>
> 4L, 4L, 2L, 3L, 3L, 2L, 3L, 2L, 4L, 3L, 4L, 1L, 4L, 2L, 1L, 1L,
>
> 2L, 4L, 4L, 3L, 2L, 3L, 4L, 2L, 2L, 2L, 3L, 4L, 2L, 2L, 1L, 2L,
>
> 1L, 4L, 2L, 2L, 4L, 4L, 3L, 5L, 2L, 4L, 4L, 2L, 2L, 3L, 3L, 3L,
>
> 4L, 3L, 1L, 4L, 2L, 2L, 4L, 1L, 1L, 4L, 0L, 2L, 2L, 1L, 2L, 0L,
>
> 1L, 2L, 4L, 2L, 3L, 2L, 3L, 5L, 4L, 4L, 2L, 3L, 2L, 1L, 2L, 4L,
>
> 1L, 4L, 3L, 1L, 2L, 5L, 4L, 0L, 4L, 2L, 3L, 1L, 4L, 0L, 3L, 2L,
>
> 4L, 2L, 2L, 3L, 4L, 4L, 2L, 0L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L,
>
> 4L, 3L, 3L, 3L, 3L, 4L, 4L, 0L, 3L, 2L, 2L, 2L, 2L, 4L, 2L, 2L,
>
> 4L, 3L, 1L, 2L, 1L, 2L, 1L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 3L, 5L,
>
> 3L, 3L, 4L, 3L, 4L, 1L, 3L, 3L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 4L,
>
> 2L, 3L, 3L, 3L, 3L, 4L, 5L, 3L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 2L,
>
> 1L, 3L), gpa = structure(c(4L, 4L, 3L, 3L, 3L, 3L, 5L, 3L, 5L,
>
> 3L, 5L, 1L, 3L, 2L, 5L, 3L, 3L, 2L, 5L, 1L, 2L, 2L, 1L, 3L, 3L,
>
> 2L, 2L, 2L, 2L, 5L, 1L, 5L, 3L, 3L, 2L, 3L, 2L, 5L, 4L, 2L, 2L,
>
> 5L, 5L, 3L, 5L, 3L, 2L, 3L, 5L, 3L, 3L, 2L, 2L, 2L, 5L, 2L, 5L,
>
> 2L, 3L, 4L, 3L, 3L, 2L, 3L, 3L, 4L, 3L, 4L, 3L, 2L, 4L, 1L, 4L,
>
> 3L, 3L, 5L, 5L, 5L, 5L, 3L, 5L, 3L, 4L, 5L, 3L, 3L, 4L, 2L, 2L,
>
> 4L, 5L, 3L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 3L, 4L, 4L, 5L, 4L, 2L,
>
> 4L, 4L, 2L, 4L, 4L, 3L, 2L, 4L, 5L, 4L, 4L, 3L, 3L, 2L, 3L, 1L,
>
> 2L, 2L, 4L, 3L, 1L, 3L, 2L, 4L, 4L, 4L, 3L, 4L, 3L, 5L, 3L, 2L,
>
> 4L, 2L, 4L, 4L, 5L, 5L, 5L, 3L, 2L, 3L, 3L, 4L, 3L, 5L, 3L, 3L,
>
> 3L, 3L, 2L, 5L, 3L, 4L, 4L, 1L, 1L, 4L, 3L, 4L, 5L, 5L, 3L, 2L,
>
> 3L, 5L, 2L, 4L, 3L, 3L, 4L, 4L, 2L, 3L, 2L, 4L, 5L, 4L, 3L, 4L,
>
> 2L, 5L, 2L, 2L, 2L, 4L, 5L, 4L, 1L, 4L, 2L, 4L, 5L, 4L, 3L, 3L,
>
> 3L, 4L, 4L, 4L, 3L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 4L, 3L,
>
> 3L, 2L, 4L, 4L, 4L, 5L, 5L, 4L, 3L, 4L, 3L, 2L, 2L, 2L, 3L, 2L,
>
> 3L, 2L, 2L, 1L, 5L, 5L, 4L, 2L, 3L, 3L, 3L, 2L, 2L, 4L, 2L, 1L,
>
> 3L, 3L, 3L, 3L, 3L, 2L, 4L, 3L, 2L, 4L, 5L, 5L, 4L, 5L, 5L, 5L,
>
> 4L, 1L, 2L, 5L, 4L, 4L, 3L, 4L, 5L, 4L, 5L, 1L, 2L, 3L, 4L, 5L,
>
> 4L, 1L, 4L, 2L, 2L, 3L, 4L, 2L, 3L, 2L, 4L, 4L, 5L, 2L, 2L, 4L,
>
> 3L, 2L, 5L, 4L, 5L, 3L, 3L, 1L, 5L, 3L, 2L, 5L, 3L, 3L, 4L, 4L,
>
> 4L, 2L, 4L, 5L, 4L, 5L, 4L, 4L, 4L, 3L, 3L, 4L, 4L, 3L, 4L, 5L,
>
> 3L, 2L, 3L, 5L, 4L, 5L, 4L, 2L, 4L, 4L, 2L, 4L, 5L, 4L, 3L, 3L,
>
> 3L, 4L, 3L, 5L, 4L, 4L, 3L, 3L, 5L, 2L, 2L, 4L, 1L, 4L, 1L, 4L,
>
> 3L, 4L, 3L, 4L, 2L, 4L, 2L, 2L, 5L, 1L, 2L, 1L, 4L, 1L, 3L, 5L,
>
> 2L, 5L, 3L, 3L, 2L, 4L, 4L, 4L, 4L, 5L, 4L, 1L, 5L, 5L, 3L, 3L,
>
> 3L, 4L, 4L, 2L, 5L, 3L, 2L, 3L, 4L, 2L, 2L, 5L, 4L, 3L, 3L, 4L,
>
> 2L, 2L, 3L, 3L, 4L, 3L, 3L, 4L, 3L, 5L, 2L, 2L, 3L, 5L, 4L, 4L,
>
> 4L, 3L, 4L, 3L, 2L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 2L, 4L, 4L, 4L,
>
> 4L, 4L, 2L, 2L, 5L, 3L, 3L, 2L, 5L, 5L, 1L, 5L, 3L, 4L, 4L, 3L,
>
> 5L, 2L, 5L, 4L, 5L, 5L, 4L, 4L, 4L, 3L, 5L, 2L, 5L, 4L, 4L, 5L,
>
> 1L, 2L, 5L, 5L, 4L, 3L, 4L, 2L, 1L, 1L, 4L, 3L, 5L, 4L, 2L, 3L,
>
> 3L, 3L, 3L, 4L, 2L, 5L, 4L, 5L, 5L, 4L, 5L, 4L, 2L, 3L, 2L, 2L,
>
> 2L, 3L, 3L, 4L, 2L, 4L, 4L, 5L, 2L, 3L, 4L, 4L, 4L, 4L, 2L, 4L,
>
> 5L, 5L, 3L, 5L, 5L, 4L, 4L, 4L, 5L, 5L, 3L, 5L, 4L, 4L, 2L, 4L,
>
> 2L, 4L, 4L, 2L, 5L, 4L, 5L, 4L, 4L, 5L, 4L, 4L, 4L, 5L, 4L, 3L,
>
> 3L, 3L, 4L, 2L, 2L, 5L, 4L, 3L, 5L, 4L, 4L, 5L, 5L, 2L, 3L, 5L,
>
> 4L, 3L, 4L, 4L, 4L, 3L, 2L, 3L, 3L, 4L, 4L, 3L, 1L, 3L, 2L, 2L,
>
> 3L, 3L, 2L, 4L, 3L, 5L, 3L, 4L, 3L, 4L, 3L, 5L, 4L, 3L, 2L, 2L,
>
> 5L, 2L, 5L, 4L, 5L, 2L, 3L, 4L, 2L, 3L, 2L, 4L, 5L, 5L, 2L, 3L,
>
> 2L, 4L, 3L, 2L, 5L, 2L, 5L, 2L, 5L, 3L, 3L, 3L, 4L, 2L, 2L, 3L,
>
> 1L, 3L, 3L, 2L, 4L, 4L, 1L, 4L, 3L, 4L, 3L, 3L, 4L, 3L, 4L, 4L,
>
> 3L, 2L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 1L, 4L, 4L, 2L, 2L, 3L,
>
> 3L, 2L, 2L, 5L, 5L, 3L, 3L, 4L, 5L, 4L, 4L, 3L, 3L, 5L, 2L, 4L,
>
> 4L, 4L, 3L, 4L, 4L, 5L, 4L, 4L, 4L, 3L, 5L, 5L, 4L, 3L, 3L, 3L,
>
> 3L, 4L, 3L, 3L, 3L, 4L, 4L, 3L, 4L, 3L, 4L, 3L, 3L, 5L, 4L, 4L,
>
> 5L, 5L, 5L, 5L, 4L, 5L, 5L, 2L, 3L, 3L, 4L, 5L, 4L, 3L, 5L, 3L,
>
> 1L, 5L, 5L, 4L, 1L, 4L, 3L, 4L, 4L, 3L, 4L, 3L, 4L, 5L, 2L, 3L,
>
> 2L, 2L, 3L, 3L, 5L, 3L, 2L, 5L, 4L, 2L, 5L, 5L, 5L, 5L, 2L, 3L,
>
> 3L, 5L, 3L, 2L, 5L, 2L, 4L, 4L, 5L, 4L, 4L, 3L, 2L, 3L, 5L, 4L,
>
> 5L, 4L, 5L, 3L, 4L, 5L, 3L, 5L, 5L, 2L, 4L, 3L, 4L, 4L, 3L, 3L,
>
> 5L, 3L, 5L, 4L, 5L, 5L, 4L, 2L, 1L, 5L, 3L, 4L, 5L, 3L, 3L, 2L,
>
> 2L, 3L, 2L, 4L, 3L, 4L, 5L, 3L, 4L, 4L, 2L, 5L, 2L, 3L, 4L, 4L,
>
> 4L, 4L, 3L, 5L, 4L, 4L, 3L, 4L, 2L, 3L, 4L, 2L, 2L, 2L, 3L, 3L,
>
> 4L, 2L, 3L, 3L, 4L, 3L, 4L, 4L, 2L, 4L, 4L, 3L, 4L, 3L, 1L, 3L,
>
> 2L, 2L, 4L, 2L, 3L, 5L, 4L, 4L, 3L, 3L, 5L, 4L, 5L, 4L, 4L, 4L,
>
> 4L, 3L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 5L, 4L, 4L, 5L, 5L, 5L, 3L,
>
> 3L, 3L, 5L, 5L, 2L, 5L, 4L, 5L, 4L, 3L, 3L, 4L, 5L, 4L, 3L, 4L,
>
> 4L, 2L, 3L, 5L, 4L, 5L, 2L, 5L, 4L, 3L, 2L, 2L, 3L, 2L, 4L, 3L,
>
> 3L, 3L, 2L, 4L, 5L, 4L, 1L, 4L, 1L, 3L, 3L, 4L, 5L, 3L, 3L, 3L,
>
> 4L, 4L, 4L, 3L, 2L, 3L, 2L, 2L, 4L, 2L, 3L, 2L, 3L, 2L, 3L, 4L,
>
> 2L, 4L, 2L, 4L, 4L, 3L, 4L, 4L, 3L, 4L, 4L, 2L, 3L, 4L, 3L, 2L,
>
> 4L, 5L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 4L, 3L, 3L, 3L, 5L, 3L, 4L,
>
> 2L, 4L, 2L, 5L, 5L, 3L, 3L, 4L, 3L, 3L, 5L, 3L, 3L, 5L, 4L, 4L,
>
> 2L, 4L, 5L, 5L, 3L, 2L, 2L, 3L, 3L, 4L, 4L, 2L, 5L, 2L, 5L, 4L,
>
> 4L, 4L, 2L, 5L, 3L, 2L, 4L, 4L, 3L, 2L, 2L, 4L, 3L, 3L, 3L, 5L,
>
> 3L, 4L, 2L, 5L, 4L, 2L, 2L, 3L, 4L, 4L, 5L, 3L, 5L, 5L, 5L, 5L,
>
> 5L, 5L, 5L, 5L, 5L, 4L, 3L, 4L, 5L, 2L, 4L, 5L, 5L, 3L, 3L, 5L,
>
> 5L, 5L, 4L, 5L, 5L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 3L, 5L, 5L,
>
> 5L, 3L, 4L, 3L, 3L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 4L, 4L, 2L, 4L,
>
> 5L, 5L, 4L, 3L, 2L, 4L, 2L, 3L, 4L, 1L, 3L, 3L, 5L, 5L, 5L, 5L,
>
> 3L, 4L, 3L, 4L, 3L, 5L, 5L, 5L, 5L, 4L, 3L, 3L, 3L, 3L, 3L, 4L,
>
> 3L, 3L, 5L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 3L, 5L, 4L, 5L, 5L, 4L,
>
> 4L, 4L, 5L, 5L, 5L, 3L, 4L, 2L, 4L, 4L, 3L, 4L, 2L, 5L, 4L, 4L,
>
> 4L, 3L, 5L, 4L, 5L, 3L, 4L, 4L, 4L, 3L, 4L, 4L, 4L, 2L, 2L, 5L,
>
> 5L, 5L, 5L, 4L, 2L, 4L, 5L, 4L, 4L, 3L, 2L, 2L, 5L, 5L, 4L, 5L,
>
> 5L, 4L, 5L, 3L, 4L, 4L, 4L, 2L, 5L, 5L, 2L, 4L, 2L, 4L, 5L, 5L,
>
> 5L, 3L, 3L, 5L, 1L, 2L, 3L, 2L, 3L, 1L, 1L, 3L, 3L, 3L, 2L, 3L,
>
> 4L, 4L, 4L, 3L, 3L, 2L, 4L, 5L, 5L, 5L, 4L, 4L, 4L, 3L, 3L, 5L,
>
> 3L, 4L, 5L, 5L, 4L, 4L, 5L, 2L, 3L, 5L, 4L, 1L, 3L, 3L, 3L, 2L,
>
> 3L, 3L, 2L, 5L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 4L, 5L, 2L, 5L, 5L,
>
> 4L, 4L, 5L, 4L, 2L, 3L, 5L, 4L, 5L, 4L, 3L, 4L, 2L, 4L, 2L, 2L,
>
> 4L, 5L, 5L, 5L, 5L, 3L, 4L, 4L, 4L, 3L, 2L, 4L, 4L, 3L, 2L, 3L,
>
> 3L, 4L, 2L, 2L, 4L, 5L, 4L, 5L, 4L, 4L, 4L, 4L, 5L, 4L, 4L, 2L,
>
> 3L, 2L, 4L, 4L, 2L, 5L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 4L, 2L, 5L,
>
> 4L, 5L, 5L, 4L, 5L, 2L, 3L, 4L, 2L, 3L, 4L, 2L, 4L, 2L, 5L, 5L,
>
> 4L, 4L, 5L, 5L, 5L, 5L, 4L, 5L, 1L, 4L, 3L, 4L, 4L, 4L, 4L, 2L,
>
> 4L, 4L, 4L, 5L, 1L, 3L, 5L, 2L, 4L, 4L, 2L, 4L, 4L, 2L, 2L, 5L,
>
> 4L, 5L, 5L, 5L, 4L, 4L, 5L, 1L, 1L, 5L, 4L, 3L, 3L, 5L, 4L, 4L,
>
> 4L, 5L, 4L, 5L, 2L, 3L, 3L, 4L, 5L, 4L, 2L, 2L, 5L, 2L, 3L, 5L,
>
> 5L, 2L, 4L, 3L, 5L, 2L, 5L, 5L, 5L, 3L, 4L), .Label = c("1",
>
> "2", "3", "4", "5"), class = "factor")), .Names = c("item25",
>
> "psd", "gpa"), row.names = c(NA, -1428L), class = "data.frame")
>
>
>
> --
>
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From NordlDJ at dshs.wa.gov  Thu Apr 10 22:04:03 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 10 Apr 2014 20:04:03 +0000
Subject: [R] how to select an element from a vector based on
	a	probability
In-Reply-To: <CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
	<5346E92B.9000000@sapo.pt>
	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Simone Gabbriellini
> Sent: Thursday, April 10, 2014 11:59 AM
> To: Rui Barradas
> Cc: r-help at r-project.org
> Subject: Re: [R] how to select an element from a vector based on a
> probability
> 
> Hello, Rui,
> 
> it does, indeed!
> 
> thanks,
> Simone
> 
> 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
> > Hello,
> >
> > Use ?sample.
> >
> > sample(x, 1, prob = x)
> >

Just be aware that, in using this method, the probability of selection of a particular value will also be a function of how frequent the value is.  For example,

set.seed(7632)
x <- c(2,2,6,2,1,1,1,3)
table(sample(x, 10000, prob=x, replace=TRUE))

   1    2    3    6 
1664 3340 1696 3300 


The probability that a vector position with a value of 1 will be selected is 1/18 (in this particular example).  However, the probability that a value of 1 will be selected is 1/6 since there are three 1's.  The probability of selecting the position with a value of 3 is 3/18.  But since there is only one position with a value of 3, the probability of getting the value 1 on any given sample is equal to the probability of getting the value 3.

 


> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
> >
> >> Hello List,
> >>
> >> I have an array like:
> >>
> >> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
> >> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
> >> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
> >> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
> >> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
> >> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
> >> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
> >> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
> >>
> >> I would like to pick up an element with a probability proportional
> to
> >> the element value, thus higher values should be picked up more often
> >> than small values (i.e., picking up 38 should be more probable than
> >> picking up 3)
> >>
> >> Do you have any idea on how to code such a rich-get-richer
> mechanism?
> >>
> >> Best regards,
> >> Simone
> >>
> >
> 
> 
> 

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From NordlDJ at dshs.wa.gov  Thu Apr 10 22:12:26 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 10 Apr 2014 20:12:26 +0000
Subject: [R] Determining 32- vs. 64-bit Windows
In-Reply-To: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>
References: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766239F4FEF@WAXMXOLYMB025.WAX.wa.lcl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/0e3c0a1e/attachment-0001.pl>

From pdalgd at gmail.com  Thu Apr 10 22:23:08 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Apr 2014 22:23:08 +0200
Subject: [R] Determining 32- vs. 64-bit Windows
In-Reply-To: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>
References: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>
Message-ID: <58F2D420-523F-4FC3-8505-AAC567A1A7B2@gmail.com>

I believe that b. is .Machine$sizeof.pointer*8. 

I am not aware of a method to figure out the difficult part of a.: whether a 32 bit R is running on 64 bit Windows. I'd expect that you have to ask the OS somehow. Google coughs up one or two interesting pointers.

-pd  

On 10 Apr 2014, at 21:48 , Fisher Dennis <fisher at plessthan.com> wrote:

> 3.0.2
> Windows
> 
> Colleagues,
> 
> If I am setting up code for others and I don?t know their configuration, what is the simplest way to find out the following within R:
> 	a.  is the system 32- or 64-bit?
> 	b.  if the system is 64-bit, is R 32- or 64-bit?
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From ruipbarradas at sapo.pt  Thu Apr 10 22:34:59 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 10 Apr 2014 21:34:59 +0100
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>	<5346E92B.9000000@sapo.pt>
	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <53470073.7080003@sapo.pt>

Hello,

Inline.

Em 10-04-2014 21:04, Nordlund, Dan (DSHS/RDA) escreveu:
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Simone Gabbriellini
>> Sent: Thursday, April 10, 2014 11:59 AM
>> To: Rui Barradas
>> Cc: r-help at r-project.org
>> Subject: Re: [R] how to select an element from a vector based on a
>> probability
>>
>> Hello, Rui,
>>
>> it does, indeed!
>>
>> thanks,
>> Simone
>>
>> 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
>>> Hello,
>>>
>>> Use ?sample.
>>>
>>> sample(x, 1, prob = x)
>>>
>
> Just be aware that, in using this method, the probability of selection of a particular value will also be a function of how frequent the value is.  For example,
>
> set.seed(7632)
> x <- c(2,2,6,2,1,1,1,3)
> table(sample(x, 10000, prob=x, replace=TRUE))
>
>     1    2    3    6
> 1664 3340 1696 3300
>
>
> The probability that a vector position with a value of 1 will be selected is 1/18 (in this particular example).  However, the probability that a value of 1 will be selected is 1/6 since there are three 1's.  The probability of selecting the position with a value of 3 is 3/18.  But since there is only one position with a value of 3, the probability of getting the value 1 on any given sample is equal to the probability of getting the value 3.

You're right, I didn't notice that. One way of avoiding that problem is 
the following.

prob <- merge(x, data.frame(x=unique(x), 
prob=unique(x)/sum(unique(x))))$prob
sample(x, 1, prob = prob)

Rui Barradas

>
>
>
>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
>>>
>>>> Hello List,
>>>>
>>>> I have an array like:
>>>>
>>>> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
>>>> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
>>>> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
>>>> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
>>>> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
>>>> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
>>>> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
>>>> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>>>>
>>>> I would like to pick up an element with a probability proportional
>> to
>>>> the element value, thus higher values should be picked up more often
>>>> than small values (i.e., picking up 38 should be more probable than
>>>> picking up 3)
>>>>
>>>> Do you have any idea on how to code such a rich-get-richer
>> mechanism?
>>>>
>>>> Best regards,
>>>> Simone
>>>>
>>>
>>
>>
>>
>
> Dan
>
> Daniel J. Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>



From ruipbarradas at sapo.pt  Thu Apr 10 22:39:21 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 10 Apr 2014 21:39:21 +0100
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <53470073.7080003@sapo.pt>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>	<5346E92B.9000000@sapo.pt>	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>	<F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
	<53470073.7080003@sapo.pt>
Message-ID: <53470179.2050602@sapo.pt>

Sorry, there's a bug. merge() sorts the data.frame so we need to sort x 
also.

sample(sort(x), 1, prob = prob)

Rui Barradas

Em 10-04-2014 21:34, Rui Barradas escreveu:
> Hello,
>
> Inline.
>
> Em 10-04-2014 21:04, Nordlund, Dan (DSHS/RDA) escreveu:
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of Simone Gabbriellini
>>> Sent: Thursday, April 10, 2014 11:59 AM
>>> To: Rui Barradas
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] how to select an element from a vector based on a
>>> probability
>>>
>>> Hello, Rui,
>>>
>>> it does, indeed!
>>>
>>> thanks,
>>> Simone
>>>
>>> 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
>>>> Hello,
>>>>
>>>> Use ?sample.
>>>>
>>>> sample(x, 1, prob = x)
>>>>
>>
>> Just be aware that, in using this method, the probability of selection
>> of a particular value will also be a function of how frequent the
>> value is.  For example,
>>
>> set.seed(7632)
>> x <- c(2,2,6,2,1,1,1,3)
>> table(sample(x, 10000, prob=x, replace=TRUE))
>>
>>     1    2    3    6
>> 1664 3340 1696 3300
>>
>>
>> The probability that a vector position with a value of 1 will be
>> selected is 1/18 (in this particular example).  However, the
>> probability that a value of 1 will be selected is 1/6 since there are
>> three 1's.  The probability of selecting the position with a value of
>> 3 is 3/18.  But since there is only one position with a value of 3,
>> the probability of getting the value 1 on any given sample is equal to
>> the probability of getting the value 3.
>
> You're right, I didn't notice that. One way of avoiding that problem is
> the following.
>
> prob <- merge(x, data.frame(x=unique(x),
> prob=unique(x)/sum(unique(x))))$prob
> sample(x, 1, prob = prob)
>
> Rui Barradas
>
>>
>>
>>
>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
>>>>
>>>>> Hello List,
>>>>>
>>>>> I have an array like:
>>>>>
>>>>> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
>>>>> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
>>>>> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
>>>>> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
>>>>> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
>>>>> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
>>>>> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
>>>>> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>>>>>
>>>>> I would like to pick up an element with a probability proportional
>>> to
>>>>> the element value, thus higher values should be picked up more often
>>>>> than small values (i.e., picking up 38 should be more probable than
>>>>> picking up 3)
>>>>>
>>>>> Do you have any idea on how to code such a rich-get-richer
>>> mechanism?
>>>>>
>>>>> Best regards,
>>>>> Simone
>>>>>
>>>>
>>>
>>>
>>>
>>
>> Dan
>>
>> Daniel J. Nordlund, PhD
>> Research and Data Analysis Division
>> Services & Enterprise Support Administration
>> Washington State Department of Social and Health Services
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Thu Apr 10 22:40:43 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Apr 2014 22:40:43 +0200
Subject: [R] Binom.test - hudge difference in p-value for little
	differences in PD forecast
In-Reply-To: <000b01cf54cc$0b9ffe50$22dffaf0$@1plusi.de>
References: <000b01cf54cc$0b9ffe50$22dffaf0$@1plusi.de>
Message-ID: <924F2637-EC9E-45E2-95D4-EF3B1256DDCC@gmail.com>


On 10 Apr 2014, at 16:49 , Alwina Hermann <alwina.hermann at 1plusi.de> wrote:

> Dear R team,
>  
> I'm not sure if I use the right distribution list, but I hope in case if
> not, you will forward it to the reference person.
>  
> Following problem occured:
> I used R to calculate the p-value for the two sided binomial test (exact -
> Pearson).
> For a very little difference for my forecast I get a very big difference in
> my p-value
>  
>  >  binom.test(1,101, 0.02402)
> 
>         Exact binomial test
> 
> data:  1 and 101
> number of successes = 1, number of trials = 101, p-value = 0.7375
> alternative hypothesis: true probability of success is not equal to 0.02402
> 95 percent confidence interval:
> 0.00025064 0.05393235
> sample estimates:
> probability of success 
>             0.00990099
> 
>> binom.test(1,101, 0.02403)
> 
>         Exact binomial test
> 
> data:  1 and 101
> number of successes = 1, number of trials = 101, p-value = 0.5243
> alternative hypothesis: true probability of success is not equal to 0.02403
> 95 percent confidence interval:
> 0.00025064 0.05393235
> sample estimates:
> probability of success 
>             0.00990099
> 
> 
> Can you please explain where this huge difference come from?
> Which mathematical explanation is given for this topic?

Check the definition of the p value (you need to study the source for that, I suppose). It's the probability of getting an observation with a point probability less than or equal to that of the observed value. The crucial bit is whether the point probability p(1) is less than or bigger than p(3):

> dbinom(0:4,101, 0.02403)
[1] 0.08572022 0.21316798 0.26242746 0.21322618 0.12862456
> dbinom(0:4,101, 0.02402)
[1] 0.08580898 0.21329771 0.26247520 0.21317403 0.12853828

I.e., in the first case, X==3 is not counted into the p-value, whereas it is in the second case.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From jlonkc at gmail.com  Thu Apr 10 22:25:31 2014
From: jlonkc at gmail.com (Karina Charest Castro)
Date: Thu, 10 Apr 2014 16:25:31 -0400
Subject: [R] Mixed models negative binomial, Error in eval(expr, envir,
	enclos)
Message-ID: <CAHdb_jP6DSKXz0Y-+du2096eGxCWUAr1yJ-Q_jy=13VxXZAm=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/683f867a/attachment-0001.pl>

From dwinsemius at comcast.net  Thu Apr 10 22:58:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Apr 2014 13:58:45 -0700
Subject: [R] Plotting a 3D surface from three variables
In-Reply-To: <CALekQEu-E-pdTbiOCCzA+sZU_R48aiuguccMtJ6eTOQ62j5ZfA@mail.gmail.com>
References: <CALekQEu-E-pdTbiOCCzA+sZU_R48aiuguccMtJ6eTOQ62j5ZfA@mail.gmail.com>
Message-ID: <A53132EC-9BCA-4EFC-90EE-FD3787CD0617@comcast.net>


On Apr 10, 2014, at 5:58 AM, Kumsa wrote:

> I'm trying to produce a 3d plot with wireframe function or any other
> package  in R . I want to show how z changes in response to x and y. But I
> fail to produce  a 3d surfaceplot with a  wireframe command  which gives me
> different  error messages.
> 
> ## Generate data
> x <- seq(from=0, to=100,by=1)
> y <- seq(from=0, to=20,by=1)
> df <- expand.grid(x=x,y=y)
> df$z<-1/(1+(exp(-(-1.42+0.04*df$x+0.4*df$y))))
> The command that I used is this one
> 
> require(lattice)
> wireframe(df ~ x * y, df, shade = TRUE, aspect = c(1, 1),light.source =
> c(10,10,10))
> 

Try changing the formula to : z ~ x + y

z ~ x * y also "works" but it looks wrong to my eyes.

-- 

David Winsemius
Alameda, CA, USA



From boris.steipe at utoronto.ca  Thu Apr 10 23:10:20 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 10 Apr 2014 17:10:20 -0400
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <53470073.7080003@sapo.pt>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>	<5346E92B.9000000@sapo.pt>
	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
	<53470073.7080003@sapo.pt>
Message-ID: <9E21F588-32FF-4D9A-A4EA-8CEED96AD30A@utoronto.ca>

But your original approach was more concise - just use unique() for the input vector (since neither length nor order matter) and the probabilities:

a <- c(1,1,1,1,2,5)
set.seed(11235813)
out <- sample(unique(a), 100, replace=TRUE, prob = unique(a))
out
    [1] 5 5 5 2 5 5 1 1 5 2 5 2 5 5 1 5 1 2 ...

table(out)/length(out)   # relative observations
out
   1    2    5 
0.13 0.25 0.62  

unique(a)/sum(unique(a)) # expected observations
[1] 0.125 0.250 0.625

Cheers,
B.


On 2014-04-10, at 4:34 PM, Rui Barradas wrote:

> Hello,
> 
> Inline.
> 
> Em 10-04-2014 21:04, Nordlund, Dan (DSHS/RDA) escreveu:
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of Simone Gabbriellini
>>> Sent: Thursday, April 10, 2014 11:59 AM
>>> To: Rui Barradas
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] how to select an element from a vector based on a
>>> probability
>>> 
>>> Hello, Rui,
>>> 
>>> it does, indeed!
>>> 
>>> thanks,
>>> Simone
>>> 
>>> 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
>>>> Hello,
>>>> 
>>>> Use ?sample.
>>>> 
>>>> sample(x, 1, prob = x)
>>>> 
>> 
>> Just be aware that, in using this method, the probability of selection of a particular value will also be a function of how frequent the value is.  For example,
>> 
>> set.seed(7632)
>> x <- c(2,2,6,2,1,1,1,3)
>> table(sample(x, 10000, prob=x, replace=TRUE))
>> 
>>    1    2    3    6
>> 1664 3340 1696 3300
>> 
>> 
>> The probability that a vector position with a value of 1 will be selected is 1/18 (in this particular example).  However, the probability that a value of 1 will be selected is 1/6 since there are three 1's.  The probability of selecting the position with a value of 3 is 3/18.  But since there is only one position with a value of 3, the probability of getting the value 1 on any given sample is equal to the probability of getting the value 3.
> 
> You're right, I didn't notice that. One way of avoiding that problem is the following.
> 
> prob <- merge(x, data.frame(x=unique(x), prob=unique(x)/sum(unique(x))))$prob
> sample(x, 1, prob = prob)
> 
> Rui Barradas
> 
>> 
>> 
>> 
>> 
>>>> Hope this helps,
>>>> 
>>>> Rui Barradas
>>>> 
>>>> Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
>>>> 
>>>>> Hello List,
>>>>> 
>>>>> I have an array like:
>>>>> 
>>>>> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
>>>>> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
>>>>> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
>>>>> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
>>>>> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
>>>>> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
>>>>> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
>>>>> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>>>>> 
>>>>> I would like to pick up an element with a probability proportional
>>> to
>>>>> the element value, thus higher values should be picked up more often
>>>>> than small values (i.e., picking up 38 should be more probable than
>>>>> picking up 3)
>>>>> 
>>>>> Do you have any idea on how to code such a rich-get-richer
>>> mechanism?
>>>>> 
>>>>> Best regards,
>>>>> Simone
>>>>> 
>>>> 
>>> 
>>> 
>>> 
>> 
>> Dan
>> 
>> Daniel J. Nordlund, PhD
>> Research and Data Analysis Division
>> Services & Enterprise Support Administration
>> Washington State Department of Social and Health Services
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ivo.welch at anderson.ucla.edu  Fri Apr 11 00:31:29 2014
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Thu, 10 Apr 2014 15:31:29 -0700
Subject: [R] better an error?
Message-ID: <CAPr7RtXtoGVTyVr2kQQgz-hxLqM+9k6jJr4apmAcmP+RN+Bmog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/993821fc/attachment-0001.pl>

From erinm.hodgess at gmail.com  Fri Apr 11 00:36:03 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 10 Apr 2014 17:36:03 -0500
Subject: [R] Version R-3.1.0 for Windows
Message-ID: <CACxE24m1ZLph9aijK9u_qCHHO1Ycssqb_jOq6xDXn9exv0hu3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/afaa212a/attachment-0001.pl>

From ligges at statistik.tu-dortmund.de  Fri Apr 11 01:00:46 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 11 Apr 2014 01:00:46 +0200
Subject: [R] Version R-3.1.0 for Windows
In-Reply-To: <CACxE24m1ZLph9aijK9u_qCHHO1Ycssqb_jOq6xDXn9exv0hu3w@mail.gmail.com>
References: <CACxE24m1ZLph9aijK9u_qCHHO1Ycssqb_jOq6xDXn9exv0hu3w@mail.gmail.com>
Message-ID: <5347229E.8000700@statistik.tu-dortmund.de>



On 11.04.2014 00:36, Erin Hodgess wrote:
> Hello!
>
> I like to build from source on Windows (64 bit).
>
> Will the Rtools be updated along with the new tar.gz file, please?

The Rtools page tells us:

Rtools31.exe 	R 3.0.x to 3.1.x

So this is the right one...

Best,
Uwe Ligges




>
> Thanks,
> Erin
>
>



From erinm.hodgess at gmail.com  Fri Apr 11 01:02:36 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 10 Apr 2014 18:02:36 -0500
Subject: [R] Version R-3.1.0 for Windows
In-Reply-To: <5347229E.8000700@statistik.tu-dortmund.de>
References: <CACxE24m1ZLph9aijK9u_qCHHO1Ycssqb_jOq6xDXn9exv0hu3w@mail.gmail.com>
	<5347229E.8000700@statistik.tu-dortmund.de>
Message-ID: <CACxE24kyj164JKh76SLuoJgv3A95+r2AXPx7Ot1xJnL-ofkDhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/072ce491/attachment-0001.pl>

From r.turner at auckland.ac.nz  Fri Apr 11 01:32:33 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 11 Apr 2014 07:32:33 +0800
Subject: [R] better an error?
In-Reply-To: <CAPr7RtXtoGVTyVr2kQQgz-hxLqM+9k6jJr4apmAcmP+RN+Bmog@mail.gmail.com>
References: <CAPr7RtXtoGVTyVr2kQQgz-hxLqM+9k6jJr4apmAcmP+RN+Bmog@mail.gmail.com>
Message-ID: <53472A11.9080602@auckland.ac.nz>



The behaviour that you get is exactly the behaviour that I, at least, 
would expect, and it seems to me to be exactly the correct behaviour.
I do not understand what you are complaining about.

cheers,

Rolf Turner

On 11/04/14 06:31, ivo welch wrote:
> I just spent about an hour bug-tracking.  I had expected the following to
> throw an error:
>
>    d <- data.frame( x=1:5, y=6:10 )
>    valid <- c(TRUE, FALSE)
>    d[valid,]
>
> I understand that R recycles "when fit," but I had not expected it to
> recycle, then truncate, and not give even a warning.  maybe there is a good
> reason for this.
>
> I would love to be able to teach R to my MFE students.  alas, I don't feel
> that I can inflict on them the mysterious errors in R.  this ranges from
> poor checking of when variables exist to auto-recycling (without an ability
> to turn this off even with an option) to the non-printing of the last
> numbered R source code statement upon an error (that I can see in the
> traceback()) to non-expected behavior (e.g., subset(d,x,select=-c("a",
> "b"))) to .  I know many of these issues can be fixed and/or do not bother
> the experts, and I am personally happy to live with R for its power despite
> its drawbacks; but IMHO it is just too much to ask from a set of bewildered
> novice master students.
>
> I hope the R team will at some point in the future pick up on making the
> core language less mysterious upon setting an option, at least in "user
> space".



From noahsilverman at ucla.edu  Fri Apr 11 02:38:37 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 10 Apr 2014 17:38:37 -0700
Subject: [R] Options in Blotter
Message-ID: <5347398D.90307@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/0c17df70/attachment-0001.pl>

From fisher at plessthan.com  Fri Apr 11 02:44:30 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Thu, 10 Apr 2014 17:44:30 -0700
Subject: [R] Determining 32- vs. 64-bit Windows
In-Reply-To: <58F2D420-523F-4FC3-8505-AAC567A1A7B2@gmail.com>
References: <7DCC2B7C-270E-45CF-9D9F-F1E14D7CB562@plessthan.com>
	<58F2D420-523F-4FC3-8505-AAC567A1A7B2@gmail.com>
Message-ID: <58D05AC0-2F38-432C-A9F7-26F62E234F80@plessthan.com>

Peter

Your proposal appears to work better than expected:	
	On a 64-bit machine, it reported
		64 when R64 was launched
		32 when R62 was launched
	On a 32-bit machine, it reported 32.

The underlying issue for me is that I am calling c code ? I want to make sure that I don?t call 64-bit c code when I am using 32-bit R (either in Windows 32- or 64-bit).  

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



On Apr 10, 2014, at 1:23 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> I believe that b. is .Machine$sizeof.pointer*8. 
> 
> I am not aware of a method to figure out the difficult part of a.: whether a 32 bit R is running on 64 bit Windows. I'd expect that you have to ask the OS somehow. Google coughs up one or two interesting pointers.
> 
> -pd  
> 
> On 10 Apr 2014, at 21:48 , Fisher Dennis <fisher at plessthan.com> wrote:
> 
>> 3.0.2
>> Windows
>> 
>> Colleagues,
>> 
>> If I am setting up code for others and I don?t know their configuration, what is the simplest way to find out the following within R:
>> 	a.  is the system 32- or 64-bit?
>> 	b.  if the system is 64-bit, is R 32- or 64-bit?
>> 
>> Dennis
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone: 1-866-PLessThan (1-866-753-7784)
>> Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 



From catagui at gmail.com  Fri Apr 11 03:44:11 2014
From: catagui at gmail.com (Catalina Aguilar Hurtado)
Date: Fri, 11 Apr 2014 11:44:11 +1000
Subject: [R] How to make a proper use of blocking in limma using voom
Message-ID: <CAAHBMXbheQov5vAYhXX_+L-32qTXRGg-ygwrMrOxrpYv+S6-bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/60a32ff8/attachment-0001.pl>

From hill0093 at umn.edu  Fri Apr 11 06:17:26 2014
From: hill0093 at umn.edu (Hurr)
Date: Thu, 10 Apr 2014 21:17:26 -0700 (PDT)
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <A9E74082-623B-4AB4-B7B6-2A028C3A7D77@comcast.net>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
	<5344F649.1020907@bitwrit.com.au>
	<1397031467054-4688456.post@n4.nabble.com>
	<5345033C.6080701@bitwrit.com.au>
	<1397092642268-4688498.post@n4.nabble.com>
	<A9E74082-623B-4AB4-B7B6-2A028C3A7D77@comcast.net>
Message-ID: <1397189846176-4688587.post@n4.nabble.com>

Yes, the initial question is answered and the code works.
I suppose that I should not have added more to it.
I should have posted a new topic.
Sorry that I am not at all an R user.
Just trying to determine if I want to use it.
I just read your link.
Sorry to be more stupid than you expect.
I did notice that it said that rudeness is not acceptable.
None of the other helpers were rude.




--
View this message in context: http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function-of-axis-value-tp4687917p4688587.html
Sent from the R help mailing list archive at Nabble.com.



From shelly1436 at gmail.com  Fri Apr 11 01:44:54 2014
From: shelly1436 at gmail.com (Sheng Li)
Date: Thu, 10 Apr 2014 19:44:54 -0400
Subject: [R] Version R-3.1.0 for Windows
In-Reply-To: <CACxE24kyj164JKh76SLuoJgv3A95+r2AXPx7Ot1xJnL-ofkDhQ@mail.gmail.com>
References: <CACxE24m1ZLph9aijK9u_qCHHO1Ycssqb_jOq6xDXn9exv0hu3w@mail.gmail.com>
	<5347229E.8000700@statistik.tu-dortmund.de>
	<CACxE24kyj164JKh76SLuoJgv3A95+r2AXPx7Ot1xJnL-ofkDhQ@mail.gmail.com>
Message-ID: <CAGyQtzZ8pqwrT6AGqkQFk=twRGHKW3kNR1-yHSNjU3XSyTCYCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/e03b9d6e/attachment-0001.pl>

From frtog at vestas.com  Fri Apr 11 07:29:25 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 11 Apr 2014 07:29:25 +0200
Subject: [R] how to select an element from a vector based
	on	a	probability
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
	<5346E92B.9000000@sapo.pt>
	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CB9768@DKRDSEXC016.vestas.net>

I think you have calculated the wrong probabilities. Shouldn't it be

> x <- c(2,2,6,2,1,1,1,3)
> MASS::fractions(table(x)/length(x))
x
  1   2   3   6 
3/8 3/8 1/8 1/8 
>

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Nordlund, Dan (DSHS/RDA)
> Sent: 10. april 2014 22:04
> To: Simone Gabbriellini; Rui Barradas
> Cc: r-help at r-project.org
> Subject: Re: [R] how to select an element from a vector based on a
> probability
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Simone Gabbriellini
> > Sent: Thursday, April 10, 2014 11:59 AM
> > To: Rui Barradas
> > Cc: r-help at r-project.org
> > Subject: Re: [R] how to select an element from a vector based on a
> > probability
> >
> > Hello, Rui,
> >
> > it does, indeed!
> >
> > thanks,
> > Simone
> >
> > 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
> > > Hello,
> > >
> > > Use ?sample.
> > >
> > > sample(x, 1, prob = x)
> > >
> 
> Just be aware that, in using this method, the probability of selection of a
> particular value will also be a function of how frequent the value is.  For
> example,
> 
> set.seed(7632)
> x <- c(2,2,6,2,1,1,1,3)
> table(sample(x, 10000, prob=x, replace=TRUE))
> 
>    1    2    3    6
> 1664 3340 1696 3300
> 
> 
> The probability that a vector position with a value of 1 will be selected is 1/18
> (in this particular example).  However, the probability that a value of 1 will be
> selected is 1/6 since there are three 1's.  The probability of selecting the
> position with a value of 3 is 3/18.  But since there is only one position with a
> value of 3, the probability of getting the value 1 on any given sample is equal
> to the probability of getting the value 3.
> 
> 
> 
> 
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
> > >
> > >> Hello List,
> > >>
> > >> I have an array like:
> > >>
> > >> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
> > >> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
> > >> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
> > >> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
> > >> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
> > >> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
> > >> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
> > >> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
> > >>
> > >> I would like to pick up an element with a probability proportional
> > to
> > >> the element value, thus higher values should be picked up more often
> > >> than small values (i.e., picking up 38 should be more probable than
> > >> picking up 3)
> > >>
> > >> Do you have any idea on how to code such a rich-get-richer
> > mechanism?
> > >>
> > >> Best regards,
> > >> Simone
> > >>
> > >
> >
> >
> >
> 
> Dan
> 
> Daniel J. Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Apr 11 07:14:30 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 Apr 2014 22:14:30 -0700 (PDT)
Subject: [R] Splitting columns  and forming new data files in R
In-Reply-To: <360473.16801.bm@smtp232.mail.bf1.yahoo.com>
References: <360473.16801.bm@smtp232.mail.bf1.yahoo.com> 
Message-ID: <1397193270.91459.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Ok, In that case, 

change `lst1New`.? Also, in your files, there was no "Sim" column.? So, I changed the name.


lst1New <- lapply(lst1,function(x) {lst2 <- setNames(lapply(x,function(y) {dat <- read.table(y,sep=" ",header=TRUE, stringsAsFactors=FALSE);names(dat)[5] <- "Sim"; dat[,1:5]}),names1); dat2 <- do.call(cbind,lst2); indx <- grepl("Sim",names(dat2)); dat3 <- dat2[indx]; dat4 <- dat2[!indx][,1:4]; names(dat4) <- gsub(".*\\.","",names(dat4)); lapply(split(names(dat3),gsub(".*\\.","",names(dat3))),function(x) {dat5 <- cbind(dat4,dat3[,x]);dat5$Tmean <- -999.9; dat6 <- dat5[,c(1:4,7:6,8,5)];colnames(dat6)[2:3] <- format(Coord[match(unique(dat6$Site),Coord$Site),3:2],digits=4); dat7 <- dat6[,-4]; mat1 <- as.matrix(dat7); colnames(mat1)[-(2:3)] <- ' '; mat1})})?


A.K.




On Friday, April 11, 2014 12:12 AM, "zilefacelvis at yahoo.com" <zilefacelvis at yahoo.com> wrote:





Hi AK, ?the program works perfect. I used a different data set and was unable to modify the program to suit the new data set. Attached.





The attached dataset has 5 columns instead of 104 columns for which the program was developed. I was unable to edit lst1NEW<-.

------ Original Message ------



From : arun
>To : Zilefac Elvis;
>Sent : 10-04-2014 22:02
>Subject : Re: Re: Splitting columns and forming new data files in R
>?
>Hi Atem, It may be that the program slows with the size of the dataset.??On Thursday, April 10, 2014 11:13 PM, Zilefac Elvis? wrote: Hi AK,
Please apply this program of yours to my attached data set. I have been struggling for hours but did not succeed. I am learning faster than I expected but this one is more than me. Thanks,
Atem.
#---------------------------------------------------------------------------
dir.create("final")
list.files()
#[1] "coordinates.csv" "final" ?????????"Precip" ?????????"Tmax" ??"Tmin"
Coord <- read.csv(list.files(pattern=".csv"),header=TRUE,stringsAsFactors=FALSE) # read coordinates (lat,long)
lfile <- list.files()[!grepl(".csv|final",list.files())] # list other files except .csv and final
files <- ?paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents lst1 <- split(files,gsub(".*\\/(.*)\\.csv","\\1",files)) 
names1 <- gsub(".*\\/(.*)\\/.*\\.csv","\\1",lst1[[1]])
lst1New <- lapply(lst1,function(x) {lst2 <- setNames(lapply(x,function(y)???{dat <- read.table(y,sep=" ",header=TRUE, stringsAsFactors=FALSE);????dat[,1:104]} ), names1); dat2 <- do.call(cbind,lst2);???indx <- grepl("Sim",names(dat2)); dat3 <- dat2[indx]; ?dat4 <- dat2[!indx][,1:4]; names(dat4) <- gsub(".*\\.","",names(dat4));???lapply(split(names(dat3),gsub(".*\\.","",names(dat3))),function(x) ? ???{dat5 <- cbind(dat4,dat3[,x]); dat5$Tmean <- -999.9;??????dat6 <- dat5[,c(1:4,7:6,8,5)];??????colnames(dat6)[2:3] <- format(Coord[match(unique(dat6$Site),Coord$Site),3:2],digits=4);??????dat7 <- dat6[,-4]; mat1 <- as.matrix(dat7); colnames(mat1)[-(2:3)] <- ' ';mat1})}) 
# Change dat to [,1:104] if you need all rows. lst2New <- lapply(lst1New,function(x) {names(x) <- NULL; x}) #head(lst2New[[1]][[1]],4)
#49.53 -96.77 
#[1,] 2000 ???1 ?????1 -9.13 8.23 -999.9 0 
#[2,] 2000 ???1 ?????2 -9.51 0.39 -999.9 0??lapply(names(lst2New),function(x)???{nm1 <- paste(x, names(lst1New[[x]]),sep="_"); ??nm2 <- paste0(paste(paste0(getwd(),"/final"),nm1,sep="/"),".csv"); ??lapply(seq_along(lst1New[[x]]),function(i) {x1 <- lst2New[[x]][[i]]; ??????????????????????????????????????????????write.csv(x1, nm2[i],quote=FALSE,row.names=FALSE)})}) 
#-----------------------------------------------------------------------------
On Wednesday, April 9, 2014 1:29 AM, arun? wrote: Hi Atem, No problem. ?Glad it worked. ?In the first instance, I should have used `[[` instead of `[` in the last line of code, which created the confusion. lapply(...., lst2New[[x]][i]; write.table...) On Wednesday,
April 9, 2014 1:35 AM, Zilefac Elvis? wrote: Wow! You finally fixed it.
I appreciate your endless efforts.
Atem.
On Tuesday, April 8, 2014 11:26 PM, arun? wrote: Hi Atem, If you change colnames(mat1)[-(2:3)] <- ' ' in 'lst1New' lst1New <- lapply(lst1,function(x) {lst2 <- setNames(lapply(x,function(y) {dat <- read.table(y,sep=" ",header=TRUE, stringsAsFactors=FALSE); dat[,1:104]} ), names1); dat2
<- do.call(cbind,lst2); indx <- grepl("Sim",names(dat2)); dat3 <-
dat2[indx];dat4 <- dat2[!indx][,1:4]; names(dat4) <- gsub(".*\\.","",names(dat4)); lapply(split(names(dat3),gsub(".*\\.","",names(dat3))),function(x) ?{dat5 <- cbind(dat4,dat3[,x]); dat5$Tmean <- -999.9; dat6 <- dat5[,c(1:4,7:6,8,5)]; colnames(dat6)[2:3] <- format(Coord[match(unique(dat6$Site),Coord$Site),3:2],digits=4); dat7 <- dat6[,-4]; mat1 <- as.matrix(dat7); colnames(mat1)[-(2:3)] <- ' ';mat1})})??lst2New <- lapply(lst1New,function(x) {names(x) <- NULL; x}) head(lst2New[[1]][[1]],2) 49.53 -96.77 
#[1,] 2000 ????1 ?????1 -9.13 8.23 -999.9 0 
#[2,] 2000 ????1 ?????2 -9.51 0.39 -999.9 0??lapply(names(lst2New),function(x) {nm1 <- paste(x,
names(lst1New[[x]]),sep="_"); nm2 <- paste0(paste(paste0(getwd(),"/final"),nm1,sep="/"),".csv");lapply(seq_along(lst1New[[x]]),function(i) {x1 <- lst2New[[x]][[i]]; write.table(x1, nm2[i],quote=FALSE,row.names=TRUE)})})??##output file 
dat1 <- read.csv(paste(paste(getwd(),"final",sep="/"),"G100_Sim001.csv",sep="/"),header=TRUE,sep=" ",row.names=1)[1:3,1:7] 
mat1N <- as.matrix(dat1) colnames(mat1N) <- gsub("X\\.|X","",dimnames(mat1N)[[2]]) colnames(mat1N)[-(2:3)] <- " " 
mat1N # ??????49.53 96.77 
#1 2000 ????1 ????1 ?-9.13 ?8.23 -999.9 0 #2 2000 ????1 ????2 ?-9.51 ?0.39 -999.9 0 #3 2000????1 ????3 -18.10 -5.67 -999.9 0 
A.K. On Wednesday, April 9, 2014 1:06 AM, arun? wrote: Hi Atem, I slightly modified: lst1New <- lapply(lst1,function(x) {lst2 <- setNames(lapply(x,function(y) {dat <- read.table(y,sep=" ",header=TRUE, stringsAsFactors=FALSE); dat[,1:104]} ), names1); dat2 <- do.call(cbind,lst2); indx <- grepl("Sim",names(dat2)); dat3 <- dat2[indx];dat4 <- dat2[!indx][,1:4]; names(dat4) <- gsub(".*\\.","",names(dat4)); lapply(split(names(dat3),gsub(".*\\.","",names(dat3))),function(x) ?{dat5 <- cbind(dat4,dat3[,x]); dat5$Tmean <-
-999.9; dat6
<- dat5[,c(1:4,7:6,8,5)]; colnames(dat6)[2:3] <- format(Coord[match(unique(dat6$Site),Coord$Site),3:2],digits=4); dat7 <- dat6[,-4]; mat1 <- as.matrix(dat7); colnames(mat1)[-(2:3)] <- "Missval";mat1})})??head(lst1New[[1]][[1]],2)??# ????Missval 49.53 -96.77 Missval Missval Missval Missval??#[1,] ???2000 ????1 ?????1 ??-9.13 ???8.23 ?-999.9 ??????0??#[2,] ???2000 ????1 ?????2 ??-9.51 ???0.39 ?-999.9 ??????0??lst2New <- lapply(lst1New,function(x) {names(x) <- NULL; x}) lapply(names(lst2New),function(x) {nm1 <- paste(x,
names(lst1New[[x]]),sep="_"); nm2
<- paste0(paste(paste0(getwd(),"/final"),nm1,sep="/"),".csv");lapply(seq_along(lst1New[[x]]),function(i) {x1 <- lst2New[[x]][[i]]; write.table(x1, nm2[i],quote=FALSE,row.names=F)})}) ##output file read.csv(paste(paste(getwd(),"final",sep="/"),"G100_Sim001.csv",sep="/"),header=TRUE,sep=" ",check.names=FALSE)[1:3,]
#Missval 49.53 -96.77 Missval Missval Missval Missval
#1 ???2000 ????1 ?????1 ??-9.13 ???8.23 ?-999.9 ??????0
#2 ???2000 ????1 ?????2 ??-9.51 ???0.39 ?-999.9 ??????0
#3 ???2000 ????1 ?????3 ?-18.10 ??-5.67 ?-999.9 ?? ??0??A.K. On Tuesday, April 8, 2014 9:28 PM, Zilefac Elvis? wrote: Hi AK, 
Let's try to use characters other than NA and see what happens. I tried 'Missval' but the Lat and Long had Missval prefixed to it. How can I get rid of any characters in Lat and Long columns? Thanks,
Atem. Hi AK, Thanks for the timely reply.??"Lat" should be on the MONTH ?column while "Long" should be on the DAY column. I guess you did it this way. I will
try the code once
I get to school. Thanks again. Atem.??------ Original Message ------ From : arun
>To : Zilefac Elvis;
>Sent : 08-04-2014 04:44
>Subject : Re: Splitting columns and forming new data files in R
> 
>Hi,
The 'lat' and 'long' names you mentioned correspond to which columns
in the "final" dataset? On Tuesday, April 8, 2014 1:17 AM, Zilefac Elvis ?wrote: Hi AK,
Please I need your help. I finally solved the previous task I sent to you.
I have Precip,Tmin and Tmax in three different folders (attached).
Each
folder
has 4 files with identical names in
all folders (we can match case). Within each file are [,YYY MM DD sim001...sim100] (some files may have more than 100 simulations. Use only the first 100). Q1) Open all three folders, go to file 1 (e.g G100), copy column 1 (sim001, do not copy date) and paste it in a new folder called "final". Do so for column 2 (sim002),...,column 100 (sim100). So from file 1 alone with 100 sims, you will have 100 files in "final". The files in "final" should be labelled for example as G100_sim001, G100_sim002,...,G100_sim100; G101_sim001,G101_sim002 etc. The format of all files in "final" is similar to:
50-110.7
196111-999.9-999.9-999.90
196112-999.9-999.9-999.92.38
196113-999.9-999.9-999.90
196114-999.9-999.9-999.90
196115-999.9-999.9-999.90
196116-999.9-999.9-999.90
196117-999.9-999.9-999.90
196118-999.9-999.9-999.90
196119-999.9-999.9-999.95.19
1961110-999.9-999.9-999.90
1961111-999.9-999.9-999.90
1961112-999.9-999.9-999.90
1961113-999.9-999.9-999.90
1961114-999.9-999.9-999.90
1961115-999.9-999.9-999.90 The columns after the date should be [Tmin,Tmax,Tmean,Precip]. Please do not include column names in output. Output files are .csv. *Fill column "Tmean" with -999.9 in all files. Therefore, using the sample I have provided, you will have 4sites*100 sims = 400 files in folder "final". Q2) From the attached coordinates file, please copy Lat andLong corresponding to the Site and past it in the first row of every file starting with that site code. For example, all files beginning with G100_sim... will have
their first row similar to: ?????49.53-96.7
196111-999.9-999.9-999.90 This looks very cumbersome
for me to handle. ?Thanks very much.
Atem.



From zilefacelvis at yahoo.com  Fri Apr 11 08:13:38 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Thu, 10 Apr 2014 23:13:38 -0700 (PDT)
Subject: [R] Splitting columns  and forming new data files in R
In-Reply-To: <1397193270.91459.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <360473.16801.bm@smtp232.mail.bf1.yahoo.com>
	<1397193270.91459.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1397196818.55548.YahooMailNeo@web160602.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140410/35469446/attachment-0001.pl>

From mbressan at arpa.veneto.it  Fri Apr 11 08:40:42 2014
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 11 Apr 2014 08:40:42 +0200
Subject: [R] print(cenfit object) to a data.frame
In-Reply-To: <5346CE1A.8010600@sapo.pt>
References: <5346C982.20103@arpa.veneto.it> <5346CE1A.8010600@sapo.pt>
Message-ID: <53478E6A.2010600@arpa.veneto.it>

thanks rui, it helps indeed..

at first, I've been trying to data.frame the output of mean (mycenfit) 
by the following:
my.df<-as.data.frame(do.call(rbind, mean(mycenfit)))
and it worked out correctly!

...but because I also needed the information about "n" and "n.cen", 
which are not provided by mean(mycenfit), I had to switch to 
print(mycenfit);
...but unfortunately, print(mycenfit) is not so easy (to me at least) to 
handle

now, I'm looking at a different possible ways to extract the same 
information directly from the object "mycenfit" (S4), which turned out 
to be quite hard (to me again)

any othe possible ideas?

cheers



From smartpink111 at yahoo.com  Fri Apr 11 10:53:20 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Apr 2014 01:53:20 -0700 (PDT)
Subject: [R] Mean of values in different files
In-Reply-To: <1397188527.25131.YahooMailNeo@web160602.mail.bf1.yahoo.com>
References: <1397188527.25131.YahooMailNeo@web160602.mail.bf1.yahoo.com>
Message-ID: <1397206400.82540.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
dir.create("final")
lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2 <-  lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(header1,","));dat1}))

lstYear <- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]]) 


lapply(seq_along(lst2),function(i) {lstN <-lapply(lst2[[i]],function(x) x[,-1]); arr1 <- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res <- cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res) <- gsub("\\_$","",gsub(" ", "_",names(res))); res[,1] <- gsub(" <", "",res[,1]); write.csv(res,paste0(paste(getwd(),"final",names(lst1)[[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)   }) 


A.K.

On Thursday, April 10, 2014 11:55 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

HI AK,
I have finished calculating my statistics and would like to merge the files into 1 files resulting from 100 simulations.

In the attached .zip file, I have 4 files for site G100_ and 4 for site G101_ identified by site code. I have 12000 (120 sites * 100 sims) such files to deal with but I have provided a sample only.

1) Replace any empty spaces (no values) with NA
2) Take the mean of values in each cell

Create a folder called "final" and store the results in it. For this sample, the folder "final" will have two files (G100 and G101). The contents of each file being the mean from 4 files. The headers, rows and columns of files in "final" are exactly the same as those of any file in sample.zip. Headers, rows and columns are the same for all files in sample.zip.

Thanks AK. Please do it at your convenience.
Regards,
Atem.



From chrisege at stud.ntnu.no  Fri Apr 11 10:36:45 2014
From: chrisege at stud.ntnu.no (Chris89)
Date: Fri, 11 Apr 2014 01:36:45 -0700 (PDT)
Subject: [R] General Copula theory
Message-ID: <1397205405072-4688594.post@n4.nabble.com>

Hi everyone!

Firstly, let me specify that I an new to copula theory, so be gentle! 

I have two data sets containing wind data for 14 years, and I am to use
Gumbel marginals and a Gumbel copula. The question is, how will I generate
data from the marginals? 

I have 14 years of data (4 observations each day), so I have taken the
maximum of each year (eliminating seasonality) and then found the parameters
of the corresponding Gumbel distribution. But then what? Should I generate n
values of Gumbel distributed data, get uniform values by the inverse
cumulative, and then put these into the Gumbel copula?

I guess this have to be wrong, but I just can't seem to find a good
procedure on this topic.

Sincerely
Chris




--
View this message in context: http://r.789695.n4.nabble.com/General-Copula-theory-tp4688594.html
Sent from the R help mailing list archive at Nabble.com.



From teresamarso at hotmail.com  Fri Apr 11 11:59:39 2014
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Fri, 11 Apr 2014 09:59:39 +0000
Subject: [R] Variable names in plotCI
In-Reply-To: <DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>,
	<DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
Message-ID: <DUB125-W65AA66C4290BA63E9E62D3B9540@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/7c558a25/attachment-0001.pl>

From simone.gabbriellini at gmail.com  Fri Apr 11 12:43:34 2014
From: simone.gabbriellini at gmail.com (Simone Gabbriellini)
Date: Fri, 11 Apr 2014 12:43:34 +0200
Subject: [R] how to select an element from a vector based on a
	probability
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5CB9768@DKRDSEXC016.vestas.net>
References: <CAEy8Jr0MsF=UMvwmAbmSJY6U=pYxo4Uyk5BSpXgfz3ErmNU=oQ@mail.gmail.com>
	<5346E92B.9000000@sapo.pt>
	<CAEy8Jr2d3shkHn1cmgWaMwFgdKJ+aJZrcjJEdooh7yWXFVBJUQ@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA2766239F4FC1@WAXMXOLYMB025.WAX.wa.lcl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CB9768@DKRDSEXC016.vestas.net>
Message-ID: <CAEy8Jr3rzif9VDsWpk7E9jfaPXcpOCSre34hfiCP1xT2jmHu6g@mail.gmail.com>

Dear Frede,

the initial question was to find probability proportional to the
values, so Rui, Dan and Boris are right...

I think I will go for Boris' solution...

best regards,
Simone

2014-04-11 7:29 GMT+02:00 Frede Aakmann T?gersen <frtog at vestas.com>:
> I think you have calculated the wrong probabilities. Shouldn't it be
>
>> x <- c(2,2,6,2,1,1,1,3)
>> MASS::fractions(table(x)/length(x))
> x
>   1   2   3   6
> 3/8 3/8 1/8 1/8
>>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Nordlund, Dan (DSHS/RDA)
>> Sent: 10. april 2014 22:04
>> To: Simone Gabbriellini; Rui Barradas
>> Cc: r-help at r-project.org
>> Subject: Re: [R] how to select an element from a vector based on a
>> probability
>>
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> > project.org] On Behalf Of Simone Gabbriellini
>> > Sent: Thursday, April 10, 2014 11:59 AM
>> > To: Rui Barradas
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] how to select an element from a vector based on a
>> > probability
>> >
>> > Hello, Rui,
>> >
>> > it does, indeed!
>> >
>> > thanks,
>> > Simone
>> >
>> > 2014-04-10 20:55 GMT+02:00 Rui Barradas <ruipbarradas at sapo.pt>:
>> > > Hello,
>> > >
>> > > Use ?sample.
>> > >
>> > > sample(x, 1, prob = x)
>> > >
>>
>> Just be aware that, in using this method, the probability of selection of a
>> particular value will also be a function of how frequent the value is.  For
>> example,
>>
>> set.seed(7632)
>> x <- c(2,2,6,2,1,1,1,3)
>> table(sample(x, 10000, prob=x, replace=TRUE))
>>
>>    1    2    3    6
>> 1664 3340 1696 3300
>>
>>
>> The probability that a vector position with a value of 1 will be selected is 1/18
>> (in this particular example).  However, the probability that a value of 1 will be
>> selected is 1/6 since there are three 1's.  The probability of selecting the
>> position with a value of 3 is 3/18.  But since there is only one position with a
>> value of 3, the probability of getting the value 1 on any given sample is equal
>> to the probability of getting the value 3.
>>
>>
>>
>>
>> > > Hope this helps,
>> > >
>> > > Rui Barradas
>> > >
>> > > Em 10-04-2014 19:49, Simone Gabbriellini escreveu:
>> > >
>> > >> Hello List,
>> > >>
>> > >> I have an array like:
>> > >>
>> > >> c(4, 3, 5, 4, 2, 2, 2, 4, 2, 6, 6, 7, 5, 5, 5, 10, 10, 11, 10,
>> > >> 12, 10, 11, 9, 12, 10, 36, 35, 36, 36, 36, 35, 35, 36, 37, 35,
>> > >> 35, 38, 35, 38, 36, 37, 36, 36, 37, 36, 35, 35, 36, 36, 35, 35,
>> > >> 36, 35, 38, 35, 35, 35, 36, 35, 35, 35, 6, 5, 8, 6, 6, 7, 1,
>> > >> 7, 7, 8, 9, 7, 8, 7, 7, 13, 13, 13, 14, 13, 13, 13, 14, 14, 15,
>> > >> 15, 14, 13, 14, 39, 39, 39, 39, 39, 39, 41, 40, 39, 39, 39, 39,
>> > >> 40, 39, 39, 41, 41, 40, 39, 40, 41, 40, 41, 40, 40, 40, 39, 41,
>> > >> 39, 39, 39, 39, 40, 39, 39, 40, 40, 39, 39, 39, 1, 4, 3, 4)
>> > >>
>> > >> I would like to pick up an element with a probability proportional
>> > to
>> > >> the element value, thus higher values should be picked up more often
>> > >> than small values (i.e., picking up 38 should be more probable than
>> > >> picking up 3)
>> > >>
>> > >> Do you have any idea on how to code such a rich-get-richer
>> > mechanism?
>> > >>
>> > >> Best regards,
>> > >> Simone
>> > >>
>> > >
>> >
>> >
>> >
>>
>> Dan
>>
>> Daniel J. Nordlund, PhD
>> Research and Data Analysis Division
>> Services & Enterprise Support Administration
>> Washington State Department of Social and Health Services
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
-----------------------------------------------------------------

Simone Gabbriellini, PhD

Post-doctoral Researcher
ANR founded research project "DIFFCERAM"
GEMASS, CNRS & Paris-Sorbonne.

mobile: +39 340 39 75 626
email: simone.gabbriellini at cnrs.fr



From kridox at ymail.com  Fri Apr 11 12:57:37 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 11 Apr 2014 19:57:37 +0900
Subject: [R] Variable names in plotCI
In-Reply-To: <DUB125-W65AA66C4290BA63E9E62D3B9540@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>
	<DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
	<DUB125-W65AA66C4290BA63E9E62D3B9540@phx.gbl>
Message-ID: <CAAcyNCyNq7Uo9jF1cT_+HNBsjsZiscmb0BEyDhWQeAQmMgEY=g@mail.gmail.com>

Hello,

When posting, you are asked to provide a reproducible code (including
packages you are using) and to not post in HTML.

The following might help:

library(plotrix)
y<-runif(10)
err<-runif(10)
plotCI(1:10,y,err,main="Basic plotCI",xaxt='n',xlab='')
axis(1,1:10,LETTERS[1:10])

Regards,
Pascal

On Fri, Apr 11, 2014 at 6:59 PM, M? Teresa Martinez Soriano
<teresamarso at hotmail.com> wrote:
>
> Hello to everyone,
> I would like to put the variable names in the x-axis of this plot instead of number 1:63:
>
> plotCI(1:num_col_comp,med,2.06*des/sqrt(n),lwd=1,col="red",scol="seashell4",main="Intervalo de confianza",xlab="Variables cl?nicas",ylab="Intervalo de confianza")abline(h=0, col="yellowgreen",lwd=1.8)
>
> I don't find the way to do it, I tried with xlab option but it doesn't work and I tried as well creatting a data.frame with the rownames of the variables and the values 1:63
> Any idea will be very appreciated
> Thanks a lot
> An example of the data set could be:y<-runif(10)
>  err<-runif(10)
>  plotCI(1:10,y,err,main="Basic plotCI")
>  plotCI(1:10,y,err,2*err,lwd=2,col="red",scol="blue",
>   main="Add colors to the points and error bars")
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From jim at bitwrit.com.au  Fri Apr 11 12:57:41 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 11 Apr 2014 20:57:41 +1000
Subject: [R] Variable names in plotCI
In-Reply-To: <DUB125-W65AA66C4290BA63E9E62D3B9540@phx.gbl>
References: <DUB125-W60DCB4648C2B8E4AA7F05AB96F0@phx.gbl>,
	<DUB125-W899283365D12C2A77F5601B96F0@phx.gbl>
	<DUB125-W65AA66C4290BA63E9E62D3B9540@phx.gbl>
Message-ID: <5347CAA5.1080405@bitwrit.com.au>

On 04/11/2014 07:59 PM, M? Teresa Martinez Soriano wrote:
>
> Hello to everyone,
> I would like to put the variable names in the x-axis of this plot instead of number 1:63:
>
> plotCI(1:num_col_comp,med,2.06*des/sqrt(n),lwd=1,col="red",scol="seashell4",main="Intervalo de confianza",xlab="Variables cl?nicas",ylab="Intervalo de confianza")abline(h=0, col="yellowgreen",lwd=1.8)
>
> I don't find the way to do it, I tried with xlab option but it doesn't work and I tried as well creatting a data.frame with the rownames of the variables and the values 1:63
> Any idea will be very appreciated
> Thanks a lot
> An example of the data set could be:y<-runif(10)
>   err<-runif(10)
>   plotCI(1:10,y,err,main="Basic plotCI")
>   plotCI(1:10,y,err,2*err,lwd=2,col="red",scol="blue",
>    main="Add colors to the points and error bars")
>   		 	   		
Hi Teresa,
Seems to be plotCI from plotrix, so try:

plotCI(1:10,y,err,main="Basic plotCI",xaxt="n")
xlabs<-c("one","two","three","four","five","six",
"seven","eight","nine","ten")
staxlab(1,at=1:10,labels=xlabs)

Jim



From info at aghmed.fsnet.co.uk  Fri Apr 11 13:15:03 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 11 Apr 2014 12:15:03 +0100
Subject: [R] Meta-analysis of prevalence at the country level with
 mgcv/gamm4
In-Reply-To: <CAL49zWPSEFD_sB6VJUr7V_whijSa3TMHTAh5jn9e1SN_vL2Hig@mail.g
	mail.com>
References: <CAL49zWPSEFD_sB6VJUr7V_whijSa3TMHTAh5jn9e1SN_vL2Hig@mail.gmail.com>
Message-ID: <Zen-1WYZQO-0005eP-5V@smarthost01a.mail.zen.net.uk>

At 13:17 10/04/2014, Julien Riou wrote:
> >
> > Message: 11
> > Date: Wed, 09 Apr 2014 18:39:30 +0100
> > From: Michael Dewey <info at aghmed.fsnet.co.uk>
> > To: Julien Riou <julien.riou.k at gmail.com>, r-help at r-project.org
> > Subject: Re: [R] Meta-analysis of prevalence at the country level with
> >         mgcv/gamm4
> > Message-ID: <Zen-1WXwTL-0005q4-0V at smarthost01a.mail.zen.net.uk>
> > Content-Type: text/plain; charset="us-ascii"; format=flowed
> >
>
>
>Hi Michael,
>
>Thank you for taking the time to help me.
>
>  So the first UK study with a median age of 25 is going to be used to
> > estimate prevalence over a range of ages? You are going to have to
> > make some very strong assumptions here which I personally would not
> > want to make.
> >
>
>I'm a little confused by this. In my understanding, the mixed-effects model
>does not do that. The slope of the relation between age and prevalence will
>be estimated from the full pool of studies, and the country-level random
>intercept will be estimated from all studies in the country. So the
>assumption here is that the relation between age and incidence is the same
>in every country, which is quite reasonable. Of course, there will be more
>uncertainty with the estimation of the random intercept if there is few
>studies in a country, or if there is a strong inter-study variance in a
>country. This will influence the confidence interval of the random
>intercept, and so the CI of the predicted prevalence for this country.

Your studies are ecological. You are estimating the relationship 
between prevalence and being in a study of median age X which is not 
necessarily the same as the relationship between prevalence and being 
a person of age X.



>Is there any possibility that in the real dataset you can fit your
> > model to those studies which do provide age-specific prevalences and
> > then use that to impute?
> >
> > You do not say when these studies were published but I would ask the
> > authors of the primary studies if they can make the information
> > available to you. You may have already done that of course. I referee
> > quite a few papers on systematic reviews and my impression is that
> > some authors are amenable to doing the work for you. You mileage may
> > vary of course.
> >
>
>Yes, it would be easier to have prevalence for age subgroups of studies,
>but we did not have access to that information for most studies even after
>contacting the authors.
>
>
> > >*Standard random-effect meta-analysis* with package meta.
> > >
> > >I used metaprop() to get a first estimate of the prevalence in each
> > country
> > >without taking age into account, and to obtain weights. As expected,
> > >heterogeneity was very high, so I used weights from the random-effects
> > >model.
> >
> > Which will be nearly equal and so hardly worth using in my opinion
> > but again your mileage may vary.
> >
>
>The weights from the random-effects method were actually far from equals,
>as sample size was highly variable between studies. With the RE method,
>small studies have much more impact.
>
>
> > I am afraid that is the way with systematic reviews, you can only
> > synthesise what you find, not what you would like to have found.
> > Anyone who has done a review will sympathise with you, not that that
> > is any consolation.
> >
>
>I'm not sure I'm following your point. My objective is to synthesise the
>included studies, while taking the age factor into account, since it is
>strongly linked to prevalence and very heterogeneous. The alternative is to
>only include studies with low median age, but I would lose a lot of
>information.
>
>Thank you again,
>Julien
>
> >
> >
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From laura.lee at ncdenr.gov  Fri Apr 11 15:38:33 2014
From: laura.lee at ncdenr.gov (Lee, Laura)
Date: Fri, 11 Apr 2014 13:38:33 +0000
Subject: [R] weights error in svyglm
Message-ID: <2789D349964A854E9524A3CD0D759E042DC97C28@NCWWDITMXMBX35.ad.ncmail>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/39b40f82/attachment-0001.pl>

From milan.cisty at stuba.sk  Fri Apr 11 13:06:22 2014
From: milan.cisty at stuba.sk (Milan Cisty)
Date: Fri, 11 Apr 2014 13:06:22 +0200
Subject: [R] grabbing GIS data from www
Message-ID: <002201cf5576$12c50f40$384f2dc0$@stuba.sk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/d9db4666/attachment-0001.pl>

From davide.viggiano at libero.it  Fri Apr 11 15:44:28 2014
From: davide.viggiano at libero.it (davide.viggiano)
Date: Fri, 11 Apr 2014 06:44:28 -0700 (PDT)
Subject: [R] Concave hull
In-Reply-To: <200911251637.36211.ct529@york.ac.uk>
References: <200911251637.36211.ct529@york.ac.uk>
Message-ID: <1397223868562-4688606.post@n4.nabble.com>

Hi, I just want to add a possible solution to the problem in the special case
all the points must stay on the edge of the outline. THis is sometimes the
case when doing image analysis and you want to order the points along a
closed path.
In this specific case, you can use some algorithm like the traveling
salesman problem, which would give you the shortest path along all your
points.
In this scenario, if your points are xy, you may use the following:

library(TSP)
tsp <- TSP(dist(xy))
tour <- solve_TSP(tsp,method='farthest')
xy <- xy[tour,]

THis may not be the most economical solution (and you might also want
contrains such as never to intersect the path) and is not valid if your
boundary is not supposed to pass through all points.




--
View this message in context: http://r.789695.n4.nabble.com/Concave-hull-tp863710p4688606.html
Sent from the R help mailing list archive at Nabble.com.



From eliza_botto at hotmail.com  Fri Apr 11 17:19:14 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 11 Apr 2014 15:19:14 +0000
Subject: [R] operating website through R
Message-ID: <BLU170-W66536136558DD6F007F2AE89540@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/618885ad/attachment-0001.pl>

From msuzen at gmail.com  Fri Apr 11 17:31:18 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Fri, 11 Apr 2014 17:31:18 +0200
Subject: [R] operating website through R
In-Reply-To: <BLU170-W66536136558DD6F007F2AE89540@phx.gbl>
References: <BLU170-W66536136558DD6F007F2AE89540@phx.gbl>
Message-ID: <CAPtbhHwf+UbY5vdPtM5kJEDFNoPp3WkTKHWL0AS91Y+=rMBQ4Q@mail.gmail.com>

You just need to pass the parameters on Giovanni_cgi.pl with action=ASCII+Output

On 11 April 2014 17:19, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear Users of R,
> I wanted to operate certain slots of this website (http://disc2.nascom.nasa.gov/Giovanni/tovas/TRMM_V7.3B42_daily.2.shtml) through R. I wanted to operate Latitude, longitude section, plot type, begin and end year and ASCII Output Resolution. The filling of these slot will produce and output file with I want to D/L at a certain location in my PC.
> I have a matrix of 2 columns and 3000 rows which contain Latitude and Longitude information which i want to upload automatically in the slots of website. I tried to use certain web scarping techniques in R but to no use.
> Is there a way of doing it in R.
> thank you very much in advance,
> Eliza
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nalimilan at club.fr  Fri Apr 11 17:36:52 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 11 Apr 2014 17:36:52 +0200
Subject: [R] weights error in svyglm
In-Reply-To: <2789D349964A854E9524A3CD0D759E042DC97C28@NCWWDITMXMBX35.ad.ncmail>
References: <2789D349964A854E9524A3CD0D759E042DC97C28@NCWWDITMXMBX35.ad.ncmail>
Message-ID: <1397230612.4791.8.camel@milan>

Le vendredi 11 avril 2014 ? 13:38 +0000, Lee, Laura a ?crit :
> Hi!
> 
> I am just learning the 'svyglm' package and have run into an error for
> which I have not found a solution. My data have been collected from a
> stratified random survey. Here is the code:
> 
> NB3<-glm.nb(COLNUM~Year+Depth+MESH+offset(LogEffort),data=data)
> 
> dstrat <- svydesign(id=~1, strata=~STRATA, weights = ~weight,
> data=data)
> 
> SNB3 <- svyglm(NB3, design=dstrat)
> 
> The error that is returned is:
> 
> Error in model.frame.glm(formula = list(coefficients =
> c(-6.96858807641624,  :
>   object '.survey.prob.weights' not found
> 
> I would appreciate any assistance in solving this problem.
The error is somewhat strange, but you should not pass the result of
glm.nb() to svyglm (where have you found this idea?). Just do
SNB3 <- svyglm(COLNUM ~ Year + Depth + MESH + offset(LogEffort), design=dstrat)


Regards



From jgrn at illinois.edu  Fri Apr 11 17:42:02 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 11 Apr 2014 10:42:02 -0500
Subject: [R] StatET and R 3.1.0
Message-ID: <CABG0rfvKTcN3s5eX0kLV591PUcZiZb3rGn5GytTpqmseZS2dRA@mail.gmail.com>

R-helpers:

I posted a message to the statet listserv, but I thought I'd ask here
as well since it is one of the major R developer environments-- has
anyone gotten the StatET plugin for Eclipse working with R 3.1.0 yet?
Any tricks?  I did manage to get rj updated to 2.0 via:

install.packages(c("rj", "rj.gd"),
repos="http://download.walware.de/rj-2.0",type="source")

But the plugin is throwing an error (using the last maintenance update
at http://download.walware.de/eclipse-4.3/testing):

Launching the R Console was cancelled, because it seems starting the R
engine failed.  Please make sure that R package 'rj' (1.1 or
compatible) is installed
and that the R library paths are set correctly for the R environment
configuration 'R'.

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007



From eliza_botto at hotmail.com  Fri Apr 11 17:45:37 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 11 Apr 2014 15:45:37 +0000
Subject: [R] operating website through R
In-Reply-To: <CAPtbhHwf+UbY5vdPtM5kJEDFNoPp3WkTKHWL0AS91Y+=rMBQ4Q@mail.gmail.com>
References: <BLU170-W66536136558DD6F007F2AE89540@phx.gbl>,
	<CAPtbhHwf+UbY5vdPtM5kJEDFNoPp3WkTKHWL0AS91Y+=rMBQ4Q@mail.gmail.com>
Message-ID: <BLU170-W84F01FE8525C50D324CA7489540@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/3b1699dd/attachment-0001.pl>

From nalimilan at club.fr  Fri Apr 11 17:49:19 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 11 Apr 2014 17:49:19 +0200
Subject: [R] sink() and UTF-8 on non-UTF-8 systems
Message-ID: <1397231359.4791.12.camel@milan>

Hi!

In the series "dealing with encoding madness on hostile systems", I'm
looking for help as regards capturing R UTF-8 output on a system where
the locale is not using UTF-8, and where some characters cannot even be
represented using the locale encoding. The case I have in mind is
printing a character vector with Russian text to the R Commander output
window on an English/French (CP1252) Windows system.

Here's a code snippet illustrating the problem:
> "\U41F"
[1] "?" # OK
> con <- file(open="w+", encoding="UTF-8")
> capture.output(cat("\U41F"), file=con)
> readLines(con, encoding="UTF-8")
[1] "<U+041F>" # Not OK

(same result without specifying 'encoding')


Now I have read ?sink and it is quite explicit about how this works:
> If file is a character string, the file will be opened using the
> current encoding. If you want a different encoding (e.g. to represent
> strings which have been stored in UTF-8), use a file connection ? but
> some ways to produce R output will already have converted such strings
> to the current encoding. 

The last words seem to apply to the case above, i.e. somewhere in the
process the UTF-8 string is converted to the locale encoding. Is there
any solution to get the correct output?


Thanks


> sessionInfo()
R Under development (unstable) (2014-04-10 r65396)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252   
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_France.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



From laura.lee at ncdenr.gov  Fri Apr 11 17:54:29 2014
From: laura.lee at ncdenr.gov (Lee, Laura)
Date: Fri, 11 Apr 2014 15:54:29 +0000
Subject: [R] weights error in svyglm
In-Reply-To: <1397230612.4791.8.camel@milan>
References: <2789D349964A854E9524A3CD0D759E042DC97C5F@NCWWDITMXMBX35.ad.ncmail>
	<2789D349964A854E9524A3CD0D759E042DC97C28@NCWWDITMXMBX35.ad.ncmail>
	<1397230612.4791.8.camel@milan>
Message-ID: 1397231671352-015-00959326.laura.lee.ncdenr.gov@smtp.mail.nc.gov

Thanks! That worked. However, what error distribution is assumed? I was hoping to use a negative binomial.

-----Original Message-----
From: Milan Bouchet-Valat [mailto:nalimilan at club.fr] 
Sent: Friday, April 11, 2014 11:37 AM
To: Lee, Laura
Cc: r-help at r-project.org
Subject: Re: [R] weights error in svyglm

Le vendredi 11 avril 2014 ? 13:38 +0000, Lee, Laura a ?crit :
> Hi!
> 
> I am just learning the 'svyglm' package and have run into an error for 
> which I have not found a solution. My data have been collected from a 
> stratified random survey. Here is the code:
> 
> NB3<-glm.nb(COLNUM~Year+Depth+MESH+offset(LogEffort),data=data)
> 
> dstrat <- svydesign(id=~1, strata=~STRATA, weights = ~weight,
> data=data)
> 
> SNB3 <- svyglm(NB3, design=dstrat)
> 
> The error that is returned is:
> 
> Error in model.frame.glm(formula = list(coefficients = 
> c(-6.96858807641624,  :
>   object '.survey.prob.weights' not found
> 
> I would appreciate any assistance in solving this problem.
The error is somewhat strange, but you should not pass the result of
glm.nb() to svyglm (where have you found this idea?). Just do
SNB3 <- svyglm(COLNUM ~ Year + Depth + MESH + offset(LogEffort), design=dstrat)


Regards

From smartpink111 at yahoo.com  Fri Apr 11 18:47:53 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Apr 2014 09:47:53 -0700 (PDT)
Subject: [R] Mean not working in function
Message-ID: <1397234873.4642.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
mysummary <- function(dataf){ for(name in names(dataf)){ cat ("Variable name: ", name, ": Mean=", mean(dataf[,name],na.rm=TRUE),"\n") }
}?

##Using some example data:

set.seed(48)
dat1 <- as.data.frame(matrix(sample(c(NA,1:20),4*20,replace=TRUE),ncol=4)) mysummary(dat1)
#Variable name:  V1 : Mean= 11.64706
#Variable name:  V2 : Mean= 10.88889
#Variable name:  V3 : Mean= 12.35 

#Variable name:  V4 : Mean= 10.52632 


#Another way would be:

mysummary2 <- function(dataf){ cat(paste(paste("Variable name: ", names(dataf), ": Mean=", format(colMeans(dataf,na.rm=TRUE),digits=7),collapse="\n"),"\n"))
}
mysummary2(dat1) 

#Variable name:  V1 : Mean= 11.64706
#Variable name:  V2 : Mean= 10.88889
#Variable name:  V3 : Mean= 12.35000
#Variable name:  V4 : Mean= 10.52632 


A.K.


I am trying following function: mysummary <- function(dataf){ for(name in names(dataf)){ cat ("Variable name: ", name, ": Mean=", mean(name),"\n") }
} The variable name is properly picked up but the mean is shows as NA. The command warnings() show:
In mean.default(name) : argument is not numeric or logical: returning NA



From alpeshpandya at gmail.com  Fri Apr 11 17:10:48 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Fri, 11 Apr 2014 11:10:48 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
Message-ID: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/482eb747/attachment-0001.pl>

From nalimilan at club.fr  Fri Apr 11 19:11:55 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 11 Apr 2014 19:11:55 +0200
Subject: [R] weights error in svyglm
In-Reply-To: <2789D349964A854E9524A3CD0D759E042DC97C5F@NCWWDITMXMBX35.ad.ncmail>
References: <2789D349964A854E9524A3CD0D759E042DC97C28@NCWWDITMXMBX35.ad.ncmail>
	<1397230612.4791.8.camel@milan>
	<2789D349964A854E9524A3CD0D759E042DC97C5F@NCWWDITMXMBX35.ad.ncmail>
Message-ID: <1397236315.4791.15.camel@milan>

Le vendredi 11 avril 2014 ? 15:54 +0000, Lee, Laura a ?crit :
> Thanks! That worked. However, what error distribution is assumed? I
> was hoping to use a negative binomial.
Since svyglm() computes designed-based standard errors, you should be
able to simply pass family=poisson instead. See
books.google.fr/books?id=L96ludyhFBsC&pg=SA10-PA44
and following sections.


Regards



From eliza_botto at hotmail.com  Fri Apr 11 20:36:27 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 11 Apr 2014 18:36:27 +0000
Subject: [R] calling in inverted commas
Message-ID: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/ec303145/attachment-0001.pl>

From tomassini at vetmed.wsu.edu  Fri Apr 11 20:37:33 2014
From: tomassini at vetmed.wsu.edu (Tomassini, Letizia)
Date: Fri, 11 Apr 2014 18:37:33 +0000
Subject: [R] partitioning around medoids
Message-ID: <3F4102760B8F244D898E18B27710D44489935266@CVM76.vetmed.wsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/aa8cec07/attachment-0001.pl>

From HDoran at air.org  Fri Apr 11 20:48:08 2014
From: HDoran at air.org (Doran, Harold)
Date: Fri, 11 Apr 2014 18:48:08 +0000
Subject: [R] Save file as Fixed Width using sprintf()
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/1b8c3fd7/attachment-0001.pl>

From smartpink111 at yahoo.com  Fri Apr 11 22:10:48 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Apr 2014 13:10:48 -0700 (PDT)
Subject: [R] Save file as Fixed Width using sprintf()
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>
Message-ID: <1397247048.24612.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
May be this helps:
xx <- paste(aa, collapse=' ')
set.seed(14) 
myMat <- matrix(rnorm(9), 3,3) 
sprintf(xx,myMat[,1],myMat[,2],myMat[,3])
# [1] "-0.661850 1.497154 -0.064881"
# "1.718954 -0.036141 1.068994"
# [3] "2.121667 1.231945 -0.376965" 

do.call(sprintf,c(xx,split(myMat,col(myMat)))) 
#[1] "-0.661850 1.497154 -0.064881" 
#"1.718954 -0.036141 1.068994" 
#[3] "2.121667 1.231945 -0.376965" 
A.K.



On Friday, April 11, 2014 3:56 PM, "Doran, Harold" <HDoran at air.org> wrote:
I have working code to write a file out as fwf as shown below. I have one question to try and automate this I cannot get to work.

I am generating thousands of data files for a simulation to be run outside of R and each file varies in its dimensions. So I am trying to write code that can write the fwf based on the dimensions of each file generated as shown below. I have commented this code with an example to show where I am stuck.

### Create a sample data matrix
myMat <- matrix(rnorm(9), 3,3)

### Create the vector of format strings to be equal to the length of the columns in myMat
aa <- rep('%4f', ncol(myMat))
xx <- paste(aa, sep='', collapse='')

### Now I could just do this below and it works
(out <- sprintf(xx, myMat[, 1], myMat[, 2], myMat[, 3]) )
out <- as.matrix(out) # convert to a character matrix
dimnames(out) <- list(rep('', nrow(out)), '') # blank row and column names
noquote(out) ## sink this file to a directory

But, the fact that the dimensions of my matrix vary at each iteration means I need to automate this part in the sprint().

myMat[, 1], myMat[, 2], myMat[, 3])

I think that's needed because something like the following does not work

(out <- sprintf(xx, myMat[, 1:3]) )


So, I thought about trying smoething like this
cols <- paste(paste('myMat[, ', 1:ncol(myMat), sep=''), ']', sep='')
cols <- paste(cols, collapse=', ')

But, this is a string with quotation marks, so I thought using cat() might work, but it does not

(out <- sprintf(xx, cat(cols) ) )

Anyone have a suggestion for the right way to do this, this is getting messy.

Thank
Harold

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jholtman at gmail.com  Fri Apr 11 22:38:38 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 11 Apr 2014 16:38:38 -0400
Subject: [R] Save file as Fixed Width using sprintf()
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>
Message-ID: <CAAxdm-5ZuQv0fEMcj3iXT9DhvOCEhHr7v28vBbbqnf4qX+zRYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/7353f67d/attachment-0001.pl>

From friendly at yorku.ca  Fri Apr 11 22:40:47 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 11 Apr 2014 16:40:47 -0400
Subject: [R] adding a frequency variable to a data frame
Message-ID: <5348534F.6050901@yorku.ca>

I'm sure this is pretty simple, but it's Friday afternoon, and I just 
don't see it...

In a data frame with a categorical/character factor, I want to add another
column giving, for each observation, the frequency of that factor level.

An example, where the variable of interest is family:

 > data("Donner", package="vcdExtra")
 > str(Donner)
'data.frame':   90 obs. of  5 variables:
  $ family  : Factor w/ 10 levels "Breen","Donner",..: 9 1 1 1 1 1 1 1 1 
1 ...
  $ age     : int  23 13 1 5 14 40 51 9 3 8 ...
  $ sex     : Factor w/ 2 levels "Female","Male": 2 2 1 2 2 1 2 2 2 2 ...
  $ survived: int  0 1 1 1 1 1 1 1 1 1 ...
  $ death   : POSIXct, format: "1846-12-29" NA ...
 > table(Donner$family)

     Breen    Donner      Eddy  FosdWolf    Graves  Keseberg McCutchen 
MurFosPik
         9        14         4         4        10 4         3        12
     Other      Reed
        23         7
 >

Here, I want to create a new variable, family.size,   where all the 
Breens have 9,
the Donners, 14,  and so on...

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From djandrija at gmail.com  Fri Apr 11 22:51:00 2014
From: djandrija at gmail.com (Andrija Djurovic)
Date: Fri, 11 Apr 2014 22:51:00 +0200
Subject: [R] adding a frequency variable to a data frame
In-Reply-To: <5348534F.6050901@yorku.ca>
References: <5348534F.6050901@yorku.ca>
Message-ID: <CABcwgRRDmDmOtzPvTxyPji5+rY5PnSHajWetyRCH-NaDb25Nvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/47a85160/attachment-0001.pl>

From djandrija at gmail.com  Fri Apr 11 22:57:06 2014
From: djandrija at gmail.com (Andrija Djurovic)
Date: Fri, 11 Apr 2014 22:57:06 +0200
Subject: [R] adding a frequency variable to a data frame
In-Reply-To: <CABcwgRRDmDmOtzPvTxyPji5+rY5PnSHajWetyRCH-NaDb25Nvw@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<CABcwgRRDmDmOtzPvTxyPji5+rY5PnSHajWetyRCH-NaDb25Nvw@mail.gmail.com>
Message-ID: <CABcwgRR1chc-ZMm8CLGo8YuHhLA0r4HKb6oxHK-Yp-QMUGVnkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140411/f5f8d679/attachment-0001.pl>

From JSorkin at grecc.umaryland.edu  Fri Apr 11 23:00:06 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 17:00:06 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <5348534F.6050901@yorku.ca>
References: <5348534F.6050901@yorku.ca>
Message-ID: <53481F96020000CB0010724B@smtp.medicine.umaryland.edu>

I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server. I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
Thank you,
John 

 
 

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From lianoglou.steve at gene.com  Fri Apr 11 23:23:22 2014
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Fri, 11 Apr 2014 14:23:22 -0700
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
Message-ID: <CAHA9McPGDEYxxfqFssHgN57e3O5PcA82eerxmwBO241kQ4bhVw@mail.gmail.com>

Hi,

On Fri, Apr 11, 2014 at 2:00 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> I bemoan the fact that I can not run R or Rstudio on my iPad.

I feel like this is something I'm not missing much, at all, but
different strokes ... :-)

> A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server. I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.

You might try to follow the instructions to get RStudio Server running:

https://www.rstudio.com/ide/docs/server/getting_started

It seems like they have packages built for many popular linux distros:

https://www.rstudio.com/ide/download/server

Once your linux server is set up, you should be able to access the
server with any client via a web browser, although I have no idea if
any of the iOS browsers are up to the task of dealing with the RStudio
web interface, but you can try and find out. RStudio's support forum
is more likely to be helpful here, for instance:

https://support.rstudio.com/hc/en-us/search?utf8=?&query=ios&commit=Search

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech



From friendly at yorku.ca  Fri Apr 11 23:25:55 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 11 Apr 2014 17:25:55 -0400
Subject: [R] adding a frequency variable to a data frame
In-Reply-To: <CABcwgRR1chc-ZMm8CLGo8YuHhLA0r4HKb6oxHK-Yp-QMUGVnkQ@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>	<CABcwgRRDmDmOtzPvTxyPji5+rY5PnSHajWetyRCH-NaDb25Nvw@mail.gmail.com>
	<CABcwgRR1chc-ZMm8CLGo8YuHhLA0r4HKb6oxHK-Yp-QMUGVnkQ@mail.gmail.com>
Message-ID: <53485DE3.9040007@yorku.ca>

Bingo! That's exactly the idiom I was looking for.
Thanks, Andrija.
-Michael


On 4/11/2014 4:57 PM, Andrija Djurovic wrote:
> another:
>
> ave(as.numeric(Donner$family), Donner$family, FUN=length)
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From JSorkin at grecc.umaryland.edu  Fri Apr 11 23:34:33 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 17:34:33 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <CAHA9McPGDEYxxfqFssHgN57e3O5PcA82eerxmwBO241kQ4bhVw@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CAHA9McPGDEYxxfqFssHgN57e3O5PcA82eerxmwBO241kQ4bhVw@mail.gmail.com>
Message-ID: <534827A9020000CB0010725F@smtp.medicine.umaryland.edu>

Steve, 
Thank you for your help.
I have seen the material you have sent me to, but do not fully
understand it. Do I have to build a linux server first? If so does it
have to run Apache or some other web server? Is RStudio server run under
Apache, if so how? On the other hand, do I simply need a box running a
flavor of Linux (without Apache)., and then simply download RStudio
server? Perhaps I am over thinking this . . .
Thanks,
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Steve Lianoglou <lianoglou.steve at gene.com> 4/11/2014 5:23 PM >>>
Hi,

On Fri, Apr 11, 2014 at 2:00 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> I bemoan the fact that I can not run R or Rstudio on my iPad.

I feel like this is something I'm not missing much, at all, but
different strokes ... :-)

> A possible work around would be to set up a server (probably under
Linux), and get the server to present a web page that to would allow me
to run R on the server. I have searched the web for a clear, simple
answer on how to do this but can not find one. There are answers, but
not for someone who has not built a Linux server. Can someone provide
either a reference to, or a short explanation of how I can build the
server, get R or RStudio to run on it, and get the server and its R or
RStudio program available to me on my iPad? I can probably find guidance
on how to build an Apache server under Linux.

You might try to follow the instructions to get RStudio Server
running:

https://www.rstudio.com/ide/docs/server/getting_started

It seems like they have packages built for many popular linux distros:

https://www.rstudio.com/ide/download/server

Once your linux server is set up, you should be able to access the
server with any client via a web browser, although I have no idea if
any of the iOS browsers are up to the task of dealing with the RStudio
web interface, but you can try and find out. RStudio's support forum
is more likely to be helpful here, for instance:

https://support.rstudio.com/hc/en-us/search?utf8=?&query=ios&commit=Search

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech


Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information.  Any unauthorized use, disclosure or distribution is
prohibited.  If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From lianoglou.steve at gene.com  Fri Apr 11 23:51:36 2014
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Fri, 11 Apr 2014 14:51:36 -0700
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <534827A9020000CB0010725F@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CAHA9McPGDEYxxfqFssHgN57e3O5PcA82eerxmwBO241kQ4bhVw@mail.gmail.com>
	<534827A9020000CB0010725F@smtp.medicine.umaryland.edu>
Message-ID: <CAHA9McNuy+jbOQS6aWk7jkkyV+AWiOtogAbzhdWRokuug79FcQ@mail.gmail.com>

I see. You might indeed be over thinking it ... since everything is
installable by the package manager for the flavor of linux you choose,
it should actually be relatively straightfoward (although if this is
your first time setting up a linux box, it can take a few tries).

I'll assume you are using an ubuntu server. There are two things you
can do to get one

(1) Get yourself a "spare" CPU. Blow out the OS on it, and setup
"vanilla" ubuntu; or
(2) Rent an ubuntu server from somewhere like linode.com

Then:

(a) Install R on it, by following the instructions here:
http://cran.rstudio.com/bin/linux/ubuntu/README.html

Which boils down to basically:
(i) adding the appropriate line to your `/etc/apt/sources.list` given
the version of ubuntu you installed (saucy, quantal, etc) ; and
(ii) Running the following from the terminal:

   sudo apt-get update
   sudo apt-get install r-base
   sudo apt-get install r-base-dev

(b) Install RStudio Server. Start from the "Download and Install"
section here (since you already installed R):
https://www.rstudio.com/ide/download/server

Then go here:
https://www.rstudio.com/ide/docs/server/getting_started

If you've set this up on your own machine (option (1) from above) then
you have to figure out how to connect it to the internet if you want
to use it from anywhere outside of your LAN.

It might seem like a lot of work, but as mentioned above -- since
these packages are available by the system's package manager, all of
the dependencies (like apache (if you need it)) will be installed for
you if you follow the (presumably correct) installation instructions
from RStudio.

=== An even easier setup ===

Just realized that there is  3rd route. You can save yourself a lot of
time by using an already built amazon machine instance that the
bioconductor folks have setup for you. Look at the instructions here:

http://www.bioconductor.org/help/bioconductor-cloud-ami/

If you follow along (you'll need an amazon account), you can rent a
machine and have it loaded w/ RStudio Server as well as some
bioconductor-specific libraries to get you started (by using the
bioconductor AMI). Once you have that up, you can connect to the
server running on Amazon's cloud via your web browser on both your CPU
(to make sure it all worked) then using an iOS device.

This would be a very easy way for you to see if taking one of the 2
avenues of setting up RStudio Server yourself would be worth the pain.

HTH,
-steve

On Fri, Apr 11, 2014 at 2:34 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Steve,
> Thank you for your help.
> I have seen the material you have sent me to, but do not fully
> understand it. Do I have to build a linux server first? If so does it
> have to run Apache or some other web server? Is RStudio server run under
> Apache, if so how? On the other hand, do I simply need a box running a
> flavor of Linux (without Apache)., and then simply download RStudio
> server? Perhaps I am over thinking this . . .
> Thanks,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Steve Lianoglou <lianoglou.steve at gene.com> 4/11/2014 5:23 PM >>>
> Hi,
>
> On Fri, Apr 11, 2014 at 2:00 PM, John Sorkin
> <JSorkin at grecc.umaryland.edu> wrote:
>> I bemoan the fact that I can not run R or Rstudio on my iPad.
>
> I feel like this is something I'm not missing much, at all, but
> different strokes ... :-)
>
>> A possible work around would be to set up a server (probably under
> Linux), and get the server to present a web page that to would allow me
> to run R on the server. I have searched the web for a clear, simple
> answer on how to do this but can not find one. There are answers, but
> not for someone who has not built a Linux server. Can someone provide
> either a reference to, or a short explanation of how I can build the
> server, get R or RStudio to run on it, and get the server and its R or
> RStudio program available to me on my iPad? I can probably find guidance
> on how to build an Apache server under Linux.
>
> You might try to follow the instructions to get RStudio Server
> running:
>
> https://www.rstudio.com/ide/docs/server/getting_started
>
> It seems like they have packages built for many popular linux distros:
>
> https://www.rstudio.com/ide/download/server
>
> Once your linux server is set up, you should be able to access the
> server with any client via a web browser, although I have no idea if
> any of the iOS browsers are up to the task of dealing with the RStudio
> web interface, but you can try and find out. RStudio's support forum
> is more likely to be helpful here, for instance:
>
> https://support.rstudio.com/hc/en-us/search?utf8=?&query=ios&commit=Search
>
> HTH,
> -steve
>
> --
> Steve Lianoglou
> Computational Biologist
> Genentech
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:21}}



From h.wickham at gmail.com  Sat Apr 12 00:01:17 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 11 Apr 2014 18:01:17 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
Message-ID: <CABdHhvF7Rg-3HG+4_iEDVJfxjkYsP6ChpggmbUaJNWT9vpS2zA@mail.gmail.com>

Even if you do get Rstudio running on a server, unfortunately it won't
help. The ipad doesn't support quite enough html to get a fully
functional Rstudio interface - almost everything works but you can't
type anything :/  It would be possible to fix this, but fundamentally
we don't believe that the Rstudio interface is the right choice for an
ipad.

Hadley

On Fri, Apr 11, 2014 at 5:00 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server. I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
> Thank you,
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:19}}



From JSorkin at grecc.umaryland.edu  Sat Apr 12 00:05:10 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 18:05:10 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <CAHA9McNuy+jbOQS6aWk7jkkyV+AWiOtogAbzhdWRokuug79FcQ@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CAHA9McPGDEYxxfqFssHgN57e3O5PcA82eerxmwBO241kQ4bhVw@mail.gmail.com>
	<534827A9020000CB0010725F@smtp.medicine.umaryland.edu>
	<CAHA9McNuy+jbOQS6aWk7jkkyV+AWiOtogAbzhdWRokuug79FcQ@mail.gmail.com>
Message-ID: <53482ED6020000CB00107274@smtp.medicine.umaryland.edu>

Steve,
Are you suggesting that all I need to is build a Linux box (easily
done, I have done many) and them simply use the package manager to
install RStudio server? This would mean I don't need to build an Apache
Server with a LAMP stack, hooray!
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Steve Lianoglou <lianoglou.steve at gene.com> 4/11/2014 5:51 PM >>>
I see. You might indeed be over thinking it ... since everything is
installable by the package manager for the flavor of linux you choose,
it should actually be relatively straightfoward (although if this is
your first time setting up a linux box, it can take a few tries).

I'll assume you are using an ubuntu server. There are two things you
can do to get one

(1) Get yourself a "spare" CPU. Blow out the OS on it, and setup
"vanilla" ubuntu; or
(2) Rent an ubuntu server from somewhere like linode.com

Then:

(a) Install R on it, by following the instructions here:
http://cran.rstudio.com/bin/linux/ubuntu/README.html

Which boils down to basically:
(i) adding the appropriate line to your `/etc/apt/sources.list` given
the version of ubuntu you installed (saucy, quantal, etc) ; and
(ii) Running the following from the terminal:

   sudo apt-get update
   sudo apt-get install r-base
   sudo apt-get install r-base-dev

(b) Install RStudio Server. Start from the "Download and Install"
section here (since you already installed R):
https://www.rstudio.com/ide/download/server

Then go here:
https://www.rstudio.com/ide/docs/server/getting_started

If you've set this up on your own machine (option (1) from above) then
you have to figure out how to connect it to the internet if you want
to use it from anywhere outside of your LAN.

It might seem like a lot of work, but as mentioned above -- since
these packages are available by the system's package manager, all of
the dependencies (like apache (if you need it)) will be installed for
you if you follow the (presumably correct) installation instructions
from RStudio.

=== An even easier setup ===

Just realized that there is  3rd route. You can save yourself a lot of
time by using an already built amazon machine instance that the
bioconductor folks have setup for you. Look at the instructions here:

http://www.bioconductor.org/help/bioconductor-cloud-ami/

If you follow along (you'll need an amazon account), you can rent a
machine and have it loaded w/ RStudio Server as well as some
bioconductor-specific libraries to get you started (by using the
bioconductor AMI). Once you have that up, you can connect to the
server running on Amazon's cloud via your web browser on both your CPU
(to make sure it all worked) then using an iOS device.

This would be a very easy way for you to see if taking one of the 2
avenues of setting up RStudio Server yourself would be worth the pain.

HTH,
-steve

On Fri, Apr 11, 2014 at 2:34 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Steve,
> Thank you for your help.
> I have seen the material you have sent me to, but do not fully
> understand it. Do I have to build a linux server first? If so does
it
> have to run Apache or some other web server? Is RStudio server run
under
> Apache, if so how? On the other hand, do I simply need a box running
a
> flavor of Linux (without Apache)., and then simply download RStudio
> server? Perhaps I am over thinking this . . .
> Thanks,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Steve Lianoglou <lianoglou.steve at gene.com> 4/11/2014 5:23 PM >>>
> Hi,
>
> On Fri, Apr 11, 2014 at 2:00 PM, John Sorkin
> <JSorkin at grecc.umaryland.edu> wrote:
>> I bemoan the fact that I can not run R or Rstudio on my iPad.
>
> I feel like this is something I'm not missing much, at all, but
> different strokes ... :-)
>
>> A possible work around would be to set up a server (probably under
> Linux), and get the server to present a web page that to would allow
me
> to run R on the server. I have searched the web for a clear, simple
> answer on how to do this but can not find one. There are answers,
but
> not for someone who has not built a Linux server. Can someone
provide
> either a reference to, or a short explanation of how I can build the
> server, get R or RStudio to run on it, and get the server and its R
or
> RStudio program available to me on my iPad? I can probably find
guidance
> on how to build an Apache server under Linux.
>
> You might try to follow the instructions to get RStudio Server
> running:
>
> https://www.rstudio.com/ide/docs/server/getting_started
>
> It seems like they have packages built for many popular linux
distros:
>
> https://www.rstudio.com/ide/download/server
>
> Once your linux server is set up, you should be able to access the
> server with any client via a web browser, although I have no idea if
> any of the iOS browsers are up to the task of dealing with the
RStudio
> web interface, but you can try and find out. RStudio's support forum
> is more likely to be helpful here, for instance:
>
>
https://support.rstudio.com/hc/en-us/search?utf8=?&query=ios&commit=Search
>
> HTH,
> -steve
>
> --
> Steve Lianoglou
> Computational Biologist
> Genentech
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use
of
> the intended recipient(s) and may contain confidential and
privileged
> information.  Any unauthorized use, disclosure or distribution is
> prohibited.  If you are not the intended recipient, please contact
the
> sender by reply email and destroy all copies of the original
message.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Steve Lianoglou
Computational Biologist
Genentech


Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information.  Any unauthorized use, disclosure or distribution is
prohibited.  If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From macqueen1 at llnl.gov  Sat Apr 12 00:05:27 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 11 Apr 2014 22:05:27 +0000
Subject: [R] Label axis tick marks with a simple function of axis value
In-Reply-To: <1397092642268-4688498.post@n4.nabble.com>
References: <1396304717602-4687917.post@n4.nabble.com>
	<5339EDF8.1070205@bitwrit.com.au>
	<1397013172001-4688443.post@n4.nabble.com>
	<5344F649.1020907@bitwrit.com.au>
	<1397031467054-4688456.post@n4.nabble.com>
	<5345033C.6080701@bitwrit.com.au>
	<1397092642268-4688498.post@n4.nabble.com>
Message-ID: <CF6DB1EA.F2D9D%macqueen1@llnl.gov>

You're on the right track, I think.

Try this example:

plot(21:30, xaxt='n')
labs <- paste(1:10,'units',sep='\n')
axis(1, at=1:10, labels=labs, mgp=c(3, 1.75, 0) )

Documentation for the mgp option is found in
  ?par
and it's not something that I would expect someone new to R to find easily.

In my opinion, the philosophy of R is that a lot of basic tools are
provided, and from them the user is expected to customize and construct
precisely what they want. Although, many of the R packages available from
CRAN exist because someone wanted to pre-write some fancy options for
users to choose from.

Of course, since all the units are the same in my example, it might make
more sense to put the units in the axis label, such as:

  plot(21:30, xlab='Units')

Note a little "trick" in that in the above example that might be
unexpected. I didn't supply both x and y. When only one of them is
supplied, it is interpreted as being y values. Since there are 10 of them,
it is as if it were:
  plot(1:10, 21:30)

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/9/14 6:17 PM, "Hurr" <hill0093 at umn.edu> wrote:

>What we've covered so far is of great value.
>For a neater plot,
>the next step will be to learn how to put
>numbers with units at each tick mark.
>I suppose I can form the number-unit string myself in
>separate code and put the tickmark in a place that
>I calculate in separate code.
>But I need to learn the plotting code.
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Label-axis-tick-marks-with-a-simple-function
>-of-axis-value-tp4687917p4688498.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From JSorkin at grecc.umaryland.edu  Sat Apr 12 00:08:53 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 18:08:53 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <CABdHhvF7Rg-3HG+4_iEDVJfxjkYsP6ChpggmbUaJNWT9vpS2zA@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CABdHhvF7Rg-3HG+4_iEDVJfxjkYsP6ChpggmbUaJNWT9vpS2zA@mail.gmail.com>
Message-ID: <53482FB5020000CB0010727A@smtp.medicine.umaryland.edu>

Hadley,
First, thank you for replying to my question. Are you saying that the iPad browser will not allow me to type the character string :/ into a browser window? I am not sure exactly what you are trying to tell me. Please forgive my lack of insight! Can you explain a but further?
Do you have any suggestions for a solution that will allow me to access R on my iPad?
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Hadley Wickham <h.wickham at gmail.com> 4/11/2014 6:01 PM >>>
Even if you do get Rstudio running on a server, unfortunately it won't
help. The ipad doesn't support quite enough html to get a fully
functional Rstudio interface - almost everything works but you can't
type anything :/  It would be possible to fix this, but fundamentally
we don't believe that the Rstudio interface is the right choice for an
ipad.

Hadley

On Fri, Apr 11, 2014 at 5:00 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server. I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
> Thank you,
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
http://had.co.nz/


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From h.wickham at gmail.com  Sat Apr 12 00:10:34 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 11 Apr 2014 18:10:34 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <53482FB5020000CB0010727A@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CABdHhvF7Rg-3HG+4_iEDVJfxjkYsP6ChpggmbUaJNWT9vpS2zA@mail.gmail.com>
	<53482FB5020000CB0010727A@smtp.medicine.umaryland.edu>
Message-ID: <CABdHhvFG_t0n+YR5WXqMvFVMh+=AH6AgXeb2zPC2=E-R_NX+fw@mail.gmail.com>

You can not type _anything_ into Rstudio if you connect to it on the
ipad. In other words, Rstudio is not currently usable on the ipad.
Hadley

On Fri, Apr 11, 2014 at 6:08 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Hadley,
> First, thank you for replying to my question. Are you saying that the iPad
> browser will not allow me to type the character string :/ into a browser
> window? I am not sure exactly what you are trying to tell me. Please forgive
> my lack of insight! Can you explain a but further?
> Do you have any suggestions for a solution that will allow me to access R on
> my iPad?
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Hadley Wickham <h.wickham at gmail.com> 4/11/2014 6:01 PM >>>
>
> Even if you do get Rstudio running on a server, unfortunately it won't
> help. The ipad doesn't support quite enough html to get a fully
> functional Rstudio interface - almost everything works but you can't
> type anything :/  It would be possible to fix this, but fundamentally
> we don't believe that the Rstudio interface is the right choice for an
> ipad.
>
> Hadley
>
> On Fri, Apr 11, 2014 at 5:00 PM, John Sorkin
> <JSorkin at grecc.umaryland.edu> wrote:
>> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible
>> work around would be to set up a server (probably under Linux), and get the
>> server to present a web page that to would allow me to run R on the server.
>> I have searched the web for a clear, simple answer on how to do this but can
>> not find one. There are answers, but not for someone who has not built a
>> Linux server. Can someone provide either a reference to, or a short
>> explanation of how I can build the server, get R or RStudio to run on it,
>> and get the server and its R or RStudio program available to me on my iPad?
>> I can probably find guidance on how to build an Apache server under Linux.
>> Thank you,
>> John
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the
>> intended recipient(s) and may contain confidential and privileged
>> information.  Any unauthorized use, disclosure or distribution is
>> prohibited.  If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> http://had.co.nz/
>
>
> Confidentiality Statement:
>
> This email message, including any attachments, is for ...{{dropped:11}}



From JSorkin at grecc.umaryland.edu  Sat Apr 12 00:15:28 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 18:15:28 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <CABdHhvFG_t0n+YR5WXqMvFVMh+=AH6AgXeb2zPC2=E-R_NX+fw@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<CABdHhvF7Rg-3HG+4_iEDVJfxjkYsP6ChpggmbUaJNWT9vpS2zA@mail.gmail.com>
	<53482FB5020000CB0010727A@smtp.medicine.umaryland.edu>
	<CABdHhvFG_t0n+YR5WXqMvFVMh+=AH6AgXeb2zPC2=E-R_NX+fw@mail.gmail.com>
Message-ID: <53483140020000CB00107280@smtp.medicine.umaryland.edu>

Hadley,
Thank you for the clarification! This is too bad as I had thought that given that RStudio server followed a web-based rather than a client-server paradigm that I could use my iPad to access an RStudio server and thus have access to R. Perhaps I wasted a loot of  $$$$ on my iPad . . .
John 

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Hadley Wickham <h.wickham at gmail.com> 4/11/2014 6:10 PM >>>
You can not type _anything_ into Rstudio if you connect to it on the
ipad. In other words, Rstudio is not currently usable on the ipad.
Hadley

On Fri, Apr 11, 2014 at 6:08 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Hadley,
> First, thank you for replying to my question. Are you saying that the iPad
> browser will not allow me to type the character string :/ into a browser
> window? I am not sure exactly what you are trying to tell me. Please forgive
> my lack of insight! Can you explain a but further?
> Do you have any suggestions for a solution that will allow me to access R on
> my iPad?
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Hadley Wickham <h.wickham at gmail.com> 4/11/2014 6:01 PM >>>
>
> Even if you do get Rstudio running on a server, unfortunately it won't
> help. The ipad doesn't support quite enough html to get a fully
> functional Rstudio interface - almost everything works but you can't
> type anything :/  It would be possible to fix this, but fundamentally
> we don't believe that the Rstudio interface is the right choice for an
> ipad.
>
> Hadley
>
> On Fri, Apr 11, 2014 at 5:00 PM, John Sorkin
> <JSorkin at grecc.umaryland.edu> wrote:
>> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible
>> work around would be to set up a server (probably under Linux), and get the
>> server to present a web page that to would allow me to run R on the server.
>> I have searched the web for a clear, simple answer on how to do this but can
>> not find one. There are answers, but not for someone who has not built a
>> Linux server. Can someone provide either a reference to, or a short
>> explanation of how I can build the server, get R or RStudio to run on it,
>> and get the server and its R or RStudio program available to me on my iPad?
>> I can probably find guidance on how to build an Apache server under Linux.
>> Thank you,
>> John
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the
>> intended recipient(s) and may contain confidential and privileged
>> information.  Any unauthorized use, disclosure or distribution is
>> prohibited.  If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> http://had.co.nz/
>
>
> Confidentiality Statement:
>
> This email message, including any attachments, is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply
> email and destroy all copies of the original message.



-- 
http://had.co.nz/


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From ligges at statistik.tu-dortmund.de  Sat Apr 12 00:53:15 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 12 Apr 2014 00:53:15 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
Message-ID: <5348725B.7070404@statistik.tu-dortmund.de>

Works for me.

Best,
Uwe Ligges



On 11.04.2014 17:10, Alpesh Pandya wrote:
> Using install.package('XML') command produces this error:
>
> trying URL
> '
> http://watson.nci.nih.gov/cran_mirror/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> '
> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
>
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open the connection
> In addition: Warning messages:
> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>    downloaded length 4276224 != reported length 4288136
> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
> file or directory'
>
>
> Upon receiving this error, I downloaded XML_3.98-1.1.zip directly from cran
> site. But this zip file is not a valid archive (cannot open using winzip).
> Also trying to install using this downloaded file produces the following
> error:
>
> Installing package into 'C:/Users/APandya/Documents/R/win-library/3.0'
> (as 'lib' is unspecified)
> Warning in install.packages :
>    error 1 in extracting from zip file
> Warning in install.packages :
>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
> file or directory'
> Error in install.packages : cannot open the connection
>
> I  downloaded this zip file from multiple sources and tried to install with
> same result.
>



From fisher at plessthan.com  Sat Apr 12 01:02:40 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 11 Apr 2014 16:02:40 -0700
Subject: [R] invalid multibyte string at '<b0>C'
Message-ID: <ECCB184D-535E-4DC6-9D56-3A5F8C782DB7@plessthan.com>

R 3.0.2
OS X Mavericks

Colleagues

I have a file that I converted from SAS (sas7bdat) to CSV (filename: ORIGINAL.csv).  I try to read it with read.csv and I receive the error message:
	Error in type.convert(data[[i]], as.is = as.is[i], dec = dec, na.strings = character(0L)) : 
	  invalid multibyte string at '<b0>C?
The problem resolves if I delete a single character from each of lines 2 and 4 of the file (filename: FIXED.csv)

readLines can read both files without problem and displays the offending character as:
	\xb0
which appears to be a degree sign.

I also tried:
	read.csv(textConnection(readLines(?ORIGINAL.csv?)))
and encountered the same error message.

In the past, I have encountered the same problem with Greek symbols (e.g., mu) and other special characters.

Short of editing the input file, is there a simple solution within R so that I can read the input data into a dataframe?
One possible (but ugly) solution would be:
	TEMP	<- readLines(FILENAME)
	TEMP	<- gsub(offendingcharacter, replacementcharacter, TEMP)
However, this would require that I find all possible offending characters and the corresponding replacements.

The files are available for inspection at:
	http://www.plessthan.com/FILES/ARCHIVE.zip

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



From dwinsemius at comcast.net  Sat Apr 12 03:06:52 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Apr 2014 18:06:52 -0700
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
Message-ID: <829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>


On Apr 11, 2014, at 2:00 PM, John Sorkin wrote:

> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server.


I fear that the response so far has been focussing on RStudio when the desire at its minimum was to run interactive R session on an iPad. Why not use an SSH client to connect to a machine that recognizes the security keys?

https://itunes.apple.com/us/app/server-auditor-ssh-client/id549039908?mt=8

I think RServe could be the server end, but I do not know how graphics devices would be handled. Maybe just create pdfs on the server? Is there a sendfile function that an SSH client could receive and allow the iPad user to open? I think the stats-rosuda-devel mailing list might be the place to find experienced users of such techniques.

-- 
David.


> I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
> Thank you,
> John 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:15}}



From JSorkin at grecc.umaryland.edu  Sat Apr 12 03:34:14 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 11 Apr 2014 21:34:14 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
Message-ID: <53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>

David,
Thank you for your assistance. 
I have, in fact been able to get things to work, at least when my iPad is on my local network. I had to do the following:
(1) install Linux (I used linux Mint) on a computer on my LAN
(2) install R on the linux box (accomplished using the Mint package manager)
(3) install Rstudio and RStudio server on the linux box (accomplished using the Mint package manager)
(4) obtain the linux computer's internal IP address (obtained using ifconfig command entered at a terminal). The internal IP address was 192.168.0.101
(5) use a browser on my iPad (I used google chrome, I believe firefox would also work) to connect to the linux box, requesting a connection using port 8787
In the brower I entered http://192.168.0.101:8787
This works like a charm; I can now control RStudio, which runs on the Linux box, by typing on my iPad. I thus gain access to RStudio on my iPad, RStudio works exactly as if it were running directly on my iPad, hooray!
 
My remaining problem is to determine how I can gain access to the linux box from outside my LAN. I know the IP address of my cable router xx.xx.xx.xx (forgive me I am not listing my external IP address for security reasons), but I don't know how I can address the linux box from outside my LAN. Clearly I can't use 192.168.0.101 as it is an internal IP address, and I can't use the external IP address, xx.xx.xx.xx as it is the address of my cable box, not the address of the Linux box behind the cable modem. If I can figure how to address the linux box from outside my LAN my problem will be solved! If anyone can help me with this last problem I would be grateful. I know it is not strictly an R question, but in my case it is related to running R, at least on my iPad.
John


 
 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> David Winsemius <dwinsemius at comcast.net> 4/11/2014 9:06 PM >>>

On Apr 11, 2014, at 2:00 PM, John Sorkin wrote:

> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server.


I fear that the response so far has been focussing on RStudio when the desire at its minimum was to run interactive R session on an iPad. Why not use an SSH client to connect to a machine that recognizes the security keys?

https://itunes.apple.com/us/app/server-auditor-ssh-client/id549039908?mt=8

I think RServe could be the server end, but I do not know how graphics devices would be handled. Maybe just create pdfs on the server? Is there a sendfile function that an SSH client could receive and allow the iPad user to open? I think the stats-rosuda-devel mailing list might be the place to find experienced users of such techniques.

-- 
David.


> I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
> Thank you,
> John 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From roy.mendelssohn at noaa.gov  Sat Apr 12 03:38:47 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Fri, 11 Apr 2014 18:38:47 -0700
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
	<53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
Message-ID: <4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>

GIYF - Google VPN and iPad.

-Roy

On Apr 11, 2014, at 6:34 PM, "John Sorkin" <JSorkin at grecc.umaryland.edu> wrote:

> David,
> Thank you for your assistance. 
> I have, in fact been able to get things to work, at least when my iPad is on my local network. I had to do the following:
> (1) install Linux (I used linux Mint) on a computer on my LAN
> (2) install R on the linux box (accomplished using the Mint package manager)
> (3) install Rstudio and RStudio server on the linux box (accomplished using the Mint package manager)
> (4) obtain the linux computer's internal IP address (obtained using ifconfig command entered at a terminal). The internal IP address was 192.168.0.101
> (5) use a browser on my iPad (I used google chrome, I believe firefox would also work) to connect to the linux box, requesting a connection using port 8787
> In the brower I entered http://192.168.0.101:8787
> This works like a charm; I can now control RStudio, which runs on the Linux box, by typing on my iPad. I thus gain access to RStudio on my iPad, RStudio works exactly as if it were running directly on my iPad, hooray!
> 
> My remaining problem is to determine how I can gain access to the linux box from outside my LAN. I know the IP address of my cable router xx.xx.xx.xx (forgive me I am not listing my external IP address for security reasons), but I don't know how I can address the linux box from outside my LAN. Clearly I can't use 192.168.0.101 as it is an internal IP address, and I can't use the external IP address, xx.xx.xx.xx as it is the address of my cable box, not the address of the Linux box behind the cable modem. If I can figure how to address the linux box from outside my LAN my problem will be solved! If anyone can help me with this last problem I would be grateful. I know it is not strictly an R question, but in my case it is related to running R, at least on my iPad.
> John
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> David Winsemius <dwinsemius at comcast.net> 4/11/2014 9:06 PM >>>
> 
> On Apr 11, 2014, at 2:00 PM, John Sorkin wrote:
> 
>> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server.
> 
> 
> I fear that the response so far has been focussing on RStudio when the desire at its minimum was to run interactive R session on an iPad. Why not use an SSH client to connect to a machine that recognizes the security keys?
> 
> https://itunes.apple.com/us/app/server-auditor-ssh-client/id549039908?mt=8
> 
> I think RServe could be the server end, but I do not know how graphics devices would be handled. Maybe just create pdfs on the server? Is there a sendfile function that an SSH client could receive and allow the iPad user to open? I think the stats-rosuda-devel mailing list might be the place to find experienced users of such techniques.
> 
> -- 
> David.
> 
> 
>> I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
>> Thank you,
>> John 
>> 
>> 
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From smartpink111 at yahoo.com  Sat Apr 12 07:06:19 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Apr 2014 22:06:19 -0700 (PDT)
Subject: [R] calling in inverted commas
In-Reply-To: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>
References: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>
Message-ID: <1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,

Not sure if this helps:
df2 <- data.frame(Col1=c(68.25, 68.75, 69.25), Col2=c(24.75, 25.25, 25.75)) 


Url1 <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&south=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_date=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42_daily&action=ASCII+Output" 


toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\?ms.*","\\1",Url1)
begin <- gsub("(.*\\.pl\\?).*","\\1",Url1)
end <- gsub(".*south=.*(\\?ms.*)","\\1",Url1)

vec2 <- strsplit(toreplace,"&")[[1]] 

##replace ".csv" with ".txt" and use write.table() if you need as text files.


lapply(seq_len(nrow(df2)),function(i) { val1 <- as.vector(rep(unlist(df2[i,]),2));replaced <-do.call(paste,list(lapply(seq_along(vec2),function(i) gsub("[-+]?(\\d*[.])?\\d+",val1[i],vec2[i])),collapse="&")); UrlNew <- paste0(begin,replaced,end); res <-read.csv(UrlNew,header=TRUE,stringsAsFactors=FALSE,skip=4,sep="",check.names=FALSE); write.csv(res,file=paste0("file_",paste(val1[1:2],collapse="_"),".csv"),row.names=FALSE,quote=FALSE)})

sapply(list.files(pattern="file_"),function(x) {x1 <-read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE); dim(x1)[1]})
#file_68.25_24.75.csv file_68.75_25.25.csv file_69.25_25.75.csv 

#                3652                 3652                 3652

### reading the downloaded file

lapply(list.files(pattern="file_"),function(x) {x1 <-read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE); x1[5:7,]}) 

#[[1]] 

#  Time(year:month:day) AccRain 

#5           1998:01:05   0.000 

#6           1998:01:06   0.000
#7           1998:01:07   0.984 

# 

#[[2]] 

#  Time(year:month:day) AccRain
#5           1998:01:05  0.0000
#6           1998:01:06  0.0925
#7           1998:01:07  0.2643
#
#[[3]] 

#  Time(year:month:day) AccRain
#5           1998:01:05  0.0000
#6           1998:01:06  0.7043 

#7           1998:01:07  0.5340 



A.K.


On Friday, April 11, 2014 2:38 PM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear useRs,
Here are three steps for downloading a file from a certain website in R. Here you see that in "URL" command (west=68.25&north=24.75&east=68.25&south=24.75) are actually the first and second column values of 1st row of a matrix called df2 (300 rows and 2 columns). more precisely, df2[1,][1]=68.25, df2[1,][2]=24.75. 
Is there a way that I can make a loop so that remaining rows and columns get inculcated in the link as such and then get saved at the desired mentioned location in 300 different text files?
URL<-("http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&south=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_date=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42_daily&action=ASCII+Output")
destfile <- "C:\\Users\\Eliza\\Desktop\\AA\\love.txt"
download.file(URL, destfile)

Any suggestion?
Thankyou very much in advance,
Eliza ??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From smartpink111 at yahoo.com  Sat Apr 12 07:15:46 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Apr 2014 22:15:46 -0700 (PDT)
Subject: [R] calling in inverted commas
In-Reply-To: <1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>
	<1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1397279746.35062.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
I noticed some special characters after sending.
It should be:
toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\&params.*","\\1",Url1)
end <- gsub(".*south=.*(\\&params.*)","\\1",Url1) 


A.K.


On Saturday, April 12, 2014 1:06 AM, arun <smartpink111 at yahoo.com> wrote:
HI,

Not sure if this helps:
df2 <- data.frame(Col1=c(68.25, 68.75, 69.25), Col2=c(24.75, 25.25, 25.75)) 


Url1 <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&south=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_date=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output" 


toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\?ms.*","\\1",Url1)
begin <- gsub("(.*\\.pl\\?).*","\\1",Url1)
end <- gsub(".*south=.*(\\?ms.*)","\\1",Url1)

vec2 <- strsplit(toreplace,"&")[[1]] 

##replace ".csv" with ".txt" and use write.table() if you need as text files.


lapply(seq_len(nrow(df2)),function(i) { val1 <- as.vector(rep(unlist(df2[i,]),2));replaced <-do.call(paste,list(lapply(seq_along(vec2),function(i) gsub("[-+]?(\\d*[.])?\\d+",val1[i],vec2[i])),collapse="&")); UrlNew <- paste0(begin,replaced,end); res <-read.csv(UrlNew,header=TRUE,stringsAsFactors=FALSE,skip=4,sep="",check.names=FALSE); write.csv(res,file=paste0("file_",paste(val1[1:2],collapse="_"),".csv"),row.names=FALSE,quote=FALSE)})

sapply(list.files(pattern="file_"),function(x) {x1 <-read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE); dim(x1)[1]})
#file_68.25_24.75.csv file_68.75_25.25.csv file_69.25_25.75.csv 

#? ? ? ? ? ? ? ? 3652? ? ? ? ? ? ? ?  3652? ? ? ? ? ? ? ?  3652

### reading the downloaded file

lapply(list.files(pattern="file_"),function(x) {x1 <-read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE); x1[5:7,]}) 

#[[1]] 

#? Time(year:month:day) AccRain 

#5? ? ? ? ?  1998:01:05?  0.000 

#6? ? ? ? ?  1998:01:06?  0.000
#7? ? ? ? ?  1998:01:07?  0.984 

# 

#[[2]] 

#? Time(year:month:day) AccRain
#5? ? ? ? ?  1998:01:05? 0.0000
#6? ? ? ? ?  1998:01:06? 0.0925
#7? ? ? ? ?  1998:01:07? 0.2643
#
#[[3]] 

#? Time(year:month:day) AccRain
#5? ? ? ? ?  1998:01:05? 0.0000
#6? ? ? ? ?  1998:01:06? 0.7043 

#7? ? ? ? ?  1998:01:07? 0.5340 



A.K.


On Friday, April 11, 2014 2:38 PM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear useRs,
Here are three steps for downloading a file from a certain website in R. Here you see that in "URL" command (west=68.25&north=24.75&east=68.25&south=24.75) are actually the first and second column values of 1st row of a matrix called df2 (300 rows and 2 columns). more precisely, df2[1,][1]=68.25, df2[1,][2]=24.75. 
Is there a way that I can make a loop so that remaining rows and columns get inculcated in the link as such and then get saved at the desired mentioned location in 300 different text files?
URL<-("http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&south=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_date=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output")

destfile <- "C:\\Users\\Eliza\\Desktop\\AA\\love.txt"
download.file(URL, destfile)

Any suggestion?
Thankyou very much in advance,
Eliza ??? ???? ??? ?? ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From frtog at vestas.com  Sat Apr 12 09:24:51 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Sat, 12 Apr 2014 09:24:51 +0200
Subject: [R] calling in inverted commas
In-Reply-To: <1397279746.35062.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>
	<1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397279746.35062.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CB9C33@DKRDSEXC016.vestas.net>


Hi

Sigh I'm getting a headache seeing ugly formatted R code. Arun, your code is almost unreadable. Have a look at e.g. http://yihui.name/en/2010/04/formatr-farewell-to-ugly-r-code/

Now to the substantial. Why not use the sprintf() function for formatting the url instead of the more involved approach using several gsub and regular expressions that not many people (including myself) easily understand.

## here is a small example using sprintf(), see ?sprintf
## %s is format specifier for string
exampleStr <- "west=%s&north=%s&east=%s&south=%s"

sprintf(exampleStr, 1, 2, 3, 4)
## > [1] "west=1&north=2&east=3&south=4"

## since % is used in format specification then if a literal % is needed in the string as here
## where you have e.g. %2F01% then escape those % with a %, i.e. % becomes %% in the string
## I have done that in urlPattern:
urlPattern <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%s&params=0|3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42_daily&action=ASCII+Output"

## some coordinates
df2 <- data.frame(Longitude = c(68.25, 68.75, 69.25), Latitude = c(24.75, 25.25, 25.75)) 

fileDestination <- c("C:/Temp")
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_")
fileNames <- paste(fileNames, "txt", sep = ".")
files <- file.path(fileDestination, fileNames)

for (i in 1:nrow(df2)){
    queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
    download.file(queryUrl, files[i])
}

## import data in first file
precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
                     sep = "", check.names = FALSE, stringsAsFactors = FALSE)

head(precip)


Here is another way using the url() function instead of download.file()

## Escaping the trouble with saving and reading files one can also do it this way
## having the dataframes in a named list
precipList <- vector("list", nrow(df2))
names(precipList) <- fileNames

for (i in 1:nrow(df2)){
    queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
    u <- url(queryUrl, open = "r")
    precipList[[i]] <- read.table(u, skip = 4, header = TRUE, na.strings = "-9999.9",
                     sep = "", check.names = FALSE, stringsAsFactors = FALSE)
    close(u)
}

str(precipList)

Have a nice day.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of arun
> Sent: 12. april 2014 07:16
> To: r-help at r-project.org
> Subject: Re: [R] calling in inverted commas
> 
> Hi,
> I noticed some special characters after sending.
> It should be:
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\&params.*","\\1",Url1)
> end <- gsub(".*south=.*(\\&params.*)","\\1",Url1)
> 
> 
> A.K.
> 
> 
> On Saturday, April 12, 2014 1:06 AM, arun <smartpink111 at yahoo.com>
> wrote:
> HI,
> 
> Not sure if this helps:
> df2 <- data.frame(Col1=c(68.25, 68.75, 69.25), Col2=c(24.75, 25.25, 25.75))
> 
> 
> Url1 <- "http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output"
> 
> 
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\?ms.*","\\1",Url1)
> begin <- gsub("(.*\\.pl\\?).*","\\1",Url1)
> end <- gsub(".*south=.*(\\?ms.*)","\\1",Url1)
> 
> vec2 <- strsplit(toreplace,"&")[[1]]
> 
> ##replace ".csv" with ".txt" and use write.table() if you need as text files.
> 
> 
> lapply(seq_len(nrow(df2)),function(i) { val1 <-
> as.vector(rep(unlist(df2[i,]),2));replaced <-
> do.call(paste,list(lapply(seq_along(vec2),function(i) gsub("[-
> +]?(\\d*[.])?\\d+",val1[i],vec2[i])),collapse="&")); UrlNew <-
> paste0(begin,replaced,end); res <-
> read.csv(UrlNew,header=TRUE,stringsAsFactors=FALSE,skip=4,sep="",check.
> names=FALSE);
> write.csv(res,file=paste0("file_",paste(val1[1:2],collapse="_"),".csv"),row.na
> mes=FALSE,quote=FALSE)})
> 
> sapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> dim(x1)[1]})
> #file_68.25_24.75.csv file_68.75_25.25.csv file_69.25_25.75.csv
> 
> #? ? ? ? ? ? ? ? 3652? ? ? ? ? ? ? ?  3652? ? ? ? ? ? ? ?  3652
> 
> ### reading the downloaded file
> 
> lapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> x1[5:7,]})
> 
> #[[1]]
> 
> #? Time(year:month:day) AccRain
> 
> #5? ? ? ? ?  1998:01:05?  0.000
> 
> #6? ? ? ? ?  1998:01:06?  0.000
> #7? ? ? ? ?  1998:01:07?  0.984
> 
> #
> 
> #[[2]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?  1998:01:05? 0.0000
> #6? ? ? ? ?  1998:01:06? 0.0925
> #7? ? ? ? ?  1998:01:07? 0.2643
> #
> #[[3]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?  1998:01:05? 0.0000
> #6? ? ? ? ?  1998:01:06? 0.7043
> 
> #7? ? ? ? ?  1998:01:07? 0.5340
> 
> 
> 
> A.K.
> 
> 
> On Friday, April 11, 2014 2:38 PM, eliza botto <eliza_botto at hotmail.com>
> wrote:
> Dear useRs,
> Here are three steps for downloading a file from a certain website in R. Here
> you see that in "URL" command
> (west=68.25&north=24.75&east=68.25&south=24.75) are actually the first
> and second column values of 1st row of a matrix called df2 (300 rows and 2
> columns). more precisely, df2[1,][1]=68.25, df2[1,][2]=24.75.
> Is there a way that I can make a loop so that remaining rows and columns get
> inculcated in the link as such and then get saved at the desired mentioned
> location in 300 different text files?
> URL<-("http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output")
> 
> destfile <- "C:\\Users\\Eliza\\Desktop\\AA\\love.txt"
> download.file(URL, destfile)
> 
> Any suggestion?
> Thankyou very much in advance,
> Eliza
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From frtog at vestas.com  Sat Apr 12 10:32:26 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Sat, 12 Apr 2014 10:32:26 +0200
Subject: [R] Save file as Fixed Width using sprintf()
In-Reply-To: <CAAxdm-5ZuQv0fEMcj3iXT9DhvOCEhHr7v28vBbbqnf4qX+zRYQ@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6868A251206@DC1VEX10MB001.air.org>
	<CAAxdm-5ZuQv0fEMcj3iXT9DhvOCEhHr7v28vBbbqnf4qX+zRYQ@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CB9C3B@DKRDSEXC016.vestas.net>

Hi

Have a look at the write.fwf ( fixed width format) in gdata package.


> ### load package
> library(gdata)
> 
> ### Create a sample data matrix
> set.seed(4324)
> myMat <- matrix(rnorm(9), 3,3)
> 
> ### cannot get it tp work with matrix so cast to dataframe
> write.fwf(as.data.frame(myMat), file = "", sep = "", colnames = FALSE)
-0.6464857-0.6289709-0.3129283
 1.4342941-0.6378252-1.6057577
 0.6456513 0.2481384-1.1617556
> 
> ### same as before
> write.fwf(as.data.frame(myMat), file = "", width = c(10,10,10), sep = "", colnames = FALSE)
-0.6464857-0.6289709-0.3129283
 1.4342941-0.6378252-1.6057577
 0.6456513 0.2481384-1.1617556
> 
> ### rounding
> write.fwf(as.data.frame(round(myMat, 6)), file = "", width = rep(9, ncol(myMat)), sep = "", colnames = FALSE)
-0.646486-0.628971-0.312928
 1.434294-0.637825-1.605758
 0.645651 0.248138-1.161756
>

With this approach I don't think you can get rid of the space between positive numbers because there should be place for a minus sign for negative values. If that's what you want????


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of jim holtman
> Sent: 11. april 2014 22:39
> To: Doran, Harold
> Cc: r-help at r-project.org
> Subject: Re: [R] Save file as Fixed Width using sprintf()
> 
> Try this.  It creates a 'list' that are the parameters for sprintf.  It
> writes out the file that I attach as the dump:
> 
> ### Create a sample data matrix
> myMat <- matrix(rnorm(9), 3,3)
> 
> # create the format required -- make sure it is wide enough
> # for 'fixed' width
> xx <- paste(rep("%8.2f", ncol(myMat)), collapse = '')
> # create a list for 'do.call(sprintf'
> callList <- vector('list', ncol(myMat) + 1)
> callList[[1]] <- xx  # store in the format
> 
> # add the columns to the list
> for (i in seq(ncol(myMat))) callList[[i + 1L]] <- myMat[, i]
> callList  # print it out
> 
> result <- do.call(sprintf, callList)
> 
> # write out the data to a file
> writeLines(result, '/temp/file.txt')
> 
> 
> Here is what is in the file:
> 
>    -0.39    0.45   -0.44
>    -0.82   -0.68   -0.43
>     2.05   -0.85    0.61
> 
> 
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Fri, Apr 11, 2014 at 2:48 PM, Doran, Harold <HDoran at air.org> wrote:
> 
> > I have working code to write a file out as fwf as shown below. I have one
> > question to try and automate this I cannot get to work.
> >
> > I am generating thousands of data files for a simulation to be run outside
> > of R and each file varies in its dimensions. So I am trying to write code
> > that can write the fwf based on the dimensions of each file generated as
> > shown below. I have commented this code with an example to show
> where I am
> > stuck.
> >
> > ### Create a sample data matrix
> > myMat <- matrix(rnorm(9), 3,3)
> >
> > ### Create the vector of format strings to be equal to the length of the
> > columns in myMat
> > aa <- rep('%4f', ncol(myMat))
> > xx <- paste(aa, sep='', collapse='')
> >
> > ### Now I could just do this below and it works
> > (out <- sprintf(xx, myMat[, 1], myMat[, 2], myMat[, 3]) )
> > out <- as.matrix(out) # convert to a character matrix
> > dimnames(out) <- list(rep('', nrow(out)), '') # blank row and column names
> > noquote(out) ## sink this file to a directory
> >
> > But, the fact that the dimensions of my matrix vary at each iteration
> > means I need to automate this part in the sprint().
> >
> > myMat[, 1], myMat[, 2], myMat[, 3])
> >
> > I think that's needed because something like the following does not work
> >
> > (out <- sprintf(xx, myMat[, 1:3]) )
> >
> >
> > So, I thought about trying smoething like this
> > cols <- paste(paste('myMat[, ', 1:ncol(myMat), sep=''), ']', sep='')
> > cols <- paste(cols, collapse=', ')
> >
> > But, this is a string with quotation marks, so I thought using cat() might
> > work, but it does not
> >
> > (out <- sprintf(xx, cat(cols) ) )
> >
> > Anyone have a suggestion for the right way to do this, this is getting
> > messy.
> >
> > Thank
> > Harold
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nalimilan at club.fr  Sat Apr 12 11:59:53 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 12 Apr 2014 11:59:53 +0200
Subject: [R] invalid multibyte string at '<b0>C'
In-Reply-To: <ECCB184D-535E-4DC6-9D56-3A5F8C782DB7@plessthan.com>
References: <ECCB184D-535E-4DC6-9D56-3A5F8C782DB7@plessthan.com>
Message-ID: <1397296793.15908.4.camel@milan>

Le vendredi 11 avril 2014 ? 16:02 -0700, Fisher Dennis a ?crit :
> R 3.0.2
> OS X Mavericks
> 
> Colleagues
> 
> I have a file that I converted from SAS (sas7bdat) to CSV (filename:
> ORIGINAL.csv).  I try to read it with read.csv and I receive the error
> message:
> 	Error in type.convert(data[[i]], as.is = as.is[i], dec = dec,
> na.strings = character(0L)) : 
> 	  invalid multibyte string at '<b0>C?
> The problem resolves if I delete a single character from each of lines
> 2 and 4 of the file (filename: FIXED.csv)
> 
> readLines can read both files without problem and displays the
> offending character as:
> 	\xb0
> which appears to be a degree sign.
> 
> I also tried:
> 	read.csv(textConnection(readLines(?ORIGINAL.csv?)))
> and encountered the same error message.
> 
> In the past, I have encountered the same problem with Greek symbols
> (e.g., mu) and other special characters.
> 
> Short of editing the input file, is there a simple solution within R
> so that I can read the input data into a dataframe?
> One possible (but ugly) solution would be:
> 	TEMP	<- readLines(FILENAME)
> 	TEMP	<- gsub(offendingcharacter, replacementcharacter, TEMP)
> However, this would require that I find all possible offending
> characters and the corresponding replacements.
Well, if the conversion too did its job correctly, you should be able to
find out what's the encoding used by the file and import these
characters correctly instead of removing them. <b0> would be the correct
degree character in ISO-8859-1. So try
read.csv(file, fileEncoding="ISO-8859-1")

> The files are available for inspection at:
> 	http://www.plessthan.com/FILES/ARCHIVE.zip
The link does not appear to work here.


Regards



From msuzen at gmail.com  Sat Apr 12 12:01:44 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sat, 12 Apr 2014 12:01:44 +0200
Subject: [R] operating website through R
In-Reply-To: <BLU170-W84F01FE8525C50D324CA7489540@phx.gbl>
References: <BLU170-W66536136558DD6F007F2AE89540@phx.gbl>
	<CAPtbhHwf+UbY5vdPtM5kJEDFNoPp3WkTKHWL0AS91Y+=rMBQ4Q@mail.gmail.com>
	<BLU170-W84F01FE8525C50D324CA7489540@phx.gbl>
Message-ID: <CAPtbhHxEEmt=Wr1EAAzgHJux=trWxBK_mFHR_HzyrqcoGs_xhw@mail.gmail.com>

This looks not so elegant, while normally data provider must have a
nice accessing API, anyway,  for example you can do this:

> myAdd <- 'http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=60&north=50&east=70&south=-50&params=0|3B42_V7&plot_type=Area+Plot&byr=2014&bmo=01&bdy=31&eyr=2014&emo=01&edy=31&begin_date=1998%2F01%2F01&end_date=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42_daily&action=ASCII+Output'

> myData <- read.table(myAdd, skip=5, header=T)

Will give you this:

> str(myData)
'data.frame':    16441 obs. of  3 variables:
 $ Latitude : num  -50 -50 -50 -50 -50 -50 -50 -50 -50 -50 ...
 $ Longitude: num  60 60.2 60.5 60.8 61 ...
 $ AccRain  : num  0 0.42 0.39 0.42 0.66 1.23 2.31 2.37 3.72 3.63 ...

For choosing different parameters, for example in case of coordinates,
you just need to change the values in 'myAdd' parameters after
Giovanni_cgi.pl?, west, north, east, south. But you must be sure that
there is a data available with those parameters, no magical error
control here.

On 11 April 2014 17:45, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear Suzen,
>
> I couldn't understand. Could you please elaborate it with a small example?
>
> :(
>
> Thanks in advance.
>
> Eliza
>
>> Date: Fri, 11 Apr 2014 17:31:18 +0200
>> Subject: Re: [R] operating website through R
>> From: msuzen at gmail.com
>> To: eliza_botto at hotmail.com
>> CC: r-help at r-project.org
>
>>
>> You just need to pass the parameters on Giovanni_cgi.pl with
>> action=ASCII+Output
>>
>> On 11 April 2014 17:19, eliza botto <eliza_botto at hotmail.com> wrote:
>> > Dear Users of R,
>> > I wanted to operate certain slots of this website
>> > (http://disc2.nascom.nasa.gov/Giovanni/tovas/TRMM_V7.3B42_daily.2.shtml)
>> > through R. I wanted to operate Latitude, longitude section, plot type, begin
>> > and end year and ASCII Output Resolution. The filling of these slot will
>> > produce and output file with I want to D/L at a certain location in my PC.
>> > I have a matrix of 2 columns and 3000 rows which contain Latitude and
>> > Longitude information which i want to upload automatically in the slots of
>> > website. I tried to use certain web scarping techniques in R but to no use.
>> > Is there a way of doing it in R.
>> > thank you very much in advance,
>> > Eliza
>> >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Apr 12 12:28:48 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Apr 2014 03:28:48 -0700 (PDT)
Subject: [R] calling in inverted commas
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5CB9C33@DKRDSEXC016.vestas.net>
References: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>	<1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397279746.35062.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CB9C33@DKRDSEXC016.vestas.net>
Message-ID: <1397298528.78524.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Thanks for the link.
I should have used ?sprintf().? BTW, I am not able to reproduce your results.

urlPattern <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%&params=0|3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output" 
##


## some coordinates
df2 <- data.frame(Longitude = c(68.25, 68.75, 69.25), Latitude = c(24.75, 25.25, 25.75))
fileDestination <- getwd()
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_") 

fileNames <- paste(fileNames, "txt", sep = ".") 

files <- file.path(fileDestination, fileNames)

for (i in 1:nrow(df2)){
???? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2]) ??? ???? download.file(queryUrl, files[i])
}



precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
+                     sep = "", check.names = FALSE, stringsAsFactors = FALSE) 

Error in read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",  : 
  more columns than column names 


So, I checked the file "precip_68.25_24.75.txt"
Giovanni Error Message 
Giovanni Error Message Page
Error: instance configuration file  is not found. 
Error: product configuration file  is not found. 
Please send email to Help Desk: help at daac.gs
fc.nasa.gov 
sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit) 

A.K.


On Saturday, April 12, 2014 3:24 AM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:

Hi

Sigh I'm getting a headache seeing ugly formatted R code. Arun, your code is almost unreadable. Have a look at e.g. http://yihui.name/en/2010/04/formatr-farewell-to-ugly-r-code/

Now to the substantial. Why not use the sprintf() function for formatting the url instead of the more involved approach using several gsub and regular expressions that not many people (including myself) easily understand.

## here is a small example using sprintf(), see ?sprintf
## %s is format specifier for string
exampleStr <- "west=%s&north=%s&east=%s&south=%s"

sprintf(exampleStr, 1, 2, 3, 4)
## > [1] "west=1&north=2&east=3&south=4"

## since % is used in format specification then if a literal % is needed in the string as here
## where you have e.g. %2F01% then escape those % with a %, i.e. % becomes %% in the string
## I have done that in urlPattern:
urlPattern <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%s&params=0|3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output"

## some coordinates
df2 <- data.frame(Longitude = c(68.25, 68.75, 69.25), Latitude = c(24.75, 25.25, 25.75)) 

fileDestination <- c("C:/Temp")
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_")
fileNames <- paste(fileNames, "txt", sep = ".")
files <- file.path(fileDestination, fileNames)

for (i in 1:nrow(df2)){
? ? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
? ? download.file(queryUrl, files[i])
}

## import data in first file
precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
? ? ? ? ? ? ? ? ? ?  sep = "", check.names = FALSE, stringsAsFactors = FALSE)

head(precip)


Here is another way using the url() function instead of download.file()

## Escaping the trouble with saving and reading files one can also do it this way
## having the dataframes in a named list
precipList <- vector("list", nrow(df2))
names(precipList) <- fileNames

for (i in 1:nrow(df2)){
? ? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
? ? u <- url(queryUrl, open = "r")
? ? precipList[[i]] <- read.table(u, skip = 4, header = TRUE, na.strings = "-9999.9",
? ? ? ? ? ? ? ? ? ?  sep = "", check.names = FALSE, stringsAsFactors = FALSE)
? ? close(u)
}

str(precipList)

Have a nice day.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of arun
> Sent: 12. april 2014 07:16
> To: r-help at r-project.org
> Subject: Re: [R] calling in inverted commas
> 
> Hi,
> I noticed some special characters after sending.
> It should be:
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\&params.*","\\1",Url1)
> end <- gsub(".*south=.*(\\&params.*)","\\1",Url1)
> 
> 
> A.K.
> 
> 
> On Saturday, April 12, 2014 1:06 AM, arun <smartpink111 at yahoo.com>
> wrote:
> HI,
> 
> Not sure if this helps:
> df2 <- data.frame(Col1=c(68.25, 68.75, 69.25), Col2=c(24.75, 25.25, 25.75))
> 
> 
> Url1 <- "http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output"
> 
> 
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\?ms.*","\\1",Url1)
> begin <- gsub("(.*\\.pl\\?).*","\\1",Url1)
> end <- gsub(".*south=.*(\\?ms.*)","\\1",Url1)
> 
> vec2 <- strsplit(toreplace,"&")[[1]]
> 
> ##replace ".csv" with ".txt" and use write.table() if you need as text files.
> 
> 
> lapply(seq_len(nrow(df2)),function(i) { val1 <-
> as.vector(rep(unlist(df2[i,]),2));replaced <-
> do.call(paste,list(lapply(seq_along(vec2),function(i) gsub("[-
> +]?(\\d*[.])?\\d+",val1[i],vec2[i])),collapse="&")); UrlNew <-
> paste0(begin,replaced,end); res <-
> read.csv(UrlNew,header=TRUE,stringsAsFactors=FALSE,skip=4,sep="",check.
> names=FALSE);
> write.csv(res,file=paste0("file_",paste(val1[1:2],collapse="_"),".csv"),row.na
> mes=FALSE,quote=FALSE)})
> 
> sapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> dim(x1)[1]})
> #file_68.25_24.75.csv file_68.75_25.25.csv file_69.25_25.75.csv
> 
> #? ? ? ? ? ? ? ? 3652? ? ? ? ? ? ? ?? 3652? ? ? ? ? ? ? ?? 3652
> 
> ### reading the downloaded file
> 
> lapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> x1[5:7,]})
> 
> #[[1]]
> 
> #? Time(year:month:day) AccRain
> 
> #5? ? ? ? ?? 1998:01:05?? 0.000
> 
> #6? ? ? ? ?? 1998:01:06?? 0.000
> #7? ? ? ? ?? 1998:01:07?? 0.984
> 
> #
> 
> #[[2]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?? 1998:01:05? 0.0000
> #6? ? ? ? ?? 1998:01:06? 0.0925
> #7? ? ? ? ?? 1998:01:07? 0.2643
> #
> #[[3]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?? 1998:01:05? 0.0000
> #6? ? ? ? ?? 1998:01:06? 0.7043
> 
> #7? ? ? ? ?? 1998:01:07? 0.5340
> 
> 
> 
> A.K.
> 
> 
> On Friday, April 11, 2014 2:38 PM, eliza botto <eliza_botto at hotmail.com>
> wrote:
> Dear useRs,
> Here are three steps for downloading a file from a certain website in R. Here
> you see that in "URL" command
> (west=68.25&north=24.75&east=68.25&south=24.75) are actually the first
> and second column values of 1st row of a matrix called df2 (300 rows and 2
> columns). more precisely, df2[1,][1]=68.25, df2[1,][2]=24.75.
> Is there a way that I can make a loop so that remaining rows and columns get
> inculcated in the link as such and then get saved at the desired mentioned
> location in 300 different text files?
> URL<-("http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output")
> 
> destfile <- "C:\\Users\\Eliza\\Desktop\\AA\\love.txt"
> download.file(URL, destfile)
> 
> Any suggestion?
> Thankyou very much in advance,
> Eliza
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Apr 12 12:42:30 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Apr 2014 03:42:30 -0700 (PDT)
Subject: [R] calling in inverted commas
In-Reply-To: <1397298528.78524.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <BLU170-W12984E276B239E46FE0E42189540@phx.gbl>	<1397279179.25920.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397279746.35062.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CB9C33@DKRDSEXC016.vestas.net>
	<1397298528.78524.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1397299350.85726.YahooMailNeo@web142605.mail.bf1.yahoo.com>



HI,

Please ignore the previous message.? I copied your codes directly from the email.? For some reason, the urlPattern <- ... showed some special characters.? I manually fixed it and now it is working.


urlPattern1<-("http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%s&params=0%%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42_daily&action=ASCII+Output") 

fileDestination <- getwd() 

fileNames <- paste("precip", df2[,1], df2[,2], sep = "_")
?fileNames <- paste(fileNames, "txt", sep = ".")
?files <- file.path(fileDestination, fileNames) 
for (i in 1:nrow(df2)){
    queryUrl <- sprintf(urlPattern1, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
    download.file(queryUrl, files[i])
}
?## import data in first file 
precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
                    sep = "", check.names = FALSE, stringsAsFactors = FALSE) 
head(precip,2)
?#  Time(year:month:day) AccRain
?#1           1998:01:01       0
?#2           1998:01:02       0 

A.K.



On , arun <smartpink111 at yahoo.com> wrote:
HI,
Thanks for the link.
I should have used ?sprintf().? BTW, I am not able to reproduce your results.

urlPattern <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%&params=0|3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output" 
##


## some coordinates
df2 <- data.frame(Longitude = c(68.25, 68.75, 69.25), Latitude = c(24.75, 25.25, 25.75))
fileDestination <- getwd()
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_") 

fileNames <- paste(fileNames, "txt", sep = ".") 

files <- file.path(fileDestination, fileNames)

for (i in 1:nrow(df2)){
???? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2]) ??? ???? download.file(queryUrl, files[i])
}



precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
+? ? ? ? ? ? ? ? ? ?  sep = "", check.names = FALSE, stringsAsFactors = FALSE) 

Error in read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",? : 
? more columns than column names 


So, I checked the file "precip_68.25_24.75.txt"
Giovanni Error Message 
Giovanni Error Message Page
Error: instance configuration file? is not found. 
Error: product configuration file? is not found. 
Please send email to Help Desk: help at daac.gs
fc.nasa.gov 
sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit) 

A.K.



On Saturday, April 12, 2014 3:24 AM, Frede Aakmann T?gersen <frtog at vestas.com> wrote:

Hi

Sigh I'm getting a headache seeing ugly formatted R code. Arun, your code is almost unreadable. Have a look at e.g. http://yihui.name/en/2010/04/formatr-farewell-to-ugly-r-code/

Now to the substantial. Why not use the sprintf() function for formatting the url instead of the more involved approach using several gsub and regular expressions that not many people (including myself) easily understand.

## here is a small example using sprintf(), see ?sprintf
## %s is format specifier for string
exampleStr <- "west=%s&north=%s&east=%s&south=%s"

sprintf(exampleStr, 1, 2, 3, 4)
## > [1] "west=1&north=2&east=3&south=4"

## since % is used in format specification then if a literal % is needed in the string as here
## where you have e.g. %2F01% then escape those % with a %, i.e. % becomes %% in the string
## I have done that in urlPattern:
urlPattern <- "http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%s&params=0|3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%%2F01%%2F01&end_date=2014%%2F01%%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7?_id=3B42_daily&action=ASCII+Output"

## some coordinates
df2 <- data.frame(Longitude = c(68.25, 68.75, 69.25), Latitude = c(24.75, 25.25, 25.75)) 

fileDestination <- c("C:/Temp")
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_")
fileNames <- paste(fileNames, "txt", sep = ".")
files <- file.path(fileDestination, fileNames)

for (i in 1:nrow(df2)){
? ? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
? ? download.file(queryUrl, files[i])
}

## import data in first file
precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9999.9",
? ? ? ? ? ? ? ? ? ?? sep = "", check.names = FALSE, stringsAsFactors = FALSE)

head(precip)


Here is another way using the url() function instead of download.file()

## Escaping the trouble with saving and reading files one can also do it this way
## having the dataframes in a named list
precipList <- vector("list", nrow(df2))
names(precipList) <- fileNames

for (i in 1:nrow(df2)){
? ? queryUrl <- sprintf(urlPattern, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])
? ? u <- url(queryUrl, open = "r")
? ? precipList[[i]] <- read.table(u, skip = 4, header = TRUE, na.strings = "-9999.9",
? ? ? ? ? ? ? ? ? ?? sep = "", check.names = FALSE, stringsAsFactors = FALSE)
? ? close(u)
}

str(precipList)

Have a nice day.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of arun
> Sent: 12. april 2014 07:16
> To: r-help at r-project.org
> Subject: Re: [R] calling in inverted commas
> 
> Hi,
> I noticed some special characters after sending.
> It should be:
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\&params.*","\\1",Url1)
> end <- gsub(".*south=.*(\\&params.*)","\\1",Url1)
> 
> 
> A.K.
> 
> 
> On Saturday, April 12, 2014 1:06 AM, arun <smartpink111 at yahoo.com>
> wrote:
> HI,
> 
> Not sure if this helps:
> df2 <- data.frame(Col1=c(68.25, 68.75, 69.25), Col2=c(24.75, 25.25, 25.75))
> 
> 
> Url1 <- "http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output"
> 
> 
> toreplace <- gsub(".*\\.pl\\?(west\\=.*south=.*)\\?ms.*","\\1",Url1)
> begin <- gsub("(.*\\.pl\\?).*","\\1",Url1)
> end <- gsub(".*south=.*(\\?ms.*)","\\1",Url1)
> 
> vec2 <- strsplit(toreplace,"&")[[1]]
> 
> ##replace ".csv" with ".txt" and use write.table() if you need as text files.
> 
> 
> lapply(seq_len(nrow(df2)),function(i) { val1 <-
> as.vector(rep(unlist(df2[i,]),2));replaced <-
> do.call(paste,list(lapply(seq_along(vec2),function(i) gsub("[-
> +]?(\\d*[.])?\\d+",val1[i],vec2[i])),collapse="&")); UrlNew <-
> paste0(begin,replaced,end); res <-
> read.csv(UrlNew,header=TRUE,stringsAsFactors=FALSE,skip=4,sep="",check.
> names=FALSE);
> write.csv(res,file=paste0("file_",paste(val1[1:2],collapse="_"),".csv"),row.na
> mes=FALSE,quote=FALSE)})
> 
> sapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> dim(x1)[1]})
> #file_68.25_24.75.csv file_68.75_25.25.csv file_69.25_25.75.csv
> 
> #? ? ? ? ? ? ? ? 3652? ? ? ? ? ? ? ?? 3652? ? ? ? ? ? ? ?? 3652
> 
> ### reading the downloaded file
> 
> lapply(list.files(pattern="file_"),function(x) {x1 <-
> read.csv(x,header=TRUE,stringsAsFactors=FALSE,check.names=FALSE);
> x1[5:7,]})
> 
> #[[1]]
> 
> #? Time(year:month:day) AccRain
> 
> #5? ? ? ? ?? 1998:01:05?? 0.000
> 
> #6? ? ? ? ?? 1998:01:06?? 0.000
> #7? ? ? ? ?? 1998:01:07?? 0.984
> 
> #
> 
> #[[2]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?? 1998:01:05? 0.0000
> #6? ? ? ? ?? 1998:01:06? 0.0925
> #7? ? ? ? ?? 1998:01:07? 0.2643
> #
> #[[3]]
> 
> #? Time(year:month:day) AccRain
> #5? ? ? ? ?? 1998:01:05? 0.0000
> #6? ? ? ? ?? 1998:01:06? 0.7043
> 
> #7? ? ? ? ?? 1998:01:07? 0.5340
> 
> 
> 
> A.K.
> 
> 
> On Friday, April 11, 2014 2:38 PM, eliza botto <eliza_botto at hotmail.com>
> wrote:
> Dear useRs,
> Here are three steps for downloading a file from a certain website in R. Here
> you see that in "URL" command
> (west=68.25&north=24.75&east=68.25&south=24.75) are actually the first
> and second column values of 1st row of a matrix called df2 (300 rows and 2
> columns). more precisely, df2[1,][1]=68.25, df2[1,][2]=24.75.
> Is there a way that I can make a loop so that remaining rows and columns get
> inculcated in the link as such and then get saved at the desired mentioned
> location in 300 different text files?
> URL<-("http://disc2.nascom.nasa.gov/daac-
> bin/Giovanni/tovas/Giovanni_cgi.pl?west=68.25&north=24.75&east=68.25&s
> outh=24.75?ms=0%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&
> bdy=1&eyr=2007&emo=12&edy=31&begin_date=1998%2F01%2F01&end_da
> te=2014%2F01%2F31&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax
> =&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRM
> M_V7?_id=3B42_daily&action=ASCII+Output")
> 
> destfile <- "C:\\Users\\Eliza\\Desktop\\AA\\love.txt"
> download.file(URL, destfile)
> 
> Any suggestion?
> Thankyou very much in advance,
> Eliza
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From frtog at vestas.com  Sat Apr 12 12:48:12 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Sat, 12 Apr 2014 12:48:12 +0200
Subject: [R] calling in inverted commas
Message-ID: <7ibug15ss9qiwxo4i88llwfs.1397299096453@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/460d4a26/attachment-0001.pl>

From frtog at vestas.com  Sat Apr 12 12:54:49 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Sat, 12 Apr 2014 12:54:49 +0200
Subject: [R] calling in inverted commas
Message-ID: <f1acnw33r7f71xhxlbnfarae.1397300086295@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/fc85a12a/attachment-0001.pl>

From ahoerner at rprogress.org  Sat Apr 12 14:36:16 2014
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Sat, 12 Apr 2014 05:36:16 -0700
Subject: [R] Selecting rows from a DF where the value in a selected column
 matches any element of a vector.
Message-ID: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/3d4646b8/attachment-0001.pl>

From sarah.goslee at gmail.com  Sat Apr 12 15:04:59 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 12 Apr 2014 09:04:59 -0400
Subject: [R] Selecting rows from a DF where the value in a selected
 column matches any element of a vector.
In-Reply-To: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
References: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
Message-ID: <CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>

You need %in% instead.

This is untested, but something like this should work:


ECwork  <-  EC07_A1[ EC07_A1$GEO_ID %in% c("01000US", "04000US06", "33000US488",
"31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000") &
      EC07_A1$SECTOR %in% c("32", "33", "42", 44", 45", 51", 54", 61", "71",
"81"), ]

(Note that your original code snippet had a shortage of ) and didn't
specify the data frame from which to take the columns.)

Sarah

On Sat, Apr 12, 2014 at 8:36 AM, Andrew Hoerner <ahoerner at rprogress.org> wrote:
> Dear Folks--
> I have a file with 3 million-odd rows of data from the 2007 U.S. Economic
> Census. I am trying to pare it down to a subset of rows that both (1) has
> any one of a vector of NAICS economic sector codes, and (2) also has any
> one of a vector of geographic ID codes.
>
> Here is the code I am trying to use.
>
> ECwork  <-  EC07_A1[ any(GEO_ID == c("01000US", "04000US06", "33000US488",
> "31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000") &
>       any(SECTOR == c("32", "33", "42", 44", 45", 51", 54", 61", "71",
> "81"), ]
>
> I get back the following error:
>
> Warning message:
> In EC07_A1$SECTOR == c("32", "33", "42", "44", "45", "51", "54",  :
>   longer object length is not a multiple of shorter object length
>
> I see what R is doing.  Instead of comparing each element of the column
> SECTOR to the row vector of codes, and returning a logical vector of the
> length of SECTOR with rows marked as TRUE that match any of the codes, it
> is lining my code list up with SECTOR as a column vector and doing
> element-by-element testing, and then recycling the code list over three
> million rows. But I am not sure how to make it do what I want -- test the
> sector code in each row against the vector of code I am looking for. I
> would be grateful if anyone could suggest an alternative that would achieve
> my ends.
>
> Oh, and I would add, if there is a way of correctly using doing this with
> the extract function [], I would like to know what it is. If not, I guess
> I'd like to know that too.
>
> Sincerely, Andrew Hoerner
>
> --
> J. Andrew Hoerner
> Director, Sustainable Economics Program
> Redefining Progress
> (510) 507-4820
>
-- 
Sarah Goslee
http://www.functionaldiversity.org



From fransiepansiekevertje at gmail.com  Sat Apr 12 17:45:55 2014
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Sat, 12 Apr 2014 17:45:55 +0200
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
	<53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
	<4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>
Message-ID: <CAFFQM6ZXsnZCocpH0rhiiiRFX02vq6gEBHjjQyVSYmsLsy-aXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/0d049b7c/attachment-0001.pl>

From rau at demogr.mpg.de  Sat Apr 12 17:19:45 2014
From: rau at demogr.mpg.de (Roland Rau)
Date: Sat, 12 Apr 2014 17:19:45 +0200
Subject: [R] Change position in package rgl
Message-ID: <53495991.3090904@demogr.mpg.de>

Dear all,

I am using package rgl and I want to change the position where I "stand".
Maybe a small example might clarify what I am looking for:


# Begininng of explanatory example
library(rgl)
data(volcano)

# the example ?rgl.surface
y <- 2 * volcano
x <- 10 * (1:nrow(y))
z <- 10 * (1:ncol(y))
ylim <- range(y)
ylen <- ylim[2] - ylim[1] + 1
colorlut <- terrain.colors(ylen)
col <- colorlut[ y-ylim[1]+1 ]

rgl.open()
rgl.surface(x, z, y, color=col, back="lines")
## now I have the nice volcano surface
## with rgl.viewpoint I can change the elevation
## and the angle from where I look at the rgl.surface
# example of ?rgl.viewpoint
start <- proc.time()[3]
while ((i <- 36*(proc.time()[3]-start)) < 360) {
  rgl.viewpoint(i,i/4);
}
# End of explanatory example

What I am looking for (in this example) would be a way for me to "stand"
on the crater of the volcano, looking in a specific direction. Is there
something like a function where I can specify my coordinates (x,y,z) and
angle and a zoom factor?

Thank you,
Roland

----------
This mail has been sent through the MPI for Demographic ...{{dropped:2}}



From murdoch.duncan at gmail.com  Sat Apr 12 19:03:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 12 Apr 2014 13:03:16 -0400
Subject: [R] Change position in package rgl
In-Reply-To: <53495991.3090904@demogr.mpg.de>
References: <53495991.3090904@demogr.mpg.de>
Message-ID: <534971D4.6050105@gmail.com>

On 12/04/2014, 11:19 AM, Roland Rau wrote:
> Dear all,
>
> I am using package rgl and I want to change the position where I "stand".
> Maybe a small example might clarify what I am looking for:
>
>
> # Begininng of explanatory example
> library(rgl)
> data(volcano)
>
> # the example ?rgl.surface
> y <- 2 * volcano
> x <- 10 * (1:nrow(y))
> z <- 10 * (1:ncol(y))
> ylim <- range(y)
> ylen <- ylim[2] - ylim[1] + 1
> colorlut <- terrain.colors(ylen)
> col <- colorlut[ y-ylim[1]+1 ]
>
> rgl.open()
> rgl.surface(x, z, y, color=col, back="lines")
> ## now I have the nice volcano surface
> ## with rgl.viewpoint I can change the elevation
> ## and the angle from where I look at the rgl.surface
> # example of ?rgl.viewpoint
> start <- proc.time()[3]
> while ((i <- 36*(proc.time()[3]-start)) < 360) {
>    rgl.viewpoint(i,i/4);
> }
> # End of explanatory example
>
> What I am looking for (in this example) would be a way for me to "stand"
> on the crater of the volcano, looking in a specific direction. Is there
> something like a function where I can specify my coordinates (x,y,z) and
> angle and a zoom factor?

I think you could hack something like that (see the description in 
?par3d of how rendering is accomplished), but there's currently no 
support for it, and it wouldn't be easy, as currently P and M in that 
description are read-only quantities computed indirectly.  So you'd have 
to essentially trick rgl into producing the P matrix corresponding to 
the viewing position you want.

I am currently working on some changes that might make this easier, but 
they likely aren't going to be released for several months.

Duncan Murdoch



From jsorkin at grecc.umaryland.edu  Sat Apr 12 19:37:46 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 12 Apr 2014 13:37:46 -0400
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <CAFFQM6ZXsnZCocpH0rhiiiRFX02vq6gEBHjjQyVSYmsLsy-aXg@mail.gmail.com>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
	<53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
	<4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>
	<CAFFQM6ZXsnZCocpH0rhiiiRFX02vq6gEBHjjQyVSYmsLsy-aXg@mail.gmail.com>
Message-ID: <534941B4020000CB001073AB@smtp.medicine.umaryland.edu>

Grand,
Thank you. I have been able to use my iPad to connect to a server running RStudio server as described in an earlier email and can use the virtual keyboard, which works but is not convenient as one needs to go from keyboard screen to another. 
My current problem is that while I can get everything to work when my iPad is on my local network, I don't know how to access my server from outside my LAN. I know my server's private IP address I know my cable modem's external IP address, but I have no idea what IP address to enter in my iPad, when my iPad is outside my LAN trying to access my server.
John

> On Apr 12, 2014, at 11:46 AM, "Frans Marcelissen <fransiepansiekevertje at gmail.com>" <fransiepansiekevertje at gmail.com> wrote:
> 
> Running rstudio (server) on an ipad.
> I do'nt have an ipad anymore, but some years ago I noticed that rstudio (server) worked fine on an ipad of you have a separate keyboard. It does not work with the virtual keyboard. The same is true with android tablets.
> Frans
> 
> 
> 2014-04-12 3:38 GMT+02:00 Roy Mendelssohn <roy.mendelssohn at noaa.gov>:
>> GIYF - Google VPN and iPad.
>> 
>> -Roy
>> 
>> On Apr 11, 2014, at 6:34 PM, "John Sorkin" <JSorkin at grecc.umaryland.edu> wrote:
>> 
>> > David,
>> > Thank you for your assistance.
>> > I have, in fact been able to get things to work, at least when my iPad is on my local network. I had to do the following:
>> > (1) install Linux (I used linux Mint) on a computer on my LAN
>> > (2) install R on the linux box (accomplished using the Mint package manager)
>> > (3) install Rstudio and RStudio server on the linux box (accomplished using the Mint package manager)
>> > (4) obtain the linux computer's internal IP address (obtained using ifconfig command entered at a terminal). The internal IP address was 192.168.0.101
>> > (5) use a browser on my iPad (I used google chrome, I believe firefox would also work) to connect to the linux box, requesting a connection using port 8787
>> > In the brower I entered http://192.168.0.101:8787
>> > This works like a charm; I can now control RStudio, which runs on the Linux box, by typing on my iPad. I thus gain access to RStudio on my iPad, RStudio works exactly as if it were running directly on my iPad, hooray!
>> >
>> > My remaining problem is to determine how I can gain access to the linux box from outside my LAN. I know the IP address of my cable router xx.xx.xx.xx (forgive me I am not listing my external IP address for security reasons), but I don't know how I can address the linux box from outside my LAN. Clearly I can't use 192.168.0.101 as it is an internal IP address, and I can't use the external IP address, xx.xx.xx.xx as it is the address of my cable box, not the address of the Linux box behind the cable modem. If I can figure how to address the linux box from outside my LAN my problem will be solved! If anyone can help me with this last problem I would be grateful. I know it is not strictly an R question, but in my case it is related to running R, at least on my iPad.
>> > John
>> >
>> >
>> >
>> >
>> > John David Sorkin M.D., Ph.D.
>> > Professor of Medicine
>> > Chief, Biostatistics and Informatics
>> > University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> > Baltimore VA Medical Center
>> > 10 North Greene Street
>> > GRECC (BT/18/GR)
>> > Baltimore, MD 21201-1524
>> > (Phone) 410-605-7119
>> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>>> David Winsemius <dwinsemius at comcast.net> 4/11/2014 9:06 PM >>>
>> >
>> > On Apr 11, 2014, at 2:00 PM, John Sorkin wrote:
>> >
>> >> I bemoan the fact that I can not run R or Rstudio on my iPad. A possible work around would be to set up a server (probably under Linux), and get the server to present a web page that to would allow me to run R on the server.
>> >
>> >
>> > I fear that the response so far has been focussing on RStudio when the desire at its minimum was to run interactive R session on an iPad. Why not use an SSH client to connect to a machine that recognizes the security keys?
>> >
>> > https://itunes.apple.com/us/app/server-auditor-ssh-client/id549039908?mt=8
>> >
>> > I think RServe could be the server end, but I do not know how graphics devices would be handled. Maybe just create pdfs on the server? Is there a sendfile function that an SSH client could receive and allow the iPad user to open? I think the stats-rosuda-devel mailing list might be the place to find experienced users of such techniques.
>> >
>> > --
>> > David.
>> >
>> >
>> >> I have searched the web for a clear, simple answer on how to do this but can not find one. There are answers, but not for someone who has not built a Linux server. Can someone provide either a reference to, or a short explanation of how I can build the server, get R or RStudio to run on it, and get the server and its R or RStudio program available to me on my iPad? I can probably find guidance on how to build an Apache server under Linux.
>> >> Thank you,
>> >> John
>> >>
>> >>
>> >>
>> >>
>> >> John David Sorkin M.D., Ph.D.
>> >> Professor of Medicine
>> >> Chief, Biostatistics and Informatics
>> >> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> >> Baltimore VA Medical Center
>> >> 10 North Greene Street
>> >> GRECC (BT/18/GR)
>> >> Baltimore, MD 21201-1524
>> >> (Phone) 410-605-7119
>> >> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>
>> >> Confidentiality Statement:
>> >> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> >
>> >
>> > Confidentiality Statement:
>> > This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> 1352 Lighthouse Avenue
>> Pacific Grove, CA 93950-2097
>> 
>> e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
>> voice: (831)-648-9029
>> fax: (831)-648-8440
>> www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jdnewmil at dcn.davis.CA.us  Sat Apr 12 20:07:59 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 12 Apr 2014 11:07:59 -0700
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <534941B4020000CB001073AB@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
	<53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
	<4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>
	<CAFFQM6ZXsnZCocpH0rhiiiRFX02vq6gEBHjjQyVSYmsLsy-aXg@mail.gmail.com>
	<534941B4020000CB001073AB@smtp.medicine.umaryland.edu>
Message-ID: <cddac0e8-c529-42ab-905d-a9d2a4d13b92@email.android.com>

That you cannot reach your home LAN from the Internet without learning something about networking is a good thing, since that offers some hope that the Russian Mafia can't use your computer to launch criminal activities against the rest of us, either.

Studying how to set up a VPN on your network router was a good recommendation that you have not acknowledged. However, that subject is networking, not R, and is definitely off topic here. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 12, 2014 10:37:46 AM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>Grand,
>Thank you. I have been able to use my iPad to connect to a server
>running RStudio server as described in an earlier email and can use the
>virtual keyboard, which works but is not convenient as one needs to go
>from keyboard screen to another. 
>My current problem is that while I can get everything to work when my
>iPad is on my local network, I don't know how to access my server from
>outside my LAN. I know my server's private IP address I know my cable
>modem's external IP address, but I have no idea what IP address to
>enter in my iPad, when my iPad is outside my LAN trying to access my
>server.
>John
>
>> On Apr 12, 2014, at 11:46 AM, "Frans Marcelissen
><fransiepansiekevertje at gmail.com>" <fransiepansiekevertje at gmail.com>
>wrote:
>> 
>> Running rstudio (server) on an ipad.
>> I do'nt have an ipad anymore, but some years ago I noticed that
>rstudio (server) worked fine on an ipad of you have a separate
>keyboard. It does not work with the virtual keyboard. The same is true
>with android tablets.
>> Frans
>> 
>> 
>> 2014-04-12 3:38 GMT+02:00 Roy Mendelssohn <roy.mendelssohn at noaa.gov>:
>>> GIYF - Google VPN and iPad.
>>> 
>>> -Roy
>>> 
>>> On Apr 11, 2014, at 6:34 PM, "John Sorkin"
><JSorkin at grecc.umaryland.edu> wrote:
>>> 
>>> > David,
>>> > Thank you for your assistance.
>>> > I have, in fact been able to get things to work, at least when my
>iPad is on my local network. I had to do the following:
>>> > (1) install Linux (I used linux Mint) on a computer on my LAN
>>> > (2) install R on the linux box (accomplished using the Mint
>package manager)
>>> > (3) install Rstudio and RStudio server on the linux box
>(accomplished using the Mint package manager)
>>> > (4) obtain the linux computer's internal IP address (obtained
>using ifconfig command entered at a terminal). The internal IP address
>was 192.168.0.101
>>> > (5) use a browser on my iPad (I used google chrome, I believe
>firefox would also work) to connect to the linux box, requesting a
>connection using port 8787
>>> > In the brower I entered http://192.168.0.101:8787
>>> > This works like a charm; I can now control RStudio, which runs on
>the Linux box, by typing on my iPad. I thus gain access to RStudio on
>my iPad, RStudio works exactly as if it were running directly on my
>iPad, hooray!
>>> >
>>> > My remaining problem is to determine how I can gain access to the
>linux box from outside my LAN. I know the IP address of my cable router
>xx.xx.xx.xx (forgive me I am not listing my external IP address for
>security reasons), but I don't know how I can address the linux box
>from outside my LAN. Clearly I can't use 192.168.0.101 as it is an
>internal IP address, and I can't use the external IP address,
>xx.xx.xx.xx as it is the address of my cable box, not the address of
>the Linux box behind the cable modem. If I can figure how to address
>the linux box from outside my LAN my problem will be solved! If anyone
>can help me with this last problem I would be grateful. I know it is
>not strictly an R question, but in my case it is related to running R,
>at least on my iPad.
>>> > John
>>> >
>>> >
>>> >
>>> >
>>> > John David Sorkin M.D., Ph.D.
>>> > Professor of Medicine
>>> > Chief, Biostatistics and Informatics
>>> > University of Maryland School of Medicine Division of Gerontology
>and Geriatric Medicine
>>> > Baltimore VA Medical Center
>>> > 10 North Greene Street
>>> > GRECC (BT/18/GR)
>>> > Baltimore, MD 21201-1524
>>> > (Phone) 410-605-7119
>>> > (Fax) 410-605-7913 (Please call phone number above prior to
>faxing)
>>> >>>> David Winsemius <dwinsemius at comcast.net> 4/11/2014 9:06 PM >>>
>>> >
>>> > On Apr 11, 2014, at 2:00 PM, John Sorkin wrote:
>>> >
>>> >> I bemoan the fact that I can not run R or Rstudio on my iPad. A
>possible work around would be to set up a server (probably under
>Linux), and get the server to present a web page that to would allow me
>to run R on the server.
>>> >
>>> >
>>> > I fear that the response so far has been focussing on RStudio when
>the desire at its minimum was to run interactive R session on an iPad.
>Why not use an SSH client to connect to a machine that recognizes the
>security keys?
>>> >
>>> >
>https://itunes.apple.com/us/app/server-auditor-ssh-client/id549039908?mt=8
>>> >
>>> > I think RServe could be the server end, but I do not know how
>graphics devices would be handled. Maybe just create pdfs on the
>server? Is there a sendfile function that an SSH client could receive
>and allow the iPad user to open? I think the stats-rosuda-devel mailing
>list might be the place to find experienced users of such techniques.
>>> >
>>> > --
>>> > David.
>>> >
>>> >
>>> >> I have searched the web for a clear, simple answer on how to do
>this but can not find one. There are answers, but not for someone who
>has not built a Linux server. Can someone provide either a reference
>to, or a short explanation of how I can build the server, get R or
>RStudio to run on it, and get the server and its R or RStudio program
>available to me on my iPad? I can probably find guidance on how to
>build an Apache server under Linux.
>>> >> Thank you,
>>> >> John
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> John David Sorkin M.D., Ph.D.
>>> >> Professor of Medicine
>>> >> Chief, Biostatistics and Informatics
>>> >> University of Maryland School of Medicine Division of Gerontology
>and Geriatric Medicine
>>> >> Baltimore VA Medical Center
>>> >> 10 North Greene Street
>>> >> GRECC (BT/18/GR)
>>> >> Baltimore, MD 21201-1524
>>> >> (Phone) 410-605-7119
>>> >> (Fax) 410-605-7913 (Please call phone number above prior to
>faxing)
>>> >>
>>> >> Confidentiality Statement:
>>> >> This email message, including any attachments, is for the sole
>use of the intended recipient(s) and may contain confidential and
>privileged information.  Any unauthorized use, disclosure or
>distribution is prohibited.  If you are not the intended recipient,
>please contact the sender by reply email and destroy all copies of the
>original message.
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible
>code.
>>> >
>>> > David Winsemius
>>> > Alameda, CA, USA
>>> >
>>> >
>>> >
>>> > Confidentiality Statement:
>>> > This email message, including any attachments, is for the sole use
>of the intended recipient(s) and may contain confidential and
>privileged information.  Any unauthorized use, disclosure or
>distribution is prohibited.  If you are not the intended recipient,
>please contact the sender by reply email and destroy all copies of the
>original message.
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the
>U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> 1352 Lighthouse Avenue
>>> Pacific Grove, CA 93950-2097
>>> 
>>> e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
>>> voice: (831)-648-9029
>>> fax: (831)-648-8440
>>> www: http://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice"
>-MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:16}}



From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Apr 12 20:08:28 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sat, 12 Apr 2014 20:08:28 +0200
Subject: [R] R, RStudio, and a server for my iPad.
In-Reply-To: <534941B4020000CB001073AB@smtp.medicine.umaryland.edu>
References: <5348534F.6050901@yorku.ca>
	<53481F96020000CB0010724B@smtp.medicine.umaryland.edu>
	<829AFB79-4323-4557-BC33-F7C319B4DA8F@comcast.net>
	<53485FD6020000CB001072A6@smtp.medicine.umaryland.edu>
	<4377D419-03F1-4F09-962F-710B8E20068B@noaa.gov>
	<CAFFQM6ZXsnZCocpH0rhiiiRFX02vq6gEBHjjQyVSYmsLsy-aXg@mail.gmail.com>,
	<534941B4020000CB001073AB@smtp.medicine.umaryland.edu>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DA788F1D7@UM-MAIL4112.unimaas.nl>

You will have to enter the external IP address and then use port forwarding.

Just google for that term (port forwarding) ... For example:

http://www.howtogeek.com/66214/how-to-forward-ports-on-your-router/
http://en.wikipedia.org/wiki/Port_forwarding

Best,
Wolfgang
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of John Sorkin [jsorkin at grecc.umaryland.edu]
Sent: Saturday, April 12, 2014 7:37 PM
To: fransiepansiekevertje at gmail.com
Cc: r-help at r-project.org
Subject: Re: [R] R, RStudio, and a server for my iPad.

Grand,
Thank you. I have been able to use my iPad to connect to a server running RStudio server as described in an earlier email and can use the virtual keyboard, which works but is not convenient as one needs to go from keyboard screen to another.
My current problem is that while I can get everything to work when my iPad is on my local network, I don't know how to access my server from outside my LAN. I know my server's private IP address I know my cable modem's external IP address, but I have no idea what IP address to enter in my iPad, when my iPad is outside my LAN trying to access my server.
John


From pertsou at gmail.com  Sat Apr 12 22:38:37 2014
From: pertsou at gmail.com (Endy BlackEndy)
Date: Sat, 12 Apr 2014 23:38:37 +0300
Subject: [R] Programing routine comp()
Message-ID: <CAGpBJKSuqujMAETEj7eS-XxJ+qs62+TacGTZPM5fW_6Sq6RT+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/f8870c7e/attachment-0001.pl>

From romain at r-enthusiasts.com  Fri Apr 11 14:48:43 2014
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 11 Apr 2014 14:48:43 +0200
Subject: [R] [R-pkgs] Rcpp11 3.1.0 is on CRAN.
Message-ID: <324CDF70-7468-4A9D-9950-93A809CFB527@r-enthusiasts.com>

Hello, 

R version 3.1.0 was released yesterday, and as always is welcome with great pleasure. One
of the features that is of particular interest to me is the support for C++11. 
I would encourage you to read 
[Writing R Extensions](http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Using-C_002b_002b11-code)
to familiarize yourself with 
what this supports means and how to take advantage of it. C++11 is a major 
upgrade of the C++ standard, making C++ more expressive, more efficient, more
fun to use and teach. It almost feels like a new language if you embrace it fully. 
The standards committee has done a great job of maintaining compatibility, which means
that code written with older standard will still compile and work. 
However, with C++11 code you write today and tomorrow will not be the same as code 
you used to write with C++98. 

To get the best of what C++11 has to offer, I'm releasing Rcpp11 today. Rcpp11
is a complete redesign of Rcpp, focused on C++11. Rcpp11 is a header only 
C++ library, distributed as an R package on CRAN, that facilitates embedding 
C++ code in R packages. 

I'll try to keep this announcement short. More details will follow on dedicated 
channels. I will just highlight a few aspects of Rcpp11 that are high level 
enough for such an annoucement. 

Header Only
===========

Rcpp11 is header only -- it consists only of a set of `.h` files. Rcpp11 has no
`.cpp` files, and no R functions. This eliminates many problems inherent to 
binary compatibility that Rcpp has been fighting with for years. 

The recommended way to use Rcpp11 is to have these lines in the `DESCRIPTION` file 
of your package: 

```
LinkingTo: Rcpp11
SystemRequirements: C++11
```

Modernized code base
====================

Many features of the original Rcpp code base are the consequence of my 
learning C++ and the internal API of R. After a few years of experience, I can 
now admit that mistakes were made while designing it. Unfortunately for reasons
outside of my control, it is not possible to fix these mistakes under the umbrella
of the Rcpp package. 

Things are radically different for Rcpp11, which I will maintain. Over the past 
few months, I have considered many features of the code base and either decided
to abandon them or upgrade them to the level of expectation we should have for a 
modern R/C++ interface. 


API
---

Most of what is usually called the API has been retained. I do not guarantee
low level compatibililty, but there is conceptual compatibility. For example, 
Rcpp11 contains all the classes we would expect: `NumericVector`, `List`, ...

I'm not going into details about what the individual differences are. Instead I 
will start documenting how to use the API provided by Rcpp11. 


Attributes
----------

Attributes is probably the best feature that has ever been contributed to Rcpp. It 
gives a mechanism for decorating C++ functions, parsing these decorations and generating
scaffolding code around them.  

This feature has not been retained in Rcpp11, but instead has been moved into a 
new package called [attributes](https://github.com/Rcpp11/attributes), 
which is being developed and will be released later. 

It is worth mentioning that code generated by Rcpp's `compileAttributes` function
should be compilable against Rcpp11. When attributes becomes available it will 
provide a more flexible approach, and provide facilities for package authors to
implement and use their own attributes.


Modules
-------

Rcpp modules was not retained as part of Rcpp11. This was a hard decision, because
I invested a lot of time developing the original code behind Rcpp modules. However
modules have significant problems which make them hard to maintain. Modules are 
also very demanding on the compiler. 

However, I still believe that the promise of Rcpp modules -- exposing C++ classes 
at the R level -- is very worthwhile. My plan is to redesign it using a different 
approach, more oriented towards code generation, ? la attributes. 


Time and Date classes
---------------------

I decided to abandon the classes responsible to handling dates and times. Better 
classes might be introduced when I'm comfortable with the design. Design 
documents and pull requests are welcome. 


Further discussion
==================

Please consider subscribing to the R and C++ mailing list that was created a few 
days ago: https://groups.google.com/forum/#!forum/r-and-cpp

The scope of the mailing list is broader, the intention is to discuss all things 
R and C++. Questions about Rcpp11, Rcpp or anything related to using C++ and R
are welcome. As of today, 37 participants are registered. Please consider 
replying to this annoucement email through the mailing list. 

Rcpp11 is developed through the Rcpp11 organisation on github. Feel free
to report issues and submit pull requests. https://github.com/Rcpp11/Rcpp11


Versioning
==========

The pattern that has been decided for versions of Rcpp11 is to use the same 
number as the mininum version of R required. Therefore this initial version
is Rcpp11 3.1.0 and interim releases might be called 3.1.0.1, 3.1.0.2, etc ...

Documentation
=============

There is no documentation yet. I personally find the heterogeneous sources
of documentation for Rcpp to be confusing. I have three goals in terms of 
documentation for Rcpp11:

 - An article is being written. This will be a casual introduction to 
   interesting features of C++11 and Rcpp11.
 - API documentation. My goal is to have a website that will make easy to 
   browse internal documentation (what to do with a NumericVector, ...) similar
   to cplusplus.com or something. 
 - I have started working on a R and C++ book. As I personally consider that 
   C++ = C++11 from now on, the book will mainly cover uses cases of Rcpp11. 

I hope to that between now and useR this year, I will make progress on the 2 first 
items of the previous list. 

Licensing
=========

Rcpp11 is licensed under the MIT license.

Future
======

This is the first release, it has required a lot of time and effort from me and
Kevin Ushey who has stepped in as a regular contributor to the package. 

This sets us with a new foundation for interfacing R and C++ for years to come. 
Many features of C++11 such as regular expressions and threads have not been 
leveraged yet with this initial release. 

C++ is more alive than ever, a new minor update of the standard is likely to 
be released this year and supported at day 0 by popular compilers. At this point
I do not anticipate to start working on a Rcpp14 package. 

In a few years (the ETA is currently 2017), a new major version of the C++ standard
will be released. It is too soon to say if it will be worthwhile to have a Rcpp17, 
but from a casual reading of the expected features, I'd say it is likely. 

I sincerely hope you will enjoy working with Rcpp11.

Romain

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages



From ahoerner at rprogress.org  Sun Apr 13 00:36:41 2014
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Sat, 12 Apr 2014 15:36:41 -0700
Subject: [R] Fwd: Selecting rows from a DF where the value in a selected
 column matches any element of a vector.
In-Reply-To: <CA+t4QRo82pRLZGbALySG-ArTJcG70n2KFbH1dJ_CU4tb0684NQ@mail.gmail.com>
References: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
	<CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>
	<CA+t4QRo82pRLZGbALySG-ArTJcG70n2KFbH1dJ_CU4tb0684NQ@mail.gmail.com>
Message-ID: <CA+t4QRoZANMYF49HMAgjmG7bAVF=sgzVoVRBpZE9Bv5R6xMsyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/daad4b2f/attachment-0001.pl>

From sarah.goslee at gmail.com  Sun Apr 13 00:52:04 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 12 Apr 2014 18:52:04 -0400
Subject: [R] Selecting rows from a DF where the value in a selected
	column matches any element of a vector.
In-Reply-To: <CA+t4QRoZANMYF49HMAgjmG7bAVF=sgzVoVRBpZE9Bv5R6xMsyg@mail.gmail.com>
References: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
	<CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>
	<CA+t4QRo82pRLZGbALySG-ArTJcG70n2KFbH1dJ_CU4tb0684NQ@mail.gmail.com>
	<CA+t4QRoZANMYF49HMAgjmG7bAVF=sgzVoVRBpZE9Bv5R6xMsyg@mail.gmail.com>
Message-ID: <2B5E2FE3-D4B2-4597-8462-30E92CD7E0FA@gmail.com>

Hi Andrew,

On Apr 12, 2014, at 6:36 PM, Andrew Hoerner <ahoerner at rprogress.org> wrote:

> Thanks Sarah! That worked!
> 
> And you are quite right about the absence of parentheses and "EC07_A1$" 's.
> I apologize for sending that code snip -- I am not quite sure how I managed
> to do it, since I had already fixed those problems and changed the code in
> order to get the error message I posted.
> 
> Apropos of nothing in particular, before I could successfully impliment
> your fix, I also had to learn another new thing. When saving a CSV file
> with write.table, if you use sep=", " (that's double-quote comma space
> double-quote) R puts the space _inside_ the quotation marks around
> character variables. I'm not sure I would call that a bug, but I bet more
> people are surprised by it than expect it.

It shouldn?t; that?s incorrect. Can you provide a reproducible example?

When I look at your code & my reply, I notice that the quote marks are wrong too; could that be the actual problem?

Sarah

> 
> Again, many thanks!
> 
> Andrew
> 
> 
> On Sat, Apr 12, 2014 at 6:04 AM, Sarah Goslee <sarah.goslee at gmail.com>wrote:
> 
>> You need %in% instead.
>> 
>> This is untested, but something like this should work:
>> 
>> 
>> ECwork  <-  EC07_A1[ EC07_A1$GEO_ID %in% c("01000US", "04000US06",
>> "33000US488",
>> "31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000") &
>>      EC07_A1$SECTOR %in% c("32", "33", "42", 44", 45", 51", 54", 61",
>> "71",
>> "81"), ]
>> 
>> (Note that your original code snippet had a shortage of ) and didn't
>> specify the data frame from which to take the columns.)
>> 
>> Sarah
>> 
>> On Sat, Apr 12, 2014 at 8:36 AM, Andrew Hoerner <ahoerner at rprogress.org>
>> wrote:
>>> Dear Folks--
>>> I have a file with 3 million-odd rows of data from the 2007 U.S. Economic
>>> Census. I am trying to pare it down to a subset of rows that both (1) has
>>> any one of a vector of NAICS economic sector codes, and (2) also has any
>>> one of a vector of geographic ID codes.
>>> 
>>> Here is the code I am trying to use.
>>> 
>>> ECwork  <-  EC07_A1[ any(GEO_ID == c("01000US", "04000US06",
>> "33000US488",
>>> "31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000")
>> &
>>>      any(SECTOR == c("32", "33", "42", 44", 45", 51", 54", 61", "71",
>>> "81"), ]
>>> 
>>> I get back the following error:
>>> 
>>> Warning message:
>>> In EC07_A1$SECTOR == c("32", "33", "42", "44", "45", "51", "54",  :
>>>  longer object length is not a multiple of shorter object length
>>> 
>>> I see what R is doing.  Instead of comparing each element of the column
>>> SECTOR to the row vector of codes, and returning a logical vector of the
>>> length of SECTOR with rows marked as TRUE that match any of the codes, it
>>> is lining my code list up with SECTOR as a column vector and doing
>>> element-by-element testing, and then recycling the code list over three
>>> million rows. But I am not sure how to make it do what I want -- test the
>>> sector code in each row against the vector of code I am looking for. I
>>> would be grateful if anyone could suggest an alternative that would
>> achieve
>>> my ends.
>>> 
>>> Oh, and I would add, if there is a way of correctly using doing this with
>>> the extract function [], I would like to know what it is. If not, I guess
>>> I'd like to know that too.
>>> 
>>> Sincerely, Andrew Hoerner
>>> 
>>> --
>>> J. Andrew Hoerner
>>> Director, Sustainable Economics Program
>>> Redefining Progress
>>> (510) 507-4820
>>> 
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 



From ahoerner at rprogress.org  Sun Apr 13 01:04:00 2014
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Sat, 12 Apr 2014 16:04:00 -0700
Subject: [R] Selecting rows from a DF where the value in a selected
 column matches any element of a vector.
In-Reply-To: <CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>
References: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
	<CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>
Message-ID: <CA+t4QRrxS+rOhQk8cnyOf8xXbFdigWtac1SM7-DhRRO42yXhPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/d39d0eff/attachment-0001.pl>

From enrraco at fimif.upt.al  Sun Apr 13 01:20:30 2014
From: enrraco at fimif.upt.al (drunkenphd)
Date: Sat, 12 Apr 2014 16:20:30 -0700 (PDT)
Subject: [R] Pie charts using plotGooglemaps
Message-ID: <1397344830813-4688678.post@n4.nabble.com>

Hi, I am trying to add some pie charts in a list of coordinates. 
Please find attached data I am using 
Basically I am using this commands: 
 data<-read.csv(file.choose(),header=T) coordinates(data) = ~ x + y
proj4string(data) = CRS("+proj=longlat +datum=WGS84") # colPalette defines
colors for plot mychart<-segmentGoogleMaps(data,
zcol=c('City','Village'),mapTypeId='ROADMAP',
filename='myMap4.htm',colPalette=c('#E41A1C','#377EB8'),
strokeColor='black') 

But a map with legends shows up without any points or pie chart
Attached my csv https://www.dropbox.com/s/pkvq6xz0ynwok9r/sample.csv
Regards






--
View this message in context: http://r.789695.n4.nabble.com/Pie-charts-using-plotGooglemaps-tp4688678.html
Sent from the R help mailing list archive at Nabble.com.



From ligges at statistik.tu-dortmund.de  Sun Apr 13 01:22:34 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 13 Apr 2014 01:22:34 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
Message-ID: <5349CABA.7000807@statistik.tu-dortmund.de>



On 12.04.2014 22:39, Alpesh Pandya wrote:
> Thank you for response Uwe. I tried multiple times by downloading the zip
> file from many sources but still the same error. This is a major road block
> for me in using R. Appreciate any help on this.

Please ask your local IT staff.

I get, using the same mirror:

 > options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
 > install.packages("XML", lib="d:/temp")
trying URL 
'http://watson.nci.nih.gov/cran_mirror/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
Content type 'application/zip' length 4288136 bytes (4.1 Mb)
opened URL
downloaded 4.1 Mb

package ?XML? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         d:\temp\RtmpqMqL8L\downloaded_packages



Best,
Uwe Ligges





>
>
> On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
>> wrote:
>
>> Works for me.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>
>>> Using install.package('XML') command produces this error:
>>>
>>> trying URL
>>> '
>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>> contrib/3.0/XML_3.98-1.1.zip
>>> '
>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>> opened URL
>>> downloaded 4.1 Mb
>>>
>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>> "Type")) :
>>>     cannot open the connection
>>> In addition: Warning messages:
>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>>     downloaded length 4276224 != reported length 4288136
>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>     cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
>>> file or directory'
>>>
>>>
>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip directly from
>>> cran
>>> site. But this zip file is not a valid archive (cannot open using winzip).
>>> Also trying to install using this downloaded file produces the following
>>> error:
>>>
>>> Installing package into 'C:/Users/APandya/Documents/R/win-library/3.0'
>>> (as 'lib' is unspecified)
>>> Warning in install.packages :
>>>     error 1 in extracting from zip file
>>> Warning in install.packages :
>>>     cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
>>> file or directory'
>>> Error in install.packages : cannot open the connection
>>>
>>> I  downloaded this zip file from multiple sources and tried to install
>>> with
>>> same result.
>>>
>>>
>
>



From jim at bitwrit.com.au  Sun Apr 13 01:57:18 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 13 Apr 2014 09:57:18 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <1397344830813-4688678.post@n4.nabble.com>
References: <1397344830813-4688678.post@n4.nabble.com>
Message-ID: <5349D2DE.2080203@bitwrit.com.au>

On 04/13/2014 09:20 AM, drunkenphd wrote:
> Hi, I am trying to add some pie charts in a list of coordinates.
> Please find attached data I am using
> Basically I am using this commands:
>   data<-read.csv(file.choose(),header=T) coordinates(data) = ~ x + y
> proj4string(data) = CRS("+proj=longlat +datum=WGS84") # colPalette defines
> colors for plot mychart<-segmentGoogleMaps(data,
> zcol=c('City','Village'),mapTypeId='ROADMAP',
> filename='myMap4.htm',colPalette=c('#E41A1C','#377EB8'),
> strokeColor='black')
>
> But a map with legends shows up without any points or pie chart
> Attached my csv https://www.dropbox.com/s/pkvq6xz0ynwok9r/sample.csv

Hi drunkenphd,
If you have the coordinates, you can use the floating.pie function in 
the plotrix package.

Jim



From enrraco at fimif.upt.al  Sun Apr 13 02:04:09 2014
From: enrraco at fimif.upt.al (drunkenphd)
Date: Sat, 12 Apr 2014 17:04:09 -0700 (PDT)
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <5349D2DE.2080203@bitwrit.com.au>
References: <1397344830813-4688678.post@n4.nabble.com>
	<5349D2DE.2080203@bitwrit.com.au>
Message-ID: <1397347449708-4688683.post@n4.nabble.com>

Jim thx,
Can you please provide me an example how to use my csv data with plotrix
float.pie???



--
View this message in context: http://r.789695.n4.nabble.com/Pie-charts-using-plotGooglemaps-tp4688678p4688683.html
Sent from the R help mailing list archive at Nabble.com.



From sarah.goslee at gmail.com  Sun Apr 13 02:19:24 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 12 Apr 2014 20:19:24 -0400
Subject: [R] Selecting rows from a DF where the value in a selected
	column matches any element of a vector.
In-Reply-To: <CA+t4QRrxS+rOhQk8cnyOf8xXbFdigWtac1SM7-DhRRO42yXhPA@mail.gmail.com>
References: <CA+t4QRqURybY11Te-o2mCtmLsXTDH5RgnW10XxS7SvDiZoPSdw@mail.gmail.com>
	<CAM_vju=2S0gwesxg2jijxj8T18vM8p0m1nVo3e052FVjzXKeng@mail.gmail.com>
	<CA+t4QRrxS+rOhQk8cnyOf8xXbFdigWtac1SM7-DhRRO42yXhPA@mail.gmail.com>
Message-ID: <155F7431-8352-4368-93F6-B7D35035B6BE@gmail.com>

See inline.

On Apr 12, 2014, at 7:04 PM, Andrew Hoerner <ahoerner at rprogress.org> wrote:

> Oops! Spoke too soon.
> 
> Your fix fixed the problem I was having before, but it turns out the test is now accepting every line. So there is still some problem with the logic or with my implimentation of it.
> 
> I thought I should produce a reproducible example without 3 million lines of data. I made a version with only the geography information and test. Here is the code I am now using, applied to a file with only the first 8 lines of my geo data in it:

Please use dput() to provide data, rather than copy & paste, since that?s not reproducible.


> 
> First I read the data in and print it out:
> 
> GEOshort.DF <- read.table("C:\\Users\\andrewH\\Documents\\Oakland Tech Project\\GEO_short.csv", 
>                       header = FALSE, sep = ",", quote = "\"",  dec = ".", skip=1, col.names=
>                       c("originalRow", "GEO_ID", "GEOGRAPHY"), fill = TRUE, colClasses="character")
> 
> Which yields:
> 
> > GEOshort.DF
>   originalRow    GEO_ID     GEOGRAPHY
> 1           1   01000US United States
> 2        3115 04000US01       Alabama
> 3        5501 04000US02        Alaska
> 4        7924 04000US04       Arizona
> 5       10571 04000US05      Arkansas
> 6       14342 04000US06    California
> 7       17913 04000US08      Colorado
> 8       20442 04000US09   Connecticut
> 
> 
> Then I try to select the rows that match my geo-codes:
> 
> GEOextract.DF  <- GEOshort.DF[
>   any(GEOshort.DF$GEO_ID %in% c("01000US", "04000US06", "33000US488", "31000US41860", 
>                               "31400US4186036084", "05000US06001", "E6000US0600153000")), ]

But that?s not what I suggested: if you use any(), then if there are any matches it will return TRUE and by expansion you?ll get all the rows. You need:

GEOextract.DF  <- GEOshort.DF[
GEOshort.DF$GEO_ID %in% c("01000US", "04000US06", "33000US488", "31000US41860", 
                              "31400US4186036084", "05000US06001", "E6000US0600153000"), ]

You can check this yourself by running just the logical portion: compare

any(GEOshort.DF$GEO_ID %in% c("01000US", "04000US06", "33000US488", "31000US41860", 
                              "31400US4186036084", "05000US06001", "E6000US0600153000"))
with

GEOshort.DF$GEO_ID %in% c("01000US", "04000US06", "33000US488", "31000US41860", 
                              "31400US4186036084", "05000US06001", ?E6000US0600153000")

> 
>         "... But pattern-matching doesn't equal comprehension."  --Peter Watts

Happy to help a Peter Watts fan. 

Sarah


> 
> 
> On Sat, Apr 12, 2014 at 6:04 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> You need %in% instead.
> 
> This is untested, but something like this should work:
> 
> 
> ECwork  <-  EC07_A1[ EC07_A1$GEO_ID %in% c("01000US", "04000US06", "33000US488",
> "31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000") &
>       EC07_A1$SECTOR %in% c("32", "33", "42", 44", 45", 51", 54", 61", "71",
> "81"), ]
> 
> (Note that your original code snippet had a shortage of ) and didn't
> specify the data frame from which to take the columns.)
> 
> Sarah
> 
> On Sat, Apr 12, 2014 at 8:36 AM, Andrew Hoerner <ahoerner at rprogress.org> wrote:
> > Dear Folks--
> > I have a file with 3 million-odd rows of data from the 2007 U.S. Economic
> > Census. I am trying to pare it down to a subset of rows that both (1) has
> > any one of a vector of NAICS economic sector codes, and (2) also has any
> > one of a vector of geographic ID codes.
> >
> > Here is the code I am trying to use.
> >
> > ECwork  <-  EC07_A1[ any(GEO_ID == c("01000US", "04000US06", "33000US488",
> > "31000US41860", "31400US4186036084" "05000US06001", "E6000US0600153000") &
> >       any(SECTOR == c("32", "33", "42", 44", 45", 51", 54", 61", "71",
> > "81"), ]
> >
> > I get back the following error:
> >
> > Warning message:
> > In EC07_A1$SECTOR == c("32", "33", "42", "44", "45", "51", "54",  :
> >   longer object length is not a multiple of shorter object length
> >
> > I see what R is doing.  Instead of comparing each element of the column
> > SECTOR to the row vector of codes, and returning a logical vector of the
> > length of SECTOR with rows marked as TRUE that match any of the codes, it
> > is lining my code list up with SECTOR as a column vector and doing
> > element-by-element testing, and then recycling the code list over three
> > million rows. But I am not sure how to make it do what I want -- test the
> > sector code in each row against the vector of code I am looking for. I
> > would be grateful if anyone could suggest an alternative that would achieve
> > my ends.
> >
> > Oh, and I would add, if there is a way of correctly using doing this with
> > the extract function [], I would like to know what it is. If not, I guess
> > I'd like to know that too.
> >
> > Sincerely, Andrew Hoerner
> >
> > --
> > J. Andrew Hoerner
> > Director, Sustainable Economics Program
> > Redefining Progress
> > (510) 507-4820
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> 
> 
> -- 
> J. Andrew Hoerner
> Director, Sustainable Economics Program
> Redefining Progress
> (510) 507-4820



From mfirke1 at swarthmore.edu  Sat Apr 12 21:29:37 2014
From: mfirke1 at swarthmore.edu (Marian L. Firke)
Date: Sat, 12 Apr 2014 15:29:37 -0400 (EDT)
Subject: [R] Adding Nested Random Effects to MCMCglmm
In-Reply-To: <64552147.2146390.1397330966952.JavaMail.zimbra@swarthmore.edu>
Message-ID: <1701963511.2146445.1397330977687.JavaMail.zimbra@swarthmore.edu>

Dear R Experts, 

Does anyone have advice for how to nest random effects in the MCMCglmm package? 

Right now, I am running my models with Individual as a random effect; however, the 25 individuals in my study are birds taken from 13 different nests, so I feel that a more accurate model would nest the variable Individual (called RNR in my code) within the variable Nest ID. 

I am trying to run both univariate and bivariate mixed models using the MCMCglmm package. (My interest is in calculating repeatability estimates using the univariate models, and in partitioning out the within-individual and between-individual correlations using the bivariate models.) I am also trying to include a fixed effect (SMI) but am not sure that I am doing this correctly for either case. 



Example Univariate MM: 
Cort0.mcmc<-MCMCglmm(CORT0_LOG10_Z~SMI_CEN, random=~indiv, family="gaussian", data=cort0.data,verbose=FALSE)

CORT0_LOG10_Z is the variable of interest (which has been measured repeatedly for each given individual) 
RNR is individual ID 
SMI_CEN is a fixed effect that varies both within and between individuals

Example piece of data frame: 

  RNR HPA CORT0_LOG10_Z  SMI_CEN  NEST_ID
1  AR04273   1   -3.29844317 1.236170087  3
2  AR04273   2   -0.51328002 0.122035902  3
3  AR04281   1    0.83631319 1.212914325  8


Example Bivariate MM: 
cort0_cort15.bivarC.mcmc<-MCMCglmm(cbind(CORT0_std,CORT15_std)~(SMI_cen), random=~us(trait):RNR, rcov=~us(trait):units, family=c("gaussian","gaussian"), prior=prior.bivar, nitt=1300000,thin=1000,burnin=300000, data=cort0_cort15,verbose=FALSE)

CORT0_std and CORT15_std are the 2 variables of interest
RNR is individual ID 
SMI_cen is a fixed effect that varies both within and between individuals

Example piece of data frame: 
RNR      SMI  SMI_avg      SMI_dev  CORT0 CORT15      SMI_cen SMI_avg_cen   CORT0_std   CORT15_std  NEST_ID
1  AR04273 18.03640 17.48987  0.546522102  0.460  4.590  1.236170087  0.73332960 -3.80922656 -3.170123623  3
2  AR04273 16.94335 17.48987 -0.546522102  3.493 13.604  0.122035902  0.73332960 -0.04862913 -0.480133012  3
3  AR04281 15.63367 15.86610 -0.232427804  4.875 13.507 -1.212914325 -1.05393597  0.56974795 -0.497849822  8

I am basing my code off of the code supplied in the 2013 paper by Dingemanse and Dochtermann about applying linear mixed modelling to behavioral ecology. 

Does anyone have advice for how to nest RNR within Nest ID, as well as insight into whether I have coded the fixed effect SMI correctly? 


Many thanks, 
Marian



From james at crosb.ie  Sat Apr 12 20:03:03 2014
From: james at crosb.ie (jcrosbie)
Date: Sat, 12 Apr 2014 11:03:03 -0700 (PDT)
Subject: [R] How two have two legends on a chart with different groups?
Message-ID: <1397325783517-4688666.post@n4.nabble.com>

I'm trying to have two legends on a chart, with two sets of data with
subgroups. Currently ggplot is are merging the to sets of data together.

I would like to have the vertical lines in there own legend and not affect
the colour shading or show up in the "type" legend.

How would I go about doing this?

df <- data.frame(val1=rnorm(300, 75, 10), val2=rnorm(300, 75,
10),type=rep(c("A", "B", "C"),100))

cuts1 <- data.frame(Stats="Stat A", vals=c(43, 70, 90))
cuts2 <- data.frame(Stats="Stat B", vals=cuts2 <- c(46, 79, 86))

cuts <- rbind(cuts1,cuts2)

ggplot(df, aes(x=val1, y=val2, group=type)) +
geom_line(aes(colour=type))+
geom_point(aes(colour=type))+
geom_vline(data=cuts, 
         aes(xintercept=vals, 
             linetype=Stats,
             colour = Stats),
         show_guide = TRUE)
I got the idea of how to do this from: Add vline to existing plot and have
it appear in ggplot2 legend?



--
View this message in context: http://r.789695.n4.nabble.com/How-two-have-two-legends-on-a-chart-with-different-groups-tp4688666.html
Sent from the R help mailing list archive at Nabble.com.



From alpeshpandya at gmail.com  Sat Apr 12 22:39:41 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Sat, 12 Apr 2014 16:39:41 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <5348725B.7070404@statistik.tu-dortmund.de>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
Message-ID: <CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/eb64fa12/attachment-0001.pl>

From Virginie.Rondeau at isped.u-bordeaux2.fr  Tue Apr  8 09:09:48 2014
From: Virginie.Rondeau at isped.u-bordeaux2.fr (Rondeau Virginie)
Date: Tue, 8 Apr 2014 09:09:48 +0200
Subject: [R] [R-pkgs] frailtypack package 2.6
Message-ID: <5343A0BC.9040105@isped.u-bordeaux2.fr>

Dear R users,

the frailtypack package, for the analysis of correlated survival data, 
has been updated on CRAN.

The major changes in version 2.6 are:

* Fit now a multivariate gaussian frailty model (two types of recurrent 
events and a terminal event). For instance here is a model that fits a 
weibull multivariate gaussian frailty model with different adjustments:

* modMultiv.weib <- 
multivPenal(Surv(TIMEGAP,INDICREC)~cluster(PATIENT)+v1+v2+ 
event2(INDICMETA)+terminal(INDICDEATH),formula.Event2=~v1+v2+v3, 
formula.terminalEvent=~v1,data=dataMultiv,hazard="Weibull") *

* New dynamic tool of prediction probabilities in Cox models, standard 
shared frailty models or joint frailty models.

* Concordance measures for clustered data.

* initialization of regression coefficients, variance of the random 
effects, and alpha now available in joint frailty models. Moreover, with 
'Alpha="none"', frailtyPenal can fit a joint model with a fixed alpha (=1).

* Interval-censored frailty models.

Best regards,

Virginie Rondeau, Alexandre Laurent




	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages



From alpeshpandya at gmail.com  Sun Apr 13 01:30:21 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Sat, 12 Apr 2014 19:30:21 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <5349CABA.7000807@statistik.tu-dortmund.de>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
Message-ID: <CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140412/7656201a/attachment-0001.pl>

From ruthy_ at hotmail.co.uk  Sun Apr 13 02:17:05 2014
From: ruthy_ at hotmail.co.uk (ruth harries)
Date: Sun, 13 Apr 2014 00:17:05 +0000
Subject: [R] Reading output of a GLMM run in R
Message-ID: <DUB128-W798F9C468F64F229485381AF560@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/0c65be61/attachment-0001.pl>

From ruthy_ at hotmail.co.uk  Sun Apr 13 02:28:43 2014
From: ruthy_ at hotmail.co.uk (ruth harries)
Date: Sun, 13 Apr 2014 00:28:43 +0000
Subject: [R] FW: Reading output of a GLMM run in R
In-Reply-To: <DUB128-W798F9C468F64F229485381AF560@phx.gbl>
References: <DUB128-W798F9C468F64F229485381AF560@phx.gbl>
Message-ID: <DUB128-W33CFE7498A22EDA44445B9AF560@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/0bd444cc/attachment-0001.pl>

From catagui at gmail.com  Sun Apr 13 08:41:39 2014
From: catagui at gmail.com (Catalina Aguilar Hurtado)
Date: Sun, 13 Apr 2014 16:41:39 +1000
Subject: [R] How to make a proper use of blocking in limma using voom
Message-ID: <CAAHBMXZ7oxyfGDb5AfB1O=md_t68HCRRpQqJJSgL2VA3_Ds2Jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/854dfa89/attachment-0001.pl>

From smartpink111 at yahoo.com  Sun Apr 13 12:11:54 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Apr 2014 03:11:54 -0700 (PDT)
Subject: [R] mean calculations from a dframe column
Message-ID: <1397383914.51315.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Andr?,?

Your codes were missing in some information. If your code looks like this:

Measure <- function(a, b) { a <- as.matrix(a) b <- as.matrix(b) Mean <- apply(a, 2, mean, na.rm = TRUE) somme <- c() for (i in seq_along(b)) somme[i] <- divide(Mean, b[i]) somme <- as.data.frame(somme) return(somme)
} MeanManqu <- function(a) apply(a, 2, mean, na.rm = TRUE)
divide <- function(a, b) { 100 - (b/a * 100)
}

df <- read.table(text="a   b     c    d   e    f 1  1      4    1  2   54 2  2     33   2  56  32 3  3      5    3  87  24 4 NA     NA    4 76  21",sep="",header=TRUE)

as.data.frame(divide(MeanManqu(as.matrix(df[,2])), df[,3])) 

#divide(MeanManqu(as.matrix(df[, 2])), df[, 3])
#1                                           -100 

#2                                          -1550 

#3                                           -150
#4                                             NA 


fun1 <- function(beginColumn, by, data) { indx <- seq(beginColumn, ncol(data), by = by) as.data.frame(t(100 - (t(data[, indx])/colMeans(data[, indx - 1], na.rm = TRUE)) *  100))
}

fun1(3,3,df) 

#      c         f 

#1  -100  2.262443 

#2 -1550 42.081448
#3  -150 56.561086
#4    NA 61.990950 


A.K.




Hello!! I am stucked..... I have a dataframe with missing values. I want to divide each cell of my data frame by the mean from the previous column. Nevertheless I have several columns. I have the code that works for comparing one column and the mean of the previous one, but how can i ask R to repaeat it for seveal columns? Here are the data: a   b     c    d   e    f...... 1  1      4    1  2   54 2  2     33   2  56  32 3  3      5    3  87  24 4 NA     NA    4 76  21 My idea is to create a new dataframe  with for example: 100-(c/mean(b)*100) in one column, and the same for 100-(f/mean(e)*100) as results , etc. in this case column "a" and column "d" are just enumerating and are not useful. Here are my codes that are working for one trial only, but then.... Helppppp divide<-function(a,b) { 100-(b/a*100) MeanManqu<-apply(a,2,mean, na.rm=TRUE) > Measure<-function(a,b){ + a<-as.matrix(a) + b<-as.matrix(b) + Mean<-apply(a,2,mean, na.rm=TRUE) + somme <- c() +
 + for (i in seq_along(b) ) somme[i] <- divide(Mean,b[i]) + somme<-as.data.frame(somme) + return(somme) + } I tried several kind of loops and also apply, tapply... but failed I tried also something like that if it helps... as.data.frame(divide(MeanManqu(as.matrix(Data[,2])), Data[,3])) but this does  work for only one trial... One of the codes I tried: MeasureGd<-function(C){ + + i<-c(3,6,9,12,15) #these are the columns i want to use for my analysis + somme<-c() + for (i in seq_along(C[,i])){ + + + + somme[i]<- as.data.frame(divide(MeanManqu(as.matrix(C[,i-1])), C[,i])) #dividing a column by the mean of the previous one... + + } + return(somme) + } If someone as an idea or the key of this problem, I would be more than grateful!!! Andr?



From jim at bitwrit.com.au  Sun Apr 13 14:09:26 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 13 Apr 2014 22:09:26 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <1397347449708-4688683.post@n4.nabble.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
Message-ID: <534A7E76.4020500@bitwrit.com.au>

On 04/13/2014 10:04 AM, drunkenphd wrote:
> Jim thx,
> Can you please provide me an example how to use my csv data with plotrix
> float.pie???
>
x11(height=10)
map(xlim=c(19,21),ylim=c(39.5,42.5))
for(pp in 1:36) floating.pie(sampledf[pp,1],sampledf[pp,2],
  unlist(sampledf[pp,3:4]),radius=0.1)

Jim



From jrkrideau at inbox.com  Sun Apr 13 14:22:01 2014
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 13 Apr 2014 04:22:01 -0800
Subject: [R] FW: Reading output of a GLMM run in R
In-Reply-To: <DUB128-W33CFE7498A22EDA44445B9AF560@phx.gbl>
References: <dub128-w798f9c468f64f229485381af560@phx.gbl>
Message-ID: <4E70D126D10.00000313jrkrideau@inbox.com>

Can you resend the information in plain text?  It looks like you sent it in html format and it is very close to completely unreadable.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ruthy_ at hotmail.co.uk
> Sent: Sun, 13 Apr 2014 00:28:43 +0000
> To: r-help at r-project.org
> Subject: [R] FW: Reading output of a GLMM run in R
> 
> 
> 
> 
> 
> 
> Hi, I am a complete novice and dummy when it comes to statistics so I
> apologise in advance... I have been asked to report the results of my
> GLMMs (I ran two) in a table. This table must state: effect, standard
> error, test statistic, and P value, for all fixed effects. Unfortunately
> I am struggling to read my output. The out put is as follows, if anyone
> would be kind enough to help I would be very grateful and will know for
> future reference which bit equates to what (also I have been told my
> degrees of freedom are different for both the tests, could someone
> explain why this is?). GLMM 1-run for predictors of step length. Response
> variable = step length. fixed effects = depth and direction threshold.
> random factor = individual Models: m2: step ~ (1 | ind) m1: step ~ Depth
> * threshold + (1 | ind) Df AIC BIC logLik deviance Chisq Chi Df
> Pr(>Chisq) m2 3 373235 373259 -186615 373229 m1 8 373225 373290 -186605
> 373209 19.767 5 0.001382 ** --- Signif. codes: 0 ?***? 0.001 ?**? 0.01
> ?*? 0.05 ?.? 0.1 ? ? 1 GLMM 2 -run to investigate potential predictors of
> PDBA. response variables = depth and step length. fixed effect =
> direction threshold. random factor = Individual Models: m3: PDBA ~ Depth
> + (1 | ind) + thresholdepth m2: PDBA ~ step * threshold + Depth *
> threshold + (1 | ind) Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> m3 6 -48205 -48157 24109 -48217 m2 11 -48430 -48341 24226 -48452 235.1 5
> < 2.2e-16 *** --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
> ? ? 1 Models: m4: PDBA ~ step + (1 | ind) + step:threshold m2: PDBA ~
> step * threshold + Depth * threshold + (1 | ind) Df AIC BIC logLik
> deviance Chisq Chi Df Pr(>Chisq) m4 6 -48206 -48158 24109 -48218 m2 11
> -48430 -48341 24226 -48452 233.81 5 < 2.2e-16 *** --- Signif. codes: 0
> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!



From ligges at statistik.tu-dortmund.de  Sun Apr 13 15:46:13 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 13 Apr 2014 15:46:13 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>	<5348725B.7070404@statistik.tu-dortmund.de>	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
Message-ID: <534A9525.90209@statistik.tu-dortmund.de>



On 13.04.2014 01:30, Alpesh Pandya wrote:
> @Uwe I tried the same steps from office as well as home network with same
> results. Are you using windows 7 with R 3.0.3?
>
> I have seen same question being asked by others without any resolution. Is
> anything special about XML package? I am OK use older version of package
> but in archives there are no zip files (only gz files). Is windows platform
> not recommended for R?

Right, and you can try to install these from sources.
But I doubt you need it. You still have not told us if you tried another 
mirror to download the XML file from and what you local IT support tells 
you while your downloads are incomplete.

Best,
Uwe Ligges





>
>
> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
>> wrote:
>
>>
>>
>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>>
>>> Thank you for response Uwe. I tried multiple times by downloading the zip
>>> file from many sources but still the same error. This is a major road
>>> block
>>> for me in using R. Appreciate any help on this.
>>>
>>
>> Please ask your local IT staff.
>>
>> I get, using the same mirror:
>>
>>> options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>>> install.packages("XML", lib="d:/temp")
>>
>> trying URL 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>> contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> package 'XML' successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>          d:\temp\RtmpqMqL8L\downloaded_packages
>>
>>
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>
>>
>>
>>>
>>> On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>>> ligges at statistik.tu-dortmund.de
>>>
>>>> wrote:
>>>>
>>>
>>>   Works for me.
>>>>
>>>> Best,
>>>> Uwe Ligges
>>>>
>>>>
>>>>
>>>>
>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>>>
>>>>   Using install.package('XML') command produces this error:
>>>>>
>>>>> trying URL
>>>>> '
>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>> '
>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>> opened URL
>>>>> downloaded 4.1 Mb
>>>>>
>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>> "Type")) :
>>>>>      cannot open the connection
>>>>> In addition: Warning messages:
>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>>>>      downloaded length 4276224 != reported length 4288136
>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>>>>> :
>>>>>      cannot open compressed file 'XML/DESCRIPTION', probable reason 'No
>>>>> such
>>>>> file or directory'
>>>>>
>>>>>
>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip directly from
>>>>> cran
>>>>> site. But this zip file is not a valid archive (cannot open using
>>>>> winzip).
>>>>> Also trying to install using this downloaded file produces the following
>>>>> error:
>>>>>
>>>>> Installing package into 'C:/Users/APandya/Documents/R/win-library/3.0'
>>>>> (as 'lib' is unspecified)
>>>>> Warning in install.packages :
>>>>>      error 1 in extracting from zip file
>>>>> Warning in install.packages :
>>>>>      cannot open compressed file 'XML/DESCRIPTION', probable reason 'No
>>>>> such
>>>>> file or directory'
>>>>> Error in install.packages : cannot open the connection
>>>>>
>>>>> I  downloaded this zip file from multiple sources and tried to install
>>>>> with
>>>>> same result.
>>>>>
>>>>>
>>>>>
>>>
>>>
>
>



From rau at demogr.mpg.de  Sun Apr 13 12:02:30 2014
From: rau at demogr.mpg.de (Roland Rau)
Date: Sun, 13 Apr 2014 12:02:30 +0200
Subject: [R] Change position in package rgl
In-Reply-To: <534971D4.6050105@gmail.com>
References: <53495991.3090904@demogr.mpg.de> <534971D4.6050105@gmail.com>
Message-ID: <534A60B6.4050207@demogr.mpg.de>

On 04/12/2014 07:03 PM, Duncan Murdoch wrote:
> I think you could hack something like that (see the description in
> ?par3d of how rendering is accomplished), but there's currently no
> support for it, and it wouldn't be easy, as currently P and M in that
> description are read-only quantities computed indirectly.  So you'd have
> to essentially trick rgl into producing the P matrix corresponding to
> the viewing position you want.
> 
> I am currently working on some changes that might make this easier, but
> they likely aren't going to be released for several months.
> 
> Duncan Murdoch
Dear Duncan,

thank you very much. I was thinking I might have missed something obvious.

Thanks,
Roland

----------
This mail has been sent through the MPI for Demographic ...{{dropped:2}}



From andre.zacharia at gmail.com  Sun Apr 13 14:01:40 2014
From: andre.zacharia at gmail.com (andre.zacharia at gmail.com)
Date: Sun, 13 Apr 2014 05:01:40 -0700 (PDT)
Subject: [R] mean calculations from a dframe column
In-Reply-To: <1397383914.51315.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1397338225448-4688674.post@n4.nabble.com>
	<1397383914.51315.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <6612484066672746085@unknownmsgid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/44eb9e49/attachment-0001.pl>

From smartpink111 at yahoo.com  Sun Apr 13 16:54:55 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Apr 2014 07:54:55 -0700 (PDT)
Subject: [R] Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397371573.15875.YahooMailNeo@web160602.mail.bf1.yahoo.com>
References: <1397188527.25131.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397371573.15875.YahooMailNeo@web160602.mail.bf1.yahoo.com>
Message-ID: <1397400895.74947.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

I am formatting the codes using library(formatR).? Hopefully, it will not be mangled in the email.
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1 <- readLines(x2) header1 <- lines1[1:2] dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE,  skip = 2) colnames(dat1) <- Reduce(paste, strsplit(header1, ",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

library(plyr) 

lapply(seq_along(lst2), function(i) { lstN <- lapply(lst2[[i]], function(x) x[, -1]) lstQ1 <- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(0, 1,  by = 0.01), na.rm = TRUE))(x)) arr1 <- array(unlist(lstQ1), dim = c(dim(lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,  lapply(lstQ1, names)[[1]])) res <- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res) <- gsub(" ", "_", colnames(res)) res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), res, stringsAsFactors = FALSE) write.csv(res1, paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile",  sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))],  function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1, dim)
#     [,1] [,2]
#[1,]  101  101
#[2,]  258  258

lapply(ReadOut1,function(x) x[1:2,1:3])
#[[1]]
#  Percentiles  txav_DJF txav_MAM
#1          0% -12.68566  7.09702
#2          1% -12.59062  7.15338
#
#[[2]]
#  Percentiles  txav_DJF txav_MAM
#1          0% -12.75516 6.841840
#2          1% -12.68244 6.910664?


###Q2:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1) lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],  length(lst1)), sep = "_")) write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),  ".csv"), row.names = FALSE, quote = FALSE)
}) ## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],  function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257 


head(ReadOut2[[1]], 2)
#  Percentiles G100_pav_ANN G101_pav_ANN
#1          0%     1.054380     1.032740
#2          1%     1.069457     1.045689 


A.K.











On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
Q1)?I need your help again. Using the previous data (attached) and the previous code below,instead of taking rowMeans, let's do?quantile(x,seq(0,1,by=0.01)).?

Delete the last 2 rows (Trend and p<)?in each file before doing?quantile(x,seq(0,1,by=0.01)).

For example, assume that I want to calculate?quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do so for the 5 sims of site G100 and then take their average. This will be approximately close to the true value than just calculating quantile(x,seq(0,1,by=0.01)) from one sim. Please do this same thing for all the files.

So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01)) calculated from all sims in that Site.

Output

The number of files in "final" remains the same (2 files). The "Year" column(will be replaced)?will contain ?the names of quantile(x,seq(0,1,by=0.01)) such as??0% ? ? ? ? ? 1% ? ? ? ? ? 2% ? ? ? ? ? 3% ? ? ? ? ? 4% ? ? ? ? ? 5% ? ? ? ? ? 6%, ..., 98% ? ? ? ? ?99% ? ? ? ? 100% . You can give this column any name such as "Percentiles".


Q2) ?From the folder "final", please go to each file identified by site name, take a column, say?col1 of txav??from each file, create a dataframe whose colnames are site codes (names of files in "final"). Create a folder called "Indices" and place this dataframe in it. The filename for the dataframe is?txav, say. So, in "Indices", you will have one file having 3 columns [, c(Percentiles, G100,G101)]. The idea is that I want to be able to pick any column from files in "final" and form a dataframe from which I will generate my qqplot or boxplot.

Thanks very much AK.
Atem
This should be the final step of this my drama, at least for now.
#==============================================================================================================

dir.create("final")
lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2 <-? lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(header1,","));dat1}))

lstYear <- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]])?


lapply(seq_along(lst2),function(i) {lstN <-lapply(lst2[[i]],function(x) x[,-1]); arr1 <- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res <- cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res) <- gsub("\\_$","",gsub(" ", "_",names(res))); res[,1] <- gsub(" <", "",res[,1]); write.csv(res,paste0(paste(getwd(),"final",names(lst1)
[[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)? })?



#====================================================================================================



From spencer.graves at structuremonitoring.com  Sun Apr 13 18:59:14 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 13 Apr 2014 09:59:14 -0700
Subject: [R] Growth of CRAN?
Message-ID: <534AC262.4010202@structuremonitoring.com>

       What data exist on the growth of CRAN?


       John Fox published some data on it in 2009 ("Aspects of the 
Social Organization and Trajectory of the R Project", R Journal, 
http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf). 
Below please find those numbers plus some additions of mine since. If 
anyone else has other numbers (or more accurate numbers), I'd like to know.


       I plan to add a "CRANpackages" data set to the "Ecdat" package 
with a title, "Growth of CRAN" unless someone else provides better 
numbers or title.  [If it already exists on CRAN, I'd like to know. I 
doubt if it does, because I couldn't find it with findFn{sos} for 
'number of CRAN packages' and 'growth of CRAN'.]


       Thanks,
       Spencer


date    packages
2001-06-21    110
2001-12-17    129
2002-06-12    162
2003-05-27    219
2003-11-16    273
2004-06-05    357
2004-10-12    406
2005-06-18    548
2005-12-16    647
2006-05-31    739
2006-12-12    911
2007-04-12    1000
2007-11-16    1300
2008-03-18    1427
2008-10-18    1614
2009-09-17    1952
2012-06-12    3786
2012-11-01    4082
2012-12-14    4210
2013-10-28    4960
2013-11-08    5000
2014-04-13    5428


* NOTE:  These numbers may differ slightly from other sources. Numbers 
through 2009 were read from a plot in Fox's paper.  Numbers since were 
read at an arbitrary time during the day, Pacific time, from a mirror in 
the United States and could differ from those recorded by someone else 
using a different mirror having the same date in local time  someplace 
else.



From jfox at mcmaster.ca  Sun Apr 13 19:26:00 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 13 Apr 2014 13:26:00 -0400
Subject: [R] Growth of CRAN?
In-Reply-To: <534AC262.4010202@structuremonitoring.com>
References: <534AC262.4010202@structuremonitoring.com>
Message-ID: <001501cf573d$70b69830$5223c890$@mcmaster.ca>

Dear Spencer,

I've attached the most recent data I have, which are from mid-2012. My
package counts came from
https://svn.r-project.org/R/branches/R-*-branch/tests/internet.Rout.save
(where the * is the R version).

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Spencer Graves
> Sent: Sunday, April 13, 2014 12:59 PM
> To: R list
> Subject: [R] Growth of CRAN?
> 
>        What data exist on the growth of CRAN?
> 
> 
>        John Fox published some data on it in 2009 ("Aspects of the
> Social Organization and Trajectory of the R Project", R Journal,
> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf).
> Below please find those numbers plus some additions of mine since. If
> anyone else has other numbers (or more accurate numbers), I'd like to
> know.
> 
> 
>        I plan to add a "CRANpackages" data set to the "Ecdat" package
> with a title, "Growth of CRAN" unless someone else provides better
> numbers or title.  [If it already exists on CRAN, I'd like to know. I
> doubt if it does, because I couldn't find it with findFn{sos} for
> 'number of CRAN packages' and 'growth of CRAN'.]
> 
> 
>        Thanks,
>        Spencer
> 
> 
> date    packages
> 2001-06-21    110
> 2001-12-17    129
> 2002-06-12    162
> 2003-05-27    219
> 2003-11-16    273
> 2004-06-05    357
> 2004-10-12    406
> 2005-06-18    548
> 2005-12-16    647
> 2006-05-31    739
> 2006-12-12    911
> 2007-04-12    1000
> 2007-11-16    1300
> 2008-03-18    1427
> 2008-10-18    1614
> 2009-09-17    1952
> 2012-06-12    3786
> 2012-11-01    4082
> 2012-12-14    4210
> 2013-10-28    4960
> 2013-11-08    5000
> 2014-04-13    5428
> 
> 
> * NOTE:  These numbers may differ slightly from other sources. Numbers
> through 2009 were read from a plot in Fox's paper.  Numbers since were
> read at an arbitrary time during the day, Pacific time, from a mirror
> in
> the United States and could differ from those recorded by someone else
> using a different mirror having the same date in local time  someplace
> else.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: packages-updated.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/002e7c71/attachment-0002.txt>

From bbolker at gmail.com  Sun Apr 13 21:16:58 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 13 Apr 2014 19:16:58 +0000
Subject: [R] FW: Reading output of a GLMM run in R
References: <dub128-w798f9c468f64f229485381af560@phx.gbl>
	<4E70D126D10.00000313jrkrideau@inbox.com>
Message-ID: <loom.20140413T204827-280@post.gmane.org>

John Kane <jrkrideau <at> inbox.com> writes:

> 
> Can you resend the information in plain text?  
> It looks like you sent it in html format and it is very close to
> completely unreadable.
> 
> John Kane
> Kingston ON Canada

  You've also posted this question at CrossValidated:

http://stats.stackexchange.com/questions/93601/
  reading-the-output-from-a-glmm-run-in-r

(broken URL to make Gmane happy).  Cross-posting between
StackOverflow forums and r mailing lists is not explicitly
prohibited by the mailing list guidelines (since those guidelines
predate StackOverflow), but it has a good chance of wasting
answerers' time (because you get parallel answers in both venues).
At least you should state in each place that you've cross-posted,
with a link.

  As I commented on CrossValidated, you haven't given enough
context (what R package or functions are you using??) to answer
the question.

  You should consider reading http://glmm.wikidot.com/faq

  If you prefer the R mailing lists to CV you should
probably post to r-sig-mixed-models at r-project.org rather than
here.


> 
> > -----Original Message-----
> > From: ruthy_ <at> hotmail.co.uk
> > Sent: Sun, 13 Apr 2014 00:28:43 +0000
> > To: r-help <at> r-project.org
> > Subject: [R] FW: Reading output of a GLMM run in R
> > 
> > 
> > 
> > 
> > 
> > 
> > Hi, I am a complete novice and dummy when it comes to statistics so I
> > apologise in advance... I have been asked to report the results of my
> > GLMMs (I ran two) in a table. This table must state: effect, standard
> > error, test statistic, and P value, for all fixed effects. Unfortunately
> > I am struggling to read my output. The out put is as follows, if anyone
> > would be kind enough to help I would be very grateful and will know for
> > future reference which bit equates to what (also I have been told my
> > degrees of freedom are different for both the tests, could someone
> > explain why this is?). GLMM 1-run for predictors of step length. Response
> > variable = step length. fixed effects = depth and direction threshold.
> > random factor = individual Models: m2: step ~ (1 | ind) m1: step ~ Depth
> > * threshold + (1 | ind) Df AIC BIC logLik deviance Chisq Chi Df
> > Pr(>Chisq) m2 3 373235 373259 -186615 373229 m1 8 373225 373290 -186605
> > 373209 19.767 5 0.001382 ** --- Signif. codes: 0 ?***? 0.001 ?**? 0.01
> > ?*? 0.05 ?.? 0.1 ? ? 1 GLMM 2 -run to investigate potential predictors of
> > PDBA. response variables = depth and step length. fixed effect =
> > direction threshold. random factor = Individual Models: m3: PDBA ~ Depth
> > + (1 | ind) + thresholdepth m2: PDBA ~ step * threshold + Depth *
> > threshold + (1 | ind) Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> > m3 6 -48205 -48157 24109 -48217 m2 11 -48430 -48341 24226 -48452 235.1 5
> > < 2.2e-16 *** --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
> > ? ? 1 Models: m4: PDBA ~ step + (1 | ind) + step:threshold m2: PDBA ~
> > step * threshold + Depth * threshold + (1 | ind) Df AIC BIC logLik
> > deviance Chisq Chi Df Pr(>Chisq) m4 6 -48206 -48158 24109 -48218 m2 11
> > -48430 -48341 24226 -48452 233.81 5 < 2.2e-16 *** --- Signif. codes: 0
> > ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
>



From bbolker at gmail.com  Sun Apr 13 21:21:28 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 13 Apr 2014 19:21:28 +0000
Subject: [R]
	=?utf-8?q?Mixed_models_negative_binomial=2C_Error_in_eval=28e?=
	=?utf-8?q?xpr=2C_envir=2C=09enclos=29?=
References: <CAHdb_jP6DSKXz0Y-+du2096eGxCWUAr1yJ-Q_jy=13VxXZAm=w@mail.gmail.com>
Message-ID: <loom.20140413T211753-676@post.gmane.org>

Karina Charest Castro <jlonkc <at> gmail.com> writes:

> 
> Hi!

  This question is more appropriate for r-sig-mixed-models at r-project.org.
Please repost there (I will add a few questions/comments below that
you should probably address when you repost)

> I am trying to do a glmer.nb but get this error:
> Error in eval(expr, envir, enclos) :
>   ..2 used in an incorrect context, no ... to look in
> 
> My data structure is data.frame
> Here my data set: d1_2
> 
> Year ID Age Reproductive_status Rank_Residuals Asso.Y1 TotalY1
> 1994 109 8 Lactating 0.23947902 9 48
> 1994 110 6 Barren -0.030977951 56 62
> 1995 1000 9 Summer_yeld 0.08624 31 55
> 1995 103 4 Barren -0.06861 29 52
> 1996 23 8 Barren -0.015726749 64 64
> 1997 1000 11 Lactating 0.148665859 5 35
> 1997 103 6 Barren -0.116539886 51 51
> 2001 105 9 Lactating -0.036222842 27 28
> 2001 106 9 Barren 0.073777158 40 40
> 2001 116 8 Barren -0.015710059 5 31

  is this your whole data set, or just the first few lines?
(If the former, then you won't be able to fit the model you want --
there are not nearly enough data.)

> library(lme4); library(MASS)
> nb.glmer <- glmer.nb(Asso.Y1 ~ Reproductive_status * Age +
> Reproductive_status * Rank_Residuals + Reproductive_status * I(Age^2) +
> (1|ID) + (1|Year), offset = log(d1_2$TotalY1), data=d1_2)

  The fixed-effect part should be identical to:

~ Reproductive_status*(Rank_Residuals+poly(Age,2,raw=TRUE))


> 
> I have also tried because I found that glmer.nb is not well understood:
> library(glmmADMB)
>     random <- MCMCglmm(cbind(Asso.Y1,TotalY1-Asso.Y1) ~ Reproductive_status
> * Age + Reproductive_status * Rank_Residuals + Reproductive_status *
> I(Age^2), random = ~ ID+Year, data = d1_2)
> BUT: Error in MCMCglmm(cbind(Asso.Y1, TotalY1 - Asso.Y1) ~
> Reproductive_status *  :
>   family must have the same length as the number of responses
> 
> I am not able to solve those problems and I have looked on forums too.
> 
> Tkx in advance!

  You're loading the glmmADMB package but calling MCMCglmm, which
is a completely different function from a completely different package,
with different syntax ...



From spencer.graves at structuremonitoring.com  Sun Apr 13 21:40:02 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 13 Apr 2014 12:40:02 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <001501cf573d$70b69830$5223c890$@mcmaster.ca>
References: <534AC262.4010202@structuremonitoring.com>
	<001501cf573d$70b69830$5223c890$@mcmaster.ca>
Message-ID: <534AE812.4040307@structuremonitoring.com>

Dear John:


       Thanks very much.


       CRANpackages is now available via SVN checkout of Ecdat from 
R-Forge.  After it passes R-Forge tests, it will be available via 
install.packages("Ecdat", repos="http://R-Forge.R-project.org").


       Best Wishes,
       Spencer


On 4/13/2014 10:26 AM, John Fox wrote:
> Dear Spencer,
>
> I've attached the most recent data I have, which are from mid-2012. My
> package counts came from
> https://svn.r-project.org/R/branches/R-*-branch/tests/internet.Rout.save
> (where the * is the R version).
>
> I hope this helps,
>   John
>
>> -----Original Message-----
>> From:r-help-bounces at r-project.org  [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Spencer Graves
>> Sent: Sunday, April 13, 2014 12:59 PM
>> To: R list
>> Subject: [R] Growth of CRAN?
>>
>>         What data exist on the growth of CRAN?
>>
>>
>>         John Fox published some data on it in 2009 ("Aspects of the
>> Social Organization and Trajectory of the R Project", R Journal,
>> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf).
>> Below please find those numbers plus some additions of mine since. If
>> anyone else has other numbers (or more accurate numbers), I'd like to
>> know.
>>
>>
>>         I plan to add a "CRANpackages" data set to the "Ecdat" package
>> with a title, "Growth of CRAN" unless someone else provides better
>> numbers or title.  [If it already exists on CRAN, I'd like to know. I
>> doubt if it does, because I couldn't find it with findFn{sos} for
>> 'number of CRAN packages' and 'growth of CRAN'.]
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> date    packages
>> 2001-06-21    110
>> 2001-12-17    129
>> 2002-06-12    162
>> 2003-05-27    219
>> 2003-11-16    273
>> 2004-06-05    357
>> 2004-10-12    406
>> 2005-06-18    548
>> 2005-12-16    647
>> 2006-05-31    739
>> 2006-12-12    911
>> 2007-04-12    1000
>> 2007-11-16    1300
>> 2008-03-18    1427
>> 2008-10-18    1614
>> 2009-09-17    1952
>> 2012-06-12    3786
>> 2012-11-01    4082
>> 2012-12-14    4210
>> 2013-10-28    4960
>> 2013-11-08    5000
>> 2014-04-13    5428
>>
>>
>> * NOTE:  These numbers may differ slightly from other sources. Numbers
>> through 2009 were read from a plot in Fox's paper.  Numbers since were
>> read at an arbitrary time during the day, Pacific time, from a mirror
>> in
>> the United States and could differ from those recorded by someone else
>> using a different mirror having the same date in local time  someplace
>> else.
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:www.structuremonitoring.com



From zilefacelvis at yahoo.com  Sun Apr 13 22:17:16 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 13 Apr 2014 13:17:16 -0700 (PDT)
Subject: [R] Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397400895.74947.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1397188527.25131.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397371573.15875.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397400895.74947.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1397420236.32660.YahooMailNeo@web160601.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/992600e0/attachment-0001.pl>

From ed.tirelli at gmail.com  Sun Apr 13 23:59:11 2014
From: ed.tirelli at gmail.com (Edson Tirelli)
Date: Sun, 13 Apr 2014 17:59:11 -0400
Subject: [R] Selecting variables in a multivariate regression
Message-ID: <CAD7AJnc2WDL3jeu6z_s+4=MwYdS=e+H8cqQUdfn_-+TAq1nqmQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/92bb6e5c/attachment-0001.pl>

From njh159 at psu.edu  Mon Apr 14 02:49:02 2014
From: njh159 at psu.edu (Nastassia J. Hajal)
Date: Sun, 13 Apr 2014 17:49:02 -0700
Subject: [R] Testing simple slopes for cross-level interactions
Message-ID: <CAE9fbBBgqG56cdtA8CGC0qMCUvo31_0nc9D1=JMRGu60smHpnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/c3e7b395/attachment-0001.pl>

From paul.tanger at colostate.edu  Mon Apr 14 03:08:51 2014
From: paul.tanger at colostate.edu (Paul Tanger)
Date: Sun, 13 Apr 2014 19:08:51 -0600
Subject: [R] correlation with missing values.. different answers
Message-ID: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/d3cc4d4f/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Mon Apr 14 03:35:49 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 13 Apr 2014 18:35:49 -0700
Subject: [R] correlation with missing values.. different answers
In-Reply-To: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
References: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
Message-ID: <6cf9f9b5-4dd2-446a-9b7a-68eaf433ed45@email.android.com>

Please post in plain text per the Posting Guide.

Read ?cor, particularly the part about "complete.cases". Your two cases have different effective input rows.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 13, 2014 6:08:51 PM PDT, Paul Tanger <paul.tanger at colostate.edu> wrote:
>Hi,
>I can't seem to figure out why this gives me different answers. 
>Probably
>something obvious, but I thought they would be the same.
>This is an minimal example from the help page of cor() :
>
>> ## swM := "swiss" with  3 "missing"s :
>> swM <- swiss
>> colnames(swM) <- abbreviate(colnames(swiss), min=6)
>> swM[1,2] <- swM[7,3] <- swM[25,5] <- NA # create 3 "missing"
>> cor(swM, use = "na.or.complete")
>       Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M
>Frtlty  1.0000000  0.37821953 -0.6548306 -0.67421581  0.4772298 
>0.38781500
>Agrclt  0.3782195  1.00000000 -0.7127078 -0.64337782  0.4014837
>-0.07168223
>Exmntn -0.6548306 -0.71270778  1.0000000  0.69776906 -0.6079436
>-0.10710047
>Eductn -0.6742158 -0.64337782  0.6977691  1.00000000 -0.1701445
>-0.08343279
>Cathlc  0.4772298  0.40148365 -0.6079436 -0.17014449  1.0000000 
>0.17221594
>Infn.M  0.3878150 -0.07168223 -0.1071005 -0.08343279  0.1722159 
>1.00000000
>> # why isn't this the same?
>> cor(swM[,c(1:2)], use = "na.or.complete")
>          Frtlty    Agrclt
>Frtlty 1.0000000 0.3920289
>Agrclt 0.3920289 1.0000000
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Apr 14 03:36:04 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Apr 2014 18:36:04 -0700 (PDT)
Subject: [R] correlation with missing values.. different answers
In-Reply-To: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
References: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
Message-ID: <1397439364.75972.YahooMailNeo@web142605.mail.bf1.yahoo.com>




Hi,

I think in this case, when you use "na.or.complete", all the NA rows are removed for the full dataset.
cor(swM[-1,1:2]) 
#          Frtlty    Agrclt
?#Frtlty 1.0000000 0.3920289 
#Agrclt 0.3920289 1.0000000 

cor(swM[-1,])[1:2,1:2] 
#Frtlty    Agrclt 
#Frtlty 1.0000000 0.3920289 
#Agrclt 0.3920289 1.0000000 

May be you can try with "pairwise.complete.obs"
cor(swM, use = "pairwise.complete.obs") 
#           Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M 
#Frtlty  1.0000000  0.39202893 -0.6531492 -0.66378886  0.4723129  0.41655603 
#Agrclt  0.3920289  1.00000000 -0.7150561 -0.65221506  0.4152007 -0.03648427 
#Exmntn -0.6531492 -0.71505612  1.0000000  0.69921153 -0.6003402 -0.11433546
?#Eductn -0.6637889 -0.65221506  0.6992115  1.00000000 -0.1791334 -0.09932185
?#Cathlc  0.4723129  0.41520069 -0.6003402 -0.17913339  1.0000000  0.18503786
?#Infn.M  0.4165560 -0.03648427 -0.1143355 -0.09932185  0.1850379  1.00000000
 cor(swM[,1:2],use="pairwise.complete.obs") 
#          Frtlty    Agrclt 
#Frtlty 1.0000000 0.3920289 
#Agrclt 0.3920289 1.0000000

A.K.

On Sunday, April 13, 2014 9:11 PM, Paul Tanger <paul.tanger at colostate.edu> wrote:
Hi,
I can't seem to figure out why this gives me different answers.? Probably
something obvious, but I thought they would be the same.
This is an minimal example from the help page of cor() :

> ## swM := "swiss" with? 3 "missing"s :
> swM <- swiss
> colnames(swM) <- abbreviate(colnames(swiss), min=6)
> swM[1,2] <- swM[7,3] <- swM[25,5] <- NA # create 3 "missing"
> cor(swM, use = "na.or.complete")
? ? ? ? ?  Frtlty? ? ? Agrclt? ?  Exmntn? ? ? Eductn? ?  Cathlc? ? ? Infn.M
Frtlty? 1.0000000? 0.37821953 -0.6548306 -0.67421581? 0.4772298? 0.38781500
Agrclt? 0.3782195? 1.00000000 -0.7127078 -0.64337782? 0.4014837 -0.07168223
Exmntn -0.6548306 -0.71270778? 1.0000000? 0.69776906 -0.6079436 -0.10710047
Eductn -0.6742158 -0.64337782? 0.6977691? 1.00000000 -0.1701445 -0.08343279
Cathlc? 0.4772298? 0.40148365 -0.6079436 -0.17014449? 1.0000000? 0.17221594
Infn.M? 0.3878150 -0.07168223 -0.1071005 -0.08343279? 0.1722159? 1.00000000
> # why isn't this the same?
> cor(swM[,c(1:2)], use = "na.or.complete")
? ? ? ? ? Frtlty? ? Agrclt
Frtlty 1.0000000 0.3920289
Agrclt 0.3920289 1.0000000

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ggrothendieck at gmail.com  Mon Apr 14 04:41:19 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 13 Apr 2014 22:41:19 -0400
Subject: [R] Growth of CRAN?
In-Reply-To: <001501cf573d$70b69830$5223c890$@mcmaster.ca>
References: <534AC262.4010202@structuremonitoring.com>
	<001501cf573d$70b69830$5223c890$@mcmaster.ca>
Message-ID: <CAP01uRmgsCvu=dtHwHATFp3=OeGkF=njin=gNGnkqZ0toRn16w@mail.gmail.com>

On Sun, Apr 13, 2014 at 1:26 PM, John Fox <jfox at mcmaster.ca> wrote:
> I've attached the most recent data I have, which are from mid-2012. My
> package counts came from
> https://svn.r-project.org/R/branches/R-*-branch/tests/internet.Rout.save
> (where the * is the R version).
>


It seems that the growth is exponential but at a lower slope (of the
log curve) after 2008 than before. A linear fit to the log curve is
shown  in blue before 2008 and in red after 2008.  What happened to
result in two such distinct regimes?

Lines <- "version date        packages
1.3     2001-06-21   110
1.4     2001-12-17   129
1.5     2002-05-29   162
#1.6     2002-10-01   163
1.7     2003-05-27   219
1.8     2003-11-16   273
1.9     2004-06-05   357
2.0     2004-10-12   406
2.1     2005-06-18   548
2.2     2005-12-16   647
2.3     2006-05-31   739
2.4     2006-12-12   911
2.5     2007-04-12  1000
2.6     2007-11-16  1300
2.7     2008-03-18  1427
2.8     2008-10-18  1614  # updated
2.9     2009-04-17  1952
2.10    2009-10-26  2088
2.11    2010-04-22  2445
2.12    2010-10-15  2837
2.13    2011-04-13  3286
2.14    2011-06-20  3618
2.15    2012-07-07  4000
"
library(zoo)
zz <- read.zoo(text = Lines, header = TRUE, index = 2)[, 2]
plot(log(zz))
d <- as.Date("2008-01-01")
abline(v = d)
pre <- time(zz) < d
fo <- log(zz) ~ time(zz)
abline(lm(fo, subset = pre), col = "blue")
abline(lm(fo, subset = !pre), col = "red")



From paul.tanger at colostate.edu  Mon Apr 14 05:02:27 2014
From: paul.tanger at colostate.edu (Paul Tanger)
Date: Sun, 13 Apr 2014 21:02:27 -0600
Subject: [R] correlation with missing values.. different answers
In-Reply-To: <1397439364.75972.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
	<1397439364.75972.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAPEW02azDm7OEx6Ldsu01kJiQidei5eit-VorT8KFHjYAQH7uw@mail.gmail.com>

Thanks, I did not realize it was deleting rows!  I was afraid to try
"pairwise.complete.obs" because it said something about resulting in a
matrix which is not "positive semi-definite" (and googling that term
just confused me more).  But I ran the dataset through JMP and got the
same answers so I think that "pairwise.complete.obs" works for what I
want to do.

On Sun, Apr 13, 2014 at 7:36 PM, arun <smartpink111 at yahoo.com> wrote:
>
>
>
> Hi,
>
> I think in this case, when you use "na.or.complete", all the NA rows are removed for the full dataset.
> cor(swM[-1,1:2])
> #          Frtlty    Agrclt
>  #Frtlty 1.0000000 0.3920289
> #Agrclt 0.3920289 1.0000000
>
> cor(swM[-1,])[1:2,1:2]
> #Frtlty    Agrclt
> #Frtlty 1.0000000 0.3920289
> #Agrclt 0.3920289 1.0000000
>
> May be you can try with "pairwise.complete.obs"
> cor(swM, use = "pairwise.complete.obs")
> #           Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M
> #Frtlty  1.0000000  0.39202893 -0.6531492 -0.66378886  0.4723129  0.41655603
> #Agrclt  0.3920289  1.00000000 -0.7150561 -0.65221506  0.4152007 -0.03648427
> #Exmntn -0.6531492 -0.71505612  1.0000000  0.69921153 -0.6003402 -0.11433546
>  #Eductn -0.6637889 -0.65221506  0.6992115  1.00000000 -0.1791334 -0.09932185
>  #Cathlc  0.4723129  0.41520069 -0.6003402 -0.17913339  1.0000000  0.18503786
>  #Infn.M  0.4165560 -0.03648427 -0.1143355 -0.09932185  0.1850379  1.00000000
>  cor(swM[,1:2],use="pairwise.complete.obs")
> #          Frtlty    Agrclt
> #Frtlty 1.0000000 0.3920289
> #Agrclt 0.3920289 1.0000000
>
> A.K.
>
> On Sunday, April 13, 2014 9:11 PM, Paul Tanger <paul.tanger at colostate.edu> wrote:
> Hi,
> I can't seem to figure out why this gives me different answers.  Probably
> something obvious, but I thought they would be the same.
> This is an minimal example from the help page of cor() :
>
>> ## swM := "swiss" with  3 "missing"s :
>> swM <- swiss
>> colnames(swM) <- abbreviate(colnames(swiss), min=6)
>> swM[1,2] <- swM[7,3] <- swM[25,5] <- NA # create 3 "missing"
>> cor(swM, use = "na.or.complete")
>            Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M
> Frtlty  1.0000000  0.37821953 -0.6548306 -0.67421581  0.4772298  0.38781500
> Agrclt  0.3782195  1.00000000 -0.7127078 -0.64337782  0.4014837 -0.07168223
> Exmntn -0.6548306 -0.71270778  1.0000000  0.69776906 -0.6079436 -0.10710047
> Eductn -0.6742158 -0.64337782  0.6977691  1.00000000 -0.1701445 -0.08343279
> Cathlc  0.4772298  0.40148365 -0.6079436 -0.17014449  1.0000000  0.17221594
> Infn.M  0.3878150 -0.07168223 -0.1071005 -0.08343279  0.1722159  1.00000000
>> # why isn't this the same?
>> cor(swM[,c(1:2)], use = "na.or.complete")
>           Frtlty    Agrclt
> Frtlty 1.0000000 0.3920289
> Agrclt 0.3920289 1.0000000
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ed.tirelli at gmail.com  Mon Apr 14 05:08:25 2014
From: ed.tirelli at gmail.com (Edson Tirelli)
Date: Sun, 13 Apr 2014 23:08:25 -0400
Subject: [R] Selecting variables in a multivariate regression
Message-ID: <CAD7AJnd_LnQJToB-dhm9fvr4SGeNJgKDU9rOB6+fjmWyaRYk6A@mail.gmail.com>

I am quite new to R and I am having trouble figuring out how to select
variables in a multivariate linear regression in R. My google-fu also
did not find anything.

Pretend I have the following formulas:

P = aX + bY
Q = cZ + bY

I have a data frame with column P, Q, X, Y, Z and I need to find a, b and c.

If I do a simple multivariate regression:

result <- lm( cbind( P, Q ) ~ X + Y + Z - 1 )

It calculates a coefficient for "c" on P's regression and for "a" on
Q's regression.

If I calculate the regressions individually then "b" will be different
in each regression.

How can I select the variables to consider in a multivariate
regression? I.e., how do I tell R to ignore cZ when calculating P, and
ignore aX when calculating Q?

Thank you,
Edson



From spencer.graves at structuremonitoring.com  Mon Apr 14 06:20:47 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 13 Apr 2014 21:20:47 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <CAP01uRmgsCvu=dtHwHATFp3=OeGkF=njin=gNGnkqZ0toRn16w@mail.gmail.com>
References: <534AC262.4010202@structuremonitoring.com>
	<001501cf573d$70b69830$5223c890$@mcmaster.ca>
	<CAP01uRmgsCvu=dtHwHATFp3=OeGkF=njin=gNGnkqZ0toRn16w@mail.gmail.com>
Message-ID: <534B621F.6080401@structuremonitoring.com>

On 4/13/2014 7:41 PM, Gabor Grothendieck wrote:
> On Sun, Apr 13, 2014 at 1:26 PM, John Fox <jfox at mcmaster.ca> wrote:
>> I've attached the most recent data I have, which are from mid-2012. My
>> package counts came from
>> https://svn.r-project.org/R/branches/R-*-branch/tests/internet.Rout.save
>> (where the * is the R version).
>>
>
> It seems that the growth is exponential but at a lower slope (of the
> log curve) after 2008 than before. A linear fit to the log curve is
> shown  in blue before 2008 and in red after 2008.  What happened to
> result in two such distinct regimes?


       I got a great fit using a 4-parameter log-logistic model with 
drm{drc};  see below.  This model suggests that CRAN will approach an 
asymptote of roughly 60,000 packages with a 95% confidence interval 
ranging from 31 to 117 thousand.


       Obviously, the confidence interval for the asymptote assumes the 
4-parameter log-logistic model is accurate.  That's probably not 
realistic but is more accurate than assuming continued exponential 
growth.  If I had time to develop more accurate predictions and 
confidence intervals, I'd try Bayesian Model Averaging with several 
different models.


       Thanks for the question and comments.


       Spencer


# Wait until "Build status: Current" at rev. 178 on Ecfun on R-Forge, then:
install.packages("Ecfun", repos="http://R-Forge.R-project.org")

(day1 <- min(CRANpackages$Date)) # 2001-06-21
str(ddate <- CRANpackages$Date-day1)
CRANpackages$CRANdays <- as.numeric(ddate)

library(drc)
CRANlogLogis4. <- drm(log(Packages)~CRANdays, data=CRANpackages, fct=LL.4())
plot(CRANlogLogis4., log='y') # best I've found so far.

plot(resid(CRANlogLogis4.))
CRANlogLogis4.
# log(Packages) = c + (d-c)/(1 + (t/t0)^b)
# where
# b = -1.36 = log(60152)
# c = 4.73
# d = 11.0
# t0 = 3309 days since 2001-06-21

(ci4 <- confint(CRANlogLogis4.))

        2.5%   97.5%
b   -1.49   -1.24  # power of time = rate at which t^b -> 0
c    4.67    4.80   #
d   10.34   11.67 # asymptote of log(Packages)
t0 2800   3818 # reference number of days

# Asymptotic number of CRAN packages
exp(ci4[3, ])
     2.5 %    97.5 %
c(31, 117)*1000


>
> Lines <- "version date        packages
> 1.3     2001-06-21   110
> 1.4     2001-12-17   129
> 1.5     2002-05-29   162
> #1.6     2002-10-01   163
> 1.7     2003-05-27   219
> 1.8     2003-11-16   273
> 1.9     2004-06-05   357
> 2.0     2004-10-12   406
> 2.1     2005-06-18   548
> 2.2     2005-12-16   647
> 2.3     2006-05-31   739
> 2.4     2006-12-12   911
> 2.5     2007-04-12  1000
> 2.6     2007-11-16  1300
> 2.7     2008-03-18  1427
> 2.8     2008-10-18  1614  # updated
> 2.9     2009-04-17  1952
> 2.10    2009-10-26  2088
> 2.11    2010-04-22  2445
> 2.12    2010-10-15  2837
> 2.13    2011-04-13  3286
> 2.14    2011-06-20  3618
> 2.15    2012-07-07  4000
> "
> library(zoo)
> zz <- read.zoo(text = Lines, header = TRUE, index = 2)[, 2]
> plot(log(zz))
> d <- as.Date("2008-01-01")
> abline(v = d)
> pre <- time(zz) < d
> fo <- log(zz) ~ time(zz)
> abline(lm(fo, subset = pre), col = "blue")
> abline(lm(fo, subset = !pre), col = "red")



From spencer.graves at structuremonitoring.com  Mon Apr 14 06:21:29 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 13 Apr 2014 21:21:29 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <CAP01uRmgsCvu=dtHwHATFp3=OeGkF=njin=gNGnkqZ0toRn16w@mail.gmail.com>
References: <534AC262.4010202@structuremonitoring.com>
	<001501cf573d$70b69830$5223c890$@mcmaster.ca>
	<CAP01uRmgsCvu=dtHwHATFp3=OeGkF=njin=gNGnkqZ0toRn16w@mail.gmail.com>
Message-ID: <534B6249.3070604@structuremonitoring.com>

(minor correct)


On 4/13/2014 7:41 PM, Gabor Grothendieck wrote:
> On Sun, Apr 13, 2014 at 1:26 PM, John Fox <jfox at mcmaster.ca> wrote:
>> I've attached the most recent data I have, which are from mid-2012. My
>> package counts came from
>> https://svn.r-project.org/R/branches/R-*-branch/tests/internet.Rout.save
>> (where the * is the R version).
>>
>
> It seems that the growth is exponential but at a lower slope (of the
> log curve) after 2008 than before. A linear fit to the log curve is
> shown  in blue before 2008 and in red after 2008.  What happened to
> result in two such distinct regimes?


       I got a great fit using a 4-parameter log-logistic model with 
drm{drc};  see below.  This model suggests that CRAN will approach an 
asymptote of roughly 60,000 packages with a 95% confidence interval 
ranging from 31 to 117 thousand.


       Obviously, the confidence interval for the asymptote assumes the 
4-parameter log-logistic model is accurate.  That's probably not 
realistic but is more accurate than assuming continued exponential 
growth.  If I had time to develop more accurate predictions and 
confidence intervals, I'd try Bayesian Model Averaging with several 
different models.


       Thanks for the question and comments.


       Spencer


# Wait until "Build status: Current" at rev. 178 on Ecdat on R-Forge, then:
install.packages("Ecdat", repos="http://R-Forge.R-project.org")

(day1 <- min(CRANpackages$Date)) # 2001-06-21
str(ddate <- CRANpackages$Date-day1)
CRANpackages$CRANdays <- as.numeric(ddate)

library(drc)
CRANlogLogis4. <- drm(log(Packages)~CRANdays, data=CRANpackages, fct=LL.4())
plot(CRANlogLogis4., log='y') # best I've found so far.

plot(resid(CRANlogLogis4.))
CRANlogLogis4.
# log(Packages) = c + (d-c)/(1 + (t/t0)^b)
# where
# b = -1.36 = log(60152)
# c = 4.73
# d = 11.0
# t0 = 3309 days since 2001-06-21

(ci4 <- confint(CRANlogLogis4.))

        2.5%   97.5%
b   -1.49   -1.24  # power of time = rate at which t^b -> 0
c    4.67    4.80   #
d   10.34   11.67 # asymptote of log(Packages)
t0 2800   3818 # reference number of days

# Asymptotic number of CRAN packages
exp(ci4[3, ])
     2.5 %    97.5 %
c(31, 117)*1000


>
> Lines <- "version date        packages
> 1.3     2001-06-21   110
> 1.4     2001-12-17   129
> 1.5     2002-05-29   162
> #1.6     2002-10-01   163
> 1.7     2003-05-27   219
> 1.8     2003-11-16   273
> 1.9     2004-06-05   357
> 2.0     2004-10-12   406
> 2.1     2005-06-18   548
> 2.2     2005-12-16   647
> 2.3     2006-05-31   739
> 2.4     2006-12-12   911
> 2.5     2007-04-12  1000
> 2.6     2007-11-16  1300
> 2.7     2008-03-18  1427
> 2.8     2008-10-18  1614  # updated
> 2.9     2009-04-17  1952
> 2.10    2009-10-26  2088
> 2.11    2010-04-22  2445
> 2.12    2010-10-15  2837
> 2.13    2011-04-13  3286
> 2.14    2011-06-20  3618
> 2.15    2012-07-07  4000
> "
> library(zoo)
> zz <- read.zoo(text = Lines, header = TRUE, index = 2)[, 2]
> plot(log(zz))
> d <- as.Date("2008-01-01")
> abline(v = d)
> pre <- time(zz) < d
> fo <- log(zz) ~ time(zz)
> abline(lm(fo, subset = pre), col = "blue")
> abline(lm(fo, subset = !pre), col = "red")



From brianjamesarb at gmail.com  Mon Apr 14 02:50:09 2014
From: brianjamesarb at gmail.com (brian arb)
Date: Sun, 13 Apr 2014 20:50:09 -0400
Subject: [R] Error using the package tm.plugin.webmining "object '.Source'
	not found"
Message-ID: <CABYizFLTQh_Ay+fjidgwMwW+fz__Vp0A4FG=q1G4tuju7ieDvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140413/01a558c9/attachment-0001.pl>

From smartpink111 at yahoo.com  Mon Apr 14 02:50:53 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Apr 2014 17:50:53 -0700 (PDT)
Subject: [R] [datatable-help] Transform characters to numbers and compare
In-Reply-To: <1397417755341-4688708.post@n4.nabble.com>
References: <1397417755341-4688708.post@n4.nabble.com>
Message-ID: <1397436653.80077.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
Try:
df2 <- df 
df2[] <- lapply(df2,function(x) as.character(as.numeric(factor(x,levels=unique(df$G1))))) 

A.K.


On Sunday, April 13, 2014 3:36 PM, Sergio.pv <serpalma.v at gmail.com> wrote:
I have a data.frame of two vectors.

df <- data.frame(G1=c("b","a","e","d","c"),
? ? ? ? ? ? ? ?  G2=c("c","d","e","b","a"))
You can see that both vectors have the same characters, but in diferent
order. I want to convert them into numbers and then compare them.

To compare G2 to G1, G1 must be the reference, so the output will be this:

df2 <- data.frame(G1=c("1","2","3","4","5"),
? ? ? ? ? ? ? ?  G2=c("5","4","3","1","2"))
Is there a way to do this?, thanks



--
View this message in context: http://r.789695.n4.nabble.com/Transform-characters-to-numbers-and-compare-tp4688708.html
Sent from the datatable-help mailing list archive at Nabble.com.
_______________________________________________
datatable-help mailing list
datatable-help at lists.r-forge.r-project.org
https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/datatable-help



From allyson_combes at hotmail.com  Mon Apr 14 06:00:33 2014
From: allyson_combes at hotmail.com (Allyson Combes)
Date: Mon, 14 Apr 2014 04:00:33 +0000
Subject: [R] =?utf-8?q?Comparing_initial_eigenvalues_to_broken_stick_resul?=
	=?utf-8?q?ts?=
Message-ID: <COL402-EAS408DDC10010BBEEE1B73110EF510@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/c6105596/attachment-0001.pl>

From eliza_botto at hotmail.com  Mon Apr 14 11:55:30 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 14 Apr 2014 09:55:30 +0000
Subject: [R] calling in inverted commas
In-Reply-To: <f1acnw33r7f71xhxlbnfarae.1397300086295@email.android.com>
References: <f1acnw33r7f71xhxlbnfarae.1397300086295@email.android.com>
Message-ID: <BLU170-W8662F36B8237BC9762360189510@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/238d3aad/attachment-0001.pl>

From dmcp at webmail.co.za  Mon Apr 14 14:19:21 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Mon, 14 Apr 2014 14:19:21 +0200
Subject: [R] mean calculations from a dframe column
In-Reply-To: <6612484066672746085@unknownmsgid>
References: <1397338225448-4688674.post@n4.nabble.com>
	<1397383914.51315.YahooMailNeo@web142602.mail.bf1.yahoo.com>,
	<6612484066672746085@unknownmsgid>
Message-ID: <62a1da7f9622574935dda844bce669bb@www.webmail.co.za>

On Sun, 13 Apr 2014 05:01:40 -0700 (PDT) "andre.zacharia at gmail.com"
<andre.zacharia at gmail.com> wrote

> Thank you very much!!!!!!
> 
..
..
>  *De :* arun kirshna [via R]
> *Envoy? :* 13 avril 2014 11:23
> *? :* andre.zacharia at gmail.com
> *Objet :* Re: mean calculations from a dframe column
> 
> Hi Andr?,
> 
> Your codes were missing in some information. If your code looks like this:
..
.. 
> Mean <- apply(a, 2, mean, na.rm = TRUE) 
..
..
..

Andre,

Just for future reference, have a look at
?colMeans
"These functions are equivalent to use of apply with FUN = mean or FUN = sum
with appropriate margins, but are a lot faster."

Cheers,
D.

____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Ensure Quality Health Care For All http://www.anc.org.za/2014/manifesto/



From h.wickham at gmail.com  Mon Apr 14 14:53:27 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 14 Apr 2014 08:53:27 -0400
Subject: [R] Growth of CRAN?
In-Reply-To: <534AC262.4010202@structuremonitoring.com>
References: <534AC262.4010202@structuremonitoring.com>
Message-ID: <CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>

For finer level detail, have a look at
https://github.com/hadley/cran-packages. It contains the description
file of every package ever uploaded to CRAN (the cache is a few months
out of date, but you can easily re-run)

Hadley

On Sun, Apr 13, 2014 at 12:59 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
>       What data exist on the growth of CRAN?
>
>
>       John Fox published some data on it in 2009 ("Aspects of the Social
> Organization and Trajectory of the R Project", R Journal,
> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf). Below
> please find those numbers plus some additions of mine since. If anyone else
> has other numbers (or more accurate numbers), I'd like to know.
>
>
>       I plan to add a "CRANpackages" data set to the "Ecdat" package with a
> title, "Growth of CRAN" unless someone else provides better numbers or
> title.  [If it already exists on CRAN, I'd like to know. I doubt if it does,
> because I couldn't find it with findFn{sos} for 'number of CRAN packages'
> and 'growth of CRAN'.]
>
>
>       Thanks,
>       Spencer
>
>
> date    packages
> 2001-06-21    110
> 2001-12-17    129
> 2002-06-12    162
> 2003-05-27    219
> 2003-11-16    273
> 2004-06-05    357
> 2004-10-12    406
> 2005-06-18    548
> 2005-12-16    647
> 2006-05-31    739
> 2006-12-12    911
> 2007-04-12    1000
> 2007-11-16    1300
> 2008-03-18    1427
> 2008-10-18    1614
> 2009-09-17    1952
> 2012-06-12    3786
> 2012-11-01    4082
> 2012-12-14    4210
> 2013-10-28    4960
> 2013-11-08    5000
> 2014-04-13    5428
>
>
> * NOTE:  These numbers may differ slightly from other sources. Numbers
> through 2009 were read from a plot in Fox's paper.  Numbers since were read
> at an arbitrary time during the day, Pacific time, from a mirror in the
> United States and could differ from those recorded by someone else using a
> different mirror having the same date in local time  someplace else.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/



From gunter.berton at gene.com  Mon Apr 14 15:33:59 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 14 Apr 2014 06:33:59 -0700
Subject: [R] Selecting variables in a multivariate regression
In-Reply-To: <CAD7AJnd_LnQJToB-dhm9fvr4SGeNJgKDU9rOB6+fjmWyaRYk6A@mail.gmail.com>
References: <CAD7AJnd_LnQJToB-dhm9fvr4SGeNJgKDU9rOB6+fjmWyaRYk6A@mail.gmail.com>
Message-ID: <CACk-te0hzaW_ACvJFsUKmrfD3yLnz_P6K07o-0WLzkFjDHguww@mail.gmail.com>

Well, this is your second post on the same topic, your first having
received no response. So you should suspect something is amiss and
reconsider before continuing, don't you think?

1. I, for one, was not able to make any sense of your query. You do
not appear to understand regression, so I would suggest you spend time
with a local statistical resource before continuing with online
posts.If my understanding of your misunderstanding is correct, you
need to comprehend basics. If not,apologies.

2. Have you read An Introduction to R (ships with R) or an online R
tutorial of your choice? If not, do so before posting here further. We
expect minimal efforts of posters to solve their own problems before
posting. Again, apologies if I err.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sun, Apr 13, 2014 at 8:08 PM, Edson Tirelli <ed.tirelli at gmail.com> wrote:
> I am quite new to R and I am having trouble figuring out how to select
> variables in a multivariate linear regression in R. My google-fu also
> did not find anything.
>
> Pretend I have the following formulas:
>
> P = aX + bY
> Q = cZ + bY
>
> I have a data frame with column P, Q, X, Y, Z and I need to find a, b and c.
>
> If I do a simple multivariate regression:
>
> result <- lm( cbind( P, Q ) ~ X + Y + Z - 1 )
>
> It calculates a coefficient for "c" on P's regression and for "a" on
> Q's regression.
>
> If I calculate the regressions individually then "b" will be different
> in each regression.
>
> How can I select the variables to consider in a multivariate
> regression? I.e., how do I tell R to ignore cZ when calculating P, and
> ignore aX when calculating Q?
>
> Thank you,
> Edson
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Mon Apr 14 15:45:57 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 14 Apr 2014 15:45:57 +0200
Subject: [R] correlation with missing values.. different answers
In-Reply-To: <CAPEW02azDm7OEx6Ldsu01kJiQidei5eit-VorT8KFHjYAQH7uw@mail.gmail.com>
References: <CAPEW02ajf3u0MruHdu_yJpZLse60YYMg2sC237OSeYOXba3F+w@mail.gmail.com>
	<1397439364.75972.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAPEW02azDm7OEx6Ldsu01kJiQidei5eit-VorT8KFHjYAQH7uw@mail.gmail.com>
Message-ID: <F67A033C-8E34-4E0B-A051-05467BA25E8C@gmail.com>


On 14 Apr 2014, at 05:02 , Paul Tanger <paul.tanger at colostate.edu> wrote:

> Thanks, I did not realize it was deleting rows!  I was afraid to try
> "pairwise.complete.obs" because it said something about resulting in a
> matrix which is not "positive semi-definite" (and googling that term
> just confused me more).  

It means that you can get a covariance matrix that isn't one. I.e., it may predict that some linear combination of your variables has negative variance. It may turn out not to be a problem in practice, but that sort of thing tends to worry theoreticians.

> But I ran the dataset through JMP and got the
> same answers so I think that "pairwise.complete.obs" works for what I
> want to do.
> 

Actually, JMP 10 claims to be using the REML method, which is different from pairwise correlations (you can get both, so it is easy to check that they differ). I'm not sure we have the REML method coded up anywhere; the ML counterpart is in package mvnmle, and one might hope that REML isn't alll that much harder.

> On Sun, Apr 13, 2014 at 7:36 PM, arun <smartpink111 at yahoo.com> wrote:
>> 
>> 
>> 
>> Hi,
>> 
>> I think in this case, when you use "na.or.complete", all the NA rows are removed for the full dataset.
>> cor(swM[-1,1:2])
>> #          Frtlty    Agrclt
>> #Frtlty 1.0000000 0.3920289
>> #Agrclt 0.3920289 1.0000000
>> 
>> cor(swM[-1,])[1:2,1:2]
>> #Frtlty    Agrclt
>> #Frtlty 1.0000000 0.3920289
>> #Agrclt 0.3920289 1.0000000
>> 
>> May be you can try with "pairwise.complete.obs"
>> cor(swM, use = "pairwise.complete.obs")
>> #           Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M
>> #Frtlty  1.0000000  0.39202893 -0.6531492 -0.66378886  0.4723129  0.41655603
>> #Agrclt  0.3920289  1.00000000 -0.7150561 -0.65221506  0.4152007 -0.03648427
>> #Exmntn -0.6531492 -0.71505612  1.0000000  0.69921153 -0.6003402 -0.11433546
>> #Eductn -0.6637889 -0.65221506  0.6992115  1.00000000 -0.1791334 -0.09932185
>> #Cathlc  0.4723129  0.41520069 -0.6003402 -0.17913339  1.0000000  0.18503786
>> #Infn.M  0.4165560 -0.03648427 -0.1143355 -0.09932185  0.1850379  1.00000000
>> cor(swM[,1:2],use="pairwise.complete.obs")
>> #          Frtlty    Agrclt
>> #Frtlty 1.0000000 0.3920289
>> #Agrclt 0.3920289 1.0000000
>> 
>> A.K.
>> 
>> On Sunday, April 13, 2014 9:11 PM, Paul Tanger <paul.tanger at colostate.edu> wrote:
>> Hi,
>> I can't seem to figure out why this gives me different answers.  Probably
>> something obvious, but I thought they would be the same.
>> This is an minimal example from the help page of cor() :
>> 
>>> ## swM := "swiss" with  3 "missing"s :
>>> swM <- swiss
>>> colnames(swM) <- abbreviate(colnames(swiss), min=6)
>>> swM[1,2] <- swM[7,3] <- swM[25,5] <- NA # create 3 "missing"
>>> cor(swM, use = "na.or.complete")
>>           Frtlty      Agrclt     Exmntn      Eductn     Cathlc      Infn.M
>> Frtlty  1.0000000  0.37821953 -0.6548306 -0.67421581  0.4772298  0.38781500
>> Agrclt  0.3782195  1.00000000 -0.7127078 -0.64337782  0.4014837 -0.07168223
>> Exmntn -0.6548306 -0.71270778  1.0000000  0.69776906 -0.6079436 -0.10710047
>> Eductn -0.6742158 -0.64337782  0.6977691  1.00000000 -0.1701445 -0.08343279
>> Cathlc  0.4772298  0.40148365 -0.6079436 -0.17014449  1.0000000  0.17221594
>> Infn.M  0.3878150 -0.07168223 -0.1071005 -0.08343279  0.1722159  1.00000000
>>> # why isn't this the same?
>>> cor(swM[,c(1:2)], use = "na.or.complete")
>>          Frtlty    Agrclt
>> Frtlty 1.0000000 0.3920289
>> Agrclt 0.3920289 1.0000000
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From pdalgd at gmail.com  Mon Apr 14 16:11:37 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 14 Apr 2014 16:11:37 +0200
Subject: [R] Selecting variables in a multivariate regression
In-Reply-To: <CACk-te0hzaW_ACvJFsUKmrfD3yLnz_P6K07o-0WLzkFjDHguww@mail.gmail.com>
References: <CAD7AJnd_LnQJToB-dhm9fvr4SGeNJgKDU9rOB6+fjmWyaRYk6A@mail.gmail.com>
	<CACk-te0hzaW_ACvJFsUKmrfD3yLnz_P6K07o-0WLzkFjDHguww@mail.gmail.com>
Message-ID: <2213FCB6-F06C-46EF-96DA-EF4F3C9A17F7@gmail.com>


On 14 Apr 2014, at 15:33 , Bert Gunter <gunter.berton at gene.com> wrote:

> Well, this is your second post on the same topic, your first having
> received no response. So you should suspect something is amiss and
> reconsider before continuing, don't you think?
> 
> 1. I, for one, was not able to make any sense of your query. You do
> not appear to understand regression, so I would suggest you spend time
> with a local statistical resource before continuing with online
> posts.If my understanding of your misunderstanding is correct, you
> need to comprehend basics. If not,apologies.
> 

The problem as such makes OK sense to me: multivariate linear model, not all regressors affecting all outputs. The simplest case of this is what is known as "seemingly unrelated regressions". The thing not known/understood by the poster is that such models are outside the scope of the MANOVA type models, which is all lm() is designed to do. The "sem" and "systemfit" packages may be of help, but some reading and/or consultation with someone with the relevant expertise may be necessary.

Peter D.

> 2. Have you read An Introduction to R (ships with R) or an online R
> tutorial of your choice? If not, do so before posting here further. We
> expect minimal efforts of posters to solve their own problems before
> posting. Again, apologies if I err.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
> On Sun, Apr 13, 2014 at 8:08 PM, Edson Tirelli <ed.tirelli at gmail.com> wrote:
>> I am quite new to R and I am having trouble figuring out how to select
>> variables in a multivariate linear regression in R. My google-fu also
>> did not find anything.
>> 
>> Pretend I have the following formulas:
>> 
>> P = aX + bY
>> Q = cZ + bY
>> 
>> I have a data frame with column P, Q, X, Y, Z and I need to find a, b and c.
>> 
>> If I do a simple multivariate regression:
>> 
>> result <- lm( cbind( P, Q ) ~ X + Y + Z - 1 )
>> 
>> It calculates a coefficient for "c" on P's regression and for "a" on
>> Q's regression.
>> 
>> If I calculate the regressions individually then "b" will be different
>> in each regression.
>> 
>> How can I select the variables to consider in a multivariate
>> regression? I.e., how do I tell R to ignore cZ when calculating P, and
>> ignore aX when calculating Q?
>> 
>> Thank you,
>> Edson
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From pertsou at gmail.com  Mon Apr 14 16:28:17 2014
From: pertsou at gmail.com (Endy BlackEndy)
Date: Mon, 14 Apr 2014 17:28:17 +0300
Subject: [R] Programming routine comp()
Message-ID: <CAGpBJKRuDyquJT097iYDhUR_F2Y1BcBXdVmrCDWzEEfuBCp1VQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/d8559c5f/attachment-0001.pl>

From pertsou at gmail.com  Mon Apr 14 16:34:22 2014
From: pertsou at gmail.com (Endy BlackEndy)
Date: Mon, 14 Apr 2014 17:34:22 +0300
Subject: [R] Programming routine comp()
Message-ID: <CAGpBJKThQ1FKAMBUbUXtq3A3MZh83UjMKDLB_svS1RT0u4xJjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/0a967af1/attachment-0001.pl>

From pavneet.arora at uk.rsagroup.com  Mon Apr 14 16:52:11 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Mon, 14 Apr 2014 15:52:11 +0100
Subject: [R] Read.table mucks up headers
Message-ID: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/47309a6d/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Mon Apr 14 17:13:32 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 14 Apr 2014 08:13:32 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
References: <534AC262.4010202@structuremonitoring.com>
	<CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
Message-ID: <534BFB1C.8070906@structuremonitoring.com>

Hi, Hadley:


On 4/14/2014 5:53 AM, Hadley Wickham wrote:
> For finer level detail, have a look at
> https://github.com/hadley/cran-packages. It contains the description
> file of every package ever uploaded to CRAN (the cache is a few months
> out of date, but you can easily re-run)


       Can that be mined to get the date of first commit to CRAN? Dates 
in description files are sometimes updated.  Example:  The "Date" in the 
Description file for the version of "fda" now on CRAN is 2013-05, but 
fda was on CRAN at least in 2006 and probably earlier.  You are listed 
as second author on that package based on work you did in by 2006.


       Spencer

> Hadley
>
> On Sun, Apr 13, 2014 at 12:59 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>>        What data exist on the growth of CRAN?
>>
>>
>>        John Fox published some data on it in 2009 ("Aspects of the Social
>> Organization and Trajectory of the R Project", R Journal,
>> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf). Below
>> please find those numbers plus some additions of mine since. If anyone else
>> has other numbers (or more accurate numbers), I'd like to know.
>>
>>
>>        I plan to add a "CRANpackages" data set to the "Ecdat" package with a
>> title, "Growth of CRAN" unless someone else provides better numbers or
>> title.  [If it already exists on CRAN, I'd like to know. I doubt if it does,
>> because I couldn't find it with findFn{sos} for 'number of CRAN packages'
>> and 'growth of CRAN'.]
>>
>>
>>        Thanks,
>>        Spencer
>>
>>
>> date    packages
>> 2001-06-21    110
>> 2001-12-17    129
>> 2002-06-12    162
>> 2003-05-27    219
>> 2003-11-16    273
>> 2004-06-05    357
>> 2004-10-12    406
>> 2005-06-18    548
>> 2005-12-16    647
>> 2006-05-31    739
>> 2006-12-12    911
>> 2007-04-12    1000
>> 2007-11-16    1300
>> 2008-03-18    1427
>> 2008-10-18    1614
>> 2009-09-17    1952
>> 2012-06-12    3786
>> 2012-11-01    4082
>> 2012-12-14    4210
>> 2013-10-28    4960
>> 2013-11-08    5000
>> 2014-04-13    5428
>>
>>
>> * NOTE:  These numbers may differ slightly from other sources. Numbers
>> through 2009 were read from a plot in Fox's paper.  Numbers since were read
>> at an arbitrary time during the day, Pacific time, from a mirror in the
>> United States and could differ from those recorded by someone else using a
>> different mirror having the same date in local time  someplace else.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From h.wickham at gmail.com  Mon Apr 14 17:15:58 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 14 Apr 2014 11:15:58 -0400
Subject: [R] Growth of CRAN?
In-Reply-To: <534BFB1C.8070906@structuremonitoring.com>
References: <534AC262.4010202@structuremonitoring.com>
	<CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
	<534BFB1C.8070906@structuremonitoring.com>
Message-ID: <CABdHhvEHmAG07iaHPFLeRY-jqoJjQfwEDhNYZubQNz7ehed_aQ@mail.gmail.com>

Yes, because it has every version of every DESCRIPTION.

Hadley

On Mon, Apr 14, 2014 at 11:13 AM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hi, Hadley:
>
>
>
> On 4/14/2014 5:53 AM, Hadley Wickham wrote:
>>
>> For finer level detail, have a look at
>> https://github.com/hadley/cran-packages. It contains the description
>> file of every package ever uploaded to CRAN (the cache is a few months
>> out of date, but you can easily re-run)
>
>
>
>       Can that be mined to get the date of first commit to CRAN? Dates in
> description files are sometimes updated.  Example:  The "Date" in the
> Description file for the version of "fda" now on CRAN is 2013-05, but fda
> was on CRAN at least in 2006 and probably earlier.  You are listed as second
> author on that package based on work you did in by 2006.
>
>
>       Spencer
>
>
>> Hadley
>>
>> On Sun, Apr 13, 2014 at 12:59 PM, Spencer Graves
>> <spencer.graves at structuremonitoring.com> wrote:
>>>
>>>        What data exist on the growth of CRAN?
>>>
>>>
>>>        John Fox published some data on it in 2009 ("Aspects of the Social
>>> Organization and Trajectory of the R Project", R Journal,
>>> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf).
>>> Below
>>> please find those numbers plus some additions of mine since. If anyone
>>> else
>>> has other numbers (or more accurate numbers), I'd like to know.
>>>
>>>
>>>        I plan to add a "CRANpackages" data set to the "Ecdat" package
>>> with a
>>> title, "Growth of CRAN" unless someone else provides better numbers or
>>> title.  [If it already exists on CRAN, I'd like to know. I doubt if it
>>> does,
>>> because I couldn't find it with findFn{sos} for 'number of CRAN packages'
>>> and 'growth of CRAN'.]
>>>
>>>
>>>        Thanks,
>>>        Spencer
>>>
>>>
>>> date    packages
>>> 2001-06-21    110
>>> 2001-12-17    129
>>> 2002-06-12    162
>>> 2003-05-27    219
>>> 2003-11-16    273
>>> 2004-06-05    357
>>> 2004-10-12    406
>>> 2005-06-18    548
>>> 2005-12-16    647
>>> 2006-05-31    739
>>> 2006-12-12    911
>>> 2007-04-12    1000
>>> 2007-11-16    1300
>>> 2008-03-18    1427
>>> 2008-10-18    1614
>>> 2009-09-17    1952
>>> 2012-06-12    3786
>>> 2012-11-01    4082
>>> 2012-12-14    4210
>>> 2013-10-28    4960
>>> 2013-11-08    5000
>>> 2014-04-13    5428
>>>
>>>
>>> * NOTE:  These numbers may differ slightly from other sources. Numbers
>>> through 2009 were read from a plot in Fox's paper.  Numbers since were
>>> read
>>> at an arbitrary time during the day, Pacific time, from a mirror in the
>>> United States and could differ from those recorded by someone else using
>>> a
>>> different mirror having the same date in local time  someplace else.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
>



-- 
http://had.co.nz/



From spencer.graves at structuremonitoring.com  Mon Apr 14 17:19:46 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 14 Apr 2014 08:19:46 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
References: <534AC262.4010202@structuremonitoring.com>
	<CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
Message-ID: <534BFC92.5000700@structuremonitoring.com>

p.s.  Have backup copies of CRAN been made, e.g., annually or with each 
new release?  Or are there summaries of the tests done with each new 
release?  I'm looking for something that could be checked to compile a 
more accurate and consistent database than what we have now.  For me, 
this is idle curiosity.  However, this could be used to help plan the 
expansion of CRAN, providing forecasts with confidence bounds.


########################


Hi, Hadley:


On 4/14/2014 5:53 AM, Hadley Wickham wrote:
> For finer level detail, have a look at
> https://github.com/hadley/cran-packages. It contains the description
> file of every package ever uploaded to CRAN (the cache is a few months
> out of date, but you can easily re-run)


       Can that be mined to get the date of first commit to CRAN? Dates 
in description files are sometimes updated.  Example:  The "Date" in the 
Description file for the version of "fda" now on CRAN is 2013-05, but 
fda was on CRAN at least in 2006 and probably earlier.  You are listed 
as second author on that package based on work you did in by 2006.


       Spencer

> Hadley
>
> On Sun, Apr 13, 2014 at 12:59 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>>        What data exist on the growth of CRAN?
>>
>>
>>        John Fox published some data on it in 2009 ("Aspects of the Social
>> Organization and Trajectory of the R Project", R Journal,
>> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf). Below
>> please find those numbers plus some additions of mine since. If anyone else
>> has other numbers (or more accurate numbers), I'd like to know.
>>
>>
>>        I plan to add a "CRANpackages" data set to the "Ecdat" package with a
>> title, "Growth of CRAN" unless someone else provides better numbers or
>> title.  [If it already exists on CRAN, I'd like to know. I doubt if it does,
>> because I couldn't find it with findFn{sos} for 'number of CRAN packages'
>> and 'growth of CRAN'.]
>>
>>
>>        Thanks,
>>        Spencer
>>
>>
>> date    packages
>> 2001-06-21    110
>> 2001-12-17    129
>> 2002-06-12    162
>> 2003-05-27    219
>> 2003-11-16    273
>> 2004-06-05    357
>> 2004-10-12    406
>> 2005-06-18    548
>> 2005-12-16    647
>> 2006-05-31    739
>> 2006-12-12    911
>> 2007-04-12    1000
>> 2007-11-16    1300
>> 2008-03-18    1427
>> 2008-10-18    1614
>> 2009-09-17    1952
>> 2012-06-12    3786
>> 2012-11-01    4082
>> 2012-12-14    4210
>> 2013-10-28    4960
>> 2013-11-08    5000
>> 2014-04-13    5428
>>
>>
>> * NOTE:  These numbers may differ slightly from other sources. Numbers
>> through 2009 were read from a plot in Fox's paper.  Numbers since were read
>> at an arbitrary time during the day, Pacific time, from a mirror in the
>> United States and could differ from those recorded by someone else using a
>> different mirror having the same date in local time  someplace else.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Mon Apr 14 17:23:19 2014
From: dcarlson at tamu.edu (dcarlson at tamu.edu)
Date: Mon, 14 Apr 2014 10:23:19 -0500
Subject: [R] Comparing initial eigenvalues to broken stick results
References: <COL402-EAS408DDC10010BBEEE1B73110EF510@phx.gbl> 
Message-ID: <02e801cf57f5$775ea890$661bf9b0$@tamu.edu>

It helps a great deal if you provide a small data set using
dput() and indicate what packages need to be loaded for the
functions you are using. This example uses random data so there
are no eigenvalues above the initial broken stick values:

> set.seed(42)
> x <- matrix(rnorm(200), 20, 10)
> require(vegan)
> bs <- rle(eigen(cor(x))$values>bstick(10,tot.var=10))
> as.vector(ifelse(bs$values[1]==TRUE, bs$lengths[1], 0))
[1] 0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Allyson
Combes
Sent: Sunday, April 13, 2014 11:01 PM
To: r-help at R-project.org
Subject: [R] Comparing initial eigenvalues to broken stick
results

I am trying to create a function that will allow me to determine
the number of components to retain based on the results of the
broken stick criterion.  In order to do so I know I need to
compare the initial eigen values to the broken stick eigen
values.  The initial eigen value which becomes lower than the
broken stick is the cutoff point so the cutoff for the number of
components to retain is the number of eigen values before this
cutoff points.   




So far this is the syntax I have and what I get.




ev <- eigen(cor(EFAexample)) 
ev 
bstick(24, tot.var=24)


> ev
$values
 [1] 7.2819381 2.3951299 1.8190170 1.6056666 0.9862474 0.9092235
0.8269931
 [8] 0.7861644 0.6978157 0.6824547 0.6333925 0.5997783 0.5737571
0.5347758
[15] 0.4976710 0.4849214 0.4502025 0.4223273 0.3819080 0.3599697
0.3353226
[22] 0.3184069 0.2146300 0.2022866


> bstick(24, tot.var=24)
    Stick1     Stick2     Stick3     Stick4     Stick5
Stick6     Stick7 
3.77595818 2.77595818 2.27595818 1.94262484 1.69262484
1.49262484 1.32595818 
    Stick8     Stick9    Stick10    Stick11    Stick12
Stick13    Stick14 
1.18310103 1.05810103 0.94698992 0.84698992 0.75608083
0.67274750 0.59582442 
   Stick15    Stick16    Stick17    Stick18    Stick19
Stick20    Stick21 
0.52439585 0.45772918 0.39522918 0.33640566 0.28085010
0.22821852 0.17821852 
   Stick22    Stick23    Stick24 
0.13059947 0.08514493 0.04166667 


In this case the cutoff would be at stick 2 thus we would only
retain 1 component.  What syntax can I use to automatically make
this comparison instead of having to do it manually each time?


Also, am I using bstick correctly?  From what I understand I
should just have to enter the number of components and the total
variance which will be the total number of components.


Any help would be greatly appreciated.  Thanks!


Allyson
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From spencer.graves at structuremonitoring.com  Mon Apr 14 17:31:28 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 14 Apr 2014 08:31:28 -0700
Subject: [R] Growth of CRAN?
In-Reply-To: <CABdHhvEHmAG07iaHPFLeRY-jqoJjQfwEDhNYZubQNz7ehed_aQ@mail.gmail.com>
References: <534AC262.4010202@structuremonitoring.com>
	<CABdHhvG5TjYSFaK+v-q6s1Cp+mcYJycXc8Grt=sDhkG5QV8Tbw@mail.gmail.com>
	<534BFB1C.8070906@structuremonitoring.com>
	<CABdHhvEHmAG07iaHPFLeRY-jqoJjQfwEDhNYZubQNz7ehed_aQ@mail.gmail.com>
Message-ID: <534BFF50.40902@structuremonitoring.com>

Hi, Hadley, et al.:


       Is anyone interested in mining the link Hadley provided below to 
compile a data.frame of the growth of the size of CRAN? I'll happily add 
it to the Ecdat package unless someone would rather put it someplace 
else.  It would be great for a study using, e.g., Bayesian Model 
Averaging to forecast the growth.  I got good results using the "drc" 
package, but findFn("growth") identified others that could ultimately be 
more useful.


       Spencer


On 4/14/2014 8:15 AM, Hadley Wickham wrote:
> Yes, because it has every version of every DESCRIPTION.
>
> Hadley
>
> On Mon, Apr 14, 2014 at 11:13 AM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> Hi, Hadley:
>>
>>
>>
>> On 4/14/2014 5:53 AM, Hadley Wickham wrote:
>>> For finer level detail, have a look at
>>> https://github.com/hadley/cran-packages. It contains the description
>>> file of every package ever uploaded to CRAN (the cache is a few months
>>> out of date, but you can easily re-run)
>>
>>
>>        Can that be mined to get the date of first commit to CRAN? Dates in
>> description files are sometimes updated.  Example:  The "Date" in the
>> Description file for the version of "fda" now on CRAN is 2013-05, but fda
>> was on CRAN at least in 2006 and probably earlier.  You are listed as second
>> author on that package based on work you did in by 2006.
>>
>>
>>        Spencer
>>
>>
>>> Hadley
>>>
>>> On Sun, Apr 13, 2014 at 12:59 PM, Spencer Graves
>>> <spencer.graves at structuremonitoring.com> wrote:
>>>>         What data exist on the growth of CRAN?
>>>>
>>>>
>>>>         John Fox published some data on it in 2009 ("Aspects of the Social
>>>> Organization and Trajectory of the R Project", R Journal,
>>>> http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf).
>>>> Below
>>>> please find those numbers plus some additions of mine since. If anyone
>>>> else
>>>> has other numbers (or more accurate numbers), I'd like to know.
>>>>
>>>>
>>>>         I plan to add a "CRANpackages" data set to the "Ecdat" package
>>>> with a
>>>> title, "Growth of CRAN" unless someone else provides better numbers or
>>>> title.  [If it already exists on CRAN, I'd like to know. I doubt if it
>>>> does,
>>>> because I couldn't find it with findFn{sos} for 'number of CRAN packages'
>>>> and 'growth of CRAN'.]
>>>>
>>>>
>>>>         Thanks,
>>>>         Spencer
>>>>
>>>>
>>>> date    packages
>>>> 2001-06-21    110
>>>> 2001-12-17    129
>>>> 2002-06-12    162
>>>> 2003-05-27    219
>>>> 2003-11-16    273
>>>> 2004-06-05    357
>>>> 2004-10-12    406
>>>> 2005-06-18    548
>>>> 2005-12-16    647
>>>> 2006-05-31    739
>>>> 2006-12-12    911
>>>> 2007-04-12    1000
>>>> 2007-11-16    1300
>>>> 2008-03-18    1427
>>>> 2008-10-18    1614
>>>> 2009-09-17    1952
>>>> 2012-06-12    3786
>>>> 2012-11-01    4082
>>>> 2012-12-14    4210
>>>> 2013-10-28    4960
>>>> 2013-11-08    5000
>>>> 2014-04-13    5428
>>>>
>>>>
>>>> * NOTE:  These numbers may differ slightly from other sources. Numbers
>>>> through 2009 were read from a plot in Fox's paper.  Numbers since were
>>>> read
>>>> at an arbitrary time during the day, Pacific time, from a mirror in the
>>>> United States and could differ from those recorded by someone else using
>>>> a
>>>> different mirror having the same date in local time  someplace else.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>

-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From ed.tirelli at gmail.com  Mon Apr 14 17:43:55 2014
From: ed.tirelli at gmail.com (Edson Tirelli)
Date: Mon, 14 Apr 2014 11:43:55 -0400
Subject: [R] Selecting variables in a multivariate regression
In-Reply-To: <CACk-te0hzaW_ACvJFsUKmrfD3yLnz_P6K07o-0WLzkFjDHguww@mail.gmail.com>
References: <CAD7AJnd_LnQJToB-dhm9fvr4SGeNJgKDU9rOB6+fjmWyaRYk6A@mail.gmail.com>
	<CACk-te0hzaW_ACvJFsUKmrfD3yLnz_P6K07o-0WLzkFjDHguww@mail.gmail.com>
Message-ID: <CAD7AJneM2Mgwrq8XOHUAXN7XC1WxS8M2L5Z7wxaMytOvnppsig@mail.gmail.com>

   Bert,

   I am sorry for having troubled you. The double post was a mistake
because gmail sent the first e-mail in html and it went into
moderation queue. The second one was sent in plain text. I did not
know the moderator approved my first post.

1. As I said, I am a beginner in statistics and in R. I did spent ~8
hours yesterday googling around, reading tutorials and testing out
solutions. I also completed a couple coursera courses on data analysis
and R programming over the last few months, but since I was not able
to solve the problem by myself, I was hoping the friendly R community
would help me.

2. Please see my comments to (1).

   Having said that, as a beginner of R, I had no idea there was a
package called "lavaan" that easily solves my problem. Someone else
pointed that to me over stackoverflow, and with his help I was able to
solve my problem:

http://stackoverflow.com/questions/23048501/selecting-variables-in-a-multivariate-regression-in-r

   Please note that my actual problem is quite more complex than that,
with 15 independent variables and 11 dependent ones. My toy example in
this question was my attempt to simplify the question so that people
with experience could point me in the right direction.

   Thank you anyway, I won't bother you again.

   Edson



On Mon, Apr 14, 2014 at 9:33 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Well, this is your second post on the same topic, your first having
> received no response. So you should suspect something is amiss and
> reconsider before continuing, don't you think?
>
> 1. I, for one, was not able to make any sense of your query. You do
> not appear to understand regression, so I would suggest you spend time
> with a local statistical resource before continuing with online
> posts.If my understanding of your misunderstanding is correct, you
> need to comprehend basics. If not,apologies.
>
> 2. Have you read An Introduction to R (ships with R) or an online R
> tutorial of your choice? If not, do so before posting here further. We
> expect minimal efforts of posters to solve their own problems before
> posting. Again, apologies if I err.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
>
>
>
>
> On Sun, Apr 13, 2014 at 8:08 PM, Edson Tirelli <ed.tirelli at gmail.com> wrote:
>> I am quite new to R and I am having trouble figuring out how to select
>> variables in a multivariate linear regression in R. My google-fu also
>> did not find anything.
>>
>> Pretend I have the following formulas:
>>
>> P = aX + bY
>> Q = cZ + bY
>>
>> I have a data frame with column P, Q, X, Y, Z and I need to find a, b and c.
>>
>> If I do a simple multivariate regression:
>>
>> result <- lm( cbind( P, Q ) ~ X + Y + Z - 1 )
>>
>> It calculates a coefficient for "c" on P's regression and for "a" on
>> Q's regression.
>>
>> If I calculate the regressions individually then "b" will be different
>> in each regression.
>>
>> How can I select the variables to consider in a multivariate
>> regression? I.e., how do I tell R to ignore cZ when calculating P, and
>> ignore aX when calculating Q?
>>
>> Thank you,
>> Edson
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
  Edson Tirelli
  Principal Software Engineer
  Red Hat Business Systems and Intelligence Group



From jdnewmil at dcn.davis.CA.us  Mon Apr 14 17:50:08 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Apr 2014 08:50:08 -0700
Subject: [R] Read.table mucks up headers
In-Reply-To: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
Message-ID: <0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>

You have not posted the input to your code so it is not reproducible. Also, you have posted in HTML, which is notorious for corrupting R code and data in emails.

If I were to guess, though, it looks to me like you are working with a UTF-8 file with a Byte Order Mark (header). I don't know the "correct" way to address this, but if you only have plain text data then the rest of your table should be valid and you could reset the name of the first column yourself like

names(sim)[1] <- "X"
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 14, 2014 7:52:11 AM PDT, Pavneet Arora <pavneet.arora at uk.rsagroup.com> wrote:
>Hey All
>
>I am trying to read in a small text file using read.table. 
>
>dput(sim)
>structure(list(??...X. = 1:7, Y1 = c(2.5501, 4.105, 5.4687, 7.0009, 
>8.5066, 9.785, 11.5167), Y2 = c(2.5501, 4.105, 5.4687, 11.0009, 
>8.5066, 9.785, 11.5167), Y3 = c(2.5501, 4.105, 5.4687, 7.0009, 
>8.5066, 9.785, 15.5167)), .Names = c("??...X.", "Y1", "Y2", "Y3"
>), class = "data.frame", row.names = c(NA, -7L))
>
>But for some reason my first header comes as "?...X. ", instead of just
>
>"X". Can some one please tell me why? And how to fix it?
>
>This is what I did in my code, using R-studio
>> sim<-read.table("C:/00Pavneet/# MSc/# temp/sim data 1.txt",header=T)
>> View(sim)
>
>
>***********************************************************************************************************************************************************************************************************************
>MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No.
>93792). Registered in England and Wales at St. Mark???s Court, Chart
>Way, Horsham, West Sussex, RH12 1XL. 
>
>Authorised by the Prudential Regulation Authority and regulated by the
>Financial Conduct Authority and the Prudential Regulation Authority.
>************************************************************************************************************************************************************************************************************************
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From S.Ellison at LGCGroup.com  Mon Apr 14 17:53:25 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 14 Apr 2014 16:53:25 +0100
Subject: [R] Read.table mucks up headers
In-Reply-To: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E9D35F08B@GOLD.corp.lgc-group.com>

> But for some reason my first header comes as "?...X. ", instead of just "X".
> Can some one please tell me why? And how to fix it?

i) What were the separator characters in the original data file header row? 
ii) Your first character is not being decoded properly; check the file encoding and set accordingly?
iii) See if the offending first character(s) can sensibly be stripped before reading the file?

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From nalimilan at club.fr  Mon Apr 14 19:09:59 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 14 Apr 2014 19:09:59 +0200
Subject: [R] Read.table mucks up headers
In-Reply-To: <0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
Message-ID: <1397495399.4315.1.camel@milan>


Le lundi 14 avril 2014 ? 08:50 -0700, Jeff Newmiller a ?crit :
> You have not posted the input to your code so it is not reproducible.
> Also, you have posted in HTML, which is notorious for corrupting R
> code and data in emails.
> 
> If I were to guess, though, it looks to me like you are working with a
> UTF-8 file with a Byte Order Mark (header). I don't know the "correct"
> way to address this, but if you only have plain text data then the
> rest of your table should be valid and you could reset the name of the
> first column yourself like
> 
> names(sim)[1] <- "X"
If the byte order mark is the problem, then the natural way of handling
this is to pass fileEncoding="UTF-8-BOM" to read.table().


Regards

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On April 14, 2014 7:52:11 AM PDT, Pavneet Arora <pavneet.arora at uk.rsagroup.com> wrote:
> >Hey All
> >
> >I am trying to read in a small text file using read.table. 
> >
> >dput(sim)
> >structure(list(??...X. = 1:7, Y1 = c(2.5501, 4.105, 5.4687, 7.0009, 
> >8.5066, 9.785, 11.5167), Y2 = c(2.5501, 4.105, 5.4687, 11.0009, 
> >8.5066, 9.785, 11.5167), Y3 = c(2.5501, 4.105, 5.4687, 7.0009, 
> >8.5066, 9.785, 15.5167)), .Names = c("??...X.", "Y1", "Y2", "Y3"
> >), class = "data.frame", row.names = c(NA, -7L))
> >
> >But for some reason my first header comes as "?...X. ", instead of just
> >
> >"X". Can some one please tell me why? And how to fix it?
> >
> >This is what I did in my code, using R-studio
> >> sim<-read.table("C:/00Pavneet/# MSc/# temp/sim data 1.txt",header=T)
> >> View(sim)
> >
> >
> >***********************************************************************************************************************************************************************************************************************
> >MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No.
> >93792). Registered in England and Wales at St. Mark???s Court, Chart
> >Way, Horsham, West Sussex, RH12 1XL. 
> >
> >Authorised by the Prudential Regulation Authority and regulated by the
> >Financial Conduct Authority and the Prudential Regulation Authority.
> >************************************************************************************************************************************************************************************************************************
> >
> >	[[alternative HTML version deleted]]
> >
> >
> >
> >------------------------------------------------------------------------
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From anna.eklof at liu.se  Mon Apr 14 07:54:27 2014
From: anna.eklof at liu.se (=?iso-8859-1?Q?Anna_Ekl=F6f?=)
Date: Mon, 14 Apr 2014 05:54:27 +0000
Subject: [R] gRain on R 3.1.0
Message-ID: <2A89054F-A00F-404F-80A3-3EA2B1DEC42A@liu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/7bffe859/attachment-0001.pl>

From kevin511511 at gmail.com  Mon Apr 14 08:13:48 2014
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Mon, 14 Apr 2014 02:13:48 -0400
Subject: [R] how to do poisson regression for a complex sample design data
	by svyglm
Message-ID: <CAB4W2n5D7WSp9j9PD3-YGCWKY6DFFwj2yr+jFLk-J=bxQUC7fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/0f47035c/attachment-0001.pl>

From marcus.kleber at web.de  Mon Apr 14 12:20:31 2014
From: marcus.kleber at web.de (mkleber74)
Date: Mon, 14 Apr 2014 03:20:31 -0700 (PDT)
Subject: [R] Trend test for hazard ratios
Message-ID: <1397470831424-4688729.post@n4.nabble.com>

Hello,

I have the following problem. I stratified my patient cohort into three
ordered groups and performed multivariate adjusted Cox regression analysis
on each group separately. Now I would like to calculate a p for trend across
the hazard ratios that I got for the three groups. How can I do that if I
only have the HR and the confidence interval? For example I got the
following HRs for one endpoint: 

1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68). 

There is a trend but how do I calculate if it is significant?

Best regards

Marcus Kleber



--
View this message in context: http://r.789695.n4.nabble.com/Trend-test-for-hazard-ratios-tp4688729.html
Sent from the R help mailing list archive at Nabble.com.



From andre.zacharia at gmail.com  Mon Apr 14 15:15:42 2014
From: andre.zacharia at gmail.com (andre.zacharia at gmail.com)
Date: Mon, 14 Apr 2014 06:15:42 -0700 (PDT)
Subject: [R] mean calculations from a dframe column
In-Reply-To: <62a1da7f9622574935dda844bce669bb@www.webmail.co.za>
References: <1397338225448-4688674.post@n4.nabble.com>
	<1397383914.51315.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<6612484066672746085@unknownmsgid>
	<62a1da7f9622574935dda844bce669bb@www.webmail.co.za>
Message-ID: <CAPrACK+dUj+bXa-avr9Tk8frm4VEXMgwmB9SdZ_9xabUkO9a1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/ac971115/attachment-0001.pl>

From chrissair at gmx.net  Mon Apr 14 16:07:36 2014
From: chrissair at gmx.net (ChrisR)
Date: Mon, 14 Apr 2014 07:07:36 -0700 (PDT)
Subject: [R] hetglm() and robust standard errors
Message-ID: <1397484456221-4688737.post@n4.nabble.com>

Hi everyone,
I am using the hetglm() command from the package 'glmx' (0.1-0). It seems
that hetglm() is incompatible with the robust standard errors estimator
provided in the 'AER' package: coeftest(mymodel,vcov=vcovHC)
Any suggestions how I could obtain robust standard errors for the
heteroscedastic probit?

Thanks,
Chris



--
View this message in context: http://r.789695.n4.nabble.com/hetglm-and-robust-standard-errors-tp4688737.html
Sent from the R help mailing list archive at Nabble.com.



From florian.burkart at gmail.com  Mon Apr 14 18:35:00 2014
From: florian.burkart at gmail.com (Florian Burkart)
Date: Mon, 14 Apr 2014 18:35:00 +0200
Subject: [R] X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*,
 face 2 at size 11 could not be loaded
Message-ID: <CAPSN_LXj6LYVWWOFENUZVkzGtw2RuZ_4cgfGZdm=VGQbGxWFMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/ff5e169d/attachment-0001.pl>

From kafi_dano at yahoo.com  Mon Apr 14 10:06:01 2014
From: kafi_dano at yahoo.com (kafi dano)
Date: Mon, 14 Apr 2014 01:06:01 -0700 (PDT)
Subject: [R] program
Message-ID: <1397462761.46343.YahooMailNeo@web124706.mail.ne1.yahoo.com>

Dear Sir.
I need your to help me to correct the attached R-code. 

when I apply this code give me the bad result 


Attached the program by using R

Thank you?









?
Kafi Dano Pati
Ph.D candidate ( mathematics/statistics)
Department of mathematical Science/ faculty of Science
University Technology Malaysia
81310 UTM, Johor Bahru, Johor, Malaysia
IC. NO. 201202F10234
Matric No. PS113113
HP. No.?00601117517559
E-mail: kafi_dano at yahoo.com
supervisor- Assoc. Prof. Robiah Binti Adnan

From goodnewsformood at sina.com  Mon Apr 14 10:10:12 2014
From: goodnewsformood at sina.com (goodnewsformood at sina.com)
Date: Mon, 14 Apr 2014 16:10:12 +0800 
Subject: [R] How to do abstraction of the document using R
Message-ID: <20140414081012.E111EDA8008@webmail.sinamail.sina.com.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/dc73fc6a/attachment-0001.pl>

From pertsou at yahoo.gr  Mon Apr 14 12:56:03 2014
From: pertsou at yahoo.gr (Endy)
Date: Mon, 14 Apr 2014 11:56:03 +0100 (BST)
Subject: [R] I can't programe routine comp()
Message-ID: <1397472963.31861.YahooMailNeo@web171702.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/ddaf24b3/attachment-0001.pl>

From fachschaftvwl at googlemail.com  Mon Apr 14 15:29:11 2014
From: fachschaftvwl at googlemail.com (jaschwer)
Date: Mon, 14 Apr 2014 06:29:11 -0700 (PDT)
Subject: [R] PGLM Package: Starting Values for Within-Model
In-Reply-To: <1368175283753-4666739.post@n4.nabble.com>
References: <1368175283753-4666739.post@n4.nabble.com>
Message-ID: <9e55bad7-955a-4892-b50b-6424ab1f0915@googlegroups.com>

Does anyone found an answer to that question? I have the same problem and 
can't find a solution.

Am Freitag, 10. Mai 2013 10:41:23 UTC+2 schrieb MaxFranke:
>
> I am currently using the PGLM package and I would like to implement a 
> within-model. Unfortunately, I do not succeed as I am not a big expert in 
> panel regression. 
>
> I am using the example data set from the PGLM package: 
>
> library(pglm) 
> data('Unions', package = 'pglm') 
> anb <- pglm(union~wage+exper+rural, Unions, family=binomial('probit'), 
> model="within",  method = "bfgs", print.level=0, R = 5, iterlim=2) 
>
> The pglm-function needs the argument start for starting values. What do I 
> use? 
>
> Thank you very much! 
>
>
>
> -- 
> View this message in context: 
> http://r.789695.n4.nabble.com/PGLM-Package-Starting-Values-for-Within-Model-tp4666739.html 
> Sent from the R help mailing list archive at Nabble.com. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From alpeshpandya at gmail.com  Mon Apr 14 17:24:55 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Mon, 14 Apr 2014 11:24:55 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <534A9525.90209@statistik.tu-dortmund.de>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
Message-ID: <CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/15612232/attachment-0001.pl>

From kevin511511 at gmail.com  Mon Apr 14 19:59:27 2014
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Mon, 14 Apr 2014 13:59:27 -0400
Subject: [R] problem on package "survey" , function svyglm,
Message-ID: <CAB4W2n6P9mc-KmE0NVrCJVvCWnao9C0ZrgSusWgk0L8ks=u1Rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/66018ded/attachment-0001.pl>

From ruipbarradas at sapo.pt  Mon Apr 14 20:17:03 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 14 Apr 2014 19:17:03 +0100
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>	<5348725B.7070404@statistik.tu-dortmund.de>	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>	<5349CABA.7000807@statistik.tu-dortmund.de>	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
Message-ID: <534C261F.8060608@sapo.pt>

Hello,
I have package XML installed on Windows 7, R 3.0.3 and I had no problem 
at all. Can't you try (it worked with me)

install.packages("XML", repos = "http://cran.dcc.fc.up.pt")

Hope this helps,

Rui Barradas

Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> I have tried these sources (almost all US mirrors):
>
> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://watson.nci.nih.gov/cran_mirror/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>
> I have confirmed with IT that there is no restriction on downloading this
> zip file from any of these sources. Also I am getting same error when I try
> from my home network as well.
>
>
> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
>> wrote:
>
>>
>>
>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>>
>>> @Uwe I tried the same steps from office as well as home network with same
>>> results. Are you using windows 7 with R 3.0.3?
>>>
>>> I have seen same question being asked by others without any resolution. Is
>>> anything special about XML package? I am OK use older version of package
>>> but in archives there are no zip files (only gz files). Is windows
>>> platform
>>> not recommended for R?
>>>
>>
>> Right, and you can try to install these from sources.
>> But I doubt you need it. You still have not told us if you tried another
>> mirror to download the XML file from and what you local IT support tells
>> you while your downloads are incomplete.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>
>>
>>>
>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>>> ligges at statistik.tu-dortmund.de
>>>
>>>> wrote:
>>>>
>>>
>>>
>>>>
>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>>>>
>>>>   Thank you for response Uwe. I tried multiple times by downloading the
>>>>> zip
>>>>> file from many sources but still the same error. This is a major road
>>>>> block
>>>>> for me in using R. Appreciate any help on this.
>>>>>
>>>>>
>>>> Please ask your local IT staff.
>>>>
>>>> I get, using the same mirror:
>>>>
>>>>   options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>>>>> install.packages("XML", lib="d:/temp")
>>>>>
>>>>
>>>> trying URL 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>
>>>> contrib/3.0/XML_3.98-1.1.zip'
>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>> opened URL
>>>> downloaded 4.1 Mb
>>>>
>>>> package 'XML' successfully unpacked and MD5 sums checked
>>>>
>>>> The downloaded binary packages are in
>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
>>>>
>>>>
>>>>
>>>> Best,
>>>> Uwe Ligges
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>> On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>>>>> ligges at statistik.tu-dortmund.de
>>>>>
>>>>>   wrote:
>>>>>>
>>>>>>
>>>>>    Works for me.
>>>>>
>>>>>>
>>>>>> Best,
>>>>>> Uwe Ligges
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>>>>>
>>>>>>    Using install.package('XML') command produces this error:
>>>>>>
>>>>>>>
>>>>>>> trying URL
>>>>>>> '
>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>>>> '
>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>> opened URL
>>>>>>> downloaded 4.1 Mb
>>>>>>>
>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>>>> "Type")) :
>>>>>>>       cannot open the connection
>>>>>>> In addition: Warning messages:
>>>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>>>>>>       downloaded length 4276224 != reported length 4288136
>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>>>>>>> file
>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>>>> "Type"))
>>>>>>> :
>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable reason
>>>>>>> 'No
>>>>>>> such
>>>>>>> file or directory'
>>>>>>>
>>>>>>>
>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip directly from
>>>>>>> cran
>>>>>>> site. But this zip file is not a valid archive (cannot open using
>>>>>>> winzip).
>>>>>>> Also trying to install using this downloaded file produces the
>>>>>>> following
>>>>>>> error:
>>>>>>>
>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
>>>>>>> win-library/3.0'
>>>>>>> (as 'lib' is unspecified)
>>>>>>> Warning in install.packages :
>>>>>>>       error 1 in extracting from zip file
>>>>>>> Warning in install.packages :
>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable reason
>>>>>>> 'No
>>>>>>> such
>>>>>>> file or directory'
>>>>>>> Error in install.packages : cannot open the connection
>>>>>>>
>>>>>>> I  downloaded this zip file from multiple sources and tried to install
>>>>>>> with
>>>>>>> same result.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>
>>>>>
>>>
>>>
>
>



From alpeshpandya at gmail.com  Mon Apr 14 20:24:23 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Mon, 14 Apr 2014 14:24:23 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <534C261F.8060608@sapo.pt>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
Message-ID: <CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/01cc6208/attachment-0001.pl>

From HDoran at air.org  Mon Apr 14 21:02:14 2014
From: HDoran at air.org (Doran, Harold)
Date: Mon, 14 Apr 2014 19:02:14 +0000
Subject: [R] system()
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686945ECC67@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/5c260fd3/attachment-0001.pl>

From ruipbarradas at sapo.pt  Mon Apr 14 21:08:50 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 14 Apr 2014 20:08:50 +0100
Subject: [R] system()
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686945ECC67@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686945ECC67@DC1VEX10MB001.air.org>
Message-ID: <534C3242.5000500@sapo.pt>

Hello,

Try instead

command <- paste(aa, fnm)
system(command)

And read the help page for ?paste

Hope this helps,

Rui Barradas


Em 14-04-2014 20:02, Doran, Harold escreveu:
> I need to send a system command to another program from within R but have a small hangup
>
> I'm trying to do something like this
>
> system("notepad myfile.txt")
>
> But, more generally this is happening to multiple files, so I loop over thousands of files. For purposes of an example, my code is something like this, which does not work
>
> aa <- 'notepad.exe'
> fnm <- 'myfile.txt'
> system("aa fnm")
>
> Any suggestions?
> Harold
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From nalimilan at club.fr  Mon Apr 14 21:07:54 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 14 Apr 2014 21:07:54 +0200
Subject: [R] problem on package "survey" , function svyglm,
In-Reply-To: <CAB4W2n6P9mc-KmE0NVrCJVvCWnao9C0ZrgSusWgk0L8ks=u1Rg@mail.gmail.com>
References: <CAB4W2n6P9mc-KmE0NVrCJVvCWnao9C0ZrgSusWgk0L8ks=u1Rg@mail.gmail.com>
Message-ID: <1397502474.4315.4.camel@milan>

Le lundi 14 avril 2014 ? 13:59 -0400, Hanze Zhang a ?crit :
> Hi,
> 
> I want to do logistic regression based on a complex sample design. I used
> package survey, but when I ran svyglm, an error message came out:
> Error in onestrat(x[index, , drop = FALSE], clusters[index],
> nPSU[index][1],  :
>   Stratum (16) has only one PSU at stage 1
> 
> 
> My code is below:
> 
> a.design<-svydesign(id = ~CASENUM ,strata = ~STRATUM ,data = a ,weights =
> ~SIZAGYWT )
> summary(logistic1 <- svyglm(ANYCONTR ~ CHAIN+OWN+HPPAT, family =
> binomial(link = "logit"), design=a.design))
> 
> 
> How to solve this issue? Thank you.
You need to merge manually the stratum with only one PSU with another
stratum. See 3.2.1 in http://books.google.fr/books?id=L96ludyhFBsC
(look for "single" in the whole book to find it).

Regards



From nalimilan at club.fr  Mon Apr 14 21:13:55 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 14 Apr 2014 21:13:55 +0200
Subject: [R] Error using the package tm.plugin.webmining "object
 '.Source' not found"
In-Reply-To: <CABYizFLTQh_Ay+fjidgwMwW+fz__Vp0A4FG=q1G4tuju7ieDvQ@mail.gmail.com>
References: <CABYizFLTQh_Ay+fjidgwMwW+fz__Vp0A4FG=q1G4tuju7ieDvQ@mail.gmail.com>
Message-ID: <1397502835.4315.9.camel@milan>

Le dimanche 13 avril 2014 ? 20:50 -0400, brian arb a ?crit :
> I recently had an issue while trying to use the package tm.plugin.webmining.
> 
> I was able to get a hack to work for me and I wanted to share the diff and
> bring this to someones attention.
> Or what is the proper way to report a bug for third party code?
You should contact the maintainer of the package. Apparently this
package was using tm's internal function .Source(), which was renamed
into Source() in tm 0.5-10.

You can likely work around this by defining this function first:
.Source <- function(defaultreader, encoding, length, lodsupport, names,
position, vectorized, class = NULL) {
    if (vectorized && (length <= 0))
        stop("vectorized sources must have positive length")

    if (!is.null(names) && (length != length(names)))
        stop("incorrect number of element names")

    structure(list(DefaultReader = defaultreader, Encoding = encoding,
Length = length,
                   LoDSupport = lodsupport, Names = names, Position =
position, Vectorized = vectorized),
              class = unique(c(class, "Source")))
}

If this doesn't work, you can install an older version of tm
(see http://cran.r-project.org/src/contrib/Archive/tm/).

Regards

> Cheers
> 
> ##### error I get when using the plugin. #####
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>   object '.Source' not found
> 
> ##### My Hack Diff #####
> diff ~/Downloads/tm.plugin.webmining/R/source.R \
> > tm.plugin.webmining/R/source.R
> 35c35,36
> <  s <- tm:::.Source(NULL, encoding, length(content_parsed), FALSE, NULL,
> 0, vectorized, class = class)
> ---
> >  s <- tm:::Source(defaultReader=readPlain, encoding=encoding,
> length=length(content_parsed),
> >   names=NA_character_, position=0, vectorized=vectorized, class=class)
> <
> 569,570c570,572
> <  s <- tm:::.Source(NULL, encoding = "UTF-8", length(content), FALSE,
> NULL, 0, vectorized = FALSE, class = "WebXMLSource")
> <  s$Content <- content
> ---
> >  s <- tm:::Source(defaultReader=readPlain, encoding="UTF-8",
> length=length(content),
> >   names=NA_character_, position=0, vectorized=FALSE, class="WebXMLSource")
> 
> 
> Using R version 3.1.0 beta (2014-03-28 r65330) -- "Spring Dance"
> 
> ##### output from console ######
> 
> > library(quantmod)
> Loading required package: Defaults
> Loading required package: xts
> Loading required package: zoo
> 
> Attaching package: 'zoo'
> 
> The following objects are masked from 'package:base':
> 
>     as.Date, as.Date.numeric
> 
> Loading required package: TTR
> Version 0.4-0 included new data defaults. See ?getSymbols.
> > library(rJava)
> > library(boilerpipeR)
> > library(namespace)
> > library(tm.plugin.webmining)
> Loading required package: tm
> Loading required package: RCurl
> Loading required package: bitops
> 
> Attaching package: 'RCurl'
> 
> The following object is masked from 'package:rJava':
> 
>     clone
> 
> Loading required package: XML
> 
> Attaching package: 'tm.plugin.webmining'
> 
> The following object is masked from 'package:RCurl':
> 
>     getURL
> 
> The following object is masked from 'package:base':
> 
>     parse
> 
> >
> > corpus <- WebCorpus(GoogleFinanceSource("NASDAQ:MSFT"))
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>   object '.Source' not found
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nalimilan at club.fr  Mon Apr 14 18:27:25 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 14 Apr 2014 18:27:25 +0200
Subject: [R] sink() and UTF-8 on non-UTF-8 systems
In-Reply-To: <1397231359.4791.12.camel@milan>
References: <1397231359.4791.12.camel@milan>
Message-ID: <1397492845.1903.1.camel@milan.ined.fr>

Suggestions, anyone?

Le vendredi 11 avril 2014 ? 17:49 +0200, Milan Bouchet-Valat a ?crit :
> Hi!
> 
> In the series "dealing with encoding madness on hostile systems", I'm
> looking for help as regards capturing R UTF-8 output on a system where
> the locale is not using UTF-8, and where some characters cannot even be
> represented using the locale encoding. The case I have in mind is
> printing a character vector with Russian text to the R Commander output
> window on an English/French (CP1252) Windows system.
> 
> Here's a code snippet illustrating the problem:
> > "\U41F"
> [1] "?" # OK
> > con <- file(open="w+", encoding="UTF-8")
> > capture.output(cat("\U41F"), file=con)
> > readLines(con, encoding="UTF-8")
> [1] "<U+041F>" # Not OK
> 
> (same result without specifying 'encoding')
> 
> 
> Now I have read ?sink and it is quite explicit about how this works:
> > If file is a character string, the file will be opened using the
> > current encoding. If you want a different encoding (e.g. to represent
> > strings which have been stored in UTF-8), use a file connection ? but
> > some ways to produce R output will already have converted such strings
> > to the current encoding. 
> 
> The last words seem to apply to the case above, i.e. somewhere in the
> process the UTF-8 string is converted to the locale encoding. Is there
> any solution to get the correct output?
> 
> 
> Thanks
> 
> 
> > sessionInfo()
> R Under development (unstable) (2014-04-10 r65396)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252   
> [3] LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
> [5] LC_TIME=French_France.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From umairdurrani at outlook.com  Mon Apr 14 22:24:57 2014
From: umairdurrani at outlook.com (umair durrani)
Date: Tue, 15 Apr 2014 01:24:57 +0500
Subject: [R] Extracting values from rows which meet a condition in R 3.0.2
Message-ID: <BLU170-W30680CEFF788B99C87D69DC9510@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/1f6e6f40/attachment-0001.pl>

From philippe.galipeau17 at gmail.com  Mon Apr 14 21:34:39 2014
From: philippe.galipeau17 at gmail.com (Philippe Galipeau)
Date: Mon, 14 Apr 2014 12:34:39 -0700 (PDT)
Subject: [R] mclogit
In-Reply-To: <CAFjS4YatB-8AQQesPuGHjNYpbnuHNtoR_XwCdGgpWMswc59E+A@mail.gmail.com>
References: <CAFjS4YatB-8AQQesPuGHjNYpbnuHNtoR_XwCdGgpWMswc59E+A@mail.gmail.com>
Message-ID: <fe35bb0a-82d1-4510-82fd-6aad66f95fe2@googlegroups.com>

Hi,
 
have you found a solution for your question 1?

Le jeudi 11 octobre 2012 19:03:16 UTC-4, Katelyn Weaver a ?crit :

> Hello, 
>
> I am new to R and am trying to complete a mixed conditional logistic 
> regression. There are two issues that I am currently having: 
>
> 1. I am not sure how to insert the random effects variable into the 
> equation. My current equation is 
> model<-mclogit(Presence~AllWet+AllAg+strata(Pair)) 
> where Presence is a binary value (present or absent), AllWet and AllAg 
> shows the proportion of the location polygons covered by each habitat 
> type, 
> and Pair is showing the paired used and random polygons. The random 
> effects 
> that I want to control for are Bird ID (same bird at multiple locations). 
> Does anyone know how to write the formula properly to include the random 
> effects? 
>
> 2. When I enter the formula I keep getting Error: could not find function 
> "mclogit" 
> When I was using the clogit function I had to add the "survival" package 
> to 
> perform the analysis. What package do I have to add for mclogit? 
>
> Any assistance on this subject would be greatly appreciated. 
>
> Thank you, 
> Katelyn 
>
> -- 
> Katelyn Weaver 
> M.Sc. Candidate 
> Long Point Waterfowl 
> Western University 
> Cell: 519-619-4472 
> Email: kwe... at uwo.ca <javascript:> 
> www.longpointwaterfowl.org 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From timmarcella at gmail.com  Mon Apr 14 23:27:33 2014
From: timmarcella at gmail.com (Tim Marcella)
Date: Mon, 14 Apr 2014 14:27:33 -0700
Subject: [R] Plot mlogit object
Message-ID: <CAGbJzA+_T=Zx-RgyBNRVkyf2fc6Jh3Bck=Tz1JeLkQT36mRuqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/5d019ec0/attachment-0001.pl>

From ligges at statistik.tu-dortmund.de  Tue Apr 15 00:02:52 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 15 Apr 2014 00:02:52 +0200
Subject: [R] gRain on R 3.1.0
In-Reply-To: <2A89054F-A00F-404F-80A3-3EA2B1DEC42A@liu.se>
References: <2A89054F-A00F-404F-80A3-3EA2B1DEC42A@liu.se>
Message-ID: <534C5B0C.70800@statistik.tu-dortmund.de>



On 14.04.2014 07:54, Anna Ekl?f wrote:
> I am using the gRain package but I can't get it to work under R 3.1.0. It is no longer available in the CRAN.
> Does anyone have suggestions for how to get a successful installation?


See:
http://cran.r-project.org/web/packages/gRain/index.html

All there...

Best,
Uwe Ligges


> A
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jim at bitwrit.com.au  Tue Apr 15 01:53:35 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 15 Apr 2014 09:53:35 +1000
Subject: [R] Extracting values from rows which meet a condition in R
	3.0.2
In-Reply-To: <BLU170-W30680CEFF788B99C87D69DC9510@phx.gbl>
References: <BLU170-W30680CEFF788B99C87D69DC9510@phx.gbl>
Message-ID: <534C74FF.7050902@bitwrit.com.au>

On 04/15/2014 06:24 AM, umair durrani wrote:
> Hi, I have a big data frame with millions of rows and more than 20 columns. Let me first describe what the data is to make question more clear. The original data frame consists of locations, velocities and accelerations of 2169 vehicles during a 15 minute period. Each vehicle has a unique Vehicle.ID, an ID of the time frame in which it was observed i.e. Frame.ID, the velocity of vehicle in that frame i.e. svel, the acceleration of vehicle in that frame i.e. sacc and the class of that vehicle, vehicle.class, i.e. 1= motorcycle, 2= car, 3 = truck. These variables were recorded after every 0.1 seconds i.e. each frame is 0.1 seconds. Here are the first 6 rows:
>> dput(head(df))structure(list(Vehicle.ID = c(2L, 2L, 2L, 2L, 2L, 2L), Frame.ID = 133:138,Vehicle.class = c(2L, 2L, 2L, 2L, 2L, 2L), Lane = c(2L, 2L, 2L, 2L, 2L, 2L), svel = c(37.29, 37.11, 36.96, 36.83, 36.73,36.64), sacc = c(0.07, 0.11, 0.15, 0.19, 0.22, 0.25)), .Names = c("Vehicle.ID", "Frame.ID", "Vehicle.class", "Lane", "svel", "sacc"), row.names = 7750:7755, class = "data.frame")
> There are some instances in vehicles' journey during the 15 minute recording period that they completely stop i.e. svel==0. This continues for some frames and then vehicles gain speed again. For the purpose of reproduciblity I am creating an example data set as follows:
> x<- data.frame(Vehicle.ID = c(rep(10,5), rep(20,5), rep(30,5), rep(40,5), rep(50,5)),vehicle.class = c(rep(2,10), rep(3,10),rep(1,5)), svel = rep(c(1,0,0,0,3),5),           sacc = rep(c(0.3,0.001,0.001,0.002,0.5),5))
> As described above some vehicles stop and have zero velocity for some time but later accelerate to get up to speed. I want to find the acceleration, sacc they apply after having zero velocity for some time (moving from standstill position). This means that I should be able to look at the FIRST row AFTER the last frame in which svel==0. In the example data this means that the car (vehicle.class==2) having a Vehicle.ID==10 had a velocity, svel equal to 1 as seen in the first row. Later, it stopped for 3 frames (3 consecutive rows) and then accelerated to velocity, svel, equal to 3. I want the acceleration sacc it applied in those 2 frames (rows 4 and 5 for vehicle 10, which come out to be 0.002 and 0.500). This means that for example data, following should be the output by vehicle.class:
> output<- data.frame(Vehicle.ID = c(10,10,20,20,30,30,40,40,50, 50),vehicle.class = c(2,2,2,2,3,3,3,3,1,1), xf = rep(c('l','f'),10),sacc = rep(c(0.002,0.500),5))
> xf identifies the last row l in which svel==0 and f is the first one after that. I have tried using plyr and for loop to split by vehicle.class but am not sure how to extract the sacc. Please note that xf should be a part of output. It is not in given data. The original data frame df has 2169 vehicles, some stopped and some did not so not all vehicles had svel==0. The vehicles which did stop didn't do it at the same time. Also, the number of rows in which svel==0 is different vehicle to vehicle.
> Thanks,
> Umair Durrani
> Master's candidate
> Civil and Environmental Engineering
> University of Windsor 		 	   		
> 	[[alternative HTML version deleted]]
>
Hi Umair,
This may be a bit slow, but I think it will do what you want:

initacc<-function(x) {
  xout<-matrix(rep(NA,4),nrow=1)
  for(drow in 2:dim(x)[1]) {
   if(x[drow-1,"svel"] == 0 && x[drow,"svel"] > 0) {
    if(!is.na(xout[1,1])) {
     xout<-rbind(xout,c(x[drow-1,"Vehicle.ID"],
      x[drow-1,"vehicle.class"],0,x[drow-1,"sacc"]))
    }
    else {
     xout[1,]<-c(x[drow-1,"Vehicle.ID"],
      x[drow-1,"vehicle.class"],0,<-x[drow-1,"sacc"])
    }
    xout<-rbind(xout,c(x[drow,"Vehicle.ID"],
     x[drow,"vehicle.class"],1,x[drow,"sacc"]))
   }
  }
  xout<-as.data.frame(xout)
  names(xout)<-
   c("Vehicle.ID","vehicle.class","xf","sacc")
  xout$xf<-ifelse(xout$xf,"f","l")
  return(xout)
}

Jim



From djnordlund at frontier.com  Tue Apr 15 03:26:52 2014
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 14 Apr 2014 18:26:52 -0700
Subject: [R] system()
In-Reply-To: <534C3242.5000500@sapo.pt>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686945ECC67@DC1VEX10MB001.air.org>
	<534C3242.5000500@sapo.pt>
Message-ID: <F62F62F0BF674030900A08456B1584FF@Aragorn>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Rui Barradas
> Sent: Monday, April 14, 2014 12:09 PM
> To: Doran, Harold; r-help at r-project.org
> Subject: Re: [R] system()
> 
> Hello,
> 
> Try instead
> 
> command <- paste(aa, fnm)
> system(command)
> 
> And read the help page for ?paste
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> Em 14-04-2014 20:02, Doran, Harold escreveu:
> > I need to send a system command to another program from within R but
> have a small hangup
> >
> > I'm trying to do something like this
> >
> > system("notepad myfile.txt")
> >
> > But, more generally this is happening to multiple files, so I loop over
> thousands of files. For purposes of an example, my code is something like
> this, which does not work
> >
> > aa <- 'notepad.exe'
> > fnm <- 'myfile.txt'
> > system("aa fnm")
> >
> > Any suggestions?
> > Harold
> >

Harold,

you haven't said what OS you are running under, but given that your example program was notepad.exe I am going to guess some flavor of MS Windows.  The suggestion to use paste() is necessary, but it will probably not be sufficient to solve your problem.  The commands suggested

> command <- paste(aa, fnm)
> system(command)

freezes R on my Win 7 Pro x64 box using either 64-bit R-3.0.3 or R-3.1.0.  You might try switching to shell() instead of system()

> command <- paste(aa, fnm)
> shell(command)

However, it all depends on what programs you are trying to run and what behavior you expect.


Dan

Daniel Nordlund
Bothell, WA USA
 



From smartpink111 at yahoo.com  Tue Apr 15 05:04:20 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Apr 2014 20:04:20 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com> 
Message-ID: <1397531060.19590.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
It is because of different dimensions of Simulation data? within each Site.
Try:
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))
sapply(lst1,length)
#G100 G101 G102 G103 G104 G105 G106 G107 G108 G109 G110 G111 G112 G113 G114 G115 
# 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100 
#G116 G117 G118 G119 G120 GG10 GG11 GG12 GG13 GG14 GG15 GG16 GG17 GG18 GG19 GG20 
# 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100? 100 
#GG21 GG22 GG23 GG24 GG25 GG26 GG27 GG28 
# 100? 100? 100? 100? 100? 100? 100? 100 

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) {
? ? lines1 <- readLines(x2)
? ? header1 <- lines1[1:2]
? ? dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE, 
? ? ? ? skip = 2)
? ? colnames(dat1) <- Reduce(paste, strsplit(header1, ","))
? ? dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

##dimensions differ within each Site
sapply(lst2,function(x) sapply(x,ncol))[1:6,5:8]
#? ?  G104 G105 G106 G107
#[1,]? 258? 257? 258? 258
#[2,]? 258? 258? 258? 258
#[3,]? 258? 258? 258? 258
#[4,]? 258? 257? 258? 258
#[5,]? 258? 258? 258? 258
#[6,]? 258? 258? 258? 258

##number of rows are consistent
sapply(lst2,function(x) any(sapply(x,nrow)!=9))
# G100? G101? G102? G103? G104? G105? G106? G107? G108? G109? G110? G111? G112 
#FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
# G113? G114? G115? G116? G117? G118? G119? G120? GG10? GG11? GG12? GG13? GG14 
#FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
# GG15? GG16? GG17? GG18? GG19? GG20? GG21? GG22? GG23? GG24? GG25? GG26? GG27 
#FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
# GG28 
#FALSE 
names1 <- unique(unlist(lapply(lst2,function(x) unlist(lapply(x,function(y) names(y)[-1])))))
length(names1)
#[1] 257


# lstYear <- lapply(lst2,function(x) lapply(x, function(y)
# y[,1,drop=FALSE])[[1]])

library(plyr)

lapply(seq_along(lst2),function(i) {lstN <- lapply(lst2[[i]],function(x) {datN <- as.data.frame(matrix(NA, nrow=9, ncol=length(names1),dimnames=list(NULL,names1)));datN[,names1] <- x[,-1]; datN }); lstQ1 <- lapply(lstN,function(x) numcolwise(function(y) quantile(y,seq(0,1,by=0.01), na.rm=TRUE))(x)); arr1 <- array(unlist(lstQ1), dim=c(dim(lstQ1[[1]]),length(lstQ1)),dimnames=list(NULL,lapply(lstQ1,names)[[1]])); res <- rowMeans(arr1, dims=2, na.rm=TRUE); colnames(res) <- gsub(" ", "_", colnames(res)); res1 <- data.frame(Percentiles=paste0(seq(0,100, by=1),"%"),res, stringsAsFactors=FALSE); write.csv(res1,paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile", sep="_"), sep= "/"), ".csv"), row.names=FALSE, quote=FALSE)})



## output files
list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))]
#[1] "final/G100_Quantile.csv" "final/G101_Quantile.csv"
#[3] "final/G102_Quantile.csv" "final/G103_Quantile.csv"
#[5] "final/G104_Quantile.csv" "final/G105_Quantile.csv"
#[7] "final/G106_Quantile.csv" "final/G107_Quantile.csv"
#[9] "final/G108_Quantile.csv" "final/G109_Quantile.csv"
#[11] "final/G110_Quantile.csv" "final/G111_Quantile.csv"
#[13] "final/G112_Quantile.csv" "final/G113_Quantile.csv"
#[15] "final/G114_Quantile.csv" "final/G115_Quantile.csv"
#[17] "final/G116_Quantile.csv" "final/G117_Quantile.csv"
#[19] "final/G118_Quantile.csv" "final/G119_Quantile.csv"
#[21] "final/G120_Quantile.csv" "final/GG10_Quantile.csv"
#[23] "final/GG11_Quantile.csv" "final/GG12_Quantile.csv"
#[25] "final/GG13_Quantile.csv" "final/GG14_Quantile.csv"
#[27] "final/GG15_Quantile.csv" "final/GG16_Quantile.csv"
#[29] "final/GG17_Quantile.csv" "final/GG18_Quantile.csv"
#[31] "final/GG19_Quantile.csv" "final/GG20_Quantile.csv"
#[33] "final/GG21_Quantile.csv" "final/GG22_Quantile.csv"
#[35] "final/GG23_Quantile.csv" "final/GG24_Quantile.csv"
#[37] "final/GG25_Quantile.csv" "final/GG26_Quantile.csv"
#[39] "final/GG27_Quantile.csv" "final/GG28_Quantile.csv"


ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1,function(x) dim(x))
#? ?  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
#[1,]? 101? 101? 101? 101? 101? 101? 101? 101? 101?  101?  101?  101?  101?  101
#[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258?  258?  258?  258?  258?  258
#? ?  [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]
#[1,]?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101
#[2,]?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258
#? ?  [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]
#[1,]?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101?  101
#[2,]?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258?  258
#? ?  [,39] [,40]
#[1,]?  101?  101
#[2,]?  258?  258

ReadOut1[[1]][1:3,1:3]
#? Percentiles? txav_DJF txav_MAM
#1? ? ? ? ? 0% -12.56619 6.795429
#2? ? ? ? ? 1% -12.45888 6.864886
#3? ? ? ? ? 2% -12.35157 6.934344

### Q2:
dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)
nrow(lstNew)
#[1] 258

lapply(2:nrow(lstNew), function(i) {
? ? dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE)
? ? colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i], 
? ? ? ? length(lst1)), sep = "_"))
? ? write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"), 
? ? ? ? ".csv"), row.names = FALSE, quote = FALSE)
})

## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
#[1] 257

head(ReadOut2[[1]], 2)
#Percentiles G100_pav_ANN G101_pav_ANN G102_pav_ANN G103_pav_ANN G104_pav_ANN
#1? ? ? ? ? 0%? ?  0.978451? ? 0.9517680? ? 0.9383280? ? 0.8519280? ? 0.9438790
#2? ? ? ? ? 1%? ?  0.992648? ? 0.9638816? ? 0.9480754? ? 0.8625262? ? 0.9548512
#? G105_pav_ANN G106_pav_ANN G107_pav_ANN G108_pav_ANN G109_pav_ANN G110_pav_ANN
#1? ? 0.9303260? ? 0.7484670? ? 0.9757010? ?  1.049533? ? 0.9841290? ? 0.7778830
#2? ? 0.9417438? ? 0.7594563? ? 0.9868968? ?  1.063668? ? 0.9968095? ? 0.7882509
#? G111_pav_ANN G112_pav_ANN G113_pav_ANN G114_pav_ANN G115_pav_ANN G116_pav_ANN
#1? ?  0.737651? ? 0.8813010? ? 0.9155330? ?  0.829001? ? 0.6778760? ? 0.5463310
#2? ?  0.746934? ? 0.8924871? ? 0.9265448? ?  0.838534? ? 0.6880397? ? 0.5527359
#? G117_pav_ANN G118_pav_ANN G119_pav_ANN G120_pav_ANN GG10_pav_ANN GG11_pav_ANN
#1? ? 0.7191360? ? 0.7470170? ? 0.7859380? ? 0.7774590? ? 0.6303150? ? 0.5200200
#2? ? 0.7278231? ? 0.7556053? ? 0.7975213? ? 0.7852408? ? 0.6381671? ? 0.5258248
#? GG12_pav_ANN GG13_pav_ANN GG14_pav_ANN GG15_pav_ANN GG16_pav_ANN GG17_pav_ANN
#1? ? 0.6672890? ?  0.851834? ? 0.5209710? ? 0.6445290? ? 0.5874320? ? 0.7263650
#2? ? 0.6761913? ?  0.861177? ? 0.5282514? ? 0.6520456? ? 0.5948674? ? 0.7365299
#? GG18_pav_ANN GG19_pav_ANN GG20_pav_ANN GG21_pav_ANN GG22_pav_ANN GG23_pav_ANN
#1? ? 0.6642220? ? 0.5385440? ? 0.5043320? ? 0.7484140? ? 0.6436940? ?  0.541165
#2? ? 0.6729234? ? 0.5454527? ? 0.5120815? ? 0.7575216? ? 0.6502167? ?  0.549040
#? GG24_pav_ANN GG25_pav_ANN GG26_pav_ANN GG27_pav_ANN GG28_pav_ANN
#1? ? 0.5067010? ? 0.7082260? ? 0.6447260? ? 0.6197480? ? 0.9163480
#2? ? 0.5136588? ? 0.7160864? ? 0.6545266? ? 0.6278891? ? 0.9284303 


Also, atttached is the script in case the email mangles the code.

A.K.



On Monday, April 14, 2014 6:26 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
I have another request for help.
Attached is a larger file (~27MB) for sample.zip. All files are same as previous except that I am using more sites to do the same thing that you did with sample.zip.

When generalizing Quantilecode.R to many sites, I receive an error when I run:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)

lapply(2:nrow(lstNew), function(i) {
? dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE)
? colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? length(lst1)), sep = "_"))
? write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),?
? ? ? ? ? ? ? ? ? ? ? ? ?".csv"), row.names = FALSE, quote = FALSE)
})

and I get this:
Error in 2:nrow(lstNew) : argument of length 0


I have tried a few tricks but could not overcome the error message.

Please help!
Atem.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Quantilecode.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/2628a0b7/attachment-0002.txt>

From smartpink111 at yahoo.com  Tue Apr 15 05:48:17 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Apr 2014 20:48:17 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <1397533697.5057.YahooMailNeo@web142601.mail.bf1.yahoo.com>





Hi,
Q1 solution already sent.

Regarding Q2, one of the files in the new Observed folder doesn't have any? data (just the Year column alone).

That may be the reason for the problem.

### Q1: working directory: Observed #Only one file per Site.??Assuming this is the
### case for the full dataset, then I guess there is no need to average
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) {
????lines1 <- readLines(x2)
????header1 <- lines1[1:2]
????dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE, 
????????skip = 2)
????colnames(dat1) <- Reduce(paste, strsplit(header1, ","))
????dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

lst3 <- lst2[sapply(seq_along(lst2),function(i){lstN <- sapply(lst2[[i]],function(x) is.integer(ncol(x)))})]


#difference in column number
sapply(seq_along(lst3), function(i) {
????sapply(lst3[[i]], function(x) ncol(x))
})
# 
#[1] 157 258 258??98 157 258 256 258 250 258 258 147 157 250 250 256 249 240
# [19] 181 188 256 146 117 258 153 256 255 246 255 256 258 257 145 258 258 255
# [37] 258 157 164 144 265 258 254 258 258 157 258 176 258 256 257 258 258 258
# [55] 248 258 156 258 157 157 258 258 258 258 258 148 258 258 258 258 257 258
# [73] 258 258 157 154 153 258 248 255 257 256 258 258 157 256 256 257 257 250
# [91] 257 139 155 256 256 257 257 256 258 258 257 258 258 258 258 157 157 157
#[109] 258 258 258 258 256 258 157 258 258 256 258

library(plyr)
library(stringr)

lst4 <- setNames(lapply(seq_along(lst3), function(i) {
????lapply(lst3[[i]], function(x) {
????????names(x)[-1] <- paste(names(x)[-1], names(lst1)[i], sep = "_")
????????names(x) <- str_trim(names(x))
????????x
????})[[1]]
}), names(lst3))

df1 <- join_all(lst4, by = "Year")
dim(df1)
# [1] 9 27311

sapply(split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1])), function(x) {
????df2 <- df1[, x]
????df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
????????seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
????ncol(df3)
})
# 
#G100 G101 G102 G103 G104 G105 G106 G107 G108 G109 G110 G111 G112 G113 G114 G115 
# 157??258??258?? 98??157??258??256??258??250??258??258??147??157??250??250??256 
#G116 G117 G118 G119 G120 GG10 GG11 GG12 GG13 GG14 GG15 GG16 GG17 GG18 GG19 GG20 
# 249??240??181??188??256??146??117??258??153??256??255??246??255??256??258??257 
#GG21 GG22 GG23 GG24 GG25 GG26 GG27 GG28 GG29 GG30 GG31 GG32 GG33 GG34 GG35 GG36 
# 145??258??258??255??258??157??164??144??265??258??254??258??258??157??258??176 
#GG37 GG38 GG39 GG40 GG41 GG42 GG43 GG44 GG45 GG46 GG47 GG48 GG49 GG50 GG51 GG52 
# 258??256??257??258??258??258??248??258??156??258??157??157??258??258??258??258 
#GG53 GG54 GG55 GG56 GG57 GG58 GG59 GG60 GG61 GG62 GG63 GG64 GG65 GG66 GG67 GG68 
# 258??148??258??258??258??258??257??258??258??258??157??154??153??258??248??255 
#GG69 GG70 GG71 GG72 GG73 GG74 GG75 GG76 GG77 GG78 GG79 GG80 GG81 GG82 GG83 GG84 
# 257??256??258??258??157??256??256??257??257??250??257??139??155??256??256??257 
#GG85 GG86 GG87 GG88 GG89 GG90 GG91 GG92 GG93 GG94 GG95 GG96 GG97 GG98 GG99 GGG1 
# 257??256??258??258??257??258??258??258??258??157??157??157??258??258??258??258 
#GGG2 GGG3 GGG4 GGG5 GGG6 GGG7 GGG8 
# 256??258??157??258??258??256??258 



lst5 <- split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1]))

lapply(seq_along(lst5), function(i) {
????df2 <- df1[, lst5[[i]]]
????df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
????????seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
????df3[1:3, 1:3]
????write.csv(df3, paste0(paste(getwd(), "final", paste(names(lst4)[[i]], "Quantile", 
????????sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
????function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))

sapply(ReadOut1, dim)[,1:3]
#???? [,1] [,2] [,3]
#[1,]??101??101??101
#[2,]??157??258??258


lapply(ReadOut1, function(x) x[1:2, 1:3])[1:3]
#[[1]]
#??Percentiles pav.DJF_G100 pav.MAM_G100
#1??????????0%????????????0???? 0.640500
#2??????????1%????????????0???? 0.664604
#
#[[2]]
#??Percentiles txav.DJF_G101 txav.MAM_G101
#1??????????0%??????-13.8756??????4.742400
#2??????????1%??????-13.8140??????4.817184
#
#[[3]]
#??Percentiles txav.DJF_G102 txav.MAM_G102
#1??????????0%???? -15.05000??????4.520700
#2??????????1%???? -14.96833??????4.543828


### Q2: Observed data

dir.create("Indices")

names1 <- unlist(lapply(ReadOut1, function(x) names(x)[-1]))
names2 <- gsub("\\_.*", "", names1)
names3 <- unique(gsub("[.]", " ", names2))

res <- do.call(rbind, lapply(seq_along(lst5), function(i) {
????df2 <- df1[, lst5[[i]]]
????vec1 <- colMeans(df2, na.rm = TRUE)
????vec2 <- rep(NA, length(names3))
????names(vec2) <- paste(names3, names(lst5)[[i]], sep = "_")
????vec2[names(vec2) %in% names(vec1)] <- vec1
????names(vec2) <- gsub("\\_.*", "", names(vec2))
????vec2
}))
dim(res)
#[1] 119 264

lapply(seq_len(ncol(res)), function(i) {
????mat1 <- t(res[, i, drop = FALSE])
????colnames(mat1) <- names(lst4)
????write.csv(mat1, paste0(paste(getwd(), "Indices", gsub(" ", "_", rownames(mat1)), 
????????sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
????function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1]??264

list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))][1]
# [1] 'Indices/pav_ANN.csv'
res[, "pav ANN", drop = FALSE]


ReadOut2[[1]]


Attached is the updated Quantilecode2.txt.

A.K.


On Monday, April 14, 2014 10:41 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Q1) Please try to correct the error using the larger data set (Sample.zip). The issue is that once you write the codes and restrict it to smaller data sets, I find it difficult to generalize it to larger data sets.

Q2) From the Quantilecode2.txt you just sent, you forgot to do the following section using the Observed.zip file. I tried to run the code to section Q1 in Quantilecode2.txt using a larger data set and received the same error :Error in 2:nrow(lstNew) : argument of length 0. I have attached a larger data set too for you to generalize the code to suit the larger data set. Please do not forget to include the code below in the final code of Q2.


Once you fix these two, I should be able to fix the rest following these examples.

Thanks AK. Sorry for overloading you with much work.
Atem.

#==============================================================================================================
dir.create("Indices")?
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1) lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],? length(lst1)), sep = "_"))?
write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),? ".csv"), row.names = FALSE, quote = FALSE)
})? 
## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257
head(ReadOut2[[1]], 2) 

#==============================================================================================================


=================================================
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Quantilecode2.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/c97a58e5/attachment-0002.txt>

From zilefacelvis at yahoo.com  Tue Apr 15 03:13:22 2014
From: zilefacelvis at yahoo.com (zilefacelvis at yahoo.com)
Date: Tue, 15 Apr 2014 01:13:22 GMT
Subject: [R] Quantile and rowMean from multiple files in a folder
Message-ID: <885060.23290.bm@smtp203.mail.bf1.yahoo.com>


   Hi AK,

   Thanks very much.

   I  did  send  you  another  email  with  a larger Sample.zip file. The
   Quantilecode.R which you initially developed for a smaller sample.zip did
   not complete the task when I used it for a larger data set. Please check to
   rectify the error message.


   Thanks,

   Atem.
   ------ Original Message ------

     From : arun
     To : R. Help;
     Cc : Zilefac Elvis;
     Sent : 14-04-2014 18:57
     Subject : Re: Quantile and rowMean from multiple files in a folder

Hi Atem,

I guess this is what you wanted.

###Q1: 
###
###working directory: Observed
 #Only one file per Site.  Assuming this is the case for the full dataset, then
 I guess there is no need to average

dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(patter
n = ".csv")))

lst2 <-  lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(
x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",
",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(head
er1,","));dat1[-c(nrow(dat1),nrow(dat1)-1),]}))


#different number of rows
 sapply(seq_along(lst2),function(i){lstN <- lapply(lst2[[i]],function(x) x[,-1]
);sapply(lstN,function(x) nrow(x))})
 #[1] 9 9 9 8 2 9

#difference in number of columns
sapply(seq_along(lst2),function(i) {sapply(lst2[[i]],function(x) ncol(x))})
 #[1] 157 258 258  98 157 258

library(plyr)
library(stringr)

lst3 <- setNames(lapply(seq_along(lst2),function(i) {lapply(lst2[[i]],function(
x) {names(x)[-1] <- paste(names(x)[-1], names(lst1)[i],sep="_"); names(x) <- st
r_trim(names(x)); x})[[1]]}), names(lst1)) 

df1 <- join_all(lst3,by="Year")
dim(df1)
 #[1]    9 1181 


sapply(split(names(df1)[-1] ,gsub(".*\\_","",names(df1)[-1])),function(x) {df2 
<- df1[,x];df3 <- data.frame(Percentiles=paste0(seq(0,100, by=1) ,"%"), numcolw
ise(function(y) quantile(y,seq(0,1,by=0.01),na.rm=TRUE))(df2),stringsAsFactors=
FALSE);ncol(df3) })
 #G100 G101 G102 G103 G104 G105 
# 157  258  258   98  157  258 

lst4 <- split(names(df1)[-1] ,gsub(".*\\_","",names(df1)[-1]))

lapply(seq_along(lst4),function(i) {df2 <- df1[,lst4[[i]]]; df3 <- data.frame(P
ercentiles=paste0(seq(0,100, by=1) ,"%"), numcolwise(function(y) quantile(y,seq
(0,1,by=0.01),na.rm=TRUE))(df2),stringsAsFactors=FALSE);df3[1:3,1:3]; write.csv
(df3,paste0(paste(getwd(), "final",paste(names(lst1)[[i]],"Quantile",sep="_"),s
ep="/"),".csv"),row.names=FALSE,quote=FALSE)}) 

ReadOut1 <- lapply(list.files(recursive=TRUE)[grep("Quantile",list.files(recurs
ive=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

sapply(ReadOut1,dim)
#     [,1] [,2] [,3] [,4] [,5] [,6]
 #[1,]  101  101  101  101  101  101 
#[2,]  157  258  258   98  157  258

lapply(ReadOut1,function(x) x[1:2,1:3])[1:3]
 #[[1]] 
#  Percentiles pav.DJF_G100 pav.MAM_G100 
#1          0%            0     0.640500 
#2          1%            0     0.664604 
# 
#[[2]] 
#  Percentiles txav.DJF_G101 txav.MAM_G101
 #1          0%      -13.8756      4.742400 
#2          1%      -13.8140      4.817184
 #
 #[[3]] 
#  Percentiles txav.DJF_G102 txav.MAM_G102
 #1          0%     -15.05000      4.520700
 #2          1%     -14.96833      4.543828 
#####
###Q2: 
###Observed data 

dir.create("Indices")
 names1 <- unlist(lapply(ReadOut1,function(x)
 names(x)[-1])) 
names2 <-  gsub("\\_.*","",names1)
 names3 <- unique(gsub("[.]", " ", names2)) 

res <- do.call(rbind,lapply(seq_along(lst4),function(i) {df2 <- df1[,lst4[[i]]]
;vec1 <- colMeans(df2,na.rm=TRUE); vec2 <- rep(NA,length(names3));names(vec2) <
- paste(names3,names(lst4)[[i]],sep="_"); vec2[names(vec2) %in% names(vec1)] <-
 vec1; names(vec2) <- gsub("\\_.*","",names(vec2)); vec2  }))


lapply(seq_len(ncol(res)),function(i) {mat1 <- t(res[,i,drop=FALSE]);colnames(m
at1) <- names(lst4); write.csv(mat1,paste0(paste(getwd(),"Indices", gsub(" ","_
",rownames(mat1)),sep="/"),".csv"),row.names=FALSE,quote=FALSE)})

##Output2:
ReadOut2 <- lapply(list.files(recursive=TRUE)[grep("Indices",list.files(recursi
ve=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

length(ReadOut2) 

#[1] 257


list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))][1]
#[1] "Indices/pav_ANN.csv" 

res[,"pav ANN",drop=FALSE] 

#      pav ANN
#[1,] 1.298811
#[2,] 7.642922 

#[3,] 6.740011 

#[4,]       NA
#[5,] 1.296650 

#[6,] 6.887622 


ReadOut2[[1]]
#      G100     G101     G102 G103    G104     G105
#1 1.298811 7.642922 6.740011   NA 1.29665 6.887622 

###Sample data 

###Working directory changed to "sample" 

dir.create("Indices_colMeans")

lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".c
sv"))) 

lst2 <-  lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(
x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",
",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(head
er1,","));dat1[-c(nrow(dat1),nrow(dat1)-1),]}))
res1 <- do.call(rbind,lapply(seq_along(lst2),function(i) {rowMeans(do.call(cbin
d,lapply(lst2[[i]],function(x) colMeans(x[,-1],na.rm=TRUE))),na.rm=TRUE) })) 

lapply(seq_len(ncol(res1)),function(i){mat1 <- t(res1[,i,drop=FALSE]); colnames
(mat1) <- names(lst2);write.csv(mat1,paste0(paste(getwd(),"Indices_colMeans",gs
ub(" ","_",rownames(mat1)),sep="/"),".csv"),row.names=FALSE,quote=FALSE)})

##Output2 Sample
ReadOut2S <- lapply(list.files(recursive=TRUE)[grep("Indices",list.files(recurs
ive=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

length(ReadOut2S)
#[1] 257

list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))][1] 

#[1] "Indices_colMeans/pav_ANN.csv" 

res1[,"pav ANN",drop=FALSE] 

#      pav ANN
#[1,] 1.545620
#[2,] 1.518553 

ReadOut2S[[1]] 

#     G100     G101 

#1 1.54562 1.518553 


A.K.


On Monday, April 14, 2014 1:05 AM, Zilefac Elvis  wrote:

Hi AK,

Q1) Please apply the Quantilecode.R to Observed.zip (attached). I tried but rec
eived an error which was self-explanatory but I could not change the dimensions
 in the code.


Q2) Please apply Quantilecode.R to both sample.zip and observed.zip. Here, inst
ead of doing quantile(y, seq(0, 1, by = 0.01), take colMeans of the indices. 


I have tried to solve both Q1 and Q2 but still unable to control the dimensions
.

Thanks,
Atem.
On Sunday, April 13, 2014 9:05 AM, arun  wrote:



Hi Atem,

On my end, the codes are not formatted in the email as seen in the screen of fo
rmatR GUI.

I am attaching the .R file in case there is some difficulty for you.
Arun



On Sunday, April 13, 2014 10:54 AM, arun  wrote:
Hi,

I am formatting the codes using library(formatR).  Hopefully, it will not be ma
ngled in the email.
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(patter
n = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1 <- readLines
(x2) header1 <- lines1[1:2] dat1 <- read.table(text = lines1, header = FALSE, s
ep = ",", stringsAsFactors = FALSE,  skip = 2) colnames(dat1) <- Reduce(paste, 
strsplit(header1, ",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

library(plyr) 

lapply(seq_along(lst2), function(i) { lstN <- lapply(lst2[[i]], function(x) x[,
 -1]) lstQ1 <- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(
0, 1,  by = 0.01), na.rm = TRUE))(x)) arr1 <- array(unlist(lstQ1), dim = c(dim(
lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,  lapply(lstQ1, names)[[1]]))
 res <- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res) <- gsub(" ", "_", 
colnames(res)) res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"
), res, stringsAsFactors = FALSE) write.csv(res1, paste0(paste(getwd(), "final"
, paste(names(lst1)[[i]], "Quantile",  sep = "_"), sep = "/"), ".csv"), row.nam
es = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(rec
ursive = TRUE))],  function(x) read.csv(x, header = TRUE, stringsAsFactors = FA
LSE))
sapply(ReadOut1,
dim)
#     [,1] [,2]
#[1,]  101  101
#[2,]  258  258

lapply(ReadOut1,function(x) x[1:2,1:3])
#[[1]]
#  Percentiles  txav_DJF txav_MAM
#1          0% -12.68566  7.09702
#2          1% -12.59062  7.15338
#
#[[2]]
#  Percentiles  txav_DJF txav_MAM
#1          0% -12.75516 6.841840
#2          1% -12.68244 6.910664 


###Q2:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)
lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbin
d, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)
[1], paste(names(lst1), rep(rownames(lstNew)[i],  length(lst1)), sep = "_")) wr
ite.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),
  ".csv"), row.names = FALSE, quote = FALSE)
}) ## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recu
rsive = TRUE))],  function(x) read.csv(x, header = TRUE, stringsAsFactors = FAL
SE))
length(ReadOut2)
# [1] 257 


head(ReadOut2[[1]], 2)
#  Percentiles G100_pav_ANN G101_pav_ANN
#1          0%     1.054380     1.032740
#2          1% 
   1.069457     1.045689 


A.K.












On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis  wrote:

Hi AK,
Q1) I need your help again. Using the previous data (attached) and the previous
 code below,instead of taking rowMeans, let's do quantile(x,seq(0,1,by=0.01)). 

Delete the last 2 rows (Trend and p<) in each file before doing quantile(x,seq(
0,1,by=0.01)).

For example, assume that I want to
calculate quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do 
so for the 5 sims of site G100 and then take their average. This will be approx
imately close to the true value than just calculating quantile(x,seq(0,1,by=0.0
1)) from one sim. Please do this same thing for all the files.

So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01))
 calculated from all sims in that Site.

Output

The number of files in "final" remains the same (2 files). The "Year" column(wi
ll be replaced) will contain  the names of quantile(x,seq(0,1,by=0.01)) such as
  0%           1%           2%           3%           4%           5%          
 6%, ..., 98%    
     99%         100% . You can give this column any name such as "Percentiles"
.


Q2)  From the folder "final", please go to each file identified by site name, t
ake a column, say col1 of txav  from each file, create a dataframe whose colnam
es are site codes (names of files in "final"). Create a folder called "Indices"
 and place this dataframe in it. The filename for the dataframe is txav, say. S
o, in "Indices", you will have one file having 3 columns [, c(Percentiles, G100
,G101)]. The idea is that I want to be able to pick any column from files in "f
inal" and form a dataframe from which I will generate my qqplot or boxplot.

Thanks very much AK.
Atem
This should be the final step of this my drama, at least for now.
#==============================================================================
================================

dir.create("final")
lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".c
sv"))) lst2 <-  lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- rea
dLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE
,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strspl
it(header1,","));dat1}))

lstYear <- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]]
) 


lapply(seq_along(lst2),function(i) {lstN <-lapply(lst2[[i]],function(x) x[,-1])
; arr1 <- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(N
ULL,lapply(lstN,names)[[1]]));res <-
cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res) <- gsub("\\_$"
,"",gsub(" ", "_",names(res))); res[,1] <- gsub(" <", "",res[,1]); write.csv(re
s,paste0(paste(getwd(),"final",names(lst1)
[[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)  }) 



#==============================================================================
======================


From smartpink111 at yahoo.com  Tue Apr 15 02:54:02 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Apr 2014 17:54:02 -0700 (PDT)
Subject: [R] Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397451939.32429.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1397188527.25131.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397371573.15875.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397400895.74947.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397401533.72895.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1397451939.32429.YahooMailNeo@web160606.mail.bf1.yahoo.com> 
Message-ID: <1397523242.83704.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Atem,

I guess this is what you wanted.

###Q1: 
###
###working directory: Observed
?#Only one file per Site.? Assuming this is the case for the full dataset, then I guess there is no need to average

dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <-? lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(header1,","));dat1[-c(nrow(dat1),nrow(dat1)-1),]}))


#different number of rows
?sapply(seq_along(lst2),function(i){lstN <- lapply(lst2[[i]],function(x) x[,-1]);sapply(lstN,function(x) nrow(x))})
?#[1] 9 9 9 8 2 9

#difference in number of columns
sapply(seq_along(lst2),function(i) {sapply(lst2[[i]],function(x) ncol(x))})
?#[1] 157 258 258? 98 157 258

library(plyr)
library(stringr)

lst3 <- setNames(lapply(seq_along(lst2),function(i) {lapply(lst2[[i]],function(x) {names(x)[-1] <- paste(names(x)[-1], names(lst1)[i],sep="_"); names(x) <- str_trim(names(x)); x})[[1]]}), names(lst1)) 

df1 <- join_all(lst3,by="Year")
dim(df1)
?#[1]? ? 9 1181 


sapply(split(names(df1)[-1] ,gsub(".*\\_","",names(df1)[-1])),function(x) {df2 <- df1[,x];df3 <- data.frame(Percentiles=paste0(seq(0,100, by=1) ,"%"), numcolwise(function(y) quantile(y,seq(0,1,by=0.01),na.rm=TRUE))(df2),stringsAsFactors=FALSE);ncol(df3) })
?#G100 G101 G102 G103 G104 G105 
# 157? 258? 258?  98? 157? 258 

lst4 <- split(names(df1)[-1] ,gsub(".*\\_","",names(df1)[-1]))

lapply(seq_along(lst4),function(i) {df2 <- df1[,lst4[[i]]]; df3 <- data.frame(Percentiles=paste0(seq(0,100, by=1) ,"%"), numcolwise(function(y) quantile(y,seq(0,1,by=0.01),na.rm=TRUE))(df2),stringsAsFactors=FALSE);df3[1:3,1:3]; write.csv(df3,paste0(paste(getwd(), "final",paste(names(lst1)[[i]],"Quantile",sep="_"),sep="/"),".csv"),row.names=FALSE,quote=FALSE)}) 

ReadOut1 <- lapply(list.files(recursive=TRUE)[grep("Quantile",list.files(recursive=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

sapply(ReadOut1,dim)
#? ?  [,1] [,2] [,3] [,4] [,5] [,6]
?#[1,]? 101? 101? 101? 101? 101? 101 
#[2,]? 157? 258? 258?  98? 157? 258

lapply(ReadOut1,function(x) x[1:2,1:3])[1:3]
?#[[1]] 
#? Percentiles pav.DJF_G100 pav.MAM_G100 
#1? ? ? ? ? 0%? ? ? ? ? ? 0? ?  0.640500 
#2? ? ? ? ? 1%? ? ? ? ? ? 0? ?  0.664604 
# 
#[[2]] 
#? Percentiles txav.DJF_G101 txav.MAM_G101
?#1? ? ? ? ? 0%? ? ? -13.8756? ? ? 4.742400 
#2? ? ? ? ? 1%? ? ? -13.8140? ? ? 4.817184
?#
?#[[3]] 
#? Percentiles txav.DJF_G102 txav.MAM_G102
?#1? ? ? ? ? 0%? ?  -15.05000? ? ? 4.520700
?#2? ? ? ? ? 1%? ?  -14.96833? ? ? 4.543828 
#####
###Q2: 
###Observed data 

dir.create("Indices")
?names1 <- unlist(lapply(ReadOut1,function(x)
?names(x)[-1])) 
names2 <-? gsub("\\_.*","",names1)
?names3 <- unique(gsub("[.]", " ", names2)) 

res <- do.call(rbind,lapply(seq_along(lst4),function(i) {df2 <- df1[,lst4[[i]]];vec1 <- colMeans(df2,na.rm=TRUE); vec2 <- rep(NA,length(names3));names(vec2) <- paste(names3,names(lst4)[[i]],sep="_"); vec2[names(vec2) %in% names(vec1)] <- vec1; names(vec2) <- gsub("\\_.*","",names(vec2)); vec2  }))


lapply(seq_len(ncol(res)),function(i) {mat1 <- t(res[,i,drop=FALSE]);colnames(mat1) <- names(lst4); write.csv(mat1,paste0(paste(getwd(),"Indices", gsub(" ","_",rownames(mat1)),sep="/"),".csv"),row.names=FALSE,quote=FALSE)})

##Output2:
ReadOut2 <- lapply(list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

length(ReadOut2) 

#[1] 257


list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))][1]
#[1] "Indices/pav_ANN.csv" 

res[,"pav ANN",drop=FALSE] 

#      pav ANN
#[1,] 1.298811
#[2,] 7.642922 

#[3,] 6.740011 

#[4,]       NA
#[5,] 1.296650 

#[6,] 6.887622?


ReadOut2[[1]]
#      G100     G101     G102 G103    G104     G105
#1 1.298811 7.642922 6.740011   NA 1.29665 6.887622?

###Sample data 

###Working directory changed to "sample" 

dir.create("Indices_colMeans")

lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv")))?

lst2 <-  lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(header1,","));dat1[-c(nrow(dat1),nrow(dat1)-1),]}))
res1 <- do.call(rbind,lapply(seq_along(lst2),function(i) {rowMeans(do.call(cbind,lapply(lst2[[i]],function(x) colMeans(x[,-1],na.rm=TRUE))),na.rm=TRUE) }))?

lapply(seq_len(ncol(res1)),function(i){mat1 <- t(res1[,i,drop=FALSE]); colnames(mat1) <- names(lst2);write.csv(mat1,paste0(paste(getwd(),"Indices_colMeans",gsub(" ","_",rownames(mat1)),sep="/"),".csv"),row.names=FALSE,quote=FALSE)})

##Output2 Sample
ReadOut2S <- lapply(list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))],function(x) read.csv(x,header=TRUE,stringsAsFactors=FALSE)) 

length(ReadOut2S)
#[1] 257

list.files(recursive=TRUE)[grep("Indices",list.files(recursive=TRUE))][1] 

#[1] "Indices_colMeans/pav_ANN.csv" 

res1[,"pav ANN",drop=FALSE] 

#      pav ANN
#[1,] 1.545620
#[2,] 1.518553 

ReadOut2S[[1]] 

#     G100     G101 

#1 1.54562 1.518553 


A.K.


On Monday, April 14, 2014 1:05 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,

Q1) Please apply the Quantilecode.R to Observed.zip (attached). I tried but received an error which was self-explanatory but I could not change the dimensions in the code.


Q2) Please apply Quantilecode.R to both sample.zip and observed.zip. Here, instead of doing?quantile(y, seq(0, 1, by = 0.01), take colMeans of the indices.?


I have tried to solve both Q1 and Q2 but still unable to control the dimensions.

Thanks,
Atem.
On Sunday, April 13, 2014 9:05 AM, arun <smartpink111 at yahoo.com> wrote:



Hi Atem,

On my end, the codes are not formatted in the email as seen in the screen of formatR GUI.

I am attaching the .R file in case there is some difficulty for you.
Arun



On Sunday, April 13, 2014 10:54 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

I am formatting the codes using library(formatR).? Hopefully, it will not be mangled in the email.
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1 <- readLines(x2) header1 <- lines1[1:2] dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE,? skip = 2) colnames(dat1) <- Reduce(paste, strsplit(header1, ",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

library(plyr) 

lapply(seq_along(lst2), function(i) { lstN <- lapply(lst2[[i]], function(x) x[, -1]) lstQ1 <- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(0, 1,? by = 0.01), na.rm = TRUE))(x)) arr1 <- array(unlist(lstQ1), dim = c(dim(lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,? lapply(lstQ1, names)[[1]])) res <- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res) <- gsub(" ", "_", colnames(res)) res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), res, stringsAsFactors = FALSE) write.csv(res1, paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile",? sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1,
dim)
#? ?? [,1] [,2]
#[1,]? 101? 101
#[2,]? 258? 258

lapply(ReadOut1,function(x) x[1:2,1:3])
#[[1]]
#? Percentiles? txav_DJF txav_MAM
#1? ? ? ? ? 0% -12.68566? 7.09702
#2? ? ? ? ? 1% -12.59062? 7.15338
#
#[[2]]
#? Percentiles? txav_DJF txav_MAM
#1? ? ? ? ? 0% -12.75516 6.841840
#2? ? ? ? ? 1% -12.68244 6.910664?


###Q2:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)
lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],? length(lst1)), sep = "_")) write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),? ".csv"), row.names = FALSE, quote = FALSE)
}) ## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257 


head(ReadOut2[[1]], 2)
#? Percentiles G100_pav_ANN G101_pav_ANN
#1? ? ? ? ? 0%? ?? 1.054380? ?? 1.032740
#2? ? ? ? ? 1%?
?? 1.069457? ?? 1.045689 


A.K.












On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
Q1)?I need your help again. Using the previous data (attached) and the previous code below,instead of taking rowMeans, let's do?quantile(x,seq(0,1,by=0.01)).?

Delete the last 2 rows (Trend and p<)?in each file before doing?quantile(x,seq(0,1,by=0.01)).

For example, assume that I want to
calculate?quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do so for the 5 sims of site G100 and then take their average. This will be approximately close to the true value than just calculating quantile(x,seq(0,1,by=0.01)) from one sim. Please do this same thing for all the files.

So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01)) calculated from all sims in that Site.

Output

The number of files in "final" remains the same (2 files). The "Year" column(will be replaced)?will contain ?the names of quantile(x,seq(0,1,by=0.01)) such as??0% ? ? ? ? ? 1% ? ? ? ? ? 2% ? ? ? ? ? 3% ? ? ? ? ? 4% ? ? ? ? ? 5% ? ? ? ? ? 6%, ..., 98% ? ?
? ? ?99% ? ? ? ? 100% . You can give this column any name such as "Percentiles".


Q2) ?From the folder "final", please go to each file identified by site name, take a column, say?col1 of txav??from each file, create a dataframe whose colnames are site codes (names of files in "final"). Create a folder called "Indices" and place this dataframe in it. The filename for the dataframe is?txav, say. So, in "Indices", you will have one file having 3 columns [, c(Percentiles, G100,G101)]. The idea is that I want to be able to pick any column from files in "final" and form a dataframe from which I will generate my qqplot or boxplot.

Thanks very much AK.
Atem
This should be the final step of this my drama, at least for now.
#==============================================================================================================

dir.create("final")
lst1 <- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2 <-? lapply(lst1,function(x1) lapply(x1, function(x2) {lines1 <- readLines(x2); header1 <- lines1[1:2]; dat1 <- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1) <- Reduce(paste,strsplit(header1,","));dat1}))

lstYear <- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]])?


lapply(seq_along(lst2),function(i) {lstN <-lapply(lst2[[i]],function(x) x[,-1]); arr1 <- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res <-
cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res) <- gsub("\\_$","",gsub(" ", "_",names(res))); res[,1] <- gsub(" <", "",res[,1]); write.csv(res,paste0(paste(getwd(),"final",names(lst1)
[[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)? })?



#====================================================================================================
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Quantilecode2.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/14715496/attachment-0002.txt>

From linglipeng at yahoo.com  Tue Apr 15 03:25:12 2014
From: linglipeng at yahoo.com (Linda Peng)
Date: Mon, 14 Apr 2014 18:25:12 -0700 (PDT)
Subject: [R] error when installing package after installing R-3.1.0 on
	windows
Message-ID: <1397525112.68332.YahooMailNeo@web160105.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/02878b22/attachment-0001.pl>

From laomeng_3 at 163.com  Tue Apr 15 03:46:31 2014
From: laomeng_3 at 163.com (meng)
Date: Tue, 15 Apr 2014 09:46:31 +0800 (CST)
Subject: [R] a question about the output of plot
Message-ID: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/9b197577/attachment-0001.pl>

From dilaradi21 at gmail.com  Tue Apr 15 04:27:34 2014
From: dilaradi21 at gmail.com (dila radi)
Date: Mon, 14 Apr 2014 19:27:34 -0700
Subject: [R] creating multiple line graphs
Message-ID: <CAMgoKB+AT2zsCrSLPRERd6e3Pga7oL10US+zB4pbx7hVaXWzvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140414/c38c3762/attachment-0001.pl>

From zilefacelvis at yahoo.com  Tue Apr 15 08:21:27 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 14 Apr 2014 23:21:27 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>

Hi AK,
All codes for simulation files work great.
I will try the code for observations and let you know.
Thanks very much.
Atem.







On Tuesday, April 15, 2014 12:01 AM, arun <smartpink111 at yahoo.com> wrote:
Yes,
my new solution ignores such cases.







On Monday, April 14, 2014 11:58 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Please ignore any such site.
I will check it and include in the analysis.
Thanks,
Atem.



On Monday, April 14, 2014 9:34 PM, arun <smartpink111 at yahoo.com> wrote:



Hi,

I looked at your Observed.zip.? In that one of the file is without any data:
GG83_Sim.csv.ind.csv
The contents of the file are just:

Year??? 
Year??? 
trend??? 
p??? < 
?

A.K.


On Monday, April 14, 2014 10:41 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Q1) Please try to correct the error using the larger data set (Sample.zip). The issue is that once you write the codes and restrict it to smaller data sets, I find it difficult to generalize it to larger data sets.

Q2) From the Quantilecode2.txt you just sent, you forgot to do the following section using the Observed.zip file. I tried to run the code to section Q1 in Quantilecode2.txt using a larger data set and received the same error :Error in 2:nrow(lstNew) : argument of length 0. I have attached a larger data set too for you to generalize the code to suit the larger data set. Please do not forget to include the code below in the final code of Q2.


Once you fix these two, I should be able to fix the rest following these examples.

Thanks AK. Sorry for overloading you with much work.
Atem.

#==============================================================================================================
dir.create("Indices")?
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1) lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],? length(lst1)), sep = "_"))?
write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),? ".csv"), row.names = FALSE, quote = FALSE)
})? 
## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257
head(ReadOut2[[1]], 2) 

#==============================================================================================================




On Monday, April 14, 2014 8:07 PM, arun <smartpink111 at yahoo.com> wrote:

HI,

Please send your emails in plain text.? If you had looked at the dimensions of `lst2`:
sapply(lst2,function(x) sapply(x,ncol))[1:6,]
? ???G100 G101 G102 G103 G104 G105 G106 G107 G108 G109 G110 G111 G112 G113 G114
[1,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 247
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257
[4,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258
[5,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???G115 G116 G117 G118 G119 G120 GG10 GG11 GG12 GG13 GG14 GG15 GG16 GG17 GG18
[1,]? 258? 247? 256? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[2,]? 258? 250? 257? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 247? 256? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 256
[4,]? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[5,]? 258? 257? 258? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 257? 249? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???GG19 GG20 GG21 GG22 GG23 GG24 GG25 GG26 GG27 GG28
[1,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 257? 258? 256? 257? 258? 258? 258? 258
[4,]? 258? 257? 258? 258? 258? 257? 258? 258? 258? 258
[5,]? 258? 258? 257? 258? 257? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258 


#the dimensions are not consistent for the Simulations
within each Site.? My codes assumed that all the datasets were having the same number of columns, rows etc.






On Monday, April 14, 2014 6:26 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
I have another request for help.
Attached is a larger file (~27MB) for sample.zip. All files are same as previous except that I am using more sites to do the same thing that you did with sample.zip.

When generalizing Quantilecode.R to many sites, I receive an error when I run:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)

lapply(2:nrow(lstNew), function(i) {
? dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE)
? colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? length(lst1)), sep = "_"))
? write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),?
? ? ? ? ? ? ? ? ? ? ? ? ?".csv"), row.names = FALSE, quote = FALSE)
})

and I get this:
Error in 2:nrow(lstNew) : argument of length 0


I have tried a few tricks but could not overcome the error message.

Please help!
Atem.

sample (1).zip
Zilefac Elvis shared from Dropbox??
View on www.dropbox.com Preview by Yahoo??

On Monday, April 14, 2014 9:22 AM, arun <smartpink111 at yahoo.com> wrote:

Ok
. I got the results but mynet is down. Will send once it gets fixed

----------
Sent from my Nokia

------Original message------
From: zilefacelvis at yahoo.com <zilefacelvis at yahoo.com>
To: "arun" <smartpink111 at yahoo.com>
Date: Monday, April 14, 2014 3:01:38 PM GMT
Subject: Re: Re: Quantile and rowMean from multiple files in a folder





In the Observed.zip I
have just one file per site while in sample.zip I have 100 files(Sims) per site.





Thanks,


Atem.

------ Original Message ------



From : arun
To : Zilefac Elvis;
Sent : 14-04-2014 00:12
Subject : Re: Quantile and rowMean from multiple files in a folder
One more doubt, do you have more than one files per Site??In the example, it was just one file per Site.? ? ? On Monday, April 14, 2014 2:08 AM, arun? wrote: Hi, The problem is in the different dimensions of the Observed datasets.? sapply(seq_along(lst2),function(i){lstN<- lapply(lst2[[i]],function(x) x[,-1]);sapply(lstN,function(x) nrow(x))}) ##after removing the trend and P value rows #[1] 9 9 9 8 2 9? ? If you want to take the average, is it through filling NAs for those years that are missing in the files?? A.K.? ? ???On Monday, April 14, 2014 1:05 AM, Zilefac Elvis?
wrote:? Hi AK,? Q1) Please apply the Quantilecode.R to Observed.zip (attached). I tried but received an error which was self-explanatory but I could not change the dimensions in the code.???Q2) Please apply Quantilecode.R to both sample.zip and observed.zip. Here, instead of doing quantile(y, seq(0, 1, by = 0.01), take colMeans of the indices.? ? I have tried to solve both Q1 and Q2 but still unable to control the dimensions.? Thanks, Atem. On Sunday, April 13, 2014 9:05 AM, arun? wrote:? ? Hi Atem,? On my end, the codes are not formatted in the email as seen in the screen of formatR GUI.? I am attaching the .R file in case there is some difficulty for you. Arun? ? On Sunday, April 13, 2014 10:54 AM, arun? wrote: Hi,? I am formatting the codes using library(formatR).?Hopefully, it will not be mangled in the email. dir.create("final") lst1<- split(list.files(pattern
=".csv"), gsub("\\_.*","", list.files(pattern =".csv")))? lst2<- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1<- readLines(x2) header1<- lines1[1:2] dat1<- read.table(text = lines1, header = FALSE, sep =",", stringsAsFactors = FALSE,?skip = 2) colnames(dat1)<- Reduce(paste, strsplit(header1,",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ] }))? library(plyr)???lapply(seq_along(lst2), function(i) { lstN<- lapply(lst2[[i]], function(x) x[, -1]) lstQ1<- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(0, 1,?by = 0.01), na.rm = TRUE))(x)) arr1<- array(unlist(lstQ1), dim = c(dim(lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,?lapply(lstQ1, names)[[1]])) res<- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res)<- gsub("","_", colnames(res)) res1<- data.frame(Percentiles = paste0(seq(0, 100, by = 1),"%"), res, stringsAsFactors = FALSE) write.csv(res1,
paste0(paste(getwd(),"final", paste(names(lst1)[[i]],"Quantile",?sep ="_"), sep ="/"),".csv"), row.names = FALSE, quote = FALSE) })? ReadOut1<- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) sapply(ReadOut1, dim) #????[,1] [,2] #[1,]?101?101 #[2,]?258?258? lapply(ReadOut1,function(x) x[1:2,1:3]) #[[1]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.68566?7.09702 #2? ? ? ? ?1% -12.59062?7.15338 # #[[2]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.75516 6.841840 #2? ? ? ? ?1% -12.68244 6.910664? ? ###Q2:? dir.create("Indices") names1<- lapply(ReadOut1, function(x) names(x))[[1]] lstNew<- simplify2array(ReadOut1) lapply(2:nrow(lstNew),
function(i) { dat1<- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1)<- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?length(lst1)), sep ="_")) write.csv(dat1, paste0(paste(getwd(),"Indices", rownames(lstNew)[i], sep ="/"), ".csv"), row.names = FALSE, quote = FALSE) }) ## Output2: ReadOut2<- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) length(ReadOut2) # [1] 257? ? head(ReadOut2[[1]], 2) #?Percentiles G100_pav_ANN G101_pav_ANN #1? ? ? ? ?0%????1.054380????1.032740 #2? ? ? ? ?1% ?1.069457????1.045689? ? A.K.? ? ? ? ? ???On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis? wrote:? Hi AK, Q1) I need your help again. Using the
previous data (attached) and the previous code below,instead of taking rowMeans, let's do quantile(x,seq(0,1,by=0.01)).???Delete the last 2 rows (Trend and p<) in each file before doing quantile(x,seq(0,1,by=0.01)).? For example, assume that I want to calculate quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do so for the 5 sims of site G100 and then take their average. This will be approximately close to the true value than just calculating quantile(x,seq(0,1,by=0.01)) from one sim. Please dothis same thing for all the files.? So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01)) calculated from all sims in that Site.? Output? The number of files in"final" remains the same (2 files). The"Year" column(will be replaced) will contain?the names of quantile(x,seq(0,1,by=0.01)) such as?0%? ? ? ????1%? ? ? ????2%? ?
? ????3%? ? ? ????4%? ? ? ????5%? ? ? ????6%, ..., 98%? ? ? ?99%? ? ????100% . You can give this column any name such as"Percentiles".???Q2)?From the folder"final", please go to each file identified by site name, take a column, say col1 of txav?from each file, create a dataframe whose colnames are site codes (names of files in"final"). Create a folder called"Indices" and place this dataframe in it. The filename for the dataframe is txav, say. So, in"Indices", you will have one file having 3 columns [, c(Percentiles, G100,G101)]. The idea is that I want to be able to pick any column from files in"final" and form a dataframe from which I will generate my qqplot or boxplot.? Thanks very much AK. Atem This should be the final step of this my drama, at least for now.
#==============================================================================================================? dir.create("final") lst1<- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2<-?lapply(lst1,function(x1) lapply(x1, function(x2) {lines1<- readLines(x2); header1<- lines1[1:2]; dat1<- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1)<- Reduce(paste,strsplit(header1,","));dat1}))? lstYear<- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]])? ? lapply(seq_along(lst2),function(i) {lstN<-lapply(lst2[[i]],function(x) x[,-1]); arr1<- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res<- cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res)<- gsub("\\_$","",gsub("","_",names(res))); res[,1]<- gsub("<","",res[,1]);
write.csv(res,paste0(paste(getwd(),"final",names(lst1) [[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)?})? ???#====================================================================================================



From jim at bitwrit.com.au  Tue Apr 15 08:33:52 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 15 Apr 2014 16:33:52 +1000
Subject: [R] creating multiple line graphs
In-Reply-To: <CAMgoKB+AT2zsCrSLPRERd6e3Pga7oL10US+zB4pbx7hVaXWzvg@mail.gmail.com>
References: <CAMgoKB+AT2zsCrSLPRERd6e3Pga7oL10US+zB4pbx7hVaXWzvg@mail.gmail.com>
Message-ID: <534CD2D0.5060005@bitwrit.com.au>

On 04/15/2014 12:27 PM, dila radi wrote:
> Hi all,
>
> I tried to draw multiple line graphs, and this is my data:
>
> structure(list(X = structure(c(3L, 1L, 2L), .Label = c("10%",
> "20%", "5%"), class = "factor"), NRM = c(0.993112, 0.9757191,
> 0.9709928), AAM = c(0.9928504, 0.9764055, 0.9702813), IDW = c(0.9923301,
> 0.9737133, 0.9640287), CCM = c(0.9929805, 0.9768217, 0.9708724
> ), MI = c(0.9931722, 0.9715817, 0.9649249)), .Names = c("X",
> "NRM", "AAM", "IDW", "CCM", "MI"), row.names = c(NA, 3L), class =
> "data.frame")
>
>
> Im using these as my codes:
> y-axis is the amount of S-index (from the data given range from 0.99 - 1.0)
> x-axis is the percentage (5%, 10% and 20%)
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0))
> plot(dt[,2], xaxt = "n",xlab="Percentage of Mising",ylab="S-index",
>       main="Performance of S-Index for Different Percentage",
>       ylim=c(0.99,1),type="l",col="blue",lwd=3)
> lines(dt[,3],col="black",lwd=3,lty=2)
> lines(dt[,4],col="red",lwd=3,type="l")
> lines(dt[,5],col="green3",lwd=3,type="l")
> lines(dt[,6],col="orange",lwd=3,lty=2)
> axis(1,at=1:3,c("5%","10%", "20%"))
> legend("topright", bty="n",c("NRM","AAM","IDW","CCM","MI"),
> lwd=c(3,3,3,3,3), lty =c(1,2,1,4),col=
> c("blue","black","green3","red","orange"))
>
> I guess there is more sophisticated way to do it. Need your help. Thank you
> so much.
>
Hi Dila,
Try this:

matplot(as.matrix(dt[,2:6]),type="b",
  col=c("blue","black","green3","red","orange"),
  pch=c("N","A","I","C","M"),lty=1:5,lwd=2)
legend("topright", bty="n",c("NRM","AAM","IDW","CCM","MI"),
  lty=1:5,col=c("blue","black","green3","red","orange"),
  pch=c("N","A","I","C","M"),lwd=2)

Jim



From jim at bitwrit.com.au  Tue Apr 15 08:36:41 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 15 Apr 2014 16:36:41 +1000
Subject: [R] a question about the output of plot
In-Reply-To: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
References: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
Message-ID: <534CD379.70707@bitwrit.com.au>

On 04/15/2014 11:46 AM, meng wrote:
> Hi all:
> I met a question about the output of plot.
> I want to output 3 plots.
> Method1: by function histogram{lattice}
> Method2: by function hist{graphics}
>
>
> But method1 failed(the output is empty),and only method 2 works.
> I can't find out the reason,and many thanks for your help.
>
>
> #Method1---failed(the output is empty)
> library(lattice)
> for(i in 1:3)
> {
> x<-rnorm(10)
>
>
> jpeg(paste("e:\\hist_",i,".jpeg"))
> histogram(x)
> dev.off()
> }
>
>
>
>
> #Method 2---works
> for(i in 1:3)
> {
> x<-rnorm(10)
>
>
> jpeg(paste("e:\\hist_",i,".jpeg"))
> hist(x)
> dev.off()
> }
>
Hi meng,
Try:

print(histogram(x))

Jim



From Achim.Zeileis at uibk.ac.at  Tue Apr 15 09:07:54 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 15 Apr 2014 09:07:54 +0200 (CEST)
Subject: [R] hetglm() and robust standard errors
In-Reply-To: <1397484456221-4688737.post@n4.nabble.com>
References: <1397484456221-4688737.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.10.1404150900040.9074@paninaro.uibk.ac.at>

On Mon, 14 Apr 2014, ChrisR wrote:

> Hi everyone,
> I am using the hetglm() command from the package 'glmx' (0.1-0). It seems
> that hetglm() is incompatible with the robust standard errors estimator
> provided in the 'AER' package: coeftest(mymodel,vcov=vcovHC)
> Any suggestions how I could obtain robust standard errors for the
> heteroscedastic probit?

Use

coeftest(mymodel, vcov = sandwich)

but the usual caveat applies that it is not quite clear what this is 
robust against. If the some aspect of the model likelihood is misspecified 
then the estimating equations are also misspecified and the estimator 
itself inconsistent. This is briefly pointed out at the end of the 
discussion in vignette("sandwich-OOP", package = "sandwich").


As for the difference between vcovHC() and sandwich():

- The HC1, HC2, HC3 methods from the vcovHC() function can only be applied 
if there is a linear predictor plus a useful measure of leverage etc. 
Thus, it cannot be applied to general heteroskedastic probit models (or it 
wouldn't be clear to me how...).

- The basic sandwich() estimator, however, can be applied easily. This 
uses just the so-called outer product of gradients. In the linear 
regression model it corresponds to the basic HC0 estimator.

hth,
Z

> Thanks,
> Chris
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/hetglm-and-robust-standard-errors-tp4688737.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From zhaoxing at uw.edu  Tue Apr 15 10:14:40 2014
From: zhaoxing at uw.edu (Xing Zhao)
Date: Tue, 15 Apr 2014 01:14:40 -0700
Subject: [R] The explanation of ns() with df =2
Message-ID: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>

Dear all

I understand the definition of Natural Cubic Splines are those with
linear constraints on the end points. However, it is hard to think
about how this can be implement when df=2. df=2 implies there is just
one knot, which, according the the definition, the curves on its left
and its right should be both be lines. This means the whole line
should be a line. But when making some fits. the result still looks
like 2nd order polynomial.

How to think about this problem?

Thanks
Xing

ns(1:15,df =2)
              1           2
 [1,] 0.0000000  0.00000000
 [2,] 0.1084782 -0.07183290
 [3,] 0.2135085 -0.13845171
 [4,] 0.3116429 -0.19464237
 [5,] 0.3994334 -0.23519080
 [6,] 0.4734322 -0.25488292
 [7,] 0.5301914 -0.24850464
 [8,] 0.5662628 -0.21084190
 [9,] 0.5793481 -0.13841863
[10,] 0.5717456 -0.03471090
[11,] 0.5469035  0.09506722
[12,] 0.5082697  0.24570166
[13,] 0.4592920  0.41197833
[14,] 0.4034184  0.58868315
[15,] 0.3440969  0.77060206
attr(,"degree")
[1] 3
attr(,"knots")
50%
  8
attr(,"Boundary.knots")
[1]  1 15
attr(,"intercept")
[1] FALSE
attr(,"class")
[1] "ns"     "basis"  "matrix"



From petr.pikal at precheza.cz  Tue Apr 15 11:26:14 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 15 Apr 2014 09:26:14 +0000
Subject: [R] I can't programe routine comp()
In-Reply-To: <1397472963.31861.YahooMailNeo@web171702.mail.ir2.yahoo.com>
References: <1397472963.31861.YahooMailNeo@web171702.mail.ir2.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BCC9FA@SRVEXCHMBX.precheza.cz>

Hi

better to use dput for presenting data as it is directly usable by anybody. So I did not test it.

Try to get names for appropriate columns

nn<-names(d)

and use get

s=survfit(Surv(get(nn[2]), get(nn[3]))~get(nn[1]), data=d)

It works with lm and shall work with survit too.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Endy
> Sent: Monday, April 14, 2014 12:56 PM
> To: r-help at r-project.org
> Subject: [R] I can't programe routine comp()
>
>     Dear R users.
> I am trying to program the comp() routine in package survMisc. I am
> reading the data below with d=read.table( "C:\\. .
> .",fill=TRUE,header=TRUE) Then I load the packages 'survival' and
> 'survMisc', library(survival), library(survMisc)
>  and I run the commands
>                                       s=survfit(Surv(d[,2],
> d[,3])~d[,1], data=d)
>                                       comp(s)
>  and I am getting the error
>                                        Error in get(t1, loc1) : object
> 'd[, 2]' not found If instead I use the commands
>                                         s=survfit(Surv(T,
> Status)~Group, data=d)
>                                        comp(s) routine comp()  runs
> perfectly. However when I am programing I can't see a way to know in
> advance the variable names in order to use them.
> Can anybody  give me a suggestion?
>
>                      Thanks in advance
>                        Endy
>
> NB. The data must be stacked in three (3) columns before red.
> They are repeated in nine (9) columns for space saving.
>
> GroupTStatusGroupTStatusGroupTStatus
>
> 120810155124141
> 116020111222041
> 11496011071210631
> 1146201110124811
> 1143301332121051
> 11377022569026411
> 11330022506023901
> 1996022409022881
> 1226022218024211
> 1119902185702791
> 11111021829027481
> 1530021562024861
> 1118202147002481
> 11167021363022721
> 14181210300210741
> 138312860023811
> 127612125802101
> 110412224602531
> 160912187002801
> 117212179902351
> 1487121709022481
> 1662121674027041
> 1194121568022111
> 1230121527022191
> 1526121324026061
> 1122129570
> 1129129320
> 174128470
> 1122128480
> 1861218500
> 14661218430
> 11921215350
> 11091214470
> 1551213840
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



From petr.pikal at precheza.cz  Tue Apr 15 11:33:13 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 15 Apr 2014 09:33:13 +0000
Subject: [R] program
In-Reply-To: <1397462761.46343.YahooMailNeo@web124706.mail.ne1.yahoo.com>
References: <1397462761.46343.YahooMailNeo@web124706.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BCCA10@SRVEXCHMBX.precheza.cz>

Hi

No attachment allowed. Well, some yes but not many.

Do not expect somebody will go through great deal of code. Try instead locate source of problems yourself. If you are lucky you will find it out without intervence of others, if not you will be able to post more straight question which can attach your audience.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of kafi dano
> Sent: Monday, April 14, 2014 10:06 AM
> To: R-help at r-project.org
> Subject: [R] program
>
> Dear Sir.
> I need your to help me to correct the attached R-code.
>
> when I apply this code give me the bad result
>
>
> Attached the program by using R
>
> Thank you
>
>
>
>
>
>
>
>
>
>
> Kafi Dano Pati
> Ph.D candidate ( mathematics/statistics) Department of mathematical
> Science/ faculty of Science University Technology Malaysia 81310 UTM,
> Johor Bahru, Johor, Malaysia IC. NO. 201202F10234 Matric No. PS113113
> HP. No. 00601117517559
> E-mail: kafi_dano at yahoo.com
> supervisor- Assoc. Prof. Robiah Binti Adnan

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



From jim at bitwrit.com.au  Tue Apr 15 11:56:01 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 15 Apr 2014 19:56:01 +1000
Subject: [R] a question about the output of plot
In-Reply-To: <76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>
References: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
	<534CD379.70707@bitwrit.com.au>
	<76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>
Message-ID: <534D0231.8000908@bitwrit.com.au>

On 04/15/2014 07:51 PM, meng wrote:
> Yes,it works !
> What's the reason for it?
>
Hi meng,
As I understand it, the lattice graphics system produces plot
objects, not actual output on a graphic device. This is in aid
of having an object that can be modified or stored rather than
an image that cannot. The overloading of "print" to produce an
image is a bit counterintuitive, but I suppose there is some
historical reason for it.

Jim



From laomeng_3 at 163.com  Tue Apr 15 11:51:58 2014
From: laomeng_3 at 163.com (meng)
Date: Tue, 15 Apr 2014 17:51:58 +0800 (CST)
Subject: [R] a question about the output of plot
In-Reply-To: <534CD379.70707@bitwrit.com.au>
References: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
	<534CD379.70707@bitwrit.com.au>
Message-ID: <76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/6f94f0e8/attachment-0001.pl>

From robertbauer1603 at gmx.de  Tue Apr 15 11:55:13 2014
From: robertbauer1603 at gmx.de (Robert Bauer)
Date: Tue, 15 Apr 2014 02:55:13 -0700 (PDT)
Subject: [R] generic function-method arguments accessible by tab-key
Message-ID: <1397555713544-4688793.post@n4.nabble.com>

Hi,

I have the following problem:
  
I wrote a Generic Function that comes with a bunch of different methods and
even more arguments. 
It's kind like this:

  if ( !isGeneric("v") ) {
    setGeneric("v", function(x, ...)
      standardGeneric("v"))
  }

setMethod('v', signature(x='character'), 
          function(x,...){
            print(x)
          }
)



So what I don't know is how to porgram the function in a way that when
typing the function in the R-console one can see all available arguments,
using the 'tab-key' for all the different methods of the function that are
actually masked by the three dots, like:
as.matrix(

so that I see: as.matrix(x=
                                 ... 
                                 row.names.force= 
                                 sep= 
                                 byrow=

another example is the generic function that shows all arguments is the
plot()-function

I figured out that these functions come with different subfunctions, like
as.matrix.default, as.matrix.spam, but when adding a sub.function: v.print,
the arguments do not show up by the v:

v.print <- function(x,y='',z=''){
print(paste(x,y,z))
}


i thought to link the v and the v.print function, but this did not bring the
anticipated result neither:
  
  if ( !isGeneric("v") ) {
    setGeneric("v", function(x, ...)
      standardGeneric("v"))
  }

setMethod('v', signature(x='character'), 
          function(x,y=x,z=x){
            v.print(x,y=y,z=z)
          }
)
  
  
maybe that's not the right way... any ideas?
thx very much in advance!

robert



--
View this message in context: http://r.789695.n4.nabble.com/generic-function-method-arguments-accessible-by-tab-key-tp4688793.html
Sent from the R help mailing list archive at Nabble.com.



From robertbauer1603 at gmx.de  Tue Apr 15 12:13:58 2014
From: robertbauer1603 at gmx.de (Robert Bauer)
Date: Tue, 15 Apr 2014 03:13:58 -0700 (PDT)
Subject: [R] generic function-method arguments accessible by tab-key
In-Reply-To: <1397555713544-4688793.post@n4.nabble.com>
References: <1397555713544-4688793.post@n4.nabble.com>
Message-ID: <1397556838591-4688794.post@n4.nabble.com>

just a note i liked to add:
so the idea is just to have the optional arguments y and z showing up in the
the v-function call using the tab-key



--
View this message in context: http://r.789695.n4.nabble.com/generic-function-method-arguments-accessible-by-tab-key-tp4688793p4688794.html
Sent from the R help mailing list archive at Nabble.com.



From pavneet.arora at uk.rsagroup.com  Tue Apr 15 10:33:07 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Tue, 15 Apr 2014 09:33:07 +0100
Subject: [R] Read.table mucks up headers
In-Reply-To: <1397495399.4315.1.camel@milan>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
	<1397495399.4315.1.camel@milan>
Message-ID: <OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/f106cb1f/attachment-0001.pl>

From pavneet.arora at uk.rsagroup.com  Tue Apr 15 11:09:12 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Tue, 15 Apr 2014 10:09:12 +0100
Subject: [R] Save multiple plots as pdf or jpeg
Message-ID: <OF6E721B9E.F3159994-ON80257CBB.003247B4-80257CBB.0032D109@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/630893cf/attachment-0001.pl>

From pavneet.arora at uk.rsagroup.com  Tue Apr 15 12:27:00 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Tue, 15 Apr 2014 11:27:00 +0100
Subject: [R] Fw: Save multiple plots as pdf or jpeg
Message-ID: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/357005f1/attachment-0001.pl>

From hongjing55544 at 163.com  Tue Apr 15 12:58:12 2014
From: hongjing55544 at 163.com (=?GBK?B?uqu67L6y?=)
Date: Tue, 15 Apr 2014 18:58:12 +0800 (CST)
Subject: [R] Some questions :How to use Friedman'Test in R
Message-ID: <2ad5a0dd.f457.14565098066.Coremail.hongjing55544@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/40a185c4/attachment-0001.pl>

From Vijayakumar_C02 at infosys.com  Tue Apr 15 13:52:09 2014
From: Vijayakumar_C02 at infosys.com (Vijayakumar Chinnamuthu)
Date: Tue, 15 Apr 2014 11:52:09 +0000
Subject: [R] R tool support
Message-ID: <A412559CCAF16D4AA192568EF14657B257B2E375@BLRKECMBX24.ad.infosys.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/7d20cb51/attachment-0001.pl>

From mark.link at hauck-aufhaeuser.de  Tue Apr 15 14:03:28 2014
From: mark.link at hauck-aufhaeuser.de (mark.link at hauck-aufhaeuser.de)
Date: Tue, 15 Apr 2014 14:03:28 +0200
Subject: [R] Error message in R
Message-ID: <4CB130CD0332D344B06D1C6EA8E943532DA24FF8@sf023.ha.int>

Hello, 

we get at a users individual following error: java.lang.OutOfMemoryError: unable to create new native thread 

Can you please tell me how I can fix this? 

Thank you very much 

Sincerely yours

Mark Link
Applikationsmanagement

Hauck & Aufh?user Privatbankiers KGaA
Kaiserstra?e 24
60311 Frankfurt am Main
Telefon +49 69 2161-1581
Fax +49 69 2161-1730

mark.link at hauck-aufhaeuser.de
www.hauck-aufhaeuser.de



________________________________________________________________________________

Der Inhalt dieser eMail ist ausschlie?lich f?r den bezeichneten Adressaten bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser eMail oder dessen Vertreter sein sollten, beachten Sie bitte, dass jede Form der Ver?ffentlichung, Vervielf?ltigung oder Weitergabe des Inhaltes dieser eMail unzul?ssig ist. Der Austausch von Nachrichten mit Hauck & Aufh?user Privatbankiers KGaA via eMail dient ausschlie?lich Informationszwecken. Bitte beachten Sie, dass wir Auftr?ge oder Weisungen per E-Mail nicht entgegen nehmen k?nnen. Verf?lschungen des urspr?nglichen Inhaltes dieser Nachricht bei der Daten?bertragung k?nnen nicht ausgeschlossen werden.

Hauck & Aufh?user Privatbankiers KGaA
Pers?nlich haftende Gesellschafter: Jochen Lucht, Hauck & Aufh?user Gesch?ftsleitungs GmbH
Vorsitzender des Aufsichtsrates: Wolfgang Deml
Kommanditgesellschaft auf Aktien mit Sitz in Frankfurt am Main, Amtsgericht Frankfurt HRB 20065
Umsatzsteuer-Identifikations-Nummer: DE114104118

_______________________________________________________________________________

The information contained in this e-mail is intended solely for the addressee. Access to this e-mail by anyone else is unauthorized. If you are not the intended recipient, any form of disclosure, reproduction, distribution or any action taken or refrained from in reliance on it, is prohibited and may be unlawful. Correspondence with Hauck & Aufhaeuser Privatbankiers KGaA via e-mail is only for information purposes. Please note that we cannot accept any orders or instructions by e-mail. The falsification of the original content of this message in the course of data transmission cannot be excluded.

Hauck & Aufhaeuser Privatbankiers KGaA
Managing partners: Jochen Lucht, Hauck & Aufhaeuser Geschaeftsleitungs GmbH
Chairman of the supervisory board: Wolfgang Deml
Partnership limited by shares domiciled in Frankfurt/Main, commercial register at local court Frankfurt HRB 20065
VAT-identification number: DE114104118

From friendly at yorku.ca  Tue Apr 15 14:18:40 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 15 Apr 2014 08:18:40 -0400
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
Message-ID: <534D23A0.5040102@yorku.ca>

No, the curves on each side of the know are cubics, joined
so they are continuous.  Se the discussion in \S 17.2 in
Fox's Applied Regression Analysis.

On 4/15/2014 4:14 AM, Xing Zhao wrote:
> Dear all
>
> I understand the definition of Natural Cubic Splines are those with
> linear constraints on the end points. However, it is hard to think
> about how this can be implement when df=2. df=2 implies there is just
> one knot, which, according the the definition, the curves on its left
> and its right should be both be lines. This means the whole line
> should be a line. But when making some fits. the result still looks
> like 2nd order polynomial.
>
> How to think about this problem?
>
> Thanks
> Xing
>
> ns(1:15,df =2)
>                1           2
>   [1,] 0.0000000  0.00000000
>   [2,] 0.1084782 -0.07183290
>   [3,] 0.2135085 -0.13845171
>   [4,] 0.3116429 -0.19464237
>   [5,] 0.3994334 -0.23519080
>   [6,] 0.4734322 -0.25488292
>   [7,] 0.5301914 -0.24850464
>   [8,] 0.5662628 -0.21084190
>   [9,] 0.5793481 -0.13841863
> [10,] 0.5717456 -0.03471090
> [11,] 0.5469035  0.09506722
> [12,] 0.5082697  0.24570166
> [13,] 0.4592920  0.41197833
> [14,] 0.4034184  0.58868315
> [15,] 0.3440969  0.77060206
> attr(,"degree")
> [1] 3
> attr(,"knots")
> 50%
>    8
> attr(,"Boundary.knots")
> [1]  1 15
> attr(,"intercept")
> [1] FALSE
> attr(,"class")
> [1] "ns"     "basis"  "matrix"
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From friendly at yorku.ca  Tue Apr 15 14:18:40 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 15 Apr 2014 08:18:40 -0400
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
Message-ID: <534D23A0.5040102@yorku.ca>

No, the curves on each side of the know are cubics, joined
so they are continuous.  Se the discussion in \S 17.2 in
Fox's Applied Regression Analysis.

On 4/15/2014 4:14 AM, Xing Zhao wrote:
> Dear all
>
> I understand the definition of Natural Cubic Splines are those with
> linear constraints on the end points. However, it is hard to think
> about how this can be implement when df=2. df=2 implies there is just
> one knot, which, according the the definition, the curves on its left
> and its right should be both be lines. This means the whole line
> should be a line. But when making some fits. the result still looks
> like 2nd order polynomial.
>
> How to think about this problem?
>
> Thanks
> Xing
>
> ns(1:15,df =2)
>                1           2
>   [1,] 0.0000000  0.00000000
>   [2,] 0.1084782 -0.07183290
>   [3,] 0.2135085 -0.13845171
>   [4,] 0.3116429 -0.19464237
>   [5,] 0.3994334 -0.23519080
>   [6,] 0.4734322 -0.25488292
>   [7,] 0.5301914 -0.24850464
>   [8,] 0.5662628 -0.21084190
>   [9,] 0.5793481 -0.13841863
> [10,] 0.5717456 -0.03471090
> [11,] 0.5469035  0.09506722
> [12,] 0.5082697  0.24570166
> [13,] 0.4592920  0.41197833
> [14,] 0.4034184  0.58868315
> [15,] 0.3440969  0.77060206
> attr(,"degree")
> [1] 3
> attr(,"knots")
> 50%
>    8
> attr(,"Boundary.knots")
> [1]  1 15
> attr(,"intercept")
> [1] FALSE
> attr(,"class")
> [1] "ns"     "basis"  "matrix"
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From deter088 at umn.edu  Tue Apr 15 14:53:40 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 15 Apr 2014 07:53:40 -0500
Subject: [R] help
In-Reply-To: <1397549882.51917.YahooMailNeo@web124702.mail.ne1.yahoo.com>
References: <1397549882.51917.YahooMailNeo@web124702.mail.ne1.yahoo.com>
Message-ID: <CAOLJphnWfCXykQW1-3OOBnUmmFR2p+0YwCihXEHqLAE4hdNaKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/b5a7e34b/attachment-0001.pl>

From ligges at statistik.tu-dortmund.de  Tue Apr 15 15:11:48 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 15 Apr 2014 15:11:48 +0200
Subject: [R] Error message in R
In-Reply-To: <4CB130CD0332D344B06D1C6EA8E943532DA24FF8@sf023.ha.int>
References: <4CB130CD0332D344B06D1C6EA8E943532DA24FF8@sf023.ha.int>
Message-ID: <534D3014.6020106@statistik.tu-dortmund.de>



On 15.04.2014 14:03, mark.link at hauck-aufhaeuser.de wrote:
> Hello,
>
> we get at a users individual following error: java.lang.OutOfMemoryError: unable to create new native thread
>
> Can you please tell me how I can fix this?

You are using the xlsx package?
Increase the java heap size, I find a solution once I Google for it....

Best,
Uwe Ligges


>
> Thank you very much
>
> Sincerely yours
>
> Mark Link
> Applikationsmanagement
>
> Hauck & Aufh?user Privatbankiers KGaA
> Kaiserstra?e 24
> 60311 Frankfurt am Main
> Telefon +49 69 2161-1581
> Fax +49 69 2161-1730
>
> mark.link at hauck-aufhaeuser.de
> www.hauck-aufhaeuser.de
>
>
>
> ________________________________________________________________________________
>
> Der Inhalt dieser eMail ist ausschlie?lich f?r den bezeichneten Adressaten bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser eMail oder dessen Vertreter sein sollten, beachten Sie bitte, dass jede Form der Ver?ffentlichung, Vervielf?ltigung oder Weitergabe des Inhaltes dieser eMail unzul?ssig ist. Der Austausch von Nachrichten mit Hauck & Aufh?user Privatbankiers KGaA via eMail dient ausschlie?lich Informationszwecken. Bitte beachten Sie, dass wir Auftr?ge oder Weisungen per E-Mail nicht entgegen nehmen k?nnen. Verf?lschungen des urspr?nglichen Inhaltes dieser Nachricht bei der Daten?bertragung k?nnen nicht ausgeschlossen werden.
>
> Hauck & Aufh?user Privatbankiers KGaA
> Pers?nlich haftende Gesellschafter: Jochen Lucht, Hauck & Aufh?user Gesch?ftsleitungs GmbH
> Vorsitzender des Aufsichtsrates: Wolfgang Deml
> Kommanditgesellschaft auf Aktien mit Sitz in Frankfurt am Main, Amtsgericht Frankfurt HRB 20065
> Umsatzsteuer-Identifikations-Nummer: DE114104118
>
> _______________________________________________________________________________
>
> The information contained in this e-mail is intended solely for the addressee. Access to this e-mail by anyone else is unauthorized. If you are not the intended recipient, any form of disclosure, reproduction, distribution or any action taken or refrained from in reliance on it, is prohibited and may be unlawful. Correspondence with Hauck & Aufhaeuser Privatbankiers KGaA via e-mail is only for information purposes. Please note that we cannot accept any orders or instructions by e-mail. The falsification of the original content of this message in the course of data transmission cannot be excluded.
>
> Hauck & Aufhaeuser Privatbankiers KGaA
> Managing partners: Jochen Lucht, Hauck & Aufhaeuser Geschaeftsleitungs GmbH
> Chairman of the supervisory board: Wolfgang Deml
> Partnership limited by shares domiciled in Frankfurt/Main, commercial register at local court Frankfurt HRB 20065
> VAT-identification number: DE114104118
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ligges at statistik.tu-dortmund.de  Tue Apr 15 15:14:00 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 15 Apr 2014 15:14:00 +0200
Subject: [R] Some questions :How to use Friedman'Test in R
In-Reply-To: <2ad5a0dd.f457.14565098066.Coremail.hongjing55544@163.com>
References: <2ad5a0dd.f457.14565098066.Coremail.hongjing55544@163.com>
Message-ID: <534D3098.4060700@statistik.tu-dortmund.de>



On 15.04.2014 12:58, ??? wrote:
> Dear R users:             I'm trying to program the Friedman'test(),but I meet some problemes.             I am reading the data below with s1=read.table("1express.txt",header=T)       Then,I get the datas1B1AD1X1544766544777766765988666666776466787776679778777886868655786777888555666676666777676888654767456765877779664676788887666354778775777454764888767876566554665776776876655766365654777889365466777778889565878666656897434777664889666777 attach(s1)friedman.test(s1????Error in friedman.test.default(s1) :   argument "groups" is missing, with no default??   I don't know what's the meaning of the problem,and I am not sure where the problem
>
> Can anybody  give me a suggestion?

Specify the groups?

Best,
Uwe Ligges



>   Thanks in advance
>                         Rocia
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ligges at statistik.tu-dortmund.de  Tue Apr 15 15:15:47 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 15 Apr 2014 15:15:47 +0200
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
Message-ID: <534D3103.4060904@statistik.tu-dortmund.de>

You have > 1e6 observations and your lines() have these many segments, 
try to plot the sensity only with few hndreds of segemnts.

Best,
Uwe Ligges


On 15.04.2014 12:27, Pavneet Arora wrote:
> Hello All,
>
> I have multiple plots that I want to save it a single file. At the moment,
> I am saving as pdf. Each plot has a qqnorm, qqline, tiny histogram in the
> top left graph with its density drawn top of it and the normal
> superimposed on the histogram.
>
> As a result, the pdf takes forever to load and doesn?t let me print, as it
> runs out of memory. I was wondering if there is a way if I can save each
> plot as jpeg and then export it on pdf. Will that make it quicker in
> loading? If so, how can I do this? And if not, then what are the
> alternatives.
>
> The code that I have at the moment is as follows:
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> pdf(file="C:/qqnorm/qqnorms.pdf") ##- Saves all plots in the same pdf file
>
>
> for (k in 1:ncol(nums2)){
>      par(mfrow=c(1,1))
>
> ##- QQNorm
>      qqnorm(nums2[,k],col="lightblue",main=names(nums2)[k])
>      qqline(nums2[,k],col="red",lwd=2)
>
> ##- Tiny Histogram
> op = par(fig=c(.02,.5,0.4,0.98), new=TRUE)
>      hist(nums2[,k],freq=F,col="blue",xlab="", ylab="", main="",
>           axes=F,density=20)
>
> ##- Density of the variable
>      lines(density(nums2[,k],na.rm=T), col="darkred", lwd=2)
>
> ##- Super-imposed Normal Density
>      curve(dnorm(x,mean=mean(nums2[,k],na.rm=T),sd=sd(nums2[,k],na.rm=T)),
>            col="black",lwd=3,add=T) ##- Footnote: title1 <- "nums2[k]"
>
> library(moments)
>      s_kurt <- kurtosis (nums2[,k])
>      s_skew <- skewness (nums2[,k])
>      mtxt <- paste ("Variable=",title1, ":" ,
>                     "Kurt=",round(s_kurt,digits=4), "Skew",
>                     round(s_skw,digits=4), sep=" ")
>
> mtext (mtxt,col="green4",side=1,line=15.6,adj=0.0,cex=0.8,font=2,las=1)
>
> }
> dev.off()
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> Structure of My data:
>
> str(nums2)
> 'data.frame':            1355615 obs. of  39 variables:
>   $ month                           : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Location_Easting_OSGR           : int  525680 524170 524520 526900
> 528060 524770 524220 525890 527350 524550 ...
>   $ Location_Northing_OSGR          : int  178240 181650 182240 177530
> 179040 181160 180830 179710 177650 180810 ...
>   $ Longitude                       : num  -0.191 -0.212 -0.206 -0.174
> -0.157 ...
>   $ Latitude                        : num  51.5 51.5 51.5 51.5 51.5 ...
>   $ Police_Force                    : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Number_of_Vehicles              : int  1 1 2 1 1 2 2 1 2 2 ...
>   $ Number_of_Casualties            : int  1 1 1 1 1 1 1 2 2 5 ...
>   $ Day_of_Week                     : int  3 4 5 6 2 3 5 6 7 7 ...
>   $ Local_Authority__District_      : int  12 12 12 12 12 12 12 12 12 12
> ...
>   $ X_1_st_Road_Class               : int  3 4 5 3 6 6 5 3 3 4 ...
>   $ X_1_st_Road_Number              : int  3218 450 0 3220 0 0 0 315 3212
> 450 ...
>   $ Road_Type                       : int  6 3 6 6 6 6 6 3 6 6 ...
>   $ Speed_limit                     : int  30 30 30 30 30 30 30 30 30 30
> ...
>   $ Junction_Detail                 : int  0 6 0 0 0 0 3 0 6 3 ...
>   $ Junction_Control                : int  -1 2 -1 -1 -1 -1 4 -1 2 4 ...
>   $ X_2_nd_Road_Class               : int  -1 5 -1 -1 -1 -1 6 -1 4 5 ...
>   $ X_2_nd_Road_Number              : int  0 0 0 0 0 0 0 0 304 0 ...
>   $ Pedestrian_Crossing_Human_Contro: int  0 0 0 0 0 0 0 0 0 0 ...
>   $ Pedestrian_Crossing_Physical_Fac: int  1 5 0 0 0 0 0 0 5 8 ...
>   $ Light_Conditions                : int  1 4 4 1 7 1 4 1 4 1 ...
>   $ Weather_Conditions              : int  2 1 1 1 1 2 1 1 1 1 ...
>   $ Road_Surface_Conditions         : int  2 1 1 1 2 2 1 1 1 1 ...
>   $ Special_Conditions_at_Site      : int  0 0 0 0 0 6 0 0 0 0 ...
>   $ Carriageway_Hazards             : int  0 0 0 0 0 0 0 0 0 0 ...
>   $ Urban_or_Rural_Area             : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Did_Police_Officer_Attend_Scene_: int  1 1 1 1 1 1 1 1 1 1 ...
>   $ year                            : int  2005 2005 2005 2005 2005 2005
> 2005 2005 2005 2005 ...
>   $ m                               : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Qrtr                            : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ h2                              : int  17 17 0 10 21 12 20 17 22 16 ...
>   $ NumberVehGrp                    : int  1 1 2 1 1 2 2 1 2 2 ...
>   $ NumberCasultGrp                 : int  1 1 1 1 1 1 1 2 2 5 ...
>   $ lati_round                      : num  51.5 51.5 51.5 51.5 51.5 ...
>   $ longi_round                     : num  -0.19 -0.21 -0.21 -0.17 -0.16
> -0.2 -0.21 -0.19 -0.17 -0.21 ...
>   $ lati_2dp                        : num  51.5 51.5 51.5 51.5 51.5 ...
>   $ lati_1dp                        : num  51.5 51.5 51.5 51.5 51.5 51.5
> 51.5 51.5 51.5 51.5 ...
>   $ longi_2dp                       : num  -0.19 -0.21 -0.21 -0.17 -0.16
> -0.2 -0.21 -0.19 -0.17 -0.21 ...
>   $ longi_1dp                       : num  -0.2 -0.2 -0.2 -0.2 -0.2 -0.2
> -0.2 -0.2 -0.2 -0.2 ...
>
>
> Also when saving as jpeg in R, I realise there is a wildcard in filenames,
> i.e.. 6 plots can be saved as:
> jpeg(filename="foo%03d.jpeg",. . . )
> dev.off()
>
> But is there any way, where I can save them as the variable name instead -
> so perhaps some use of macro or loop to do so?
>
>
>
> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ligges at statistik.tu-dortmund.de  Tue Apr 15 15:16:48 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 15 Apr 2014 15:16:48 +0200
Subject: [R] error when installing package after installing R-3.1.0 on
 windows
In-Reply-To: <1397525112.68332.YahooMailNeo@web160105.mail.bf1.yahoo.com>
References: <1397525112.68332.YahooMailNeo@web160105.mail.bf1.yahoo.com>
Message-ID: <534D3140.4040902@statistik.tu-dortmund.de>



On 15.04.2014 03:25, Linda Peng wrote:
> Hi,
>
> I encountered following error" Warning in install.packages("xlsx") :   'lib = "C:/Program Files/R/R-3.1.0/library"' is not writable". This is right after I installed R-3.1.0 on windows after previous R-2.15.2 which is still existing.


If you want to install into that libvrary, you need administrator 
permissions, i.e. start R via right click and "Start as Administrator". 
Otehrwise install into a personal library.

Best,
Uwe Ligges



> I checked the folder permission and it doesn't have read-only set. Did anybody experienced the same or have suggestions what to check or fix?
>
> Thanks for the help,
>
> Linda
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jfox at mcmaster.ca  Tue Apr 15 15:17:39 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 15 Apr 2014 09:17:39 -0400
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <534D23A0.5040102@yorku.ca>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
	<534D23A0.5040102@yorku.ca>
Message-ID: <web-505799764@cgpsrv2.cis.mcmaster.ca>

Dear Xing Zhao,

To elaborate slightly on Michael's comments, a natural cubic spline with 2 df has one *interior* knot and two boundary knots (as is apparent in the output you provided). The linearity constraint applies beyond the boundary knots.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

On Tue, 15 Apr 2014 08:18:40 -0400
 Michael Friendly <friendly at yorku.ca> wrote:
> No, the curves on each side of the know are cubics, joined
> so they are continuous.  Se the discussion in \S 17.2 in
> Fox's Applied Regression Analysis.
> 
> On 4/15/2014 4:14 AM, Xing Zhao wrote:
> > Dear all
> >
> > I understand the definition of Natural Cubic Splines are those with
> > linear constraints on the end points. However, it is hard to think
> > about how this can be implement when df=2. df=2 implies there is just
> > one knot, which, according the the definition, the curves on its left
> > and its right should be both be lines. This means the whole line
> > should be a line. But when making some fits. the result still looks
> > like 2nd order polynomial.
> >
> > How to think about this problem?
> >
> > Thanks
> > Xing
> >
> > ns(1:15,df =2)
> >                1           2
> >   [1,] 0.0000000  0.00000000
> >   [2,] 0.1084782 -0.07183290
> >   [3,] 0.2135085 -0.13845171
> >   [4,] 0.3116429 -0.19464237
> >   [5,] 0.3994334 -0.23519080
> >   [6,] 0.4734322 -0.25488292
> >   [7,] 0.5301914 -0.24850464
> >   [8,] 0.5662628 -0.21084190
> >   [9,] 0.5793481 -0.13841863
> > [10,] 0.5717456 -0.03471090
> > [11,] 0.5469035  0.09506722
> > [12,] 0.5082697  0.24570166
> > [13,] 0.4592920  0.41197833
> > [14,] 0.4034184  0.58868315
> > [15,] 0.3440969  0.77060206
> > attr(,"degree")
> > [1] 3
> > attr(,"knots")
> > 50%
> >    8
> > attr(,"Boundary.knots")
> > [1]  1 15
> > attr(,"intercept")
> > [1] FALSE
> > attr(,"class")
> > [1] "ns"     "basis"  "matrix"
> >
> 
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From therneau at mayo.edu  Tue Apr 15 15:32:31 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 15 Apr 2014 08:32:31 -0500
Subject: [R] Trend test for hazard ratios
In-Reply-To: <mailman.19.1397556011.24959.r-help@r-project.org>
References: <mailman.19.1397556011.24959.r-help@r-project.org>
Message-ID: <3dfcdc$gc1e36@ironport9.mayo.edu>

You can do statistical tests within a single model, for whether portions of it fit or do 
not fit.  But one cannot take three separate fits and compare them.  The program needs 
context to know how the three relate to one another.  Say that "group" is your strata 
variable, trt the variable of interest, and x1, x2 are adjusters.

    fit <- coxph(Surv(time,status) ~ trt * strata(group) + x1 + x2, data=mydata)

Will fit a model with a separate treatment coefficient for each of the groups, and a 
separate baseline hazard for each.  One can now create a contrast that corresponds to your 
trend test, using vcov(fit) for the variance matrix and coef(fit) to retrieve the 
coefficients.

Terry T.



On 04/15/2014 05:00 AM, r-help-request at r-project.org wrote:
> Hello,
>
> I have the following problem. I stratified my patient cohort into three
> ordered groups and performed multivariate adjusted Cox regression analysis
> on each group separately. Now I would like to calculate a p for trend across
> the hazard ratios that I got for the three groups. How can I do that if I
> only have the HR and the confidence interval? For example I got the
> following HRs for one endpoint:
>
> 1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68).
>
> There is a trend but how do I calculate if it is significant?
>
> Best regards
>
> Marcus Kleber
>



From jdnewmil at dcn.davis.CA.us  Tue Apr 15 15:46:19 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Apr 2014 06:46:19 -0700
Subject: [R] R tool support
In-Reply-To: <A412559CCAF16D4AA192568EF14657B257B2E375@BLRKECMBX24.ad.infosys.com>
References: <A412559CCAF16D4AA192568EF14657B257B2E375@BLRKECMBX24.ad.infosys.com>
Message-ID: <9b1e5394-c0e0-4c03-8de7-14948ff1eb11@email.android.com>

This request is off-topic per the Posting Guide, which you seem not to have read (this question is clearly a development question, and you are posting using HTML email format which is not supported on this list).

Please note that that .NET is not one of the development environments supported by the core R developers (see the Writing R Extensions documentation), so it is not even clear to me that you will obtain assistance on the R-devel mailing list, but it would at least be relevant there.

I have seen a web site that discusses calling R from .NET, so it has apparently been done before.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 15, 2014 4:52:09 AM PDT, Vijayakumar Chinnamuthu <Vijayakumar_C02 at infosys.com> wrote:
>Hi,
>
>We are using on R tool for our one of the project and looking for some
>technical  support.
>Could you please help us.
>
>Flow:
>1. We have C#.Net Application which uses R.NET Dll's for invoking R
>2. R internally uses qcc package (mqcc function) for plotting the
>chart.
>
>Requirement:
>
>
>1.       We need to access qcc package in our .Net Application.
>
>2.       Qcc packages function(mqcc should be accessible in our .Net
>application)
>
>3.       Share a sample application which does this.
>
>
>Thanks,
>Vijay
>
>
>**************** CAUTION - Disclaimer *****************
>This e-mail contains PRIVILEGED AND CONFIDENTIAL INFORMATION intended
>solely
>for the use of the addressee(s). If you are not the intended recipient,
>please
>notify the sender by e-mail and delete the original message. Further,
>you are not
>to copy, disclose, or distribute this e-mail or its contents to any
>other person and
>any such actions are unlawful. This e-mail may contain viruses. Infosys
>has taken
>every reasonable precaution to minimize this risk, but is not liable
>for any damage
>you may sustain as a result of any virus in this e-mail. You should
>carry out your
>own virus checks before opening the e-mail or attachment. Infosys
>reserves the
>right to monitor and review the content of all messages sent to or from
>this e-mail
>address. Messages sent to or from this e-mail address may be stored on
>the
>Infosys e-mail system.
>***INFOSYS******** End of Disclaimer ********INFOSYS***
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From goran.brostrom at umu.se  Tue Apr 15 15:54:08 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 15 Apr 2014 15:54:08 +0200
Subject: [R] Trend test for hazard ratios
In-Reply-To: <3dfcdc$gc1e36@ironport9.mayo.edu>
References: <mailman.19.1397556011.24959.r-help@r-project.org>
	<3dfcdc$gc1e36@ironport9.mayo.edu>
Message-ID: <534D3A00.1040203@umu.se>

> On 04/15/2014 05:00 AM, r-help-request at r-project.org wrote:
>> Hello,
>>
>> I have the following problem. I stratified my patient cohort into three
>> ordered groups and performed multivariate adjusted Cox regression analysis
>> on each group separately. Now I would like to calculate a p for trend across
>> the hazard ratios that I got for the three groups. How can I do that if I
>> only have the HR and the confidence interval? For example I got the
>> following HRs for one endpoint:
>>
>> 1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68).
>>
>> There is a trend but how do I calculate if it is significant?

You may treat the log of the estimates as independent observations from 
normal distributions with known (or estimated) variances, and find a 
suitable test statistic in the book

D.J. Bartholomew, R.E. Barlow, H.D. Brunk and J.M. Bremner (1972). 
Statistical Inference under Order Restrictions , Chichester: 
John Wiley and Sons.

G?ran B.

>>
>> Best regards
>>
>> Marcus Kleber
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From spencer.graves at structuremonitoring.com  Tue Apr 15 17:53:15 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 15 Apr 2014 08:53:15 -0700
Subject: [R] get element of list with default?
Message-ID: <534D55EB.6060602@structuremonitoring.com>

Hello:


       Do you know of a simple function to return the value of a named 
element of a list if that exists, and return a default value otherwise?


       It's an easy function to write (e.g., below).  I plan to add this 
to the "Ecfun" package unless I find it in another CRAN package.


       Thanks,
       Spencer


     getElement <- function(element, default, list){
#       get element of list;  return elDefault if absent
         El <- list[[element]]
         if(is.null(El)){
             El <- default
         }
         El
     }



From fisher at plessthan.com  Tue Apr 15 17:58:35 2014
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 15 Apr 2014 08:58:35 -0700
Subject: [R] Displaying "<=" in axis values
Message-ID: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>

R 3.0.2
OS X

Colleagues

In a graphic, the x-axis values
	2, 4, 6, 8, 10, 12

I would like to present these as:
	? 2, ? 4, ? 6, ?8, ? 10, ? 12

I have tried to accomplish this with 
	expression 
and 
	bquote 
without success.  Can someone provide the appropriate code?  

Thanks.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



From gunter.berton at gene.com  Tue Apr 15 18:16:42 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 15 Apr 2014 09:16:42 -0700
Subject: [R] Displaying "<=" in axis values
In-Reply-To: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
References: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
Message-ID: <CACk-te2yOn5Kr6NhS17LUgPUXGmTwHzNfaWp5tfxHwGE6jUS=Q@mail.gmail.com>

Show us your code.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Apr 15, 2014 at 8:58 AM, Dennis Fisher <fisher at plessthan.com> wrote:
> R 3.0.2
> OS X
>
> Colleagues
>
> In a graphic, the x-axis values
>         2, 4, 6, 8, 10, 12
>
> I would like to present these as:
>         ? 2, ? 4, ? 6, ?8, ? 10, ? 12
>
> I have tried to accomplish this with
>         expression
> and
>         bquote
> without success.  Can someone provide the appropriate code?
>
> Thanks.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Tue Apr 15 18:19:15 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 15 Apr 2014 12:19:15 -0400
Subject: [R] Displaying "<=" in axis values
In-Reply-To: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
References: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
Message-ID: <32ADEB6A-B53F-4614-8218-C59E1C8D6653@utoronto.ca>

The following works for me:

x <- rnorm(10)
plot(x, xaxt="n")
axis(side=1, at=axTicks(1),lab=c("? a","? b","? c","? d","= e"))

(In case the characters get mangled in transition:
 I have used le, ge, approx. equal, ne, and equal in this example)

Cheer,s
B.



On 2014-04-15, at 11:58 AM, Dennis Fisher wrote:

> R 3.0.2
> OS X
> 
> Colleagues
> 
> In a graphic, the x-axis values
> 	2, 4, 6, 8, 10, 12
> 
> I would like to present these as:
> 	? 2, ? 4, ? 6, ?8, ? 10, ? 12
> 
> I have tried to accomplish this with 
> 	expression 
> and 
> 	bquote 
> without success.  Can someone provide the appropriate code?  
> 
> Thanks.
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From marc_schwartz at me.com  Tue Apr 15 18:22:56 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 15 Apr 2014 11:22:56 -0500
Subject: [R] get element of list with default?
In-Reply-To: <534D55EB.6060602@structuremonitoring.com>
References: <534D55EB.6060602@structuremonitoring.com>
Message-ID: <D266FB84-65A5-4EA5-A038-55EBD99FC100@me.com>

On Apr 15, 2014, at 10:53 AM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:

> Hello:
> 
> 
>      Do you know of a simple function to return the value of a named element of a list if that exists, and return a default value otherwise?
> 
> 
>      It's an easy function to write (e.g., below).  I plan to add this to the "Ecfun" package unless I find it in another CRAN package.
> 
> 
>      Thanks,
>      Spencer
> 
> 
>    getElement <- function(element, default, list){
> #       get element of list;  return elDefault if absent
>        El <- list[[element]]
>        if(is.null(El)){
>            El <- default
>        }
>        El
>    }


Hi Spencer,

I don't know of a function elsewhere, but you can probably simplify the above with:

  getElement <- function(element, default, list) {
    ifelse(is.null(list[[element]]), default, list[[element]])
  }


MyList <- list(L1 = 1, L2 = 2) 

> MyList
$L1
[1] 1

$L2
[1] 2



> getElement("L1", 5, MyList) 
[1] 1

> getElement("L2", 5, MyList) 
[1] 2

> getElement("L3", 5, MyList) 
[1] 5


You might want to think about the ordering of the function arguments, given typical use, for ease of calling it. For example:

  getElement <- function(list, element, default = SomeValue)

Another consideration is that the above function will only get the element if it is a 'first level' element in the list. If it is in a sub-list of the main list, you would need to think about a recursive approach of some type, along the lines of what ?rapply does.

Regards,

Marc Schwartz



From boris.steipe at utoronto.ca  Tue Apr 15 18:28:32 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 15 Apr 2014 12:28:32 -0400
Subject: [R] Displaying "<=" in axis values
In-Reply-To: <32ADEB6A-B53F-4614-8218-C59E1C8D6653@utoronto.ca>
References: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
	<32ADEB6A-B53F-4614-8218-C59E1C8D6653@utoronto.ca>
Message-ID: <7F1DE110-9B70-484E-9B09-4036CBCFF7BC@utoronto.ca>

... and obviously, if you want the original values:

x <- rnorm(10)
plot(x, xaxt="n")
axis(side=1, at=axTicks(1),labels=paste("?", axTicks(1)))


B.


On 2014-04-15, at 12:19 PM, Boris Steipe wrote:

> The following works for me:
> 
> x <- rnorm(10)
> plot(x, xaxt="n")
> axis(side=1, at=axTicks(1),lab=c("? a","? b","? c","? d","= e"))
> 
> (In case the characters get mangled in transition:
> I have used le, ge, approx. equal, ne, and equal in this example)
> 
> Cheer,s
> B.
> 
> 
> 
> On 2014-04-15, at 11:58 AM, Dennis Fisher wrote:
> 
>> R 3.0.2
>> OS X
>> 
>> Colleagues
>> 
>> In a graphic, the x-axis values
>> 	2, 4, 6, 8, 10, 12
>> 
>> I would like to present these as:
>> 	? 2, ? 4, ? 6, ?8, ? 10, ? 12
>> 
>> I have tried to accomplish this with 
>> 	expression 
>> and 
>> 	bquote 
>> without success.  Can someone provide the appropriate code?  
>> 
>> Thanks.
>> 
>> Dennis
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone: 1-866-PLessThan (1-866-753-7784)
>> Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From marc_schwartz at me.com  Tue Apr 15 18:30:07 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 15 Apr 2014 11:30:07 -0500
Subject: [R] get element of list with default?
In-Reply-To: <D266FB84-65A5-4EA5-A038-55EBD99FC100@me.com>
References: <534D55EB.6060602@structuremonitoring.com>
	<D266FB84-65A5-4EA5-A038-55EBD99FC100@me.com>
Message-ID: <FB0C69AD-4203-44D5-9E0A-C97A972AE601@me.com>


On Apr 15, 2014, at 11:22 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

> On Apr 15, 2014, at 10:53 AM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
> 
>> Hello:
>> 
>> 
>>     Do you know of a simple function to return the value of a named element of a list if that exists, and return a default value otherwise?
>> 
>> 
>>     It's an easy function to write (e.g., below).  I plan to add this to the "Ecfun" package unless I find it in another CRAN package.
>> 
>> 
>>     Thanks,
>>     Spencer
>> 
>> 
>>   getElement <- function(element, default, list){
>> #       get element of list;  return elDefault if absent
>>       El <- list[[element]]
>>       if(is.null(El)){
>>           El <- default
>>       }
>>       El
>>   }
> 
> 
> Hi Spencer,
> 
> I don't know of a function elsewhere, but you can probably simplify the above with:
> 
>  getElement <- function(element, default, list) {
>    ifelse(is.null(list[[element]]), default, list[[element]])
>  }
> 
> 
> MyList <- list(L1 = 1, L2 = 2) 
> 
>> MyList
> $L1
> [1] 1
> 
> $L2
> [1] 2
> 
> 
> 
>> getElement("L1", 5, MyList) 
> [1] 1
> 
>> getElement("L2", 5, MyList) 
> [1] 2
> 
>> getElement("L3", 5, MyList) 
> [1] 5
> 
> 
> You might want to think about the ordering of the function arguments, given typical use, for ease of calling it. For example:
> 
>  getElement <- function(list, element, default = SomeValue)
> 
> Another consideration is that the above function will only get the element if it is a 'first level' element in the list. If it is in a sub-list of the main list, you would need to think about a recursive approach of some type, along the lines of what ?rapply does.
> 
> Regards,
> 
> Marc Schwartz


Spencer,

A quick heads up here. I forgot, that there is already a function called getElement() in base R which appears to be designed to handle S4 objects and slots, lacking the default return value however, where it returns NULL if the 'name' element is not present:

> getElement
function (object, name) 
{
    if (isS4(object)) 
        slot(object, name)
    else object[[name, exact = TRUE]]
}
<bytecode: 0x100905870>
<environment: namespace:base>


Thus, I would suggest calling your variant something else, or wrap the default function in your version, if you need/want to handle S4 objects and slots.

Regards,

Marc



From h.wickham at gmail.com  Tue Apr 15 18:33:26 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 15 Apr 2014 11:33:26 -0500
Subject: [R] get element of list with default?
In-Reply-To: <534D55EB.6060602@structuremonitoring.com>
References: <534D55EB.6060602@structuremonitoring.com>
Message-ID: <CABdHhvEP=XRA-nTkR933CF2=JE5yGGUNiypKWkrn0Qye9ak1Sw@mail.gmail.com>

You really want to use the names of the list since lists can contain
null.  I'd recommend something more like:

getElement <- function(x, i, default) {
  if (i %in% names(x)) return(x[[i]])
  default
}

Hadley

On Tue, Apr 15, 2014 at 10:53 AM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hello:
>
>
>       Do you know of a simple function to return the value of a named
> element of a list if that exists, and return a default value otherwise?
>
>
>       It's an easy function to write (e.g., below).  I plan to add this to
> the "Ecfun" package unless I find it in another CRAN package.
>
>
>       Thanks,
>       Spencer
>
>
>     getElement <- function(element, default, list){
> #       get element of list;  return elDefault if absent
>         El <- list[[element]]
>         if(is.null(El)){
>             El <- default
>         }
>         El
>     }
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/



From rmh at temple.edu  Tue Apr 15 18:42:03 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 15 Apr 2014 12:42:03 -0400
Subject: [R] a question about the output of plot
In-Reply-To: <76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>
References: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
	<534CD379.70707@bitwrit.com.au>
	<76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>
Message-ID: <CAGx1TMB-PkA5To7WYyLy-f9YVDLtwAEAGH6ipmE4CF1asPCqnQ@mail.gmail.com>

Please see R FAQ 7.22

7.22 Why do lattice/trellis graphics not work?
==============================================

The most likely reason is that you forgot to tell R to display the graph.
Lattice functions such as `xyplot()' create a graph object, but do not
display it (the same is true of *ggplot2*
(http://CRAN.R-project.org/package=ggplot2) graphics, and Trellis graphics
in S-PLUS).  The `print()' method for the graph object produces the actual
display.  When you use these functions interactively at the command line,
the result is automatically printed, but in `source()' or inside your own
functions you will need an explicit `print()' statement.

On Tue, Apr 15, 2014 at 5:51 AM, meng <laomeng_3 at 163.com> wrote:
> Yes,it works !
> What's the reason for it?
>
>
> Many thanks!
>
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2014-04-15 14:36:41,"Jim Lemon" <jim at bitwrit.com.au> wrote:
>>On 04/15/2014 11:46 AM, meng wrote:
>>> Hi all:
>>> I met a question about the output of plot.
>>> I want to output 3 plots.
>>> Method1: by function histogram{lattice}
>>> Method2: by function hist{graphics}
>>>
>>>
>>> But method1 failed(the output is empty),and only method 2 works.
>>> I can't find out the reason,and many thanks for your help.
>>>
>>>
>>> #Method1---failed(the output is empty)
>>> library(lattice)
>>> for(i in 1:3)
>>> {
>>> x<-rnorm(10)
>>>
>>>
>>> jpeg(paste("e:\\hist_",i,".jpeg"))
>>> histogram(x)
>>> dev.off()
>>> }
>>>
>>>
>>>
>>>
>>> #Method 2---works
>>> for(i in 1:3)
>>> {
>>> x<-rnorm(10)
>>>
>>>
>>> jpeg(paste("e:\\hist_",i,".jpeg"))
>>> hist(x)
>>> dev.off()
>>> }
>>>
>>Hi meng,
>>Try:
>>
>>print(histogram(x))
>>
>>Jim
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Tue Apr 15 18:45:42 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 15 Apr 2014 17:45:42 +0100
Subject: [R] system()
In-Reply-To: <F62F62F0BF674030900A08456B1584FF@Aragorn>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686945ECC67@DC1VEX10MB001.air.org>	<534C3242.5000500@sapo.pt>
	<F62F62F0BF674030900A08456B1584FF@Aragorn>
Message-ID: <534D6236.6050009@sapo.pt>

Hello,

Thanks, and sorry for the bug.
I used what the op was using [system()] without checking if it worked. 
shell() worked in Windows 7/R 3.1.0.

sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Rui Barradas

Em 15-04-2014 02:26, Daniel Nordlund escreveu:
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Rui Barradas
>> Sent: Monday, April 14, 2014 12:09 PM
>> To: Doran, Harold; r-help at r-project.org
>> Subject: Re: [R] system()
>>
>> Hello,
>>
>> Try instead
>>
>> command <- paste(aa, fnm)
>> system(command)
>>
>> And read the help page for ?paste
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 14-04-2014 20:02, Doran, Harold escreveu:
>>> I need to send a system command to another program from within R but
>> have a small hangup
>>>
>>> I'm trying to do something like this
>>>
>>> system("notepad myfile.txt")
>>>
>>> But, more generally this is happening to multiple files, so I loop over
>> thousands of files. For purposes of an example, my code is something like
>> this, which does not work
>>>
>>> aa <- 'notepad.exe'
>>> fnm <- 'myfile.txt'
>>> system("aa fnm")
>>>
>>> Any suggestions?
>>> Harold
>>>
>
> Harold,
>
> you haven't said what OS you are running under, but given that your example program was notepad.exe I am going to guess some flavor of MS Windows.  The suggestion to use paste() is necessary, but it will probably not be sufficient to solve your problem.  The commands suggested
>
>> command <- paste(aa, fnm)
>> system(command)
>
> freezes R on my Win 7 Pro x64 box using either 64-bit R-3.0.3 or R-3.1.0.  You might try switching to shell() instead of system()
>
>> command <- paste(aa, fnm)
>> shell(command)
>
> However, it all depends on what programs you are trying to run and what behavior you expect.
>
>
> Dan
>
> Daniel Nordlund
> Bothell, WA USA
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From dwinsemius at comcast.net  Tue Apr 15 19:02:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Apr 2014 10:02:14 -0700
Subject: [R] Displaying "<=" in axis values
In-Reply-To: <32ADEB6A-B53F-4614-8218-C59E1C8D6653@utoronto.ca>
References: <FE8B006B-7665-4C02-9B99-43FE243B6CF8@plessthan.com>
	<32ADEB6A-B53F-4614-8218-C59E1C8D6653@utoronto.ca>
Message-ID: <09999C48-FFCE-4992-8639-3B59D0E3FE4B@comcast.net>


On Apr 15, 2014, at 9:19 AM, Boris Steipe wrote:

> The following works for me:
> 
> x <- rnorm(10)
> plot(x, xaxt="n")
> axis(side=1, at=axTicks(1),lab=c("? a","? b","? c","? d","= e"))
> 
> (In case the characters get mangled in transition:
> I have used le, ge, approx. equal, ne, and equal in this example)

I thought the suggestion to use axTicks() was an excellent one. This would generalize it to the construction of the labels argument:

     ..., lab=sapply( paste("?", axTicks(1)), as.expression)    0

-- 
David.
> 
> Cheer,s
> B.
> 
> 
> 
> On 2014-04-15, at 11:58 AM, Dennis Fisher wrote:
> 
>> R 3.0.2
>> OS X
>> 
>> Colleagues
>> 
>> In a graphic, the x-axis values
>> 	2, 4, 6, 8, 10, 12
>> 
>> I would like to present these as:
>> 	? 2, ? 4, ? 6, ?8, ? 10, ? 12
>> 
>> I have tried to accomplish this with 
>> 	expression 
>> and 
>> 	bquote 
>> without success.  Can someone provide the appropriate code?  
>> 
>> Thanks.



David Winsemius
Alameda, CA, USA



From zhaoxing at uw.edu  Tue Apr 15 19:17:58 2014
From: zhaoxing at uw.edu (Xing Zhao)
Date: Tue, 15 Apr 2014 10:17:58 -0700
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <web-505799764@cgpsrv2.cis.mcmaster.ca>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
	<534D23A0.5040102@yorku.ca> <web-505799764@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>

Dear Michael and Fox

Thanks for your elaboration. Combining your explanations would, to my
understanding, lead to the following  calculation of degree of
freedoms.

3 (cubic on the right side of the *interior* knot 8)
+ 3 (cubic on the left side of the *interior* knot 8)
- 1 (two curves must be continuous at the *interior* knot 8)
- 1 (two curves must have 1st order derivative continuous at the
*interior* knot 8)
- 1 (two curves must have 2nd order derivative continuous at the
*interior* knot 8)
- 1 (right side cubic curve must have 2nd order derivative = 0 at the
boundary knot 15 due to the linearity constraint)
- 1 (similar for the left)
= 1, not 2

Where is the problem?

Best,
Xing

On Tue, Apr 15, 2014 at 6:17 AM, John Fox <jfox at mcmaster.ca> wrote:
> Dear Xing Zhao,
>
> To elaborate slightly on Michael's comments, a natural cubic spline with 2 df has one *interior* knot and two boundary knots (as is apparent in the output you provided). The linearity constraint applies beyond the boundary knots.
>
> I hope this helps,
>  John
>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
> On Tue, 15 Apr 2014 08:18:40 -0400
>  Michael Friendly <friendly at yorku.ca> wrote:
>> No, the curves on each side of the know are cubics, joined
>> so they are continuous.  Se the discussion in \S 17.2 in
>> Fox's Applied Regression Analysis.
>>
>> On 4/15/2014 4:14 AM, Xing Zhao wrote:
>> > Dear all
>> >
>> > I understand the definition of Natural Cubic Splines are those with
>> > linear constraints on the end points. However, it is hard to think
>> > about how this can be implement when df=2. df=2 implies there is just
>> > one knot, which, according the the definition, the curves on its left
>> > and its right should be both be lines. This means the whole line
>> > should be a line. But when making some fits. the result still looks
>> > like 2nd order polynomial.
>> >
>> > How to think about this problem?
>> >
>> > Thanks
>> > Xing
>> >
>> > ns(1:15,df =2)
>> >                1           2
>> >   [1,] 0.0000000  0.00000000
>> >   [2,] 0.1084782 -0.07183290
>> >   [3,] 0.2135085 -0.13845171
>> >   [4,] 0.3116429 -0.19464237
>> >   [5,] 0.3994334 -0.23519080
>> >   [6,] 0.4734322 -0.25488292
>> >   [7,] 0.5301914 -0.24850464
>> >   [8,] 0.5662628 -0.21084190
>> >   [9,] 0.5793481 -0.13841863
>> > [10,] 0.5717456 -0.03471090
>> > [11,] 0.5469035  0.09506722
>> > [12,] 0.5082697  0.24570166
>> > [13,] 0.4592920  0.41197833
>> > [14,] 0.4034184  0.58868315
>> > [15,] 0.3440969  0.77060206
>> > attr(,"degree")
>> > [1] 3
>> > attr(,"knots")
>> > 50%
>> >    8
>> > attr(,"Boundary.knots")
>> > [1]  1 15
>> > attr(,"intercept")
>> > [1] FALSE
>> > attr(,"class")
>> > [1] "ns"     "basis"  "matrix"
>> >
>>
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>



From phhs80 at gmail.com  Tue Apr 15 19:23:24 2014
From: phhs80 at gmail.com (Paul Smith)
Date: Tue, 15 Apr 2014 18:23:24 +0100
Subject: [R] Testing correlation of equation in a SUR model fitted by
	systemfit
Message-ID: <CALS=5mrwmeVqPbLdhQwzRXCcfB1wMApaw1W-hjR+cDiTUzH8mA@mail.gmail.com>

Dear All,

How to test whether the correlation in the matrix of correlation of a
two-equations SUR model fitted by package systemfit are significant?

Thanks in advance,

Paul



From marcus.kleber at web.de  Tue Apr 15 19:28:40 2014
From: marcus.kleber at web.de (mkleber74)
Date: Tue, 15 Apr 2014 10:28:40 -0700 (PDT)
Subject: [R] Trend test for hazard ratios
In-Reply-To: <1397470831424-4688729.post@n4.nabble.com>
References: <1397470831424-4688729.post@n4.nabble.com>
Message-ID: <1397582920161-4688837.post@n4.nabble.com>

Hi Terry,

thank you for your suggestion. I tried to do it the way that you described.
I fitted my Cox model with strata and I get coefficients and P values for my
ZlnGalectin in the different strata (see summary below). So am not so
familiar with R so please excuse my perhaps stupid questions but are the P
values below like "p=2.386e-06" something similar like my P for trend (they
seem to be very low?) or if not how can I calculate it now? 


> summary(fit_mort)
Call:
coxph(formula = Surv(obstime2010, death2010) ~ ZlnGalectin3 * 
    strata(CKD_KDIGO), data = gal.df)

  n= 2573, number of events= 758 
   (743 observations deleted due to missingness)

                                                                                           
coef       exp(coef)   se(coef)      z    Pr(>|z|)
ZlnGalectin3                                                                         
0.20725   1.23029  0.07064  2.934   0.00335 **
ZlnGalectin3:strata(CKD_KDIGO)CKD_KDIGO=60,01 - 90,00  0.04165   1.04253 
0.09178  0.454   0.65000 
ZlnGalectin3:strata(CKD_KDIGO)CKD_KDIGO=90,01+           -0.06830   0.93398 
0.12113 -0.564  0.57282 
                                                                              
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

                                                                                         
exp(coef) exp(-coef) lower .95  upper .95
ZlnGalectin3                                                                            
1.230     0.8128    1.0712   1.413
ZlnGalectin3:strata(CKD_KDIGO)CKD_KDIGO=60,01 - 90,00     1.043     0.9592   
0.8709   1.248
ZlnGalectin3:strata(CKD_KDIGO)CKD_KDIGO=90,01+              0.934     1.0707   
0.7366   1.184
                                                                      
Concordance= 0.559  (se = 0.017 )
Rsquare= 0.011   (max possible= 0.978 )
Likelihood ratio test = 28.87  on 3 df,   p=2.386e-06
Wald test               = 28.64  on 3 df,   p=2.665e-06
Score (logrank) test = 28.46  on 3 df,   p=2.906e-06



--
View this message in context: http://r.789695.n4.nabble.com/Trend-test-for-hazard-ratios-tp4688729p4688837.html
Sent from the R help mailing list archive at Nabble.com.



From dwinsemius at comcast.net  Tue Apr 15 19:35:12 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Apr 2014 10:35:12 -0700
Subject: [R] Save multiple plots as pdf or jpeg
In-Reply-To: <OF6E721B9E.F3159994-ON80257CBB.003247B4-80257CBB.0032D109@uk.royalsun.com>
References: <OF6E721B9E.F3159994-ON80257CBB.003247B4-80257CBB.0032D109@uk.royalsun.com>
Message-ID: <8C19E3E7-0519-4C5D-8F05-63879E5A91BD@comcast.net>


On Apr 15, 2014, at 2:09 AM, Pavneet Arora wrote:

> As a result, the pdf takes forever to load and doesn?t let me print, as it 
> runs out of memory. I was wondering if there is a way if I can save each 
> plot as jpeg and then export it on pdf. Will that make it quicker in 
> loading? If so, how can I do this? And if not, then what are the 
> alternatives.

Here's the problem

>  1355615 obs. of ....

... followed  by:

 qqnorm(nums2[,k],col="lightblue",main=names(nums2)[k]) 
....

PDF files may take multiple text characters to include one point.

And the further problem is linked to your chosen format.

> 
> Also when saving as jpeg in R, I realise there is a wildcard in filenames, 
> i.e.. 6 plots can be saved as:
> jpeg(filename="foo%03d.jpeg",. . . )
> dev.off()
'
 As far as I know, jpeg does not have a multi-page option. You can deliver jpegs embedded in other formats like .doc or pdf but those would be mediated by programs designed to do that.

The tiff format is bitmapped and has multi-page options.

-- 

David Winsemius
Alameda, CA, USA



From jfox at mcmaster.ca  Tue Apr 15 19:54:35 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 15 Apr 2014 13:54:35 -0400
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>	<534D23A0.5040102@yorku.ca>
	<web-505799764@cgpsrv2.cis.mcmaster.ca>
	<CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>
Message-ID: <003901cf58d3$c36b3300$4a419900$@mcmaster.ca>

Dear Xing,

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Xing Zhao
> Sent: Tuesday, April 15, 2014 1:18 PM
> To: John Fox
> Cc: r-help at r-project.org; Michael Friendly
> Subject: Re: [R] The explanation of ns() with df =2
> 
> Dear Michael and Fox
> 
> Thanks for your elaboration. Combining your explanations would, to my
> understanding, lead to the following  calculation of degree of
> freedoms.
> 
> 3 (cubic on the right side of the *interior* knot 8)
> + 3 (cubic on the left side of the *interior* knot 8)
> - 1 (two curves must be continuous at the *interior* knot 8)

You shouldn't subtract 1 for continuity since you haven't allowed a
different level on each side of the knot (that is your initial counting of 3
parameters for the cubic doesn't include a constant).

Best,
 John

> - 1 (two curves must have 1st order derivative continuous at the
> *interior* knot 8)
> - 1 (two curves must have 2nd order derivative continuous at the
> *interior* knot 8)
> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
> boundary knot 15 due to the linearity constraint)
> - 1 (similar for the left)
> = 1, not 2
> 
> Where is the problem?
> 
> Best,
> Xing
> 
> On Tue, Apr 15, 2014 at 6:17 AM, John Fox <jfox at mcmaster.ca> wrote:
> > Dear Xing Zhao,
> >
> > To elaborate slightly on Michael's comments, a natural cubic spline
> with 2 df has one *interior* knot and two boundary knots (as is
> apparent in the output you provided). The linearity constraint applies
> beyond the boundary knots.
> >
> > I hope this helps,
> >  John
> >
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> > On Tue, 15 Apr 2014 08:18:40 -0400
> >  Michael Friendly <friendly at yorku.ca> wrote:
> >> No, the curves on each side of the know are cubics, joined
> >> so they are continuous.  Se the discussion in \S 17.2 in
> >> Fox's Applied Regression Analysis.
> >>
> >> On 4/15/2014 4:14 AM, Xing Zhao wrote:
> >> > Dear all
> >> >
> >> > I understand the definition of Natural Cubic Splines are those
> with
> >> > linear constraints on the end points. However, it is hard to think
> >> > about how this can be implement when df=2. df=2 implies there is
> just
> >> > one knot, which, according the the definition, the curves on its
> left
> >> > and its right should be both be lines. This means the whole line
> >> > should be a line. But when making some fits. the result still
> looks
> >> > like 2nd order polynomial.
> >> >
> >> > How to think about this problem?
> >> >
> >> > Thanks
> >> > Xing
> >> >
> >> > ns(1:15,df =2)
> >> >                1           2
> >> >   [1,] 0.0000000  0.00000000
> >> >   [2,] 0.1084782 -0.07183290
> >> >   [3,] 0.2135085 -0.13845171
> >> >   [4,] 0.3116429 -0.19464237
> >> >   [5,] 0.3994334 -0.23519080
> >> >   [6,] 0.4734322 -0.25488292
> >> >   [7,] 0.5301914 -0.24850464
> >> >   [8,] 0.5662628 -0.21084190
> >> >   [9,] 0.5793481 -0.13841863
> >> > [10,] 0.5717456 -0.03471090
> >> > [11,] 0.5469035  0.09506722
> >> > [12,] 0.5082697  0.24570166
> >> > [13,] 0.4592920  0.41197833
> >> > [14,] 0.4034184  0.58868315
> >> > [15,] 0.3440969  0.77060206
> >> > attr(,"degree")
> >> > [1] 3
> >> > attr(,"knots")
> >> > 50%
> >> >    8
> >> > attr(,"Boundary.knots")
> >> > [1]  1 15
> >> > attr(,"intercept")
> >> > [1] FALSE
> >> > attr(,"class")
> >> > [1] "ns"     "basis"  "matrix"
> >> >
> >>
> >>
> >> --
> >> Michael Friendly     Email: friendly AT yorku DOT ca
> >> Professor, Psychology Dept. & Chair, Quantitative Methods
> >> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> >> 4700 Keele Street    Web:   http://www.datavis.ca
> >> Toronto, ONT  M3J 1P3 CANADA
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Apr 15 17:17:47 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Apr 2014 08:17:47 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397544324.94583.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
Message-ID: <1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi Atem,
May be this works.
### Q1: working directory: Observed #Only one file per Site.  Assuming this is the
### case for the full dataset, then I guess there is no need to average
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) {
    lines1 <- readLines(x2)
    header1 <- lines1[1:2]
    dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE, 
        skip = 2)
    colnames(dat1) <- Reduce(paste, strsplit(header1, ","))
    dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

 lst3 <- lst2[sapply(seq_along(lst2),function(i){lstN <- sapply(lst2[[i]],function(x) is.integer(ncol(x)))})]
length(lst2)
#[1] 120
 length(lst3)
#[1] 119

library(plyr)
library(stringr)

lst4 <- setNames(lapply(seq_along(lst3), function(i) {
    lapply(lst3[[i]], function(x) {
        names(x)[-1] <- paste(names(x)[-1], names(lst1)[i], sep = "_")
        names(x) <- str_trim(names(x))
        x
    })[[1]]
}), names(lst3))
df1 <- join_all(lst4, by = "Year")
dim(df1)
# [1] 9 27311

dimCol <- sapply(split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1])), function(x) {
    df2 <- df1[, x]
    df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
        seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
    ncol(df3)
})

lst5 <- split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1]))

lapply(seq_along(lst5), function(i) {
    df2 <- df1[, lst5[[i]]]
    df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
        seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
     write.csv(df3, paste0(paste(getwd(), "final", paste(names(lst4)[[i]], "Quantile", 
     sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
    function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
dir.create("Indices")
 sapply(ReadOut1, dim)[,1:3]  ##different dimensions
#     [,1] [,2] [,3]
#[1,]  101  101  101
#[2,]  157  258  258

names1 <- unlist(lapply(ReadOut1, function(x) names(x)[-1]))
names2 <- gsub("\\_.*", "", names1)
names3 <- unique(gsub("[.]", " ", names2))

length(names3)
#[1] 264
#lstNew <- simplify2array(ReadOut1)  ###results you got
# nrow(lstNew)
#NULL####

ReadOut2 <-  lapply(seq_along(ReadOut1),function(i) {df2 <- ReadOut1[[i]]; df3 <-as.data.frame(matrix(NA,nrow=101,ncol=length(names3), dimnames=list(NULL, names3))); names(df2) <- gsub("[.]"," ", gsub("\\_.*","", names(df2))); df2 <- df2[,-1]; df3[,match(names(df2), names(df3))] <- df2; df3})

lstNew <- simplify2array(ReadOut2)
 nrow(lstNew)
#[1] 264

 lapply(1:nrow(lstNew), function(i) { dat1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE); colnames(dat1) <- c("Percentiles", paste(names(lst3), rep(rownames(lstNew)[i],length(lst3)),sep="_")); write.csv(dat1,paste0(paste(getwd(), "Indices", gsub(" ", "_",rownames(lstNew)[i]), sep="/"),".csv"),row.names=FALSE, quote=FALSE)})


## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
    function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
#[1] 264

ReadOut2[[1]][1:3,1:3]
#  Percentiles G100_pav.ANN G101_pav.ANN
#1          0%     0.766900      0.96240
#2          1%     0.796132      0.96572
#3          2%     0.825364      0.96904


Attached is the file.

A.K.



On Tuesday, April 15, 2014 4:00 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
I tried all codes for observations. All others work great except this (probably due to different dimensions.
What I did is that I took the Observed.zip file, deleted the station which had no data and applied the code. However, this section of the code did not work. The problem is that lstNew is NULL. So, nothing is actually written to "Indices".

I will check ReadOut1 when I get up from sleep.

Thanks,
Atem.

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]?
lstNew <- simplify2array(ReadOut1)
nrow(lstNew)?
#[1] NULL?
lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],??length(lst1)), sep = "_")) write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),??".csv"), row.names = FALSE, quote = FALSE)
})?
===================================================================================================================


On Tuesday, April 15, 2014 12:45 AM, arun <smartpink111 at yahoo.com> wrote:
HI? Atem,

No problem.? Hope it works for Observation files too.? Remember that before you run the same code for sample in Observation, check the dimensions of the files (as I did previously).? If there is change of dimensions, make them the same dimensions using the methods I showed.? Then, I guess it should work.
A.K.






On Tuesday, April 15, 2014 2:21 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
All codes for simulation files work great.
I will try the code for observations and let you know.
Thanks very much.
Atem.








On Tuesday, April 15, 2014 12:01 AM, arun <smartpink111 at yahoo.com> wrote:
Yes,
my new solution ignores such cases.







On Monday, April 14, 2014 11:58 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Please ignore any such site.
I will check it and include in the analysis.
Thanks,
Atem.



On Monday, April 14, 2014 9:34 PM, arun <smartpink111 at yahoo.com> wrote:



Hi,

I looked at your Observed.zip.? In that one of the file is without any data:
GG83_Sim.csv.ind.csv
The contents of the file are just:

Year??? 
Year??? 
trend??? 
p??? < 


A.K.


On Monday, April 14, 2014 10:41 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Q1) Please try to correct the error using the larger data set (Sample.zip). The issue is that once you write the codes and restrict it to smaller data sets, I find it difficult to generalize it to larger data sets.

Q2) From the Quantilecode2.txt you just sent, you forgot to do the following section using the Observed.zip file. I tried to run the code to section Q1 in Quantilecode2.txt using a larger data set and received the same error :Error in 2:nrow(lstNew) : argument of length 0. I have attached a larger data set too for you to generalize the code to suit the larger data set. Please do not forget to include the code below in the final code of Q2.


Once you fix these two, I should be able to fix the rest following these examples.

Thanks AK. Sorry for overloading you with much work.
Atem.

#==============================================================================================================
dir.create("Indices")?
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1) lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],? length(lst1)), sep = "_"))?
write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),? ".csv"), row.names = FALSE, quote = FALSE)
})? 
## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257
head(ReadOut2[[1]], 2) 

#==============================================================================================================




On Monday, April 14, 2014 8:07 PM, arun <smartpink111 at yahoo.com> wrote:

HI,

Please send your emails in plain text.? If you had looked at the dimensions of `lst2`:
sapply(lst2,function(x) sapply(x,ncol))[1:6,]
? ???G100 G101 G102 G103 G104 G105 G106 G107 G108 G109 G110 G111 G112 G113 G114
[1,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 247
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257
[4,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258
[5,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???G115 G116 G117 G118 G119 G120 GG10 GG11 GG12 GG13 GG14 GG15 GG16 GG17 GG18
[1,]? 258? 247? 256? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[2,]? 258? 250? 257? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 247? 256? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 256
[4,]? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[5,]? 258? 257? 258? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 257? 249? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???GG19 GG20 GG21 GG22 GG23 GG24 GG25 GG26 GG27 GG28
[1,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 257? 258? 256? 257? 258? 258? 258? 258
[4,]? 258? 257? 258? 258? 258? 257? 258? 258? 258? 258
[5,]? 258? 258? 257? 258? 257? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258 


#the dimensions are not consistent for the Simulations
within each Site.? My codes assumed that all the datasets were having the same number of columns, rows etc.






On Monday, April 14, 2014 6:26 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
I have another request for help.
Attached is a larger file (~27MB) for sample.zip. All files are same as previous except that I am using more sites to do the same thing that you did with sample.zip.

When generalizing Quantilecode.R to many sites, I receive an error when I run:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)

lapply(2:nrow(lstNew), function(i) {
? dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE)
? colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? length(lst1)), sep = "_"))
? write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),?
? ? ? ? ? ? ? ? ? ? ? ? ?".csv"), row.names = FALSE, quote = FALSE)
})

and I get this:
Error in 2:nrow(lstNew) : argument of length 0


I have tried a few tricks but could not overcome the error message.

Please help!
Atem.

sample (1).zip
Zilefac Elvis shared from Dropbox??
View on www.dropbox.com Preview by Yahoo??

On Monday, April 14, 2014 9:22 AM, arun <smartpink111 at yahoo.com> wrote:

Ok
. I got the results but mynet is down. Will send once it gets fixed

----------
Sent from my Nokia

------Original message------
From: zilefacelvis at yahoo.com <zilefacelvis at yahoo.com>
To: "arun" <smartpink111 at yahoo.com>
Date: Monday, April 14, 2014 3:01:38 PM GMT
Subject: Re: Re: Quantile and rowMean from multiple files in a folder





In the Observed.zip I
have just one file per site while in sample.zip I have 100 files(Sims) per site.





Thanks,


Atem.

------ Original Message ------



From : arun
To : Zilefac Elvis;
Sent : 14-04-2014 00:12
Subject : Re: Quantile and rowMean from multiple files in a folder
One more doubt, do you have more than one files per Site??In the example, it was just one file per Site.? ? ? On Monday, April 14, 2014 2:08 AM, arun? wrote: Hi, The problem is in the different dimensions of the Observed datasets.? sapply(seq_along(lst2),function(i){lstN<- lapply(lst2[[i]],function(x) x[,-1]);sapply(lstN,function(x) nrow(x))}) ##after removing the trend and P value rows #[1] 9 9 9 8 2 9? ? If you want to take the average, is it through filling NAs for those years that are missing in the files?? A.K.? ? ???On Monday, April 14, 2014 1:05 AM, Zilefac Elvis?
wrote:? Hi AK,? Q1) Please apply the Quantilecode.R to Observed.zip (attached). I tried but received an error which was self-explanatory but I could not change the dimensions in the code.???Q2) Please apply Quantilecode.R to both sample.zip and observed.zip. Here, instead of doing quantile(y, seq(0, 1, by = 0.01), take colMeans of the indices.? ? I have tried to solve both Q1 and Q2 but still unable to control the dimensions.? Thanks, Atem. On Sunday, April 13, 2014 9:05 AM, arun? wrote:? ? Hi Atem,? On my end, the codes are not formatted in the email as seen in the screen of formatR GUI.? I am attaching the .R file in case there is some difficulty for you. Arun? ? On Sunday, April 13, 2014 10:54 AM, arun? wrote: Hi,? I am formatting the codes using library(formatR).?Hopefully, it will not be mangled in the email. dir.create("final") lst1<- split(list.files(pattern
=".csv"), gsub("\\_.*","", list.files(pattern =".csv")))? lst2<- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1<- readLines(x2) header1<- lines1[1:2] dat1<- read.table(text = lines1, header = FALSE, sep =",", stringsAsFactors = FALSE,?skip = 2) colnames(dat1)<- Reduce(paste, strsplit(header1,",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ] }))? library(plyr)???lapply(seq_along(lst2), function(i) { lstN<- lapply(lst2[[i]], function(x) x[, -1]) lstQ1<- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(0, 1,?by = 0.01), na.rm = TRUE))(x)) arr1<- array(unlist(lstQ1), dim = c(dim(lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,?lapply(lstQ1, names)[[1]])) res<- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res)<- gsub("","_", colnames(res)) res1<- data.frame(Percentiles = paste0(seq(0, 100, by = 1),"%"), res, stringsAsFactors = FALSE) write.csv(res1,
paste0(paste(getwd(),"final", paste(names(lst1)[[i]],"Quantile",?sep ="_"), sep ="/"),".csv"), row.names = FALSE, quote = FALSE) })? ReadOut1<- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) sapply(ReadOut1, dim) #????[,1] [,2] #[1,]?101?101 #[2,]?258?258? lapply(ReadOut1,function(x) x[1:2,1:3]) #[[1]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.68566?7.09702 #2? ? ? ? ?1% -12.59062?7.15338 # #[[2]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.75516 6.841840 #2? ? ? ? ?1% -12.68244 6.910664? ? ###Q2:? dir.create("Indices") names1<- lapply(ReadOut1, function(x) names(x))[[1]] lstNew<- simplify2array(ReadOut1) lapply(2:nrow(lstNew),
function(i) { dat1<- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1)<- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?length(lst1)), sep ="_")) write.csv(dat1, paste0(paste(getwd(),"Indices", rownames(lstNew)[i], sep ="/"), ".csv"), row.names = FALSE, quote = FALSE) }) ## Output2: ReadOut2<- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) length(ReadOut2) # [1] 257? ? head(ReadOut2[[1]], 2) #?Percentiles G100_pav_ANN G101_pav_ANN #1? ? ? ? ?0%????1.054380????1.032740 #2? ? ? ? ?1% ?1.069457????1.045689? ? A.K.? ? ? ? ? ???On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis? wrote:? Hi AK, Q1) I need your help again. Using the
previous data (attached) and the previous code below,instead of taking rowMeans, let's do quantile(x,seq(0,1,by=0.01)).???Delete the last 2 rows (Trend and p<) in each file before doing quantile(x,seq(0,1,by=0.01)).? For example, assume that I want to calculate quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do so for the 5 sims of site G100 and then take their average. This will be approximately close to the true value than just calculating quantile(x,seq(0,1,by=0.01)) from one sim. Please dothis same thing for all the files.? So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01)) calculated from all sims in that Site.? Output? The number of files in"final" remains the same (2 files). The"Year" column(will be replaced) will contain?the names of quantile(x,seq(0,1,by=0.01)) such as?0%? ? ? ????1%? ? ? ????2%? ?
? ????3%? ? ? ????4%? ? ? ????5%? ? ? ????6%, ..., 98%? ? ? ?99%? ? ????100% . You can give this column any name such as"Percentiles".???Q2)?From the folder"final", please go to each file identified by site name, take a column, say col1 of txav?from each file, create a dataframe whose colnames are site codes (names of files in"final"). Create a folder called"Indices" and place this dataframe in it. The filename for the dataframe is txav, say. So, in"Indices", you will have one file having 3 columns [, c(Percentiles, G100,G101)]. The idea is that I want to be able to pick any column from files in"final" and form a dataframe from which I will generate my qqplot or boxplot.? Thanks very much AK. Atem This should be the final step of this my drama, at least for now.
#==============================================================================================================? dir.create("final") lst1<- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2<-?lapply(lst1,function(x1) lapply(x1, function(x2) {lines1<- readLines(x2); header1<- lines1[1:2]; dat1<- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1)<- Reduce(paste,strsplit(header1,","));dat1}))? lstYear<- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]])? ? lapply(seq_along(lst2),function(i) {lstN<-lapply(lst2[[i]],function(x) x[,-1]); arr1<- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res<- cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res)<- gsub("\\_$","",gsub("","_",names(res))); res[,1]<- gsub("<","",res[,1]);
write.csv(res,paste0(paste(getwd(),"final",names(lst1) [[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)?})? ???#====================================================================================================??
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Quantilecode2ObservedNew.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/9ce08982/attachment-0002.txt>

From anthonyromar at live.com  Tue Apr 15 19:33:10 2014
From: anthonyromar at live.com (antony romar)
Date: Tue, 15 Apr 2014 23:03:10 +0530
Subject: [R] R - Need Help : Using R's qcc package in .Net Appln
Message-ID: <BAY179-W233561FE59147F616E4750AB500@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/d4f57a17/attachment-0001.pl>

From endri81 at gmail.com  Tue Apr 15 20:43:32 2014
From: endri81 at gmail.com (DrunkenPhD)
Date: Tue, 15 Apr 2014 11:43:32 -0700 (PDT)
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <534A7E76.4020500@bitwrit.com.au>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
Message-ID: <bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>

Sorry Jim not for my beginner level :(((

So if my data are like this :

x                             y                   City          Village

19.9437314          40.7086377          120         425

20.2214171          41.4924336          1              1

20.0955891          39.9481364          4              4

20.9506636          40.6447347          10           15

how do I plot for every point(x,y) a pie chart with slices(City,Village)?
Regards


how do I plot for every point(x,y) a pie chart with slices(City,Village)?


 



 



 



 



 



 

From monaly.mistry at gmail.com  Tue Apr 15 19:02:08 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Tue, 15 Apr 2014 18:02:08 +0100
Subject: [R] using for loop for data frame
Message-ID: <CANpv+66OrVpnZd++MJDd8JMb4yLkoVfbxSZp=gdgAgVeafO8eA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/c2645f6e/attachment-0001.pl>

From monaly.mistry at gmail.com  Tue Apr 15 19:23:19 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Tue, 15 Apr 2014 18:23:19 +0100
Subject: [R] nearest neighbour
In-Reply-To: <533DC341.7020505@auckland.ac.nz>
References: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>
	<533DC341.7020505@auckland.ac.nz>
Message-ID: <CANpv+67QMOssPE6vrE8_Cq6DNh5MxK4Zx_dPXhru9DfWdsgGvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/9b0be917/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Tue Apr 15 22:04:44 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 15 Apr 2014 13:04:44 -0700
Subject: [R] get element of list with default?
In-Reply-To: <CABdHhvEP=XRA-nTkR933CF2=JE5yGGUNiypKWkrn0Qye9ak1Sw@mail.gmail.com>
References: <534D55EB.6060602@structuremonitoring.com>
	<CABdHhvEP=XRA-nTkR933CF2=JE5yGGUNiypKWkrn0Qye9ak1Sw@mail.gmail.com>
Message-ID: <534D90DC.5070107@structuremonitoring.com>

Thanks to Marc Schwartz and Hadley Wickham:


       Based on their comments, I think I'll add a combination of 
Hadley's code and getElement{base} Ecfun in a form like 
getElement2(object, name, default).


       Best Wishes,
       Spencer


On 4/15/2014 9:33 AM, Hadley Wickham wrote:
> You really want to use the names of the list since lists can contain
> null.  I'd recommend something more like:
>
> getElement <- function(x, i, default) {
>    if (i %in% names(x)) return(x[[i]])
>    default
> }
>
> Hadley
>
> On Tue, Apr 15, 2014 at 10:53 AM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> Hello:
>>
>>
>>        Do you know of a simple function to return the value of a named
>> element of a list if that exists, and return a default value otherwise?
>>
>>
>>        It's an easy function to write (e.g., below).  I plan to add this to
>> the "Ecfun" package unless I find it in another CRAN package.
>>
>>
>>        Thanks,
>>        Spencer
>>
>>
>>      getElement <- function(element, default, list){
>> #       get element of list;  return elDefault if absent
>>          El <- list[[element]]
>>          if(is.null(El)){
>>              El <- default
>>          }
>>          El
>>      }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From Brent.D.Mast at hud.gov  Tue Apr 15 22:22:59 2014
From: Brent.D.Mast at hud.gov (Mast, Brent D)
Date: Tue, 15 Apr 2014 16:22:59 -0400
Subject: [R] lm predictions for rows with missing y values
Message-ID: <598B1AFF65DDEB4083C14C81FF2CC0C304A4181EA7@ELANNEPV115.exh.prod.hud.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/9741b360/attachment-0001.pl>

From cadeb at usgs.gov  Tue Apr 15 22:26:59 2014
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 15 Apr 2014 14:26:59 -0600
Subject: [R] indexing names for looping across computations done on pairs of
	matrices
Message-ID: <CAM5M9BRxdmoEs1su80X7F8V0YYbMDUjj-e6CXUHY5iG8rf1n6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140415/64ee4c53/attachment-0001.pl>

From zilefacelvis at yahoo.com  Tue Apr 15 22:38:06 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 15 Apr 2014 13:38:06 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397544324.94583.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1397594286.23631.YahooMailNeo@web160602.mail.bf1.yahoo.com>

Hi AK,
Thanks very much. I worked great.
Many thanks.
Atem.


On Tuesday, April 15, 2014 9:20 AM, arun <smartpink111 at yahoo.com> wrote:


Hi Atem,
May be this works.
### Q1: working directory: Observed #Only one file per Site.? Assuming this is the
### case for the full dataset, then I guess there is no need to average
dir.create("final")
lst1 <- split(list.files(pattern = ".csv"), gsub("\\_.*", "", list.files(pattern = ".csv")))

lst2 <- lapply(lst1, function(x1) lapply(x1, function(x2) {
? ? lines1 <- readLines(x2)
? ? header1 <- lines1[1:2]
? ? dat1 <- read.table(text = lines1, header = FALSE, sep = ",", stringsAsFactors = FALSE, 
? ? ? ? skip = 2)
? ? colnames(dat1) <- Reduce(paste, strsplit(header1, ","))
? ? dat1[-c(nrow(dat1), nrow(dat1) - 1), ]
}))

lst3 <- lst2[sapply(seq_along(lst2),function(i){lstN <- sapply(lst2[[i]],function(x) is.integer(ncol(x)))})]
length(lst2)
#[1] 120
length(lst3)
#[1] 119

library(plyr)
library(stringr)

lst4 <- setNames(lapply(seq_along(lst3), function(i) {
? ? lapply(lst3[[i]], function(x) {
? ? ? ? names(x)[-1] <- paste(names(x)[-1], names(lst1)[i], sep = "_")
? ? ? ? names(x) <- str_trim(names(x))
? ? ? ? x
? ? })[[1]]
}), names(lst3))
df1 <- join_all(lst4, by = "Year")
dim(df1)
# [1] 9 27311

dimCol <- sapply(split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1])), function(x) {
? ? df2 <- df1[, x]
? ? df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
? ? ? ? seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
? ? ncol(df3)
})

lst5 <- split(names(df1)[-1], gsub(".*\\_", "", names(df1)[-1]))

lapply(seq_along(lst5), function(i) {
? ? df2 <- df1[, lst5[[i]]]
? ? df3 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), numcolwise(function(y) quantile(y, 
? ? ? ? seq(0, 1, by = 0.01), na.rm = TRUE))(df2), stringsAsFactors = FALSE)
? ?  write.csv(df3, paste0(paste(getwd(), "final", paste(names(lst4)[[i]], "Quantile", 
? ?  sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
dir.create("Indices")
sapply(ReadOut1, dim)[,1:3]? ##different dimensions
#? ?  [,1] [,2] [,3]
#[1,]? 101? 101? 101
#[2,]? 157? 258? 258

names1 <- unlist(lapply(ReadOut1, function(x) names(x)[-1]))
names2 <- gsub("\\_.*", "", names1)
names3 <- unique(gsub("[.]", " ", names2))

length(names3)
#[1] 264
#lstNew <- simplify2array(ReadOut1)? ###results you got
# nrow(lstNew)
#NULL####

ReadOut2 <-? lapply(seq_along(ReadOut1),function(i) {df2 <- ReadOut1[[i]]; df3 <-as.data.frame(matrix(NA,nrow=101,ncol=length(names3), dimnames=list(NULL, names3))); names(df2) <- gsub("[.]"," ", gsub("\\_.*","", names(df2))); df2 <- df2[,-1]; df3[,match(names(df2), names(df3))] <- df2; df3})

lstNew <- simplify2array(ReadOut2)
nrow(lstNew)
#[1] 264

lapply(1:nrow(lstNew), function(i) { dat1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE); colnames(dat1) <- c("Percentiles", paste(names(lst3), rep(rownames(lstNew)[i],length(lst3)),sep="_")); write.csv(dat1,paste0(paste(getwd(), "Indices", gsub(" ", "_",rownames(lstNew)[i]), sep="/"),".csv"),row.names=FALSE, quote=FALSE)})


## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
#[1] 264

ReadOut2[[1]][1:3,1:3]
#? Percentiles G100_pav.ANN G101_pav.ANN
#1? ? ? ? ? 0%? ?  0.766900? ? ? 0.96240
#2? ? ? ? ? 1%? ?  0.796132? ? ? 0.96572
#3? ? ? ? ? 2%? ?  0.825364? ? ? 0.96904


Attached is the file.

A.K.




On Tuesday, April 15, 2014 4:00 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
I tried all codes for observations. All others work great except this (probably due to different dimensions.
What I did is that I took the Observed.zip file, deleted the station which had no data and applied the code. However, this section of the code did not work. The problem is that lstNew is NULL. So, nothing is actually written to "Indices".

I will check ReadOut1 when I get up from sleep.

Thanks,
Atem.

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]?
lstNew <- simplify2array(ReadOut1)
nrow(lstNew)?
#[1] NULL?
lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],??length(lst1)), sep = "_")) write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),??".csv"), row.names = FALSE, quote = FALSE)
})?
===================================================================================================================


On Tuesday, April 15, 2014 12:45 AM, arun <smartpink111 at yahoo.com> wrote:
HI? Atem,

No problem.? Hope it works for Observation files too.? Remember that before you run the same code for sample in Observation, check the dimensions of the files (as I did previously).? If there is change of dimensions, make them the same dimensions using the methods I showed.? Then, I guess it should work.
A.K.






On Tuesday, April 15, 2014 2:21 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
All codes for simulation files work great.
I will try the code for observations and let you know.
Thanks very much.
Atem.








On Tuesday, April 15, 2014 12:01 AM, arun <smartpink111 at yahoo.com> wrote:
Yes,
my new solution ignores such cases.







On Monday, April 14, 2014 11:58 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Please ignore any such site.
I will check it and include in the analysis.
Thanks,
Atem.



On Monday, April 14, 2014 9:34 PM, arun <smartpink111 at yahoo.com> wrote:



Hi,

I looked at your Observed.zip.? In that one of the file is without any data:
GG83_Sim.csv.ind.csv
The contents of the file are just:

Year??? 
Year??? 
trend??? 
p??? < 


A.K.


On Monday, April 14, 2014 10:41 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Q1) Please try to correct the error using the larger data set (Sample.zip). The issue is that once you write the codes and restrict it to smaller data sets, I find it difficult to generalize it to larger data sets.

Q2) From the Quantilecode2.txt you just sent, you forgot to do the following section using the Observed.zip file. I tried to run the code to section Q1 in Quantilecode2.txt using a larger data set and received the same error :Error in 2:nrow(lstNew) : argument of length 0. I have attached a larger data set too for you to generalize the code to suit the larger data set. Please do not forget to include the code below in the final code of Q2.


Once you fix these two, I should be able to fix the rest following these examples.

Thanks AK. Sorry for overloading you with much work.
Atem.

#==============================================================================================================
dir.create("Indices")?
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1) lapply(2:nrow(lstNew), function(i) { dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],? length(lst1)), sep = "_"))?
write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),? ".csv"), row.names = FALSE, quote = FALSE)
})? 
## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
length(ReadOut2)
# [1] 257
head(ReadOut2[[1]], 2) 

#==============================================================================================================




On Monday, April 14, 2014 8:07 PM, arun <smartpink111 at yahoo.com> wrote:

HI,

Please send your emails in plain text.? If you had looked at the dimensions of `lst2`:
sapply(lst2,function(x) sapply(x,ncol))[1:6,]
? ???G100 G101 G102 G103 G104 G105 G106 G107 G108 G109 G110 G111 G112 G113 G114
[1,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 247
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257
[4,]? 258? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258
[5,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???G115 G116 G117 G118 G119 G120 GG10 GG11 GG12 GG13 GG14 GG15 GG16 GG17 GG18
[1,]? 258? 247? 256? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[2,]? 258? 250? 257? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 247? 256? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 256
[4,]? 258? 258? 258? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 257? 258
[5,]? 258? 257? 258? 258? 258? 256? 258? 258? 258? 258? 258? 258? 258? 258? 258
[6,]? 258? 257? 249? 257? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
? ???GG19 GG20 GG21 GG22 GG23 GG24 GG25 GG26 GG27 GG28
[1,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[2,]? 258? 258? 258? 258? 258? 258? 258? 258? 258? 258
[3,]? 258? 258? 257? 258? 256? 257? 258? 258? 258? 258
[4,]? 258? 257? 258? 258? 258? 257? 258? 258? 258? 258
[5,]? 258? 258? 257? 258? 257? 258? 258? 258? 258? 258
[6,]? 258? 258? 258? 258? 257? 258? 258? 258? 258? 258 


#the dimensions are not consistent for the Simulations
within each Site.? My codes assumed that all the datasets were having the same number of columns, rows etc.






On Monday, April 14, 2014 6:26 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,
I have another request for help.
Attached is a larger file (~27MB) for sample.zip. All files are same as previous except that I am using more sites to do the same thing that you did with sample.zip.

When generalizing Quantilecode.R to many sites, I receive an error when I run:

dir.create("Indices")
names1 <- lapply(ReadOut1, function(x) names(x))[[1]]
lstNew <- simplify2array(ReadOut1)

lapply(2:nrow(lstNew), function(i) {
? dat1 <- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE)
? colnames(dat1) <- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? length(lst1)), sep = "_"))
? write.csv(dat1, paste0(paste(getwd(), "Indices", rownames(lstNew)[i], sep = "/"),?
? ? ? ? ? ? ? ? ? ? ? ? ?".csv"), row.names = FALSE, quote = FALSE)
})

and I get this:
Error in 2:nrow(lstNew) : argument of length 0


I have tried a few tricks but could not overcome the error message.

Please help!
Atem.

sample (1).zip
Zilefac Elvis shared from Dropbox??
View on www.dropbox.com Preview by Yahoo??

On Monday, April 14, 2014 9:22 AM, arun <smartpink111 at yahoo.com> wrote:

Ok
. I got the results but mynet is down. Will send once it gets fixed

----------
Sent from my Nokia

------Original message------
From: zilefacelvis at yahoo.com <zilefacelvis at yahoo.com>
To: "arun" <smartpink111 at yahoo.com>
Date: Monday, April 14, 2014 3:01:38 PM GMT
Subject: Re: Re: Quantile and rowMean from multiple files in a folder





In the Observed.zip I
have just one file per site while in sample.zip I have 100 files(Sims) per site.





Thanks,


Atem.

------ Original Message ------



From : arun
To : Zilefac Elvis;
Sent : 14-04-2014 00:12
Subject : Re: Quantile and rowMean from multiple files in a folder
One more doubt, do you have more than one files per Site??In the example, it was just one file per Site.? ? ? On Monday, April 14, 2014 2:08 AM, arun? wrote: Hi, The problem is in the different dimensions of the Observed datasets.? sapply(seq_along(lst2),function(i){lstN<- lapply(lst2[[i]],function(x) x[,-1]);sapply(lstN,function(x) nrow(x))}) ##after removing the trend and P value rows #[1] 9 9 9 8 2 9? ? If you want to take the average, is it through filling NAs for those years that are missing in the files?? A.K.? ? ???On Monday, April 14, 2014 1:05 AM, Zilefac Elvis?
wrote:? Hi AK,? Q1) Please apply the Quantilecode.R to Observed.zip (attached). I tried but received an error which was self-explanatory but I could not change the dimensions in the code.???Q2) Please apply Quantilecode.R to both sample.zip and observed.zip. Here, instead of doing quantile(y, seq(0, 1, by = 0.01), take colMeans of the indices.? ? I have tried to solve both Q1 and Q2 but still unable to control the dimensions.? Thanks, Atem. On Sunday, April 13, 2014 9:05 AM, arun? wrote:? ? Hi Atem,? On my end, the codes are not formatted in the email as seen in the screen of formatR GUI.? I am attaching the .R file in case there is some difficulty for you. Arun? ? On Sunday, April 13, 2014 10:54 AM, arun? wrote: Hi,? I am formatting the codes using library(formatR).?Hopefully, it will not be mangled in the email. dir.create("final") lst1<- split(list.files(pattern
=".csv"), gsub("\\_.*","", list.files(pattern =".csv")))? lst2<- lapply(lst1, function(x1) lapply(x1, function(x2) { lines1<- readLines(x2) header1<- lines1[1:2] dat1<- read.table(text = lines1, header = FALSE, sep =",", stringsAsFactors = FALSE,?skip = 2) colnames(dat1)<- Reduce(paste, strsplit(header1,",")) dat1[-c(nrow(dat1), nrow(dat1) - 1), ] }))? library(plyr)???lapply(seq_along(lst2), function(i) { lstN<- lapply(lst2[[i]], function(x) x[, -1]) lstQ1<- lapply(lstN, function(x) numcolwise(function(y) quantile(y, seq(0, 1,?by = 0.01), na.rm = TRUE))(x)) arr1<- array(unlist(lstQ1), dim = c(dim(lstQ1[[1]]), length(lstQ1)), dimnames = list(NULL,?lapply(lstQ1, names)[[1]])) res<- rowMeans(arr1, dims = 2, na.rm = TRUE) colnames(res)<- gsub("","_", colnames(res)) res1<- data.frame(Percentiles = paste0(seq(0, 100, by = 1),"%"), res, stringsAsFactors = FALSE) write.csv(res1,
paste0(paste(getwd(),"final", paste(names(lst1)[[i]],"Quantile",?sep ="_"), sep ="/"),".csv"), row.names = FALSE, quote = FALSE) })? ReadOut1<- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) sapply(ReadOut1, dim) #????[,1] [,2] #[1,]?101?101 #[2,]?258?258? lapply(ReadOut1,function(x) x[1:2,1:3]) #[[1]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.68566?7.09702 #2? ? ? ? ?1% -12.59062?7.15338 # #[[2]] #?Percentiles?txav_DJF txav_MAM #1? ? ? ? ?0% -12.75516 6.841840 #2? ? ? ? ?1% -12.68244 6.910664? ? ###Q2:? dir.create("Indices") names1<- lapply(ReadOut1, function(x) names(x))[[1]] lstNew<- simplify2array(ReadOut1) lapply(2:nrow(lstNew),
function(i) { dat1<- data.frame(lstNew[1], do.call(cbind, lstNew[i, ]), stringsAsFactors = FALSE) colnames(dat1)<- c(rownames(lstNew)[1], paste(names(lst1), rep(rownames(lstNew)[i],?length(lst1)), sep ="_")) write.csv(dat1, paste0(paste(getwd(),"Indices", rownames(lstNew)[i], sep ="/"), ".csv"), row.names = FALSE, quote = FALSE) }) ## Output2: ReadOut2<- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))],?function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE)) length(ReadOut2) # [1] 257? ? head(ReadOut2[[1]], 2) #?Percentiles G100_pav_ANN G101_pav_ANN #1? ? ? ? ?0%????1.054380????1.032740 #2? ? ? ? ?1% ?1.069457????1.045689? ? A.K.? ? ? ? ? ???On Sunday, April 13, 2014 2:46 AM, Zilefac Elvis? wrote:? Hi AK, Q1) I need your help again. Using the
previous data (attached) and the previous code below,instead of taking rowMeans, let's do quantile(x,seq(0,1,by=0.01)).???Delete the last 2 rows (Trend and p<) in each file before doing quantile(x,seq(0,1,by=0.01)).? For example, assume that I want to calculate quantile(x,seq(0,1,by=0.01)) for each column of Site G100. I will do so for the 5 sims of site G100 and then take their average. This will be approximately close to the true value than just calculating quantile(x,seq(0,1,by=0.01)) from one sim. Please dothis same thing for all the files.? So, when you do rowMeans, it should be the mean of quantile(x,seq(0,1,by=0.01)) calculated from all sims in that Site.? Output? The number of files in"final" remains the same (2 files). The"Year" column(will be replaced) will contain?the names of quantile(x,seq(0,1,by=0.01)) such as?0%? ? ? ????1%? ? ? ????2%? ?
? ????3%? ? ? ????4%? ? ? ????5%? ? ? ????6%, ..., 98%? ? ? ?99%? ? ????100% . You can give this column any name such as"Percentiles".???Q2)?From the folder"final", please go to each file identified by site name, take a column, say col1 of txav?from each file, create a dataframe whose colnames are site codes (names of files in"final"). Create a folder called"Indices" and place this dataframe in it. The filename for the dataframe is txav, say. So, in"Indices", you will have one file having 3 columns [, c(Percentiles, G100,G101)]. The idea is that I want to be able to pick any column from files in"final" and form a dataframe from which I will generate my qqplot or boxplot.? Thanks very much AK. Atem This should be the final step of this my drama, at least for now.
#==============================================================================================================? dir.create("final") lst1<- split(list.files(pattern=".csv"),gsub("\\_.*","",list.files(pattern=".csv"))) lst2<-?lapply(lst1,function(x1) lapply(x1, function(x2) {lines1<- readLines(x2); header1<- lines1[1:2]; dat1<- read.table(text=lines1,header=FALSE,sep=",",stringsAsFactors=FALSE, skip=2); colnames(dat1)<- Reduce(paste,strsplit(header1,","));dat1}))? lstYear<- lapply(lst2,function(x) lapply(x, function(y) y[,1,drop=FALSE])[[1]])? ? lapply(seq_along(lst2),function(i) {lstN<-lapply(lst2[[i]],function(x) x[,-1]); arr1<- array(unlist(lstN),dim=c(dim(lstN[[1]]),length(lstN)),dimnames=list(NULL,lapply(lstN,names)[[1]]));res<- cbind(lstYear[[i]],rowMeans(arr1,dims=2,na.rm=TRUE)); names(res)<- gsub("\\_$","",gsub("","_",names(res))); res[,1]<- gsub("<","",res[,1]);
write.csv(res,paste0(paste(getwd(),"final",names(lst1) [[i]],sep="/"),".csv"),row.names=FALSE,quote=FALSE)?})? ???#====================================================================================================??



From c-w.hoffmann at sunrise.ch  Tue Apr 15 22:49:42 2014
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Tue, 15 Apr 2014 22:49:42 +0200
Subject: [R] was: 127.0.0.1:22381/doc/html/index.html hep.start won't start
Message-ID: <534D9B66.8090800@sunrise.ch>

Dear All,

I narrowed down my problem to

library(tcltk)

in .First() which causes the freezing of R and Aquamacs running it.

What could make tcltk behave in this way?

Christian

I am using Aquamacs 3.0a (GNU Emacs 24.3.50.2)with R3.0.3, newly 
installed: sessionInfo()
-----------
R version 3.0.3 (2014-03-06)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.0.3 tools_3.0.3
---------

The FIREWALL has nothing to do with it

Has anyone seen this to happen, too?

Christian



From dwinsemius at comcast.net  Tue Apr 15 22:51:15 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Apr 2014 13:51:15 -0700
Subject: [R] Trend test for hazard ratios
In-Reply-To: <3dfcdc$gc1e36@ironport9.mayo.edu>
References: <mailman.19.1397556011.24959.r-help@r-project.org>
	<3dfcdc$gc1e36@ironport9.mayo.edu>
Message-ID: <5EAC8DA1-919F-44F8-95FF-168AB813F409@comcast.net>


On Apr 15, 2014, at 6:32 AM, Therneau, Terry M., Ph.D. wrote:

> You can do statistical tests within a single model, for whether portions of it fit or do not fit.  But one cannot take three separate fits and compare them.  The program needs context to know how the three relate to one another.  Say that "group" is your strata variable, trt the variable of interest, and x1, x2 are adjusters.
> 
>   fit <- coxph(Surv(time,status) ~ trt * strata(group) + x1 + x2, data=mydata)
> 
> Will fit a model with a separate treatment coefficient for each of the groups, and a separate baseline hazard for each.  One can now create a contrast that corresponds to your trend test, using vcov(fit) for the variance matrix and coef(fit) to retrieve the coefficients.
> 

I have at the moment on my workspace a dataset of breast cancer cases extracted from SEER that has a factor representing three grades of histology: 
$Grade.abb. $ Grade.abb     : Factor w/ 3 levels "Well","Moderate", "Poorly"

It would be reasonable to test whether the grading has a "trend" in its effect when controlling for other factors (and it would be surprising to a medical audience if there were no effect.). So I compare across models using  AgeStgSiz.NG.Rad as my "linear" trend" model (with one df for an `as.numeric` version, AgeStgSizRad as my no-grade-included baseline, and AgeStgSiz.FG.Rad as my full factor version:

> AgeStgSiz.NG.Rad <- coxph( Surv(Survmon, Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+ SEER.historic.stage.A+ as.numeric(Size.cat) + as.numeric(Grade.abb) + Rgrp , data=BrILR)
> AgeStgSizRad <- coxph( Surv(Survmon, Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+ SEER.historic.stage.A+ as.numeric(Size.cat) + Rgrp , data=BrILR)
> AgeStgSiz.FG.Rad <- coxph( Surv(Survmon, Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+ SEER.historic.stage.A+ as.numeric(Size.cat) + Grade.abb + Rgrp , data=BrILR)
> 2*diff(summary(AgeStgSizRad)[['loglik']])
[1] 5166.291
> 2*diff(summary(AgeStgSiz.NG.Rad)[['loglik']])
[1] 5888.492
> 2*diff(summary(AgeStgSiz.FG.Rad)[['loglik']])
[1] 5889.379

So there is strong evidence that adding grade to the existing covariates improves the fit but that representing as separate factor values with one extra degree of freedom may not be needed. When I add grade as a stratum I get a very different 2*loglikelihood:

> AgeStgSiz.SG.Rad <- coxph( Surv(Survmon, Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+ SEER.historic.stage.A+ as.numeric(Size.cat) + strata(Grade.abb) + Rgrp , data=BrILR)
> 2*diff(summary(AgeStgSiz.SG.Rad)[['loglik']])
[1] 3980.908

> dput( vcov(AgeStgSiz.SG.Rad) )
structure(c(9.00241385282728e-06, -4.45446264398645e-07, 5.18927440846587e-07, 
2.62020260612094e-07, 7.47434378232446e-07, -4.45446264398645e-07, 
0.0046168537719431, 0.00445692601518848, -8.67833275051278e-07, 
-3.68093395861629e-05, 5.18927440846587e-07, 0.00445692601518848, 
0.00464685164887969, -1.61616621634903e-05, -3.77256742079467e-05, 
2.62020260612094e-07, -8.67833275051278e-07, -1.61616621634903e-05, 
7.84049821976807e-06, 1.8221575745622e-06, 7.47434378232446e-07, 
-3.68093395861629e-05, -3.77256742079467e-05, 1.8221575745622e-06, 
0.000313989310316303), .Dim = c(5L, 5L), .Dimnames = list(c("AgeDx", 
"SEER.historic.stage.ALocalized", "SEER.historic.stage.ARegional", 
"as.numeric(Size.cat)", "RgrpTRUE"), c("AgeDx", "SEER.historic.stage.ALocalized", 
"SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"
)))
> dput(coef(AgeStgSiz.SG.Rad))
structure(c(0.0393472050734995, 0.901971276489615, 1.46695753267995, 
0.108860100649677, -0.273688779502084), .Names = c("AgeDx", "SEER.historic.stage.ALocalized", 
"SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"
))

I'm not particularly facile with contrast construction with var-covar matrices, so hoping for a worked example. Also wondering of the cross-model comparisons are invalid or less powerful?


> Terry T.
> 
> 
> 
> On 04/15/2014 05:00 AM, r-help-request at r-project.org wrote:
>> Hello,
>> 
>> I have the following problem. I stratified my patient cohort into three
>> ordered groups and performed multivariate adjusted Cox regression analysis
>> on each group separately. Now I would like to calculate a p for trend across
>> the hazard ratios that I got for the three groups. How can I do that if I
>> only have the HR and the confidence interval? For example I got the
>> following HRs for one endpoint:
>> 
>> 1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68).
>> 
>> There is a trend but how do I calculate if it is significant?
>> 
>> Best regards
>> 
>> Marcus Kleber
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From wdunlap at tibco.com  Tue Apr 15 23:08:49 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 15 Apr 2014 21:08:49 +0000
Subject: [R] get element of list with default?
In-Reply-To: <534D90DC.5070107@structuremonitoring.com>
References: <534D55EB.6060602@structuremonitoring.com>
	<CABdHhvEP=XRA-nTkR933CF2=JE5yGGUNiypKWkrn0Qye9ak1Sw@mail.gmail.com>
	<534D90DC.5070107@structuremonitoring.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC665C@PA-MBX01.na.tibco.com>

I think the following is a trifle faster than the i%in%names(x) version,
probably because it only does the name lookup once.  (I also don't
like to use return() - it is too much like goto.)

getElement3 <- function(x, i, default) {
   i <- match(i, names(x))
   if (is.na(i)) {
      default
   } else {
      x[[i]]
   }
}

Like the others, it does not check the assumption that 'i' is a character
vector of length 1.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Spencer Graves
> Sent: Tuesday, April 15, 2014 1:05 PM
> To: Hadley Wickham
> Cc: R list
> Subject: Re: [R] get element of list with default?
> 
> Thanks to Marc Schwartz and Hadley Wickham:
> 
> 
>        Based on their comments, I think I'll add a combination of
> Hadley's code and getElement{base} Ecfun in a form like
> getElement2(object, name, default).
> 
> 
>        Best Wishes,
>        Spencer
> 
> 
> On 4/15/2014 9:33 AM, Hadley Wickham wrote:
> > You really want to use the names of the list since lists can contain
> > null.  I'd recommend something more like:
> >
> > getElement <- function(x, i, default) {
> >    if (i %in% names(x)) return(x[[i]])
> >    default
> > }
> >
> > Hadley
> >
> > On Tue, Apr 15, 2014 at 10:53 AM, Spencer Graves
> > <spencer.graves at structuremonitoring.com> wrote:
> >> Hello:
> >>
> >>
> >>        Do you know of a simple function to return the value of a named
> >> element of a list if that exists, and return a default value otherwise?
> >>
> >>
> >>        It's an easy function to write (e.g., below).  I plan to add this to
> >> the "Ecfun" package unless I find it in another CRAN package.
> >>
> >>
> >>        Thanks,
> >>        Spencer
> >>
> >>
> >>      getElement <- function(element, default, list){
> >> #       get element of list;  return elDefault if absent
> >>          El <- list[[element]]
> >>          if(is.null(El)){
> >>              El <- default
> >>          }
> >>          El
> >>      }
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.CA.us  Tue Apr 15 23:11:19 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Apr 2014 14:11:19 -0700
Subject: [R] R - Need Help : Using R's qcc package in .Net Appln
In-Reply-To: <BAY179-W233561FE59147F616E4750AB500@phx.gbl>
References: <BAY179-W233561FE59147F616E4750AB500@phx.gbl>
Message-ID: <bd454a79-ceda-4af7-8441-1a6a3ea62258@email.android.com>

This request, like the one from earlier today, is off-topic on R-help, and off-topic on the other mailing lists you cross posted to. It is rude to cross post to multiple mailing lists... pick the appropriate place according to the relevant Posting Guide and stick with it. Not only are you broadcasting to inappropriate lists at this point, but you are apparently being impatient with the response to your posts on the R.NET discussion website[1]... abusing other forums because the appropriate forum is slow is also rude.

[1] rdotnet.codeplex.com/discussions
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 15, 2014 10:33:10 AM PDT, antony romar <anthonyromar at live.com> wrote:
>Hi, I am very much interested  in using R. I have a query: 1.I have
>.Net Application from which am trying to invoke R libraries from
>R.NET(Libraries provided in Codeplex)2. R uses a Package called
>qcc(qualityChart Controls) which has a function mqcc() with set of
>parameters passed to it. After executing this in R it produces a plot
>in R. 3. My Query : Is there any way to include/add/reference qcc
>packge  in .Net Application. Sample Example on this will be greatly
>appreciated. Regards,Antony 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Tue Apr 15 23:12:33 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 15 Apr 2014 14:12:33 -0700
Subject: [R] lm predictions for rows with missing y values
In-Reply-To: <598B1AFF65DDEB4083C14C81FF2CC0C304A4181EA7@ELANNEPV115.exh.prod.hud.gov>
References: <598B1AFF65DDEB4083C14C81FF2CC0C304A4181EA7@ELANNEPV115.exh.prod.hud.gov>
Message-ID: <CACk-te3aAMyXwK4oYc3nTYYQ6RciBhd02gJx6ZsD-st-Az+OBg@mail.gmail.com>

Yes. I believe what you're looking for is:

See ?predict.lm and what it has to say about the na.action=na.exclude
argument to lm.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Apr 15, 2014 at 1:22 PM, Mast, Brent D <Brent.D.Mast at hud.gov> wrote:
> Hi.
>
> I'm trying to produce lm fitted values and standard errors for cases with missing y values. I know how to compute these myself with matrix algebra, but I'm wondering if there is an appropriate na.action in the lm function to do this.
> Here is some simple code where I use na.action=NULL with a dataset with 2 missing y values, but the model won't estimate. It also won't run with na.action=TRUE or FALSE. Any suggestions would be appreciated.
>
> Thanks much,
> Brent Mast
>
> x <- rnorm(15)
> y <- x + rnorm(15)
> lm <- lm(y ~ x)
> fit <- fitted(lm)
> fit
> # 2 new x cases
> newx <- c(x,-3, 3)
> # set y to NA for new cases
> newy <- matrix(,17,1)
> newy[1:15,1] <- y
> newdata <- data.frame(newy,newx)
> newdata
> lmnew <- lm(newy ~ newx,newdata,na.action=NULL)
> fitnew <- fitted(lmnew)
> fitnew
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Tue Apr 15 23:22:25 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 15 Apr 2014 22:22:25 +0100
Subject: [R] lm predictions for rows with missing y values
In-Reply-To: <598B1AFF65DDEB4083C14C81FF2CC0C304A4181EA7@ELANNEPV115.exh.prod.hud.gov>
References: <598B1AFF65DDEB4083C14C81FF2CC0C304A4181EA7@ELANNEPV115.exh.prod.hud.gov>
Message-ID: <534DA311.6040804@sapo.pt>

Hello,

I believe you want na.action = na.exclude.

lmnew <- lm(newy ~ newx,newdata,na.action=na.exclude)


na.action can not be set to TRUE or FALSE. From the help page ?lm

na.action 	

a function which indicates what should happen when the data contain NAs. 
The default is set by the na.action setting of options, and is na.fail 
if that is unset. The ?factory-fresh? default is na.omit. Another 
possible value is NULL, no action. Value na.exclude can be useful.

Hope this helps,

Rui Barradas

Em 15-04-2014 21:22, Mast, Brent D escreveu:
> Hi.
>
> I'm trying to produce lm fitted values and standard errors for cases with missing y values. I know how to compute these myself with matrix algebra, but I'm wondering if there is an appropriate na.action in the lm function to do this.
> Here is some simple code where I use na.action=NULL with a dataset with 2 missing y values, but the model won't estimate. It also won't run with na.action=TRUE or FALSE. Any suggestions would be appreciated.
>
> Thanks much,
> Brent Mast
>
> x <- rnorm(15)
> y <- x + rnorm(15)
> lm <- lm(y ~ x)
> fit <- fitted(lm)
> fit
> # 2 new x cases
> newx <- c(x,-3, 3)
> # set y to NA for new cases
> newy <- matrix(,17,1)
> newy[1:15,1] <- y
> newdata <- data.frame(newy,newx)
> newdata
> lmnew <- lm(newy ~ newx,newdata,na.action=NULL)
> fitnew <- fitted(lmnew)
> fitnew
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From robertbauer1603 at gmx.de  Tue Apr 15 23:27:13 2014
From: robertbauer1603 at gmx.de (Robert Bauer)
Date: Tue, 15 Apr 2014 14:27:13 -0700 (PDT)
Subject: [R] generic function-method arguments accessible by tab-key
In-Reply-To: <1397556838591-4688794.post@n4.nabble.com>
References: <1397555713544-4688793.post@n4.nabble.com>
	<1397556838591-4688794.post@n4.nabble.com>
Message-ID: <1397597233605-4688859.post@n4.nabble.com>

found the solution:

v <- function(x, ...) UseMethod("v")

setMethod('v', signature(x='character'), function(x, ...) v.print(x, ...))
setMethod('v', signature(x='numeric'), function(x, ...) v.numeric(x, ...))

v.print <- function(x,y=x,z=x) print(paste(x,y,z))
v.numeric <- function(x,u=3*x) print(u*x)

examples:
v(1)
v('a')

The tab-key after typing 'v( gives:
x=
...
u=
y=
z=



--
View this message in context: http://r.789695.n4.nabble.com/generic-function-method-arguments-accessible-by-tab-key-tp4688793p4688859.html
Sent from the R help mailing list archive at Nabble.com.



From ruipbarradas at sapo.pt  Tue Apr 15 23:35:15 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 15 Apr 2014 22:35:15 +0100
Subject: [R] using for loop for data frame
In-Reply-To: <CANpv+66OrVpnZd++MJDd8JMb4yLkoVfbxSZp=gdgAgVeafO8eA@mail.gmail.com>
References: <CANpv+66OrVpnZd++MJDd8JMb4yLkoVfbxSZp=gdgAgVeafO8eA@mail.gmail.com>
Message-ID: <534DA613.80500@sapo.pt>

Hello,

Inline.

Em 15-04-2014 18:02, Monaly Mistry escreveu:
> Hi,
>
> I have a data frame with 15 different years and each year has a different
> sample size.  I'm having trouble writing a for loop to have a t-test done
> for each year for two of the columns.  Thus far I have been able to loop
> over the years but the output is the same t-test 15 times.  I'm new to
> writing loops and functions, and am trying to figure out a way to use them
> together (if there are any general rules to follow, I would be great-full
> to know)
>
> for(year in 1998:2012){
>    b <-t.test(tr$adj_ind_pop_dif, tr$ind_nei_dif, paired=TRUE)
>    print(b)
> }

The problem with this loop is that you don't use the variable 'year' in 
it. It just repeats the same test 15 times.
>
> the other way I did it was to take subsets of the dataframe and then do a
> separate t-test for each
> ab<-subset(tr, BroedJaar =="1999")
> t.test(ab$ind_nei_dif, ab$adj_ind_pop_dif, paired=TRUE)

So BroedJaar is a character variable? Try

for(year in 1998:2012){
	ab <- subset(tr, BroedJaar == as.character(year))
	b <- t.test(ab$adj_ind_pop_dif, ab$ind_nei_dif, paired=TRUE)
	print(b)
}


Note however that this won't store the results of the t-tests, all but 
the last one will be lost. (The last one is stored in 'b'.)
If you want the results of the 15 tests you can do

result <- lapply(1998:2012, function(year){
		ab <- subset(tr, BroedJaar == as.character(year))
		t.test(ab$adj_ind_pop_dif, ab$ind_nei_dif, paired=TRUE)
	})
names(result) <- 1998:2012

Then you can access the results with something like

result[[1]]  # first test
result[["1998"]]  # equivalent


Hope this helps,

Rui Barradas

>
> Best,
>
> Monaly.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From boris.steipe at utoronto.ca  Wed Apr 16 00:09:45 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 15 Apr 2014 18:09:45 -0400
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
Message-ID: <66A72FBF-2FCB-403F-A0E9-F4B241AA4AB6@utoronto.ca>

Here you go:

install.packages("plotrix")
library(plotrix)

?floating.pie

dat<- data.frame(x=c(19.9437314, 20.2214171, 20.0955891, 20.9506636),
                 y=c(40.7086377, 41.4924336, 39.9481364, 40.6447347),
                 City=c(120,1, 4, 10),
                 Village=c(425, 1, 4, 15)
                )

# first, set up an existing plot to plot your pies into, for example
plot(c(min(dat$x)-0.5, max(dat$x)+0.5), 
     c(min(dat$y)-0.5, max(dat$y)+0.5), 
     xlab = "", ylab = "", type = "n"
    )

# your pie-chart sectors are rows of the City and Village columns
sectors = cbind(dat$City,dat$Village)

# plot each pie chart in turn
for (i in 1:length(dat$x)) {
    floating.pie(dat$x[i],
                 dat$y[i],
                 sectors[i,],
                 radius=0.1
                )
}

Enjoy,
B.


On 2014-04-15, at 2:43 PM, DrunkenPhD wrote:

> Sorry Jim not for my beginner level :(((
> 
> So if my data are like this :
> 
> x                             y                   City          Village
> 
> 19.9437314          40.7086377          120         425
> 
> 20.2214171          41.4924336          1              1
> 
> 20.0955891          39.9481364          4              4
> 
> 20.9506636          40.6447347          10           15
> 
> how do I plot for every point(x,y) a pie chart with slices(City,Village)?
> Regards
> 
> 
> how do I plot for every point(x,y) a pie chart with slices(City,Village)?
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From laomeng_3 at 163.com  Wed Apr 16 01:48:17 2014
From: laomeng_3 at 163.com (meng)
Date: Wed, 16 Apr 2014 07:48:17 +0800 (CST)
Subject: [R] a question about the output of plot
In-Reply-To: <534D0231.8000908@bitwrit.com.au>
References: <272d3df7.3534.14563106916.Coremail.laomeng_3@163.com>
	<534CD379.70707@bitwrit.com.au>
	<76cdcbbc.cc9e.14564ccde16.Coremail.laomeng_3@163.com>
	<534D0231.8000908@bitwrit.com.au>
Message-ID: <1ab20cc0.158f7.14567ca88ef.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/4ed30a4e/attachment-0001.pl>

From r.turner at auckland.ac.nz  Wed Apr 16 03:04:57 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 16 Apr 2014 09:04:57 +0800
Subject: [R] nearest neighbour
In-Reply-To: <CANpv+67QMOssPE6vrE8_Cq6DNh5MxK4Zx_dPXhru9DfWdsgGvw@mail.gmail.com>
References: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>
	<533DC341.7020505@auckland.ac.nz>
	<CANpv+67QMOssPE6vrE8_Cq6DNh5MxK4Zx_dPXhru9DfWdsgGvw@mail.gmail.com>
Message-ID: <534DD739.8000006@auckland.ac.nz>


Please keep communications on-list unless there is a genuine reason not to.

To answer your question:  Yes, you need to convert to ppp format; the 
nnwhich() function requires its first argument to be of class "ppp".
My example showed you how to construct or "estimate" a window if you 
don't have or know the window a priori.

cheers,

Rolf Turner

On 16/04/14 01:23, Monaly Mistry wrote:
> Hi Rolf,
>
> Thank you very much,  I just have one other question, do I need to
> change the data frame into ppp format?  I've tried using as.ppp but get
> the following error message:
> Error: x,y coords given but no window specified
>
> Best,
>
> Monaly.
>
>
> On Thu, Apr 3, 2014 at 9:23 PM, Rolf Turner <r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>> wrote:
>
>     On 04/04/14 01:16, Monaly Mistry wrote:
>
>         Hi,
>
>         If I have a data frame of the location of individuals (x and y
>         coordinate),
>         how do I find the 5 nearest neighbours for each individual.
>
>
>     The nnwhich() function from the spatstat package will do this for you.
>
>     E.g.:
>
>     require(spatstat) # You need to have *installed* spatstat!
>     W <- ripras(ddd)  # Where "ddd" is the name of your data frame.
>     X <- ppp(x=ddd[,1],y=ddd[,2],window=W)
>     n5 <- nnwhich(X,k=1:5)



From r.turner at auckland.ac.nz  Wed Apr 16 03:07:44 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 16 Apr 2014 09:07:44 +0800
Subject: [R] nearest neighbour
In-Reply-To: <CANpv+67QMOssPE6vrE8_Cq6DNh5MxK4Zx_dPXhru9DfWdsgGvw@mail.gmail.com>
References: <CANpv+65g24nh+i+38kHs8P2THFvfUi31_285RMY1n0oxqqVBng@mail.gmail.com>
	<533DC341.7020505@auckland.ac.nz>
	<CANpv+67QMOssPE6vrE8_Cq6DNh5MxK4Zx_dPXhru9DfWdsgGvw@mail.gmail.com>
Message-ID: <534DD7E0.7040508@auckland.ac.nz>


Sorry, your communication *was* on-list.  I guess my eyes are going!

Please ignore the first sentence of my previous post.

cheers,

Rolf



From mamin89 at live.com  Wed Apr 16 01:15:01 2014
From: mamin89 at live.com (Manan Amin)
Date: Tue, 15 Apr 2014 19:15:01 -0400
Subject: [R] Regarding snp data
Message-ID: <BLU403-EAS371BF3082DFA38D5747E39CC4500@phx.gbl>


Hello,

I have a data file of 108mb with snps data of 0,1,2.  I am new in the program and have to do this project.  My first step is to get the p value using chisq.test function.  I have tried running the function however since I am new to language I am aware of how to do this step. My error am getting is cannot allocate vector of size.  Now I have data loaded as in table text file into a variable called data and passing that variable to function chisq.test with df value of 2.
Sent from my iPhone


From smartpink111 at yahoo.com  Wed Apr 16 04:11:11 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Apr 2014 19:11:11 -0700 (PDT)
Subject: [R] indexing names for looping across computations done on
	pairs of	matrices
In-Reply-To: <CAM5M9BRxdmoEs1su80X7F8V0YYbMDUjj-e6CXUHY5iG8rf1n6g@mail.gmail.com>
References: <CAM5M9BRxdmoEs1su80X7F8V0YYbMDUjj-e6CXUHY5iG8rf1n6g@mail.gmail.com>
Message-ID: <1397614271.28409.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi, 

If the two pairs of matrices are in a list:
set.seed(42)
lst1 <- lapply(1:11, function(x) matrix(sample(40, 20, replace=TRUE), 5,4)) 

names(lst1) <- paste0("gs", paste0("4.",seq(0,100,by=10)))
set.seed(585) 

lst2 <- lapply(1:11, function(x) matrix(sample(40, 20, replace=TRUE), 5,4)) 

names(lst2) <- paste0("ps", paste0("1.",seq(0,100,by=10)))
mean.comb <- data.frame(simulation=0:10, mean.horses.removed=sapply(seq_along(lst1),function(i) mean(rowSums(lst1[[i]]*lst2[[i]]))))?

#or 

# if the datasets are standalone with no particular order
#just for demonstration
attach(lst1) 

attach(lst2)

vec1 <- sample(paste0("gs", paste0("4.",seq(0,100,by=10))), 11, replace=FALSE)
vec2 <- sample(paste0("ps", paste0("1.",seq(0,100,by=10))), 11, replace=FALSE) 

vec1New <- vec1[order(as.numeric(gsub(".*\\.","",vec1)))] 

vec2New <- vec2[order(as.numeric(gsub(".*\\.","",vec2)))] 

mean.comb2 <- data.frame(simulation=0:10, mean.horses.removed=sapply(seq_along(vec1New),function(i) mean(rowSums(get(vec1New[i])* get(vec2New[i])))))
identical(mean.comb,mean.comb2) 

#[1] TRUE 


A.K.





On Tuesday, April 15, 2014 4:30 PM, "Cade, Brian" <cadeb at usgs.gov> wrote:
So I know I must be missing something simple and obvious for the following
data manipulation where I have (in this example) 11 pairs of matrices
(gs4.0 to gs4.100 and ps1.0 to ps1.100) from some population simulations
(all with same dimensions) where I want to get some summary statistics on
the products of the cells in a pair (e.g., gs4.0 * ps1.0).? The code I
wrote below works fine, but it seems like there ought to be a simple way to
index the extensions on the names (.0 to .100) in a for loop to simplify
this code greatly.? I've spent some time trying various things using
paste() and assign() and have had no success.

mean.comb <- as.matrix(0:10,nrow = 11, ncol=1)
mean.comb <- cbind(mean.comb,0)

###to see list of files created
gs4files <- ls(pattern="gs4.*0")
ps1files <- ls(pattern="ps1.*0")

mean.comb[1,2] <- mean(apply(gs4.0 * ps1.0,1,sum))
mean.comb[2,2] <- mean(apply(gs4.10 * ps1.10,1,sum))
mean.comb[3,2] <- mean(apply(gs4.20 * ps1.20,1,sum))
mean.comb[4,2] <- mean(apply(gs4.30 * ps1.30,1,sum))
mean.comb[5,2] <- mean(apply(gs4.40 * ps1.40,1,sum))
mean.comb[6,2] <- mean(apply(gs4.50 * ps1.50,1,sum))
mean.comb[7,2] <- mean(apply(gs4.60 * ps1.60,1,sum))
mean.comb[8,2] <- mean(apply(gs4.70 * ps1.70,1,sum))
mean.comb[9,2] <- mean(apply(gs4.80 * ps1.80,1,sum))
mean.comb[10,2] <- mean(apply(gs4.90 * ps1.90,1,sum))
mean.comb[11,2] <- mean(apply(gs4.100 * ps1.100,1,sum))

mean.comb<- data.frame(mean.comb)
colnames(mean.comb) <- c("simulation", "mean.horses.removed")


Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO? 80526-8818

email:? cadeb at usgs.gov <brian_cade at usgs.gov>
tel:? 970 226-9326

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From zhaoxing at uw.edu  Wed Apr 16 06:10:42 2014
From: zhaoxing at uw.edu (Xing Zhao)
Date: Tue, 15 Apr 2014 21:10:42 -0700
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <003901cf58d3$c36b3300$4a419900$@mcmaster.ca>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
	<534D23A0.5040102@yorku.ca> <web-505799764@cgpsrv2.cis.mcmaster.ca>
	<CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>
	<003901cf58d3$c36b3300$4a419900$@mcmaster.ca>
Message-ID: <CAFQiRr6YMzQCx0LJPKwZoWbq=Rfwb0GFaiYQsxcocgMe3fBvPQ@mail.gmail.com>

Dear John

Sorry I use 3 degree of freedom for  cubic spline. After using 4, it
is still not 2. I may make some naive mistake, but I cannot figure
out. Where is the problem?

4 (cubic on the right side of the *interior* knot 8)
+ 4 (cubic on the left side of the *interior* knot 8)
- 1 (two curves must be continuous at the *interior* knot 8)
- 1 (two curves must have 1st order derivative continuous at the
*interior* knot 8)
- 1 (two curves must have 2nd order derivative continuous at the
*interior* knot 8)
- 1 (right side cubic curve must have 2nd order derivative = 0 at the
boundary knot 15 due to the linearity constraint)
- 1 (similar for the left)
= 3, not 2

Thanks
Xing

On Tue, Apr 15, 2014 at 10:54 AM, John Fox <jfox at mcmaster.ca> wrote:
> Dear Xing,
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Xing Zhao
>> Sent: Tuesday, April 15, 2014 1:18 PM
>> To: John Fox
>> Cc: r-help at r-project.org; Michael Friendly
>> Subject: Re: [R] The explanation of ns() with df =2
>>
>> Dear Michael and Fox
>>
>> Thanks for your elaboration. Combining your explanations would, to my
>> understanding, lead to the following  calculation of degree of
>> freedoms.
>>
>> 3 (cubic on the right side of the *interior* knot 8)
>> + 3 (cubic on the left side of the *interior* knot 8)
>> - 1 (two curves must be continuous at the *interior* knot 8)
>
> You shouldn't subtract 1 for continuity since you haven't allowed a
> different level on each side of the knot (that is your initial counting of 3
> parameters for the cubic doesn't include a constant).
>
> Best,
>  John
>
>> - 1 (two curves must have 1st order derivative continuous at the
>> *interior* knot 8)
>> - 1 (two curves must have 2nd order derivative continuous at the
>> *interior* knot 8)
>> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
>> boundary knot 15 due to the linearity constraint)
>> - 1 (similar for the left)
>> = 1, not 2
>>
>> Where is the problem?
>>
>> Best,
>> Xing
>>
>> On Tue, Apr 15, 2014 at 6:17 AM, John Fox <jfox at mcmaster.ca> wrote:
>> > Dear Xing Zhao,
>> >
>> > To elaborate slightly on Michael's comments, a natural cubic spline
>> with 2 df has one *interior* knot and two boundary knots (as is
>> apparent in the output you provided). The linearity constraint applies
>> beyond the boundary knots.
>> >
>> > I hope this helps,
>> >  John
>> >
>> > ------------------------------------------------
>> > John Fox, Professor
>> > McMaster University
>> > Hamilton, Ontario, Canada
>> > http://socserv.mcmaster.ca/jfox/
>> >
>> > On Tue, 15 Apr 2014 08:18:40 -0400
>> >  Michael Friendly <friendly at yorku.ca> wrote:
>> >> No, the curves on each side of the know are cubics, joined
>> >> so they are continuous.  Se the discussion in \S 17.2 in
>> >> Fox's Applied Regression Analysis.
>> >>
>> >> On 4/15/2014 4:14 AM, Xing Zhao wrote:
>> >> > Dear all
>> >> >
>> >> > I understand the definition of Natural Cubic Splines are those
>> with
>> >> > linear constraints on the end points. However, it is hard to think
>> >> > about how this can be implement when df=2. df=2 implies there is
>> just
>> >> > one knot, which, according the the definition, the curves on its
>> left
>> >> > and its right should be both be lines. This means the whole line
>> >> > should be a line. But when making some fits. the result still
>> looks
>> >> > like 2nd order polynomial.
>> >> >
>> >> > How to think about this problem?
>> >> >
>> >> > Thanks
>> >> > Xing
>> >> >
>> >> > ns(1:15,df =2)
>> >> >                1           2
>> >> >   [1,] 0.0000000  0.00000000
>> >> >   [2,] 0.1084782 -0.07183290
>> >> >   [3,] 0.2135085 -0.13845171
>> >> >   [4,] 0.3116429 -0.19464237
>> >> >   [5,] 0.3994334 -0.23519080
>> >> >   [6,] 0.4734322 -0.25488292
>> >> >   [7,] 0.5301914 -0.24850464
>> >> >   [8,] 0.5662628 -0.21084190
>> >> >   [9,] 0.5793481 -0.13841863
>> >> > [10,] 0.5717456 -0.03471090
>> >> > [11,] 0.5469035  0.09506722
>> >> > [12,] 0.5082697  0.24570166
>> >> > [13,] 0.4592920  0.41197833
>> >> > [14,] 0.4034184  0.58868315
>> >> > [15,] 0.3440969  0.77060206
>> >> > attr(,"degree")
>> >> > [1] 3
>> >> > attr(,"knots")
>> >> > 50%
>> >> >    8
>> >> > attr(,"Boundary.knots")
>> >> > [1]  1 15
>> >> > attr(,"intercept")
>> >> > [1] FALSE
>> >> > attr(,"class")
>> >> > [1] "ns"     "basis"  "matrix"
>> >> >
>> >>
>> >>
>> >> --
>> >> Michael Friendly     Email: friendly AT yorku DOT ca
>> >> Professor, Psychology Dept. & Chair, Quantitative Methods
>> >> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> >> 4700 Keele Street    Web:   http://www.datavis.ca
>> >> Toronto, ONT  M3J 1P3 CANADA
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From aguitatierra at hotmail.com  Wed Apr 16 08:22:00 2014
From: aguitatierra at hotmail.com (Beatriz R. Gonzalez Dominguez)
Date: Wed, 16 Apr 2014 08:22:00 +0200
Subject: [R] netCDF to raster and spatial projection
Message-ID: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>

I've recently started using R for spatial data. I'd be really grateful 
if you could could help me with this. Thanks!

Sorry I don't provide a reproducible example. Please ask me if you have 
any questions about the data.

I've extracted data from a multidimensional netCDF file. This file had 
longitude, latitude and temperature data (for 12 months of a specific year).

 From this netCDF I've got a data frame for January with these 
variables: longitude, latitude, temperature.

With this data frame I've created a raster.

     # Packages
     library("sp")
     library("raster")
     library("rgdal")
     library("ncdf")
     library("maptools")
     library("rgeos")
     library("sm")
     library("chron")

     # Dataframe to raster
     # Create spatial points data frame
     coordinates(tmp.df01) <- ~ lon + lat
     # Coerce to SpatialPixelsDataFrame
     gridded(tmp.df01) <- T
     # Coerce to raster
     rasterDF1 <- raster(tmp.df01)
     > print(tmp.df01)
     class       : SpatialPixelsDataFrame
     dimensions  : 103, 241, 24823, 1  (nrow, ncol, npixels, nlayers)
     resolution  : 0.02083333, 0.02083333  (x, y)
     extent      : 5.739583, 10.76042, 45.73958, 47.88542  (xmin, xmax, 
ymin, ymax)
     coord. ref. : NA
     names       :           TabsM_1
     min values  : -18.1389980316162
     max values  :  2.26920962333679

There is no value for 'coord. ref.'

The projection of the original netCDF was WGS84. So I gave this 
projection to the raster.

     proj4string(rasterDF1) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 
+towgs84=0,0,0"

Then, I wanted to reproject my raster to another projection:

     # Reprojecting into CH1903_LV03
     # First, change the coordinate reference system (crs)
     proj4string(rasterDF1) <- "+init=epsg:21781"
     # Second, reproject the raster
     rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))

At this point I get the following error:

     Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
       load package rgdal for spTransform methods

But the package rgdal is already uploaded! It must be something wrong in 
the code!



From e.raco at fimif.edu.al  Wed Apr 16 08:33:06 2014
From: e.raco at fimif.edu.al (Endri Raco)
Date: Wed, 16 Apr 2014 08:33:06 +0200
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <66A72FBF-2FCB-403F-A0E9-F4B241AA4AB6@utoronto.ca>
References: <1397344830813-4688678.post@n4.nabble.com>
	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<66A72FBF-2FCB-403F-A0E9-F4B241AA4AB6@utoronto.ca>
Message-ID: <CACje6_ZfPnUeWrHTuUN=iP3HEXeX1aXO1p-3Lb7oWo09+bJg+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/fa684714/attachment-0001.pl>

From petr.pikal at precheza.cz  Wed Apr 16 10:03:06 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 16 Apr 2014 08:03:06 +0000
Subject: [R] I can't programe routine comp()
In-Reply-To: <CAGpBJKQ2nXLrwVoFvnjZ+spqL+XwObA-s7uvh+O22jTLo5meXw@mail.gmail.com>
References: <1397472963.31861.YahooMailNeo@web171702.mail.ir2.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BCC9FA@SRVEXCHMBX.precheza.cz>
	<CAGpBJKQ2nXLrwVoFvnjZ+spqL+XwObA-s7uvh+O22jTLo5meXw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BCCD3C@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/8868d5cd/attachment-0001.pl>

From frtog at vestas.com  Wed Apr 16 10:17:38 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 16 Apr 2014 10:17:38 +0200
Subject: [R] netCDF to raster and spatial projection
In-Reply-To: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>
References: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>

Hi Beatriz

Try to skip this step

>      # Reprojecting into CH1903_LV03
>      # First, change the coordinate reference system (crs)
>      proj4string(rasterDF1) <- "+init=epsg:21781"


And just do this

>      # Second, reproject the raster
>      rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
>

Also there is a spTransform both in the rgdal and sp packages. So are they masking each other? rgdal should be before sp in the search() list.

I cannot be of more help since you provided no data. 


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Beatriz R. Gonzalez Dominguez
> Sent: 16. april 2014 08:22
> To: r-help at r-project.org
> Subject: [R] netCDF to raster and spatial projection
> 
> I've recently started using R for spatial data. I'd be really grateful
> if you could could help me with this. Thanks!
> 
> Sorry I don't provide a reproducible example. Please ask me if you have
> any questions about the data.
> 
> I've extracted data from a multidimensional netCDF file. This file had
> longitude, latitude and temperature data (for 12 months of a specific year).
> 
>  From this netCDF I've got a data frame for January with these
> variables: longitude, latitude, temperature.
> 
> With this data frame I've created a raster.
> 
>      # Packages
>      library("sp")
>      library("raster")
>      library("rgdal")
>      library("ncdf")
>      library("maptools")
>      library("rgeos")
>      library("sm")
>      library("chron")
> 
>      # Dataframe to raster
>      # Create spatial points data frame
>      coordinates(tmp.df01) <- ~ lon + lat
>      # Coerce to SpatialPixelsDataFrame
>      gridded(tmp.df01) <- T
>      # Coerce to raster
>      rasterDF1 <- raster(tmp.df01)
>      > print(tmp.df01)
>      class       : SpatialPixelsDataFrame
>      dimensions  : 103, 241, 24823, 1  (nrow, ncol, npixels, nlayers)
>      resolution  : 0.02083333, 0.02083333  (x, y)
>      extent      : 5.739583, 10.76042, 45.73958, 47.88542  (xmin, xmax,
> ymin, ymax)
>      coord. ref. : NA
>      names       :           TabsM_1
>      min values  : -18.1389980316162
>      max values  :  2.26920962333679
> 
> There is no value for 'coord. ref.'
> 
> The projection of the original netCDF was WGS84. So I gave this
> projection to the raster.
> 
>      proj4string(rasterDF1) <- "+proj=longlat +datum=WGS84 +ellps=WGS84
> +towgs84=0,0,0"
> 
> Then, I wanted to reproject my raster to another projection:
> 
>      # Reprojecting into CH1903_LV03
>      # First, change the coordinate reference system (crs)
>      proj4string(rasterDF1) <- "+init=epsg:21781"
>      # Second, reproject the raster
>      rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
> 
> At this point I get the following error:
> 
>      Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
>        load package rgdal for spTransform methods
> 
> But the package rgdal is already uploaded! It must be something wrong in
> the code!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From aguitatierra at hotmail.com  Wed Apr 16 10:59:32 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 16 Apr 2014 10:59:32 +0200
Subject: [R] netCDF to raster and spatial projection
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>
References: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>
Message-ID: <BLU0-SMTP31790459AB6F45B1608B842D9530@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/004814d0/attachment-0001.pl>

From luca.cerone at gmail.com  Wed Apr 16 11:03:38 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 16 Apr 2014 11:03:38 +0200
Subject: [R] R regular expression and locales
Message-ID: <CAFnz2--jiY4Bgyu_UO9mKartcVL0ejpBBktHzzYh6fAeEoUCmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/9311e5bd/attachment-0001.pl>

From pavneet.arora at uk.rsagroup.com  Wed Apr 16 11:04:24 2014
From: pavneet.arora at uk.rsagroup.com (starter)
Date: Wed, 16 Apr 2014 02:04:24 -0700 (PDT)
Subject: [R] Save multiple plots as pdf or jpeg
In-Reply-To: <8C19E3E7-0519-4C5D-8F05-63879E5A91BD@comcast.net>
References: <OF6E721B9E.F3159994-ON80257CBB.003247B4-80257CBB.0032D109@uk.royalsun.com>
	<8C19E3E7-0519-4C5D-8F05-63879E5A91BD@comcast.net>
Message-ID: <1397639064310-4688878.post@n4.nabble.com>

David you mentioned that one can deliver jpegs embedded in other formats like
pdf. Do you know which programs can allow me to do that or how I can go on
about it?

Or does it involve some kind of loop whereby, it saves the plots as jpeg and
then collates them into pdf. So it?s a multi-page document but the graphs
are pictures saved as jpegs (or png/bitmap)




--
View this message in context: http://r.789695.n4.nabble.com/Save-multiple-plots-as-pdf-or-jpeg-tp4688802p4688878.html
Sent from the R help mailing list archive at Nabble.com.



From pavneet.arora at uk.rsagroup.com  Wed Apr 16 11:00:34 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Wed, 16 Apr 2014 10:00:34 +0100
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <534D3103.4060904@statistik.tu-dortmund.de>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
Message-ID: <OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/de3484db/attachment-0001.pl>

From julien.riou.k at gmail.com  Wed Apr 16 11:24:47 2014
From: julien.riou.k at gmail.com (Julien Riou)
Date: Wed, 16 Apr 2014 11:24:47 +0200
Subject: [R] Meta-analysis of prevalence at the country level with
	mgcv/gamm4
In-Reply-To: <Zen-1WYZQO-0005eP-5V@smarthost01a.mail.zen.net.uk>
References: <CAL49zWPSEFD_sB6VJUr7V_whijSa3TMHTAh5jn9e1SN_vL2Hig@mail.gmail.com>
	<Zen-1WYZQO-0005eP-5V@smarthost01a.mail.zen.net.uk>
Message-ID: <CAL49zWMcs6iyXG9yiai+CsL96HWNQrsT5YjdyvVO29miRxNoeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/ed7c81a2/attachment-0001.pl>

From jim at bitwrit.com.au  Wed Apr 16 11:51:43 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 16 Apr 2014 19:51:43 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
Message-ID: <534E52AF.8020506@bitwrit.com.au>

On 04/16/2014 04:43 AM, DrunkenPhD wrote:
> Sorry Jim not for my beginner level :(((
>
> So if my data are like this :
>
> xyCityVillage
>
> 19.943731440.7086377120425
>
> 20.221417141.492433611
>
> 20.095589139.948136444
>
> 20.950663640.64473471015
>
> how do I plot for every point(x,y) a pie chart with slices(City,Village)?
>
> Regards
>
>
> how do I plot for every point(x,y) a pie chart with slices(City,Village)?
>
>
Okay, let's try again.

# get yer data
sampledf<-read.table(text="x y City Village
  19.9437314 40.7086377 120 425
  20.2214171 41.4924336 1 1
  20.0955891 39.9481364 4 4
  20.9506636 40.6447347 10 15",header=TRUE)
# make the graphics device high enough to hold Albania
x11(height=10,width=5)
# display the map upon which you want the pies
map(xlim=c(19,21.1),ylim=c(39.5,42.6))
# display the pies
library(plotrix)
for(pp in 1:4) floating.pie(sampledf[pp,"x"],sampledf[pp,"y"],
  unlist(sampledf[pp,c("City","Village")]),radius=0.1)

Jim



From ashisdeb83 at gmail.com  Wed Apr 16 12:07:10 2014
From: ashisdeb83 at gmail.com (Ashis Deb)
Date: Wed, 16 Apr 2014 15:37:10 +0530
Subject: [R] Writing a function in a corrrect way
Message-ID: <CAFcJUTqy_A9GiqQeSAMWo-EPLmYc6KjkdBN+ekCpG-xkmhSyTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/ecdf621a/attachment-0001.pl>

From jim at bitwrit.com.au  Wed Apr 16 12:06:14 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 16 Apr 2014 20:06:14 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<534E52AF.8020506@bitwrit.com.au>
	<7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
Message-ID: <534E5616.8050905@bitwrit.com.au>

On 04/16/2014 07:59 PM, DrunkenPhD wrote:
> Ok this seems to work perfect,
>
> Dont want to be boring but what if plotting in real map smth like:
>
> hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype =
> 'roadmap')
> ggmap(hdf, extent = 'device')
>
I'm not sure that this will work, as ggmap is part of ggplot2 and thus 
based on grid graphics. The plotrix package is written for base 
graphics. If there have been any transformations of coordinates, the 
pies might be in the wrong place or not appear at all. Just substitute 
the above call for the map call in my example and "print" the resulting 
object, then see what happens with the pies.

Jim



From frtog at vestas.com  Wed Apr 16 12:10:54 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 16 Apr 2014 12:10:54 +0200
Subject: [R] netCDF to raster and spatial projection
In-Reply-To: <BLU0-SMTP31790459AB6F45B1608B842D9530@phx.gbl>
References: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>
	<BLU0-SMTP31790459AB6F45B1608B842D9530@phx.gbl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA619@DKRDSEXC016.vestas.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/8ba14e33/attachment-0001.pl>

From jim at bitwrit.com.au  Wed Apr 16 12:17:49 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 16 Apr 2014 20:17:49 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <f23e2132-07fd-45e0-8a17-2ddb30c59480@googlegroups.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<534E52AF.8020506@bitwrit.com.au>
	<7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
	<f23e2132-07fd-45e0-8a17-2ddb30c59480@googlegroups.com>
Message-ID: <534E58CD.9080203@bitwrit.com.au>

See inline

On 04/16/2014 08:13 PM, DrunkenPhD wrote:
> No nothing :((((
> I tried :
>  > hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype
> = 'roadmap')
>  > sampledf<-read.table(text="x y City Village
>
> 19.9437314 40.7086377 120 425
> 20.2214171 41.4924336 1 1
> 20.0955891 39.9481364 4 4
> 20.9506636 40.6447347 10 15",header=TRUE)
> # make the graphics device high enough to hold Albania
> x11(height=10,width=5)
> # display the map upon which you want the pies

hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8,
  maptype = 'roadmap')
ggmap(hdf, extent = 'device')
# I don't know if you have to do anything else here

> # display the pies
> library(plotrix)
> for(pp in 1:4) floating.pie(sampledf[pp,"x"],sampledf[pp,"y"],
> unlist(sampledf[pp,c("City","Village")]),radius=0.1)
>
> but pffff nothing
> What to do

Look at the documentation for ggmap (I don't have the package on my 
system, so I can't do it for you). Try par("usr") to see the coordinates 
of the plot.

Jim



From frtog at vestas.com  Wed Apr 16 12:25:37 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 16 Apr 2014 12:25:37 +0200
Subject: [R] netCDF to raster and spatial projection
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA619@DKRDSEXC016.vestas.net>
References: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>
	<BLU0-SMTP31790459AB6F45B1608B842D9530@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA619@DKRDSEXC016.vestas.net>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA623@DKRDSEXC016.vestas.net>

Hi Bea

Well the first hit lead me to rasterProject{raster}. Will this suit you?


> rasterMG.proj <- projectRaster(rasterMG, crs=CRS("+init=epsg:21781"))
> print(rasterMG.proj)

class       : RasterLayer 
dimensions  : 116, 91, 10556  (nrow, ncol, ncell)
resolution  : 40.1, 40.1  (x, y)
extent      : 478794.9, 482444, 646645.8, 651297.4  (xmin, xmax, ymin, ymax)
coord. ref. : +init=epsg:21781 +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs 
data source : in memory
names       : part.a 
values      : 0, 1  (min, max)


The difference can be seen by plotting.

plot(rasterMG)
plot(rasterMG.proj)




Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Frede Aakmann T?gersen
> Sent: 16. april 2014 12:11
> To: Bea GD; r-help at r-project.org
> Subject: Re: [R] netCDF to raster and spatial projection
> 
> Well no need to have your data. Usually one can find some suitable data in
> the help for the functions under question. So here is a reproducible example
> from ?meuse.grid.
> 
> > data(meuse.grid)
> > coordinates(meuse.grid) <- ~x+y
> > proj4string(meuse.grid) <- CRS("+init=epsg:28992") # see ?meuse for this
> crs
> > gridded(meuse.grid) <- TRUE
> > summary(meuse.grid)
> 
> Object of class SpatialPixelsDataFrame
> Coordinates:
>      min    max
> x 178440 181560
> y 329600 333760
> Is projected: TRUE
> proj4string :
> [+init=epsg:28992 +proj=sterea +lat_0=52.15616055555555
> +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000
> +ellps=bessel +units=m +no_defs]
> Number of points: 3103
> Grid attributes:
>   cellcentre.offset cellsize cells.dim
> x            178460       40        78
> y            329620       40       104
> Data attributes:
>      part.a           part.b            dist        soil     ffreq
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   1:1665   1: 779
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.1193   2:1084   2:1335
>  Median :0.0000   Median :1.0000   Median :0.2715   3: 354   3: 989
>  Mean   :0.3986   Mean   :0.6014   Mean   :0.2971
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.4402
>  Max.   :1.0000   Max.   :1.0000   Max.   :0.9926
> 
> > rasterMG <- raster(meuse.grid)
> > print(rasterMG)
> 
> class       : RasterLayer
> dimensions  : 104, 78, 8112  (nrow, ncol, ncell)
> resolution  : 40, 40  (x, y)
> extent      : 178440, 181560, 329600, 333760  (xmin, xmax, ymin, ymax)
> coord. ref. : +init=epsg:28992 +proj=sterea +lat_0=52.15616055555555
> +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000
> +ellps=bessel +units=m +no_defs
> data source : in memory
> names       : part.a
> values      : 0, 1  (min, max)
> 
> > rasterMG.proj <- spTransform(rasterMG, CRS("+init=epsg:21781"))
> Error in spTransform(rasterMG, CRS("+init=epsg:21781")) :
>   load package rgdal for spTransform methods
> >
> 
> Now perhaps doing the projection before casting it to a raster will work (yes
> I'm guessing since error thrown above is not very informative and traceback()
> does not give anything useful).
> 
> > meuse.grid.proj <- spTransform(meuse.grid, CRS("+init=epsg:21781"))
> Warning message:
> In spTransform(meuse.grid, CRS("+init=epsg:21781")) :
>   Grid warping not available, coercing to points
> 
> > summary(meuse.grid.proj)
> 
> Object of class SpatialPointsDataFrame
> Coordinates:
>        min      max
> x 479029.8 482197.1
> y 646927.4 651003.9
> Is projected: TRUE
> proj4string :
> [+init=epsg:21781 +proj=somerc +lat_0=46.95240555555556
> +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel
> +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs]
> Number of points: 3103
> Data attributes:
>      part.a           part.b            dist        soil     ffreq
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   1:1665   1: 779
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.1193   2:1084   2:1335
>  Median :0.0000   Median :1.0000   Median :0.2715   3: 354   3: 989
>  Mean   :0.3986   Mean   :0.6014   Mean   :0.2971
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.4402
>  Max.   :1.0000   Max.   :1.0000   Max.   :0.9926
> 
> > gridded(meuse.grid.proj) <- TRUE
> suggested tolerance minimum: 0.737332
> Error in points2grid(points, tolerance, round) :
>   dimension 1 : coordinate intervals are not constant
> >
> 
> A warning and an error indicates that the projection results in something that
> is not on a regular grid.
> 
> I don't know what to do but to read some more of the documentation for sp,
> rgdal, etc.
> 
> Hopefully somebody comes up with something that helps us.
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com<mailto:frtog at vestas.com>
> http://www.vestas.com<http://www.vestas.com/>
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to
> www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> If you have received this e-mail in error please contact the sender.
> 
> From: Bea GD [mailto:aguitatierra at hotmail.com]
> Sent: 16. april 2014 11:00
> To: Frede Aakmann T?gersen; r-help at r-project.org
> Subject: Re: [R] netCDF to raster and spatial projection
> 
> Hi Frede,
> 
> Thanks so much for your reply!
> 
> I've tried what you said but I get the following error:
> 
> 
> 
> Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
> 
>   load package rgdal for spTransform methods
> 
> I've checked search() and rgdal is before sp.
> 
> 
> > search()
> 
>  [1] ".GlobalEnv"        "package:chron"     "package:sm"        "package:rgeos"
> 
>  [5] "package:maptools"  "package:ncdf"      "package:rgdal"
> "package:raster"
> 
>  [9] "package:sp"        "tools:rstudio"     "package:stats"     "package:graphics"
> 
> [13] "package:grDevices" "package:utils"     "package:datasets"
> "package:methods"
> 
> [17] "Autoloads"         "package:base"
> 
> Also, when I do library("rgdal") I get this message:
> 
> 
> > library("rgdal")
> 
> rgdal: version: 0.8-16, (SVN revision 498)
> 
> Geospatial Data Abstraction Library extensions to R successfully loaded
> 
> Loaded GDAL runtime: GDAL 1.10.1, released 2013/08/26
> 
> Path to GDAL shared files: C:/Users/bgonzale/Documents/R/win-
> library/3.0/rgdal/gdal
> 
> GDAL does not use iconv for recoding strings.
> 
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> 
> Path to PROJ.4 shared files: C:/Users/bgonzale/Documents/R/win-
> library/3.0/rgdal/proj
> 
> Maybe the problem is something to do with this? I don't know how to fix it.
> 
> I'd like to provide you with some data, how would be the best way to
> post/sahre a raster?
> 
> Thanks!
> 
> 
> On 16.04.2014 10:17, Frede Aakmann T?gersen wrote:
> 
> Hi Beatriz
> 
> 
> 
> Try to skip this step
> 
> 
> 
>      # Reprojecting into CH1903_LV03
> 
>      # First, change the coordinate reference system (crs)
> 
>      proj4string(rasterDF1) <- "+init=epsg:21781"
> 
> 
> 
> 
> 
> And just do this
> 
> 
> 
>      # Second, reproject the raster
> 
>      rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
> 
> 
> 
> 
> 
> Also there is a spTransform both in the rgdal and sp packages. So are they
> masking each other? rgdal should be before sp in the search() list.
> 
> 
> 
> I cannot be of more help since you provided no data.
> 
> 
> 
> 
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> 
> 
> 
> Frede Aakmann T?gersen
> 
> Specialist, M.Sc., Ph.D.
> 
> Plant Performance & Modeling
> 
> 
> 
> Technology & Service Solutions
> 
> T +45 9730 5135
> 
> M +45 2547 6050
> 
> frtog at vestas.com<mailto:frtog at vestas.com>
> 
> http://www.vestas.com
> 
> 
> 
> Company reg. name: Vestas Wind Systems A/S
> 
> This e-mail is subject to our e-mail disclaimer statement.
> 
> Please refer to
> www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> 
> If you have received this e-mail in error please contact the sender.
> 
> 
> 
> -----Original Message-----
> 
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>
> [mailto:r-help-bounces at r-project.org]
> 
> On Behalf Of Beatriz R. Gonzalez Dominguez
> 
> Sent: 16. april 2014 08:22
> 
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> 
> Subject: [R] netCDF to raster and spatial projection
> 
> 
> 
> I've recently started using R for spatial data. I'd be really grateful
> 
> if you could could help me with this. Thanks!
> 
> 
> 
> Sorry I don't provide a reproducible example. Please ask me if you have
> 
> any questions about the data.
> 
> 
> 
> I've extracted data from a multidimensional netCDF file. This file had
> 
> longitude, latitude and temperature data (for 12 months of a specific year).
> 
> 
> 
>  From this netCDF I've got a data frame for January with these
> 
> variables: longitude, latitude, temperature.
> 
> 
> 
> With this data frame I've created a raster.
> 
> 
> 
>      # Packages
> 
>      library("sp")
> 
>      library("raster")
> 
>      library("rgdal")
> 
>      library("ncdf")
> 
>      library("maptools")
> 
>      library("rgeos")
> 
>      library("sm")
> 
>      library("chron")
> 
> 
> 
>      # Dataframe to raster
> 
>      # Create spatial points data frame
> 
>      coordinates(tmp.df01) <- ~ lon + lat
> 
>      # Coerce to SpatialPixelsDataFrame
> 
>      gridded(tmp.df01) <- T
> 
>      # Coerce to raster
> 
>      rasterDF1 <- raster(tmp.df01)
> 
>      > print(tmp.df01)
> 
>      class       : SpatialPixelsDataFrame
> 
>      dimensions  : 103, 241, 24823, 1  (nrow, ncol, npixels, nlayers)
> 
>      resolution  : 0.02083333, 0.02083333  (x, y)
> 
>      extent      : 5.739583, 10.76042, 45.73958, 47.88542  (xmin, xmax,
> 
> ymin, ymax)
> 
>      coord. ref. : NA
> 
>      names       :           TabsM_1
> 
>      min values  : -18.1389980316162
> 
>      max values  :  2.26920962333679
> 
> 
> 
> There is no value for 'coord. ref.'
> 
> 
> 
> The projection of the original netCDF was WGS84. So I gave this
> 
> projection to the raster.
> 
> 
> 
>      proj4string(rasterDF1) <- "+proj=longlat +datum=WGS84 +ellps=WGS84
> 
> +towgs84=0,0,0"
> 
> 
> 
> Then, I wanted to reproject my raster to another projection:
> 
> 
> 
>      # Reprojecting into CH1903_LV03
> 
>      # First, change the coordinate reference system (crs)
> 
>      proj4string(rasterDF1) <- "+init=epsg:21781"
> 
>      # Second, reproject the raster
> 
>      rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
> 
> 
> 
> At this point I get the following error:
> 
> 
> 
>      Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
> 
>        load package rgdal for spTransform methods
> 
> 
> 
> But the package rgdal is already uploaded! It must be something wrong in
> 
> the code!
> 
> 
> 
> ______________________________________________
> 
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> 
> https://stat.ethz.ch/mailman/listinfo/r-help
> 
> PLEASE do read the posting guide http://www.R-project.org/posting-
> 
> guide.html
> 
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]



From jim at bitwrit.com.au  Wed Apr 16 12:56:09 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 16 Apr 2014 20:56:09 +1000
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <CACje6_bgVMdvq8EjAUGThGL=_-sTVmdF9-966y_-rW5kiKQApw@mail.gmail.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>	<1397347449708-4688683.post@n4.nabble.com>	<534A7E76.4020500@bitwrit.com.au>	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>	<534E52AF.8020506@bitwrit.com.au>	<7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>	<f23e2132-07fd-45e0-8a17-2ddb30c59480@googlegroups.com>	<534E58CD.9080203@bitwrit.com.au>
	<CACje6_bgVMdvq8EjAUGThGL=_-sTVmdF9-966y_-rW5kiKQApw@mail.gmail.com>
Message-ID: <534E61C9.6040108@bitwrit.com.au>

On 04/16/2014 08:29 PM, Endri Raco wrote:
> I see function *segmentGoogleMaps* from package *plotGoogleMaps* does
> exactly what I need with data from dataset *meuse*.
> When I ran code:
> coordinates(sampledf)<-~x+y # convert to SPDF
> proj4string(sampledf) <- CRS('+init=epsg:28992')# adding Coordinate
> Referent Sys.
> # Create web map of Point data
> m<-plotGoogleMaps(sampledf,filename='myMap1.htm')
>
> Everything works just fine. When I try to run code:
>
> # colPalette defines colors for plot
> m<-segmentGoogleMaps(sampledf, zcol=c('City','Village'),
> mapTypeId='ROADMAP',
> filename='myMap4.htm',colPalette=c('#E41A1C','#377EB8'),
> strokeColor='black')
>
> everything goes wrong and all points seems to show in one single
> coordinate pair.
>
> The problem is I think that data in meuse dataset are different from
> mine (I think UTM).
> When tried to convert same result.
> I desperately need to see pie chart in a google map so please help
> solving this issue
>
Whoa! All bets are off! plotGoogleMaps generates overlays on an HTML 
page linked to Google Maps. This is way off what you do with R graphics 
devices. Your best bet is to search:

pie chart google maps

on Google and start reading. I have used plotGoogleMaps, but never put 
pie charts on them, and I really don't have time to learn how at the moment.

Jim



From goran.brostrom at umu.se  Wed Apr 16 13:07:23 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 16 Apr 2014 13:07:23 +0200
Subject: [R] Trend test for hazard ratios
In-Reply-To: <5EAC8DA1-919F-44F8-95FF-168AB813F409@comcast.net>
References: <mailman.19.1397556011.24959.r-help@r-project.org>	<3dfcdc$gc1e36@ironport9.mayo.edu>
	<5EAC8DA1-919F-44F8-95FF-168AB813F409@comcast.net>
Message-ID: <534E646B.1070309@umu.se>

On 04/15/2014 10:51 PM, David Winsemius wrote:
>
> On Apr 15, 2014, at 6:32 AM, Therneau, Terry M., Ph.D. wrote:
>
>> You can do statistical tests within a single model, for whether
>> portions of it fit or do not fit.  But one cannot take three
>> separate fits and compare them.  The program needs context to know
>> how the three relate to one another.  Say that "group" is your
>> strata variable, trt the variable of interest, and x1, x2 are
>> adjusters.
>>
>> fit <- coxph(Surv(time,status) ~ trt * strata(group) + x1 + x2,
>> data=mydata)
>>
>> Will fit a model with a separate treatment coefficient for each of
>> the groups, and a separate baseline hazard for each.  One can now
>> create a contrast that corresponds to your trend test, using
>> vcov(fit) for the variance matrix and coef(fit) to retrieve the
>> coefficients.
>>
>
> I have at the moment on my workspace a dataset of breast cancer cases
> extracted from SEER that has a factor representing three grades of
> histology: $Grade.abb. $ Grade.abb     : Factor w/ 3 levels
> "Well","Moderate", "Poorly"
>
> It would be reasonable to test whether the grading has a "trend" in
> its effect when controlling for other factors (and it would be
> surprising to a medical audience if there were no effect.). So I
> compare across models using  AgeStgSiz.NG.Rad as my "linear" trend"
> model (with one df for an `as.numeric` version, AgeStgSizRad as my
> no-grade-included baseline, and AgeStgSiz.FG.Rad as my full factor
> version:

David, your problem is different from the original one; I think you can 
solve yours by transforming the (unordered) factor to an ordered.

Try

AgeStgSiz.NG.Rad <- coxph(Surv(Survmon,
Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
SEER.historic.stage.A+ as.numeric(Size.cat) + ordered(Grade.abb)
  + Rgrp , data=BrILR)

and contrasts based on orthogonal polynomials are used for Grade.abb

see ?contr.poly

G?ran B.
>
>> AgeStgSiz.NG.Rad <- coxph( Surv(Survmon,
>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>> SEER.historic.stage.A+ as.numeric(Size.cat) + as.numeric(Grade.abb)
>> + Rgrp , data=BrILR) AgeStgSizRad <- coxph( Surv(Survmon,
>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>> SEER.historic.stage.A+ as.numeric(Size.cat) + Rgrp , data=BrILR)
>> AgeStgSiz.FG.Rad <- coxph( Surv(Survmon,
>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>> SEER.historic.stage.A+ as.numeric(Size.cat) + Grade.abb + Rgrp ,
>> data=BrILR) 2*diff(summary(AgeStgSizRad)[['loglik']])
> [1] 5166.291
>> 2*diff(summary(AgeStgSiz.NG.Rad)[['loglik']])
> [1] 5888.492
>> 2*diff(summary(AgeStgSiz.FG.Rad)[['loglik']])
> [1] 5889.379
>
> So there is strong evidence that adding grade to the existing
> covariates improves the fit but that representing as separate factor
> values with one extra degree of freedom may not be needed. When I add
> grade as a stratum I get a very different 2*loglikelihood:
>
>> AgeStgSiz.SG.Rad <- coxph( Surv(Survmon,
>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>> SEER.historic.stage.A+ as.numeric(Size.cat) + strata(Grade.abb) +
>> Rgrp , data=BrILR) 2*diff(summary(AgeStgSiz.SG.Rad)[['loglik']])
> [1] 3980.908
>
>> dput( vcov(AgeStgSiz.SG.Rad) )
> structure(c(9.00241385282728e-06, -4.45446264398645e-07,
> 5.18927440846587e-07, 2.62020260612094e-07, 7.47434378232446e-07,
> -4.45446264398645e-07, 0.0046168537719431, 0.00445692601518848,
> -8.67833275051278e-07, -3.68093395861629e-05, 5.18927440846587e-07,
> 0.00445692601518848, 0.00464685164887969, -1.61616621634903e-05,
> -3.77256742079467e-05, 2.62020260612094e-07, -8.67833275051278e-07,
> -1.61616621634903e-05, 7.84049821976807e-06, 1.8221575745622e-06,
> 7.47434378232446e-07, -3.68093395861629e-05, -3.77256742079467e-05,
> 1.8221575745622e-06, 0.000313989310316303), .Dim = c(5L, 5L),
> .Dimnames = list(c("AgeDx", "SEER.historic.stage.ALocalized",
> "SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"),
> c("AgeDx", "SEER.historic.stage.ALocalized",
> "SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"
> )))
>> dput(coef(AgeStgSiz.SG.Rad))
> structure(c(0.0393472050734995, 0.901971276489615, 1.46695753267995,
> 0.108860100649677, -0.273688779502084), .Names = c("AgeDx",
> "SEER.historic.stage.ALocalized", "SEER.historic.stage.ARegional",
> "as.numeric(Size.cat)", "RgrpTRUE" ))
>
> I'm not particularly facile with contrast construction with var-covar
> matrices, so hoping for a worked example. Also wondering of the
> cross-model comparisons are invalid or less powerful?
>
>
>> Terry T.
>>
>>
>>
>> On 04/15/2014 05:00 AM, r-help-request at r-project.org wrote:
>>> Hello,
>>>
>>> I have the following problem. I stratified my patient cohort into
>>> three ordered groups and performed multivariate adjusted Cox
>>> regression analysis on each group separately. Now I would like to
>>> calculate a p for trend across the hazard ratios that I got for
>>> the three groups. How can I do that if I only have the HR and the
>>> confidence interval? For example I got the following HRs for one
>>> endpoint:
>>>
>>> 1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68).
>>>
>>> There is a trend but how do I calculate if it is significant?
>>>
>>> Best regards
>>>
>>> Marcus Kleber
>>>
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>> read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius Alameda, CA, USA
>
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jfox at mcmaster.ca  Wed Apr 16 13:11:31 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Apr 2014 07:11:31 -0400
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <CAFQiRr6YMzQCx0LJPKwZoWbq=Rfwb0GFaiYQsxcocgMe3fBvPQ@mail.gmail.com>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
	<534D23A0.5040102@yorku.ca> <web-505799764@cgpsrv2.cis.mcmaster.ca>
	<CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>
	<003901cf58d3$c36b3300$4a419900$@mcmaster.ca>
	<CAFQiRr6YMzQCx0LJPKwZoWbq=Rfwb0GFaiYQsxcocgMe3fBvPQ@mail.gmail.com>
Message-ID: <8B49A398-8800-4C45-AE59-3E1E565E13AA@mcmaster.ca>

Dear Xing,

My point wasn't that you should add 1 df for a constant to each cubic but that you need not subtract 1 for continuity. I'm sorry that I didn't make that clear. When you use the natural spline in a regression, there's a constant in the model as a separate term with 1 df, which in effect adjusts the level of the regression curve (assuming one X for simplicity). If you add a constant to each component cubic, the constant in the model is rendered redundant, accounting for the extra df.

I'm afraid that if this is still not sufficiently clear, I'll have to defer to someone with greater powers of explanation.

Best,
John

-------------------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox

> On Apr 16, 2014, at 12:10 AM, Xing Zhao <zhaoxing at uw.edu> wrote:
> 
> Dear John
> 
> Sorry I use 3 degree of freedom for  cubic spline. After using 4, it
> is still not 2. I may make some naive mistake, but I cannot figure
> out. Where is the problem?
> 
> 4 (cubic on the right side of the *interior* knot 8)
> + 4 (cubic on the left side of the *interior* knot 8)
> - 1 (two curves must be continuous at the *interior* knot 8)
> - 1 (two curves must have 1st order derivative continuous at the
> *interior* knot 8)
> - 1 (two curves must have 2nd order derivative continuous at the
> *interior* knot 8)
> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
> boundary knot 15 due to the linearity constraint)
> - 1 (similar for the left)
> = 3, not 2
> 
> Thanks
> Xing
> 
>> On Tue, Apr 15, 2014 at 10:54 AM, John Fox <jfox at mcmaster.ca> wrote:
>> Dear Xing,
>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of Xing Zhao
>>> Sent: Tuesday, April 15, 2014 1:18 PM
>>> To: John Fox
>>> Cc: r-help at r-project.org; Michael Friendly
>>> Subject: Re: [R] The explanation of ns() with df =2
>>> 
>>> Dear Michael and Fox
>>> 
>>> Thanks for your elaboration. Combining your explanations would, to my
>>> understanding, lead to the following  calculation of degree of
>>> freedoms.
>>> 
>>> 3 (cubic on the right side of the *interior* knot 8)
>>> + 3 (cubic on the left side of the *interior* knot 8)
>>> - 1 (two curves must be continuous at the *interior* knot 8)
>> 
>> You shouldn't subtract 1 for continuity since you haven't allowed a
>> different level on each side of the knot (that is your initial counting of 3
>> parameters for the cubic doesn't include a constant).
>> 
>> Best,
>> John
>> 
>>> - 1 (two curves must have 1st order derivative continuous at the
>>> *interior* knot 8)
>>> - 1 (two curves must have 2nd order derivative continuous at the
>>> *interior* knot 8)
>>> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
>>> boundary knot 15 due to the linearity constraint)
>>> - 1 (similar for the left)
>>> = 1, not 2
>>> 
>>> Where is the problem?
>>> 
>>> Best,
>>> Xing
>>> 
>>>> On Tue, Apr 15, 2014 at 6:17 AM, John Fox <jfox at mcmaster.ca> wrote:
>>>> Dear Xing Zhao,
>>>> 
>>>> To elaborate slightly on Michael's comments, a natural cubic spline
>>> with 2 df has one *interior* knot and two boundary knots (as is
>>> apparent in the output you provided). The linearity constraint applies
>>> beyond the boundary knots.
>>>> 
>>>> I hope this helps,
>>>> John
>>>> 
>>>> ------------------------------------------------
>>>> John Fox, Professor
>>>> McMaster University
>>>> Hamilton, Ontario, Canada
>>>> http://socserv.mcmaster.ca/jfox/
>>>> 
>>>> On Tue, 15 Apr 2014 08:18:40 -0400
>>>> Michael Friendly <friendly at yorku.ca> wrote:
>>>>> No, the curves on each side of the know are cubics, joined
>>>>> so they are continuous.  Se the discussion in \S 17.2 in
>>>>> Fox's Applied Regression Analysis.
>>>>> 
>>>>>> On 4/15/2014 4:14 AM, Xing Zhao wrote:
>>>>>> Dear all
>>>>>> 
>>>>>> I understand the definition of Natural Cubic Splines are those
>>> with
>>>>>> linear constraints on the end points. However, it is hard to think
>>>>>> about how this can be implement when df=2. df=2 implies there is
>>> just
>>>>>> one knot, which, according the the definition, the curves on its
>>> left
>>>>>> and its right should be both be lines. This means the whole line
>>>>>> should be a line. But when making some fits. the result still
>>> looks
>>>>>> like 2nd order polynomial.
>>>>>> 
>>>>>> How to think about this problem?
>>>>>> 
>>>>>> Thanks
>>>>>> Xing
>>>>>> 
>>>>>> ns(1:15,df =2)
>>>>>>               1           2
>>>>>>  [1,] 0.0000000  0.00000000
>>>>>>  [2,] 0.1084782 -0.07183290
>>>>>>  [3,] 0.2135085 -0.13845171
>>>>>>  [4,] 0.3116429 -0.19464237
>>>>>>  [5,] 0.3994334 -0.23519080
>>>>>>  [6,] 0.4734322 -0.25488292
>>>>>>  [7,] 0.5301914 -0.24850464
>>>>>>  [8,] 0.5662628 -0.21084190
>>>>>>  [9,] 0.5793481 -0.13841863
>>>>>> [10,] 0.5717456 -0.03471090
>>>>>> [11,] 0.5469035  0.09506722
>>>>>> [12,] 0.5082697  0.24570166
>>>>>> [13,] 0.4592920  0.41197833
>>>>>> [14,] 0.4034184  0.58868315
>>>>>> [15,] 0.3440969  0.77060206
>>>>>> attr(,"degree")
>>>>>> [1] 3
>>>>>> attr(,"knots")
>>>>>> 50%
>>>>>>   8
>>>>>> attr(,"Boundary.knots")
>>>>>> [1]  1 15
>>>>>> attr(,"intercept")
>>>>>> [1] FALSE
>>>>>> attr(,"class")
>>>>>> [1] "ns"     "basis"  "matrix"
>>>>> 
>>>>> 
>>>>> --
>>>>> Michael Friendly     Email: friendly AT yorku DOT ca
>>>>> Professor, Psychology Dept. & Chair, Quantitative Methods
>>>>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>>>>> 4700 Keele Street    Web:   http://www.datavis.ca
>>>>> Toronto, ONT  M3J 1P3 CANADA
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From aguitatierra at hotmail.com  Wed Apr 16 13:33:11 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 16 Apr 2014 13:33:11 +0200
Subject: [R] netCDF to raster and spatial projection
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5CBA623@DKRDSEXC016.vestas.net>
References: <BLU0-SMTP5989426528FB2E2E5F2249D9530@phx.gbl>	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA57E@DKRDSEXC016.vestas.net>	<BLU0-SMTP31790459AB6F45B1608B842D9530@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA619@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5CBA623@DKRDSEXC016.vestas.net>
Message-ID: <BLU0-SMTP1862D7D03A62C86D93C80AD9530@phx.gbl>

Hi Frede,

Thanks so much! It seems to work perfectly, exactly what I wanted to do! :)

All the best,

Bea

On 16.04.2014 12:25, Frede Aakmann T?gersen wrote:
> Hi Bea
>
> Well the first hit lead me to rasterProject{raster}. Will this suit you?
>
>
>> rasterMG.proj <- projectRaster(rasterMG, crs=CRS("+init=epsg:21781"))
>> print(rasterMG.proj)
> class       : RasterLayer
> dimensions  : 116, 91, 10556  (nrow, ncol, ncell)
> resolution  : 40.1, 40.1  (x, y)
> extent      : 478794.9, 482444, 646645.8, 651297.4  (xmin, xmax, ymin, ymax)
> coord. ref. : +init=epsg:21781 +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs
> data source : in memory
> names       : part.a
> values      : 0, 1  (min, max)
>
>
> The difference can be seen by plotting.
>
> plot(rasterMG)
> plot(rasterMG.proj)
>
>
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Frede Aakmann T?gersen
>> Sent: 16. april 2014 12:11
>> To: Bea GD; r-help at r-project.org
>> Subject: Re: [R] netCDF to raster and spatial projection
>>
>> Well no need to have your data. Usually one can find some suitable data in
>> the help for the functions under question. So here is a reproducible example
>> from ?meuse.grid.
>>
>>> data(meuse.grid)
>>> coordinates(meuse.grid) <- ~x+y
>>> proj4string(meuse.grid) <- CRS("+init=epsg:28992") # see ?meuse for this
>> crs
>>> gridded(meuse.grid) <- TRUE
>>> summary(meuse.grid)
>> Object of class SpatialPixelsDataFrame
>> Coordinates:
>>       min    max
>> x 178440 181560
>> y 329600 333760
>> Is projected: TRUE
>> proj4string :
>> [+init=epsg:28992 +proj=sterea +lat_0=52.15616055555555
>> +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000
>> +ellps=bessel +units=m +no_defs]
>> Number of points: 3103
>> Grid attributes:
>>    cellcentre.offset cellsize cells.dim
>> x            178460       40        78
>> y            329620       40       104
>> Data attributes:
>>       part.a           part.b            dist        soil     ffreq
>>   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   1:1665   1: 779
>>   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.1193   2:1084   2:1335
>>   Median :0.0000   Median :1.0000   Median :0.2715   3: 354   3: 989
>>   Mean   :0.3986   Mean   :0.6014   Mean   :0.2971
>>   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.4402
>>   Max.   :1.0000   Max.   :1.0000   Max.   :0.9926
>>
>>> rasterMG <- raster(meuse.grid)
>>> print(rasterMG)
>> class       : RasterLayer
>> dimensions  : 104, 78, 8112  (nrow, ncol, ncell)
>> resolution  : 40, 40  (x, y)
>> extent      : 178440, 181560, 329600, 333760  (xmin, xmax, ymin, ymax)
>> coord. ref. : +init=epsg:28992 +proj=sterea +lat_0=52.15616055555555
>> +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000
>> +ellps=bessel +units=m +no_defs
>> data source : in memory
>> names       : part.a
>> values      : 0, 1  (min, max)
>>
>>> rasterMG.proj <- spTransform(rasterMG, CRS("+init=epsg:21781"))
>> Error in spTransform(rasterMG, CRS("+init=epsg:21781")) :
>>    load package rgdal for spTransform methods
>> Now perhaps doing the projection before casting it to a raster will work (yes
>> I'm guessing since error thrown above is not very informative and traceback()
>> does not give anything useful).
>>
>>> meuse.grid.proj <- spTransform(meuse.grid, CRS("+init=epsg:21781"))
>> Warning message:
>> In spTransform(meuse.grid, CRS("+init=epsg:21781")) :
>>    Grid warping not available, coercing to points
>>
>>> summary(meuse.grid.proj)
>> Object of class SpatialPointsDataFrame
>> Coordinates:
>>         min      max
>> x 479029.8 482197.1
>> y 646927.4 651003.9
>> Is projected: TRUE
>> proj4string :
>> [+init=epsg:21781 +proj=somerc +lat_0=46.95240555555556
>> +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel
>> +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs]
>> Number of points: 3103
>> Data attributes:
>>       part.a           part.b            dist        soil     ffreq
>>   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   1:1665   1: 779
>>   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.1193   2:1084   2:1335
>>   Median :0.0000   Median :1.0000   Median :0.2715   3: 354   3: 989
>>   Mean   :0.3986   Mean   :0.6014   Mean   :0.2971
>>   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.4402
>>   Max.   :1.0000   Max.   :1.0000   Max.   :0.9926
>>
>>> gridded(meuse.grid.proj) <- TRUE
>> suggested tolerance minimum: 0.737332
>> Error in points2grid(points, tolerance, round) :
>>    dimension 1 : coordinate intervals are not constant
>> A warning and an error indicates that the projection results in something that
>> is not on a regular grid.
>>
>> I don't know what to do but to read some more of the documentation for sp,
>> rgdal, etc.
>>
>> Hopefully somebody comes up with something that helps us.
>>
>> Yours sincerely / Med venlig hilsen
>>
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com<mailto:frtog at vestas.com>
>> http://www.vestas.com<http://www.vestas.com/>
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to
>> www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
>> If you have received this e-mail in error please contact the sender.
>>
>> From: Bea GD [mailto:aguitatierra at hotmail.com]
>> Sent: 16. april 2014 11:00
>> To: Frede Aakmann T?gersen; r-help at r-project.org
>> Subject: Re: [R] netCDF to raster and spatial projection
>>
>> Hi Frede,
>>
>> Thanks so much for your reply!
>>
>> I've tried what you said but I get the following error:
>>
>>
>>
>> Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
>>
>>    load package rgdal for spTransform methods
>>
>> I've checked search() and rgdal is before sp.
>>
>>
>>> search()
>>   [1] ".GlobalEnv"        "package:chron"     "package:sm"        "package:rgeos"
>>
>>   [5] "package:maptools"  "package:ncdf"      "package:rgdal"
>> "package:raster"
>>
>>   [9] "package:sp"        "tools:rstudio"     "package:stats"     "package:graphics"
>>
>> [13] "package:grDevices" "package:utils"     "package:datasets"
>> "package:methods"
>>
>> [17] "Autoloads"         "package:base"
>>
>> Also, when I do library("rgdal") I get this message:
>>
>>
>>> library("rgdal")
>> rgdal: version: 0.8-16, (SVN revision 498)
>>
>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>
>> Loaded GDAL runtime: GDAL 1.10.1, released 2013/08/26
>>
>> Path to GDAL shared files: C:/Users/bgonzale/Documents/R/win-
>> library/3.0/rgdal/gdal
>>
>> GDAL does not use iconv for recoding strings.
>>
>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>
>> Path to PROJ.4 shared files: C:/Users/bgonzale/Documents/R/win-
>> library/3.0/rgdal/proj
>>
>> Maybe the problem is something to do with this? I don't know how to fix it.
>>
>> I'd like to provide you with some data, how would be the best way to
>> post/sahre a raster?
>>
>> Thanks!
>>
>>
>> On 16.04.2014 10:17, Frede Aakmann T?gersen wrote:
>>
>> Hi Beatriz
>>
>>
>>
>> Try to skip this step
>>
>>
>>
>>       # Reprojecting into CH1903_LV03
>>
>>       # First, change the coordinate reference system (crs)
>>
>>       proj4string(rasterDF1) <- "+init=epsg:21781"
>>
>>
>>
>>
>>
>> And just do this
>>
>>
>>
>>       # Second, reproject the raster
>>
>>       rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
>>
>>
>>
>>
>>
>> Also there is a spTransform both in the rgdal and sp packages. So are they
>> masking each other? rgdal should be before sp in the search() list.
>>
>>
>>
>> I cannot be of more help since you provided no data.
>>
>>
>>
>>
>>
>> Yours sincerely / Med venlig hilsen
>>
>>
>>
>>
>>
>> Frede Aakmann T?gersen
>>
>> Specialist, M.Sc., Ph.D.
>>
>> Plant Performance & Modeling
>>
>>
>>
>> Technology & Service Solutions
>>
>> T +45 9730 5135
>>
>> M +45 2547 6050
>>
>> frtog at vestas.com<mailto:frtog at vestas.com>
>>
>> http://www.vestas.com
>>
>>
>>
>> Company reg. name: Vestas Wind Systems A/S
>>
>> This e-mail is subject to our e-mail disclaimer statement.
>>
>> Please refer to
>> www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
>>
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>
>> -----Original Message-----
>>
>> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>
>> [mailto:r-help-bounces at r-project.org]
>>
>> On Behalf Of Beatriz R. Gonzalez Dominguez
>>
>> Sent: 16. april 2014 08:22
>>
>> To: r-help at r-project.org<mailto:r-help at r-project.org>
>>
>> Subject: [R] netCDF to raster and spatial projection
>>
>>
>>
>> I've recently started using R for spatial data. I'd be really grateful
>>
>> if you could could help me with this. Thanks!
>>
>>
>>
>> Sorry I don't provide a reproducible example. Please ask me if you have
>>
>> any questions about the data.
>>
>>
>>
>> I've extracted data from a multidimensional netCDF file. This file had
>>
>> longitude, latitude and temperature data (for 12 months of a specific year).
>>
>>
>>
>>   From this netCDF I've got a data frame for January with these
>>
>> variables: longitude, latitude, temperature.
>>
>>
>>
>> With this data frame I've created a raster.
>>
>>
>>
>>       # Packages
>>
>>       library("sp")
>>
>>       library("raster")
>>
>>       library("rgdal")
>>
>>       library("ncdf")
>>
>>       library("maptools")
>>
>>       library("rgeos")
>>
>>       library("sm")
>>
>>       library("chron")
>>
>>
>>
>>       # Dataframe to raster
>>
>>       # Create spatial points data frame
>>
>>       coordinates(tmp.df01) <- ~ lon + lat
>>
>>       # Coerce to SpatialPixelsDataFrame
>>
>>       gridded(tmp.df01) <- T
>>
>>       # Coerce to raster
>>
>>       rasterDF1 <- raster(tmp.df01)
>>
>>       > print(tmp.df01)
>>
>>       class       : SpatialPixelsDataFrame
>>
>>       dimensions  : 103, 241, 24823, 1  (nrow, ncol, npixels, nlayers)
>>
>>       resolution  : 0.02083333, 0.02083333  (x, y)
>>
>>       extent      : 5.739583, 10.76042, 45.73958, 47.88542  (xmin, xmax,
>>
>> ymin, ymax)
>>
>>       coord. ref. : NA
>>
>>       names       :           TabsM_1
>>
>>       min values  : -18.1389980316162
>>
>>       max values  :  2.26920962333679
>>
>>
>>
>> There is no value for 'coord. ref.'
>>
>>
>>
>> The projection of the original netCDF was WGS84. So I gave this
>>
>> projection to the raster.
>>
>>
>>
>>       proj4string(rasterDF1) <- "+proj=longlat +datum=WGS84 +ellps=WGS84
>>
>> +towgs84=0,0,0"
>>
>>
>>
>> Then, I wanted to reproject my raster to another projection:
>>
>>
>>
>>       # Reprojecting into CH1903_LV03
>>
>>       # First, change the coordinate reference system (crs)
>>
>>       proj4string(rasterDF1) <- "+init=epsg:21781"
>>
>>       # Second, reproject the raster
>>
>>       rasterDF1.CH <- spTransform(rasterDF1, crs("+init=epsg:21781"))
>>
>>
>>
>> At this point I get the following error:
>>
>>
>>
>>       Error in spTransform(rasterDF1, crs("+init=epsg:21781")) :
>>
>>         load package rgdal for spTransform methods
>>
>>
>>
>> But the package rgdal is already uploaded! It must be something wrong in
>>
>> the code!
>>
>>
>>
>> ______________________________________________
>>
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-help
>>
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>
>> guide.html
>>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>
>



From arne.henningsen at gmail.com  Wed Apr 16 13:48:49 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Wed, 16 Apr 2014 13:48:49 +0200
Subject: [R] Testing correlation of equation in a SUR model fitted by
	systemfit
In-Reply-To: <CALS=5mrwmeVqPbLdhQwzRXCcfB1wMApaw1W-hjR+cDiTUzH8mA@mail.gmail.com>
References: <CALS=5mrwmeVqPbLdhQwzRXCcfB1wMApaw1W-hjR+cDiTUzH8mA@mail.gmail.com>
Message-ID: <CAMTWbJjncM5te4kvVL7aq+67hoGPv=_3Ctuuj0JrttvNkXJ13w@mail.gmail.com>

Dear Paul

On 15 April 2014 19:23, Paul Smith <phhs80 at gmail.com> wrote:
> How to test whether the correlation in the matrix of correlation of a
> two-equations SUR model fitted by package systemfit are significant?

You can use a likelihood-ratio test to compare the SUR model with the
corresponding OLS model. The only difference is that the OLS model
assumes that all off-diagonal elements of the covariance matrix of the
residuals of the different equations are zero. An example:

library( "systemfit" )

# load data set
data( "Kmenta" )

# specify system of equations
eqDemand <- consump ~ price + income
eqSupply <- consump ~ price + farmPrice + trend
system <- list( demand = eqDemand, supply = eqSupply )

# estimate OLS model
fitols <- systemfit( system, data=Kmenta )

# estimate SUR model
fitsur <- systemfit( system, "SUR", data = Kmenta )

# LR test: OLS vs. SUR
lrtest( fitols, fitsur )

# estimate iterated SUR model
fititsur <- systemfit( system, "SUR", data = Kmenta, maxit = 100 )

# LR test: OLS vs. SUR
lrtest( fitols, fititsur )


If you have further questions regarding the systemfit package, you can
also use the "help" forum at systemfit's R-Forge site:

https://r-forge.r-project.org/projects/systemfit/

... and please do not forget to cite systemfit in your publications
(see output of the R command 'citation("systemfit")').

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name



From e.raco at fimif.edu.al  Wed Apr 16 12:29:21 2014
From: e.raco at fimif.edu.al (Endri Raco)
Date: Wed, 16 Apr 2014 12:29:21 +0200
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <534E58CD.9080203@bitwrit.com.au>
References: <1397344830813-4688678.post@n4.nabble.com>
	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<534E52AF.8020506@bitwrit.com.au>
	<7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
	<f23e2132-07fd-45e0-8a17-2ddb30c59480@googlegroups.com>
	<534E58CD.9080203@bitwrit.com.au>
Message-ID: <CACje6_bgVMdvq8EjAUGThGL=_-sTVmdF9-966y_-rW5kiKQApw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/a26cd9b5/attachment-0001.pl>

From endri81 at gmail.com  Wed Apr 16 11:59:45 2014
From: endri81 at gmail.com (DrunkenPhD)
Date: Wed, 16 Apr 2014 02:59:45 -0700 (PDT)
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <534E52AF.8020506@bitwrit.com.au>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<534E52AF.8020506@bitwrit.com.au>
Message-ID: <7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>

Ok this seems to work perfect,

Dont want to be boring but what if plotting in real map smth like:

hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype = 
'roadmap')
ggmap(hdf, extent = 'device')

Regards

On Wednesday, April 16, 2014 11:51:43 AM UTC+2, Jim Lemon wrote:
>
> On 04/16/2014 04:43 AM, DrunkenPhD wrote: 
> > Sorry Jim not for my beginner level :((( 
> > 
> > So if my data are like this : 
> > 
> > xyCityVillage 
> > 
> > 19.943731440.7086377120425 
> > 
> > 20.221417141.492433611 
> > 
> > 20.095589139.948136444 
> > 
> > 20.950663640.64473471015 
> > 
> > how do I plot for every point(x,y) a pie chart with 
> slices(City,Village)? 
> > 
> > Regards 
> > 
> > 
> > how do I plot for every point(x,y) a pie chart with 
> slices(City,Village)? 
> > 
> > 
> Okay, let's try again. 
>
> # get yer data 
> sampledf<-read.table(text="x y City Village 
>   19.9437314 40.7086377 120 425 
>   20.2214171 41.4924336 1 1 
>   20.0955891 39.9481364 4 4 
>   20.9506636 40.6447347 10 15",header=TRUE) 
> # make the graphics device high enough to hold Albania 
> x11(height=10,width=5) 
> # display the map upon which you want the pies 
> map(xlim=c(19,21.1),ylim=c(39.5,42.6)) 
> # display the pies 
> library(plotrix) 
> for(pp in 1:4) floating.pie(sampledf[pp,"x"],sampledf[pp,"y"], 
>   unlist(sampledf[pp,c("City","Village")]),radius=0.1) 
>
> Jim 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From endri81 at gmail.com  Wed Apr 16 12:13:57 2014
From: endri81 at gmail.com (DrunkenPhD)
Date: Wed, 16 Apr 2014 03:13:57 -0700 (PDT)
Subject: [R] Pie charts using plotGooglemaps
In-Reply-To: <7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
References: <1397344830813-4688678.post@n4.nabble.com>	<5349D2DE.2080203@bitwrit.com.au>
	<1397347449708-4688683.post@n4.nabble.com>
	<534A7E76.4020500@bitwrit.com.au>
	<bd4de092-ca27-4856-a5da-5c8fe6b4a8fc@googlegroups.com>
	<534E52AF.8020506@bitwrit.com.au>
	<7ea23866-68b4-4f0a-bef2-b9a5e9d3fc09@googlegroups.com>
Message-ID: <f23e2132-07fd-45e0-8a17-2ddb30c59480@googlegroups.com>

No nothing :((((
I tried :
> hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype = 
'roadmap')
> sampledf<-read.table(text="x y City Village

 19.9437314 40.7086377 120 425
 20.2214171 41.4924336 1 1
 20.0955891 39.9481364 4 4
 20.9506636 40.6447347 10 15",header=TRUE)
# make the graphics device high enough to hold Albania
x11(height=10,width=5)
# display the map upon which you want the pies
map(hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype =
                       'roadmap')
    ggmap(hdf, extent = 'device'))
# display the pies
library(plotrix)
for(pp in 1:4) floating.pie(sampledf[pp,"x"],sampledf[pp,"y"],
                            
unlist(sampledf[pp,c("City","Village")]),radius=0.1)

but pffff nothing 
What to do






On Wednesday, April 16, 2014 11:59:45 AM UTC+2, DrunkenPhD wrote:
>
> Ok this seems to work perfect,
>
> Dont want to be boring but what if plotting in real map smth like:
>
> hdf <- get_map(location = c(20.166065, 41.270679), zoom = 8, maptype = 
> 'roadmap')
> ggmap(hdf, extent = 'device')
>
> Regards
>
> On Wednesday, April 16, 2014 11:51:43 AM UTC+2, Jim Lemon wrote:
>>
>> On 04/16/2014 04:43 AM, DrunkenPhD wrote: 
>> > Sorry Jim not for my beginner level :((( 
>> > 
>> > So if my data are like this : 
>> > 
>> > xyCityVillage 
>> > 
>> > 19.943731440.7086377120425 
>> > 
>> > 20.221417141.492433611 
>> > 
>> > 20.095589139.948136444 
>> > 
>> > 20.950663640.64473471015 
>> > 
>> > how do I plot for every point(x,y) a pie chart with 
>> slices(City,Village)? 
>> > 
>> > Regards 
>> > 
>> > 
>> > how do I plot for every point(x,y) a pie chart with 
>> slices(City,Village)? 
>> > 
>> > 
>> Okay, let's try again. 
>>
>> # get yer data 
>> sampledf<-read.table(text="x y City Village 
>>   19.9437314 40.7086377 120 425 
>>   20.2214171 41.4924336 1 1 
>>   20.0955891 39.9481364 4 4 
>>   20.9506636 40.6447347 10 15",header=TRUE) 
>> # make the graphics device high enough to hold Albania 
>> x11(height=10,width=5) 
>> # display the map upon which you want the pies 
>> map(xlim=c(19,21.1),ylim=c(39.5,42.6)) 
>> # display the pies 
>> library(plotrix) 
>> for(pp in 1:4) floating.pie(sampledf[pp,"x"],sampledf[pp,"y"], 
>>   unlist(sampledf[pp,c("City","Village")]),radius=0.1) 
>>
>> Jim 
>>
>> ______________________________________________ 
>> R-h... at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help 
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html 
>> and provide commented, minimal, self-contained, reproducible code. 
>>
>

From luca.cerone at gmail.com  Wed Apr 16 14:10:03 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 16 Apr 2014 14:10:03 +0200
Subject: [R] Lazy loading of CSV file
Message-ID: <CAFnz2-8hq6CFseg5su7Q_vYX6dqKGgTAZqsEQKmeygkZEjn1TA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/527e7538/attachment-0001.pl>

From eliza_botto at hotmail.com  Wed Apr 16 14:33:50 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 16 Apr 2014 12:33:50 +0000
Subject: [R] multiple plots on same sheet in R
Message-ID: <BLU170-W131A3B36B24B28B410E134889530@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/a8304bf3/attachment-0001.pl>

From kridox at ymail.com  Wed Apr 16 15:21:37 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 16 Apr 2014 22:21:37 +0900
Subject: [R] multiple plots on same sheet in R
In-Reply-To: <BLU170-W131A3B36B24B28B410E134889530@phx.gbl>
References: <BLU170-W131A3B36B24B28B410E134889530@phx.gbl>
Message-ID: <CAAcyNCw7e_rszM37Ek3Rk6wzh21dYRDGEehF8t0aB2jnc37X_Q@mail.gmail.com>

Hi,

Did you have a look at the "rasterVis" package?

Regards,
Pascal

On Wed, Apr 16, 2014 at 9:33 PM, eliza botto <eliza_botto at hotmail.com> wrote:
>   Dear useRs,
> I drew 12 separate raster maps. I want to combine them in such a way the they appear on the same sheet in R, which will later on be saved. Each row should contain three raster maps, so in total we should have 4 rows with each row containing 3 rasters. I know that mfrow() can do it but I don't exactly know how?
>
> Eliza
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan



From jdnewmil at dcn.davis.CA.us  Wed Apr 16 15:39:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 16 Apr 2014 06:39:17 -0700
Subject: [R] Lazy loading of CSV file
In-Reply-To: <CAFnz2-8hq6CFseg5su7Q_vYX6dqKGgTAZqsEQKmeygkZEjn1TA@mail.gmail.com>
References: <CAFnz2-8hq6CFseg5su7Q_vYX6dqKGgTAZqsEQKmeygkZEjn1TA@mail.gmail.com>
Message-ID: <ebac67da-a6b8-4487-a550-cdfa09f2c1ef@email.android.com>

The standard way to put data into a package is to convert it to RDA as described in the Writing R Extensions document. This is faster and more compact than CSV.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 16, 2014 5:10:03 AM PDT, Luca Cerone <luca.cerone at gmail.com> wrote:
>Hi, in a package I am developing some functions need to use some
>external
>data.
>I have these data as a set of .csv files that I have placed in the
>inst/extdata folder.
>
>At the moment I have a file "db-internal.r" where I  load all the
>internal
>databases that could be used by the functions in my package;
>and assign them to some global (to the package) variables (all with the
>prefix db_ in front of them)
>For example (I didn't come out with a better name, sorry)
>
>db_italian_cities = read.csv(system.file("extdata/italian_cities.csv")
>
>like this I can use db_italian_cities in my functions.
>
>Some of these datasets are quite big and really slow down loading the
>package, plus for some of the task the package is meant to solve they
>might
>not even be required.
>I would like to be able to lazyload these datasets only when needed,
>how
>can I possibly achieve this without creating special databases?
>
>Some of them could change, so I intend to be able to download the most
>recent ones through a function that ensure the package is using the
>most
>recent version,
>so I would really prefer to simply use csv files.
>
>Thanks a lot in advance for the help!
>
>Cheers,
>Luca
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From luca.cerone at gmail.com  Wed Apr 16 16:51:15 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 16 Apr 2014 16:51:15 +0200
Subject: [R] Lazy loading of CSV file
In-Reply-To: <ebac67da-a6b8-4487-a550-cdfa09f2c1ef@email.android.com>
References: <CAFnz2-8hq6CFseg5su7Q_vYX6dqKGgTAZqsEQKmeygkZEjn1TA@mail.gmail.com>
	<ebac67da-a6b8-4487-a550-cdfa09f2c1ef@email.android.com>
Message-ID: <CAFnz2-8fHYNHzJkZg8UHOWdWL2Xg4057FXihRTVOkm1e6QWd3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/fc35bd75/attachment-0001.pl>

From cadeb at usgs.gov  Wed Apr 16 17:21:26 2014
From: cadeb at usgs.gov (Cade, Brian)
Date: Wed, 16 Apr 2014 09:21:26 -0600
Subject: [R] indexing names for looping across computations done on
 pairs of matrices
In-Reply-To: <1397614271.28409.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAM5M9BRxdmoEs1su80X7F8V0YYbMDUjj-e6CXUHY5iG8rf1n6g@mail.gmail.com>
	<1397614271.28409.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAM5M9BSj1UT3Dt-xisv2dDDMdoDntnNorZQuzj7JWkQL0N3WrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/125d253e/attachment-0001.pl>

From petretta at unina.it  Wed Apr 16 17:30:29 2014
From: petretta at unina.it (petretta at unina.it)
Date: Wed, 16 Apr 2014 17:30:29 +0200
Subject: [R] interpreting weight in meta-analysis of proportion
Message-ID: <20140416173029.16146m31zmhbu4np@inbox.unina.it>

Dear all,

I use R 3.0 for Windows.

I performed a meta-analysis of the prevalence (single proportion)  
reported in 14 different studyes using the command:

res<-metaprop(case,n,sm="PFT", comb.fixed=FALSE, comb.random=TRUE,  
studlab<- paste(Study))

print(res)

A referee ask a brief explanation of the W-statistic reported in the  
results, in particular, why the summ of the individual weights of all  
the studies is 100%.

Any suggestion is welcome.


-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy



From luca.cerone at gmail.com  Wed Apr 16 18:03:38 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 16 Apr 2014 18:03:38 +0200
Subject: [R] Lazy loading of CSV file
In-Reply-To: <CAFnz2-8fHYNHzJkZg8UHOWdWL2Xg4057FXihRTVOkm1e6QWd3Q@mail.gmail.com>
References: <CAFnz2-8hq6CFseg5su7Q_vYX6dqKGgTAZqsEQKmeygkZEjn1TA@mail.gmail.com>
	<ebac67da-a6b8-4487-a550-cdfa09f2c1ef@email.android.com>
	<CAFnz2-8fHYNHzJkZg8UHOWdWL2Xg4057FXihRTVOkm1e6QWd3Q@mail.gmail.com>
Message-ID: <CAFnz2-9xw7XrMLBR8Fjy5=6sKB8bRA1ErkAsgK0Yx9H6mGMobA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/a42aa895/attachment-0001.pl>

From felasa at gmail.com  Wed Apr 16 18:13:19 2014
From: felasa at gmail.com (Federico Lasa)
Date: Wed, 16 Apr 2014 11:13:19 -0500
Subject: [R] multiple plots on same sheet in R
In-Reply-To: <BLU170-W131A3B36B24B28B410E134889530@phx.gbl>
References: <BLU170-W131A3B36B24B28B410E134889530@phx.gbl>
Message-ID: <CAE8W1T33+hXSUq79F5=5Q4y=PHVaJtP57XD1XPf56tr9r8ZnLA@mail.gmail.com>

see: ?par

Does running

par(mfrow=c(4,3))

do the job?


On Wed, Apr 16, 2014 at 7:33 AM, eliza botto <eliza_botto at hotmail.com> wrote:
>   Dear useRs,
> I drew 12 separate raster maps. I want to combine them in such a way the they appear on the same sheet in R, which will later on be saved. Each row should contain three raster maps, so in total we should have 4 rows with each row containing 3 rasters. I know that mfrow() can do it but I don't exactly know how?
>
> Eliza
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dkrstajic at hotmail.com  Wed Apr 16 18:18:24 2014
From: dkrstajic at hotmail.com (Damjan)
Date: Wed, 16 Apr 2014 16:18:24 +0000
Subject: [R] paper on cross-validation pitfalls
Message-ID: <DUB125-W11E9F27019DD5125DCB518B4530@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/a31c296e/attachment-0001.pl>

From smartpink111 at yahoo.com  Wed Apr 16 19:03:50 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Apr 2014 10:03:50 -0700 (PDT)
Subject: [R] Mean not working in function
In-Reply-To: <1397234873.4642.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1397234873.4642.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1397667830.2409.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(48)
dat1 <- data.frame(matrix(sample(c(NA, 1:20), 4 * 20, replace = TRUE), ncol = 4),  fac1 = sample(LETTERS, 20, replace = TRUE)) mysummary <- function(dataf) { indx <- sapply(dataf, is.numeric) for (name in names(dataf)[indx]) { cat("Variable name: ", name, ": Mean=", mean(dataf[, name], na.rm = TRUE),  "\n") }
} mysummary2 <- function(dataf) { indx <- sapply(dataf, is.numeric) cat(paste(paste("Variable name: ", names(dataf)[indx], ": Mean=", format(colMeans(dataf[,  indx], na.rm = TRUE), digits = 7), collapse = "\n"), "\n"))
}?

A.K.



Thanks for the reply.
How can I avoid getting factor variables in this loop. I think I need to use dataf[sapply(df2, is.numeric)], but I am not able to combine it with: mean(dataf[,name],na.rm=TRUE). 


On Friday, April 11, 2014 12:47 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
mysummary <- function(dataf){ for(name in names(dataf)){ cat ("Variable name: ", name, ": Mean=", mean(dataf[,name],na.rm=TRUE),"\n") }
}?

##Using some example data:

set.seed(48)
dat1 <- as.data.frame(matrix(sample(c(NA,1:20),4*20,replace=TRUE),ncol=4)) mysummary(dat1)
#Variable name:? V1 : Mean= 11.64706
#Variable name:? V2 : Mean= 10.88889
#Variable name:? V3 : Mean= 12.35 

#Variable name:? V4 : Mean= 10.52632 


#Another way would be:

mysummary2 <- function(dataf){ cat(paste(paste("Variable name: ", names(dataf), ": Mean=", format(colMeans(dataf,na.rm=TRUE),digits=7),collapse="\n"),"\n"))
}
mysummary2(dat1) 

#Variable name:? V1 : Mean= 11.64706
#Variable name:? V2 : Mean= 10.88889
#Variable name:? V3 : Mean= 12.35000
#Variable name:? V4 : Mean= 10.52632 


A.K.


I am trying following function: mysummary <- function(dataf){ for(name in names(dataf)){ cat ("Variable name: ", name, ": Mean=", mean(name),"\n") }
} The variable name is properly picked up but the mean is shows as NA. The command warnings() show:
In mean.default(name) : argument is not numeric or logical: returning NA



From anton.francois134 at gmail.com  Wed Apr 16 14:59:41 2014
From: anton.francois134 at gmail.com (Anton FRANCOIS)
Date: Wed, 16 Apr 2014 14:59:41 +0200
Subject: [R] Problems installing packages
Message-ID: <CACnL63b+i5PDF3v=4AiUMMX4q9RpobJosTKNpa10vAzQzA4cgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/29693e41/attachment-0001.pl>

From kh.m.a.rehman at gmail.com  Wed Apr 16 15:35:55 2014
From: kh.m.a.rehman at gmail.com (Muhammad Abdur Rehman Khawaja)
Date: Wed, 16 Apr 2014 18:35:55 +0500
Subject: [R] Extracting Width and Length of Each Shape in EPS File
Message-ID: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/a348c094/attachment-0001.pl>

From jascha.lehmann at pik-potsdam.de  Wed Apr 16 17:07:54 2014
From: jascha.lehmann at pik-potsdam.de (jlehm)
Date: Wed, 16 Apr 2014 08:07:54 -0700 (PDT)
Subject: [R] plot legend in filled.contour plot with infinite limits
Message-ID: <1397660874539-4688905.post@n4.nabble.com>

Dear R-users,

<http://r.789695.n4.nabble.com/file/n4688905/example.jpg> 

I would like to manipulate the legend bar of a filled.contour plot in the
same way as it is done in the attached example I found on the web.

So, in particular, I would like to limit my z-range and then have triangles
at the ends of the legend that indicate that higher values than max(z-range)
or lower values than min(z-range) are included in the last color given at
then ends of the legend.

Does anyone have an idea how to do this?

Any help would be highly appreciated as I just can't find a solution myself.



--
View this message in context: http://r.789695.n4.nabble.com/plot-legend-in-filled-contour-plot-with-infinite-limits-tp4688905.html
Sent from the R help mailing list archive at Nabble.com.



From osmallenbroek at gmail.com  Wed Apr 16 19:21:40 2014
From: osmallenbroek at gmail.com (Oscar Smallenbroek)
Date: Wed, 16 Apr 2014 19:21:40 +0200
Subject: [R] clmm model specification
Message-ID: <CAN6qCRL=nud+oixN0TPUv1Mw1ME3pBD7oAc4SmRqLsM70yGvXg@mail.gmail.com>

Hello All,

I'm trying to fit a cumulative link mixed model clmm(). I'm currently
having issues with the diagnosing what is wrong with my model from the
output I am getting. I've attached the output in PDF.

The model:
I'm estimating the effect of education, social status, class of parents and
control variables on the educational attainment of respondents (eduRes).
Education and class are ordinal variables. The mixed effects are country
level and describe the education system.

The problems:
I've identified a few sources of error. First I am using an SPSS data set
which gives me some errors when I load it in (see pdf). Second I could be
miss-using the commands in R because I am new to it.
Thirdly, the Hessian is above 1e4.
Fourth, the output I got from my null model changes the variable names (no
idea why).
This also happened the first time I tried fitting the model. I fixed this
by chancing the contrast for eduPar, eduRes and the EGP (all the ordinal
variables). These variables now seem to have the right names. However the
cohort and gender dummies do not.
Lastly, when I add my country level variables the hessian does not compute.

Any suggestions are welcome.

Regards,

Oscar
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rquestions.pdf
Type: application/pdf
Size: 83356 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/9c88c8bf/attachment-0002.pdf>

From acos at dpi.inpe.br  Wed Apr 16 20:06:46 2014
From: acos at dpi.inpe.br (=?iso-8859-1?Q?Alexsandro_C=E2ndido_de_Oliveira_Silva?=)
Date: Wed, 16 Apr 2014 15:06:46 -0300
Subject: [R] Values cells
Message-ID: <05fd01cf599e$a167c130$e4374390$@dpi.inpe.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/9c25c5fb/attachment-0001.pl>

From frtog at vestas.com  Wed Apr 16 20:44:46 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 16 Apr 2014 20:44:46 +0200
Subject: [R] Values cells
In-Reply-To: <05fd01cf599e$a167c130$e4374390$@dpi.inpe.br>
References: <05fd01cf599e$a167c130$e4374390$@dpi.inpe.br>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA52BE@DKRDSEXC016.vestas.net>

Well, if you are using the print method on a raster object  what do you get then?

Try this:

> library(raster)
Loading required package: sp
>      logo <- raster(system.file("external/rlogo.grd", package="raster")) 
> print(logo)
class       : RasterLayer 
band        : 1  (of  3  bands)
dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
resolution  : 1, 1  (x, y)
extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=merc 
data source : c:\Programmer\R\R-3.0.2\library\raster\external\rlogo.grd 
names       : red 
values      : 0, 255  (min, max)

See the values entry. Since this is a color image there are 3 bands. What you see above is for the first band ("red").

Going from 0 to 255 for red is no surprise. You will probably see the same for green and blue as well.

What are you really looking for?

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Alexsandro C?ndido de Oliveira Silva
> Sent: 16. april 2014 20:07
> To: r-help at r-project.org
> Subject: [R] Values cells
> 
> Hi folks,
> 
> I'm using the raster package.
> 
> I need to get the min and max values between the cells of a raster,
> something like this: [min, max]. How?
> 
> 
> 
> ---
> Este email est? limpo de v?rus e malwares porque a prote??o do avast!
> Antiv?rus est? ativa.
> 
> 
> 	[[alternative HTML version deleted]]



From lmarotta at stanford.edu  Wed Apr 16 20:45:50 2014
From: lmarotta at stanford.edu (Luana Marotta)
Date: Wed, 16 Apr 2014 11:45:50 -0700
Subject: [R] Using pre-defined IRT parameters in ltm package
Message-ID: <CAPuc1zRHv6WUxan=VOqUYpQ7g6xLSTmaerCiLCD=-4g7fp=JxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/c6942ba7/attachment-0001.pl>

From searl at vt.edu  Wed Apr 16 21:01:14 2014
From: searl at vt.edu (Steve E.)
Date: Wed, 16 Apr 2014 12:01:14 -0700 (PDT)
Subject: [R] help incorporating data subset lengths in function with ddply
Message-ID: <1397674874215-4688926.post@n4.nabble.com>

Dear R Community,

I am having some trouble with a task that I hope you might be able to help
with. I have a dataset that includes the time and corresponding stream
discharge from numerous storms (example of structure with simplified data
below). I would like to produce a field that details the duration of each
storm, where each storm is a subset of the data and the duration runs from
zero to end for each unique storm. I have been trying to accomplish this
with ddply but to no avail as I am unable to provide ddply (e.g., below)
with the length of the storm (i.e., subset of data). Thank you in advance,
any help would be appreciated.


existing df:
storm,Q_time,Q
s1,2008-08-07 21:15:00,0.000
s1,2008-08-07 21:16:00,3.020
s1,2008-08-07 21:17:00,6.041
s1,2008-08-07 21:18:00,9.061
s1,2008-08-07 21:19:00,12.082
s1,2008-08-07 21:20:00,15.102
s1,2008-08-07 21:21:00,18.123
s1,2008-08-07 21:22:00,11.143
s1,2008-08-07 21:23:00,0.000
s2,2010-10-05 21:00:00,0.000
s2,2010-10-05 21:01:00,1.812
s2,2010-10-05 21:02:00,3.625
s2,2010-10-05 21:03:00,5.437
s2,2010-10-05 21:04:00,7.249
s2,2010-10-05 21:05:00,9.061
s2,2010-10-05 21:06:00,0.874
s2,2010-10-05 21:07:00,0.000

desired df:
storm,Q_time,Q, duration
s1,2008-08-07 21:15:00,0.000,1
s1,2008-08-07 21:16:00,3.020,2
s1,2008-08-07 21:17:00,6.041,3
s1,2008-08-07 21:18:00,9.061,4
s1,2008-08-07 21:19:00,12.082,5
s1,2008-08-07 21:20:00,15.102,6
s1,2008-08-07 21:21:00,18.123,7
s1,2008-08-07 21:22:00,11.143,8
s1,2008-08-07 21:23:00,0.000,9
s2,2010-10-05 21:00:00,0.000,1
s2,2010-10-05 21:01:00,1.812,2
s2,2010-10-05 21:02:00,3.625,3
s2,2010-10-05 21:03:00,5.437,4
s2,2010-10-05 21:04:00,7.249,5
s2,2010-10-05 21:05:00,9.061,6
s2,2010-10-05 21:06:00,0.874,7
s2,2010-10-05 21:07:00,0.000,8

I have been trying variations of the following statement, but I cannot seem
to get the length of the subset correct as I receive an error of the type
'Error: arguments imply differing number of rows: 2401, 0'.

newdf <- ddply(df, "storm", transform, FUN = function(x)
{duration=seq(from=1, by=1, length.out=nrow(x))})

I would really like to get a handle on ddply in this instance as it will be
quite helpful for many other similar calculations that I need to do with
this dataset.

Thanks again,
Stevan




--
View this message in context: http://r.789695.n4.nabble.com/help-incorporating-data-subset-lengths-in-function-with-ddply-tp4688926.html
Sent from the R help mailing list archive at Nabble.com.



From frtog at vestas.com  Wed Apr 16 21:35:11 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 16 Apr 2014 21:35:11 +0200
Subject: [R] help incorporating data subset lengths in function with
 ddply
In-Reply-To: <1397674874215-4688926.post@n4.nabble.com>
References: <1397674874215-4688926.post@n4.nabble.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA52C7@DKRDSEXC016.vestas.net>

Hi

Do you seek something like this:


mydat <- read.table(text="
storm,Q_time,Q, duration
s1,2008-08-07 21:15:00,0.000,1
s1,2008-08-07 21:16:00,3.020,2
s1,2008-08-07 21:17:00,6.041,3
s1,2008-08-07 21:18:00,9.061,4
s1,2008-08-07 21:19:00,12.082,5
s1,2008-08-07 21:20:00,15.102,6
s1,2008-08-07 21:21:00,18.123,7
s1,2008-08-07 21:22:00,11.143,8
s1,2008-08-07 21:23:00,0.000,9
s2,2010-10-05 21:00:00,0.000,1
s2,2010-10-05 21:01:00,1.812,2
s2,2010-10-05 21:02:00,3.625,3
s2,2010-10-05 21:03:00,5.437,4
s2,2010-10-05 21:04:00,7.249,5
s2,2010-10-05 21:05:00,9.061,6
s2,2010-10-05 21:06:00,0.874,7
s2,2010-10-05 21:07:00,0.000,8",
                    h = TRUE, sep =",", stringsAsFactors = FALSE)

mydat$Q_time <- as.POSIXct(strptime(mydat$Q_time, format = "%Y-%m-%d %H:%M:%S"))

tmp <- aggregate(Q_time ~ storm, data = mydat, FUN = function(x) diff(range(x)))

tmp

str(tmp)



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Steve E.
> Sent: 16. april 2014 21:01
> To: r-help at r-project.org
> Subject: [R] help incorporating data subset lengths in function with ddply
> 
> Dear R Community,
> 
> I am having some trouble with a task that I hope you might be able to help
> with. I have a dataset that includes the time and corresponding stream
> discharge from numerous storms (example of structure with simplified data
> below). I would like to produce a field that details the duration of each
> storm, where each storm is a subset of the data and the duration runs from
> zero to end for each unique storm. I have been trying to accomplish this
> with ddply but to no avail as I am unable to provide ddply (e.g., below)
> with the length of the storm (i.e., subset of data). Thank you in advance,
> any help would be appreciated.
> 
> 
> existing df:
> storm,Q_time,Q
> s1,2008-08-07 21:15:00,0.000
> s1,2008-08-07 21:16:00,3.020
> s1,2008-08-07 21:17:00,6.041
> s1,2008-08-07 21:18:00,9.061
> s1,2008-08-07 21:19:00,12.082
> s1,2008-08-07 21:20:00,15.102
> s1,2008-08-07 21:21:00,18.123
> s1,2008-08-07 21:22:00,11.143
> s1,2008-08-07 21:23:00,0.000
> s2,2010-10-05 21:00:00,0.000
> s2,2010-10-05 21:01:00,1.812
> s2,2010-10-05 21:02:00,3.625
> s2,2010-10-05 21:03:00,5.437
> s2,2010-10-05 21:04:00,7.249
> s2,2010-10-05 21:05:00,9.061
> s2,2010-10-05 21:06:00,0.874
> s2,2010-10-05 21:07:00,0.000
> 
> desired df:
> storm,Q_time,Q, duration
> s1,2008-08-07 21:15:00,0.000,1
> s1,2008-08-07 21:16:00,3.020,2
> s1,2008-08-07 21:17:00,6.041,3
> s1,2008-08-07 21:18:00,9.061,4
> s1,2008-08-07 21:19:00,12.082,5
> s1,2008-08-07 21:20:00,15.102,6
> s1,2008-08-07 21:21:00,18.123,7
> s1,2008-08-07 21:22:00,11.143,8
> s1,2008-08-07 21:23:00,0.000,9
> s2,2010-10-05 21:00:00,0.000,1
> s2,2010-10-05 21:01:00,1.812,2
> s2,2010-10-05 21:02:00,3.625,3
> s2,2010-10-05 21:03:00,5.437,4
> s2,2010-10-05 21:04:00,7.249,5
> s2,2010-10-05 21:05:00,9.061,6
> s2,2010-10-05 21:06:00,0.874,7
> s2,2010-10-05 21:07:00,0.000,8
> 
> I have been trying variations of the following statement, but I cannot seem
> to get the length of the subset correct as I receive an error of the type
> 'Error: arguments imply differing number of rows: 2401, 0'.
> 
> newdf <- ddply(df, "storm", transform, FUN = function(x)
> {duration=seq(from=1, by=1, length.out=nrow(x))})
> 
> I would really like to get a handle on ddply in this instance as it will be
> quite helpful for many other similar calculations that I need to do with
> this dataset.
> 
> Thanks again,
> Stevan
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/help-
> incorporating-data-subset-lengths-in-function-with-ddply-tp4688926.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Wed Apr 16 22:09:58 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Apr 2014 13:09:58 -0700
Subject: [R] Regarding snp data
In-Reply-To: <BLU403-EAS371BF3082DFA38D5747E39CC4500@phx.gbl>
References: <BLU403-EAS371BF3082DFA38D5747E39CC4500@phx.gbl>
Message-ID: <A081E2CD-6583-4656-9044-DA80B21455A2@comcast.net>


On Apr 15, 2014, at 4:15 PM, Manan Amin wrote:

> 
> Hello,
> 
> I have a data file of 108mb with snps data of 0,1,2.  I am new in the program and have to do this project.  My first step is to get the p value using chisq.test function.  I have tried running the function however since I am new to language I am aware of how to do this step. My error am getting is cannot allocate vector of size.  Now I have data loaded as in table text file into a variable called data and passing that variable to function chisq.test with df value of 2.
> Sent from my iPhone

Since you have gotten no response in 20 hours, you should start asking yourself whether anyone will be able to offer assistance with what little information you have provided. Try reading the Posting Guide to see what level of detail is expected for communication on a technical newsgroup such as R-help.


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From searl at vt.edu  Wed Apr 16 22:02:16 2014
From: searl at vt.edu (Steve E.)
Date: Wed, 16 Apr 2014 13:02:16 -0700 (PDT)
Subject: [R] help incorporating data subset lengths in function with
	ddply
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA52C7@DKRDSEXC016.vestas.net>
References: <1397674874215-4688926.post@n4.nabble.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA52C7@DKRDSEXC016.vestas.net>
Message-ID: <1397678536676-4688933.post@n4.nabble.com>

Hi Frede - Thank you for responding. Not quite what I am after. Notice that I
included two data sets in my post, the first is the raw data whereas the
second (the desired df) is similar but has a column of sequential numbers in
another column at the end - that column of sequential numbers for each storm
(i.e., subset of data) is what I am after. Thanks again, Stevan



--
View this message in context: http://r.789695.n4.nabble.com/help-incorporating-data-subset-lengths-in-function-with-ddply-tp4688926p4688933.html
Sent from the R help mailing list archive at Nabble.com.



From akssoares at gmail.com  Wed Apr 16 21:35:02 2014
From: akssoares at gmail.com (Ana Karla Silva Soares)
Date: Wed, 16 Apr 2014 16:35:02 -0300
Subject: [R] Help in analysis of similarity in Iramuteq
Message-ID: <CAAiUqK=EkP7uaSVB5hkzRUPfo27=GViA3Wh7RgiqwXmkjDGB9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/0878bfa8/attachment-0001.pl>

From dwinsemius at comcast.net  Wed Apr 16 22:48:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Apr 2014 13:48:23 -0700
Subject: [R] Trend test for hazard ratios
In-Reply-To: <534E646B.1070309@umu.se>
References: <mailman.19.1397556011.24959.r-help@r-project.org>	<3dfcdc$gc1e36@ironport9.mayo.edu>
	<5EAC8DA1-919F-44F8-95FF-168AB813F409@comcast.net>
	<534E646B.1070309@umu.se>
Message-ID: <F03BE399-BB58-4990-8D39-C23F369B856B@comcast.net>


On Apr 16, 2014, at 4:07 AM, G?ran Brostr?m wrote:

> On 04/15/2014 10:51 PM, David Winsemius wrote:
>> 
>> On Apr 15, 2014, at 6:32 AM, Therneau, Terry M., Ph.D. wrote:
>> 
>>> You can do statistical tests within a single model, for whether
>>> portions of it fit or do not fit.  But one cannot take three
>>> separate fits and compare them.  The program needs context to know
>>> how the three relate to one another.  Say that "group" is your
>>> strata variable, trt the variable of interest, and x1, x2 are
>>> adjusters.
>>> 
>>> fit <- coxph(Surv(time,status) ~ trt * strata(group) + x1 + x2,
>>> data=mydata)
>>> 
>>> Will fit a model with a separate treatment coefficient for each of
>>> the groups, and a separate baseline hazard for each.  One can now
>>> create a contrast that corresponds to your trend test, using
>>> vcov(fit) for the variance matrix and coef(fit) to retrieve the
>>> coefficients.
>>> 
>> 
>> I have at the moment on my workspace a dataset of breast cancer cases
>> extracted from SEER that has a factor representing three grades of
>> histology: $Grade.abb. $ Grade.abb     : Factor w/ 3 levels
>> "Well","Moderate", "Poorly"
>> 
>> It would be reasonable to test whether the grading has a "trend" in
>> its effect when controlling for other factors (and it would be
>> surprising to a medical audience if there were no effect.). So I
>> compare across models using  AgeStgSiz.NG.Rad as my "linear" trend"
>> model (with one df for an `as.numeric` version, AgeStgSizRad as my
>> no-grade-included baseline, and AgeStgSiz.FG.Rad as my full factor
>> version:
> 
> David, your problem is different from the original one; I think you can solve yours by transforming the (unordered) factor to an ordered.

Thank you for your interest, I don't see that it is different. I think I do understand model comparison when the models do not have strata.

> 
> Try
> 
> AgeStgSiz.NG.Rad <- coxph(Surv(Survmon,
> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
> SEER.historic.stage.A+ as.numeric(Size.cat) + ordered(Grade.abb)
> + Rgrp , data=BrILR)
> 
> and contrasts based on orthogonal polynomials are used for Grade.abb
> 
> see ?contr.poly

Yes. That should give similar (and hopefully identical)  results to those obtained with the nested models for which I supplied the deviance estimates. The as.numeric() version would correspond to the linear term in an ordered factor polynomial contrast (although it would not be identical since it is not in the full model.) It should be reported as "highly significant" since it is associated with a change in deviance of 5888.492 - 5166.291 on one d.f.. Because there was no material difference in deviance (change of less than 1)  with adding the covariate as an unordered factor, I would predict that the quadratic term should report a p-value in the conventionally "insignificant" range and that is what is seen:

(AgeStgSiz.OG.Rad <- coxph( Surv(Survmon, Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+ SEER.historic.stage.A+ as.numeric(Size.cat) + ordered(Grade.abb) + Rgrp , data=BrILR))
Call:
coxph(formula = Surv(Survmon, Vital.status.recode..study.cutoff.used. == 
    "Dead") ~ AgeDx + SEER.historic.stage.A + as.numeric(Size.cat) + 
    ordered(Grade.abb) + Rgrp, data = BrILR)


                                  coef exp(coef) se(coef)       z    p
AgeDx                           0.0393     1.040   0.0030  13.099 0.00
SEER.historic.stage.ALocalized  0.8986     2.456   0.0679  13.225 0.00
SEER.historic.stage.ARegional   1.4663     4.333   0.0682  21.513 0.00
as.numeric(Size.cat)            0.1101     1.116   0.0028  39.362 0.00
ordered(Grade.abb).L            0.5291     1.697   0.0234  22.608 0.00
ordered(Grade.abb).Q           -0.0166     0.984   0.0177  -0.941 0.35
RgrpTRUE                       -0.2696     0.764   0.0177 -15.212 0.00

Likelihood ratio test=5889  on 7 df, p=0  n= 59583, number of events= 13070

Notice that : 1- pchisq( 2*diff(summary(AgeStgSiz.FG.Rad)[['loglik']]) -2*diff(summary(AgeStgSiz.NG.Rad)[['loglik']]), 1)
[1] 0.3462616
 
... is exactly the p-value reported for the quadratic term. (And the z-statistic is the negative of the square root of the difference in deviance.)

I was hoping for a demonstration of taking the coef() and vcov() values to construct contrast estimates and variances? I've tried hacking the estimable function in the gmodels package so that it would accept an object that had a coef and vcov object, but I'm "not quite there yet".

-- 
David.

> 
> G?ran B.
>> 
>>> AgeStgSiz.NG.Rad <- coxph( Surv(Survmon,
>>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>>> SEER.historic.stage.A+ as.numeric(Size.cat) + as.numeric(Grade.abb)
>>> + Rgrp , data=BrILR) AgeStgSizRad <- coxph( Surv(Survmon,
>>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>>> SEER.historic.stage.A+ as.numeric(Size.cat) + Rgrp , data=BrILR)
>>> AgeStgSiz.FG.Rad <- coxph( Surv(Survmon,
>>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>>> SEER.historic.stage.A+ as.numeric(Size.cat) + Grade.abb + Rgrp ,
>>> data=BrILR) 2*diff(summary(AgeStgSizRad)[['loglik']])
>> [1] 5166.291
>>> 2*diff(summary(AgeStgSiz.NG.Rad)[['loglik']])
>> [1] 5888.492
>>> 2*diff(summary(AgeStgSiz.FG.Rad)[['loglik']])
>> [1] 5889.379
>> 
>> So there is strong evidence that adding grade to the existing
>> covariates improves the fit but that representing as separate factor
>> values with one extra degree of freedom may not be needed. When I add
>> grade as a stratum I get a very different 2*loglikelihood:
>> 
>>> AgeStgSiz.SG.Rad <- coxph( Surv(Survmon,
>>> Vital.status.recode..study.cutoff.used.=="Dead") ~ AgeDx+
>>> SEER.historic.stage.A+ as.numeric(Size.cat) + strata(Grade.abb) +
>>> Rgrp , data=BrILR) 2*diff(summary(AgeStgSiz.SG.Rad)[['loglik']])
>> [1] 3980.908
>> 
>>> dput( vcov(AgeStgSiz.SG.Rad) )
>> structure(c(9.00241385282728e-06, -4.45446264398645e-07,
>> 5.18927440846587e-07, 2.62020260612094e-07, 7.47434378232446e-07,
>> -4.45446264398645e-07, 0.0046168537719431, 0.00445692601518848,
>> -8.67833275051278e-07, -3.68093395861629e-05, 5.18927440846587e-07,
>> 0.00445692601518848, 0.00464685164887969, -1.61616621634903e-05,
>> -3.77256742079467e-05, 2.62020260612094e-07, -8.67833275051278e-07,
>> -1.61616621634903e-05, 7.84049821976807e-06, 1.8221575745622e-06,
>> 7.47434378232446e-07, -3.68093395861629e-05, -3.77256742079467e-05,
>> 1.8221575745622e-06, 0.000313989310316303), .Dim = c(5L, 5L),
>> .Dimnames = list(c("AgeDx", "SEER.historic.stage.ALocalized",
>> "SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"),
>> c("AgeDx", "SEER.historic.stage.ALocalized",
>> "SEER.historic.stage.ARegional", "as.numeric(Size.cat)", "RgrpTRUE"
>> )))
>>> dput(coef(AgeStgSiz.SG.Rad))
>> structure(c(0.0393472050734995, 0.901971276489615, 1.46695753267995,
>> 0.108860100649677, -0.273688779502084), .Names = c("AgeDx",
>> "SEER.historic.stage.ALocalized", "SEER.historic.stage.ARegional",
>> "as.numeric(Size.cat)", "RgrpTRUE" ))
>> 
>> I'm not particularly facile with contrast construction with var-covar
>> matrices, so hoping for a worked example. Also wondering of the
>> cross-model comparisons are invalid or less powerful?
>> 
>> 
>>> Terry T.
>>> 
>>> 
>>> 
>>> On 04/15/2014 05:00 AM, r-help-request at r-project.org wrote:
>>>> Hello,
>>>> 
>>>> I have the following problem. I stratified my patient cohort into
>>>> three ordered groups and performed multivariate adjusted Cox
>>>> regression analysis on each group separately. Now I would like to
>>>> calculate a p for trend across the hazard ratios that I got for
>>>> the three groups. How can I do that if I only have the HR and the
>>>> confidence interval? For example I got the following HRs for one
>>>> endpoint:
>>>> 
>>>> 1.09(0.68-1.74),	1.29(0.94-1.76) and 1.64(1.01-2.68).
>>>> 
>>>> There is a trend but how do I calculate if it is significant?
>>>> 
>>>> Best regards
>>>> 
>>>> Marcus Kleber
>>>> 
>>> 
>>> ______________________________________________ R-help at r-project.org
>>> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>> read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius Alameda, CA, USA
>> 
>> ______________________________________________ R-help at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>> read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From tlumley at uw.edu  Wed Apr 16 23:33:47 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 17 Apr 2014 09:33:47 +1200
Subject: [R] problem on package "survey" , function svyglm,
In-Reply-To: <1397502474.4315.4.camel@milan>
References: <CAB4W2n6P9mc-KmE0NVrCJVvCWnao9C0ZrgSusWgk0L8ks=u1Rg@mail.gmail.com>
	<1397502474.4315.4.camel@milan>
Message-ID: <CAJ55+d+Mt9kFaS0dvw_=n682fe2NgPJivzgL10GK-KO+S-zRtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/4648e83d/attachment-0001.pl>

From ligges at statistik.tu-dortmund.de  Thu Apr 17 00:10:01 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 Apr 2014 00:10:01 +0200
Subject: [R] Problems installing packages
In-Reply-To: <CACnL63b+i5PDF3v=4AiUMMX4q9RpobJosTKNpa10vAzQzA4cgQ@mail.gmail.com>
References: <CACnL63b+i5PDF3v=4AiUMMX4q9RpobJosTKNpa10vAzQzA4cgQ@mail.gmail.com>
Message-ID: <534EFFB9.4010807@statistik.tu-dortmund.de>



On 16.04.2014 14:59, Anton FRANCOIS wrote:
> Hello,
>
> I am woking on ubuntu 13.10 (saucy)
>
> And my version() function return:
>
> version
>
>
>   _
>
> platform i686-pc-linux-gnu
>
> arch i686
>
> os linux-gnu
>
> system i686, linux-gnu
>
> status
>
> major 3
>
> minor 1.0
>
> year 2014
>
> month 04
>
> day 10
>
> svn rev 65387
>
> language R
>
> version.string R version 3.1.0 (2014-04-10)
>
> nickname Spring Dance
>
>
>
> With my class (we are all on ubuntu 13.10) we tried to install plural
> packages, like rDeducer, ggplot2 and doBy.
> Originally I was working with R 3.0.1, and I managed to install ggplot2 but
> not others.
> So I upgrade to 3.1.0 version, And no package would install.
> I get each time the warning message :
>
>
> Warning message:
>
> In install.packages("ggplot2") :
>
> installation of package ???ggplot2??? had non-zero exit status
>
> Maybe the problem comes from jJava, or a bad compilator ?
>
> I really do not know what to do to make it working.
> Can you help ?

Not without the output and the error messages....

Best,
Uwe Ligges


>
> Thank for the answer.
> Sincerly
>
> Anton Francois
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From macqueen1 at llnl.gov  Thu Apr 17 00:15:56 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 16 Apr 2014 22:15:56 +0000
Subject: [R] Values cells
In-Reply-To: <05fd01cf599e$a167c130$e4374390$@dpi.inpe.br>
References: <05fd01cf599e$a167c130$e4374390$@dpi.inpe.br>
Message-ID: <CF744ECA.F38C0%macqueen1@llnl.gov>

I'm pretty sure this is described and not hard to find in the raster
package documentation, which you can download from the CRAN package page.
In addition, r-sig-geo is generally the best place to ask question related
to R's 'geo' packages (which includes raster).

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/16/14 11:06 AM, "Alexsandro C?ndido de Oliveira Silva"
<acos at dpi.inpe.br> wrote:

>Hi folks,
>
>I?m using the raster package.
>
>I need to get the min and max values between the cells of a raster,
>something like this: [min, max]. How?
>
>
>
>---
>Este email est? limpo de v?rus e malwares porque a prote??o do avast!
>Antiv?rus est? ativa.
>
>
>	[[alternative HTML version deleted]]
>



From ligges at statistik.tu-dortmund.de  Thu Apr 17 00:55:06 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 Apr 2014 00:55:06 +0200
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
	<OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
Message-ID: <534F0A4A.6070304@statistik.tu-dortmund.de>



On 16.04.2014 11:00, Pavneet Arora wrote:
> Hello Uwe
>
> Can you explain what you mean by "try to plot the sensity only with few
> hundreds of segemnts"
 >
> Do you mean that I should take some kind of sample and do it? And if so
> what's the best number for the sample and how do i ensure that its not
> biased?

Just ensure that you various plots do not contain too many elements to 
be plotted. If you really need many of these, a bitmap graphics may be 
exceptionally a better idea.

Best,
Uwe Ligges




>
>
>
>
>
> From:   Uwe Ligges <ligges at statistik.tu-dortmund.de>
> To:     Pavneet Arora/UK/RoyalSun at RoyalSun, r-help at r-project.org,
> pavneet17 at yahoo.co.uk
> Date:   15/04/2014 14:08
> Subject:        Re: [R] Fw: Save multiple plots as pdf or jpeg
>
>
>
> You have > 1e6 observations and your lines() have these many segments,
> try to plot the sensity only with few hndreds of segemnts.
>
> Best,
> Uwe Ligges
>
>
> On 15.04.2014 12:27, Pavneet Arora wrote:
>> Hello All,
>>
>> I have multiple plots that I want to save it a single file. At the
> moment,
>> I am saving as pdf. Each plot has a qqnorm, qqline, tiny histogram in
> the
>> top left graph with its density drawn top of it and the normal
>> superimposed on the histogram.
>>
>> As a result, the pdf takes forever to load and doesn?t let me print, as
> it
>> runs out of memory. I was wondering if there is a way if I can save each
>> plot as jpeg and then export it on pdf. Will that make it quicker in
>> loading? If so, how can I do this? And if not, then what are the
>> alternatives.
>>
>> The code that I have at the moment is as follows:
>>
>>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> pdf(file="C:/qqnorm/qqnorms.pdf") ##- Saves all plots in the same pdf
> file
>>
>>
>> for (k in 1:ncol(nums2)){
>>       par(mfrow=c(1,1))
>>
>> ##- QQNorm
>>       qqnorm(nums2[,k],col="lightblue",main=names(nums2)[k])
>>       qqline(nums2[,k],col="red",lwd=2)
>>
>> ##- Tiny Histogram
>> op = par(fig=c(.02,.5,0.4,0.98), new=TRUE)
>>       hist(nums2[,k],freq=F,col="blue",xlab="", ylab="", main="",
>>            axes=F,density=20)
>>
>> ##- Density of the variable
>>       lines(density(nums2[,k],na.rm=T), col="darkred", lwd=2)
>>
>> ##- Super-imposed Normal Density
>> curve(dnorm(x,mean=mean(nums2[,k],na.rm=T),sd=sd(nums2[,k],na.rm=T)),
>>             col="black",lwd=3,add=T) ##- Footnote: title1 <- "nums2[k]"
>>
>> library(moments)
>>       s_kurt <- kurtosis (nums2[,k])
>>       s_skew <- skewness (nums2[,k])
>>       mtxt <- paste ("Variable=",title1, ":" ,
>>                      "Kurt=",round(s_kurt,digits=4), "Skew",
>>                      round(s_skw,digits=4), sep=" ")
>>
>> mtext (mtxt,col="green4",side=1,line=15.6,adj=0.0,cex=0.8,font=2,las=1)
>>
>> }
>> dev.off()
>>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>>
>> Structure of My data:
>>
>> str(nums2)
>> 'data.frame':            1355615 obs. of  39 variables:
>>    $ month                           : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Location_Easting_OSGR           : int  525680 524170 524520 526900
>> 528060 524770 524220 525890 527350 524550 ...
>>    $ Location_Northing_OSGR          : int  178240 181650 182240 177530
>> 179040 181160 180830 179710 177650 180810 ...
>>    $ Longitude                       : num  -0.191 -0.212 -0.206 -0.174
>> -0.157 ...
>>    $ Latitude                        : num  51.5 51.5 51.5 51.5 51.5 ...
>>    $ Police_Force                    : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Number_of_Vehicles              : int  1 1 2 1 1 2 2 1 2 2 ...
>>    $ Number_of_Casualties            : int  1 1 1 1 1 1 1 2 2 5 ...
>>    $ Day_of_Week                     : int  3 4 5 6 2 3 5 6 7 7 ...
>>    $ Local_Authority__District_      : int  12 12 12 12 12 12 12 12 12 12
>> ...
>>    $ X_1_st_Road_Class               : int  3 4 5 3 6 6 5 3 3 4 ...
>>    $ X_1_st_Road_Number              : int  3218 450 0 3220 0 0 0 315
> 3212
>> 450 ...
>>    $ Road_Type                       : int  6 3 6 6 6 6 6 3 6 6 ...
>>    $ Speed_limit                     : int  30 30 30 30 30 30 30 30 30 30
>> ...
>>    $ Junction_Detail                 : int  0 6 0 0 0 0 3 0 6 3 ...
>>    $ Junction_Control                : int  -1 2 -1 -1 -1 -1 4 -1 2 4 ...
>>    $ X_2_nd_Road_Class               : int  -1 5 -1 -1 -1 -1 6 -1 4 5 ...
>>    $ X_2_nd_Road_Number              : int  0 0 0 0 0 0 0 0 304 0 ...
>>    $ Pedestrian_Crossing_Human_Contro: int  0 0 0 0 0 0 0 0 0 0 ...
>>    $ Pedestrian_Crossing_Physical_Fac: int  1 5 0 0 0 0 0 0 5 8 ...
>>    $ Light_Conditions                : int  1 4 4 1 7 1 4 1 4 1 ...
>>    $ Weather_Conditions              : int  2 1 1 1 1 2 1 1 1 1 ...
>>    $ Road_Surface_Conditions         : int  2 1 1 1 2 2 1 1 1 1 ...
>>    $ Special_Conditions_at_Site      : int  0 0 0 0 0 6 0 0 0 0 ...
>>    $ Carriageway_Hazards             : int  0 0 0 0 0 0 0 0 0 0 ...
>>    $ Urban_or_Rural_Area             : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Did_Police_Officer_Attend_Scene_: int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ year                            : int  2005 2005 2005 2005 2005 2005
>> 2005 2005 2005 2005 ...
>>    $ m                               : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Qrtr                            : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ h2                              : int  17 17 0 10 21 12 20 17 22 16
> ...
>>    $ NumberVehGrp                    : int  1 1 2 1 1 2 2 1 2 2 ...
>>    $ NumberCasultGrp                 : int  1 1 1 1 1 1 1 2 2 5 ...
>>    $ lati_round                      : num  51.5 51.5 51.5 51.5 51.5 ...
>>    $ longi_round                     : num  -0.19 -0.21 -0.21 -0.17 -0.16
>> -0.2 -0.21 -0.19 -0.17 -0.21 ...
>>    $ lati_2dp                        : num  51.5 51.5 51.5 51.5 51.5 ...
>>    $ lati_1dp                        : num  51.5 51.5 51.5 51.5 51.5 51.5
>> 51.5 51.5 51.5 51.5 ...
>>    $ longi_2dp                       : num  -0.19 -0.21 -0.21 -0.17 -0.16
>> -0.2 -0.21 -0.19 -0.17 -0.21 ...
>>    $ longi_1dp                       : num  -0.2 -0.2 -0.2 -0.2 -0.2 -0.2
>> -0.2 -0.2 -0.2 -0.2 ...
>>
>>
>> Also when saving as jpeg in R, I realise there is a wildcard in
> filenames,
>> i.e.. 6 plots can be saved as:
>> jpeg(filename="foo%03d.jpeg",. . . )
>> dev.off()
>>
>> But is there any way, where I can save them as the variable name instead
> -
>> so perhaps some use of macro or loop to do so?
>>
>>
>>
>>
> ***********************************************************************************************************************************************************************************************************************
>> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No.
> 93792). Registered in England and Wales at St. Mark???s Court, Chart Way,
> Horsham, West Sussex, RH12 1XL.
>>
>> Authorised by the Prudential Regulation Authority and regulated by the
> Financial Conduct Authority and the Prudential Regulation Authority.
>>
> ************************************************************************************************************************************************************************************************************************
>>
>>                 [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> ______________________________________________________________________________________________
> The following message has been automatically added  to comply with the RSA
> Group IT Security requirements:
>
> This email have arrived via the Internet without any form of encryption or
> verification of the sender.
> As such you should be especially cautious about its origin and content.
> Replies which contain sensitive information or legal/contractual
> obligations are particularly vulnerable.
> In these cases you should not reply unless you are authorised to do so,
> and adequate encryption is employed.
>
> If you have any questions, please speak to the Service Centre on x7979.
> ______________________________________________________________________________________________
>
>
>
> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark?s Court, Chart Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>



From jdnewmil at dcn.davis.CA.us  Thu Apr 17 00:56:08 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 16 Apr 2014 15:56:08 -0700
Subject: [R] Extracting Width and Length of Each Shape in EPS File
In-Reply-To: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
References: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
Message-ID: <467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>

Have you read the vignettes that accompany that package?

You should also read the Posting Guide for this mailing list, as HTML email is not in general a good idea on this list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 16, 2014 6:35:55 AM PDT, Muhammad Abdur Rehman Khawaja <kh.m.a.rehman at gmail.com> wrote:
>Respected Fellows,
>I need little bit guidance regarding, how Can I
>Extract/Calculate/Measure
>width and length of each every shape in .eps file. EPS file is being
>generated from Adobe Illustrator.
>I have used grImport Library in R language to import eps file in R
>environment, but I couldn't understand in which format the data is in
>and
>How can I manipulate it.
>I'll shall be thankful for your cooperation
>------
>Kind Regards
>Khawaja Muhammad Abdur Rehman
>Mechatronics Engineer NUST
>Professional Profile:
>http://pk.linkedin.com/in/khawajamechatronicscaps/<kh.m.a.rehman at gmail.com>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From f.harrell at vanderbilt.edu  Thu Apr 17 02:01:53 2014
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Wed, 16 Apr 2014 19:01:53 -0500
Subject: [R] [R-pkgs] Updates to Hmisc, rms, and greport packages
Message-ID: <534F19F1.1050905@vanderbilt.edu>

The Hmisc package has had a number of updates/fixes:

Changes in version 3.14-4 (2014-04-13)
    * rcspline.eval: stop new logic for ignoring outer values when there 
are many ties when there are also many ties on interior values.  Added 
new logic to use interior unique values of x when the number of unique x 
is small.
    * latexBuild: generalized with insert argument
    * latex.default: modified to use mods of latexBuild, fixed bug with 
caption.loc='bottom' (thanks: YacineH)
    * latex.default: fixed bug where comma did not appear after 
caption={} for ctable (thanks: Johannes Hofrichter)
    * tests: fit.mult.impute.bootstrap.r: added new example (thanks: 
Jane Cook)
    * fit.mult.impute: added call for fit.mult.impute in returned 
object, replacing call from fitter; makes update work for fit.mult.impute
    * summary.formula: fixed recognition of multiple left-hand-side 
variables to trigger call to summaryM (thanks: Kevin Thorpe)
    * summaryM: changed group label to '' instead of 0 for formulas like 
age + sex ~ 1
    * Ecdf: added what argument to all functions
    * nobsY: return constructed id vector
    * addMarginal: instead of .marginal. being logical, make it contain 
names of variables being marginalized over
    * mChoice.c: fixed some inconsistencies

The rms package has also had some changes, and the survfit.formula 
function has been REMOVED, replaced by the npsurv function:

Changes in version 4.2-0 (2014-04-13)
    * Deprecated survfit.formula so would not overlap with function in 
survival
    * Added function npsurv, survplot.npsurv
    * REMOVED survfit.formula
    * Used new type argument to label.Surv for fitting functions
    * cph: added weights argument to residuals.coxph (Thanks: Thomas Lumley)
    * survfit.cph: fixed bug in using wrong type variable.  Thanks: 
Zhiyuan Sun
    * cph: added weighted=TRUE in call to residuals.coxph (Thanks: T Lumley)
    * orm.fit: improved ormfit to not try to deal with NaN in V, 
assuming that step-halving will happen

Some improvements have been made in the greport package:

Changes in version 0.5-1 (2014-04-15)
    * survReport: changed to use npsurv instead of survfit.formula
	 * exReport: changed order of output so that analysis of randomized 
patients marked for exclusions appears last; use LaTeX chngpage package 
to allow detailed table to go into left margin so as to be centered on page
    * exReport: added adjustwidth argument
	 * accrualReport: allowed enrollment target N to be omitted
    * exReport: fine tuning
    * nriskReport: new report to show number of subjects still being 
followed at each day
	 * Merge: added support for data.table
    * nriskReport: added id() variable
    * exReport: fixed bug when there is an exclusion with 0 frequency
    * accrualReport: improved graphics formatting, added minrand argument
    * accrualReport: added enrollmax argument, clarified notation
    * exReport: added ignoreExcl, ignoreRand arguments
    * all: added greportOption texwhere; default is 'gentex'; can 
specify texwhere='' to write non-appendix LaTeX code to console as for knitr
    * dReport: for byx for discrete Y, sense when Y is binary and use 
Wilson interval instead of bootstrap; adjust SE using confidence 
interval if proportion is 0 or 1
    * dReport: changed discreteness non-binary classification to use 
maximum number of unique values or Y instead of minimum
    * add globalVariables call to nriskReport


-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages



From paul at stat.auckland.ac.nz  Thu Apr 17 01:31:29 2014
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 17 Apr 2014 11:31:29 +1200
Subject: [R] Extracting Width and Length of Each Shape in EPS File
In-Reply-To: <467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>
References: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
	<467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>
Message-ID: <534F12D1.5050803@stat.auckland.ac.nz>

Hi

Here is a demonstration that might give you some ideas ...

library(grImport)
PostScriptTrace("flower.ps", "flower.xml")
flower <- readPicture("flower.xml")

grid.newpage()
grid.picture(flower)

# Extract each path, then look at the 'summary' for the path
for (i in 1:flower at summary@numPaths) {
   bb <- flower[i]@summary
   # Draw the result as a check
   grid.polygon(c(bb at xscale[1], bb at xscale[2],
                  bb at xscale[2], bb at xscale[1]),
                c(bb at yscale[1], bb at yscale[1],
                  bb at yscale[2], bb at yscale[2]),
                default.units="native",
                gp=gpar(col=NA, fill=adjustcolor(i, alpha=.5)),
                vp="picture.shape::picture.scale")
}

The flower.ps file in that example is available here ...

https://www.stat.auckland.ac.nz/~paul/R/grImport/importFiles.tar.gz

Hope that helps.

Paul

On 04/17/14 10:56, Jeff Newmiller wrote:
> Have you read the vignettes that accompany that package?
>
> You should also read the Posting Guide for this mailing list, as HTML email is not in general a good idea on this list.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 16, 2014 6:35:55 AM PDT, Muhammad Abdur Rehman Khawaja <kh.m.a.rehman at gmail.com> wrote:
>> Respected Fellows,
>> I need little bit guidance regarding, how Can I
>> Extract/Calculate/Measure
>> width and length of each every shape in .eps file. EPS file is being
>> generated from Adobe Illustrator.
>> I have used grImport Library in R language to import eps file in R
>> environment, but I couldn't understand in which format the data is in
>> and
>> How can I manipulate it.
>> I'll shall be thankful for your cooperation
>> ------
>> Kind Regards
>> Khawaja Muhammad Abdur Rehman
>> Mechatronics Engineer NUST
>> Professional Profile:
>> http://pk.linkedin.com/in/khawajamechatronicscaps/<kh.m.a.rehman at gmail.com>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ahmedatia80 at gmail.com  Thu Apr 17 02:54:31 2014
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Wed, 16 Apr 2014 17:54:31 -0700
Subject: [R] xyplot y scale label help
Message-ID: <CAG6S0Ok9NSNToxoLCMakFCpgA=cFTVj4jy2MviC1L__z3NPKaw@mail.gmail.com>

Hi R usres,

I would like to specify y label units in xyplot. I tried

the yaxp, but it does not work.

Following are my codes;

trellis.device(col=F)
xyplot(GY~N|S,data = Ahmed,
layout=c(5,1,1),
xlab=expression(paste("N rate (kg ", ha^-1,")")),
ylab=expression(paste("Biomass yield (Mg  ",ha^-1,")")),
        ylim=c(12,20),  #xlim=c(-50,700),
  strip = function(...) strip.default(...,style = 1), col=0,
        par.strip.text = list(cex = 0.7),
        scales = list(alternating=F, cex=0.7,yaxp=c(12,20,8)),aspect = 2,
  panel = function(x,y,subscripts,groups,...) {
   #panel.grid(-1,-1)
         m1 <- lm(y ~ x)
         x.seq <- data.frame(x=seq(min(x)*0.95,max(x)*1.05,max(x)/10))
         pred <- predict(m1, x.seq, se.fit=T)
         grid.polygon(c(x.seq$x,rev(x.seq$x)),
          c(pred$fit + 2*pred$se.fit, rev(pred$fit - 2*pred$se.fit) ),
          gp=gpar(col=0, fill="light grey", alpha = 1), default.units
= "native")
   llines(x.seq$x, pred$fit, lty = 1)
         panel.xyplot(x,y)
         print(round(summary(m1)$coef[ 2,c(1,4) ],3) )
         #ltext(0,0.5,paste("Slope = ",round(summary(m1)$coef[2],3),sep=""),
                                # cex=0.65, adj=0)
         #ltext(0,0.4,paste("P(slope) =
",round(summary(m1)$coef[2,4],3),sep=""),
                                # cex=0.65, adj=0)
                                 print(summary(m1))
    }
   )

Any ideas

Thank you


Ahmed M. Attia


Research Assistant
Dept. of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215
FAX: 001-308-455-4024



From jdnewmil at dcn.davis.ca.us  Thu Apr 17 03:18:23 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 16 Apr 2014 18:18:23 -0700 (PDT)
Subject: [R] help incorporating data subset lengths in function with
 ddply
In-Reply-To: <1397674874215-4688926.post@n4.nabble.com>
References: <1397674874215-4688926.post@n4.nabble.com>
Message-ID: <alpine.BSF.2.00.1404161810270.83173@pedal.dcn.davis.ca.us>

Note that ddply is a heavyweight solution, and as your data gets larger 
you may find that using it for little things like this hits performance.

Also, "df" is a base function that you might actually want to use someday,
and you also introduce confusion in the mind of someone reading your code
if you redefine it this way.

existingdf <- read.csv( text=
"storm,Q_time,Q
s1,2008-08-07 21:15:00,0.000
s1,2008-08-07 21:16:00,3.020
s1,2008-08-07 21:17:00,6.041
s1,2008-08-07 21:18:00,9.061
s1,2008-08-07 21:19:00,12.082
s1,2008-08-07 21:20:00,15.102
s1,2008-08-07 21:21:00,18.123
s1,2008-08-07 21:22:00,11.143
s1,2008-08-07 21:23:00,0.000
s2,2010-10-05 21:00:00,0.000
s2,2010-10-05 21:01:00,1.812
s2,2010-10-05 21:02:00,3.625
s2,2010-10-05 21:03:00,5.437
s2,2010-10-05 21:04:00,7.249
s2,2010-10-05 21:05:00,9.061
s2,2010-10-05 21:06:00,0.874
s2,2010-10-05 21:07:00,0.000
", as.is=TRUE )

library(plyr)
# plyr solution
newdf <- ddply( existingdf
               , "storm"
               , function( DF ) {
                   transform( DF
                            , duration=seq.int( length.out=nrow( DF ) ) )
                 }
               )

# base R solution
newdf2 <- transform( existingdf
                    , duration=ave( rep( 1, nrow(existingdf) )
                                  , storm
                                  , FUN=cumsum ) )


On Wed, 16 Apr 2014, Steve E. wrote:

> Dear R Community,
>
> I am having some trouble with a task that I hope you might be able to help
> with. I have a dataset that includes the time and corresponding stream
> discharge from numerous storms (example of structure with simplified data
> below). I would like to produce a field that details the duration of each
> storm, where each storm is a subset of the data and the duration runs from
> zero to end for each unique storm. I have been trying to accomplish this
> with ddply but to no avail as I am unable to provide ddply (e.g., below)
> with the length of the storm (i.e., subset of data). Thank you in advance,
> any help would be appreciated.
>
>
> existing df:
> storm,Q_time,Q
> s1,2008-08-07 21:15:00,0.000
> s1,2008-08-07 21:16:00,3.020
> s1,2008-08-07 21:17:00,6.041
> s1,2008-08-07 21:18:00,9.061
> s1,2008-08-07 21:19:00,12.082
> s1,2008-08-07 21:20:00,15.102
> s1,2008-08-07 21:21:00,18.123
> s1,2008-08-07 21:22:00,11.143
> s1,2008-08-07 21:23:00,0.000
> s2,2010-10-05 21:00:00,0.000
> s2,2010-10-05 21:01:00,1.812
> s2,2010-10-05 21:02:00,3.625
> s2,2010-10-05 21:03:00,5.437
> s2,2010-10-05 21:04:00,7.249
> s2,2010-10-05 21:05:00,9.061
> s2,2010-10-05 21:06:00,0.874
> s2,2010-10-05 21:07:00,0.000
>
> desired df:
> storm,Q_time,Q, duration
> s1,2008-08-07 21:15:00,0.000,1
> s1,2008-08-07 21:16:00,3.020,2
> s1,2008-08-07 21:17:00,6.041,3
> s1,2008-08-07 21:18:00,9.061,4
> s1,2008-08-07 21:19:00,12.082,5
> s1,2008-08-07 21:20:00,15.102,6
> s1,2008-08-07 21:21:00,18.123,7
> s1,2008-08-07 21:22:00,11.143,8
> s1,2008-08-07 21:23:00,0.000,9
> s2,2010-10-05 21:00:00,0.000,1
> s2,2010-10-05 21:01:00,1.812,2
> s2,2010-10-05 21:02:00,3.625,3
> s2,2010-10-05 21:03:00,5.437,4
> s2,2010-10-05 21:04:00,7.249,5
> s2,2010-10-05 21:05:00,9.061,6
> s2,2010-10-05 21:06:00,0.874,7
> s2,2010-10-05 21:07:00,0.000,8
>
> I have been trying variations of the following statement, but I cannot seem
> to get the length of the subset correct as I receive an error of the type
> 'Error: arguments imply differing number of rows: 2401, 0'.
>
> newdf <- ddply(df, "storm", transform, FUN = function(x)
> {duration=seq(from=1, by=1, length.out=nrow(x))})
>
> I would really like to get a handle on ddply in this instance as it will be
> quite helpful for many other similar calculations that I need to do with
> this dataset.
>
> Thanks again,
> Stevan
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/help-incorporating-data-subset-lengths-in-function-with-ddply-tp4688926.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From jdnewmil at dcn.davis.CA.us  Thu Apr 17 03:35:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 16 Apr 2014 18:35:48 -0700
Subject: [R] help incorporating data subset lengths in function
	with	ddply
In-Reply-To: <1397678536676-4688933.post@n4.nabble.com>
References: <1397674874215-4688926.post@n4.nabble.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA52C7@DKRDSEXC016.vestas.net>
	<1397678536676-4688933.post@n4.nabble.com>
Message-ID: <1e068b32-ffd8-469a-b906-dbad469bb260@email.android.com>

Note that the solution you asked for is not robust in the presence of missing data, though Frede's suggestion or something like it would be.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 16, 2014 1:02:16 PM PDT, "Steve E." <searl at vt.edu> wrote:
>Hi Frede - Thank you for responding. Not quite what I am after. Notice
>that I
>included two data sets in my post, the first is the raw data whereas
>the
>second (the desired df) is similar but has a column of sequential
>numbers in
>another column at the end - that column of sequential numbers for each
>storm
>(i.e., subset of data) is what I am after. Thanks again, Stevan
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/help-incorporating-data-subset-lengths-in-function-with-ddply-tp4688926p4688933.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From friendly at yorku.ca  Thu Apr 17 04:03:12 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 16 Apr 2014 22:03:12 -0400
Subject: [R] ggplot2:  using coord_trans for logit -> probability
Message-ID: <534F3660.8010106@yorku.ca>

I'm trying to see if & how I can use coord_trans() with ggplot2 to 
transform the
Y axis of a plot on the logit scale to the probability scale, as opposed 
to  recalculating
everything "manually" and constructing a new plot.
Here is a simple example of the 'base' plot I'd like to transform:

data(Arthritis, package="vcdExtra")
Arthritis$Better <- as.numeric(Arthritis$Improved > "None")
arth.logistic <- glm(Better ~ Age, data=Arthritis, family=binomial)

# get fitted values on the logit scale
pred <- data.frame(Arthritis,
                    predict(arth.logistic, se.fit=TRUE))
library(ggplot2)
library(scales)
# plot on logit scale
gg <- ggplot(pred, aes(x=Age, y=fit)) +
   geom_line(size = 2) + theme_bw() +
   geom_ribbon(aes(ymin = fit - 1.96 * se.fit,
                   ymax = fit + 1.96 * se.fit,), alpha = 0.2,  color = 
"transparent") +
   labs(x = "Age", y = "Log odds (Better)")
gg

Things I've tried that don't work:

 > gg + coord_trans(ytrans="logis")
Error in get(as.character(FUN), mode = "function", envir = envir) :
   object 'logis_trans' of mode 'function' was not found
 >
 > gg + coord_trans(ytrans=probability_trans("logis"))
Error in if (zero_range(range)) { : missing value where TRUE/FALSE needed
In addition: Warning message:
In qfun(x, ...) : NaNs produced
 >

Doing what I want "manually":

# doing it manually
pred2 <- within(pred, {
              prob  <- plogis(fit)
              lower <- plogis(fit - 1.96 * se.fit)
              upper <- plogis(fit + 1.96 * se.fit)
              })


gg2 <- ggplot(pred2, aes(x=Age, y=prob)) +
   geom_line(size = 2) + theme_bw() +
   geom_ribbon(aes(ymin = lower,
                   ymax = upper), alpha = 0.2,  color = "transparent") +
   labs(x = "Age", y = "Probability (Better)")
gg2



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From kevin511511 at gmail.com  Thu Apr 17 04:37:05 2014
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Wed, 16 Apr 2014 22:37:05 -0400
Subject: [R] problem on package "survey" , function svyglm,
In-Reply-To: <CAJ55+d+Mt9kFaS0dvw_=n682fe2NgPJivzgL10GK-KO+S-zRtg@mail.gmail.com>
References: <CAB4W2n6P9mc-KmE0NVrCJVvCWnao9C0ZrgSusWgk0L8ks=u1Rg@mail.gmail.com>
	<1397502474.4315.4.camel@milan>
	<CAJ55+d+Mt9kFaS0dvw_=n682fe2NgPJivzgL10GK-KO+S-zRtg@mail.gmail.com>
Message-ID: <CAB4W2n6mkGPymfQ=Me1Z6BOd+M2pdqn=uBnGrGwPEz-tFfQZqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/6f2e671c/attachment-0001.pl>

From timmarcella at gmail.com  Thu Apr 17 04:37:06 2014
From: timmarcella at gmail.com (Tim Marcella)
Date: Wed, 16 Apr 2014 19:37:06 -0700
Subject: [R] ggplot2: using coord_trans for logit -> probability
In-Reply-To: <534F3660.8010106@yorku.ca>
References: <534F3660.8010106@yorku.ca>
Message-ID: <CAGbJzAJQ=nYcANZmkwxmKz9zuk-9CtAV_M4d8s+FeoLf1i5MDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/344d945d/attachment-0001.pl>

From timmarcella at gmail.com  Thu Apr 17 04:40:14 2014
From: timmarcella at gmail.com (Tim Marcella)
Date: Wed, 16 Apr 2014 19:40:14 -0700
Subject: [R] ggplot2: using coord_trans for logit -> probability
In-Reply-To: <CAGbJzAJQ=nYcANZmkwxmKz9zuk-9CtAV_M4d8s+FeoLf1i5MDw@mail.gmail.com>
References: <534F3660.8010106@yorku.ca>
	<CAGbJzAJQ=nYcANZmkwxmKz9zuk-9CtAV_M4d8s+FeoLf1i5MDw@mail.gmail.com>
Message-ID: <CAGbJzA+OsT+ztbK6VRZr=B3ucYJ50-N2B8cQt8qbUToyqZtiLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140416/8441597c/attachment-0001.pl>

From mark.manger at utoronto.ca  Thu Apr 17 05:01:41 2014
From: mark.manger at utoronto.ca (Mark Manger)
Date: Thu, 17 Apr 2014 03:01:41 +0000
Subject: [R] Labeling/identifying observations in plot after MclustDR from
	Mclust
Message-ID: <80EBCCC5D613EB4FBAD6964110D88C5E8F4723DD@arborexmbx4.UTORARBOR.UTORAD.Utoronto.ca>

Hi,

I?m trying to figure out how to label points in a contour plot produced from the output of MclustDR, the dimension reduction function in the Mclust package.

The original data frame has row names

		RRcoarse govtDeficit    res_gdp GrossFixedCapForm_UN fuelExports
AUS_76    2.000  -4.5125520  1.5197260              26.5169  12.7851900
AUS_81    3.500  -3.6041720  3.7029600              27.1058  20.8597300
AUS_91    4.000  -1.2131010  3.8150380              24.1444  20.5832700
AUS_01    4.000   0.0279132  4.4617860              26.9491  25.5349700
AUT_76    2.000  -2.7850080  7.0378630              25.7365   1.6797000
AUT_81    1.000  -3.4403770  6.4757080              23.2928   1.4688700

I then use these variables to 

imbalances.selections.def = subset(imbalances.all, select=c(5:8,10:12), cu_gdp < 0)
clusters.defs = Mclust(imbalances.selections.def, G=1:10)


I use MclustDR to reduce the dimensions to plot the results, which works beautifully and produces a nice contour plot.

dr.defs = MclustDR(clusters.defs)
plot(dr.defs, what="contour?)

But the plot is not particularly informative unless I know which observation is which.

How can I label the points displayed in the plot to identify the observations? I can probably extract this from the dr.defs object whose str() is below, but I don?t know how to do that, or somehow from the original data frame row names. Help would be greatly appreciated. I know this is trivial in a regular plot(x,y) situation.

str(dr.defs)

List of 22
 $ call         : language MclustDR(object = clusters.defs)
 $ type         : chr "Mclust"
 $ x            : num [1:49, 1:7] 2 3.5 4 4 2 1 1 2 2 2 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:49] "AUS_76" "AUS_81" "AUS_91" "AUS_01" ...
  .. ..$ : chr [1:7] "RRcoarse" "govtDeficit" "res_gdp" "GrossFixedCapForm_UN" ...
 $ Sigma        : num [1:7, 1:7] 0.875 0.116 -0.781 -0.525 2.339 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:7] "RRcoarse" "govtDeficit" "res_gdp" "GrossFixedCapForm_UN" ?
etc etc etc

Many thanks in advance,

Mark S. Manger 
Assistant Professor

Munk School of Global Affairs and Department of Political Science

University of Toronto
Observatory Site | 315 Bloor Street West | Room 212
Toronto, ON   M5S 0A7

mark.manger at utoronto.ca



From smartpink111 at yahoo.com  Thu Apr 17 05:32:10 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Apr 2014 20:32:10 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397666044.32104.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397544324.94583.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397594286.23631.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397610472.82885.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397666044.32104.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1397705530.79250.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Use this code after `lst2`.
lapply(seq_along(lst2), function(i) {
    lstN <- lapply(lst2[[i]], function(x) {
        datN <- as.data.frame(matrix(NA, nrow = 101, ncol = length(names1), dimnames = list(NULL, 
            names1)))
        x1 <- x[, -1]
        qt <- numcolwise(function(y) quantile(y, seq(0, 1, by = 0.01), na.rm = TRUE))(x1)
        datN[, match(names(x1), names(datN))] <- qt
        datN
    })
    arr1 <- array(unlist(lstN), dim = c(dim(lstN[[1]]), length(lstN)), dimnames = list(NULL, 
        names1))
    res <- rowMeans(arr1, dims = 2, na.rm = TRUE)
    colnames(res) <- gsub(" ", "_", colnames(res))
    res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), res, stringsAsFactors = FALSE)
    write.csv(res1, paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile", 
        sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
    function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1, function(x) dim(x)) 

lstNew <- simplify2array(ReadOut1)
 nrow(lstNew)
#[1] 258
dir.create("Indices")
lapply(2:nrow(lstNew), function(i) {
    dat1 <- data.frame(Percentiles = lstNew[1], do.call(cbind, 
        lstNew[i, ]), stringsAsFactors = FALSE)
    colnames(dat1) <- c("Percentiles", paste(names(lst2), rep(rownames(lstNew)[i], 
        length(lst2)), sep = "_"))
    write.csv(dat1, paste0(paste(getwd(), "Indices", gsub(" ", "_", rownames(lstNew)[i]), 
        sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
    function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
names(ReadOut2) <- gsub(".*\\/(.*)\\.csv","\\1",list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))])
ReadOut2$pint_DJF[1:3,1:3]
#  Percentiles G100_pint_DJF G101_pint_DJF
#1          0%      0.982001      1.020892
#2          1%      1.005563      1.039288
#3          2%      1.029126      1.057685
any(is.na(ReadOut2$pint_DJF))
?[1] FALSE 
A.K.







On Wednesday, April 16, 2014 12:34 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
I tried the updated "Quantilecode.txt". It works well but when I open the files in "Indices", I find some columns filled with NAs. This should not be the case given that I am working with simulations and there are no missing values in the process. The ##not correct section yielded no NAs. Check for example, pint_..._DJF in "Indices".

Let be be sure we are in the same page. I removed the ##not correct section of the code, ran the code from beginning to end; Q1 and then Q2. My results are found in the "Indices" folder.

Thanks,
Atem.



From zhaoxing at uw.edu  Thu Apr 17 07:22:02 2014
From: zhaoxing at uw.edu (Xing Zhao)
Date: Wed, 16 Apr 2014 22:22:02 -0700
Subject: [R] The explanation of ns() with df =2
In-Reply-To: <8B49A398-8800-4C45-AE59-3E1E565E13AA@mcmaster.ca>
References: <CAFQiRr7xfFfvhJiwryZXm+SVn7yHZgdqWmqNCr9exBRqWC+swg@mail.gmail.com>
	<534D23A0.5040102@yorku.ca> <web-505799764@cgpsrv2.cis.mcmaster.ca>
	<CAFQiRr6Ymtkn6U_LS6S4T5f+x7htE7TPvZ6LvwSg_VjKE_Ujhw@mail.gmail.com>
	<003901cf58d3$c36b3300$4a419900$@mcmaster.ca>
	<CAFQiRr6YMzQCx0LJPKwZoWbq=Rfwb0GFaiYQsxcocgMe3fBvPQ@mail.gmail.com>
	<8B49A398-8800-4C45-AE59-3E1E565E13AA@mcmaster.ca>
Message-ID: <CAFQiRr4SUjUZNvNgcxqMRDCs6a6VDNFaXS7a_MiwPsfNr1njSw@mail.gmail.com>

Dear John,

Thanks for your patience, got your idea

Best,
Xing

On Wed, Apr 16, 2014 at 4:11 AM, John Fox <jfox at mcmaster.ca> wrote:
> Dear Xing,
>
> My point wasn't that you should add 1 df for a constant to each cubic but that you need not subtract 1 for continuity. I'm sorry that I didn't make that clear. When you use the natural spline in a regression, there's a constant in the model as a separate term with 1 df, which in effect adjusts the level of the regression curve (assuming one X for simplicity). If you add a constant to each component cubic, the constant in the model is rendered redundant, accounting for the extra df.
>
> I'm afraid that if this is still not sufficiently clear, I'll have to defer to someone with greater powers of explanation.
>
> Best,
> John
>
> -------------------------------------------------------------
> John Fox
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox
>
>> On Apr 16, 2014, at 12:10 AM, Xing Zhao <zhaoxing at uw.edu> wrote:
>>
>> Dear John
>>
>> Sorry I use 3 degree of freedom for  cubic spline. After using 4, it
>> is still not 2. I may make some naive mistake, but I cannot figure
>> out. Where is the problem?
>>
>> 4 (cubic on the right side of the *interior* knot 8)
>> + 4 (cubic on the left side of the *interior* knot 8)
>> - 1 (two curves must be continuous at the *interior* knot 8)
>> - 1 (two curves must have 1st order derivative continuous at the
>> *interior* knot 8)
>> - 1 (two curves must have 2nd order derivative continuous at the
>> *interior* knot 8)
>> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
>> boundary knot 15 due to the linearity constraint)
>> - 1 (similar for the left)
>> = 3, not 2
>>
>> Thanks
>> Xing
>>
>>> On Tue, Apr 15, 2014 at 10:54 AM, John Fox <jfox at mcmaster.ca> wrote:
>>> Dear Xing,
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>>> project.org] On Behalf Of Xing Zhao
>>>> Sent: Tuesday, April 15, 2014 1:18 PM
>>>> To: John Fox
>>>> Cc: r-help at r-project.org; Michael Friendly
>>>> Subject: Re: [R] The explanation of ns() with df =2
>>>>
>>>> Dear Michael and Fox
>>>>
>>>> Thanks for your elaboration. Combining your explanations would, to my
>>>> understanding, lead to the following  calculation of degree of
>>>> freedoms.
>>>>
>>>> 3 (cubic on the right side of the *interior* knot 8)
>>>> + 3 (cubic on the left side of the *interior* knot 8)
>>>> - 1 (two curves must be continuous at the *interior* knot 8)
>>>
>>> You shouldn't subtract 1 for continuity since you haven't allowed a
>>> different level on each side of the knot (that is your initial counting of 3
>>> parameters for the cubic doesn't include a constant).
>>>
>>> Best,
>>> John
>>>
>>>> - 1 (two curves must have 1st order derivative continuous at the
>>>> *interior* knot 8)
>>>> - 1 (two curves must have 2nd order derivative continuous at the
>>>> *interior* knot 8)
>>>> - 1 (right side cubic curve must have 2nd order derivative = 0 at the
>>>> boundary knot 15 due to the linearity constraint)
>>>> - 1 (similar for the left)
>>>> = 1, not 2
>>>>
>>>> Where is the problem?
>>>>
>>>> Best,
>>>> Xing
>>>>
>>>>> On Tue, Apr 15, 2014 at 6:17 AM, John Fox <jfox at mcmaster.ca> wrote:
>>>>> Dear Xing Zhao,
>>>>>
>>>>> To elaborate slightly on Michael's comments, a natural cubic spline
>>>> with 2 df has one *interior* knot and two boundary knots (as is
>>>> apparent in the output you provided). The linearity constraint applies
>>>> beyond the boundary knots.
>>>>>
>>>>> I hope this helps,
>>>>> John
>>>>>
>>>>> ------------------------------------------------
>>>>> John Fox, Professor
>>>>> McMaster University
>>>>> Hamilton, Ontario, Canada
>>>>> http://socserv.mcmaster.ca/jfox/
>>>>>
>>>>> On Tue, 15 Apr 2014 08:18:40 -0400
>>>>> Michael Friendly <friendly at yorku.ca> wrote:
>>>>>> No, the curves on each side of the know are cubics, joined
>>>>>> so they are continuous.  Se the discussion in \S 17.2 in
>>>>>> Fox's Applied Regression Analysis.
>>>>>>
>>>>>>> On 4/15/2014 4:14 AM, Xing Zhao wrote:
>>>>>>> Dear all
>>>>>>>
>>>>>>> I understand the definition of Natural Cubic Splines are those
>>>> with
>>>>>>> linear constraints on the end points. However, it is hard to think
>>>>>>> about how this can be implement when df=2. df=2 implies there is
>>>> just
>>>>>>> one knot, which, according the the definition, the curves on its
>>>> left
>>>>>>> and its right should be both be lines. This means the whole line
>>>>>>> should be a line. But when making some fits. the result still
>>>> looks
>>>>>>> like 2nd order polynomial.
>>>>>>>
>>>>>>> How to think about this problem?
>>>>>>>
>>>>>>> Thanks
>>>>>>> Xing
>>>>>>>
>>>>>>> ns(1:15,df =2)
>>>>>>>               1           2
>>>>>>>  [1,] 0.0000000  0.00000000
>>>>>>>  [2,] 0.1084782 -0.07183290
>>>>>>>  [3,] 0.2135085 -0.13845171
>>>>>>>  [4,] 0.3116429 -0.19464237
>>>>>>>  [5,] 0.3994334 -0.23519080
>>>>>>>  [6,] 0.4734322 -0.25488292
>>>>>>>  [7,] 0.5301914 -0.24850464
>>>>>>>  [8,] 0.5662628 -0.21084190
>>>>>>>  [9,] 0.5793481 -0.13841863
>>>>>>> [10,] 0.5717456 -0.03471090
>>>>>>> [11,] 0.5469035  0.09506722
>>>>>>> [12,] 0.5082697  0.24570166
>>>>>>> [13,] 0.4592920  0.41197833
>>>>>>> [14,] 0.4034184  0.58868315
>>>>>>> [15,] 0.3440969  0.77060206
>>>>>>> attr(,"degree")
>>>>>>> [1] 3
>>>>>>> attr(,"knots")
>>>>>>> 50%
>>>>>>>   8
>>>>>>> attr(,"Boundary.knots")
>>>>>>> [1]  1 15
>>>>>>> attr(,"intercept")
>>>>>>> [1] FALSE
>>>>>>> attr(,"class")
>>>>>>> [1] "ns"     "basis"  "matrix"
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Michael Friendly     Email: friendly AT yorku DOT ca
>>>>>> Professor, Psychology Dept. & Chair, Quantitative Methods
>>>>>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>>>>>> 4700 Keele Street    Web:   http://www.datavis.ca
>>>>>> Toronto, ONT  M3J 1P3 CANADA
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From zilefacelvis at yahoo.com  Thu Apr 17 07:31:50 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 16 Apr 2014 22:31:50 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397705530.79250.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397544324.94583.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397594286.23631.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397610472.82885.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397666044.32104.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397705530.79250.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1397712710.2720.YahooMailNeo@web160604.mail.bf1.yahoo.com>

Hi AK,
Thanks very much.
Atem.



On Wednesday, April 16, 2014 9:32 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Use this code after `lst2`.
lapply(seq_along(lst2), function(i) {
? ? lstN <- lapply(lst2[[i]], function(x) {
? ? ? ? datN <- as.data.frame(matrix(NA, nrow = 101, ncol = length(names1), dimnames = list(NULL, 
? ? ? ? ? ? names1)))
? ? ? ? x1 <- x[, -1]
? ? ? ? qt <- numcolwise(function(y) quantile(y, seq(0, 1, by = 0.01), na.rm = TRUE))(x1)
? ? ? ? datN[, match(names(x1), names(datN))] <- qt
? ? ? ? datN
? ? })
? ? arr1 <- array(unlist(lstN), dim = c(dim(lstN[[1]]), length(lstN)), dimnames = list(NULL, 
? ? ? ? names1))
? ? res <- rowMeans(arr1, dims = 2, na.rm = TRUE)
? ? colnames(res) <- gsub(" ", "_", colnames(res))
? ? res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), res, stringsAsFactors = FALSE)
? ? write.csv(res1, paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile", 
? ? ? ? sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1, function(x) dim(x)) 

lstNew <- simplify2array(ReadOut1)
nrow(lstNew)
#[1] 258
dir.create("Indices")
lapply(2:nrow(lstNew), function(i) {
? ? dat1 <- data.frame(Percentiles = lstNew[1], do.call(cbind, 
? ? ? ? lstNew[i, ]), stringsAsFactors = FALSE)
? ? colnames(dat1) <- c("Percentiles", paste(names(lst2), rep(rownames(lstNew)[i], 
? ? ? ? length(lst2)), sep = "_"))
? ? write.csv(dat1, paste0(paste(getwd(), "Indices", gsub(" ", "_", rownames(lstNew)[i]), 
? ? ? ? sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
names(ReadOut2) <- gsub(".*\\/(.*)\\.csv","\\1",list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))])
ReadOut2$pint_DJF[1:3,1:3]
#? Percentiles G100_pint_DJF G101_pint_DJF
#1? ? ? ? ? 0%? ? ? 0.982001? ? ? 1.020892
#2? ? ? ? ? 1%? ? ? 1.005563? ? ? 1.039288
#3? ? ? ? ? 2%? ? ? 1.029126? ? ? 1.057685
any(is.na(ReadOut2$pint_DJF))
?[1] FALSE 
A.K.








On Wednesday, April 16, 2014 12:34 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
I tried the updated "Quantilecode.txt". It works well but when I open the files in "Indices", I find some columns filled with NAs. This should not be the case given that I am working with simulations and there are no missing values in the process. The ##not correct section yielded no NAs. Check for example, pint_..._DJF in "Indices".

Let be be sure we are in the same page. I removed the ##not correct section of the code, ran the code from beginning to end; Q1 and then Q2. My results are found in the "Indices" folder.

Thanks,
Atem.



From gursoyfurkan at gmail.com  Thu Apr 17 08:23:09 2014
From: gursoyfurkan at gmail.com (=?UTF-8?Q?Furkan_G=C3=BCrsoy?=)
Date: Thu, 17 Apr 2014 09:23:09 +0300
Subject: [R] Finding best cut points to discretize continuous values for ID3
	algorithm
Message-ID: <CAC+7TqgPVWF2F3t8B6-VUWFH_VoUyFa6k3UG+G2URv7g-+1w3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/2fd92153/attachment-0001.pl>

From gorillayue at gmail.com  Thu Apr 17 06:10:39 2014
From: gorillayue at gmail.com (Yue Li)
Date: Thu, 17 Apr 2014 00:10:39 -0400
Subject: [R] Fontconfig error in R 3.10 when running
Message-ID: <45B923FB-E42D-45D9-BD9C-707DAC1584F6@gmail.com>

Dear List,

After updating to R 3.10 and Bioconductor 2.14, I'm having a rather frustrating error whenever I try using function like cairo_ps to save eps figures as demonstrated in the following example:

cairo_ps('test.eps')
plot(c(1:10),c(1:10))
Fontconfig error: Cannot load default config file
dev.off()

The plot displays distorted text (attached), and I just couldn't figure out where the fix is after google for hours. Any helps will be very much appreciated.

Many thanks,
Yue



From zhaoxing at uw.edu  Thu Apr 17 10:43:38 2014
From: zhaoxing at uw.edu (Xing Zhao)
Date: Thu, 17 Apr 2014 01:43:38 -0700
Subject: [R] graph: add 2 inches on the left outer region,
	but keep everything unchanged
Message-ID: <CAFQiRr7EmAGQpsiwrm-PqGc9y1p5wJ_0DqBc0ZFVt9ZRsJRCWg@mail.gmail.com>

Hi R experts,

My original graph was plotted, and for some reason, I need to add
extra '2' inches on the left side.
Meanwhile, I want to keep everything unchanged. Particularly, the
length-width ratio for each panel of the original graph is nice,
therefore I want to keep the original ratio

Adding 2 inches to the pdf(width=) and oma=c(0,2,0,0) does not keep
the original length-width ratio.


Thanks for your help
Xing


#orignal plot

pdf(file="d:/test.pdf",width=7, height=7)
par(mfrow=c(3,4), mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.037)

plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')

dev.off()


#new plot
#want to keep everything unchanged, but 2 inches on the left outer region

pdf(file="d:/test.pdf",width=9, height=7)
par(mfrow=c(3,4), mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.03,oma=c(0,2,0,0))

plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')
plot(c(-2,32),c(-0.1,0.9),
type="line",ylim=c(-0.1,0.9),xlab='',ylab="", xaxt='n', yaxt='n')

dev.off()



From smartpink111 at yahoo.com  Thu Apr 17 11:27:42 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Apr 2014 02:27:42 -0700 (PDT)
Subject: [R] Exclude rows by criteria
Message-ID: <1397726862.3320.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(49)
dat1 <- data.frame(group=factor(sample(4,20,replace=TRUE)), year=factor(sample(2003:2014,20,replace=TRUE))) 

indx <- with(dat1, as.numeric(as.character(year)) <=2007 | as.numeric(as.character(year)) >2012 )

with(dat1[!indx,],chisq.test(group,year))
A.K.



I am analyzing two columns (both are factors): group and year by chi-square test: chisq.test(group,year) How can I exclude data (rows) where year is <2007 or >2012 ?
Thanks for your help.



From Thierry.ONKELINX at inbo.be  Thu Apr 17 12:23:21 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 17 Apr 2014 10:23:21 +0000
Subject: [R] ggplot2:  using coord_trans for logit -> probability
In-Reply-To: <534F3660.8010106@yorku.ca>
References: <534F3660.8010106@yorku.ca>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A28FB3@inbomail.inbo.be>

Dear Michael,

You can use geom_smooth directly.

ggplot(pred, aes(x = Age, y = Better)) + geom_smooth(method = "glm", family = binomial)

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
Verzonden: donderdag 17 april 2014 4:03
Aan: R-help
Onderwerp: [R] ggplot2: using coord_trans for logit -> probability

I'm trying to see if & how I can use coord_trans() with ggplot2 to transform the Y axis of a plot on the logit scale to the probability scale, as opposed to  recalculating everything "manually" and constructing a new plot.
Here is a simple example of the 'base' plot I'd like to transform:

data(Arthritis, package="vcdExtra")
Arthritis$Better <- as.numeric(Arthritis$Improved > "None") arth.logistic <- glm(Better ~ Age, data=Arthritis, family=binomial)

# get fitted values on the logit scale
pred <- data.frame(Arthritis,
                    predict(arth.logistic, se.fit=TRUE))
library(ggplot2)
library(scales)
# plot on logit scale
gg <- ggplot(pred, aes(x=Age, y=fit)) +
   geom_line(size = 2) + theme_bw() +
   geom_ribbon(aes(ymin = fit - 1.96 * se.fit,
                   ymax = fit + 1.96 * se.fit,), alpha = 0.2,  color =
"transparent") +
   labs(x = "Age", y = "Log odds (Better)") gg

Things I've tried that don't work:

 > gg + coord_trans(ytrans="logis")
Error in get(as.character(FUN), mode = "function", envir = envir) :
   object 'logis_trans' of mode 'function' was not found  >  > gg + coord_trans(ytrans=probability_trans("logis"))
Error in if (zero_range(range)) { : missing value where TRUE/FALSE needed In addition: Warning message:
In qfun(x, ...) : NaNs produced
 >

Doing what I want "manually":

# doing it manually
pred2 <- within(pred, {
              prob  <- plogis(fit)
              lower <- plogis(fit - 1.96 * se.fit)
              upper <- plogis(fit + 1.96 * se.fit)
              })


gg2 <- ggplot(pred2, aes(x=Age, y=prob)) +
   geom_line(size = 2) + theme_bw() +
   geom_ribbon(aes(ymin = lower,
                   ymax = upper), alpha = 0.2,  color = "transparent") +
   labs(x = "Age", y = "Probability (Better)")
gg2



--
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.



From info at aghmed.fsnet.co.uk  Thu Apr 17 13:43:06 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 17 Apr 2014 12:43:06 +0100
Subject: [R] interpreting weight in meta-analysis of proportion
In-Reply-To: <20140416173029.16146m31zmhbu4np@inbox.unina.it>
References: <20140416173029.16146m31zmhbu4np@inbox.unina.it>
Message-ID: <Zen-1Wakio-0009TP-RO@smarthost01b.mail.zen.net.uk>

At 16:30 16/04/2014, petretta at unina.it wrote:
>Dear all,
>
>I use R 3.0 for Windows.
>
>I performed a meta-analysis of the prevalence (single proportion)
>reported in 14 different studyes using the command:
>
>res<-metaprop(case,n,sm="PFT", comb.fixed=FALSE, comb.random=TRUE,
>studlab<- paste(Study))

Using which package?


>print(res)
>
>A referee ask a brief explanation of the W-statistic reported in the
>results, in particular, why the summ of the individual weights of all
>the studies is 100%.

What did you expect the weights to sum to, I wonder.

>Any suggestion is welcome.
>
>
>--
>Mario Petretta
>Department of Translational Medical Sciences
>Naples University Federico II
>Italy
>
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From kmersman at smail.uni-koeln.de  Thu Apr 17 13:43:34 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Thu, 17 Apr 2014 13:43:34 +0200
Subject: [R] NeweyWest in sandwich-package
Message-ID: <000d01cf5a32$43f0e880$cbd2b980$@uni-koeln.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/0ebbb43e/attachment-0001.pl>

From friendly at yorku.ca  Thu Apr 17 14:44:38 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 17 Apr 2014 08:44:38 -0400
Subject: [R] ggplot2:  using coord_trans for logit -> probability
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3A28FB3@inbomail.inbo.be>
References: <534F3660.8010106@yorku.ca>
	<AA818EAD2576BC488B4F623941DA7427F3A28FB3@inbomail.inbo.be>
Message-ID: <534FCCB6.3030004@yorku.ca>

I know I can do that.  My example was just a toy version of a more 
complex graph I
generate on the logit scale, and save as gg.
I wanted to know if there was a way to transform it to the probability 
scale by using

gg + coord_trans()
with some suitable argument(s)

for example, this *does* work to transform x -> log(x)

gg + coord_trans(x="log")

Reading the documentation in scales, I tried

plogis_trans <- function () {
     probability_trans("logis")
}

but I get errors when I try to use it:

 > gg + coord_trans(y="plogis")
Error in if (zero_range(range)) { : missing value where TRUE/FALSE needed
In addition: Warning message:
In qfun(x, ...) : NaNs produced



-Michael

On 4/17/2014 6:23 AM, ONKELINX, Thierry wrote:
> Dear Michael,
>
> You can use geom_smooth directly.
>
> ggplot(pred, aes(x = Age, y = Better)) + geom_smooth(method = "glm", family = binomial)
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
> Verzonden: donderdag 17 april 2014 4:03
> Aan: R-help
> Onderwerp: [R] ggplot2: using coord_trans for logit -> probability
>
> I'm trying to see if & how I can use coord_trans() with ggplot2 to transform the Y axis of a plot on the logit scale to the probability scale, as opposed to  recalculating everything "manually" and constructing a new plot.
> Here is a simple example of the 'base' plot I'd like to transform:
>
> data(Arthritis, package="vcdExtra")
> Arthritis$Better <- as.numeric(Arthritis$Improved > "None") arth.logistic <- glm(Better ~ Age, data=Arthritis, family=binomial)
>
> # get fitted values on the logit scale
> pred <- data.frame(Arthritis,
>                      predict(arth.logistic, se.fit=TRUE))
> library(ggplot2)
> library(scales)
> # plot on logit scale
> gg <- ggplot(pred, aes(x=Age, y=fit)) +
>     geom_line(size = 2) + theme_bw() +
>     geom_ribbon(aes(ymin = fit - 1.96 * se.fit,
>                     ymax = fit + 1.96 * se.fit,), alpha = 0.2,  color =
> "transparent") +
>     labs(x = "Age", y = "Log odds (Better)") gg
>
> Things I've tried that don't work:
>
>   > gg + coord_trans(ytrans="logis")
> Error in get(as.character(FUN), mode = "function", envir = envir) :
>     object 'logis_trans' of mode 'function' was not found  >  > gg + coord_trans(ytrans=probability_trans("logis"))
> Error in if (zero_range(range)) { : missing value where TRUE/FALSE needed In addition: Warning message:
> In qfun(x, ...) : NaNs produced
>   >
>
> Doing what I want "manually":
>
> # doing it manually
> pred2 <- within(pred, {
>                prob  <- plogis(fit)
>                lower <- plogis(fit - 1.96 * se.fit)
>                upper <- plogis(fit + 1.96 * se.fit)
>                })
>
>
> gg2 <- ggplot(pred2, aes(x=Age, y=prob)) +
>     geom_line(size = 2) + theme_bw() +
>     geom_ribbon(aes(ymin = lower,
>                     ymax = upper), alpha = 0.2,  color = "transparent") +
>     labs(x = "Age", y = "Probability (Better)")
> gg2
>
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



From stevan.lauriault at gmail.com  Thu Apr 17 16:13:28 2014
From: stevan.lauriault at gmail.com (Stevan Lauriault)
Date: Thu, 17 Apr 2014 10:13:28 -0400
Subject: [R] kde {ks}
Message-ID: <CAFQvP03oUMRTWGDPQzPQkc7GFm3Vwoy=zKGfEeZV_q5dk-msDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/a0631d37/attachment-0001.pl>

From michael.mahometa at ssc.utexas.edu  Thu Apr 17 16:26:44 2014
From: michael.mahometa at ssc.utexas.edu (Mahometa, Michael J)
Date: Thu, 17 Apr 2014 14:26:44 +0000
Subject: [R] Help with SSlogis and nls
Message-ID: <7535C534-541E-409C-BF9E-FABC40540324@ssc.utexas.edu>

Hi,

I'm trying to use SSlogis to fit a logistic model, but I get the error:
"step factor 0.000488281 reduced below 'minFactor' of 0.000976562"

I know I can use the nls.control within nls to help with this error, but the nls call that is producing this error looks to be from _within_ SSlogis. So my question is:
How can I use nls.control for influencing the nls call within SSlogis?

Thanks,
Michael


From ivo.welch at anderson.ucla.edu  Thu Apr 17 16:55:29 2014
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Thu, 17 Apr 2014 07:55:29 -0700
Subject: [R] kaveri with R on GPU?
Message-ID: <CAPr7RtUa1GLnR8jQgvZGjD2zyMWXJe27R=XjdRyQouxwT9iUUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/cfa435c3/attachment-0001.pl>

From boris.steipe at utoronto.ca  Thu Apr 17 17:15:33 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Apr 2014 11:15:33 -0400
Subject: [R] plot legend in filled.contour plot with infinite limits
In-Reply-To: <1397660874539-4688905.post@n4.nabble.com>
References: <1397660874539-4688905.post@n4.nabble.com>
Message-ID: <9F93A06A-18A5-4105-A085-1807C79DB740@utoronto.ca>

filled.contour() is written in R as a layout wrapper for .filled.contour(), which does the actual plotting. The code handles the construction of the key legend. I have added a parameter
key.extend = FALSE to the function and I believe it does what you were asking for, judging from the incredibly small thumbnail you were referring to.

The function code is here, followed by examples adapted from the help page.

Give it a spin and if it doesn't do what you need and you can't change it yourself, let me know.

Enjoy,
B.


filled.contour2 = function (x = seq(0, 1, length.out = nrow(z)), y = seq(0, 1, 
    length.out = ncol(z)), z, xlim = range(x, finite = TRUE), 
    ylim = range(y, finite = TRUE), zlim = range(z, finite = TRUE), 
    levels = pretty(zlim, nlevels), nlevels = 20, color.palette = cm.colors, 
    col = color.palette(length(levels) - 1), plot.title, plot.axes, 
    key.title, key.axes, asp = NA, xaxs = "i", yaxs = "i", las = 1,
    key.extend = FALSE, 
    axes = TRUE, frame.plot = axes, ...) 
{
    if (missing(z)) {
        if (!missing(x)) {
            if (is.list(x)) {
                z <- x$z
                y <- x$y
                x <- x$x
            }
            else {
                z <- x
                x <- seq.int(0, 1, length.out = nrow(z))
            }
        }
        else stop("no 'z' matrix specified")
    }
    else if (is.list(x)) {
        y <- x$y
        x <- x$x
    }
    if (any(diff(x) <= 0) || any(diff(y) <= 0)) 
        stop("increasing 'x' and 'y' values expected")
    mar.orig <- (par.orig <- par(c("mar", "las", "mfrow")))$mar
    on.exit(par(par.orig))
    w <- (3 + mar.orig[2L]) * par("csi") * 2.54
    w <- lcm(w * ifelse(key.extend, 0.9, 1.0))
    layout(matrix(c(2, 1), ncol = 2L), widths = c(1, w))	
    par(las = las)
    mar <- mar.orig
    mar[4L] <- mar[2L]
    mar[2L] <- 1
    par(mar = mar)
    plot.new()
    plot.window(xlim = c(0, 1), ylim = range(levels), xaxs = "i", 
        yaxs = "i")

    if (key.extend) {
    	# expand levels by one step above and below
    	dl <- diff(levels[1:2])   # level to level distance
        # draw key-color rectangles but skip the first and last level
        last <- length(levels)
        xi <- 0
        xa <- 1
        rect(xi, levels[2:(last-2)],
             xa, levels[3:(last-1)],
             col = col[2:(length(col)-1)])    	
        # allow drawing triangles into the margins
        apex <- 1.6   # apex height as factor of dl
        clipmax <- apex + (0.05*apex)  # add fudge factor 5%
                                       # to account for line width
        clip(xi,xa, levels[1]-(dl*clipmax), levels[last]+(dl*clipmax))
        # draw the range extension polygons
        polygon(c(xi,xi,xa,xa,xa/2),
                c(levels[2]-(dl), levels[2], levels[2],
                  levels[2]-(dl), levels[1]-(dl*apex)),
                col = col[1])
        polygon(c(xi,xi,xa,xa,xa/2),
                c(levels[last-1]+(dl), levels[last-1], levels[last-1],
                  levels[last-1]+(dl), levels[last]+(dl*apex)),
                col = col[length(col)])                
    }
    else {
        rect(0, levels[-length(levels)], 1, levels[-1L], col = col)    	
    }        
    if (missing(key.axes) && axes) {
    	if (key.extend) {axis(4, lwd = 0, lwd.tick=1)}
        else {axis(4)}
    }
    else key.axes
    if (key.extend) {
        clip(xi,xa, levels[1]-(dl*apex), levels[last]+(dl* apex))
        polygon(c(xi,xa/2,xa,xa,xa/2,xi),
                c(levels[2]-(dl),
                  levels[1]-(dl*1.5),
                  levels[2]-(dl),
                  levels[last-1]+(dl),
                  levels[last]+(dl*1.5),
                  levels[last-1]+(dl) ),
                  lwd = 1.1 )
    }
    else {
    	box()
    }
    if (!missing(key.title)) 
        key.title
    mar <- mar.orig
    mar[4L] <- 1
    par(mar = mar)
    plot.new()
    plot.window(xlim, ylim, "", xaxs = xaxs, yaxs = yaxs, asp = asp)
    .filled.contour(x, y, z, levels, col)
    if (missing(plot.axes)) {
        if (axes) {
            title(main = "", xlab = "", ylab = "")
            Axis(x, side = 1)
            Axis(y, side = 2)
        }
    }
    else plot.axes
    if (frame.plot) 
        box()
    if (missing(plot.title)) 
        title(...)
    else plot.title
    invisible()
}


# Examples:

# same as original:
filled.contour2(volcano, color = terrain.colors, asp = 1)
# with extended key:
filled.contour2(volcano, color = terrain.colors, asp = 1, key.extend = TRUE)

# more ...
x <- 10*1:nrow(volcano)
y <- 10*1:ncol(volcano)
filled.contour2(x, y, volcano, key.extend = TRUE, color = terrain.colors,
    plot.title = title(main = "The Topography of Maunga Whau",
    xlab = "Meters North", ylab = "Meters West"),
    plot.axes = { axis(1, seq(100, 800, by = 100))
                  axis(2, seq(100, 600, by = 100)) },
    key.title = title(main = "Height\n(meters)", cex.main=0.7),
    key.axes = axis(4, seq(90, 190, by = 10)) ) # maybe also asp = 1
mtext(paste("filled.contour(.) from", R.version.string),
      side = 1, line = 4, adj = 1, cex = .66)

a <- expand.grid(1:20, 1:20)
b <- matrix(a[,1] + a[,2], 20)
filled.contour2(x = 1:20, y = 1:20, z = b, key.extend = TRUE,
               plot.axes = { axis(1); axis(2); points(10, 10) })

filled.contour2(cos(r^2)*exp(-r/(2*pi)), frame.plot = FALSE,
               plot.axes = {}, key.extend=TRUE)






On 2014-04-16, at 11:07 AM, jlehm wrote:

> Dear R-users,
> 
> <http://r.789695.n4.nabble.com/file/n4688905/example.jpg> 
> 
> I would like to manipulate the legend bar of a filled.contour plot in the
> same way as it is done in the attached example I found on the web.
> 
> So, in particular, I would like to limit my z-range and then have triangles
> at the ends of the legend that indicate that higher values than max(z-range)
> or lower values than min(z-range) are included in the last color given at
> then ends of the legend.
> 
> Does anyone have an idea how to do this?
> 
> Any help would be highly appreciated as I just can't find a solution myself.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/plot-legend-in-filled-contour-plot-with-infinite-limits-tp4688905.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From yueli at cs.toronto.edu  Thu Apr 17 14:57:33 2014
From: yueli at cs.toronto.edu (Yue Li)
Date: Thu, 17 Apr 2014 08:57:33 -0400
Subject: [R] Fontconfig error in R 3.10 when running
Message-ID: <0DCFF50D-25E9-4A26-B216-8A43027325C7@cs.toronto.edu>

Dear List,

After updating to R 3.10 and Bioconductor 2.14, I'm having a rather frustrating error whenever I try using function like cairo_ps to save eps figures as demonstrated in the following example:

cairo_ps('test.eps')
plot(c(1:10),c(1:10))
Fontconfig error: Cannot load default config file
dev.off()

The plot displays distorted text (attached), and I just couldn't figure out where the fix is after google for hours. Any helps will be very much appreciated.

Many thanks,
Yue



From ingmar.heinrich at crobo.com  Thu Apr 17 11:37:16 2014
From: ingmar.heinrich at crobo.com (Ingmar Heinrich)
Date: Thu, 17 Apr 2014 11:37:16 +0200
Subject: [R] Integrating R with Elasticsearch and Symfony2
Message-ID: <CAH8gUS7PFsTtCatM8xkicGy=2hGQMRpCBC-FGQ_w2k4rX-VQUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/e3421907/attachment-0001.pl>

From s.schillebeeckx11 at imperial.ac.uk  Thu Apr 17 16:24:42 2014
From: s.schillebeeckx11 at imperial.ac.uk (Schillebeeckx, Simon)
Date: Thu, 17 Apr 2014 14:24:42 +0000
Subject: [R]  Panel Data Estimators (within, between,
 Random Effects estimator)
Message-ID: <9C8EDBCB98458D48BAE3CB871FA0BCF8553BA7DF@icexch-m1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/da7e663a/attachment-0001.pl>

From boris.steipe at utoronto.ca  Thu Apr 17 17:39:48 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Apr 2014 11:39:48 -0400
Subject: [R] Help in analysis of similarity in Iramuteq
In-Reply-To: <CAAiUqK=EkP7uaSVB5hkzRUPfo27=GViA3Wh7RgiqwXmkjDGB9Q@mail.gmail.com>
References: <CAAiUqK=EkP7uaSVB5hkzRUPfo27=GViA3Wh7RgiqwXmkjDGB9Q@mail.gmail.com>
Message-ID: <F9A5D9FE-6AA9-401C-80D6-D2B8FA2BDBB6@utoronto.ca>

I think there is far too little information here to be able to even start guessing. But if you provide a small, reproducible example of the problem, I am sure you will get an answer in very short time. Let me recommend that you read the posting guide ...
Cheers,
B.

On 2014-04-16, at 3:35 PM, Ana Karla Silva Soares wrote:

> I am conducting the analysis of similarity and when I request the 3D graph
> the following error appears:
> 
> erreur R
> None1
> none
> none
> 
> Can anyone help me?
> Thank you.
> 
> Ana Karla S Soares
> 
> 
> -- 
> Ana Karla Silva Soares
> Doutoranda em Psicologia Social - UFPB
> Mestre em Psicologia Social - UFPB
> Graduada em Psicologia - UFPB
> CV Lattes:
> http://buscatextual.cnpq.br/buscatextual/visualizacv.jsp?id=K4206524T0
> Contatos: a <tiago.souzalima at hotmail.com>kssoares at gmail.com / (83) 9652-8800
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From zilefacelvis at yahoo.com  Thu Apr 17 18:23:17 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Thu, 17 Apr 2014 09:23:17 -0700 (PDT)
Subject: [R] : Quantile and rowMean from multiple files in a folder
In-Reply-To: <1397712710.2720.YahooMailNeo@web160604.mail.bf1.yahoo.com>
References: <276148.51195.bm@smtp234.mail.bf1.yahoo.com>
	<1397499968.91158.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1397527419.97667.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1397529592.87441.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397532696.65366.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397533380.79619.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397534482.53506.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397534562.44287.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1397542887.89222.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1397544324.94583.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397548812.62519.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1397575067.67556.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397594286.23631.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1397610472.82885.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1397666044.32104.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1397705530.79250.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1397712710.2720.YahooMailNeo@web160604.mail.bf1.yahoo.com>
Message-ID: <1397751797.28789.YahooMailNeo@web160605.mail.bf1.yahoo.com>

Hi AK,
Thanks very much for the updated code.
My simulated results are even more consistent with observations after apply the updated version of the code.

Cheers,
Atem.



On Wednesday, April 16, 2014 11:31 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
Thanks very much.
Atem.




On Wednesday, April 16, 2014 9:32 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Use this code after `lst2`.
lapply(seq_along(lst2), function(i) {
? ? lstN <- lapply(lst2[[i]], function(x) {
? ? ? ? datN <- as.data.frame(matrix(NA, nrow = 101, ncol = length(names1), dimnames = list(NULL, 
? ? ? ? ? ? names1)))
? ? ? ? x1 <- x[, -1]
? ? ? ? qt <- numcolwise(function(y) quantile(y, seq(0, 1, by = 0.01), na.rm = TRUE))(x1)
? ? ? ? datN[, match(names(x1), names(datN))] <- qt
? ? ? ? datN
? ? })
? ? arr1 <- array(unlist(lstN), dim = c(dim(lstN[[1]]), length(lstN)), dimnames = list(NULL, 
? ? ? ? names1))
? ? res <- rowMeans(arr1, dims = 2, na.rm = TRUE)
? ? colnames(res) <- gsub(" ", "_", colnames(res))
? ? res1 <- data.frame(Percentiles = paste0(seq(0, 100, by = 1), "%"), res, stringsAsFactors = FALSE)
? ? write.csv(res1, paste0(paste(getwd(), "final", paste(names(lst1)[[i]], "Quantile", 
? ? ? ? sep = "_"), sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

ReadOut1 <- lapply(list.files(recursive = TRUE)[grep("Quantile", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
sapply(ReadOut1, function(x) dim(x)) 

lstNew <- simplify2array(ReadOut1)
nrow(lstNew)
#[1] 258
dir.create("Indices")
lapply(2:nrow(lstNew), function(i) {
? ? dat1 <- data.frame(Percentiles = lstNew[1], do.call(cbind, 
? ? ? ? lstNew[i, ]), stringsAsFactors = FALSE)
? ? colnames(dat1) <- c("Percentiles", paste(names(lst2), rep(rownames(lstNew)[i], 
? ? ? ? length(lst2)), sep = "_"))
? ? write.csv(dat1, paste0(paste(getwd(), "Indices", gsub(" ", "_", rownames(lstNew)[i]), 
? ? ? ? sep = "/"), ".csv"), row.names = FALSE, quote = FALSE)
})

## Output2:
ReadOut2 <- lapply(list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))], 
? ? function(x) read.csv(x, header = TRUE, stringsAsFactors = FALSE))
names(ReadOut2) <- gsub(".*\\/(.*)\\.csv","\\1",list.files(recursive = TRUE)[grep("Indices", list.files(recursive = TRUE))])
ReadOut2$pint_DJF[1:3,1:3]
#? Percentiles G100_pint_DJF G101_pint_DJF
#1? ? ? ? ? 0%? ? ? 0.982001? ? ? 1.020892
#2? ? ? ? ? 1%? ? ? 1.005563? ? ? 1.039288
#3? ? ? ? ? 2%? ? ? 1.029126? ? ? 1.057685
any(is.na(ReadOut2$pint_DJF))
?[1] FALSE 
A.K.








On Wednesday, April 16, 2014 12:34 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi AK,
I tried the updated "Quantilecode.txt". It works well but when I open the files in "Indices", I find some columns filled with NAs. This should not be the case given that I am working with simulations and there are no missing values in the process. The ##not correct section yielded no NAs. Check for example, pint_..._DJF in "Indices".

Let be be sure we are in the same page. I removed the ##not correct section of the code, ran the code from beginning to end; Q1 and then Q2. My results are found in the "Indices" folder.

Thanks,
Atem.



From jascha.lehmann at pik-potsdam.de  Thu Apr 17 18:21:11 2014
From: jascha.lehmann at pik-potsdam.de (jlehm)
Date: Thu, 17 Apr 2014 09:21:11 -0700 (PDT)
Subject: [R] plot legend in filled.contour plot with infinite limits
In-Reply-To: <9F93A06A-18A5-4105-A085-1807C79DB740@utoronto.ca>
References: <1397660874539-4688905.post@n4.nabble.com>
	<9F93A06A-18A5-4105-A085-1807C79DB740@utoronto.ca>
Message-ID: <1397751671656-4689000.post@n4.nabble.com>

This is great!! Thank you so much!!!

If have to admit, though, that this script is a bit too advanced for me as
that I could understand it.

But perhaps I could ask you for one more thing?

If possible, I would like, if the triangles replaced the first and the last
box of the legend, instead of beeing added on top / below the legend maxima
/minima.

If also tried to change apex <- 1, so that the height of the triangle is the
same as the height of the boxes. This worked for the filled triangle but not
for its border. Could you tell me how to fix this?

By the way, sorry for the small thumbnail. I added a new larger figure that
I just created with ferret.

Thanks again and happy Easter,
J <http://r.789695.n4.nabble.com/file/n4689000/example_legend.png> 



--
View this message in context: http://r.789695.n4.nabble.com/plot-legend-in-filled-contour-plot-with-infinite-limits-tp4688905p4689000.html
Sent from the R help mailing list archive at Nabble.com.



From searl at vt.edu  Thu Apr 17 18:18:36 2014
From: searl at vt.edu (Steve E.)
Date: Thu, 17 Apr 2014 09:18:36 -0700 (PDT)
Subject: [R] help incorporating data subset lengths in function with
	ddply
In-Reply-To: <alpine.BSF.2.00.1404161810270.83173@pedal.dcn.davis.ca.us>
References: <1397674874215-4688926.post@n4.nabble.com>
	<alpine.BSF.2.00.1404161810270.83173@pedal.dcn.davis.ca.us>
Message-ID: <1397751516897-4688999.post@n4.nabble.com>

Jeff - Thanks so very much for the solution and tips, all very much
appreciated! Regards, Stevan



--
View this message in context: http://r.789695.n4.nabble.com/help-incorporating-data-subset-lengths-in-function-with-ddply-tp4688926p4688999.html
Sent from the R help mailing list archive at Nabble.com.



From tim at mlhim.org  Thu Apr 17 17:35:53 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Thu, 17 Apr 2014 12:35:53 -0300
Subject: [R] XML getNodeSet
Message-ID: <CA+=OU3VASdoUByVrY_KfJ0ty3xwrRv974K2hSBhVL9pce0+htg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/8c3dbd4f/attachment-0001.pl>

From boris.steipe at utoronto.ca  Thu Apr 17 19:41:11 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Apr 2014 13:41:11 -0400
Subject: [R] plot legend in filled.contour plot with infinite limits
In-Reply-To: <1397751671656-4689000.post@n4.nabble.com>
References: <1397660874539-4688905.post@n4.nabble.com>
	<9F93A06A-18A5-4105-A085-1807C79DB740@utoronto.ca>
	<1397751671656-4689000.post@n4.nabble.com>
Message-ID: <57B7B651-ECA5-411D-910E-46C8EBAF2DC1@utoronto.ca>


On 2014-04-17, at 12:21 PM, jlehm wrote:

> This is great!! Thank you so much!!!
> 
> If have to admit, though, that this script is a bit too advanced for me as
> that I could understand it.

Most of it is the original code of the function :-)


> But perhaps I could ask you for one more thing?
> 
> If possible, I would like, if the triangles replaced the first and the last
> box of the legend, instead of beeing added on top / below the legend maxima
> /minima.

This is intentional: the triangles are not simply added to the key rectangles, but the shape of the first and last rectangle is changed to indicate that this key extends beyond the plotted range. Note that there is no horizontal line between the triangular and the rectangular part. I think that's the right way to do it, from an information design perspective. If you must have it different, I have parametrized that part now: just set "kbh" to 0 (or some intermediate value) in the code.

> If also tried to change apex <- 1, so that the height of the triangle is the
> same as the height of the boxes. This worked for the filled triangle but not
> for its border. Could you tell me how to fix this?

Great. This is a bug - I overlooked to use the variable "apex" also when the "box" is drawn. Thanks for noticing. Updated below.

> 
> By the way, sorry for the small thumbnail. I added a new larger figure that
> I just created with ferret.

:-(   
They don't give units for their keys. You can do better now :-)


> Thanks again and happy Easter,
> J <http://r.789695.n4.nabble.com/file/n4689000/example_legend.png> 



Cheers,
B


======== updated filled.contour2 ======================================

filled.contour2 = function (x = seq(0, 1, length.out = nrow(z)), y = seq(0, 1, 
    length.out = ncol(z)), z, xlim = range(x, finite = TRUE), 
    ylim = range(y, finite = TRUE), zlim = range(z, finite = TRUE), 
    levels = pretty(zlim, nlevels), nlevels = 20, color.palette = cm.colors, 
    col = color.palette(length(levels) - 1), plot.title, plot.axes, 
    key.title, key.axes, asp = NA, xaxs = "i", yaxs = "i", las = 1,
    key.extend = FALSE, 
    axes = TRUE, frame.plot = axes, ...) 
{
    if (missing(z)) {
        if (!missing(x)) {
            if (is.list(x)) {
                z <- x$z
                y <- x$y
                x <- x$x
            }
            else {
                z <- x
                x <- seq.int(0, 1, length.out = nrow(z))
            }
        }
        else stop("no 'z' matrix specified")
    }
    else if (is.list(x)) {
        y <- x$y
        x <- x$x
    }
    if (any(diff(x) <= 0) || any(diff(y) <= 0)) 
        stop("increasing 'x' and 'y' values expected")
    mar.orig <- (par.orig <- par(c("mar", "las", "mfrow")))$mar
    on.exit(par(par.orig))
    w <- (3 + mar.orig[2L]) * par("csi") * 2.54
    w <- lcm(w * ifelse(key.extend, 0.9, 1.0))
    layout(matrix(c(2, 1), ncol = 2L), widths = c(1, w))	
    par(las = las)
    mar <- mar.orig
    mar[4L] <- mar[2L]
    mar[2L] <- 1
    par(mar = mar)
    plot.new()
    plot.window(xlim = c(0, 1), ylim = range(levels), xaxs = "i", 
        yaxs = "i")

    if (key.extend) {
    	# expand levels by one step above and below
    	dl <- diff(levels[1:2])   # level to level distance
        # draw key-color rectangles but skip the first and last level
        last <- length(levels)
        xi <- 0
        xa <- 1
        rect(xi, levels[2:(last-2)],
             xa, levels[3:(last-1)],
             col = col[2:(length(col)-1)])    	
        # allow drawing triangles into the margins
        apex <- 1.0   # apex height as factor of dl
        kbh <- 1.0    # height of rectangular part of polygon
                      # as factor of dl. kbh <- 0 draws the polygon
                      # as a triangle.
        clipmax <- apex + (0.05*apex)  # add fudge factor 5%
                                       # to account for line width
        clip(xi,xa, levels[1]-(dl*clipmax), levels[last]+(dl*clipmax))
        # draw the range extension polygons
        polygon(c(xi,xi,xa,xa,xa/2),
                c(levels[2]-(dl*kbh), levels[2], levels[2],
                  levels[2]-(dl*kbh), levels[1]-(dl*apex)),
                col = col[1])
        polygon(c(xi,xi,xa,xa,xa/2),
                c(levels[last-1]+(dl*kbh), levels[last-1], levels[last-1],
                  levels[last-1]+(dl*kbh), levels[last]+(dl*apex)),
                col = col[length(col)])                
    }
    else {
        rect(0, levels[-length(levels)], 1, levels[-1L], col = col)    	
    }        
    if (missing(key.axes) && axes) {
    	if (key.extend) {axis(4, lwd = 0, lwd.tick=1)}
        else {axis(4)}
    }
    else key.axes
    if (key.extend) {
        clip(xi,xa, levels[1]-(dl*apex), levels[last]+(dl* apex))
        polygon(c(xi,xa/2,xa,xa,xa/2,xi),
                c(levels[2]-(dl*kbh),
                  levels[1]-(dl*apex),
                  levels[2]-(dl*kbh),
                  levels[last-1]+(dl*kbh),
                  levels[last]+(dl*apex),
                  levels[last-1]+(dl*kbh) ),
                  lwd = 1.1 )
    }
    else {
    	box()
    }
    if (!missing(key.title)) 
        key.title
    mar <- mar.orig
    mar[4L] <- 1
    par(mar = mar)
    plot.new()
    plot.window(xlim, ylim, "", xaxs = xaxs, yaxs = yaxs, asp = asp)
    .filled.contour(x, y, z, levels, col)
    if (missing(plot.axes)) {
        if (axes) {
            title(main = "", xlab = "", ylab = "")
            Axis(x, side = 1)
            Axis(y, side = 2)
        }
    }
    else plot.axes
    if (frame.plot) 
        box()
    if (missing(plot.title)) 
        title(...)
    else plot.title
    invisible()
}




=======================================================================

> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/plot-legend-in-filled-contour-plot-with-infinite-limits-tp4688905p4689000.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Apr 17 20:08:40 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Apr 2014 11:08:40 -0700 (PDT)
Subject: [R] Exclude rows by criteria
In-Reply-To: <1397726862.3320.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1397726862.3320.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1397758120.69425.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

If the column is "numeric" class, you don't need as.numeric(as.character(...)).? My response was based on your original post

"
I am analyzing two columns (both are factors):"

Using the same example,
indx1 <- with(dat1,year <=2007 |year >2012)
Warning messages:
1: In Ops.factor(year, 2007) : <= not meaningful for factors
2: In Ops.factor(year, 2012) : > not meaningful for factors
> indx1 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 


If you didn't get this messages, probably the column is already "numeric" class.


To avoid confusions (in the future), it is better to post a reproducible example using ?dput()

A.K.




Thanks for your prompt response.  The 'year' variable is already numeric. Do we need to use 'as.numeric(as.character(year)) <=2007' ? Can we not just use 'year<=2007' ? 


On Thursday, April 17, 2014 5:27 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
May be this helps:
set.seed(49)
dat1 <- data.frame(group=factor(sample(4,20,replace=TRUE)), year=factor(sample(2003:2014,20,replace=TRUE))) 

indx <- with(dat1, as.numeric(as.character(year)) <=2007 | as.numeric(as.character(year)) >2012 )

with(dat1[!indx,],chisq.test(group,year))
A.K.



I am analyzing two columns (both are factors): group and year by chi-square test: chisq.test(group,year) How can I exclude data (rows) where year is <2007 or >2012 ?
Thanks for your help.



From jascha.lehmann at pik-potsdam.de  Thu Apr 17 20:31:42 2014
From: jascha.lehmann at pik-potsdam.de (jlehm)
Date: Thu, 17 Apr 2014 11:31:42 -0700 (PDT)
Subject: [R] plot legend in filled.contour plot with infinite limits
In-Reply-To: <57B7B651-ECA5-411D-910E-46C8EBAF2DC1@utoronto.ca>
References: <1397660874539-4688905.post@n4.nabble.com>
	<9F93A06A-18A5-4105-A085-1807C79DB740@utoronto.ca>
	<1397751671656-4689000.post@n4.nabble.com>
	<57B7B651-ECA5-411D-910E-46C8EBAF2DC1@utoronto.ca>
Message-ID: <1397759502044-4689012.post@n4.nabble.com>

This is it! :-)

Thank's a million time for your help!

Best,
J



--
View this message in context: http://r.789695.n4.nabble.com/plot-legend-in-filled-contour-plot-with-infinite-limits-tp4688905p4689012.html
Sent from the R help mailing list archive at Nabble.com.



From brian.s.diggs at gmail.com  Thu Apr 17 20:35:07 2014
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Thu, 17 Apr 2014 11:35:07 -0700
Subject: [R] ggplot2:  using coord_trans for logit -> probability
In-Reply-To: <534FCCB6.3030004@yorku.ca>
References: <534F3660.8010106@yorku.ca>	<AA818EAD2576BC488B4F623941DA7427F3A28FB3@inbomail.inbo.be>
	<534FCCB6.3030004@yorku.ca>
Message-ID: <53501EDB.3010507@gmail.com>

On 4/17/2014 5:44 AM, Michael Friendly wrote:
> I know I can do that.  My example was just a toy version of a more
> complex graph I
> generate on the logit scale, and save as gg.
> I wanted to know if there was a way to transform it to the probability
> scale by using
>
> gg + coord_trans()
> with some suitable argument(s)
>
> for example, this *does* work to transform x -> log(x)
>
> gg + coord_trans(x="log")
>
> Reading the documentation in scales, I tried
>
> plogis_trans <- function () {
>      probability_trans("logis")
> }
>
> but I get errors when I try to use it:
>
>  > gg + coord_trans(y="plogis")
> Error in if (zero_range(range)) { : missing value where TRUE/FALSE needed
> In addition: Warning message:
> In qfun(x, ...) : NaNs produced

The logis distribution (q/p functions) is the inverse of the one that 
you want for this transformation. As such, you need to set up a custom 
transformation.

inverse_logit_trans <- trans_new("inverse logit",
                                  transform = plogis,
                                  inverse = qlogis)

gg + coord_trans(ytrans = inverse_logit_trans)

gg + scale_y_continuous(trans = inverse_logit_trans)

The difference between these is that coord_trans only transforms the 
coordinate scale; it does not change the location of the breaks or the 
labels associated with them. The trans argument in a scale, on the other 
hand, determines appropriate breaks slightly differently but sill labels 
them based on the data (not transformed) values.

There are two ways to get what you want: do the transformations in the 
aesthetics, or create a break determining function for the custom 
transformation which works on the transformed scale as well as forcing 
the labeling on the transformed scale.

ggplot(pred, aes(x=Age, y=plogis(fit))) +
   geom_line(size = 2) + theme_bw() +
   geom_ribbon(aes(ymin = plogis(fit - 1.96 * se.fit),
                   ymax = plogis(fit + 1.96 * se.fit)), alpha = 0.2, 
color = "transparent") +
   labs(x = "Age", y = "Probability (Better)")


OR

library("functional")
inverse_logit_brks_trans <-
   trans_new("inverse logit",
             transform = plogis,
             inverse = qlogis,
             breaks = Compose(plogis, extended_breaks(), qlogis),
             format = Compose(plogis, format_format()))

gg + coord_trans(ytrans = inverse_logit_brks_trans)

gg + scale_y_continuous(trans = inverse_logit_brks_trans)

Note that the coord_trans version of this second one ignores the breaks 
and labels aspects of the defined transformation. You need to use the 
latter (passing it to scale_y_continuous) to get the full effect of what 
you showed in gg2.


> -Michael
>
> On 4/17/2014 6:23 AM, ONKELINX, Thierry wrote:
>> Dear Michael,
>>
>> You can use geom_smooth directly.
>>
>> ggplot(pred, aes(x = Age, y = Better)) + geom_smooth(method = "glm",
>> family = binomial)
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data.
>> ~ John Tukey
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
>> Verzonden: donderdag 17 april 2014 4:03
>> Aan: R-help
>> Onderwerp: [R] ggplot2: using coord_trans for logit -> probability
>>
>> I'm trying to see if & how I can use coord_trans() with ggplot2 to
>> transform the Y axis of a plot on the logit scale to the probability
>> scale, as opposed to  recalculating everything "manually" and
>> constructing a new plot.
>> Here is a simple example of the 'base' plot I'd like to transform:
>>
>> data(Arthritis, package="vcdExtra")
>> Arthritis$Better <- as.numeric(Arthritis$Improved > "None")
>> arth.logistic <- glm(Better ~ Age, data=Arthritis, family=binomial)
>>
>> # get fitted values on the logit scale
>> pred <- data.frame(Arthritis,
>>                      predict(arth.logistic, se.fit=TRUE))
>> library(ggplot2)
>> library(scales)
>> # plot on logit scale
>> gg <- ggplot(pred, aes(x=Age, y=fit)) +
>>     geom_line(size = 2) + theme_bw() +
>>     geom_ribbon(aes(ymin = fit - 1.96 * se.fit,
>>                     ymax = fit + 1.96 * se.fit,), alpha = 0.2,  color =
>> "transparent") +
>>     labs(x = "Age", y = "Log odds (Better)") gg
>>
>> Things I've tried that don't work:
>>
>>   > gg + coord_trans(ytrans="logis")
>> Error in get(as.character(FUN), mode = "function", envir = envir) :
>>     object 'logis_trans' of mode 'function' was not found  >  > gg +
>> coord_trans(ytrans=probability_trans("logis"))
>> Error in if (zero_range(range)) { : missing value where TRUE/FALSE
>> needed In addition: Warning message:
>> In qfun(x, ...) : NaNs produced
>>   >
>>
>> Doing what I want "manually":
>>
>> # doing it manually
>> pred2 <- within(pred, {
>>                prob  <- plogis(fit)
>>                lower <- plogis(fit - 1.96 * se.fit)
>>                upper <- plogis(fit + 1.96 * se.fit)
>>                })
>>
>>
>> gg2 <- ggplot(pred2, aes(x=Age, y=prob)) +
>>     geom_line(size = 2) + theme_bw() +
>>     geom_ribbon(aes(ymin = lower,
>>                     ymax = upper), alpha = 0.2,  color = "transparent") +
>>     labs(x = "Age", y = "Probability (Better)")
>> gg2
>>
>>
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
>> Dit bericht en eventuele bijlagen geven enkel de visie van de
>> schrijver weer en binden het INBO onder geen enkel beding, zolang dit
>> bericht niet bevestigd is door een geldig ondertekend document.
>> The views expressed in this message and any annex are purely those of
>> the writer and may not be regarded as stating an official position of
>> INBO, as long as the message is not confirmed by a duly signed document.
>>
>
>



From tim at mlhim.org  Thu Apr 17 20:54:06 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Thu, 17 Apr 2014 15:54:06 -0300
Subject: [R] XML getNodeSet
In-Reply-To: <CA+=OU3VASdoUByVrY_KfJ0ty3xwrRv974K2hSBhVL9pce0+htg@mail.gmail.com>
References: <CA+=OU3VASdoUByVrY_KfJ0ty3xwrRv974K2hSBhVL9pce0+htg@mail.gmail.com>
Message-ID: <CA+=OU3WW5s-+OrCQoRTWGHasi_6yzX7J-vG+c9fLAa3CHs7cuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/760e32fb/attachment-0001.pl>

From deter088 at umn.edu  Thu Apr 17 22:07:03 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 17 Apr 2014 15:07:03 -0500
Subject: [R] conditional probability removal
Message-ID: <CAOLJphns_U0+GtRoXRvbwQLnGS1-Hqq=yr83d2uaEarPqdESfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/3c7d7100/attachment-0001.pl>

From boris.steipe at utoronto.ca  Thu Apr 17 22:17:20 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Apr 2014 16:17:20 -0400
Subject: [R] conditional probability removal
In-Reply-To: <CAOLJphns_U0+GtRoXRvbwQLnGS1-Hqq=yr83d2uaEarPqdESfg@mail.gmail.com>
References: <CAOLJphns_U0+GtRoXRvbwQLnGS1-Hqq=yr83d2uaEarPqdESfg@mail.gmail.com>
Message-ID: <421B0F15-3F67-40BE-A0F0-741CAE7B96A0@utoronto.ca>

I think the discussion in this thread
  https://stat.ethz.ch/pipermail/r-help/2014-April/368816.html
applies exactly.

See the parameter "prob" of sample.

Cheers,
B.


On 2014-04-17, at 4:07 PM, Charles Determan Jr wrote:

> Greetings,
> 
> I would like to randomly remove elements from a numeric vector but with
> different probabilities for higher numbers.
> 
> For example:
> 
> dat <- sample(seq(10), 100, replace=T)
> 
> # now I would like to say randomly remove elements but with a higher chance
> of removing elements >= 5 and even greater for elements >= 8.
> 
> I am unfamiliar if there is a way to define conditional probabilities.  Any
> insight would be appreciated.
> 
> Regards,
> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Thu Apr 17 22:11:28 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 17 Apr 2014 13:11:28 -0700
Subject: [R] Integrating R with Elasticsearch and Symfony2
In-Reply-To: <CAH8gUS7PFsTtCatM8xkicGy=2hGQMRpCBC-FGQ_w2k4rX-VQUw@mail.gmail.com>
References: <CAH8gUS7PFsTtCatM8xkicGy=2hGQMRpCBC-FGQ_w2k4rX-VQUw@mail.gmail.com>
Message-ID: <69d0b518-c79e-4147-b0d6-c367956fe242@email.android.com>

The Posting Guide would be a good resource to refer to, since it points out what is on topic and some related lists including R-devel.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 17, 2014 2:37:16 AM PDT, Ingmar Heinrich <ingmar.heinrich at crobo.com> wrote:
>Hi,
>
>I have no idea if this is the right place to ask - if not, please tell
>me a
>better suited one :)
>
>We are currently building a system that consists of an Angular-JS
>frontend,
>a Symfony2 backend and an Elasticsearch 1.1 cluster, all on Ubuntu
>12.04.
>Now we're starting to do statistical analysis with R, but only so far
>standalone with the Windows edition of R and CSV exports of the data.
>
>So what I would like to find out is what would be a good way to
>integrate R
>into our architecture. We could exec R from Symfony2, we could develop
>an
>Elasticsearch plugin, we could run R from the command line and pump the
>results back to Elasticsearch...
>
>Any good ideas or contacts appreciated!
>
>Thanks,
>  Ingmar
>
>
>*Ingmar Heinrich*
>
>*CTO*
>
>
>
>*crobo GmbH*
>
>Berlin HQ: Schwedter Str. 263 | 10119 Berlin | Germany
>
>Hamburg Office: Wendenstr. 21 | 20097 Hamburg | Germany
>t: +49 (0)30-6108147-01
>
>e: ingmar.heinrich at crobo.com
>
>s: ingmar.heinrich
>
>w: www.crobo.com
>
>
>Managing Director: Matthias Lesch
>Sitz und Registergericht: Berlin Charlottenburg HRB139518B
>USt-IdNr: DE281528178
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Thu Apr 17 22:33:31 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 17 Apr 2014 21:33:31 +0100
Subject: [R] conditional probability removal
In-Reply-To: <421B0F15-3F67-40BE-A0F0-741CAE7B96A0@utoronto.ca>
References: <CAOLJphns_U0+GtRoXRvbwQLnGS1-Hqq=yr83d2uaEarPqdESfg@mail.gmail.com>
	<421B0F15-3F67-40BE-A0F0-741CAE7B96A0@utoronto.ca>
Message-ID: <53503A9B.1050305@sapo.pt>

Hello,

The discussion in that thread applies, maybe with

prob <- 1L + (dat >= 5) + (dat >= 8)

Hope this helps,

Rui Barradas

Em 17-04-2014 21:17, Boris Steipe escreveu:
> I think the discussion in this thread
>    https://stat.ethz.ch/pipermail/r-help/2014-April/368816.html
> applies exactly.
>
> See the parameter "prob" of sample.
>
> Cheers,
> B.
>
>
> On 2014-04-17, at 4:07 PM, Charles Determan Jr wrote:
>
>> Greetings,
>>
>> I would like to randomly remove elements from a numeric vector but with
>> different probabilities for higher numbers.
>>
>> For example:
>>
>> dat <- sample(seq(10), 100, replace=T)
>>
>> # now I would like to say randomly remove elements but with a higher chance
>> of removing elements >= 5 and even greater for elements >= 8.
>>
>> I am unfamiliar if there is a way to define conditional probabilities.  Any
>> insight would be appreciated.
>>
>> Regards,
>> Charles
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From kristi.glover at hotmail.com  Thu Apr 17 23:12:24 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Thu, 17 Apr 2014 18:12:24 -0300
Subject: [R] how I can I extract x,y and z values?
Message-ID: <COL130-W817DFCFA0E28D3EFE874B4FA520@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/947ca63d/attachment-0001.pl>

From rory.kirchner at gmail.com  Thu Apr 17 20:42:16 2014
From: rory.kirchner at gmail.com (Rory Kirchner)
Date: Thu, 17 Apr 2014 14:42:16 -0400
Subject: [R] Installation issues on OSX
Message-ID: <386E0C24-DD3A-49AC-A0B2-12AE755F7F5E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/f193437c/attachment-0001.pl>

From macqueen1 at llnl.gov  Fri Apr 18 00:22:55 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 17 Apr 2014 22:22:55 +0000
Subject: [R] Installation issues on OSX
In-Reply-To: <386E0C24-DD3A-49AC-A0B2-12AE755F7F5E@gmail.com>
References: <386E0C24-DD3A-49AC-A0B2-12AE755F7F5E@gmail.com>
Message-ID: <CF75A1B7.F3DF7%macqueen1@llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140417/0daca049/attachment-0001.pl>

From smartpink111 at yahoo.com  Fri Apr 18 03:04:44 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Apr 2014 18:04:44 -0700 (PDT)
Subject: [R] how I can I extract x,y and z values?
In-Reply-To: <COL130-W817DFCFA0E28D3EFE874B4FA520@phx.gbl>
References: <COL130-W817DFCFA0E28D3EFE874B4FA520@phx.gbl>
Message-ID: <1397783084.33113.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Please check
str(B)
do.call(cbind,B$smooth) #gives x and y values

#Couldn't find z values.
A.K.





On Thursday, April 17, 2014 5:12 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
Hi R User, 

I was calculating a temperature (nestedness value) using nestedtemp and was able to plot the temperature for each species and sites, but I could not extract the information into table what is displayed in figure. 
It must be simple but I could not extract. any suggestions?

library(bipartite)
data(vazarr)
vazarr[1:5,1:5]
B<-nestedtemp(vazarr) 
plot(B)

I wanted to see the information of the plot B into a table. Also, In the figure I wanted to change the colors so that it would be more contrast. 
your suggestions would help me a lot. 
Thanks,
KG


??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From Eli.Ateljevich at water.ca.gov  Fri Apr 18 04:08:57 2014
From: Eli.Ateljevich at water.ca.gov (Ateljevich, Eli@DWR)
Date: Fri, 18 Apr 2014 02:08:57 +0000
Subject: [R] Mixtures of smooths on the same covariate in mgcv?
Message-ID: <73F8F665C0FCF549AF963069AB8CB27F328E51@057-SN2MPN1-042.057d.mgd.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/8c2023b5/attachment-0001.pl>

From thanoon.younis80 at gmail.com  Fri Apr 18 09:13:23 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Fri, 18 Apr 2014 10:13:23 +0300
Subject: [R] inverse normal distribution function
Message-ID: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/3a45c37c/attachment-0001.pl>

From Achim.Zeileis at uibk.ac.at  Fri Apr 18 11:22:44 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 18 Apr 2014 11:22:44 +0200 (CEST)
Subject: [R] NeweyWest in sandwich-package
In-Reply-To: <000d01cf5a32$43f0e880$cbd2b980$@uni-koeln.de>
References: <000d01cf5a32$43f0e880$cbd2b980$@uni-koeln.de>
Message-ID: <alpine.DEB.2.10.1404181113040.28703@paninaro.uibk.ac.at>

On Thu, 17 Apr 2014, Katharina Mersmann wrote:

> This post was nearly what I was searching for.
>
> Im actually trying to reproduce my Stata results in R and don?t overcome 
> the problem of the NeweyWest Estimators. I have quarterly PanelData
>
> In Stata i used:
>
> newey y x, lag(4) force
>
> In R this should be
>
> reg1.2<-lm(y~x)
> coeftest(reg1.2, df = Inf, vcov = NeweyWest(reg1.2, lag = 4,prewhite=0))
>
> but i get slightly different Std. Dev. and P-values.
>
> Do i use the wrong command? Or the wrong specification?

It's hard to say what is the source of the differences without a 
reproducible example. The most obvious candidate is a degrees of freedom 
adjustment, though. By default, NeweyWest() divides by n, the sample size. 
But some implementations also use division by n-k, where k is the number 
of estimated parameters. So maybe

coeftest(reg1.2, df = Inf,
   vcov = NeweyWest(reg1.2, lag = 4, prewhite = 0, adjust = TRUE))

replicates the Stata results exactly?

Note though that the literature usually recommends automatic bandwidth 
selection and prewhitening (as implemented in the defaults of NeweyWest). 
I'm not sure whether there are results for the degrees of freedom 
adjustment.


>
>
>
>
> Thanks a lot for your suggestions!
>
> Katie
>
>
>
>
>
>
>
>
>
> Achim Zeileis-4 wrote
>
>> On Sun, 27 Jun 2010, Jurica Brajkovi? wrote:
>
>>
>
>>> I want to calculate Newey West robust standard error using NeweyWest.
>
>>> Comparing the results to what I get in STATA, in order to get the same
>
>>> results in I need to specify "prewhite=0". Can someone explain what this
>
>>> prewhite command means?
>
>>
>
>> It controls whether autocorrelation in the estimating functions should be
>
>> removed/reduced by using a VAR model.
>
>>
>
>> ?NeweyWest says:
>
>>
>
>> prewhite: logical or integer. Should the estimating functions be
>
>>            prewhitened? If 'TRUE' or greater than 0 a VAR model of order
>
>>            'as.integer(prewhite)' is fitted via 'ar' with method '"ols"'
>
>>            and 'demean = FALSE'. The default is to use VAR(1)
>
>>            prewhitening.
>
>>
>
>> The "Details" section adds:  To obtain the estimator described in Newey &
>
>> West (1987), prewhitening has to be suppressed.
>
>>
>
>> References can also be found on the manual page as well as in Section 3.2
>
>> of vignette("sandwich", package = "sandwich").
>
>> Z
>
>>
>
>>>
>
>>>
>
>>> Thanks
>
>>>
>
>>>
>
>>>    [[alternative HTML version deleted]]
>
>>>
>
>>> ______________________________________________
>
>>>
>
>
>
>> R-help@
>
>
>
>>  mailing list
>
>>>  <https://stat.ethz.ch/mailman/listinfo/r-help>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
>>> PLEASE do read the posting guide
>
>>>  <http://www.R-project.org/posting-guide.html>
> http://www.R-project.org/posting-guide.html
>
>>> and provide commented, minimal, self-contained, reproducible code.
>
>>>
>
>>
>
>> ______________________________________________
>
>
>
>> R-help@
>
>
>
>>  mailing list
>
>>  <https://stat.ethz.ch/mailman/listinfo/r-help>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
>> PLEASE do read the posting guide
>
>>  <http://www.R-project.org/posting-guide.html>
> http://www.R-project.org/posting-guide.html
>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>



From petretta at unina.it  Fri Apr 18 13:02:50 2014
From: petretta at unina.it (petretta at unina.it)
Date: Fri, 18 Apr 2014 13:02:50 +0200
Subject: [R] interpreting weight in meta-analysis of proportion
Message-ID: <6750e290e1eb95e94d9356677b57e89a.squirrel@webmailsquirrel.unina.it>

Prof. Dewey, sorry for the trivial question and many thank for the replay.


> Using which package?

In this case I used the meta package, but I know that for all but the
DerSimonian-Laird method the R function rma.uni of R package metafor is
called internally.

> What did you expect the weights to sum to, I wonder.

I think that, to better explain the influence of single study in pooling
the effect size, the weight are presented as percentage of the sum of
total weight of each study, but I ask for a confirm. Nevertheless, I ask
if it is possible to obtain for each study the value of the absolute
weight, other than the relative weight, or at least the absolute value of
the sum of the weights.

Sincerely

Mario Petretta
>Department of Translational Medical Sciences
>Naples University Federico II
>Italy
>




Message: 2
Date: Thu, 17 Apr 2014 12:43:06 +0100
From: Michael Dewey <info at aghmed.fsnet.co.uk>
To: petretta at unina.it, r-help at r-project.org
Subject: Re: [R] interpreting weight in meta-analysis of proportion
Message-ID: <Zen-1Wakio-0009TP-RO at smarthost01b.mail.zen.net.uk>
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 16:30 16/04/2014, petretta at unina.it wrote:
>Dear all,
>
>I use R 3.0 for Windows.
>
>I performed a meta-analysis of the prevalence (single proportion)
>reported in 14 different studyes using the command:
>
>res<-metaprop(case,n,sm="PFT", comb.fixed=FALSE, comb.random=TRUE,
>studlab<- paste(Study))

Using which package?


>print(res)
>
>A referee ask a brief explanation of the W-statistic reported in the
>results, in particular, why the summ of the individual weights of all
>the studies is 100%.

What did you expect the weights to sum to, I wonder.

>Any suggestion is welcome.
>
>
>--
>Mario Petretta
>Department of Translational Medical Sciences
>Naples University Federico II
>Italy
>
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From r.turner at auckland.ac.nz  Fri Apr 18 14:46:58 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 18 Apr 2014 20:46:58 +0800
Subject: [R] inverse normal distribution function
In-Reply-To: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>
References: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>
Message-ID: <53511EC2.9060003@auckland.ac.nz>

On 18/04/14 15:13, thanoon younis wrote:
> dear all members
>
> i want to use inverse normal distribution in R to show the value of
> variable Z when Z represent the ordered categorical variables. i hope
> anyone gives me an example on this distribution

(1) Your question makes no sense.  The normal distribution has nothing 
to do (at least not directly) with categorical variables.

(2) The inverse cumulative distribution function for the normal 
distribution is well documented in R.  Learn how to search.

(3) It would appear that you need to (a) learn some statistics, and
(b) learn something about R.

(4) Don't expect others to do your work for you.

cheers,

Rolf Turner



From bernd.weiss at uni-koeln.de  Fri Apr 18 15:57:55 2014
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Fri, 18 Apr 2014 15:57:55 +0200
Subject: [R] interpreting weight in meta-analysis of proportion
In-Reply-To: <6750e290e1eb95e94d9356677b57e89a.squirrel@webmailsquirrel.unina.it>
References: <6750e290e1eb95e94d9356677b57e89a.squirrel@webmailsquirrel.unina.it>
Message-ID: <53512F63.2080203@uni-koeln.de>

On 18.04.2014 13:02, petretta at unina.it wrote:
> Prof. Dewey, sorry for the trivial question and many thank for the replay.
> 
> 
>> Using which package?
> 
> In this case I used the meta package, but I know that for all but the
> DerSimonian-Laird method the R function rma.uni of R package metafor is
> called internally.
> 
>> What did you expect the weights to sum to, I wonder.
> 
> I think that, to better explain the influence of single study in pooling
> the effect size, the weight are presented as percentage of the sum of
> total weight of each study, but I ask for a confirm. Nevertheless, I ask
> if it is possible to obtain for each study the value of the absolute
> weight, other than the relative weight, or at least the absolute value of
> the sum of the weights.
> 

## This is an example from the examples-section
res <- metaprop(4:1, c(10, 20, 30, 40), comb.fixed=FALSE, comb.random=TRUE)

## Object res contains a lot of interesting information
## Open ?metaprop and read the section on "values"
str(res)

## Obtaining the random-effects weights
res$w.random

## Calculating relative weights manually
res$w.random/(sum(res$w.random))

HTH,

Bernd



From sneha.bishnoi at gmail.com  Fri Apr 18 17:37:13 2014
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Fri, 18 Apr 2014 11:37:13 -0400
Subject: [R] Kmodes weighted version shows an error
Message-ID: <CAOsJHwB_RurNVRfRN+3eDDKi1YvnfkFwHGQT9z3OeOciHj_j+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/c53f9b9d/attachment-0001.pl>

From ba.arslan at gmail.com  Fri Apr 18 13:38:21 2014
From: ba.arslan at gmail.com (=?UTF-8?Q?Berna_Arslan_Uzunda=C4=9F?=)
Date: Fri, 18 Apr 2014 14:38:21 +0300
Subject: [R] Mediation with multilevel data - Random slopes or not?
Message-ID: <CAM1uU0ZE-q02cXZA3wX1n9KndQEVH_LG5vEkfdv8Y-RV0T7z7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/ef686ce2/attachment-0001.pl>

From snafa at hotmail.it  Fri Apr 18 16:54:18 2014
From: snafa at hotmail.it (=?iso-8859-1?B?c3ToIHNuYWZh?=)
Date: Fri, 18 Apr 2014 16:54:18 +0200
Subject: [R] plotting a 3D poisson surface with persp package
Message-ID: <DUB109-W101E817E2C8F985998E8E7FC85D0@phx.gbl>

Hi everyone,
I have fitted a poisson GLMM with the fallowing formula:
M1 <- glmer(ID ~ DE + PR +(1 | Plot/Site), data = DATA, family = poisson)
where ID = my dependent variable representing the count of a bird speciesDE = bush height (independent variable)PR = number of preys (independent variable)(1 | Plot/Site) = my random structure
This is my output
Random effects: Groups      Name        Variance Std.Dev. Site:Plot (Intercept) 0.5663   0.7525   Plot     (Intercept) 0.5778   0.7601  Number of obs: 491, groups: Site:Plot, 41; Plot, 41
Fixed effects:            Estimate Std. Error z value Pr(>|z|)    (Intercept)  0.40556    0.31162   1.301  0.19311    DE             -0.14328    0.02647  -5.413 6.19e-08 ***PR              0.03933    0.01133   3.470  0.00052 ***


Since both the covariate (DE and PR) are significant, my idea is to plot everything in a 3D graph (x = DE; y = PR, z = ID) in persp  (i.e. a poisson plane). 
When I try to do that with some simulated data, I obtain the type of graph that I need, with the poisson surface ad a nice grid on it.
The code that I used is:
x1 <- rnorm (100)x2 <- rnorm (100)abc <- function ( x1 , x2 ) {   y <-  exp ((1)*((+1 + (-0.2 * x1 + 0.2 * x2))))   }    par(bg ="white")x1r <- range ( x1 ) x1seq <- seq ( x1r [1], x1r[2], length=50)x2r <- range ( x2 ) x2seq <- seq ( x2r [1], x2r[2], length=50)z <- outer(x1seq, x2seq, abc)
persp (x = x1seq, y = x2seq, z= z, theta =-30, zlim = c(-0.2,10) )

Nevertheless, when I try to do it with my own data, I obtain the poisson surface, but without the grid! The surface, instead, is colored in black and I can't understand why.
The code is:
x1 <-DATA$DEx2 <-DATA$PRabc <- function ( x1 , x2 ) {   y <-  exp ((1)*((+0.4055 + (-0.1432 * x1 + 0.0393 * x2))))   }    par(bg ="white")x1r <- range ( DATA$DE ) x1seq <- seq ( x1r [1], x1r[2], length=491)
x2r <- range ( DATA2$DE) x2seq <- seq ( x2r [1], x2r[2], length=491)z <- outer(x1seq, x2seq, abc)  #I think that the problem is here, because probably I have to do a prediction... but I can't                                                          use the predict function because I have random factors...
persp (x = x1seq, y = x2seq, z= z, theta =-30, zlim = c(-0.2,10) )
Can someone help me? (I have attached the two graphs)I hope that I have provided enough details, If not please ask.
Thanks a lot,
Marco



 
 		 	   		  

From mailinglist at nicolasturaro.com  Fri Apr 18 18:13:52 2014
From: mailinglist at nicolasturaro.com (Nicola Sturaro Sommacal)
Date: Fri, 18 Apr 2014 18:13:52 +0200
Subject: [R] Difference between times
Message-ID: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/8b584497/attachment-0001.pl>

From kh.m.a.rehman at gmail.com  Fri Apr 18 13:53:57 2014
From: kh.m.a.rehman at gmail.com (Muhammad Abdur Rehman Khawaja)
Date: Fri, 18 Apr 2014 16:53:57 +0500
Subject: [R] Extracting Width and Length of Each Shape in EPS File
In-Reply-To: <534F12D1.5050803@stat.auckland.ac.nz>
References: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
	<467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>
	<534F12D1.5050803@stat.auckland.ac.nz>
Message-ID: <CAOjuMoDUSkS2nFwrDeahf-kSxTQLfq379bmr7K2Lw7GNPrkPLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/60e85050/attachment-0001.pl>

From kh.m.a.rehman at gmail.com  Fri Apr 18 15:49:45 2014
From: kh.m.a.rehman at gmail.com (Muhammad Abdur Rehman Khawaja)
Date: Fri, 18 Apr 2014 18:49:45 +0500
Subject: [R] Extracting Width and Length of Each Shape in EPS File
In-Reply-To: <CAOjuMoDUSkS2nFwrDeahf-kSxTQLfq379bmr7K2Lw7GNPrkPLA@mail.gmail.com>
References: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
	<467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>
	<534F12D1.5050803@stat.auckland.ac.nz>
	<CAOjuMoDUSkS2nFwrDeahf-kSxTQLfq379bmr7K2Lw7GNPrkPLA@mail.gmail.com>
Message-ID: <CAOjuMoBNpVAkUNwQpudyU2_TvM056=ADGgvOHr18S6roJ1gexQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140418/10baecb1/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Fri Apr 18 19:22:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 18 Apr 2014 10:22:48 -0700
Subject: [R] Extracting Width and Length of Each Shape in EPS File
In-Reply-To: <CAOjuMoBNpVAkUNwQpudyU2_TvM056=ADGgvOHr18S6roJ1gexQ@mail.gmail.com>
References: <CAOjuMoAepncsO_+uSz5cnoVKb6S3CfKSUDB5JKcnr13jjmxKOw@mail.gmail.com>
	<467c2727-7567-4772-88d9-1c0ec785202c@email.android.com>
	<534F12D1.5050803@stat.auckland.ac.nz>
	<CAOjuMoDUSkS2nFwrDeahf-kSxTQLfq379bmr7K2Lw7GNPrkPLA@mail.gmail.com>
	<CAOjuMoBNpVAkUNwQpudyU2_TvM056=ADGgvOHr18S6roJ1gexQ@mail.gmail.com>
Message-ID: <940fd03b-5ae5-42bd-8b13-a942f33e24c3@email.android.com>

How are we supposed to know what you are capable of? Regardless of the answer to that, I strongly suspect that you would not find that the effort required would yield a result worth your effort. R is really an interpreted language, so your ".exe" would just be calling the R interpreter for you... none of the configuration details of getting R installed would go away. You would also probably activate some GPL responsibilities if you were to share that ".exe" with anyone.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 18, 2014 6:49:45 AM PDT, Muhammad Abdur Rehman Khawaja <kh.m.a.rehman at gmail.com> wrote:
>Can I convert above code into .exe?
>
>
>On Fri, Apr 18, 2014 at 4:53 PM, Muhammad Abdur Rehman Khawaja <
>kh.m.a.rehman at gmail.com> wrote:
>
>> Thank you very much
>>
>>
>>
>>
>>
>> On Thu, Apr 17, 2014 at 4:31 AM, Paul Murrell
><paul at stat.auckland.ac.nz>wrote:
>>
>>> Hi
>>>
>>> Here is a demonstration that might give you some ideas ...
>>>
>>> library(grImport)
>>> PostScriptTrace("flower.ps", "flower.xml")
>>> flower <- readPicture("flower.xml")
>>>
>>> grid.newpage()
>>> grid.picture(flower)
>>>
>>> # Extract each path, then look at the 'summary' for the path
>>> for (i in 1:flower at summary@numPaths) {
>>>   bb <- flower[i]@summary
>>>   # Draw the result as a check
>>>   grid.polygon(c(bb at xscale[1], bb at xscale[2],
>>>                  bb at xscale[2], bb at xscale[1]),
>>>                c(bb at yscale[1], bb at yscale[1],
>>>                  bb at yscale[2], bb at yscale[2]),
>>>                default.units="native",
>>>                gp=gpar(col=NA, fill=adjustcolor(i, alpha=.5)),
>>>                vp="picture.shape::picture.scale")
>>> }
>>>
>>> The flower.ps file in that example is available here ...
>>>
>>> https://www.stat.auckland.ac.nz/~paul/R/grImport/importFiles.tar.gz
>>>
>>> Hope that helps.
>>>
>>> Paul
>>>
>>>
>>> On 04/17/14 10:56, Jeff Newmiller wrote:
>>>
>>>> Have you read the vignettes that accompany that package?
>>>>
>>>> You should also read the Posting Guide for this mailing list, as
>HTML
>>>> email is not in general a good idea on this list.
>>>> ------------------------------------------------------------
>>>> ---------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>>> Go...
>>>>                                        Live:   OO#.. Dead: OO#.. 
>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>  rocks...1k
>>>> ------------------------------------------------------------
>>>> ---------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On April 16, 2014 6:35:55 AM PDT, Muhammad Abdur Rehman Khawaja <
>>>> kh.m.a.rehman at gmail.com> wrote:
>>>>
>>>>> Respected Fellows,
>>>>> I need little bit guidance regarding, how Can I
>>>>> Extract/Calculate/Measure
>>>>> width and length of each every shape in .eps file. EPS file is
>being
>>>>> generated from Adobe Illustrator.
>>>>> I have used grImport Library in R language to import eps file in R
>>>>> environment, but I couldn't understand in which format the data is
>in
>>>>> and
>>>>> How can I manipulate it.
>>>>> I'll shall be thankful for your cooperation
>>>>> ------
>>>>> Kind Regards
>>>>> Khawaja Muhammad Abdur Rehman
>>>>> Mechatronics Engineer NUST
>>>>> Professional Profile:
>>>>> http://pk.linkedin.com/in/khawajamechatronicscaps/<kh.m.
>>>>> a.rehman at gmail.com>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>>>
>>
>>



From ruipbarradas at sapo.pt  Fri Apr 18 20:46:18 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 18 Apr 2014 19:46:18 +0100
Subject: [R] Difference between times
In-Reply-To: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
Message-ID: <535172FA.7050507@sapo.pt>

Hello,

The reason why is that you've misspelled CET (not CEST)

 > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = 
"CEST")
Warning messages:
1: In strptime(x, format, tz = tz) : unknown timezone 'CEST'
2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
   unknown timezone 'CEST'
 > dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "GMT")
 > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "CET")
 > dt1-dt2
Time difference of -2 hours


Hope this helps,

Rui Barradas

Em 18-04-2014 17:13, Nicola Sturaro Sommacal escreveu:
> Hi.
>
> I am new to POSIX and I'd like to understand the reason of this difference.
>
> dt1 = as.POSIXct("2014-03-29 09.00", format="%Y-%m-%d %H.%M")
> dt2 = as.POSIXct("2014-03-30 09.00", format="%Y-%m-%d %H.%M")
> dt2-dt1
>
>> dt1[1] "2014-03-29 09:00:00 CET"> dt2[1] "2014-03-30 09:00:00 CEST"> dt2-dt1
>
> Time difference of 23 hours
>
> This is right, because on Mar 31 at 2 PM we jump directly to 3PM, DST.
>
> On the contrary, I don't understand the following:
>
> dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "CEST")
> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "GMT")
>
>> dt1[1] "2014-04-18 09:00:00 CEST"> dt2[1] "2014-04-18 09:00:00 GMT"> dt1-dt2Time difference of 0 secs
>
>
> I should expected a time difference of 2 hours, as CEST is GMT+2.
>
> Anyone can help me?
>
> Thank you,
> Nicola
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ripley at stats.ox.ac.uk  Fri Apr 18 21:59:28 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Apr 2014 20:59:28 +0100
Subject: [R] Difference between times
In-Reply-To: <535172FA.7050507@sapo.pt>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
	<535172FA.7050507@sapo.pt>
Message-ID: <53518420.3060206@stats.ox.ac.uk>

On 18/04/2014 19:46, Rui Barradas wrote:
> Hello,
>
> The reason why is that you've misspelled CET (not CEST)

Neither CET nor CEST are portable time-zone names.  We have not been 
given the 'at a minimum' information required by the posting guide, so 
please read ?Sys.timezone on your system.


>
>  > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
> "CEST")
> Warning messages:
> 1: In strptime(x, format, tz = tz) : unknown timezone 'CEST'
> 2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
>    unknown timezone 'CEST'
>  > dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
> "GMT")
>  > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
> "CET")
>  > dt1-dt2
> Time difference of -2 hours
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 18-04-2014 17:13, Nicola Sturaro Sommacal escreveu:
>> Hi.
>>
>> I am new to POSIX and I'd like to understand the reason of this
>> difference.
>>
>> dt1 = as.POSIXct("2014-03-29 09.00", format="%Y-%m-%d %H.%M")
>> dt2 = as.POSIXct("2014-03-30 09.00", format="%Y-%m-%d %H.%M")
>> dt2-dt1
>>
>>> dt1[1] "2014-03-29 09:00:00 CET"> dt2[1] "2014-03-30 09:00:00 CEST">
>>> dt2-dt1
>>
>> Time difference of 23 hours
>>
>> This is right, because on Mar 31 at 2 PM we jump directly to 3PM, DST.
>>
>> On the contrary, I don't understand the following:
>>
>> dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>> "CEST")
>> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "GMT")
>>
>>> dt1[1] "2014-04-18 09:00:00 CEST"> dt2[1] "2014-04-18 09:00:00 GMT">
>>> dt1-dt2Time difference of 0 secs
>>
>>
>> I should expected a time difference of 2 hours, as CEST is GMT+2.
>>
>> Anyone can help me?
>>
>> Thank you,
>> Nicola
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dwinsemius at comcast.net  Fri Apr 18 22:46:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 18 Apr 2014 13:46:56 -0700
Subject: [R] Difference between times
In-Reply-To: <53518420.3060206@stats.ox.ac.uk>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
	<535172FA.7050507@sapo.pt> <53518420.3060206@stats.ox.ac.uk>
Message-ID: <CB5D0A98-916A-48E4-A879-E33C5D24BD5B@comcast.net>


On Apr 18, 2014, at 12:59 PM, Prof Brian Ripley wrote:

> On 18/04/2014 19:46, Rui Barradas wrote:
>> Hello,
>> 
>> The reason why is that you've misspelled CET (not CEST)
> 
> Neither CET nor CEST are portable time-zone names.  We have not been given the 'at a minimum' information required by the posting guide, so please read ?Sys.timezone on your system.

Dear Prof;

Thanks for the impetus to yet again read that page. Despite frequently reading help pages and in particular reading that one many times, I still was not getting the 'tz' arguments correct on a Mac. I do now see that I was spelling my TZ incorrectly (as "Americas/Los_Angeles" rather than "America/Los_Angeles". 

Fellow Mac users may face a problem when using the Finder unless they set it up to display hidden ('dot') files. The /usr/ folder is "greyed out" but it still does open. If I restore my Finder defaults to not show system files and folders, I no longer see that directory and would not have been able to resolve my spelling error on my own:


> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "America/New_York")
>  dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "America/Los_Angeles")
>  dt1-dt2
Time difference of 3 hours

I don't suppose a warning could be issued by the as.POSIXct code when a "tz" argument is not found in the database to let people know that 'UTC' will be the default?

-- 
David.


> 
> 
>> 
>> > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>> "CEST")
>> Warning messages:
>> 1: In strptime(x, format, tz = tz) : unknown timezone 'CEST'
>> 2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
>>   unknown timezone 'CEST'
>> > dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>> "GMT")
>> > dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>> "CET")
>> > dt1-dt2
>> Time difference of -2 hours
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 18-04-2014 17:13, Nicola Sturaro Sommacal escreveu:
>>> Hi.
>>> 
>>> I am new to POSIX and I'd like to understand the reason of this
>>> difference.
>>> 
>>> dt1 = as.POSIXct("2014-03-29 09.00", format="%Y-%m-%d %H.%M")
>>> dt2 = as.POSIXct("2014-03-30 09.00", format="%Y-%m-%d %H.%M")
>>> dt2-dt1
>>> 
>>>> dt1[1] "2014-03-29 09:00:00 CET"> dt2[1] "2014-03-30 09:00:00 CEST">
>>>> dt2-dt1
>>> 
>>> Time difference of 23 hours
>>> 
>>> This is right, because on Mar 31 at 2 PM we jump directly to 3PM, DST.
>>> 
>>> On the contrary, I don't understand the following:
>>> 
>>> dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>>> "CEST")
>>> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "GMT")
>>> 
>>>> dt1[1] "2014-04-18 09:00:00 CEST"> dt2[1] "2014-04-18 09:00:00 GMT">
>>>> dt1-dt2Time difference of 0 secs
>>> 
>>> 
>>> I should expected a time difference of 2 hours, as CEST is GMT+2.
>>> 
>>> Anyone can help me?
>>> 
>>> Thank you,
>>> Nicola
>>> 
>>>    [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From Scott.Waichler at pnnl.gov  Sat Apr 19 00:00:12 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Fri, 18 Apr 2014 22:00:12 +0000
Subject: [R] problem with pip2d() from ptinpoly
Message-ID: <074C83DAD4825242A20B2D83FDBCB8880861DC@EX10MBOX03.pnnl.gov>

Hi,

pip2d() doesn't seem to work correctly for me.  I have a plot of a triangle that a query point fits inside, but the point is defined as outside the polygon by pip2d.  

library(ptinpoly)
verts <- matrix(c(594891,115309,594444,117201,594891,117201), ncol=2, byrow=T)
query <- matrix(c(594885.0,115435.0), ncol=2, byrow=T)
pip2d(Vertices = verts, Queries = query)  # result = -1
# contrary to -1 output of pip2d, plot shows point lies within triangle
plot(c(594400, 595000), c(115000, 117500), type="n")
polygon(verts, border="red")
points(x=query[,1], y=query[,2], col="blue")

Scott Waichler
Pacific Northwest National Laboratory
Richland, WA, USA



From boris.steipe at utoronto.ca  Sat Apr 19 00:48:45 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 18 Apr 2014 18:48:45 -0400
Subject: [R] problem with pip2d() from ptinpoly
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8880861DC@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8880861DC@EX10MBOX03.pnnl.gov>
Message-ID: <946D4E2B-F851-4FD2-A4A3-F17B75EF7D6D@utoronto.ca>

Apparently it matters whether your polygon is defined clockwise or counterclockwise. 

A point outside your triangle is recognized ...
> q2 <- matrix(c(594893.0,115435.0), ncol=2, byrow=T)
> pip2d(Vertices = verts, Queries = q2)
[1] 1

... and defining the triangle in counterclockwise sense gives the expected behaviour.
> v2 <- matrix(c(594891,115309,594891,117201,594444,117201), ncol=2, byrow=T)
> pip2d(Vertices = v2, Queries = query)
[1] 1

Cheers,
B.



On 2014-04-18, at 6:00 PM, Waichler, Scott R wrote:

> Hi,
> 
> pip2d() doesn't seem to work correctly for me.  I have a plot of a triangle that a query point fits inside, but the point is defined as outside the polygon by pip2d.  
> 
> library(ptinpoly)
> verts <- matrix(c(594891,115309,594444,117201,594891,117201), ncol=2, byrow=T)
> query <- matrix(c(594885.0,115435.0), ncol=2, byrow=T)
> pip2d(Vertices = verts, Queries = query)  # result = -1
> # contrary to -1 output of pip2d, plot shows point lies within triangle
> plot(c(594400, 595000), c(115000, 117500), type="n")
> polygon(verts, border="red")
> points(x=query[,1], y=query[,2], col="blue")
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gleynes+r at gmail.com  Sat Apr 19 00:07:51 2014
From: gleynes+r at gmail.com (Gene Leynes)
Date: Fri, 18 Apr 2014 17:07:51 -0500
Subject: [R] R Example scripts
Message-ID: <CAOBARVi1+L9Sb+qUwo16f3OmXTkv2gmuBzz3o4n8zFvc-U8WZQ@mail.gmail.com>

A few years ago R changed the way help was handled so that the HTML
files are no longer available in the library directory.  Around that
time the R example files that used to be in some of the libraries also
vanished.

I'm wondering where the "r-ex" folder went. Is it totally unsupported
and gone? Is it hidden in the mysterious rdx or rdb files?

In particular I'm looking for the latest example scripts in the baysem
package. I don't see them in the source code or the installed library.



From petretta at unina.it  Sat Apr 19 09:17:38 2014
From: petretta at unina.it (Mario Petretta)
Date: Sat, 19 Apr 2014 09:17:38 +0200
Subject: [R] R:  interpreting weight in meta-analysis of proportion
In-Reply-To: <53512F63.2080203@uni-koeln.de>
References: <6750e290e1eb95e94d9356677b57e89a.squirrel@webmailsquirrel.unina.it>
	<53512F63.2080203@uni-koeln.de>
Message-ID: <00a201cf5b9f$71fe90b0$55fbb210$@unina.it>

Fine !

Many many thanks!

Mario


-----Messaggio originale-----
Da: Bernd Weiss [mailto:bernd.weiss at uni-koeln.de] 
Inviato: venerd? 18 aprile 2014 15.58
A: petretta at unina.it; R-help at r-project.org
Oggetto: Re: [R] interpreting weight in meta-analysis of proportion

On 18.04.2014 13:02, petretta at unina.it wrote:
> Prof. Dewey, sorry for the trivial question and many thank for the replay.
> 
> 
>> Using which package?
> 
> In this case I used the meta package, but I know that for all but the 
> DerSimonian-Laird method the R function rma.uni of R package metafor 
> is called internally.
> 
>> What did you expect the weights to sum to, I wonder.
> 
> I think that, to better explain the influence of single study in 
> pooling the effect size, the weight are presented as percentage of the 
> sum of total weight of each study, but I ask for a confirm. 
> Nevertheless, I ask if it is possible to obtain for each study the 
> value of the absolute weight, other than the relative weight, or at 
> least the absolute value of the sum of the weights.
> 

## This is an example from the examples-section res <- metaprop(4:1, c(10,
20, 30, 40), comb.fixed=FALSE, comb.random=TRUE)

## Object res contains a lot of interesting information ## Open ?metaprop
and read the section on "values"
str(res)

## Obtaining the random-effects weights
res$w.random

## Calculating relative weights manually
res$w.random/(sum(res$w.random))

HTH,

Bernd



From murdoch.duncan at gmail.com  Sat Apr 19 13:12:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Apr 2014 07:12:04 -0400
Subject: [R] R Example scripts
In-Reply-To: <CAOBARVi1+L9Sb+qUwo16f3OmXTkv2gmuBzz3o4n8zFvc-U8WZQ@mail.gmail.com>
References: <CAOBARVi1+L9Sb+qUwo16f3OmXTkv2gmuBzz3o4n8zFvc-U8WZQ@mail.gmail.com>
Message-ID: <53525A04.1030202@gmail.com>

On 18/04/2014, 6:07 PM, Gene Leynes wrote:
> A few years ago R changed the way help was handled so that the HTML
> files are no longer available in the library directory.  Around that
> time the R example files that used to be in some of the libraries also
> vanished.
>
> I'm wondering where the "r-ex" folder went. Is it totally unsupported
> and gone? Is it hidden in the mysterious rdx or rdb files?

The source for the examples will be in the \examples{} section of the 
.Rd source file -- that didn't change.  What changed was how the source 
is processed.  The files are now parsed into a binary format that is 
stored in the database files.

You can extract the examples from the source file using the tools::Rd2ex 
function.  You can extract them from the binary database using this 
function on an Rd object, which is obtainable using the internal 
function .getHelpFile.

So for example, to see the code for the example for rwishart, you could do

tools::Rd2ex(".../bayesm/man/rwishart.Rd")

if you have the source file installed there, or

library(bayesm)
Rd <- utils:::.getHelpFile(?rwishart)
tools::Rd2ex(Rd)

if you have the package installed.

Duncan Murdoch
>
> In particular I'm looking for the latest example scripts in the baysem
> package. I don't see them in the source code or the installed library.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pavneet.arora at uk.rsagroup.com  Sat Apr 19 14:30:54 2014
From: pavneet.arora at uk.rsagroup.com (starter)
Date: Sat, 19 Apr 2014 05:30:54 -0700 (PDT)
Subject: [R] Read.table mucks up headers
In-Reply-To: <OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
	<1397495399.4315.1.camel@milan>
	<OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
Message-ID: <1397910654957-4689099.post@n4.nabble.com>

Hello Milan

It had worked perfectly before, but now I am trying on a different text file
but using the trick you showed I just get the headers in the output and that
too as "row.names" and "X".

*code:*
corr <- read.table("E:/temp/corrosion
data.txt",header=T,fileEncoding="UTF-8-BOM")

> dput(corr)
structure(list(?...Weight. = c(13.74, 12.97, 10.78, 10.53, 10.16, 
9.38, 9.23, 9.2, 17.24, 18, 15.12, 16.08, 13.71, 13.81, 12.61, 
14.03), Piece = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L), Time = c(96L, 84L, 72L, 60L, 48L, 36L, 24L, 
12L, 96L, 96L, 72L, 60L, 48L, 36L, 24L, 12L)), .Names = c("?...Weight.", 
"Piece", "Time"), class = "data.frame", row.names = c(NA, -16L
))

> str(corr)
'data.frame':	16 obs. of  3 variables:
 $ ?...Weight.: num  13.7 13 10.8 10.5 10.2 ...
 $ Piece      : int  1 1 1 1 1 1 1 1 2 2 ...
 $ Time       : int  96 84 72 60 48 36 24 12 96 96 ...

Please tell me what I am doing wrong.



--
View this message in context: http://r.789695.n4.nabble.com/Read-table-mucks-up-headers-tp4688742p4689099.html
Sent from the R help mailing list archive at Nabble.com.



From ligges at statistik.tu-dortmund.de  Sat Apr 19 15:12:47 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 19 Apr 2014 15:12:47 +0200
Subject: [R] Read.table mucks up headers
In-Reply-To: <1397910654957-4689099.post@n4.nabble.com>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>	<1397495399.4315.1.camel@milan>	<OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
	<1397910654957-4689099.post@n4.nabble.com>
Message-ID: <5352764F.4040903@statistik.tu-dortmund.de>



On 19.04.2014 14:30, starter wrote:
> Hello Milan
>
> It had worked perfectly before, but now I am trying on a different text file
> but using the trick you showed I just get the headers in the output and that
> too as "row.names" and "X".
>
> *code:*
> corr <- read.table("E:/temp/corrosion
> data.txt",header=T,fileEncoding="UTF-8-BOM")


Which R version?
Are you sure this is UTF-8-BOM and not "UCS-2LE" or "UTF-16LE"?

Best,
Uwe Ligges


>> dput(corr)
> structure(list(?...Weight. = c(13.74, 12.97, 10.78, 10.53, 10.16,
> 9.38, 9.23, 9.2, 17.24, 18, 15.12, 16.08, 13.71, 13.81, 12.61,
> 14.03), Piece = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L), Time = c(96L, 84L, 72L, 60L, 48L, 36L, 24L,
> 12L, 96L, 96L, 72L, 60L, 48L, 36L, 24L, 12L)), .Names = c("?...Weight.",
> "Piece", "Time"), class = "data.frame", row.names = c(NA, -16L
> ))
>
>> str(corr)
> 'data.frame':	16 obs. of  3 variables:
>   $ ?...Weight.: num  13.7 13 10.8 10.5 10.2 ...
>   $ Piece      : int  1 1 1 1 1 1 1 1 2 2 ...
>   $ Time       : int  96 84 72 60 48 36 24 12 96 96 ...
>
> Please tell me what I am doing wrong.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Read-table-mucks-up-headers-tp4688742p4689099.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From Scott.Waichler at pnnl.gov  Sat Apr 19 15:49:34 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Sat, 19 Apr 2014 13:49:34 +0000
Subject: [R] problem with pip2d() from ptinpoly
In-Reply-To: <946D4E2B-F851-4FD2-A4A3-F17B75EF7D6D@utoronto.ca>
References: <074C83DAD4825242A20B2D83FDBCB8880861DC@EX10MBOX03.pnnl.gov>
	<946D4E2B-F851-4FD2-A4A3-F17B75EF7D6D@utoronto.ca>
Message-ID: <074C83DAD4825242A20B2D83FDBCB8880872A9@EX10MBOX03.pnnl.gov>

Thank you for catching that, Boris.  I'm surprised, given that there is no mention of sense of direction in the package documentation.

Scott Waichler

> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
> Sent: Friday, April 18, 2014 3:49 PM
> To: Waichler, Scott R; r-help at r-project.org
> Subject: Re: [R] problem with pip2d() from ptinpoly
> 
> Apparently it matters whether your polygon is defined clockwise or
> counterclockwise.
> 
> A point outside your triangle is recognized ...
> > q2 <- matrix(c(594893.0,115435.0), ncol=2, byrow=T) pip2d(Vertices =
> > verts, Queries = q2)
> [1] 1
> 
> ... and defining the triangle in counterclockwise sense gives the expected
> behaviour.
> > v2 <- matrix(c(594891,115309,594891,117201,594444,117201), ncol=2,
> > byrow=T) pip2d(Vertices = v2, Queries = query)
> [1] 1
> 
> Cheers,
> B.
>
> On 2014-04-18, at 6:00 PM, Waichler, Scott R wrote:
> 
> > Hi,
> >
> > pip2d() doesn't seem to work correctly for me.  I have a plot of a
> triangle that a query point fits inside, but the point is defined as
> outside the polygon by pip2d.
> >
> > library(ptinpoly)
> > verts <- matrix(c(594891,115309,594444,117201,594891,117201), ncol=2,
> > byrow=T) query <- matrix(c(594885.0,115435.0), ncol=2, byrow=T)
> > pip2d(Vertices = verts, Queries = query)  # result = -1 # contrary to
> > -1 output of pip2d, plot shows point lies within triangle
> > plot(c(594400, 595000), c(115000, 117500), type="n") polygon(verts,
> > border="red") points(x=query[,1], y=query[,2], col="blue")
> >
> > Scott Waichler
> > Pacific Northwest National Laboratory
> > Richland, WA, USA



From tim at mlhim.org  Sat Apr 19 16:00:23 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Sat, 19 Apr 2014 11:00:23 -0300
Subject: [R] XML getNodeSet
In-Reply-To: <CA+=OU3WW5s-+OrCQoRTWGHasi_6yzX7J-vG+c9fLAa3CHs7cuQ@mail.gmail.com>
References: <CA+=OU3VASdoUByVrY_KfJ0ty3xwrRv974K2hSBhVL9pce0+htg@mail.gmail.com>
	<CA+=OU3WW5s-+OrCQoRTWGHasi_6yzX7J-vG+c9fLAa3CHs7cuQ@mail.gmail.com>
Message-ID: <CA+=OU3W6fGQRiYrXG+bZpSFRXMa0F=09ZCTpY3mixXu2f4aH1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/39cbebb9/attachment-0001.pl>

From doorz at xs4all.nl  Sat Apr 19 16:43:27 2014
From: doorz at xs4all.nl (Alex van der Spek)
Date: Sat, 19 Apr 2014 16:43:27 +0200
Subject: [R] Foreign function interface
Message-ID: <53528B8F.5050406@xs4all.nl>

I read the Foreign Function Interface for R.

The documentation does not prescribe the calling convention though.

Does that mean __stdcall on W32 and __cdecl for Linux?

Regards,
Alex van der Spek



From smartpink111 at yahoo.com  Sat Apr 19 19:40:49 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 19 Apr 2014 10:40:49 -0700 (PDT)
Subject: [R] cbind with row names to serveral files in R
Message-ID: <1397929249.34802.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
The rownames part is not clear as your expected output and input files didn't show them as rownames. 


##Suppose you have all the files in a folder
##here I am creating the names of those files

files1 <- paste0("sample", rep(1:777, each=29),"chr",1:29,".txt")
length(files1)
#[1] 22533
lst1 <-? split(files1,as.numeric(gsub(".*chr(\\d+)\\..*","\\1",files1)))

##use list.files() 

##in your case, ##not tested

lst1 <- split(list.files(pattern="sample\\d+"), as.numeric(gsub(".*chr(\\d+)\\..*","\\1",list.files(pattern="sample\\d+")))) ##in case other files are also in the folder

library(plyr)

lst2 <- lapply(lst1,function(x) {x1 <-join_all(lapply(x,function(y) read.table(y,header=TRUE,stringsAsFactors=FALSE,sep="")),c("Name","Chr","Position")) })


lapply(seq_along(lst2),function(i) write.table(lst2[[i]],paste0("LRRrawallchr",i,".txt"),row.names=FALSE,quote=FALSE))


###if you need to create rownames using the first three columns:
lapply(seq_along(lst2),function(i) {x1 <- lst2[[i]]; row.names(x1) <- as.character(interaction(x1[,1:3],sep="_")); x2 <- x1[,-(1:3)]; write.table(x2, paste0("LRRrawallchr",i,".txt"), quote=FALSE)})



A.K.


I would like to use the `cbind` in a list of files. However each file are splited in a specific chromosome (chr) `(k in 1:29)`, and specific sample `(i in 1:777)`. The files are like:


sample1chr1.txt, sample1chr2.txt ... sample1chr29.txt, sample2chr1.txt ... sample777chr29.txt

All files have exactly the same rows names (3 first collumns represent my row names). I would like to get a final file to each chr merging to all sample files, with and do not repeat the row names in the final file (the first 3 collumns representing my rows names).

I tried this:

`#Creating file with row names (3 first collumns) to each Chr
{
{for(k in 1:29){
? infile <- paste0("sample1chr",k,".txt")
? outfile <- paste0("LRRrawallchr",k,".txt")
? rows <- read.table(infile, header=TRUE, sep="\t")
? rows <- rows[, -grep("Log.R.Ratio", colnames(rows))]
? write.table(rows, outfile, sep=";")}}`

`#Cbind in one file per Chr
{? for(i in 1:777)
? for(k in 1:29){
??? base <- paste0("LRRrawallchr",k,".txt")
??? chr <- read.table(base, header=TRUE, sep=";")
??? infile <- paste0("sample",i,"chr",k,".txt")
??? chr2 <- read.table(infile, header=TRUE, sep="\t")
??? outfile <- paste0("LRRrawallchr",k,".txt")
??? chr2 <- chr2[, -grep("Name", colnames(chr2))]
??? chr2 <- chr2[, -grep("Chr", colnames(chr2))]
??? chr2 <- chr2[, -grep("Position", colnames(chr2))]
??? chr <- cbind(chr, chr2)
??? write.table(chr, outfile, sep=";", row.names=FALSE, col.names=FALSE)}
}`

Input example (sample1chr1.txt):

?? 

???? Name?? Chr Position sample1value
??? BAC-11034 1 128?????????? 0.302
??? BAC-11044 1 129?????????? -0.56
??? BAC-11057 1 134?????????? 0.0840

Input example (sample2chr1.txt):

??? Name?? Chr Position? sample2value
??? BAC-11034 1 128?????????? 0.25
??? BAC-11044 1 129?????????? 0.41
??? BAC-11057 1 134????????? -0.14

Expected output (LRRrawallchr1):

??? Name?????? Chr Position??? sample1value?? sample2value
??? BAC-11034 1 128??????? 0.302????????? 0.25
??? BAC-11044 1 129??????? -0.56????????? 0.41
??? BAC-11057 1 134??????? 0.0840???????? -0.14

I have 22553 diferent .txt files (29 files (one per chr) to each of 777 samples). All 22553 files (sample1chr1.txt, sample1chr2.txt ... sample1chr29.txt, sample2chr1.txt ... sample777chr29.txt) are like above example.? 

I wanna 29 files like (LRRrawallchr1), one per Chr. The "LRRrawallchr,k," files have to be with 777+3 (800 collumns). The 3 row names and one collumn per sample.

Cheers! 




From philip.c.robinson at gmail.com  Sat Apr 19 22:25:59 2014
From: philip.c.robinson at gmail.com (Philip Robinson)
Date: Sun, 20 Apr 2014 06:25:59 +1000
Subject: [R] cex values being ignored in the curve function
Message-ID: <5352DBD7.9080903@gmail.com>

Dear R-Community,

The cex values in curve seem to be being ignored. I have searched 
previous help questions and also the web generally, and cannot find this 
being a major problem so I am suspicious of something odd happening but 
I am at a loss to work out why.

I am trying to plot this:

b1      <- -0.858
pow    <- 0.8
ratio   <- 1
sig      <- 0.05

curve((qnorm(1-sig/2)+qnorm(pow))^2/b1^2/x/(ratio/(1+ratio))/(1/(1+ratio)),from=0.005,to=0.08,main="This 
needs to be bigger",xlab="And this bigger too",ylab="And this too", 
cex=1,cex.lab=3.5, cex.axis=3.5, cex.main=3.5, cex.sub=3.5)

But no matter what value of cex I make it, or whether I break up the 
arguments into :

title(main="something",cex.main=3)
axis(cex.axis=2)

or parse this before plotting : par(cex.lab=1.5, cex.axis=1.5, 
cex.main=3.5, cex.sub=1.5)

I cannot get the main, axis titles or axis numbers to change in size, 
whatever I do.

I am using a macbook pro, with mavericks, R-studio and R 3.1.0 
"spring-dance", and I am initiating the plot with:

X11( width=width , height=height , type="cairo").

Any help would be greatly appreciated.

thanks
Philip



From tellsathish at gmail.com  Sat Apr 19 10:57:55 2014
From: tellsathish at gmail.com (Sathish Kumar)
Date: Sat, 19 Apr 2014 01:57:55 -0700
Subject: [R] Need help to convert data frame to transaction set.
Message-ID: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>

Hi,

To convert coerce the data set to transaction data set I used the code

trans4 <- as(split(a[,"Cust_ID"], a[,"Parts"]), "transactions")

but I am getting the following error-

Error in as(split(a[, "Cust_ID"], a[, "Parts"]), "transactions") : nomethod
or default for coercing ?list? to ?transactions?



Then I tried first converting the data set to matrix structure using the
code

c_m<-as.matrix(c_df)
 c_m



then entered the following code


trans2 <- as(c_m, "transactions")

but got the following error

Error in as(c_m, "transactions") : no method or default for coercing
?matrix? to ?transactions?
Please let me know how to correct the problem.

Thanks
Sathish

From burakomersaracoglu at hotmail.com  Sat Apr 19 11:10:09 2014
From: burakomersaracoglu at hotmail.com (=?windows-1254?B?YnVyYWsg9m1lciBzYXJh529nbHU=?=)
Date: Sat, 19 Apr 2014 09:10:09 +0000
Subject: [R] R Statistical Computing Language Preference Help
In-Reply-To: <DUB124-W452D940D5D8F644DDAB8CFC65C0@phx.gbl>
References: <DUB124-W452D940D5D8F644DDAB8CFC65C0@phx.gbl>
Message-ID: <DUB124-W206F3329F54E3CE3C38181C65C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/07fb8bef/attachment-0001.pl>

From francesco.brundu at gmail.com  Sat Apr 19 12:05:52 2014
From: francesco.brundu at gmail.com (Francesco Brundu)
Date: Sat, 19 Apr 2014 12:05:52 +0200
Subject: [R] How to use rainbow function without the gamma argument
Message-ID: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/d1d1dc0f/attachment-0001.pl>

From mailinglist at nicolasturaro.com  Sat Apr 19 14:03:28 2014
From: mailinglist at nicolasturaro.com (Nicola Sturaro Sommacal)
Date: Sat, 19 Apr 2014 14:03:28 +0200
Subject: [R] Difference between times
In-Reply-To: <53518420.3060206@stats.ox.ac.uk>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
	<535172FA.7050507@sapo.pt> <53518420.3060206@stats.ox.ac.uk>
Message-ID: <CAM8ViJOsMRJU8m0xfmZi2=qJ140VJmdRQYuvGtEf1z6TGvzBTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/5c38444a/attachment-0001.pl>

From mailinglist at nicolasturaro.com  Sat Apr 19 14:05:10 2014
From: mailinglist at nicolasturaro.com (Nicola Sturaro Sommacal)
Date: Sat, 19 Apr 2014 14:05:10 +0200
Subject: [R] Difference between times
In-Reply-To: <CAM8ViJOsMRJU8m0xfmZi2=qJ140VJmdRQYuvGtEf1z6TGvzBTA@mail.gmail.com>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>
	<535172FA.7050507@sapo.pt> <53518420.3060206@stats.ox.ac.uk>
	<CAM8ViJOsMRJU8m0xfmZi2=qJ140VJmdRQYuvGtEf1z6TGvzBTA@mail.gmail.com>
Message-ID: <CAM8ViJPFyveZFFyKp-oEbKqV0U_xXhuzdMzYDYuShYYd6b-8Vw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/3ae4b3c2/attachment-0001.pl>

From b.h.willis at bham.ac.uk  Sat Apr 19 17:51:19 2014
From: b.h.willis at bham.ac.uk (Brian Willis)
Date: Sat, 19 Apr 2014 08:51:19 -0700 (PDT)
Subject: [R] Extracting the names of coefficients of random effects
Message-ID: <1397922679520-4689109.post@n4.nabble.com>

Hi All,
I need to be able to manipulate the names of the coefficients from
*ranef()*.

If there is any missing data when fitting a mixed model using lmer, no
estimate is returned for the associated level for that random effect. Thus
if the data input for regions had levels 
	*Region*
        Bolton
	Bradford                              	         				                                	  
        Cambridge		                                                 
        Durham						 
and there was missing data on Bradford then 
* ranef(model)*					gives 
	                                                     (Intercept)
Bolton:                               	          -0.0981763413
Cambridge		                                   0.0151102347
Durham						   0.1837142259

This becomes a problem if I want to use *predict( )* on new data where there
is no missing data on Bradford. In such an instance

	*predict (model, newdata = newInput) *	gives the following error message 

             ?Error in (function (x, n)  : new levels detected in newdata?

I could get round this by checking the Region field of the new data
?newInput? against the names of the levels of the intercept coefficients
from* ranef().*
However, I?m not sure how to access these since if 
*x<- ranef(model)
x *
This gives the same output above, but

	*x[1,1]* only returns the numeric value  -0.0981763413

x is a dataframe with only one field (column) with numeric values and the
names of the levels are not present or identified. There must be a variable
which defines ?Bolton?, Bradford? etc since if I use the write.table
function
*write.table (x, file="/desktop/Dummy.csv", sep = ",",  col.names = NA, 
qmethod = "double")*
This outputs both the names (?Bolton?, Bradford?..) and their corresponding
numeric values to a spreadsheet.

Does anyone know how to do this without resorting to outputting to a
spreadsheet?
 
Regards,

Brian H Willis
Health and Population Sciences
University of Birmingham




--
View this message in context: http://r.789695.n4.nabble.com/Extracting-the-names-of-coefficients-of-random-effects-tp4689109.html
Sent from the R help mailing list archive at Nabble.com.



From gunter.berton at gene.com  Sat Apr 19 23:03:24 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 19 Apr 2014 14:03:24 -0700
Subject: [R] cex values being ignored in the curve function
In-Reply-To: <5352DBD7.9080903@gmail.com>
References: <5352DBD7.9080903@gmail.com>
Message-ID: <CACk-te1HHP=pQ+_T-w_RzY5QA3MkE08ZBqWy15UQbodV3N-EEw@mail.gmail.com>

Don't know if this helps, but works for me on a PC under Windows 7
with the default graphics device. Try a different device, maybe (e.g.
pdf) ??

-- Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch


Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype



From gunter.berton at gene.com  Sat Apr 19 23:17:32 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 19 Apr 2014 14:17:32 -0700
Subject: [R] R Statistical Computing Language Preference Help
In-Reply-To: <DUB124-W206F3329F54E3CE3C38181C65C0@phx.gbl>
References: <DUB124-W452D940D5D8F644DDAB8CFC65C0@phx.gbl>
	<DUB124-W206F3329F54E3CE3C38181C65C0@phx.gbl>
Message-ID: <CACk-te3k=Vnt5+7t1YUe3DTec1Ns2UXSGCHWiNcq8mhKsVnWAg@mail.gmail.com>

Search!

Googling on "How to set language for R" produced this:

https://stat.ethz.ch/pipermail/r-help/2008-October/178503.html

If this is not what you need, a little more searching may be required.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sat, Apr 19, 2014 at 2:10 AM, burak ?mer sara?oglu
<burakomersaracoglu at hotmail.com> wrote:
>
>
> Dear R Developers and Help Specialists;
> I downloaded and installed R to learn and use it during solutions of my scientific studies.
> At first, I got in trouble with it with the menu languages. It is in Turkish and I have to change it to English but I can not find where the language preferences menu or options menu is.
> Could you please let me know how I can select the English Language as the main language of the software (for menus, help etc.)
> Your kindness and help will be very much appriciated.
> Please do not publish on web my e-mail.
> Have a nice day.
> Best Regards
> Dr. Burak Omer Saracoglu
> PhD in Graduate School of Science Engineering and Technology
> MSc in Industrial Engineering
> BSc in Naval Architecture and Marine Engineering
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Sat Apr 19 23:18:14 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 19 Apr 2014 17:18:14 -0400
Subject: [R] How to use rainbow function without the gamma argument
In-Reply-To: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>
References: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>
Message-ID: <DE449B69-90D5-4A69-B9D4-88D6DF4A5EBF@utoronto.ca>

Have you looked at ?rainbow ?
Is there a reason why you don't simply leave the gamma parameter away?

Try:
pie(rep(1,100), col=rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75))

Cheers,
B.


On 2014-04-19, at 6:05 AM, Francesco Brundu wrote:

> Hi all,
> I am using an old code (probably written for R 2.5) and it stops when
> calling rainbow() with gamma argument. I saw that gamma argument is not
> present in newer version of R rainbow function. How can I translate this
> line of code:
> 
> rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5)
> 
> ?
> 
> It fails with:
> 
> Error in rainbow(100, s = 1, v = 0.75, start = 0, end = 0.75, gamma = 1.5)
> :
>  unused argument (gamma = 1.5)
> Calls: nmfconsensus ... matrix.abs.plot -> image -> image.default -> rainbow
> Execution halted
> 
> Thanks
> 
> ~ Francesco Brundu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From msuzen at gmail.com  Sun Apr 20 00:03:06 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sun, 20 Apr 2014 00:03:06 +0200
Subject: [R] inverse normal distribution function
In-Reply-To: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>
References: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>
Message-ID: <CAPtbhHwm0p5kMiDaF8r7bx8oF8L52KPdAT_JQfV4rjr+oViJ8w@mail.gmail.com>

You may want to read about generalized linear modelling and link
functions for forming appropriate categorical variable/link function.
See documentations in R:  ?glm, ?family and ?inverse.gaussian.  Also
look at the original paper of Nelder, John; Wedderburn, Robert , it is
available freely with the courtesy of JSTOR:
http://www.jstor.org/discover/10.2307/2344614

On 18 April 2014 09:13, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> dear all members
>
> i want to use inverse normal distribution in R to show the value of
> variable Z when Z represent the ordered categorical variables. i hope
> anyone gives me an example on this distribution
> .
>
> thanks to all
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From msuzen at gmail.com  Sun Apr 20 01:19:02 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sun, 20 Apr 2014 01:19:02 +0200
Subject: [R] inverse normal distribution function
In-Reply-To: <CABLo8nGB3whr7wCH0sCqmfv7v2RT9d5POLT1dCJud+QXWMcv2Q@mail.gmail.com>
References: <CABLo8nFHTaZ23E_aZTrS-3Wa7cq7Ziz0waTfVNM=ea-c1HMacQ@mail.gmail.com>
	<CAPtbhHwm0p5kMiDaF8r7bx8oF8L52KPdAT_JQfV4rjr+oViJ8w@mail.gmail.com>
	<CABLo8nGB3whr7wCH0sCqmfv7v2RT9d5POLT1dCJud+QXWMcv2Q@mail.gmail.com>
Message-ID: <CAPtbhHzAJ3uRhJvp2SdtLu9htpeVNXTLKw0d2nNqVCC5vPsdZQ@mail.gmail.com>

Not sure how would you do that but there is a package SEM on CRAN for
structural equation models.

On 20 April 2014 01:10, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> thank you so much Suzen
> i want to use bayesian analysis in structural equation models with ordered
> categorical data and i want to use inverse normal as a distribution of
> thresholds and i  dont find any paper or documents in R or another program
> about inverse normal.
>
> best regards
>



From boris.steipe at utoronto.ca  Sun Apr 20 02:16:21 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 19 Apr 2014 20:16:21 -0400
Subject: [R] How to use rainbow function without the gamma argument
In-Reply-To: <CAFc_i-E0bF8ghQr9DSs3cjWiNY2MocE4LJNVVW_G4tSqv1-bvA@mail.gmail.com>
References: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>
	<DE449B69-90D5-4A69-B9D4-88D6DF4A5EBF@utoronto.ca>
	<CAFc_i-E0bF8ghQr9DSs3cjWiNY2MocE4LJNVVW_G4tSqv1-bvA@mail.gmail.com>
Message-ID: <C1196A55-830A-49AF-9FFD-9AE3903D961D@utoronto.ca>

If it MUST be parameter-compatible with the old call, you could just add "..." to your local version of rainbow. The unused parameter will then be dropped. 

Here's how:

# The original creates an error ...
rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5)

Error in rainbow(100, s = 1, v = 0.75, start = 0, end = 0.75, gamma = 1.5) : 
  unused argument (gamma = 1.5)

# The code of the function is here:
> rainbow
function (n, s = 1, v = 1, start = 0, end = max(1, n - 1)/n, 
    alpha = 1) 
{
    if ((n <- as.integer(n[1L])) > 0) {
        if (start == end || any(c(start, end) < 0) || any(c(start, 
            end) > 1)) 
            stop("'start' and 'end' must be distinct and in [0, 1].")
        hsv(h = seq.int(start, ifelse(start > end, 1, 0) + end, 
            length.out = n)%%1, s, v, alpha)
    }
    else character()
}
<bytecode: 0x101968950>
<environment: namespace:grDevices>

# I add ... to the parameters and define a local version of rainbow

rainbow = function (n, s = 1, v = 1, start = 0, end = max(1, n - 1)/n, 
     alpha = 1, ...) 
 {
     if ((n <- as.integer(n[1L])) > 0) {
         if (start == end || any(c(start, end) < 0) || any(c(start, 
             end) > 1)) 
             stop("'start' and 'end' must be distinct and in [0, 1].")
         hsv(h = seq.int(start, ifelse(start > end, 1, 0) + end, 
             length.out = n)%%1, s, v, alpha)
     }
     else character()
 }

# same code except for the dots...
# Now it accepts and discards unused arguments
> rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5, gefingerpoken = TRUE)
  [1] "#BF0000FF" "#BF0900FF" "#BF1100FF" "#BF1A00FF" "#BF2300FF" "#BF2B00FF" "#BF3400FF"
[...]
 [99] "#5700BFFF" "#6000BFFF"

# and if I want the original back, I just delete my local version ...
> rm(rainbow)
> rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5)
Error in rainbow(100, s = 1, v = 0.75, start = 0, end = 0.75, gamma = 1.5) : 
  unused argument (gamma = 1.5)

> rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75)
  [1] "#BF0000FF" "#BF0900FF" "#BF1100FF" "#BF1A00FF" "#BF2300FF" "#BF2B00FF" "#BF3400FF"
[...]
 [99] "#5700BFFF" "#6000BFFF"

You can read about the '...' argument in the Introduction to R. Here we use it not to pass variables on, but to have them not cause an error when present.

HOWEVER: I personally would consider this poor style. It's probably better to review and update your old code. There may be other less obvious problems.

YMMV
B.





On 2014-04-19, at 7:19 PM, Francesco Brundu wrote:

> Hi Boris,
> yes I tried this way and it worked. The fact is that I wanted to be compliant with the old code, I did not want to change anything. So I wanted to find a new way to rewrite the code.
> Thanks
> 
> ~ Francesco Brundu
> 
> 
> On 19 April 2014 23:18, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Have you looked at ?rainbow ?
> Is there a reason why you don't simply leave the gamma parameter away?
> 
> Try:
> pie(rep(1,100), col=rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75))
> 
> Cheers,
> B.
> 
> 
> On 2014-04-19, at 6:05 AM, Francesco Brundu wrote:
> 
> > Hi all,
> > I am using an old code (probably written for R 2.5) and it stops when
> > calling rainbow() with gamma argument. I saw that gamma argument is not
> > present in newer version of R rainbow function. How can I translate this
> > line of code:
> >
> > rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5)
> >
> > ?
> >
> > It fails with:
> >
> > Error in rainbow(100, s = 1, v = 0.75, start = 0, end = 0.75, gamma = 1.5)
> > :
> >  unused argument (gamma = 1.5)
> > Calls: nmfconsensus ... matrix.abs.plot -> image -> image.default -> rainbow
> > Execution halted
> >
> > Thanks
> >
> > ~ Francesco Brundu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 



From smartpink111 at yahoo.com  Sun Apr 20 03:43:33 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 19 Apr 2014 18:43:33 -0700 (PDT)
Subject: [R] Need help to convert data frame to transaction set.
In-Reply-To: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>
References: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>
Message-ID: <1397958213.97544.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

Without a reproducible example using ?dput() or the package name, it is a bit difficult to comment.

Assuming that you used:
library(arules)
?data("AdultUCI")
AdultUCI$ID <- 1:nrow(AdultUCI)

lst1 <- split(AdultUCI[,"ID"], AdultUCI[,"marital-status"])
?as(lst1, "transactions")
#transactions in sparse format with
# 7 transactions (rows) and
# 48842 items (columns)



A.K.


On Saturday, April 19, 2014 5:01 PM, Sathish Kumar <tellsathish at gmail.com> wrote:
Hi,

To convert coerce the data set to transaction data set I used the code

trans4 <- as(split(a[,"Cust_ID"], a[,"Parts"]), "transactions")

but I am getting the following error-

Error in as(split(a[, "Cust_ID"], a[, "Parts"]), "transactions") : nomethod
or default for coercing ?list? to ?transactions?



Then I tried first converting the data set to matrix structure using the
code

c_m<-as.matrix(c_df)
c_m



then entered the following code


trans2 <- as(c_m, "transactions")

but got the following error

Error in as(c_m, "transactions") : no method or default for coercing
?matrix? to ?transactions?
Please let me know how to correct the problem.

Thanks
Sathish
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Apr 20 07:36:12 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 19 Apr 2014 22:36:12 -0700 (PDT)
Subject: [R] Need help to convert data frame to transaction set.
In-Reply-To: <CA+zKt6iLFhSTFoQtbzrU0EQPUod-9UhVw7Y=nZqP5v_W87=j3A@mail.gmail.com>
References: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>	<1397958213.97544.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CA+zKt6iLFhSTFoQtbzrU0EQPUod-9UhVw7Y=nZqP5v_W87=j3A@mail.gmail.com>
Message-ID: <1397972172.73574.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi Satish,

Using your code:
part<-read.csv("spares.csv")
str(part)
#'data.frame':??? 838 obs. of? 1 variable:
# $ Cust_ID.Parts: Factor w/ 838 levels "100\tAIR\tFILTER\tHOUSING\t",..: 161 333 495 727 728 768 769 770 784 785 ...

#I guess you have only two columns in the dataset

?lines1 <- readLines("spares.csv")
?head(lines1)
#[1] "Cust_ID\tParts\t\t\t"????? "1\tFENDERS\t\t\t"???????? 
#[3] "2\tFENDERS\t\t\t"????????? "3\tOIL\tFILTERS\t\t"????? 
#[5] "4\tBMW\tSERVICE\tFLUIDS\t" "4\tOIL\tFILTER\t\t"?????? 


part<-read.csv("spares.csv",header=TRUE,sep="\t")
?str(part)
#'data.frame':??? 838 obs. of? 5 variables:
# $ Cust_ID: int? 1 2 3 4 4 5 5 5 6 6 ...
# $ Parts? : Factor w/ 26 levels "AIR","ALTERNATOR",..: 9 9 16 4 16 6 9 12 6 9 ...
# $ X????? : Factor w/ 14 levels "","BLADES","CAR",..: 1 1 6 14 5 1 1 1 1 1 ...
# $ X.1??? : Factor w/ 6 levels "","(AXLE","CARE",..: 1 1 1 4 1 1 1 1 1 1 ...
# $ X.2??? : Factor w/ 2 levels "","BOOT)": 1 1 1 1 1 1 1 1 1 1 ...


part$Parts <- interaction(part[,2:5],sep=" ",drop=TRUE)
?part <- part[,1:2]
?str(part)
#'data.frame':??? 838 obs. of? 2 variables:
# $ Cust_ID: int? 1 2 3 4 4 5 5 5 6 6 ...
# $ Parts? : Factor w/ 31 levels "ALTERNATOR?? ",..: 6 6 21 28 20 3 6 8 3 6 ...
as(split(part[,"Cust_ID"],part[,"Parts"]),"transactions")
#transactions in sparse format with
# 31 transactions (rows) and
# 502 items (columns)
A.K.



On Saturday, April 19, 2014 11:08 PM, Sathish Kumar <tellsathish at gmail.com> wrote:

Hi AK,

I have attached? the data set. 

And as you suggested, I coded as follows but?still I am getting?an error 

> part<-read.csv("spares.csv")
> part
>lst1<-split(part[,"Cust_ID"],part[,"Parts"])
> as(lst1, "transactions")

Error in as(lst1, "transactions") : 
? no method or default for coercing ?list? to ?transactions?



On Sat, Apr 19, 2014 at 6:43 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>
>Without a reproducible example using ?dput() or the package name, it is a bit difficult to comment.
>
>Assuming that you used:
>library(arules)
>?data("AdultUCI")
>AdultUCI$ID <- 1:nrow(AdultUCI)
>
>lst1 <- split(AdultUCI[,"ID"], AdultUCI[,"marital-status"])
>?as(lst1, "transactions")
>#transactions in sparse format with
># 7 transactions (rows) and
># 48842 items (columns)
>
>
>
>A.K.
>
>
>
>On Saturday, April 19, 2014 5:01 PM, Sathish Kumar <tellsathish at gmail.com> wrote:
>Hi,
>
>To convert coerce the data set to transaction data set I used the code
>
>trans4 <- as(split(a[,"Cust_ID"], a[,"Parts"]), "transactions")
>
>but I am getting the following error-
>
>Error in as(split(a[, "Cust_ID"], a[, "Parts"]), "transactions") : nomethod
>or default for coercing ?list? to ?transactions?
>
>
>
>Then I tried first converting the data set to matrix structure using the
>code
>
>c_m<-as.matrix(c_df)
>c_m
>
>
>
>then entered the following code
>
>
>trans2 <- as(c_m, "transactions")
>
>but got the following error
>
>Error in as(c_m, "transactions") : no method or default for coercing
>?matrix? to ?transactions?
>Please let me know how to correct the problem.
>
>Thanks
>Sathish
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>



From ripley at stats.ox.ac.uk  Sun Apr 20 09:50:36 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 20 Apr 2014 08:50:36 +0100
Subject: [R] Difference between times
In-Reply-To: <CB5D0A98-916A-48E4-A879-E33C5D24BD5B@comcast.net>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>	<535172FA.7050507@sapo.pt>
	<53518420.3060206@stats.ox.ac.uk>
	<CB5D0A98-916A-48E4-A879-E33C5D24BD5B@comcast.net>
Message-ID: <53537C4C.1040704@stats.ox.ac.uk>

On 18/04/2014 21:46, David Winsemius wrote:
>
> On Apr 18, 2014, at 12:59 PM, Prof Brian Ripley wrote:
>
>> On 18/04/2014 19:46, Rui Barradas wrote:
>>> Hello,
>>>
>>> The reason why is that you've misspelled CET (not CEST)
>>
>> Neither CET nor CEST are portable time-zone names.  We have not been given the 'at a minimum' information required by the posting guide, so please read ?Sys.timezone on your system.
>
> Dear Prof;
>
> Thanks for the impetus to yet again read that page. Despite frequently reading help pages and in particular reading that one many times, I still was not getting the 'tz' arguments correct on a Mac. I do now see that I was spelling my TZ incorrectly (as "Americas/Los_Angeles" rather than "America/Los_Angeles".
>
> Fellow Mac users may face a problem when using the Finder unless they set it up to display hidden ('dot') files. The /usr/ folder is "greyed out" but it still does open. If I restore my Finder defaults to not show system files and folders, I no longer see that directory and would not have been able to resolve my spelling error on my own:
>
>
>> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "America/New_York")
>>   dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "America/Los_Angeles")
>>   dt1-dt2
> Time difference of 3 hours
>
> I don't suppose a warning could be issued by the as.POSIXct code when a "tz" argument is not found in the database to let people know that 'UTC' will be the default?

No, as the underlying POSIX function does not report this.  We could 
perhaps do this on platforms which use --with-internal-tzcode but not 
e.g. on Linux.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Apr 20 11:16:12 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 20 Apr 2014 10:16:12 +0100
Subject: [R] Difference between times
In-Reply-To: <53537C4C.1040704@stats.ox.ac.uk>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>	<535172FA.7050507@sapo.pt>	<53518420.3060206@stats.ox.ac.uk>	<CB5D0A98-916A-48E4-A879-E33C5D24BD5B@comcast.net>
	<53537C4C.1040704@stats.ox.ac.uk>
Message-ID: <5353905C.2030306@stats.ox.ac.uk>

On 20/04/2014 08:50, Prof Brian Ripley wrote:
> On 18/04/2014 21:46, David Winsemius wrote:
>>
>> On Apr 18, 2014, at 12:59 PM, Prof Brian Ripley wrote:
>>
>>> On 18/04/2014 19:46, Rui Barradas wrote:
>>>> Hello,
>>>>
>>>> The reason why is that you've misspelled CET (not CEST)
>>>
>>> Neither CET nor CEST are portable time-zone names.  We have not been
>>> given the 'at a minimum' information required by the posting guide,
>>> so please read ?Sys.timezone on your system.
>>
>> Dear Prof;
>>
>> Thanks for the impetus to yet again read that page. Despite frequently
>> reading help pages and in particular reading that one many times, I
>> still was not getting the 'tz' arguments correct on a Mac. I do now
>> see that I was spelling my TZ incorrectly (as "Americas/Los_Angeles"
>> rather than "America/Los_Angeles".
>>
>> Fellow Mac users may face a problem when using the Finder unless they
>> set it up to display hidden ('dot') files. The /usr/ folder is "greyed
>> out" but it still does open. If I restore my Finder defaults to not
>> show system files and folders, I no longer see that directory and
>> would not have been able to resolve my spelling error on my own:

You can always use the command-line or OlsonNames() in R.
>>
>>> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>>> "America/New_York")
>>>   dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>>> "America/Los_Angeles")
>>>   dt1-dt2
>> Time difference of 3 hours
>>
>> I don't suppose a warning could be issued by the as.POSIXct code when
>> a "tz" argument is not found in the database to let people know that
>> 'UTC' will be the default?
>
> No, as the underlying POSIX function does not report this.  We could
> perhaps do this on platforms which use --with-internal-tzcode but not
> e.g. on Linux.

In fact we already do: R 3.1.0 on a Mac shows

 > as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = 
"Americas/New_York")
[1] "2014-04-18 09:00:00 GMT"
Warning messages:
1: In strptime(x, format, tz = tz) : unknown timezone 'Americas/New_York'
2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
   unknown timezone 'Americas/New_York'
3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Americas/New_York'


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andre.zacharia at gmail.com  Sun Apr 20 11:52:28 2014
From: andre.zacharia at gmail.com (Andre Zacharia)
Date: Sun, 20 Apr 2014 09:52:28 +0000
Subject: [R] to divide column cells by the mean of another column
Message-ID: <-9037856679275383611@unknownmsgid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140420/4658be9a/attachment-0001.pl>

From bbolker at gmail.com  Sun Apr 20 02:54:10 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 20 Apr 2014 00:54:10 +0000
Subject: [R] Extracting the names of coefficients of random effects
References: <1397922679520-4689109.post@n4.nabble.com>
Message-ID: <loom.20140420T025045-488@post.gmane.org>

Brian Willis <b.h.willis <at> bham.ac.uk> writes:

> 
> Hi All,
> I need to be able to manipulate the names of the coefficients from
> *ranef()*.
> 
> If there is any missing data when fitting a mixed model using lmer, no
> estimate is returned for the associated level for that random effect. Thus
> if the data input for regions had levels 
> 	*Region*
>         Bolton
> 	Bradford                    
>         Cambridge
>         Durham						 
> and there was missing data on Bradford then 
> * ranef(model)*					gives 
> 	                                                     (Intercept)
> Bolton:                               	          -0.0981763413
> Cambridge		                                   0.0151102347
> Durham						   0.1837142259


  I think you want to use rownames():

library(lme4)
d <- expand.grid(f=factor(LETTERS[1:10]),rep=1:10)
d$y <- rnorm(100)
m <- lmer(y~(1|f),data=d)

rownames(ranef(m)[[1]])

> This becomes a problem if I want to use *predict( )* on new data where there
> is no missing data on Bradford. In such an instance
> 
> 	*predict (model, newdata = newInput) *
> gives the following error message 
> 
>              ?Error in (function (x, n)  : new levels detected in newdata?
> 
> I could get round this by checking the Region field of the new data
> ?newInput? against the names of the levels of the intercept coefficients
> from* ranef().*
> However, I?m not sure how to access these since if 
> *x<- ranef(model)
> x *

  You should also check the allow.new.levels argument in
?predict.merMod, and send followups to r-sig-mixed-models at r-project.org.



From mardones.p at gmail.com  Sun Apr 20 06:32:31 2014
From: mardones.p at gmail.com (Pedro Mardones)
Date: Sun, 20 Apr 2014 01:32:31 -0300
Subject: [R] Replicating SAS example in R
Message-ID: <CAEd7G2fPcKmuyOszDrRRaB64mSEVL-01XeDbwxFChWzX1E_KBw@mail.gmail.com>

Dear R community;

I'm trying to replicate an example I found on a publication using the
following data

dat <- data.frame(F = c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,
2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3), T =
c(1,1,1,1,1,1,1,1,2,2,2,
2,2,2,2,2,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2),
R =
c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,
10,10,10,10,11,11,11,11,12,12,12,12), E =
c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,
16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,
42,43,44,45,46,47,48), HT =
c(7.3,10.3,14.8,2.9,14.9,1.8,5.1,17.7,14.1,13,19.3,
20.7,24.9,16,14.9,24.9,24.3,28.6,31.8,32.7,29.1,24.7,30.1,31.9,42.2,45.6,40.7,
34.5,38.4,46.4,38,41.7,50.7,53.2,50.1,41.4,53,37.9,50.9,51,69.5,53.8,53.8,62.1,
54.3,63,47,65.4))

F, T are two treatments
R is a row of plants nested within F & T (according to the example)
E are the plants within the rows R

The experimental unit is R but the example considers subsampling, so in
other words, the idea is to use all the data at plant-level (E) for the
analysis instead of the row-level means.

The SAS model used in the example is

PROC GLM DATA=dat;
CLASS F T R;
MODEL HT = F|T R(F T);
TEST H = F|T E=R(F T);
CONTRAST 'First vs Third in F' F -1 0 1 / E = R(F T);
MEANS F / LSD E = R(F T) CLDIFF;
RUN;

My R version looks like
options(contrasts = c("contr.SAS", "contr.poly"))
dat$F <- as.factor(dat$F)
dat$T <- as.factor(dat$T)
dat$R <- as.factor(dat$R)
m2 <- aov(HT ~ F*T + Error(R/F*T), data = dat)
summary(m2)

which gives me similar results to the SAS example. However, I haven't been
able to replicate the CONTRAST and MEANS commands

I'd appreciate any hint (maybe using lmer instead?)

Thanks in advance

************************************************************************************

SAS output attached as pdf
-------------- next part --------------
A non-text attachment was scrubbed...
Name: anovaexamples.pdf
Type: application/pdf
Size: 154055 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140420/ddffd6f1/attachment-0002.pdf>

From francesco.brundu at gmail.com  Sun Apr 20 01:19:33 2014
From: francesco.brundu at gmail.com (Francesco Brundu)
Date: Sun, 20 Apr 2014 01:19:33 +0200
Subject: [R] How to use rainbow function without the gamma argument
In-Reply-To: <DE449B69-90D5-4A69-B9D4-88D6DF4A5EBF@utoronto.ca>
References: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>
	<DE449B69-90D5-4A69-B9D4-88D6DF4A5EBF@utoronto.ca>
Message-ID: <CAFc_i-E0bF8ghQr9DSs3cjWiNY2MocE4LJNVVW_G4tSqv1-bvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140420/afcf1585/attachment-0001.pl>

From francesco.brundu at gmail.com  Sun Apr 20 02:24:22 2014
From: francesco.brundu at gmail.com (Francesco Brundu)
Date: Sun, 20 Apr 2014 02:24:22 +0200
Subject: [R] How to use rainbow function without the gamma argument
In-Reply-To: <C1196A55-830A-49AF-9FFD-9AE3903D961D@utoronto.ca>
References: <CAFc_i-GduEgN7hEvEdTaYy4r-w45jn+3bQ8x91DGo_5vDjCA3w@mail.gmail.com>
	<DE449B69-90D5-4A69-B9D4-88D6DF4A5EBF@utoronto.ca>
	<CAFc_i-E0bF8ghQr9DSs3cjWiNY2MocE4LJNVVW_G4tSqv1-bvA@mail.gmail.com>
	<C1196A55-830A-49AF-9FFD-9AE3903D961D@utoronto.ca>
Message-ID: <CAFc_i-HOhyjj8DScNveJ7cf-QSqKPE93QYSP3L-3XPUaZoj_sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140420/d02c32ec/attachment-0001.pl>

From tellsathish at gmail.com  Sun Apr 20 04:27:23 2014
From: tellsathish at gmail.com (Sathish Kumar)
Date: Sat, 19 Apr 2014 19:27:23 -0700
Subject: [R] Need help to convert data frame to transaction set.
In-Reply-To: <1397958213.97544.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>
	<1397958213.97544.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CA+zKt6hx8Y7pLYd7yD970V4n_q1qikTpz=0_+3bimEvBngPu4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/1fe87ad2/attachment-0001.pl>

From tellsathish at gmail.com  Sun Apr 20 08:31:19 2014
From: tellsathish at gmail.com (Sathish Kumar)
Date: Sat, 19 Apr 2014 23:31:19 -0700
Subject: [R] Need help to convert data frame to transaction set.
In-Reply-To: <1397972172.73574.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CA+zKt6jG9=zwZcU-32j6t+KDW-N=Gw4f-vBgt139Cqt=dGnPyw@mail.gmail.com>
	<1397958213.97544.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CA+zKt6iLFhSTFoQtbzrU0EQPUod-9UhVw7Y=nZqP5v_W87=j3A@mail.gmail.com>
	<1397972172.73574.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CA+zKt6gzCBgSVc3UyCWdLJ2wczWytR_AWgtQMqVfXi3WuMaceA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140419/87aaad7c/attachment-0001.pl>

From gunter.berton at gene.com  Sun Apr 20 16:14:26 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 20 Apr 2014 07:14:26 -0700
Subject: [R] to divide column cells by the mean of another column
In-Reply-To: <-9037856679275383611@unknownmsgid>
References: <-9037856679275383611@unknownmsgid>
Message-ID: <CACk-te2Qqr5uomzs6DMOtump1nWNakPPZ=tceZRQtLpngxW-Vw@mail.gmail.com>

R has no "cells".

You need to do your homework by reading "An Introduction to R" , which
ships with R, or one of the many R web tutorials of your choice. What
you describe is trivial once you have made a minimal effort to learn
R. In particular, ?"["  explains how to index data frames; but a
tutorial is a better option for a learner.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sun, Apr 20, 2014 at 2:52 AM, Andre Zacharia
<andre.zacharia at gmail.com> wrote:
> Dear all,
>
> I am getting data columnwise that I need to divide by the mean of another
> column
>
> If the column is the previous one this code works perfectly well:
>
> fun1 <- function(beginColumn, by, data) { indx <- seq(beginColumn,
> ncol(data), by = by) as.data.frame(t(100 - (t(data[, indx])/colMeans(data[,
> indx - 1], na.rm = TRUE)) *  100))
> }
> (Arun helped me with this code, thank you again!...)
>
> But, the things is now more complicated...
>
> I need to program a function that allow me to divide for example cells from
> column 3 on mean from column 2 and cells from column 4 on mean of column 2
> and the 5 etc. Then column 6 is another column from whch I  need to extract
> the mean and to do the same with column 7 and 8, etc...
>
> so if  I have:
>
> 1  2  3 4  1  5
> 2  5  4 7  2  8
> 3  4  5 9  3  7
> 4  7  7 9  4  3
>
> The serie 1,2,3,4 ar just enumerating so not useful at this timepoint.
>
> the results should be (from excel...):
>  4,5 33,3333333 11,1111111 -11,1111111   11,1111111 -55,5555556 -77,7777778
> -11,1111111 -100 -55,5555556   -55,5555556 -100
> 33,3333333
> I tried to work on modyfying indx-1 by 2*indx-2, but this is not doing the
> job... I tried many other things so that I am now stucked.
>
> Does Anyone has a brilliant idea?
>
> Many many thanks
>
> Andr? ZACHARIA
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From smartpink111 at yahoo.com  Sun Apr 20 17:30:17 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 20 Apr 2014 08:30:17 -0700 (PDT)
Subject: [R] to divide column cells by the mean of another column
In-Reply-To: <-9037856679275383611@unknownmsgid>
References: <-9037856679275383611@unknownmsgid>
Message-ID: <1398007817.58048.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

May be this helps:
fun1 <- function(beginColumn, by, data) {
??? indx <- seq(beginColumn, ncol(data), by = by)
??? dataNew <- data[, indx[1]:ncol(data)]
??? indx1 <- cumsum(seq(ncol(data)) %in% indx)
??? indx2 <- indx1[indx1 != 0]
??? lst1 <- lapply(split(seq_along(indx2), indx2), function(i) {
??????? x1 <- dataNew[, i, drop = FALSE]
??????? if (ncol(x1) > 1) {
??????????? x1[, -1]/mean(x1[, 1])
??????? }
??? })
??? res <- data.frame(lst1[sapply(lst1, length) > 0])
??? colnames(res) <- gsub(".*\\.", "", colnames(res))
??? res
}

set.seed(458)
dat1 <- as.data.frame(matrix(sample(5,10*5,replace=TRUE),ncol=10))

set.seed(34)
dat2 <- as.data.frame(matrix(sample(20,21*5,replace=TRUE),ncol=21))
?fun1(2,4,dat1)
fun1(2,5,dat2)

A.K.





On Sunday, April 20, 2014 5:55 AM, Andre Zacharia <andre.zacharia at gmail.com> wrote:
Dear all,

I am getting data columnwise that I need to divide by the mean of another
column

If the column is the previous one this code works perfectly well:

fun1 <- function(beginColumn, by, data) { indx <- seq(beginColumn,
ncol(data), by = by) as.data.frame(t(100 - (t(data[, indx])/colMeans(data[,
indx - 1], na.rm = TRUE)) *? 100))
}
(Arun helped me with this code, thank you again!...)

But, the things is now more complicated...

I need to program a function that allow me to divide for example cells from
column 3 on mean from column 2 and cells from column 4 on mean of column 2
and the 5 etc. Then column 6 is another column from whch I? need to extract
the mean and to do the same with column 7 and 8, etc...

so if? I have:

1? 2? 3 4? 1? 5
2? 5? 4 7? 2? 8
3? 4? 5 9? 3? 7
4? 7? 7 9? 4? 3

The serie 1,2,3,4 ar just enumerating so not useful at this timepoint.

the results should be (from excel...):
4,5 33,3333333 11,1111111 -11,1111111?  11,1111111 -55,5555556 -77,7777778
-11,1111111 -100 -55,5555556?  -55,5555556 -100
33,3333333
I tried to work on modyfying indx-1 by 2*indx-2, but this is not doing the
job... I tried many other things so that I am now stucked.

Does Anyone has a brilliant idea?

Many many thanks

Andr? ZACHARIA

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From smartpink111 at yahoo.com  Sun Apr 20 18:17:55 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 20 Apr 2014 09:17:55 -0700 (PDT)
Subject: [R] to divide column cells by the mean of another column
In-Reply-To: <1398007817.58048.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <-9037856679275383611@unknownmsgid>
	<1398007817.58048.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1398010675.65542.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Andre,


A slight correction:
fun1 <- function(beginColumn, by, data) {
??? indx <- seq(beginColumn, ncol(data), by = by)
??? dataNew <- data[, indx[1]:ncol(data)]
??? indx1 <- cumsum(seq(ncol(data)) %in% indx)
??? indx2 <- indx1[indx1 != 0]
??? lst1 <- lapply(split(seq_along(indx2), indx2), function(i) {
??????? x1 <- dataNew[, i, drop = FALSE]
??????? if (ncol(x1) > 1) {
??????????? x1[, -1, drop = FALSE]/mean(x1[, 1]) ###changed
??????? }
??? })
??? 
??? res <- data.frame(lst1[sapply(lst1, length) > 0])
??? colnames(res) <- gsub(".*\\.", "", colnames(res))
??? res
}



Also, you can try:
fun2 <- function(beginColumn, by, data) {
??? indx <- seq(beginColumn, ncol(data), by = by)
??? indx1 <- head(indx + 1, -1)
??? indx2 <- tail(indx - 1, -1)
??? vec1 <- as.vector(sapply(seq_along(indx1), function(i) indx1[i]:indx2[i]))
??? if (ncol(data) > tail(indx, 1)) {
??????? vec2 <- c(vec1, (tail(indx, 1) + 1):ncol(dat1))
??? } else {
??????? vec2 <- vec1
??? }
??? means1 <- rep(colMeans(data[, indx]), each = by - 1, length.out = length(vec2))
??? res <- as.data.frame(t(t(data[, vec2])/means1))
??? res
}

set.seed(458)
dat1 <- as.data.frame(matrix(sample(5,10*5,replace=TRUE),ncol=10))

identical(fun1(2,4,dat1),fun2(2,4,dat1))
#[1] TRUE
A.K.



Hi,

May be this helps:
fun1 <- function(beginColumn, by, data) {
??? indx <- seq(beginColumn, ncol(data), by = by)
??? dataNew <- data[, indx[1]:ncol(data)]
??? indx1 <- cumsum(seq(ncol(data)) %in% indx)
??? indx2 <- indx1[indx1 != 0]
??? lst1 <- lapply(split(seq_along(indx2), indx2), function(i) {
??????? x1 <- dataNew[, i, drop = FALSE]
??????? if (ncol(x1) > 1) {
??????????? x1[, -1]/mean(x1[, 1])
??????? }
??? })
??? res <- data.frame(lst1[sapply(lst1, length) > 0])
??? colnames(res) <- gsub(".*\\.", "", colnames(res))
??? res
}

set.seed(458)
dat1 <- as.data.frame(matrix(sample(5,10*5,replace=TRUE),ncol=10))

set.seed(34)
dat2 <- as.data.frame(matrix(sample(20,21*5,replace=TRUE),ncol=21))
?fun1(2,4,dat1)
fun1(2,5,dat2)

A.K.






On Sunday, April 20, 2014 5:55 AM, Andre Zacharia <andre.zacharia at gmail.com> wrote:
Dear all,

I am getting data columnwise that I need to divide by the mean of another
column

If the column is the previous one this code works perfectly well:

fun1 <- function(beginColumn, by, data) { indx <- seq(beginColumn,
ncol(data), by = by) as.data.frame(t(100 - (t(data[, indx])/colMeans(data[,
indx - 1], na.rm = TRUE)) *? 100))
}
(Arun helped me with this code, thank you again!...)

But, the things is now more complicated...

I need to program a function that allow me to divide for example cells from
column 3 on mean from column 2 and cells from column 4 on mean of column 2
and the 5 etc. Then column 6 is another column from whch I? need to extract
the mean and to do the same with column 7 and 8, etc...

so if? I have:

1? 2? 3 4? 1? 5
2? 5? 4 7? 2? 8
3? 4? 5 9? 3? 7
4? 7? 7 9? 4? 3

The serie 1,2,3,4 ar just enumerating so not useful at this timepoint.

the results should be (from excel...):
4,5 33,3333333 11,1111111 -11,1111111?? 11,1111111 -55,5555556 -77,7777778
-11,1111111 -100 -55,5555556?? -55,5555556 -100
33,3333333
I tried to work on modyfying indx-1 by 2*indx-2, but this is not doing the
job... I tried many other things so that I am now stucked.

Does Anyone has a brilliant idea?

Many many thanks

Andr? ZACHARIA

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From joanna.hagen at student.manchester.ac.uk  Sun Apr 20 17:51:13 2014
From: joanna.hagen at student.manchester.ac.uk (mfbx9jhy)
Date: Sun, 20 Apr 2014 08:51:13 -0700 (PDT)
Subject: [R] What do the colours of the scatterplot3d actually show?
Message-ID: <1398009073007-4689148.post@n4.nabble.com>

Hello, 

Please could anyone tell me the significance of the graded red-black color
when using scatterplot3d? 

At first I thought it was just going from the very 'near' to the back of the
chart area, but as you can see from the pictures some of the points in the
back are bright red. The description from ?scatterplot mentions that
hightlight3d "points will be drawn in different colors related to y
coordinates"... but as you can tell from the plot is isn't true either; with
come short points being black as well as red...


<http://r.789695.n4.nabble.com/file/n4689148/Rplot.png> 


any help would be fantastic, I'm very very new to R

Cheers, 

Jo




--
View this message in context: http://r.789695.n4.nabble.com/What-do-the-colours-of-the-scatterplot3d-actually-show-tp4689148.html
Sent from the R help mailing list archive at Nabble.com.



From ligges at statistik.tu-dortmund.de  Sun Apr 20 19:43:01 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 20 Apr 2014 19:43:01 +0200
Subject: [R] What do the colours of the scatterplot3d actually show?
In-Reply-To: <1398009073007-4689148.post@n4.nabble.com>
References: <1398009073007-4689148.post@n4.nabble.com>
Message-ID: <53540725.9010002@statistik.tu-dortmund.de>



On 20.04.2014 17:51, mfbx9jhy wrote:
> Hello,
>
> Please could anyone tell me the significance of the graded red-black color
> when using scatterplot3d?
>
> At first I thought it was just going from the very 'near' to the back of the
> chart area, but as you can see from the pictures some of the points in the
> back are bright red. The description from ?scatterplot mentions that
> hightlight3d "points will be drawn in different colors related to y
> coordinates"... but as you can tell from the plot is isn't true either; with
> come short points being black as well as red...
>
>
> <http://r.789695.n4.nabble.com/file/n4689148/Rplot.png>
>
>
> any help would be fantastic, I'm very very new to R


All points in bright red appear to be within [0,5] on the "elong" 
labelled  axis. If you find a point that is not, please tell me which 
one and send me the data and the code so that I could check what happens.

Best,
Uwe Ligges




> Cheers,
>
> Jo
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/What-do-the-colours-of-the-scatterplot3d-actually-show-tp4689148.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From dwinsemius at comcast.net  Sun Apr 20 20:35:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 20 Apr 2014 11:35:50 -0700
Subject: [R] Difference between times
In-Reply-To: <5353905C.2030306@stats.ox.ac.uk>
References: <CAM8ViJMHb49Bu355FPuOHvenFnwtS7fq_8DpPs9T0UBrZcoDTw@mail.gmail.com>	<535172FA.7050507@sapo.pt>	<53518420.3060206@stats.ox.ac.uk>	<CB5D0A98-916A-48E4-A879-E33C5D24BD5B@comcast.net>
	<53537C4C.1040704@stats.ox.ac.uk> <5353905C.2030306@stats.ox.ac.uk>
Message-ID: <3FF0AEA1-33DD-4D3E-8A8C-B89AEE82EE45@comcast.net>


On Apr 20, 2014, at 2:16 AM, Prof Brian Ripley wrote:

> On 20/04/2014 08:50, Prof Brian Ripley wrote:
>> On 18/04/2014 21:46, David Winsemius wrote:
>>> 
>>> On Apr 18, 2014, at 12:59 PM, Prof Brian Ripley wrote:
>>> 
>>>> On 18/04/2014 19:46, Rui Barradas wrote:
>>>>> Hello,
>>>>> 
>>>>> The reason why is that you've misspelled CET (not CEST)
>>>> 
>>>> Neither CET nor CEST are portable time-zone names.  We have not been
>>>> given the 'at a minimum' information required by the posting guide,
>>>> so please read ?Sys.timezone on your system.
>>> 
>>> Dear Prof;
>>> 
>>> Thanks for the impetus to yet again read that page. Despite frequently
>>> reading help pages and in particular reading that one many times, I
>>> still was not getting the 'tz' arguments correct on a Mac. I do now
>>> see that I was spelling my TZ incorrectly (as "Americas/Los_Angeles"
>>> rather than "America/Los_Angeles".
>>> 
>>> Fellow Mac users may face a problem when using the Finder unless they
>>> set it up to display hidden ('dot') files. The /usr/ folder is "greyed
>>> out" but it still does open. If I restore my Finder defaults to not
>>> show system files and folders, I no longer see that directory and
>>> would not have been able to resolve my spelling error on my own:
> 
> You can always use the command-line or OlsonNames() in R.

I'm not finding an OlsonNames function on a Mac (but is that because I haven't updated?). Before seeing that the zone-checking feature had been added as a feature, I was building an OlsonNames function that extracts the sub-directories of the zoneinfo directory and appends the file names to them as well as extracting the non-OlsonNames entries in zoneinfo. My plan had been to make my own warnings in strptime, but that appears to be unnecessary.

OlsonNames <- function(onlyOlson=FALSE) { 
  MacOlsonDirs <- system('ls -p /usr/share/zoneinfo ', intern=TRUE)
  OlsonNames <- unlist( lapply( MacOlsonDirs[grep("/$", MacOlsonDirs)], 
                            function(dir) paste0( dir, 
                                           system( paste0('ls -p /usr/share/zoneinfo/', dir) , 
                                                   intern=TRUE) ) ) )
  nonOlsonNames <- MacOlsonDirs[grepl("^[A-Z]", MacOlsonDirs) & ! grepl("/$", MacOlsonDirs) ]
  if ( !onlyOlson){ c(OlsonNames, nonOlsonNames)} else {OlsonNames}
   }

Yes. It is because I haven't updated. I now see this in the NEWS that was posted in this list 10 days ago.

There is more support to explore the system's idea of time-zone
    names.  Sys.timezone() tries to give the current system setting
    by name (and succeeds at least on Linux, OS X, Solaris and
    Windows), and OlsonNames() lists the names in the system's Olson
    database. Sys.timezone(location = FALSE) gives the previous
    behaviour.
 
I guess I will have fun comparing my efforts with those of the masters.

>>> 
>>>> dt2 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>>>> "America/New_York")
>>>>  dt1 = as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz =
>>>> "America/Los_Angeles")
>>>>  dt1-dt2
>>> Time difference of 3 hours
>>> 
>>> I don't suppose a warning could be issued by the as.POSIXct code when
>>> a "tz" argument is not found in the database to let people know that
>>> 'UTC' will be the default?
>> 
>> No, as the underlying POSIX function does not report this.  We could
>> perhaps do this on platforms which use --with-internal-tzcode but not
>> e.g. on Linux.
> 
> In fact we already do: R 3.1.0 on a Mac shows

My apologies. And thank you to whomever added the feature and to you, Prof, for checking and letting us know. I was going to offer the code above as a patch but that seems not needed now. I have not yet updated to 3.1.0. The Mavericks/3.1.0 incompatibilities have been scaring me off from updating. Still on Lion/3.0.2.

> 
> > as.POSIXct("2014-04-18 09.00", format="%Y-%m-%d %H.%M", tz = "Americas/New_York")
> [1] "2014-04-18 09:00:00 GMT"
> Warning messages:
> 1: In strptime(x, format, tz = tz) : unknown timezone 'Americas/New_York'
> 2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
>  unknown timezone 'Americas/New_York'
> 3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Americas/New_York'

Thank you, all of R-Core.


> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

David Winsemius
Alameda, CA, USA



From alpeshpandya at gmail.com  Sun Apr 20 20:45:44 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Sun, 20 Apr 2014 14:45:44 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
Message-ID: <CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140420/4a535488/attachment-0001.pl>

From murdoch.duncan at gmail.com  Sun Apr 20 23:26:45 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Apr 2014 17:26:45 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>	<5348725B.7070404@statistik.tu-dortmund.de>	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>	<5349CABA.7000807@statistik.tu-dortmund.de>	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>	<534A9525.90209@statistik.tu-dortmund.de>	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>	<534C261F.8060608@sapo.pt>	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
	<CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
Message-ID: <53543B95.1070302@gmail.com>

On 20/04/2014, 2:45 PM, Alpesh Pandya wrote:
> I keep on trying from various networks but I still get the same error. I
> don't this this has anything to do with network or ability to download the
> package (as I can install other packages fine). This must be something in
> base R or dependencies issues (that R is not spelling out).

This is very clearly a problem with your setup, not with R:  nobody else 
is reporting it.

What you should do is download the .zip file using some other means 
(e.g. Firefox, etc.) and check whether the size comes out properly 
(4,288,694 bytes; not sure why you saw the numbers you saw).  If it 
does, then install the package from the .zip file.  If it doesn't, then 
tell your IT people to fix your system.

Duncan Murdoch

>
> I know R is geared for Mac and Windows is kind of looked down upon but I
> have no option but use windows and need this XML package running to
> complete my education. Any help on this would be appreciated.
>
>
> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya <alpeshpandya at gmail.com>wrote:
>
>> Thank you for response Rui.
>>
>> I still get the same error with this repository.
>>
>> Installing package into ???C:/Users/APandya/Documents/R/win-library/3.0???
>> (as ???lib??? is unspecified)
>> trying URL '
>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>> :
>>    cannot open the connection
>> In addition: Warning messages:
>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>    downloaded length 4276224 != reported length 4288136
>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
>> file or directory'
>>
>>
>>
>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas <ruipbarradas at sapo.pt>wrote:
>>
>>> Hello,
>>> I have package XML installed on Windows 7, R 3.0.3 and I had no problem
>>> at all. Can't you try (it worked with me)
>>>
>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
>>>
>>>   I have tried these sources (almost all US mirrors):
>>>>
>>>> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
>>>> 3.0/XML_3.98-1.1.zip
>>>> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>> contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>
>>>> I have confirmed with IT that there is no restriction on downloading this
>>>> zip file from any of these sources. Also I am getting same error when I
>>>> try
>>>> from my home network as well.
>>>>
>>>>
>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
>>>> ligges at statistik.tu-dortmund.de
>>>>
>>>>> wrote:
>>>>>
>>>>
>>>>
>>>>>
>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>>>>>
>>>>>   @Uwe I tried the same steps from office as well as home network with
>>>>>> same
>>>>>> results. Are you using windows 7 with R 3.0.3?
>>>>>>
>>>>>> I have seen same question being asked by others without any
>>>>>> resolution. Is
>>>>>> anything special about XML package? I am OK use older version of
>>>>>> package
>>>>>> but in archives there are no zip files (only gz files). Is windows
>>>>>> platform
>>>>>> not recommended for R?
>>>>>>
>>>>>>
>>>>> Right, and you can try to install these from sources.
>>>>> But I doubt you need it. You still have not told us if you tried another
>>>>> mirror to download the XML file from and what you local IT support tells
>>>>> you while your downloads are incomplete.
>>>>>
>>>>> Best,
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>
>>>>>>   wrote:
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>>>>>>>
>>>>>>>    Thank you for response Uwe. I tried multiple times by downloading
>>>>>>> the
>>>>>>>
>>>>>>>> zip
>>>>>>>> file from many sources but still the same error. This is a major road
>>>>>>>> block
>>>>>>>> for me in using R. Appreciate any help on this.
>>>>>>>>
>>>>>>>>
>>>>>>>>   Please ask your local IT staff.
>>>>>>>
>>>>>>> I get, using the same mirror:
>>>>>>>
>>>>>>>    options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>>>>>>>
>>>>>>>> install.packages("XML", lib="d:/temp")
>>>>>>>>
>>>>>>>>
>>>>>>> trying URL 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>
>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>> opened URL
>>>>>>> downloaded 4.1 Mb
>>>>>>>
>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
>>>>>>>
>>>>>>> The downloaded binary packages are in
>>>>>>>            d:\temp\RtmpqMqL8L\downloaded_packages
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Best,
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>>>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>>>
>>>>>>>>    wrote:
>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>      Works for me.
>>>>>>>>
>>>>>>>>
>>>>>>>>> Best,
>>>>>>>>> Uwe Ligges
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>>>>>>>>
>>>>>>>>>     Using install.package('XML') command produces this error:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> trying URL
>>>>>>>>>> '
>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>>> '
>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>>>>> opened URL
>>>>>>>>>> downloaded 4.1 Mb
>>>>>>>>>>
>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>>>>>>> "Type")) :
>>>>>>>>>>        cannot open the connection
>>>>>>>>>> In addition: Warning messages:
>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>>>>>>>>>        downloaded length 4276224 != reported length 4288136
>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>>>>>>>>>> file
>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>>>>>>> "Type"))
>>>>>>>>>> :
>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION', probable
>>>>>>>>>> reason
>>>>>>>>>> 'No
>>>>>>>>>> such
>>>>>>>>>> file or directory'
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip directly
>>>>>>>>>> from
>>>>>>>>>> cran
>>>>>>>>>> site. But this zip file is not a valid archive (cannot open using
>>>>>>>>>> winzip).
>>>>>>>>>> Also trying to install using this downloaded file produces the
>>>>>>>>>> following
>>>>>>>>>> error:
>>>>>>>>>>
>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
>>>>>>>>>> win-library/3.0'
>>>>>>>>>> (as 'lib' is unspecified)
>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>        error 1 in extracting from zip file
>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION', probable
>>>>>>>>>> reason
>>>>>>>>>> 'No
>>>>>>>>>> such
>>>>>>>>>> file or directory'
>>>>>>>>>> Error in install.packages : cannot open the connection
>>>>>>>>>>
>>>>>>>>>> I  downloaded this zip file from multiple sources and tried to
>>>>>>>>>> install
>>>>>>>>>> with
>>>>>>>>>> same result.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>
>> --
>> Thanks and Regards
>> Alpesh
>>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewmil at dcn.davis.CA.us  Sun Apr 20 23:32:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 20 Apr 2014 14:32:55 -0700
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
	<CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
Message-ID: <41c66d77-3b40-4314-aa2a-f5a619f53f60@email.android.com>

Hard to help you when the problem simply does not happen for others.

As for Windows being not a focus, that is not at all true. I use it regularly on Windows at work. That being said, there are thousands of packages and those each involve their own subset of R users. There are also many operating system configurations that may not all be fully tested. Blaming "R" or "Windows", or blaming us for "preventing" you from getting your education (isn't that something between you and your educational institution?) are not going to be effective strategies for problem solving.

Are you able to use other aspects of R beyond the XML package? Have you tried communicating with the maintainers of that package?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya <alpeshpandya at gmail.com> wrote:
>I keep on trying from various networks but I still get the same error.
>I
>don't this this has anything to do with network or ability to download
>the
>package (as I can install other packages fine). This must be something
>in
>base R or dependencies issues (that R is not spelling out).
>
>I know R is geared for Mac and Windows is kind of looked down upon but
>I
>have no option but use windows and need this XML package running to
>complete my education. Any help on this would be appreciated.
>
>
>On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
><alpeshpandya at gmail.com>wrote:
>
>> Thank you for response Rui.
>>
>> I still get the same error with this repository.
>>
>> Installing package into
>???C:/Users/APandya/Documents/R/win-library/3.0???
>> (as ???lib??? is unspecified)
>> trying URL '
>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type"))
>> :
>>   cannot open the connection
>> In addition: Warning messages:
>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>   downloaded length 4276224 != reported length 4288136
>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>file
>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type")) :
>>   cannot open compressed file 'XML/DESCRIPTION', probable reason 'No
>such
>> file or directory'
>>
>>
>>
>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
><ruipbarradas at sapo.pt>wrote:
>>
>>> Hello,
>>> I have package XML installed on Windows 7, R 3.0.3 and I had no
>problem
>>> at all. Can't you try (it worked with me)
>>>
>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
>>>
>>>  I have tried these sources (almost all US mirrors):
>>>>
>>>>
>http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
>>>> 3.0/XML_3.98-1.1.zip
>>>>
>http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>
>http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>> contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>
>http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>
>http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>
>>>> I have confirmed with IT that there is no restriction on
>downloading this
>>>> zip file from any of these sources. Also I am getting same error
>when I
>>>> try
>>>> from my home network as well.
>>>>
>>>>
>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
>>>> ligges at statistik.tu-dortmund.de
>>>>
>>>>> wrote:
>>>>>
>>>>
>>>>
>>>>>
>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>>>>>
>>>>>  @Uwe I tried the same steps from office as well as home network
>with
>>>>>> same
>>>>>> results. Are you using windows 7 with R 3.0.3?
>>>>>>
>>>>>> I have seen same question being asked by others without any
>>>>>> resolution. Is
>>>>>> anything special about XML package? I am OK use older version of
>>>>>> package
>>>>>> but in archives there are no zip files (only gz files). Is
>windows
>>>>>> platform
>>>>>> not recommended for R?
>>>>>>
>>>>>>
>>>>> Right, and you can try to install these from sources.
>>>>> But I doubt you need it. You still have not told us if you tried
>another
>>>>> mirror to download the XML file from and what you local IT support
>tells
>>>>> you while your downloads are incomplete.
>>>>>
>>>>> Best,
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>
>>>>>>  wrote:
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>>>>>>>
>>>>>>>   Thank you for response Uwe. I tried multiple times by
>downloading
>>>>>>> the
>>>>>>>
>>>>>>>> zip
>>>>>>>> file from many sources but still the same error. This is a
>major road
>>>>>>>> block
>>>>>>>> for me in using R. Appreciate any help on this.
>>>>>>>>
>>>>>>>>
>>>>>>>>  Please ask your local IT staff.
>>>>>>>
>>>>>>> I get, using the same mirror:
>>>>>>>
>>>>>>>  
>options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>>>>>>>
>>>>>>>> install.packages("XML", lib="d:/temp")
>>>>>>>>
>>>>>>>>
>>>>>>> trying URL 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>
>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>> opened URL
>>>>>>> downloaded 4.1 Mb
>>>>>>>
>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
>>>>>>>
>>>>>>> The downloaded binary packages are in
>>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Best,
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>>>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>>>
>>>>>>>>   wrote:
>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>     Works for me.
>>>>>>>>
>>>>>>>>
>>>>>>>>> Best,
>>>>>>>>> Uwe Ligges
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>>>>>>>>
>>>>>>>>>    Using install.package('XML') command produces this error:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> trying URL
>>>>>>>>>> '
>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>>> '
>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>>>>> opened URL
>>>>>>>>>> downloaded 4.1 Mb
>>>>>>>>>>
>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>c("Package",
>>>>>>>>>> "Type")) :
>>>>>>>>>>       cannot open the connection
>>>>>>>>>> In addition: Warning messages:
>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...)
>:
>>>>>>>>>>       downloaded length 4276224 != reported length 4288136
>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
>from zip
>>>>>>>>>> file
>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>c("Package",
>>>>>>>>>> "Type"))
>>>>>>>>>> :
>>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable
>>>>>>>>>> reason
>>>>>>>>>> 'No
>>>>>>>>>> such
>>>>>>>>>> file or directory'
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
>directly
>>>>>>>>>> from
>>>>>>>>>> cran
>>>>>>>>>> site. But this zip file is not a valid archive (cannot open
>using
>>>>>>>>>> winzip).
>>>>>>>>>> Also trying to install using this downloaded file produces
>the
>>>>>>>>>> following
>>>>>>>>>> error:
>>>>>>>>>>
>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
>>>>>>>>>> win-library/3.0'
>>>>>>>>>> (as 'lib' is unspecified)
>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>       error 1 in extracting from zip file
>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable
>>>>>>>>>> reason
>>>>>>>>>> 'No
>>>>>>>>>> such
>>>>>>>>>> file or directory'
>>>>>>>>>> Error in install.packages : cannot open the connection
>>>>>>>>>>
>>>>>>>>>> I  downloaded this zip file from multiple sources and tried
>to
>>>>>>>>>> install
>>>>>>>>>> with
>>>>>>>>>> same result.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>
>> --
>> Thanks and Regards
>> Alpesh
>>



From frtog at vestas.com  Mon Apr 21 08:01:17 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Mon, 21 Apr 2014 08:01:17 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <41c66d77-3b40-4314-aa2a-f5a619f53f60@email.android.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
	<CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
	<41c66d77-3b40-4314-aa2a-f5a619f53f60@email.android.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA54A2@DKRDSEXC016.vestas.net>

Well now, I think I have seen something similar to Alpesh.

Recently I needed the climatol package that I have used some time ago. It is not maintained anymore but I downloaded the latest version, climatol_2.2.tar.gz,  from archives (http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz ) . Trying to install that package from local file  using R-3.1.0 on Windows 8  resulted in this:

## From R Console
> utils:::menuInstallLocal()
Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable reason 'No such file or directory'
>

And yes I know where the file is located, since choose.files() is used.

However I tried the same on our linux (R-3.0.2) cluster and it succeeded:

[frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
* installing to library ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
* installing *source* package ?climatol? ...
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (climatol)
[frtog at dkrdsfshn2 ~]$ R

R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library("climatol")
> ?rosavent
> q()
Save workspace image? [y/n/c]: n
[frtog at dkrdsfshn2 ~]$


Now unzipping and untaring climatol_2.2.tar.gz I thought to examine whether I could build the package on my Windows box. Only R stuff and no foreign language as C, FORTRAN, etc. so it should be easy.

## Command shell in Windows
Microsoft Windows [Version 6.2.9200]
(c) 2012 Microsoft Corporation. All rights reserved.

C:\Users\frtog>cd Desktop

C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build climatol
* checking for file 'climatol/DESCRIPTION' ... OK
* preparing 'climatol':
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* looking to see if a 'data/datalist' file should be added
* building 'climatol_2.2.tar.gz'

Now trying to install from that local file I Still got the same error as above.



Trying to do some debugging on read.dcf() (Emacs/ESS)


R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(chmhelp=FALSE, help_type="text")
> options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient.exe', show.error.locations=TRUE)
> debug(read.dcf)
> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
debug: {
    if (is.character(file)) {
        file <- gzfile(file)
        on.exit(close(file))
    }
    if (!inherits(file, "connection"))
        stop("'file' must be a character string or connection")
    if (!all)
        return(.Internal(readDCF(file, fields, keep.white)))
    .assemble_things_into_a_data_frame <- function(tags, vals,
        nums) {
        tf <- factor(tags, levels = unique(tags))
        cnts <- table(nums, tf)
        out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
            levels(tf)))
        if (all(cnts <= 1L)) {
            out[cbind(nums, tf)] <- vals
            out <- as.data.frame(out, stringsAsFactors = FALSE)
        }
        else {
            levs <- colSums(cnts > 1L) == 0L
            if (any(levs)) {
                inds <- tf %in% levels(tf)[levs]
                out[cbind(nums[inds], tf[inds])] <- vals[inds]
            }
            out <- as.data.frame(out, stringsAsFactors = FALSE)
            for (l in levels(tf)[!levs]) {
                out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
                i <- tf == l
                out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
            }
        }
        out
    }
    on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
        add = TRUE)
    Sys.setlocale("LC_CTYPE", "C")
    lines <- readLines(file)
    ind <- grep("^[^[:blank:]][^:]*$", lines)
    if (length(ind)) {
        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
        stop(gettextf("Invalid DCF format.\nRegular lines must have a tag.\nOffending lines start with:\n%s",
            paste0("  ", lines, collapse = "\n")), domain = NA)
    }
    line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
    nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
    nums <- nums[line_is_not_empty]
    lines <- lines[line_is_not_empty]
    line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
        lines)
    if (any(line_is_escaped_blank))
        lines[line_is_escaped_blank] <- ""
    line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
    ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
    if (length(ind)) {
        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
        stop(gettextf("Invalid DCF format.\nContinuation lines must not start a record.\nOffending lines start with:\n%s",
            paste0("  ", lines, collapse = "\n")), domain = NA)
    }
    lengths <- rle(cumsum(line_has_tag))$lengths
    pos <- cumsum(lengths)
    tags <- sub(":.*", "", lines[line_has_tag])
    lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "", lines[line_has_tag])
    foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
    lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
    lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
    vals <- mapply(function(from, to) paste(lines[from:to], collapse = "\n"),
        c(1L, pos[-length(pos)] + 1L), pos)
    out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
    if (!is.null(fields))
        out <- out[fields]
    out
}
Browse[2]> str(file)
 chr "climatol_2.2.tar.gz/DESCRIPTION"
Browse[2]> head(file)
[1] "climatol_2.2.tar.gz/DESCRIPTION"
Browse[2]>
debug: if (is.character(file)) {
    file <- gzfile(file)
    on.exit(close(file))
}
Browse[2]>
debug: file <- gzfile(file)
Browse[2]>
debug: on.exit(close(file))
Browse[2]>
debug: if (!inherits(file, "connection")) stop("'file' must be a character string or connection")
Browse[2]>
debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]> str(file)
Classes 'gzfile', 'connection'  atomic [1:1] 3
  ..- attr(*, "conn_id")=<externalptr>
Browse[2]> file
                      description                             class
"climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
                             mode                              text
                             "rb"                            "text"
                           opened                          can read
                         "closed"                             "yes"
                        can write
                            "yes"
Browse[2]>
debug: return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]>
Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open the connection
In addition: Warning message:
In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable reason 'No such file or directory'
>

Well coming to debug: if (!all) return(.Internal(readDCF(file, fields, keep.white))) I loose control and R returns to prompt with an error.

Hopefully one of you can replicate this. If not then it must have something with Windows OS to do. But what?



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender.

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Jeff Newmiller
> Sent: 20. april 2014 23:33
> To: Alpesh Pandya; Rui Barradas
> Cc: r-help at r-project.org; Uwe Ligges
> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
>
> Hard to help you when the problem simply does not happen for others.
>
> As for Windows being not a focus, that is not at all true. I use it regularly on
> Windows at work. That being said, there are thousands of packages and
> those each involve their own subset of R users. There are also many
> operating system configurations that may not all be fully tested. Blaming "R"
> or "Windows", or blaming us for "preventing" you from getting your
> education (isn't that something between you and your educational
> institution?) are not going to be effective strategies for problem solving.
>
> Are you able to use other aspects of R beyond the XML package? Have you
> tried communicating with the maintainers of that package?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> <alpeshpandya at gmail.com> wrote:
> >I keep on trying from various networks but I still get the same error.
> >I
> >don't this this has anything to do with network or ability to download
> >the
> >package (as I can install other packages fine). This must be something
> >in
> >base R or dependencies issues (that R is not spelling out).
> >
> >I know R is geared for Mac and Windows is kind of looked down upon but
> >I
> >have no option but use windows and need this XML package running to
> >complete my education. Any help on this would be appreciated.
> >
> >
> >On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> ><alpeshpandya at gmail.com>wrote:
> >
> >> Thank you for response Rui.
> >>
> >> I still get the same error with this repository.
> >>
> >> Installing package into
> >???C:/Users/APandya/Documents/R/win-library/3.0???
> >> (as ???lib??? is unspecified)
> >> trying URL '
> >> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> opened URL
> >> downloaded 4.1 Mb
> >>
> >> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type"))
> >> :
> >>   cannot open the connection
> >> In addition: Warning messages:
> >> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >>   downloaded length 4276224 != reported length 4288136
> >> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >file
> >> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >>   cannot open compressed file 'XML/DESCRIPTION', probable reason 'No
> >such
> >> file or directory'
> >>
> >>
> >>
> >> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> ><ruipbarradas at sapo.pt>wrote:
> >>
> >>> Hello,
> >>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >problem
> >>> at all. Can't you try (it worked with me)
> >>>
> >>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >>>
> >>>  I have tried these sources (almost all US mirrors):
> >>>>
> >>>>
> >http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >>>> 3.0/XML_3.98-1.1.zip
> >>>>
> >http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>
> >http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>> contrib/3.0/XML_3.98-1.1.zip
> >>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>
> >http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>
> >http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> 1.1.zip
> >>>>
> >>>> I have confirmed with IT that there is no restriction on
> >downloading this
> >>>> zip file from any of these sources. Also I am getting same error
> >when I
> >>>> try
> >>>> from my home network as well.
> >>>>
> >>>>
> >>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >>>> ligges at statistik.tu-dortmund.de
> >>>>
> >>>>> wrote:
> >>>>>
> >>>>
> >>>>
> >>>>>
> >>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >>>>>
> >>>>>  @Uwe I tried the same steps from office as well as home network
> >with
> >>>>>> same
> >>>>>> results. Are you using windows 7 with R 3.0.3?
> >>>>>>
> >>>>>> I have seen same question being asked by others without any
> >>>>>> resolution. Is
> >>>>>> anything special about XML package? I am OK use older version of
> >>>>>> package
> >>>>>> but in archives there are no zip files (only gz files). Is
> >windows
> >>>>>> platform
> >>>>>> not recommended for R?
> >>>>>>
> >>>>>>
> >>>>> Right, and you can try to install these from sources.
> >>>>> But I doubt you need it. You still have not told us if you tried
> >another
> >>>>> mirror to download the XML file from and what you local IT support
> >tells
> >>>>> you while your downloads are incomplete.
> >>>>>
> >>>>> Best,
> >>>>> Uwe Ligges
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>
> >>>>>>  wrote:
> >>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>>
> >>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >>>>>>>
> >>>>>>>   Thank you for response Uwe. I tried multiple times by
> >downloading
> >>>>>>> the
> >>>>>>>
> >>>>>>>> zip
> >>>>>>>> file from many sources but still the same error. This is a
> >major road
> >>>>>>>> block
> >>>>>>>> for me in using R. Appreciate any help on this.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>  Please ask your local IT staff.
> >>>>>>>
> >>>>>>> I get, using the same mirror:
> >>>>>>>
> >>>>>>>
> >options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >>>>>>>
> >>>>>>>> install.packages("XML", lib="d:/temp")
> >>>>>>>>
> >>>>>>>>
> >>>>>>> trying URL 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>
> >>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>>> opened URL
> >>>>>>> downloaded 4.1 Mb
> >>>>>>>
> >>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >>>>>>>
> >>>>>>> The downloaded binary packages are in
> >>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> Best,
> >>>>>>> Uwe Ligges
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>
> >>>>>>>>   wrote:
> >>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>     Works for me.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>> Best,
> >>>>>>>>> Uwe Ligges
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >>>>>>>>>
> >>>>>>>>>    Using install.package('XML') command produces this error:
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>> trying URL
> >>>>>>>>>> '
> >>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>>> '
> >>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>>>>>> opened URL
> >>>>>>>>>> downloaded 4.1 Mb
> >>>>>>>>>>
> >>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >c("Package",
> >>>>>>>>>> "Type")) :
> >>>>>>>>>>       cannot open the connection
> >>>>>>>>>> In addition: Warning messages:
> >>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...)
> >:
> >>>>>>>>>>       downloaded length 4276224 != reported length 4288136
> >>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >from zip
> >>>>>>>>>> file
> >>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >c("Package",
> >>>>>>>>>> "Type"))
> >>>>>>>>>> :
> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable
> >>>>>>>>>> reason
> >>>>>>>>>> 'No
> >>>>>>>>>> such
> >>>>>>>>>> file or directory'
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >directly
> >>>>>>>>>> from
> >>>>>>>>>> cran
> >>>>>>>>>> site. But this zip file is not a valid archive (cannot open
> >using
> >>>>>>>>>> winzip).
> >>>>>>>>>> Also trying to install using this downloaded file produces
> >the
> >>>>>>>>>> following
> >>>>>>>>>> error:
> >>>>>>>>>>
> >>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >>>>>>>>>> win-library/3.0'
> >>>>>>>>>> (as 'lib' is unspecified)
> >>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>       error 1 in extracting from zip file
> >>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION', probable
> >>>>>>>>>> reason
> >>>>>>>>>> 'No
> >>>>>>>>>> such
> >>>>>>>>>> file or directory'
> >>>>>>>>>> Error in install.packages : cannot open the connection
> >>>>>>>>>>
> >>>>>>>>>> I  downloaded this zip file from multiple sources and tried
> >to
> >>>>>>>>>> install
> >>>>>>>>>> with
> >>>>>>>>>> same result.
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>
> >>>>>>
> >>>>
> >>>>
> >>
> >>
> >> --
> >> Thanks and Regards
> >> Alpesh
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From spencer.graves at structuremonitoring.com  Mon Apr 21 09:30:59 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 21 Apr 2014 00:30:59 -0700
Subject: [R] reading & understanding SVG?
Message-ID: <5354C933.4050808@structuremonitoring.com>

Hello:


       What would you suggest I use to read and manipulate an SVG file?


       I'd like to extract components of an svg file.  I see it's XML, 
but I have very little experience with either SVG or XML.  I've tried 
GIMP and findFn{sos} without finding a clear suggestion of where to start.


       Thanks,
       Spencer



From jdnewmil at dcn.davis.CA.us  Mon Apr 21 09:43:53 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 21 Apr 2014 00:43:53 -0700
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA54A2@DKRDSEXC016.vestas.net>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
	<CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
	<41c66d77-3b40-4314-aa2a-f5a619f53f60@email.android.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA54A2@DKRDSEXC016.vestas.net>
Message-ID: <453de45e-5e96-4289-af87-599a45cb4b31@email.android.com>

Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
>Well now, I think I have seen something similar to Alpesh.
>
>Recently I needed the climatol package that I have used some time ago.
>It is not maintained anymore but I downloaded the latest version,
>climatol_2.2.tar.gz,  from archives
>(http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
>) . Trying to install that package from local file  using R-3.1.0 on
>Windows 8  resulted in this:
>
>## From R Console
>> utils:::menuInstallLocal()
>Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type")) :
>  cannot open the connection
>In addition: Warning messages:
>1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>file
>2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>:
>cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
>reason 'No such file or directory'
>>
>
>And yes I know where the file is located, since choose.files() is used.
>
>However I tried the same on our linux (R-3.0.2) cluster and it
>succeeded:
>
>[frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
>* installing to library
>?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
>* installing *source* package ?climatol? ...
>** R
>** data
>** inst
>** preparing package for lazy loading
>** help
>*** installing help indices
>** building package indices
>** installing vignettes
>** testing if installed package can be loaded
>* DONE (climatol)
>[frtog at dkrdsfshn2 ~]$ R
>
>R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>Copyright (C) 2013 The R Foundation for Statistical Computing
>Platform: x86_64-unknown-linux-gnu (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>> library("climatol")
>> ?rosavent
>> q()
>Save workspace image? [y/n/c]: n
>[frtog at dkrdsfshn2 ~]$
>
>
>Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
>whether I could build the package on my Windows box. Only R stuff and
>no foreign language as C, FORTRAN, etc. so it should be easy.
>
>## Command shell in Windows
>Microsoft Windows [Version 6.2.9200]
>(c) 2012 Microsoft Corporation. All rights reserved.
>
>C:\Users\frtog>cd Desktop
>
>C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
>climatol
>* checking for file 'climatol/DESCRIPTION' ... OK
>* preparing 'climatol':
>* checking DESCRIPTION meta-information ... OK
>* checking for LF line-endings in source and make files
>* checking for empty or unneeded directories
>* looking to see if a 'data/datalist' file should be added
>* building 'climatol_2.2.tar.gz'
>
>Now trying to install from that local file I Still got the same error
>as above.
>
>
>
>Trying to do some debugging on read.dcf() (Emacs/ESS)
>
>
>R version 3.1.0 (2014-04-10) -- "Spring Dance"
>Copyright (C) 2014 The R Foundation for Statistical Computing
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>> > options(chmhelp=FALSE, help_type="text")
>> options(STERM='iESS', str.dendrogram.last="'",
>editor='emacsclient.exe', show.error.locations=TRUE)
>> debug(read.dcf)
>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
>debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type"))
>debug: {
>    if (is.character(file)) {
>        file <- gzfile(file)
>        on.exit(close(file))
>    }
>    if (!inherits(file, "connection"))
>        stop("'file' must be a character string or connection")
>    if (!all)
>        return(.Internal(readDCF(file, fields, keep.white)))
>    .assemble_things_into_a_data_frame <- function(tags, vals,
>        nums) {
>        tf <- factor(tags, levels = unique(tags))
>        cnts <- table(nums, tf)
>     out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
>            levels(tf)))
>        if (all(cnts <= 1L)) {
>            out[cbind(nums, tf)] <- vals
>            out <- as.data.frame(out, stringsAsFactors = FALSE)
>        }
>        else {
>            levs <- colSums(cnts > 1L) == 0L
>            if (any(levs)) {
>                inds <- tf %in% levels(tf)[levs]
>                out[cbind(nums[inds], tf[inds])] <- vals[inds]
>            }
>            out <- as.data.frame(out, stringsAsFactors = FALSE)
>            for (l in levels(tf)[!levs]) {
>                out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
>                i <- tf == l
>                out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
>            }
>        }
>        out
>    }
>    on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
>        add = TRUE)
>    Sys.setlocale("LC_CTYPE", "C")
>    lines <- readLines(file)
>    ind <- grep("^[^[:blank:]][^:]*$", lines)
>    if (length(ind)) {
>        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
>stop(gettextf("Invalid DCF format.\nRegular lines must have a
>tag.\nOffending lines start with:\n%s",
>            paste0("  ", lines, collapse = "\n")), domain = NA)
>    }
>    line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
>    nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
>    nums <- nums[line_is_not_empty]
>    lines <- lines[line_is_not_empty]
>    line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
>        lines)
>    if (any(line_is_escaped_blank))
>        lines[line_is_escaped_blank] <- ""
>    line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
>    ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
>    if (length(ind)) {
>        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
>stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
>record.\nOffending lines start with:\n%s",
>            paste0("  ", lines, collapse = "\n")), domain = NA)
>    }
>    lengths <- rle(cumsum(line_has_tag))$lengths
>    pos <- cumsum(lengths)
>    tags <- sub(":.*", "", lines[line_has_tag])
>lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
>lines[line_has_tag])
>    foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
>    lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
>    lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
>vals <- mapply(function(from, to) paste(lines[from:to], collapse =
>"\n"),
>        c(1L, pos[-length(pos)] + 1L), pos)
>    out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
>    if (!is.null(fields))
>        out <- out[fields]
>    out
>}
>Browse[2]> str(file)
> chr "climatol_2.2.tar.gz/DESCRIPTION"
>Browse[2]> head(file)
>[1] "climatol_2.2.tar.gz/DESCRIPTION"
>Browse[2]>
>debug: if (is.character(file)) {
>    file <- gzfile(file)
>    on.exit(close(file))
>}
>Browse[2]>
>debug: file <- gzfile(file)
>Browse[2]>
>debug: on.exit(close(file))
>Browse[2]>
>debug: if (!inherits(file, "connection")) stop("'file' must be a
>character string or connection")
>Browse[2]>
>debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
>Browse[2]> str(file)
>Classes 'gzfile', 'connection'  atomic [1:1] 3
>  ..- attr(*, "conn_id")=<externalptr>
>Browse[2]> file
>                      description                             class
>"climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
>                             mode                              text
>                             "rb"                            "text"
>                           opened                          can read
>                         "closed"                             "yes"
>                        can write
>                            "yes"
>Browse[2]>
>debug: return(.Internal(readDCF(file, fields, keep.white)))
>Browse[2]>
>Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type")) :
>  cannot open the connection
>In addition: Warning message:
>In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
>reason 'No such file or directory'
>>
>
>Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
>keep.white))) I loose control and R returns to prompt with an error.
>
>Hopefully one of you can replicate this. If not then it must have
>something with Windows OS to do. But what?
>
>
>
>Yours sincerely / Med venlig hilsen
>
>
>Frede Aakmann T?gersen
>Specialist, M.Sc., Ph.D.
>Plant Performance & Modeling
>
>Technology & Service Solutions
>T +45 9730 5135
>M +45 2547 6050
>frtog at vestas.com
>http://www.vestas.com
>
>Company reg. name: Vestas Wind Systems A/S
>This e-mail is subject to our e-mail disclaimer statement.
>Please refer to www.vestas.com/legal/notice
>If you have received this e-mail in error please contact the sender.
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org]
>> On Behalf Of Jeff Newmiller
>> Sent: 20. april 2014 23:33
>> To: Alpesh Pandya; Rui Barradas
>> Cc: r-help at r-project.org; Uwe Ligges
>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
>>
>> Hard to help you when the problem simply does not happen for others.
>>
>> As for Windows being not a focus, that is not at all true. I use it
>regularly on
>> Windows at work. That being said, there are thousands of packages and
>> those each involve their own subset of R users. There are also many
>> operating system configurations that may not all be fully tested.
>Blaming "R"
>> or "Windows", or blaming us for "preventing" you from getting your
>> education (isn't that something between you and your educational
>> institution?) are not going to be effective strategies for problem
>solving.
>>
>> Are you able to use other aspects of R beyond the XML package? Have
>you
>> tried communicating with the maintainers of that package?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
>> <alpeshpandya at gmail.com> wrote:
>> >I keep on trying from various networks but I still get the same
>error.
>> >I
>> >don't this this has anything to do with network or ability to
>download
>> >the
>> >package (as I can install other packages fine). This must be
>something
>> >in
>> >base R or dependencies issues (that R is not spelling out).
>> >
>> >I know R is geared for Mac and Windows is kind of looked down upon
>but
>> >I
>> >have no option but use windows and need this XML package running to
>> >complete my education. Any help on this would be appreciated.
>> >
>> >
>> >On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
>> ><alpeshpandya at gmail.com>wrote:
>> >
>> >> Thank you for response Rui.
>> >>
>> >> I still get the same error with this repository.
>> >>
>> >> Installing package into
>> >???C:/Users/APandya/Documents/R/win-library/3.0???
>> >> (as ???lib??? is unspecified)
>> >> trying URL '
>> >> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> >> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>> >> opened URL
>> >> downloaded 4.1 Mb
>> >>
>> >> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>> >"Type"))
>> >> :
>> >>   cannot open the connection
>> >> In addition: Warning messages:
>> >> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>> >>   downloaded length 4276224 != reported length 4288136
>> >> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
>zip
>> >file
>> >> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>> >"Type")) :
>> >>   cannot open compressed file 'XML/DESCRIPTION', probable reason
>'No
>> >such
>> >> file or directory'
>> >>
>> >>
>> >>
>> >> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
>> ><ruipbarradas at sapo.pt>wrote:
>> >>
>> >>> Hello,
>> >>> I have package XML installed on Windows 7, R 3.0.3 and I had no
>> >problem
>> >>> at all. Can't you try (it worked with me)
>> >>>
>> >>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
>> >>>
>> >>> Hope this helps,
>> >>>
>> >>> Rui Barradas
>> >>>
>> >>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
>> >>>
>> >>>  I have tried these sources (almost all US mirrors):
>> >>>>
>> >>>>
>>
>>http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>>
>http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
>> >>>> 3.0/XML_3.98-1.1.zip
>> >>>>
>> >http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>>
>>
>>http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>> >>>> contrib/3.0/XML_3.98-1.1.zip
>> >>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>>
>>
>>http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>> >>>>
>> >http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
>> 1.1.zip
>> >>>>
>> >>>> I have confirmed with IT that there is no restriction on
>> >downloading this
>> >>>> zip file from any of these sources. Also I am getting same error
>> >when I
>> >>>> try
>> >>>> from my home network as well.
>> >>>>
>> >>>>
>> >>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
>> >>>> ligges at statistik.tu-dortmund.de
>> >>>>
>> >>>>> wrote:
>> >>>>>
>> >>>>
>> >>>>
>> >>>>>
>> >>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>> >>>>>
>> >>>>>  @Uwe I tried the same steps from office as well as home
>network
>> >with
>> >>>>>> same
>> >>>>>> results. Are you using windows 7 with R 3.0.3?
>> >>>>>>
>> >>>>>> I have seen same question being asked by others without any
>> >>>>>> resolution. Is
>> >>>>>> anything special about XML package? I am OK use older version
>of
>> >>>>>> package
>> >>>>>> but in archives there are no zip files (only gz files). Is
>> >windows
>> >>>>>> platform
>> >>>>>> not recommended for R?
>> >>>>>>
>> >>>>>>
>> >>>>> Right, and you can try to install these from sources.
>> >>>>> But I doubt you need it. You still have not told us if you
>tried
>> >another
>> >>>>> mirror to download the XML file from and what you local IT
>support
>> >tells
>> >>>>> you while your downloads are incomplete.
>> >>>>>
>> >>>>> Best,
>> >>>>> Uwe Ligges
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>> >>>>>> ligges at statistik.tu-dortmund.de
>> >>>>>>
>> >>>>>>  wrote:
>> >>>>>>>
>> >>>>>>>
>> >>>>>>
>> >>>>>>
>> >>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>> >>>>>>>
>> >>>>>>>   Thank you for response Uwe. I tried multiple times by
>> >downloading
>> >>>>>>> the
>> >>>>>>>
>> >>>>>>>> zip
>> >>>>>>>> file from many sources but still the same error. This is a
>> >major road
>> >>>>>>>> block
>> >>>>>>>> for me in using R. Appreciate any help on this.
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>>  Please ask your local IT staff.
>> >>>>>>>
>> >>>>>>> I get, using the same mirror:
>> >>>>>>>
>> >>>>>>>
>> >options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>> >>>>>>>
>> >>>>>>>> install.packages("XML", lib="d:/temp")
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>> trying URL
>'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>> >>>>>>>
>> >>>>>>> contrib/3.0/XML_3.98-1.1.zip'
>> >>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>> >>>>>>> opened URL
>> >>>>>>> downloaded 4.1 Mb
>> >>>>>>>
>> >>>>>>> package 'XML' successfully unpacked and MD5 sums checked
>> >>>>>>>
>> >>>>>>> The downloaded binary packages are in
>> >>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> Best,
>> >>>>>>> Uwe Ligges
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>> >>>>>>>> ligges at statistik.tu-dortmund.de
>> >>>>>>>>
>> >>>>>>>>   wrote:
>> >>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>     Works for me.
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>>> Best,
>> >>>>>>>>> Uwe Ligges
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>> >>>>>>>>>
>> >>>>>>>>>    Using install.package('XML') command produces this
>error:
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>> trying URL
>> >>>>>>>>>> '
>> >>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>> >>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>> >>>>>>>>>> '
>> >>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
>Mb)
>> >>>>>>>>>> opened URL
>> >>>>>>>>>> downloaded 4.1 Mb
>> >>>>>>>>>>
>> >>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>> >c("Package",
>> >>>>>>>>>> "Type")) :
>> >>>>>>>>>>       cannot open the connection
>> >>>>>>>>>> In addition: Warning messages:
>> >>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
>...)
>> >:
>> >>>>>>>>>>       downloaded length 4276224 != reported length 4288136
>> >>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
>> >from zip
>> >>>>>>>>>> file
>> >>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>> >c("Package",
>> >>>>>>>>>> "Type"))
>> >>>>>>>>>> :
>> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
>probable
>> >>>>>>>>>> reason
>> >>>>>>>>>> 'No
>> >>>>>>>>>> such
>> >>>>>>>>>> file or directory'
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
>> >directly
>> >>>>>>>>>> from
>> >>>>>>>>>> cran
>> >>>>>>>>>> site. But this zip file is not a valid archive (cannot
>open
>> >using
>> >>>>>>>>>> winzip).
>> >>>>>>>>>> Also trying to install using this downloaded file produces
>> >the
>> >>>>>>>>>> following
>> >>>>>>>>>> error:
>> >>>>>>>>>>
>> >>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
>> >>>>>>>>>> win-library/3.0'
>> >>>>>>>>>> (as 'lib' is unspecified)
>> >>>>>>>>>> Warning in install.packages :
>> >>>>>>>>>>       error 1 in extracting from zip file
>> >>>>>>>>>> Warning in install.packages :
>> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
>probable
>> >>>>>>>>>> reason
>> >>>>>>>>>> 'No
>> >>>>>>>>>> such
>> >>>>>>>>>> file or directory'
>> >>>>>>>>>> Error in install.packages : cannot open the connection
>> >>>>>>>>>>
>> >>>>>>>>>> I  downloaded this zip file from multiple sources and
>tried
>> >to
>> >>>>>>>>>> install
>> >>>>>>>>>> with
>> >>>>>>>>>> same result.
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>
>> >>>>>>
>> >>>>
>> >>>>
>> >>
>> >>
>> >> --
>> >> Thanks and Regards
>> >> Alpesh
>> >>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From aguitatierra at hotmail.com  Mon Apr 21 10:43:24 2014
From: aguitatierra at hotmail.com (Beatriz R. Gonzalez Dominguez)
Date: Mon, 21 Apr 2014 10:43:24 +0200
Subject: [R] for loop to list files
Message-ID: <BLU0-SMTP4704C9A906CEC9520A80FA7D95E0@phx.gbl>

Dear all,

I'm trying to create a loop to select a series of files into my computer 
but I haven't been successful until now. I've looked into different 
possibilities but none has worked. I'd appretiate if you could help me 
by providing me with some ideas.

Basically what  I'd like to do is to create a character string variable 
[1:5], same as the one that could be obtained with 'list.files', but 
using a 'for' loop.

This is one of the things I've tried but obviously doesn't yield the 
results I would like:

for(i in 1976:1981){
   PE.files_01_7681 <- paste("val_mapped_petpe_", i, "01.txt", sep="")
  paste(PE.files_01_7681[i])
}

Many thanks!



From jorgeivanvelez at gmail.com  Mon Apr 21 10:46:51 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Mon, 21 Apr 2014 18:46:51 +1000
Subject: [R] for loop to list files
In-Reply-To: <BLU0-SMTP4704C9A906CEC9520A80FA7D95E0@phx.gbl>
References: <BLU0-SMTP4704C9A906CEC9520A80FA7D95E0@phx.gbl>
Message-ID: <CAKL8G3H0CpB=-Y+xoMnTfruEaC=OYSc=VNM0J4e3BPKvFLf0sQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/a496cf1b/attachment-0001.pl>

From aguitatierra at hotmail.com  Mon Apr 21 10:55:38 2014
From: aguitatierra at hotmail.com (Beatriz R. Gonzalez Dominguez)
Date: Mon, 21 Apr 2014 10:55:38 +0200
Subject: [R] for loop to list files
In-Reply-To: <CAKL8G3H0CpB=-Y+xoMnTfruEaC=OYSc=VNM0J4e3BPKvFLf0sQ@mail.gmail.com>
References: <BLU0-SMTP4704C9A906CEC9520A80FA7D95E0@phx.gbl>
	<CAKL8G3H0CpB=-Y+xoMnTfruEaC=OYSc=VNM0J4e3BPKvFLf0sQ@mail.gmail.com>
Message-ID: <BLU0-SMTP32709C0C3F94AF3A91A14F0D95E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/1eb40110/attachment-0001.pl>

From frtog at vestas.com  Mon Apr 21 11:38:29 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Mon, 21 Apr 2014 11:38:29 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
Message-ID: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/ae5a2e5a/attachment-0001.pl>

From info at aghmed.fsnet.co.uk  Mon Apr 21 12:13:55 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 21 Apr 2014 11:13:55 +0100
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <453de45e-5e96-4289-af87-599a45cb4b31@email.android.com>
References: <CAEv=oxPiOM11SYJQhiff2QCRDRBHEa=VjNYrP=rvgysQma3uyw@mail.gmail.com>
	<5348725B.7070404@statistik.tu-dortmund.de>
	<CAEv=oxPeE1CiTfp3ct7aLEA5Hf_eqA=0_LmMjGsAoc_32ash-w@mail.gmail.com>
	<5349CABA.7000807@statistik.tu-dortmund.de>
	<CAEv=oxO4LGeymj5-aGxTCEDtckeVoyyhh3Wi=w0VZ4SpHaW-ag@mail.gmail.com>
	<534A9525.90209@statistik.tu-dortmund.de>
	<CAEv=oxO-i16F5CoQDz9RCXwxw51QamPm6_CfoVippi+q0SZH+w@mail.gmail.com>
	<534C261F.8060608@sapo.pt>
	<CAEv=oxP4qKSsvkJMqoAr2TYYH3SF-gcZ==81C55ffGkdam6XHg@mail.gmail.com>
	<CAEv=oxPE2ksTPtiVKbtd0ADf=fELWxUtcD+wfOPh8UHfsHZ+XQ@mail.gmail.com>
	<41c66d77-3b40-4314-aa2a-f5a619f53f60@email.android.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA54A2@DKRDSEXC016.vestas.net>
	<453de45e-5e96-4289-af87-599a45cb4b31@email.android.com>
Message-ID: <Zen-1WcBEj-0000oP-JV@smarthost01b.mail.zen.net.uk>

At 08:43 21/04/2014, Jeff Newmiller wrote:
>Frede... Windows uses zip files (binary, aka 
>pre-compiled format) for packages by default, 
>because most installations don't have the 
>development tools installed. You need to setup 
>RTools and use the "source" option to 
>install_package in order to handle the tar.gz 
>package file, or download and install the zip file instead.

Jeff, Frede did say that there is no C or Fortran 
in the package which suggests that it should be 
possible to install it under Windows without 
installing RTools first if I understand correctly.

>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>---------------------------------------------------------------------------
>Sent from my phone. Please excuse my brevity.
>
>On April 20, 2014 11:01:17 PM PDT, "Frede 
>Aakmann T??gersen" <frtog at vestas.com> wrote:
> >Well now, I think I have seen something similar to Alpesh.
> >
> >Recently I needed the climatol package that I have used some time ago.
> >It is not maintained anymore but I downloaded the latest version,
> >climatol_2.2.tar.gz,  from archives
> >(http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> >) . Trying to install that package from local file  using R-3.1.0 on
> >Windows 8  resulted in this:
> >
> >## From R Console
> >> utils:::menuInstallLocal()
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning messages:
> >1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >file
> >2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> >:
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >And yes I know where the file is located, since choose.files() is used.
> >
> >However I tried the same on our linux (R-3.0.2) cluster and it
> >succeeded:
> >
> >[frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> >* installing to library
> >?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> >* installing *source* package ?climatol? ...
> >** R
> >** data
> >** inst
> >** preparing package for lazy loading
> >** help
> >*** installing help indices
> >** building package indices
> >** installing vignettes
> >** testing if installed package can be loaded
> >* DONE (climatol)
> >[frtog at dkrdsfshn2 ~]$ R
> >
> >R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> >Copyright (C) 2013 The R Foundation for Statistical Computing
> >Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> library("climatol")
> >> ?rosavent
> >> q()
> >Save workspace image? [y/n/c]: n
> >[frtog at dkrdsfshn2 ~]$
> >
> >
> >Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> >whether I could build the package on my Windows box. Only R stuff and
> >no foreign language as C, FORTRAN, etc. so it should be easy.
> >
> >## Command shell in Windows
> >Microsoft Windows [Version 6.2.9200]
> >(c) 2012 Microsoft Corporation. All rights reserved.
> >
> >C:\Users\frtog>cd Desktop
> >
> >C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> >climatol
> >* checking for file 'climatol/DESCRIPTION' ... OK
> >* preparing 'climatol':
> >* checking DESCRIPTION meta-information ... OK
> >* checking for LF line-endings in source and make files
> >* checking for empty or unneeded directories
> >* looking to see if a 'data/datalist' file should be added
> >* building 'climatol_2.2.tar.gz'
> >
> >Now trying to install from that local file I Still got the same error
> >as above.
> >
> >
> >
> >Trying to do some debugging on read.dcf() (Emacs/ESS)
> >
> >
> >R version 3.1.0 (2014-04-10) -- "Spring Dance"
> >Copyright (C) 2014 The R Foundation for Statistical Computing
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> > options(chmhelp=FALSE, help_type="text")
> >> options(STERM='iESS', str.dendrogram.last="'",
> >editor='emacsclient.exe', show.error.locations=TRUE)
> >> debug(read.dcf)
> >> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> >debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type"))
> >debug: {
> >    if (is.character(file)) {
> >        file <- gzfile(file)
> >        on.exit(close(file))
> >    }
> >    if (!inherits(file, "connection"))
> >        stop("'file' must be a character string or connection")
> >    if (!all)
> >        return(.Internal(readDCF(file, fields, keep.white)))
> >    .assemble_things_into_a_data_frame <- function(tags, vals,
> >        nums) {
> >        tf <- factor(tags, levels = unique(tags))
> >        cnts <- table(nums, tf)
> >     out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> >            levels(tf)))
> >        if (all(cnts <= 1L)) {
> >            out[cbind(nums, tf)] <- vals
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >        }
> >        else {
> >            levs <- colSums(cnts > 1L) == 0L
> >            if (any(levs)) {
> >                inds <- tf %in% levels(tf)[levs]
> >                out[cbind(nums[inds], tf[inds])] <- vals[inds]
> >            }
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >            for (l in levels(tf)[!levs]) {
> >                out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> >                i <- tf == l
> >                out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> >            }
> >        }
> >        out
> >    }
> >    on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> >        add = TRUE)
> >    Sys.setlocale("LC_CTYPE", "C")
> >    lines <- readLines(file)
> >    ind <- grep("^[^[:blank:]][^:]*$", lines)
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nRegular lines must have a
> >tag.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> >    nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> >    nums <- nums[line_is_not_empty]
> >    lines <- lines[line_is_not_empty]
> >    line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> >        lines)
> >    if (any(line_is_escaped_blank))
> >        lines[line_is_escaped_blank] <- ""
> >    line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> >    ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> >record.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    lengths <- rle(cumsum(line_has_tag))$lengths
> >    pos <- cumsum(lengths)
> >    tags <- sub(":.*", "", lines[line_has_tag])
> >lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> >lines[line_has_tag])
> >    foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> >    lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> >    lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> >vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> >"\n"),
> >        c(1L, pos[-length(pos)] + 1L), pos)
> >    out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> >    if (!is.null(fields))
> >        out <- out[fields]
> >    out
> >}
> >Browse[2]> str(file)
> > chr "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]> head(file)
> >[1] "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]>
> >debug: if (is.character(file)) {
> >    file <- gzfile(file)
> >    on.exit(close(file))
> >}
> >Browse[2]>
> >debug: file <- gzfile(file)
> >Browse[2]>
> >debug: on.exit(close(file))
> >Browse[2]>
> >debug: if (!inherits(file, "connection")) stop("'file' must be a
> >character string or connection")
> >Browse[2]>
> >debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]> str(file)
> >Classes 'gzfile', 'connection'  atomic [1:1] 3
> >  ..- attr(*, "conn_id")=<externalptr>
> >Browse[2]> file
> >                      description                             class
> >"climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> >                             mode                              text
> >                             "rb"                            "text"
> >                           opened                          can read
> >                         "closed"                             "yes"
> >                        can write
> >                            "yes"
> >Browse[2]>
> >debug: return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]>
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning message:
> >In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> >keep.white))) I loose control and R returns to prompt with an error.
> >
> >Hopefully one of you can replicate this. If not then it must have
> >something with Windows OS to do. But what?
> >
> >
> >
> >Yours sincerely / Med venlig hilsen
> >
> >
> >Frede Aakmann T??gersen
> >Specialist, M.Sc., Ph.D.
> >Plant Performance & Modeling
> >
> >Technology & Service Solutions
> >T +45 9730 5135
> >M +45 2547 6050
> >frtog at vestas.com
> >http://www.vestas.com
> >
> >Company reg. name: Vestas Wind Systems A/S
> >This e-mail is subject to our e-mail disclaimer statement.
> >Please refer to www.vestas.com/legal/notice
> >If you have received this e-mail in error please contact the sender.
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >[mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Jeff Newmiller
> >> Sent: 20. april 2014 23:33
> >> To: Alpesh Pandya; Rui Barradas
> >> Cc: r-help at r-project.org; Uwe Ligges
> >> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>
> >> Hard to help you when the problem simply does not happen for others.
> >>
> >> As for Windows being not a focus, that is not at all true. I use it
> >regularly on
> >> Windows at work. That being said, there are thousands of packages and
> >> those each involve their own subset of R users. There are also many
> >> operating system configurations that may not all be fully tested.
> >Blaming "R"
> >> or "Windows", or blaming us for "preventing" you from getting your
> >> education (isn't that something between you and your educational
> >> institution?) are not going to be effective strategies for problem
> >solving.
> >>
> >> Are you able to use other aspects of R beyond the XML package? Have
> >you
> >> tried communicating with the maintainers of that package?
> >>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> >> <alpeshpandya at gmail.com> wrote:
> >> >I keep on trying from various networks but I still get the same
> >error.
> >> >I
> >> >don't this this has anything to do with network or ability to
> >download
> >> >the
> >> >package (as I can install other packages fine). This must be
> >something
> >> >in
> >> >base R or dependencies issues (that R is not spelling out).
> >> >
> >> >I know R is geared for Mac and Windows is kind of looked down upon
> >but
> >> >I
> >> >have no option but use windows and need this XML package running to
> >> >complete my education. Any help on this would be appreciated.
> >> >
> >> >
> >> >On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> >> ><alpeshpandya at gmail.com>wrote:
> >> >
> >> >> Thank you for response Rui.
> >> >>
> >> >> I still get the same error with this repository.
> >> >>
> >> >> Installing package into
> >> >?????????C:/Users/APandya/Documents/R/win-library/3.0?????????
> >> >> (as ?????????lib????????? is unspecified)
> >> >> trying URL '
> >> >> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> >> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >> opened URL
> >> >> downloaded 4.1 Mb
> >> >>
> >> >> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type"))
> >> >> :
> >> >>   cannot open the connection
> >> >> In addition: Warning messages:
> >> >> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >> >>   downloaded length 4276224 != reported length 4288136
> >> >> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> >zip
> >> >file
> >> >> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type")) :
> >> >>   cannot open compressed file 'XML/DESCRIPTION', probable reason
> >'No
> >> >such
> >> >> file or directory'
> >> >>
> >> >>
> >> >>
> >> >> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> >> ><ruipbarradas at sapo.pt>wrote:
> >> >>
> >> >>> Hello,
> >> >>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >> >problem
> >> >>> at all. Can't you try (it worked with me)
> >> >>>
> >> >>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >> >>>
> >> >>> Hope this helps,
> >> >>>
> >> >>> Rui Barradas
> >> >>>
> >> >>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >> >>>
> >> >>>  I have tried these sources (almost all US mirrors):
> >> >>>>
> >> >>>>
> >>
> >>http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >> >>>> 3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> >> 1.1.zip
> >> >>>>
> >> >>>> I have confirmed with IT that there is no restriction on
> >> >downloading this
> >> >>>> zip file from any of these sources. Also I am getting same error
> >> >when I
> >> >>>> try
> >> >>>> from my home network as well.
> >> >>>>
> >> >>>>
> >> >>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >> >>>> ligges at statistik.tu-dortmund.de
> >> >>>>
> >> >>>>> wrote:
> >> >>>>>
> >> >>>>
> >> >>>>
> >> >>>>>
> >> >>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >> >>>>>
> >> >>>>>  @Uwe I tried the same steps from office as well as home
> >network
> >> >with
> >> >>>>>> same
> >> >>>>>> results. Are you using windows 7 with R 3.0.3?
> >> >>>>>>
> >> >>>>>> I have seen same question being asked by others without any
> >> >>>>>> resolution. Is
> >> >>>>>> anything special about XML package? I am OK use older version
> >of
> >> >>>>>> package
> >> >>>>>> but in archives there are no zip files (only gz files). Is
> >> >windows
> >> >>>>>> platform
> >> >>>>>> not recommended for R?
> >> >>>>>>
> >> >>>>>>
> >> >>>>> Right, and you can try to install these from sources.
> >> >>>>> But I doubt you need it. You still have not told us if you
> >tried
> >> >another
> >> >>>>> mirror to download the XML file from and what you local IT
> >support
> >> >tells
> >> >>>>> you while your downloads are incomplete.
> >> >>>>>
> >> >>>>> Best,
> >> >>>>> Uwe Ligges
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >> >>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>
> >> >>>>>>  wrote:
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >> >>>>>>>
> >> >>>>>>>   Thank you for response Uwe. I tried multiple times by
> >> >downloading
> >> >>>>>>> the
> >> >>>>>>>
> >> >>>>>>>> zip
> >> >>>>>>>> file from many sources but still the same error. This is a
> >> >major road
> >> >>>>>>>> block
> >> >>>>>>>> for me in using R. Appreciate any help on this.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>  Please ask your local IT staff.
> >> >>>>>>>
> >> >>>>>>> I get, using the same mirror:
> >> >>>>>>>
> >> >>>>>>>
> >> >options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >> >>>>>>>
> >> >>>>>>>> install.packages("XML", lib="d:/temp")
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>> trying URL
> >'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>
> >> >>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >> >>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >>>>>>> opened URL
> >> >>>>>>> downloaded 4.1 Mb
> >> >>>>>>>
> >> >>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >> >>>>>>>
> >> >>>>>>> The downloaded binary packages are in
> >> >>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> Best,
> >> >>>>>>> Uwe Ligges
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >> >>>>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>>>
> >> >>>>>>>>   wrote:
> >> >>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>     Works for me.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>> Best,
> >> >>>>>>>>> Uwe Ligges
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >> >>>>>>>>>
> >> >>>>>>>>>    Using install.package('XML') command produces this
> >error:
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>> trying URL
> >> >>>>>>>>>> '
> >> >>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>>>>>>>> '
> >> >>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> >Mb)
> >> >>>>>>>>>> opened URL
> >> >>>>>>>>>> downloaded 4.1 Mb
> >> >>>>>>>>>>
> >> >>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type")) :
> >> >>>>>>>>>>       cannot open the connection
> >> >>>>>>>>>> In addition: Warning messages:
> >> >>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> >...)
> >> >:
> >> >>>>>>>>>>       downloaded length 4276224 != reported length 4288136
> >> >>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >> >from zip
> >> >>>>>>>>>> file
> >> >>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type"))
> >> >>>>>>>>>> :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >> >directly
> >> >>>>>>>>>> from
> >> >>>>>>>>>> cran
> >> >>>>>>>>>> site. But this zip file is not a valid archive (cannot
> >open
> >> >using
> >> >>>>>>>>>> winzip).
> >> >>>>>>>>>> Also trying to install using this downloaded file produces
> >> >the
> >> >>>>>>>>>> following
> >> >>>>>>>>>> error:
> >> >>>>>>>>>>
> >> >>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >> >>>>>>>>>> win-library/3.0'
> >> >>>>>>>>>> (as 'lib' is unspecified)
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       error 1 in extracting from zip file
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>> Error in install.packages : cannot open the connection
> >> >>>>>>>>>>
> >> >>>>>>>>>> I  downloaded this zip file from multiple sources and
> >tried
> >> >to
> >> >>>>>>>>>> install
> >> >>>>>>>>>> with
> >> >>>>>>>>>> same result.
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>
> >> >>>>
> >> >>
> >> >>
> >> >> --
> >> >> Thanks and Regards
> >> >> Alpesh
> >> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From peter.crowther at melandra.com  Mon Apr 21 12:34:21 2014
From: peter.crowther at melandra.com (Peter Crowther)
Date: Mon, 21 Apr 2014 11:34:21 +0100
Subject: [R] reading & understanding SVG?
In-Reply-To: <5354C933.4050808@structuremonitoring.com>
References: <5354C933.4050808@structuremonitoring.com>
Message-ID: <CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/d9c1058d/attachment-0001.pl>

From nalimilan at club.fr  Mon Apr 21 13:10:58 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 21 Apr 2014 13:10:58 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
Message-ID: <1398078658.5143.2.camel@milan>

Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
> Hi
> 
> Couldn't find a zip file in the archives.
> 
> Why didn't 'R CMD build' (in a command shell on Windows) not make a
> zip file? I did try to build from the climatol library that holds the
> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
> etc.
R CMD build produces *source* packages, and .zip packages are *binary*.

> Did you see the debug information on read.fcf? For me it seems like R
> has open a file handler to the DESCRIPTION file. Wouldn't the error
> already be thrown there and not when read.fcf is called if the .tar.gz
> format was the problem?
> 
> I'll try and locate a zip
Does install.packages(choose.file(), type="source") work? I'm not sure
what utils:::menuInstallLocal() does.


Regards


> Sendt fra Samsung mobil
> 
> 
> -------- Oprindelig meddelelse --------
> Fra: Jeff Newmiller
> Dato:21/04/2014 09.44 (GMT+01:00)
> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
> 
> Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
> >Well now, I think I have seen something similar to Alpesh.
> >
> >Recently I needed the climatol package that I have used some time ago.
> >It is not maintained anymore but I downloaded the latest version,
> >climatol_2.2.tar.gz,  from archives
> >(http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> >) . Trying to install that package from local file  using R-3.1.0 on
> >Windows 8  resulted in this:
> >
> >## From R Console
> >> utils:::menuInstallLocal()
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning messages:
> >1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >file
> >2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> >:
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >And yes I know where the file is located, since choose.files() is used.
> >
> >However I tried the same on our linux (R-3.0.2) cluster and it
> >succeeded:
> >
> >[frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> >* installing to library
> >?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> >* installing *source* package ?climatol? ...
> >** R
> >** data
> >** inst
> >** preparing package for lazy loading
> >** help
> >*** installing help indices
> >** building package indices
> >** installing vignettes
> >** testing if installed package can be loaded
> >* DONE (climatol)
> >[frtog at dkrdsfshn2 ~]$ R
> >
> >R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> >Copyright (C) 2013 The R Foundation for Statistical Computing
> >Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> library("climatol")
> >> ?rosavent
> >> q()
> >Save workspace image? [y/n/c]: n
> >[frtog at dkrdsfshn2 ~]$
> >
> >
> >Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> >whether I could build the package on my Windows box. Only R stuff and
> >no foreign language as C, FORTRAN, etc. so it should be easy.
> >
> >## Command shell in Windows
> >Microsoft Windows [Version 6.2.9200]
> >(c) 2012 Microsoft Corporation. All rights reserved.
> >
> >C:\Users\frtog>cd Desktop
> >
> >C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> >climatol
> >* checking for file 'climatol/DESCRIPTION' ... OK
> >* preparing 'climatol':
> >* checking DESCRIPTION meta-information ... OK
> >* checking for LF line-endings in source and make files
> >* checking for empty or unneeded directories
> >* looking to see if a 'data/datalist' file should be added
> >* building 'climatol_2.2.tar.gz'
> >
> >Now trying to install from that local file I Still got the same error
> >as above.
> >
> >
> >
> >Trying to do some debugging on read.dcf() (Emacs/ESS)
> >
> >
> >R version 3.1.0 (2014-04-10) -- "Spring Dance"
> >Copyright (C) 2014 The R Foundation for Statistical Computing
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> > options(chmhelp=FALSE, help_type="text")
> >> options(STERM='iESS', str.dendrogram.last="'",
> >editor='emacsclient.exe', show.error.locations=TRUE)
> >> debug(read.dcf)
> >> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> >debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type"))
> >debug: {
> >    if (is.character(file)) {
> >        file <- gzfile(file)
> >        on.exit(close(file))
> >    }
> >    if (!inherits(file, "connection"))
> >        stop("'file' must be a character string or connection")
> >    if (!all)
> >        return(.Internal(readDCF(file, fields, keep.white)))
> >    .assemble_things_into_a_data_frame <- function(tags, vals,
> >        nums) {
> >        tf <- factor(tags, levels = unique(tags))
> >        cnts <- table(nums, tf)
> >     out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> >            levels(tf)))
> >        if (all(cnts <= 1L)) {
> >            out[cbind(nums, tf)] <- vals
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >        }
> >        else {
> >            levs <- colSums(cnts > 1L) == 0L
> >            if (any(levs)) {
> >                inds <- tf %in% levels(tf)[levs]
> >                out[cbind(nums[inds], tf[inds])] <- vals[inds]
> >            }
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >            for (l in levels(tf)[!levs]) {
> >                out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> >                i <- tf == l
> >                out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> >            }
> >        }
> >        out
> >    }
> >    on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> >        add = TRUE)
> >    Sys.setlocale("LC_CTYPE", "C")
> >    lines <- readLines(file)
> >    ind <- grep("^[^[:blank:]][^:]*$", lines)
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nRegular lines must have a
> >tag.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> >    nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> >    nums <- nums[line_is_not_empty]
> >    lines <- lines[line_is_not_empty]
> >    line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> >        lines)
> >    if (any(line_is_escaped_blank))
> >        lines[line_is_escaped_blank] <- ""
> >    line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> >    ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> >record.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    lengths <- rle(cumsum(line_has_tag))$lengths
> >    pos <- cumsum(lengths)
> >    tags <- sub(":.*", "", lines[line_has_tag])
> >lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> >lines[line_has_tag])
> >    foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> >    lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> >    lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> >vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> >"\n"),
> >        c(1L, pos[-length(pos)] + 1L), pos)
> >    out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> >    if (!is.null(fields))
> >        out <- out[fields]
> >    out
> >}
> >Browse[2]> str(file)
> > chr "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]> head(file)
> >[1] "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]>
> >debug: if (is.character(file)) {
> >    file <- gzfile(file)
> >    on.exit(close(file))
> >}
> >Browse[2]>
> >debug: file <- gzfile(file)
> >Browse[2]>
> >debug: on.exit(close(file))
> >Browse[2]>
> >debug: if (!inherits(file, "connection")) stop("'file' must be a
> >character string or connection")
> >Browse[2]>
> >debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]> str(file)
> >Classes 'gzfile', 'connection'  atomic [1:1] 3
> >  ..- attr(*, "conn_id")=<externalptr>
> >Browse[2]> file
> >                      description                             class
> >"climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> >                             mode                              text
> >                             "rb"                            "text"
> >                           opened                          can read
> >                         "closed"                             "yes"
> >                        can write
> >                            "yes"
> >Browse[2]>
> >debug: return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]>
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning message:
> >In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> >keep.white))) I loose control and R returns to prompt with an error.
> >
> >Hopefully one of you can replicate this. If not then it must have
> >something with Windows OS to do. But what?
> >
> >
> >
> >Yours sincerely / Med venlig hilsen
> >
> >
> >Frede Aakmann T?gersen
> >Specialist, M.Sc., Ph.D.
> >Plant Performance & Modeling
> >
> >Technology & Service Solutions
> >T +45 9730 5135
> >M +45 2547 6050
> >frtog at vestas.com
> >http://www.vestas.com
> >
> >Company reg. name: Vestas Wind Systems A/S
> >This e-mail is subject to our e-mail disclaimer statement.
> >Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> >If you have received this e-mail in error please contact the sender.
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >[mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Jeff Newmiller
> >> Sent: 20. april 2014 23:33
> >> To: Alpesh Pandya; Rui Barradas
> >> Cc: r-help at r-project.org; Uwe Ligges
> >> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>
> >> Hard to help you when the problem simply does not happen for others.
> >>
> >> As for Windows being not a focus, that is not at all true. I use it
> >regularly on
> >> Windows at work. That being said, there are thousands of packages and
> >> those each involve their own subset of R users. There are also many
> >> operating system configurations that may not all be fully tested.
> >Blaming "R"
> >> or "Windows", or blaming us for "preventing" you from getting your
> >> education (isn't that something between you and your educational
> >> institution?) are not going to be effective strategies for problem
> >solving.
> >>
> >> Are you able to use other aspects of R beyond the XML package? Have
> >you
> >> tried communicating with the maintainers of that package?
> >>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> >> <alpeshpandya at gmail.com> wrote:
> >> >I keep on trying from various networks but I still get the same
> >error.
> >> >I
> >> >don't this this has anything to do with network or ability to
> >download
> >> >the
> >> >package (as I can install other packages fine). This must be
> >something
> >> >in
> >> >base R or dependencies issues (that R is not spelling out).
> >> >
> >> >I know R is geared for Mac and Windows is kind of looked down upon
> >but
> >> >I
> >> >have no option but use windows and need this XML package running to
> >> >complete my education. Any help on this would be appreciated.
> >> >
> >> >
> >> >On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> >> ><alpeshpandya at gmail.com>wrote:
> >> >
> >> >> Thank you for response Rui.
> >> >>
> >> >> I still get the same error with this repository.
> >> >>
> >> >> Installing package into
> >> >???C:/Users/APandya/Documents/R/win-library/3.0???
> >> >> (as ???lib??? is unspecified)
> >> >> trying URL '
> >> >> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> >> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >> opened URL
> >> >> downloaded 4.1 Mb
> >> >>
> >> >> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type"))
> >> >> :
> >> >>   cannot open the connection
> >> >> In addition: Warning messages:
> >> >> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >> >>   downloaded length 4276224 != reported length 4288136
> >> >> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> >zip
> >> >file
> >> >> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type")) :
> >> >>   cannot open compressed file 'XML/DESCRIPTION', probable reason
> >'No
> >> >such
> >> >> file or directory'
> >> >>
> >> >>
> >> >>
> >> >> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> >> ><ruipbarradas at sapo.pt>wrote:
> >> >>
> >> >>> Hello,
> >> >>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >> >problem
> >> >>> at all. Can't you try (it worked with me)
> >> >>>
> >> >>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >> >>>
> >> >>> Hope this helps,
> >> >>>
> >> >>> Rui Barradas
> >> >>>
> >> >>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >> >>>
> >> >>>  I have tried these sources (almost all US mirrors):
> >> >>>>
> >> >>>>
> >>
> >>http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >> >>>> 3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> >> 1.1.zip
> >> >>>>
> >> >>>> I have confirmed with IT that there is no restriction on
> >> >downloading this
> >> >>>> zip file from any of these sources. Also I am getting same error
> >> >when I
> >> >>>> try
> >> >>>> from my home network as well.
> >> >>>>
> >> >>>>
> >> >>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >> >>>> ligges at statistik.tu-dortmund.de
> >> >>>>
> >> >>>>> wrote:
> >> >>>>>
> >> >>>>
> >> >>>>
> >> >>>>>
> >> >>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >> >>>>>
> >> >>>>>  @Uwe I tried the same steps from office as well as home
> >network
> >> >with
> >> >>>>>> same
> >> >>>>>> results. Are you using windows 7 with R 3.0.3?
> >> >>>>>>
> >> >>>>>> I have seen same question being asked by others without any
> >> >>>>>> resolution. Is
> >> >>>>>> anything special about XML package? I am OK use older version
> >of
> >> >>>>>> package
> >> >>>>>> but in archives there are no zip files (only gz files). Is
> >> >windows
> >> >>>>>> platform
> >> >>>>>> not recommended for R?
> >> >>>>>>
> >> >>>>>>
> >> >>>>> Right, and you can try to install these from sources.
> >> >>>>> But I doubt you need it. You still have not told us if you
> >tried
> >> >another
> >> >>>>> mirror to download the XML file from and what you local IT
> >support
> >> >tells
> >> >>>>> you while your downloads are incomplete.
> >> >>>>>
> >> >>>>> Best,
> >> >>>>> Uwe Ligges
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >> >>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>
> >> >>>>>>  wrote:
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >> >>>>>>>
> >> >>>>>>>   Thank you for response Uwe. I tried multiple times by
> >> >downloading
> >> >>>>>>> the
> >> >>>>>>>
> >> >>>>>>>> zip
> >> >>>>>>>> file from many sources but still the same error. This is a
> >> >major road
> >> >>>>>>>> block
> >> >>>>>>>> for me in using R. Appreciate any help on this.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>  Please ask your local IT staff.
> >> >>>>>>>
> >> >>>>>>> I get, using the same mirror:
> >> >>>>>>>
> >> >>>>>>>
> >> >options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >> >>>>>>>
> >> >>>>>>>> install.packages("XML", lib="d:/temp")
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>> trying URL
> >'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>
> >> >>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >> >>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >>>>>>> opened URL
> >> >>>>>>> downloaded 4.1 Mb
> >> >>>>>>>
> >> >>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >> >>>>>>>
> >> >>>>>>> The downloaded binary packages are in
> >> >>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> Best,
> >> >>>>>>> Uwe Ligges
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >> >>>>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>>>
> >> >>>>>>>>   wrote:
> >> >>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>     Works for me.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>> Best,
> >> >>>>>>>>> Uwe Ligges
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >> >>>>>>>>>
> >> >>>>>>>>>    Using install.package('XML') command produces this
> >error:
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>> trying URL
> >> >>>>>>>>>> '
> >> >>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>>>>>>>> '
> >> >>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> >Mb)
> >> >>>>>>>>>> opened URL
> >> >>>>>>>>>> downloaded 4.1 Mb
> >> >>>>>>>>>>
> >> >>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type")) :
> >> >>>>>>>>>>       cannot open the connection
> >> >>>>>>>>>> In addition: Warning messages:
> >> >>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> >...)
> >> >:
> >> >>>>>>>>>>       downloaded length 4276224 != reported length 4288136
> >> >>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >> >from zip
> >> >>>>>>>>>> file
> >> >>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type"))
> >> >>>>>>>>>> :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >> >directly
> >> >>>>>>>>>> from
> >> >>>>>>>>>> cran
> >> >>>>>>>>>> site. But this zip file is not a valid archive (cannot
> >open
> >> >using
> >> >>>>>>>>>> winzip).
> >> >>>>>>>>>> Also trying to install using this downloaded file produces
> >> >the
> >> >>>>>>>>>> following
> >> >>>>>>>>>> error:
> >> >>>>>>>>>>
> >> >>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >> >>>>>>>>>> win-library/3.0'
> >> >>>>>>>>>> (as 'lib' is unspecified)
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       error 1 in extracting from zip file
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>> Error in install.packages : cannot open the connection
> >> >>>>>>>>>>
> >> >>>>>>>>>> I  downloaded this zip file from multiple sources and
> >tried
> >> >to
> >> >>>>>>>>>> install
> >> >>>>>>>>>> with
> >> >>>>>>>>>> same result.
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>
> >> >>>>
> >> >>
> >> >>
> >> >> --
> >> >> Thanks and Regards
> >> >> Alpesh
> >> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nalimilan at club.fr  Mon Apr 21 13:17:41 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 21 Apr 2014 13:17:41 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
Message-ID: <1398079061.5143.5.camel@milan>

Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
> Hi
> 
> Couldn't find a zip file in the archives.
> 
> Why didn't 'R CMD build' (in a command shell on Windows) not make a
> zip file? I did try to build from the climatol library that holds the
> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
> etc.
R CMD build produces *source* packages, and .zip packages are *binary*.

> Did you see the debug information on read.fcf? For me it seems like R
> has open a file handler to the DESCRIPTION file. Wouldn't the error
> already be thrown there and not when read.fcf is called if the .tar.gz
> format was the problem?
> 
> I'll try and locate a zip
Does install.packages(choose.file(), type="source") work? I'm not sure
what utils:::menuInstallLocal() does.


Regards


> Sendt fra Samsung mobil
> 
> 
> -------- Oprindelig meddelelse --------
> Fra: Jeff Newmiller
> Dato:21/04/2014 09.44 (GMT+01:00)
> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
> 
> Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
> >Well now, I think I have seen something similar to Alpesh.
> >
> >Recently I needed the climatol package that I have used some time ago.
> >It is not maintained anymore but I downloaded the latest version,
> >climatol_2.2.tar.gz,  from archives
> >(http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> >) . Trying to install that package from local file  using R-3.1.0 on
> >Windows 8  resulted in this:
> >
> >## From R Console
> >> utils:::menuInstallLocal()
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning messages:
> >1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >file
> >2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> >:
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >And yes I know where the file is located, since choose.files() is used.
> >
> >However I tried the same on our linux (R-3.0.2) cluster and it
> >succeeded:
> >
> >[frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> >* installing to library
> >?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> >* installing *source* package ?climatol? ...
> >** R
> >** data
> >** inst
> >** preparing package for lazy loading
> >** help
> >*** installing help indices
> >** building package indices
> >** installing vignettes
> >** testing if installed package can be loaded
> >* DONE (climatol)
> >[frtog at dkrdsfshn2 ~]$ R
> >
> >R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> >Copyright (C) 2013 The R Foundation for Statistical Computing
> >Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> library("climatol")
> >> ?rosavent
> >> q()
> >Save workspace image? [y/n/c]: n
> >[frtog at dkrdsfshn2 ~]$
> >
> >
> >Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> >whether I could build the package on my Windows box. Only R stuff and
> >no foreign language as C, FORTRAN, etc. so it should be easy.
> >
> >## Command shell in Windows
> >Microsoft Windows [Version 6.2.9200]
> >(c) 2012 Microsoft Corporation. All rights reserved.
> >
> >C:\Users\frtog>cd Desktop
> >
> >C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> >climatol
> >* checking for file 'climatol/DESCRIPTION' ... OK
> >* preparing 'climatol':
> >* checking DESCRIPTION meta-information ... OK
> >* checking for LF line-endings in source and make files
> >* checking for empty or unneeded directories
> >* looking to see if a 'data/datalist' file should be added
> >* building 'climatol_2.2.tar.gz'
> >
> >Now trying to install from that local file I Still got the same error
> >as above.
> >
> >
> >
> >Trying to do some debugging on read.dcf() (Emacs/ESS)
> >
> >
> >R version 3.1.0 (2014-04-10) -- "Spring Dance"
> >Copyright (C) 2014 The R Foundation for Statistical Computing
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> >R is free software and comes with ABSOLUTELY NO WARRANTY.
> >You are welcome to redistribute it under certain conditions.
> >Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> >R is a collaborative project with many contributors.
> >Type 'contributors()' for more information and
> >'citation()' on how to cite R or R packages in publications.
> >
> >Type 'demo()' for some demos, 'help()' for on-line help, or
> >'help.start()' for an HTML browser interface to help.
> >Type 'q()' to quit R.
> >
> >> > options(chmhelp=FALSE, help_type="text")
> >> options(STERM='iESS', str.dendrogram.last="'",
> >editor='emacsclient.exe', show.error.locations=TRUE)
> >> debug(read.dcf)
> >> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> >debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type"))
> >debug: {
> >    if (is.character(file)) {
> >        file <- gzfile(file)
> >        on.exit(close(file))
> >    }
> >    if (!inherits(file, "connection"))
> >        stop("'file' must be a character string or connection")
> >    if (!all)
> >        return(.Internal(readDCF(file, fields, keep.white)))
> >    .assemble_things_into_a_data_frame <- function(tags, vals,
> >        nums) {
> >        tf <- factor(tags, levels = unique(tags))
> >        cnts <- table(nums, tf)
> >     out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> >            levels(tf)))
> >        if (all(cnts <= 1L)) {
> >            out[cbind(nums, tf)] <- vals
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >        }
> >        else {
> >            levs <- colSums(cnts > 1L) == 0L
> >            if (any(levs)) {
> >                inds <- tf %in% levels(tf)[levs]
> >                out[cbind(nums[inds], tf[inds])] <- vals[inds]
> >            }
> >            out <- as.data.frame(out, stringsAsFactors = FALSE)
> >            for (l in levels(tf)[!levs]) {
> >                out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> >                i <- tf == l
> >                out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> >            }
> >        }
> >        out
> >    }
> >    on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> >        add = TRUE)
> >    Sys.setlocale("LC_CTYPE", "C")
> >    lines <- readLines(file)
> >    ind <- grep("^[^[:blank:]][^:]*$", lines)
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nRegular lines must have a
> >tag.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> >    nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> >    nums <- nums[line_is_not_empty]
> >    lines <- lines[line_is_not_empty]
> >    line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> >        lines)
> >    if (any(line_is_escaped_blank))
> >        lines[line_is_escaped_blank] <- ""
> >    line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> >    ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> >    if (length(ind)) {
> >        lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> >record.\nOffending lines start with:\n%s",
> >            paste0("  ", lines, collapse = "\n")), domain = NA)
> >    }
> >    lengths <- rle(cumsum(line_has_tag))$lengths
> >    pos <- cumsum(lengths)
> >    tags <- sub(":.*", "", lines[line_has_tag])
> >lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> >lines[line_has_tag])
> >    foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> >    lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> >    lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> >vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> >"\n"),
> >        c(1L, pos[-length(pos)] + 1L), pos)
> >    out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> >    if (!is.null(fields))
> >        out <- out[fields]
> >    out
> >}
> >Browse[2]> str(file)
> > chr "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]> head(file)
> >[1] "climatol_2.2.tar.gz/DESCRIPTION"
> >Browse[2]>
> >debug: if (is.character(file)) {
> >    file <- gzfile(file)
> >    on.exit(close(file))
> >}
> >Browse[2]>
> >debug: file <- gzfile(file)
> >Browse[2]>
> >debug: on.exit(close(file))
> >Browse[2]>
> >debug: if (!inherits(file, "connection")) stop("'file' must be a
> >character string or connection")
> >Browse[2]>
> >debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]> str(file)
> >Classes 'gzfile', 'connection'  atomic [1:1] 3
> >  ..- attr(*, "conn_id")=<externalptr>
> >Browse[2]> file
> >                      description                             class
> >"climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> >                             mode                              text
> >                             "rb"                            "text"
> >                           opened                          can read
> >                         "closed"                             "yes"
> >                        can write
> >                            "yes"
> >Browse[2]>
> >debug: return(.Internal(readDCF(file, fields, keep.white)))
> >Browse[2]>
> >Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >"Type")) :
> >  cannot open the connection
> >In addition: Warning message:
> >In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> >cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >reason 'No such file or directory'
> >>
> >
> >Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> >keep.white))) I loose control and R returns to prompt with an error.
> >
> >Hopefully one of you can replicate this. If not then it must have
> >something with Windows OS to do. But what?
> >
> >
> >
> >Yours sincerely / Med venlig hilsen
> >
> >
> >Frede Aakmann T?gersen
> >Specialist, M.Sc., Ph.D.
> >Plant Performance & Modeling
> >
> >Technology & Service Solutions
> >T +45 9730 5135
> >M +45 2547 6050
> >frtog at vestas.com
> >http://www.vestas.com
> >
> >Company reg. name: Vestas Wind Systems A/S
> >This e-mail is subject to our e-mail disclaimer statement.
> >Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> >If you have received this e-mail in error please contact the sender.
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >[mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Jeff Newmiller
> >> Sent: 20. april 2014 23:33
> >> To: Alpesh Pandya; Rui Barradas
> >> Cc: r-help at r-project.org; Uwe Ligges
> >> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>
> >> Hard to help you when the problem simply does not happen for others.
> >>
> >> As for Windows being not a focus, that is not at all true. I use it
> >regularly on
> >> Windows at work. That being said, there are thousands of packages and
> >> those each involve their own subset of R users. There are also many
> >> operating system configurations that may not all be fully tested.
> >Blaming "R"
> >> or "Windows", or blaming us for "preventing" you from getting your
> >> education (isn't that something between you and your educational
> >> institution?) are not going to be effective strategies for problem
> >solving.
> >>
> >> Are you able to use other aspects of R beyond the XML package? Have
> >you
> >> tried communicating with the maintainers of that package?
> >>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> >> <alpeshpandya at gmail.com> wrote:
> >> >I keep on trying from various networks but I still get the same
> >error.
> >> >I
> >> >don't this this has anything to do with network or ability to
> >download
> >> >the
> >> >package (as I can install other packages fine). This must be
> >something
> >> >in
> >> >base R or dependencies issues (that R is not spelling out).
> >> >
> >> >I know R is geared for Mac and Windows is kind of looked down upon
> >but
> >> >I
> >> >have no option but use windows and need this XML package running to
> >> >complete my education. Any help on this would be appreciated.
> >> >
> >> >
> >> >On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> >> ><alpeshpandya at gmail.com>wrote:
> >> >
> >> >> Thank you for response Rui.
> >> >>
> >> >> I still get the same error with this repository.
> >> >>
> >> >> Installing package into
> >> >???C:/Users/APandya/Documents/R/win-library/3.0???
> >> >> (as ???lib??? is unspecified)
> >> >> trying URL '
> >> >> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> >> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >> opened URL
> >> >> downloaded 4.1 Mb
> >> >>
> >> >> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type"))
> >> >> :
> >> >>   cannot open the connection
> >> >> In addition: Warning messages:
> >> >> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >> >>   downloaded length 4276224 != reported length 4288136
> >> >> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> >zip
> >> >file
> >> >> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >> >"Type")) :
> >> >>   cannot open compressed file 'XML/DESCRIPTION', probable reason
> >'No
> >> >such
> >> >> file or directory'
> >> >>
> >> >>
> >> >>
> >> >> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> >> ><ruipbarradas at sapo.pt>wrote:
> >> >>
> >> >>> Hello,
> >> >>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >> >problem
> >> >>> at all. Can't you try (it worked with me)
> >> >>>
> >> >>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >> >>>
> >> >>> Hope this helps,
> >> >>>
> >> >>> Rui Barradas
> >> >>>
> >> >>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >> >>>
> >> >>>  I have tried these sources (almost all US mirrors):
> >> >>>>
> >> >>>>
> >>
> >>http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >> >>>> 3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >>
> >>http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >> >>>>
> >> >http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> >> 1.1.zip
> >> >>>>
> >> >>>> I have confirmed with IT that there is no restriction on
> >> >downloading this
> >> >>>> zip file from any of these sources. Also I am getting same error
> >> >when I
> >> >>>> try
> >> >>>> from my home network as well.
> >> >>>>
> >> >>>>
> >> >>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >> >>>> ligges at statistik.tu-dortmund.de
> >> >>>>
> >> >>>>> wrote:
> >> >>>>>
> >> >>>>
> >> >>>>
> >> >>>>>
> >> >>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >> >>>>>
> >> >>>>>  @Uwe I tried the same steps from office as well as home
> >network
> >> >with
> >> >>>>>> same
> >> >>>>>> results. Are you using windows 7 with R 3.0.3?
> >> >>>>>>
> >> >>>>>> I have seen same question being asked by others without any
> >> >>>>>> resolution. Is
> >> >>>>>> anything special about XML package? I am OK use older version
> >of
> >> >>>>>> package
> >> >>>>>> but in archives there are no zip files (only gz files). Is
> >> >windows
> >> >>>>>> platform
> >> >>>>>> not recommended for R?
> >> >>>>>>
> >> >>>>>>
> >> >>>>> Right, and you can try to install these from sources.
> >> >>>>> But I doubt you need it. You still have not told us if you
> >tried
> >> >another
> >> >>>>> mirror to download the XML file from and what you local IT
> >support
> >> >tells
> >> >>>>> you while your downloads are incomplete.
> >> >>>>>
> >> >>>>> Best,
> >> >>>>> Uwe Ligges
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >> >>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>
> >> >>>>>>  wrote:
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >> >>>>>>>
> >> >>>>>>>   Thank you for response Uwe. I tried multiple times by
> >> >downloading
> >> >>>>>>> the
> >> >>>>>>>
> >> >>>>>>>> zip
> >> >>>>>>>> file from many sources but still the same error. This is a
> >> >major road
> >> >>>>>>>> block
> >> >>>>>>>> for me in using R. Appreciate any help on this.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>  Please ask your local IT staff.
> >> >>>>>>>
> >> >>>>>>> I get, using the same mirror:
> >> >>>>>>>
> >> >>>>>>>
> >> >options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >> >>>>>>>
> >> >>>>>>>> install.packages("XML", lib="d:/temp")
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>> trying URL
> >'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>
> >> >>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >> >>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >> >>>>>>> opened URL
> >> >>>>>>> downloaded 4.1 Mb
> >> >>>>>>>
> >> >>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >> >>>>>>>
> >> >>>>>>> The downloaded binary packages are in
> >> >>>>>>>           d:\temp\RtmpqMqL8L\downloaded_packages
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> Best,
> >> >>>>>>> Uwe Ligges
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>  On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >> >>>>>>>> ligges at statistik.tu-dortmund.de
> >> >>>>>>>>
> >> >>>>>>>>   wrote:
> >> >>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>     Works for me.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>> Best,
> >> >>>>>>>>> Uwe Ligges
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >> >>>>>>>>>
> >> >>>>>>>>>    Using install.package('XML') command produces this
> >error:
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>> trying URL
> >> >>>>>>>>>> '
> >> >>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >> >>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >> >>>>>>>>>> '
> >> >>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> >Mb)
> >> >>>>>>>>>> opened URL
> >> >>>>>>>>>> downloaded 4.1 Mb
> >> >>>>>>>>>>
> >> >>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type")) :
> >> >>>>>>>>>>       cannot open the connection
> >> >>>>>>>>>> In addition: Warning messages:
> >> >>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> >...)
> >> >:
> >> >>>>>>>>>>       downloaded length 4276224 != reported length 4288136
> >> >>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >> >from zip
> >> >>>>>>>>>> file
> >> >>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >> >c("Package",
> >> >>>>>>>>>> "Type"))
> >> >>>>>>>>>> :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >> >directly
> >> >>>>>>>>>> from
> >> >>>>>>>>>> cran
> >> >>>>>>>>>> site. But this zip file is not a valid archive (cannot
> >open
> >> >using
> >> >>>>>>>>>> winzip).
> >> >>>>>>>>>> Also trying to install using this downloaded file produces
> >> >the
> >> >>>>>>>>>> following
> >> >>>>>>>>>> error:
> >> >>>>>>>>>>
> >> >>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >> >>>>>>>>>> win-library/3.0'
> >> >>>>>>>>>> (as 'lib' is unspecified)
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       error 1 in extracting from zip file
> >> >>>>>>>>>> Warning in install.packages :
> >> >>>>>>>>>>       cannot open compressed file 'XML/DESCRIPTION',
> >probable
> >> >>>>>>>>>> reason
> >> >>>>>>>>>> 'No
> >> >>>>>>>>>> such
> >> >>>>>>>>>> file or directory'
> >> >>>>>>>>>> Error in install.packages : cannot open the connection
> >> >>>>>>>>>>
> >> >>>>>>>>>> I  downloaded this zip file from multiple sources and
> >tried
> >> >to
> >> >>>>>>>>>> install
> >> >>>>>>>>>> with
> >> >>>>>>>>>> same result.
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>
> >> >>>>
> >> >>
> >> >>
> >> >> --
> >> >> Thanks and Regards
> >> >> Alpesh
> >> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Mon Apr 21 13:21:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Apr 2014 07:21:00 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <1398078658.5143.2.camel@milan>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
	<1398078658.5143.2.camel@milan>
Message-ID: <5354FF1C.3000607@gmail.com>

On 21/04/2014, 7:10 AM, Milan Bouchet-Valat wrote:
> Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
>> Hi
>>
>> Couldn't find a zip file in the archives.
>>
>> Why didn't 'R CMD build' (in a command shell on Windows) not make a
>> zip file? I did try to build from the climatol library that holds the
>> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
>> etc.
> R CMD build produces *source* packages, and .zip packages are *binary*.
>
>> Did you see the debug information on read.fcf? For me it seems like R
>> has open a file handler to the DESCRIPTION file. Wouldn't the error
>> already be thrown there and not when read.fcf is called if the .tar.gz
>> format was the problem?
>>
>> I'll try and locate a zip
> Does install.packages(choose.file(), type="source") work?

That will also need "repos=NULL", or it will go out to a repository to 
look for the package.

That should work if the package doesn't have compiled code.  It will 
handle compiled code only if Frede has the appropriate tools installed.


I'm not sure
> what utils:::menuInstallLocal() does.

It is essentially

install.packages(choose.file(), type="binary", repos=NULL)

so it's not what Frede needs.

Duncan
>
>
> Regards
>
>
>> Sendt fra Samsung mobil
>>
>>
>> -------- Oprindelig meddelelse --------
>> Fra: Jeff Newmiller
>> Dato:21/04/2014 09.44 (GMT+01:00)
>> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
>> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
>> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
>>
>> Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
>>> Well now, I think I have seen something similar to Alpesh.
>>>
>>> Recently I needed the climatol package that I have used some time ago.
>>> It is not maintained anymore but I downloaded the latest version,
>>> climatol_2.2.tar.gz,  from archives
>>> (http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
>>> ) . Trying to install that package from local file  using R-3.1.0 on
>>> Windows 8  resulted in this:
>>>
>>> ## From R Console
>>>> utils:::menuInstallLocal()
>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>> "Type")) :
>>>   cannot open the connection
>>> In addition: Warning messages:
>>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>>> file
>>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>>> :
>>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
>>> reason 'No such file or directory'
>>>>
>>>
>>> And yes I know where the file is located, since choose.files() is used.
>>>
>>> However I tried the same on our linux (R-3.0.2) cluster and it
>>> succeeded:
>>>
>>> [frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
>>> * installing to library
>>> ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
>>> * installing *source* package ?climatol? ...
>>> ** R
>>> ** data
>>> ** inst
>>> ** preparing package for lazy loading
>>> ** help
>>> *** installing help indices
>>> ** building package indices
>>> ** installing vignettes
>>> ** testing if installed package can be loaded
>>> * DONE (climatol)
>>> [frtog at dkrdsfshn2 ~]$ R
>>>
>>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>>> Copyright (C) 2013 The R Foundation for Statistical Computing
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>>   Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>>> library("climatol")
>>>> ?rosavent
>>>> q()
>>> Save workspace image? [y/n/c]: n
>>> [frtog at dkrdsfshn2 ~]$
>>>
>>>
>>> Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
>>> whether I could build the package on my Windows box. Only R stuff and
>>> no foreign language as C, FORTRAN, etc. so it should be easy.
>>>
>>> ## Command shell in Windows
>>> Microsoft Windows [Version 6.2.9200]
>>> (c) 2012 Microsoft Corporation. All rights reserved.
>>>
>>> C:\Users\frtog>cd Desktop
>>>
>>> C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
>>> climatol
>>> * checking for file 'climatol/DESCRIPTION' ... OK
>>> * preparing 'climatol':
>>> * checking DESCRIPTION meta-information ... OK
>>> * checking for LF line-endings in source and make files
>>> * checking for empty or unneeded directories
>>> * looking to see if a 'data/datalist' file should be added
>>> * building 'climatol_2.2.tar.gz'
>>>
>>> Now trying to install from that local file I Still got the same error
>>> as above.
>>>
>>>
>>>
>>> Trying to do some debugging on read.dcf() (Emacs/ESS)
>>>
>>>
>>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>>> Copyright (C) 2014 The R Foundation for Statistical Computing
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>>   Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>>>> options(chmhelp=FALSE, help_type="text")
>>>> options(STERM='iESS', str.dendrogram.last="'",
>>> editor='emacsclient.exe', show.error.locations=TRUE)
>>>> debug(read.dcf)
>>>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
>>> debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>> "Type"))
>>> debug: {
>>>     if (is.character(file)) {
>>>         file <- gzfile(file)
>>>         on.exit(close(file))
>>>     }
>>>     if (!inherits(file, "connection"))
>>>         stop("'file' must be a character string or connection")
>>>     if (!all)
>>>         return(.Internal(readDCF(file, fields, keep.white)))
>>>     .assemble_things_into_a_data_frame <- function(tags, vals,
>>>         nums) {
>>>         tf <- factor(tags, levels = unique(tags))
>>>         cnts <- table(nums, tf)
>>>      out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
>>>             levels(tf)))
>>>         if (all(cnts <= 1L)) {
>>>             out[cbind(nums, tf)] <- vals
>>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
>>>         }
>>>         else {
>>>             levs <- colSums(cnts > 1L) == 0L
>>>             if (any(levs)) {
>>>                 inds <- tf %in% levels(tf)[levs]
>>>                 out[cbind(nums[inds], tf[inds])] <- vals[inds]
>>>             }
>>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
>>>             for (l in levels(tf)[!levs]) {
>>>                 out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
>>>                 i <- tf == l
>>>                 out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
>>>             }
>>>         }
>>>         out
>>>     }
>>>     on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
>>>         add = TRUE)
>>>     Sys.setlocale("LC_CTYPE", "C")
>>>     lines <- readLines(file)
>>>     ind <- grep("^[^[:blank:]][^:]*$", lines)
>>>     if (length(ind)) {
>>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
>>> stop(gettextf("Invalid DCF format.\nRegular lines must have a
>>> tag.\nOffending lines start with:\n%s",
>>>             paste0("  ", lines, collapse = "\n")), domain = NA)
>>>     }
>>>     line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
>>>     nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
>>>     nums <- nums[line_is_not_empty]
>>>     lines <- lines[line_is_not_empty]
>>>     line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
>>>         lines)
>>>     if (any(line_is_escaped_blank))
>>>         lines[line_is_escaped_blank] <- ""
>>>     line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
>>>     ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
>>>     if (length(ind)) {
>>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
>>> stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
>>> record.\nOffending lines start with:\n%s",
>>>             paste0("  ", lines, collapse = "\n")), domain = NA)
>>>     }
>>>     lengths <- rle(cumsum(line_has_tag))$lengths
>>>     pos <- cumsum(lengths)
>>>     tags <- sub(":.*", "", lines[line_has_tag])
>>> lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
>>> lines[line_has_tag])
>>>     foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
>>>     lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
>>>     lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
>>> vals <- mapply(function(from, to) paste(lines[from:to], collapse =
>>> "\n"),
>>>         c(1L, pos[-length(pos)] + 1L), pos)
>>>     out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
>>>     if (!is.null(fields))
>>>         out <- out[fields]
>>>     out
>>> }
>>> Browse[2]> str(file)
>>> chr "climatol_2.2.tar.gz/DESCRIPTION"
>>> Browse[2]> head(file)
>>> [1] "climatol_2.2.tar.gz/DESCRIPTION"
>>> Browse[2]>
>>> debug: if (is.character(file)) {
>>>     file <- gzfile(file)
>>>     on.exit(close(file))
>>> }
>>> Browse[2]>
>>> debug: file <- gzfile(file)
>>> Browse[2]>
>>> debug: on.exit(close(file))
>>> Browse[2]>
>>> debug: if (!inherits(file, "connection")) stop("'file' must be a
>>> character string or connection")
>>> Browse[2]>
>>> debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
>>> Browse[2]> str(file)
>>> Classes 'gzfile', 'connection'  atomic [1:1] 3
>>>   ..- attr(*, "conn_id")=<externalptr>
>>> Browse[2]> file
>>>                       description                             class
>>> "climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
>>>                              mode                              text
>>>                              "rb"                            "text"
>>>                            opened                          can read
>>>                          "closed"                             "yes"
>>>                         can write
>>>                             "yes"
>>> Browse[2]>
>>> debug: return(.Internal(readDCF(file, fields, keep.white)))
>>> Browse[2]>
>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>> "Type")) :
>>>   cannot open the connection
>>> In addition: Warning message:
>>> In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
>>> reason 'No such file or directory'
>>>>
>>>
>>> Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
>>> keep.white))) I loose control and R returns to prompt with an error.
>>>
>>> Hopefully one of you can replicate this. If not then it must have
>>> something with Windows OS to do. But what?
>>>
>>>
>>>
>>> Yours sincerely / Med venlig hilsen
>>>
>>>
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>>
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com
>>> http://www.vestas.com
>>>
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
>>> If you have received this e-mail in error please contact the sender.
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org]
>>>> On Behalf Of Jeff Newmiller
>>>> Sent: 20. april 2014 23:33
>>>> To: Alpesh Pandya; Rui Barradas
>>>> Cc: r-help at r-project.org; Uwe Ligges
>>>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
>>>>
>>>> Hard to help you when the problem simply does not happen for others.
>>>>
>>>> As for Windows being not a focus, that is not at all true. I use it
>>> regularly on
>>>> Windows at work. That being said, there are thousands of packages and
>>>> those each involve their own subset of R users. There are also many
>>>> operating system configurations that may not all be fully tested.
>>> Blaming "R"
>>>> or "Windows", or blaming us for "preventing" you from getting your
>>>> education (isn't that something between you and your educational
>>>> institution?) are not going to be effective strategies for problem
>>> solving.
>>>>
>>>> Are you able to use other aspects of R beyond the XML package? Have
>>> you
>>>> tried communicating with the maintainers of that package?
>>>>
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>>                                        Live:   OO#.. Dead: OO#..
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>>
>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
>>>> <alpeshpandya at gmail.com> wrote:
>>>>> I keep on trying from various networks but I still get the same
>>> error.
>>>>> I
>>>>> don't this this has anything to do with network or ability to
>>> download
>>>>> the
>>>>> package (as I can install other packages fine). This must be
>>> something
>>>>> in
>>>>> base R or dependencies issues (that R is not spelling out).
>>>>>
>>>>> I know R is geared for Mac and Windows is kind of looked down upon
>>> but
>>>>> I
>>>>> have no option but use windows and need this XML package running to
>>>>> complete my education. Any help on this would be appreciated.
>>>>>
>>>>>
>>>>> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
>>>>> <alpeshpandya at gmail.com>wrote:
>>>>>
>>>>>> Thank you for response Rui.
>>>>>>
>>>>>> I still get the same error with this repository.
>>>>>>
>>>>>> Installing package into
>>>>> ???C:/Users/APandya/Documents/R/win-library/3.0???
>>>>>> (as ???lib??? is unspecified)
>>>>>> trying URL '
>>>>>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>> opened URL
>>>>>> downloaded 4.1 Mb
>>>>>>
>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>> "Type"))
>>>>>> :
>>>>>>    cannot open the connection
>>>>>> In addition: Warning messages:
>>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>>>>>    downloaded length 4276224 != reported length 4288136
>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
>>> zip
>>>>> file
>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>>>> "Type")) :
>>>>>>    cannot open compressed file 'XML/DESCRIPTION', probable reason
>>> 'No
>>>>> such
>>>>>> file or directory'
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
>>>>> <ruipbarradas at sapo.pt>wrote:
>>>>>>
>>>>>>> Hello,
>>>>>>> I have package XML installed on Windows 7, R 3.0.3 and I had no
>>>>> problem
>>>>>>> at all. Can't you try (it worked with me)
>>>>>>>
>>>>>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
>>>>>>>
>>>>>>>   I have tried these sources (almost all US mirrors):
>>>>>>>>
>>>>>>>>
>>>>
>>>> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>
>>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
>>>>>>>> 3.0/XML_3.98-1.1.zip
>>>>>>>>
>>>>> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>
>>>>
>>>> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>
>>>>
>>>> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>
>>>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
>>>> 1.1.zip
>>>>>>>>
>>>>>>>> I have confirmed with IT that there is no restriction on
>>>>> downloading this
>>>>>>>> zip file from any of these sources. Also I am getting same error
>>>>> when I
>>>>>>>> try
>>>>>>>> from my home network as well.
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
>>>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>>>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>>>>>>>>>
>>>>>>>>>   @Uwe I tried the same steps from office as well as home
>>> network
>>>>> with
>>>>>>>>>> same
>>>>>>>>>> results. Are you using windows 7 with R 3.0.3?
>>>>>>>>>>
>>>>>>>>>> I have seen same question being asked by others without any
>>>>>>>>>> resolution. Is
>>>>>>>>>> anything special about XML package? I am OK use older version
>>> of
>>>>>>>>>> package
>>>>>>>>>> but in archives there are no zip files (only gz files). Is
>>>>> windows
>>>>>>>>>> platform
>>>>>>>>>> not recommended for R?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>> Right, and you can try to install these from sources.
>>>>>>>>> But I doubt you need it. You still have not told us if you
>>> tried
>>>>> another
>>>>>>>>> mirror to download the XML file from and what you local IT
>>> support
>>>>> tells
>>>>>>>>> you while your downloads are incomplete.
>>>>>>>>>
>>>>>>>>> Best,
>>>>>>>>> Uwe Ligges
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>>>>>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>>>>>
>>>>>>>>>>   wrote:
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>>>>>>>>>>>
>>>>>>>>>>>    Thank you for response Uwe. I tried multiple times by
>>>>> downloading
>>>>>>>>>>> the
>>>>>>>>>>>
>>>>>>>>>>>> zip
>>>>>>>>>>>> file from many sources but still the same error. This is a
>>>>> major road
>>>>>>>>>>>> block
>>>>>>>>>>>> for me in using R. Appreciate any help on this.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>   Please ask your local IT staff.
>>>>>>>>>>>
>>>>>>>>>>> I get, using the same mirror:
>>>>>>>>>>>
>>>>>>>>>>>
>>>>> options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>>>>>>>>>>>
>>>>>>>>>>>> install.packages("XML", lib="d:/temp")
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>> trying URL
>>> 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>>>>>
>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
>>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
>>>>>>>>>>> opened URL
>>>>>>>>>>> downloaded 4.1 Mb
>>>>>>>>>>>
>>>>>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
>>>>>>>>>>>
>>>>>>>>>>> The downloaded binary packages are in
>>>>>>>>>>>            d:\temp\RtmpqMqL8L\downloaded_packages
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Best,
>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>>>>>>>>>>>> ligges at statistik.tu-dortmund.de
>>>>>>>>>>>>
>>>>>>>>>>>>    wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>      Works for me.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>> Best,
>>>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>>>>>>>>>>>>>
>>>>>>>>>>>>>     Using install.package('XML') command produces this
>>> error:
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>> trying URL
>>>>>>>>>>>>>> '
>>>>>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>>>>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>>>>>>>>>>>>>> '
>>>>>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
>>> Mb)
>>>>>>>>>>>>>> opened URL
>>>>>>>>>>>>>> downloaded 4.1 Mb
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>>>>> c("Package",
>>>>>>>>>>>>>> "Type")) :
>>>>>>>>>>>>>>        cannot open the connection
>>>>>>>>>>>>>> In addition: Warning messages:
>>>>>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
>>> ...)
>>>>> :
>>>>>>>>>>>>>>        downloaded length 4276224 != reported length 4288136
>>>>>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
>>>> >from zip
>>>>>>>>>>>>>> file
>>>>>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>>>>> c("Package",
>>>>>>>>>>>>>> "Type"))
>>>>>>>>>>>>>> :
>>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
>>> probable
>>>>>>>>>>>>>> reason
>>>>>>>>>>>>>> 'No
>>>>>>>>>>>>>> such
>>>>>>>>>>>>>> file or directory'
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
>>>>> directly
>>>>>>>>>>>>>> from
>>>>>>>>>>>>>> cran
>>>>>>>>>>>>>> site. But this zip file is not a valid archive (cannot
>>> open
>>>>> using
>>>>>>>>>>>>>> winzip).
>>>>>>>>>>>>>> Also trying to install using this downloaded file produces
>>>>> the
>>>>>>>>>>>>>> following
>>>>>>>>>>>>>> error:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
>>>>>>>>>>>>>> win-library/3.0'
>>>>>>>>>>>>>> (as 'lib' is unspecified)
>>>>>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>>>>>        error 1 in extracting from zip file
>>>>>>>>>>>>>> Warning in install.packages :
>>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
>>> probable
>>>>>>>>>>>>>> reason
>>>>>>>>>>>>>> 'No
>>>>>>>>>>>>>> such
>>>>>>>>>>>>>> file or directory'
>>>>>>>>>>>>>> Error in install.packages : cannot open the connection
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> I  downloaded this zip file from multiple sources and
>>> tried
>>>>> to
>>>>>>>>>>>>>> install
>>>>>>>>>>>>>> with
>>>>>>>>>>>>>> same result.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Thanks and Regards
>>>>>> Alpesh
>>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pavneet.arora at uk.rsagroup.com  Mon Apr 21 14:40:06 2014
From: pavneet.arora at uk.rsagroup.com (starter)
Date: Mon, 21 Apr 2014 05:40:06 -0700 (PDT)
Subject: [R] Read.table mucks up headers
In-Reply-To: <5352764F.4040903@statistik.tu-dortmund.de>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
	<1397495399.4315.1.camel@milan>
	<OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
	<1397910654957-4689099.post@n4.nabble.com>
	<5352764F.4040903@statistik.tu-dortmund.de>
Message-ID: <1398084006577-4689185.post@n4.nabble.com>

Hello Uwe

I tried both the options you mentioned but all i get as output then is the
header line and the headers as "row.names" and "X."



--
View this message in context: http://r.789695.n4.nabble.com/Read-table-mucks-up-headers-tp4688742p4689185.html
Sent from the R help mailing list archive at Nabble.com.



From aguitatierra at hotmail.com  Mon Apr 21 14:53:12 2014
From: aguitatierra at hotmail.com (Beatriz R. Gonzalez Dominguez)
Date: Mon, 21 Apr 2014 14:53:12 +0200
Subject: [R] Loop to extract from variables in the workspace
Message-ID: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>

Dear all,

I'm starting to work with loops and I'm stucked on something.
I've been searching and trying different possibilities but I don't get 
to the solution.
I'd be very grateful if you could share any ideas that you think may help.

library("raster")

# All my variables are in the workspace

# This is what I'd like to obtain, but with a loop (I'm working with 
several years and variables).
PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
PE.coords_01_1985 <- extract(RR_1985_1, coords, df=T)
PE.coords_01_1986 <- extract(RR_1986_1, coords, df=T)
PE.coords_01_1987 <- extract(RR_1987_1, coords, df=T)
PE.coords_01_1988 <- extract(RR_1988_1, coords, df=T)
PE.coords_01_1989 <- extract(RR_1989_1, coords, df=T)
PE.coords_01_1990 <- extract(RR_1990_1, coords, df=T)


# This is one of the things I've tried.

for(i in 1981:2010){
file <- c(paste("RR_", i, "_1", sep=""))
extract <- extract(file, coords, df=T)}
names.a <- paste("PE.coords_01_", i, sep="")
assign(names.a, value=extract)
}

# I get the following error.
Error in (function (classes, fdef, mtable) :
unable to find an inherited method for function ?extract?
for signature ?"character", "SpatialPointsDataFrame"?
# I think the error must be something when I'm defining 'file'

Thanks a lot for any help!



From frtog at vestas.com  Mon Apr 21 14:55:22 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Mon, 21 Apr 2014 14:55:22 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <5354FF1C.3000607@gmail.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
	<1398078658.5143.2.camel@milan> <5354FF1C.3000607@gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA54DE@DKRDSEXC016.vestas.net>

Sorry guys

I didn't do my homework, sorry for cluttering the list. I did know about the source argument.

This worked like a charm:

> install.packages(choose.files(), type="source", repos=NULL)
* installing *source* package 'climatol' ...
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* DONE (climatol)

when choosing the cmiatol_2.2.tar.gz file.

Thanks for your help. That still leaves Alpesh out in the limbo :-(

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender.

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: 21. april 2014 13:21
> To: Milan Bouchet-Valat; Frede Aakmann T?gersen
> Cc: r-help at r-project.org; Uwe Ligges; Alpesh Pandya
> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
>
> On 21/04/2014, 7:10 AM, Milan Bouchet-Valat wrote:
> > Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
> >> Hi
> >>
> >> Couldn't find a zip file in the archives.
> >>
> >> Why didn't 'R CMD build' (in a command shell on Windows) not make a
> >> zip file? I did try to build from the climatol library that holds the
> >> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
> >> etc.
> > R CMD build produces *source* packages, and .zip packages are *binary*.
> >
> >> Did you see the debug information on read.fcf? For me it seems like R
> >> has open a file handler to the DESCRIPTION file. Wouldn't the error
> >> already be thrown there and not when read.fcf is called if the .tar.gz
> >> format was the problem?
> >>
> >> I'll try and locate a zip
> > Does install.packages(choose.file(), type="source") work?
>
> That will also need "repos=NULL", or it will go out to a repository to
> look for the package.
>
> That should work if the package doesn't have compiled code.  It will
> handle compiled code only if Frede has the appropriate tools installed.
>
>
> I'm not sure
> > what utils:::menuInstallLocal() does.
>
> It is essentially
>
> install.packages(choose.file(), type="binary", repos=NULL)
>
> so it's not what Frede needs.
>
> Duncan
> >
> >
> > Regards
> >
> >
> >> Sendt fra Samsung mobil
> >>
> >>
> >> -------- Oprindelig meddelelse --------
> >> Fra: Jeff Newmiller
> >> Dato:21/04/2014 09.44 (GMT+01:00)
> >> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
> >> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
> >> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>
> >> Frede... Windows uses zip files (binary, aka pre-compiled format) for
> packages by default, because most installations don't have the development
> tools installed. You need to setup RTools and use the "source" option to
> install_package in order to handle the tar.gz package file, or download and
> install the zip file instead.
> >> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
> >>                                        Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> >> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen"
> <frtog at vestas.com> wrote:
> >>> Well now, I think I have seen something similar to Alpesh.
> >>>
> >>> Recently I needed the climatol package that I have used some time ago.
> >>> It is not maintained anymore but I downloaded the latest version,
> >>> climatol_2.2.tar.gz,  from archives
> >>> (http://cran.r-
> project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> >>> ) . Trying to install that package from local file  using R-3.1.0 on
> >>> Windows 8  resulted in this:
> >>>
> >>> ## From R Console
> >>>> utils:::menuInstallLocal()
> >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>> "Type")) :
> >>>   cannot open the connection
> >>> In addition: Warning messages:
> >>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >>> file
> >>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> >>> :
> >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION',
> probable
> >>> reason 'No such file or directory'
> >>>>
> >>>
> >>> And yes I know where the file is located, since choose.files() is used.
> >>>
> >>> However I tried the same on our linux (R-3.0.2) cluster and it
> >>> succeeded:
> >>>
> >>> [frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> >>> * installing to library
> >>> ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> >>> * installing *source* package ?climatol? ...
> >>> ** R
> >>> ** data
> >>> ** inst
> >>> ** preparing package for lazy loading
> >>> ** help
> >>> *** installing help indices
> >>> ** building package indices
> >>> ** installing vignettes
> >>> ** testing if installed package can be loaded
> >>> * DONE (climatol)
> >>> [frtog at dkrdsfshn2 ~]$ R
> >>>
> >>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> >>> Copyright (C) 2013 The R Foundation for Statistical Computing
> >>> Platform: x86_64-unknown-linux-gnu (64-bit)
> >>>
> >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> >>> You are welcome to redistribute it under certain conditions.
> >>> Type 'license()' or 'licence()' for distribution details.
> >>>
> >>>   Natural language support but running in an English locale
> >>>
> >>> R is a collaborative project with many contributors.
> >>> Type 'contributors()' for more information and
> >>> 'citation()' on how to cite R or R packages in publications.
> >>>
> >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> >>> 'help.start()' for an HTML browser interface to help.
> >>> Type 'q()' to quit R.
> >>>
> >>>> library("climatol")
> >>>> ?rosavent
> >>>> q()
> >>> Save workspace image? [y/n/c]: n
> >>> [frtog at dkrdsfshn2 ~]$
> >>>
> >>>
> >>> Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> >>> whether I could build the package on my Windows box. Only R stuff and
> >>> no foreign language as C, FORTRAN, etc. so it should be easy.
> >>>
> >>> ## Command shell in Windows
> >>> Microsoft Windows [Version 6.2.9200]
> >>> (c) 2012 Microsoft Corporation. All rights reserved.
> >>>
> >>> C:\Users\frtog>cd Desktop
> >>>
> >>> C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> >>> climatol
> >>> * checking for file 'climatol/DESCRIPTION' ... OK
> >>> * preparing 'climatol':
> >>> * checking DESCRIPTION meta-information ... OK
> >>> * checking for LF line-endings in source and make files
> >>> * checking for empty or unneeded directories
> >>> * looking to see if a 'data/datalist' file should be added
> >>> * building 'climatol_2.2.tar.gz'
> >>>
> >>> Now trying to install from that local file I Still got the same error
> >>> as above.
> >>>
> >>>
> >>>
> >>> Trying to do some debugging on read.dcf() (Emacs/ESS)
> >>>
> >>>
> >>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
> >>> Copyright (C) 2014 The R Foundation for Statistical Computing
> >>> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>>
> >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> >>> You are welcome to redistribute it under certain conditions.
> >>> Type 'license()' or 'licence()' for distribution details.
> >>>
> >>>   Natural language support but running in an English locale
> >>>
> >>> R is a collaborative project with many contributors.
> >>> Type 'contributors()' for more information and
> >>> 'citation()' on how to cite R or R packages in publications.
> >>>
> >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> >>> 'help.start()' for an HTML browser interface to help.
> >>> Type 'q()' to quit R.
> >>>
> >>>>> options(chmhelp=FALSE, help_type="text")
> >>>> options(STERM='iESS', str.dendrogram.last="'",
> >>> editor='emacsclient.exe', show.error.locations=TRUE)
> >>>> debug(read.dcf)
> >>>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> >>> debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"),
> c("Package",
> >>> "Type"))
> >>> debug: {
> >>>     if (is.character(file)) {
> >>>         file <- gzfile(file)
> >>>         on.exit(close(file))
> >>>     }
> >>>     if (!inherits(file, "connection"))
> >>>         stop("'file' must be a character string or connection")
> >>>     if (!all)
> >>>         return(.Internal(readDCF(file, fields, keep.white)))
> >>>     .assemble_things_into_a_data_frame <- function(tags, vals,
> >>>         nums) {
> >>>         tf <- factor(tags, levels = unique(tags))
> >>>         cnts <- table(nums, tf)
> >>>      out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> >>>             levels(tf)))
> >>>         if (all(cnts <= 1L)) {
> >>>             out[cbind(nums, tf)] <- vals
> >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> >>>         }
> >>>         else {
> >>>             levs <- colSums(cnts > 1L) == 0L
> >>>             if (any(levs)) {
> >>>                 inds <- tf %in% levels(tf)[levs]
> >>>                 out[cbind(nums[inds], tf[inds])] <- vals[inds]
> >>>             }
> >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> >>>             for (l in levels(tf)[!levs]) {
> >>>                 out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> >>>                 i <- tf == l
> >>>                 out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> >>>             }
> >>>         }
> >>>         out
> >>>     }
> >>>     on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> >>>         add = TRUE)
> >>>     Sys.setlocale("LC_CTYPE", "C")
> >>>     lines <- readLines(file)
> >>>     ind <- grep("^[^[:blank:]][^:]*$", lines)
> >>>     if (length(ind)) {
> >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >>> stop(gettextf("Invalid DCF format.\nRegular lines must have a
> >>> tag.\nOffending lines start with:\n%s",
> >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> >>>     }
> >>>     line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> >>>     nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> >>>     nums <- nums[line_is_not_empty]
> >>>     lines <- lines[line_is_not_empty]
> >>>     line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> >>>         lines)
> >>>     if (any(line_is_escaped_blank))
> >>>         lines[line_is_escaped_blank] <- ""
> >>>     line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> >>>     ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> >>>     if (length(ind)) {
> >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >>> stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> >>> record.\nOffending lines start with:\n%s",
> >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> >>>     }
> >>>     lengths <- rle(cumsum(line_has_tag))$lengths
> >>>     pos <- cumsum(lengths)
> >>>     tags <- sub(":.*", "", lines[line_has_tag])
> >>> lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> >>> lines[line_has_tag])
> >>>     foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> >>>     lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> >>>     lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> >>> vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> >>> "\n"),
> >>>         c(1L, pos[-length(pos)] + 1L), pos)
> >>>     out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> >>>     if (!is.null(fields))
> >>>         out <- out[fields]
> >>>     out
> >>> }
> >>> Browse[2]> str(file)
> >>> chr "climatol_2.2.tar.gz/DESCRIPTION"
> >>> Browse[2]> head(file)
> >>> [1] "climatol_2.2.tar.gz/DESCRIPTION"
> >>> Browse[2]>
> >>> debug: if (is.character(file)) {
> >>>     file <- gzfile(file)
> >>>     on.exit(close(file))
> >>> }
> >>> Browse[2]>
> >>> debug: file <- gzfile(file)
> >>> Browse[2]>
> >>> debug: on.exit(close(file))
> >>> Browse[2]>
> >>> debug: if (!inherits(file, "connection")) stop("'file' must be a
> >>> character string or connection")
> >>> Browse[2]>
> >>> debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> >>> Browse[2]> str(file)
> >>> Classes 'gzfile', 'connection'  atomic [1:1] 3
> >>>   ..- attr(*, "conn_id")=<externalptr>
> >>> Browse[2]> file
> >>>                       description                             class
> >>> "climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> >>>                              mode                              text
> >>>                              "rb"                            "text"
> >>>                            opened                          can read
> >>>                          "closed"                             "yes"
> >>>                         can write
> >>>                             "yes"
> >>> Browse[2]>
> >>> debug: return(.Internal(readDCF(file, fields, keep.white)))
> >>> Browse[2]>
> >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>> "Type")) :
> >>>   cannot open the connection
> >>> In addition: Warning message:
> >>> In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION',
> probable
> >>> reason 'No such file or directory'
> >>>>
> >>>
> >>> Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> >>> keep.white))) I loose control and R returns to prompt with an error.
> >>>
> >>> Hopefully one of you can replicate this. If not then it must have
> >>> something with Windows OS to do. But what?
> >>>
> >>>
> >>>
> >>> Yours sincerely / Med venlig hilsen
> >>>
> >>>
> >>> Frede Aakmann T?gersen
> >>> Specialist, M.Sc., Ph.D.
> >>> Plant Performance & Modeling
> >>>
> >>> Technology & Service Solutions
> >>> T +45 9730 5135
> >>> M +45 2547 6050
> >>> frtog at vestas.com
> >>> http://www.vestas.com
> >>>
> >>> Company reg. name: Vestas Wind Systems A/S
> >>> This e-mail is subject to our e-mail disclaimer statement.
> >>> Please refer to
> www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> >>> If you have received this e-mail in error please contact the sender.
> >>>
> >>>> -----Original Message-----
> >>>> From: r-help-bounces at r-project.org
> >>> [mailto:r-help-bounces at r-project.org]
> >>>> On Behalf Of Jeff Newmiller
> >>>> Sent: 20. april 2014 23:33
> >>>> To: Alpesh Pandya; Rui Barradas
> >>>> Cc: r-help at r-project.org; Uwe Ligges
> >>>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>>>
> >>>> Hard to help you when the problem simply does not happen for others.
> >>>>
> >>>> As for Windows being not a focus, that is not at all true. I use it
> >>> regularly on
> >>>> Windows at work. That being said, there are thousands of packages
> and
> >>>> those each involve their own subset of R users. There are also many
> >>>> operating system configurations that may not all be fully tested.
> >>> Blaming "R"
> >>>> or "Windows", or blaming us for "preventing" you from getting your
> >>>> education (isn't that something between you and your educational
> >>>> institution?) are not going to be effective strategies for problem
> >>> solving.
> >>>>
> >>>> Are you able to use other aspects of R beyond the XML package? Have
> >>> you
> >>>> tried communicating with the maintainers of that package?
> >>>>
> >>> ---------------------------------------------------------------------------
> >>>> Jeff Newmiller                        The     .....       .....  Go
> >>> Live...
> >>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>> Go...
> >>>>                                        Live:   OO#.. Dead: OO#..
> >>> Playing
> >>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> rocks...1k
> >>>>
> >>> ---------------------------------------------------------------------------
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> >>>> <alpeshpandya at gmail.com> wrote:
> >>>>> I keep on trying from various networks but I still get the same
> >>> error.
> >>>>> I
> >>>>> don't this this has anything to do with network or ability to
> >>> download
> >>>>> the
> >>>>> package (as I can install other packages fine). This must be
> >>> something
> >>>>> in
> >>>>> base R or dependencies issues (that R is not spelling out).
> >>>>>
> >>>>> I know R is geared for Mac and Windows is kind of looked down upon
> >>> but
> >>>>> I
> >>>>> have no option but use windows and need this XML package running
> to
> >>>>> complete my education. Any help on this would be appreciated.
> >>>>>
> >>>>>
> >>>>> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> >>>>> <alpeshpandya at gmail.com>wrote:
> >>>>>
> >>>>>> Thank you for response Rui.
> >>>>>>
> >>>>>> I still get the same error with this repository.
> >>>>>>
> >>>>>> Installing package into
> >>>>> ???C:/Users/APandya/Documents/R/win-library/3.0???
> >>>>>> (as ???lib??? is unspecified)
> >>>>>> trying URL '
> >>>>>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>> opened URL
> >>>>>> downloaded 4.1 Mb
> >>>>>>
> >>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>>>> "Type"))
> >>>>>> :
> >>>>>>    cannot open the connection
> >>>>>> In addition: Warning messages:
> >>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >>>>>>    downloaded length 4276224 != reported length 4288136
> >>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> >>> zip
> >>>>> file
> >>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>>>> "Type")) :
> >>>>>>    cannot open compressed file 'XML/DESCRIPTION', probable reason
> >>> 'No
> >>>>> such
> >>>>>> file or directory'
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> >>>>> <ruipbarradas at sapo.pt>wrote:
> >>>>>>
> >>>>>>> Hello,
> >>>>>>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >>>>> problem
> >>>>>>> at all. Can't you try (it worked with me)
> >>>>>>>
> >>>>>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >>>>>>>
> >>>>>>>   I have tried these sources (almost all US mirrors):
> >>>>>>>>
> >>>>>>>>
> >>>>
> >>>> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-
> 1.1.zip
> >>>>>>>>
> >>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >>>>>>>> 3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-
> 1.1.zip
> >>>>>>>>
> >>>>
> >>>> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-
> 1.1.zip
> >>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>
> >>>> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-
> 1.1.zip
> >>>>>>>>
> >>>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> >>>> 1.1.zip
> >>>>>>>>
> >>>>>>>> I have confirmed with IT that there is no restriction on
> >>>>> downloading this
> >>>>>>>> zip file from any of these sources. Also I am getting same error
> >>>>> when I
> >>>>>>>> try
> >>>>>>>> from my home network as well.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >>>>>>>>>
> >>>>>>>>>   @Uwe I tried the same steps from office as well as home
> >>> network
> >>>>> with
> >>>>>>>>>> same
> >>>>>>>>>> results. Are you using windows 7 with R 3.0.3?
> >>>>>>>>>>
> >>>>>>>>>> I have seen same question being asked by others without any
> >>>>>>>>>> resolution. Is
> >>>>>>>>>> anything special about XML package? I am OK use older version
> >>> of
> >>>>>>>>>> package
> >>>>>>>>>> but in archives there are no zip files (only gz files). Is
> >>>>> windows
> >>>>>>>>>> platform
> >>>>>>>>>> not recommended for R?
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>> Right, and you can try to install these from sources.
> >>>>>>>>> But I doubt you need it. You still have not told us if you
> >>> tried
> >>>>> another
> >>>>>>>>> mirror to download the XML file from and what you local IT
> >>> support
> >>>>> tells
> >>>>>>>>> you while your downloads are incomplete.
> >>>>>>>>>
> >>>>>>>>> Best,
> >>>>>>>>> Uwe Ligges
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >>>>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>>>
> >>>>>>>>>>   wrote:
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >>>>>>>>>>>
> >>>>>>>>>>>    Thank you for response Uwe. I tried multiple times by
> >>>>> downloading
> >>>>>>>>>>> the
> >>>>>>>>>>>
> >>>>>>>>>>>> zip
> >>>>>>>>>>>> file from many sources but still the same error. This is a
> >>>>> major road
> >>>>>>>>>>>> block
> >>>>>>>>>>>> for me in using R. Appreciate any help on this.
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>   Please ask your local IT staff.
> >>>>>>>>>>>
> >>>>>>>>>>> I get, using the same mirror:
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>> options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >>>>>>>>>>>
> >>>>>>>>>>>> install.packages("XML", lib="d:/temp")
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>> trying URL
> >>> 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>>>>>
> >>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>>>>>>> opened URL
> >>>>>>>>>>> downloaded 4.1 Mb
> >>>>>>>>>>>
> >>>>>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >>>>>>>>>>>
> >>>>>>>>>>> The downloaded binary packages are in
> >>>>>>>>>>>            d:\temp\RtmpqMqL8L\downloaded_packages
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> Best,
> >>>>>>>>>>> Uwe Ligges
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >>>>>>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>>>>>
> >>>>>>>>>>>>    wrote:
> >>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>      Works for me.
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>> Best,
> >>>>>>>>>>>>> Uwe Ligges
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>     Using install.package('XML') command produces this
> >>> error:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>> trying URL
> >>>>>>>>>>>>>> '
> >>>>>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>>>>>>> '
> >>>>>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> >>> Mb)
> >>>>>>>>>>>>>> opened URL
> >>>>>>>>>>>>>> downloaded 4.1 Mb
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >>>>> c("Package",
> >>>>>>>>>>>>>> "Type")) :
> >>>>>>>>>>>>>>        cannot open the connection
> >>>>>>>>>>>>>> In addition: Warning messages:
> >>>>>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> >>> ...)
> >>>>> :
> >>>>>>>>>>>>>>        downloaded length 4276224 != reported length
> 4288136
> >>>>>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >>>> >from zip
> >>>>>>>>>>>>>> file
> >>>>>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >>>>> c("Package",
> >>>>>>>>>>>>>> "Type"))
> >>>>>>>>>>>>>> :
> >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> >>> probable
> >>>>>>>>>>>>>> reason
> >>>>>>>>>>>>>> 'No
> >>>>>>>>>>>>>> such
> >>>>>>>>>>>>>> file or directory'
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >>>>> directly
> >>>>>>>>>>>>>> from
> >>>>>>>>>>>>>> cran
> >>>>>>>>>>>>>> site. But this zip file is not a valid archive (cannot
> >>> open
> >>>>> using
> >>>>>>>>>>>>>> winzip).
> >>>>>>>>>>>>>> Also trying to install using this downloaded file produces
> >>>>> the
> >>>>>>>>>>>>>> following
> >>>>>>>>>>>>>> error:
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >>>>>>>>>>>>>> win-library/3.0'
> >>>>>>>>>>>>>> (as 'lib' is unspecified)
> >>>>>>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>>>>>        error 1 in extracting from zip file
> >>>>>>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> >>> probable
> >>>>>>>>>>>>>> reason
> >>>>>>>>>>>>>> 'No
> >>>>>>>>>>>>>> such
> >>>>>>>>>>>>>> file or directory'
> >>>>>>>>>>>>>> Error in install.packages : cannot open the connection
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> I  downloaded this zip file from multiple sources and
> >>> tried
> >>>>> to
> >>>>>>>>>>>>>> install
> >>>>>>>>>>>>>> with
> >>>>>>>>>>>>>> same result.
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Thanks and Regards
> >>>>>> Alpesh
> >>>>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>>> guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>    [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From frtog at vestas.com  Mon Apr 21 15:17:06 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 21 Apr 2014 15:17:06 +0200
Subject: [R] Loop to extract from variables in the workspace
In-Reply-To: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>
References: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA54EA@DKRDSEXC016.vestas.net>

Hi Beatriz

Did you read the help for extract{raster} carefully?

Several things can be wrong.

1) First argument to extract is not a file name but a raster object.
2) In the loop you name an object extract as an intermediate name to hold the result from the extract function. Do you think there could be a name clash? R is clever but perhaps not clever enough.
3) coords are of the right class (see ?extract).
4) assign can be useful from time to time. But in a loop?

I think the things you are doing are some intermediate results that needs more processing. Do you think this is the right way to do that. For instance instead of storing the immediate result as separate objects why not store those in a list.

Perhaps if you tell us what you would like to do  overall, i.e. from first to last, then we will be able to help you to become more efficient.  


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Beatriz R. Gonzalez Dominguez
> Sent: 21. april 2014 14:53
> To: r-help at r-project.org
> Subject: [R] Loop to extract from variables in the workspace
> 
> Dear all,
> 
> I'm starting to work with loops and I'm stucked on something.
> I've been searching and trying different possibilities but I don't get
> to the solution.
> I'd be very grateful if you could share any ideas that you think may help.
> 
> library("raster")
> 
> # All my variables are in the workspace
> 
> # This is what I'd like to obtain, but with a loop (I'm working with
> several years and variables).
> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
> PE.coords_01_1985 <- extract(RR_1985_1, coords, df=T)
> PE.coords_01_1986 <- extract(RR_1986_1, coords, df=T)
> PE.coords_01_1987 <- extract(RR_1987_1, coords, df=T)
> PE.coords_01_1988 <- extract(RR_1988_1, coords, df=T)
> PE.coords_01_1989 <- extract(RR_1989_1, coords, df=T)
> PE.coords_01_1990 <- extract(RR_1990_1, coords, df=T)
> 
> 
> # This is one of the things I've tried.
> 
> for(i in 1981:2010){
> file <- c(paste("RR_", i, "_1", sep=""))
> extract <- extract(file, coords, df=T)}
> names.a <- paste("PE.coords_01_", i, sep="")
> assign(names.a, value=extract)
> }
> 
> # I get the following error.
> Error in (function (classes, fdef, mtable) :
> unable to find an inherited method for function 'extract'
> for signature '"character", "SpatialPointsDataFrame"'
> # I think the error must be something when I'm defining 'file'
> 
> Thanks a lot for any help!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nalimilan at club.fr  Mon Apr 21 15:19:43 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 21 Apr 2014 15:19:43 +0200
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <5354FF1C.3000607@gmail.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
	<1398078658.5143.2.camel@milan> <5354FF1C.3000607@gmail.com>
Message-ID: <1398086383.5143.24.camel@milan>

Le lundi 21 avril 2014 ? 07:21 -0400, Duncan Murdoch a ?crit :
> On 21/04/2014, 7:10 AM, Milan Bouchet-Valat wrote:
> > Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
> >> Hi
> >>
> >> Couldn't find a zip file in the archives.
> >>
> >> Why didn't 'R CMD build' (in a command shell on Windows) not make a
> >> zip file? I did try to build from the climatol library that holds the
> >> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
> >> etc.
> > R CMD build produces *source* packages, and .zip packages are *binary*.
> >
> >> Did you see the debug information on read.fcf? For me it seems like R
> >> has open a file handler to the DESCRIPTION file. Wouldn't the error
> >> already be thrown there and not when read.fcf is called if the .tar.gz
> >> format was the problem?
> >>
> >> I'll try and locate a zip
> > Does install.packages(choose.file(), type="source") work?
> 
> That will also need "repos=NULL", or it will go out to a repository to 
> look for the package.
Usually install.packages() prints a warning and assumes repos=NULL iwhen
type="source". And since I'm lazy, I've sticked to the short
version. ;-)

> That should work if the package doesn't have compiled code.  It will 
> handle compiled code only if Frede has the appropriate tools installed.
> 
> 
> I'm not sure
> > what utils:::menuInstallLocal() does.
> 
> It is essentially
> 
> install.packages(choose.file(), type="binary", repos=NULL)
> 
> so it's not what Frede needs.
OK, so that's what I suspected.


Regards

> Duncan
> >
> >
> > Regards
> >
> >
> >> Sendt fra Samsung mobil
> >>
> >>
> >> -------- Oprindelig meddelelse --------
> >> Fra: Jeff Newmiller
> >> Dato:21/04/2014 09.44 (GMT+01:00)
> >> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
> >> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
> >> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>
> >> Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
> >> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
> >>                                        Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> >> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
> >>> Well now, I think I have seen something similar to Alpesh.
> >>>
> >>> Recently I needed the climatol package that I have used some time ago.
> >>> It is not maintained anymore but I downloaded the latest version,
> >>> climatol_2.2.tar.gz,  from archives
> >>> (http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> >>> ) . Trying to install that package from local file  using R-3.1.0 on
> >>> Windows 8  resulted in this:
> >>>
> >>> ## From R Console
> >>>> utils:::menuInstallLocal()
> >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>> "Type")) :
> >>>   cannot open the connection
> >>> In addition: Warning messages:
> >>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> >>> file
> >>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> >>> :
> >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >>> reason 'No such file or directory'
> >>>>
> >>>
> >>> And yes I know where the file is located, since choose.files() is used.
> >>>
> >>> However I tried the same on our linux (R-3.0.2) cluster and it
> >>> succeeded:
> >>>
> >>> [frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> >>> * installing to library
> >>> ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> >>> * installing *source* package ?climatol? ...
> >>> ** R
> >>> ** data
> >>> ** inst
> >>> ** preparing package for lazy loading
> >>> ** help
> >>> *** installing help indices
> >>> ** building package indices
> >>> ** installing vignettes
> >>> ** testing if installed package can be loaded
> >>> * DONE (climatol)
> >>> [frtog at dkrdsfshn2 ~]$ R
> >>>
> >>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> >>> Copyright (C) 2013 The R Foundation for Statistical Computing
> >>> Platform: x86_64-unknown-linux-gnu (64-bit)
> >>>
> >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> >>> You are welcome to redistribute it under certain conditions.
> >>> Type 'license()' or 'licence()' for distribution details.
> >>>
> >>>   Natural language support but running in an English locale
> >>>
> >>> R is a collaborative project with many contributors.
> >>> Type 'contributors()' for more information and
> >>> 'citation()' on how to cite R or R packages in publications.
> >>>
> >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> >>> 'help.start()' for an HTML browser interface to help.
> >>> Type 'q()' to quit R.
> >>>
> >>>> library("climatol")
> >>>> ?rosavent
> >>>> q()
> >>> Save workspace image? [y/n/c]: n
> >>> [frtog at dkrdsfshn2 ~]$
> >>>
> >>>
> >>> Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> >>> whether I could build the package on my Windows box. Only R stuff and
> >>> no foreign language as C, FORTRAN, etc. so it should be easy.
> >>>
> >>> ## Command shell in Windows
> >>> Microsoft Windows [Version 6.2.9200]
> >>> (c) 2012 Microsoft Corporation. All rights reserved.
> >>>
> >>> C:\Users\frtog>cd Desktop
> >>>
> >>> C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> >>> climatol
> >>> * checking for file 'climatol/DESCRIPTION' ... OK
> >>> * preparing 'climatol':
> >>> * checking DESCRIPTION meta-information ... OK
> >>> * checking for LF line-endings in source and make files
> >>> * checking for empty or unneeded directories
> >>> * looking to see if a 'data/datalist' file should be added
> >>> * building 'climatol_2.2.tar.gz'
> >>>
> >>> Now trying to install from that local file I Still got the same error
> >>> as above.
> >>>
> >>>
> >>>
> >>> Trying to do some debugging on read.dcf() (Emacs/ESS)
> >>>
> >>>
> >>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
> >>> Copyright (C) 2014 The R Foundation for Statistical Computing
> >>> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>>
> >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> >>> You are welcome to redistribute it under certain conditions.
> >>> Type 'license()' or 'licence()' for distribution details.
> >>>
> >>>   Natural language support but running in an English locale
> >>>
> >>> R is a collaborative project with many contributors.
> >>> Type 'contributors()' for more information and
> >>> 'citation()' on how to cite R or R packages in publications.
> >>>
> >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> >>> 'help.start()' for an HTML browser interface to help.
> >>> Type 'q()' to quit R.
> >>>
> >>>>> options(chmhelp=FALSE, help_type="text")
> >>>> options(STERM='iESS', str.dendrogram.last="'",
> >>> editor='emacsclient.exe', show.error.locations=TRUE)
> >>>> debug(read.dcf)
> >>>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> >>> debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>> "Type"))
> >>> debug: {
> >>>     if (is.character(file)) {
> >>>         file <- gzfile(file)
> >>>         on.exit(close(file))
> >>>     }
> >>>     if (!inherits(file, "connection"))
> >>>         stop("'file' must be a character string or connection")
> >>>     if (!all)
> >>>         return(.Internal(readDCF(file, fields, keep.white)))
> >>>     .assemble_things_into_a_data_frame <- function(tags, vals,
> >>>         nums) {
> >>>         tf <- factor(tags, levels = unique(tags))
> >>>         cnts <- table(nums, tf)
> >>>      out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> >>>             levels(tf)))
> >>>         if (all(cnts <= 1L)) {
> >>>             out[cbind(nums, tf)] <- vals
> >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> >>>         }
> >>>         else {
> >>>             levs <- colSums(cnts > 1L) == 0L
> >>>             if (any(levs)) {
> >>>                 inds <- tf %in% levels(tf)[levs]
> >>>                 out[cbind(nums[inds], tf[inds])] <- vals[inds]
> >>>             }
> >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> >>>             for (l in levels(tf)[!levs]) {
> >>>                 out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> >>>                 i <- tf == l
> >>>                 out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> >>>             }
> >>>         }
> >>>         out
> >>>     }
> >>>     on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> >>>         add = TRUE)
> >>>     Sys.setlocale("LC_CTYPE", "C")
> >>>     lines <- readLines(file)
> >>>     ind <- grep("^[^[:blank:]][^:]*$", lines)
> >>>     if (length(ind)) {
> >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >>> stop(gettextf("Invalid DCF format.\nRegular lines must have a
> >>> tag.\nOffending lines start with:\n%s",
> >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> >>>     }
> >>>     line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> >>>     nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> >>>     nums <- nums[line_is_not_empty]
> >>>     lines <- lines[line_is_not_empty]
> >>>     line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> >>>         lines)
> >>>     if (any(line_is_escaped_blank))
> >>>         lines[line_is_escaped_blank] <- ""
> >>>     line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> >>>     ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> >>>     if (length(ind)) {
> >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> >>> stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> >>> record.\nOffending lines start with:\n%s",
> >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> >>>     }
> >>>     lengths <- rle(cumsum(line_has_tag))$lengths
> >>>     pos <- cumsum(lengths)
> >>>     tags <- sub(":.*", "", lines[line_has_tag])
> >>> lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> >>> lines[line_has_tag])
> >>>     foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> >>>     lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> >>>     lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> >>> vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> >>> "\n"),
> >>>         c(1L, pos[-length(pos)] + 1L), pos)
> >>>     out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> >>>     if (!is.null(fields))
> >>>         out <- out[fields]
> >>>     out
> >>> }
> >>> Browse[2]> str(file)
> >>> chr "climatol_2.2.tar.gz/DESCRIPTION"
> >>> Browse[2]> head(file)
> >>> [1] "climatol_2.2.tar.gz/DESCRIPTION"
> >>> Browse[2]>
> >>> debug: if (is.character(file)) {
> >>>     file <- gzfile(file)
> >>>     on.exit(close(file))
> >>> }
> >>> Browse[2]>
> >>> debug: file <- gzfile(file)
> >>> Browse[2]>
> >>> debug: on.exit(close(file))
> >>> Browse[2]>
> >>> debug: if (!inherits(file, "connection")) stop("'file' must be a
> >>> character string or connection")
> >>> Browse[2]>
> >>> debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> >>> Browse[2]> str(file)
> >>> Classes 'gzfile', 'connection'  atomic [1:1] 3
> >>>   ..- attr(*, "conn_id")=<externalptr>
> >>> Browse[2]> file
> >>>                       description                             class
> >>> "climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> >>>                              mode                              text
> >>>                              "rb"                            "text"
> >>>                            opened                          can read
> >>>                          "closed"                             "yes"
> >>>                         can write
> >>>                             "yes"
> >>> Browse[2]>
> >>> debug: return(.Internal(readDCF(file, fields, keep.white)))
> >>> Browse[2]>
> >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>> "Type")) :
> >>>   cannot open the connection
> >>> In addition: Warning message:
> >>> In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> >>> reason 'No such file or directory'
> >>>>
> >>>
> >>> Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> >>> keep.white))) I loose control and R returns to prompt with an error.
> >>>
> >>> Hopefully one of you can replicate this. If not then it must have
> >>> something with Windows OS to do. But what?
> >>>
> >>>
> >>>
> >>> Yours sincerely / Med venlig hilsen
> >>>
> >>>
> >>> Frede Aakmann T?gersen
> >>> Specialist, M.Sc., Ph.D.
> >>> Plant Performance & Modeling
> >>>
> >>> Technology & Service Solutions
> >>> T +45 9730 5135
> >>> M +45 2547 6050
> >>> frtog at vestas.com
> >>> http://www.vestas.com
> >>>
> >>> Company reg. name: Vestas Wind Systems A/S
> >>> This e-mail is subject to our e-mail disclaimer statement.
> >>> Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> >>> If you have received this e-mail in error please contact the sender.
> >>>
> >>>> -----Original Message-----
> >>>> From: r-help-bounces at r-project.org
> >>> [mailto:r-help-bounces at r-project.org]
> >>>> On Behalf Of Jeff Newmiller
> >>>> Sent: 20. april 2014 23:33
> >>>> To: Alpesh Pandya; Rui Barradas
> >>>> Cc: r-help at r-project.org; Uwe Ligges
> >>>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> >>>>
> >>>> Hard to help you when the problem simply does not happen for others.
> >>>>
> >>>> As for Windows being not a focus, that is not at all true. I use it
> >>> regularly on
> >>>> Windows at work. That being said, there are thousands of packages and
> >>>> those each involve their own subset of R users. There are also many
> >>>> operating system configurations that may not all be fully tested.
> >>> Blaming "R"
> >>>> or "Windows", or blaming us for "preventing" you from getting your
> >>>> education (isn't that something between you and your educational
> >>>> institution?) are not going to be effective strategies for problem
> >>> solving.
> >>>>
> >>>> Are you able to use other aspects of R beyond the XML package? Have
> >>> you
> >>>> tried communicating with the maintainers of that package?
> >>>>
> >>> ---------------------------------------------------------------------------
> >>>> Jeff Newmiller                        The     .....       .....  Go
> >>> Live...
> >>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>> Go...
> >>>>                                        Live:   OO#.. Dead: OO#..
> >>> Playing
> >>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> rocks...1k
> >>>>
> >>> ---------------------------------------------------------------------------
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> >>>> <alpeshpandya at gmail.com> wrote:
> >>>>> I keep on trying from various networks but I still get the same
> >>> error.
> >>>>> I
> >>>>> don't this this has anything to do with network or ability to
> >>> download
> >>>>> the
> >>>>> package (as I can install other packages fine). This must be
> >>> something
> >>>>> in
> >>>>> base R or dependencies issues (that R is not spelling out).
> >>>>>
> >>>>> I know R is geared for Mac and Windows is kind of looked down upon
> >>> but
> >>>>> I
> >>>>> have no option but use windows and need this XML package running to
> >>>>> complete my education. Any help on this would be appreciated.
> >>>>>
> >>>>>
> >>>>> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> >>>>> <alpeshpandya at gmail.com>wrote:
> >>>>>
> >>>>>> Thank you for response Rui.
> >>>>>>
> >>>>>> I still get the same error with this repository.
> >>>>>>
> >>>>>> Installing package into
> >>>>> ???C:/Users/APandya/Documents/R/win-library/3.0???
> >>>>>> (as ???lib??? is unspecified)
> >>>>>> trying URL '
> >>>>>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>> opened URL
> >>>>>> downloaded 4.1 Mb
> >>>>>>
> >>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>>>> "Type"))
> >>>>>> :
> >>>>>>    cannot open the connection
> >>>>>> In addition: Warning messages:
> >>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> >>>>>>    downloaded length 4276224 != reported length 4288136
> >>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> >>> zip
> >>>>> file
> >>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> >>>>> "Type")) :
> >>>>>>    cannot open compressed file 'XML/DESCRIPTION', probable reason
> >>> 'No
> >>>>> such
> >>>>>> file or directory'
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> >>>>> <ruipbarradas at sapo.pt>wrote:
> >>>>>>
> >>>>>>> Hello,
> >>>>>>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> >>>>> problem
> >>>>>>> at all. Can't you try (it worked with me)
> >>>>>>>
> >>>>>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> >>>>>>>
> >>>>>>>   I have tried these sources (almost all US mirrors):
> >>>>>>>>
> >>>>>>>>
> >>>>
> >>>> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> >>>>>>>> 3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>
> >>>> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>
> >>>> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>
> >>>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> >>>> 1.1.zip
> >>>>>>>>
> >>>>>>>> I have confirmed with IT that there is no restriction on
> >>>>> downloading this
> >>>>>>>> zip file from any of these sources. Also I am getting same error
> >>>>> when I
> >>>>>>>> try
> >>>>>>>> from my home network as well.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> >>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> >>>>>>>>>
> >>>>>>>>>   @Uwe I tried the same steps from office as well as home
> >>> network
> >>>>> with
> >>>>>>>>>> same
> >>>>>>>>>> results. Are you using windows 7 with R 3.0.3?
> >>>>>>>>>>
> >>>>>>>>>> I have seen same question being asked by others without any
> >>>>>>>>>> resolution. Is
> >>>>>>>>>> anything special about XML package? I am OK use older version
> >>> of
> >>>>>>>>>> package
> >>>>>>>>>> but in archives there are no zip files (only gz files). Is
> >>>>> windows
> >>>>>>>>>> platform
> >>>>>>>>>> not recommended for R?
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>> Right, and you can try to install these from sources.
> >>>>>>>>> But I doubt you need it. You still have not told us if you
> >>> tried
> >>>>> another
> >>>>>>>>> mirror to download the XML file from and what you local IT
> >>> support
> >>>>> tells
> >>>>>>>>> you while your downloads are incomplete.
> >>>>>>>>>
> >>>>>>>>> Best,
> >>>>>>>>> Uwe Ligges
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> >>>>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>>>
> >>>>>>>>>>   wrote:
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> >>>>>>>>>>>
> >>>>>>>>>>>    Thank you for response Uwe. I tried multiple times by
> >>>>> downloading
> >>>>>>>>>>> the
> >>>>>>>>>>>
> >>>>>>>>>>>> zip
> >>>>>>>>>>>> file from many sources but still the same error. This is a
> >>>>> major road
> >>>>>>>>>>>> block
> >>>>>>>>>>>> for me in using R. Appreciate any help on this.
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>   Please ask your local IT staff.
> >>>>>>>>>>>
> >>>>>>>>>>> I get, using the same mirror:
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>> options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> >>>>>>>>>>>
> >>>>>>>>>>>> install.packages("XML", lib="d:/temp")
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>> trying URL
> >>> 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>>>>>
> >>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> >>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> >>>>>>>>>>> opened URL
> >>>>>>>>>>> downloaded 4.1 Mb
> >>>>>>>>>>>
> >>>>>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> >>>>>>>>>>>
> >>>>>>>>>>> The downloaded binary packages are in
> >>>>>>>>>>>            d:\temp\RtmpqMqL8L\downloaded_packages
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> Best,
> >>>>>>>>>>> Uwe Ligges
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> >>>>>>>>>>>> ligges at statistik.tu-dortmund.de
> >>>>>>>>>>>>
> >>>>>>>>>>>>    wrote:
> >>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>      Works for me.
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>> Best,
> >>>>>>>>>>>>> Uwe Ligges
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>     Using install.package('XML') command produces this
> >>> error:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>> trying URL
> >>>>>>>>>>>>>> '
> >>>>>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> >>>>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> >>>>>>>>>>>>>> '
> >>>>>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> >>> Mb)
> >>>>>>>>>>>>>> opened URL
> >>>>>>>>>>>>>> downloaded 4.1 Mb
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> >>>>> c("Package",
> >>>>>>>>>>>>>> "Type")) :
> >>>>>>>>>>>>>>        cannot open the connection
> >>>>>>>>>>>>>> In addition: Warning messages:
> >>>>>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> >>> ...)
> >>>>> :
> >>>>>>>>>>>>>>        downloaded length 4276224 != reported length 4288136
> >>>>>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> >>>> >from zip
> >>>>>>>>>>>>>> file
> >>>>>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> >>>>> c("Package",
> >>>>>>>>>>>>>> "Type"))
> >>>>>>>>>>>>>> :
> >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> >>> probable
> >>>>>>>>>>>>>> reason
> >>>>>>>>>>>>>> 'No
> >>>>>>>>>>>>>> such
> >>>>>>>>>>>>>> file or directory'
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> >>>>> directly
> >>>>>>>>>>>>>> from
> >>>>>>>>>>>>>> cran
> >>>>>>>>>>>>>> site. But this zip file is not a valid archive (cannot
> >>> open
> >>>>> using
> >>>>>>>>>>>>>> winzip).
> >>>>>>>>>>>>>> Also trying to install using this downloaded file produces
> >>>>> the
> >>>>>>>>>>>>>> following
> >>>>>>>>>>>>>> error:
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> >>>>>>>>>>>>>> win-library/3.0'
> >>>>>>>>>>>>>> (as 'lib' is unspecified)
> >>>>>>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>>>>>        error 1 in extracting from zip file
> >>>>>>>>>>>>>> Warning in install.packages :
> >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> >>> probable
> >>>>>>>>>>>>>> reason
> >>>>>>>>>>>>>> 'No
> >>>>>>>>>>>>>> such
> >>>>>>>>>>>>>> file or directory'
> >>>>>>>>>>>>>> Error in install.packages : cannot open the connection
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> I  downloaded this zip file from multiple sources and
> >>> tried
> >>>>> to
> >>>>>>>>>>>>>> install
> >>>>>>>>>>>>>> with
> >>>>>>>>>>>>>> same result.
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Thanks and Regards
> >>>>>> Alpesh
> >>>>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>>> guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >



From smartpink111 at yahoo.com  Mon Apr 21 15:19:49 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 Apr 2014 06:19:49 -0700 (PDT)
Subject: [R] Loops (run the same function per different columns)
Message-ID: <1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

Using the example data from library(gvlma)

library(gvlma)
data(CarMileageData)
CarMileageNew <- CarMileageData[,c(5,6,3)]
?lst1 <- list()
?y <- c("NumGallons", "NumDaysBetw")
?for(i in seq_along(y)){
?lst1[[i]] <- gvlma(lm(get(y[i])~MilesLastFill,data=CarMileageNew))
?lst1}
pdf("gvlmaplot.pdf")
?lapply(lst1,plot)
dev.off()


You could also use ?lapply().


A.K.



Hi
I have a spread sheet with a column Samples (column1) and then 34 more columns with different concentrations of fatty acids per sample. Im trying to run the same function 34 times. In this case (the first of 34), I have a fatty acid called C14.0 (column 2). I'm a newbie with R so I spent the last 4 days looking for a way of doing it (without running the same function 34 times with a different fatty acid each time). I saw that people do similar things with loops but I cannot get them to work.
I have tried the script below but it does not work.

y<-c("C14.0","C15.0","C16.0")
for (i in y) {
FA.ml=lm(i~Sample,data=FA)
gvlmaFA<-gvlma(FA.ml)
gvlmaFA
}


I really appreciate if someone can give me a hand with that. I know would have been finished if I had typed the 34 fatty acids but I want to learn how to do it with loops.
Cheers 




From murdoch.duncan at gmail.com  Mon Apr 21 15:28:28 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Apr 2014 09:28:28 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <1398086383.5143.24.camel@milan>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>	<1398078658.5143.2.camel@milan>
	<5354FF1C.3000607@gmail.com> <1398086383.5143.24.camel@milan>
Message-ID: <53551CFC.8000307@gmail.com>

On 21/04/2014 9:19 AM, Milan Bouchet-Valat wrote:
> Le lundi 21 avril 2014 ? 07:21 -0400, Duncan Murdoch a ?crit :
> > On 21/04/2014, 7:10 AM, Milan Bouchet-Valat wrote:
> > > Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann T?gersen a ?crit :
> > >> Hi
> > >>
> > >> Couldn't find a zip file in the archives.
> > >>
> > >> Why didn't 'R CMD build' (in a command shell on Windows) not make a
> > >> zip file? I did try to build from the climatol library that holds the
> > >> typical files as DESCRIPTION, LICENSE, etc. as well as folders like R,
> > >> etc.
> > > R CMD build produces *source* packages, and .zip packages are *binary*.
> > >
> > >> Did you see the debug information on read.fcf? For me it seems like R
> > >> has open a file handler to the DESCRIPTION file. Wouldn't the error
> > >> already be thrown there and not when read.fcf is called if the .tar.gz
> > >> format was the problem?
> > >>
> > >> I'll try and locate a zip
> > > Does install.packages(choose.file(), type="source") work?
> >
> > That will also need "repos=NULL", or it will go out to a repository to
> > look for the package.
> Usually install.packages() prints a warning and assumes repos=NULL iwhen
> type="source". And since I'm lazy, I've sticked to the short
> version. ;-)

Right, if the file is a .tar.gz file, it does that.  I often install 
directly from source directories, and there it fails.

Duncan Murdoch

>
> > That should work if the package doesn't have compiled code.  It will
> > handle compiled code only if Frede has the appropriate tools installed.
> >
> >
> > I'm not sure
> > > what utils:::menuInstallLocal() does.
> >
> > It is essentially
> >
> > install.packages(choose.file(), type="binary", repos=NULL)
> >
> > so it's not what Frede needs.
> OK, so that's what I suspected.
>
>
> Regards
>
> > Duncan
> > >
> > >
> > > Regards
> > >
> > >
> > >> Sendt fra Samsung mobil
> > >>
> > >>
> > >> -------- Oprindelig meddelelse --------
> > >> Fra: Jeff Newmiller
> > >> Dato:21/04/2014 09.44 (GMT+01:00)
> > >> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
> > >> Cc: r-help at r-project.org,Uwe Ligges ,Duncan Murdoch
> > >> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML package
> > >>
> > >> Frede... Windows uses zip files (binary, aka pre-compiled format) for packages by default, because most installations don't have the development tools installed. You need to setup RTools and use the "source" option to install_package in order to handle the tar.gz package file, or download and install the zip file instead.
> > >> ---------------------------------------------------------------------------
> > >> Jeff Newmiller                        The     .....       .....  Go Live...
> > >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
> > >>                                        Live:   OO#.. Dead: OO#..  Playing
> > >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > >> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> > >> ---------------------------------------------------------------------------
> > >> Sent from my phone. Please excuse my brevity.
> > >>
> > >> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann T?gersen" <frtog at vestas.com> wrote:
> > >>> Well now, I think I have seen something similar to Alpesh.
> > >>>
> > >>> Recently I needed the climatol package that I have used some time ago.
> > >>> It is not maintained anymore but I downloaded the latest version,
> > >>> climatol_2.2.tar.gz,  from archives
> > >>> (http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
> > >>> ) . Trying to install that package from local file  using R-3.1.0 on
> > >>> Windows 8  resulted in this:
> > >>>
> > >>> ## From R Console
> > >>>> utils:::menuInstallLocal()
> > >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> > >>> "Type")) :
> > >>>   cannot open the connection
> > >>> In addition: Warning messages:
> > >>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
> > >>> file
> > >>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> > >>> :
> > >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> > >>> reason 'No such file or directory'
> > >>>>
> > >>>
> > >>> And yes I know where the file is located, since choose.files() is used.
> > >>>
> > >>> However I tried the same on our linux (R-3.0.2) cluster and it
> > >>> succeeded:
> > >>>
> > >>> [frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
> > >>> * installing to library
> > >>> ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
> > >>> * installing *source* package ?climatol? ...
> > >>> ** R
> > >>> ** data
> > >>> ** inst
> > >>> ** preparing package for lazy loading
> > >>> ** help
> > >>> *** installing help indices
> > >>> ** building package indices
> > >>> ** installing vignettes
> > >>> ** testing if installed package can be loaded
> > >>> * DONE (climatol)
> > >>> [frtog at dkrdsfshn2 ~]$ R
> > >>>
> > >>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> > >>> Copyright (C) 2013 The R Foundation for Statistical Computing
> > >>> Platform: x86_64-unknown-linux-gnu (64-bit)
> > >>>
> > >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> > >>> You are welcome to redistribute it under certain conditions.
> > >>> Type 'license()' or 'licence()' for distribution details.
> > >>>
> > >>>   Natural language support but running in an English locale
> > >>>
> > >>> R is a collaborative project with many contributors.
> > >>> Type 'contributors()' for more information and
> > >>> 'citation()' on how to cite R or R packages in publications.
> > >>>
> > >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> > >>> 'help.start()' for an HTML browser interface to help.
> > >>> Type 'q()' to quit R.
> > >>>
> > >>>> library("climatol")
> > >>>> ?rosavent
> > >>>> q()
> > >>> Save workspace image? [y/n/c]: n
> > >>> [frtog at dkrdsfshn2 ~]$
> > >>>
> > >>>
> > >>> Now unzipping and untaring climatol_2.2.tar.gz I thought to examine
> > >>> whether I could build the package on my Windows box. Only R stuff and
> > >>> no foreign language as C, FORTRAN, etc. so it should be easy.
> > >>>
> > >>> ## Command shell in Windows
> > >>> Microsoft Windows [Version 6.2.9200]
> > >>> (c) 2012 Microsoft Corporation. All rights reserved.
> > >>>
> > >>> C:\Users\frtog>cd Desktop
> > >>>
> > >>> C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R CMD build
> > >>> climatol
> > >>> * checking for file 'climatol/DESCRIPTION' ... OK
> > >>> * preparing 'climatol':
> > >>> * checking DESCRIPTION meta-information ... OK
> > >>> * checking for LF line-endings in source and make files
> > >>> * checking for empty or unneeded directories
> > >>> * looking to see if a 'data/datalist' file should be added
> > >>> * building 'climatol_2.2.tar.gz'
> > >>>
> > >>> Now trying to install from that local file I Still got the same error
> > >>> as above.
> > >>>
> > >>>
> > >>>
> > >>> Trying to do some debugging on read.dcf() (Emacs/ESS)
> > >>>
> > >>>
> > >>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
> > >>> Copyright (C) 2014 The R Foundation for Statistical Computing
> > >>> Platform: x86_64-w64-mingw32/x64 (64-bit)
> > >>>
> > >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
> > >>> You are welcome to redistribute it under certain conditions.
> > >>> Type 'license()' or 'licence()' for distribution details.
> > >>>
> > >>>   Natural language support but running in an English locale
> > >>>
> > >>> R is a collaborative project with many contributors.
> > >>> Type 'contributors()' for more information and
> > >>> 'citation()' on how to cite R or R packages in publications.
> > >>>
> > >>> Type 'demo()' for some demos, 'help()' for on-line help, or
> > >>> 'help.start()' for an HTML browser interface to help.
> > >>> Type 'q()' to quit R.
> > >>>
> > >>>>> options(chmhelp=FALSE, help_type="text")
> > >>>> options(STERM='iESS', str.dendrogram.last="'",
> > >>> editor='emacsclient.exe', show.error.locations=TRUE)
> > >>>> debug(read.dcf)
> > >>>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos = NULL)
> > >>> debugging in: read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> > >>> "Type"))
> > >>> debug: {
> > >>>     if (is.character(file)) {
> > >>>         file <- gzfile(file)
> > >>>         on.exit(close(file))
> > >>>     }
> > >>>     if (!inherits(file, "connection"))
> > >>>         stop("'file' must be a character string or connection")
> > >>>     if (!all)
> > >>>         return(.Internal(readDCF(file, fields, keep.white)))
> > >>>     .assemble_things_into_a_data_frame <- function(tags, vals,
> > >>>         nums) {
> > >>>         tf <- factor(tags, levels = unique(tags))
> > >>>         cnts <- table(nums, tf)
> > >>>      out <- array(NA_character_, dim = dim(cnts), dimnames = list(NULL,
> > >>>             levels(tf)))
> > >>>         if (all(cnts <= 1L)) {
> > >>>             out[cbind(nums, tf)] <- vals
> > >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> > >>>         }
> > >>>         else {
> > >>>             levs <- colSums(cnts > 1L) == 0L
> > >>>             if (any(levs)) {
> > >>>                 inds <- tf %in% levels(tf)[levs]
> > >>>                 out[cbind(nums[inds], tf[inds])] <- vals[inds]
> > >>>             }
> > >>>             out <- as.data.frame(out, stringsAsFactors = FALSE)
> > >>>             for (l in levels(tf)[!levs]) {
> > >>>                 out[[l]] <- rep.int(list(NA_character_), nrow(cnts))
> > >>>                 i <- tf == l
> > >>>                 out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
> > >>>             }
> > >>>         }
> > >>>         out
> > >>>     }
> > >>>     on.exit(Sys.setlocale("LC_CTYPE", Sys.getlocale("LC_CTYPE")),
> > >>>         add = TRUE)
> > >>>     Sys.setlocale("LC_CTYPE", "C")
> > >>>     lines <- readLines(file)
> > >>>     ind <- grep("^[^[:blank:]][^:]*$", lines)
> > >>>     if (length(ind)) {
> > >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> > >>> stop(gettextf("Invalid DCF format.\nRegular lines must have a
> > >>> tag.\nOffending lines start with:\n%s",
> > >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> > >>>     }
> > >>>     line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
> > >>>     nums <- cumsum(diff(c(FALSE, line_is_not_empty) > 0L) > 0L)
> > >>>     nums <- nums[line_is_not_empty]
> > >>>     lines <- lines[line_is_not_empty]
> > >>>     line_is_escaped_blank <- grepl("^[[:space:]]+\\.[[:space:]]*$",
> > >>>         lines)
> > >>>     if (any(line_is_escaped_blank))
> > >>>         lines[line_is_escaped_blank] <- ""
> > >>>     line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
> > >>>     ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
> > >>>     if (length(ind)) {
> > >>>         lines <- strtrim(lines[ind], 0.7 * getOption("width"))
> > >>> stop(gettextf("Invalid DCF format.\nContinuation lines must not start a
> > >>> record.\nOffending lines start with:\n%s",
> > >>>             paste0("  ", lines, collapse = "\n")), domain = NA)
> > >>>     }
> > >>>     lengths <- rle(cumsum(line_has_tag))$lengths
> > >>>     pos <- cumsum(lengths)
> > >>>     tags <- sub(":.*", "", lines[line_has_tag])
> > >>> lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
> > >>> lines[line_has_tag])
> > >>>     foldable <- rep.int(is.na(match(tags, keep.white)), lengths)
> > >>>     lines[foldable] <- sub("^[[:space:]]*", "", lines[foldable])
> > >>>     lines[foldable] <- sub("[[:space:]]*$", "", lines[foldable])
> > >>> vals <- mapply(function(from, to) paste(lines[from:to], collapse =
> > >>> "\n"),
> > >>>         c(1L, pos[-length(pos)] + 1L), pos)
> > >>>     out <- .assemble_things_into_a_data_frame(tags, vals, nums[pos])
> > >>>     if (!is.null(fields))
> > >>>         out <- out[fields]
> > >>>     out
> > >>> }
> > >>> Browse[2]> str(file)
> > >>> chr "climatol_2.2.tar.gz/DESCRIPTION"
> > >>> Browse[2]> head(file)
> > >>> [1] "climatol_2.2.tar.gz/DESCRIPTION"
> > >>> Browse[2]>
> > >>> debug: if (is.character(file)) {
> > >>>     file <- gzfile(file)
> > >>>     on.exit(close(file))
> > >>> }
> > >>> Browse[2]>
> > >>> debug: file <- gzfile(file)
> > >>> Browse[2]>
> > >>> debug: on.exit(close(file))
> > >>> Browse[2]>
> > >>> debug: if (!inherits(file, "connection")) stop("'file' must be a
> > >>> character string or connection")
> > >>> Browse[2]>
> > >>> debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> > >>> Browse[2]> str(file)
> > >>> Classes 'gzfile', 'connection'  atomic [1:1] 3
> > >>>   ..- attr(*, "conn_id")=<externalptr>
> > >>> Browse[2]> file
> > >>>                       description                             class
> > >>> "climatol_2.2.tar.gz/DESCRIPTION"                          "gzfile"
> > >>>                              mode                              text
> > >>>                              "rb"                            "text"
> > >>>                            opened                          can read
> > >>>                          "closed"                             "yes"
> > >>>                         can write
> > >>>                             "yes"
> > >>> Browse[2]>
> > >>> debug: return(.Internal(readDCF(file, fields, keep.white)))
> > >>> Browse[2]>
> > >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> > >>> "Type")) :
> > >>>   cannot open the connection
> > >>> In addition: Warning message:
> > >>> In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
> > >>> cannot open compressed file 'climatol_2.2.tar.gz/DESCRIPTION', probable
> > >>> reason 'No such file or directory'
> > >>>>
> > >>>
> > >>> Well coming to debug: if (!all) return(.Internal(readDCF(file, fields,
> > >>> keep.white))) I loose control and R returns to prompt with an error.
> > >>>
> > >>> Hopefully one of you can replicate this. If not then it must have
> > >>> something with Windows OS to do. But what?
> > >>>
> > >>>
> > >>>
> > >>> Yours sincerely / Med venlig hilsen
> > >>>
> > >>>
> > >>> Frede Aakmann T?gersen
> > >>> Specialist, M.Sc., Ph.D.
> > >>> Plant Performance & Modeling
> > >>>
> > >>> Technology & Service Solutions
> > >>> T +45 9730 5135
> > >>> M +45 2547 6050
> > >>> frtog at vestas.com
> > >>> http://www.vestas.com
> > >>>
> > >>> Company reg. name: Vestas Wind Systems A/S
> > >>> This e-mail is subject to our e-mail disclaimer statement.
> > >>> Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> > >>> If you have received this e-mail in error please contact the sender.
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: r-help-bounces at r-project.org
> > >>> [mailto:r-help-bounces at r-project.org]
> > >>>> On Behalf Of Jeff Newmiller
> > >>>> Sent: 20. april 2014 23:33
> > >>>> To: Alpesh Pandya; Rui Barradas
> > >>>> Cc: r-help at r-project.org; Uwe Ligges
> > >>>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing XML package
> > >>>>
> > >>>> Hard to help you when the problem simply does not happen for others.
> > >>>>
> > >>>> As for Windows being not a focus, that is not at all true. I use it
> > >>> regularly on
> > >>>> Windows at work. That being said, there are thousands of packages and
> > >>>> those each involve their own subset of R users. There are also many
> > >>>> operating system configurations that may not all be fully tested.
> > >>> Blaming "R"
> > >>>> or "Windows", or blaming us for "preventing" you from getting your
> > >>>> education (isn't that something between you and your educational
> > >>>> institution?) are not going to be effective strategies for problem
> > >>> solving.
> > >>>>
> > >>>> Are you able to use other aspects of R beyond the XML package? Have
> > >>> you
> > >>>> tried communicating with the maintainers of that package?
> > >>>>
> > >>> ---------------------------------------------------------------------------
> > >>>> Jeff Newmiller                        The     .....       .....  Go
> > >>> Live...
> > >>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > >>> Go...
> > >>>>                                        Live:   OO#.. Dead: OO#..
> > >>> Playing
> > >>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > >>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> > >>> rocks...1k
> > >>>>
> > >>> ---------------------------------------------------------------------------
> > >>>> Sent from my phone. Please excuse my brevity.
> > >>>>
> > >>>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
> > >>>> <alpeshpandya at gmail.com> wrote:
> > >>>>> I keep on trying from various networks but I still get the same
> > >>> error.
> > >>>>> I
> > >>>>> don't this this has anything to do with network or ability to
> > >>> download
> > >>>>> the
> > >>>>> package (as I can install other packages fine). This must be
> > >>> something
> > >>>>> in
> > >>>>> base R or dependencies issues (that R is not spelling out).
> > >>>>>
> > >>>>> I know R is geared for Mac and Windows is kind of looked down upon
> > >>> but
> > >>>>> I
> > >>>>> have no option but use windows and need this XML package running to
> > >>>>> complete my education. Any help on this would be appreciated.
> > >>>>>
> > >>>>>
> > >>>>> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
> > >>>>> <alpeshpandya at gmail.com>wrote:
> > >>>>>
> > >>>>>> Thank you for response Rui.
> > >>>>>>
> > >>>>>> I still get the same error with this repository.
> > >>>>>>
> > >>>>>> Installing package into
> > >>>>> ???C:/Users/APandya/Documents/R/win-library/3.0???
> > >>>>>> (as ???lib??? is unspecified)
> > >>>>>> trying URL '
> > >>>>>> http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> > >>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> > >>>>>> opened URL
> > >>>>>> downloaded 4.1 Mb
> > >>>>>>
> > >>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> > >>>>> "Type"))
> > >>>>>> :
> > >>>>>>    cannot open the connection
> > >>>>>> In addition: Warning messages:
> > >>>>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
> > >>>>>>    downloaded length 4276224 != reported length 4288136
> > >>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting from
> > >>> zip
> > >>>>> file
> > >>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> > >>>>> "Type")) :
> > >>>>>>    cannot open compressed file 'XML/DESCRIPTION', probable reason
> > >>> 'No
> > >>>>> such
> > >>>>>> file or directory'
> > >>>>>>
> > >>>>>>
> > >>>>>>
> > >>>>>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
> > >>>>> <ruipbarradas at sapo.pt>wrote:
> > >>>>>>
> > >>>>>>> Hello,
> > >>>>>>> I have package XML installed on Windows 7, R 3.0.3 and I had no
> > >>>>> problem
> > >>>>>>> at all. Can't you try (it worked with me)
> > >>>>>>>
> > >>>>>>> install.packages("XML", repos = "http://cran.dcc.fc.up.pt")
> > >>>>>>>
> > >>>>>>> Hope this helps,
> > >>>>>>>
> > >>>>>>> Rui Barradas
> > >>>>>>>
> > >>>>>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
> > >>>>>>>
> > >>>>>>>   I have tried these sources (almost all US mirrors):
> > >>>>>>>>
> > >>>>>>>>
> > >>>>
> > >>>> http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>>
> > >>> http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>> http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
> > >>>>>>>> 3.0/XML_3.98-1.1.zip
> > >>>>>>>>
> > >>>>> http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>>
> > >>>>
> > >>>> http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> > >>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>> http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>> http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>> http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>>
> > >>>>
> > >>>> http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>>
> > >>>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
> > >>>> 1.1.zip
> > >>>>>>>>
> > >>>>>>>> I have confirmed with IT that there is no restriction on
> > >>>>> downloading this
> > >>>>>>>> zip file from any of these sources. Also I am getting same error
> > >>>>> when I
> > >>>>>>>> try
> > >>>>>>>> from my home network as well.
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
> > >>>>>>>> ligges at statistik.tu-dortmund.de
> > >>>>>>>>
> > >>>>>>>>> wrote:
> > >>>>>>>>>
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
> > >>>>>>>>>
> > >>>>>>>>>   @Uwe I tried the same steps from office as well as home
> > >>> network
> > >>>>> with
> > >>>>>>>>>> same
> > >>>>>>>>>> results. Are you using windows 7 with R 3.0.3?
> > >>>>>>>>>>
> > >>>>>>>>>> I have seen same question being asked by others without any
> > >>>>>>>>>> resolution. Is
> > >>>>>>>>>> anything special about XML package? I am OK use older version
> > >>> of
> > >>>>>>>>>> package
> > >>>>>>>>>> but in archives there are no zip files (only gz files). Is
> > >>>>> windows
> > >>>>>>>>>> platform
> > >>>>>>>>>> not recommended for R?
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>> Right, and you can try to install these from sources.
> > >>>>>>>>> But I doubt you need it. You still have not told us if you
> > >>> tried
> > >>>>> another
> > >>>>>>>>> mirror to download the XML file from and what you local IT
> > >>> support
> > >>>>> tells
> > >>>>>>>>> you while your downloads are incomplete.
> > >>>>>>>>>
> > >>>>>>>>> Best,
> > >>>>>>>>> Uwe Ligges
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
> > >>>>>>>>>> ligges at statistik.tu-dortmund.de
> > >>>>>>>>>>
> > >>>>>>>>>>   wrote:
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
> > >>>>>>>>>>>
> > >>>>>>>>>>>    Thank you for response Uwe. I tried multiple times by
> > >>>>> downloading
> > >>>>>>>>>>> the
> > >>>>>>>>>>>
> > >>>>>>>>>>>> zip
> > >>>>>>>>>>>> file from many sources but still the same error. This is a
> > >>>>> major road
> > >>>>>>>>>>>> block
> > >>>>>>>>>>>> for me in using R. Appreciate any help on this.
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>   Please ask your local IT staff.
> > >>>>>>>>>>>
> > >>>>>>>>>>> I get, using the same mirror:
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>> options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
> > >>>>>>>>>>>
> > >>>>>>>>>>>> install.packages("XML", lib="d:/temp")
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>> trying URL
> > >>> 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
> > >>>>>>>>>>>
> > >>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
> > >>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1 Mb)
> > >>>>>>>>>>> opened URL
> > >>>>>>>>>>> downloaded 4.1 Mb
> > >>>>>>>>>>>
> > >>>>>>>>>>> package 'XML' successfully unpacked and MD5 sums checked
> > >>>>>>>>>>>
> > >>>>>>>>>>> The downloaded binary packages are in
> > >>>>>>>>>>>            d:\temp\RtmpqMqL8L\downloaded_packages
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>> Best,
> > >>>>>>>>>>> Uwe Ligges
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
> > >>>>>>>>>>>> ligges at statistik.tu-dortmund.de
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>    wrote:
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>      Works for me.
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>> Best,
> > >>>>>>>>>>>>> Uwe Ligges
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>     Using install.package('XML') command produces this
> > >>> error:
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>> trying URL
> > >>>>>>>>>>>>>> '
> > >>>>>>>>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
> > >>>>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
> > >>>>>>>>>>>>>> '
> > >>>>>>>>>>>>>> Content type 'application/zip' length 4288136 bytes (4.1
> > >>> Mb)
> > >>>>>>>>>>>>>> opened URL
> > >>>>>>>>>>>>>> downloaded 4.1 Mb
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
> > >>>>> c("Package",
> > >>>>>>>>>>>>>> "Type")) :
> > >>>>>>>>>>>>>>        cannot open the connection
> > >>>>>>>>>>>>>> In addition: Warning messages:
> > >>>>>>>>>>>>>> 1: In download.file(url, destfile, method, mode = "wb",
> > >>> ...)
> > >>>>> :
> > >>>>>>>>>>>>>>        downloaded length 4276224 != reported length 4288136
> > >>>>>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in extracting
> > >>>> >from zip
> > >>>>>>>>>>>>>> file
> > >>>>>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
> > >>>>> c("Package",
> > >>>>>>>>>>>>>> "Type"))
> > >>>>>>>>>>>>>> :
> > >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> > >>> probable
> > >>>>>>>>>>>>>> reason
> > >>>>>>>>>>>>>> 'No
> > >>>>>>>>>>>>>> such
> > >>>>>>>>>>>>>> file or directory'
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> Upon receiving this error, I downloaded XML_3.98-1.1.zip
> > >>>>> directly
> > >>>>>>>>>>>>>> from
> > >>>>>>>>>>>>>> cran
> > >>>>>>>>>>>>>> site. But this zip file is not a valid archive (cannot
> > >>> open
> > >>>>> using
> > >>>>>>>>>>>>>> winzip).
> > >>>>>>>>>>>>>> Also trying to install using this downloaded file produces
> > >>>>> the
> > >>>>>>>>>>>>>> following
> > >>>>>>>>>>>>>> error:
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> Installing package into 'C:/Users/APandya/Documents/R/
> > >>>>>>>>>>>>>> win-library/3.0'
> > >>>>>>>>>>>>>> (as 'lib' is unspecified)
> > >>>>>>>>>>>>>> Warning in install.packages :
> > >>>>>>>>>>>>>>        error 1 in extracting from zip file
> > >>>>>>>>>>>>>> Warning in install.packages :
> > >>>>>>>>>>>>>>        cannot open compressed file 'XML/DESCRIPTION',
> > >>> probable
> > >>>>>>>>>>>>>> reason
> > >>>>>>>>>>>>>> 'No
> > >>>>>>>>>>>>>> such
> > >>>>>>>>>>>>>> file or directory'
> > >>>>>>>>>>>>>> Error in install.packages : cannot open the connection
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> I  downloaded this zip file from multiple sources and
> > >>> tried
> > >>>>> to
> > >>>>>>>>>>>>>> install
> > >>>>>>>>>>>>>> with
> > >>>>>>>>>>>>>> same result.
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>
> > >>>>>>
> > >>>>>> --
> > >>>>>> Thanks and Regards
> > >>>>>> Alpesh
> > >>>>>>
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >>>> guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >> 	[[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>



From aguitatierra at hotmail.com  Mon Apr 21 16:27:17 2014
From: aguitatierra at hotmail.com (Beatriz R. Gonzalez Dominguez)
Date: Mon, 21 Apr 2014 16:27:17 +0200
Subject: [R] Loop to extract from variables in the workspace
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA54EA@DKRDSEXC016.vestas.net>
References: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA54EA@DKRDSEXC016.vestas.net>
Message-ID: <BLU0-SMTP2869D275E60143FAD7E192BD95E0@phx.gbl>

Hi Frede,

Many thanks for your reply.
1. The first argument in extract is a Formal class RasterLayer in the 
Workspace (e.g RR_1981_1 ).

2. I created an intermediate name to hold the result fromthe extract 
function because I'd like to create several dataframes with the output 
of the iterative (loop) extraction. I'd like to get the same result as 
when I do:

PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
[... this works no problem]

3. 'coords' is a SpatialPointsDataFrame.

4. I used assign in the loop becuase I thought it was the way forward to 
create new variables out of it. Isn't it?

What I'd like to do is to use coordinate points ('coords') to extract 
raster pixel values (eg. 'RR_1981_1') on which the points are overlying. 
Then I'd like to build a bigger data frame including the data from all 
the outputs (i.e. PE.coords_01_1981, PE.coords_01_1982).

Hope to have explained myself properly. Please let me know if anything 
else should be clarified.

Best wishes,

Bea


On 21/04/2014 15:17, Frede Aakmann T?gersen wrote:
> Hi Beatriz
>
> Did you read the help for extract{raster} carefully?
>
> Several things can be wrong.
>
> 1) First argument to extract is not a file name but a raster object.
> 2) In the loop you name an object extract as an intermediate name to hold the result from the extract function. Do you think there could be a name clash? R is clever but perhaps not clever enough.
> 3) coords are of the right class (see ?extract).
> 4) assign can be useful from time to time. But in a loop?
>
> I think the things you are doing are some intermediate results that needs more processing. Do you think this is the right way to do that. For instance instead of storing the immediate result as separate objects why not store those in a list.
>
> Perhaps if you tell us what you would like to do  overall, i.e. from first to last, then we will be able to help you to become more efficient.
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Beatriz R. Gonzalez Dominguez
>> Sent: 21. april 2014 14:53
>> To: r-help at r-project.org
>> Subject: [R] Loop to extract from variables in the workspace
>>
>> Dear all,
>>
>> I'm starting to work with loops and I'm stucked on something.
>> I've been searching and trying different possibilities but I don't get
>> to the solution.
>> I'd be very grateful if you could share any ideas that you think may help.
>>
>> library("raster")
>>
>> # All my variables are in the workspace
>>
>> # This is what I'd like to obtain, but with a loop (I'm working with
>> several years and variables).
>> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
>> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
>> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
>> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
>> PE.coords_01_1985 <- extract(RR_1985_1, coords, df=T)
>> PE.coords_01_1986 <- extract(RR_1986_1, coords, df=T)
>> PE.coords_01_1987 <- extract(RR_1987_1, coords, df=T)
>> PE.coords_01_1988 <- extract(RR_1988_1, coords, df=T)
>> PE.coords_01_1989 <- extract(RR_1989_1, coords, df=T)
>> PE.coords_01_1990 <- extract(RR_1990_1, coords, df=T)
>>
>>
>> # This is one of the things I've tried.
>>
>> for(i in 1981:2010){
>> file <- c(paste("RR_", i, "_1", sep=""))
>> extract <- extract(file, coords, df=T)}
>> names.a <- paste("PE.coords_01_", i, sep="")
>> assign(names.a, value=extract)
>> }
>>
>> # I get the following error.
>> Error in (function (classes, fdef, mtable) :
>> unable to find an inherited method for function 'extract'
>> for signature '"character", "SpatialPointsDataFrame"'
>> # I think the error must be something when I'm defining 'file'
>>
>> Thanks a lot for any help!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Mon Apr 21 16:37:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Apr 2014 10:37:56 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <CAEv=oxPd1hTBgE=CQN1dxcM6sSR3xReO2dKZoLM=nTH+vtVSpw@mail.gmail.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>	<1398078658.5143.2.camel@milan>	<5354FF1C.3000607@gmail.com>	<1398086383.5143.24.camel@milan>	<53551CFC.8000307@gmail.com>
	<CAEv=oxPd1hTBgE=CQN1dxcM6sSR3xReO2dKZoLM=nTH+vtVSpw@mail.gmail.com>
Message-ID: <53552D44.3020608@gmail.com>

On 21/04/2014 10:30 AM, Alpesh Pandya wrote:
> Frede's suggestion was very helpful to me and I could resolve the 
> issue finally.
>
> I created new archive manually using source code for XML package (only 
> R code) and winzip utility. Then ran this command for installation and 
> that worked fine.
>
> install.packages("C:/Course/WorkingData/XML_3.98-1.1.zip", repos = NULL)
> Installing package into ?C:/Users/APandya/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> package ?XML? successfully unpacked and MD5 sums checked
>

That is not a valid way to install it.  Don't expect it to work.

Duncan Murdoch

>
>
>
> On Mon, Apr 21, 2014 at 9:28 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 21/04/2014 9:19 AM, Milan Bouchet-Valat wrote:
>
>         Le lundi 21 avril 2014 ? 07:21 -0400, Duncan Murdoch a ?crit :
>         > On 21/04/2014, 7:10 AM, Milan Bouchet-Valat wrote:
>         > > Le lundi 21 avril 2014 ? 11:38 +0200, Frede Aakmann
>         T?gersen a ?crit :
>         > >> Hi
>         > >>
>         > >> Couldn't find a zip file in the archives.
>         > >>
>         > >> Why didn't 'R CMD build' (in a command shell on Windows)
>         not make a
>         > >> zip file? I did try to build from the climatol library
>         that holds the
>         > >> typical files as DESCRIPTION, LICENSE, etc. as well as
>         folders like R,
>         > >> etc.
>         > > R CMD build produces *source* packages, and .zip packages
>         are *binary*.
>         > >
>         > >> Did you see the debug information on read.fcf? For me it
>         seems like R
>         > >> has open a file handler to the DESCRIPTION file. Wouldn't
>         the error
>         > >> already be thrown there and not when read.fcf is called
>         if the .tar.gz
>         > >> format was the problem?
>         > >>
>         > >> I'll try and locate a zip
>         > > Does install.packages(choose.file(), type="source") work?
>         >
>         > That will also need "repos=NULL", or it will go out to a
>         repository to
>         > look for the package.
>         Usually install.packages() prints a warning and assumes
>         repos=NULL iwhen
>         type="source". And since I'm lazy, I've sticked to the short
>         version. ;-)
>
>
>     Right, if the file is a .tar.gz file, it does that.  I often
>     install directly from source directories, and there it fails.
>
>     Duncan Murdoch
>
>
>
>         > That should work if the package doesn't have compiled code.
>          It will
>         > handle compiled code only if Frede has the appropriate tools
>         installed.
>         >
>         >
>         > I'm not sure
>         > > what utils:::menuInstallLocal() does.
>         >
>         > It is essentially
>         >
>         > install.packages(choose.file(), type="binary", repos=NULL)
>         >
>         > so it's not what Frede needs.
>         OK, so that's what I suspected.
>
>
>         Regards
>
>         > Duncan
>         > >
>         > >
>         > > Regards
>         > >
>         > >
>         > >> Sendt fra Samsung mobil
>         > >>
>         > >>
>         > >> -------- Oprindelig meddelelse --------
>         > >> Fra: Jeff Newmiller
>         > >> Dato:21/04/2014 09.44 (GMT+01:00)
>         > >> Til: Frede Aakmann T?gersen ,Alpesh Pandya ,Rui Barradas
>         > >> Cc: r-help at r-project.org
>         <mailto:r-help at r-project.org>,Uwe Ligges ,Duncan Murdoch
>         > >> Emne: RE: [R] R 3.0.3, Windows 7: Problem installing XML
>         package
>         > >>
>         > >> Frede... Windows uses zip files (binary, aka pre-compiled
>         format) for packages by default, because most installations
>         don't have the development tools installed. You need to setup
>         RTools and use the "source" option to install_package in order
>         to handle the tar.gz package file, or download and install the
>         zip file instead.
>         > >>
>         ---------------------------------------------------------------------------
>         > >> Jeff Newmiller  The     .....       .....  Go Live...
>         > >> DCN:<jdnewmil at dcn.davis.ca.us
>         <mailto:jdnewmil at dcn.davis.ca.us>>    Basics: ##.#.      
>         ##.#.  Live Go...
>         > >>  Live:   OO#.. Dead: OO#..  Playing
>         > >> Research Engineer (Solar/Batteries      O.O#.       #.O#.
>          with
>         > >> /Software/Embedded Controllers)       .OO#.       .OO#.
>          rocks...1k
>         > >>
>         ---------------------------------------------------------------------------
>         > >> Sent from my phone. Please excuse my brevity.
>         > >>
>         > >> On April 20, 2014 11:01:17 PM PDT, "Frede Aakmann
>         T?gersen" <frtog at vestas.com <mailto:frtog at vestas.com>> wrote:
>         > >>> Well now, I think I have seen something similar to Alpesh.
>         > >>>
>         > >>> Recently I needed the climatol package that I have used
>         some time ago.
>         > >>> It is not maintained anymore but I downloaded the latest
>         version,
>         > >>> climatol_2.2.tar.gz,  from archives
>         > >>>
>         (http://cran.r-project.org/src/contrib/Archive/climatol/climatol_2.2.tar.gz
>         > >>> ) . Trying to install that package from local file
>          using R-3.1.0 on
>         > >>> Windows 8  resulted in this:
>         > >>>
>         > >>> ## From R Console
>         > >>>> utils:::menuInstallLocal()
>         > >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package",
>         > >>> "Type")) :
>         > >>>   cannot open the connection
>         > >>> In addition: Warning messages:
>         > >>> 1: In unzip(zipname, exdir = dest) : error 1 in
>         extracting from zip
>         > >>> file
>         > >>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package", "Type"))
>         > >>> :
>         > >>> cannot open compressed file
>         'climatol_2.2.tar.gz/DESCRIPTION', probable
>         > >>> reason 'No such file or directory'
>         > >>>>
>         > >>>
>         > >>> And yes I know where the file is located, since
>         choose.files() is used.
>         > >>>
>         > >>> However I tried the same on our linux (R-3.0.2) cluster
>         and it
>         > >>> succeeded:
>         > >>>
>         > >>> [frtog at dkrdsfshn2 ~]$ R CMD INSTALL climatol_2.2.tar.gz
>         > >>> * installing to library
>         > >>> ?/gpfs02/gcdistro/app/R/3.0.2-gcc4.8.2/lib64/R/library?
>         > >>> * installing *source* package ?climatol? ...
>         > >>> ** R
>         > >>> ** data
>         > >>> ** inst
>         > >>> ** preparing package for lazy loading
>         > >>> ** help
>         > >>> *** installing help indices
>         > >>> ** building package indices
>         > >>> ** installing vignettes
>         > >>> ** testing if installed package can be loaded
>         > >>> * DONE (climatol)
>         > >>> [frtog at dkrdsfshn2 ~]$ R
>         > >>>
>         > >>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>         > >>> Copyright (C) 2013 The R Foundation for Statistical
>         Computing
>         > >>> Platform: x86_64-unknown-linux-gnu (64-bit)
>         > >>>
>         > >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>         > >>> You are welcome to redistribute it under certain conditions.
>         > >>> Type 'license()' or 'licence()' for distribution details.
>         > >>>
>         > >>>   Natural language support but running in an English locale
>         > >>>
>         > >>> R is a collaborative project with many contributors.
>         > >>> Type 'contributors()' for more information and
>         > >>> 'citation()' on how to cite R or R packages in publications.
>         > >>>
>         > >>> Type 'demo()' for some demos, 'help()' for on-line help, or
>         > >>> 'help.start()' for an HTML browser interface to help.
>         > >>> Type 'q()' to quit R.
>         > >>>
>         > >>>> library("climatol")
>         > >>>> ?rosavent
>         > >>>> q()
>         > >>> Save workspace image? [y/n/c]: n
>         > >>> [frtog at dkrdsfshn2 ~]$
>         > >>>
>         > >>>
>         > >>> Now unzipping and untaring climatol_2.2.tar.gz I thought
>         to examine
>         > >>> whether I could build the package on my Windows box.
>         Only R stuff and
>         > >>> no foreign language as C, FORTRAN, etc. so it should be
>         easy.
>         > >>>
>         > >>> ## Command shell in Windows
>         > >>> Microsoft Windows [Version 6.2.9200]
>         > >>> (c) 2012 Microsoft Corporation. All rights reserved.
>         > >>>
>         > >>> C:\Users\frtog>cd Desktop
>         > >>>
>         > >>> C:\Users\frtog\Desktop>c:\Programmer\R\R-3.1.0\bin\x64\R
>         CMD build
>         > >>> climatol
>         > >>> * checking for file 'climatol/DESCRIPTION' ... OK
>         > >>> * preparing 'climatol':
>         > >>> * checking DESCRIPTION meta-information ... OK
>         > >>> * checking for LF line-endings in source and make files
>         > >>> * checking for empty or unneeded directories
>         > >>> * looking to see if a 'data/datalist' file should be added
>         > >>> * building 'climatol_2.2.tar.gz'
>         > >>>
>         > >>> Now trying to install from that local file I Still got
>         the same error
>         > >>> as above.
>         > >>>
>         > >>>
>         > >>>
>         > >>> Trying to do some debugging on read.dcf() (Emacs/ESS)
>         > >>>
>         > >>>
>         > >>> R version 3.1.0 (2014-04-10) -- "Spring Dance"
>         > >>> Copyright (C) 2014 The R Foundation for Statistical
>         Computing
>         > >>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>         > >>>
>         > >>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>         > >>> You are welcome to redistribute it under certain conditions.
>         > >>> Type 'license()' or 'licence()' for distribution details.
>         > >>>
>         > >>>   Natural language support but running in an English locale
>         > >>>
>         > >>> R is a collaborative project with many contributors.
>         > >>> Type 'contributors()' for more information and
>         > >>> 'citation()' on how to cite R or R packages in publications.
>         > >>>
>         > >>> Type 'demo()' for some demos, 'help()' for on-line help, or
>         > >>> 'help.start()' for an HTML browser interface to help.
>         > >>> Type 'q()' to quit R.
>         > >>>
>         > >>>>> options(chmhelp=FALSE, help_type="text")
>         > >>>> options(STERM='iESS', str.dendrogram.last="'",
>         > >>> editor='emacsclient.exe', show.error.locations=TRUE)
>         > >>>> debug(read.dcf)
>         > >>>> install.packages("~/Desktop/climatol_2.2.tar.gz", repos
>         = NULL)
>         > >>> debugging in: read.dcf(file.path(pkgname,
>         "DESCRIPTION"), c("Package",
>         > >>> "Type"))
>         > >>> debug: {
>         > >>>     if (is.character(file)) {
>         > >>>         file <- gzfile(file)
>         > >>>         on.exit(close(file))
>         > >>>     }
>         > >>>     if (!inherits(file, "connection"))
>         > >>>         stop("'file' must be a character string or
>         connection")
>         > >>>     if (!all)
>         > >>> return(.Internal(readDCF(file, fields, keep.white)))
>         > >>>     .assemble_things_into_a_data_frame <- function(tags,
>         vals,
>         > >>>         nums) {
>         > >>>         tf <- factor(tags, levels = unique(tags))
>         > >>>         cnts <- table(nums, tf)
>         > >>>      out <- array(NA_character_, dim = dim(cnts),
>         dimnames = list(NULL,
>         > >>>             levels(tf)))
>         > >>>         if (all(cnts <= 1L)) {
>         > >>>             out[cbind(nums, tf)] <- vals
>         > >>>             out <- as.data.frame(out, stringsAsFactors =
>         FALSE)
>         > >>>         }
>         > >>>         else {
>         > >>>             levs <- colSums(cnts > 1L) == 0L
>         > >>>             if (any(levs)) {
>         > >>>                 inds <- tf %in% levels(tf)[levs]
>         > >>> out[cbind(nums[inds], tf[inds])] <- vals[inds]
>         > >>>             }
>         > >>>             out <- as.data.frame(out, stringsAsFactors =
>         FALSE)
>         > >>>             for (l in levels(tf)[!levs]) {
>         > >>>                 out[[l]] <- rep.int
>         <http://rep.int>(list(NA_character_), nrow(cnts))
>         > >>>                 i <- tf == l
>         > >>> out[[l]][unique(nums[i])] <- split(vals[i], nums[i])
>         > >>>             }
>         > >>>         }
>         > >>>         out
>         > >>>     }
>         > >>>     on.exit(Sys.setlocale("LC_CTYPE",
>         Sys.getlocale("LC_CTYPE")),
>         > >>>         add = TRUE)
>         > >>>     Sys.setlocale("LC_CTYPE", "C")
>         > >>>     lines <- readLines(file)
>         > >>>     ind <- grep("^[^[:blank:]][^:]*$", lines)
>         > >>>     if (length(ind)) {
>         > >>>         lines <- strtrim(lines[ind], 0.7 *
>         getOption("width"))
>         > >>> stop(gettextf("Invalid DCF format.\nRegular lines must
>         have a
>         > >>> tag.\nOffending lines start with:\n%s",
>         > >>>             paste0("  ", lines, collapse = "\n")),
>         domain = NA)
>         > >>>     }
>         > >>>     line_is_not_empty <- !grepl("^[[:space:]]*$", lines)
>         > >>>     nums <- cumsum(diff(c(FALSE, line_is_not_empty) >
>         0L) > 0L)
>         > >>>     nums <- nums[line_is_not_empty]
>         > >>>     lines <- lines[line_is_not_empty]
>         > >>>     line_is_escaped_blank <-
>         grepl("^[[:space:]]+\\.[[:space:]]*$",
>         > >>>         lines)
>         > >>>     if (any(line_is_escaped_blank))
>         > >>>         lines[line_is_escaped_blank] <- ""
>         > >>>     line_has_tag <- grepl("^[^[:blank:]][^:]*:", lines)
>         > >>>     ind <- which(!line_has_tag[which(diff(nums) > 0L) + 1L])
>         > >>>     if (length(ind)) {
>         > >>>         lines <- strtrim(lines[ind], 0.7 *
>         getOption("width"))
>         > >>> stop(gettextf("Invalid DCF format.\nContinuation lines
>         must not start a
>         > >>> record.\nOffending lines start with:\n%s",
>         > >>>             paste0("  ", lines, collapse = "\n")),
>         domain = NA)
>         > >>>     }
>         > >>>     lengths <- rle(cumsum(line_has_tag))$lengths
>         > >>>     pos <- cumsum(lengths)
>         > >>>     tags <- sub(":.*", "", lines[line_has_tag])
>         > >>> lines[line_has_tag] <- sub("[^:]*:[[:space:]]*", "",
>         > >>> lines[line_has_tag])
>         > >>>     foldable <- rep.int <http://rep.int>(is.na
>         <http://is.na>(match(tags, keep.white)), lengths)
>         > >>>     lines[foldable] <- sub("^[[:space:]]*", "",
>         lines[foldable])
>         > >>>     lines[foldable] <- sub("[[:space:]]*$", "",
>         lines[foldable])
>         > >>> vals <- mapply(function(from, to) paste(lines[from:to],
>         collapse =
>         > >>> "\n"),
>         > >>>         c(1L, pos[-length(pos)] + 1L), pos)
>         > >>>     out <- .assemble_things_into_a_data_frame(tags,
>         vals, nums[pos])
>         > >>>     if (!is.null(fields))
>         > >>>         out <- out[fields]
>         > >>>     out
>         > >>> }
>         > >>> Browse[2]> str(file)
>         > >>> chr "climatol_2.2.tar.gz/DESCRIPTION"
>         > >>> Browse[2]> head(file)
>         > >>> [1] "climatol_2.2.tar.gz/DESCRIPTION"
>         > >>> Browse[2]>
>         > >>> debug: if (is.character(file)) {
>         > >>>     file <- gzfile(file)
>         > >>>     on.exit(close(file))
>         > >>> }
>         > >>> Browse[2]>
>         > >>> debug: file <- gzfile(file)
>         > >>> Browse[2]>
>         > >>> debug: on.exit(close(file))
>         > >>> Browse[2]>
>         > >>> debug: if (!inherits(file, "connection")) stop("'file'
>         must be a
>         > >>> character string or connection")
>         > >>> Browse[2]>
>         > >>> debug: if (!all) return(.Internal(readDCF(file, fields,
>         keep.white)))
>         > >>> Browse[2]> str(file)
>         > >>> Classes 'gzfile', 'connection'  atomic [1:1] 3
>         > >>>   ..- attr(*, "conn_id")=<externalptr>
>         > >>> Browse[2]> file
>         > >>>                       description                      
>             class
>         > >>> "climatol_2.2.tar.gz/DESCRIPTION"                      
>          "gzfile"
>         > >>>                              mode                      
>              text
>         > >>>                              "rb"                      
>            "text"
>         > >>>                            opened                      
>          can read
>         > >>>                          "closed"                      
>             "yes"
>         > >>>                         can write
>         > >>>                             "yes"
>         > >>> Browse[2]>
>         > >>> debug: return(.Internal(readDCF(file, fields, keep.white)))
>         > >>> Browse[2]>
>         > >>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package",
>         > >>> "Type")) :
>         > >>>   cannot open the connection
>         > >>> In addition: Warning message:
>         > >>> In read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package", "Type")) :
>         > >>> cannot open compressed file
>         'climatol_2.2.tar.gz/DESCRIPTION', probable
>         > >>> reason 'No such file or directory'
>         > >>>>
>         > >>>
>         > >>> Well coming to debug: if (!all)
>         return(.Internal(readDCF(file, fields,
>         > >>> keep.white))) I loose control and R returns to prompt
>         with an error.
>         > >>>
>         > >>> Hopefully one of you can replicate this. If not then it
>         must have
>         > >>> something with Windows OS to do. But what?
>         > >>>
>         > >>>
>         > >>>
>         > >>> Yours sincerely / Med venlig hilsen
>         > >>>
>         > >>>
>         > >>> Frede Aakmann T?gersen
>         > >>> Specialist, M.Sc., Ph.D.
>         > >>> Plant Performance & Modeling
>         > >>>
>         > >>> Technology & Service Solutions
>         > >>> T +45 9730 5135 <tel:%2B45%209730%205135>
>         > >>> M +45 2547 6050 <tel:%2B45%202547%206050>
>         > >>> frtog at vestas.com <mailto:frtog at vestas.com>
>         > >>> http://www.vestas.com
>         > >>>
>         > >>> Company reg. name: Vestas Wind Systems A/S
>         > >>> This e-mail is subject to our e-mail disclaimer statement.
>         > >>> Please refer to www.vestas.com/legal/notice
>         <http://www.vestas.com/legal/notice><http://www.vestas.com/legal/notice>
>         > >>> If you have received this e-mail in error please contact
>         the sender.
>         > >>>
>         > >>>> -----Original Message-----
>         > >>>> From: r-help-bounces at r-project.org
>         <mailto:r-help-bounces at r-project.org>
>         > >>> [mailto:r-help-bounces at r-project.org
>         <mailto:r-help-bounces at r-project.org>]
>         > >>>> On Behalf Of Jeff Newmiller
>         > >>>> Sent: 20. april 2014 23:33
>         > >>>> To: Alpesh Pandya; Rui Barradas
>         > >>>> Cc: r-help at r-project.org <mailto:r-help at r-project.org>;
>         Uwe Ligges
>         > >>>> Subject: Re: [R] R 3.0.3, Windows 7: Problem installing
>         XML package
>         > >>>>
>         > >>>> Hard to help you when the problem simply does not
>         happen for others.
>         > >>>>
>         > >>>> As for Windows being not a focus, that is not at all
>         true. I use it
>         > >>> regularly on
>         > >>>> Windows at work. That being said, there are thousands
>         of packages and
>         > >>>> those each involve their own subset of R users. There
>         are also many
>         > >>>> operating system configurations that may not all be
>         fully tested.
>         > >>> Blaming "R"
>         > >>>> or "Windows", or blaming us for "preventing" you from
>         getting your
>         > >>>> education (isn't that something between you and your
>         educational
>         > >>>> institution?) are not going to be effective strategies
>         for problem
>         > >>> solving.
>         > >>>>
>         > >>>> Are you able to use other aspects of R beyond the XML
>         package? Have
>         > >>> you
>         > >>>> tried communicating with the maintainers of that package?
>         > >>>>
>         > >>>
>         ---------------------------------------------------------------------------
>         > >>>> Jeff Newmiller      The     .....       .....  Go
>         > >>> Live...
>         > >>>> DCN:<jdnewmil at dcn.davis.ca.us
>         <mailto:jdnewmil at dcn.davis.ca.us>>    Basics: ##.#.      
>         ##.#.  Live
>         > >>> Go...
>         > >>>>        Live:   OO#.. Dead: OO#..
>         > >>> Playing
>         > >>>> Research Engineer (Solar/Batteries            O.O#.    
>           #.O#.  with
>         > >>>> /Software/Embedded Controllers)               .OO#.    
>           .OO#.
>         > >>> rocks...1k
>         > >>>>
>         > >>>
>         ---------------------------------------------------------------------------
>         > >>>> Sent from my phone. Please excuse my brevity.
>         > >>>>
>         > >>>> On April 20, 2014 11:45:44 AM PDT, Alpesh Pandya
>         > >>>> <alpeshpandya at gmail.com
>         <mailto:alpeshpandya at gmail.com>> wrote:
>         > >>>>> I keep on trying from various networks but I still get
>         the same
>         > >>> error.
>         > >>>>> I
>         > >>>>> don't this this has anything to do with network or
>         ability to
>         > >>> download
>         > >>>>> the
>         > >>>>> package (as I can install other packages fine). This
>         must be
>         > >>> something
>         > >>>>> in
>         > >>>>> base R or dependencies issues (that R is not spelling
>         out).
>         > >>>>>
>         > >>>>> I know R is geared for Mac and Windows is kind of
>         looked down upon
>         > >>> but
>         > >>>>> I
>         > >>>>> have no option but use windows and need this XML
>         package running to
>         > >>>>> complete my education. Any help on this would be
>         appreciated.
>         > >>>>>
>         > >>>>>
>         > >>>>> On Mon, Apr 14, 2014 at 2:24 PM, Alpesh Pandya
>         > >>>>> <alpeshpandya at gmail.com
>         <mailto:alpeshpandya at gmail.com>>wrote:
>         > >>>>>
>         > >>>>>> Thank you for response Rui.
>         > >>>>>>
>         > >>>>>> I still get the same error with this repository.
>         > >>>>>>
>         > >>>>>> Installing package into
>         > >>>>> ???C:/Users/APandya/Documents/R/win-library/3.0???
>         > >>>>>> (as ???lib??? is unspecified)
>         > >>>>>> trying URL '
>         > >>>>>>
>         http://cran.dcc.fc.up.pt/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>         > >>>>>> Content type 'application/zip' length 4288136 bytes
>         (4.1 Mb)
>         > >>>>>> opened URL
>         > >>>>>> downloaded 4.1 Mb
>         > >>>>>>
>         > >>>>>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package",
>         > >>>>> "Type"))
>         > >>>>>> :
>         > >>>>>>    cannot open the connection
>         > >>>>>> In addition: Warning messages:
>         > >>>>>> 1: In download.file(url, destfile, method, mode =
>         "wb", ...) :
>         > >>>>>>    downloaded length 4276224 != reported length 4288136
>         > >>>>>> 2: In unzip(zipname, exdir = dest) : error 1 in
>         extracting from
>         > >>> zip
>         > >>>>> file
>         > >>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package",
>         > >>>>> "Type")) :
>         > >>>>>>    cannot open compressed file 'XML/DESCRIPTION',
>         probable reason
>         > >>> 'No
>         > >>>>> such
>         > >>>>>> file or directory'
>         > >>>>>>
>         > >>>>>>
>         > >>>>>>
>         > >>>>>> On Mon, Apr 14, 2014 at 2:17 PM, Rui Barradas
>         > >>>>> <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>wrote:
>         > >>>>>>
>         > >>>>>>> Hello,
>         > >>>>>>> I have package XML installed on Windows 7, R 3.0.3
>         and I had no
>         > >>>>> problem
>         > >>>>>>> at all. Can't you try (it worked with me)
>         > >>>>>>>
>         > >>>>>>> install.packages("XML", repos =
>         "http://cran.dcc.fc.up.pt")
>         > >>>>>>>
>         > >>>>>>> Hope this helps,
>         > >>>>>>>
>         > >>>>>>> Rui Barradas
>         > >>>>>>>
>         > >>>>>>> Em 14-04-2014 16:24, Alpesh Pandya escreveu:
>         > >>>>>>>
>         > >>>>>>>   I have tried these sources (almost all US mirrors):
>         > >>>>>>>>
>         > >>>>>>>>
>         > >>>>
>         > >>>>
>         http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         > >>>
>         http://cran.stat.ucla.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         http://streaming.stat.iastate.edu/CRAN/bin/windows/contrib/
>         > >>>>>>>> 3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         > >>>>>
>         http://ftp.ussg.iu.edu/CRAN/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         > >>>>
>         > >>>>
>         http://rweb.quant.ku.edu/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>> http://watson.nci.nih.gov/cran_mirror/bin/windows/
>         > >>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         http://cran.mtu.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         http://cran.wustl.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         http://cran.case.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         > >>>>
>         > >>>>
>         http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>
>         > >>>>>
>         http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/3.0/XML_3.98-
>         > >>>> 1.1.zip
>         > >>>>>>>>
>         > >>>>>>>> I have confirmed with IT that there is no
>         restriction on
>         > >>>>> downloading this
>         > >>>>>>>> zip file from any of these sources. Also I am
>         getting same error
>         > >>>>> when I
>         > >>>>>>>> try
>         > >>>>>>>> from my home network as well.
>         > >>>>>>>>
>         > >>>>>>>>
>         > >>>>>>>> On Sun, Apr 13, 2014 at 9:46 AM, Uwe Ligges <
>         > >>>>>>>> ligges at statistik.tu-dortmund.de
>         <mailto:ligges at statistik.tu-dortmund.de>
>         > >>>>>>>>
>         > >>>>>>>>> wrote:
>         > >>>>>>>>>
>         > >>>>>>>>
>         > >>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>> On 13.04.2014 01:30, Alpesh Pandya wrote:
>         > >>>>>>>>>
>         > >>>>>>>>>   @Uwe I tried the same steps from office as well
>         as home
>         > >>> network
>         > >>>>> with
>         > >>>>>>>>>> same
>         > >>>>>>>>>> results. Are you using windows 7 with R 3.0.3?
>         > >>>>>>>>>>
>         > >>>>>>>>>> I have seen same question being asked by others
>         without any
>         > >>>>>>>>>> resolution. Is
>         > >>>>>>>>>> anything special about XML package? I am OK use
>         older version
>         > >>> of
>         > >>>>>>>>>> package
>         > >>>>>>>>>> but in archives there are no zip files (only gz
>         files). Is
>         > >>>>> windows
>         > >>>>>>>>>> platform
>         > >>>>>>>>>> not recommended for R?
>         > >>>>>>>>>>
>         > >>>>>>>>>>
>         > >>>>>>>>> Right, and you can try to install these from sources.
>         > >>>>>>>>> But I doubt you need it. You still have not told
>         us if you
>         > >>> tried
>         > >>>>> another
>         > >>>>>>>>> mirror to download the XML file from and what you
>         local IT
>         > >>> support
>         > >>>>> tells
>         > >>>>>>>>> you while your downloads are incomplete.
>         > >>>>>>>>>
>         > >>>>>>>>> Best,
>         > >>>>>>>>> Uwe Ligges
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>
>         > >>>>>>>>>> On Sat, Apr 12, 2014 at 7:22 PM, Uwe Ligges <
>         > >>>>>>>>>> ligges at statistik.tu-dortmund.de
>         <mailto:ligges at statistik.tu-dortmund.de>
>         > >>>>>>>>>>
>         > >>>>>>>>>>   wrote:
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>
>         > >>>>>>>>>>
>         > >>>>>>>>>>> On 12.04.2014 22:39, Alpesh Pandya wrote:
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>  Thank you for response Uwe. I tried multiple
>         times by
>         > >>>>> downloading
>         > >>>>>>>>>>> the
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>> zip
>         > >>>>>>>>>>>> file from many sources but still the same
>         error. This is a
>         > >>>>> major road
>         > >>>>>>>>>>>> block
>         > >>>>>>>>>>>> for me in using R. Appreciate any help on this.
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>   Please ask your local IT staff.
>         > >>>>>>>>>>>
>         > >>>>>>>>>>> I get, using the same mirror:
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>
>         options("repos"=c(CRAN="http://watson.nci.nih.gov/cran_mirror"))
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>> install.packages("XML", lib="d:/temp")
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>> trying URL
>         > >>> 'http://watson.nci.nih.gov/cran_mirror/bin/windows/
>         > >>>>>>>>>>>
>         > >>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip'
>         > >>>>>>>>>>> Content type 'application/zip' length 4288136
>         bytes (4.1 Mb)
>         > >>>>>>>>>>> opened URL
>         > >>>>>>>>>>> downloaded 4.1 Mb
>         > >>>>>>>>>>>
>         > >>>>>>>>>>> package 'XML' successfully unpacked and MD5 sums
>         checked
>         > >>>>>>>>>>>
>         > >>>>>>>>>>> The downloaded binary packages are in
>         > >>>>>>>>>>>        d:\temp\RtmpqMqL8L\downloaded_packages
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>> Best,
>         > >>>>>>>>>>> Uwe Ligges
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>
>         > >>>>>>>>>>>   On Fri, Apr 11, 2014 at 6:53 PM, Uwe Ligges <
>         > >>>>>>>>>>>> ligges at statistik.tu-dortmund.de
>         <mailto:ligges at statistik.tu-dortmund.de>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>    wrote:
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>    Works for me.
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>> Best,
>         > >>>>>>>>>>>>> Uwe Ligges
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>> On 11.04.2014 17:10, Alpesh Pandya wrote:
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>   Using install.package('XML') command
>         produces this
>         > >>> error:
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>
>         > >>>>>>>>>>>>>> trying URL
>         > >>>>>>>>>>>>>> '
>         > >>>>>>>>>>>>>>
>         http://watson.nci.nih.gov/cran_mirror/bin/windows/
>         > >>>>>>>>>>>>>> contrib/3.0/XML_3.98-1.1.zip
>         > >>>>>>>>>>>>>> '
>         > >>>>>>>>>>>>>> Content type 'application/zip' length 4288136
>         bytes (4.1
>         > >>> Mb)
>         > >>>>>>>>>>>>>> opened URL
>         > >>>>>>>>>>>>>> downloaded 4.1 Mb
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>> Error in read.dcf(file.path(pkgname,
>         "DESCRIPTION"),
>         > >>>>> c("Package",
>         > >>>>>>>>>>>>>> "Type")) :
>         > >>>>>>>>>>>>>>        cannot open the connection
>         > >>>>>>>>>>>>>> In addition: Warning messages:
>         > >>>>>>>>>>>>>> 1: In download.file(url, destfile, method,
>         mode = "wb",
>         > >>> ...)
>         > >>>>> :
>         > >>>>>>>>>>>>>>        downloaded length 4276224 != reported
>         length 4288136
>         > >>>>>>>>>>>>>> 2: In unzip(zipname, exdir = dest) : error 1
>         in extracting
>         > >>>> >from zip
>         > >>>>>>>>>>>>>> file
>         > >>>>>>>>>>>>>> 3: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>         > >>>>> c("Package",
>         > >>>>>>>>>>>>>> "Type"))
>         > >>>>>>>>>>>>>> :
>         > >>>>>>>>>>>>>>        cannot open compressed file
>         'XML/DESCRIPTION',
>         > >>> probable
>         > >>>>>>>>>>>>>> reason
>         > >>>>>>>>>>>>>> 'No
>         > >>>>>>>>>>>>>> such
>         > >>>>>>>>>>>>>> file or directory'
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>> Upon receiving this error, I downloaded
>         XML_3.98-1.1.zip
>         > >>>>> directly
>         > >>>>>>>>>>>>>> from
>         > >>>>>>>>>>>>>> cran
>         > >>>>>>>>>>>>>> site. But this zip file is not a valid
>         archive (cannot
>         > >>> open
>         > >>>>> using
>         > >>>>>>>>>>>>>> winzip).
>         > >>>>>>>>>>>>>> Also trying to install using this downloaded
>         file produces
>         > >>>>> the
>         > >>>>>>>>>>>>>> following
>         > >>>>>>>>>>>>>> error:
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>> Installing package into
>         'C:/Users/APandya/Documents/R/
>         > >>>>>>>>>>>>>> win-library/3.0'
>         > >>>>>>>>>>>>>> (as 'lib' is unspecified)
>         > >>>>>>>>>>>>>> Warning in install.packages :
>         > >>>>>>>>>>>>>>        error 1 in extracting from zip file
>         > >>>>>>>>>>>>>> Warning in install.packages :
>         > >>>>>>>>>>>>>>        cannot open compressed file
>         'XML/DESCRIPTION',
>         > >>> probable
>         > >>>>>>>>>>>>>> reason
>         > >>>>>>>>>>>>>> 'No
>         > >>>>>>>>>>>>>> such
>         > >>>>>>>>>>>>>> file or directory'
>         > >>>>>>>>>>>>>> Error in install.packages : cannot open the
>         connection
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>> I  downloaded this zip file from multiple
>         sources and
>         > >>> tried
>         > >>>>> to
>         > >>>>>>>>>>>>>> install
>         > >>>>>>>>>>>>>> with
>         > >>>>>>>>>>>>>> same result.
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>>>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>>>
>         > >>>>>>>>>>
>         > >>>>>>>>>>
>         > >>>>>>>>
>         > >>>>>>>>
>         > >>>>>>
>         > >>>>>>
>         > >>>>>> --
>         > >>>>>> Thanks and Regards
>         > >>>>>> Alpesh
>         > >>>>>>
>         > >>>>
>         > >>>> ______________________________________________
>         > >>>> R-help at r-project.org <mailto:R-help at r-project.org>
>         mailing list
>         > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>         > >>>> PLEASE do read the posting guide
>         http://www.R-project.org/posting-
>         > >>>> guide.html
>         > >>>> and provide commented, minimal, self-contained,
>         reproducible code.
>         > >>
>         > >>
>         > >>    [[alternative HTML version deleted]]
>         > >>
>         > >> ______________________________________________
>         > >> R-help at r-project.org <mailto:R-help at r-project.org>
>         mailing list
>         > >> https://stat.ethz.ch/mailman/listinfo/r-help
>         > >> PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         > >> and provide commented, minimal, self-contained,
>         reproducible code.
>         > >
>         > > ______________________________________________
>         > > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list
>         > > https://stat.ethz.ch/mailman/listinfo/r-help
>         > > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         > > and provide commented, minimal, self-contained,
>         reproducible code.
>         > >
>
>
>
>
>
> -- 
> Thanks and Regards
> Alpesh



From spencer.graves at structuremonitoring.com  Mon Apr 21 16:40:02 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 21 Apr 2014 07:40:02 -0700
Subject: [R] reading & understanding SVG?
In-Reply-To: <CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
References: <5354C933.4050808@structuremonitoring.com>
	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
Message-ID: <53552DC2.2010009@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/6d47651b/attachment-0001.pl>

From spencer.graves at structuremonitoring.com  Mon Apr 21 16:43:29 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 21 Apr 2014 07:43:29 -0700
Subject: [R] reading & understanding SVG?
In-Reply-To: <CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
References: <5354C933.4050808@structuremonitoring.com>
	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
Message-ID: <53552E91.7050805@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/1f9e3dc8/attachment-0001.pl>

From erinm.hodgess at gmail.com  Mon Apr 21 16:48:45 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 21 Apr 2014 09:48:45 -0500
Subject: [R] constructing a sequence of POSIXct dates
Message-ID: <CACxE24nwn3dUHxFKyF9b=r7VTNFT2WGPrNdHWAod_+kQrQ3Z-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/a8a4e6d0/attachment-0001.pl>

From erinm.hodgess at gmail.com  Mon Apr 21 16:55:18 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 21 Apr 2014 09:55:18 -0500
Subject: [R] constructing a sequence of POSIXct dates
In-Reply-To: <CACxE24nwn3dUHxFKyF9b=r7VTNFT2WGPrNdHWAod_+kQrQ3Z-A@mail.gmail.com>
References: <CACxE24nwn3dUHxFKyF9b=r7VTNFT2WGPrNdHWAod_+kQrQ3Z-A@mail.gmail.com>
Message-ID: <CACxE24==H4Th-kQ2NrDu7F0jxUM66MVHCQvNZLvVQg18yeJqCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/35c5d426/attachment-0001.pl>

From michael.weylandt at gmail.com  Mon Apr 21 17:04:14 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 21 Apr 2014 11:04:14 -0400
Subject: [R] constructing a sequence of POSIXct dates
In-Reply-To: <CACxE24==H4Th-kQ2NrDu7F0jxUM66MVHCQvNZLvVQg18yeJqCg@mail.gmail.com>
References: <CACxE24nwn3dUHxFKyF9b=r7VTNFT2WGPrNdHWAod_+kQrQ3Z-A@mail.gmail.com>
	<CACxE24==H4Th-kQ2NrDu7F0jxUM66MVHCQvNZLvVQg18yeJqCg@mail.gmail.com>
Message-ID: <D1784C07-10AB-4C36-BC8A-A5234026908D@gmail.com>



On Apr 21, 2014, at 10:55, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Never mind....solved it

xkcd.com/979/


> 
> 
> On Mon, Apr 21, 2014 at 9:48 AM, Erin Hodgess <erinm.hodgess at gmail.com>wrote:
> 
>> Hello!
>> 
>> I have the following:
>> 
>>> time1a <- as.POSIXct(paste(2008,08,01,sep="-"))
>>> time1b <- as.POSIXct(paste(2008,08,11,sep="-"))
>>> time1a
>> [1] "2008-08-01 CDT"
>>> time1b
>> [1] "2008-08-11 CDT"
>>> time1c <- seq(from=as.POSIXct(time1a),to=as.POSIXct(time1b),by="days")
>>> class(time1c)
>> [1] "POSIXct" "POSIXt"
>>> print(time1c)
>> [1] "2008-08-01 CDT" "2008-08-02 CDT" "2008-08-03 CDT" "2008-08-04 CDT"
>> [5] "2008-08-05 CDT" "2008-08-06 CDT" "2008-08-07 CDT" "2008-08-08 CDT"
>> [9] "2008-08-09 CDT" "2008-08-10 CDT" "2008-08-11 CDT"
>> 
>> I have generated the correct sequence.  However, time1c must be a POSIXct
>> object.  How do I remove the second class, please?

Don't. POSIXt is a virtual superclass to which all POSIXct objects should belong. 

Code which works with POSIXct objects but not POSIXct/POSIXt is almost certainly buggy. 

Michael



From alpeshpandya at gmail.com  Mon Apr 21 16:30:23 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Mon, 21 Apr 2014 10:30:23 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <53551CFC.8000307@gmail.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
	<1398078658.5143.2.camel@milan> <5354FF1C.3000607@gmail.com>
	<1398086383.5143.24.camel@milan> <53551CFC.8000307@gmail.com>
Message-ID: <CAEv=oxPd1hTBgE=CQN1dxcM6sSR3xReO2dKZoLM=nTH+vtVSpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/51a31547/attachment-0001.pl>

From boris.steipe at utoronto.ca  Mon Apr 21 17:19:28 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 21 Apr 2014 11:19:28 -0400
Subject: [R] reading & understanding SVG?
In-Reply-To: <53552E91.7050805@structuremonitoring.com>
References: <5354C933.4050808@structuremonitoring.com>
	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
	<53552E91.7050805@structuremonitoring.com>
Message-ID: <AE9C88A9-C6EF-4A99-9B1A-A4706DC5FED1@utoronto.ca>

Indeed you don't need R. This is accomplished in two minutes with the excellent, free, and open software inkscape. But before I type more and since I have it open anyway, I'll just send you the three images off-list.

B.




On 2014-04-21, at 10:43 AM, Spencer Graves wrote:

> p.s.  I don't need to use R for this, though I'd prefer to stay with 
> something that's free, open-source software.  I tried GIMP, but couldn't 
> see how to access the layers.
> 
> 
> Hi, Peter:
> 
> 
> On 4/21/2014 3:34 AM, Peter Crowther wrote:
>> Spencer, what "components" do you want to extract?  Do the SVG files 
>> have a reasonably well-defined structure?  I've done a fair amount 
>> with SVG and may be able to help.
> 
> 
>       Thanks.  I should have been more specific:  I'd like to try to 
> extract into 3 separate files the weapons of mass destruction symbols 
> from the "WMD_world_map.svg" image in the Wiikipedia article on "Weapons 
> of mass destruction" 
> (https://upload.wikimedia.org/wikipedia/commons/1/1d/WMD_world_map.svg).
> 
> 
>       I've opened it in Emacs enough to see that it's a structured text 
> file consistent with what little I know about XML.  It looks to me like 
> a list, but without convenient names for the list components.
> 
> 
>       Thanks again,
>       Spencer
> 
> 
> p.s.  I found the biohazard symbol by itself 
> (https://upload.wikimedia.org/wikipedia/commons/c/c0/Biohazard_symbol.svg), 
> but I didn't find the radioactive and skull-and-crossbones symbols in 
> exactly that form.  (I didn't look seriously beyond Wikimedia commons, 
> because I'm making a video, and I want something I can release under the 
> Creative Commons Attribution-Share Alike license.
> 
>> 
>> - Peter
>> 
>> 
>> On 21 April 2014 08:30, Spencer Graves 
>> <spencer.graves at structuremonitoring.com 
>> <mailto:spencer.graves at structuremonitoring.com>> wrote:
>> 
>>    Hello:
>> 
>> 
>>          What would you suggest I use to read and manipulate an SVG file?
>> 
>> 
>>          I'd like to extract components of an svg file.  I see it's
>>    XML, but I have very little experience with either SVG or XML.
>>     I've tried GIMP and findFn{sos} without finding a clear
>>    suggestion of where to start.
>> 
>> 
>>          Thanks,
>>          Spencer
>> 
>>    ______________________________________________
>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>    PLEASE do read the posting guide
>>    http://www.R-project.org/posting-guide.html
>>    and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 
> -- 
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:www.structuremonitoring.com
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From spencer.graves at structuremonitoring.com  Mon Apr 21 17:49:18 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 21 Apr 2014 08:49:18 -0700
Subject: [R] reading & understanding SVG?
In-Reply-To: <AE9C88A9-C6EF-4A99-9B1A-A4706DC5FED1@utoronto.ca>
References: <5354C933.4050808@structuremonitoring.com>
	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
	<53552E91.7050805@structuremonitoring.com>
	<AE9C88A9-C6EF-4A99-9B1A-A4706DC5FED1@utoronto.ca>
Message-ID: <53553DFE.9050202@structuremonitoring.com>

       Awesome.


       Are there things one might like to do in R reading them directly 
as svg that aren't so easy after converting to another format like png?


       Thanks again,
       Spencer


p.s.  To confirm, I received the three files you sent offline, converted 
then to png using GIMP (already installed), and plotted one using 
rasterImageAdj (recently added to Ecfun on R-Forge; this calls 
rasterImage{graphics} after reducing either the x or y space to 
eliminate distortion.  This makes it easier to use if you don't want 
distortion in image from rasterImage.)


On 4/21/2014 8:19 AM, Boris Steipe wrote:
> Indeed you don't need R. This is accomplished in two minutes with the excellent, free, and open software inkscape. But before I type more and since I have it open anyway, I'll just send you the three images off-list.
>
> B.
>
>
>
>
> On 2014-04-21, at 10:43 AM, Spencer Graves wrote:
>
>> p.s.  I don't need to use R for this, though I'd prefer to stay with
>> something that's free, open-source software.  I tried GIMP, but couldn't
>> see how to access the layers.
>>
>>
>> Hi, Peter:
>>
>>
>> On 4/21/2014 3:34 AM, Peter Crowther wrote:
>>> Spencer, what "components" do you want to extract?  Do the SVG files
>>> have a reasonably well-defined structure?  I've done a fair amount
>>> with SVG and may be able to help.
>>
>>        Thanks.  I should have been more specific:  I'd like to try to
>> extract into 3 separate files the weapons of mass destruction symbols
>> from the "WMD_world_map.svg" image in the Wiikipedia article on "Weapons
>> of mass destruction"
>> (https://upload.wikimedia.org/wikipedia/commons/1/1d/WMD_world_map.svg).
>>
>>
>>        I've opened it in Emacs enough to see that it's a structured text
>> file consistent with what little I know about XML.  It looks to me like
>> a list, but without convenient names for the list components.
>>
>>
>>        Thanks again,
>>        Spencer
>>
>>
>> p.s.  I found the biohazard symbol by itself
>> (https://upload.wikimedia.org/wikipedia/commons/c/c0/Biohazard_symbol.svg),
>> but I didn't find the radioactive and skull-and-crossbones symbols in
>> exactly that form.  (I didn't look seriously beyond Wikimedia commons,
>> because I'm making a video, and I want something I can release under the
>> Creative Commons Attribution-Share Alike license.
>>
>>> - Peter
>>>
>>>
>>> On 21 April 2014 08:30, Spencer Graves
>>> <spencer.graves at structuremonitoring.com
>>> <mailto:spencer.graves at structuremonitoring.com>> wrote:
>>>
>>>     Hello:
>>>
>>>
>>>           What would you suggest I use to read and manipulate an SVG file?
>>>
>>>
>>>           I'd like to extract components of an svg file.  I see it's
>>>     XML, but I have very little experience with either SVG or XML.
>>>      I've tried GIMP and findFn{sos} without finding a clear
>>>     suggestion of where to start.
>>>
>>>
>>>           Thanks,
>>>           Spencer
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     PLEASE do read the posting guide
>>>     http://www.R-project.org/posting-guide.html
>>>     and provide commented, minimal, self-contained, reproducible code.
>>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From boris.steipe at utoronto.ca  Mon Apr 21 18:02:12 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 21 Apr 2014 12:02:12 -0400
Subject: [R] reading & understanding SVG?
In-Reply-To: <53553DFE.9050202@structuremonitoring.com>
References: <5354C933.4050808@structuremonitoring.com>
	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
	<53552E91.7050805@structuremonitoring.com>
	<AE9C88A9-C6EF-4A99-9B1A-A4706DC5FED1@utoronto.ca>
	<53553DFE.9050202@structuremonitoring.com>
Message-ID: <CF0E2BEE-C984-4952-B54A-C44699B6B644@utoronto.ca>

Google for png vs. svg.
png is a raster graphics format, svg is a vector graphics format.
Which one is the right one to used depends totally on the purpose.


B.


On 2014-04-21, at 11:49 AM, Spencer Graves wrote:

>      Awesome.
> 
> 
>      Are there things one might like to do in R reading them directly as svg that aren't so easy after converting to another format like png?
> 
> 
>      Thanks again,
>      Spencer
> 
> 
> p.s.  To confirm, I received the three files you sent offline, converted then to png using GIMP (already installed), and plotted one using rasterImageAdj (recently added to Ecfun on R-Forge; this calls rasterImage{graphics} after reducing either the x or y space to eliminate distortion.  This makes it easier to use if you don't want distortion in image from rasterImage.)
> 
> 
> On 4/21/2014 8:19 AM, Boris Steipe wrote:
>> Indeed you don't need R. This is accomplished in two minutes with the excellent, free, and open software inkscape. But before I type more and since I have it open anyway, I'll just send you the three images off-list.
>> 
>> B.
>> 
>> 
>> 
>> 
>> On 2014-04-21, at 10:43 AM, Spencer Graves wrote:
>> 
>>> p.s.  I don't need to use R for this, though I'd prefer to stay with
>>> something that's free, open-source software.  I tried GIMP, but couldn't
>>> see how to access the layers.
>>> 
>>> 
>>> Hi, Peter:
>>> 
>>> 
>>> On 4/21/2014 3:34 AM, Peter Crowther wrote:
>>>> Spencer, what "components" do you want to extract?  Do the SVG files
>>>> have a reasonably well-defined structure?  I've done a fair amount
>>>> with SVG and may be able to help.
>>> 
>>>       Thanks.  I should have been more specific:  I'd like to try to
>>> extract into 3 separate files the weapons of mass destruction symbols
>>> from the "WMD_world_map.svg" image in the Wiikipedia article on "Weapons
>>> of mass destruction"
>>> (https://upload.wikimedia.org/wikipedia/commons/1/1d/WMD_world_map.svg).
>>> 
>>> 
>>>       I've opened it in Emacs enough to see that it's a structured text
>>> file consistent with what little I know about XML.  It looks to me like
>>> a list, but without convenient names for the list components.
>>> 
>>> 
>>>       Thanks again,
>>>       Spencer
>>> 
>>> 
>>> p.s.  I found the biohazard symbol by itself
>>> (https://upload.wikimedia.org/wikipedia/commons/c/c0/Biohazard_symbol.svg),
>>> but I didn't find the radioactive and skull-and-crossbones symbols in
>>> exactly that form.  (I didn't look seriously beyond Wikimedia commons,
>>> because I'm making a video, and I want something I can release under the
>>> Creative Commons Attribution-Share Alike license.
>>> 
>>>> - Peter
>>>> 
>>>> 
>>>> On 21 April 2014 08:30, Spencer Graves
>>>> <spencer.graves at structuremonitoring.com
>>>> <mailto:spencer.graves at structuremonitoring.com>> wrote:
>>>> 
>>>>    Hello:
>>>> 
>>>> 
>>>>          What would you suggest I use to read and manipulate an SVG file?
>>>> 
>>>> 
>>>>          I'd like to extract components of an svg file.  I see it's
>>>>    XML, but I have very little experience with either SVG or XML.
>>>>     I've tried GIMP and findFn{sos} without finding a clear
>>>>    suggestion of where to start.
>>>> 
>>>> 
>>>>          Thanks,
>>>>          Spencer
>>>> 
>>>>    ______________________________________________
>>>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>>>    PLEASE do read the posting guide
>>>>    http://www.R-project.org/posting-guide.html
>>>>    and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 



From dcarlson at tamu.edu  Mon Apr 21 18:06:58 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 21 Apr 2014 11:06:58 -0500
Subject: [R] reading & understanding SVG?
In-Reply-To: <53552E91.7050805@structuremonitoring.com>
References: <5354C933.4050808@structuremonitoring.com>	<CALhdq6vs19ftFS11hEq5iKG8+6E8UFOwRPajVax=b+o9OExeDQ@mail.gmail.com>
	<53552E91.7050805@structuremonitoring.com>
Message-ID: <025301cf5d7b$b960c080$2c224180$@tamu.edu>

I was able to grab the logos by bringing the .svg file into
Inkscape (open source .svg editor). The three logos are grouped
so you can select them and then paste them into another
document. Then you'll have to ungroup the three logos and select
each logo separately.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Spencer
Graves
Sent: Monday, April 21, 2014 9:43 AM
To: Peter Crowther
Cc: R list
Subject: Re: [R] reading & understanding SVG?

p.s.  I don't need to use R for this, though I'd prefer to stay
with 
something that's free, open-source software.  I tried GIMP, but
couldn't 
see how to access the layers.


Hi, Peter:


On 4/21/2014 3:34 AM, Peter Crowther wrote:
> Spencer, what "components" do you want to extract?  Do the SVG
files 
> have a reasonably well-defined structure?  I've done a fair
amount 
> with SVG and may be able to help.


       Thanks.  I should have been more specific:  I'd like to
try to 
extract into 3 separate files the weapons of mass destruction
symbols 
from the "WMD_world_map.svg" image in the Wiikipedia article on
"Weapons 
of mass destruction" 
(https://upload.wikimedia.org/wikipedia/commons/1/1d/WMD_world_m
ap.svg).


       I've opened it in Emacs enough to see that it's a
structured text 
file consistent with what little I know about XML.  It looks to
me like 
a list, but without convenient names for the list components.


       Thanks again,
       Spencer


p.s.  I found the biohazard symbol by itself 
(https://upload.wikimedia.org/wikipedia/commons/c/c0/Biohazard_s
ymbol.svg), 
but I didn't find the radioactive and skull-and-crossbones
symbols in 
exactly that form.  (I didn't look seriously beyond Wikimedia
commons, 
because I'm making a video, and I want something I can release
under the 
Creative Commons Attribution-Share Alike license.

>
> - Peter
>
>
> On 21 April 2014 08:30, Spencer Graves 
> <spencer.graves at structuremonitoring.com 
> <mailto:spencer.graves at structuremonitoring.com>> wrote:
>
>     Hello:
>
>
>           What would you suggest I use to read and manipulate
an SVG file?
>
>
>           I'd like to extract components of an svg file.  I
see it's
>     XML, but I have very little experience with either SVG or
XML.
>      I've tried GIMP and findFn{sos} without finding a clear
>     suggestion of where to start.
>
>
>           Thanks,
>           Spencer
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing
list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained,
reproducible code.
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San JosC), CA 95126
ph:  408-655-4567
web:www.structuremonitoring.com


	[[alternative HTML version deleted]]



From jdnewmil at dcn.davis.CA.us  Mon Apr 21 20:09:31 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 21 Apr 2014 11:09:31 -0700
Subject: [R] for loop to list files
In-Reply-To: <BLU0-SMTP32709C0C3F94AF3A91A14F0D95E0@phx.gbl>
References: <BLU0-SMTP4704C9A906CEC9520A80FA7D95E0@phx.gbl>
	<CAKL8G3H0CpB=-Y+xoMnTfruEaC=OYSc=VNM0J4e3BPKvFLf0sQ@mail.gmail.com>
	<BLU0-SMTP32709C0C3F94AF3A91A14F0D95E0@phx.gbl>
Message-ID: <33bc1772-f07d-4de5-a913-c5161e7fbc1c@email.android.com>

You seem overly intent on getting a for loop into your code. Jorge's solution has the same effect as your for loop.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 21, 2014 1:55:38 AM PDT, "Beatriz R. Gonzalez Dominguez" <aguitatierra at hotmail.com> wrote:
>Hi Jorge,
>
>Thanks so much! Exactly what I wanted. Finally I wrote:
>
>for(i in 1976:1981){
>PE.files_01_7681 <- paste("val_mapped_petpe_", 1976:i, "01.txt",
>sep="")
>}
>
>Cheers,
>Bea
>
>
>On 21/04/2014 10:46, Jorge I Velez wrote:
>> Hi Beatriz,
>>
>> Try
>>
>> paste("val_mapped_petpe_", 1976:1981, "01.txt", sep="")
>>
>> Best,
>> Jorge.-
>>
>>
>> On Mon, Apr 21, 2014 at 6:43 PM, Beatriz R. Gonzalez Dominguez 
>> <aguitatierra at hotmail.com <mailto:aguitatierra at hotmail.com>> wrote:
>>
>>     Dear all,
>>
>>     I'm trying to create a loop to select a series of files into my
>>     computer but I haven't been successful until now. I've looked
>into
>>     different possibilities but none has worked. I'd appretiate if
>you
>>     could help me by providing me with some ideas.
>>
>>     Basically what  I'd like to do is to create a character string
>>     variable [1:5], same as the one that could be obtained with
>>     'list.files', but using a 'for' loop.
>>
>>     This is one of the things I've tried but obviously doesn't yield
>>     the results I would like:
>>
>>     for(i in 1976:1981){
>>       PE.files_01_7681 <- paste("val_mapped_petpe_", i, "01.txt",
>sep="")
>>      paste(PE.files_01_7681[i])
>>     }
>>
>>     Many thanks!
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>>
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From marongiu.luigi at gmail.com  Mon Apr 21 20:24:07 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 21 Apr 2014 19:24:07 +0100
Subject: [R] find maximum values on the density function of a bimodal
	distribution
Message-ID: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/bc1061f4/attachment-0001.pl>

From marta_mtm at hotmail.com  Mon Apr 21 17:08:27 2014
From: marta_mtm at hotmail.com (=?iso-8859-1?B?TWFydGEgVG9iZfFh?=)
Date: Mon, 21 Apr 2014 17:08:27 +0200
Subject: [R] Hi ,
 Is it possible select a different number of rows by each group with
 R????
Message-ID: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/271b0865/attachment-0001.pl>

From alpeshpandya at gmail.com  Mon Apr 21 17:11:53 2014
From: alpeshpandya at gmail.com (Alpesh Pandya)
Date: Mon, 21 Apr 2014 11:11:53 -0400
Subject: [R] R 3.0.3, Windows 7: Problem installing XML package
In-Reply-To: <53552D44.3020608@gmail.com>
References: <1hpqqgymypyh2r0egojexoow.1398072443517@email.android.com>
	<1398078658.5143.2.camel@milan> <5354FF1C.3000607@gmail.com>
	<1398086383.5143.24.camel@milan> <53551CFC.8000307@gmail.com>
	<CAEv=oxPd1hTBgE=CQN1dxcM6sSR3xReO2dKZoLM=nTH+vtVSpw@mail.gmail.com>
	<53552D44.3020608@gmail.com>
Message-ID: <CAEv=oxMRwwXiQXrYfy9SJ8sDGg2vMb11Nb=FdjFCj_-CrFQcFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/7e9af9d3/attachment-0001.pl>

From dcarlson at tamu.edu  Mon Apr 21 22:38:19 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 21 Apr 2014 15:38:19 -0500
Subject: [R] find maximum values on the density function of a
	bimodal	distribution
In-Reply-To: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
Message-ID: <02d601cf5da1$a1121b70$e3365250$@tamu.edu>

This will work, as long as there are exactly 2 distinct modes:

> runs <- rle(sign(diff(d.rv$y)))
> length(runs$lengths) # There should be 4 runs if there are
exactly 2 modes
[1] 4
> mode1 <- runs$lengths[1]+1 
> mode2 <- length(d.rv$x)- runs$lengths[4]
> d.rv$y[c(mode1, mode2)] # The 2 modes:
[1] 0.04012983 0.04049404

--------------------------------------------------
David L Carlson
Listowner, Webmaster
http://people.tamu.edu/~dcarlson/nar/

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Monday, April 21, 2014 1:24 PM
To: r-help at r-project.org
Subject: [R] find maximum values on the density function of a
bimodal distribution

*dear all,I have a bimodal distribution and i would like to
identify the
two most frequent values. Using unimodal values i found from the
R archive
that is possible to identify the most frequent value, which
corresponds to
the peak of the density function:from Bert Gunter, Fri Mar 13
04rv <-
rbinom(10000,1,0.1) + rnorm(10000)d.rv = density(rv)d.x =
d.rv$xd.y =
d.rv$yd.rv.max =
d.rv$x[which.max(d.rv$y)]plot(d.rv)abline(v=d.rv.max)The
following is instead a bimodal distribution, so how to identify
the two
peak values?rv <-c(-0.161948986691092,    6.25551346546337,
14.4449902518518,    5.71035851092391,    14.2659690175213,
13.4326694168529,    2.25851352934142,    19.0283322756163,
18.7578638985237,    3.6079681449722,    12.8469831785319,
16.8172446560292,    0.586180794938773,    -2.78468096182699,
6.41435801855101,    5.40404032358274,    16.422996950473,
0.0146677573458032,    6.42413783291763,    16.9133720373153,
21.2106745914211,    4.04126872437582,    10.8506381906698,
8.74969277743266,    14.2820697977719,    15.9914414284944,
8.35395871093583,    22.322063211793,    14.3922587603495,
-0.889640152783791,    15.5590006991235,    13.8636215566311,
8.04175502056292,    -1.85932938527655,    3.0791620072771,
20.5240745935955,    3.68821147789088,    7.38116287748327,
8.13585591202069,    5.94733543506892,    7.77891267272758,
14.4774347329043,    0.309628817532129,    -9.0260821589798,
12.4102239527495,    -4.64595423395751,    17.3141235128072,
20.1952807795295,    -8.18424754421263,
-1.58917260547841)d.rv =
density(rv)d.x = d.rv$xd.y = d.rv$yd.rv.max =
d.rv$x[which.max(d.rv$y)]plot(d.rv)Thank you.Best wishes,Luigi*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From tim at mlhim.org  Mon Apr 21 22:40:35 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Mon, 21 Apr 2014 17:40:35 -0300
Subject: [R] List of Dataframes
Message-ID: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/4d774656/attachment-0001.pl>

From dcarlson at tamu.edu  Mon Apr 21 22:45:43 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 21 Apr 2014 15:45:43 -0500
Subject: [R] Hi ,
	Is it possible select a different number of rows by each group with
	R????
In-Reply-To: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
References: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
Message-ID: <02f001cf5da2$aa1bafa0$fe530ee0$@tamu.edu>

Look below at your question. R-help does not support html email
so you must use plain text if you want to get an answer.

-------------------------------------
David L Carlson

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Marta Tobe?a
Sent: Monday, April 21, 2014 10:08 AM
To: r-help at r-project.org
Subject: [R] Hi , Is it possible select a different number of
rows by each group with R????

Hi , Is it possible select a different number of rows by each
group with R????
I must to select different number (specific quantity in
field2:Table1) of rows in each group(field1:Table2). I have
these 2
tables:Table1Table2field1field2field1field3field4field51310.375S
pRm12610.416667SpRm23910.458333SpRm34310.5SpRm45310.541667SpRm56
310.583333SpRm67310.625SpJm18910.666667SpJm29610.708333SpJm31031
0.75SpJm411310.791667SpJm512310.833333SpJm613310.875SpJm714320.9
16667SpJm820.958333SpJm921SpJm1021.041667SpJm1121.083333SpJm1221
.125SpJm1321.166667SpJm1421.208333SpJm1521.25SpJm1621.291667SpJm
1721.333333SpJm18Thanks youMarta

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From tim at mlhim.org  Mon Apr 21 22:47:10 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Mon, 21 Apr 2014 17:47:10 -0300
Subject: [R] List of Dataframes
In-Reply-To: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
References: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
Message-ID: <CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/276807f9/attachment-0001.pl>

From gupta567varun at gmail.com  Mon Apr 21 22:32:51 2014
From: gupta567varun at gmail.com (VG)
Date: Mon, 21 Apr 2014 16:32:51 -0400
Subject: [R] How to draw a histogram for some intervals in R
Message-ID: <CAN7A_QwiCOLC3Q8g2YOrdtksX_yzptGy2Kkyb0ug0P3=ybGfrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/039f3f8b/attachment-0001.pl>

From gunter.berton at gene.com  Mon Apr 21 23:17:21 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Apr 2014 14:17:21 -0700
Subject: [R] find maximum values on the density function of a bimodal
	distribution
In-Reply-To: <02d601cf5da1$a1121b70$e3365250$@tamu.edu>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
	<02d601cf5da1$a1121b70$e3365250$@tamu.edu>
Message-ID: <CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>

Well, yes and no, David.

Yours is one possible interpretation -- just work verbatim with the
finite sample and, as you say, hope it's well behaved.

But if the data are a noisy  *sample* from a bimodal distribution and
the purpose is to estimate the *population* modes, then, of course,
it's a different kettle of fish. As what was desired wasn't clear to
me, and I wasn't going to wade through his HTML text mess anyway(note:
you are asked to post in **plain text** for this reason), I didn't
reply.  However, if this is relevant, a search on "bump hunting"  or
"1-d clustering" might bring up something useful. I'm sure there's an
R package or 20 that addresses this.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Apr 21, 2014 at 1:38 PM, David Carlson <dcarlson at tamu.edu> wrote:
> This will work, as long as there are exactly 2 distinct modes:
>
>> runs <- rle(sign(diff(d.rv$y)))
>> length(runs$lengths) # There should be 4 runs if there are
> exactly 2 modes
> [1] 4
>> mode1 <- runs$lengths[1]+1
>> mode2 <- length(d.rv$x)- runs$lengths[4]
>> d.rv$y[c(mode1, mode2)] # The 2 modes:
> [1] 0.04012983 0.04049404
>
> --------------------------------------------------
> David L Carlson
> Listowner, Webmaster
> http://people.tamu.edu/~dcarlson/nar/
>
> ----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Monday, April 21, 2014 1:24 PM
> To: r-help at r-project.org
> Subject: [R] find maximum values on the density function of a
> bimodal distribution
>
> *dear all,I have a bimodal distribution and i would like to
> identify the
> two most frequent values. Using unimodal values i found from the
> R archive
> that is possible to identify the most frequent value, which
> corresponds to
> the peak of the density function:from Bert Gunter, Fri Mar 13
> 04rv <-
> rbinom(10000,1,0.1) + rnorm(10000)d.rv = density(rv)d.x =
> d.rv$xd.y =
> d.rv$yd.rv.max =
> d.rv$x[which.max(d.rv$y)]plot(d.rv)abline(v=d.rv.max)The
> following is instead a bimodal distribution, so how to identify
> the two
> peak values?rv <-c(-0.161948986691092,    6.25551346546337,
> 14.4449902518518,    5.71035851092391,    14.2659690175213,
> 13.4326694168529,    2.25851352934142,    19.0283322756163,
> 18.7578638985237,    3.6079681449722,    12.8469831785319,
> 16.8172446560292,    0.586180794938773,    -2.78468096182699,
> 6.41435801855101,    5.40404032358274,    16.422996950473,
> 0.0146677573458032,    6.42413783291763,    16.9133720373153,
> 21.2106745914211,    4.04126872437582,    10.8506381906698,
> 8.74969277743266,    14.2820697977719,    15.9914414284944,
> 8.35395871093583,    22.322063211793,    14.3922587603495,
> -0.889640152783791,    15.5590006991235,    13.8636215566311,
> 8.04175502056292,    -1.85932938527655,    3.0791620072771,
> 20.5240745935955,    3.68821147789088,    7.38116287748327,
> 8.13585591202069,    5.94733543506892,    7.77891267272758,
> 14.4774347329043,    0.309628817532129,    -9.0260821589798,
> 12.4102239527495,    -4.64595423395751,    17.3141235128072,
> 20.1952807795295,    -8.18424754421263,
> -1.58917260547841)d.rv =
> density(rv)d.x = d.rv$xd.y = d.rv$yd.rv.max =
> d.rv$x[which.max(d.rv$y)]plot(d.rv)Thank you.Best wishes,Luigi*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From JSorkin at grecc.umaryland.edu  Tue Apr 22 00:25:29 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 21 Apr 2014 18:25:29 -0400
Subject: [R] Spline regression (or any localized regression) in the setting
 of a random effects model.
In-Reply-To: <CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
	<02d601cf5da1$a1121b70$e3365250$@tamu.edu>
	<CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
Message-ID: <53556299020000CB00107DB7@smtp.medicine.umaryland.edu>

Colleagues,
Is there any R program that will allow me to run a localized regression (e.g. smoothing spline) in the context of a random effects model? I have data on the growth of animals and want to create growth curves. I am not certain what shape the growth curve would take, so I would like to start with some sort of smoothed (but not "linear") regression to determine the shape of the growth curves. I would like to use a random effects model because I have multiple pairs of observations (age and weight) for each animal. If the shape of the growth curves appear to fit some parametric distribution, I will switch to a parametric model.
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From gunter.berton at gene.com  Tue Apr 22 00:38:57 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Apr 2014 15:38:57 -0700
Subject: [R] Spline regression (or any localized regression) in the
 setting of a random effects model.
In-Reply-To: <53556299020000CB00107DB7@smtp.medicine.umaryland.edu>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
	<02d601cf5da1$a1121b70$e3365250$@tamu.edu>
	<CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
	<53556299020000CB00107DB7@smtp.medicine.umaryland.edu>
Message-ID: <CACk-te27JmqKdwk+xissWXkYNwRMakMTZa_8aDYQkVLpoftt6g@mail.gmail.com>

See gam() and gamm() in the mgcv package.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Apr 21, 2014 at 3:25 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Colleagues,
> Is there any R program that will allow me to run a localized regression (e.g. smoothing spline) in the context of a random effects model? I have data on the growth of animals and want to create growth curves. I am not certain what shape the growth curve would take, so I would like to start with some sort of smoothed (but not "linear") regression to determine the shape of the growth curves. I would like to use a random effects model because I have multiple pairs of observations (age and weight) for each animal. If the shape of the growth curves appear to fit some parametric distribution, I will switch to a parametric model.
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:14}}



From carlosalvarezroa at hotmail.com  Tue Apr 22 01:31:58 2014
From: carlosalvarezroa at hotmail.com (CRoa)
Date: Mon, 21 Apr 2014 16:31:58 -0700 (PDT)
Subject: [R] Loops (run the same function per different columns)
In-Reply-To: <1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1398064692015-4689171.post@n4.nabble.com>
	<1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <DUB405-EAS80798C2DBA8F289C4A522EC45E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140421/ae8d7717/attachment-0001.pl>

From jim at bitwrit.com.au  Tue Apr 22 02:18:11 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 22 Apr 2014 10:18:11 +1000
Subject: [R] How to draw a histogram for some intervals in R
In-Reply-To: <CAN7A_QwiCOLC3Q8g2YOrdtksX_yzptGy2Kkyb0ug0P3=ybGfrw@mail.gmail.com>
References: <CAN7A_QwiCOLC3Q8g2YOrdtksX_yzptGy2Kkyb0ug0P3=ybGfrw@mail.gmail.com>
Message-ID: <5355B543.5020408@bitwrit.com.au>

On 04/22/2014 06:32 AM, VG wrote:
> Hello Everyone,
> I have a text file which has data in this format.
>
> gene    start    end    freq
> Slc19a1    81    144    1
> Slc19a1    192    255    6
> Slc19a1    273    336    7
> Slc19a1    363    426    4
> Slc19a1    465    528    3
> Slc19a1    540    603    5
> Slc19a1    813    876    5
> Slc19a1    912    975    6
> Slc19a1    987    1050    8
> Slc19a1    1062    1125    6
> Slc19a1    1170    1233    8
> Slc19a1    1278    1341    6
>
> I want to draw a histogram between start and end of the above files on the
> x axis and freq associated with each interval on the y axis. How can I do
> this. I am just beginning to plot graphs in R.
>
Hi VG,
Here is a very basic way to do this:

vgdf<-read.table(text="gene    start    end    freq
Slc19a1    81    144    1
Slc19a1    192    255    6
Slc19a1    273    336    7
Slc19a1    363    426    4
Slc19a1    465    528    3
Slc19a1    540    603    5
Slc19a1    813    876    5
Slc19a1    912    975    6
Slc19a1    987    1050    8
Slc19a1    1062    1125    6
Slc19a1    1170    1233    8
Slc19a1    1278    1341    6",header=TRUE)

fbePlot<-function(ext,freq) {
  plot(range(ext),range(freq),type="n",xlab="Extent",ylab="Frequency")
  dimext<-dim(ext)
  for(extent in 1:dimext[1])
   rect(ext[extent,1],0,ext[extent,2],freq[extent])
}

fbePlot(vgdf[,c("start","end")],vgdf[,"freq"])

Jim



From kfrost at wisc.edu  Tue Apr 22 02:20:11 2014
From: kfrost at wisc.edu (Kenneth Frost)
Date: Mon, 21 Apr 2014 19:20:11 -0500
Subject: [R] Spline regression (or any localized regression) in the
 setting of a random effects model.
In-Reply-To: <CACk-te27JmqKdwk+xissWXkYNwRMakMTZa_8aDYQkVLpoftt6g@mail.gmail.com>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>
	<02d601cf5da1$a1121b70$e3365250$@tamu.edu>
	<CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
	<53556299020000CB00107DB7@smtp.medicine.umaryland.edu>
	<CACk-te27JmqKdwk+xissWXkYNwRMakMTZa_8aDYQkVLpoftt6g@mail.gmail.com>
Message-ID: <7710c00218317.53556f6b@wiscmail.wisc.edu>

Also, you might want to check out the gamm4 package.
Ken

On 04/21/14, Bert Gunter  wrote:
> See gam() and gamm() in the mgcv package.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
> On Mon, Apr 21, 2014 at 3:25 PM, John Sorkin
> <JSorkin at grecc.umaryland.edu> wrote:
> > Colleagues,
> > Is there any R program that will allow me to run a localized regression (e.g. smoothing spline) in the context of a random effects model? I have data on the growth of animals and want to create growth curves. I am not certain what shape the growth curve would take, so I would like to start with some sort of smoothed (but not "linear") regression to determine the shape of the growth curves. I would like to use a random effects model because I have multiple pairs of observations (age and weight) for each animal. If the shape of the growth curves appear to fit some parametric distribution, I will switch to a parametric model.
> > Thank you,
> > John
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >
> > Confidentiality Statement:
> > This email message, including any attachments, is for ...{{dropped:14}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Kenneth Frost
Postdoctoral Research Associate -?Dept. of Plant Pathology
University of Wisconsin - Madison
Lab: (608) 262-9914
Mobile: (608) 556-9637
kfrost at wisc.edu



From mbmiller+l at gmail.com  Tue Apr 22 02:59:47 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Mon, 21 Apr 2014 19:59:47 -0500
Subject: [R] reading data saved with writeBin() into anything other than R
Message-ID: <alpine.DEB.2.00.1404211929390.11630@taxa.psych.umn.edu>

After saving a file like so...

con <- gzcon("file.gz", "wb"))
writeBin(vector, con, size=2)
close(con)

I can read it back into R like so...

con <- gzcon("file.gz", "rb"))
vector <- readBin(con, integer(), 48000000, size=2, signed=FALSE)
close(con)

...and I'm wondering what other programs might be able to read in these 
data.  It seems to be very straightforward:  When I store 5436 integers 
for each of 7694 subjects, at two bytes per integer that ought to be 
5436*7696*2 = 83670912 bytes, and it is exactly that:

$ zcat file.gz | wc -c
83670912

So if I just convert every pair of bytes to an integer, I guess that will 
do it.  I stored them this way because it was compact, but I guess this 
system also can work well when other software needs to read the data. 
For me that other software would probably be Octave.  I'm interested if 
anyone here has read in these files using Octave, or a C program or 
anything else.  If I don't get a good answer here, I'll try the Octave 
list, and I'll send my best answers here.


The rest of this is some related info for readers of this list.  You don't 
need to read below to answer my question above.  Thanks.


In case anyone is interested, I did some comparisons of loading speed and 
file size for a number of ways of storing my data.  These data all consist 
of positive numbers between 0 and 2, with three digits to the right of the 
decimal, so I can save them as floating point double-precision, or 
multiply by 1000 and store them as integers.  The test here as for a 
matrix of 5000 x 7845 = 39,225,000 values.  These are the file sizes:

    202.1 MB  tab-delimited text file, original, uncompressed
     29.9 MB  tab-delimited text file, original, gzip compressed
    187.7 MB  tab-delimited text file, integers, uncompressed
     24.6 MB  tab-delimited text file, integers, gzip compressed
     38.9 MB  R save() original numeric values (doubles)
     27.0 MB  R save() integers
     19.7 MB  R writeBin() 16-bit integer gzipped

So, for file size (important in my case), the gzipped writeBin() method 
storing 16-bit integers was the winner.  Impressively, storing the data 
that way and dividing by 1000 on the fly to return the original numbers 
was faster than reading an Rdata file of the matrix:

The integer text file:

> system.time( D <- matrix( scan( file = "D/D000", what=integer(0) ), ncol=7845, byrow=TRUE ) )
Read 39225000 items
     user  system elapsed
   10.626   0.344  10.971


The R save() original numeric values (doubles):

> system.time( load("D000_test.Rdata") )
     user  system elapsed
    5.579   0.119   5.698


The R save() integers:

> system.time( load("D000_test.Rdata") )
     user  system elapsed
    4.863   0.050   4.913


The writeBin() 16-bit integer gzipped file:

> con <- gzcon(file("D000_test.gz", "rb"))
> system.time( D <- matrix( readBin( con, integer(), 7845*5000, size=2, signed=FALSE ), ncol=7845, byrow=TRUE ) )
     user  system elapsed
    3.769   0.138   3.906
> close(con)


The writeBin() 16-bit integer gzipped file, converted to numeric by 
dividing by 1000 on the fly:

> system.time( D <- matrix( readBin( con, integer(), 7845*5000, size=2, signed=FALSE ), ncol=7845, byrow=TRUE )/1000 )
     user  system elapsed
    4.159   0.237   4.397
> close(con)


Best,

Mike

-- 
Michael B. Miller, Ph.D.
Minnesota Center for Twin and Family Research
Department of Psychology
University of Minnesota
http://scholar.google.com/citations?user=EV_phq4AAAAJ



From smartpink111 at yahoo.com  Tue Apr 22 03:01:27 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 Apr 2014 18:01:27 -0700 (PDT)
Subject: [R] List of Dataframes
In-Reply-To: <CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
References: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
	<CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
Message-ID: <1398128487.14874.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
#or you could use:
do.call(rbind,result)


A.K.


On Monday, April 21, 2014 4:48 PM, Timothy W. Cook <tim at mlhim.org> wrote:
Okay, all day on this and I send the msg. and almost immediately discover
that:

dat <- ldply(result)

solves the problem.




On Mon, Apr 21, 2014 at 5:40 PM, Timothy W. Cook <tim at mlhim.org> wrote:

> I am processing an arbitrary number of XML files and extracting specific
> nodes.? I then create a dataframe for each nodeset.
> I return a list containing these dataframes.
>
> Example:
>
> > str(result)List of 2
>? $ :'data.frame':??? 1 obs. of? 5 variables:
>?  ..$ data-name? ? ?  : chr "Etiologic diagnosis of Acute Febrile Hemorrhagic Syndrome"
>?  ..$ valid-time-begin: chr "2014-04-28T01:31:49Z"
>?  ..$ valid-time-end? : chr "3014-04-28T01:31:48Z"
>?  ..$ DvString-dv? ?  : chr "Typhoid fever"
>?  ..$ language? ? ? ? : chr "en-US"
>? $ :'data.frame':??? 1 obs. of? 5 variables:
>?  ..$ data-name? ? ?  : chr "Etiologic diagnosis of Acute Febrile Hemorrhagic Syndrome"
>?  ..$ valid-time-begin: chr "2014-04-29T01:02:00Z"
>?  ..$ valid-time-end? : chr "3014-04-29T01:01:59Z"
>?  ..$ DvString-dv? ?  : chr "Dengue"
>?  ..$ language? ? ? ? : chr "en-US"
>
>
> I would like to have each of the list items as a row in one dataframe.? My
> attempts so far have been unsuccessful. I have tried t(), merge(),
> lapply(), etc.? Short of some elaborate *for loop* (I know is frowned
> upon)? I am out of answers.
>
> I would think this is a fairly common need, maybe even a FAQ that I
> haven't found yet.
>
> Thanks in advance.
>
>
>
>
>
>
>
> --
>
> ============================================
> Timothy Cook
> LinkedIn Profile:http://www.linkedin.com/in/timothywaynecook
> MLHIM http://www.mlhim.org
>
>


-- 

============================================
Timothy Cook
LinkedIn Profile:http://www.linkedin.com/in/timothywaynecook
MLHIM http://www.mlhim.org

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From wdunlap at tibco.com  Tue Apr 22 03:20:00 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 22 Apr 2014 01:20:00 +0000
Subject: [R] reading data saved with writeBin() into anything other than
 R
In-Reply-To: <alpine.DEB.2.00.1404211929390.11630@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1404211929390.11630@taxa.psych.umn.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B933FACA542@PA-MBX01.na.tibco.com>

> For me that other software would probably be Octave.  I'm interested if
> anyone here has read in these files using Octave, or a C program or
> anything else.

I typed 'octave read binary file' into google.com and the first hit was
the Octave help file for its fread function.  In C fread is also a good way
to go (C and Octave have different argument lists for their fread functions.)
In the Linux shell you can use the od command.

% R --quiet
> con <- gzcon(file("/tmp/file.gz", "wb")) # your gzcon("/tmp/file.gz", "wb") resulted in an error message
> writeBin(c(121:130,129:121), con, size=2)
> close(con)
> q("no")
% zcat /tmp/file.gz | od --format d2
0000000    121    122    123    124    125    126    127    128
0000020    129    130    129    128    127    126    125    124
0000040    123    122    121
0000046

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Mike Miller
> Sent: Monday, April 21, 2014 6:00 PM
> To: R-Help List
> Subject: [R] reading data saved with writeBin() into anything other than R
> 
> After saving a file like so...
> 
> con <- gzcon("file.gz", "wb"))
> writeBin(vector, con, size=2)
> close(con)
> 
> I can read it back into R like so...
> 
> con <- gzcon("file.gz", "rb"))
> vector <- readBin(con, integer(), 48000000, size=2, signed=FALSE)
> close(con)
> 
> ...and I'm wondering what other programs might be able to read in these
> data.  It seems to be very straightforward:  When I store 5436 integers
> for each of 7694 subjects, at two bytes per integer that ought to be
> 5436*7696*2 = 83670912 bytes, and it is exactly that:
> 
> $ zcat file.gz | wc -c
> 83670912
> 
> So if I just convert every pair of bytes to an integer, I guess that will
> do it.  I stored them this way because it was compact, but I guess this
> system also can work well when other software needs to read the data.
> For me that other software would probably be Octave.  I'm interested if
> anyone here has read in these files using Octave, or a C program or
> anything else.  If I don't get a good answer here, I'll try the Octave
> list, and I'll send my best answers here.
> 
> 
> The rest of this is some related info for readers of this list.  You don't
> need to read below to answer my question above.  Thanks.
> 
> 
> In case anyone is interested, I did some comparisons of loading speed and
> file size for a number of ways of storing my data.  These data all consist
> of positive numbers between 0 and 2, with three digits to the right of the
> decimal, so I can save them as floating point double-precision, or
> multiply by 1000 and store them as integers.  The test here as for a
> matrix of 5000 x 7845 = 39,225,000 values.  These are the file sizes:
> 
>     202.1 MB  tab-delimited text file, original, uncompressed
>      29.9 MB  tab-delimited text file, original, gzip compressed
>     187.7 MB  tab-delimited text file, integers, uncompressed
>      24.6 MB  tab-delimited text file, integers, gzip compressed
>      38.9 MB  R save() original numeric values (doubles)
>      27.0 MB  R save() integers
>      19.7 MB  R writeBin() 16-bit integer gzipped
> 
> So, for file size (important in my case), the gzipped writeBin() method
> storing 16-bit integers was the winner.  Impressively, storing the data
> that way and dividing by 1000 on the fly to return the original numbers
> was faster than reading an Rdata file of the matrix:
> 
> The integer text file:
> 
> > system.time( D <- matrix( scan( file = "D/D000", what=integer(0) ), ncol=7845,
> byrow=TRUE ) )
> Read 39225000 items
>      user  system elapsed
>    10.626   0.344  10.971
> 
> 
> The R save() original numeric values (doubles):
> 
> > system.time( load("D000_test.Rdata") )
>      user  system elapsed
>     5.579   0.119   5.698
> 
> 
> The R save() integers:
> 
> > system.time( load("D000_test.Rdata") )
>      user  system elapsed
>     4.863   0.050   4.913
> 
> 
> The writeBin() 16-bit integer gzipped file:
> 
> > con <- gzcon(file("D000_test.gz", "rb"))
> > system.time( D <- matrix( readBin( con, integer(), 7845*5000, size=2, signed=FALSE ),
> ncol=7845, byrow=TRUE ) )
>      user  system elapsed
>     3.769   0.138   3.906
> > close(con)
> 
> 
> The writeBin() 16-bit integer gzipped file, converted to numeric by
> dividing by 1000 on the fly:
> 
> > system.time( D <- matrix( readBin( con, integer(), 7845*5000, size=2, signed=FALSE ),
> ncol=7845, byrow=TRUE )/1000 )
>      user  system elapsed
>     4.159   0.237   4.397
> > close(con)
> 
> 
> Best,
> 
> Mike
> 
> --
> Michael B. Miller, Ph.D.
> Minnesota Center for Twin and Family Research
> Department of Psychology
> University of Minnesota
> http://scholar.google.com/citations?user=EV_phq4AAAAJ
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jholtman at gmail.com  Tue Apr 22 05:24:51 2014
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 21 Apr 2014 23:24:51 -0400
Subject: [R] List of Dataframes
In-Reply-To: <CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
References: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
	<CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
Message-ID: <C9BDCD27-5187-4F29-9029-DE723CAA0050@gmail.com>

also

do.call(rbind, result)

Sent from my iPad

On Apr 21, 2014, at 16:47, "Timothy W. Cook" <tim at mlhim.org> wrote:

> Okay, all day on this and I send the msg. and almost immediately discover
> that:
> 
> dat <- ldply(result)
> 
> solves the problem.
> 
> 
> 
> 
> On Mon, Apr 21, 2014 at 5:40 PM, Timothy W. Cook <tim at mlhim.org> wrote:
> 
>> I am processing an arbitrary number of XML files and extracting specific
>> nodes.  I then create a dataframe for each nodeset.
>> I return a list containing these dataframes.
>> 
>> Example:
>> 
>>> str(result)List of 2
>> $ :'data.frame':    1 obs. of  5 variables:
>>  ..$ data-name       : chr "Etiologic diagnosis of Acute Febrile Hemorrhagic Syndrome"
>>  ..$ valid-time-begin: chr "2014-04-28T01:31:49Z"
>>  ..$ valid-time-end  : chr "3014-04-28T01:31:48Z"
>>  ..$ DvString-dv     : chr "Typhoid fever"
>>  ..$ language        : chr "en-US"
>> $ :'data.frame':    1 obs. of  5 variables:
>>  ..$ data-name       : chr "Etiologic diagnosis of Acute Febrile Hemorrhagic Syndrome"
>>  ..$ valid-time-begin: chr "2014-04-29T01:02:00Z"
>>  ..$ valid-time-end  : chr "3014-04-29T01:01:59Z"
>>  ..$ DvString-dv     : chr "Dengue"
>>  ..$ language        : chr "en-US"
>> 
>> 
>> I would like to have each of the list items as a row in one dataframe.  My
>> attempts so far have been unsuccessful. I have tried t(), merge(),
>> lapply(), etc.  Short of some elaborate *for loop* (I know is frowned
>> upon)  I am out of answers.
>> 
>> I would think this is a fairly common need, maybe even a FAQ that I
>> haven't found yet.
>> 
>> Thanks in advance.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> ============================================
>> Timothy Cook
>> LinkedIn Profile:http://www.linkedin.com/in/timothywaynecook
>> MLHIM http://www.mlhim.org
>> 
>> 
> 
> 
> -- 
> 
> ============================================
> Timothy Cook
> LinkedIn Profile:http://www.linkedin.com/in/timothywaynecook
> MLHIM http://www.mlhim.org
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From mbmiller+l at gmail.com  Tue Apr 22 05:28:59 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Mon, 21 Apr 2014 22:28:59 -0500
Subject: [R] reading data saved with writeBin() into anything other than
 R
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FACA542@PA-MBX01.na.tibco.com>
References: <alpine.DEB.2.00.1404211929390.11630@taxa.psych.umn.edu>
	<E66794E69CFDE04D9A70842786030B933FACA542@PA-MBX01.na.tibco.com>
Message-ID: <alpine.DEB.2.00.1404212038190.11630@taxa.psych.umn.edu>

On Tue, 22 Apr 2014, William Dunlap wrote:

>> For me that other software would probably be Octave.  I'm interested if 
>> anyone here has read in these files using Octave, or a C program or 
>> anything else.
>
> I typed 'octave read binary file' into google.com and the first hit was 
> the Octave help file for its fread function.  In C fread is also a good 
> way to go (C and Octave have different argument lists for their fread 
> functions.) In the Linux shell you can use the od command.

Thanks!  My mistake was that I was searching using "R" and "writebin" in 
my search string which limited my results too severely.  I actually 
figured that out before your message came in and felt a little 
embarrassed, and that has only gotten worse.  But you did give me 
something cool that I didn't know:


> % R --quiet
>> con <- gzcon(file("/tmp/file.gz", "wb")) # your gzcon("/tmp/file.gz", "wb") resulted in an error message
>> writeBin(c(121:130,129:121), con, size=2)
>> close(con)
>> q("no")
> % zcat /tmp/file.gz | od --format d2
> 0000000    121    122    123    124    125    126    127    128
> 0000020    129    130    129    128    127    126    125    124
> 0000040    123    122    121
> 0000046


That's really neat.  With my data, I can do this to return the original 
matrix:

zcat file.gz | od -vtd2 -w15392 -An > matrix.txt

It is quite fast, too:

$ time -p zcat D1.gz | od -vtd2 -w15392 -An >/dev/null
real 6.08
user 6.86
sys 0.08


If I had realized how little my writeBin() output files had to do with R, 
I probably wouldn't have posted here, but I'm glad I did.


FYI -- I was able to use fread() in Octave on the uncompressed version of 
the file, but it isn't handling the zipped version as expected.  That's an 
Octave problem, so I'll deal with them on that one.  I might not have zlib 
compiled in, or maybe they still have a bug in that function.

Thanks!

Mike



From jim at bitwrit.com.au  Tue Apr 22 05:30:33 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 22 Apr 2014 13:30:33 +1000
Subject: [R] Labeling/identifying observations in plot after MclustDR
 from	Mclust
In-Reply-To: <80EBCCC5D613EB4FBAD6964110D88C5E8F4723DD@arborexmbx4.UTORARBOR.UTORAD.Utoronto.ca>
References: <80EBCCC5D613EB4FBAD6964110D88C5E8F4723DD@arborexmbx4.UTORARBOR.UTORAD.Utoronto.ca>
Message-ID: <5355E259.9030602@bitwrit.com.au>

On 04/17/2014 01:01 PM, Mark Manger wrote:
> Hi,
>
> I?m trying to figure out how to label points in a contour plot produced from the output of MclustDR, the dimension reduction function in the Mclust package.
>
> The original data frame has row names
>
> 		RRcoarse govtDeficit    res_gdp GrossFixedCapForm_UN fuelExports
> AUS_76    2.000  -4.5125520  1.5197260              26.5169  12.7851900
> AUS_81    3.500  -3.6041720  3.7029600              27.1058  20.8597300
> AUS_91    4.000  -1.2131010  3.8150380              24.1444  20.5832700
> AUS_01    4.000   0.0279132  4.4617860              26.9491  25.5349700
> AUT_76    2.000  -2.7850080  7.0378630              25.7365   1.6797000
> AUT_81    1.000  -3.4403770  6.4757080              23.2928   1.4688700
>
> I then use these variables to
>
> imbalances.selections.def = subset(imbalances.all, select=c(5:8,10:12), cu_gdp<  0)
> clusters.defs = Mclust(imbalances.selections.def, G=1:10)
>
>
> I use MclustDR to reduce the dimensions to plot the results, which works beautifully and produces a nice contour plot.
>
> dr.defs = MclustDR(clusters.defs)
> plot(dr.defs, what="contour?)
>
> But the plot is not particularly informative unless I know which observation is which.
>
> How can I label the points displayed in the plot to identify the observations? I can probably extract this from the dr.defs object whose str() is below, but I don?t know how to do that, or somehow from the original data frame row names. Help would be greatly appreciated. I know this is trivial in a regular plot(x,y) situation.
>
> str(dr.defs)
>
> List of 22
>   $ call         : language MclustDR(object = clusters.defs)
>   $ type         : chr "Mclust"
>   $ x            : num [1:49, 1:7] 2 3.5 4 4 2 1 1 2 2 2 ...
>    ..- attr(*, "dimnames")=List of 2
>    .. ..$ : chr [1:49] "AUS_76" "AUS_81" "AUS_91" "AUS_01" ...
>    .. ..$ : chr [1:7] "RRcoarse" "govtDeficit" "res_gdp" "GrossFixedCapForm_UN" ...
>   $ Sigma        : num [1:7, 1:7] 0.875 0.116 -0.781 -0.525 2.339 ...
>    ..- attr(*, "dimnames")=List of 2
>    .. ..$ : chr [1:7] "RRcoarse" "govtDeficit" "res_gdp" "GrossFixedCapForm_UN" ?
> etc etc etc
>
Hi Mark,
I didn't see an answer to your question, but you might find the 
boxed.labels function (plotrix) helpful. I think your labels can be 
obtained using:

mylabels<-rownames(dr.defs$x)

and by calling:

boxed.labels(x,y,mylabels)

where x and y are the coordinates of the points you want to label, you 
will get the labels placed at the points. I suggest boxed.labels because 
the labels will have a little box around them and a background that 
prevents the underlying image from obscuring them.

Jim



From frtog at vestas.com  Tue Apr 22 07:04:16 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 22 Apr 2014 07:04:16 +0200
Subject: [R] Loop to extract from variables in the workspace
In-Reply-To: <BLU0-SMTP2869D275E60143FAD7E192BD95E0@phx.gbl>
References: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA54EA@DKRDSEXC016.vestas.net>
	<BLU0-SMTP2869D275E60143FAD7E192BD95E0@phx.gbl>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA55C5@DKRDSEXC016.vestas.net>


Well, sticking to your loop that you seem comfortable with try this:

## list to hold dataframes
extracList <- vector("list", length(1981:2010))

cnt <- 0
for(i in 1981:2010){
	cnt <- cnt + 1
	rasterObj <-get( c(paste("RR_", i, "_1", sep="")))
      	extractList[[cnt]]<- extract(rasterObj, coords, df=T)}
 }

See ?get which is kind of the opposite of assign.

To coerce the list of dataframes into one dataframe several methods are available:

do.call("rbind", extractList)

plyr::rbind.fill(extractList)

plyr::ldply(extractList, data.frame)

as.data.frame(data.table::rbindlist(extractList))

This was taken from http://stackoverflow.com/questions/2851327/converting-a-list-of-data-frames-into-one-data-frame-in-r where you get get some pros and cons on the methods.

The fastest way will probably be to create a huge dataframe and during the loop calculated the row indices of that dataframe for each raster into the result from extract should be put.



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: Beatriz R. Gonzalez Dominguez [mailto:aguitatierra at hotmail.com]
> Sent: 21. april 2014 16:27
> To: Frede Aakmann T?gersen; r-help at r-project.org
> Subject: Re: [R] Loop to extract from variables in the workspace
> 
> Hi Frede,
> 
> Many thanks for your reply.
> 1. The first argument in extract is a Formal class RasterLayer in the
> Workspace (e.g RR_1981_1 ).
> 
> 2. I created an intermediate name to hold the result fromthe extract
> function because I'd like to create several dataframes with the output
> of the iterative (loop) extraction. I'd like to get the same result as
> when I do:
> 
> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
> [... this works no problem]
> 
> 3. 'coords' is a SpatialPointsDataFrame.
> 
> 4. I used assign in the loop becuase I thought it was the way forward to
> create new variables out of it. Isn't it?
> 
> What I'd like to do is to use coordinate points ('coords') to extract
> raster pixel values (eg. 'RR_1981_1') on which the points are overlying.
> Then I'd like to build a bigger data frame including the data from all
> the outputs (i.e. PE.coords_01_1981, PE.coords_01_1982).
> 
> Hope to have explained myself properly. Please let me know if anything
> else should be clarified.
> 
> Best wishes,
> 
> Bea
> 
> 
> On 21/04/2014 15:17, Frede Aakmann T?gersen wrote:
> > Hi Beatriz
> >
> > Did you read the help for extract{raster} carefully?
> >
> > Several things can be wrong.
> >
> > 1) First argument to extract is not a file name but a raster object.
> > 2) In the loop you name an object extract as an intermediate name to hold
> the result from the extract function. Do you think there could be a name
> clash? R is clever but perhaps not clever enough.
> > 3) coords are of the right class (see ?extract).
> > 4) assign can be useful from time to time. But in a loop?
> >
> > I think the things you are doing are some intermediate results that needs
> more processing. Do you think this is the right way to do that. For instance
> instead of storing the immediate result as separate objects why not store
> those in a list.
> >
> > Perhaps if you tell us what you would like to do  overall, i.e. from first to
> last, then we will be able to help you to become more efficient.
> >
> >
> > Yours sincerely / Med venlig hilsen
> >
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org]
> >> On Behalf Of Beatriz R. Gonzalez Dominguez
> >> Sent: 21. april 2014 14:53
> >> To: r-help at r-project.org
> >> Subject: [R] Loop to extract from variables in the workspace
> >>
> >> Dear all,
> >>
> >> I'm starting to work with loops and I'm stucked on something.
> >> I've been searching and trying different possibilities but I don't get
> >> to the solution.
> >> I'd be very grateful if you could share any ideas that you think may help.
> >>
> >> library("raster")
> >>
> >> # All my variables are in the workspace
> >>
> >> # This is what I'd like to obtain, but with a loop (I'm working with
> >> several years and variables).
> >> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
> >> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
> >> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
> >> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
> >> PE.coords_01_1985 <- extract(RR_1985_1, coords, df=T)
> >> PE.coords_01_1986 <- extract(RR_1986_1, coords, df=T)
> >> PE.coords_01_1987 <- extract(RR_1987_1, coords, df=T)
> >> PE.coords_01_1988 <- extract(RR_1988_1, coords, df=T)
> >> PE.coords_01_1989 <- extract(RR_1989_1, coords, df=T)
> >> PE.coords_01_1990 <- extract(RR_1990_1, coords, df=T)
> >>
> >>
> >> # This is one of the things I've tried.
> >>
> >> for(i in 1981:2010){
> >> file <- c(paste("RR_", i, "_1", sep=""))
> >> extract <- extract(file, coords, df=T)}
> >> names.a <- paste("PE.coords_01_", i, sep="")
> >> assign(names.a, value=extract)
> >> }
> >>
> >> # I get the following error.
> >> Error in (function (classes, fdef, mtable) :
> >> unable to find an inherited method for function 'extract'
> >> for signature '"character", "SpatialPointsDataFrame"'
> >> # I think the error must be something when I'm defining 'file'
> >>
> >> Thanks a lot for any help!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.



From kpmainali at gmail.com  Tue Apr 22 10:25:08 2014
From: kpmainali at gmail.com (Kumar Mainali)
Date: Tue, 22 Apr 2014 03:25:08 -0500
Subject: [R] mvpart - easy way to calculate deviance explained by variables
Message-ID: <CABK368jQF-ybQF4aEirKeZMLcuch0-CeXEWP6VFD6-GrrC6xSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/5da940cc/attachment-0001.pl>

From pavneet.arora at uk.rsagroup.com  Tue Apr 22 10:59:51 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Tue, 22 Apr 2014 09:59:51 +0100
Subject: [R] Read.table mucks up headers
In-Reply-To: <5352764F.4040903@statistik.tu-dortmund.de>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>	<1397495399.4315.1.camel@milan>
	<OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
	<1397910654957-4689099.post@n4.nabble.com>
	<5352764F.4040903@statistik.tu-dortmund.de>
Message-ID: <OFF16A7971.FEED8101-ON80257CC2.00316102-80257CC2.0031F5F4@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/dc0a36f8/attachment-0001.pl>

From tim at mlhim.org  Tue Apr 22 11:13:19 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Tue, 22 Apr 2014 06:13:19 -0300
Subject: [R] List of Dataframes
In-Reply-To: <1398128487.14874.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
	<CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
	<1398128487.14874.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CA+=OU3XFCm4s=0k_Nt7V531-Qy1K=Q31dxiHrab7goC_e1jtJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/68c3972c/attachment-0001.pl>

From tim at mlhim.org  Tue Apr 22 11:14:19 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Tue, 22 Apr 2014 06:14:19 -0300
Subject: [R] List of Dataframes
In-Reply-To: <C9BDCD27-5187-4F29-9029-DE723CAA0050@gmail.com>
References: <CA+=OU3VM_yoiQAGx6_UmCGT7__QT4Tk29BbOK3bXBYvyyrGmrA@mail.gmail.com>
	<CA+=OU3VR=8UjbVE1QUDzKjQzmfuEDeXSPqS5x0u1-pa8kWH22A@mail.gmail.com>
	<C9BDCD27-5187-4F29-9029-DE723CAA0050@gmail.com>
Message-ID: <CA+=OU3VtmhX-JGYLXpmmFygEt9AYGfDMQh+zChQuVpitKETNng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/27bc3335/attachment-0001.pl>

From trisco7 at gmail.com  Tue Apr 22 13:13:52 2014
From: trisco7 at gmail.com (tripti gupta)
Date: Tue, 22 Apr 2014 16:43:52 +0530
Subject: [R] Fetch tweets using searchTwitter()
Message-ID: <CAB76e9thwtJmZJD9dyqRyjbodqXhVah1O2nw3_TDRZOYaYBNQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/d926cddb/attachment-0001.pl>

From m.robinson11 at uq.edu.au  Tue Apr 22 08:32:09 2014
From: m.robinson11 at uq.edu.au (Matthew Robinson)
Date: Tue, 22 Apr 2014 06:32:09 +0000
Subject: [R] lm models over all possible pairwise combinations of the
 columns of two matrices
Message-ID: <87661ED2-0B10-4EFF-95CE-43DF9D1A8855@uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/19f6e48e/attachment-0001.pl>

From dominik.wagner at uni-trier.de  Tue Apr 22 12:56:13 2014
From: dominik.wagner at uni-trier.de (Dipl. Kfm Dominik Wagner MSc; MSc)
Date: Tue, 22 Apr 2014 12:56:13 +0200
Subject: [R] metafor - rstudent(res) - omitted rows
Message-ID: <CAGQ7FNEHKgpn6U-17uougYVds6ybDAcAyeaRzQKocucoZWfwmw@mail.gmail.com>

Dear all,

I am quite new to R. Now my following easy question.

I use metafor and performed an outlier test with rstudent(res).
This is resulting in 1000 rows of 1578 and 578 omitted rows (starting with
row 598).


   1. How can I display all 1578 rows in R-studio? Because in the
   standardized residual plot it starts with study 1 (see attachment). In
   R-studio with row 598.
   2. How can I just plot the standardized residuals with manipulated
   x-axis to see every single study?


Thank you very much for your help.

Cordially

Dominik

-- 

_________________________________________________


*Dipl.-Kfm. Dominik Wagner MSc. MSc.*
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 353039 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/d7862a00/attachment-0002.pdf>

From aljehani-k at hotmail.com  Tue Apr 22 13:11:13 2014
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Tue, 22 Apr 2014 14:11:13 +0300
Subject: [R] joint distribution
Message-ID: <DUB120-W3611EDC34EC99A233AEBFC85590@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/b6993222/attachment-0001.pl>

From dcarlson at tamu.edu  Tue Apr 22 15:25:06 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 22 Apr 2014 08:25:06 -0500
Subject: [R] find maximum values on the density function of a bimodal
	distribution
In-Reply-To: <CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
References: <CAMk+s2S8oGmP56sdFgV7GP6+4=6KTLw59W0Y1Mh+7bjRka49ew@mail.gmail.com>	<02d601cf5da1$a1121b70$e3365250$@tamu.edu>
	<CACk-te08t0aD3AXnS51UgQ7TuuWg6hwuA7EVsMWJtaTqzBcwzw@mail.gmail.com>
Message-ID: <03cd01cf5e2e$467edee0$d37c9ca0$@tamu.edu>

Following on Bert's comments, you can see some of the issues by plotting histograms of the original data:

> hist(rv, breaks=15)
> abline(v= d.rv$x[c(mode1, mode2)], lty=2)
> hist(rv, breaks=25)
> abline(v= d.rv$x[c(mode1, mode2)], lty=2)

The density plot smooths the values into two peaks, but the histogram hints at the possibility that the underlying values are tri-modal. On the kernel density plot, different bandwidths will give different pictures. The default bandwidth is about 3.3. The manual page recommends bw="SJ" which gives about 3.8. Larger bandwidths smooth more and smaller bandwidths smooth less.

> plot(density(rv, bw=5)) # Unimodal
> plot(density(rv, bw=4)) # Barely bimodal
> plot(density(rv, bw=3)) # Bimodal
> plot(density(rv, bw=2)) # Bimodal with hints of more
> plot(density(rv, bw=1)) # Multimodal

David C

-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Monday, April 21, 2014 4:17 PM
To: David Carlson
Cc: Luigi Marongiu; r-help at r-project.org
Subject: Re: [R] find maximum values on the density function of a bimodal distribution

Well, yes and no, David.

Yours is one possible interpretation -- just work verbatim with the
finite sample and, as you say, hope it's well behaved.

But if the data are a noisy  *sample* from a bimodal distribution and
the purpose is to estimate the *population* modes, then, of course,
it's a different kettle of fish. As what was desired wasn't clear to
me, and I wasn't going to wade through his HTML text mess anyway(note:
you are asked to post in **plain text** for this reason), I didn't
reply.  However, if this is relevant, a search on "bump hunting"  or
"1-d clustering" might bring up something useful. I'm sure there's an
R package or 20 that addresses this.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Apr 21, 2014 at 1:38 PM, David Carlson <dcarlson at tamu.edu> wrote:
> This will work, as long as there are exactly 2 distinct modes:
>
>> runs <- rle(sign(diff(d.rv$y)))
>> length(runs$lengths) # There should be 4 runs if there are
> exactly 2 modes
> [1] 4
>> mode1 <- runs$lengths[1]+1
>> mode2 <- length(d.rv$x)- runs$lengths[4]
>> d.rv$y[c(mode1, mode2)] # The 2 modes:
> [1] 0.04012983 0.04049404
>
> --------------------------------------------------
> David L Carlson
> Listowner, Webmaster
> http://people.tamu.edu/~dcarlson/nar/
>
> ----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Monday, April 21, 2014 1:24 PM
> To: r-help at r-project.org
> Subject: [R] find maximum values on the density function of a
> bimodal distribution
>
> *dear all,I have a bimodal distribution and i would like to
> identify the
> two most frequent values. Using unimodal values i found from the
> R archive
> that is possible to identify the most frequent value, which
> corresponds to
> the peak of the density function:from Bert Gunter, Fri Mar 13
> 04rv <-
> rbinom(10000,1,0.1) + rnorm(10000)d.rv = density(rv)d.x =
> d.rv$xd.y =
> d.rv$yd.rv.max =
> d.rv$x[which.max(d.rv$y)]plot(d.rv)abline(v=d.rv.max)The
> following is instead a bimodal distribution, so how to identify
> the two
> peak values?rv <-c(-0.161948986691092,    6.25551346546337,
> 14.4449902518518,    5.71035851092391,    14.2659690175213,
> 13.4326694168529,    2.25851352934142,    19.0283322756163,
> 18.7578638985237,    3.6079681449722,    12.8469831785319,
> 16.8172446560292,    0.586180794938773,    -2.78468096182699,
> 6.41435801855101,    5.40404032358274,    16.422996950473,
> 0.0146677573458032,    6.42413783291763,    16.9133720373153,
> 21.2106745914211,    4.04126872437582,    10.8506381906698,
> 8.74969277743266,    14.2820697977719,    15.9914414284944,
> 8.35395871093583,    22.322063211793,    14.3922587603495,
> -0.889640152783791,    15.5590006991235,    13.8636215566311,
> 8.04175502056292,    -1.85932938527655,    3.0791620072771,
> 20.5240745935955,    3.68821147789088,    7.38116287748327,
> 8.13585591202069,    5.94733543506892,    7.77891267272758,
> 14.4774347329043,    0.309628817532129,    -9.0260821589798,
> 12.4102239527495,    -4.64595423395751,    17.3141235128072,
> 20.1952807795295,    -8.18424754421263,
> -1.58917260547841)d.rv =
> density(rv)d.x = d.rv$xd.y = d.rv$yd.rv.max =
> d.rv$x[which.max(d.rv$y)]plot(d.rv)Thank you.Best wishes,Luigi*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From Matthias.Kohl at stamats.de  Tue Apr 22 15:35:40 2014
From: Matthias.Kohl at stamats.de (Prof. Dr. Matthias Kohl)
Date: Tue, 22 Apr 2014 15:35:40 +0200
Subject: [R] joint distribution
In-Reply-To: <DUB120-W3611EDC34EC99A233AEBFC85590@phx.gbl>
References: <DUB120-W3611EDC34EC99A233AEBFC85590@phx.gbl>
Message-ID: <5356702C.9000608@stamats.de>

have a look at our package distr:

library(distr)
x1 <- Norm(mean = 0, sd = 1)
x2 <- Binom(size = 1, prob = 0.75)
x3 <- x1 + x2
plot(x3)
# to get density, cdf, quantile, and random numbers use
d(x3)(5)
p(x3)(0)
q(x3)(0.975)
r(x3)(20)

# you can also have additonal coefficients; eg.
x4 <- 3*x1 + 2*x2
plot(x4)

For more details on the computations see http://arxiv.org/abs/1006.0764

hth,
Matthias

On 22.04.2014 13:11, Ms khulood aljehani wrote:
>
> Hello
> i have two independent variablesx1 from normal (0,1)x2 from bernoulli (o.75)
> i need the density estimation of(b1*x1) + (b2*x2)
> where b1 and b2 are two fixed coefficients
> thank you 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Prof. Dr. Matthias Kohl
www.stamats.de



From pavneet.arora at uk.rsagroup.com  Tue Apr 22 15:59:55 2014
From: pavneet.arora at uk.rsagroup.com (starter)
Date: Tue, 22 Apr 2014 06:59:55 -0700 (PDT)
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <534F0A4A.6070304@statistik.tu-dortmund.de>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
	<OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
	<534F0A4A.6070304@statistik.tu-dortmund.de>
Message-ID: <1398175195594-4689256.post@n4.nabble.com>

That is what I was trying to achieve; i.e. plot all my graphs using a loop
function. But somewhere in the loop it converts each graph into png or
bitmap image and then compiles all these png or bitmap images in a pdf file. 
So each page in a pdf file is a bitmap or png picture of my graph.

Does that make any sense?



--
View this message in context: http://r.789695.n4.nabble.com/Fw-Save-multiple-plots-as-pdf-or-jpeg-tp4688801p4689256.html
Sent from the R help mailing list archive at Nabble.com.



From gunter.berton at gene.com  Tue Apr 22 16:00:45 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 22 Apr 2014 07:00:45 -0700
Subject: [R] lm models over all possible pairwise combinations of the
 columns of two matrices
In-Reply-To: <87661ED2-0B10-4EFF-95CE-43DF9D1A8855@uq.edu.au>
References: <87661ED2-0B10-4EFF-95CE-43DF9D1A8855@uq.edu.au>
Message-ID: <CACk-te01JRXfJ_T+HWdm57bWEOBVvX-2RtryAJu-kzw_7FHWEQ@mail.gmail.com>

Well...

If my arithmetic and understanding is correct, that's 32 billion
combinations, which, to put it politely, is nuts. As all you'll be
doing is generating random numbers anyway, the fastest way to do this
is just to use a random number generator.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Apr 21, 2014 at 11:32 PM, Matthew Robinson
<m.robinson11 at uq.edu.au> wrote:
> Dear all,
>
> I am working through a problem at the moment and have got stuck. I have searched around on the help list for assistance but could not find anything - but apologies if I have missed something. A dummy example of my problem is below. I will continue to work on it, but any help would be greatly appreciated.
>
> Thanks in advance for your time.
>
> Best wishes,
> Matt
>
>
> I have a matrix of response variables:
>
> p<-matrix(c(rnorm(120,1),
> rnorm(120,1),
> rnorm(120,1)),
> 120,3)
>
> and two matrices of covariates:
>
> g<-matrix(c(rep(1:3, each=40),
> rep(3:1, each=40),
> rep(1:3, 40)),
> 120,3)
> m<-matrix(c(rep(1:2, 60),
> rep(2:1, 60),
> rep(1:2, each=60)),
> 120,3)
>
> For all combinations of the columns of the covariate matrices g and m I want to run these two models:
>
> test <- function(uniq_m, uniq_g, p = p) {
>
>
> full <- lm(p ~ factor(uniq_m) * factor(uniq_g))
>     null <- lm(p ~ factor(uniq_m) + factor(uniq_g))
>     return(list('f'=full, 'n'=null))
> }
>
> So I want to test for an interaction between column 1 of m and column 1 of g, then column 2 of m and column 1 of g, then column 2 of m and column 2 of g...and so forth across all possible pairwise interactions. The response variable is the same each time and is a matrix containing multiple columns.
>
>
> So far, I can do this for a single combination of columns:
>
> test_1 <- test(m[ ,1], g[ ,1], p)
>
> And I can also run the model over all columns of m and one coloumn of g:
>
> test_2 <- apply(m, 2, function(uniq_m) {
> test(uniq_m, g[ ,1], p = p)
> })
>
>
> I can then get the F statistics for each response variable of each model:
>
> sapply(summary(test_2[[1]]$f), function(x) x$fstatistic)
> sapply(summary(test_2[[1]]$n), function(x) x$fstatistic)
>
> And I can compare models for each response variable using an F-test:
>
> d1<-colSums(matrix(residuals(test_2[[1]]$n),nrow(g),ncol(p))^2)
> d2<-colSums(matrix(residuals(test_2[[2]]$f),nrow(g),ncol(p))^2)
> F<-((d1-d2) / (d2/114))
>
>
> My question is how do I run the lm models over all combinations of columns from the m and the g matrix, and get the F-statistics? While this is a dummy example, the real analysis will have a response matrix that is 700 x 8000, and the covariate matrices will be 700 x 4000 and 700 x 100 so I need something that is as fast as possible.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr 22 16:05:52 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 22 Apr 2014 16:05:52 +0200
Subject: [R] metafor - rstudent(res) - omitted rows
In-Reply-To: <CAGQ7FNEHKgpn6U-17uougYVds6ybDAcAyeaRzQKocucoZWfwmw@mail.gmail.com>
References: <CAGQ7FNEHKgpn6U-17uougYVds6ybDAcAyeaRzQKocucoZWfwmw@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DA9E3988D@UM-MAIL4112.unimaas.nl>

I think this may help:

http://www.metafor-project.org/doku.php/tips:handling_missing_data

I am not sure I understand your second question. All studies are shown (for which the standardized residual can be computed), but since there are so many studies, these plots are not really all that helpful. If you only want to plot the standardized residuals, then you could start with:

options(na.action = "na.pass")
sav <- rstandard(res)
plot(sav$slab, sav$z, pch=19, cex=.4, type="o")

and just start tweaking this. You will have to reduce the size of the axis annotations (look into cex.axis), probably make them vertically aligned (las), and stretch that plot very wide if you want to make out individual points. Look into help(par) for more details cex.axis and las, and help(Devices) for setting up a much wider plot.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Dipl. Kfm Dominik Wagner MSc; MSc
> Sent: Tuesday, April 22, 2014 12:56
> To: r-help at r-project.org
> Subject: [R] metafor - rstudent(res) - omitted rows
> 
> Dear all,
> 
> I am quite new to R. Now my following easy question.
> 
> I use metafor and performed an outlier test with rstudent(res).
> This is resulting in 1000 rows of 1578 and 578 omitted rows (starting
> with
> row 598).
> 
> 
>    1. How can I display all 1578 rows in R-studio? Because in the
>    standardized residual plot it starts with study 1 (see attachment). In
>    R-studio with row 598.
>    2. How can I just plot the standardized residuals with manipulated
>    x-axis to see every single study?
> 
> 
> Thank you very much for your help.
> 
> Cordially
> 
> Dominik
> 
> --
> 
> _________________________________________________
> 
> 
> *Dipl.-Kfm. Dominik Wagner MSc. MSc.*

From cjrinconr at unal.edu.co  Tue Apr 22 16:26:15 2014
From: cjrinconr at unal.edu.co (Carlos Javier Rincon Rodriguez)
Date: Tue, 22 Apr 2014 09:26:15 -0500
Subject: [R] KappaSize
Message-ID: <CABeLv6h0ME2f53YCn49wTGM99J7WF8tPj6P5Vm_AF1PmaPuGAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/193078d6/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Tue Apr 22 17:16:40 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 22 Apr 2014 08:16:40 -0700
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <1398175195594-4689256.post@n4.nabble.com>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
	<OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
	<534F0A4A.6070304@statistik.tu-dortmund.de>
	<1398175195594-4689256.post@n4.nabble.com>
Message-ID: <6982453b-d4bd-447e-884b-5bca39111d34@email.android.com>

Sounds like you are getting what you want... except that you used the word "but". If you are not getting what you want, then what is it that you do want? In particular, how do you intend to review or use many plots generated at once if not in a PDF file?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 22, 2014 6:59:55 AM PDT, starter <pavneet.arora at uk.rsagroup.com> wrote:
>That is what I was trying to achieve; i.e. plot all my graphs using a
>loop
>function. But somewhere in the loop it converts each graph into png or
>bitmap image and then compiles all these png or bitmap images in a pdf
>file. 
>So each page in a pdf file is a bitmap or png picture of my graph.
>
>Does that make any sense?
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Fw-Save-multiple-plots-as-pdf-or-jpeg-tp4688801p4689256.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Tue Apr 22 17:17:58 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 22 Apr 2014 08:17:58 -0700
Subject: [R] KappaSize
In-Reply-To: <CABeLv6h0ME2f53YCn49wTGM99J7WF8tPj6P5Vm_AF1PmaPuGAw@mail.gmail.com>
References: <CABeLv6h0ME2f53YCn49wTGM99J7WF8tPj6P5Vm_AF1PmaPuGAw@mail.gmail.com>
Message-ID: <CACk-te3ek9e1j2rhKW+pnYEijpwwwJKmtOTzFDYh+1KqfH7mDA@mail.gmail.com>

update to the latest R version first.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Apr 22, 2014 at 7:26 AM, Carlos Javier Rincon Rodriguez
<cjrinconr at unal.edu.co> wrote:
> Hello, good morning.
>
> I need to calculate a kappa coeficient between three raters and the scale
> have five categories outcome. Until now I read the command CI3Cats for the
> package KappaSize in order to calculate the sample size, but when i save
> the package into the library, R can read it and i dont understand the
> reason. that is the message that i have:
>
>> library(kappaSize)
> Error in eval(expr, envir, enclos) :
>   no se pudo encontrar la funci?n ".getNamespace"
> Adem?s: Mensajes de aviso perdidos
> package 'kappaSize' was built under R version 3.1.0
> Error : unable to load R code in package 'kappaSize'
> Error: package/namespace load failed for 'kappaSize'
>
> Now, after find the sample size and recolect the information, i ll need to
> calculate the kappa between three raters with multiple outcome categories.
> Untill now I could it find the command to do that.
>
> Thank for the help that anyone can give me.
>
> Best regard,
>
> Carlos.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bogaso.christofer at gmail.com  Tue Apr 22 17:30:08 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 22 Apr 2014 21:15:08 +0545
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <534452BA.4050605@sapo.pt>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>
	<534452BA.4050605@sapo.pt>
Message-ID: <CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/244a5119/attachment-0001.pl>

From ruipbarradas at sapo.pt  Tue Apr 22 18:38:16 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 22 Apr 2014 17:38:16 +0100
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>	<534452BA.4050605@sapo.pt>
	<CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>
Message-ID: <53569AF8.3040202@sapo.pt>

Hello,

Have you tried which=2?

dat <- readHTMLTable(readLines(Link), which = 2, header = TRUE, 
na.strings = "-")

dat[, 3:15] <- lapply(dat[, 3:15], function(x) sub("([[:digit:]]) [ab]", 
"\\1", x))
dat[, 3:15] <- lapply(dat[, 3:15], function(x)as.numeric(as.character(x)))

str(dat)


Hope this helps,

Rui Barradas

Em 22-04-2014 16:30, Christofer Bogaso escreveu:
> Hi Rui,
>
> Sorry to late reply. Thanks for your pointer.
>
> However using this method, I am having difficulty to download related
> data from same site.
>
> I need to download data from:
>
>   'http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352'
>
> So I tried following:
>
> library(XML)
> Link <-
> 'http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352'
> readHTMLTable(readLines(Link), which = 1, header = TRUE, na.strings = "-")
>
> Unfortunately I didnot get what I wanted.
>
> Can you (or someone) please help me on this?
>
> Thanks for your time.
>
>
> On Wed, Apr 9, 2014 at 1:34 AM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     Try the following.
>
>     library(XML)
>     URL <-
>     "http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>     <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>"
>
>     dat <- readHTMLTable(readLines(URL), which=1, header=TRUE,
>     na.strings = "-")
>
>     str(dat)
>     dat[4:10] <- lapply(dat[4:10], function(x) as.numeric(as.character(x)))
>     head(dat)
>
>
>     Hope this helps,
>
>     Rui Barradas
>
>     Em 08-04-2014 20:40, Christofer Bogaso escreveu:
>
>         Hi again,
>
>         I am looking some way to download this data:
>
>         http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>         <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>
>
>         So far I have tried following code:
>
>         library(XML)
>         data <- xmlParse("
>         http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>         <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>
>         ")
>
>         However not be able to get in right way.
>
>         Really appreciate if someone point me on right approach.
>
>         Thanks for your time.
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>



From ruipbarradas at sapo.pt  Tue Apr 22 18:49:28 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 22 Apr 2014 17:49:28 +0100
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <53569AF8.3040202@sapo.pt>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>	<534452BA.4050605@sapo.pt>	<CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>
	<53569AF8.3040202@sapo.pt>
Message-ID: <53569D98.5070109@sapo.pt>

Hello,

I've just noticed that na.strings is not needed and will not be used by 
readHTMLTable. I was with the false impression that the dots argument 
was to pass other arguments to read.table, but it's not, they're passed 
to as.data.frame, that doesn't use na.strings.

Rui Barradas

Em 22-04-2014 17:38, Rui Barradas escreveu:
> Hello,
>
> Have you tried which=2?
>
> dat <- readHTMLTable(readLines(Link), which = 2, header = TRUE,
> na.strings = "-")
>
> dat[, 3:15] <- lapply(dat[, 3:15], function(x) sub("([[:digit:]]) [ab]",
> "\\1", x))
> dat[, 3:15] <- lapply(dat[, 3:15], function(x)as.numeric(as.character(x)))
>
> str(dat)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 22-04-2014 16:30, Christofer Bogaso escreveu:
>> Hi Rui,
>>
>> Sorry to late reply. Thanks for your pointer.
>>
>> However using this method, I am having difficulty to download related
>> data from same site.
>>
>> I need to download data from:
>>
>>
>> 'http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352'
>>
>>
>> So I tried following:
>>
>> library(XML)
>> Link <-
>> 'http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352'
>>
>> readHTMLTable(readLines(Link), which = 1, header = TRUE, na.strings =
>> "-")
>>
>> Unfortunately I didnot get what I wanted.
>>
>> Can you (or someone) please help me on this?
>>
>> Thanks for your time.
>>
>>
>> On Wed, Apr 9, 2014 at 1:34 AM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>
>>     Hello,
>>
>>     Try the following.
>>
>>     library(XML)
>>     URL <-
>>
>> "http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>>
>>
>> <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>"
>>
>>
>>     dat <- readHTMLTable(readLines(URL), which=1, header=TRUE,
>>     na.strings = "-")
>>
>>     str(dat)
>>     dat[4:10] <- lapply(dat[4:10], function(x)
>> as.numeric(as.character(x)))
>>     head(dat)
>>
>>
>>     Hope this helps,
>>
>>     Rui Barradas
>>
>>     Em 08-04-2014 20:40, Christofer Bogaso escreveu:
>>
>>         Hi again,
>>
>>         I am looking some way to download this data:
>>
>>
>> http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>>
>>
>> <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>
>>
>>
>>         So far I have tried following code:
>>
>>         library(XML)
>>         data <- xmlParse("
>>
>> http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>>
>>
>> <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>
>>
>>         ")
>>
>>         However not be able to get in right way.
>>
>>         Really appreciate if someone point me on right approach.
>>
>>         Thanks for your time.
>>
>>                  [[alternative HTML version deleted]]
>>
>>         ________________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/__listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/__posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>> code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Apr 22 19:45:59 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Apr 2014 10:45:59 -0700 (PDT)
Subject: [R] Hi ,
	Is it possible select a different number of rows by each group with
	R????
In-Reply-To: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
References: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
Message-ID: <1398188759.90767.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi Marta,
It's not clear whether you wanted to select the first "n" rows specified by field2 in the first dataset or just random rows.
##using a modified example if my guess is correct

dat1 <- structure(list(field1 = 1:3, field2 = c(3L, 6L, 4L)), .Names = c("field1", 
"field2"), class = "data.frame", row.names = c(NA, -3L))



dat2 <- structure(list(field1 = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L), field3 = c(0.375, 0.416667, 0.458333, 0.5, 0.541667, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.708333, 
0.75, 0.791667, 0.833333, 0.875), field4 = c("Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp"), field5 = c("Rm1", "Rm2", "Rm3", "Rm4", "Rm5", "Rm6", "Jm1", 
"Jm2", "Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Rm6", "Jm1", "Jm2", 
"Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Jm3", "Jm4", "Jm5", "Jm6", 
"Jm7")), .Names = c("field1", "field3", "field4", "field5"), class = "data.frame", row.names = c(NA, 
-26L))


##for selecting the first 'n' rows

dat2New <- merge(dat1,dat2,by="field1")
library(plyr)
res1 <- ddply(dat2New,.(field1),function(x) head(x,unique(x$field2)))[,-2]


#or
res2 <- dat2[with(dat1,rep(match(field1, dat2$field1),field2)+sequence(field2)-1),]

A.K.


?Sorry, I think now the message is correct.

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2).
I have these 2 tables:

Table1
field1 field2
1 3
2 6
3 9
4 3
5 3
6 3
7 3
8 9
9 6
10 3
11 3
12 3
13 3
14 3
?????????????????????? 
Table2
field1 field3 field4 field5
1 0.375 Sp Rm1
1 0.416667 Sp Rm2
1 0.458333 Sp Rm3
1 0.5??????? Sp Rm4
1 0.541667 Sp Rm5
1 0.583333 Sp Rm6
1 0.625 Sp Jm1
1 0.666667 Sp Jm2
1 0.708333 Sp Jm3
1 0.75?? Sp Jm4
1 0.791667 Sp Jm5
1 0.833333 Sp Jm6
1 0.875 Sp Jm7

thx!!! 


On Monday, April 21, 2014 4:02 PM, Marta Tobe?a <marta_mtm at hotmail.com> wrote:

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2). I have these 2 tables:Table1Table2field1field2field1field3field4field51310.375SpRm12610.416667SpRm23910.458333SpRm34310.5SpRm45310.541667SpRm56310.583333SpRm67310.625SpJm18910.666667SpJm29610.708333SpJm310310.75SpJm411310.791667SpJm512310.833333SpJm613310.875SpJm714320.916667SpJm820.958333SpJm921SpJm1021.041667SpJm1121.083333SpJm1221.125SpJm1321.166667SpJm1421.208333SpJm1521.25SpJm1621.291667SpJm1721.333333SpJm18Thanks youMarta ??? ???????? ?????? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From motyocska at yahoo.com  Tue Apr 22 21:32:55 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 22 Apr 2014 12:32:55 -0700 (PDT)
Subject: [R] finding value for a parameter in an equation
Message-ID: <1398195175.48901.YahooMailNeo@web161604.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/9e738c94/attachment-0001.pl>

From ruipbarradas at sapo.pt  Tue Apr 22 22:13:16 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 22 Apr 2014 21:13:16 +0100
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <CA+dpOJ=g5Mvy5dMB_eBb1wY5ZPndceWarV+8OSsoZo4e=8+n0A@mail.gmail.com>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>	<534452BA.4050605@sapo.pt>	<CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>	<53569AF8.3040202@sapo.pt>	<53569D98.5070109@sapo.pt>
	<CA+dpOJ=g5Mvy5dMB_eBb1wY5ZPndceWarV+8OSsoZo4e=8+n0A@mail.gmail.com>
Message-ID: <5356CD5C.1030207@sapo.pt>

Hello,

I'm getting the data, apparently correct. What I'm getting is the following:


dput(dat)
structure(list(Updated = structure(c(1L, 1L, 1L, 4L, 6L, 5L,
7L, 6L, 2L, 3L), .Label = c("09:06:41 CT 22 Apr 2014", "10:57:42 CT 22 
Apr 2014",
"10:57:46 CT 22 Apr 2014", "11:10:10 CT 22 Apr 2014", "11:21:31 CT 22 
Apr 2014",
"11:21:34 CT 22 Apr 2014", "11:21:46 CT 22 Apr 2014"), class = "factor"),
     `Hi / Lo Limit` = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L), .Label = "No Limit / 0.001", class = "factor"),
     Volume = c(0, 41, 0, 27, 3, 61, 256, 221, 20, 16), High = c(NA,
     0.237, NA, 0.159, 0.116, 0.084, 0.058, 0.038, 0.024, 0.016
     ), Low = c(NA, 0.214, 0.16, 0.131, 0.081, 0.063, 0.039, 0.021,
     0.014, 0.009), `Prior Settle` = c(0.253, 0.207, 0.164, 0.124,
     0.09, 0.061, 0.041, 0.026, 0.016, 0.01), Change = c(NA, 0.03,
     -0.002, 0.026, 0.021, 0.017, 0.012, 0.008, 0.006, 0.004),
     Last = c(NA, 0.237, 0.162, 0.15, 0.111, 0.078, 0.053, 0.034,
     0.022, 0.014), `Strike Price` = c(4450, 4500, 4550, 4600,
     4650, 4700, 4750, 4800, 4850, 4900), Last = c(0.006, 0.008,
     0.011, 0.019, 0.031, 0.05, 0.073, 0.105, 0.141, 0.182), Change = c(0,
     -0.002, -0.006, -0.008, -0.012, -0.014, -0.021, -0.024, -0.028,
     -0.031), `Prior Settle` = c(0.006, 0.01, 0.017, 0.027, 0.043,
     0.064, 0.094, 0.129, 0.169, 0.213), Low = c(0.005, 0.008,
     0.011, 0.019, 0.03, 0.047, 0.067, 0.101, 0.137, 0.182), High = 
c(0.006,
     0.01, 0.02, 0.03, 0.046, 0.07, 0.098, 0.134, 0.171, NA),
     Volume = c(4, 81, 2, 76, 2, 3, 1, 0, 0, 0), `Hi / Lo Limit` = 
structure(c(1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "No Limit / 0.001", 
class = "factor"),
     Updated = structure(c(1L, 2L, 3L, 4L, 5L, 8L, 5L, 6L, 7L,
     1L), .Label = c("09:06:41 CT 22 Apr 2014", "09:11:58 CT 22 Apr 2014",
     "09:22:42 CT 22 Apr 2014", "10:22:14 CT 22 Apr 2014", "11:10:06 CT 
22 Apr 2014",
     "11:17:56 CT 22 Apr 2014", "11:18:10 CT 22 Apr 2014", "11:21:34 CT 
22 Apr 2014"
     ), class = "factor")), .Names = c("Updated", "Hi / Lo Limit",
"Volume", "High", "Low", "Prior Settle", "Change", "Last", "Strike Price",
"Last", "Change", "Prior Settle", "Low", "High", "Volume", "Hi / Lo Limit",
"Updated"), row.names = c(NA, -10L), class = "data.frame")


Rui Barradas

Em 22-04-2014 19:35, Christofer Bogaso escreveu:
> Hi Rui,
>
> Thanks for your prompt reply.
>
> However unfortunately I see that the correct information is not getting
> fetched.
>
> Here I have tried another page:
>
> Link <-
> 'http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352&strikeRange=Active'
>
> readHTMLTable((Link), which = 2, header = TRUE, na.strings = "-")
>
> I am not getting right data which is there in the site. Any additional
> adjustment I need to do?
>
> Thanks and regards,
>
>
> On Tue, Apr 22, 2014 at 10:34 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     I've just noticed that na.strings is not needed and will not be used
>     by readHTMLTable. I was with the false impression that the dots
>     argument was to pass other arguments to read.table, but it's not,
>     they're passed to as.data.frame, that doesn't use na.strings.
>
>     Rui Barradas
>
>     Em 22-04-2014 17:38, Rui Barradas escreveu:
>
>         Hello,
>
>         Have you tried which=2?
>
>         dat <- readHTMLTable(readLines(Link), which = 2, header = TRUE,
>         na.strings = "-")
>
>         dat[, 3:15] <- lapply(dat[, 3:15], function(x)
>         sub("([[:digit:]]) [ab]",
>         "\\1", x))
>         dat[, 3:15] <- lapply(dat[, 3:15],
>         function(x)as.numeric(as.__character(x)))
>
>         str(dat)
>
>
>         Hope this helps,
>
>         Rui Barradas
>
>         Em 22-04-2014 16:30, Christofer Bogaso escreveu:
>
>             Hi Rui,
>
>             Sorry to late reply. Thanks for your pointer.
>
>             However using this method, I am having difficulty to
>             download related
>             data from same site.
>
>             I need to download data from:
>
>
>             'http://www.cmegroup.com/__trading/energy/natural-gas/__natural-gas_quotes_globex___options.html?optionExpiration=__K4#optionProductId=1352
>             <http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352>'
>
>
>             So I tried following:
>
>             library(XML)
>             Link <-
>             'http://www.cmegroup.com/__trading/energy/natural-gas/__natural-gas_quotes_globex___options.html?optionExpiration=__K4#optionProductId=1352
>             <http://www.cmegroup.com/trading/energy/natural-gas/natural-gas_quotes_globex_options.html?optionExpiration=K4#optionProductId=1352>'
>
>             readHTMLTable(readLines(Link), which = 1, header = TRUE,
>             na.strings =
>             "-")
>
>             Unfortunately I didnot get what I wanted.
>
>             Can you (or someone) please help me on this?
>
>             Thanks for your time.
>
>
>             On Wed, Apr 9, 2014 at 1:34 AM, Rui Barradas
>             <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>             <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
>             wrote:
>
>                  Hello,
>
>                  Try the following.
>
>                  library(XML)
>                  URL <-
>
>             "http://www.cmegroup.com/____trading/interest-rates/stir/____eurodollar_quotes_openOutcry.____html
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html>
>
>
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>             <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>>"
>
>
>                  dat <- readHTMLTable(readLines(URL), which=1, header=TRUE,
>                  na.strings = "-")
>
>                  str(dat)
>                  dat[4:10] <- lapply(dat[4:10], function(x)
>             as.numeric(as.character(x)))
>                  head(dat)
>
>
>                  Hope this helps,
>
>                  Rui Barradas
>
>                  Em 08-04-2014 20:40, Christofer Bogaso escreveu:
>
>                      Hi again,
>
>                      I am looking some way to download this data:
>
>
>             http://www.cmegroup.com/____trading/interest-rates/stir/____eurodollar_quotes_openOutcry.____html
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html>
>
>
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>             <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>>
>
>
>                      So far I have tried following code:
>
>                      library(XML)
>                      data <- xmlParse("
>
>             http://www.cmegroup.com/____trading/interest-rates/stir/____eurodollar_quotes_openOutcry.____html
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html>
>
>
>             <http://www.cmegroup.com/__trading/interest-rates/stir/__eurodollar_quotes_openOutcry.__html
>             <http://www.cmegroup.com/trading/interest-rates/stir/eurodollar_quotes_openOutcry.html>>
>
>                      ")
>
>                      However not be able to get in right way.
>
>                      Really appreciate if someone point me on right
>             approach.
>
>                      Thanks for your time.
>
>                               [[alternative HTML version deleted]]
>
>                      __________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org>
>             <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>             mailing list
>             https://stat.ethz.ch/mailman/____listinfo/r-help
>             <https://stat.ethz.ch/mailman/__listinfo/r-help>
>                      <https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>>
>                      PLEASE do read the posting guide
>             http://www.R-project.org/____posting-guide.html
>             <http://www.R-project.org/__posting-guide.html>
>                      <http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>>
>                      and provide commented, minimal, self-contained,
>             reproducible
>             code.
>
>
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>



From btyner at gmail.com  Wed Apr 23 02:59:57 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 22 Apr 2014 20:59:57 -0400
Subject: [R] detecting the sourcing of site profile on Startup versus
	post-Startup
Message-ID: <5357108D.3040704@gmail.com>

Greetings,

Is there any way to programmatically detect whether a piece of code is
being run within the initial (Startup) sourcing of the site profile?

For example, say I have a site profile, "/path/to/Rprofile.site". Is
there any function "my_func" which would return different values for
these two instances:

   Rscript --no-site-profile --no-init-profile -e
"sys.source('/path/to/Rprofile.site', envir = .BaseNamespaceEnv); my_func()"

versus:

   export R_PROFILE=/path/to/Rprofile.site
   Rscript --no-init-profile -e "my_func()"

Regards,
Ben



From sjtuliuli at gmail.com  Wed Apr 23 05:27:09 2014
From: sjtuliuli at gmail.com (Li Liu)
Date: Wed, 23 Apr 2014 11:27:09 +0800
Subject: [R] Fwd: How to custom initialize such that we can pre-load data
	and libraries.
In-Reply-To: <CADnvbW6xw_4bWCiVrzDVu2PaK0uEOM6GGy33VJcrEitQJzNbLw@mail.gmail.com>
References: <CADnvbW6xw_4bWCiVrzDVu2PaK0uEOM6GGy33VJcrEitQJzNbLw@mail.gmail.com>
Message-ID: <CADnvbW635QKtpCRqjDR6j4ABJ3XG-XN_4QtDs891kvyLuky8dw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/1c370a96/attachment-0001.pl>

From Zhuang.Kang at moodys.com  Tue Apr 22 16:58:53 2014
From: Zhuang.Kang at moodys.com (Kang, Zhuang)
Date: Tue, 22 Apr 2014 14:58:53 +0000
Subject: [R] loess.control extrapolation
Message-ID: <52438FECE69DB24189DB10F5FDEDBF6E2045278B@PTC-WPMSX704.ad.moodys.net>

Dear r-help,

What exactly the extrapolation in loess does by using suface="direct"? I tried to dig into stats:::simpleLoess and even the C/fortan code, but find it's real difficult to read through them. 

A toy example is below, I would appreciate if anyone to show me how to (closely enough)  replicate the value of extrapolation.

Thanks!


# a toy example with extrapolation in loess
xx2<-as.data.frame(cbind(c(1,2,3,4,5,6,7,8,9,10,11),c(3,5,6,7,8,9,8,8,NA,NA,NA)))
plot(xx2,type="b",col=2)
ll<-loess(V2~V1,data=xx2,control=loess.control(surface="direct"),degree=2)
xx2p<-predict(ll,xx2)
plot(xx2,type="b",ylim=c(0,15))
lines(xx2$V1,xx2p,type="p",col=2)

# spline can't exactly replicate the extrapolation
zz<-spline(xx2$V1[1:8],xx2p[1:8],xout=c(9,10,11),
           method="fmm")
zz$y-xx2p[9:11]
# not the same.. difference is:
#           9          10          11 
# 0.004405272 0.055746248 0.244225235



-----------------------------------------

The information contained in this e-mail message, and any attachment thereto, is confidential and may not be disclosed without our express permission. If you are not the intended recipient or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that you have received this message in error and that any review, dissemination, distribution or copying of this message, or any attachment thereto, in whole or in part, is strictly prohibited. If you have received this message in error, please immediately notify us by telephone, fax or e-mail and delete the message and all of its attachments. Thank you. Every effort is made to keep our network free from viruses. You should, however, review this e-mail message, as well as any attachment thereto, for viruses. We take no responsibility and have no liability for any computer virus which may be transferred via this e-mail message.



From sathish316 at gmail.com  Tue Apr 22 16:37:38 2014
From: sathish316 at gmail.com (Sathish Kumar)
Date: Tue, 22 Apr 2014 20:07:38 +0530
Subject: [R] How to convert R package and dependencies to debian packages?
Message-ID: <CAORY-37vKi_Cx9tufAZb54Dqae7Zj0234pZenby1kfFbp-wYZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/c22db062/attachment-0001.pl>

From ilikescience1 at gmail.com  Tue Apr 22 18:41:46 2014
From: ilikescience1 at gmail.com (Brandon Vaughan)
Date: Tue, 22 Apr 2014 12:41:46 -0400
Subject: [R] JAGS returning error after sampling MCMC chain
Message-ID: <CAMhq6n+8Hg15X7+b9z1YD2iuBx71QHqGYA-kjaNkacnOiLPXuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/9defa587/attachment-0001.pl>

From soeren.groettrup at gmail.com  Tue Apr 22 19:29:37 2014
From: soeren.groettrup at gmail.com (Soeren Groettrup)
Date: Tue, 22 Apr 2014 19:29:37 +0200
Subject: [R] R dataset copyrights
Message-ID: <5356A701.3050901@gmail.com>

Hi everybody,

I've been searching the web for quite a time now and haven't found a 
satisfying answer. I was wondering if the datasets provided within the R 
packages are open, and thus can be used in publications? Concretely, can 
the data, for example, be exported from R and uploaded in a different 
format (like csv) to a website to be accessible for students to work 
with the data in SPSS or Matlab? Is it enough to cite the source or 
paper or do I need a permission for every dataset?

Thanks in advance for your replies,
S?ren Gr?ttrup



From gleynes+r at gmail.com  Tue Apr 22 20:34:23 2014
From: gleynes+r at gmail.com (Gene Leynes)
Date: Tue, 22 Apr 2014 13:34:23 -0500
Subject: [R] R Example scripts
In-Reply-To: <53525A04.1030202@gmail.com>
References: <CAOBARVi1+L9Sb+qUwo16f3OmXTkv2gmuBzz3o4n8zFvc-U8WZQ@mail.gmail.com>
	<53525A04.1030202@gmail.com>
Message-ID: <CAOBARVjtvG05rD_Q-qzxt23r2-1fQ6Cc-9ri6dq6qwDEA2QMYw@mail.gmail.com>

Duncan,

First, thank you. It's amazing how many things R has built in... such
as these quirky functions! I really appreciate the example.

Second, as it turns out I was looking for something that doesn't exist
in bayesm, although it wasn't obvious to me until I followed your
answer and read the package web page more carefully
(http://www.perossi.org/home/bsm-1/bayesm).

I was looking for those extended examples that some packages have. For
example e1071 has a file called svn.R in the /doc folder.  Many
packages, such as formatR and hmeasure have scripts with the same name
as the package in the /doc folder. I thought (mistakenly) that those
extended examples had been moved / encoded.

For anyone searching for "bayesm examples" you may find this link
helpful, because it does have some examples and more info about the
book by Peter Rossi:
http://www.perossi.org/home/bsm-1


On Sat, Apr 19, 2014 at 6:12 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 18/04/2014, 6:07 PM, Gene Leynes wrote:
>>
>> A few years ago R changed the way help was handled so that the HTML
>> files are no longer available in the library directory.  Around that
>> time the R example files that used to be in some of the libraries also
>> vanished.
>>
>> I'm wondering where the "r-ex" folder went. Is it totally unsupported
>> and gone? Is it hidden in the mysterious rdx or rdb files?
>
>
> The source for the examples will be in the \examples{} section of the .Rd
> source file -- that didn't change.  What changed was how the source is
> processed.  The files are now parsed into a binary format that is stored in
> the database files.
>
> You can extract the examples from the source file using the tools::Rd2ex
> function.  You can extract them from the binary database using this function
> on an Rd object, which is obtainable using the internal function
> .getHelpFile.
>
> So for example, to see the code for the example for rwishart, you could do
>
> tools::Rd2ex(".../bayesm/man/rwishart.Rd")
>
> if you have the source file installed there, or
>
> library(bayesm)
> Rd <- utils:::.getHelpFile(?rwishart)
> tools::Rd2ex(Rd)
>
> if you have the package installed.
>
> Duncan Murdoch
>>
>>
>> In particular I'm looking for the latest example scripts in the baysem
>> package. I don't see them in the source code or the installed library.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



From bogaso.christofer at gmail.com  Tue Apr 22 20:35:14 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 23 Apr 2014 00:20:14 +0545
Subject: [R] Need to download this data... can someone help?
In-Reply-To: <53569D98.5070109@sapo.pt>
References: <CA+dpOJkDVSmZhyHBhXv1qS=aS38MSSwKi_u3TbOG7G0fvGmMsg@mail.gmail.com>
	<534452BA.4050605@sapo.pt>
	<CA+dpOJ=p1ogXy-db5spHSk4g9-f_R1Dq7pRDkYDPcCZryMXbiA@mail.gmail.com>
	<53569AF8.3040202@sapo.pt> <53569D98.5070109@sapo.pt>
Message-ID: <CA+dpOJ=g5Mvy5dMB_eBb1wY5ZPndceWarV+8OSsoZo4e=8+n0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/5e50d196/attachment-0001.pl>

From elelop03 at gmail.com  Tue Apr 22 22:00:38 2014
From: elelop03 at gmail.com (Elena Lopez)
Date: Tue, 22 Apr 2014 15:00:38 -0500
Subject: [R] Questions regarding cvAUC package (cross validation AUC)
Message-ID: <CAOef5+6ELkSNBoHPvMT+chLR6RKJHC88u4u0umcXeXFiSMaXSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/9e16b8ff/attachment-0001.pl>

From bpschn01 at gmail.com  Tue Apr 22 23:15:31 2014
From: bpschn01 at gmail.com (Brad P)
Date: Tue, 22 Apr 2014 16:15:31 -0500
Subject: [R] LASSO covTest doesn't work when used inside a function
Message-ID: <CAMAcwjwSq3Dw8FPWbXQjFn1SXpWvF+h27ryOsvTLaQ-CH7az9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/5f0af539/attachment-0001.pl>

From ashisdeb83 at gmail.com  Wed Apr 23 07:10:20 2014
From: ashisdeb83 at gmail.com (Ashis Deb)
Date: Wed, 23 Apr 2014 10:40:20 +0530
Subject: [R] Problem in handling Date format
Message-ID: <CAFcJUTphgrUy7r5cRsyzpeWd4hA_9===+LCB5_8O0pJSrCLVdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/a1c9f3d0/attachment-0001.pl>

From dwinsemius at comcast.net  Wed Apr 23 07:52:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 22 Apr 2014 22:52:25 -0700
Subject: [R] Problem in handling Date format
In-Reply-To: <CAFcJUTphgrUy7r5cRsyzpeWd4hA_9===+LCB5_8O0pJSrCLVdQ@mail.gmail.com>
References: <CAFcJUTphgrUy7r5cRsyzpeWd4hA_9===+LCB5_8O0pJSrCLVdQ@mail.gmail.com>
Message-ID: <94EF9272-54F1-4EF8-8EC8-F55712FB179F@comcast.net>


On Apr 22, 2014, at 10:10 PM, Ashis Deb wrote:

> Hi all  ,
> 
> I have this  data  like ,  ashdata
> 
>             YHOO.Open  YHOO.High YHOO.Low YHOO.Close YHOO.Volume YHOO.Adjusted
> 2007-01-03     25.85     26.26    25.26      25.61    26352700         25.61
> 2007-01-04     25.64     26.92    25.52      26.85    32512200         26.85
> 2007-01-05     26.70     27.87    26.66      27.74    64264600         27.74
> 2007-01-08     27.70     28.04    27.43      27.92    25713700         27.92
> 2007-01-09     28.00     28.05    27.41      27.58    25621500         27.58
> 2007-01-10     27.48     28.92    27.44      28.70    40240000         28.70
> 
> 
>> I had put it in a csv in my desktop using
> write.csv(ashdata,"D:/ashdata1.csv")
> 
> Then I tried to access the csv using read.csv("D:/ashdata1.csv")
> 
> but when I accessed the data , the "date" format changed to numeric
> expression like
> 
> 10 ,20 ,30 ,
> 
> Can anybody suggest a simple way to handle Dates in R , could not find any
> function .
> 

The initial display looks like an xts or zoo data-object. The dates would be row.names and the interior entries part of the coredata matrix. `write.csv` might not be the proper vehicle for saving such an object.
It sounds like you got the dates read in as character variables which unfortunately means they were probably automatically converted to factors, given the stringsAsFactors is an option that is TRUE by default.

-- 
David.


> Sorry for such a basic Questions.
> 
> 
> Thanks You
> 
> ASHIS
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From abetz58 at gmail.com  Wed Apr 23 08:33:44 2014
From: abetz58 at gmail.com (andreas betz)
Date: Tue, 22 Apr 2014 23:33:44 -0700
Subject: [R] fitting a family of curves
Message-ID: <CAMBc2W40nDR15hvYDauOMGHdCq=Bi+KuHv4X+11v-Jp2UeypDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140422/68f29d52/attachment-0001.pl>

From kpmainali at utexas.edu  Wed Apr 23 10:00:02 2014
From: kpmainali at utexas.edu (Kumar Mainali)
Date: Wed, 23 Apr 2014 03:00:02 -0500
Subject: [R] mvpart - is there a convenient way to calculate deviance
	explained by variables?
Message-ID: <CABK368hAYN1VRPZKCmBrjXkJuGLn1EWwtt86seBBK=__ZzecYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/4806dd76/attachment-0001.pl>

From frtog at vestas.com  Wed Apr 23 10:53:34 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 23 Apr 2014 10:53:34 +0200
Subject: [R] finding value for a parameter in an equation
In-Reply-To: <1398195175.48901.YahooMailNeo@web161604.mail.bf1.yahoo.com>
References: <1398195175.48901.YahooMailNeo@web161604.mail.bf1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA5CE3@DKRDSEXC016.vestas.net>

Hi Andras

I suppose you want to find the real root of your equation if such exists for the particular settings of the parameters. For that you can use uniroot().

So define a function based on your equation like this:

f <- function(E, D1, D2, IC501, IC502, ECON, ALPHA, M1, M2){
    1 - D1/(IC501*((E/(ECON-E))^(1/M1)))+D2/(IC502*((E/(ECON-E))^(1/M2))) +
        (ALPHA*D1*D2)/(IC501*IC502*((E/(ECON-E))^(0.5/M1+0.5/M2)))
}

Now do some plotting to see how the functions behaves:

## Parameters
D1 <-c(0.2,0.6,0.8)
D2 <-c(114,190,304)
IC501 <-0.62             
IC502 <-137.8
ECON <-5.95
ALPHA <-0.00005
M1 <-0.84 
M2 <-0.96

# vector for E
E <- seq(1,15, len = 100)

## three curves for each set of values of D1 and D2
plot(E, f(E, D1[1], D2[1], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col = "red")
lines(E, f(E, D1[2], D2[2], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col = "green")
lines(E, f(E, D1[3], D2[3], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col = "blue")

f() is only defined on the open interval (0;6).

Attached figure shows that there is real roots for the 3 values of  D1 and D2 somewhere between 0 and 1.

And those can be found as

> uniroot(f, c(0.0001,1), D1=D1[1], D2=D2[2], IC501=IC501, IC502=IC502, ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
$root
[1] 0.0003440589

$f.root
[1] 21.33889

$iter
[1] 14

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

> uniroot(f, c(0.0001,1), D1=D1[2], D2=D2[2], IC501=IC501, IC502=IC502, ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
$root
[1] 0.3840484

$f.root
[1] -9.45929e-05

$iter
[1] 9

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

> uniroot(f, c(0.0001,1), D1=D1[3], D2=D2[3], IC501=IC501, IC502=IC502, ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
$root
[1] 0.1476688

$f.root
[1] -0.001927616

$iter
[1] 9

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

>


> uniroot(f, c(0.0001,1), D1=D1[2], D2=D2[2], IC501=IC501, IC502=IC502, ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
$root
[1] 0.3840484

$f.root
[1] -9.45929e-05

$iter
[1] 9

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

But




Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Andras Farkas
> Sent: 22. april 2014 21:33
> To: r-help at r-project.org
> Subject: [R] finding value for a parameter in an equation
> 
> Dear All,
> 
> please provide some insights for the following:
> 
> we have:
> 
> D1 <-c(0.2,0.6,0.8)
> D2 <-c(114,190,304)
> IC501 <-0.62
> IC502 <-137.8
> ECON <-5.95
> ALPHA <-0.00005
> M1 <-0.84
> M2 <-0.96
> 
> and the equation:
> 
> 1 = D1/(IC501*((E/(ECON-E))^(1/M1)))+D2/(IC502*((E/(ECON-
> E))^(1/M2)))+(ALPHA*D1*D2)/(IC501*IC502*((E/(ECON-
> E))^(0.5/M1+0.5/M2)))
> 
> In this equation the value for parameter "E" is what I am trying to calculate
> (all other parameters are known) for each pairs of D1 and D2 (ie:?input D1[1]
> and D2[1] and the rest of the parameters first then substitute D1[2] and
> D2[2], then substitute D1[3] and D2[3]). It seems as if the equation can not
> be re-arranged so that "E"?could be directly calculated, so looking to see if
> you could help me?perhaps with a thought on how this could be solved with
> R,
> 
> thanks as always,
> 
> Andras
> 	[[alternative HTML version deleted]]

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot_of_f.png
Type: image/png
Size: 5682 bytes
Desc: plot_of_f.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/e60f98c5/attachment-0002.png>

From frtog at vestas.com  Wed Apr 23 11:04:09 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 23 Apr 2014 11:04:09 +0200
Subject: [R] finding value for a parameter in an equation
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA5CE3@DKRDSEXC016.vestas.net>
References: <1398195175.48901.YahooMailNeo@web161604.mail.bf1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA5CE3@DKRDSEXC016.vestas.net>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA5D03@DKRDSEXC016.vestas.net>

Sorry I made a copy and paste error. To get all the details of the curves between 0 and I had to use:

E <- seq(0,10, len = 2000) 

Sorry for the inconvenience.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Frede Aakmann T?gersen
> Sent: 23. april 2014 10:54
> To: Andras Farkas; r-help at r-project.org
> Subject: Re: [R] finding value for a parameter in an equation
> 
> Hi Andras
> 
> I suppose you want to find the real root of your equation if such exists for
> the particular settings of the parameters. For that you can use uniroot().
> 
> So define a function based on your equation like this:
> 
> f <- function(E, D1, D2, IC501, IC502, ECON, ALPHA, M1, M2){
>     1 - D1/(IC501*((E/(ECON-E))^(1/M1)))+D2/(IC502*((E/(ECON-E))^(1/M2)))
> +
>         (ALPHA*D1*D2)/(IC501*IC502*((E/(ECON-E))^(0.5/M1+0.5/M2)))
> }
> 
> Now do some plotting to see how the functions behaves:
> 
> ## Parameters
> D1 <-c(0.2,0.6,0.8)
> D2 <-c(114,190,304)
> IC501 <-0.62
> IC502 <-137.8
> ECON <-5.95
> ALPHA <-0.00005
> M1 <-0.84
> M2 <-0.96
> 
> # vector for E
> E <- seq(1,15, len = 100)
> 
> ## three curves for each set of values of D1 and D2
> plot(E, f(E, D1[1], D2[1], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col =
> "red")
> lines(E, f(E, D1[2], D2[2], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col
> = "green")
> lines(E, f(E, D1[3], D2[3], IC501, IC502, ECON, ALPHA, M1, M2), type = "l", col
> = "blue")
> 
> f() is only defined on the open interval (0;6).
> 
> Attached figure shows that there is real roots for the 3 values of  D1 and D2
> somewhere between 0 and 1.
> 
> And those can be found as
> 
> > uniroot(f, c(0.0001,1), D1=D1[1], D2=D2[2], IC501=IC501, IC502=IC502,
> ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
> $root
> [1] 0.0003440589
> 
> $f.root
> [1] 21.33889
> 
> $iter
> [1] 14
> 
> $init.it
> [1] NA
> 
> $estim.prec
> [1] 6.103516e-05
> 
> > uniroot(f, c(0.0001,1), D1=D1[2], D2=D2[2], IC501=IC501, IC502=IC502,
> ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
> $root
> [1] 0.3840484
> 
> $f.root
> [1] -9.45929e-05
> 
> $iter
> [1] 9
> 
> $init.it
> [1] NA
> 
> $estim.prec
> [1] 6.103516e-05
> 
> > uniroot(f, c(0.0001,1), D1=D1[3], D2=D2[3], IC501=IC501, IC502=IC502,
> ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
> $root
> [1] 0.1476688
> 
> $f.root
> [1] -0.001927616
> 
> $iter
> [1] 9
> 
> $init.it
> [1] NA
> 
> $estim.prec
> [1] 6.103516e-05
> 
> >
> 
> 
> > uniroot(f, c(0.0001,1), D1=D1[2], D2=D2[2], IC501=IC501, IC502=IC502,
> ECON=ECON, ALPHA=ALPHA, M1=M1, M2=M2)
> $root
> [1] 0.3840484
> 
> $f.root
> [1] -9.45929e-05
> 
> $iter
> [1] 9
> 
> $init.it
> [1] NA
> 
> $estim.prec
> [1] 6.103516e-05
> 
> But
> 
> 
> 
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org]
> > On Behalf Of Andras Farkas
> > Sent: 22. april 2014 21:33
> > To: r-help at r-project.org
> > Subject: [R] finding value for a parameter in an equation
> >
> > Dear All,
> >
> > please provide some insights for the following:
> >
> > we have:
> >
> > D1 <-c(0.2,0.6,0.8)
> > D2 <-c(114,190,304)
> > IC501 <-0.62
> > IC502 <-137.8
> > ECON <-5.95
> > ALPHA <-0.00005
> > M1 <-0.84
> > M2 <-0.96
> >
> > and the equation:
> >
> > 1 = D1/(IC501*((E/(ECON-E))^(1/M1)))+D2/(IC502*((E/(ECON-
> > E))^(1/M2)))+(ALPHA*D1*D2)/(IC501*IC502*((E/(ECON-
> > E))^(0.5/M1+0.5/M2)))
> >
> > In this equation the value for parameter "E" is what I am trying to calculate
> > (all other parameters are known) for each pairs of D1 and D2 (ie:?input
> D1[1]
> > and D2[1] and the rest of the parameters first then substitute D1[2] and
> > D2[2], then substitute D1[3] and D2[3]). It seems as if the equation can not
> > be re-arranged so that "E"?could be directly calculated, so looking to see if
> > you could help me?perhaps with a thought on how this could be solved with
> > R,
> >
> > thanks as always,
> >
> > Andras
> > 	[[alternative HTML version deleted]]



From pavneet.arora at uk.rsagroup.com  Wed Apr 23 11:14:19 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Wed, 23 Apr 2014 10:14:19 +0100
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <6982453b-d4bd-447e-884b-5bca39111d34@email.android.com>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
	<OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
	<534F0A4A.6070304@statistik.tu-dortmund.de>
	<1398175195594-4689256.post@n4.nabble.com>
	<6982453b-d4bd-447e-884b-5bca39111d34@email.android.com>
Message-ID: <OFF209995A.4613D9C7-ON80257CC3.002FEBC1-80257CC3.0033482F@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/9396039a/attachment-0001.pl>

From aguitatierra at hotmail.com  Wed Apr 23 11:37:24 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 23 Apr 2014 11:37:24 +0200
Subject: [R] Loop to extract from variables in the workspace
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA55C5@DKRDSEXC016.vestas.net>
References: <BLU0-SMTP3069DA52B91B3A9FF9E83E3D95E0@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA54EA@DKRDSEXC016.vestas.net>
	<BLU0-SMTP2869D275E60143FAD7E192BD95E0@phx.gbl>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5DA55C5@DKRDSEXC016.vestas.net>
Message-ID: <BLU0-SMTP10500C4190BC730963E82B6D9580@phx.gbl>

Dear Frede,

Sorry for the late reply, yesterday I was out of office.

Thanks so much for your code! It has just compacted in a few lines what 
I had written in several 'paragraphs'!

To be honest, I'm not familiar to work with lists in R. I think one of 
its main advantages is the reduced size of the outputs.

Thanks again and have a nice day,

Bea


On 22.04.2014 07:04, Frede Aakmann T?gersen wrote:
> Well, sticking to your loop that you seem comfortable with try this:
>
> ## list to hold dataframes
> extracList <- vector("list", length(1981:2010))
>
> cnt <- 0
> for(i in 1981:2010){
> 	cnt <- cnt + 1
> 	rasterObj <-get( c(paste("RR_", i, "_1", sep="")))
>        	extractList[[cnt]]<- extract(rasterObj, coords, df=T)}
>   }
>
> See ?get which is kind of the opposite of assign.
>
> To coerce the list of dataframes into one dataframe several methods are available:
>
> do.call("rbind", extractList)
>
> plyr::rbind.fill(extractList)
>
> plyr::ldply(extractList, data.frame)
>
> as.data.frame(data.table::rbindlist(extractList))
>
> This was taken from http://stackoverflow.com/questions/2851327/converting-a-list-of-data-frames-into-one-data-frame-in-r where you get get some pros and cons on the methods.
>
> The fastest way will probably be to create a huge dataframe and during the loop calculated the row indices of that dataframe for each raster into the result from extract should be put.
>
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: Beatriz R. Gonzalez Dominguez [mailto:aguitatierra at hotmail.com]
>> Sent: 21. april 2014 16:27
>> To: Frede Aakmann T?gersen; r-help at r-project.org
>> Subject: Re: [R] Loop to extract from variables in the workspace
>>
>> Hi Frede,
>>
>> Many thanks for your reply.
>> 1. The first argument in extract is a Formal class RasterLayer in the
>> Workspace (e.g RR_1981_1 ).
>>
>> 2. I created an intermediate name to hold the result fromthe extract
>> function because I'd like to create several dataframes with the output
>> of the iterative (loop) extraction. I'd like to get the same result as
>> when I do:
>>
>> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
>> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
>> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
>> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
>> [... this works no problem]
>>
>> 3. 'coords' is a SpatialPointsDataFrame.
>>
>> 4. I used assign in the loop becuase I thought it was the way forward to
>> create new variables out of it. Isn't it?
>>
>> What I'd like to do is to use coordinate points ('coords') to extract
>> raster pixel values (eg. 'RR_1981_1') on which the points are overlying.
>> Then I'd like to build a bigger data frame including the data from all
>> the outputs (i.e. PE.coords_01_1981, PE.coords_01_1982).
>>
>> Hope to have explained myself properly. Please let me know if anything
>> else should be clarified.
>>
>> Best wishes,
>>
>> Bea
>>
>>
>> On 21/04/2014 15:17, Frede Aakmann T?gersen wrote:
>>> Hi Beatriz
>>>
>>> Did you read the help for extract{raster} carefully?
>>>
>>> Several things can be wrong.
>>>
>>> 1) First argument to extract is not a file name but a raster object.
>>> 2) In the loop you name an object extract as an intermediate name to hold
>> the result from the extract function. Do you think there could be a name
>> clash? R is clever but perhaps not clever enough.
>>> 3) coords are of the right class (see ?extract).
>>> 4) assign can be useful from time to time. But in a loop?
>>>
>>> I think the things you are doing are some intermediate results that needs
>> more processing. Do you think this is the right way to do that. For instance
>> instead of storing the immediate result as separate objects why not store
>> those in a list.
>>> Perhaps if you tell us what you would like to do  overall, i.e. from first to
>> last, then we will be able to help you to become more efficient.
>>>
>>> Yours sincerely / Med venlig hilsen
>>>
>>>
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>>
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com
>>> http://www.vestas.com
>>>
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice
>>> If you have received this e-mail in error please contact the sender.
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org]
>>>> On Behalf Of Beatriz R. Gonzalez Dominguez
>>>> Sent: 21. april 2014 14:53
>>>> To: r-help at r-project.org
>>>> Subject: [R] Loop to extract from variables in the workspace
>>>>
>>>> Dear all,
>>>>
>>>> I'm starting to work with loops and I'm stucked on something.
>>>> I've been searching and trying different possibilities but I don't get
>>>> to the solution.
>>>> I'd be very grateful if you could share any ideas that you think may help.
>>>>
>>>> library("raster")
>>>>
>>>> # All my variables are in the workspace
>>>>
>>>> # This is what I'd like to obtain, but with a loop (I'm working with
>>>> several years and variables).
>>>> PE.coords_01_1981 <- extract(RR_1981_1, coords, df=T)
>>>> PE.coords_01_1982 <- extract(RR_1982_1, coords, df=T)
>>>> PE.coords_01_1983 <- extract(RR_1983_1, coords, df=T)
>>>> PE.coords_01_1984 <- extract(RR_1984_1, coords, df=T)
>>>> PE.coords_01_1985 <- extract(RR_1985_1, coords, df=T)
>>>> PE.coords_01_1986 <- extract(RR_1986_1, coords, df=T)
>>>> PE.coords_01_1987 <- extract(RR_1987_1, coords, df=T)
>>>> PE.coords_01_1988 <- extract(RR_1988_1, coords, df=T)
>>>> PE.coords_01_1989 <- extract(RR_1989_1, coords, df=T)
>>>> PE.coords_01_1990 <- extract(RR_1990_1, coords, df=T)
>>>>
>>>>
>>>> # This is one of the things I've tried.
>>>>
>>>> for(i in 1981:2010){
>>>> file <- c(paste("RR_", i, "_1", sep=""))
>>>> extract <- extract(file, coords, df=T)}
>>>> names.a <- paste("PE.coords_01_", i, sep="")
>>>> assign(names.a, value=extract)
>>>> }
>>>>
>>>> # I get the following error.
>>>> Error in (function (classes, fdef, mtable) :
>>>> unable to find an inherited method for function 'extract'
>>>> for signature '"character", "SpatialPointsDataFrame"'
>>>> # I think the error must be something when I'm defining 'file'
>>>>
>>>> Thanks a lot for any help!
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
>



From Thierry.ONKELINX at inbo.be  Wed Apr 23 11:44:33 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 23 Apr 2014 09:44:33 +0000
Subject: [R] Fw: Save multiple plots as pdf or jpeg
In-Reply-To: <OFF209995A.4613D9C7-ON80257CC3.002FEBC1-80257CC3.0033482F@uk.royalsun.com>
References: <OFA641FD2D.64708D73-ON80257CBB.00395FBD-80257CBB.0039F095@uk.royalsun.com>
	<534D3103.4060904@statistik.tu-dortmund.de>
	<OF816796D6.D966518E-ON80257CBC.00315C26-80257CBC.00320685@uk.royalsun.com>
	<534F0A4A.6070304@statistik.tu-dortmund.de>
	<1398175195594-4689256.post@n4.nabble.com>
	<6982453b-d4bd-447e-884b-5bca39111d34@email.android.com>
	<OFF209995A.4613D9C7-ON80257CC3.002FEBC1-80257CC3.0033482F@uk.royalsun.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A37C24@inbomail.inbo.be>

Have a look at the knitr package. http://yihui.name/knitr/demo/minimal/

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Pavneet Arora
Verzonden: woensdag 23 april 2014 11:14
Aan: Jeff Newmiller
CC: r-help at r-project.org
Onderwerp: Re: [R] Fw: Save multiple plots as pdf or jpeg

Sorry I should have been more clearer. Let me repharse.

At the moment I have a loop that plots a histogram of the variable, along with rug and super-imposed normal curve over it. It does that for a lot of variables in the dataset and then compiles them into a pdf. Whereby each page on the pdf corresponds to the histogram of 1 variable.

However, it takes ages to load and takes up a lot of memory. So I was wondering if there is a way that before it gets compiled into a pdf, if I can convert my graphs into png or bitmaps images and then compile them into pdf?

This is my code so far:

pdf(file="C:/#temp/Histo and2.pdf") ##- Saves all plots in the same pdf file
for(k in 1:ncol(nums2)){    hist(nums2[,k],freq=F,col="lightblue1",
#density=20   ##- Density -> Gives shaded bars
 main=names(nums2)[k],col.main="blue",cex.main=0.8,font=2,
                                 xlab=names(nums2)[k])  ##- Font=2 => bold

 #rug(jitter(nums2[,k]),side=1,col="antiquewhite3")

 lines(density(nums2[,k],na.rm=T),col="navy",lwd=2)          ##- Density
Function of data

 curve(dnorm(x,mean=mean(nums2[,k],na.rm=T),sd=sd(nums2[,k],na.rm=T)),
                                  col="brown",lwd=3,add=T)

                            #  readline(prompt="Press [enter] to
continue")
}
dev.off()
Hope this is much clearer?




From:   Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
To:     Pavneet Arora/UK/RoyalSun at RoyalSun, r-help at r-project.org
Date:   22/04/2014 16:09
Subject:        Re: [R] Fw: Save multiple plots as pdf or jpeg



Sounds like you are getting what you want... except that you used the word
"but". If you are not getting what you want, then what is it that you do
want? In particular, how do you intend to review or use many plots
generated at once if not in a PDF file?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go
Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#. rocks...1k
---------------------------------------------------------------------------

Sent from my phone. Please excuse my brevity.

On April 22, 2014 6:59:55 AM PDT, starter <pavneet.arora at uk.rsagroup.com>
wrote:
>That is what I was trying to achieve; i.e. plot all my graphs using a
>loop
>function. But somewhere in the loop it converts each graph into png or
>bitmap image and then compiles all these png or bitmap images in a pdf
>file.
>So each page in a pdf file is a bitmap or png picture of my graph.
>
>Does that make any sense?
>
>
>
>--
>View this message in context:
>
http://r.789695.n4.nabble.com/Fw-Save-multiple-plots-as-pdf-or-jpeg-tp4688801p4689256.html

>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.





______________________________________________________________________________________________

The following message has been automatically added to comply with the RSA
Group IT Security requirements:

This email arrived via the internet, over a secure Opportunistic TLS
encryption connection.
This means the email was sent using encryption but the senders domain has
not been verified for its authenticity.
As such you still need to be cautious about its origin and content.
Replies which contain sensitive information or legal/contractual
obligations are particularly vulnerable.
In these cases you should not reply unless you are authorised to do so.

If you have any questions, please speak to the Service Centre on x7979.
______________________________________________________________________________________________


***********************************************************************************************************************************************************************************************************************
MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, Horsham, West Sussex, RH12 1XL.

Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
************************************************************************************************************************************************************************************************************************

        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From aguitatierra at hotmail.com  Wed Apr 23 11:54:06 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 23 Apr 2014 11:54:06 +0200
Subject: [R] Clear selected objects from workspace
Message-ID: <BLU0-SMTP1763F2C5751530BD10586A6D9580@phx.gbl>

Dear R users,

I've got over a hundred R objects in the workspace. They all follow a 
pattern for years and months. Like this:
TT_1981_1, TT_1981_2, TT_1981_3, . . . . TT_1981_12
.
.
.
TT_2010_1, . . .

If now, I'd like to remove a selection of them, how is the best way to 
do it? Currently I need to use a big chunk of code.

I've tried various things but they don't work.
For instance:
rm(paste("RR_", 1981:2010, "_1", sep=""))
rm(list(paste("RR_", 1981:2010, "_1", sep="")))

I'd be great if you have any ideas that you think may help.

Thanks a lot!

Beatriz



From nicomet80 at gmail.com  Wed Apr 23 11:58:21 2014
From: nicomet80 at gmail.com (Nico Met)
Date: Wed, 23 Apr 2014 10:58:21 +0100
Subject: [R] Formatting with strings
Message-ID: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/af850b3c/attachment-0001.pl>

From jim at bitwrit.com.au  Wed Apr 23 12:01:42 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 23 Apr 2014 20:01:42 +1000
Subject: [R] Clear selected objects from workspace
In-Reply-To: <BLU0-SMTP1763F2C5751530BD10586A6D9580@phx.gbl>
References: <BLU0-SMTP1763F2C5751530BD10586A6D9580@phx.gbl>
Message-ID: <53578F86.9020309@bitwrit.com.au>

On 04/23/2014 07:54 PM, Bea GD wrote:
> Dear R users,
>
> I've got over a hundred R objects in the workspace. They all follow a
> pattern for years and months. Like this:
> TT_1981_1, TT_1981_2, TT_1981_3, . . . . TT_1981_12
> .
> .
> .
> TT_2010_1, . . .
>
> If now, I'd like to remove a selection of them, how is the best way to
> do it? Currently I need to use a big chunk of code.
>
> I've tried various things but they don't work.
> For instance:
> rm(paste("RR_", 1981:2010, "_1", sep=""))
> rm(list(paste("RR_", 1981:2010, "_1", sep="")))
>
Hi Beatriz,
Try this:

rm(list=paste("TT",1981:2010,"1",sep="_"))

Jim



From motyocska at yahoo.com  Wed Apr 23 12:05:28 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 23 Apr 2014 03:05:28 -0700 (PDT)
Subject: [R] finding value for a parameter in an equation
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5DA5D03@DKRDSEXC016.vestas.net>
Message-ID: <1398247528.35241.YahooMailAndroidMobile@web161606.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/bf8a5ad9/attachment-0001.pl>

From aguitatierra at hotmail.com  Wed Apr 23 12:20:04 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 23 Apr 2014 12:20:04 +0200
Subject: [R] Clear selected objects from workspace
In-Reply-To: <53578F86.9020309@bitwrit.com.au>
References: <BLU0-SMTP1763F2C5751530BD10586A6D9580@phx.gbl>
	<53578F86.9020309@bitwrit.com.au>
Message-ID: <BLU0-SMTP16683DFD31A1E8748B1B1D9D9580@phx.gbl>

Thank you a lot Jim. Much cleaner now!


On 23.04.2014 12:01, Jim Lemon wrote:
> On 04/23/2014 07:54 PM, Bea GD wrote:
>> Dear R users,
>>
>> I've got over a hundred R objects in the workspace. They all follow a
>> pattern for years and months. Like this:
>> TT_1981_1, TT_1981_2, TT_1981_3, . . . . TT_1981_12
>> .
>> .
>> .
>> TT_2010_1, . . .
>>
>> If now, I'd like to remove a selection of them, how is the best way to
>> do it? Currently I need to use a big chunk of code.
>>
>> I've tried various things but they don't work.
>> For instance:
>> rm(paste("RR_", 1981:2010, "_1", sep=""))
>> rm(list(paste("RR_", 1981:2010, "_1", sep="")))
>>
> Hi Beatriz,
> Try this:
>
> rm(list=paste("TT",1981:2010,"1",sep="_"))
>
> Jim
>
>



From murdoch.duncan at gmail.com  Wed Apr 23 12:55:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Apr 2014 06:55:54 -0400
Subject: [R] detecting the sourcing of site profile on Startup versus
 post-Startup
In-Reply-To: <5357108D.3040704@gmail.com>
References: <5357108D.3040704@gmail.com>
Message-ID: <53579C3A.1020106@gmail.com>

On 22/04/2014, 8:59 PM, Benjamin Tyner wrote:
> Greetings,
>
> Is there any way to programmatically detect whether a piece of code is
> being run within the initial (Startup) sourcing of the site profile?
>
> For example, say I have a site profile, "/path/to/Rprofile.site". Is
> there any function "my_func" which would return different values for
> these two instances:
>
>     Rscript --no-site-profile --no-init-profile -e
> "sys.source('/path/to/Rprofile.site', envir = .BaseNamespaceEnv); my_func()"
>
> versus:
>
>     export R_PROFILE=/path/to/Rprofile.site
>     Rscript --no-init-profile -e "my_func()"
>

The commandArgs() function could see the different command lines and 
your function could deduce the difference from that.

As far as I know, R keeps no other records of the startup process, but 
if you can modify other files, you could leave a record when .First was 
run, and see that it was run before Rprofile.site in the first case. 
See ?Startup.

Duncan Murdoch



From frtog at vestas.com  Wed Apr 23 13:14:48 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 23 Apr 2014 13:14:48 +0200
Subject: [R] finding value for a parameter in an equation
Message-ID: <tblif0lovdflc5onn51julpg.1398251395272@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/82b9d891/attachment-0001.pl>

From motyocska at yahoo.com  Wed Apr 23 13:33:40 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 23 Apr 2014 04:33:40 -0700 (PDT)
Subject: [R] finding value for a parameter in an equation,
	much appreciate the help. I will double check sources.
In-Reply-To: <tblif0lovdflc5onn51julpg.1398251395272@email.android.com>
Message-ID: <1398252820.79301.YahooMailAndroidMobile@web161602.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/b279ea2d/attachment-0001.pl>

From jholtman at gmail.com  Wed Apr 23 14:45:10 2014
From: jholtman at gmail.com (jim holtman)
Date: Wed, 23 Apr 2014 08:45:10 -0400
Subject: [R] Formatting with strings
In-Reply-To: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>
References: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>
Message-ID: <CAAxdm-62Rjvr6x8Z7DLyHoou4mnkvq1arEdkGfgJ5uD4iN4oNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/62d8d103/attachment-0001.pl>

From nicomet80 at gmail.com  Wed Apr 23 15:11:02 2014
From: nicomet80 at gmail.com (Nico Met)
Date: Wed, 23 Apr 2014 14:11:02 +0100
Subject: [R] Formatting with strings
In-Reply-To: <CAAxdm-62Rjvr6x8Z7DLyHoou4mnkvq1arEdkGfgJ5uD4iN4oNw@mail.gmail.com>
References: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>
	<CAAxdm-62Rjvr6x8Z7DLyHoou4mnkvq1arEdkGfgJ5uD4iN4oNw@mail.gmail.com>
Message-ID: <CAMMD=S6OKzd3TfZA1KBSggU2D8S2ByK5DCu+EPoap5u+Bt9zDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/03d86b88/attachment-0001.pl>

From erinm.hodgess at gmail.com  Wed Apr 23 15:11:01 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 23 Apr 2014 08:11:01 -0500
Subject: [R] accessing the date stamp from an xts object
Message-ID: <CACxE24mqTwjSOmXK9XxuYXsosVskdYX1wXRxF7zbGVDSNtCEuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/97b0b364/attachment-0001.pl>

From erinm.hodgess at gmail.com  Wed Apr 23 15:17:39 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 23 Apr 2014 08:17:39 -0500
Subject: [R] accessing the date stamp from an xts object
In-Reply-To: <CACxE24mqTwjSOmXK9XxuYXsosVskdYX1wXRxF7zbGVDSNtCEuA@mail.gmail.com>
References: <CACxE24mqTwjSOmXK9XxuYXsosVskdYX1wXRxF7zbGVDSNtCEuA@mail.gmail.com>
Message-ID: <CACxE24k2RLG_YrpzV3OW2HqW5iDVDpeciECBD1VsFgfqZW1hzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/6f35415d/attachment-0001.pl>

From wbonat at gmail.com  Wed Apr 23 12:12:17 2014
From: wbonat at gmail.com (Wagner Bonat)
Date: Wed, 23 Apr 2014 12:12:17 +0200
Subject: [R] Derivative of expm function
Message-ID: <CANt=4Mi15TUDoag_-evKsARt20Onomu_P3oR8acRi9gi05ksSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/930f319c/attachment-0001.pl>

From cmohamma at gmail.com  Wed Apr 23 10:04:34 2014
From: cmohamma at gmail.com (Cyrus Mohammadian)
Date: Wed, 23 Apr 2014 01:04:34 -0700
Subject: [R] Errors with stConstruct() and STFDF()
Message-ID: <3247AF97-63A7-4EAE-9E2F-5DDD0B0DFFB5@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/0e2e182a/attachment-0001.pl>

From 2130756 at my.ipleiria.pt  Wed Apr 23 15:27:14 2014
From: 2130756 at my.ipleiria.pt (Mickael Vieira Da Silva)
Date: Wed, 23 Apr 2014 13:27:14 +0000
Subject: [R] cannot load rcmdr
Message-ID: <0206caf2551846c095769ecec345b81a@DB4PR02MB176.eurprd02.prod.outlook.com>

After install the package RCMDR, I try to load it and it always apears the same error message:



Error : .onAttach failed in attachNamespace() for 'Rcmdr', details:
  call: Commander()
  error: could not find function "assignInMyNamespace"
Error: package/namespace load failed for 'Rcmdr'



I have the R version 2.14.2
the same error apears with a newest version

How can I solve this problem?

best regards

From m.roth at 5-cent.us  Wed Apr 23 15:58:00 2014
From: m.roth at 5-cent.us (m.roth at 5-cent.us)
Date: Wed, 23 Apr 2014 09:58:00 -0400
Subject: [R] meta-question about R
Message-ID: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>

This really isn't about R, but configuring R. We're running R 3.0.2-1, the
current default package, on CentOS 6.5 On a long-running job, R is
creating files in /dev/shm: each set of three files are named (8 hex
digits)-(4 hex digits)-(4 hex digits)-(4 hex digits)-(12 hex digits), and
then sem.(same as the name)_counter_mutex, and (same as the name)_counter.

For example,
156d23b0-9e67-46e2-afab-14a648252890
156d23b0-9e67-46e2-afab-14a648252890_counter
sem.156d23b0-9e67-46e2-afab-14a648252890_counter_mutex

Is there some way to configure R to add a prefix, say, to each of these
files? We're running rkhunter (rootkit hunter) for security, and it
complains about suspicious files, and I'd like some way to be able to tell
it to, say, ignore R_temp.whatever....

If this has been answered before, please give me a link.

Thanks in advance.

        mark, sysadmin



From wdunlap at tibco.com  Wed Apr 23 17:39:50 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 23 Apr 2014 15:39:50 +0000
Subject: [R] R Example scripts
In-Reply-To: <53525A04.1030202@gmail.com>
References: <CAOBARVi1+L9Sb+qUwo16f3OmXTkv2gmuBzz3o4n8zFvc-U8WZQ@mail.gmail.com>
	<53525A04.1030202@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FACA923@PA-MBX01.na.tibco.com>

> library(bayesm)
> Rd <- utils:::.getHelpFile(?rwishart)
> tools::Rd2ex(Rd)

Or you could use example() to get a character vector of the example
code in a help file.
   library(bayesm)
   example(rwishart, give.lines=TRUE)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Duncan Murdoch
> Sent: Saturday, April 19, 2014 4:12 AM
> To: gleynes+r at gmail.com; r-help
> Subject: Re: [R] R Example scripts
> 
> On 18/04/2014, 6:07 PM, Gene Leynes wrote:
> > A few years ago R changed the way help was handled so that the HTML
> > files are no longer available in the library directory.  Around that
> > time the R example files that used to be in some of the libraries also
> > vanished.
> >
> > I'm wondering where the "r-ex" folder went. Is it totally unsupported
> > and gone? Is it hidden in the mysterious rdx or rdb files?
> 
> The source for the examples will be in the \examples{} section of the
> .Rd source file -- that didn't change.  What changed was how the source
> is processed.  The files are now parsed into a binary format that is
> stored in the database files.
> 
> You can extract the examples from the source file using the tools::Rd2ex
> function.  You can extract them from the binary database using this
> function on an Rd object, which is obtainable using the internal
> function .getHelpFile.
> 
> So for example, to see the code for the example for rwishart, you could do
> 
> tools::Rd2ex(".../bayesm/man/rwishart.Rd")
> 
> if you have the source file installed there, or
> 
> library(bayesm)
> Rd <- utils:::.getHelpFile(?rwishart)
> tools::Rd2ex(Rd)
> 
> if you have the package installed.
> 
> Duncan Murdoch
> >
> > In particular I'm looking for the latest example scripts in the baysem
> > package. I don't see them in the source code or the installed library.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From tom at maladmin.com  Wed Apr 23 17:47:49 2014
From: tom at maladmin.com (Tom Wright)
Date: Wed, 23 Apr 2014 11:47:49 -0400
Subject: [R] packages implementing graph algorithms
Message-ID: <1398268069.4539.3.camel@tom-laptop.sickkids.ca>

Are there any packages implementing graph search algorithms? 
I'm looking for the equivalent of matlab findshortestpath in the
bioinfomatics toolbox.

Thanks,
Tom



From gunter.berton at gene.com  Wed Apr 23 17:54:14 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 23 Apr 2014 08:54:14 -0700
Subject: [R] packages implementing graph algorithms
In-Reply-To: <1398268069.4539.3.camel@tom-laptop.sickkids.ca>
References: <1398268069.4539.3.camel@tom-laptop.sickkids.ca>
Message-ID: <CACk-te12qs=BELjV0_3gKvcGbV-yPx-cUeoJvSOq_hN+1i6dYg@mail.gmail.com>

I would suggest you post this to the Bioconductor list. You might also
have a look at the CRAN gR task view if you haven't already done so --
though no guarantees of finding what you want here, of course.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Wed, Apr 23, 2014 at 8:47 AM, Tom Wright <tom at maladmin.com> wrote:
> Are there any packages implementing graph search algorithms?
> I'm looking for the equivalent of matlab findshortestpath in the
> bioinfomatics toolbox.
>
> Thanks,
> Tom
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From kripa777 at hotmail.com  Wed Apr 23 17:54:23 2014
From: kripa777 at hotmail.com (Kripa R)
Date: Wed, 23 Apr 2014 15:54:23 +0000
Subject: [R] illumina array - remove probes in discontinued genes
Message-ID: <BAY179-W775384D7EC00A573E1D53B99580@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/5fa4f047/attachment-0001.pl>

From 538280 at gmail.com  Wed Apr 23 18:36:58 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 23 Apr 2014 10:36:58 -0600
Subject: [R] fitting a family of curves
In-Reply-To: <CAMBc2W40nDR15hvYDauOMGHdCq=Bi+KuHv4X+11v-Jp2UeypDw@mail.gmail.com>
References: <CAMBc2W40nDR15hvYDauOMGHdCq=Bi+KuHv4X+11v-Jp2UeypDw@mail.gmail.com>
Message-ID: <CAFEqCdyaTjFF+xsphVmRZx29O4MGMkR=XWCE0JxSbjh0K3usqA@mail.gmail.com>

Can you provide some sample data and the family of curves that you
would like to fit?

Reproducible examples greatly increase your chances of receiving a
useful response.

On Wed, Apr 23, 2014 at 12:33 AM, andreas betz <abetz58 at gmail.com> wrote:
> Hello,
>
> is it possible to fit a group of curves simultaneously to an equation with
> some parameters shared among the curves others fit for each curve
> individually. Several commercial software programs like Originlab have this
> option often referred to as global fit. I would appreciate any advice or
> referral to packages.
>
>
> Thank you
>
> Andreas
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From pjmiller_57 at yahoo.com  Wed Apr 23 19:35:31 2014
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Wed, 23 Apr 2014 10:35:31 -0700 (PDT)
Subject: [R] Analysis of censored cost data
Message-ID: <1398274531.77891.YahooMailNeo@web160905.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/935609c7/attachment-0001.pl>

From rshepard at appl-ecosys.com  Wed Apr 23 20:23:00 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 23 Apr 2014 11:23:00 -0700 (PDT)
Subject: [R] Analysis of censored cost data
In-Reply-To: <1398274531.77891.YahooMailNeo@web160905.mail.bf1.yahoo.com>
References: <1398274531.77891.YahooMailNeo@web160905.mail.bf1.yahoo.com>
Message-ID: <alpine.LNX.2.11.1404231120510.12012@localhost>

On Wed, 23 Apr 2014, Paul Miller wrote:

> Am intested in using R to analyze censored cost data.

Paul,

   What are censored cost data? Too high to be affordable; too low to cover
materials?

> My best guess so far is the NADA package. Not sure if this is the best
> thing to do what I need though.

   NADA works well with left-censored chemical data provided by analytical
laboratories. Survival packages work great with right-censored medical/part
failure data.

Rich



From farrukhmphil at yahoo.com  Wed Apr 23 18:44:19 2014
From: farrukhmphil at yahoo.com (farrukh jamal)
Date: Wed, 23 Apr 2014 09:44:19 -0700 (PDT)
Subject: [R] Request for R " Initial value of MLE"
Message-ID: <1398271459.18486.YahooMailNeo@web160504.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/a0363ff6/attachment-0001.pl>

From smartpink111 at yahoo.com  Wed Apr 23 20:48:02 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Apr 2014 11:48:02 -0700 (PDT)
Subject: [R] Formatting with strings
In-Reply-To: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>
References: <CAMMD=S7OfmWPdy00vs1T-wRPNtgr8X5XV6+viHFOqzAYC3XKzg@mail.gmail.com>
Message-ID: <1398278882.10594.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
?
You could try:
Lines1 <- readLines(textConnection("---CLUSTER 1 ---
3
4
5
6
---CLUSTER 2 ---
9
10
8
11"))
indx <- grepl("CLUSTER", Lines1)
res <- data.frame(Object=Lines1[!indx], Cluster=
as.numeric(as.character(factor(cumsum(indx)[-which(indx)], labels=gsub("\\D+","",Lines1[indx])))))

res

A.K.

----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, April 23, 2014 3:28 PM
Subject: [R] Formatting with strings

Dear all, I have object where I stored clusters in the following manner:

---CLUSTER 1 ---
3
4
5
6
---CLUSTER 2 ---
9
10
8
11

Now want to format the data in the following way:

Object? Cluster
3? ? ? ? ? ? 1
4? ? ? ? ? ? 1
5? ? ? ? ? ? 1
6? ? ? ? ? ? 1
9? ? ? ? ? ? 2
10? ? ? ? ? 2
8? ? ? ? ? ? 2
11? ? ? ? ? 2


How can I do this in R?

Thanks

Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From sjkiss at gmail.com  Wed Apr 23 22:09:34 2014
From: sjkiss at gmail.com (Simon Kiss)
Date: Wed, 23 Apr 2014 16:09:34 -0400
Subject: [R] escape characters for apostrophes in a .csv file
Message-ID: <47773E8A-960E-489B-99BF-4DFB52557033@gmail.com>

Hello: 
I have a .csv file that includes some character strings (open ended survey responses) that includes some apostrophe. Using read.csv() the file reads in just fine, except upon being read in the apostrophes are displayed with the double-slash, i.e. 'I've' becomes 'I\\'ve'.  I'd like to print these responess out for a report.  Is there a way that I can have the apostrophes read in as original or print them out without the escape characters.
Thank you. 
*********************************
Simon J. Kiss, PhD



From murdoch.duncan at gmail.com  Wed Apr 23 22:36:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Apr 2014 16:36:08 -0400
Subject: [R] escape characters for apostrophes in a .csv file
In-Reply-To: <47773E8A-960E-489B-99BF-4DFB52557033@gmail.com>
References: <47773E8A-960E-489B-99BF-4DFB52557033@gmail.com>
Message-ID: <53582438.2090805@gmail.com>

On 23/04/2014 4:09 PM, Simon Kiss wrote:
> Hello:
> I have a .csv file that includes some character strings (open ended survey responses) that includes some apostrophe. Using read.csv() the file reads in just fine, except upon being read in the apostrophes are displayed with the double-slash, i.e. 'I've' becomes 'I\\'ve'.  I'd like to print these responess out for a report.  Is there a way that I can have the apostrophes read in as original or print them out without the escape characters.

That sounds very strange.  I would guess that your csv file has 
backslashes in it, not just apostrophes.  You probably need to use 
read.table with appropriate options to interpret the backslashes as 
escape characters.  (Normal CSV files don't escape apostrophes, they are 
enclosed in double quotes, e.g.

"That's strange"

would be what is stored.  R will read this without adding any escapes.

Duncan Murdoch



From monaly.mistry at gmail.com  Wed Apr 23 23:08:26 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Wed, 23 Apr 2014 22:08:26 +0100
Subject: [R] running something similar to bootstrap
Message-ID: <CANpv+65DhH2s4CL_jwZR_+3aTXkQBHyKLY=N4Ge69KRtGPXWOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/bfdbee8c/attachment-0001.pl>

From jim at bitwrit.com.au  Wed Apr 23 23:18:23 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 24 Apr 2014 07:18:23 +1000
Subject: [R] meta-question about R
In-Reply-To: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
Message-ID: <53582E1F.40606@bitwrit.com.au>

On 04/23/2014 11:58 PM, m.roth at 5-cent.us wrote:
> This really isn't about R, but configuring R. We're running R 3.0.2-1, the
> current default package, on CentOS 6.5 On a long-running job, R is
> creating files in /dev/shm: each set of three files are named (8 hex
> digits)-(4 hex digits)-(4 hex digits)-(4 hex digits)-(12 hex digits), and
> then sem.(same as the name)_counter_mutex, and (same as the name)_counter.
>
> For example,
> 156d23b0-9e67-46e2-afab-14a648252890
> 156d23b0-9e67-46e2-afab-14a648252890_counter
> sem.156d23b0-9e67-46e2-afab-14a648252890_counter_mutex
>
> Is there some way to configure R to add a prefix, say, to each of these
> files? We're running rkhunter (rootkit hunter) for security, and it
> complains about suspicious files, and I'd like some way to be able to tell
> it to, say, ignore R_temp.whatever....
>
Hi mark,
I assume that the problem is to identify the files in /dev/shm, not to 
simply change your R code to tack the prefix onto the files as it 
produces them. As your hexadecimal digits are probably randomly 
generated, the solution may be to identify all the files that have 
"_counter_mutex" in the name, then chip off the appropriate bits to get 
the troublesome first name.

filenames<-list.files(pattern="_counter_mutex")
# function to return the two other filenames
strip_fn<-function(x) {
  f2<-substr(x,5,nchar(x)-6)
  f1<-substr(f2,1,nchar(f2)-8)
  return(c(f1,f2))
}
# get all the filenames
filenames<-c(filenames,unlist(sapply(filenames,strip_fn)))
# stick on the prefix
newfilenames<-paste("R_temp",filenames,sep=".")
# create the commands
fnmove<-paste("mv",filenames,newfilenames)
# move the filenames
for(fn in 1:length(fnmove)) system(fnmove[fn])

Warning - I haven't tested the last bit of this, but it should work. 
There is probably some really neat string of heiroglyphs in a regular 
expression that will do this as well.

Jim



From jfox at mcmaster.ca  Wed Apr 23 23:21:42 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Apr 2014 17:21:42 -0400
Subject: [R] cannot load rcmdr
In-Reply-To: <0206caf2551846c095769ecec345b81a@DB4PR02MB176.eurprd02.prod.outlook.com>
References: <0206caf2551846c095769ecec345b81a@DB4PR02MB176.eurprd02.prod.outlook.com>
Message-ID: <web-507083683@cgpsrv2.cis.mcmaster.ca>

Dear Mickael,

assignInMyNamespace() is a standard R function, in the tools package, and so with up-to-date versions of R and the Rcmdr package, you should not be experiencing this problem. Can you provide some more information, such as the operating system you're using, the R version (current is 3.1.0), and the version of the Rcmdr package (current is 2.0-4)? If you're not using the latest versions, I'd start by updating.

I hope this helps,
 John

On Wed, 23 Apr 2014 13:27:14 +0000
 Mickael Vieira Da Silva <2130756 at my.ipleiria.pt> wrote:
> After install the package RCMDR, I try to load it and it always apears the same error message:
> 
> 
> 
> Error : .onAttach failed in attachNamespace() for 'Rcmdr', details:
>   call: Commander()
>   error: could not find function "assignInMyNamespace"
> Error: package/namespace load failed for 'Rcmdr'
> 
> 
> 
> I have the R version 2.14.2
> the same error apears with a newest version
> 
> How can I solve this problem?
> 
> best regards

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From reynolda at uw.edu  Thu Apr 24 01:51:54 2014
From: reynolda at uw.edu (Alex Reynolds)
Date: Wed, 23 Apr 2014 16:51:54 -0700
Subject: [R] rgl and axes3d() labels
Message-ID: <CABgwozgvKa6QH+JiHNZ-hNMiADUtwH2H1y6Ow_zBw+nwkjTOkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/d8610808/attachment-0001.pl>

From reynolda at uw.edu  Thu Apr 24 03:02:14 2014
From: reynolda at uw.edu (Alex Reynolds)
Date: Wed, 23 Apr 2014 18:02:14 -0700
Subject: [R] rgl and axes3d() labels
In-Reply-To: <53585C32.5040501@gmail.com>
References: <CABgwozgvKa6QH+JiHNZ-hNMiADUtwH2H1y6Ow_zBw+nwkjTOkw@mail.gmail.com>
	<53585C32.5040501@gmail.com>
Message-ID: <CABgwoziwUGNeP4sA3Bh4t4+VorJO7cm=Nt-7ioyApcsx=G6aTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/c183a36b/attachment-0001.pl>

From btyner at gmail.com  Thu Apr 24 03:11:09 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 23 Apr 2014 21:11:09 -0400
Subject: [R] detecting the sourcing of site profile on Startup versus
 post-Startup
In-Reply-To: <53579C3A.1020106@gmail.com>
References: <5357108D.3040704@gmail.com> <53579C3A.1020106@gmail.com>
Message-ID: <535864AD.5000706@gmail.com>


   Thanks  Duncan!  Yes, I considered taking advantage of .First, but was
   concerned that the .First defined by the site profile could be masked by a
   possible .First defined by the user profile (I neglected to mention that
   "--no-init-profile"  [sic]  in  the  example  I gave was a simplifying
   assumption, sorry about that).
   On 04/23/2014 06:55 AM, Duncan Murdoch wrote:

     On 22/04/2014, 8:59 PM, Benjamin Tyner wrote:

     Greetings,
     Is there any way to programmatically detect whether a piece of code is
     being run within the initial (Startup) sourcing of the site profile?
     For example, say I have a site profile, "/path/to/Rprofile.site". Is
     there any function "my_func" which would return different values for
     these two instances:
         Rscript --no-site-profile --no-init-profile -e
     "sys.source('/path/to/Rprofile.site',  envir  = .BaseNamespaceEnv);
     my_func()"
     versus:
         export R_PROFILE=/path/to/Rprofile.site
         Rscript --no-init-profile -e "my_func()"

     The commandArgs() function could see the different command lines and your
     function could deduce the difference from that.
     As far as I know, R keeps no other records of the startup process, but if
     you can modify other files, you could leave a record when .First was run,
     and see that it was run before Rprofile.site in the first case. See
     ?Startup.
     Duncan Murdoch

   --
   

From jdnewmil at dcn.davis.CA.us  Thu Apr 24 03:31:33 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 23 Apr 2014 18:31:33 -0700
Subject: [R] detecting the sourcing of site profile on Startup versus
	post-Startup
In-Reply-To: <535864AD.5000706@gmail.com>
References: <5357108D.3040704@gmail.com> <53579C3A.1020106@gmail.com>
	<535864AD.5000706@gmail.com>
Message-ID: <966edfaf-8898-431a-a7ac-ab5e63409e3d@email.android.com>

Regardless of whether this is possible, it seems like a bad idea (side effects in a functional programming environment). If you want to do something special in startup then write a different function that does that stuff and then call the desired functions explicitly when you want them to be called.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 23, 2014 6:11:09 PM PDT, Benjamin Tyner <btyner at gmail.com> wrote:
>
> Thanks  Duncan!  Yes, I considered taking advantage of .First, but was
>concerned that the .First defined by the site profile could be masked
>by a
>possible .First defined by the user profile (I neglected to mention
>that
> "--no-init-profile"  [sic]  in  the  example  I gave was a simplifying
>   assumption, sorry about that).
>   On 04/23/2014 06:55 AM, Duncan Murdoch wrote:
>
>     On 22/04/2014, 8:59 PM, Benjamin Tyner wrote:
>
>     Greetings,
> Is there any way to programmatically detect whether a piece of code is
>   being run within the initial (Startup) sourcing of the site profile?
>   For example, say I have a site profile, "/path/to/Rprofile.site". Is
>   there any function "my_func" which would return different values for
>     these two instances:
>         Rscript --no-site-profile --no-init-profile -e
>    "sys.source('/path/to/Rprofile.site',  envir  = .BaseNamespaceEnv);
>     my_func()"
>     versus:
>         export R_PROFILE=/path/to/Rprofile.site
>         Rscript --no-init-profile -e "my_func()"
>
>The commandArgs() function could see the different command lines and
>your
>     function could deduce the difference from that.
>As far as I know, R keeps no other records of the startup process, but
>if
>you can modify other files, you could leave a record when .First was
>run,
>    and see that it was run before Rprofile.site in the first case. See
>     ?Startup.
>     Duncan Murdoch
>
>   --
>   
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Apr 24 03:45:59 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Apr 2014 18:45:59 -0700 (PDT)
Subject: [R] Loops (run the same function per different columns)
In-Reply-To: <1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1398303959.35422.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
I guess you got an output like this using my script:
##Please use ?dput() to show the example data.

FA <- structure(list(Sample = c("L1 Control", "L1 Control", "L1 Control", 
"BBM Control", "BBM Control", "BBM Control", "L1 Ash", "L1 Ash", 
"L1 Ash", "BBM Ash", "BBM Ash", "BBM Ash"), C14.0 = c(0.456509192, 
0.513989684, 0.555894496, 0.418392781, 0.405826292, 0.398633968, 
0.504528078, 0.548667997, 0.499237645, 0.380582244, 0.395617943, 
0.389027115), C15.0 = c(0.469562687, 0.527958026, 0.502389699, 
0.385119329, 0.368564514, 0.391851493, 0.479125577, 0.517533922, 
0.490619858, 0.380051535, 0.384498216, 0.370815474), C15.1 = c(0.774909216, 
0.732083085, 0.706407924, 1.318261983, 1.114889958, 1.238411437, 
0.793236101, 0.632962545, 0.74858627, 0.996870831, 0.963780759, 
0.923329859)), .Names = c("Sample", "C14.0", "C15.0", "C15.1"
), class = "data.frame", row.names = c(NA, -12L))

library(gvlma)
y <- names(FA)[-1]
?y
#[1] "C14.0" "C15.0" "C15.1"

lst1 <- setNames(vector("list", length(y)),y)

?for(i in y){
?lst1[[i]] <- gvlma(lm(get(i)~Sample,data=FA))
?lst1}?

lst1[[1]]
#
#Call:
#lm(formula = get(y[i]) ~ Sample, data = FA)
#---------------------------------------

But, you wanted to show each of the list output as in gvlmaFA.

gvlmaFA <- gvlma(lm(C14.0~Sample,data=FA))


In my previous script, I didn't name the list.? Here, by setting the names as in "y", it could be easier.? I guess you wanted to reflect that in the model formula as well.

lst2 <- setNames(vector("list", length(y)), y)
for(names in y){
lst2[[names]] <- eval(bquote(gvlma(lm(.(names1)~ Sample, data=FA)), list(names1=as.name(names))))
lst2}

identical(gvlmaFA, lst2[[1]])
#[1] TRUE

A.K.






Hi Arun,
Your script works but it does not do what I was after. To be a bit more specific,? this the table FA in which Im working on ( but the original one has 34 fatty acids instead of 3: C14.0, C15.0, and C15.1).

Sample
??? 

C14:0
??? 

C15:0
??? 

C15:1

L1 Control
??? 

0.456509192
??? 

0.469562687
??? 

0.774909216

L1 Control
??? 

0.513989684
??? 

0.527958026
??? 

0.732083085

L1 Control
??? 

0.555894496
??? 

0.502389699
??? 

0.706407924

BBM Control
??? 

0.418392781
??? 

0.385119329
??? 

1.318261983

BBM Control
??? 

0.405826292
??? 

0.368564514
??? 

1.114889958

BBM Control
??? 

0.398633968
??? 

0.391851493
??? 

1.238411437

L1 Ash
??? 

0.504528078
??? 

0.479125577
??? 

0.793236101

L1 Ash
??? 

0.548667997
??? 

0.517533922
??? 

0.632962545

L1 Ash
??? 

0.499237645
??? 

0.490619858
??? 

0.74858627

BBM Ash
??? 

0.380582244
??? 

0.380051535
??? 

0.996870831

BBM Ash
??? 

0.395617943
??? 

0.384498216
??? 

0.963780759

BBM Ash
??? 

0.389027115
??? 

0.370815474
??? 

0.923329859

I just want to run the following script but with C15.0, C15.1 and the other 32 so I can quickly scroll up and down to see who does not meet the assumptions.

FA.ml=lm(C14.0~Sample,data=FA)
gvlmaFA<-gvlma(FA.ml)
gvlmaFA

This is the result when I run the script

Call:
lm(formula = C14.0 ~ Sample, data = FA)

Coefficients:
????? (Intercept)? SampleBBM Control?????? SampleL1 Ash?? SampleL1 Control? 
????????? 0.38841??????????? 0.01921??????????? 0.12907??????????? 0.12039? 


ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
Level of Significance =? 0.05 

Call:
?gvlma(x = FA.ml) 

?????????????????????? Value p-value?????????????????? Decision
Global Stat??????? 4.757e+00 0.31312??? Assumptions acceptable.
Skewness?????????? 1.944e-02 0.88911??? Assumptions acceptable.
Kurtosis?????????? 1.462e-01 0.70219??? Assumptions acceptable.
Link Function????? 3.682e-16 1.00000??? Assumptions acceptable.
Heteroscedasticity 4.592e+00 0.03213 Assumptions NOT satisfied!

I really appreciate if you can help me with this issue. This would be really useful for me since I have large tables of data.
Cheers


On Monday, April 21, 2014 9:19 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

Using the example data from library(gvlma)

library(gvlma)
data(CarMileageData)
CarMileageNew <- CarMileageData[,c(5,6,3)]
?lst1 <- list()
?y <- c("NumGallons", "NumDaysBetw")
?for(i in seq_along(y)){
?lst1[[i]] <- gvlma(lm(get(y[i])~MilesLastFill,data=CarMileageNew))
?lst1}
pdf("gvlmaplot.pdf")
?lapply(lst1,plot)
dev.off()


You could also use ?lapply().


A.K.



Hi
I have a spread sheet with a column Samples (column1) and then 34 more columns with different concentrations of fatty acids per sample. Im trying to run the same function 34 times. In this case (the first of 34), I have a fatty acid called C14.0 (column 2). I'm a newbie with R so I spent the last 4 days looking for a way of doing it (without running the same function 34 times with a different fatty acid each time). I saw that people do similar things with loops but I cannot get them to work.
I have tried the script below but it does not work.

y<-c("C14.0","C15.0","C16.0")
for (i in y) {
FA.ml=lm(i~Sample,data=FA)
gvlmaFA<-gvlma(FA.ml)
gvlmaFA
}


I really appreciate if someone can give me a hand with that. I know would have been finished if I had typed the 34 fatty acids but I want to learn how to do it with loops.
Cheers



From smartpink111 at yahoo.com  Thu Apr 24 04:47:08 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Apr 2014 19:47:08 -0700 (PDT)
Subject: [R] "aggregate" help
Message-ID: <1398307628.15579.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
Please use ?dput() to show the datasets as one of the rows (Id "four") in first dataset didn't show 11 elements.

df1 <- structure(list(Id = c("one", "one", "two", "two", "three", "three", 
"three", "four", "five", "five"), col1 = c("a1", NA, "b1", "b1", 
NA, NA, "c1", "d1", "e1", NA), col2 = c("a2", NA, "b2", "b2", 
"c2", NA, "c2", "D2", "e2", "e2"), col3 = c("a3", "a3", "b3", 
"b3", "c3", "c3", "c3", "d3", "E3", "e3"), col4 = c("a4", "a4", 
"B4", "b4", "c4", "c4", "c4", "d4", "e4", "E4"), col5 = c("a5", 
"a5", "b5", "b5", "C5", "c5", "c5", "d5", "e5", "e5"), col6 = c("A6", 
"a6", "b6", "B6", "c6", "c6", "C6", "d6", "e6", "e6"), col7 = c("a7", 
"A7", "b7", "b7", "c7", "c7", "c7", NA, "e7", "e7"), col8 = c("a8", 
"a8", "b8", "b8", "c8", "c8", "c8", NA, "e8", "e8"), col9 = c("a9", 
"a9", "b9", "b9", "c9", "C9", NA, "", "e9", "e9"), col10 = c(NA, 
"a10", "b10", "b10", NA, "c10", NA, "", NA, "e10")), .Names = c("Id", 
"col1", "col2", "col3", "col4", "col5", "col6", "col7", "col8", 
"col9", "col10"), class = "data.frame", row.names = c(NA, -10L
))


df2 <- structure(list(Id = c("one", "one", "two", "two", "three", "three", 
"three", "four", "five", "five"), colnew = c("A6", "A7", "B4", 
"B6", "C5", "C9", "C6", "D2", "E3", "E4")), .Names = c("Id", 
"colnew"), class = "data.frame", row.names = c(NA, -10L))

#expected result

res <- structure(list(Id = c("one", "two", "three", "four", "five"), 
??? col1 = c("a1", "b1", "c1", "d1", "e1"), col2 = c("a2", "b2", 
??? "c2", "D2", "e2"), col3 = c("a3", "b3", "c3", "d3", "E3"), 
??? col4 = c("a4", "B4", "c4", "d4", "E4"), col5 = c("a5", "b5", 
??? "C5", "d5", "e5"), col6 = c("A6", "B6", "C6", "d6", "e6"), 
??? col7 = c("A7", "b7", "c7", NA, "e7"), col8 = c("a8", "b8", 
??? "c8", NA, "e8"), col9 = c("a9", "b9", "C9", "", "e9"), col10 = c("a10", 
??? "b10", "c10", "", "e10")), .Names = c("Id", "col1", "col2", 
"col3", "col4", "col5", "col6", "col7", "col8", "col9", "col10"
), class = "data.frame", row.names = c(NA, -5L))


##there would be simple ways to perform this operation.

res1 <- as.data.frame(t(sapply(split(df1, df1$Id), function(x) {
??? x1 <- x[, -1]
??? c(Id = unique(x[, 1]), apply(x1, 2, function(y) {
??????? y1 <- unique(y[!is.na(y)])
??????? y2 <- if (length(y1) == 0) NA else y1
??????? if (any(y2 %in% df2$colnew)) unique(toupper(y2)) else y2
??? }))
})), stringsAsFactors = FALSE)
res1 <- res1[order(gsub("\\d+", "", res1$col1)), ]
row.names(res1) <- 1:nrow(res1)
identical(res, res1)
# [1] TRUE


A.K.




I am stuck in a situation and seek urgent help!.

I have a DF something like this;

Id??????? col1? col2? col3? col4? col5? col6?? col7?? col8? col9? col10
one????? a1??? a2??? a3???? a4??? a5??? A6???? a7???? a8??? a9??? NA
one????? NA??? NA??? a3???? a4??? a5??? a6???? A7???? a8??? a9??? a10
two????? b1??? b2???? b3???? B4??? b5??? b6???? b7??? b8???? b9?? b10
two????? b1??? b2???? b3???? b4??? b5??? B6???? b7??? b8???? b9?? b10
three??? NA?? c2????? c3??? c4??? C5??? c6???? c7??? c8???? c9?? NA
three??? NA??? NA??? c3??? c4??? c5??? c6???? c7??? c8???? C9?? c10
three??? c1??? c2???? c3??? c4??? c5??? C6???? c7??? c8??? NA??? NA
four????? d1??? D2???? d3???? d4??? d5??? d6?? NA?? NA? 
five????? e1??? e2??? E3???? e4???? e5???? e6??? e7?? e8???? e9?? NA
five????? NA??? e2??? e3???? E4???? e5???? e6??? e7?? e8???? e9?? e10


* each row is different and some has NA.
* the capital letters in some cells are key values which will be useful for further analysis

I have another DF which has only the key values

Id???? colnew??? 
one???? A6??? 
one???? A7
two???? B4
two???? B6
three?? C5
three?? C9
three?? C6
four???? D2? 
five???? E3
five???? E4


Now,
I need to aggregate the first DF? based on "ID" values to get "unique" entries for each "ID" so that the output should look like the below

Id??????? col1? col2? col3? col4? col5? col6?? col7?? col8? col9? col10
one????? a1??? a2??? a3???? a4??? a5??? A6???? A7???? a8??? a9??? a10
two????? b1??? b2???? b3???? B4??? b5??? B6???? b7??? b8???? b9?? b10
three??? c1?? c2????? c3??? c4??? C5??? C6???? c7??? c8???? C9?? c10
four????? d1??? D2???? d3???? d4??? d5??? d6?? NA?? NA? 
five????? e1??? e2??? E3???? E4???? e5???? e6??? e7?? e8???? e9?? e10


Thanks for the help
Regards,
karthick 




From smartpink111 at yahoo.com  Thu Apr 24 05:01:33 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Apr 2014 20:01:33 -0700 (PDT)
Subject: [R] Hi ,
	Is it possible select a different number of rows by each group with
	R????
In-Reply-To: <1398188759.90767.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
	<1398188759.90767.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1398308493.86920.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi Marta,
If you need random selection, you could use:

do.call(rbind,lapply(split(dat2,dat2$field1),function(x) x[sample(1:nrow(x),dat1$field2[!is.na(match(dat1$field1,x$field1))],replace=FALSE),]))
A.K.


On Tuesday, April 22, 2014 1:45 PM, arun <smartpink111 at yahoo.com> wrote:


Hi Marta,
It's not clear whether you wanted to select the first "n" rows specified by field2 in the first dataset or just random rows.
##using a modified example if my guess is correct

dat1 <- structure(list(field1 = 1:3, field2 = c(3L, 6L, 4L)), .Names = c("field1", 
"field2"), class = "data.frame", row.names = c(NA, -3L))



dat2 <- structure(list(field1 = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L), field3 = c(0.375, 0.416667, 0.458333, 0.5, 0.541667, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.708333, 
0.75, 0.791667, 0.833333, 0.875), field4 = c("Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp"), field5 = c("Rm1", "Rm2", "Rm3", "Rm4", "Rm5", "Rm6", "Jm1", 
"Jm2", "Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Rm6", "Jm1", "Jm2", 
"Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Jm3", "Jm4", "Jm5", "Jm6", 
"Jm7")), .Names = c("field1", "field3", "field4", "field5"), class = "data.frame", row.names = c(NA, 
-26L))


##for selecting the first 'n' rows

dat2New <- merge(dat1,dat2,by="field1")
library(plyr)
res1 <- ddply(dat2New,.(field1),function(x) head(x,unique(x$field2)))[,-2]


#or
res2 <- dat2[with(dat1,rep(match(field1, dat2$field1),field2)+sequence(field2)-1),]

A.K.


?Sorry, I think now the message is correct.

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2).
I have these 2 tables:

Table1
field1 field2
1 3
2 6
3 9
4 3
5 3
6 3
7 3
8 9
9 6
10 3
11 3
12 3
13 3
14 3
?????????????????????? 
Table2
field1 field3 field4 field5
1 0.375 Sp Rm1
1 0.416667 Sp Rm2
1 0.458333 Sp Rm3
1 0.5??????? Sp Rm4
1 0.541667 Sp Rm5
1 0.583333 Sp Rm6
1 0.625 Sp Jm1
1 0.666667 Sp Jm2
1 0.708333 Sp Jm3
1 0.75?? Sp Jm4
1 0.791667 Sp Jm5
1 0.833333 Sp Jm6
1 0.875 Sp Jm7

thx!!! 



On Monday, April 21, 2014 4:02 PM, Marta Tobe?a <marta_mtm at hotmail.com> wrote:

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2). I have these 2 tables:Table1Table2field1field2field1field3field4field51310.375SpRm12610.416667SpRm23910.458333SpRm34310.5SpRm45310.541667SpRm56310.583333SpRm67310.625SpJm18910.666667SpJm29610.708333SpJm310310.75SpJm411310.791667SpJm512310.833333SpJm613310.875SpJm714320.916667SpJm820.958333SpJm921SpJm1021.041667SpJm1121.083333SpJm1221.125SpJm1321.166667SpJm1421.208333SpJm1521.25SpJm1621.291667SpJm1721.333333SpJm18Thanks youMarta ??? ???????? ?????? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wdunlap at tibco.com  Thu Apr 24 05:22:01 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 24 Apr 2014 03:22:01 +0000
Subject: [R] meta-question about R
In-Reply-To: <53582E1F.40606@bitwrit.com.au>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
Message-ID: <E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>

Aren't those files support for named semaphores (made with sem_open())?
Packages like BH and RSQLite contain calls to sem_open.   Is your long-running
R process using such a package?

I don't think you would want to delete those files, but perhaps you can look into
whatever R package creates them and see if you can modify the code to give
them better names and then add those names to rkhunter's whitelist.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jim Lemon
> Sent: Wednesday, April 23, 2014 2:18 PM
> To: m.roth at 5-cent.us
> Cc: r-help at r-project.org
> Subject: Re: [R] meta-question about R
> 
> On 04/23/2014 11:58 PM, m.roth at 5-cent.us wrote:
> > This really isn't about R, but configuring R. We're running R 3.0.2-1, the
> > current default package, on CentOS 6.5 On a long-running job, R is
> > creating files in /dev/shm: each set of three files are named (8 hex
> > digits)-(4 hex digits)-(4 hex digits)-(4 hex digits)-(12 hex digits), and
> > then sem.(same as the name)_counter_mutex, and (same as the name)_counter.
> >
> > For example,
> > 156d23b0-9e67-46e2-afab-14a648252890
> > 156d23b0-9e67-46e2-afab-14a648252890_counter
> > sem.156d23b0-9e67-46e2-afab-14a648252890_counter_mutex
> >
> > Is there some way to configure R to add a prefix, say, to each of these
> > files? We're running rkhunter (rootkit hunter) for security, and it
> > complains about suspicious files, and I'd like some way to be able to tell
> > it to, say, ignore R_temp.whatever....
> >
> Hi mark,
> I assume that the problem is to identify the files in /dev/shm, not to
> simply change your R code to tack the prefix onto the files as it
> produces them. As your hexadecimal digits are probably randomly
> generated, the solution may be to identify all the files that have
> "_counter_mutex" in the name, then chip off the appropriate bits to get
> the troublesome first name.
> 
> filenames<-list.files(pattern="_counter_mutex")
> # function to return the two other filenames
> strip_fn<-function(x) {
>   f2<-substr(x,5,nchar(x)-6)
>   f1<-substr(f2,1,nchar(f2)-8)
>   return(c(f1,f2))
> }
> # get all the filenames
> filenames<-c(filenames,unlist(sapply(filenames,strip_fn)))
> # stick on the prefix
> newfilenames<-paste("R_temp",filenames,sep=".")
> # create the commands
> fnmove<-paste("mv",filenames,newfilenames)
> # move the filenames
> for(fn in 1:length(fnmove)) system(fnmove[fn])
> 
> Warning - I haven't tested the last bit of this, but it should work.
> There is probably some really neat string of heiroglyphs in a regular
> expression that will do this as well.
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m.roth at 5-cent.us  Wed Apr 23 23:28:36 2014
From: m.roth at 5-cent.us (m.roth at 5-cent.us)
Date: Wed, 23 Apr 2014 17:28:36 -0400
Subject: [R] meta-question about R
In-Reply-To: <53582E1F.40606@bitwrit.com.au>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
Message-ID: <6cb7eb88011fe0eb551dc21c1ffe789c.squirrel@host290.hostmonster.com>

Jim Lemon wrote:
> On 04/23/2014 11:58 PM, m.roth at 5-cent.us wrote:
>> This really isn't about R, but configuring R. We're running R 3.0.2-1,
>> the current default package, on CentOS 6.5 On a long-running job, R is
>> creating files in /dev/shm: each set of three files are named (8 hex
>> digits)-(4 hex digits)-(4 hex digits)-(4 hex digits)-(12 hex digits),
>> and then sem.(same as the name)_counter_mutex, and (same as the
>> name)_counter.
>>
>> For example,
>> 156d23b0-9e67-46e2-afab-14a648252890
>> 156d23b0-9e67-46e2-afab-14a648252890_counter
>> sem.156d23b0-9e67-46e2-afab-14a648252890_counter_mutex
>>
>> Is there some way to configure R to add a prefix, say, to each of these
>> files? We're running rkhunter (rootkit hunter) for security, and it
>> complains about suspicious files, and I'd like some way to be able to
>> tell it to, say, ignore R_temp.whatever....
>>
> I assume that the problem is to identify the files in /dev/shm, not to
> simply change your R code to tack the prefix onto the files as it
> produces them. As your hexadecimal digits are probably randomly

Um, no - it's to get R to change its naming std. for /dev/shm files.
rkhunter is a program that looks for rootkits. I cannot give it a shell or
other scripting language command to run; rather, I can only give it
filenames, or wildcarded filenames in its configuration file. Ideally, I'd
like, as I said, to have the files named something like R_<hex name),
sem.R_<hex name>_whatever.

And I am a tad leery of just telling it that /dev/shm/* is ok, because
there is malware out there that will put its executable in /dev/shm so as
to remove the traces of it after you reboot to recover....

        mark



From carlosalvarezroa at hotmail.com  Thu Apr 24 01:10:50 2014
From: carlosalvarezroa at hotmail.com (CRoa)
Date: Wed, 23 Apr 2014 16:10:50 -0700 (PDT)
Subject: [R] Loops (run the same function per different columns)
In-Reply-To: <1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1398064692015-4689171.post@n4.nabble.com>
	<1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <BLU0-SMTP213DFF3DA6748B4C8300C98C4580@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140423/b2b53c00/attachment-0001.pl>

From nospam at lisse.NA  Thu Apr 24 02:21:37 2014
From: nospam at lisse.NA (Dr Eberhard Lisse)
Date: Thu, 24 Apr 2014 01:21:37 +0100
Subject: [R] INET_NTOA equivalent?
Message-ID: <53585911.1020306@lisse.NA>

In MySQL

	SELECT INET_ATON('127.0.0.1')

returns the integer 2130706433

Is there a function in R to reverse that, ie so that something like

	ip <- inet_ntoa(2130706433)

would put  '127.0.0.1' into ip?

greetings, el



From maechler at stat.math.ethz.ch  Thu Apr 24 11:01:00 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2014 11:01:00 +0200
Subject: [R] Derivative of expm function
In-Reply-To: <CANt=4Mi15TUDoag_-evKsARt20Onomu_P3oR8acRi9gi05ksSQ@mail.gmail.com>
References: <CANt=4Mi15TUDoag_-evKsARt20Onomu_P3oR8acRi9gi05ksSQ@mail.gmail.com>
Message-ID: <21336.53964.832181.404593@stat.math.ethz.ch>

>>>>> Wagner Bonat <wbonat at gmail.com>
>>>>>     on Wed, 23 Apr 2014 12:12:17 +0200 writes:

    > Hi all !
    > I am look for some efficient method to compute the derivative of
    > exponential matrix function in R. For example, I have a simple matrix like

    > log.Sigma  <- matrix(c(par1, rho, rho, par2),2,2)

    > require(Matrix)
    > Sigma <- expm(log.Sigma)

    > I want some method to compute the derivatives of Sigma in relation the
    > parameters par1, par2 and rho. Some idea ?

The  'expm' package has slightly newer / more reliable
algorithms for the matrix exponential.

It also contains an  expmFrechet()  function
which computes the Frechet derivative of the matrix exponential.

I'm pretty confident -- but did not start thinking more deeply --
that this should provide the necessary parts to get
partial derivatives like yours as well.

Martin Maechler, ETH Zurich

    > Wagner Hugo Bonat
    > LEG - Laborat?rio de Estat?stica e Geoinforma??o
    > UFPR - Universidade Federal do Paran?



From maechler at stat.math.ethz.ch  Thu Apr 24 11:33:40 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2014 11:33:40 +0200
Subject: [R] INET_NTOA equivalent?
In-Reply-To: <53585911.1020306@lisse.NA>
References: <53585911.1020306@lisse.NA>
Message-ID: <21336.55924.373415.911753@stat.math.ethz.ch>

>>>>> "EL" == Eberhard Lisse <nospam at lisse.NA>
>>>>>     on Thu, 24 Apr 2014 01:21:37 +0100 writes:

    EL> In MySQL
    EL> SELECT INET_ATON('127.0.0.1')

    EL> returns the integer 2130706433

    EL> Is there a function in R to reverse that, ie so that something like

    EL> ip <- inet_ntoa(2130706433)

    EL> would put  '127.0.0.1' into ip?

almost:

  install.packages("sfsmisc")
  require("sfsmisc")

  # NTOA :

  > digitsBase(2130706433, base = 256)
  Class 'basedInt'(base = 256) [1:1]
       [,1]
  [1,]  127
  [2,]    0
  [3,]    0
  [4,]    1

  # ATON :

  > as.intBase(digitsBase(2130706433, base = 256), base = 256)
	   1 
  2130706433 
  > 

So, an easy solution seems


> ip.ntoa <- function(n) paste(sfsmisc::digitsBase(n, base = 256), collapse=".")
> ip.ntoa(2130706433)
[1] "127.0.0.1"
> 

but that does not vectorize (work for  length(n) > 1 )
correctly.

The correct solution then is

ip.ntoa <- function(n) 
    apply(sfsmisc::digitsBase(n, base = 256), 2, paste, collapse=".")

and that does work nicely:

> ip.ntoa(1000000000+ (0:10))

 [1] "59.154.202.0"  "59.154.202.1"  "59.154.202.2"  "59.154.202.3"  "59.154.202.4" 
 [6] "59.154.202.5"  "59.154.202.6"  "59.154.202.7"  "59.154.202.8"  "59.154.202.9" 
[11] "59.154.202.10"

right ?

--
Martin Maechler, ETH Zurich



From mohammed.ouassou at statkart.no  Thu Apr 24 12:31:32 2014
From: mohammed.ouassou at statkart.no (Mohammed Ouassou)
Date: Thu, 24 Apr 2014 12:31:32 +0200
Subject: [R] Cramer Rao upper bound computation
Message-ID: <1398335492.3103.4.camel@localhost.localdomain>

 Dear R users;

I have a question about Cramer Rao upper/lower bounds

Is it possible to compute Crammer Rao upper/lower bounds from residuals
and  corresponding covariance matrices ?


Any suggestions will be appreciated, thanks in advance.


M.O



From murdoch.duncan at gmail.com  Thu Apr 24 13:05:32 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 07:05:32 -0400
Subject: [R] rgl and axes3d() labels
In-Reply-To: <CABgwoziwUGNeP4sA3Bh4t4+VorJO7cm=Nt-7ioyApcsx=G6aTA@mail.gmail.com>
References: <CABgwozgvKa6QH+JiHNZ-hNMiADUtwH2H1y6Ow_zBw+nwkjTOkw@mail.gmail.com>	<53585C32.5040501@gmail.com>
	<CABgwoziwUGNeP4sA3Bh4t4+VorJO7cm=Nt-7ioyApcsx=G6aTA@mail.gmail.com>
Message-ID: <5358EFFC.7020002@gmail.com>

On 23/04/2014, 9:02 PM, Alex Reynolds wrote:
> Unfortunately, that doesn't help as it removes axis lines. It looks like
> I can't use segments3d() without knowing what the bounds are of the
> current axes and I don't know what to call to expose those.
>
> Thanks again for your help, though, I appreciate it. Hopefully this gets
> fixed in a future release!

There is no bug, so it won't be fixed.

Duncan Murdoch

>
> -Alex
>
>
> On Wed, Apr 23, 2014 at 5:34 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 23/04/2014, 7:51 PM, Alex Reynolds wrote:
>
>         I am making an rgl-based 3d plot. It works fine, except when I
>         try to
>         remove axis value labels and tick marks with axes3d(labels=FALSE,
>         ticks=FALSE):
>
>         ---------------------------
>         rgl.open()
>         offset <- 50
>         par3d(windowRect=c(offset, offset, 1280+offset, 1280+offset))
>         rm(offset)
>         rgl.clear()
>         rgl.viewpoint(theta=__thetaStart, phi=30, fov=30, zoom=1)
>         spheres3d(df$PC1, df$PC2, df$PC3, radius=featureRadius,
>         color=df$rColor,
>         alpha=featureTransparency, shininess=featureShininess)
>         aspect3d(1, 1, 1)
>
>         /* ------ */
>         axes3d(col='black', box=FALSE, labels=FALSE, ticks=FALSE)
>         /* ------ */
>
>         title3d("", "", "PCoA1", "PCoA2", "PCoA3", col='black', line=1)
>         texts3d(df$PC1, df$PC2, df$PC3, text=df$ctName, color="blue",
>         adj=c(0,0))
>         bg3d("white")
>         rgl.clear(type='lights')
>         rgl.light(-45, 20, ambient='black', diffuse='#dddddd',
>         specular='white')
>         rgl.light(60, 30, ambient='#dddddd', diffuse='#dddddd',
>         specular='black')
>         filename <- paste("results/PCoA.labeled.__pdf", sep="")
>         rgl.postscript(filename, fmt="pdf")
>         ---------------------------
>
>         When I run this code, these flags are ignored and I still get
>         axis labels
>         and tick marks. What am I misunderstanding about the documentation?
>
>
>     If you specify edges="bbox" (the default), labels is ignored, and
>     the bbox3d() function is used to draw the axes.  There's no ticks
>     argument, so it'll be absorbed by the ... argument.
>
>     I don't know what you want, but you might get it with
>
>       axes3d(edges=c("x", "y", "z"), col='black', box=FALSE,
>     labels=FALSE, tick=FALSE)
>
>     This won't join the axis lines at the lower corner; if that's what
>     you want, I'd just draw them explicitly using segments3d.
>
>     BTW, mixing rgl.* functions with *3d functions is likely to give you
>     strange results.  I don't recommend it.
>
>     Duncan Murdoch
>
>



From S.Ellison at LGCGroup.com  Thu Apr 24 13:34:07 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 24 Apr 2014 12:34:07 +0100
Subject: [R] Request for R " Initial value of MLE"
In-Reply-To: <1398271459.18486.YahooMailNeo@web160504.mail.bf1.yahoo.com>
References: <1398271459.18486.YahooMailNeo@web160504.mail.bf1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E9D6DD2E2@GOLD.corp.lgc-group.com>

> Sir I have this problem,
> 
> >? res <-
> maxLik(logLik=loglik1,start=c(a=1.5,b=1.5,c=1.5,dee=2),method="BFGS")
> There were 50 or more warnings (use warnings() to see the first 50)
> > summary(res)
> "Maximum Likelihood estimation
> BFGS maximisation, 0 iterations
> Return code 100: Initial value out of range."
> 
> Dear sir how we give the initial value to estimate the parameters.

i) Avoid cross-posting; some folk get a bit snippy about that.

ii) read the help page for maxLik and look for an argument specifying the initial value of parameters


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From jim at bitwrit.com.au  Thu Apr 24 13:42:12 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 24 Apr 2014 21:42:12 +1000
Subject: [R] meta-question about R
In-Reply-To: <5358ECE9.6080006@5-cent.us>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
	<E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>
	<5358ECE9.6080006@5-cent.us>
Message-ID: <5358F894.9090302@bitwrit.com.au>

On 04/24/2014 08:52 PM, mark wrote:
> On 04/23/14 23:22, William Dunlap wrote:
>> Aren't those files support for named semaphores (made with sem_open())?
>> Packages like BH and RSQLite contain calls to sem_open. Is your
>> long-running
>> R process using such a package?
>>
>> I don't think you would want to delete those files, but perhaps you
>> can look into
>> whatever R package creates them and see if you can modify the code to
>> give
>> them better names and then add those names to rkhunter's whitelist.
>
> You don't seem to understand what I'm asking. I have zero intention of
> deleting those files. I'm sure that my user's long-running job is
> creating them. What I'm asking is if ANYONE HERE knows if there is some
> configuration file, or command inside R, that would tell R, whatever
> package it's using (I assume that all packages inherit from the
> top-level process), when it creates files in /dev/shm, to name them
> something that I can use with wildcards in rkhunter's configuration file
> so that rkhunter ignores them.
>
> mark

Hi mark,
You are correct, I didn't understand what you were asking. Doing a bit 
of searching, the sem_open function's first argument is the name of the 
file that is to be created. It doesn't sound like you are specifying 
these filenames, so it is probably a matter of finding the function that 
calls sem_open or sem_init. I would approach this by grepping the source 
code of the functions that you are calling, but as I have no idea what 
these functions are (or how many levels of function calling goes on 
before one of these two functions is called), I can't provide a 
straightforward answer. If you do find the offending function, you can 
just edit the source code to include your "R_temp" prefix, save the 
edited function, and "source" it to replace the function that is not 
providing the prefixes.

Jim



From murdoch.duncan at gmail.com  Thu Apr 24 13:58:18 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 07:58:18 -0400
Subject: [R] meta-question about R
In-Reply-To: <5358F894.9090302@bitwrit.com.au>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>	<53582E1F.40606@bitwrit.com.au>	<E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>	<5358ECE9.6080006@5-cent.us>
	<5358F894.9090302@bitwrit.com.au>
Message-ID: <5358FC5A.1020504@gmail.com>

On 24/04/2014, 7:42 AM, Jim Lemon wrote:
> On 04/24/2014 08:52 PM, mark wrote:
>> On 04/23/14 23:22, William Dunlap wrote:
>>> Aren't those files support for named semaphores (made with sem_open())?
>>> Packages like BH and RSQLite contain calls to sem_open. Is your
>>> long-running
>>> R process using such a package?
>>>
>>> I don't think you would want to delete those files, but perhaps you
>>> can look into
>>> whatever R package creates them and see if you can modify the code to
>>> give
>>> them better names and then add those names to rkhunter's whitelist.
>>
>> You don't seem to understand what I'm asking. I have zero intention of
>> deleting those files. I'm sure that my user's long-running job is
>> creating them. What I'm asking is if ANYONE HERE knows if there is some
>> configuration file, or command inside R, that would tell R, whatever
>> package it's using (I assume that all packages inherit from the
>> top-level process), when it creates files in /dev/shm, to name them
>> something that I can use with wildcards in rkhunter's configuration file
>> so that rkhunter ignores them.
>>
>> mark
>
> Hi mark,
> You are correct, I didn't understand what you were asking. Doing a bit
> of searching, the sem_open function's first argument is the name of the
> file that is to be created. It doesn't sound like you are specifying
> these filenames, so it is probably a matter of finding the function that
> calls sem_open or sem_init. I would approach this by grepping the source
> code of the functions that you are calling, but as I have no idea what
> these functions are (or how many levels of function calling goes on
> before one of these two functions is called), I can't provide a
> straightforward answer. If you do find the offending function, you can
> just edit the source code to include your "R_temp" prefix, save the
> edited function, and "source" it to replace the function that is not
> providing the prefixes.
>

Using debug(sem_open) is a quick way to find who is calling them.  R 
will break execution when it enters that function.  Use the debugger 
"where" command to see the calling stack.

Duncan Murdoch



From info at aghmed.fsnet.co.uk  Thu Apr 24 14:19:07 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 24 Apr 2014 13:19:07 +0100
Subject: [R] metafor - rstudent(res) - omitted rows
In-Reply-To: <CAGQ7FNEHKgpn6U-17uougYVds6ybDAcAyeaRzQKocucoZWfwmw@mail.g
	mail.com>
References: <CAGQ7FNEHKgpn6U-17uougYVds6ybDAcAyeaRzQKocucoZWfwmw@mail.gmail.com>
Message-ID: <Zen-1WdIcX-0003fh-Gf@smarthost01d.mail.zen.net.uk>

At 11:56 22/04/2014, Dipl. Kfm Dominik Wagner MSc; MSc wrote:
>Dear all,
>
>I am quite new to R. Now my following easy question.
>
>I use metafor and performed an outlier test with rstudent(res).
>This is resulting in 1000 rows of 1578 and 578 omitted rows (starting with
>row 598).
>
>
>    1. How can I display all 1578 rows in R-studio? Because in the
>    standardized residual plot it starts with study 1 (see attachment). In
>    R-studio with row 598.
>    2. How can I just plot the standardized residuals with manipulated
>    x-axis to see every single study?

I cannot help with your Rstudio probelm as I do not use it but as far 
as your plotting question is concerned:

1 - do you really want to see all of the residuals? Why not just keep 
the ones outside the range -2 to +2 which you might then need to study further
2 - the pictures would probably be clearer if you identify and do not 
print out the two studies with r very close to -1 as they are 
compressing everything else
3 - hollow circles are often a good idea when you have overprinting.




>Thank you very much for your help.
>
>Cordially
>
>Dominik
>
>--
>
>_________________________________________________
>
>
>*Dipl.-Kfm. Dominik Wagner MSc. MSc.*
>
>Content-Type: application/pdf; name="Rplot.pdf"
>Content-Disposition: attachment; filename="Rplot.pdf"
>X-Attachment-Id: f_hub2q8dv0

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From lordpreetam at gmail.com  Thu Apr 24 14:49:23 2014
From: lordpreetam at gmail.com (Preetam Pal)
Date: Thu, 24 Apr 2014 18:19:23 +0530
Subject: [R] CHAID in R
Message-ID: <CAHVFrXHQozYaZfqCWocpTd=z1xTtojcEbaFq_BWLmf75Oa-UhQ@mail.gmail.com>

Hi,
I want to implement CHAID in R, but at this point am not sure how to go
about it.
Would be glad if someone please helps me out with it. I am attaching the
data set for your perusal.
The variable in the 1st column is the dependent variable.
Thanks,
Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

From murdoch.duncan at gmail.com  Thu Apr 24 16:05:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 10:05:19 -0400
Subject: [R] meta-question about R
In-Reply-To: <259fdde0e6df373d15675b4f1690df3c.squirrel@host290.hostmonster.com>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
	<E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>
	<5358ECE9.6080006@5-cent.us> <5358F894.9090302@bitwrit.com.au>
	<5358FC5A.1020504@gmail.com>
	<259fdde0e6df373d15675b4f1690df3c.squirrel@host290.hostmonster.com>
Message-ID: <53591A1F.4080902@gmail.com>

On 24/04/2014 9:56 AM, m.roth at 5-cent.us wrote:
> Duncan Murdoch wrote:
> > On 24/04/2014, 7:42 AM, Jim Lemon wrote:
> >> On 04/24/2014 08:52 PM, mark wrote:
> >>> On 04/23/14 23:22, William Dunlap wrote:
> <snip>
> >>> deleting those files. I'm sure that my user's long-running job is
> >>> creating them. What I'm asking is if ANYONE HERE knows if there is some
> >>> configuration file, or command inside R, that would tell R, whatever
> >>> package it's using (I assume that all packages inherit from the
> >>> top-level process), when it creates files in /dev/shm, to name them
> >>> something that I can use with wildcards in rkhunter's configuration
> >>> file so that rkhunter ignores them.
>
> >> You are correct, I didn't understand what you were asking. Doing a bit
> >> of searching, the sem_open function's first argument is the name of the
> >> file that is to be created. It doesn't sound like you are specifying
> >> these filenames, so it is probably a matter of finding the function that
> >> calls sem_open or sem_init. I would approach this by grepping the source
> >> code of the functions that you are calling, but as I have no idea what
> >> these functions are (or how many levels of function calling goes on
> >> before one of these two functions is called), I can't provide a
> >> straightforward answer. If you do find the offending function, you can
> >> just edit the source code to include your "R_temp" prefix, save the
> >> edited function, and "source" it to replace the function that is not
> >> providing the prefixes.
> >
> > Using debug(sem_open) is a quick way to find who is calling them.  R
> > will break execution when it enters that function.  Use the debugger
> > "where" command to see the calling stack.
>
> Thank you both very much - that's what I needed to know. One question,
> though - is there an R.conf or something, where the default is format of
> that filename is set? I've looked through the rpm for R-core, and what
> .../etc/... files are in it, and I don't see that. Is there such a config,
> or is that hard-coded into R itself?

There isn't an R.conf file.  Jim told you how the filename is set in the 
low level sem_open; you'll have to look at the source of the caller to 
see how it determines the name it uses.

Duncan Murdoch



From tom at maladmin.com  Thu Apr 24 17:45:15 2014
From: tom at maladmin.com (Tom Wright)
Date: Thu, 24 Apr 2014 11:45:15 -0400
Subject: [R] Fast way to populate a sparse matrix
Message-ID: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/998deaae/attachment-0001.pl>

From smartpink111 at yahoo.com  Thu Apr 24 18:23:59 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 24 Apr 2014 09:23:59 -0700 (PDT)
Subject: [R] Hi ,
	Is it possible select a different number of rows by each group with
	R????
In-Reply-To: <1398308493.86920.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <DUB123-W26EA3DC193617BEED1F7E58F5E0@phx.gbl>
	<1398188759.90767.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1398308493.86920.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1398356639.29084.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Marta,

If your first dataset "field2" is greater than the number of rows for a particular "field1" in second dataset, this error could happen.

e.g. using modified dat1:
dat1 <- structure(list(field1 = 1:3, field2 = c(3L, 20L, 4L)), .Names = c("field1", 
"field2"), class = "data.frame", row.names = c(NA, -3L))




?lapply(split(dat2,dat2$field1),function(x) x[sample(1:nrow(x),dat1$field2[!is.na(match(dat1$field1,x$field1))],replace=FALSE),])
#Error in sample.int(length(x), size, replace, prob) : 
#? cannot take a sample larger than the population when 'replace = FALSE'

#In that case,?
res <- do.call(rbind, lapply(split(dat2, dat2$field1), function(x) {
??? length1 <- dat1$field2[!is.na(match(dat1$field1, x$field1))]
??? length2 <- if (length1 >= nrow(x)) 
??????? nrow(x) else length1
??? x[sample(nrow(x), length2, replace = FALSE), ]
}))



##instead of randomly selecting 20 rows for field1==2 in dat2, the above code selected the maximum number of rows

nrow(dat2[dat2$field1==2,])
#[1] 8


res[1:2,]
#??? field1?? field3 field4 field5
#1.8????? 1 0.666667???? Sp??? Jm2
#1.6????? 1 0.583333???? Sp??? Rm6



A.K.

Hi Arun,

Thanks for your suggestions.

I tried your new script, with a little sample works well. However when I tried with the huge database, the script doesn't work. ?

Error in sample.int(length(x), size, replace, prob) :
? cannot take a sample larger than the population when 'replace = FALSE' 



On Wednesday, April 23, 2014 11:01 PM, arun <smartpink111 at yahoo.com> wrote:


Hi Marta,
If you need random selection, you could use:

do.call(rbind,lapply(split(dat2,dat2$field1),function(x) x[sample(1:nrow(x),dat1$field2[!is.na(match(dat1$field1,x$field1))],replace=FALSE),]))
A.K.



On Tuesday, April 22, 2014 1:45 PM, arun <smartpink111 at yahoo.com> wrote:


Hi Marta,
It's not clear whether you wanted to select the first "n" rows specified by field2 in the first dataset or just random rows.
##using a modified example if my guess is correct

dat1 <- structure(list(field1 = 1:3, field2 = c(3L, 6L, 4L)), .Names = c("field1", 
"field2"), class = "data.frame", row.names = c(NA, -3L))



dat2 <- structure(list(field1 = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L), field3 = c(0.375, 0.416667, 0.458333, 0.5, 0.541667, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.583333, 
0.625, 0.666667, 0.708333, 0.75, 0.791667, 0.833333, 0.875, 0.708333, 
0.75, 0.791667, 0.833333, 0.875), field4 = c("Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", "Sp", 
"Sp"), field5 = c("Rm1", "Rm2", "Rm3", "Rm4", "Rm5", "Rm6", "Jm1", 
"Jm2", "Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Rm6", "Jm1", "Jm2", 
"Jm3", "Jm4", "Jm5", "Jm6", "Jm7", "Jm3", "Jm4", "Jm5", "Jm6", 
"Jm7")), .Names = c("field1", "field3", "field4", "field5"), class = "data.frame", row.names = c(NA, 
-26L))


##for selecting the first 'n' rows

dat2New <- merge(dat1,dat2,by="field1")
library(plyr)
res1 <- ddply(dat2New,.(field1),function(x) head(x,unique(x$field2)))[,-2]


#or
res2 <- dat2[with(dat1,rep(match(field1, dat2$field1),field2)+sequence(field2)-1),]

A.K.


?Sorry, I think now the message is correct.

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2).
I have these 2 tables:

Table1
field1 field2
1 3
2 6
3 9
4 3
5 3
6 3
7 3
8 9
9 6
10 3
11 3
12 3
13 3
14 3
?????????????????????? 
Table2
field1 field3 field4 field5
1 0.375 Sp Rm1
1 0.416667 Sp Rm2
1 0.458333 Sp Rm3
1 0.5??????? Sp Rm4
1 0.541667 Sp Rm5
1 0.583333 Sp Rm6
1 0.625 Sp Jm1
1 0.666667 Sp Jm2
1 0.708333 Sp Jm3
1 0.75?? Sp Jm4
1 0.791667 Sp Jm5
1 0.833333 Sp Jm6
1 0.875 Sp Jm7

thx!!! 



On Monday, April 21, 2014 4:02 PM, Marta Tobe?a <marta_mtm at hotmail.com> wrote:

Hi , Is it possible select a different number of rows by each group with R????
I must to select different number (specific quantity in field2:Table1) of rows in each group(field1:Table2). I have these 2 tables:Table1Table2field1field2field1field3field4field51310.375SpRm12610.416667SpRm23910.458333SpRm34310.5SpRm45310.541667SpRm56310.583333SpRm67310.625SpJm18910.666667SpJm29610.708333SpJm310310.75SpJm411310.791667SpJm512310.833333SpJm613310.875SpJm714320.916667SpJm820.958333SpJm921SpJm1021.041667SpJm1121.083333SpJm1221.125SpJm1321.166667SpJm1421.208333SpJm1521.25SpJm1621.291667SpJm1721.333333SpJm18Thanks youMarta ??? ???????? ?????? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From kpmainali at utexas.edu  Thu Apr 24 18:44:50 2014
From: kpmainali at utexas.edu (Kumar Mainali)
Date: Thu, 24 Apr 2014 11:44:50 -0500
Subject: [R] mvpart question - how to calculate deviance explained by
	variables?
Message-ID: <CABK368j6HUrhm-borp1tH5edUr_hzXTxT6Ao3_EaN7R0b6YD_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/770a5b20/attachment-0001.pl>

From reynolda at uw.edu  Thu Apr 24 18:49:32 2014
From: reynolda at uw.edu (Alex Reynolds)
Date: Thu, 24 Apr 2014 09:49:32 -0700
Subject: [R] rgl and axes3d() labels
In-Reply-To: <5358EFFC.7020002@gmail.com>
References: <CABgwozgvKa6QH+JiHNZ-hNMiADUtwH2H1y6Ow_zBw+nwkjTOkw@mail.gmail.com>
	<53585C32.5040501@gmail.com>
	<CABgwoziwUGNeP4sA3Bh4t4+VorJO7cm=Nt-7ioyApcsx=G6aTA@mail.gmail.com>
	<5358EFFC.7020002@gmail.com>
Message-ID: <C303907F-2D95-4A8B-84E2-8A7A47D19BDA@uw.edu>

Or perhaps the documentation could be updated to clear up what works and what doesn't. It seems pretty confusing to put options in the docs that do not work as described.

-Alex

> On Apr 24, 2014, at 4:05 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 23/04/2014, 9:02 PM, Alex Reynolds wrote:
>> Unfortunately, that doesn't help as it removes axis lines. It looks like
>> I can't use segments3d() without knowing what the bounds are of the
>> current axes and I don't know what to call to expose those.
>> 
>> Thanks again for your help, though, I appreciate it. Hopefully this gets
>> fixed in a future release!
> 
> There is no bug, so it won't be fixed.
> 
> Duncan Murdoch
> 
>> 
>> -Alex
>> 
>> 
>> On Wed, Apr 23, 2014 at 5:34 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>> 
>>    On 23/04/2014, 7:51 PM, Alex Reynolds wrote:
>> 
>>        I am making an rgl-based 3d plot. It works fine, except when I
>>        try to
>>        remove axis value labels and tick marks with axes3d(labels=FALSE,
>>        ticks=FALSE):
>> 
>>        ---------------------------
>>        rgl.open()
>>        offset <- 50
>>        par3d(windowRect=c(offset, offset, 1280+offset, 1280+offset))
>>        rm(offset)
>>        rgl.clear()
>>        rgl.viewpoint(theta=__thetaStart, phi=30, fov=30, zoom=1)
>>        spheres3d(df$PC1, df$PC2, df$PC3, radius=featureRadius,
>>        color=df$rColor,
>>        alpha=featureTransparency, shininess=featureShininess)
>>        aspect3d(1, 1, 1)
>> 
>>        /* ------ */
>>        axes3d(col='black', box=FALSE, labels=FALSE, ticks=FALSE)
>>        /* ------ */
>> 
>>        title3d("", "", "PCoA1", "PCoA2", "PCoA3", col='black', line=1)
>>        texts3d(df$PC1, df$PC2, df$PC3, text=df$ctName, color="blue",
>>        adj=c(0,0))
>>        bg3d("white")
>>        rgl.clear(type='lights')
>>        rgl.light(-45, 20, ambient='black', diffuse='#dddddd',
>>        specular='white')
>>        rgl.light(60, 30, ambient='#dddddd', diffuse='#dddddd',
>>        specular='black')
>>        filename <- paste("results/PCoA.labeled.__pdf", sep="")
>>        rgl.postscript(filename, fmt="pdf")
>>        ---------------------------
>> 
>>        When I run this code, these flags are ignored and I still get
>>        axis labels
>>        and tick marks. What am I misunderstanding about the documentation?
>> 
>> 
>>    If you specify edges="bbox" (the default), labels is ignored, and
>>    the bbox3d() function is used to draw the axes.  There's no ticks
>>    argument, so it'll be absorbed by the ... argument.
>> 
>>    I don't know what you want, but you might get it with
>> 
>>      axes3d(edges=c("x", "y", "z"), col='black', box=FALSE,
>>    labels=FALSE, tick=FALSE)
>> 
>>    This won't join the axis lines at the lower corner; if that's what
>>    you want, I'd just draw them explicitly using segments3d.
>> 
>>    BTW, mixing rgl.* functions with *3d functions is likely to give you
>>    strange results.  I don't recommend it.
>> 
>>    Duncan Murdoch
> 



From astronasrin at gmail.com  Thu Apr 24 16:55:54 2014
From: astronasrin at gmail.com (Nasrin Pak)
Date: Thu, 24 Apr 2014 08:55:54 -0600
Subject: [R] Remove top values from a data set
Message-ID: <CABN-ZadVWvBv0N7_GPX5sfojx9pFX3HTRLAPGh2=0_-t-uiF=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/3a5a136c/attachment-0001.pl>

From m.roth at 5-cent.us  Thu Apr 24 12:52:25 2014
From: m.roth at 5-cent.us (mark)
Date: Thu, 24 Apr 2014 06:52:25 -0400
Subject: [R] meta-question about R
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
	<E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>
Message-ID: <5358ECE9.6080006@5-cent.us>

On 04/23/14 23:22, William Dunlap wrote:
> Aren't those files support for named semaphores (made with sem_open())?
> Packages like BH and RSQLite contain calls to sem_open.   Is your long-running
> R process using such a package?
>
> I don't think you would want to delete those files, but perhaps you can look into
> whatever R package creates them and see if you can modify the code to give
> them better names and then add those names to rkhunter's whitelist.

You don't seem to understand what I'm asking. I have zero intention of 
deleting those files. I'm sure that my user's long-running job is creating 
them. What I'm asking is if ANYONE HERE knows if there is some configuration 
file, or command inside R, that would tell R, whatever package it's using (I 
assume that all packages inherit from the top-level process), when it creates 
files in /dev/shm, to name them something that I can use with wildcards in 
rkhunter's configuration file so that rkhunter ignores them.

	mark
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Jim Lemon
>> Sent: Wednesday, April 23, 2014 2:18 PM
>> To: m.roth at 5-cent.us
>> Cc: r-help at r-project.org
>> Subject: Re: [R] meta-question about R
>>
>> On 04/23/2014 11:58 PM, m.roth at 5-cent.us wrote:
>>> This really isn't about R, but configuring R. We're running R 3.0.2-1, the
>>> current default package, on CentOS 6.5 On a long-running job, R is
>>> creating files in /dev/shm: each set of three files are named (8 hex
>>> digits)-(4 hex digits)-(4 hex digits)-(4 hex digits)-(12 hex digits), and
>>> then sem.(same as the name)_counter_mutex, and (same as the name)_counter.
>>>
>>> For example,
>>> 156d23b0-9e67-46e2-afab-14a648252890
>>> 156d23b0-9e67-46e2-afab-14a648252890_counter
>>> sem.156d23b0-9e67-46e2-afab-14a648252890_counter_mutex
>>>
>>> Is there some way to configure R to add a prefix, say, to each of these
>>> files? We're running rkhunter (rootkit hunter) for security, and it
>>> complains about suspicious files, and I'd like some way to be able to tell
>>> it to, say, ignore R_temp.whatever....
>>>
>> Hi mark,
>> I assume that the problem is to identify the files in /dev/shm, not to
>> simply change your R code to tack the prefix onto the files as it
>> produces them. As your hexadecimal digits are probably randomly
>> generated, the solution may be to identify all the files that have
>> "_counter_mutex" in the name, then chip off the appropriate bits to get
>> the troublesome first name.
>>
>> filenames<-list.files(pattern="_counter_mutex")
>> # function to return the two other filenames
>> strip_fn<-function(x) {
>>    f2<-substr(x,5,nchar(x)-6)
>>    f1<-substr(f2,1,nchar(f2)-8)
>>    return(c(f1,f2))
>> }
>> # get all the filenames
>> filenames<-c(filenames,unlist(sapply(filenames,strip_fn)))
>> # stick on the prefix
>> newfilenames<-paste("R_temp",filenames,sep=".")
>> # create the commands
>> fnmove<-paste("mv",filenames,newfilenames)
>> # move the filenames
>> for(fn in 1:length(fnmove)) system(fnmove[fn])
>>
>> Warning - I haven't tested the last bit of this, but it should work.
>> There is probably some really neat string of heiroglyphs in a regular
>> expression that will do this as well.
>>
>> Jim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From m.roth at 5-cent.us  Thu Apr 24 15:56:10 2014
From: m.roth at 5-cent.us (m.roth at 5-cent.us)
Date: Thu, 24 Apr 2014 09:56:10 -0400
Subject: [R] meta-question about R
In-Reply-To: <5358FC5A.1020504@gmail.com>
References: <0658a67eb5be7dc02067e33147296944.squirrel@host290.hostmonster.com>
	<53582E1F.40606@bitwrit.com.au>
	<E66794E69CFDE04D9A70842786030B933FACAAEA@PA-MBX01.na.tibco.com>
	<5358ECE9.6080006@5-cent.us> <5358F894.9090302@bitwrit.com.au>
	<5358FC5A.1020504@gmail.com>
Message-ID: <259fdde0e6df373d15675b4f1690df3c.squirrel@host290.hostmonster.com>

Duncan Murdoch wrote:
> On 24/04/2014, 7:42 AM, Jim Lemon wrote:
>> On 04/24/2014 08:52 PM, mark wrote:
>>> On 04/23/14 23:22, William Dunlap wrote:
<snip>
>>> deleting those files. I'm sure that my user's long-running job is
>>> creating them. What I'm asking is if ANYONE HERE knows if there is some
>>> configuration file, or command inside R, that would tell R, whatever
>>> package it's using (I assume that all packages inherit from the
>>> top-level process), when it creates files in /dev/shm, to name them
>>> something that I can use with wildcards in rkhunter's configuration
>>> file so that rkhunter ignores them.

>> You are correct, I didn't understand what you were asking. Doing a bit
>> of searching, the sem_open function's first argument is the name of the
>> file that is to be created. It doesn't sound like you are specifying
>> these filenames, so it is probably a matter of finding the function that
>> calls sem_open or sem_init. I would approach this by grepping the source
>> code of the functions that you are calling, but as I have no idea what
>> these functions are (or how many levels of function calling goes on
>> before one of these two functions is called), I can't provide a
>> straightforward answer. If you do find the offending function, you can
>> just edit the source code to include your "R_temp" prefix, save the
>> edited function, and "source" it to replace the function that is not
>> providing the prefixes.
>
> Using debug(sem_open) is a quick way to find who is calling them.  R
> will break execution when it enters that function.  Use the debugger
> "where" command to see the calling stack.

Thank you both very much - that's what I needed to know. One question,
though - is there an R.conf or something, where the default is format of
that filename is set? I've looked through the rpm for R-core, and what
.../etc/... files are in it, and I don't see that. Is there such a config,
or is that hard-coded into R itself?

        mark



From nospam at lisse.na  Thu Apr 24 11:34:59 2014
From: nospam at lisse.na (Eberhard Lisse)
Date: Thu, 24 Apr 2014 10:34:59 +0100
Subject: [R] INET_NTOA equivalent?
In-Reply-To: <21336.55924.373415.911753@stat.math.ethz.ch>
References: <53585911.1020306@lisse.NA>
	<21336.55924.373415.911753@stat.math.ethz.ch>
Message-ID: <5358DAC3.2040304@lisse.na>

Thank you,

el

on 2014-04-24, 10:33 Martin Maechler said the following:
>>>>>> "EL" == Eberhard Lisse <nospam at lisse.NA>
>>>>>>     on Thu, 24 Apr 2014 01:21:37 +0100 writes:
> 
>     EL> In MySQL
>     EL> SELECT INET_ATON('127.0.0.1')
> 
>     EL> returns the integer 2130706433
> 
>     EL> Is there a function in R to reverse that, ie so that something like
> 
>     EL> ip <- inet_ntoa(2130706433)
> 
>     EL> would put  '127.0.0.1' into ip?
> 
> almost:
> 
>   install.packages("sfsmisc")
>   require("sfsmisc")
> 
>   # NTOA :
> 
>   > digitsBase(2130706433, base = 256)
>   Class 'basedInt'(base = 256) [1:1]
>        [,1]
>   [1,]  127
>   [2,]    0
>   [3,]    0
>   [4,]    1
> 
>   # ATON :
> 
>   > as.intBase(digitsBase(2130706433, base = 256), base = 256)
> 	   1 
>   2130706433 
>   > 
> 
> So, an easy solution seems
> 
> 
>> ip.ntoa <- function(n) paste(sfsmisc::digitsBase(n, base = 256), collapse=".")
>> ip.ntoa(2130706433)
> [1] "127.0.0.1"
>>
> 
> but that does not vectorize (work for  length(n) > 1 )
> correctly.
> 
> The correct solution then is
> 
> ip.ntoa <- function(n) 
>     apply(sfsmisc::digitsBase(n, base = 256), 2, paste, collapse=".")
> 
> and that does work nicely:
> 
>> ip.ntoa(1000000000+ (0:10))
> 
>  [1] "59.154.202.0"  "59.154.202.1"  "59.154.202.2"  "59.154.202.3"  "59.154.202.4" 
>  [6] "59.154.202.5"  "59.154.202.6"  "59.154.202.7"  "59.154.202.8"  "59.154.202.9" 
> [11] "59.154.202.10"
> 
> right ?
> 
> --
> Martin Maechler, ETH Zurich
> 
>



From jholtman at gmail.com  Thu Apr 24 19:01:57 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 24 Apr 2014 13:01:57 -0400
Subject: [R] Remove top values from a data set
In-Reply-To: <CABN-ZadVWvBv0N7_GPX5sfojx9pFX3HTRLAPGh2=0_-t-uiF=Q@mail.gmail.com>
References: <CABN-ZadVWvBv0N7_GPX5sfojx9pFX3HTRLAPGh2=0_-t-uiF=Q@mail.gmail.com>
Message-ID: <CAAxdm-7_BJMN9=AMJJ+S313EXRuw7Hhzy-8+CMe_29BEu+jvMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/f4f04e7b/attachment-0001.pl>

From vishal_c64 at yahoo.com  Thu Apr 24 13:04:01 2014
From: vishal_c64 at yahoo.com (Vishal Chari)
Date: Thu, 24 Apr 2014 04:04:01 -0700 (PDT)
Subject: [R] Unable to install rqpd
Message-ID: <1398337441.52076.YahooMailBasic@web124501.mail.ne1.yahoo.com>

Hello,

 I am unable to install package rqpd. I have also tried to download for source but not able to do so.
Please help

thank in advance
regards
vishal



From noahsilverman at ucla.edu  Thu Apr 24 19:20:18 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 24 Apr 2014 10:20:18 -0700
Subject: [R] Perceptual Mapping
Message-ID: <535947D2.7050203@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/bb7acd79/attachment-0001.pl>

From vweinbir at gmail.com  Thu Apr 24 14:15:12 2014
From: vweinbir at gmail.com (Verena Weinbir)
Date: Thu, 24 Apr 2014 14:15:12 +0200
Subject: [R] Metafor: How to integrate effectsizes?
In-Reply-To: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
References: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
Message-ID: <CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/ae5d3f1c/attachment-0001.pl>

From gunter.berton at gene.com  Thu Apr 24 20:50:10 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 24 Apr 2014 11:50:10 -0700
Subject: [R] Perceptual Mapping
In-Reply-To: <535947D2.7050203@ucla.edu>
References: <535947D2.7050203@ucla.edu>
Message-ID: <CACk-te3c6BP4Z8Sr0m6GUG4Tz5_sHfzzMtnyBdAMGWB=qbW3Fg@mail.gmail.com>

google on "perceptual mapping with R"

Here is one of the hits:

http://marketing-yogi.blogspot.com/2012/12/session-4-rcode-perceptual-maps.html

It does not look like mds. It appears to be  (closely related to?) PCA.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Thu, Apr 24, 2014 at 10:20 AM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> Hi,
>
> Someone just asked me to analyze a fairly large data set using something
> they called "perceptual mapping".  I'm not familiar with the term, but a
> quick check in Google seems to indicate that it is just another term for
> Multidimensional Scaling.  However, they insist that it is something
> different.
>
> Is anybody here familiar with "perceptual mapping" with multidimensional
> data?  If so, can you point to me to any examples using R?
>
> Thanks,
>
>
> --
> *Noah Silverman, PhD* | UCLA Department of Statistics
> 8117 Math Sciences Building, Los Angeles, CA 90095
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From 23085738 at nwu.ac.za  Thu Apr 24 20:26:33 2014
From: 23085738 at nwu.ac.za (KD Makatjane)
Date: Thu, 24 Apr 2014 20:26:33 +0200
Subject: [R] instal tar.gz package on windows
Message-ID: <53597397020000B20002AAB1@v-pgw-nlx2.p.nwu.ac.za>

Good evening sir/madam
My name is katleho makatjane. I am currently a B.com statistics student at North West University Mafikeng campus.  I have installed R 3.1.0 on my laptop but my main problem is to install all necessary packages so that I may be able to start using it for my analysis. It gives me error while trying to install them from downloaded files. And again it can connect to the internet to download them automatically. Can you please help me out on how to install the R packages. I am using a 32bit windows 7 ultimate operating system
 
Yours faithfully
 
Katleho Makatjane
North West University
Mafikeng Campus
Department of Statistics and Economics
Contact: +27734630271
 
 
Vrywaringsklousule / Disclaimer:  http://www.nwu.ac.za/it/gov-man/disclaimer.html 

From sarah.goslee at gmail.com  Thu Apr 24 21:20:00 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 24 Apr 2014 15:20:00 -0400
Subject: [R] instal tar.gz package on windows
In-Reply-To: <53597397020000B20002AAB1@v-pgw-nlx2.p.nwu.ac.za>
References: <53597397020000B20002AAB1@v-pgw-nlx2.p.nwu.ac.za>
Message-ID: <CAM_vjukRBRMUKZUGh+_xS_Q2N309Cbu8VNQNG-0hMXz5UEPFiA@mail.gmail.com>

Normally on Windows you should install the Windows binary from the
*.zip file, not the source from the *.tar.gz file.

If you look at a CRAN page the available files are labeled that way.

You might also be interested in
?install.packages

There are further instructions available on your local CRAN mirror, including:

Installation of Packages

Please type help("INSTALL") or help("install.packages") in R for
information on how to install packages from this repository. The
manual R Installation and Administration (also contained in the R base
sources) explains the process in detail.


Sarah

On Thu, Apr 24, 2014 at 2:26 PM, KD Makatjane <23085738 at nwu.ac.za> wrote:
> Good evening sir/madam
> My name is katleho makatjane. I am currently a B.com statistics student at North West University Mafikeng campus.  I have installed R 3.1.0 on my laptop but my main problem is to install all necessary packages so that I may be able to start using it for my analysis. It gives me error while trying to install them from downloaded files. And again it can connect to the internet to download them automatically. Can you please help me out on how to install the R packages. I am using a 32bit windows 7 ultimate operating system
>
> Yours faithfully
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From sarah.goslee at gmail.com  Thu Apr 24 21:22:42 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 24 Apr 2014 15:22:42 -0400
Subject: [R] Unable to install rqpd
In-Reply-To: <1398337441.52076.YahooMailBasic@web124501.mail.ne1.yahoo.com>
References: <1398337441.52076.YahooMailBasic@web124501.mail.ne1.yahoo.com>
Message-ID: <CAM_vjum48TFUdwRmfodkCxWrJBd6LB9dLgDTmpr+UahCuiZ_9w@mail.gmail.com>

How did you try to install the package?
What happens when you try?
What operating system are you using?
What version of R are you using?

Did you try Google, and read any of the other discussions of how to
install rqpd?
Did you read the posting guide (linked at bottom of this and every
message) and provide the necessary background information?

Sarah

On Thu, Apr 24, 2014 at 7:04 AM, Vishal Chari <vishal_c64 at yahoo.com> wrote:
> Hello,
>
>  I am unable to install package rqpd. I have also tried to download for source but not able to do so.
> Please help
>
> thank in advance
> regards
> vishal
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From 538280 at gmail.com  Thu Apr 24 23:33:44 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 24 Apr 2014 15:33:44 -0600
Subject: [R] R dataset copyrights
In-Reply-To: <5356A701.3050901@gmail.com>
References: <5356A701.3050901@gmail.com>
Message-ID: <CAFEqCdxXi0jo5BCa0f8NwkYHig-RneirKeDjMhOg1WFkmJUK-g@mail.gmail.com>

Many, probably even most (but I have not checked) of the datasets
available in R packages have help files with a references section.
That section should lead you to an original source that may have the
copyright information and is what should be referenced.

My understanding (but I am not a lawyer, do not play one on TV, or
claim to be any type of legal expert) is that you cannot copyright
facts, but you can copyright the layout and presentation of facts.  So
real data about the real world cannot be copyrighted, but the layout
and presentation can be.  So if you photocopy a page from a journal
and post that you may be in trouble for copying and distributing the
layout and presentation of the data, but not the data itself.  But if
you transform the numbers to a file to be read by the computer then
you have just copied the facts which are not copyrighted.

On the other hand simulated or otherwise made up datasets could be
considered to be fiction and therefore able to be copyrighted.  I
remember hearing (but I don't remember where or when) that some
textbook authors are encouraged to use simulated data instead of real
data (it can have the same mean, sd, etc. as a real dataset so the
interpretation is the same) in textbooks so that the copyright of the
textbook also applies to the data.  It is not always clear whether a
dataset is fact or simulated, so it is best to obtain permission or
check official statements from the source.

Beyond what is legal you should consider what is right.  Even if you
don't have to cite a data source, you should try to give credit where
it is due (and possibly blame if there is an error).  At a minimum you
should cite original sources when they can be found and also mention
where you obtained the data if not from the original source.  Think of
the effort that people went through to collect the data and make it
available to you, how would you feel if you put that much effort into
something then someone else stole the credit or other rewards.  Many
data sources have statements on how the data can be used and it is
best to follow those instructions/requests, is it really that hard to
add a reference to where the data came from and how you obtained it?

In some educational cases it may be better to initially hide the
source of the data, for example the outliers dataset in the
TeachingDemos package would be a lot less useful for its intended
purposes if students were to read its help page before analyzing it,
therefore I have no problem with teachers using it without telling
students where it came from (and since it is simulated I could
possibly claim copyright), though I would appreciate a mention after
the fact (once the lesson is learned the teacher could say "by the
way, this data came from ...") and I expect that others would feel
similarly (I should add a note to that effect to the documentation
page).  But you should check the sources to see if this is
specifically allowed or disallowed.

I probably have not fully answered your question, but hopefully this
gives a little more guidance.

On Tue, Apr 22, 2014 at 11:29 AM, Soeren Groettrup
<soeren.groettrup at gmail.com> wrote:
> Hi everybody,
>
> I've been searching the web for quite a time now and haven't found a
> satisfying answer. I was wondering if the datasets provided within the R
> packages are open, and thus can be used in publications? Concretely, can the
> data, for example, be exported from R and uploaded in a different format
> (like csv) to a website to be accessible for students to work with the data
> in SPSS or Matlab? Is it enough to cite the source or paper or do I need a
> permission for every dataset?
>
> Thanks in advance for your replies,
> S?ren Gr?ttrup
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From 538280 at gmail.com  Thu Apr 24 23:56:28 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 24 Apr 2014 15:56:28 -0600
Subject: [R] Fast way to populate a sparse matrix
In-Reply-To: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>
References: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>
Message-ID: <CAFEqCdz3n1wOg6B7g401QTT+ciiPNi0FR_4fLmy0v_D-yUVHcQ@mail.gmail.com>

Convert your 'targets' matrix into a 2 column matrix with the 1st
column representing the row and the 2nd the column where you want your
values, then change the values to a single vector and you can just use
the targets matrix as the subsetting in 1 step without (explicit)
looping, for example:

library(Matrix)

adjM <- Matrix(0,nrow=10,ncol=10)

locs <- cbind( sample(1:10), sample(1:10) )
vals <- rnorm(10)

adjM[ locs ] <- vals

I would expect this to be faster than looping (but have not tested).

On Thu, Apr 24, 2014 at 9:45 AM, Tom Wright <tom at maladmin.com> wrote:
> I need to generate a sparse matrix. Currently I have the data held in two
> regular matrices. One 'targets' holds the column subscripts while the other
> 'scores' holds the values. I have written a 'toy' sample below. Using this
> approach takes about 90 seconds to populate a 30000 x 30000 element matrix.
> I'm going to need to scale this up by a factor of about 1000 so I really
> need a faster way of populating the sparse matrix.
> Any advice received gratefully.
>
> # toy code starts here
>
> require('Matrix')
> set.seed(0)
>
> adjM<-Matrix(0,nrow=10,ncol=10)
>
> #generate the scores for the sparse matrix, with the target locations
> targets<-matrix(nrow=10,ncol=5)
> scores<-matrix(nrow=10,ncol=5)
> for(iloc in 1:10)
>   {
>   targets[iloc,]<-sample(1:10,5,replace=FALSE)
>   scores[iloc,]<-rnorm(5)
>   }
>
> #populate the sparse matrix
> for(iloc in 1:10)
>   {
>   adjM[iloc,targets[iloc,!is.na(targets[iloc,])]]<-scores[iloc,!is.na
> (targets[iloc,])]
>   }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From ross at biostat.ucsf.edu  Fri Apr 25 00:40:59 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 24 Apr 2014 15:40:59 -0700
Subject: [R] no line number from error
Message-ID: <1398379259.6236.65.camel@localhost>

 > r1 <- totalEffect.all(dsim, simjob)
 Error: attempt to apply non-function
 > traceback()
 1: totalEffect.all(dsim, simjob)
 > class(totalEffect.all)
 [1] "function"
How can I find out where in totalEffect.all the error is arising?
My only theory for the lack of line number was that totaEffect.all was
not a function; it is.  Further, previous calls to the function worked,
and errors in it produced line numbers.  After fixing a previous error
I'm now getting this.

All my code is sourced from files except for the driver.  The driver
code is in the same file that defines totalEffect.all.

In this particular case I stepped through with the debugger and found
that in the  line
accums[[m]]$delta$accum(up - down, data)

the delta object was NULL and so accum is not a function on it.  But I
hope there's a better way to locate an error.

R 3.0.3



From noahsilverman at ucla.edu  Fri Apr 25 01:14:20 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Thu, 24 Apr 2014 16:14:20 -0700
Subject: [R] Perceptual Mapping
In-Reply-To: <CACk-te3c6BP4Z8Sr0m6GUG4Tz5_sHfzzMtnyBdAMGWB=qbW3Fg@mail.gmail.com>
References: <535947D2.7050203@ucla.edu>
	<CACk-te3c6BP4Z8Sr0m6GUG4Tz5_sHfzzMtnyBdAMGWB=qbW3Fg@mail.gmail.com>
Message-ID: <53599ACC.9050107@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/8ad9af95/attachment-0001.pl>

From murdoch.duncan at gmail.com  Fri Apr 25 01:29:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 19:29:55 -0400
Subject: [R] no line number from error
In-Reply-To: <1398379259.6236.65.camel@localhost>
References: <1398379259.6236.65.camel@localhost>
Message-ID: <53599E73.4090708@gmail.com>

On 24/04/2014, 6:40 PM, Ross Boylan wrote:
>   > r1 <- totalEffect.all(dsim, simjob)
>   Error: attempt to apply non-function
>   > traceback()
>   1: totalEffect.all(dsim, simjob)
>   > class(totalEffect.all)
>   [1] "function"
> How can I find out where in totalEffect.all the error is arising?
> My only theory for the lack of line number was that totaEffect.all was
> not a function; it is.  Further, previous calls to the function worked,
> and errors in it produced line numbers.  After fixing a previous error
> I'm now getting this.
>
> All my code is sourced from files except for the driver.  The driver
> code is in the same file that defines totalEffect.all.

I don't understand this.  If totalEffect.all is in a file that is not 
sourced, where did it come from?

Generally the rule is that if you source a function from a file you'll 
get line number information attached to it, so you should see a line 
number reported when an error occurs, or during debugging.  There are 
exceptions:  you can turn this off, and by default, it is turned off for 
functions defined in packages (but you can turn it on if you re-install 
from source).

>
> In this particular case I stepped through with the debugger and found
> that in the  line
> accums[[m]]$delta$accum(up - down, data)
>
> the delta object was NULL and so accum is not a function on it.  But I
> hope there's a better way to locate an error.

If the line that triggered this error was in a function that had line 
number information, it sounds like it might be a bug.  Can you simplify 
it down to a simple reproducible example that I could look at?

Duncan Murdoch



From ross at biostat.ucsf.edu  Fri Apr 25 01:34:37 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 24 Apr 2014 16:34:37 -0700
Subject: [R] no line number from error
In-Reply-To: <53599E73.4090708@gmail.com>
References: <1398379259.6236.65.camel@localhost> <53599E73.4090708@gmail.com>
Message-ID: <1398382477.6236.68.camel@localhost>

On Thu, 2014-04-24 at 19:29 -0400, Duncan Murdoch wrote:
> On 24/04/2014, 6:40 PM, Ross Boylan wrote:
> >   > r1 <- totalEffect.all(dsim, simjob)
> >   Error: attempt to apply non-function
> >   > traceback()
> >   1: totalEffect.all(dsim, simjob)
> >   > class(totalEffect.all)
> >   [1] "function"
> > How can I find out where in totalEffect.all the error is arising?
> > My only theory for the lack of line number was that totaEffect.all was
> > not a function; it is.  Further, previous calls to the function worked,
> > and errors in it produced line numbers.  After fixing a previous error
> > I'm now getting this.
> >
> > All my code is sourced from files except for the driver.  The driver
> > code is in the same file that defines totalEffect.all.
> 
> I don't understand this.  If totalEffect.all is in a file that is not 
> sourced, where did it come from?
totalEffect is sourced; by "driver" I meant the surrounding code that
sets up dsim and simjob and calls totalEffect.
> 
> Generally the rule is that if you source a function from a file you'll 
> get line number information attached to it, so you should see a line 
> number reported when an error occurs, or during debugging.  There are 
> exceptions:  you can turn this off, and by default, it is turned off for 
> functions defined in packages (but you can turn it on if you re-install 
> from source).
I'm not in a package.

BTW, I encountered several more instances of the error--that is, from
different spots in the code--and never got a line number.

Ross
> 
> >
> > In this particular case I stepped through with the debugger and found
> > that in the  line
> > accums[[m]]$delta$accum(up - down, data)
> >
> > the delta object was NULL and so accum is not a function on it.  But I
> > hope there's a better way to locate an error.
> 
> If the line that triggered this error was in a function that had line 
> number information, it sounds like it might be a bug.  Can you simplify 
> it down to a simple reproducible example that I could look at?
> 
> Duncan Murdoch
>



From btyner at gmail.com  Fri Apr 25 03:17:37 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 24 Apr 2014 21:17:37 -0400
Subject: [R] detecting the sourcing of site profile on Startup versus
 post-Startup
In-Reply-To: <966edfaf-8898-431a-a7ac-ab5e63409e3d@email.android.com>
References: <5357108D.3040704@gmail.com> <53579C3A.1020106@gmail.com>
	<535864AD.5000706@gmail.com>
	<966edfaf-8898-431a-a7ac-ab5e63409e3d@email.android.com>
Message-ID: <5359B7B1.1070408@gmail.com>

Jeff,

I absolutely agree it is a bad idea to rely on side effects.

I did figure out one way to skin this cat. It relies on an the following
from line 909 of src/main/main.c,

    R_LoadProfile(R_OpenSiteFile(), baseEnv);
    R_LockBinding(install(".Library.site"), R_BaseEnv);
    R_LoadProfile(R_OpenInitFile(), R_GlobalEnv);

to illustrate, if one puts at the top of the site profile:

   if (bindingIsLocked(".Library.site", .BaseNamespaceEnv)) {
      # site profile has already finished loading;
      # put code here for that case. for example,
      if (identical(.BaseNamespaceEnv$.GoodJob, Sys.getpid())) {
          warning("you appear to be using the same file for both site
and user profiles, or to have sourced this file post-startup.")
      }
      warning("this file is not intended to be used in this fashion.")
   } else {
      # site profile is in process of loading;
      # put code here for that case. for example,
      message("good job! startup loaded the correct site profile.")
      .GoodJob <- Sys.getpid()
   }

Not exactly best practice to rely on an implementation detail, but I
found it interesting nevertheless.

Regards
Ben


On 04/23/2014 09:31 PM, Jeff Newmiller wrote:
> Regardless of whether this is possible, it seems like a bad idea (side effects in a functional programming environment). If you want to do something special in startup then write a different function that does that stuff and then call the desired functions explicitly when you want them to be called.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
>
> On April 23, 2014 6:11:09 PM PDT, Benjamin Tyner <btyner at gmail.com> wrote:
>> Thanks  Duncan!  Yes, I considered taking advantage of .First, but was
>> concerned that the .First defined by the site profile could be masked
>> by a
>> possible .First defined by the user profile (I neglected to mention
>> that
>> "--no-init-profile"  [sic]  in  the  example  I gave was a simplifying
>>   assumption, sorry about that).
>>   On 04/23/2014 06:55 AM, Duncan Murdoch wrote:
>>
>>     On 22/04/2014, 8:59 PM, Benjamin Tyner wrote:
>>
>>     Greetings,
>> Is there any way to programmatically detect whether a piece of code is
>>   being run within the initial (Startup) sourcing of the site profile?
>>   For example, say I have a site profile, "/path/to/Rprofile.site". Is
>>   there any function "my_func" which would return different values for
>>     these two instances:
>>         Rscript --no-site-profile --no-init-profile -e
>>    "sys.source('/path/to/Rprofile.site',  envir  = .BaseNamespaceEnv);
>>     my_func()"
>>     versus:
>>         export R_PROFILE=/path/to/Rprofile.site
>>         Rscript --no-init-profile -e "my_func()"
>>
>> The commandArgs() function could see the different command lines and
>> your
>>     function could deduce the difference from that.
>> As far as I know, R keeps no other records of the startup process, but
>> if
>> you can modify other files, you could leave a record when .First was
>> run,
>>    and see that it was run before Rprofile.site in the first case. See
>>     ?Startup.
>>     Duncan Murdoch
>>
>>   --
>>   
>>
>>
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
//


From Raghu.Erapaneedi at mpi-muenster.mpg.de  Thu Apr 24 21:15:36 2014
From: Raghu.Erapaneedi at mpi-muenster.mpg.de (Raghu)
Date: Thu, 24 Apr 2014 21:15:36 +0200
Subject: [R] instal tar.gz package on windows
In-Reply-To: <53597397020000B20002AAB1@v-pgw-nlx2.p.nwu.ac.za>
References: <53597397020000B20002AAB1@v-pgw-nlx2.p.nwu.ac.za>
Message-ID: <535962D8.9070104@mpi-muenster.mpg.de>

The discussion in the forum solves your issue

http://stackoverflow.com/questions/1474081/how-do-i-install-an-r-package-from-source

Raghu

On Thu 24 Apr 2014 08:26:33 PM CEST, KD Makatjane wrote:
> Good evening sir/madam
> My name is katleho makatjane. I am currently a B.com statistics student at North West University Mafikeng campus.  I have installed R 3.1.0 on my laptop but my main problem is to install all necessary packages so that I may be able to start using it for my analysis. It gives me error while trying to install them from downloaded files. And again it can connect to the internet to download them automatically. Can you please help me out on how to install the R packages. I am using a 32bit windows 7 ultimate operating system
>
> Yours faithfully
>
> Katleho Makatjane
> North West University
> Mafikeng Campus
> Department of Statistics and Economics
> Contact: +27734630271
>
>
> Vrywaringsklousule / Disclaimer:  http://www.nwu.ac.za/it/gov-man/disclaimer.html
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
--
Raghu Erapaneedi
Max Planck Institute for Molecular Biomedicine
Mammalian Cell Signalling Laboratory
Department of Vascular Cell Biology
Roentgenstr-20
D-48149 Muenster
Germany
Tel:+49(0)251-70365-223



From jjw3952 at rit.edu  Thu Apr 24 21:27:35 2014
From: jjw3952 at rit.edu (Jacob Warren (RIT Student))
Date: Thu, 24 Apr 2014 15:27:35 -0400
Subject: [R] LogLikelihood of a Distribution Given Fixed Parameters
Message-ID: <CADqzGTsbAr+4Z2P79PQ9f=iB+FHuo3ppGpUDZzi2jy979XFgcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140424/5afc4def/attachment-0001.pl>

From c_millan.01 at hotmail.com  Fri Apr 25 03:40:58 2014
From: c_millan.01 at hotmail.com (christian millan)
Date: Fri, 25 Apr 2014 01:40:58 +0000
Subject: [R] HELP with fonts
Message-ID: <BLU181-W933F0CD514CB68D3B2D7FBD75A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/b3b116dc/attachment-0001.pl>

From r.turner at auckland.ac.nz  Fri Apr 25 06:50:28 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 25 Apr 2014 16:50:28 +1200
Subject: [R] LogLikelihood of a Distribution Given Fixed Parameters
In-Reply-To: <CADqzGTsbAr+4Z2P79PQ9f=iB+FHuo3ppGpUDZzi2jy979XFgcw@mail.gmail.com>
References: <CADqzGTsbAr+4Z2P79PQ9f=iB+FHuo3ppGpUDZzi2jy979XFgcw@mail.gmail.com>
Message-ID: <5359E994.9070601@auckland.ac.nz>


As usual I am too lazy to fight my way through the rather convoluted 
code presented, but it seems to me that you just want to calculate a log 
likelihood.  And that is bog-simple:

The log likelihood for i.i.d. data is just the sum of log f(y_i) where 
the y_i are your observed values and f() is the density function of the 
distribution that you have in mind.

Where there is (right) censoring you take the sum of log f(y_i) over all
the non-censored values and then add k*(1-F(cens.time)) where k is the 
number of censored values and F() is the cumulative distribution 
function corresponding to f().

In your case it would appear that f(y) = dlnorm(y,1.66,0.25) and
F(y) = plnorm(y,1.66,0.25).  Note that instead of using 1-F(cens.time) 
you can use plnorm(cens.time,1.66,0.25,lower=TRUE) and that instead of 
taking logs explicitly you can set log=TRUE in the calls to dlnorm() and 
plnorm().

cheers,

Rolf Turner

On 25/04/14 07:27, Jacob Warren (RIT Student) wrote:
> I'm trying to figure out if there is a way in R to get the loglikelihood of
> a distribution fit to a set of data where the parameter values are fixed.
> For example, I want to simulate data from a given alternate lognormal
> distribution and then I will fit it to a lognormal distribution with null
> parameter values to see what the likelihood of the null distribution is
> given random data from the alternate distribution.
>
> I have been using fitdistrplus for other purposes but I cannot use it to
> fix both parameter values.
>
> Here is an example of what I've been working with...
>
> nullmu<-1.66 #set null mu
> altmu<-1.58 #set alt mu
> sd.log<-0.25 #set common sigma
> cens.time<-6 #if simulated times are greater than this turn them into right
> censored times
>
> #simulating lognormal data (time) from altnative dist
> (sim<-rlnorm(n=samplesize, meanlog=altmu, sdlog=sd.log))
> #if the time was > cens.time replace time with cens.time
> (sim[which(sim>cens.time)]<-cens.time)
> sim
>
> #create a variable indicating censoring
> (cens<-sim)
> cens[which(sim==cens.time)]<-NA
> cens
>
> #create the data frame to be passed to fitdistcens and fitdist
> (x<-data.frame(left=sim,right=cens))
>
>
> #if there is censored data use fitdistcens else use fitdist
> ifelse(length(which(is.na(cens)))>0,
> simfit<-fitdistcens(censdata=x, distr="lnorm"),
> simfit<-fitdist(data=x[,1], distr="lnorm")
> )
>
> #Now I can get the loglikelihood of the MLE fitted distribution
> simfit$loglik
>
> #I want to get the loglikelihood of the distribution with the null
> parameterization
> #This is what I can't get to work
> #I can't seem to find any function that allows me to set both parameter
> values
> #so I can get to loglikelihood of the of the parameterization given the data
> nulldist<-fitdistcens(censdata=x, distr="lnorm", start=list(meanlog=nullmu,
> sdlog=sd.log)
>
> #Then I want to do a likelihood ratio test between the two distributions
> pchisq((-2*simfit$loglik--2*nulldist$loglik), df=2, lower.tail=FALSE)



From ripley at stats.ox.ac.uk  Fri Apr 25 08:23:38 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2014 07:23:38 +0100
Subject: [R] R dataset copyrights
In-Reply-To: <CAFEqCdxXi0jo5BCa0f8NwkYHig-RneirKeDjMhOg1WFkmJUK-g@mail.gmail.com>
References: <5356A701.3050901@gmail.com>
	<CAFEqCdxXi0jo5BCa0f8NwkYHig-RneirKeDjMhOg1WFkmJUK-g@mail.gmail.com>
Message-ID: <5359FF6A.1090509@stats.ox.ac.uk>

On 24/04/2014 22:33, Greg Snow wrote:
> Many, probably even most (but I have not checked) of the datasets
> available in R packages have help files with a references section.
> That section should lead you to an original source that may have the
> copyright information and is what should be referenced.
>
> My understanding (but I am not a lawyer, do not play one on TV, or
> claim to be any type of legal expert) is that you cannot copyright
> facts, but you can copyright the layout and presentation of facts.  So
> real data about the real world cannot be copyrighted, but the layout
> and presentation can be.  So if you photocopy a page from a journal
> and post that you may be in trouble for copying and distributing the
> layout and presentation of the data, but not the data itself.  But if
> you transform the numbers to a file to be read by the computer then
> you have just copied the facts which are not copyrighted.

You most likely also copied the layout (which numbers/strings are in 
which rows ...).  There are legal precedents involving telephone 
directories, for example.

There was a May 2007 thread about this: see 
https://stat.ethz.ch/pipermail/r-help/2007-May/131780.html and replies.

>
> On the other hand simulated or otherwise made up datasets could be
> considered to be fiction and therefore able to be copyrighted.  I
> remember hearing (but I don't remember where or when) that some
> textbook authors are encouraged to use simulated data instead of real
> data (it can have the same mean, sd, etc. as a real dataset so the
> interpretation is the same) in textbooks so that the copyright of the
> textbook also applies to the data.  It is not always clear whether a
> dataset is fact or simulated, so it is best to obtain permission or
> check official statements from the source.
>
> Beyond what is legal you should consider what is right.  Even if you
> don't have to cite a data source, you should try to give credit where
> it is due (and possibly blame if there is an error).  At a minimum you
> should cite original sources when they can be found and also mention
> where you obtained the data if not from the original source.  Think of
> the effort that people went through to collect the data and make it
> available to you, how would you feel if you put that much effort into
> something then someone else stole the credit or other rewards.  Many
> data sources have statements on how the data can be used and it is
> best to follow those instructions/requests, is it really that hard to
> add a reference to where the data came from and how you obtained it?
>
> In some educational cases it may be better to initially hide the
> source of the data, for example the outliers dataset in the
> TeachingDemos package would be a lot less useful for its intended
> purposes if students were to read its help page before analyzing it,
> therefore I have no problem with teachers using it without telling
> students where it came from (and since it is simulated I could
> possibly claim copyright), though I would appreciate a mention after
> the fact (once the lesson is learned the teacher could say "by the
> way, this data came from ...") and I expect that others would feel
> similarly (I should add a note to that effect to the documentation
> page).  But you should check the sources to see if this is
> specifically allowed or disallowed.
>
> I probably have not fully answered your question, but hopefully this
> gives a little more guidance.
>
> On Tue, Apr 22, 2014 at 11:29 AM, Soeren Groettrup
> <soeren.groettrup at gmail.com> wrote:
>> Hi everybody,
>>
>> I've been searching the web for quite a time now and haven't found a
>> satisfying answer. I was wondering if the datasets provided within the R
>> packages are open, and thus can be used in publications? Concretely, can the
>> data, for example, be exported from R and uploaded in a different format
>> (like csv) to a website to be accessible for students to work with the data
>> in SPSS or Matlab? Is it enough to cite the source or paper or do I need a
>> permission for every dataset?
>>
>> Thanks in advance for your replies,
>> S?ren Gr?ttrup
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stefanML at collocations.de  Fri Apr 25 09:09:31 2014
From: stefanML at collocations.de (Stefan Evert)
Date: Fri, 25 Apr 2014 09:09:31 +0200
Subject: [R] Fast way to populate a sparse matrix
In-Reply-To: <CAFEqCdz3n1wOg6B7g401QTT+ciiPNi0FR_4fLmy0v_D-yUVHcQ@mail.gmail.com>
References: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>
	<CAFEqCdz3n1wOg6B7g401QTT+ciiPNi0FR_4fLmy0v_D-yUVHcQ@mail.gmail.com>
Message-ID: <B4FDB139-2EB9-4559-903D-503EC8A93E46@collocations.de>


On 24 Apr 2014, at 23:56, Greg Snow <538280 at gmail.com> wrote:

> library(Matrix)
> 
> adjM <- Matrix(0,nrow=10,ncol=10)
> 
> locs <- cbind( sample(1:10), sample(1:10) )
> vals <- rnorm(10)
> 
> adjM[ locs ] <- vals

... and once you've got your data in this format, why not construct the sparse matrix directly?

	adjM <- sparseMatrix(i = locs[,1], j = locs[,2], x = vals)

I've found this to be very efficient and have used it with sparse matrices containing up to around 100 million nonzero entries.

Hope this helps,
Stefan


From maechler at stat.math.ethz.ch  Fri Apr 25 10:20:45 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 25 Apr 2014 10:20:45 +0200
Subject: [R] Fast way to populate a sparse matrix
In-Reply-To: <B4FDB139-2EB9-4559-903D-503EC8A93E46@collocations.de>
References: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>
	<CAFEqCdz3n1wOg6B7g401QTT+ciiPNi0FR_4fLmy0v_D-yUVHcQ@mail.gmail.com>
	<B4FDB139-2EB9-4559-903D-503EC8A93E46@collocations.de>
Message-ID: <21338.6877.979103.626514@stat.math.ethz.ch>

>>>>> Stefan Evert <stefanML at collocations.de>
>>>>>     on Fri, 25 Apr 2014 09:09:31 +0200 writes:

    > On 24 Apr 2014, at 23:56, Greg Snow <538280 at gmail.com> wrote:

    >> library(Matrix)
    >> 
    >> adjM <- Matrix(0,nrow=10,ncol=10)
    >> 
    >> locs <- cbind( sample(1:10), sample(1:10) )
    >> vals <- rnorm(10)
    >> 
    >> adjM[ locs ] <- vals

    > ... and once you've got your data in this format, why not construct the sparse matrix directly?

    > adjM <- sparseMatrix(i = locs[,1], j = locs[,2], x = vals)

    > I've found this to be very efficient and have used it with sparse matrices containing up to around 100 million nonzero entries.

Yes, indeed,  thank you Stefan!

Let me reiterate :

__  Unless you can use special constructors such as  
__
__   Diagonal()      # diagonal matrices
__   bdiag()         # block diagonal matrices
__   bandSparse()    # "banded diagonal" matrices
__   kronecker(a, b) # where a or b are sparse
__
__   (and maybe another one I forgot)
__
__  *the* way to efficiently construct large sparse matrices is
__    sparseMatrix()
__    or sometimes its alternative / precursor  spMatrix().
__
__    Matrix(d, ...., sparse=TRUE)
__
__  is nice and fine only for relatively *small* matrices,
__  as it really works from a dense original 'd' (directly or via replication)


    > Hope this helps,

I do hope, too.
I'm very happy for suggestions on  how  we as Matrix authors
could make this better known.

Recently, someone proposed to make the 'rsparseMatrix()'
utility function from  help(sparseMatrix)
into an "official" Matrix package function.  If I did that,
I could start using  rsparseMatrix() in typical examples rather
than the current often use of  Matrix()  or
as(<traditional matrix>, "sparseMatrix")
both of which are perfect for the small examples that are
typical for help files.

Martin Maechler,
ETH Zurich



From sergio.fonda99 at gmail.com  Fri Apr 25 11:17:44 2014
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Fri, 25 Apr 2014 11:17:44 +0200
Subject: [R] Unbalanced manova
In-Reply-To: <CAJRuHoq31tVOSt_-46vrmAd=E91QE4WGeJLRv84e7aka_ok=5g@mail.gmail.com>
References: <CAJRuHoq31tVOSt_-46vrmAd=E91QE4WGeJLRv84e7aka_ok=5g@mail.gmail.com>
Message-ID: <CAJRuHopHvLcm56gB=ZMJnjhtLfAgja63pPvfZ0ZzxBB1AWcG6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/8cc8cebe/attachment-0001.pl>

From careyshan at gmail.com  Fri Apr 25 12:26:03 2014
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 25 Apr 2014 11:26:03 +0100
Subject: [R] Linear line on pairs plot
Message-ID: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/f6db9c77/attachment-0001.pl>

From frtog at vestas.com  Fri Apr 25 12:57:50 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 25 Apr 2014 12:57:50 +0200
Subject: [R] Linear line on pairs plot
In-Reply-To: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>

Hi

Have a look on how panel.smooth is defined:

panel.smooth
function (x, y, col = par("col"), bg = NA, pch = par("pch"), 
    cex = 1, col.smooth = "red", span = 2/3, iter = 3, ...) 
{
    points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok <- is.finite(x) & is.finite(y)
    if (any(ok)) 
        lines(stats::lowess(x[ok], y[ok], f = span, iter = iter), 
            col = col.smooth, ...)
}
<bytecode: 0x000000000bfb2ce0>
<environment: namespace:graphics>


And change that to something like this:


panel.regression <- function (x, y, col = par("col"), bg = NA, pch = par("pch"), 
    cex = 1, col.regres = "red", ...) 
{
    points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok <- is.finite(x) & is.finite(y)
    if (any(ok)) 
        abline(stats::lm(y[ok] ~ x[ok]), col = col.regres, ...)
}


Substitute panel.smooth with panel.regression in your pairs.panel() function and you have it.



Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Shane Carey
> Sent: 25. april 2014 12:26
> To: r-help at r-project.org
> Subject: [R] Linear line on pairs plot
> 
> Hi,
> 
> Im trying to plot a linear line on the scatter plot using the pairs()
> function. At the moment the line is non linear. However, I want a linear
> line and the associated R value.
> 
> Here is my current code:
> 
> panel.cor.scale <- function(x, y, digits=2, prefix="", cex.cor)
> {
>   usr <- par("usr"); on.exit(par(usr))
>   par(usr = c(0, 1, 0, 1))
>   r = (cor(x, y,use="pairwise"))
>   txt <- format(c(r, 0.123456789), digits=digits)[1]
>   txt <- paste(prefix, txt, sep="")
>   if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
>   text(0.5, 0.5, txt, cex = cex * abs(r))
> }
> 
> 
> panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
> {
>   usr <- par("usr"); on.exit(par(usr))
>   par(usr = c(0, 1, 0, 1))
>   r = (cor(x, y,use="pairwise"))
>   txt <- format(c(r, 0.123456789), digits=digits)[1]
>   txt <- paste(prefix, txt, sep="")
>   if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
>   text(0.5, 0.5, txt, cex = cex )
> }
> 
> 
> panel.hist <- function(x, ...)
> {
>   usr <- par("usr"); on.exit(par(usr))
>   par(usr = c(usr[1:2], 0, 1.5) )
>   h <- hist(x, plot = FALSE)
>   breaks <- h$breaks; nB <- length(breaks)
>   y <- h$counts; y <- y/max(y)
>   rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
> }
> 
> 
> pairs.panels <- function (x,y,smooth=TRUE,scale=FALSE)
> {if (smooth ){
>   if (scale) {
> 
> pairs(x,diag.panel=panel.hist,upper.panel=panel.cor.scale,lower.panel=pane
> l.smooth)
>   }
>   else
> {pairs(x,diag.panel=panel.hist,upper.panel=panel.cor,lower.panel=panel.sm
> ooth)
>   } #else
> {pairs(x,diag.panel=panel.hist,upper.panel=panel.cor,lower.panel=panel.sm
> ooth)
> }
>  else #smooth is not true
>  { if (scale) {pairs(x,diag.panel=panel.hist,upper.panel=panel.cor.scale)
>  } else {pairs(x,diag.panel=panel.hist,upper.panel=panel.cor) }
>  } #end of else (smooth)
> } #end of function
> 
> pairs.panels(iris[1:4])
> 
> Thanks
> 
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From william108 at gmail.com  Fri Apr 25 13:06:01 2014
From: william108 at gmail.com (Bill)
Date: Fri, 25 Apr 2014 20:06:01 +0900
Subject: [R] why does it say all the cases are complete?
Message-ID: <CAJnbHt+XCtjQKjeHRxXd7VmcZbcSnW-WN9J8HahkvD2+cnPvWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/4b3c045f/attachment-0001.pl>

From careyshan at gmail.com  Fri Apr 25 13:14:00 2014
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 25 Apr 2014 12:14:00 +0100
Subject: [R] Linear line on pairs plot
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
Message-ID: <CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/e2cdba3a/attachment-0001.pl>

From info at aghmed.fsnet.co.uk  Fri Apr 25 13:21:48 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 25 Apr 2014 12:21:48 +0100
Subject: [R] Metafor: How to integrate effectsizes?
In-Reply-To: <CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.g
	mail.com>
References: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
	<CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.gmail.com>
Message-ID: <Zen-1WdeCc-0007OW-6m@smarthost01b.mail.zen.net.uk>

At 13:15 24/04/2014, Verena Weinbir wrote:
>Hello!
>
>I am using the metafor package for my master's thesis as an R-newbie. While
>calculating effectsizes from my dataset (mean values and
>standarddeviations) using "escalc" shouldn't be a problem (I hope ;-)), I
>wonder how I could at this point integrate additional studies, which only
>state conhens d (no information about mean value and sds available), to
>calculate an overall analysis.  I would be very grateful for your support!

You mean Cohen's d I think.

You will need some more information to enable you to calculate its 
standard error. Have a look at Rosenthal's chapter in
@book{cooper94,
    author = {Cooper, H and Hedges, L V},
    title = {A handbook of research synthesis},
    year = {1994},
    publisher = {Russell Sage},
    address = {New York},
    keywords = {meta-analysis}
}
(There is an updated edition)
This gives you more information about converting effect sizes and 
extracting them from unpromising beginnings.

It often requires some ingenuity to get the information you need so 
have a go and then get back here with more details if you run into problems


>Best regards,
>
>Verena
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From frtog at vestas.com  Fri Apr 25 13:24:48 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Fri, 25 Apr 2014 13:24:48 +0200
Subject: [R] Linear line on pairs plot
In-Reply-To: <CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
	<CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9DE@DKRDSEXC016.vestas.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/c2a71205/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Fri Apr 25 13:30:47 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 25 Apr 2014 11:30:47 +0000
Subject: [R] why does it say all the cases are complete?
In-Reply-To: <CAJnbHt+XCtjQKjeHRxXd7VmcZbcSnW-WN9J8HahkvD2+cnPvWg@mail.gmail.com>
References: <CAJnbHt+XCtjQKjeHRxXd7VmcZbcSnW-WN9J8HahkvD2+cnPvWg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A40831@inbomail.inbo.be>

You have no missing data. Note that the string "" is not missing! You need to code missings as NA. Have look at ?is.na

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Bill
Verzonden: vrijdag 25 april 2014 13:06
Aan: r-help at r-project.org
Onderwerp: [R] why does it say all the cases are complete?

Hi, Can someone explain why it says the cases are complete. It seems they are not.

head(x)
  rnum    Exam.Title Patient.ID  Age Sex Impression2
1    1 Temporal bone    3529243 009Y   M
2    2 Temporal bone    3529243 010Y   M
3    3          Head    3508570 002M   M
4    4        Sacrum    3494713 004D   F
5    5          Head    3471128 015M   F
6    6          Head    3494480 022M   M
  Impression3 AgeByYear Exposure      Reason   Result
1                     9        H
2                    10        H
3                     0        H   premature Negative
4                     0        P
5                     1        H     seizure negative
6                     1        H head trauma Negative
  Repeat Result.1
1      h        P
2     r1        P
3               N
4               P
5               N
6      h        N
> complete.cases(x[1:5,])
[1] TRUE TRUE TRUE TRUE TRUE
> class(x)
[1] "data.frame"
> str(x)
'data.frame': 978 obs. of  13 variables:
 $ rnum       : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Exam.Title : Factor w/ 75 levels "Abdomen","Abdomen (Post CE)",..: 74 74
21 68 21 21 21 21 2 3 ...
 $ Patient.ID : int  3529243 3529243 3508570 3494713 3471128 3494480
3494480 3553704 3295006 3295006 ...
 $ Age        : Factor w/ 53 levels "000Y","001D",..: 30 33 4 11 43 51 51
40 33 33 ...
 $ Sex        : Factor w/ 2 levels "F","M": 2 2 2 1 1 2 2 2 1 1 ...
 $ Impression2: Factor w/ 114 levels "","????","?????",..: 1 1 1 1 1 1 1 1
1 57 ...
 $ Impression3: Factor w/ 22 levels "","??","??????",..: 1 1 1 1 1 1 1 1 1
13 ...
 $ AgeByYear  : int  9 10 0 0 1 1 1 13 10 10 ...
 $ Exposure   : Factor w/ 27 levels "A","A 2","A P",..: 11 11 11 27 11 11
11 11 1 2 ...
 $ Reason     : Factor w/ 112 levels "","abnormal behavior, check",..: 1 1
80 1 87 36 36 36 1 1 ...
 $ Result     : Factor w/ 7 levels "","Inconclusive",..: 1 1 4 1 3 4 4 4 1
1 ...
 $ Repeat     : Factor w/ 13 levels "","h","r1","r10",..: 2 3 1 1 1 2 3 1 2
6 ...
 $ Result.1   : Factor w/ 2 levels "N","P": 2 2 1 2 1 1 1 1 2 2 ...
> mode(x)
[1] "list"

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.



From bt_jannis at yahoo.de  Fri Apr 25 13:36:00 2014
From: bt_jannis at yahoo.de (Jannis)
Date: Fri, 25 Apr 2014 13:36:00 +0200
Subject: [R] maximum size of dump.frames files?
Message-ID: <535A48A0.7070001@yahoo.de>

Hi R users,


is there any possibility that the file created by:

    dump.frames(dumpto = file.name, to.file = TRUE)

has any upper size limitations? I use the command above to debug R Code 
run on a cluster environment. Looking at the logs, I get an indication 
that an error occoured but the file with the dumped frames is not 
created. Instead, the process on the cluster seems to be halted. When 
running the same thing on smaller files (and probably hence smaller 
objects in the workspace) my mechanisms walks flawlessly with the 
dump.frames file saved.


Any ideas?


Jannis



From mohammed.ouassou at statkart.no  Fri Apr 25 13:40:31 2014
From: mohammed.ouassou at statkart.no (Mohammed Ouassou)
Date: Fri, 25 Apr 2014 13:40:31 +0200
Subject: [R] Cramer Rao upper/lower bounds- No Comments ?
Message-ID: <1398426031.3105.3.camel@localhost.localdomain>

Dear R users;

I have a question about Cramer Rao upper/lower bounds

Is it possible to compute Crammer Rao upper/lower bounds from residuals
and  corresponding covariance matrices ?


Any suggestions will be appreciated, thanks in advance.


M.O



From careyshan at gmail.com  Fri Apr 25 13:42:17 2014
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 25 Apr 2014 12:42:17 +0100
Subject: [R] Linear line on pairs plot
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9DE@DKRDSEXC016.vestas.net>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
	<CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9DE@DKRDSEXC016.vestas.net>
Message-ID: <CA+jRDxBgbSPT5Dq0wOXpnJ9Hhx3ir+cZ-RMU3nhU9Aq7GLywig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/40e1dc87/attachment-0001.pl>

From careyshan at gmail.com  Fri Apr 25 13:56:21 2014
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 25 Apr 2014 12:56:21 +0100
Subject: [R] Linear line on pairs plot
In-Reply-To: <CA+jRDxBgbSPT5Dq0wOXpnJ9Hhx3ir+cZ-RMU3nhU9Aq7GLywig@mail.gmail.com>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
	<CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9DE@DKRDSEXC016.vestas.net>
	<CA+jRDxBgbSPT5Dq0wOXpnJ9Hhx3ir+cZ-RMU3nhU9Aq7GLywig@mail.gmail.com>
Message-ID: <CA+jRDxCvMStpbsiDsbb7aNnLGyFyiOKXazG4sW70W48nsv1Wfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/e61ae899/attachment-0001.pl>

From careyshan at gmail.com  Fri Apr 25 13:57:05 2014
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 25 Apr 2014 12:57:05 +0100
Subject: [R] Linear line on pairs plot
In-Reply-To: <CA+jRDxCvMStpbsiDsbb7aNnLGyFyiOKXazG4sW70W48nsv1Wfg@mail.gmail.com>
References: <CA+jRDxDPmzAC-JB7Sq_GO_SUFW9HWa6v9Fqjar2AYYB00uSXGA@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9A8@DKRDSEXC016.vestas.net>
	<CA+jRDxA4=wezD-rMquYvZifiq1G40bQ5KWo75JwOj3WJeJi2GQ@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9E9DE@DKRDSEXC016.vestas.net>
	<CA+jRDxBgbSPT5Dq0wOXpnJ9Hhx3ir+cZ-RMU3nhU9Aq7GLywig@mail.gmail.com>
	<CA+jRDxCvMStpbsiDsbb7aNnLGyFyiOKXazG4sW70W48nsv1Wfg@mail.gmail.com>
Message-ID: <CA+jRDxAZsBpFkH+Vfv7x0nsb99iUVKMOOkV22NStuDZpMqu+3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/78a98ddf/attachment-0001.pl>

From jfox at mcmaster.ca  Fri Apr 25 14:43:30 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 25 Apr 2014 08:43:30 -0400
Subject: [R] Unbalanced manova
In-Reply-To: <CAJRuHopHvLcm56gB=ZMJnjhtLfAgja63pPvfZ0ZzxBB1AWcG6Q@mail.gmail.com>
References: <CAJRuHoq31tVOSt_-46vrmAd=E91QE4WGeJLRv84e7aka_ok=5g@mail.gmail.com>
	<CAJRuHopHvLcm56gB=ZMJnjhtLfAgja63pPvfZ0ZzxBB1AWcG6Q@mail.gmail.com>
Message-ID: <web-507333880@cgpsrv2.cis.mcmaster.ca>

Dear Sergio,

The Anova() function in the car package can perform MANOVA with a multivariate linear model fit to unbalanced data by lm() -- see the examples in ?Anova. I'm not sure what you mean by "avoiding NA values," however. With the default na.action, which is na.omit, lm() will perform a complete-case analysis, omitting cases with NA for any variable in the model.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


On Fri, 25 Apr 2014 11:17:44 +0200
 Sergio Fonda <sergio.fonda99 at gmail.com> wrote:
> Hello list,
> I would be very grateful if somebody could suggest me which kind of call
> may be used to perform a manova with unbalanced data avoiding NA values.
> Thanks a lot
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From sarah.goslee at gmail.com  Fri Apr 25 15:15:47 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 25 Apr 2014 09:15:47 -0400
Subject: [R] Unable to install rqpd
In-Reply-To: <1398396086.73743.YahooMailBasic@web124505.mail.ne1.yahoo.com>
References: <CAM_vjum48TFUdwRmfodkCxWrJBd6LB9dLgDTmpr+UahCuiZ_9w@mail.gmail.com>
	<1398396086.73743.YahooMailBasic@web124505.mail.ne1.yahoo.com>
Message-ID: <CAM_vjumXxg4Wyd2aCH=iD77-Hs-bF6V=Z2gaJt40TETzHA3GQA@mail.gmail.com>

Well, you could upgrade to the latest version of R, as the R-Forge
page states, "R-Forge provides these binaries only for the most recent
version of R, but not for older versions."

If there's no Windows binary, it' s possible that some necessary
requirement isn't available for Windows. You'll need to do some
further investigation on your own to find that out.

Please reply to the list, not just to me.

Sarah

On Thu, Apr 24, 2014 at 11:21 PM, Vishal Chari <vishal_c64 at yahoo.com> wrote:
>
> Hi,
>
> I have tried following command in R 3.0.1 and R.2.14 on windows 7 'install.packages("rqpd",repos="http://R-Forge.R-project.org")'
> I got  following two messages:
>
> i) package ?rqpd? is available as a source package but not as a binary
> ii) package ?rqpd? is not available (for R version 3.0.1) same for (R 2.1.4)
> So I tried installing zip file from  this site http://r-forge.r-project.org/R/?group_id=1082
> On this site Linux file can be downloaded but Windows file is missing. Message HTTP 404 not found
> Please help
> Thanks for prompt reply
>
> Regards
> vishal
>
> --------------------------------------------
> On Thu, 4/24/14, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
>  Subject: Re: [R] Unable to install rqpd
>  To: "Vishal Chari" <vishal_c64 at yahoo.com>
>  Cc: "r-help" <r-help at r-project.org>
>  Date: Thursday, April 24, 2014, 3:22 PM
>
>  How did you try to install the
>  package?
>  What happens when you try?
>  What operating system are you using?
>  What version of R are you using?
>
>  Did you try Google, and read any of the other discussions of
>  how to
>  install rqpd?
>  Did you read the posting guide (linked at bottom of this and
>  every
>  message) and provide the necessary background information?
>
>  Sarah
>
>  On Thu, Apr 24, 2014 at 7:04 AM, Vishal Chari <vishal_c64 at yahoo.com>
>  wrote:
>  > Hello,
>  >
>  >  I am unable to install package rqpd. I have also
>  tried to download for source but not able to do so.
>  > Please help
>  >
>  > thank in advance
>  > regards
>  > vishal
>  >
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From kmersman at smail.uni-koeln.de  Fri Apr 25 15:52:54 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Fri, 25 Apr 2014 15:52:54 +0200
Subject: [R] purtest and missing values (plm-package)
Message-ID: <000301cf608d$a8672160$f9356420$@uni-koeln.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/92820731/attachment-0001.pl>

From info at aghmed.fsnet.co.uk  Fri Apr 25 16:22:50 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 25 Apr 2014 15:22:50 +0100
Subject: [R] Metafor: How to integrate effectsizes?
In-Reply-To: <CAMuCtg7Xsvypi48xjAPGePZsTKOf7dz4Y2w1Px1OCf7p7FNKDg@mail.g
	mail.com>
References: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
	<CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.gmail.com>
	<Zen-1WdeCc-0007OW-6m@smarthost01b.mail.zen.net.uk>
	<CAMuCtg7Xsvypi48xjAPGePZsTKOf7dz4Y2w1Px1OCf7p7FNKDg@mail.gmail.com>
Message-ID: <Zen-1Wdh1f-000AIS-Ux@smarthost01c.mail.zen.net.uk>

At 12:33 25/04/2014, you wrote:
>Thank you very much for your reply and the book recommendation, Michael.
>
>Yes, I mean Cohen's d - sorry for the typo :-)
>
>Just to make this sure for me: There is no 
>possibility to integrate stated Cohens' ds in an 
>R-Metaanalysis (or a MA at all), if there is no 
>further information traceable regarding SE or the like?

If there is really no other information like 
sample sizes, significance level, value of some 
significance test then you would have to impute a 
value from somewhere. That would seem a last resort.

I have cc'ed this back to the list, please keep 
it on the list so others may benefit and contribute.


>best regards,
>
>Verena
>
>
>On Fri, Apr 25, 2014 at 1:21 PM, Michael Dewey 
><<mailto:info at aghmed.fsnet.co.uk>info at aghmed.fsnet.co.uk> wrote:
>At 13:15 24/04/2014, Verena Weinbir wrote:
>Hello!
>
>I am using the metafor package for my master's thesis as an R-newbie. While
>calculating effectsizes from my dataset (mean values and
>standarddeviations) using "escalc" shouldn't be a problem (I hope ;-)), I
>wonder how I could at this point integrate additional studies, which only
>state conhens d (no information about mean value and sds available), to
>calculate an overall analysis. ? I would be very grateful for your support!
>
>
>You mean Cohen's d I think.
>
>You will need some more information to enable 
>you to calculate its standard error. Have a look at Rosenthal's chapter in
>@book{cooper94,
>?  ? author = {Cooper, H and Hedges, L V},
>?  ? title = {A handbook of research synthesis},
>?  ? year = {1994},
>?  ? publisher = {Russell Sage},
>?  ? address = {New York},
>?  ? keywords = {meta-analysis}
>}
>(There is an updated edition)
>This gives you more information about converting 
>effect sizes and extracting them from unpromising beginnings.
>
>It often requires some ingenuity to get the 
>information you need so have a go and then get 
>back here with more details if you run into problems
>
>
>Best regards,
>
>Verena
>
>?  ?  ?  ?  [[alternative HTML version deleted]]
>
>
>Michael Dewey
><mailto:info at aghmed.fsnet.co.uk>info at aghmed.fsnet.co.uk
>http://www.aghmed.fsnet.co.uk/home.html
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From kmersman at smail.uni-koeln.de  Fri Apr 25 16:46:30 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Fri, 25 Apr 2014 16:46:30 +0200
Subject: [R] purtest and missing values (plm-package)
In-Reply-To: <000301cf608d$a8672160$f9356420$@uni-koeln.de>
References: <000301cf608d$a8672160$f9356420$@uni-koeln.de>
Message-ID: <001a01cf6095$256fc7f0$704f57d0$@uni-koeln.de>

Because, my inbox shows a "cutted-email-version", once again:

Hello R-Community,

I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.
Now I want to run different unit-root tests.

For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )

Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu ?test and Im, Pesaran & Shin-test ) for which I use the purtest function, from plm-package.
But I don?t know how to apply it, if my series contains missing values ( so only a error-message is created)

> purtest(data.plm,data=data.plm, test = "levinlin",exo = "none",lags ="SIC")
Fehler in lm.fit(X, y) : NA/NaN/Inf in 'x'
Zus?tzlich: Warnmeldung:
In Ops.factor(object[2:length(object)], object[1:(length(object) -  :
  - not meaningful for factors

So my Question is:
1.	Is there a way to handle the missing values? 
2.	Do I just omit them? And if, is there a way to integrate this by adding an ? na.omit? into the function ?


To make it easier explaining the way of proceeding, a reproducible example could be:

data("Grunfeld", package = "plm")
y <- data.frame(split(Grunfeld$inv, Grunfeld$firm))
purtest(y, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # works no missing data

# add an NA

data("Grunfeld", package = "plm") 
x <?data.frame(split(Grunfeldinv, Grunfeld$firm))
Grunfeldinv[2]<?NA
purtest(x, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # Error in lm.fit(X, x) : NA/NaN/Inf in 'x'

Thanks for your hints and suggestions! 
Katie


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Katharina Mersmann
Gesendet: Freitag, 25. April 2014 15:53
An: r-help at r-project.org
Betreff: [R] purtest and missing values (plm-package)

Hello R-Community,

 

I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.

Now I want to run different unit-root tests.

 

For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )

 

Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu b



From smartpink111 at yahoo.com  Fri Apr 25 18:01:27 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 25 Apr 2014 09:01:27 -0700 (PDT)
Subject: [R] purtest and missing values (plm-package)
In-Reply-To: <001a01cf6095$256fc7f0$704f57d0$@uni-koeln.de>
References: <000301cf608d$a8672160$f9356420$@uni-koeln.de>
	<001a01cf6095$256fc7f0$704f57d0$@uni-koeln.de>
Message-ID: <1398441687.26108.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

May be this helps:
library(plm)
data(Grunfeld)
?Grunfeld$inv[c(2,8)] <- NA
?GrunfeldNew <- subset(Grunfeld, !year %in% year[is.na(inv)])

x <- data.frame(split(GrunfeldNew$inv, GrunfeldNew$firm))
purtest(x, pmax = 4, exo = "none", test = "levinlin",lags="SIC")
#??? Levin-Lin-Chu Unit-Root Test (ex. var. : None )
#
#data:? x
#z.x1 = 5.0507, p-value = 4.402e-07
#alternative hypothesis: stationarity
#
#Warning message:
#In selectT(l, theTs) : the time serie is short


A.K.


On Friday, April 25, 2014 10:48 AM, Katharina Mersmann <kmersman at smail.uni-koeln.de> wrote:
Because, my inbox shows a "cutted-email-version", once again:

Hello R-Community,

I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.
Now I want to run different unit-root tests.

For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )

Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu ?test and Im, Pesaran & Shin-test ) for which I use the purtest function, from plm-package.
But I don?t know how to apply it, if my series contains missing values ( so only a error-message is created)

> purtest(data.plm,data=data.plm, test = "levinlin",exo = "none",lags ="SIC")
Fehler in lm.fit(X, y) : NA/NaN/Inf in 'x'
Zus?tzlich: Warnmeldung:
In Ops.factor(object[2:length(object)], object[1:(length(object) -? :
? - not meaningful for factors

So my Question is:
1.??? Is there a way to handle the missing values? 
2.??? Do I just omit them? And if, is there a way to integrate this by adding an ? na.omit? into the function ?


To make it easier explaining the way of proceeding, a reproducible example could be:

data("Grunfeld", package = "plm")
y <- data.frame(split(Grunfeld$inv, Grunfeld$firm))
purtest(y, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # works no missing data

# add an NA

data("Grunfeld", package = "plm") 
x <?data.frame(split(Grunfeldinv, Grunfeld$firm))
Grunfeldinv[2]<?NA
purtest(x, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # Error in lm.fit(X, x) : NA/NaN/Inf in 'x'

Thanks for your hints and suggestions! 
Katie


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Katharina Mersmann
Gesendet: Freitag, 25. April 2014 15:53
An: r-help at r-project.org
Betreff: [R] purtest and missing values (plm-package)

Hello R-Community,



I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.

Now I want to run different unit-root tests.



For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )



Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu b

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pensterfuzzer at yahoo.de  Fri Apr 25 18:17:36 2014
From: pensterfuzzer at yahoo.de (Werner W.)
Date: Fri, 25 Apr 2014 17:17:36 +0100
Subject: [R] Problem with new(er) R version's matrix package
Message-ID: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/22ab879c/attachment-0001.pl>

From dwinsemius at comcast.net  Fri Apr 25 19:36:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 25 Apr 2014 10:36:24 -0700
Subject: [R] HELP with fonts
In-Reply-To: <BLU181-W933F0CD514CB68D3B2D7FBD75A0@phx.gbl>
References: <BLU181-W933F0CD514CB68D3B2D7FBD75A0@phx.gbl>
Message-ID: <1F613012-2F25-4AEB-91AC-F867ED2DB53D@comcast.net>


On Apr 24, 2014, at 6:40 PM, christian millan wrote:

> Hi,I have been trying to make my axis fonts and axis labels fonts in bold even when the I write the right command. I writing font.lab=2, font.axis=2 but the bold fonts don't show up. Any help?

There are three different plotting systems in R. You should include full code with an example dataset. And you should post in plain text. And you should read the Posting Guide.

When I do this I see bold axis labels and bold tick labels.

 plot(1:10, font.lab=2, font.axis=2)


> Thanks!
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From liusiqi.nine at gmail.com  Fri Apr 25 19:58:30 2014
From: liusiqi.nine at gmail.com (Si Qi L.)
Date: Fri, 25 Apr 2014 18:58:30 +0100
Subject: [R] sensitivity and specificity
Message-ID: <CABmq+QX=HKZX3GOn36B_Nf=qsMT=uCOGxqhbJ-jHPWFsAGQb=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/2f38d26a/attachment-0001.pl>

From dwinsemius at comcast.net  Fri Apr 25 20:09:22 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 25 Apr 2014 11:09:22 -0700
Subject: [R] sensitivity and specificity
In-Reply-To: <CABmq+QX=HKZX3GOn36B_Nf=qsMT=uCOGxqhbJ-jHPWFsAGQb=A@mail.gmail.com>
References: <CABmq+QX=HKZX3GOn36B_Nf=qsMT=uCOGxqhbJ-jHPWFsAGQb=A@mail.gmail.com>
Message-ID: <6C74279F-E5CC-4FBA-9D59-FE9931CE26D0@comcast.net>


On Apr 25, 2014, at 10:58 AM, Si Qi L. wrote:

> Hi guys,
> 
> I will be very grateful if you guys can do me a little favor on R. I am
> calculating the sensitivity and specificity for a 2*2 matrix, such as
> 
> t
>       0    1
>  0 1427  110
>  1  271  166
> 
> 
> 
> My codes are:   sens <- function(ct) { ct[2,2] / sum(ct[,2]) }
>                          spec <- function(ct) { ct[1,1] / sum(ct[,1]) }
> 
> But it doesn't show any numerical results.

What is the "it" that doesn't show any results? You show no code that uses these functions and you don't even include a reproducible example for `t`. 

(BTW using 't' as an object name may cause confusion since t() is a commonly used matrix function.


> Would you please help me to fix
> it? Mnay thanks for your help.:)
> 
> Best regards,
> 
> Siqi
> 
> 	[[alternative HTML version deleted]]

And please take the time to read the Posting Guide and learn to post in plain text as requested there.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From dwinsemius at comcast.net  Fri Apr 25 20:15:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 25 Apr 2014 11:15:25 -0700
Subject: [R] Problem with new(er) R version's matrix package
In-Reply-To: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>
References: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>
Message-ID: <0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>


On Apr 25, 2014, at 9:17 AM, Werner W. wrote:

> Dear Rs,
> 
> I am re-executing some older code. It does work in the ancient R 2.12.0 which I still have on my PC but with the new version R 3.1.0 it does not work any more (but some other new stuff, which won't work with 2.12).
> 
> The problem arises in context with the systemfit package using the matrix package. In R 3.1.0 the following error is thrown:
> Error in as.matrix(solve(W, tol = solvetol)[1:ncol(xMat), 1:ncol(xMat)]) : error in evaluating the argument 'x' in selecting a method for function 'as.matrix': Error in .solve.sparse.dgC(as(a, "dgCMatrix"), b = b, tol = tol) : LU computationally singular: ratio of extreme entries in |diag(U)| = 7.012e-39
> 
> However, I have no clue what I can do about this. Was there some change in the defaults of the matrix package? I couldn't find anything apparent in the changelog. As the same code works in R 2.12.0, I suppose that the problem is not my data.

You have not told us what version of the Matrix package you were using. As such I would suggest that you review the Changelog which is a link for the CRAN page for pkg:Matrix and go back 4 years or so since R major versions change about once a year.

http://cran.r-project.org/web/packages/Matrix/ChangeLog


> 
> If anyone has an idea about this, I would really appreciate your hints.
> 
> Thanks!
> Werner
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From macqueen1 at llnl.gov  Fri Apr 25 20:26:23 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 25 Apr 2014 18:26:23 +0000
Subject: [R] sensitivity and specificity
In-Reply-To: <CABmq+QX=HKZX3GOn36B_Nf=qsMT=uCOGxqhbJ-jHPWFsAGQb=A@mail.gmail.com>
References: <CABmq+QX=HKZX3GOn36B_Nf=qsMT=uCOGxqhbJ-jHPWFsAGQb=A@mail.gmail.com>
Message-ID: <CF7FF47B.F4BC5%macqueen1@llnl.gov>

Try this:

> sens <- function(ct) { ct[2,2] / sum(ct[,2]) }
> spec <- function(ct) { ct[1,1] / sum(ct[,1]) }
> 
> 
> myt <- matrix( c(1427,271,110,166), ncol=2)
> 
> sens(myt)
[1] 0.6014493
> 
> spec(myt)
[1] 0.8404005
>

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/25/14 10:58 AM, "Si Qi L." <liusiqi.nine at gmail.com> wrote:

>Hi guys,
>
>I will be very grateful if you guys can do me a little favor on R. I am
>calculating the sensitivity and specificity for a 2*2 matrix, such as
>
> t
>       0    1
>  0 1427  110
>  1  271  166
>
>
>
>My codes are:   sens <- function(ct) { ct[2,2] / sum(ct[,2]) }
>                          spec <- function(ct) { ct[1,1] / sum(ct[,1]) }
>
>But it doesn't show any numerical results. Would you please help me to fix
>it? Mnay thanks for your help.:)
>
>Best regards,
>
>Siqi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Apr 25 21:34:50 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 25 Apr 2014 21:34:50 +0200
Subject: [R] Metafor: How to integrate effectsizes?
In-Reply-To: <Zen-1Wdh1f-000AIS-Ux@smarthost01c.mail.zen.net.uk>
References: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
	<CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.gmail.com>
	<Zen-1WdeCc-0007OW-6m@smarthost01b.mail.zen.net.uk>
	<CAMuCtg7Xsvypi48xjAPGePZsTKOf7dz4Y2w1Px1OCf7p7FNKDg@mail.gmail.com>
	<Zen-1Wdh1f-000AIS-Ux@smarthost01c.mail.zen.net.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DAA4F3A14@UM-MAIL4112.unimaas.nl>

If you know the d-value and the corresponding group sizes for a study, then it's possible to add that study to the rest of the dataset. Also, if you only know the test statistic from an independent samples t-test (or only the p-value corresponding to that test), it's possible to back-compute what the standardized mean difference is.

I added an illustration of this to the metafor package website:

http://www.metafor-project.org/doku.php/tips:assembling_data_smd

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Friday, April 25, 2014 16:23
> To: Verena Weinbir
> Cc: r-help at r-project.org
> Subject: Re: [R] Metafor: How to integrate effectsizes?
> 
> At 12:33 25/04/2014, you wrote:
> >Thank you very much for your reply and the book recommendation, Michael.
> >
> >Yes, I mean Cohen's d - sorry for the typo :-)
> >
> >Just to make this sure for me: There is no
> >possibility to integrate stated Cohens' ds in an
> >R-Metaanalysis (or a MA at all), if there is no
> >further information traceable regarding SE or the like?
> 
> If there is really no other information like
> sample sizes, significance level, value of some
> significance test then you would have to impute a
> value from somewhere. That would seem a last resort.
> 
> I have cc'ed this back to the list, please keep
> it on the list so others may benefit and contribute.
> 
> 
> >best regards,
> >
> >Verena
> >
> >
> >On Fri, Apr 25, 2014 at 1:21 PM, Michael Dewey
> ><<mailto:info at aghmed.fsnet.co.uk>info at aghmed.fsnet.co.uk> wrote:
> >At 13:15 24/04/2014, Verena Weinbir wrote:
> >Hello!
> >
> >I am using the metafor package for my master's thesis as an R-newbie.
> While
> >calculating effectsizes from my dataset (mean values and
> >standarddeviations) using "escalc" shouldn't be a problem (I hope ;-)),
> I
> >wonder how I could at this point integrate additional studies, which
> only
> >state conhens d (no information about mean value and sds available), to
> >calculate an overall analysis. ? I would be very grateful for your
> support!
> >
> >
> >You mean Cohen's d I think.
> >
> >You will need some more information to enable
> >you to calculate its standard error. Have a look at Rosenthal's chapter
> in
> >@book{cooper94,
> >?  ? author = {Cooper, H and Hedges, L V},
> >?  ? title = {A handbook of research synthesis},
> >?  ? year = {1994},
> >?  ? publisher = {Russell Sage},
> >?  ? address = {New York},
> >?  ? keywords = {meta-analysis}
> >}
> >(There is an updated edition)
> >This gives you more information about converting
> >effect sizes and extracting them from unpromising beginnings.
> >
> >It often requires some ingenuity to get the
> >information you need so have a go and then get
> >back here with more details if you run into problems
> >
> >
> >Best regards,
> >
> >Verena



From Michael.Folkes at dfo-mpo.gc.ca  Fri Apr 25 21:49:48 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Fri, 25 Apr 2014 12:49:48 -0700
Subject: [R] mgcv::gam.check qq plot residuals are not standardized?
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00EE17E94@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/364f431d/attachment-0001.pl>

From s.wood at bath.ac.uk  Fri Apr 25 23:31:30 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 25 Apr 2014 22:31:30 +0100
Subject: [R] mgcv::gam.check qq plot residuals are not standardized?
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB00EE17E94@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB00EE17E94@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <535AD432.6020005@bath.ac.uk>

Hi Michael,

You seem to have a quite recent mgcv if you are using qq.gam, so a help 
file for version 1.3 is probably not going to be much help (gam.fit2 no 
longer exists, for example).

By default qq.gam plots deviance residuals (see ?qq.gam). So the default 
is standardization. When possible it then computes correct reference 
quantiles for these, assuming that the model is correct.

See...
http://www.sciencedirect.com/science/article/pii/S0167947312000692
for details (or http://opus.bath.ac.uk/27091/1/qq_gam_resub.pdf)

best,
Simon

On 25/04/14 20:49, Folkes, Michael wrote:
> Hello all,
>
> I looking for confirmation of what I'm seeing. The qq plot in gam.check
> and qq.gam is not standardizing the residuals.
>
> The current help doesn't suggest they're standardized.
>
> Somehow I found, online, a help for gam.check from  version [Package
> mgcv version 1.3-23 Index]:
>
> "If the fit method is based on magic or gam.fit2 then there is no global
> search and the problems with phantom local minima are much reduced. The
> first plot in this case will simply be a normal QQ plot of the
> standardized residuals."
>
>
>
> This text is absent from the current help file.
>
> If I'm correct, why is it that they aren't being standardized?
>
> Much appreciated.
>
> Michael
>
> _______________________________________________________
>
> Michael Folkes
>
> Salmon Stock Assessment
>
> Canadian Dept. of Fisheries & Oceans
>
> Pacific Biological Station
>
> 3190 Hammond Bay Rd.
>
> Nanaimo, B.C., Canada
>
> V9T-6N7
>
> Ph (250) 756-7264 Fax (250) 756-7053  Michael.Folkes at dfo-mpo.gc.ca
> <mailto:Michael.Folkes at dfo-mpo.gc.ca>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283



From fongchunchan at gmail.com  Sat Apr 26 02:26:17 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Fri, 25 Apr 2014 17:26:17 -0700
Subject: [R] Can't plot transparency images in R-3.1.0
Message-ID: <CAB-BZ9+vdBPcWJxHPDHD80p2x=Xfar3yLGjXAvkgtY5GRdunKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/001894b0/attachment-0001.pl>

From uma at sophie.unam.mx  Sat Apr 26 04:06:28 2014
From: uma at sophie.unam.mx (Ulises M. Alvarez)
Date: Fri, 25 Apr 2014 21:06:28 -0500
Subject: [R] Can't plot transparency images in R-3.1.0
In-Reply-To: <CAB-BZ9+vdBPcWJxHPDHD80p2x=Xfar3yLGjXAvkgtY5GRdunKA@mail.gmail.com>
References: <CAB-BZ9+vdBPcWJxHPDHD80p2x=Xfar3yLGjXAvkgtY5GRdunKA@mail.gmail.com>
Message-ID: <535B14A4.1060402@sophie.unam.mx>

On 04/25/2014 07:26 PM, Fong Chun Chan wrote:
> Hi all,
>
> I recently upgraded to R-3.1.0 from R-3.0.2. Things seem to be fine, but
> when trying to plot a ggplot image with transparency, I get the following
> issue:
>
> Warning message:
> In grid.Call.graphics(L_polygon, x$x, x$y, index) :
>    semi-transparency is not supported on this device: reported only once per
> page
>
> This only appears to affect my R-3.1.0 installation and not my R-3.0.2 as I
> can still plot normally with it. Has anyone else experienced this problem?
>
> Thanks,

Hi:

After the upgrade to 3.1.0, did you execute?

update.packages(checkBuilt=TRUE)

I did it, and I have no problem running the code that you provide.

sessionInfo()
# R version 3.1.0 (2014-04-10)
# Platform: x86_64-pc-linux-gnu (64-bit)
#
# locale:
#  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
#  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
#  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
#  [7] LC_PAPER=en_US.utf8       LC_NAME=C
#  [9] LC_ADDRESS=C              LC_TELEPHONE=C
# [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
#
# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods
# base
#
# other attached packages:
# [1] ggplot2_0.9.3.1
-- 
Ulises M. Alvarez
http://sophie.unam.mx/



From plessthanpointohfive at gmail.com  Sat Apr 26 04:42:29 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Fri, 25 Apr 2014 22:42:29 -0400
Subject: [R] Within ID variable delete all rows after reaching a specific
	value
Message-ID: <CAOxgQ=Unzh4BsU-P0AVJDU+pT6GZuP9uUH1zZvX45bXEL6HFNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/26f148e6/attachment-0001.pl>

From soracem at tcd.ie  Fri Apr 25 15:59:05 2014
From: soracem at tcd.ie (soracem)
Date: Fri, 25 Apr 2014 06:59:05 -0700 (PDT)
Subject: [R] ideal: object 'normalize' not found.
Message-ID: <1398434345784-4689459.post@n4.nabble.com>

Dear all, 
When I try to run IDEAL it gives me an error saying: Error in
ideal(mydatarc.working, codes = mydatarc.working$codes, dropList = list(lop
= 0),  : object 'normalize' not found. 
Below is what I did

require(pscl)
mydata<-read.csv(file.choose())
summary(mydata)
legNames<-mydata[,1]
pty1<-mydata[,2]
leg<-mydata[,3]
state<-mydata[,4]
const<-mydata[,5]

mydata <- mydata[, -c(1:5)]
summary(mydata)
mydatarc<-rollcall(mydata, yea=1, nay=0, missing=NA, notInLegis = 99,
legis.names=legNames, vote.names=NULL,
             legis.data=NULL , vote.data=NULL)
summary(mydatarc)
summary(mydatarc,verbose=TRUE)
summary(mydatarc,verbose=TRUE)$lopsided 

mydatarc.working <- dropRollCall(mydatarc,
                                 dropList=list(lop=0))
summary(mydatarc.working)

idealobject<- ideal (mydatarc.working, 
                     codes = mydatarc.working$codes,
                     dropList = list(lop=0),
                     d = 1, 
                     maxiter = 10000, 
                     thin = 100, 
                     burnin = 5000,
                     impute = FALSE,
                     mda = FALSE,
                     normalize = TRUE,
                     meanzero = normalize,
                     priors = NULL, 
                     startvals = "eigen",
                     store.item = TRUE, 
                     file = NULL,
                     verbose=FALSE)
what am I doing wrong?
Thanks for your help, 
Best,
Miriam



--
View this message in context: http://r.789695.n4.nabble.com/ideal-object-normalize-not-found-tp4689459.html
Sent from the R help mailing list archive at Nabble.com.



From carlosalvarezroa at hotmail.com  Fri Apr 25 14:28:58 2014
From: carlosalvarezroa at hotmail.com (CRoa)
Date: Fri, 25 Apr 2014 05:28:58 -0700 (PDT)
Subject: [R] Loops (run the same function per different columns)
In-Reply-To: <1398303959.35422.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1398064692015-4689171.post@n4.nabble.com>
	<1398086389.83374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1398303959.35422.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <DUB405-EAS292084BDB3D4F50F91E05B6C45A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/13822c72/attachment-0001.pl>

From bt_jannis at yahoo.de  Fri Apr 25 14:31:53 2014
From: bt_jannis at yahoo.de (Jannis)
Date: Fri, 25 Apr 2014 14:31:53 +0200
Subject: [R] access environment in which an error occoured
Message-ID: <535A55B9.5050101@yahoo.de>

Dear R users,


is there any way to access/print/save the content of an environment in 
which an error occoured? Image the following testcase:


test =  function() {
   b =  3
   plot(notavailable)
}


dump.frames.mod = function() {
    save(list=ls(parent.frame(1)), file='dummy.RData')
}
options(error = quote({dump.frames.mod()}))

test()

The call to plot() here would create an error in which case I would like 
to save the whole environment in which it occoured (in this case only 
the object b) to some file for later debugging. The way I tried to 
implement it above, only the content of the global environment is saved 
(probably because dump.frames.mod is called from this environment). Is 
there any way to save the content of the environment down in the stack 
where the error actually occoured? I know about the dump.frames() 
function which somehow does not work this case (see my earlier post: 
http://r.789695.n4.nabble.com/maximum-size-of-dump-frames-files-td4689444.html).


Thanks
Jannis



From tomassini at vetmed.wsu.edu  Fri Apr 25 20:04:39 2014
From: tomassini at vetmed.wsu.edu (Tomassini, Letizia)
Date: Fri, 25 Apr 2014 18:04:39 +0000
Subject: [R] partitioning around medoids
Message-ID: <3F4102760B8F244D898E18B27710D4448993BD61@CVM76.vetmed.wsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/3ab98da9/attachment-0001.pl>

From stephengmatthews at gmail.com  Fri Apr 25 21:00:28 2014
From: stephengmatthews at gmail.com (Stephen G Matthews)
Date: Fri, 25 Apr 2014 20:00:28 +0100
Subject: [R] error from hist() with POSIXt 00 seconds for breaks of secs,
 mins, hours, or day
Message-ID: <CAPAXk6WDXt85oHHGb3=oDTUS19wcvyS7eU2TG8Qjn2UdiWZHZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/443d4453/attachment-0001.pl>

From evan.cooch at gmail.com  Fri Apr 25 22:12:48 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 25 Apr 2014 16:12:48 -0400
Subject: [R] extrafont query | importing only 1 TTF
Message-ID: <535AC1C0.2030503@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140425/dcfb65bf/attachment-0001.pl>

From cjhon217 at gmail.com  Sat Apr 26 03:35:46 2014
From: cjhon217 at gmail.com (chris Jhon)
Date: Sat, 26 Apr 2014 10:35:46 +0900
Subject: [R] about rect.hclust
Message-ID: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/fc547890/attachment-0001.pl>

From jim at bitwrit.com.au  Sat Apr 26 06:03:46 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 26 Apr 2014 14:03:46 +1000
Subject: [R] Within ID variable delete all rows after reaching a
 specific value
In-Reply-To: <CAOxgQ=Unzh4BsU-P0AVJDU+pT6GZuP9uUH1zZvX45bXEL6HFNA@mail.gmail.com>
References: <CAOxgQ=Unzh4BsU-P0AVJDU+pT6GZuP9uUH1zZvX45bXEL6HFNA@mail.gmail.com>
Message-ID: <535B3022.9080207@bitwrit.com.au>

On 04/26/2014 12:42 PM, Jennifer Sabatier wrote:
> So, I know that's a confusing Subject header.
>
> Here's similar data:
>
>
> tmp<- data.frame(matrix(
>                          c(rbinom(1000, 1, .03),
>                            array(1:127, c(1000,1)),
>                            array(format(seq(ISOdate(1990,1,1), by='month',
> length=56), format='%d.%m.%Y'), c(1000,1))),
>                          ncol=3))
> tmp<- tmp[with(tmp, order(X2, X3)), ]
> table(tmp$X1)
>
>
> X1 is the variable of interest - disease status.  It's a survival-type of
> variable, where you are 0 until you become 1.
> X2 is the person ID variable.
> X3 is the clinic date (here it's monthly, just for example...but in my real
> data it's a bit more complicated - definitely not equally spaced nor the
> same number of visits to the clinic per ID.).
>
> Some people stay X1 = 0 for all clinic visits.  Only a small proportion
> become X1=1.
>
> However, the data has errors I need to clean off.  Once someone becomes
> X1=1 they should have no more rows in the dataset.  These are data entry
> errors.
>
> In my data I have people who continue to have rows in the data.  Sometimes
> the rows show X1=0 and sometimes X1=1.  Sometimes there's just one more row
> and sometimes there are many more rows.
>
> How can I go through, find the first X1 = 1, and then delete any rows after
> that, for each value of X2?
>
> Thanks!
>
> Jen
>
Hi Jen,
This might do what you want:

tmp$X3<-as.Date(tmp$X3,"%d.%m.%Y")
tmp<-tmp[order(tmp$X2,tmp$X3),]
first<-TRUE
for(patno in unique(tmp$X2)) {
  cat(patno,"\n")
  tmpbit<-tmp[tmp$X2 == patno,]
  firstone<-which(tmpbit$X1 == 1)[1]
  cat(firstone,"\n")
  if(is.na(firstone)) firstone<-dim(tmpbit)[1]
  newtmpbit<-tmpbit[1:firstone,]
  if(first) {
   newtmp<-newtmpbit
   first<-FALSE
  }
  else newtmp<-rbind(newtmp,newtmpbit)
}

Jim



From peter.langfelder at gmail.com  Sat Apr 26 06:53:08 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 25 Apr 2014 21:53:08 -0700
Subject: [R] about rect.hclust
In-Reply-To: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
References: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
Message-ID: <CA+hbrhXMmYP_WyUMh2k3EUZWhaGi3FcDEcRCPZB1EexcQK=FNQ@mail.gmail.com>

On Fri, Apr 25, 2014 at 6:35 PM, chris Jhon <cjhon217 at gmail.com> wrote:
> Hi,
>
> I am  using hclust and cutree to cluster a data frame y and cut it into few
> clusters as follows
>
> y
>   V1 V2 V3 V4
> A  1  2  3  4
> B  5  6  7  8
> C  9 10 11 12
> D 13 14 15 16
> E 17 18 19 20
>> clu<-hclust(dist(y),method="complete")
>  clu<-hclust(dist(y),method="complete")
>> clu
> Call:
> hclust(d = dist(y), method = "complete")
> Cluster method   : complete
> Distance         : euclidean
> Number of objects: 5
>> plot(clu)
>> ct<-cutree(clu,k=3)
>> rect.hclust(clu,3,border="red")
>> ct
> A B C D E
> 1 1 2 2 3
> The question is how to plot the cluster number on the dendrogram plot?

Package WGCNA (which I maintain) contains the function
plotDendroAndColors that allows you to indicate (multiple) clusters
under a dendrogram by colors, for example as in this image:

http://labs.genetics.ucla.edu/horvath/CoexpressionNetwork/BranchCutting/Example-Dendrogram-10.png

In the simplest use, you could call it as

plotDendroAndColors(clu, ct, "Clusters", main = "My clusters")

It will show cluster 1 as black, 2 as red etc. If you have more
clusters than colors in the standard pallette (which only contains 8
different colors), you can use

plotDendroAndColors(clu, labels2colors(ct), "Clusters", main = "My clusters")

Function labels2colors converts integer numeric labels to discrete
colors; the color sequence used by labels2colors can be seen by typing

standardColors()

Hope this helps,

Peter



From jefferis at gmail.com  Sat Apr 26 07:41:19 2014
From: jefferis at gmail.com (Gregory Jefferis)
Date: Sat, 26 Apr 2014 06:41:19 +0100
Subject: [R] about rect.hclust
In-Reply-To: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
References: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
Message-ID: <044B2E98-D191-47C7-BB00-B8361DFDEA53@gmail.com>

On 26 Apr 2014, at 02:35, chris Jhon <cjhon217 at gmail.com> wrote:

> The question is how to plot the cluster number on the dendrogram plot?

Besides Peter Langfelder?s suggestion, you may also want to take a look at CRAN packages dendroextras or dendextend

For example using the dendro	extras

# set up your data
##
y=read.table(text=" V1 V2 V3 V4
A  1  2  3  4
B  5  6  7  8
C  9 10 11 12
D 13 14 15 16
E 17 18 19 20",header=T)
clu<-hclust(dist(y),method="complete")
plot(clu)

# plot dendrogram coloured by cluster:
##
library(dendroextras)
cluc=colour_clusters(clu, k=3, labels=TRUE)
plot(cluc)

Best wishes,

Greg Jefferis.



From arne.henningsen at gmail.com  Sat Apr 26 08:15:37 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sat, 26 Apr 2014 08:15:37 +0200
Subject: [R] Problem with new(er) R version's matrix package
In-Reply-To: <0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>
References: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>
	<0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>
Message-ID: <CAMTWbJhsXZK98XyOrokt_qRoqXYkkD2DnnAwRD-fDT7n5G-R_Q@mail.gmail.com>

On 25 April 2014 20:15, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Apr 25, 2014, at 9:17 AM, Werner W. wrote:
>
>> Dear Rs,
>>
>> I am re-executing some older code. It does work in the ancient R 2.12.0 which I still have on my PC but with the new version R 3.1.0 it does not work any more (but some other new stuff, which won't work with 2.12).
>>
>> The problem arises in context with the systemfit package using the matrix package. In R 3.1.0 the following error is thrown:
>> Error in as.matrix(solve(W, tol = solvetol)[1:ncol(xMat), 1:ncol(xMat)]) : error in evaluating the argument 'x' in selecting a method for function 'as.matrix': Error in .solve.sparse.dgC(as(a, "dgCMatrix"), b = b, tol = tol) : LU computationally singular: ratio of extreme entries in |diag(U)| = 7.012e-39
>>
>> However, I have no clue what I can do about this. Was there some change in the defaults of the matrix package? I couldn't find anything apparent in the changelog. As the same code works in R 2.12.0, I suppose that the problem is not my data.
>
> You have not told us what version of the Matrix package you were using.
> As such I would suggest that you review the Changelog which is a link
> for the CRAN page for pkg:Matrix and go back 4 years or so since R
> major versions change about once a year.
>
> http://cran.r-project.org/web/packages/Matrix/ChangeLog

In addition, please provide a minimal, self-contained, reproducible example.

Best,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name



From jdnewmil at dcn.davis.ca.us  Sat Apr 26 09:32:45 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 26 Apr 2014 00:32:45 -0700 (PDT)
Subject: [R] Within ID variable delete all rows after reaching a
 specific value
In-Reply-To: <535B3022.9080207@bitwrit.com.au>
References: <CAOxgQ=Unzh4BsU-P0AVJDU+pT6GZuP9uUH1zZvX45bXEL6HFNA@mail.gmail.com>
	<535B3022.9080207@bitwrit.com.au>
Message-ID: <alpine.BSF.2.00.1404260019190.19227@pedal.dcn.davis.ca.us>

Jennifer:

a) Don't post in HTML... read the Posting Guide.

b) Don't make data frames by first making matrices... you rarely create 
what you think you are creating. In your case, your code creates a bunch 
of factor columns... use the str() function to verify that your data are 
sensible before analyzing it.

c) The ave and cumsum functions are useful here:

tmp <- data.frame( X1 = rbinom( 1000, 1, .03 )
                  , X2 = array( 1:127, c(1000,1) )
                  , X3 = array( format( seq( ISOdate(1990,1,1)
                                           , by='month'
                                           , length=56 )
                                      , format='%d.%m.%Y')
                              , c( 1000, 1 ) ) )
tmp <- tmp[ with( tmp, order( X2, X3 ) ), ]
tmp2 <- subset( tmp
               , 1 >= ave( X1
                         , X2
                         , FUN=function( x ) {
                             cumsum( cumsum( x ) )
                           } ) ) )

which generates a vector of increasing values once the first nonzero value 
is found in each group, and then only keeps the rows for which those 
increasing values are zero or one.

On Sat, 26 Apr 2014, Jim Lemon wrote:

> On 04/26/2014 12:42 PM, Jennifer Sabatier wrote:
>> So, I know that's a confusing Subject header.
>> 
>> Here's similar data:
>> 
>> 
>> tmp<- data.frame(matrix(
>>                          c(rbinom(1000, 1, .03),
>>                            array(1:127, c(1000,1)),
>>                            array(format(seq(ISOdate(1990,1,1), by='month',
>> length=56), format='%d.%m.%Y'), c(1000,1))),
>>                          ncol=3))
>> tmp<- tmp[with(tmp, order(X2, X3)), ]
>> table(tmp$X1)
>> 
>> 
>> X1 is the variable of interest - disease status.  It's a survival-type of
>> variable, where you are 0 until you become 1.
>> X2 is the person ID variable.
>> X3 is the clinic date (here it's monthly, just for example...but in my real
>> data it's a bit more complicated - definitely not equally spaced nor the
>> same number of visits to the clinic per ID.).
>> 
>> Some people stay X1 = 0 for all clinic visits.  Only a small proportion
>> become X1=1.
>> 
>> However, the data has errors I need to clean off.  Once someone becomes
>> X1=1 they should have no more rows in the dataset.  These are data entry
>> errors.
>> 
>> In my data I have people who continue to have rows in the data.  Sometimes
>> the rows show X1=0 and sometimes X1=1.  Sometimes there's just one more row
>> and sometimes there are many more rows.
>> 
>> How can I go through, find the first X1 = 1, and then delete any rows after
>> that, for each value of X2?
>> 
>> Thanks!
>> 
>> Jen
>> 
> Hi Jen,
> This might do what you want:
>
> tmp$X3<-as.Date(tmp$X3,"%d.%m.%Y")
> tmp<-tmp[order(tmp$X2,tmp$X3),]
> first<-TRUE
> for(patno in unique(tmp$X2)) {
> cat(patno,"\n")
> tmpbit<-tmp[tmp$X2 == patno,]
> firstone<-which(tmpbit$X1 == 1)[1]
> cat(firstone,"\n")
> if(is.na(firstone)) firstone<-dim(tmpbit)[1]
> newtmpbit<-tmpbit[1:firstone,]
> if(first) {
>  newtmp<-newtmpbit
>  first<-FALSE
> }
> else newtmp<-rbind(newtmp,newtmpbit)
> }
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From smartpink111 at yahoo.com  Sat Apr 26 09:32:24 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Apr 2014 00:32:24 -0700 (PDT)
Subject: [R] Within ID variable delete all rows after reaching a
	specific value
In-Reply-To: <535B3022.9080207@bitwrit.com.au>
References: <CAOxgQ=Unzh4BsU-P0AVJDU+pT6GZuP9uUH1zZvX45bXEL6HFNA@mail.gmail.com>
	<535B3022.9080207@bitwrit.com.au>
Message-ID: <1398497544.41555.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,

You may also try:
set.seed(425)

##your code
tmp <- data.frame(....

#####

tmp1 <- tmp
str(tmp1)
#'data.frame':??? 1000 obs. of? 3 variables:
# $ X1: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
# $ X2: Factor w/ 127 levels "1","10","100",..: 1 1 1 1 1 1 1 1 2 2 ...
# $ X3: Factor w/ 56 levels "01.01.1990","01.01.1991",..: 1 21 17 37 33 51 48 10 11 45 #...


?tmp1 <- tmp1[with(tmp1,order(X2, as.Date(X3, "%d.%m.%Y"))),]
tmp2 <- tmp1[with(tmp1,!ave(as.numeric(as.character(X1)),X2, FUN=function(x)? cumsum(cumsum(x)) >1 )),]

###checking results with Jim's method
tmp2New <- tmp2
tmp2New$X3 <- as.Date(tmp2New$X3, "%d.%m.%Y")
identical(tmp2New,newtmp) ##Jim's result
#[1] TRUE

A.K.




On Saturday, April 26, 2014 12:07 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
On 04/26/2014 12:42 PM, Jennifer Sabatier wrote:
> So, I know that's a confusing Subject header.
>
> Here's similar data:
>
>
> tmp<- data.frame(matrix(
>? ? ? ? ? ? ? ? ? ? ? ? ? c(rbinom(1000, 1, .03),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? array(1:127, c(1000,1)),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? array(format(seq(ISOdate(1990,1,1), by='month',
> length=56), format='%d.%m.%Y'), c(1000,1))),
>? ? ? ? ? ? ? ? ? ? ? ? ? ncol=3))
> tmp<- tmp[with(tmp, order(X2, X3)), ]
> table(tmp$X1)
>
>
> X1 is the variable of interest - disease status.? It's a survival-type of
> variable, where you are 0 until you become 1.
> X2 is the person ID variable.
> X3 is the clinic date (here it's monthly, just for example...but in my real
> data it's a bit more complicated - definitely not equally spaced nor the
> same number of visits to the clinic per ID.).
>
> Some people stay X1 = 0 for all clinic visits.? Only a small proportion
> become X1=1.
>
> However, the data has errors I need to clean off.? Once someone becomes
> X1=1 they should have no more rows in the dataset.? These are data entry
> errors.
>
> In my data I have people who continue to have rows in the data.? Sometimes
> the rows show X1=0 and sometimes X1=1.? Sometimes there's just one more row
> and sometimes there are many more rows.
>
> How can I go through, find the first X1 = 1, and then delete any rows after
> that, for each value of X2?
>
> Thanks!
>
> Jen
>
Hi Jen,
This might do what you want:

tmp$X3<-as.Date(tmp$X3,"%d.%m.%Y")
tmp<-tmp[order(tmp$X2,tmp$X3),]
first<-TRUE
for(patno in unique(tmp$X2)) {
? cat(patno,"\n")
? tmpbit<-tmp[tmp$X2 == patno,]
? firstone<-which(tmpbit$X1 == 1)[1]
? cat(firstone,"\n")
? if(is.na(firstone)) firstone<-dim(tmpbit)[1]
? newtmpbit<-tmpbit[1:firstone,]
? if(first) {
?  newtmp<-newtmpbit
?  first<-FALSE
? }
? else newtmp<-rbind(newtmp,newtmpbit)
}

Jim


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jefferis at gmail.com  Sat Apr 26 09:36:52 2014
From: jefferis at gmail.com (Gregory Jefferis)
Date: Sat, 26 Apr 2014 08:36:52 +0100
Subject: [R] about rect.hclust
In-Reply-To: <044B2E98-D191-47C7-BB00-B8361DFDEA53@gmail.com>
References: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
	<044B2E98-D191-47C7-BB00-B8361DFDEA53@gmail.com>
Message-ID: <47785C8B-D12D-47E6-8631-6F2105E9BF0E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/fe633bd4/attachment-0001.pl>

From smartpink111 at yahoo.com  Sat Apr 26 10:45:40 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Apr 2014 01:45:40 -0700 (PDT)
Subject: [R] Simple Loop Counter
Message-ID: <1398501940.56138.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
May be this helps:
for(i in letters) {
? n <- n+1
? x[n,] <- c(i, n)
cat("loop", n, "\n")
}
x
#or
for(i in seq_along(letters)) {
? n <- n+1
? x[n,] <- c(letters[i], n)
cat("loop", i, "\n")
}
x

A.K.


#How can I add the loop counter in #2 to the loop in #1.?
#***************
#1.
x <- matrix( , ncol = 2, nrow = 26) # empty matrix
n <- 0???? #set n to 0
for(i in letters) {
? n <- n+1
? x[n,] <- c(i, n)
}
x
#***********
#2.
for (i in 1:10) {
cat("loop", i, "\n")
}



From tal.galili at gmail.com  Sat Apr 26 12:03:57 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 26 Apr 2014 13:03:57 +0300
Subject: [R] about rect.hclust
In-Reply-To: <47785C8B-D12D-47E6-8631-6F2105E9BF0E@gmail.com>
References: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
	<044B2E98-D191-47C7-BB00-B8361DFDEA53@gmail.com>
	<47785C8B-D12D-47E6-8631-6F2105E9BF0E@gmail.com>
Message-ID: <CANdJ3dXtYmBju9P_HjurE2WxqLZnqcNTEpXGFgskcxuY1qnMqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/5aad1ecb/attachment-0001.pl>

From kmersman at smail.uni-koeln.de  Sat Apr 26 12:26:41 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Sat, 26 Apr 2014 12:26:41 +0200
Subject: [R] purtest and missing values (plm-package)
In-Reply-To: <1398441687.26108.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <000301cf608d$a8672160$f9356420$@uni-koeln.de>
	<001a01cf6095$256fc7f0$704f57d0$@uni-koeln.de>
	<1398441687.26108.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <000301cf613a$0434f290$0c9ed7b0$@uni-koeln.de>

Hey arun,
I am thankful for your help and assistance! With the example it works! 

Have a nice day,
Katie

-----Urspr?ngliche Nachricht-----
Von: arun [mailto:smartpink111 at yahoo.com] 
Gesendet: Freitag, 25. April 2014 18:01
An: r-help at r-project.org
Cc: Katharina Mersmann
Betreff: Re: [R] purtest and missing values (plm-package)



Hi,

May be this helps:
library(plm)
data(Grunfeld)
 Grunfeld$inv[c(2,8)] <- NA
 GrunfeldNew <- subset(Grunfeld, !year %in% year[is.na(inv)])

x <- data.frame(split(GrunfeldNew$inv, GrunfeldNew$firm)) purtest(x, pmax = 4, exo = "none", test = "levinlin",lags="SIC") #    Levin-Lin-Chu Unit-Root Test (ex. var. : None ) #
#data:  x
#z.x1 = 5.0507, p-value = 4.402e-07
#alternative hypothesis: stationarity
#
#Warning message:
#In selectT(l, theTs) : the time serie is short


A.K.


On Friday, April 25, 2014 10:48 AM, Katharina Mersmann <kmersman at smail.uni-koeln.de> wrote:
Because, my inbox shows a "cutted-email-version", once again:

Hello R-Community,

I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.
Now I want to run different unit-root tests.

For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )

Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu ?test and Im, Pesaran & Shin-test ) for which I use the purtest function, from plm-package.
But I don?t know how to apply it, if my series contains missing values ( so only a error-message is created)

> purtest(data.plm,data=data.plm, test = "levinlin",exo = "none",lags 
> ="SIC")
Fehler in lm.fit(X, y) : NA/NaN/Inf in 'x'
Zus?tzlich: Warnmeldung:
In Ops.factor(object[2:length(object)], object[1:(length(object) -  :
  - not meaningful for factors

So my Question is:
1.    Is there a way to handle the missing values? 
2.    Do I just omit them? And if, is there a way to integrate this by adding an ? na.omit? into the function ?


To make it easier explaining the way of proceeding, a reproducible example could be:

data("Grunfeld", package = "plm")
y <- data.frame(split(Grunfeld$inv, Grunfeld$firm)) purtest(y, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # works no missing data

# add an NA

data("Grunfeld", package = "plm")
x <?data.frame(split(Grunfeldinv, Grunfeld$firm)) Grunfeldinv[2]<?NA purtest(x, pmax = 4, exo = "none", test = "levinlin",lags=?SIC?) # Error in lm.fit(X, x) : NA/NaN/Inf in 'x'

Thanks for your hints and suggestions! 
Katie


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Katharina Mersmann
Gesendet: Freitag, 25. April 2014 15:53
An: r-help at r-project.org
Betreff: [R] purtest and missing values (plm-package)

Hello R-Community,



I have quarterly panel-data and not surprisingly missing values, in a few variables, which are differently distributed around the panel.

Now I want to run different unit-root tests.



For ADF on the pooled data set, I chose CADF-package, which can determine the number of lags automa. by SIC and handles missing values. (I hope this is the right one )



Secondly I want to run an LLC and IPS test specificially for the panel data (Levin, Lin & Chu b

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From info at aghmed.fsnet.co.uk  Sat Apr 26 13:38:16 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 26 Apr 2014 12:38:16 +0100
Subject: [R] Metafor: How to integrate effectsizes?
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DAA4F3A14@UM-MAIL4112.uni
	maas.nl>
References: <CAMuCtg627YQ-mArR1RWWM-xm6M5BV0j4WatLFq=3iSLnq3AhwQ@mail.gmail.com>
	<CAMuCtg7ypqrSqBboJBa-YSO28+9Hdw2W7U-WVchKUSfXuBQCvw@mail.gmail.com>
	<Zen-1WdeCc-0007OW-6m@smarthost01b.mail.zen.net.uk>
	<CAMuCtg7Xsvypi48xjAPGePZsTKOf7dz4Y2w1Px1OCf7p7FNKDg@mail.gmail.com>
	<Zen-1Wdh1f-000AIS-Ux@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DAA4F3A14@UM-MAIL4112.unimaas.nl>
Message-ID: <Zen-1We0w6-000Flj-C4@smarthost01b.mail.zen.net.uk>

At 20:34 25/04/2014, Viechtbauer Wolfgang (STAT) wrote:
>If you know the d-value and the corresponding 
>group sizes for a study, then it's possible to 
>add that study to the rest of the dataset. Also, 
>if you only know the test statistic from an 
>independent samples t-test (or only the p-value 
>corresponding to that test), it's possible to 
>back-compute what the standardized mean difference is.
>
>I added an illustration of this to the metafor package website:
>
>http://www.metafor-project.org/doku.php/tips:assembling_data_smd

Verena might also like to look at the compute.es 
package available from CRAN to see whether any of 
the conversions programmed there do the job.


>Best,
>Wolfgang
>
>--
>Wolfgang Viechtbauer, Ph.D., Statistician
>Department of Psychiatry and Psychology
>School for Mental Health and Neuroscience
>Faculty of Health, Medicine, and Life Sciences
>Maastricht University, P.O. Box 616 (VIJV1)
>6200 MD Maastricht, The Netherlands
>+31 (43) 388-4170 | http://www.wvbauer.com
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> > On Behalf Of Michael Dewey
> > Sent: Friday, April 25, 2014 16:23
> > To: Verena Weinbir
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Metafor: How to integrate effectsizes?
> >
> > At 12:33 25/04/2014, you wrote:
> > >Thank you very much for your reply and the book recommendation, Michael.
> > >
> > >Yes, I mean Cohen's d - sorry for the typo :-)
> > >
> > >Just to make this sure for me: There is no
> > >possibility to integrate stated Cohens' ds in an
> > >R-Metaanalysis (or a MA at all), if there is no
> > >further information traceable regarding SE or the like?
> >
> > If there is really no other information like
> > sample sizes, significance level, value of some
> > significance test then you would have to impute a
> > value from somewhere. That would seem a last resort.
> >
> > I have cc'ed this back to the list, please keep
> > it on the list so others may benefit and contribute.
> >
> >
> > >best regards,
> > >
> > >Verena
> > >
> > >
> > >On Fri, Apr 25, 2014 at 1:21 PM, Michael Dewey
> > ><<mailto:info at aghmed.fsnet.co.uk>info at aghmed.fsnet.co.uk> wrote:
> > >At 13:15 24/04/2014, Verena Weinbir wrote:
> > >Hello!
> > >
> > >I am using the metafor package for my master's thesis as an R-newbie.
> > While
> > >calculating effectsizes from my dataset (mean values and
> > >standarddeviations) using "escalc" shouldn't be a problem (I hope ;-)),
> > I
> > >wonder how I could at this point integrate additional studies, which
> > only
> > >state conhens d (no information about mean value and sds available), to
> > >calculate an overall analysis. ? I would be very grateful for your
> > support!
> > >
> > >
> > >You mean Cohen's d I think.
> > >
> > >You will need some more information to enable
> > >you to calculate its standard error. Have a look at Rosenthal's chapter
> > in
> > >@book{cooper94,
> > >?  ? author = {Cooper, H and Hedges, L V},
> > >?  ? title = {A handbook of research synthesis},
> > >?  ? year = {1994},
> > >?  ? publisher = {Russell Sage},
> > >?  ? address = {New York},
> > >?  ? keywords = {meta-analysis}
> > >}
> > >(There is an updated edition)
> > >This gives you more information about converting
> > >effect sizes and extracting them from unpromising beginnings.
> > >
> > >It often requires some ingenuity to get the
> > >information you need so have a go and then get
> > >back here with more details if you run into problems
> > >
> > >
> > >Best regards,
> > >
> > >Verena

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From ruipbarradas at sapo.pt  Sat Apr 26 15:17:09 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 26 Apr 2014 14:17:09 +0100
Subject: [R] Cramer Rao upper/lower bounds- No Comments ?
In-Reply-To: <1398426031.3105.3.camel@localhost.localdomain>
References: <1398426031.3105.3.camel@localhost.localdomain>
Message-ID: <535BB1D5.3060400@sapo.pt>

Hello,

Is this homework? There's a no homework policy here.

Em 25-04-2014 12:40, Mohammed Ouassou escreveu:
> Dear R users;
>
> I have a question about Cramer Rao upper/lower bounds

Cramer Rao _lower_ bound, not upper.
>
> Is it possible to compute Crammer Rao upper/lower bounds from residuals
> and  corresponding covariance matrices ?

Residuals of what?

Hope this helps,

Rui Barradas
>
>
> Any suggestions will be appreciated, thanks in advance.
>
>
> M.O
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pavneet.arora at uk.rsagroup.com  Sat Apr 26 15:47:25 2014
From: pavneet.arora at uk.rsagroup.com (starter)
Date: Sat, 26 Apr 2014 06:47:25 -0700 (PDT)
Subject: [R] Read.table mucks up headers
In-Reply-To: <5352764F.4040903@statistik.tu-dortmund.de>
References: <OFD4C1E2C2.FDAD6D74-ON80257CBA.00514CAB-80257CBA.005238DB@uk.royalsun.com>
	<0f233a3b-f4d4-4b69-9231-ad3fe82857c2@email.android.com>
	<1397495399.4315.1.camel@milan>
	<OFB93726F6.DD7DA7CA-ON80257CBB.002EEAAC-80257CBB.002F8358@uk.royalsun.com>
	<1397910654957-4689099.post@n4.nabble.com>
	<5352764F.4040903@statistik.tu-dortmund.de>
Message-ID: <1398520045370-4689519.post@n4.nabble.com>

Hello Uwe & Others

Thanks for all your help, I figured out what the problem was. It wasn't
working with old R version. Once I updated it to the latest version, it
seemed to work.

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/Read-table-mucks-up-headers-tp4688742p4689519.html
Sent from the R help mailing list archive at Nabble.com.



From ggrothendieck at gmail.com  Sat Apr 26 16:19:15 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 26 Apr 2014 10:19:15 -0400
Subject: [R] [R-sig-DB] Update results not being written to existing
 data frame when using sqldf UPDATE
In-Reply-To: <CAKK9E9oR1g4X8A18Nqpz4AdsMc-vpoOc3Co_dVkzVKh0-nuoCw@mail.gmail.com>
References: <CAKK9E9oR1g4X8A18Nqpz4AdsMc-vpoOc3Co_dVkzVKh0-nuoCw@mail.gmail.com>
Message-ID: <CAP01uRn4eahRbf+QGJoDS0ZUjpT3Gq4b=a0c6T2sP1SJPcSecw@mail.gmail.com>

On Sat, Apr 26, 2014 at 10:06 AM, Christopher Lowenkamp
<clowenkamp at gmail.com> wrote:
> RStudio Version 0.98.501
> R version 3.1.0
> Mac OSX 10.9.2
>
> Packages loaded:
> sqldf
> gsubfn
> proto
> RSQLite
> DBI
> RSQLite.extfuns
> tcltk
>
> Good morning:
>
> I am trying to run an sqldf update with two tables.  Both tables contain a
> variable called ?off_id?.  I am trying to update a variable in tablea (v2)
> with the number of times each record in tablea appears in tableb.
>
> ##
>
> tablea <- data.frame(off_id = c(12, 14, 16, 17, 18, 22, 1, 5, 7, 44, 4, 3),
> v2 = 0)
>
> tableb <- data.frame(off_id = c(12, 12, 14, 14, 14, 14, 16, 17, 12, 12, 1,
> 18, 18, 5, 7, 3, 16, 1, 1, 3, 3, 3, 1))
>
> sql1     <-         "UPDATE tablea SET v2 = (SELECT count(*) FROM tableb
> WHERE tableb.off_id = tablea.off_id)"
>
> sql2     <-         ?SELECT * FROM tablea?
>
> #The following code returns "NULL"
>
> sqldf(sql1, sql2)
>
> #When I run the following I do get back the data but tablea$v2 still does
> not update
>
> sqldf(c(sql1, sql2), method = "raw")
>
> #If I run the following I get the expected results in tablec$v2, but
> tablea$v2 does not update
>
> tablec <- as.data.frame(sqldf(c(sql1, sql2)))
>
> ##
>
> I am wondering what I am doing wrong.  Is there a way to get tablea$v2 to
> update?  I did check at https://code.google.com/p/sqldf/ (and have read
> through FAQ 8 a number of times) but don't see an answer to the problem I
> am having.
>
>

sqldf never modies any object in your R work space.  It did update the
table in the main sqlite database but its up to you if you want to
write it back to R.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From xmliu1988 at gmail.com  Sat Apr 26 11:54:34 2014
From: xmliu1988 at gmail.com (xmliu1988 at gmail.com)
Date: Sat, 26 Apr 2014 17:54:34 +0800
Subject: [R] Faster way to transform vector [3 8 4 6 1 5] to [2 6 3 5 1 4]
Message-ID: <2014042617543124741425@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/8e2640c6/attachment-0001.pl>

From clowenkamp at gmail.com  Sat Apr 26 16:06:44 2014
From: clowenkamp at gmail.com (Christopher Lowenkamp)
Date: Sat, 26 Apr 2014 10:06:44 -0400
Subject: [R] Update results not being written to existing data frame when
 using sqldf UPDATE
Message-ID: <CAKK9E9oR1g4X8A18Nqpz4AdsMc-vpoOc3Co_dVkzVKh0-nuoCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/dae24697/attachment-0001.pl>

From fongchunchan at gmail.com  Sat Apr 26 17:27:58 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Sat, 26 Apr 2014 08:27:58 -0700
Subject: [R] Can't plot transparency images in R-3.1.0
In-Reply-To: <535B14A4.1060402@sophie.unam.mx>
References: <CAB-BZ9+vdBPcWJxHPDHD80p2x=Xfar3yLGjXAvkgtY5GRdunKA@mail.gmail.com>
	<535B14A4.1060402@sophie.unam.mx>
Message-ID: <CAB-BZ9J+xyeNCPvAd4iTvOW7YwvfiZ6JO5cZuLdfJYJzr46jmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/5391101b/attachment-0001.pl>

From wdunlap at tibco.com  Sat Apr 26 17:35:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 26 Apr 2014 08:35:22 -0700
Subject: [R] Faster way to transform vector [3 8 4 6 1 5] to [2 6 3 5 1
	4]
In-Reply-To: <2014042617543124741425@gmail.com>
References: <2014042617543124741425@gmail.com>
Message-ID: <CAF8bMca-DwaVpgD=znE3K4uPU5ZVC+38ss0073adsCrzG_epKg@mail.gmail.com>

Look into the rank function.

If there are duplicated values in the input vector its 'ties' argument
says how to deal with them. If there are ties I think your algorithm
puts the last one in the first position, e.g., it maps
c(101,101,101,102,102) to c(3,2,1,5,4).  rank does not include this
option, but if that is really what you want to do you can use
   myRank <- function (x)  rev(rank(rev(x), ties = "first"))

On Sat, Apr 26, 2014 at 2:54 AM, xmliu1988 at gmail.com
<xmliu1988 at gmail.com> wrote:
> Hi,
>
> could anybody help me to find a fast way to fix the following question?
>
> Given a verctor of length N, for example bo = [3  8  4  6  1  5],
> I want to drive a vector whose elements are 1, 2, ..., N and the order of elements is the same as that in verctor bo.
> In this example, the result is supposed to be bt = [2  6  3  5  1 4].
>
> I used the following code to solove this:
>
> bo <- c(3,  8,  4,  6,  1,  5)
> N <- length(bo)
> bt <- rep(0, N)
> M <- max(bo)
> temp <- bo
>   for(i in 1 : N)
>             {
>                 min <- M
>                 i_min <- 0
>
>                 for(j in 1 : N)
>                 {
>                     if(min >= temp[j])
>                     {
>                           min <- temp[j]
>                           i_min <-j
>                      }
>                 }
>                 bt[i_min] <- i
>                 temp[i_min] <- M+ 1
>              }
>> bt
> [1] 2 6 3 5 1 4
>
> However, the time complexity is O(N2).
> When N is larger than 1000000, it takes too much time.
> Is there any faster way to fix it?
>
> best
> Xueming
>
>
>
> xmliu1988 at gmail.com
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bill Dunlap
TIBCO Software
wdunlap tibco.com



From jorgeivanvelez at gmail.com  Sat Apr 26 17:41:02 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 27 Apr 2014 01:41:02 +1000
Subject: [R] Faster way to transform vector [3 8 4 6 1 5] to [2 6 3 5 1
	4]
In-Reply-To: <2014042617543124741425@gmail.com>
References: <2014042617543124741425@gmail.com>
Message-ID: <CAKL8G3FX6WrBKsQSqmf9LtHi4uoSAmy6ESQfXmC6K9W+Re9AEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/ba446fe3/attachment-0001.pl>

From rguy at 123mail.org  Sat Apr 26 17:42:01 2014
From: rguy at 123mail.org (Rguy)
Date: Sat, 26 Apr 2014 16:42:01 +0100
Subject: [R] mapply echoes function call when browser() is called from
	within FUN
Message-ID: <CAEorq2M1putEXsw-MciWRjP9ruKbEn2hhY=Zpe2=77dtgSk8Sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/0df70ee2/attachment-0001.pl>

From marongiu.luigi at gmail.com  Sat Apr 26 18:06:32 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sat, 26 Apr 2014 17:06:32 +0100
Subject: [R] lattice plot formatting: pch, abbreviation and labels
Message-ID: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>

Dear all,
I am trying to use the lattice plot, but the syntax is quite
difficult. Specifically I have eight variables (1 to 8) each of them
further subdivided in two classes (negative=0 and positive=1). I am
using the stripplot() to represent these values. I would like to
represent the negative and positive values with black and white dots
so I have tried to use the argument pch=c(16, 1) both in the main
stripplot function and embedded in the scale argument. However the
resulting plot shows that some points are drawn with the pch=16 and
other with pch=1 irrespective of their class.
Is there a way to draw the values for the variable positivity = 0 with
pch=16 and those with positivity = 1 with pch=0?

In addition I would like to change the labels under the axis from 0,1
to N,P. However when I placed labels=c("N", "P") or labels=list("N",
"P") in the main stripplot() I did not obtained any difference and
when placed within the scale argument also the -labels were modified.
Is there a way to change the label 0 with N and the label 1 with P?

final problem: I would like to abbreviate the "Unstimulated" box label
with "Unst.". I have tried the abbreviate=TRUE argument but again the
syntax is too complex for me and it did not work.
Is there a way to abbreviate the variables names?

Thank you very much for your help.
Best wishes,
Luigi


CODE:::::::::


### open plot library
library(lattice)

my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
"Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
    column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")
attach(my.data)

stripplot(my.data$copy ~ factor(my.data$positivity)|factor(my.data$stimulation,
            levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
"Rv2654", "Rv3879", "Rv3873","PHA")),
            my.data, hor=F, layout = c(8,1), scales = list(relation = "same"),
      jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
      ylab=expression(bold("Copy")),
xlab=expression(bold("Stimulation")), main="Plot",
      par.settings = list(strip.background=list(col="white")),
            par.strip.text=list(font=2))



From murdoch.duncan at gmail.com  Sat Apr 26 18:06:46 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 12:06:46 -0400
Subject: [R] mapply echoes function call when browser() is called from
 within FUN
In-Reply-To: <CAEorq2M1putEXsw-MciWRjP9ruKbEn2hhY=Zpe2=77dtgSk8Sg@mail.gmail.com>
References: <CAEorq2M1putEXsw-MciWRjP9ruKbEn2hhY=Zpe2=77dtgSk8Sg@mail.gmail.com>
Message-ID: <535BD996.4050401@gmail.com>

On 26/04/2014, 11:42 AM, Rguy wrote:
> When mapply is applied to a function that has a call to browser() within
> it, the result can be a disastrous amount of feedback.
>
> To clarify this situation please consider the following function,
> containing a call to browser within it:
>
> plus = function(a, b) {browser(); a + b}
>
> A plain vanilla call to plus() yields the following:
>
> LAPTOP_32G_01> plus(1,2)
> Called from: plus(1, 2)
> Browse[1]>
> [1] 3
>
> Now consider the following application of mapply to plus:
>
> LAPTOP_32G_01> mapply(plus, 1:2, 1:2)
> Called from: (function (a, b)
> {
>      browser()
>      a + b
> })(dots[[1L]][[1L]], dots[[2L]][[1L]])
> Browse[1]>
> Called from: (function (a, b)
> {
>      browser()
>      a + b
> })(dots[[1L]][[2L]], dots[[2L]][[2L]])
> Browse[1]>
> [1] 2 4
>
> Notice that at each step, after the browser is called, mapply prints out
> the function call including its arguments:
>
> Called from: (function (a, b)
> {
>      browser()
>      a + b
> })(dots[[1L]][[1L]], dots[[2L]][[1L]])
>
> etc.
>
> In the present case this does no harm except to make things a little harder
> to read. However, if one of the inputs happens to be a data frame with a
> million rows, the entire million rows are printed to the screen. I have
> been bitten by this, which is why I am writing this note. I have a question
> and a request:

I don't see the argument values being printed in your example, and if I 
replace them with dataframes, I still don't see them.  So it's not quite 
as simple as you describe to get the voluminous output.

Reproducible examples are needed if you want something fixed.

>
> Question: Is there some way to prevent mapply (or browser) from echoing the
> function call when browser is called from within FUN?

Yes, use the skipCalls argument to browser.

Duncan Murdoch

>
> Request: If not, could the ability to turn off this echoing be provided. As
> things stand, calling browser from within FUN, when FUN is a realistically
> big function or has realistically big arguments, is a disaster.
>
> Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From smartpink111 at yahoo.com  Sat Apr 26 17:20:54 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Apr 2014 08:20:54 -0700 (PDT)
Subject: [R] Faster way to transform vector [3 8 4 6 1 5] to [2 6 3 5 1
	4]
In-Reply-To: <2014042617543124741425@gmail.com>
References: <2014042617543124741425@gmail.com>
Message-ID: <1398525654.46418.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Perhaps,
rank(bo)
#[1] 2 6 3 5 1 4
A.K.




On Saturday, April 26, 2014 11:00 AM, "xmliu1988 at gmail.com" <xmliu1988 at gmail.com> wrote:
Hi,

could anybody help me to find a fast way to fix the following question?

Given a verctor of length N, for example bo = [3? 8? 4? 6? 1? 5],
I want to drive a vector whose elements are 1, 2, ..., N and the order of elements is the same as that in verctor bo.
In this example, the result is supposed to be bt = [2? 6? 3? 5? 1 4].

I used the following code to solove this:

bo <- c(3,? 8,? 4,? 6,? 1,? 5)
N <- length(bo)
bt <- rep(0, N)
M <- max(bo)
temp <- bo
? for(i in 1 : N)
? ? ? ? ? ? {
? ? ? ? ? ? ? ? min <- M
? ? ? ? ? ? ? ? i_min <- 0
? ? ? ? ? ? ? ? ? 
? ? ? ? ? ? ? ? for(j in 1 : N)
? ? ? ? ? ? ? ? {
? ? ? ? ? ? ? ? ? ? if(min >= temp[j])
? ? ? ? ? ? ? ? ? ? {
? ? ? ? ? ? ? ? ? ? ? ? ? min <- temp[j]
? ? ? ? ? ? ? ? ? ? ? ? ? i_min <-j
? ? ? ? ? ? ? ? ? ?  }
? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? bt[i_min] <- i
? ? ? ? ? ? ? ? temp[i_min] <- M+ 1
? ? ? ? ? ?  }
> bt
[1] 2 6 3 5 1 4

However, the time complexity is O(N2).
When N is larger than 1000000, it takes too much time.
Is there any faster way to fix it?

best
Xueming



xmliu1988 at gmail.com
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From marc_grt at yahoo.fr  Sat Apr 26 20:29:25 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sat, 26 Apr 2014 20:29:25 +0200
Subject: [R] GLM using truncated lognormal distribution
Message-ID: <535BFB05.1000107@yahoo.fr>

Dear honorable list-members,

I know how to fit a truncated lognormal distribution (or Gaussian) 
(example here:
http://max2.ese.u-psud.fr/epc/conservation/Girondot/Publications/Blog_r/Entrees/2012/5/24_Adjust_a_truncated_lognormal_distribution.html 
) but I would like to use it in the context of glm.

Rather than using family=gaussian(), ideally I would like to have a 
family=truncated_gaussian().
I see using fix(gaussian) how is organized the gaussian() function. It 
is not 100% clear now but I think I could manage to change it to do a 
family=truncated_gaussian().

But before to do it, perhaps it exists already.

I find the package truncnorm but it does not do this function.

Thanks a lot for any advice,

Marc



From atclark at umn.edu  Sat Apr 26 20:52:18 2014
From: atclark at umn.edu (Adam Clark)
Date: Sat, 26 Apr 2014 13:52:18 -0500
Subject: [R] writing a package with doParallel and compiled C
Message-ID: <CAL7OOdwES0MBM3YBZSW5Q+6WvoSL6cPnnnC_tv7XMf3HuTk1_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/1ce8d9a2/attachment-0001.pl>

From jdnewmil at dcn.davis.CA.us  Sat Apr 26 21:12:54 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 26 Apr 2014 12:12:54 -0700
Subject: [R] writing a package with doParallel and compiled C
In-Reply-To: <CAL7OOdwES0MBM3YBZSW5Q+6WvoSL6cPnnnC_tv7XMf3HuTk1_A@mail.gmail.com>
References: <CAL7OOdwES0MBM3YBZSW5Q+6WvoSL6cPnnnC_tv7XMf3HuTk1_A@mail.gmail.com>
Message-ID: <fbc8a904-08a7-4366-98d7-6d205953d71d@email.android.com>

I am going to go out on a limb and suggest that you not do this at all. Packages are good places for algorithms, and parallel processing is an infrastructure optimization that a) is not always an efficiency win, and b) can be quite sensitive to the actual infrastructure that is available (best solutions for Windows and *nix platforms often being noticeably different).
If you have considered this already and still intend to proceed, I have to defer to someone else for an answer to your actual question.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 26, 2014 11:52:18 AM PDT, Adam Clark <atclark at umn.edu> wrote:
>Hi all,
>
>Any tips on how to use doParallel as part of a function in a package
>that I
>am writing? The function calls compiled C code, and (as far as I know),
>doParallel requires you to load C functions for each core that you use
>(either with the .packages argument to foreach(), or by explicitly
>loading
>the object for each loop).
>
>However - the package doesn't pass the "check" command when I try to
>build
>it. I suspect that this is because the package isn't yet loaded into
>the
>namespace while it is being checked, and doParallel can therefore not
>find
>it.
>
>Does anyone know whether my suspicion is wrong, or whether there is a
>better way to handle doParallel in this case?
>
>Many thanks,



From maechler at stat.math.ethz.ch  Sat Apr 26 22:00:13 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Apr 2014 22:00:13 +0200
Subject: [R] Problem with new(er) R version's matrix package
In-Reply-To: <CAMTWbJhsXZK98XyOrokt_qRoqXYkkD2DnnAwRD-fDT7n5G-R_Q@mail.gmail.com>
References: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>
	<0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>
	<CAMTWbJhsXZK98XyOrokt_qRoqXYkkD2DnnAwRD-fDT7n5G-R_Q@mail.gmail.com>
Message-ID: <21340.4173.717293.642419@stat.math.ethz.ch>

>>>>> Arne Henningsen <arne.henningsen at gmail.com>
>>>>>     on Sat, 26 Apr 2014 08:15:37 +0200 writes:

    > On 25 April 2014 20:15, David Winsemius
    > <dwinsemius at comcast.net> wrote:
    >> 
    >> On Apr 25, 2014, at 9:17 AM, Werner W. wrote:
    >> 
    >>> Dear Rs,
    >>> 
    >>> I am re-executing some older code. It does work in the
    >>> ancient R 2.12.0 which I still have on my PC but with
    >>> the new version R 3.1.0 it does not work any more (but
    >>> some other new stuff, which won't work with 2.12).
    >>> 
    >>> The problem arises in context with the systemfit package
    >>> using the matrix package. In R 3.1.0 the following error
    >>> is thrown: Error in as.matrix(solve(W, tol =
    >>> solvetol)[1:ncol(xMat), 1:ncol(xMat)]) : error in
    >>> evaluating the argument 'x' in selecting a method for
    >>> function 'as.matrix': Error in .solve.sparse.dgC(as(a,
    >>> "dgCMatrix"), b = b, tol = tol) : LU computationally
    >>> singular: ratio of extreme entries in |diag(U)| =
    >>> 7.012e-39
    >>> 
    >>> However, I have no clue what I can do about this. Was
    >>> there some change in the defaults of the matrix package?
    >>> I couldn't find anything apparent in the changelog. As
    >>> the same code works in R 2.12.0, I suppose that the
    >>> problem is not my data.
    >> 
    >> You have not told us what version of the Matrix package
    >> you were using.  As such I would suggest that you review
    >> the Changelog which is a link for the CRAN page for
    >> pkg:Matrix and go back 4 years or so since R major
    >> versions change about once a year.
    >> 
    >> http://cran.r-project.org/web/packages/Matrix/ChangeLog

    > In addition, please provide a minimal, self-contained,
    > reproducible example.

Yes, please do.   As maintainer of the Matrix package, I'm
willing to look into the situation of course.

As was mentioned, many things have changed in 4 years.
The error message above looks like you'd want to invert a
(very close to) singular matrix, and there could be quite few
reasons why parts of the older code gave slightly different
answers.

Without a reproducible example, we can't get started though.

Best regards,
Martin Maechler, ETH Zurich



From clare.embling at plymouth.ac.uk  Sat Apr 26 22:27:24 2014
From: clare.embling at plymouth.ac.uk (cembling)
Date: Sat, 26 Apr 2014 13:27:24 -0700 (PDT)
Subject: [R] For loop processing too slow - pre-format data.frame?
Message-ID: <1398544044516-4689543.post@n4.nabble.com>

Hi,

I am bootstrapping, but my loops are taking way too long & I need to make it
faster. Looking on the R-help archive I suspect it may be due to not
specifying the size of my data.frame, mainly because I don't know in advance
how large it has to be. Can anyone help?

My data looks like this (first 5 entries of 'SpeyBay'):

  Year JulianDay Hour Day Month Quarter Season SeaState Visibility TideState
1 2005        91    6   1     4       2      2        2          2      2.18
2 2005        91    7   1     4       2      2        2          2      1.53
3 2005        91    9   1     4       2      2        2          3      0.80
4 2005        91   11   1     4       2      2        2          4      0.96
5 2005        91   14   1     4       2      2        1          6      2.25
  TideHeight CetPres Segment
1          2       0       1
2          3       0       1
3          5       0       2
4         -5       0       3
5         -2       0       4

I am bootstrapping 1000 times but re-sampling on segment (since my data is
autocorrelated), which means I am trying to reconstruct my data based on
random segments e.g. segment 3, then segment 1, each of which may include
from 1-14 data rows. So I don't know how many rows I am going to get in
advance.

When I run my for loop, I just use rbind with undefined size of the new
variable e.g. 'tempD2', and I suspect it is this that is slowing down the
whole process (probably partly due to having a for loop within a for loop).

Can anyone give me any advice on how to pre-define a data frame (if this is
what the data shown above is) that can have an undefined size - or how to
make it big enough to take all the data?). I've been trying to figure this
out for ages with no luck & sure it's something simple!

Code shown below - any tips on making the code faster would be greatly
appreciated - the last run took several hours which is just not practical!

Many thanks in advance,
Clare Embling

CODE: 

SpringWatch <- 504
SummerWatch <- 704
AutumnWatch <- 392
MaxSample <- 704

signif <- 0

for(j in 1:1000){

   # resampling 2 different years (D & E) in 3 different seasons (2, 3 & 4)
separately
   D2S <- sample(D2Start:D2Stop,MaxSample,replace=T)
   D3S <- sample(D3Start:D3Stop,MaxSample,replace=T)
   D4S <- sample(D4Start:D4Stop,MaxSample,replace=T)
   E2S <- sample(E2Start:E2Stop,MaxSample,replace=T)
   E3S <- sample(E3Start:E3Stop,MaxSample,replace=T)
   E4S <- sample(E4Start:E4Stop,MaxSample,replace=T)

   # Creating new data frames with the first sampled segment
   TempD2 <- SpeyBay[(Segment==D2S[1]),]
   TempD3 <- SpeyBay[(Segment==D3S[1]),]
   TempD4 <- SpeyBay[(Segment==D4S[1]),]
   TempE2 <- SpeyBay[(Segment==E2S[1]),]
   TempE3 <- SpeyBay[(Segment==E3S[1]),]
   TempE4 <- SpeyBay[(Segment==E4S[1]),]

   # loop to add together all the rows of data for each segment sampled
   for(i in 2:MaxSample) {
      TempD2 <- rbind(TempD2,SpeyBay[(Segment==D2S[i]),])
      TempD3 <- rbind(TempD3,SpeyBay[(Segment==D3S[i]),])
      TempD4 <- rbind(TempD4,SpeyBay[(Segment==D4S[i]),])
      TempE2 <- rbind(TempE2,SpeyBay[(Segment==E2S[i]),])
      TempE3 <- rbind(TempE3,SpeyBay[(Segment==E3S[i]),])
      TempE4 <- rbind(TempE4,SpeyBay[(Segment==E4S[i]),])
   }
   # But actually I only want a certain number of rows of data...
   NewD2 <- TempD2[1:SpringWatch,]   
   NewD3 <- TempD3[1:SummerWatch,]   
   NewD4 <- TempD4[1:AutumnWatch,]   
   NewE2 <- TempE2[1:SpringWatch,]   
   NewE3 <- TempE3[1:SummerWatch,]   
   NewE4 <- TempE4[1:AutumnWatch,]   

   # then combine together (could do this in one step!
   NewD <- rbind(NewD2,NewD3,NewD4)
   NewE <- rbind(NewE2,NewE3,NewE4)

   CompDE <- rbind(NewD,NewE)

   #Run a GLM-GEE on the resampled distributions to see if there is a
statistical difference between years 

   NewGLMGEE1 <-
geeglm(CetPres~Year++SeaState,data=CompDE,family=binomial,id=Segment,corstr="ar1")
   pv <- summary(NewGLMGEE1)$coefficients[, "Pr(>|W|)"]  ## will extract
them
   signif[j] <- pv[2] # only interested in the significance of Year in the
model
}








--
View this message in context: http://r.789695.n4.nabble.com/For-loop-processing-too-slow-pre-format-data-frame-tp4689543.html
Sent from the R help mailing list archive at Nabble.com.



From evan.cooch at gmail.com  Sat Apr 26 22:54:32 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Sat, 26 Apr 2014 16:54:32 -0400
Subject: [R] help using extrafont package | R graphics
Message-ID: <535C1D08.80609@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140426/76e16220/attachment-0001.pl>

From nicomet80 at gmail.com  Sun Apr 27 02:37:11 2014
From: nicomet80 at gmail.com (Nico Met)
Date: Sun, 27 Apr 2014 01:37:11 +0100
Subject: [R] average and median values for each of the class
Message-ID: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/c48e0fe4/attachment-0001.pl>

From dulcalma at bigpond.com  Sun Apr 27 03:06:58 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 27 Apr 2014 11:06:58 +1000
Subject: [R] lattice plot formatting: pch, abbreviation and labels
In-Reply-To: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>
References: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>
Message-ID: <002a01cf61b4$fdd47300$f97d5900$@bigpond.com>

Hi Luigi

You are typing things unnecessarily: do not use the attach command unless
absolutely necessary - it has unfortunate consequences.
It is better to use with or within.
alpha is not available with some devices with bad consequences if used; its
default is 1 anyway.

Once you have stated a data.frame as the data object it is usually not
necessary to use the data.frame$ sign in to signify column names: use the
column names.
data = "a data.frame" is the equivalent to with

You are reordering the levels of stimulation and changing the name of 1 so I
thought it was easiest to make a column stim and do things there otherwise
it the relevelling could be done in the data argument using the subset
argument. Then the change to "Unst" could be done by using  strip    =
strip.custom(factor.levels = ...),

To change for the -/+ I made a group - the easiest way.
Have a look a changing the negative symbol to 20 or something else as it is
hard to visualise. You may vary things with changing cex (remember to have 2
values 1 for each group).

If you do str(xyplot object) you will get a big print of the object and
within that the x limits are shown as "0", "1" which means that the x values
are 1 and 2
There is a command to get these things but I have forgotten it

my.data$stimulation <- factor(levels = c("Unstimulated",
"ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
my.data$stim <- factor(my.data$stimulation, labels = c("Unst.",
"ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
my.data$pos <- ifelse(sign(my.data$copy) > 0, 2,1)

  stripplot(copy ~ factor(positivity)|stim,my.data,
            groups = pos,
            hor = F,
            layout = c(8,1),
            scales = list(x = list(at = c(1,2),
                                   labels = c("N","P"))),
            jitter.x = TRUE,
            amount = 2,
            pch = c(16,1),
            col = "black",
            ylab = expression(bold("Copy")),
            xlab = expression(bold("Stimulation")),
            main="Plot",
            par.settings = list(strip.background=list(col="white")),
par.strip.text=list(font=2)
            )
            
Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Luigi Marongiu
Sent: Sunday, 27 April 2014 02:07
To: r-help at r-project.org
Subject: [R] lattice plot formatting: pch, abbreviation and labels

Dear all,
I am trying to use the lattice plot, but the syntax is quite
difficult. Specifically I have eight variables (1 to 8) each of them
further subdivided in two classes (negative=0 and positive=1). I am
using the stripplot() to represent these values. I would like to
represent the negative and positive values with black and white dots
so I have tried to use the argument pch=c(16, 1) both in the main
stripplot function and embedded in the scale argument. However the
resulting plot shows that some points are drawn with the pch=16 and
other with pch=1 irrespective of their class.
Is there a way to draw the values for the variable positivity = 0 with
pch=16 and those with positivity = 1 with pch=0?

In addition I would like to change the labels under the axis from 0,1
to N,P. However when I placed labels=c("N", "P") or labels=list("N",
"P") in the main stripplot() I did not obtained any difference and
when placed within the scale argument also the -labels were modified.
Is there a way to change the label 0 with N and the label 1 with P?

final problem: I would like to abbreviate the "Unstimulated" box label
with "Unst.". I have tried the abbreviate=TRUE argument but again the
syntax is too complex for me and it did not work.
Is there a way to abbreviate the variables names?

Thank you very much for your help.
Best wishes,
Luigi


CODE:::::::::


### open plot library
library(lattice)

my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
"Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
    column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 
192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.
8765622,499.2899303,
 
2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611
.486543,6205.229575,
 
870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418
.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 
142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.
3543635,3167.959757,
 
3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2
466141,9600.963594,
 
1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958
.495138,7224.503437,
 
208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73
980805,8930.784541,
 
4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.26
4531581,1518.610307,
 
2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7
034054,24043.61463,
 
0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,72
65.573875,
 
97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795
.75462,30676.769,
 
5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.
178549,1792.679176,
 
3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,1694
1.865,31453.96708,
 
2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.
88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")
attach(my.data)

stripplot(my.data$copy ~
factor(my.data$positivity)|factor(my.data$stimulation,
            levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
"Rv2654", "Rv3879", "Rv3873","PHA")),
            my.data, hor=F, layout = c(8,1), scales = list(relation =
"same"),
      jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
      ylab=expression(bold("Copy")),
xlab=expression(bold("Stimulation")), main="Plot",
      par.settings = list(strip.background=list(col="white")),
            par.strip.text=list(font=2))

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Apr 27 03:14:38 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Apr 2014 18:14:38 -0700 (PDT)
Subject: [R] average and median values for each of the class
In-Reply-To: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
Message-ID: <1398561278.66105.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
Your dput() suggests dat as data.frame.
##Using the results you got,

res2 <- do.call(rbind,lapply(unique(dat$class),function(i) {x1 <-rbind(dat[dat$class==i,], avg[avg$class==i,], med[med$class==i,]); rownames(x1)[!grepl("ara",rownames(x1))] <- paste0(c("Avg", "Med"), i); x1}))


A.K.



On Saturday, April 26, 2014 8:39 PM, Nico Met <nicomet80 at gmail.com> wrote:
Dear all,



I have a matrix (dimension, 16 x 12) where? 2nd column represents class
(1,1,1,1,1,2,2,2, etc) information. I want to estimate average? and median
values for each of the class and add this information as a row at end of
the each classes.


for example:

dput(dat)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,

3L, 3L, 3L, 4L, 4L, 4L, 5L), name1 = c(2.554923977, 2.371586762,

2.497293431, 2.464827875, 2.981934845, 2.228995664, 2.099640729,

1.900314302, 2.630005966, 2.632590262, 2.581887814, 2.408797563,

2.098761103, 3.070460716, 1.436980716, 1.645121806), name2 = c(1.297412278,

1.104804244, 1.30621114, 1.126009533, 1.466740841, 1.012041118,

0.923466541, 0.840575023, 1.285530176, 1.041909333, 1.194917856,

1.085015826, 1.047492703, 1.587558217, 0.593340012, 0.723630088

), name3 = c(0.587160798, 0.596127884, 0.623760721, 0.549016135,

0.686642084, 0.487523394, 0.458620467, 0.397974913, 0.615928976,

0.546005649, 0.657383069, 0.546613129, 0.476503461, 0.749062102,

0.304160587, 0.29037358), name4 = c(2.833441759, 2.713374426,

2.532626548, 2.409093102, 3.014912721, 2.113507947, 2.017291324,

1.667744912, 2.602560666, 2.31649643, 2.761204809, 2.433963493,

2.229911767, 3.191646399, 1.269919241, 1.387479858), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 1.791300389,

1.669079382, 1.500209628, 2.164401874, 1.830038378, 2.106750025,

1.92888294, 1.707217549, 2.585082653, 1.114841754, 1.315712452

), name6 = c(0.715129844, 0.688186262, 0.70133748, 0.709362008,

0.712145174, 0.563593885, 0.532109761, 0.472197304, 0.690165016,

0.65635473, 0.615835066, 0.64310098, 0.562974891, 0.900622255,

0.408546784, 0.416284408), name7 = c(1.995505133, 1.860095899,

1.843151597, 1.709861774, 2.155993511, 1.506409746, 1.315405587,

1.234544153, 1.96629927, 1.74879757, 1.93994009, 1.660173854,

1.556735295, 2.355723318, 0.866634243, 1.013367677), name8 = c(0.275484997,

0.233856392, 0.294021245, 0.315504347, 0.251906585, 0.250263636,

0.348599173, 0.273806933, 0.32067937, 0.278581115, 0.293726291,

0.308350808, 0.201297444, 0.351927886, 0.204230625, 0.185681471

), name9 = c(2.461066627, 2.210756164, 2.289047888, 2.253988252,

2.668184733, 1.911697836, 1.793443775, 1.560027186, 2.36941155,

1.961911111, 2.391501376, 2.002215107, 1.932144233, 2.73705052,

1.15580754, 1.807697999), name10 = c(0.723025351, 0.613147422,

0.805399925, 0.65651577, 0.779389048, 0.54260459, 0.492283542,

0.507969501, 0.749700016, 0.644231327, 0.810319215, 0.620331891,

0.600240557, 0.884775748, 0.40006142, 0.391661912), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.361013073,

0.430744786, 0.468818055, 0.166072668, 0.369262627, 0.297666411,

0.256091173, 0.123021464, 0.308188684, 0.646436241, 0.722972632

)), .Names = c("class", "name1", "name2", "name3", "name4", "name5",

"name6", "name7", "name8", "name9", "name10", "name11"), class = "data.frame",
row.names = c("ara1",

"ara2", "ara3", "ara4", "ara5", "ara6", "ara7", "ara8", "ara9",

"ara10", "ara11", "ara12", "ara13", "ara14", "ara15", "ara16"

))


I wrote this:



avg<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"],
function(x) mean(x,na.rm=T)) )


med<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x)
median(x,na.rm=T)) )


# avg

#? class? ? name1? ?  name2? ?  name3? ? name4? ? name5? ?  name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?  1 2.574113 1.2602356 0.6085415 2.700690 2.124379 0.7052322 1.912922
#0.2741547 2.376609 0.7154955 0.3654845

#2? ?  2 2.214739 1.0154032 0.4900119 2.100276 1.781248 0.5645165 1.505665
#0.2983373 1.908645 0.5731394 0.3566621

#3? ?  3 2.541092 1.1072810 0.5833339 2.503888 1.955224 0.6384303 1.782971
#0.2935527 2.118543 0.6916275 0.3076734

#4? ?  4 2.202068 1.0761303 0.5099087 2.230492 1.802381 0.6240480 1.593031
#0.2524853 1.941667 0.6283592 0.3592155

#5? ?  5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726

#> med

#? class? ? name1? ?  name2? ?  name3? ? name4? ? name5? ?  name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?  1 2.497293 1.2974123 0.5961279 2.713374 2.141073 0.7093620 1.860096
#0.2754850 2.289048 0.7230254 0.3637169

#2? ?  2 2.164318 0.9677538 0.4730719 2.065400 1.730190 0.5478518 1.410908
#0.2972432 1.852571 0.5252870 0.3958789

#3? ?  3 2.581888 1.0850158 0.5466131 2.433963 1.928883 0.6431010 1.748798
#0.2937263 2.002215 0.6442313 0.2976664

#4? ?  4 2.098761 1.0474927 0.4765035 2.229912 1.707218 0.5629749 1.556735
#0.2042306 1.932144 0.6002406 0.3081887

#5? ?  5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726




But I do not know how can I add this information in the original data?


For example, for class 1, the output will look like this:

dput(res1)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 1L, 1L), name1 =
c(2.554923977,

2.371586762, 2.497293431, 2.464827875, 2.981934845, 2.574113378,

2.497293431), name2 = c(1.297412278, 1.104804244, 1.30621114,

1.126009533, 1.466740841, 1.260235607, 1.297412278), name3 = c(0.587160798,

0.596127884, 0.623760721, 0.549016135, 0.686642084, 0.608541525,

0.596127884), name4 = c(2.833441759, 2.713374426, 2.532626548,

2.409093102, 3.014912721, 2.700689711, 2.713374426), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 2.124379049,

2.141072829), name6 = c(0.715129844, 0.688186262, 0.70133748,

0.709362008, 0.712145174, 0.705232154, 0.709362008), name7 = c(1.995505133,

1.860095899, 1.843151597, 1.709861774, 2.155993511, 1.912921583,

1.860095899), name8 = c(0.275484997, 0.233856392, 0.294021245,

0.315504347, 0.251906585, 0.274154713, 0.275484997), name9 = c(2.461066627,

2.210756164, 2.289047888, 2.253988252, 2.668184733, 2.376608733,

2.289047888), name10 = c(0.723025351, 0.613147422, 0.805399925,

0.65651577, 0.779389048, 0.715495503, 0.723025351), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.365484455,

0.363716904)), .Names = c("class", "name1", "name2", "name3",

"name4", "name5", "name6", "name7", "name8", "name9", "name10",

"name11"), class = "data.frame", row.names = c("ara1", "ara2",

"ara3", "ara4", "ara5", "Avg", "Med"))



And same will be for other classes.


Thanks a lot !!!!


Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sun Apr 27 06:54:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 26 Apr 2014 21:54:44 -0700
Subject: [R] average and median values for each of the class
In-Reply-To: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
Message-ID: <78364FB1-78D7-4192-9AB4-6239CEFCE10A@comcast.net>


On Apr 26, 2014, at 5:37 PM, Nico Met wrote:

> Dear all,
> 
> 
> 
> I have a matrix (dimension, 16 x 12) where  2nd column represents class
> (1,1,1,1,1,2,2,2, etc) information. I want to estimate average  and median
> values for each of the class and add this information as a row at end of
> the each classes.
> 
Well it does have a dimension attribute but it is a data.frame, NOT a matrix. The term "class" is a reserved word in R. What is it that you mean by that word? if it is for each column then:

sapply( dat, function(x) c( mean(x), median(x)) )



> sapply( dat, function(x) c( mean_x = mean(x), median_x = median(x)) )
          class    name1    name2     name3    name4    name5     name6
mean_x   2.4375 2.350258 1.102291 0.5358036 2.343448 1.895963 0.6242466
median_x 2.0000 2.436813 1.094910 0.5478146 2.421528 1.942289 0.6497279
           name7     name8    name9    name10    name11
mean_x   1.67054 0.2742449 2.094122 0.6388536 0.3736069
median_x 1.72933 0.2770331 2.106486 0.6322816 0.3623650

-- 
David.


> 
> for example:
> 
> dput(dat)
> 
> structure(list(class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 
> 3L, 3L, 3L, 4L, 4L, 4L, 5L), name1 = c(2.554923977, 2.371586762,
> 
> 2.497293431, 2.464827875, 2.981934845, 2.228995664, 2.099640729,
> 
> 1.900314302, 2.630005966, 2.632590262, 2.581887814, 2.408797563,
> 
> 2.098761103, 3.070460716, 1.436980716, 1.645121806), name2 = c(1.297412278,
> 
> 1.104804244, 1.30621114, 1.126009533, 1.466740841, 1.012041118,
> 
> 0.923466541, 0.840575023, 1.285530176, 1.041909333, 1.194917856,
> 
> 1.085015826, 1.047492703, 1.587558217, 0.593340012, 0.723630088
> 
> ), name3 = c(0.587160798, 0.596127884, 0.623760721, 0.549016135,
> 
> 0.686642084, 0.487523394, 0.458620467, 0.397974913, 0.615928976,
> 
> 0.546005649, 0.657383069, 0.546613129, 0.476503461, 0.749062102,
> 
> 0.304160587, 0.29037358), name4 = c(2.833441759, 2.713374426,
> 
> 2.532626548, 2.409093102, 3.014912721, 2.113507947, 2.017291324,
> 
> 1.667744912, 2.602560666, 2.31649643, 2.761204809, 2.433963493,
> 
> 2.229911767, 3.191646399, 1.269919241, 1.387479858), name5 = c(2.172365295,
> 
> 1.955695471, 2.141072829, 1.975743278, 2.377018372, 1.791300389,
> 
> 1.669079382, 1.500209628, 2.164401874, 1.830038378, 2.106750025,
> 
> 1.92888294, 1.707217549, 2.585082653, 1.114841754, 1.315712452
> 
> ), name6 = c(0.715129844, 0.688186262, 0.70133748, 0.709362008,
> 
> 0.712145174, 0.563593885, 0.532109761, 0.472197304, 0.690165016,
> 
> 0.65635473, 0.615835066, 0.64310098, 0.562974891, 0.900622255,
> 
> 0.408546784, 0.416284408), name7 = c(1.995505133, 1.860095899,
> 
> 1.843151597, 1.709861774, 2.155993511, 1.506409746, 1.315405587,
> 
> 1.234544153, 1.96629927, 1.74879757, 1.93994009, 1.660173854,
> 
> 1.556735295, 2.355723318, 0.866634243, 1.013367677), name8 = c(0.275484997,
> 
> 0.233856392, 0.294021245, 0.315504347, 0.251906585, 0.250263636,
> 
> 0.348599173, 0.273806933, 0.32067937, 0.278581115, 0.293726291,
> 
> 0.308350808, 0.201297444, 0.351927886, 0.204230625, 0.185681471
> 
> ), name9 = c(2.461066627, 2.210756164, 2.289047888, 2.253988252,
> 
> 2.668184733, 1.911697836, 1.793443775, 1.560027186, 2.36941155,
> 
> 1.961911111, 2.391501376, 2.002215107, 1.932144233, 2.73705052,
> 
> 1.15580754, 1.807697999), name10 = c(0.723025351, 0.613147422,
> 
> 0.805399925, 0.65651577, 0.779389048, 0.54260459, 0.492283542,
> 
> 0.507969501, 0.749700016, 0.644231327, 0.810319215, 0.620331891,
> 
> 0.600240557, 0.884775748, 0.40006142, 0.391661912), name11 = c(0.308565619,
> 
> 0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.361013073,
> 
> 0.430744786, 0.468818055, 0.166072668, 0.369262627, 0.297666411,
> 
> 0.256091173, 0.123021464, 0.308188684, 0.646436241, 0.722972632
> 
> )), .Names = c("class", "name1", "name2", "name3", "name4", "name5",
> 
> "name6", "name7", "name8", "name9", "name10", "name11"), class = "data.frame",
> row.names = c("ara1",
> 
> "ara2", "ara3", "ara4", "ara5", "ara6", "ara7", "ara8", "ara9",
> 
> "ara10", "ara11", "ara12", "ara13", "ara14", "ara15", "ara16"
> 
> ))
> 
> 
> I wrote this:
> 
> 
> 
> avg<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"],
> function(x) mean(x,na.rm=T)) )
> 
> 
> med<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x)
> median(x,na.rm=T)) )
> 
> 
> # avg
> 
> #  class    name1     name2     name3    name4    name5     name6    name7
>    name#8    name9    name10    name11
> 
> #1     1 2.574113 1.2602356 0.6085415 2.700690 2.124379 0.7052322 1.912922
> #0.2741547 2.376609 0.7154955 0.3654845
> 
> #2     2 2.214739 1.0154032 0.4900119 2.100276 1.781248 0.5645165 1.505665
> #0.2983373 1.908645 0.5731394 0.3566621
> 
> #3     3 2.541092 1.1072810 0.5833339 2.503888 1.955224 0.6384303 1.782971
> #0.2935527 2.118543 0.6916275 0.3076734
> 
> #4     4 2.202068 1.0761303 0.5099087 2.230492 1.802381 0.6240480 1.593031
> #0.2524853 1.941667 0.6283592 0.3592155
> 
> #5     5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
> #0.1856815 1.807698 0.3916619 0.7229726
> 
> #> med
> 
> #  class    name1     name2     name3    name4    name5     name6    name7
>    name#8    name9    name10    name11
> 
> #1     1 2.497293 1.2974123 0.5961279 2.713374 2.141073 0.7093620 1.860096
> #0.2754850 2.289048 0.7230254 0.3637169
> 
> #2     2 2.164318 0.9677538 0.4730719 2.065400 1.730190 0.5478518 1.410908
> #0.2972432 1.852571 0.5252870 0.3958789
> 
> #3     3 2.581888 1.0850158 0.5466131 2.433963 1.928883 0.6431010 1.748798
> #0.2937263 2.002215 0.6442313 0.2976664
> 
> #4     4 2.098761 1.0474927 0.4765035 2.229912 1.707218 0.5629749 1.556735
> #0.2042306 1.932144 0.6002406 0.3081887
> 
> #5     5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
> #0.1856815 1.807698 0.3916619 0.7229726
> 
> 
> 
> 
> But I do not know how can I add this information in the original data?
> 
> 
> For example, for class 1, the output will look like this:
> 
> dput(res1)
> 
> structure(list(class = c(1L, 1L, 1L, 1L, 1L, 1L, 1L), name1 =
> c(2.554923977,
> 
> 2.371586762, 2.497293431, 2.464827875, 2.981934845, 2.574113378,
> 
> 2.497293431), name2 = c(1.297412278, 1.104804244, 1.30621114,
> 
> 1.126009533, 1.466740841, 1.260235607, 1.297412278), name3 = c(0.587160798,
> 
> 0.596127884, 0.623760721, 0.549016135, 0.686642084, 0.608541525,
> 
> 0.596127884), name4 = c(2.833441759, 2.713374426, 2.532626548,
> 
> 2.409093102, 3.014912721, 2.700689711, 2.713374426), name5 = c(2.172365295,
> 
> 1.955695471, 2.141072829, 1.975743278, 2.377018372, 2.124379049,
> 
> 2.141072829), name6 = c(0.715129844, 0.688186262, 0.70133748,
> 
> 0.709362008, 0.712145174, 0.705232154, 0.709362008), name7 = c(1.995505133,
> 
> 1.860095899, 1.843151597, 1.709861774, 2.155993511, 1.912921583,
> 
> 1.860095899), name8 = c(0.275484997, 0.233856392, 0.294021245,
> 
> 0.315504347, 0.251906585, 0.274154713, 0.275484997), name9 = c(2.461066627,
> 
> 2.210756164, 2.289047888, 2.253988252, 2.668184733, 2.376608733,
> 
> 2.289047888), name10 = c(0.723025351, 0.613147422, 0.805399925,
> 
> 0.65651577, 0.779389048, 0.715495503, 0.723025351), name11 = c(0.308565619,
> 
> 0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.365484455,
> 
> 0.363716904)), .Names = c("class", "name1", "name2", "name3",
> 
> "name4", "name5", "name6", "name7", "name8", "name9", "name10",
> 
> "name11"), class = "data.frame", row.names = c("ara1", "ara2",
> 
> "ara3", "ara4", "ara5", "Avg", "Med"))
> 
> 
> 
> And same will be for other classes.
> 
> 
> Thanks a lot !!!!
> 
> 
> Nico
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From a.chandhial at btinternet.com  Sun Apr 27 10:14:38 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Sun, 27 Apr 2014 09:14:38 +0100 (BST)
Subject: [R] time when packages installed
Message-ID: <1398586478.58278.YahooMailNeo@web186003.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/8bfd0dd7/attachment-0001.pl>

From bhh at xs4all.nl  Sun Apr 27 11:01:51 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 27 Apr 2014 11:01:51 +0200
Subject: [R] average and median values for each of the class
In-Reply-To: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
Message-ID: <7BC993EE-D9A9-4287-980A-8B1F78007445@xs4all.nl>


On 27-04-2014, at 02:37, Nico Met <nicomet80 at gmail.com> wrote:

> Dear all,
> 
> 
> 
> I have a matrix (dimension, 16 x 12) where  2nd column represents class
> (1,1,1,1,1,2,2,2, etc) information. I want to estimate average  and median
> values for each of the class and add this information as a row at end of
> the each classes.
> 
> 
> for example:
> 
> dput(dat)
> 
> structure(list(class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 
> 3L, 3L, 3L, 4L, 4L, 4L, 5L), name1 = c(2.554923977, 2.371586762,
> 
> 2.497293431, 2.464827875, 2.981934845, 2.228995664, 2.099640729,
> 
> 1.900314302, 2.630005966, 2.632590262, 2.581887814, 2.408797563,
> 
> 2.098761103, 3.070460716, 1.436980716, 1.645121806), name2 = c(1.297412278,
> 
> 1.104804244, 1.30621114, 1.126009533, 1.466740841, 1.012041118,
> 
> 0.923466541, 0.840575023, 1.285530176, 1.041909333, 1.194917856,
> 
> 1.085015826, 1.047492703, 1.587558217, 0.593340012, 0.723630088
> 
> ), name3 = c(0.587160798, 0.596127884, 0.623760721, 0.549016135,
> 
> 0.686642084, 0.487523394, 0.458620467, 0.397974913, 0.615928976,
> 
> 0.546005649, 0.657383069, 0.546613129, 0.476503461, 0.749062102,
> 
> 0.304160587, 0.29037358), name4 = c(2.833441759, 2.713374426,
> 
> 2.532626548, 2.409093102, 3.014912721, 2.113507947, 2.017291324,
> 
> 1.667744912, 2.602560666, 2.31649643, 2.761204809, 2.433963493,
> 
> 2.229911767, 3.191646399, 1.269919241, 1.387479858), name5 = c(2.172365295,
> 
> 1.955695471, 2.141072829, 1.975743278, 2.377018372, 1.791300389,
> 
> 1.669079382, 1.500209628, 2.164401874, 1.830038378, 2.106750025,
> 
> 1.92888294, 1.707217549, 2.585082653, 1.114841754, 1.315712452
> 
> ), name6 = c(0.715129844, 0.688186262, 0.70133748, 0.709362008,
> 
> 0.712145174, 0.563593885, 0.532109761, 0.472197304, 0.690165016,
> 
> 0.65635473, 0.615835066, 0.64310098, 0.562974891, 0.900622255,
> 
> 0.408546784, 0.416284408), name7 = c(1.995505133, 1.860095899,
> 
> 1.843151597, 1.709861774, 2.155993511, 1.506409746, 1.315405587,
> 
> 1.234544153, 1.96629927, 1.74879757, 1.93994009, 1.660173854,
> 
> 1.556735295, 2.355723318, 0.866634243, 1.013367677), name8 = c(0.275484997,
> 
> 0.233856392, 0.294021245, 0.315504347, 0.251906585, 0.250263636,
> 
> 0.348599173, 0.273806933, 0.32067937, 0.278581115, 0.293726291,
> 
> 0.308350808, 0.201297444, 0.351927886, 0.204230625, 0.185681471
> 
> ), name9 = c(2.461066627, 2.210756164, 2.289047888, 2.253988252,
> 
> 2.668184733, 1.911697836, 1.793443775, 1.560027186, 2.36941155,
> 
> 1.961911111, 2.391501376, 2.002215107, 1.932144233, 2.73705052,
> 
> 1.15580754, 1.807697999), name10 = c(0.723025351, 0.613147422,
> 
> 0.805399925, 0.65651577, 0.779389048, 0.54260459, 0.492283542,
> 
> 0.507969501, 0.749700016, 0.644231327, 0.810319215, 0.620331891,
> 
> 0.600240557, 0.884775748, 0.40006142, 0.391661912), name11 = c(0.308565619,
> 
> 0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.361013073,
> 
> 0.430744786, 0.468818055, 0.166072668, 0.369262627, 0.297666411,
> 
> 0.256091173, 0.123021464, 0.308188684, 0.646436241, 0.722972632
> 
> )), .Names = c("class", "name1", "name2", "name3", "name4", "name5",
> 
> "name6", "name7", "name8", "name9", "name10", "name11"), class = "data.frame",
> row.names = c("ara1",
> 
> "ara2", "ara3", "ara4", "ara5", "ara6", "ara7", "ara8", "ara9",
> 
> "ara10", "ara11", "ara12", "ara13", "ara14", "ara15", "ara16"
> 
> ))
> 
> 
> I wrote this:
> 
> 
> 
> avg<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"],
> function(x) mean(x,na.rm=T)) )
> 
> 
> med<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x)
> median(x,na.rm=T)) )
> 
> 
> # avg
> 
> #  class    name1     name2     name3    name4    name5     name6    name7
>    name#8    name9    name10    name11
> 
> #1     1 2.574113 1.2602356 0.6085415 2.700690 2.124379 0.7052322 1.912922
> #0.2741547 2.376609 0.7154955 0.3654845
> 
> #2     2 2.214739 1.0154032 0.4900119 2.100276 1.781248 0.5645165 1.505665
> #0.2983373 1.908645 0.5731394 0.3566621
> 
> #3     3 2.541092 1.1072810 0.5833339 2.503888 1.955224 0.6384303 1.782971
> #0.2935527 2.118543 0.6916275 0.3076734
> 
> #4     4 2.202068 1.0761303 0.5099087 2.230492 1.802381 0.6240480 1.593031
> #0.2524853 1.941667 0.6283592 0.3592155
> 
> #5     5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
> #0.1856815 1.807698 0.3916619 0.7229726
> 
> #> med
> 
> #  class    name1     name2     name3    name4    name5     name6    name7
>    name#8    name9    name10    name11
> 
> #1     1 2.497293 1.2974123 0.5961279 2.713374 2.141073 0.7093620 1.860096
> #0.2754850 2.289048 0.7230254 0.3637169
> 
> #2     2 2.164318 0.9677538 0.4730719 2.065400 1.730190 0.5478518 1.410908
> #0.2972432 1.852571 0.5252870 0.3958789
> 
> #3     3 2.581888 1.0850158 0.5466131 2.433963 1.928883 0.6431010 1.748798
> #0.2937263 2.002215 0.6442313 0.2976664
> 
> #4     4 2.098761 1.0474927 0.4765035 2.229912 1.707218 0.5629749 1.556735
> #0.2042306 1.932144 0.6002406 0.3081887
> 
> #5     5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
> #0.1856815 1.807698 0.3916619 0.7229726
> 
> 
> 
> 
> But I do not know how can I add this information in the original data?
> 
> 
> For example, for class 1, the output will look like this:
> 
> dput(res1)
> 
> structure(list(class = c(1L, 1L, 1L, 1L, 1L, 1L, 1L), name1 =
> c(2.554923977,
> 
> 2.371586762, 2.497293431, 2.464827875, 2.981934845, 2.574113378,
> 
> 2.497293431), name2 = c(1.297412278, 1.104804244, 1.30621114,
> 
> 1.126009533, 1.466740841, 1.260235607, 1.297412278), name3 = c(0.587160798,
> 
> 0.596127884, 0.623760721, 0.549016135, 0.686642084, 0.608541525,
> 
> 0.596127884), name4 = c(2.833441759, 2.713374426, 2.532626548,
> 
> 2.409093102, 3.014912721, 2.700689711, 2.713374426), name5 = c(2.172365295,
> 
> 1.955695471, 2.141072829, 1.975743278, 2.377018372, 2.124379049,
> 
> 2.141072829), name6 = c(0.715129844, 0.688186262, 0.70133748,
> 
> 0.709362008, 0.712145174, 0.705232154, 0.709362008), name7 = c(1.995505133,
> 
> 1.860095899, 1.843151597, 1.709861774, 2.155993511, 1.912921583,
> 
> 1.860095899), name8 = c(0.275484997, 0.233856392, 0.294021245,
> 
> 0.315504347, 0.251906585, 0.274154713, 0.275484997), name9 = c(2.461066627,
> 
> 2.210756164, 2.289047888, 2.253988252, 2.668184733, 2.376608733,
> 
> 2.289047888), name10 = c(0.723025351, 0.613147422, 0.805399925,
> 
> 0.65651577, 0.779389048, 0.715495503, 0.723025351), name11 = c(0.308565619,
> 
> 0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.365484455,
> 
> 0.363716904)), .Names = c("class", "name1", "name2", "name3",
> 
> "name4", "name5", "name6", "name7", "name8", "name9", "name10",
> 
> "name11"), class = "data.frame", row.names = c("ara1", "ara2",
> 
> "ara3", "ara4", "ara5", "Avg", "Med"))
> 
> 
> 
> And same will be for other classes.


Please do not post in HTML, as requested by Posting Guide.
It tends to mess things up and makes your code and results unreadable.

You cannot use ?Avg? and ?Med? unmodified as rownames.
For each ?class? (group would ba better name) you must append something different e.g. the ?class?-number.

Try this:

library(plyr)
g <- function(dat) { 
    avg <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) mean(x,na.rm=T)) )
    med <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) median(x,na.rm=T)) )   
    z <- rbind(dat,avg,med) 
    z
}
DAT1 <- ddply(dat,.(class),.fun=g)    
rownames(DAT1) <- do.call(c,lapply(split(dat,dat["class"]),
                                        FUN=function(x) c(rownames(x),paste0("Avg",x[,"class"][1]),paste0("Med",x[,"class"][1]))))
DAT1

Convoluted but it works. Maybe someone else can come up with something shorter and more elegant.

Berend



From murdoch.duncan at gmail.com  Sun Apr 27 11:50:31 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Apr 2014 05:50:31 -0400
Subject: [R] time when packages installed
In-Reply-To: <1398586478.58278.YahooMailNeo@web186003.mail.ir2.yahoo.com>
References: <1398586478.58278.YahooMailNeo@web186003.mail.ir2.yahoo.com>
Message-ID: <535CD2E7.1040605@gmail.com>

On 27/04/2014, 4:14 AM, amarjit chandhial wrote:
>
>
> Is there a way in R to list the packages I installed by date ?
>
> Or to list the packages I installed in the last n days ?
>

R doesn't record that itself, but your OS probably does.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Sun Apr 27 12:29:24 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 27 Apr 2014 11:29:24 +0100
Subject: [R] time when packages installed
In-Reply-To: <535CD2E7.1040605@gmail.com>
References: <1398586478.58278.YahooMailNeo@web186003.mail.ir2.yahoo.com>
	<535CD2E7.1040605@gmail.com>
Message-ID: <535CDC04.1020808@stats.ox.ac.uk>

On 27/04/2014 10:50, Duncan Murdoch wrote:
> On 27/04/2014, 4:14 AM, amarjit chandhial wrote:
>>
>>
>> Is there a way in R to list the packages I installed by date ?
>>
>> Or to list the packages I installed in the last n days ?
>>
>
> R doesn't record that itself, but your OS probably does.

It must do.  So see ?dir and ?file.info.  E.g.

pkgs <- dir(.libPaths(), full.names = TRUE)
finf <- file.info(pkgs)
finf[difftime(Sys.time(), finf[,"mtime"], units = "days") <= 2 , 4, 
drop=FALSE]

shows all those up to 2 days old.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From smartpink111 at yahoo.com  Sun Apr 27 13:11:41 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 27 Apr 2014 04:11:41 -0700 (PDT)
Subject: [R] average and median values for each of the class
In-Reply-To: <1398561278.66105.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
	<1398561278.66105.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1398597101.47358.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could also try:
library(plyr)


fun1 <- function(data, .group) {
??? f1 <- function(x) c(x, mean(x, na.rm = TRUE), median(x, na.rm = TRUE))
??? res <- ddply(data, .group, sapply, FUN = f1)
??? vec1 <- as.vector(table(res[, .group]))
??? indx <- sort(c(cumsum(vec1) - 1, cumsum(vec1)))
??? UniqGroup <- unique(data[, .group])
??? rownames(res)[indx] <- paste0(rep(c("Avg", "Med"), length(UniqGroup)), rep(UniqGroup, 
??????? each = 2))
??? rownames(res)[-indx] <- rownames(data)
??? res
}
fun1(dat,"class")
all.equal(res2,fun1(dat,"class"))
#[1] TRUE



A.K.




On Saturday, April 26, 2014 9:14 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Your dput() suggests dat as data.frame.
##Using the results you got,

res2 <- do.call(rbind,lapply(unique(dat$class),function(i) {x1 <-rbind(dat[dat$class==i,], avg[avg$class==i,], med[med$class==i,]); rownames(x1)[!grepl("ara",rownames(x1))] <- paste0(c("Avg", "Med"), i); x1}))


A.K.




On Saturday, April 26, 2014 8:39 PM, Nico Met <nicomet80 at gmail.com> wrote:
Dear all,



I have a matrix (dimension, 16 x 12) where? 2nd column represents class
(1,1,1,1,1,2,2,2, etc) information. I want to estimate average? and median
values for each of the class and add this information as a row at end of
the each classes.


for example:

dput(dat)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,

3L, 3L, 3L, 4L, 4L, 4L, 5L), name1 = c(2.554923977, 2.371586762,

2.497293431, 2.464827875, 2.981934845, 2.228995664, 2.099640729,

1.900314302, 2.630005966, 2.632590262, 2.581887814, 2.408797563,

2.098761103, 3.070460716, 1.436980716, 1.645121806), name2 = c(1.297412278,

1.104804244, 1.30621114, 1.126009533, 1.466740841, 1.012041118,

0.923466541, 0.840575023, 1.285530176, 1.041909333, 1.194917856,

1.085015826, 1.047492703, 1.587558217, 0.593340012, 0.723630088

), name3 = c(0.587160798, 0.596127884, 0.623760721, 0.549016135,

0.686642084, 0.487523394, 0.458620467, 0.397974913, 0.615928976,

0.546005649, 0.657383069, 0.546613129, 0.476503461, 0.749062102,

0.304160587, 0.29037358), name4 = c(2.833441759, 2.713374426,

2.532626548, 2.409093102, 3.014912721, 2.113507947, 2.017291324,

1.667744912, 2.602560666, 2.31649643, 2.761204809, 2.433963493,

2.229911767, 3.191646399, 1.269919241, 1.387479858), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 1.791300389,

1.669079382, 1.500209628, 2.164401874, 1.830038378, 2.106750025,

1.92888294, 1.707217549, 2.585082653, 1.114841754, 1.315712452

), name6 = c(0.715129844, 0.688186262, 0.70133748, 0.709362008,

0.712145174, 0.563593885, 0.532109761, 0.472197304, 0.690165016,

0.65635473, 0.615835066, 0.64310098, 0.562974891, 0.900622255,

0.408546784, 0.416284408), name7 = c(1.995505133, 1.860095899,

1.843151597, 1.709861774, 2.155993511, 1.506409746, 1.315405587,

1.234544153, 1.96629927, 1.74879757, 1.93994009, 1.660173854,

1.556735295, 2.355723318, 0.866634243, 1.013367677), name8 = c(0.275484997,

0.233856392, 0.294021245, 0.315504347, 0.251906585, 0.250263636,

0.348599173, 0.273806933, 0.32067937, 0.278581115, 0.293726291,

0.308350808, 0.201297444, 0.351927886, 0.204230625, 0.185681471

), name9 = c(2.461066627, 2.210756164, 2.289047888, 2.253988252,

2.668184733, 1.911697836, 1.793443775, 1.560027186, 2.36941155,

1.961911111, 2.391501376, 2.002215107, 1.932144233, 2.73705052,

1.15580754, 1.807697999), name10 = c(0.723025351, 0.613147422,

0.805399925, 0.65651577, 0.779389048, 0.54260459, 0.492283542,

0.507969501, 0.749700016, 0.644231327, 0.810319215, 0.620331891,

0.600240557, 0.884775748, 0.40006142, 0.391661912), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.361013073,

0.430744786, 0.468818055, 0.166072668, 0.369262627, 0.297666411,

0.256091173, 0.123021464, 0.308188684, 0.646436241, 0.722972632

)), .Names = c("class", "name1", "name2", "name3", "name4", "name5",

"name6", "name7", "name8", "name9", "name10", "name11"), class = "data.frame",
row.names = c("ara1",

"ara2", "ara3", "ara4", "ara5", "ara6", "ara7", "ara8", "ara9",

"ara10", "ara11", "ara12", "ara13", "ara14", "ara15", "ara16"

))


I wrote this:



avg<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"],
function(x) mean(x,na.rm=T)) )


med<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x)
median(x,na.rm=T)) )


# avg

#? class? ? name1? ?? name2? ?? name3? ? name4? ? name5? ?? name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?? 1 2.574113 1.2602356 0.6085415 2.700690 2.124379 0.7052322 1.912922
#0.2741547 2.376609 0.7154955 0.3654845

#2? ?? 2 2.214739 1.0154032 0.4900119 2.100276 1.781248 0.5645165 1.505665
#0.2983373 1.908645 0.5731394 0.3566621

#3? ?? 3 2.541092 1.1072810 0.5833339 2.503888 1.955224 0.6384303 1.782971
#0.2935527 2.118543 0.6916275 0.3076734

#4? ?? 4 2.202068 1.0761303 0.5099087 2.230492 1.802381 0.6240480 1.593031
#0.2524853 1.941667 0.6283592 0.3592155

#5? ?? 5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726

#> med

#? class? ? name1? ?? name2? ?? name3? ? name4? ? name5? ?? name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?? 1 2.497293 1.2974123 0.5961279 2.713374 2.141073 0.7093620 1.860096
#0.2754850 2.289048 0.7230254 0.3637169

#2? ?? 2 2.164318 0.9677538 0.4730719 2.065400 1.730190 0.5478518 1.410908
#0.2972432 1.852571 0.5252870 0.3958789

#3? ?? 3 2.581888 1.0850158 0.5466131 2.433963 1.928883 0.6431010 1.748798
#0.2937263 2.002215 0.6442313 0.2976664

#4? ?? 4 2.098761 1.0474927 0.4765035 2.229912 1.707218 0.5629749 1.556735
#0.2042306 1.932144 0.6002406 0.3081887

#5? ?? 5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726




But I do not know how can I add this information in the original data?


For example, for class 1, the output will look like this:

dput(res1)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 1L, 1L), name1 =
c(2.554923977,

2.371586762, 2.497293431, 2.464827875, 2.981934845, 2.574113378,

2.497293431), name2 = c(1.297412278, 1.104804244, 1.30621114,

1.126009533, 1.466740841, 1.260235607, 1.297412278), name3 = c(0.587160798,

0.596127884, 0.623760721, 0.549016135, 0.686642084, 0.608541525,

0.596127884), name4 = c(2.833441759, 2.713374426, 2.532626548,

2.409093102, 3.014912721, 2.700689711, 2.713374426), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 2.124379049,

2.141072829), name6 = c(0.715129844, 0.688186262, 0.70133748,

0.709362008, 0.712145174, 0.705232154, 0.709362008), name7 = c(1.995505133,

1.860095899, 1.843151597, 1.709861774, 2.155993511, 1.912921583,

1.860095899), name8 = c(0.275484997, 0.233856392, 0.294021245,

0.315504347, 0.251906585, 0.274154713, 0.275484997), name9 = c(2.461066627,

2.210756164, 2.289047888, 2.253988252, 2.668184733, 2.376608733,

2.289047888), name10 = c(0.723025351, 0.613147422, 0.805399925,

0.65651577, 0.779389048, 0.715495503, 0.723025351), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.365484455,

0.363716904)), .Names = c("class", "name1", "name2", "name3",

"name4", "name5", "name6", "name7", "name8", "name9", "name10",

"name11"), class = "data.frame", row.names = c("ara1", "ara2",

"ara3", "ara4", "ara5", "Avg", "Med"))



And same will be for other classes.


Thanks a lot !!!!


Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Sun Apr 27 14:33:48 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 27 Apr 2014 14:33:48 +0200
Subject: [R] average and median values for each of the class
In-Reply-To: <7BC993EE-D9A9-4287-980A-8B1F78007445@xs4all.nl>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
	<7BC993EE-D9A9-4287-980A-8B1F78007445@xs4all.nl>
Message-ID: <7CB3D70B-0F35-4428-AE15-720BB10024C2@xs4all.nl>


On 27-04-2014, at 11:01, Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> On 27-04-2014, at 02:37, Nico Met <nicomet80 at gmail.com> wrote:
> 
>> Dear all,
>> 
>> I have a matrix (dimension, 16 x 12) where  2nd column represents class
>> (1,1,1,1,1,2,2,2, etc) information. I want to estimate average  and median
>> values for each of the class and add this information as a row at end of
>> the each classes.
>> ?...
>> 
>> And same will be for other classes.
> 
> ??
> For each ?class? (group would ba better name) you must append something different e.g. the ?class?-number.
> 
> Try this:
> 
> library(plyr)
> g <- function(dat) { 
>    avg <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) mean(x,na.rm=T)) )
>    med <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) median(x,na.rm=T)) )   
>    z <- rbind(dat,avg,med) 
>    z
> }
> DAT1 <- ddply(dat,.(class),.fun=g)    
> rownames(DAT1) <- do.call(c,lapply(split(dat,dat["class"]),
>                                        FUN=function(x) c(rownames(x),paste0("Avg",x[,"class"][1]),paste0("Med",x[,"class"][1]))))
> DAT1
> 
> Convoluted but it works. Maybe someone else can come up with something shorter and more elegant.

Or something like this if you don?t want to use package plyr

g <- function(dat) { 
    avg <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) mean(x,na.rm=T)) )
    med <- as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x) median(x,na.rm=T)) )   
    z <- rbind(dat,avg,med)  
    rownames(z) <- c(rownames(dat),paste0("Avg",dat[,"class"][1]),paste0("Med",dat[,"class"][1]))   
    print(z)
    z
} 

D <- lapply(split(dat,dat["class"]),FUN=g)
DAT2 <- do.call(rbind, lapply(D, data.frame)) 
# alternatively         
# DAT2 <- do.call(rbind, lapply(D,FUN=function(x) x )) 
rownames(DAT2) <- sub("[0-9]+\\.","",rownames(DAT2))
DAT2


Berend



From kafi_dano at yahoo.com  Sun Apr 27 13:30:01 2014
From: kafi_dano at yahoo.com (kafi dano)
Date: Sun, 27 Apr 2014 04:30:01 -0700 (PDT)
Subject: [R] help me
Message-ID: <1398598201.37168.YahooMailNeo@web124704.mail.ne1.yahoo.com>

please help me and correct why this program give me error?
bcos I want to apply the condition follow the attached below? 


# program (R) used estimate beta of robust ridge (weighted stacklose) 
? rm(list=ls())
? library(MASS)
? library(mvoutlier)
? library(robustbase)
? library(car)
? library(quantreg) 
? n<-21
? p<-3
?? data<-read.csv('C:/Users/Kafi/Documents/stacklose.csv',header=TRUE)
???????????? cell<-data
????????????? y<-as.matrix(cell[,1])
????????????? x1<-cell[,2] 
????????????? x2<-cell[,3] 
????????????? x3<-cell[,4]
?stack<- as.matrix(data.frame(y,x1,x2,x3))
?stack
? d <- lm(y ~ x1+x2+x3)$residuals
? d1<-lm(y ~ x1+x2+x3)$fit
? d2<-abs(d)
? k<-4.685
? w<-NULL
?? for(i in 1:n){
?? if(d2<=k){w[i]=d{1-(d/k)^2}^2} else{w[i]=0}}
?? w


?
Kafi Dano Pati
Ph.D candidate ( mathematics/statistics)
Department of mathematical Science/ faculty of Science
University Technology Malaysia
81310 UTM, Johor Bahru, Johor, Malaysia
IC. NO. 201202F10234
Matric No. PS113113
HP. No.?00601117517559
E-mail: kafi_dano at yahoo.com
supervisor- Assoc. Prof. Robiah Binti Adnan

From pensterfuzzer at yahoo.de  Sun Apr 27 18:48:23 2014
From: pensterfuzzer at yahoo.de (Werner W.)
Date: Sun, 27 Apr 2014 17:48:23 +0100
Subject: [R] Problem with new(er) R version's matrix package
In-Reply-To: <21340.4173.717293.642419@stat.math.ethz.ch>
References: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>	<0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>	<CAMTWbJhsXZK98XyOrokt_qRoqXYkkD2DnnAwRD-fDT7n5G-R_Q@mail.gmail.com>
	<21340.4173.717293.642419@stat.math.ethz.ch>
Message-ID: <1398617303.69204.YahooMailNeo@web172903.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/fc6022e0/attachment-0001.pl>

From a.chandhial at btinternet.com  Sun Apr 27 19:00:14 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Sun, 27 Apr 2014 18:00:14 +0100 (BST)
Subject: [R] time when packages installed
In-Reply-To: <535CDC04.1020808@stats.ox.ac.uk>
References: <1398586478.58278.YahooMailNeo@web186003.mail.ir2.yahoo.com>
	<535CD2E7.1040605@gmail.com> <535CDC04.1020808@stats.ox.ac.uk>
Message-ID: <1398618014.51147.YahooMailNeo@web186002.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/979187fb/attachment-0001.pl>

From dulcalma at bigpond.com  Mon Apr 28 03:25:10 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 28 Apr 2014 11:25:10 +1000
Subject: [R] lattice plot formatting: pch, abbreviation and labels
In-Reply-To: <CAMk+s2SDJ13rQXzm_O503vYLF7nEPDVfRcXbNHwbDAzb6TB-Kg@mail.gmail.com>
References: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>	<002a01cf61b4$fdd47300$f97d5900$@bigpond.com>
	<CAMk+s2SDJ13rQXzm_O503vYLF7nEPDVfRcXbNHwbDAzb6TB-Kg@mail.gmail.com>
Message-ID: <001201cf6280$b3229e00$1967da00$@bigpond.com>

Hi Luigi

Here are 2 ways of doing it.

The first is a "cheats" way ie easy.

The second is a substitute for the proper way who's code eludes me at the moment. I changed the lty on the ablines  as it appears confusing and as you are bolding it seems more appropriate. A better way may be to change 1 line type.

stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
      my.data,
      group = positivity,
      hor=F,
      layout = c(8,1),
      scales = list(x = list(at = c(1,2), labels = c("N","P"))),
      jitter.data=TRUE, pch=c(16,1), col="black",
      ylab=expression(bold("Copy")),
      xlab=expression(bold("Stimulation")),
      main="Plot",
      par.settings = list(strip.background=list(col="white")),
            par.strip.text=list(font=2),
      key = list(space="top",
                 columns=2,
                 text=list(c("Positive", "Negative"), col="black"),
                 points=list(pch=c(16,1), col="black")),
      panel = function(x, y,...){
              pnl = panel.number()
              #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)

              panel.average(x, y, fun = mean, horizontal = F, lty = 3, col.line = c("red","black"), type = "l")

              panel.stripplot(x,y, ...)
            }
      )

stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
      my.data,
      group = positivity,
      hor=F,
      layout = c(8,1),
      scales = list(x = list(at = c(1,2), labels = c("N","P"))),
      jitter.data=TRUE, pch=c(16,1), col="black",
      ylab=expression(bold("Copy")),
      xlab=expression(bold("Stimulation")),
      main="Plot",
      par.settings = list(strip.background=list(col="white")),
            par.strip.text=list(font=2),
      key = list(space="top",
                 columns=2,
                 text=list(c("Positive", "Negative"), col="black"),
                 points=list(pch=c(16,1), col="black")),
      panel = function(x, y,...){
                pnl = panel.number()
                #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
                for (j in 1:2){
                  with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
                     panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )

              }

               panel.stripplot(x,y, ...)
            }
      )

Remember abline and panel.abline etc only take 1 line at a time so if you have more than 1 group you have 2 call it more than once 

Regards 
Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Monday, 28 April 2014 04:03
To: Duncan Mackay
Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels

Dear Duncan,
may I bother you a bit more with the same data set? I would like now
to add a segment corresponding to the median values, as we discussed
antecedently.
I have tried to use the code you wrote in the previous mails, but it
hasn't worked. First I have found the aggregate medians values and
assigned to datmeA, then pasted the code you wrote, but without
success. Would be possible to substitute the panel.abline with
panel.segments? but in this case how to tell lattice what are the
values for "N" or "P"?
Best wishes,
Luigi

CODE::::
library(lattice)

my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
"Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
    column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")


key.plot<-list(
  space="top", columns=2,
  text=list(c("Positive", "Negative"), col="black"),
  points=list(pch=c(16,1), col="black"))

datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)

stripplot(
      copy ~ factor(positivity)|factor(stimulation,
            levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654",
"Rv3879", "Rv3873","PHA")),
            group = positivity,
      my.data,
      hor=F,
      layout = c(8,1),
            scales = list(x = list(at = c(1,2), labels = c("N","P"))),
      jitter.data=TRUE, pch=c(16,1), col="black",
      ylab=expression(bold("Copy")),
xlab=expression(bold("Stimulation")), main="Plot",
      par.settings = list(strip.background=list(col="white")),
            par.strip.text=list(font=2),
      key = key.plot,
            panel = function(x, y){
              pnl = panel.number()
              panel.abline(h = datmeA[datmeA[,2]==

levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)

              panel.stripplot(x,y, ...)
            }
      )

On Sun, Apr 27, 2014 at 2:06 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> You are typing things unnecessarily: do not use the attach command unless
> absolutely necessary - it has unfortunate consequences.
> It is better to use with or within.
> alpha is not available with some devices with bad consequences if used; its
> default is 1 anyway.
>
> Once you have stated a data.frame as the data object it is usually not
> necessary to use the data.frame$ sign in to signify column names: use the
> column names.
> data = "a data.frame" is the equivalent to with
>
> You are reordering the levels of stimulation and changing the name of 1 so I
> thought it was easiest to make a column stim and do things there otherwise
> it the relevelling could be done in the data argument using the subset
> argument. Then the change to "Unst" could be done by using  strip    =
> strip.custom(factor.levels = ...),
>
> To change for the -/+ I made a group - the easiest way.
> Have a look a changing the negative symbol to 20 or something else as it is
> hard to visualise. You may vary things with changing cex (remember to have 2
> values 1 for each group).
>
> If you do str(xyplot object) you will get a big print of the object and
> within that the x limits are shown as "0", "1" which means that the x values
> are 1 and 2
> There is a command to get these things but I have forgotten it
>
> my.data$stimulation <- factor(levels = c("Unstimulated",
> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
> my.data$stim <- factor(my.data$stimulation, labels = c("Unst.",
> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
> my.data$pos <- ifelse(sign(my.data$copy) > 0, 2,1)
>
>   stripplot(copy ~ factor(positivity)|stim,my.data,
>             groups = pos,
>             hor = F,
>             layout = c(8,1),
>             scales = list(x = list(at = c(1,2),
>                                    labels = c("N","P"))),
>             jitter.x = TRUE,
>             amount = 2,
>             pch = c(16,1),
>             col = "black",
>             ylab = expression(bold("Copy")),
>             xlab = expression(bold("Stimulation")),
>             main="Plot",
>             par.settings = list(strip.background=list(col="white")),
> par.strip.text=list(font=2)
>             )
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Luigi Marongiu
> Sent: Sunday, 27 April 2014 02:07
> To: r-help at r-project.org
> Subject: [R] lattice plot formatting: pch, abbreviation and labels
>
> Dear all,
> I am trying to use the lattice plot, but the syntax is quite
> difficult. Specifically I have eight variables (1 to 8) each of them
> further subdivided in two classes (negative=0 and positive=1). I am
> using the stripplot() to represent these values. I would like to
> represent the negative and positive values with black and white dots
> so I have tried to use the argument pch=c(16, 1) both in the main
> stripplot function and embedded in the scale argument. However the
> resulting plot shows that some points are drawn with the pch=16 and
> other with pch=1 irrespective of their class.
> Is there a way to draw the values for the variable positivity = 0 with
> pch=16 and those with positivity = 1 with pch=0?
>
> In addition I would like to change the labels under the axis from 0,1
> to N,P. However when I placed labels=c("N", "P") or labels=list("N",
> "P") in the main stripplot() I did not obtained any difference and
> when placed within the scale argument also the -labels were modified.
> Is there a way to change the label 0 with N and the label 1 with P?
>
> final problem: I would like to abbreviate the "Unstimulated" box label
> with "Unst.". I have tried the abbreviate=TRUE argument but again the
> syntax is too complex for me and it did not work.
> Is there a way to abbreviate the variables names?
>
> Thank you very much for your help.
> Best wishes,
> Luigi
>
>
> CODE:::::::::
>
>
> ### open plot library
> library(lattice)
>
> my.data<-structure(list(
>    column_1 = 1:120,
>    column_2 = structure(c(
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
> "Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>     column_3 = structure(c(
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 0,0,0,0,0,0,0,0)),
>      column_4 = c(
>
> 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.
> 8765622,499.2899303,
>
> 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611
> .486543,6205.229575,
>
> 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418
> .651212,7345.712517,
>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>
> 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.
> 3543635,3167.959757,
>
> 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2
> 466141,9600.963594,
>
> 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958
> .495138,7224.503437,
>
> 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73
> 980805,8930.784541,
>
> 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.26
> 4531581,1518.610307,
>
> 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7
> 034054,24043.61463,
>
> 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,72
> 65.573875,
>
> 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795
> .75462,30676.769,
>
> 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.
> 178549,1792.679176,
>
> 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,1694
> 1.865,31453.96708,
>
> 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.
> 88646,26050.47191)),
> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
> c(NA, -120L),
>  class = "data.frame")
> attach(my.data)
>
> stripplot(my.data$copy ~
> factor(my.data$positivity)|factor(my.data$stimulation,
>             levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
> "Rv2654", "Rv3879", "Rv3873","PHA")),
>             my.data, hor=F, layout = c(8,1), scales = list(relation =
> "same"),
>       jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
> xlab=expression(bold("Stimulation")), main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From craigpoconnell at hotmail.com  Mon Apr 28 03:19:44 2014
From: craigpoconnell at hotmail.com (Craig O'Connell)
Date: Sun, 27 Apr 2014 21:19:44 -0400
Subject: [R] =?windows-1252?q?lme4_Error_Help=3A_=93maxstephalfit=85pwrssU?=
 =?windows-1252?q?pdate=94?=
Message-ID: <BLU169-W100522438783894807A10CBC7470@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140427/ab7cdcd2/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Mon Apr 28 08:32:55 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 28 Apr 2014 06:32:55 +0000
Subject: [R]
 =?windows-1252?q?lme4_Error_Help=3A_=93maxstephalfit=85pwrssU?=
 =?windows-1252?q?pdate=94?=
In-Reply-To: <BLU169-W100522438783894807A10CBC7470@phx.gbl>
References: <BLU169-W100522438783894807A10CBC7470@phx.gbl>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A40DE2@inbomail.inbo.be>

Dear Craig,

It is better to ask questions about lme4 at r-sig-mixed-models (in cc).

Are you using a recent version of lme4? Try upgrading lme4 and see if you still get the error.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Craig O'Connell
Verzonden: maandag 28 april 2014 3:20
Aan: r-help at r-project.org
Onderwerp: [R] lme4 Error Help: ?maxstephalfit?pwrssUpdate?

I am using a mixed model to assess the effects of various variables (i.e. treatment, density, visibility) on bee behavior (e.g., avoidance frequency - total avoidances per total visits; feeding frequency, and mating frequency).  Bee individuals is my random factor (n=63 different bees), whereas treatment type, animal density, and air visibility are my fixed factors.
However, when I run my models, I immediately get an error that I cannot fix.  Here is a sample of my data:
Bee   Treatment    Visits    Avoid   Feeding    Mating    Density   Visibility

1   C   5   0   5   0      5        4
2   C   4   0   3   0      5        4
3   C   3   0   3   0      5        4
...
63

1   PC  2   0   1   1      5        4
2   PC  3   0   0   3      5        4
3   PC  1   0   0   0      5        4
...
63

1   M   5   0   1   3      5        4
2   M   3   2   0   0      5        4
3   M   2   0   0   2      5        4
...
63One I create my .txt file, I being my coding in R by first loading lme4.  After that, my coding starts off as follows:
barrierdat = read.table("GLMMROW.txt", header=TRUE) barrierdat barrierdat$Visibility = as.factor(barrierdat$Visibility);
barrierdat$Density    = as.factor(barrierdat$Density);

p01.glmer = glmer(Avoidance~offset(log(Visits))+(1|Bee),            family=poisson,
                  data=egghead);  # null model; p02.glmer = glmer(Avoidance~offset(log(Visits))+(1|Bee)+Treatment,  family=poisson,
                  data=egghead);
p03.glmer = glmer(Avoidance~offset(log(Visits))+(1|Bee)+Visibility, family=poisson,
                  data=egghead);
p04.glmer = glmer(Avoidance~offset(log(Visits))+(1|Bee)+Density,    family=poisson,
                  data=egghead);However, upon immediately running my models (e.g. p01.glmer), I receive the error:
Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

Does anybody know what the issue is?  I ran similar data several weeks ago and had no issues.  Any Suggestions on how to proceed?

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.



From luca.cerone at gmail.com  Mon Apr 28 09:45:15 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Mon, 28 Apr 2014 09:45:15 +0200
Subject: [R] delay evaluation of expression
Message-ID: <CAFnz2--wMFDGHqQJGF-EQWERGfJG1hjabNc6sW-=z46QjkrMcA@mail.gmail.com>

Dear all,
in one of my packages I need to load some data from .Rdata files that
are to be used from
some functions (but not all off them). I would like to delay the
loading of this datasets
only when needed. In other cases I successfully used lazyLoad and
delayedAssign(),
but when I try to load a .Rdata file I get this message: Error: cannot
add bindings to a locked environment

What would be the best way to load such a db only the first time that is needed?
Thanks a lot for you help,

Cheers,
Luca



From caroline.lustenberger at hotmail.com  Mon Apr 28 12:03:55 2014
From: caroline.lustenberger at hotmail.com (Caroline Lustenberger)
Date: Mon, 28 Apr 2014 12:03:55 +0200
Subject: [R] linear mixed model for non-normal negative and continous data
Message-ID: <DUB110-W77FDB4E4F048BD295154DBE0470@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/5d0c088d/attachment-0001.pl>

From christoph.schlaechter at gmail.com  Mon Apr 28 10:37:53 2014
From: christoph.schlaechter at gmail.com (=?UTF-8?Q?Christoph_Schl=C3=A4chter?=)
Date: Mon, 28 Apr 2014 10:37:53 +0200
Subject: [R] subset of obersevation depending on multiple conditions
Message-ID: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/3a70af1d/attachment-0001.pl>

From dntssa at yahoo.com  Mon Apr 28 09:51:29 2014
From: dntssa at yahoo.com (john james)
Date: Mon, 28 Apr 2014 00:51:29 -0700 (PDT)
Subject: [R] Ridge regression for beta and gamma models
Message-ID: <1398671489.40062.YahooMailNeo@web125506.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/be1d5668/attachment-0001.pl>

From xmliu1988 at gmail.com  Mon Apr 28 10:43:33 2014
From: xmliu1988 at gmail.com (xmliu1988 at gmail.com)
Date: Mon, 28 Apr 2014 16:43:33 +0800
Subject: [R] Faster way to transform vector [3 8 4 6 1 5] to [2 6 3 5 1
	4]
References: <2014042617543124741425@gmail.com>, 
	<CAKL8G3FX6WrBKsQSqmf9LtHi4uoSAmy6ESQfXmC6K9W+Re9AEw@mail.gmail.com>
Message-ID: <201404281643309771193@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/d9699045/attachment-0001.pl>

From ivan.calandra at univ-fcomte.fr  Mon Apr 28 12:39:34 2014
From: ivan.calandra at univ-fcomte.fr (Ivan Calandra)
Date: Mon, 28 Apr 2014 12:39:34 +0200
Subject: [R] subset of obersevation depending on multiple conditions
In-Reply-To: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>
References: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>
Message-ID: <535E2FE6.2050709@univ-fcomte.fr>

Hi Christoph,

I'm not sure I understand your conditions. It is an "AND" or an "OR", 
i.e. must both conditions be met to subset or any one of them?
 From your explanation, I would think you really mean AND, but then I 
don't understand why you would select both lines 3 and 4.

I would just say:
df[df$N <= 0.3, ]
but I might be missing something.

You should also be careful with floating point numbers, I guess.

HTH,
Ivan

--
Ivan Calandra
University of Franche-Comt?
Laboratoire Chrono-Environnement
Bureau ATER -107L
16, Route de Gray
25030 Besan?on Cedex, France
ivan.calandra at univ-fcomte.fr
+33 (0) 381 66 20 60
http://chrono-environnement.univ-fcomte.fr/spip.php?article1830

Le 28/04/14 10:37, Christoph Schl?chter a ?crit :
> Hello,
>
> I want to subset a data.frame containing the variables "Date" in (%Y %m %d
> ) and "N".
>
> I want to print "Date" and "N" if  N is less than or equal to 0.3 and if
> "N" is also less than or equal to 0.3 on the day before the day where "N"
> is less than or equal to 0.3.
>
> This would be the case in line 3 and 4 , 6 and 7, 12 to 18, and so on.
>
> "Date"    "N"
> "1"    2010-01-01    0
> "2"    2010-01-02    1.9
> "3"    2010-01-03    0
> "4"    2010-01-04    0
> "5"    2010-01-05    1.6
> "6"    2010-01-06    0
> "7"    2010-01-07    0.3
> "8"    2010-01-08    0
> "9"    2010-01-09    1.1
> "10"    2010-01-10    1.7
> "11"    2010-01-11    2.6
> "12"    2010-01-12    0
> "13"    2010-01-13    0
> "14"    2010-01-14    0
> "15"    2010-01-15    0
> "16"    2010-01-16    0
> "17"    2010-01-17    0
> "18"    2010-01-18    0.2
> "19"    2010-01-19    0
> "20"    2010-01-20    0
> "21"    2010-01-21    0
> "22"    2010-01-22    0
> "23"    2010-01-23    0
> "24"    2010-01-24    0
> "25"    2010-01-25    0
> "26"    2010-01-26    0
> "27"    2010-01-27    1.9
> "28"    2010-01-28    6.2
> "29"    2010-01-29    0
> "30"    2010-01-30    0
>
> I tried some methods with subset but I couldn't work it out. Maybe I have
> to use something like " for (i in x) {} but as a beginner I really don't
> know how to do it.
>
> Can somebody please help me with this.
>
> Thanks in advance,
>
> Christoph
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Apr 28 12:54:27 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 28 Apr 2014 03:54:27 -0700 (PDT)
Subject: [R] average and median values for each of the class
In-Reply-To: <1398597101.47358.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAMMD=S6uLxB8xa=k6EScgXQPnucST_jdjYTsUSf8Jds9_R7jfQ@mail.gmail.com>
	<1398561278.66105.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1398597101.47358.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1398682467.13472.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
I noticed that if ?mean" or ?median in fun1 is changed to other functions, for e.g. ?sum, it will show error message.
##Using shortened version that runs
library(plyr)
fun1 <- function(data, .group) {
??? f1 <- function(x) c(x, mean(x, na.rm = TRUE), sum(x, na.rm = TRUE))
??? res <- ddply(data, .group, sapply, FUN = f1)
??? res
}
fun1(dat,"class")##check the value of class column. This creates error in the full version.

To be a bit more general, you can try this:
fun2 <- function(data, .group, funcVec) {
??? data <- data[order(data[, .group]), ]
??? f1 <- function(x) c(x, eval(parse(text = paste0("c(", paste(paste0(funcVec, "(", 
??????? "x,", "na.rm=TRUE", ")"), collapse = ","), ")"))))
??? res <- ddply(data, .group, sapply, FUN = f1)[, -1]
??? indx <- table(factor(data[, .group], levels = unique(data[, .group]))) + length(funcVec)
??? res <- cbind(class = as.numeric(rep(names(indx), indx)), res)
??? indxN <- as.numeric(sort(rep(cumsum(indx), length(funcVec)) - rep((seq(funcVec) - 
??????? 1), each = length(indx))))
??? UniqGroup <- unique(data[, .group])
??? rownames(res)[indxN] <- paste0(rep(gsub("[.]", "", toupper(abbreviate(funcVec, 
??????? min = 4))), length(UniqGroup)), rep(UniqGroup, each = length(funcVec)))
??? rownames(res)[-indxN] <- rownames(data)
??? res
}

vec1 <- c("mean", "median", "sd", "sum")
vec2 <- "mean"
vec3 <- c("mean", "median", "min", "max", "sd")
vec4 <- c("mean", "median", "min", "max", "sd", "sum", "var")
library(plotrix)? ## for ?std.error
vec5 <- c("mean", "median", "min", "max", "var", "sd", "std.error", "prod")
library(psych)? ### for ?skew,?kurtosi
vec6 <- c("mean", "median", "min", "max", "var", "sd", "std.error", "prod", "skew", 
??? "kurtosi")
fun2(dat, "class", vec1)
fun2(dat, "class", vec2)
fun2(dat, "class", vec3)
fun2(dat, "class", vec4)
fun2(dat, "class", vec5)
fun2(dat, "class", vec6)

#or running all the above in a loop
?lapply(paste0("vec",1:6),function(x) fun2(dat,"class",get(x)))
A.K.


On Sunday, April 27, 2014 7:11 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
You could also try:
library(plyr)


fun1 <- function(data, .group) {
??? f1 <- function(x) c(x, mean(x, na.rm = TRUE), median(x, na.rm = TRUE))
??? res <- ddply(data, .group, sapply, FUN = f1)
??? vec1 <- as.vector(table(res[, .group]))
??? indx <- sort(c(cumsum(vec1) - 1, cumsum(vec1)))
??? UniqGroup <- unique(data[, .group])
??? rownames(res)[indx] <- paste0(rep(c("Avg", "Med"), length(UniqGroup)), rep(UniqGroup, 
??????? each = 2))
??? rownames(res)[-indx] <- rownames(data)
??? res
}
fun1(dat,"class")
all.equal(res2,fun1(dat,"class"))
#[1] TRUE



A.K.





On Saturday, April 26, 2014 9:14 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Your dput() suggests dat as data.frame.
##Using the results you got,

res2 <- do.call(rbind,lapply(unique(dat$class),function(i) {x1 <-rbind(dat[dat$class==i,], avg[avg$class==i,], med[med$class==i,]); rownames(x1)[!grepl("ara",rownames(x1))] <- paste0(c("Avg", "Med"), i); x1}))


A.K.




On Saturday, April 26, 2014 8:39 PM, Nico Met <nicomet80 at gmail.com> wrote:
Dear all,



I have a matrix (dimension, 16 x 12) where? 2nd column represents class
(1,1,1,1,1,2,2,2, etc) information. I want to estimate average? and median
values for each of the class and add this information as a row at end of
the each classes.


for example:

dput(dat)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,

3L, 3L, 3L, 4L, 4L, 4L, 5L), name1 = c(2.554923977, 2.371586762,

2.497293431, 2.464827875, 2.981934845, 2.228995664, 2.099640729,

1.900314302, 2.630005966, 2.632590262, 2.581887814, 2.408797563,

2.098761103, 3.070460716, 1.436980716, 1.645121806), name2 = c(1.297412278,

1.104804244, 1.30621114, 1.126009533, 1.466740841, 1.012041118,

0.923466541, 0.840575023, 1.285530176, 1.041909333, 1.194917856,

1.085015826, 1.047492703, 1.587558217, 0.593340012, 0.723630088

), name3 = c(0.587160798, 0.596127884, 0.623760721, 0.549016135,

0.686642084, 0.487523394, 0.458620467, 0.397974913, 0.615928976,

0.546005649, 0.657383069, 0.546613129, 0.476503461, 0.749062102,

0.304160587, 0.29037358), name4 = c(2.833441759, 2.713374426,

2.532626548, 2.409093102, 3.014912721, 2.113507947, 2.017291324,

1.667744912, 2.602560666, 2.31649643, 2.761204809, 2.433963493,

2.229911767, 3.191646399, 1.269919241, 1.387479858), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 1.791300389,

1.669079382, 1.500209628, 2.164401874, 1.830038378, 2.106750025,

1.92888294, 1.707217549, 2.585082653, 1.114841754, 1.315712452

), name6 = c(0.715129844, 0.688186262, 0.70133748, 0.709362008,

0.712145174, 0.563593885, 0.532109761, 0.472197304, 0.690165016,

0.65635473, 0.615835066, 0.64310098, 0.562974891, 0.900622255,

0.408546784, 0.416284408), name7 = c(1.995505133, 1.860095899,

1.843151597, 1.709861774, 2.155993511, 1.506409746, 1.315405587,

1.234544153, 1.96629927, 1.74879757, 1.93994009, 1.660173854,

1.556735295, 2.355723318, 0.866634243, 1.013367677), name8 = c(0.275484997,

0.233856392, 0.294021245, 0.315504347, 0.251906585, 0.250263636,

0.348599173, 0.273806933, 0.32067937, 0.278581115, 0.293726291,

0.308350808, 0.201297444, 0.351927886, 0.204230625, 0.185681471

), name9 = c(2.461066627, 2.210756164, 2.289047888, 2.253988252,

2.668184733, 1.911697836, 1.793443775, 1.560027186, 2.36941155,

1.961911111, 2.391501376, 2.002215107, 1.932144233, 2.73705052,

1.15580754, 1.807697999), name10 = c(0.723025351, 0.613147422,

0.805399925, 0.65651577, 0.779389048, 0.54260459, 0.492283542,

0.507969501, 0.749700016, 0.644231327, 0.810319215, 0.620331891,

0.600240557, 0.884775748, 0.40006142, 0.391661912), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.361013073,

0.430744786, 0.468818055, 0.166072668, 0.369262627, 0.297666411,

0.256091173, 0.123021464, 0.308188684, 0.646436241, 0.722972632

)), .Names = c("class", "name1", "name2", "name3", "name4", "name5",

"name6", "name7", "name8", "name9", "name10", "name11"), class = "data.frame",
row.names = c("ara1",

"ara2", "ara3", "ara4", "ara5", "ara6", "ara7", "ara8", "ara9",

"ara10", "ara11", "ara12", "ara13", "ara14", "ara15", "ara16"

))


I wrote this:



avg<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"],
function(x) mean(x,na.rm=T)) )


med<-as.data.frame(aggregate(dat[,2:dim(dat)[2]], dat["class"], function(x)
median(x,na.rm=T)) )


# avg

#? class? ? name1? ?? name2? ?? name3? ? name4? ? name5? ?? name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?? 1 2.574113 1.2602356 0.6085415 2.700690 2.124379 0.7052322 1.912922
#0.2741547 2.376609 0.7154955 0.3654845

#2? ?? 2 2.214739 1.0154032 0.4900119 2.100276 1.781248 0.5645165 1.505665
#0.2983373 1.908645 0.5731394 0.3566621

#3? ?? 3 2.541092 1.1072810 0.5833339 2.503888 1.955224 0.6384303 1.782971
#0.2935527 2.118543 0.6916275 0.3076734

#4? ?? 4 2.202068 1.0761303 0.5099087 2.230492 1.802381 0.6240480 1.593031
#0.2524853 1.941667 0.6283592 0.3592155

#5? ?? 5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726

#> med

#? class? ? name1? ?? name2? ?? name3? ? name4? ? name5? ?? name6? ? name7
? ? name#8? ? name9? ? name10? ? name11

#1? ?? 1 2.497293 1.2974123 0.5961279 2.713374 2.141073 0.7093620 1.860096
#0.2754850 2.289048 0.7230254 0.3637169

#2? ?? 2 2.164318 0.9677538 0.4730719 2.065400 1.730190 0.5478518 1.410908
#0.2972432 1.852571 0.5252870 0.3958789

#3? ?? 3 2.581888 1.0850158 0.5466131 2.433963 1.928883 0.6431010 1.748798
#0.2937263 2.002215 0.6442313 0.2976664

#4? ?? 4 2.098761 1.0474927 0.4765035 2.229912 1.707218 0.5629749 1.556735
#0.2042306 1.932144 0.6002406 0.3081887

#5? ?? 5 1.645122 0.7236301 0.2903736 1.387480 1.315712 0.4162844 1.013368
#0.1856815 1.807698 0.3916619 0.7229726




But I do not know how can I add this information in the original data?


For example, for class 1, the output will look like this:

dput(res1)

structure(list(class = c(1L, 1L, 1L, 1L, 1L, 1L, 1L), name1 =
c(2.554923977,

2.371586762, 2.497293431, 2.464827875, 2.981934845, 2.574113378,

2.497293431), name2 = c(1.297412278, 1.104804244, 1.30621114,

1.126009533, 1.466740841, 1.260235607, 1.297412278), name3 = c(0.587160798,

0.596127884, 0.623760721, 0.549016135, 0.686642084, 0.608541525,

0.596127884), name4 = c(2.833441759, 2.713374426, 2.532626548,

2.409093102, 3.014912721, 2.700689711, 2.713374426), name5 = c(2.172365295,

1.955695471, 2.141072829, 1.975743278, 2.377018372, 2.124379049,

2.141072829), name6 = c(0.715129844, 0.688186262, 0.70133748,

0.709362008, 0.712145174, 0.705232154, 0.709362008), name7 = c(1.995505133,

1.860095899, 1.843151597, 1.709861774, 2.155993511, 1.912921583,

1.860095899), name8 = c(0.275484997, 0.233856392, 0.294021245,

0.315504347, 0.251906585, 0.274154713, 0.275484997), name9 = c(2.461066627,

2.210756164, 2.289047888, 2.253988252, 2.668184733, 2.376608733,

2.289047888), name10 = c(0.723025351, 0.613147422, 0.805399925,

0.65651577, 0.779389048, 0.715495503, 0.723025351), name11 = c(0.308565619,

0.453808281, 0.363716904, 0.376332596, 0.324998876, 0.365484455,

0.363716904)), .Names = c("class", "name1", "name2", "name3",

"name4", "name5", "name6", "name7", "name8", "name9", "name10",

"name11"), class = "data.frame", row.names = c("ara1", "ara2",

"ara3", "ara4", "ara5", "Avg", "Med"))



And same will be for other classes.


Thanks a lot !!!!


Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From christian.kamenik at astra.admin.ch  Mon Apr 28 13:01:51 2014
From: christian.kamenik at astra.admin.ch (christian.kamenik at astra.admin.ch)
Date: Mon, 28 Apr 2014 11:01:51 +0000
Subject: [R] Trouble with subset.ffdf
Message-ID: <F3DDE626408063448975429A27B423DC38538FC0@sb00114a.adb.intra.admin.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/46c4156c/attachment.pl>

From maechler at stat.math.ethz.ch  Mon Apr 28 13:06:24 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Apr 2014 13:06:24 +0200
Subject: [R] Problem with new(er) R version's matrix package
In-Reply-To: <1398617303.69204.YahooMailNeo@web172903.mail.ir2.yahoo.com>
References: <1398442656.519.YahooMailNeo@web172904.mail.ir2.yahoo.com>
	<0F8C5E08-2A01-47C6-BF55-8EAD44F7CD28@comcast.net>
	<CAMTWbJhsXZK98XyOrokt_qRoqXYkkD2DnnAwRD-fDT7n5G-R_Q@mail.gmail.com>
	<21340.4173.717293.642419@stat.math.ethz.ch>
	<1398617303.69204.YahooMailNeo@web172903.mail.ir2.yahoo.com>
Message-ID: <21342.13872.853046.192634@stat.math.ethz.ch>

>>>>> Werner W <pensterfuzzer at yahoo.de>
>>>>>     on Sun, 27 Apr 2014 17:48:23 +0100 writes:

    > Dear Martin, Arne, David,

    > Thanks for considering my problem. However, I have a bit of a problem in making a small reproducible example. So far, I tried to drill down into the code and to quick fix this by setting the particular tolerance to zero which switches off the check in ".solve.sparse.dgC". The obstacle I got stuck with doing that is, seemingly, the "solvetol" parameter from systemfit.control is not handed through all the way. 
    > ".calcGLS" from systemfit still hands it over but it does not reach ".solve.sparse.dgC"


    > This is the stack at that point before the error is thrown:
    > Browse[2]> where
    > where 1: .solve.sparse.dgC(as(a, "dgCMatrix"), b = b, tol = tol)
    > where 2: solve.dsC.dC(a, b)
    > where 3: solve(a, as(b, "CsparseMatrix"))
    > where 4: solve(a, as(b, "CsparseMatrix"))
    > where 5: eval(expr, envir, enclos)
    > where 6: eval(call, sys.frame(sys.parent()))
    > where 7: callGeneric(a, as(b, "CsparseMatrix"))
    > where 8: solve(forceCspSymmetric(a, isTri = FALSE), b = Diagonal(nrow(a)))
    > where 9: solve(forceCspSymmetric(a, isTri = FALSE), b = Diagonal(nrow(a)))
    > where 10: .local(a, b, ...)
    > where 11: solve(W, tol = solvetol)
    > where 12: solve(W, tol = solvetol)
    > where 13: as.matrix(solve(W, tol = solvetol)[1:ncol(xMat), 1:ncol(xMat)])
    > where 14: .calcGLS(xMat = xMatAll, R.restr = R.restr, q.restr = q.restr,
    > sigma = rcov, validObsEq = validObsEq, useMatrix = control$useMatrix,
    > solvetol = control$solvetol)
    > where 15 at ILLS.R#465: systemfit(eqsys, method = "SUR", data = dat, restrict.matrix = restrmat,
    > control = sysfit.contr)

    > I will now further try to create a small, reproducible example.

Thank you, Werner,  the above is already very useful!

Currently, I'd concluded that there must be a buglet in either
systemfit or Matrix  as you assert that the 'tol' argument is
not passed all the way down the Matrix package sparse solver.
[after 10 more minutes ..]
My current guess is that the buglet is in 'Matrix'...
I see the phenomenon also, using   example(systemfit)
so we have a reproducible example for 
   "tol is not passed all the way to the Matrix solve(..)",
and I will investigate that later.  
There are a few more urgent things currently, and other
duties...

    > I also have to better understand what the procedure is doing to be able to decide whether the previous results were wrong or this newly occurring error is wrong.

Indeed, the above is the real question you should address and
you have to do yourself alone.

    > Many thanks,
    > Werner

    > Martin Maechler <maechler at stat.math.ethz.ch> schrieb am 22:00 Samstag, 26.April 2014:
 
>>>>> Arne Henningsen <arne.henningsen at gmail.com>
    >> 
    >>>>>>> ? ?  on Sat, 26 Apr 2014 08:15:37 +0200 writes:
    >> 
    >> ? ? > On 25 April 2014 20:15, David Winsemius
    >> ? ? > <dwinsemius at comcast.net> wrote:
    >> ? ? >> 
    >> ? ? >> On Apr 25, 2014, at 9:17 AM, Werner W. wrote:
    >> ? ? >> 
    >> ? ? >>> Dear Rs,
    >> ? ? >>> 
    >> ? ? >>> I am re-executing some older code. It does work in the
    >> ? ? >>> ancient R 2.12.0 which I still have on my PC but with
    >> ? ? >>> the new version R 3.1.0 it does not work any more (but
    >> ? ? >>> some other new stuff, which won't work with 2.12).
    >> ? ? >>> 
    >> ? ? >>> The problem arises in context with the systemfit package
    >> ? ? >>> using the matrix package. In R 3.1.0 the following error
    >> ? ? >>> is thrown: Error in as.matrix(solve(W, tol =
    >> ? ? >>> solvetol)[1:ncol(xMat), 1:ncol(xMat)]) : error in
    >> ? ? >>> evaluating the argument 'x' in selecting a method for
    >> ? ? >>> function 'as.matrix': Error in .solve.sparse.dgC(as(a,
    >> ? ? >>> "dgCMatrix"), b = b, tol = tol) : LU computationally
    >> ? ? >>> singular: ratio of extreme entries in |diag(U)| =
    >> ? ? >>> 7.012e-39
    >> ? ? >>> 
    >> ? ? >>> However, I have no clue what I can do about this. Was
    >> ? ? >>> there some change in the defaults of the matrix package?
    >> ? ? >>> I couldn't find anything apparent in the changelog. As
    >> ? ? >>> the same code works in R 2.12.0, I suppose that the
    >> ? ? >>> problem is not my data.
    >> ? ? >> 
    >> ? ? >> You have not told us what version of the Matrix package
    >> ? ? >> you were using.? As such I would suggest that you review
    >> ? ? >> the Changelog which is a link for the CRAN page for
    >> ? ? >> pkg:Matrix and go back 4 years or so since R major
    >> ? ? >> versions change about once a year.
    >> ? ? >> 
    >> ? ? >> http://cran.r-project.org/web/packages/Matrix/ChangeLog
    >> 
    >> ? ? > In addition, please provide a minimal, self-contained,
    >> ? ? > reproducible example.
    >> 
    >> Yes, please do.?  As maintainer of the Matrix package, I'm
    >> willing to look into the situation of course.
    >> 
    >> As was mentioned, many things have changed in 4 years.
    >> The error message above looks like you'd want to invert a
    >> (very close to) singular matrix, and there could be quite few
    >> reasons why parts of the older code gave slightly different
    >> answers.
    >> 
    >> Without a reproducible example, we can't get started though.
    >> 
    >> Best regards,
    >> Martin Maechler, ETH Zurich
    >> 
    >> 
    >> 
    >>


From Thierry.ONKELINX at inbo.be  Mon Apr 28 13:19:01 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 28 Apr 2014 11:19:01 +0000
Subject: [R] linear mixed model for non-normal negative and continous
 data
In-Reply-To: <DUB110-W77FDB4E4F048BD295154DBE0470@phx.gbl>
References: <DUB110-W77FDB4E4F048BD295154DBE0470@phx.gbl>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A4116C@inbomail.inbo.be>

Dear Caroline,

Check the homogeneity of the variances. If they are inhomogeneous, you can add a variance function to deal with it. However, you will need to switch to the lme() from the nlme package.

Best regards,

Thierry

PS R-Sig-mixed-models is a better list for this kind of questions.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Caroline Lustenberger
Verzonden: maandag 28 april 2014 12:04
Aan: r-help at r-project.org
Onderwerp: [R] linear mixed model for non-normal negative and continous data

Dear all



I try to fit a linear mixed model to my data. In short, my dependent variable reflects changes of the bone level (Knmn, in mm), thus this variable is continous and provides negative values. I have two different groups (factor Group) that were measured 3 times each (thus repeated measures, factor Timepoint). I used the following model:



mod_Knmn<-lmer(Knmn~Group*Timepoint+(1|VPnr),data=data)



When performing a qq-plot my residuals are clearly deviant from the norm (long-tailed). Due to negative values I cannot perform classical transformation methods (e.g. log transformation). How could I proccede with this data. Is there a possibility to use a generalized linear model?



Thanks and all the best

Caroline

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From smartpink111 at yahoo.com  Mon Apr 28 13:58:26 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 28 Apr 2014 04:58:26 -0700 (PDT)
Subject: [R] subset of obersevation depending on multiple conditions
Message-ID: <1398686306.58313.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

The conditions are not very clear.? Based on the rows you wanted to pick, may be this helps,

#It is better to dput() the example.

? ? dat <- structure(list(Date = structure(c(14610, 14611, 14612, 14613, 
14614, 14615, 14616, 14617, 14618, 14619, 14620, 14621, 14622, 
14623, 14624, 14625, 14626, 14627, 14628, 14629, 14630, 14631, 
14632, 14633, 14634, 14635, 14636, 14637, 14638, 14639), class = "Date"), 
??? N = c(0, 1.9, 0, 0, 1.6, 0, 0.3, 0, 1.1, 1.7, 2.6, 0, 0, 
??? 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 1.9, 6.2, 0, 0)), .Names = c("Date", 
"N"), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", 
"10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", 
"21", "22", "23", "24", "25", "26", "27", "28", "29", "30"), class = "data.frame")


indx <- with(dat, N <=0.3)

rowInd <- unlist(lapply(split(seq_along(indx), cumsum(c(TRUE, diff(indx) == 1))), function(x) {
??? x1 <- indx[x]
??? x2 <- with(dat, N[x])
??? x3 <- if (length(x2[x1]) > 1) 
??????? !cumsum(c(0, diff(x2[x1])) < 0)
??? x[c(x3, rep(FALSE, length(x2) - length(x3)))]
}), use.names = FALSE)
rowInd
# [1]? 3? 4? 6? 7 12 13 14 15 16 17 18 29 30
dat[rowInd,]



A.K.


Hello,

I want to subset a data.frame containing the variables "Date" in (%Y %m %d
) and "N".

I want to print "Date" and "N" if? N is less than or equal to 0.3 and if
"N" is also less than or equal to 0.3 on the day before the day where "N"
is less than or equal to 0.3.

This would be the case in line 3 and 4 , 6 and 7, 12 to 18, and so on.

"Date"??? "N"
"1"??? 2010-01-01??? 0
"2"??? 2010-01-02??? 1.9
"3"??? 2010-01-03??? 0
"4"??? 2010-01-04??? 0
"5"??? 2010-01-05??? 1.6
"6"??? 2010-01-06??? 0
"7"??? 2010-01-07??? 0.3
"8"??? 2010-01-08??? 0
"9"??? 2010-01-09??? 1.1
"10"??? 2010-01-10??? 1.7
"11"??? 2010-01-11??? 2.6
"12"??? 2010-01-12??? 0
"13"??? 2010-01-13??? 0
"14"??? 2010-01-14??? 0
"15"??? 2010-01-15??? 0
"16"??? 2010-01-16??? 0
"17"??? 2010-01-17??? 0
"18"??? 2010-01-18??? 0.2
"19"??? 2010-01-19??? 0
"20"??? 2010-01-20??? 0
"21"??? 2010-01-21??? 0
"22"??? 2010-01-22??? 0
"23"??? 2010-01-23??? 0
"24"??? 2010-01-24??? 0
"25"??? 2010-01-25??? 0
"26"??? 2010-01-26??? 0
"27"??? 2010-01-27??? 1.9
"28"??? 2010-01-28??? 6.2
"29"??? 2010-01-29??? 0
"30"??? 2010-01-30??? 0

I tried some methods with subset but I couldn't work it out. Maybe I have
to use something like " for (i in x) {} but as a beginner I really don't
know how to do it.

Can somebody please help me with this.

Thanks in advance,

Christoph 



From frtog at vestas.com  Mon Apr 28 14:27:31 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 28 Apr 2014 14:27:31 +0200
Subject: [R] subset of obersevation depending on multiple conditions
In-Reply-To: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>
References: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9EF5E@DKRDSEXC016.vestas.net>

Hi

Here is a very simple way.


mydat <- read.table(text="
Date    N
2010-01-01    0
2010-01-02    1.9
2010-01-03    0
2010-01-04    0
2010-01-05    1.6
2010-01-06    0
2010-01-07    0.3
2010-01-08    0
2010-01-09    1.1
2010-01-10    1.7
2010-01-11    2.6
2010-01-12    0
2010-01-13    0
2010-01-14    0
2010-01-15    0
2010-01-16    0
2010-01-17    0
2010-01-18    0.2
2010-01-19    0
2010-01-20    0
2010-01-21    0
2010-01-22    0
2010-01-23    0
2010-01-24    0
2010-01-25    0
2010-01-26    0
2010-01-27    1.9
2010-01-28    6.2
2010-01-29    0
2010-01-30    0", sep = "", h = TRUE)

mydat$NdayBefore <- c(NA, mydat[-nrow(mydat), "N"])

head(mydat)

subset(mydat, N <= 0.3)

subset(mydat, N <= 0.3 & NdayBefore <= 0.3)

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Christoph Schl?chter
> Sent: 28. april 2014 10:38
> To: r-help at r-project.org
> Subject: [R] subset of obersevation depending on multiple conditions
> 
> Hello,
> 
> I want to subset a data.frame containing the variables "Date" in (%Y %m %d
> ) and "N".
> 
> I want to print "Date" and "N" if  N is less than or equal to 0.3 and if
> "N" is also less than or equal to 0.3 on the day before the day where "N"
> is less than or equal to 0.3.
> 
> This would be the case in line 3 and 4 , 6 and 7, 12 to 18, and so on.
> 
> "Date"    "N"
> "1"    2010-01-01    0
> "2"    2010-01-02    1.9
> "3"    2010-01-03    0
> "4"    2010-01-04    0
> "5"    2010-01-05    1.6
> "6"    2010-01-06    0
> "7"    2010-01-07    0.3
> "8"    2010-01-08    0
> "9"    2010-01-09    1.1
> "10"    2010-01-10    1.7
> "11"    2010-01-11    2.6
> "12"    2010-01-12    0
> "13"    2010-01-13    0
> "14"    2010-01-14    0
> "15"    2010-01-15    0
> "16"    2010-01-16    0
> "17"    2010-01-17    0
> "18"    2010-01-18    0.2
> "19"    2010-01-19    0
> "20"    2010-01-20    0
> "21"    2010-01-21    0
> "22"    2010-01-22    0
> "23"    2010-01-23    0
> "24"    2010-01-24    0
> "25"    2010-01-25    0
> "26"    2010-01-26    0
> "27"    2010-01-27    1.9
> "28"    2010-01-28    6.2
> "29"    2010-01-29    0
> "30"    2010-01-30    0
> 
> I tried some methods with subset but I couldn't work it out. Maybe I have
> to use something like " for (i in x) {} but as a beginner I really don't
> know how to do it.
> 
> Can somebody please help me with this.
> 
> Thanks in advance,
> 
> Christoph
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frtog at vestas.com  Mon Apr 28 14:35:54 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 28 Apr 2014 14:35:54 +0200
Subject: [R] subset of obersevation depending on multiple conditions
In-Reply-To: <1398686306.58313.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1398686306.58313.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9EF6A@DKRDSEXC016.vestas.net>

So Christoph now have 3 methods giving him three different results. Of course it is not really clear what Christoph really wants ;-)

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of arun
> Sent: 28. april 2014 13:58
> To: R. Help
> Subject: Re: [R] subset of obersevation depending on multiple conditions
> 
> Hi,
> 
> The conditions are not very clear.? Based on the rows you wanted to pick,
> may be this helps,
> 
> #It is better to dput() the example.
> 
> ? ? dat <- structure(list(Date = structure(c(14610, 14611, 14612, 14613,
> 14614, 14615, 14616, 14617, 14618, 14619, 14620, 14621, 14622,
> 14623, 14624, 14625, 14626, 14627, 14628, 14629, 14630, 14631,
> 14632, 14633, 14634, 14635, 14636, 14637, 14638, 14639), class = "Date"),
> ??? N = c(0, 1.9, 0, 0, 1.6, 0, 0.3, 0, 1.1, 1.7, 2.6, 0, 0,
> ??? 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 1.9, 6.2, 0, 0)), .Names = c("Date",
> "N"), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
> "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> "21", "22", "23", "24", "25", "26", "27", "28", "29", "30"), class = "data.frame")
> 
> 
> indx <- with(dat, N <=0.3)
> 
> rowInd <- unlist(lapply(split(seq_along(indx), cumsum(c(TRUE, diff(indx) ==
> 1))), function(x) {
> ??? x1 <- indx[x]
> ??? x2 <- with(dat, N[x])
> ??? x3 <- if (length(x2[x1]) > 1)
> ??????? !cumsum(c(0, diff(x2[x1])) < 0)
> ??? x[c(x3, rep(FALSE, length(x2) - length(x3)))]
> }), use.names = FALSE)
> rowInd
> # [1]? 3? 4? 6? 7 12 13 14 15 16 17 18 29 30
> dat[rowInd,]
> 
> 
> 
> A.K.
> 
> 
> Hello,
> 
> I want to subset a data.frame containing the variables "Date" in (%Y %m %d
> ) and "N".
> 
> I want to print "Date" and "N" if? N is less than or equal to 0.3 and if
> "N" is also less than or equal to 0.3 on the day before the day where "N"
> is less than or equal to 0.3.
> 
> This would be the case in line 3 and 4 , 6 and 7, 12 to 18, and so on.
> 
> "Date"??? "N"
> "1"??? 2010-01-01??? 0
> "2"??? 2010-01-02??? 1.9
> "3"??? 2010-01-03??? 0
> "4"??? 2010-01-04??? 0
> "5"??? 2010-01-05??? 1.6
> "6"??? 2010-01-06??? 0
> "7"??? 2010-01-07??? 0.3
> "8"??? 2010-01-08??? 0
> "9"??? 2010-01-09??? 1.1
> "10"??? 2010-01-10??? 1.7
> "11"??? 2010-01-11??? 2.6
> "12"??? 2010-01-12??? 0
> "13"??? 2010-01-13??? 0
> "14"??? 2010-01-14??? 0
> "15"??? 2010-01-15??? 0
> "16"??? 2010-01-16??? 0
> "17"??? 2010-01-17??? 0
> "18"??? 2010-01-18??? 0.2
> "19"??? 2010-01-19??? 0
> "20"??? 2010-01-20??? 0
> "21"??? 2010-01-21??? 0
> "22"??? 2010-01-22??? 0
> "23"??? 2010-01-23??? 0
> "24"??? 2010-01-24??? 0
> "25"??? 2010-01-25??? 0
> "26"??? 2010-01-26??? 0
> "27"??? 2010-01-27??? 1.9
> "28"??? 2010-01-28??? 6.2
> "29"??? 2010-01-29??? 0
> "30"??? 2010-01-30??? 0
> 
> I tried some methods with subset but I couldn't work it out. Maybe I have
> to use something like " for (i in x) {} but as a beginner I really don't
> know how to do it.
> 
> Can somebody please help me with this.
> 
> Thanks in advance,
> 
> Christoph
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Mon Apr 28 17:22:57 2014
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 28 Apr 2014 10:22:57 -0500
Subject: [R] Forecast Package in R version 3.1.0
Message-ID: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/8f01ccf2/attachment.pl>

From murdoch.duncan at gmail.com  Mon Apr 28 17:27:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Apr 2014 11:27:12 -0400
Subject: [R] Forecast Package in R version 3.1.0
In-Reply-To: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>
Message-ID: <535E7350.4000001@gmail.com>

On 28/04/2014 11:22 AM, Paul Bernal wrote:
> Dear R community, hello,
>
> Hope everybody is doing great. I just downloaded R version 3.1.0, and,
> whenever I try to load the forecast package, the following error message
> appears:
>
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>    there is no package called ?Rcpp?
> Error: package or namespace load failed for ?forecast?
>
> Does anybody knows or have an idea of what could be happeing with this new
> version of R?

Just what it says: the forecast package depends on the Rcpp package, but 
you don't have Rcpp installed. Install it and this error should go away.

Duncan Murdoch


From paulbernal07 at gmail.com  Mon Apr 28 17:31:42 2014
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 28 Apr 2014 10:31:42 -0500
Subject: [R] Forecast Package in R version 3.1.0
In-Reply-To: <535E7350.4000001@gmail.com>
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>
	<535E7350.4000001@gmail.com>
Message-ID: <CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/650fd1db/attachment.pl>

From edd at debian.org  Mon Apr 28 17:39:20 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 28 Apr 2014 15:39:20 +0000
Subject: [R] Forecast Package in R version 3.1.0
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>
	<535E7350.4000001@gmail.com>
	<CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>
Message-ID: <loom.20140428T173851-383@post.gmane.org>

Paul Bernal <paulbernal07 <at> gmail.com> writes:
> This is what is happening when I try downloading the Rcpp package in R
> version 3.1.0
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>   there is no package called ???Rcpp???
> Error: package or namespace load failed for ???forecast???

That is conflicting with the fact that the package page for Rcpp shows
you binaries for

  three R versions (devel, release, old-release) on Windows
  three R versions (devel, release, old-release) on OS X 'snow leopard'
  one R version (release) on OS X 'mavericks'

whereas you have not even told us what OS you use.

Dirk


From rshepard at appl-ecosys.com  Mon Apr 28 18:04:10 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 28 Apr 2014 09:04:10 -0700
Subject: [R] Forecast Package in R version 3.1.0
In-Reply-To: <loom.20140428T173851-383@post.gmane.org>
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>
	<535E7350.4000001@gmail.com>
	<CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>
	<loom.20140428T173851-383@post.gmane.org>
Message-ID: <alpine.LNX.2.11.1404280903060.23711@localhost>

On Mon, 28 Apr 2014, Dirk Eddelbuettel wrote:

> That is conflicting with the fact that the package page for Rcpp shows
> you binaries for
>
>  three R versions (devel, release, old-release) on Windows
>  three R versions (devel, release, old-release) on OS X 'snow leopard'
>  one R version (release) on OS X 'mavericks'
>
> whereas you have not even told us what OS you use.

   FWIW, I run Slackware-14.1 and just installed Rcpp (as root) with
install.packages("Rcpp")

   No issues at all.

Rich


From ruipbarradas at sapo.pt  Mon Apr 28 18:17:01 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 28 Apr 2014 17:17:01 +0100
Subject: [R] Forecast Package in R version 3.1.0
In-Reply-To: <alpine.LNX.2.11.1404280903060.23711@localhost>
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>	<535E7350.4000001@gmail.com>	<CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>	<loom.20140428T173851-383@post.gmane.org>
	<alpine.LNX.2.11.1404280903060.23711@localhost>
Message-ID: <535E7EFD.9010302@sapo.pt>

Hello,

Or maybe better,

install.packages("forecast", dependencies = TRUE)


since package forecast depends on several other packages

Hope this helps,

Rui Barradas

Em 28-04-2014 17:04, Rich Shepard escreveu:
> On Mon, 28 Apr 2014, Dirk Eddelbuettel wrote:
>
>> That is conflicting with the fact that the package page for Rcpp shows
>> you binaries for
>>
>>  three R versions (devel, release, old-release) on Windows
>>  three R versions (devel, release, old-release) on OS X 'snow leopard'
>>  one R version (release) on OS X 'mavericks'
>>
>> whereas you have not even told us what OS you use.
>
>    FWIW, I run Slackware-14.1 and just installed Rcpp (as root) with
> install.packages("Rcpp")
>
>    No issues at all.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Apr 28 18:18:49 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 28 Apr 2014 09:18:49 -0700
Subject: [R] Job openings for 2 statisticians at Roche in Basel, Switzerland
Message-ID: <CACk-te0haZHgXKgEjX75OsZAgwBXhRyRoXmH-5dK0v-WDyZCoA@mail.gmail.com>

Roche Pharmaceuticals has openings for two nonclinical statisticians
at its Basel, Switzerland R&D site.  The positions' initial focus will
be working with process and  formulation chemists. A solid background
in linear models, Design of Experiments, and English fluency are
minimal requirements.

For further information, please go to:

 http://careers.roche.com/en/jobs/switzerland/development/2958368052/nonclinical-biostatistician.html#sthash.G0mkwDCS.dpuf

Bert Gunter
Genentech Nonclinical Biostatistics


From murdoch.duncan at gmail.com  Mon Apr 28 18:34:27 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Apr 2014 12:34:27 -0400
Subject: [R] Forecast Package in R version 3.1.0
In-Reply-To: <CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>
References: <CAMOcQfMWnba=3OSBwZtpaBkFOBTtN9qBTgczv5cRXhK8fRkNiA@mail.gmail.com>	<535E7350.4000001@gmail.com>
	<CAMOcQfO-Ltc5rDG-b5Tk2eyfU+f5O1nP8w2+wYYVnt4D59Yz1A@mail.gmail.com>
Message-ID: <535E8313.4020009@gmail.com>

On 28/04/2014 11:31 AM, Paul Bernal wrote:
> Dear Duncan,
>
> This is what is happening when I try downloading the Rcpp package in R 
> version 3.1.0
>
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = 
> vI[[i]]) :
>   there is no package called ?Rcpp?
> Error: package or namespace load failed for ?forecast?

Others have told you how to solve this problem, so I will assume that's 
done, and just offer some advice for future problems:  Don't be vague 
about what you did to trigger the error message, cut and paste the exact 
code or describe the exact circumstances that led to it.  I can say with 
some certainty that you wouldn't get the message above from "downloading 
the Rcpp package", but if you had posted the code that you used, I could 
probably have told you what you were doing wrong.

Duncan Murdoch

>
>
>
>
> 2014-04-28 10:27 GMT-05:00 Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>>:
>
>     On 28/04/2014 11:22 AM, Paul Bernal wrote:
>
>         Dear R community, hello,
>
>         Hope everybody is doing great. I just downloaded R version
>         3.1.0, and,
>         whenever I try to load the forecast package, the following
>         error message
>         appears:
>
>         Error in loadNamespace(i, c(lib.loc, .libPaths()),
>         versionCheck = vI[[i]])
>         :
>            there is no package called ?Rcpp?
>         Error: package or namespace load failed for ?forecast?
>
>         Does anybody knows or have an idea of what could be happeing
>         with this new
>         version of R?
>
>
>     Just what it says: the forecast package depends on the Rcpp
>     package, but you don't have Rcpp installed. Install it and this
>     error should go away.
>
>     Duncan Murdoch
>
>


From jjw3952 at rit.edu  Mon Apr 28 16:51:23 2014
From: jjw3952 at rit.edu (Jacob Warren (RIT Student))
Date: Mon, 28 Apr 2014 10:51:23 -0400
Subject: [R] LogLikelihood of a Distribution Given Fixed Parameters
In-Reply-To: <5359E994.9070601@auckland.ac.nz>
References: <CADqzGTsbAr+4Z2P79PQ9f=iB+FHuo3ppGpUDZzi2jy979XFgcw@mail.gmail.com>
	<5359E994.9070601@auckland.ac.nz>
Message-ID: <CADqzGTuPunR_dk9=+zW18-10fZ6ibZqQ_fAzH1tCYDv+hWP_Hg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/89648ce0/attachment.pl>

From craigpoconnell at hotmail.com  Mon Apr 28 13:57:53 2014
From: craigpoconnell at hotmail.com (Craig O'Connell)
Date: Mon, 28 Apr 2014 07:57:53 -0400
Subject: [R]
 =?windows-1252?q?lme4_Error_Help=3A_=93maxstephalfit=85pwrssU?=
 =?windows-1252?q?pdate=94?=
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3A40DE2@inbomail.inbo.be>
References: <BLU169-W100522438783894807A10CBC7470@phx.gbl>,
	<AA818EAD2576BC488B4F623941DA7427F3A40DE2@inbomail.inbo.be>
Message-ID: <BLU169-W5721C82192B395DA6BFB33C7470@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/da5b1f03/attachment.pl>

From cjhon217 at gmail.com  Mon Apr 28 17:49:31 2014
From: cjhon217 at gmail.com (chris Jhon)
Date: Tue, 29 Apr 2014 00:49:31 +0900
Subject: [R] about rect.hclust
In-Reply-To: <CANdJ3dXtYmBju9P_HjurE2WxqLZnqcNTEpXGFgskcxuY1qnMqQ@mail.gmail.com>
References: <CAMGMbo_V8jg_FmJ2sdNedtTx_U2bqztkotpYKPJkcmAVCKuuOA@mail.gmail.com>
	<044B2E98-D191-47C7-BB00-B8361DFDEA53@gmail.com>
	<47785C8B-D12D-47E6-8631-6F2105E9BF0E@gmail.com>
	<CANdJ3dXtYmBju9P_HjurE2WxqLZnqcNTEpXGFgskcxuY1qnMqQ@mail.gmail.com>
Message-ID: <CAMGMbo8VqmcT+FfvMUxWZWABU0ZjuL5XwCARUoYeZEaOTkr9WA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/b6c38015/attachment.pl>

From amitra at lpnhe.in2p3.fr  Mon Apr 28 19:47:10 2014
From: amitra at lpnhe.in2p3.fr (Ayan Mitra)
Date: Mon, 28 Apr 2014 10:47:10 -0700 (PDT)
Subject: [R] Label customization in R plots
Message-ID: <1398707230722-4689616.post@n4.nabble.com>

Hi all,
         I am a new comer in R . i am trying to figure out how to put in the
label of a plot the basic statistics values like mean=
               no of data = 
               media = 
               chi-square =


in a box.

I tried a lot to search over the net but couldn't find one as yet. 
Thanks in advance for suggestions.

Ayan.



--
View this message in context: http://r.789695.n4.nabble.com/Label-customization-in-R-plots-tp4689616.html
Sent from the R help mailing list archive at Nabble.com.


From alej.c.s at gmail.com  Mon Apr 28 20:35:44 2014
From: alej.c.s at gmail.com (Alejo C.S.)
Date: Mon, 28 Apr 2014 15:35:44 -0300
Subject: [R] About lm(y~1)
Message-ID: <CAEeP31sKSr6F1Ch7nF3ttwktfOGK-zkzgmwSQY8Tko02TEKHeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/fab2a41b/attachment.pl>

From noahsilverman at ucla.edu  Mon Apr 28 21:00:20 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Mon, 28 Apr 2014 12:00:20 -0700
Subject: [R] Color points in princomp() plot
Message-ID: <535EA544.2020502@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/1d3d0369/attachment.pl>

From ruipbarradas at sapo.pt  Mon Apr 28 21:00:37 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 28 Apr 2014 20:00:37 +0100
Subject: [R] About lm(y~1)
In-Reply-To: <CAEeP31sKSr6F1Ch7nF3ttwktfOGK-zkzgmwSQY8Tko02TEKHeg@mail.gmail.com>
References: <CAEeP31sKSr6F1Ch7nF3ttwktfOGK-zkzgmwSQY8Tko02TEKHeg@mail.gmail.com>
Message-ID: <535EA555.1070601@sapo.pt>

Hello,

That will compute a "fit" with coefficient equal to mean(y) and std 
error equal to sd(y)/sqrt(length(y))

Hope this helps,

Rui Barradas

Em 28-04-2014 19:35, Alejo C.S. escreveu:
> Dear list,
> Reading a function I found this:
>
> lm ( y ~ 1 )
>
> I know that Y ~ -1 + A  is a straight-line with no y-intercept; that is, a
> fit forced through (0,0). But I never saw the first example. Any tip?
>
> Thanks in advance!
>
> C.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From fongchunchan at gmail.com  Mon Apr 28 21:26:34 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Mon, 28 Apr 2014 12:26:34 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
Message-ID: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/e37402b5/attachment.pl>

From dwinsemius at comcast.net  Mon Apr 28 21:36:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 28 Apr 2014 12:36:50 -0700
Subject: [R] Label customization in R plots
In-Reply-To: <1398707230722-4689616.post@n4.nabble.com>
References: <1398707230722-4689616.post@n4.nabble.com>
Message-ID: <4852A740-1238-401B-A3A0-C75DE60BF733@comcast.net>


On Apr 28, 2014, at 10:47 AM, Ayan Mitra wrote:

> Hi all,
>         I am a new comer in R . i am trying to figure out how to put in the
> label of a plot the basic statistics values like mean=
>               no of data = 
>               media = 
>               chi-square =

In base graphics you could do this with functions 'rect' and 'text'.

For lattice (and probably ggplot2), there is a gridExtra package that has 'tableGrob'

-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Mon Apr 28 23:15:04 2014
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 28 Apr 2014 16:15:04 -0500
Subject: [R] Label customization in R plots
In-Reply-To: <4852A740-1238-401B-A3A0-C75DE60BF733@comcast.net>
References: <1398707230722-4689616.post@n4.nabble.com>
	<4852A740-1238-401B-A3A0-C75DE60BF733@comcast.net>
Message-ID: <004701cf6326$eca6b890$c5f429b0$@tamu.edu>

You can also use the legend() function which will draw the box
and arrange the text in a single column (or three columns if you
want a single row). It also has shortcuts for positioning the
box such as "topleft" or "bottomright."

?legend

for more details.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David
Winsemius
Sent: Monday, April 28, 2014 2:37 PM
To: Ayan Mitra
Cc: r-help at r-project.org
Subject: Re: [R] Label customization in R plots


On Apr 28, 2014, at 10:47 AM, Ayan Mitra wrote:

> Hi all,
>         I am a new comer in R . i am trying to figure out how
to put in the
> label of a plot the basic statistics values like mean=
>               no of data = 
>               media = 
>               chi-square =

In base graphics you could do this with functions 'rect' and
'text'.

For lattice (and probably ggplot2), there is a gridExtra package
that has 'tableGrob'

-- 

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From gunter.berton at gene.com  Mon Apr 28 23:21:49 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 28 Apr 2014 14:21:49 -0700
Subject: [R] Label customization in R plots
In-Reply-To: <4852A740-1238-401B-A3A0-C75DE60BF733@comcast.net>
References: <1398707230722-4689616.post@n4.nabble.com>
	<4852A740-1238-401B-A3A0-C75DE60BF733@comcast.net>
Message-ID: <CACk-te0kWMpEiDn9Wfivq+XEtYYCemvswYH9rN2_p4cvdv6H3Q@mail.gmail.com>

See also ?panel.text for lattice. This presumes that you know how to
use panel functions, however.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Apr 28, 2014 at 12:36 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Apr 28, 2014, at 10:47 AM, Ayan Mitra wrote:
>
>> Hi all,
>>         I am a new comer in R . i am trying to figure out how to put in the
>> label of a plot the basic statistics values like mean=
>>               no of data =
>>               media =
>>               chi-square =
>
> In base graphics you could do this with functions 'rect' and 'text'.
>
> For lattice (and probably ggplot2), there is a gridExtra package that has 'tableGrob'
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From noahsilverman at ucla.edu  Mon Apr 28 23:41:38 2014
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Mon, 28 Apr 2014 14:41:38 -0700
Subject: [R] Color points in princomp() plot
Message-ID: <535ECB12.9080408@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/6e58f9d7/attachment.pl>

From manfredini.denise at gmail.com  Mon Apr 28 23:10:51 2014
From: manfredini.denise at gmail.com (Denise Manfredini)
Date: Mon, 28 Apr 2014 18:10:51 -0300
Subject: [R] SVEC with exogen vector
Message-ID: <CAOJjuNaXuQPm39pQ5YrK0haUaWjEWD9_po7raBVRHBpW1D=x+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/a09fe4cf/attachment.pl>

From liusiqi.nine at gmail.com  Tue Apr 29 00:36:19 2014
From: liusiqi.nine at gmail.com (Si Qi L.)
Date: Mon, 28 Apr 2014 23:36:19 +0100
Subject: [R] About Tree Package
Message-ID: <CABmq+QU-zoyGoFjy0jsrn-kA1bm_g3cKK6ZdFAZEJMBn5=UNZg@mail.gmail.com>

Hi,

I will be very grateful if you can give a help on my problem. I am
really stuck on it now. The problem is that I need to construct a
classification tree model and prune tree in order to test the learning
dataset for getting its sensitivity and specificity. But my codes
seems wrong somewhere, will you guys please help me out? Many
thanks!:D

These are codes:

library(tree)
attach(learning.set1)
Status.f<- factor(Status)

tree1<-tree(Status.f  ~ Gender.compl+ X2.4.times.per.month+
Once.a.month+Council.tenant+Living.with.friends.family+Living.with.parents+Owner.occupier+X1.year.to.2.years+X2.to.4.years+X3.months.to.a.year+Less.than.3.months+Empl.compl+Reqloanamount+EmpNetMonthlyPay+Customer_Age+RTI+acc.compl+iic.compl+irb.compl+jbc.compl+jic.compl+jq.compl+kic.compl+lbc.compl+mbc.compl+njc.compl+or.compl+pq.compl+pr.compl+qic.compl+teb.compl+tpb.compl+vbc.compl+yzb.compl+zr.compl,
method="class", data=learning.set1, split="gini")

summary(tree1)
print(tree1)
plot(tree1)
text(tree1)
pfit<-prune.tree(tree1,
k=tree1$cptable[which.min(tree1$cptable[,"xerror"]),"CP"])
plot(pfit, uniform=TRUE)
text(pfit)
pred<-predict(tree1,learning.set1,type="vector")
table1<-table(learning.set1$Status,predict(tree1,type="vector"))
> table1

       0    1

  0 1429  108

  1  273  164

sum<-sum(learning.set1$Status==pred)/length(pred)
sens<- function(table1) { table1[2,2] / sum(table1[,2]) }
spec<- function(table1) { table1[1,1] / sum(table1[,1]) }
myt<-matrix(c(1429,273,108,164), ncol=2)
sens
spec


From dwinsemius at comcast.net  Tue Apr 29 00:40:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 28 Apr 2014 15:40:23 -0700
Subject: [R] Color points in princomp() plot
In-Reply-To: <535ECB12.9080408@ucla.edu>
References: <535ECB12.9080408@ucla.edu>
Message-ID: <4BD20796-5C6E-4A7E-8ADC-8803B4590CAC@comcast.net>


On Apr 28, 2014, at 2:41 PM, Noah Silverman wrote:

> Hi,
> 
> The princomp() function has a nice method to generate a pretty biplot of
> the data.  I have some data where the points are divided into a few
> groups.  My intention is to generate a biplot, using princomp, but color
> the points based on group membership.  The hope is that points will show
> some kind of clustering by group in the biplot.
> 
> However, I can't figure out how to indicate individual point color in a
> biplot.  The only setting I found was to indicate a single color for
> *all* the points.
> 
> Any ideas?

Offer some code?

The help page says you can provide a vector for coloring sets of points.

> 	[[alternative HTML version deleted]]

And when you do offer code it should be with plain text format.

-- 
David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Tue Apr 29 01:00:33 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 29 Apr 2014 09:00:33 +1000
Subject: [R] Label customization in R plots
In-Reply-To: <1398707230722-4689616.post@n4.nabble.com>
References: <1398707230722-4689616.post@n4.nabble.com>
Message-ID: <535EDD91.3050609@bitwrit.com.au>

On 04/29/2014 03:47 AM, Ayan Mitra wrote:
> Hi all,
>           I am a new comer in R . i am trying to figure out how to put in the
> label of a plot the basic statistics values like mean=
>                 no of data =
>                 media =
>                 chi-square =
>
>
> in a box.
>
> I tried a lot to search over the net but couldn't find one as yet.
> Thanks in advance for suggestions.
>
Hi Ayan,
Have a look at the addtable2plot function in the plotrix package.

Jim


From r.turner at auckland.ac.nz  Tue Apr 29 02:07:40 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 29 Apr 2014 12:07:40 +1200
Subject: [R] LogLikelihood of a Distribution Given Fixed Parameters
In-Reply-To: <CADqzGTuPunR_dk9=+zW18-10fZ6ibZqQ_fAzH1tCYDv+hWP_Hg@mail.gmail.com>
References: <CADqzGTsbAr+4Z2P79PQ9f=iB+FHuo3ppGpUDZzi2jy979XFgcw@mail.gmail.com>
	<5359E994.9070601@auckland.ac.nz>
	<CADqzGTuPunR_dk9=+zW18-10fZ6ibZqQ_fAzH1tCYDv+hWP_Hg@mail.gmail.com>
Message-ID: <535EED4C.1030303@auckland.ac.nz>



Indeed it should be lower=FALSE.  Duhhhh!  Sorry 'bout that!

cheers,

Rolf

On 29/04/14 02:51, Jacob Warren (RIT Student) wrote:
> Thanks Rolf. That took care of it. It should be lower=FALSE through
> right? I want the upper tail because my values are right censored?
> Regards,
> Jake
>
>
> On Fri, Apr 25, 2014 at 12:50 AM, Rolf Turner <r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>> wrote:
>
>
>     As usual I am too lazy to fight my way through the rather convoluted
>     code presented, but it seems to me that you just want to calculate a
>     log likelihood.  And that is bog-simple:
>
>     The log likelihood for i.i.d. data is just the sum of log f(y_i)
>     where the y_i are your observed values and f() is the density
>     function of the distribution that you have in mind.
>
>     Where there is (right) censoring you take the sum of log f(y_i) over all
>     the non-censored values and then add k*(1-F(cens.time)) where k is
>     the number of censored values and F() is the cumulative distribution
>     function corresponding to f().
>
>     In your case it would appear that f(y) = dlnorm(y,1.66,0.25) and
>     F(y) = plnorm(y,1.66,0.25).  Note that instead of using
>     1-F(cens.time) you can use plnorm(cens.time,1.66,0.25,__lower=TRUE)
>     and that instead of taking logs explicitly you can set log=TRUE in
>     the calls to dlnorm() and plnorm().
>
>     cheers,
>
>     Rolf Turner
>
>
>     On 25/04/14 07:27, Jacob Warren (RIT Student) wrote:
>
>         I'm trying to figure out if there is a way in R to get the
>         loglikelihood of
>         a distribution fit to a set of data where the parameter values
>         are fixed.
>         For example, I want to simulate data from a given alternate
>         lognormal
>         distribution and then I will fit it to a lognormal distribution
>         with null
>         parameter values to see what the likelihood of the null
>         distribution is
>         given random data from the alternate distribution.
>
>         I have been using fitdistrplus for other purposes but I cannot
>         use it to
>         fix both parameter values.
>
>         Here is an example of what I've been working with...
>
>         nullmu<-1.66 #set null mu
>         altmu<-1.58 #set alt mu
>         sd.log<-0.25 #set common sigma
>         cens.time<-6 #if simulated times are greater than this turn them
>         into right
>         censored times
>
>         #simulating lognormal data (time) from altnative dist
>         (sim<-rlnorm(n=samplesize, meanlog=altmu, sdlog=sd.log))
>         #if the time was > cens.time replace time with cens.time
>         (sim[which(sim>cens.time)]<-__cens.time)
>         sim
>
>         #create a variable indicating censoring
>         (cens<-sim)
>         cens[which(sim==cens.time)]<-__NA
>         cens
>
>         #create the data frame to be passed to fitdistcens and fitdist
>         (x<-data.frame(left=sim,right=__cens))
>
>
>         #if there is censored data use fitdistcens else use fitdist
>         ifelse(length(which(is.na <http://is.na>(__cens)))>0,
>         simfit<-fitdistcens(censdata=__x, distr="lnorm"),
>         simfit<-fitdist(data=x[,1], distr="lnorm")
>         )
>
>         #Now I can get the loglikelihood of the MLE fitted distribution
>         simfit$loglik
>
>         #I want to get the loglikelihood of the distribution with the null
>         parameterization
>         #This is what I can't get to work
>         #I can't seem to find any function that allows me to set both
>         parameter
>         values
>         #so I can get to loglikelihood of the of the parameterization
>         given the data
>         nulldist<-fitdistcens(__censdata=x, distr="lnorm",
>         start=list(meanlog=nullmu,
>         sdlog=sd.log)
>
>         #Then I want to do a likelihood ratio test between the two
>         distributions
>         pchisq((-2*simfit$loglik--2*__nulldist$loglik), df=2,
>         lower.tail=FALSE)
>
>
>


From r.turner at auckland.ac.nz  Tue Apr 29 02:40:02 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 29 Apr 2014 12:40:02 +1200
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
Message-ID: <535EF4E2.6050700@auckland.ac.nz>


Probably not much help to you, but for what it's worth:

* on my system cairo.h is in /usr/include/cairo

Perhaps the CAIRO flags that you set are not adequately guiding the search.

* you need to have the *development* version of cairo installed; on my 
system (Fedora 17) I do:

	sudo yum install cairo-devel.x86_64

to effect this.

* I believe that to get cairo to fly properly you also need to have 
(the development version of) *pango* installed.  On my system I do

	sudo yum install pango-devel.x86_64

to effect this.

* I don't know how (or even if it is possible) to get yum to install 
packages to a "custom" location --- as you would apparently need to do, 
since you have created a custom ".../usr/local" under your home directory.

* I was under the impression that to get cairo to fly one needs to do

	./configure --with-cairo

All of the foregoing may be a red herring, off the point and have 
nothing to do with the problem that you are having.  I don't really know 
what I'm doing.  I just follow recipes. :-)  Good luck.

cheers,

Rolf Turner

On 29/04/14 07:26, Fong Chun Chan wrote:
> Hi,
>
> I am trying to get the R package Cairo installed. I've been successfully in
> building the latest version of Cairo library (1.12.16,
> http://cairographics.org/) from source and installed into ~/usr/local using
>
> ./configure --prefix=/home/fong/usr/local
>
> I set the my CAIRO_LIBS and CAIRO_CLAGS environment variables in my
> ~/.bashrc:
>
> export CAIRO_LIBS=${HOME}/usr/local/lib
> export CAIRO_CFLAGS=${HOME}/usr/local/include
>
> When I try to install Cairo in R using:
>
> install.packages('Cairo')
>
> I get the following error:
>
> checking for pkg-config... /home/fong/usr/local/bin/pkg-config
> configure: CAIRO_CFLAGS=/home/fong/usr/local/include/cairo
> checking if R was compiled with the RConn patch... no
> checking cairo.h usability... no
> checking cairo.h presence... no
> checking for cairo.h... no
> configure: error: Cannot find cairo.h! Please install cairo (
> http://www.cairographics.org/) and/or set CAIRO_CFLAGS/LIBS correspondingly.
> ERROR: configuration failed for package 'Cairo'
>
> But I can see the cairo.h header in /home/fong/usr/local/include/cairo. I
> been trying to scouring the internet for answers, but I can't seem to find
> any work for me. If anyone has any suggestions that would be helpful.
>
> Thanks
>
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C
>            LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] vimcom.plus_0.9-93 setwidth_1.0-3     colorout_1.0-2
>
> loaded via a namespace (and not attached):
> [1] tcltk_3.1.0 tools_3.1.0


From wdunlap at tibco.com  Tue Apr 29 02:47:11 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Apr 2014 17:47:11 -0700
Subject: [R] delay evaluation of expression
In-Reply-To: <CAFnz2-_6rzLjW9yGi31S+unArXJ1xLvEaEqvwjO9gBnwi2Lnmg@mail.gmail.com>
References: <CAFnz2--wMFDGHqQJGF-EQWERGfJG1hjabNc6sW-=z46QjkrMcA@mail.gmail.com>
	<CAF8bMcZH1GfSnOsBywhmDRZM1em=YV3XEP586r6T47Lxjn7yYQ@mail.gmail.com>
	<CAFnz2-_6rzLjW9yGi31S+unArXJ1xLvEaEqvwjO9gBnwi2Lnmg@mail.gmail.com>
Message-ID: <CAF8bMcZTtxLhDDo+DrXez50XJpH2T+q2+aKt1p-4n9v9qqjSDw@mail.gmail.com>

> I have tried, but it doesn't help because when you use the load_all()
> function of devtools,
> the datasets are not lazyLoaded but fully evaluated..

Does LazyLoad:yes in yourPackage/DESCRIPTION work for you when you use
the command line 'R CMD INSTALL yourPackage?

I don't use devtools, but perhaps you should ask its author about how
to do what you want.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 28, 2014 at 3:21 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
> Hi William,
> I have tried, but it doesn't help because when you use the load_all()
> function of devtools,
> the datasets are not lazyLoaded but fully evaluated..
>
> I have solved for the moment saving them as rds files (saveRDS()) and
> using the function delayedAssign()
>
> I was wondering if there is some better way to manage this, though.
>
> Thanks for your help,
> Luca
>
> 2014-04-29 0:06 GMT+02:00 William Dunlap <wdunlap at tibco.com>:
>> Have you tried putting the line
>>   LazyData; true
>> (or yes) into your package's DESCRIPTION file?
>>
>> See 'Writing R Extensions', section 1.1.6 'Data in packages.'
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 28, 2014 at 12:45 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
>>> Dear all,
>>> in one of my packages I need to load some data from .Rdata files that
>>> are to be used from
>>> some functions (but not all off them). I would like to delay the
>>> loading of this datasets
>>> only when needed. In other cases I successfully used lazyLoad and
>>> delayedAssign(),
>>> but when I try to load a .Rdata file I get this message: Error: cannot
>>> add bindings to a locked environment
>>>
>>> What would be the best way to load such a db only the first time that is needed?
>>> Thanks a lot for you help,
>>>
>>> Cheers,
>>> Luca
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Luca Cerone
>
> Tel: +34 692 06 71 28
> Skype: luca.cerone


From peter.langfelder at gmail.com  Tue Apr 29 03:36:52 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 28 Apr 2014 18:36:52 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
Message-ID: <CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>

Make sure you have cairo-devel installed, and remove the lines

export CAIRO_LIBS=${HOME}/usr/local/lib
export CAIRO_CFLAGS=${HOME}/usr/local/include

from your .bashrc file. If you have cairo-devel installed normally,
the headers should be found with default settings of all search paths.
The settings you have are, to the best of my somewhat limited
knowledge, wrong - you need to prefix each directory with an
appropriate compiler flags (-L for library directories, and -I for
include directories). Anyway, as I said, 1. install cairo-devel using
your package manager, and 2. remove the two lines from .bashrc.

Peter


On Mon, Apr 28, 2014 at 12:26 PM, Fong Chun Chan <fongchunchan at gmail.com> wrote:
> Hi,
>
> I am trying to get the R package Cairo installed. I've been successfully in
> building the latest version of Cairo library (1.12.16,
> http://cairographics.org/) from source and installed into ~/usr/local using
>
> ./configure --prefix=/home/fong/usr/local
>
> I set the my CAIRO_LIBS and CAIRO_CLAGS environment variables in my
> ~/.bashrc:
>
> export CAIRO_LIBS=${HOME}/usr/local/lib
> export CAIRO_CFLAGS=${HOME}/usr/local/include
>
> When I try to install Cairo in R using:
>
> install.packages('Cairo')
>
> I get the following error:
>
> checking for pkg-config... /home/fong/usr/local/bin/pkg-config
> configure: CAIRO_CFLAGS=/home/fong/usr/local/include/cairo
> checking if R was compiled with the RConn patch... no
> checking cairo.h usability... no
> checking cairo.h presence... no
> checking for cairo.h... no
> configure: error: Cannot find cairo.h! Please install cairo (
> http://www.cairographics.org/) and/or set CAIRO_CFLAGS/LIBS correspondingly.
> ERROR: configuration failed for package 'Cairo'
>
> But I can see the cairo.h header in /home/fong/usr/local/include/cairo. I
> been trying to scouring the internet for answers, but I can't seem to find
> any work for me. If anyone has any suggestions that would be helpful.
>
> Thanks
>
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C
>           LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] vimcom.plus_0.9-93 setwidth_1.0-3     colorout_1.0-2
>
> loaded via a namespace (and not attached):
> [1] tcltk_3.1.0 tools_3.1.0
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fongchunchan at gmail.com  Tue Apr 29 04:14:27 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Mon, 28 Apr 2014 19:14:27 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
	<CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
Message-ID: <CAB-BZ9+mOD7m97ULPet=HHrjfuvYjdd+KJgTqDOBfn-PR_GMpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/b4e16a5b/attachment.pl>

From boris.steipe at utoronto.ca  Tue Apr 29 04:36:55 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 28 Apr 2014 22:36:55 -0400
Subject: [R] Color points in princomp() plot
In-Reply-To: <535EA544.2020502@ucla.edu>
References: <535EA544.2020502@ucla.edu>
Message-ID: <0FB67D22-DC1B-48BD-ADFF-23735374ABE6@utoronto.ca>

At first I thought this is easy: use the same strategy you use for all of these types of questions. Plot with type="n" to suppress output of points, then use points() or text() to get the colors and shapes and whatnot you need ...

Turns out biplot() does not use a type argument ...

... and you can't simply fake it by setting cex to a really small value, because biplot() actually creates two plots: one for the scores, then one for the axes. And once you have plotted the axes, the axis limits for the plot have changed, and you can't easily apply points() anymore.

... and you can't easily rescale, because ... well, have a look at the code.

The code, incidentally can be found with getAnywhere(<function.name>).

So what's the solution ...

Since I've wanted this capability for some time, I modified the original biplot() to accept a type parameter type={"t" (Default) | "p" | "n"}. For "t", the function behaves almost exactly as before. For "p" it plots points, and should accept all the usual arguments for that. For "n" it plots nothing except the axes. You can then add the points as desired.

I also added two parameters col.arrows = "red", and col.text = "black" to have extra control.

Here is an example. (Note, you have to load the function, below, first.





library(MASS)
data(crabs)
PRC <- prcomp(crabs[, 4:8])

myBiplot(PRC)
myBiplot(PRC, choices=2:3, cex = 0.7, col.text="#445599") # much as before


# use filled points, color by the value found in column 4 of the data
r <- range(crabs[,4]) 
n <- 15
cv <- cm.colors(n)  
c <- cv[cut(crabs[,4],n)]  
myBiplot(PRC, choices=2:3, type = "p", pch=20, col=c, col.arrows = "#FF6600")


# finally: plot nothing then use points() for detailed control 
myBiplot(PRC, choices=2:3, type = "n")  # no points

# blue/orange crab males/females - as given by rows in the data
points(PRC$x[  1: 50, 2:3], pch=21, bg="#0066FF")
points(PRC$x[ 51:100, 2:3], pch=24, bg="#0066FF")
points(PRC$x[101:150, 2:3], pch=21, bg="#FF6600")
points(PRC$x[151:200, 2:3], pch=24, bg="#FF6600")




Enjoy,
Boris

==============================================================
myBiplot <- function (x, choices = 1L:2L, scale = 1,
                      pc.biplot = FALSE, var.axes = TRUE,
                      type = "t",
                      col,
                      col.arrows = "#FF0000",
                      col.text = "#000000",
                      cex = rep(par("cex"), 2),
                      expand = 1, 
                      xlabs = NULL, ylabs = NULL,
                      xlim = NULL, ylim = NULL, 
                      main = NULL, sub = NULL,
                      xlab = NULL, ylab = NULL, 
                      arrow.len = 0.1,
                      ...
                      )

{
	if (length(choices) != 2L) 
        stop("length of choices must be 2")
    if (!length(scores <- x$x)) 
        stop(gettextf("object '%s' has no scores", deparse(substitute(x))), 
            domain = NA)
    if (is.complex(scores)) 
        stop("biplots are not defined for complex PCA")
        
    lam <- x$sdev[choices]
    n <- NROW(scores)
    lam <- lam * sqrt(n)
    
    if (scale < 0 || scale > 1) 
        warning("'scale' is outside [0, 1]")
    if (scale != 0) 
        lam <- lam^scale
    else lam <- 1
    if (pc.biplot) 
        lam <- lam/sqrt(n)
        
    y <- t(t(x$rotation[, choices]) * lam)
    x <- t(t(scores[, choices])/lam)  # note that from here on
                                      # x is no longer the PC object
                                      # originally pased into the function
    n <- nrow(x)
    p <- nrow(y)
    
    if (missing(xlabs)) {
        xlabs <- dimnames(x)[[1L]]
        if (is.null(xlabs)) 
            xlabs <- 1L:n
    }
    xlabs <- as.character(xlabs)
    dimnames(x) <- list(xlabs, dimnames(x)[[2L]])
    
    if (missing(ylabs)) {
        ylabs <- dimnames(y)[[1L]]
        if (is.null(ylabs)) 
            ylabs <- paste("Var", 1L:p)
    }
    ylabs <- as.character(ylabs)
    dimnames(y) <- list(ylabs, dimnames(y)[[2L]])

    if (length(cex) == 1L) 
        cex <- c(cex, cex)

    unsigned.range <- function(x) c(-abs(min(x, na.rm = TRUE)), 
        abs(max(x, na.rm = TRUE)))
    rangx1 <- unsigned.range(x[, 1L])
    rangx2 <- unsigned.range(x[, 2L])
    rangy1 <- unsigned.range(y[, 1L])
    rangy2 <- unsigned.range(y[, 2L])

    if (missing(xlim) && missing(ylim)) 
        xlim <- ylim <- rangx1 <- rangx2 <- range(rangx1, rangx2)
    else if (missing(xlim)) 
        xlim <- rangx1
    else if (missing(ylim)) 
        ylim <- rangx2

    ratio <- max(rangy1/rangx1, rangy2/rangx2)/expand
    on.exit(par(op))
    op <- par(pty = "s")
    if (!is.null(main)) 
        op <- c(op, par(mar = par("mar") + c(0, 0, 1, 0)))

    # first, plot scores - either normally, or as row labels
    if (type == "p") {
	    plot(x, type = type, xlim = xlim, ylim = ylim, col = col, 
        xlab = xlab, ylab = ylab, sub = sub, main = main, ...)
    }
    else if (type == "t") {
        plot(x, type = "n", xlim = xlim, ylim = ylim, 
             xlab = xlab, ylab = ylab, sub = sub, main = main, ...)
        text(x, xlabs, cex = cex[1L], col = col.text, ...)
    	
    }
    else if (type == "n") {  # plot an empty frame
	    plot(x, type = type, xlim = xlim, ylim = ylim, 
        xlab = xlab, ylab = ylab, sub = sub, main = main, ...)
    }

    par(new = TRUE)
    dev.hold()
    on.exit(dev.flush(), add = TRUE)
    plot(y, axes = FALSE, type = "n", xlim = xlim * ratio, ylim = ylim * 
        ratio, xlab = "", ylab = "", col = col.arrows, ...)
    axis(3, col = col.arrows, ...)
    axis(4, col = col.arrows, ...)
    box(col = "#000000")
    text(y, labels = ylabs, cex = cex[2L], col = col.arrows, ...)
    if (var.axes) 
        arrows(0, 0, y[, 1L] * 0.8, y[, 2L] * 0.8, col = col.arrows, 
            length = arrow.len)
    # now replot into xlim, ylim scaled by lam, to reset par("usr")
    # to the  correct values needed for subsequent application of points(),
    # text() etc.
    par(new = TRUE)
    dev.hold()
    on.exit(dev.flush(), add = TRUE)
	plot(0, type = "n", xlim = xlim * lam[1], ylim = ylim * lam[2], 
    xlab = '', ylab = '', sub = '', main = '', xaxt='n', yaxt='n', axes=FALSE)

    invisible()

}

==============================================================


On 2014-04-28, at 3:00 PM, Noah Silverman wrote:

> Hi,
> 
> The princomp() function has a nice method to generate a pretty biplot of
> the data.  I have some data where the points are divided into a few
> groups.  My intention is to generate a biplot, using princomp, but color
> the points based on group membership.  The hope is that points will show
> some kind of clustering by group in the biplot.
> 
> However, I can't figure out how to indicate individual point color in a
> biplot.  The only setting I found was to indicate a single color for
> *all* the points.
> 
> Any ideas?
> 
> 
> -- 
> *Noah Silverman, PhD* | UCLA Department of Statistics
> 8117 Math Sciences Building, Los Angeles, CA 90095
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From guadalupebastos at gmail.com  Tue Apr 29 03:07:12 2014
From: guadalupebastos at gmail.com (Guadalupe Bastos)
Date: Mon, 28 Apr 2014 20:07:12 -0500
Subject: [R] problems with cloropleth map of Japan
Message-ID: <CAHk1vE-UQQ-==_=NpFw+4KRyVgzNkwW6OdCTcYMCV-0WowY__w@mail.gmail.com>

Hi:
I have recently started working with creating maps in R. I have been able
to create cloropleth maps for Europe without a problem.
However, when I try doing the same for Japan, which shapefile is downloaded
from the website http://gadm.org/country , R stops working. The message
that pops up is "Error: R for windows GUI front-end has stopped working". I
can see the map was created at the back of the screen, but I'm not able to
save it.
I don't know if this is a bug or if there's something I'm doing wrong. The
idea of this code is that Japan only has a value for all the country of my
variable (the value is 2.15). And what I want is for Japan to be shaded in
the corresponding color. So it will be only one color for the whole country.
Here is the code. You'll need to download the shapefile from
http://gadm.org/country and un-zip in the directory you are working.

I hope you can help me. Thanks in advance!

rm(list=ls(all=TRUE))
#--------------------------------------------------------------
#USER INSTRUCTIONS:
#First time user: install packages
#install.packages(c("sp", "maptools", "rgdal"), dependencies=TRUE)  #It's
very important that this package is installed this way
  #Install this package if it's the first time you run this
#install.packages("ggplot2")
#install.packages("ggmap")
#install.packages("rgeos")
#install.packages("foreign")

#----------------------------------------------------------------------------
# Libraries we use:
library(maptools)
library(ggplot2)
library(ggmap)
library(rgeos)
library(foreign)


#-------------------------------------------------------------------------------
# JAPAN
#-------------------------------------------------------------------------------
#Download shapefile from
#http://gadm.org/country

# read administrative boundaries (change folder appropriately)
japMap <- readShapePoly(fn="JPN_adm/JPN_adm0.shp")

summary(japMap)
# data
japEdu <- data.frame(1,2); names(japEdu) <- c('GEO','Value')
japEdu$GEO <- 114
japEdu$Value <- 2.15

japMapDf=fortify(japMap, region='ID_0')

# merge map and data
japEduMapDf <- merge(japMapDf, japEdu, by.x="id", by.y="GEO")
japEduMapDf <- japEduMapDf[order(japEduMapDf$order),]

# ggplot mapping
# data layer
m0 <- ggplot(data=japEduMapDf)

# empty map (only borders)
m1 <- m0 + geom_path(aes(x=long, y=lat, group=group), color='gray') +
coord_equal()

# fill with education expenditure data
m2 <- m1 + geom_polygon(aes(x=long, y=lat, group=group, fill=Value))
m2

From fongchunchan at gmail.com  Tue Apr 29 05:16:25 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Mon, 28 Apr 2014 20:16:25 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CA+hbrhWK-L0akogvmmqj8Stz3HOiiFVDdgF3PdXvrkn1M_RRgg@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
	<CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
	<CAB-BZ9+mOD7m97ULPet=HHrjfuvYjdd+KJgTqDOBfn-PR_GMpw@mail.gmail.com>
	<CA+hbrhWK-L0akogvmmqj8Stz3HOiiFVDdgF3PdXvrkn1M_RRgg@mail.gmail.com>
Message-ID: <CAB-BZ9JXDJJX98LR3Rm9nXyNm=cSgKMu9qYPF-AS_X9g_1uL9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140428/b5013394/attachment.pl>

From cassiejones26 at gmail.com  Tue Apr 29 06:15:18 2014
From: cassiejones26 at gmail.com (cassie jones)
Date: Tue, 29 Apr 2014 09:45:18 +0530
Subject: [R] Fwd: problem with kmeans
In-Reply-To: <CAFkmApMcifd3v6Mm1-oAEc-7PbfRPFSJ+Kr6OoShqUEEZPtb-Q@mail.gmail.com>
References: <CAFkmApMcifd3v6Mm1-oAEc-7PbfRPFSJ+Kr6OoShqUEEZPtb-Q@mail.gmail.com>
Message-ID: <CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/cc3989e5/attachment.pl>

From peter.langfelder at gmail.com  Tue Apr 29 06:34:44 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 28 Apr 2014 21:34:44 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CAB-BZ9JXDJJX98LR3Rm9nXyNm=cSgKMu9qYPF-AS_X9g_1uL9w@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
	<CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
	<CAB-BZ9+mOD7m97ULPet=HHrjfuvYjdd+KJgTqDOBfn-PR_GMpw@mail.gmail.com>
	<CA+hbrhWK-L0akogvmmqj8Stz3HOiiFVDdgF3PdXvrkn1M_RRgg@mail.gmail.com>
	<CAB-BZ9JXDJJX98LR3Rm9nXyNm=cSgKMu9qYPF-AS_X9g_1uL9w@mail.gmail.com>
Message-ID: <CA+hbrhU7C8Epp5-7ujS0aJUT3v0v4hEmFs024z0ZSQax0LQe-w@mail.gmail.com>

I **think** the linker is missing a directive to actually link in the
cairo library. Try adding -lcairo to the LIB flags, something like

export CAIRO_LIBS='-L${HOME}/usr/local/lib -lcairo'

or simply

export CAIRO_LIBS=-l${HOME}/usr/local/lib/libcairo.so

I am not 100% sure of the syntax, but this may work.

Note that my pkg-config gives me this for cairo:

$ pkg-config --cflags --libs cairo
-I/usr/include/cairo -I/usr/include/glib-2.0
-I/usr/lib64/glib-2.0/include -I/usr/include/pixman-1
-I/usr/include/freetype2 -I/usr/include/libpng15 -I/usr/include/libdrm
 -lcairo

There are many more -I directives than what you had, but I'm not sure
if all of it is really necessary. if your configure or compilation
fail, it is something to keep in mind.

HTH,

Peter

On Mon, Apr 28, 2014 at 8:16 PM, Fong Chun Chan <fongchunchan at gmail.com> wrote:
> Thanks Peter. From the config.log file, the issue appears to occur here at
> the "/home/fong/Cairo/conftest.c:28: undefined reference to `cairo_create'"
>
>
> -----
>
> configure:3631: gcc -std=gnu99 -o conftest -g -O2
> -I/home/fong/usr/local/include/cairo   conftest.c -lz
> -L/home/fong/usr/local/lib >&5
> configure:3631: $? = 0
> configure:3648: result: -lz
> configure:3657: checking whether Cairo programs can be compiled
> configure:3671: gcc -std=gnu99 -o conftest -g -O2
> -I/home/fong/usr/local/include/cairo   conftest.c -lz
> -L/home/fong/usr/local/lib >&5
> /tmp/ccIr2WlB.o: In function `main':
> /home/fong/Cairo/conftest.c:28: undefined reference to `cairo_create'
> collect2: ld returned 1 exit status
> configure:3671: $? = 1
> configure: failed program was:
> | /* confdefs.h */
> | #define PACKAGE_NAME "Cairo"
> | #define PACKAGE_TARNAME "cairo"
> | #define PACKAGE_VERSION "1.3"
> | #define PACKAGE_STRING "Cairo 1.3"
> | #define PACKAGE_BUGREPORT "Simon.Urbanek at r-project.org"
> | #define PACKAGE_URL ""
> | #define STDC_HEADERS 1
> | #define HAVE_SYS_WAIT_H 1
> | #define HAVE_SYS_TYPES_H 1
> | #define HAVE_SYS_STAT_H 1
> | #define HAVE_STDLIB_H 1
> | #define HAVE_STRING_H 1
> | #define HAVE_MEMORY_H 1
> | #define HAVE_STRINGS_H 1
> | #define HAVE_INTTYPES_H 1
> | #define HAVE_STDINT_H 1
> | #define HAVE_UNISTD_H 1
> | #define HAVE_STRING_H 1
> | #define HAVE_SYS_TIME_H 1
> | #define HAVE_UNISTD_H 1
> | /* end confdefs.h.  */
>
>
> On Mon, Apr 28, 2014 at 7:50 PM, Peter Langfelder
> <peter.langfelder at gmail.com> wrote:
>>
>> On Mon, Apr 28, 2014 at 7:14 PM, Fong Chun Chan <fongchunchan at gmail.com>
>> wrote:
>> > Hi Peter,
>> >
>> > Thanks for the reply. I don't have access to the package manager
>> > unfortunately as I am working on a cluster where I don't have admin. So
>> > everything has to installed into my ~/export
>> > CAIRO_LIBS=-L${HOME}/usr/local/lib
>> > export CAIRO_CFLAGS=-I${HOME}/usr/local/include
>> > /local. I tried looking into homebrew/linuxbrew, but the gcc compiler
>> > (4.1.2) is not suitable for linuxbrew and installing a new gcc compiler
>> > isn't a simply endeavor from source.
>>
>> I see - in that case I think you are on the right track.
>>
>> >
>> > I installed cairo from source specifically the
>> > http://cairographics.org/releases/cairo-1.12.16.tar.xz download. What is
>> > this cairo-devel you are referring to? It seems to be something related
>> > to
>> > using the package manager?
>>
>> If you install from source, you (usually) also get the development
>> files (the content of cairo-devel) by default.
>>
>> >
>> > In any case, your second point about the "-L for library directories,
>> > and -I
>> > for
>> > include directories" was actually useful. Rather than remove those lines
>> > (as
>> > that didn't help), I modified my ~/.bashrc a bit (I am also limited in
>> > my
>> > understanding paths)
>> >
>> > export CAIRO_LIBS=-L${HOME}/usr/local/lib
>> > export CAIRO_CFLAGS=-I${HOME}/usr/local/include
>> >
>> > This actually got around that issue! But now I've run into another
>> > issue:
>> >
>> > checking for pkg-config... /home/fong/usr/local/bin/pkg-config
>> > configure: CAIRO_CFLAGS=-I/home/fong/usr/local/include/cairo
>> > checking if R was compiled with the RConn patch... no
>> > checking cairo.h usability... yes
>> > checking cairo.h presence... yes
>> > checking for cairo.h... yes
>> > checking for PNG support in Cairo... yes
>> > checking for ATS font support in Cairo... no
>> > configure: CAIRO_LIBS=-L/home/fong/usr/local/lib
>> > checking for library containing deflate... -lz
>> > checking whether Cairo programs can be compiled... configure: error:
>> > Cannot
>> > compile a simple Cairo program. See config.log for details.
>> > ERROR: configuration failed for package ?Cairo?
>>
>> If you look at the config.log file and post the releavant part (don't
>> post the whole thing, it's huge), I (or R compiling experts) can try
>> to help you more.
>>
>> Peter
>
>


From maitra.mbox.ignored at inbox.com  Tue Apr 29 06:35:10 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Mon, 28 Apr 2014 23:35:10 -0500
Subject: [R] Fwd: problem with kmeans
In-Reply-To: <CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>
References: <CAFkmApMcifd3v6Mm1-oAEc-7PbfRPFSJ+Kr6OoShqUEEZPtb-Q@mail.gmail.com>
	<CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>
Message-ID: <20140428233510.2bc12b5201b2b9882c33b612@inbox.com>

Cassie,

I am sorry but do you even know what k-means does? That it is a locally
optimal algorithm. That different software implement the same algorithm
differently.

FYI, R uses the Hartigan-Wong (1979) algorithm by default, which is
probably the most efficient out there. 

I suggest you first go to a multivariate statistics class before
passing such sweeping statements. (Btw, did these same "some people"
tell you that most other software do not provide the kinds of broad
abilities which R provides, and therefore are not even comparable.)

And then, please read the help function for how to "improve" your run
of k-means using R.  

HTH,
Ranjan


On Tue, 29 Apr 2014 09:45:18 +0530 cassie jones
<cassiejones26 at gmail.com> wrote:

> Dear R-users,
> 
> I am trying to run kmeans on a set comprising of 100 observations. But R
> somehow can not figure out the true underlying groups, although other
> software such as Jmp, MINITAB are producing the desired result.
> 
> Following is a brief example of what I am doing.
> 
> library(stringdist)
> test=c('hematolgy','hemtology','oncology','onclogy',
> 'oncolgy','dermatolgy','dermatoloy','dematology',
> 'neurolog','nerology','neurolgy','nerology')
> 
> dis=stringdistmatrix(test,test, method = "lv")
> 
> set.seed(123)
> cl=kmeans(dis,4)
> 
> 
> grp_cl=vector('list',4)
> 
> for(i in 1:4)
> {
>     grp_cl[[i]]=test[which(cl$cluster==i)]
> }
> grp_cl
> 
> [[1]]
> [1] "oncology" "onclogy"
> 
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
> 
> [[3]]
> [1] "oncolgy"
> 
> [[4]]
> [1] "hematolgy"  "hemtology"  "dermatolgy" "dermatoloy" "dematology"
> 
> In the above example, the 'test' variable consists of a set of
> terminologies with various typos and I am trying to group the similar types
> of words based on their string distance. Unfortunately kmeans is not able
> to replicate the following result that the other software are able to
> produce.
> [[1]]
> [1] "oncology" "onclogy"  "oncolgy"
> 
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
> 
> [[3]]
> [1] "dermatolgy" "dermatoloy" "dematology"
> 
> [[4]]
> [1] "hematolgy"  "hemtology"
> 
> 
> Does anyone know if there is a way out, I have heard from a lot of people
> that multivariate analysis in R does not produce the desired result most of
> the time. Any help is really appreciated.
> 
> 
> Thanks in advance.
> 
> 
> Cassie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From peter.langfelder at gmail.com  Tue Apr 29 06:44:25 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 28 Apr 2014 21:44:25 -0700
Subject: [R] Fwd: problem with kmeans
In-Reply-To: <CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>
References: <CAFkmApMcifd3v6Mm1-oAEc-7PbfRPFSJ+Kr6OoShqUEEZPtb-Q@mail.gmail.com>
	<CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>
Message-ID: <CA+hbrhVVZnPABSoab9SUc5w-3ZoK0REVVz5OYYvMjV4vLJexZQ@mail.gmail.com>

You are using the wrong algorithm. You want Partitioning around
Medoids (PAM, function pam), not k-means. PAM is also known as
k-medoids, which is where the confusion may come from.

use

library(cluster)

cl = pam(dis, 4)

and see if you get what you want.

HTH,

Peter



On Mon, Apr 28, 2014 at 9:15 PM, cassie jones <cassiejones26 at gmail.com> wrote:
> Dear R-users,
>
> I am trying to run kmeans on a set comprising of 100 observations. But R
> somehow can not figure out the true underlying groups, although other
> software such as Jmp, MINITAB are producing the desired result.
>
> Following is a brief example of what I am doing.
>
> library(stringdist)
> test=c('hematolgy','hemtology','oncology','onclogy',
> 'oncolgy','dermatolgy','dermatoloy','dematology',
> 'neurolog','nerology','neurolgy','nerology')
>
> dis=stringdistmatrix(test,test, method = "lv")
>
> set.seed(123)
> cl=kmeans(dis,4)
>
>
> grp_cl=vector('list',4)
>
> for(i in 1:4)
> {
>     grp_cl[[i]]=test[which(cl$cluster==i)]
> }
> grp_cl
>
> [[1]]
> [1] "oncology" "onclogy"
>
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
>
> [[3]]
> [1] "oncolgy"
>
> [[4]]
> [1] "hematolgy"  "hemtology"  "dermatolgy" "dermatoloy" "dematology"
>
> In the above example, the 'test' variable consists of a set of
> terminologies with various typos and I am trying to group the similar types
> of words based on their string distance. Unfortunately kmeans is not able
> to replicate the following result that the other software are able to
> produce.
> [[1]]
> [1] "oncology" "onclogy"  "oncolgy"
>
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
>
> [[3]]
> [1] "dermatolgy" "dermatoloy" "dematology"
>
> [[4]]
> [1] "hematolgy"  "hemtology"
>
>
> Does anyone know if there is a way out, I have heard from a lot of people
> that multivariate analysis in R does not produce the desired result most of
> the time. Any help is really appreciated.
>
>
> Thanks in advance.
>
>
> Cassie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Apr 29 09:58:57 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Apr 2014 00:58:57 -0700 (PDT)
Subject: [R] Difference between comma separated values in column
Message-ID: <1398758337.68252.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

It is better to show the example data using ?dput().? Here, it is not clear whether the columns are character columns or lists.
##If it is the latter case

dat1 <- data.frame(V1=I(list(1:3, c(1,2,4), c(2,3,4,5))), V2= I(list(c(3,6,5), c(7,10,9), 2:5)))
?dat1$V3 <- mapply(`c`,mapply(`-`, lapply(dat1$V2, `[`,-1), lapply(dat1$V1,head,-1)), lapply(dat1$V1,tail,1))
?dat1
#????????? V1???????? V2???????? V3
#1??? 1, 2, 3??? 3, 6, 5??? 5, 3, 3
#2??? 1, 2, 4?? 7, 10, 9??? 9, 7, 4
#3 2, 3, 4, 5 2, 3, 4, 5 1, 1, 1, 5


##If the columns are character vectors.

dat2 <- structure(list(V1 = c("1,2,3", "1,2,4", "2,3,4,5"), V2 = c("3,6,5", 
"7,10,9", "2,3,4,5")), .Names = c("V1", "V2"), row.names = c(NA, 
-3L), class = "data.frame")
?lst1 <- sapply(dat2, function(x) lapply(strsplit(x, split=","),as.numeric))
dat2$V3 <- unlist(lapply(mapply(`c`,mapply(`-`, lapply(lst1[,2],`[`, -1), lapply(lst1[,1], head,-1)), lapply(lst1[,1], tail,1)), paste, collapse=","))
?dat2
#?????? V1????? V2????? V3
#1?? 1,2,3?? 3,6,5?? 5,3,3
#2?? 1,2,4? 7,10,9?? 9,7,4
#3 2,3,4,5 2,3,4,5 1,1,1,5


A.K.


?Hi,

I have a quick question in R. I have dataframe with two columns with multiple values separated by comma.
Example:
?????????? 
??????? V1?????????? V2
1??? 1, 2, 3????? 3, 6, 5
2??? 1, 2, 4????? 7, 10, 9
3??? 2, 3, 4, 5?? 2, 3, 4, 5

I want to calculate the difference between both the column.

Expected results (suppose results are stored in V3) - it is basically subtracting (n-th) value of the column1 from? (n-th + 1) value of column2.
?????? 
??????? V3????????? 
1??? 6-1, 5-2, 3????? 
2??? 10-1, 9-2, 4??? 
3??? 3-2, 4-3, 5-4, 5

which gives??? (Last value doesn't matter)
???? 
?????? V3????????? 
1??? 5, 3, 3????? 
2??? 9, 7, 4??? 
3??? 1, 1, 1, 5

Would greatly appreciate if anyone can suggest how can I proceed? 



From dulcalma at bigpond.com  Tue Apr 29 11:20:46 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 29 Apr 2014 19:20:46 +1000
Subject: [R] lattice plot formatting: pch, abbreviation and labels
In-Reply-To: <CAMk+s2R2euedW=9vMkzc4c=oYvmGOKkU8zj8Hsnpm2J-nu3Yew@mail.gmail.com>
References: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>	<002a01cf61b4$fdd47300$f97d5900$@bigpond.com>	<CAMk+s2SDJ13rQXzm_O503vYLF7nEPDVfRcXbNHwbDAzb6TB-Kg@mail.gmail.com>	<001201cf6280$b3229e00$1967da00$@bigpond.com>
	<CAMk+s2R2euedW=9vMkzc4c=oYvmGOKkU8zj8Hsnpm2J-nu3Yew@mail.gmail.com>
Message-ID: <002101cf638c$4e847ab0$eb8d7010$@bigpond.com>

Hi Luigi

Only minor changes needed.

When you go back to a normal xyplot the rules of ratio variables apply the x-axis default in your case something like pretty(range(x)
So the x-axis limits range from 0-1 
and the panel limits therefore are 0-1 +/- 4%
With strip stripplot being categorical the limits are for values 1 and 2 so the top value for 2 is not being shown
(easily seen with str(xyplot object))

You missed out the assigning of groups to the segments.
You could do this by a for loop of 1:2 or by using groups/panel.groups.
I have not got the time to dig out the code to do it at the moment.

xyplot(copy ~ positivity|stimulation, data = my.data,
       group = factor(positivity),
       as.table = TRUE,
       layout = c(8,1),
       xlim  = c(-1,2),
       scales = list(x = list(at = c(0,1), 
                             labels = c("N","P"),
                             rot = 0)),
      jitter.data=TRUE, 
      pch=c(16,1),
      col="black",
      ylab=expression(bold("Copy")),
      xlab=expression(bold("Stimulation")),
      main="Plot",
      par.settings = list(strip.background=list(col="white")),
                                     par.strip.text=list(font=2),
      key = list(space="top",
                 columns=2,
                 text=list(c("Positive", "Negative"), col="black"),
                 points=list(pch=c(16,1), col="black")),
      panel = function(x, y,...){
                pnl = panel.number()
                #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
                #for (j in 1:2){
                #  with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
                #     panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
               for (j in 1:2){
                panel.segments(x0 = (j-1)-0.25, y0 =  datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"], # amend to copy
                             x1 = (j-1)+0.25,  y1 = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"],
                             lwd = 2, col = c("magenta","grey")[j])
                }

               panel.stripplot(x,y, ...)
            }
      )
If you wanted full N P then

       scales = list(x = list(at = c(0,1),
                             alternating = F,
                             labels = c("Negative","Positive"),
                             rot = 90)),  # rot = 0 if labels as before

Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Tuesday, 29 April 2014 04:34
To: Duncan Mackay
Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels

Dear Duncan,
sorry to pester you again with this, but probably the solution is
getting closer. following one of your previous tips i could write the
xyplot synthax as you suggested:

library(lattice)
my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
"Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
 column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")

key.plot<-list(
  space="top", columns=2,
  text=list(c("Positive", "Negative"), col="black"),
  points=list(pch=c(16,1), col="black"))

datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)


#### HERE IS THE IMPORTANT BIT ###

xyplot(copy ~ positivity|stimulation,
  my.data,
  group = positivity,
  hor=F,
  as.table = TRUE,
  layout = c(8,1),
  scales = list(x = list(alternating = FALSE, at = c(0.2,0.8), labels
= c("P","N"))),
  pch=c(16,1), col="black",
  ylab=expression(bold("Copy")),
  xlab=expression(bold("Stimulation")),
  main="Plot",
  par.settings = list(strip.background=list(col="white")),
  par.strip.text=list(font=2),
  key = list(space="top", columns=2, text=list(c("Positive",
"Negative"), col="black"), points=list(pch=c(16,1), col="black")),
  panel = function(x, y, ...){
  pnl = panel.number()
  panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
                              x1 = x+0.25,  y1 = datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
     lwd = 2, col = c("magenta","grey"))
  panel.stripplot(x,y, ...)
               }
       )

############################

beside beign less elegant than stripplot() -- there is no jittering
and requires the positions for the labels -- there are mainly two
problems:
1. the dots are too close to the margins -- I tried to use the 'at'
argument but it did not work
2. the segments are replicated -- there should be a 'panel.group'
somewhere but I obtained a lot of errors when I tried to place it.

Wouldn't be easier to use the stripplot directly, using maybe a factor
to place the segments? I tried to place the panel.function in
stripplot but it did not work at all...

stripplot(copy ~ factor(positivity)|factor(stimulation, levels =
c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879",
"Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = list(space="top",  columns=2, text=list(c("Positive",
"Negative"), col="black"), points=list(pch=c(16,1), col="black")),
        panel = function(x, y, ...){
                pnl = panel.number()
                panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
                                          x1= x+0.25,  y1 =
datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"],
                 lwd = 2, col = c("magenta","grey"))
                panel.stripplot(x,y, ...)
               }
       )


Best wishes,
Luigi

On Mon, Apr 28, 2014 at 2:25 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Here are 2 ways of doing it.
>
> The first is a "cheats" way ie easy.
>
> The second is a substitute for the proper way who's code eludes me at the moment. I changed the lty on the ablines  as it appears confusing and as you are bolding it seems more appropriate. A better way may be to change 1 line type.
>
> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>       my.data,
>       group = positivity,
>       hor=F,
>       layout = c(8,1),
>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
>       xlab=expression(bold("Stimulation")),
>       main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = list(space="top",
>                  columns=2,
>                  text=list(c("Positive", "Negative"), col="black"),
>                  points=list(pch=c(16,1), col="black")),
>       panel = function(x, y,...){
>               pnl = panel.number()
>               #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>
>               panel.average(x, y, fun = mean, horizontal = F, lty = 3, col.line = c("red","black"), type = "l")
>
>               panel.stripplot(x,y, ...)
>             }
>       )
>
> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>       my.data,
>       group = positivity,
>       hor=F,
>       layout = c(8,1),
>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
>       xlab=expression(bold("Stimulation")),
>       main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = list(space="top",
>                  columns=2,
>                  text=list(c("Positive", "Negative"), col="black"),
>                  points=list(pch=c(16,1), col="black")),
>       panel = function(x, y,...){
>                 pnl = panel.number()
>                 #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>                 for (j in 1:2){
>                   with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
>                      panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
>
>               }
>
>                panel.stripplot(x,y, ...)
>             }
>       )
>
> Remember abline and panel.abline etc only take 1 line at a time so if you have more than 1 group you have 2 call it more than once
>
> Regards
> Duncan
>
> -----Original Message-----
> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
> Sent: Monday, 28 April 2014 04:03
> To: Duncan Mackay
> Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels
>
> Dear Duncan,
> may I bother you a bit more with the same data set? I would like now
> to add a segment corresponding to the median values, as we discussed
> antecedently.
> I have tried to use the code you wrote in the previous mails, but it
> hasn't worked. First I have found the aggregate medians values and
> assigned to datmeA, then pasted the code you wrote, but without
> success. Would be possible to substitute the panel.abline with
> panel.segments? but in this case how to tell lattice what are the
> values for "N" or "P"?
> Best wishes,
> Luigi
>
> CODE::::
> library(lattice)
>
> my.data<-structure(list(
>    column_1 = 1:120,
>    column_2 = structure(c(
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
> "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>     column_3 = structure(c(
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 0,0,0,0,0,0,0,0)),
>      column_4 = c(
>  192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
>  2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
>  870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>  142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
>  3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
>  1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
>  208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
>  4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
>  2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
>  0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
>  97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
>  5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
>  3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
>  2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
> c(NA, -120L),
>  class = "data.frame")
>
>
> key.plot<-list(
>   space="top", columns=2,
>   text=list(c("Positive", "Negative"), col="black"),
>   points=list(pch=c(16,1), col="black"))
>
> datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)
>
> stripplot(
>       copy ~ factor(positivity)|factor(stimulation,
>             levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654",
> "Rv3879", "Rv3873","PHA")),
>             group = positivity,
>       my.data,
>       hor=F,
>       layout = c(8,1),
>             scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
> xlab=expression(bold("Stimulation")), main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = key.plot,
>             panel = function(x, y){
>               pnl = panel.number()
>               panel.abline(h = datmeA[datmeA[,2]==
>
> levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>
>               panel.stripplot(x,y, ...)
>             }
>       )
>
> On Sun, Apr 27, 2014 at 2:06 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> Hi Luigi
>>
>> You are typing things unnecessarily: do not use the attach command unless
>> absolutely necessary - it has unfortunate consequences.
>> It is better to use with or within.
>> alpha is not available with some devices with bad consequences if used; its
>> default is 1 anyway.
>>
>> Once you have stated a data.frame as the data object it is usually not
>> necessary to use the data.frame$ sign in to signify column names: use the
>> column names.
>> data = "a data.frame" is the equivalent to with
>>
>> You are reordering the levels of stimulation and changing the name of 1 so I
>> thought it was easiest to make a column stim and do things there otherwise
>> it the relevelling could be done in the data argument using the subset
>> argument. Then the change to "Unst" could be done by using  strip    =
>> strip.custom(factor.levels = ...),
>>
>> To change for the -/+ I made a group - the easiest way.
>> Have a look a changing the negative symbol to 20 or something else as it is
>> hard to visualise. You may vary things with changing cex (remember to have 2
>> values 1 for each group).
>>
>> If you do str(xyplot object) you will get a big print of the object and
>> within that the x limits are shown as "0", "1" which means that the x values
>> are 1 and 2
>> There is a command to get these things but I have forgotten it
>>
>> my.data$stimulation <- factor(levels = c("Unstimulated",
>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>> my.data$stim <- factor(my.data$stimulation, labels = c("Unst.",
>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>> my.data$pos <- ifelse(sign(my.data$copy) > 0, 2,1)
>>
>>   stripplot(copy ~ factor(positivity)|stim,my.data,
>>             groups = pos,
>>             hor = F,
>>             layout = c(8,1),
>>             scales = list(x = list(at = c(1,2),
>>                                    labels = c("N","P"))),
>>             jitter.x = TRUE,
>>             amount = 2,
>>             pch = c(16,1),
>>             col = "black",
>>             ylab = expression(bold("Copy")),
>>             xlab = expression(bold("Stimulation")),
>>             main="Plot",
>>             par.settings = list(strip.background=list(col="white")),
>> par.strip.text=list(font=2)
>>             )
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf Of Luigi Marongiu
>> Sent: Sunday, 27 April 2014 02:07
>> To: r-help at r-project.org
>> Subject: [R] lattice plot formatting: pch, abbreviation and labels
>>
>> Dear all,
>> I am trying to use the lattice plot, but the syntax is quite
>> difficult. Specifically I have eight variables (1 to 8) each of them
>> further subdivided in two classes (negative=0 and positive=1). I am
>> using the stripplot() to represent these values. I would like to
>> represent the negative and positive values with black and white dots
>> so I have tried to use the argument pch=c(16, 1) both in the main
>> stripplot function and embedded in the scale argument. However the
>> resulting plot shows that some points are drawn with the pch=16 and
>> other with pch=1 irrespective of their class.
>> Is there a way to draw the values for the variable positivity = 0 with
>> pch=16 and those with positivity = 1 with pch=0?
>>
>> In addition I would like to change the labels under the axis from 0,1
>> to N,P. However when I placed labels=c("N", "P") or labels=list("N",
>> "P") in the main stripplot() I did not obtained any difference and
>> when placed within the scale argument also the -labels were modified.
>> Is there a way to change the label 0 with N and the label 1 with P?
>>
>> final problem: I would like to abbreviate the "Unstimulated" box label
>> with "Unst.". I have tried the abbreviate=TRUE argument but again the
>> syntax is too complex for me and it did not work.
>> Is there a way to abbreviate the variables names?
>>
>> Thank you very much for your help.
>> Best wishes,
>> Luigi
>>
>>
>> CODE:::::::::
>>
>>
>> ### open plot library
>> library(lattice)
>>
>> my.data<-structure(list(
>>    column_1 = 1:120,
>>    column_2 = structure(c(
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
>> "Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>>     column_3 = structure(c(
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 0,0,0,0,0,0,0,0)),
>>      column_4 = c(
>>
>> 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.
>> 8765622,499.2899303,
>>
>> 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611
>> .486543,6205.229575,
>>
>> 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418
>> .651212,7345.712517,
>>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>>
>> 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.
>> 3543635,3167.959757,
>>
>> 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2
>> 466141,9600.963594,
>>
>> 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958
>> .495138,7224.503437,
>>
>> 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73
>> 980805,8930.784541,
>>
>> 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.26
>> 4531581,1518.610307,
>>
>> 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7
>> 034054,24043.61463,
>>
>> 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,72
>> 65.573875,
>>
>> 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795
>> .75462,30676.769,
>>
>> 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.
>> 178549,1792.679176,
>>
>> 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,1694
>> 1.865,31453.96708,
>>
>> 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.
>> 88646,26050.47191)),
>> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
>> c(NA, -120L),
>>  class = "data.frame")
>> attach(my.data)
>>
>> stripplot(my.data$copy ~
>> factor(my.data$positivity)|factor(my.data$stimulation,
>>             levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
>> "Rv2654", "Rv3879", "Rv3873","PHA")),
>>             my.data, hor=F, layout = c(8,1), scales = list(relation =
>> "same"),
>>       jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
>>       ylab=expression(bold("Copy")),
>> xlab=expression(bold("Stimulation")), main="Plot",
>>       par.settings = list(strip.background=list(col="white")),
>>             par.strip.text=list(font=2))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From dulcalma at bigpond.com  Tue Apr 29 11:26:04 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 29 Apr 2014 19:26:04 +1000
Subject: [R] lattice plot formatting: pch, abbreviation and labels
In-Reply-To: <CAMk+s2R2euedW=9vMkzc4c=oYvmGOKkU8zj8Hsnpm2J-nu3Yew@mail.gmail.com>
References: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>	<002a01cf61b4$fdd47300$f97d5900$@bigpond.com>	<CAMk+s2SDJ13rQXzm_O503vYLF7nEPDVfRcXbNHwbDAzb6TB-Kg@mail.gmail.com>	<001201cf6280$b3229e00$1967da00$@bigpond.com>
	<CAMk+s2R2euedW=9vMkzc4c=oYvmGOKkU8zj8Hsnpm2J-nu3Yew@mail.gmail.com>
Message-ID: <002201cf638d$0c04e660$240eb320$@bigpond.com>

Hi Luigi

Only minor changes needed.

When you go back to a normal xyplot the rules of ratio variables apply the x-axis default in your case something like pretty(range(x)
So the x-axis limits range from 0-1 
and the panel limits therefore are 0-1 +/- 4%
With strip stripplot being categorical the limits are for values 1 and 2 so the top value for 2 is not being shown
(easily seen with str(xyplot object))

You missed out the assigning of groups to the segments.
You could do this by a for loop of 1:2 or by using groups/panel.groups.
I have not got the time to dig out the code to do it at the moment.

xyplot(copy ~ positivity|stimulation, data = my.data,
       group = factor(positivity),
       as.table = TRUE,
       layout = c(8,1),
       xlim  = c(-1,2),
       scales = list(x = list(at = c(0,1), 
                             labels = c("N","P"),
                             rot = 0)),
      jitter.data=TRUE, 
      pch=c(16,1),
      col="black",
      ylab=expression(bold("Copy")),
      xlab=expression(bold("Stimulation")),
      main="Plot",
      par.settings = list(strip.background=list(col="white")),
                                     par.strip.text=list(font=2),
      key = list(space="top",
                 columns=2,
                 text=list(c("Positive", "Negative"), col="black"),
                 points=list(pch=c(16,1), col="black")),
      panel = function(x, y,...){
                pnl = panel.number()
                #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
                #for (j in 1:2){
                #  with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
                #     panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
               for (j in 1:2){
                panel.segments(x0 = (j-1)-0.25, y0 =  datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"], # amend to copy
                             x1 = (j-1)+0.25,  y1 = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"],
                             lwd = 2, col = c("magenta","grey")[j])
                }

               panel.stripplot(x,y, ...)
            }
      )
If you wanted full N P then

       scales = list(x = list(at = c(0,1),
                             alternating = F,
                             labels = c("Negative","Positive"),
                             rot = 90)),  # rot = 0 if labels as before

Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Tuesday, 29 April 2014 04:34
To: Duncan Mackay
Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels

Dear Duncan,
sorry to pester you again with this, but probably the solution is
getting closer. following one of your previous tips i could write the
xyplot synthax as you suggested:

library(lattice)
my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
"Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
 column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")

key.plot<-list(
  space="top", columns=2,
  text=list(c("Positive", "Negative"), col="black"),
  points=list(pch=c(16,1), col="black"))

datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)


#### HERE IS THE IMPORTANT BIT ###

xyplot(copy ~ positivity|stimulation,
  my.data,
  group = positivity,
  hor=F,
  as.table = TRUE,
  layout = c(8,1),
  scales = list(x = list(alternating = FALSE, at = c(0.2,0.8), labels
= c("P","N"))),
  pch=c(16,1), col="black",
  ylab=expression(bold("Copy")),
  xlab=expression(bold("Stimulation")),
  main="Plot",
  par.settings = list(strip.background=list(col="white")),
  par.strip.text=list(font=2),
  key = list(space="top", columns=2, text=list(c("Positive",
"Negative"), col="black"), points=list(pch=c(16,1), col="black")),
  panel = function(x, y, ...){
  pnl = panel.number()
  panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
                              x1 = x+0.25,  y1 = datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
     lwd = 2, col = c("magenta","grey"))
  panel.stripplot(x,y, ...)
               }
       )

############################

beside beign less elegant than stripplot() -- there is no jittering
and requires the positions for the labels -- there are mainly two
problems:
1. the dots are too close to the margins -- I tried to use the 'at'
argument but it did not work
2. the segments are replicated -- there should be a 'panel.group'
somewhere but I obtained a lot of errors when I tried to place it.

Wouldn't be easier to use the stripplot directly, using maybe a factor
to place the segments? I tried to place the panel.function in
stripplot but it did not work at all...

stripplot(copy ~ factor(positivity)|factor(stimulation, levels =
c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879",
"Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = list(space="top",  columns=2, text=list(c("Positive",
"Negative"), col="black"), points=list(pch=c(16,1), col="black")),
        panel = function(x, y, ...){
                pnl = panel.number()
                panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
levels(datmeA[,2])[pnl],"ratio"],
                                          x1= x+0.25,  y1 =
datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"],
                 lwd = 2, col = c("magenta","grey"))
                panel.stripplot(x,y, ...)
               }
       )


Best wishes,
Luigi

On Mon, Apr 28, 2014 at 2:25 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Here are 2 ways of doing it.
>
> The first is a "cheats" way ie easy.
>
> The second is a substitute for the proper way who's code eludes me at the moment. I changed the lty on the ablines  as it appears confusing and as you are bolding it seems more appropriate. A better way may be to change 1 line type.
>
> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>       my.data,
>       group = positivity,
>       hor=F,
>       layout = c(8,1),
>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
>       xlab=expression(bold("Stimulation")),
>       main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = list(space="top",
>                  columns=2,
>                  text=list(c("Positive", "Negative"), col="black"),
>                  points=list(pch=c(16,1), col="black")),
>       panel = function(x, y,...){
>               pnl = panel.number()
>               #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>
>               panel.average(x, y, fun = mean, horizontal = F, lty = 3, col.line = c("red","black"), type = "l")
>
>               panel.stripplot(x,y, ...)
>             }
>       )
>
> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>       my.data,
>       group = positivity,
>       hor=F,
>       layout = c(8,1),
>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
>       xlab=expression(bold("Stimulation")),
>       main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = list(space="top",
>                  columns=2,
>                  text=list(c("Positive", "Negative"), col="black"),
>                  points=list(pch=c(16,1), col="black")),
>       panel = function(x, y,...){
>                 pnl = panel.number()
>                 #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>                 for (j in 1:2){
>                   with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
>                      panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
>
>               }
>
>                panel.stripplot(x,y, ...)
>             }
>       )
>
> Remember abline and panel.abline etc only take 1 line at a time so if you have more than 1 group you have 2 call it more than once
>
> Regards
> Duncan
>
> -----Original Message-----
> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
> Sent: Monday, 28 April 2014 04:03
> To: Duncan Mackay
> Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels
>
> Dear Duncan,
> may I bother you a bit more with the same data set? I would like now
> to add a segment corresponding to the median values, as we discussed
> antecedently.
> I have tried to use the code you wrote in the previous mails, but it
> hasn't worked. First I have found the aggregate medians values and
> assigned to datmeA, then pasted the code you wrote, but without
> success. Would be possible to substitute the panel.abline with
> panel.segments? but in this case how to tell lattice what are the
> values for "N" or "P"?
> Best wishes,
> Luigi
>
> CODE::::
> library(lattice)
>
> my.data<-structure(list(
>    column_1 = 1:120,
>    column_2 = structure(c(
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
> "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>     column_3 = structure(c(
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 0,0,0,0,0,0,0,0)),
>      column_4 = c(
>  192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
>  2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
>  870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>  142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
>  3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
>  1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
>  208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
>  4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
>  2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
>  0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
>  97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
>  5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
>  3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
>  2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
> c(NA, -120L),
>  class = "data.frame")
>
>
> key.plot<-list(
>   space="top", columns=2,
>   text=list(c("Positive", "Negative"), col="black"),
>   points=list(pch=c(16,1), col="black"))
>
> datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)
>
> stripplot(
>       copy ~ factor(positivity)|factor(stimulation,
>             levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654",
> "Rv3879", "Rv3873","PHA")),
>             group = positivity,
>       my.data,
>       hor=F,
>       layout = c(8,1),
>             scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>       jitter.data=TRUE, pch=c(16,1), col="black",
>       ylab=expression(bold("Copy")),
> xlab=expression(bold("Stimulation")), main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>             par.strip.text=list(font=2),
>       key = key.plot,
>             panel = function(x, y){
>               pnl = panel.number()
>               panel.abline(h = datmeA[datmeA[,2]==
>
> levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>
>               panel.stripplot(x,y, ...)
>             }
>       )
>
> On Sun, Apr 27, 2014 at 2:06 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> Hi Luigi
>>
>> You are typing things unnecessarily: do not use the attach command unless
>> absolutely necessary - it has unfortunate consequences.
>> It is better to use with or within.
>> alpha is not available with some devices with bad consequences if used; its
>> default is 1 anyway.
>>
>> Once you have stated a data.frame as the data object it is usually not
>> necessary to use the data.frame$ sign in to signify column names: use the
>> column names.
>> data = "a data.frame" is the equivalent to with
>>
>> You are reordering the levels of stimulation and changing the name of 1 so I
>> thought it was easiest to make a column stim and do things there otherwise
>> it the relevelling could be done in the data argument using the subset
>> argument. Then the change to "Unst" could be done by using  strip    =
>> strip.custom(factor.levels = ...),
>>
>> To change for the -/+ I made a group - the easiest way.
>> Have a look a changing the negative symbol to 20 or something else as it is
>> hard to visualise. You may vary things with changing cex (remember to have 2
>> values 1 for each group).
>>
>> If you do str(xyplot object) you will get a big print of the object and
>> within that the x limits are shown as "0", "1" which means that the x values
>> are 1 and 2
>> There is a command to get these things but I have forgotten it
>>
>> my.data$stimulation <- factor(levels = c("Unstimulated",
>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>> my.data$stim <- factor(my.data$stimulation, labels = c("Unst.",
>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>> my.data$pos <- ifelse(sign(my.data$copy) > 0, 2,1)
>>
>>   stripplot(copy ~ factor(positivity)|stim,my.data,
>>             groups = pos,
>>             hor = F,
>>             layout = c(8,1),
>>             scales = list(x = list(at = c(1,2),
>>                                    labels = c("N","P"))),
>>             jitter.x = TRUE,
>>             amount = 2,
>>             pch = c(16,1),
>>             col = "black",
>>             ylab = expression(bold("Copy")),
>>             xlab = expression(bold("Stimulation")),
>>             main="Plot",
>>             par.settings = list(strip.background=list(col="white")),
>> par.strip.text=list(font=2)
>>             )
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf Of Luigi Marongiu
>> Sent: Sunday, 27 April 2014 02:07
>> To: r-help at r-project.org
>> Subject: [R] lattice plot formatting: pch, abbreviation and labels
>>
>> Dear all,
>> I am trying to use the lattice plot, but the syntax is quite
>> difficult. Specifically I have eight variables (1 to 8) each of them
>> further subdivided in two classes (negative=0 and positive=1). I am
>> using the stripplot() to represent these values. I would like to
>> represent the negative and positive values with black and white dots
>> so I have tried to use the argument pch=c(16, 1) both in the main
>> stripplot function and embedded in the scale argument. However the
>> resulting plot shows that some points are drawn with the pch=16 and
>> other with pch=1 irrespective of their class.
>> Is there a way to draw the values for the variable positivity = 0 with
>> pch=16 and those with positivity = 1 with pch=0?
>>
>> In addition I would like to change the labels under the axis from 0,1
>> to N,P. However when I placed labels=c("N", "P") or labels=list("N",
>> "P") in the main stripplot() I did not obtained any difference and
>> when placed within the scale argument also the -labels were modified.
>> Is there a way to change the label 0 with N and the label 1 with P?
>>
>> final problem: I would like to abbreviate the "Unstimulated" box label
>> with "Unst.". I have tried the abbreviate=TRUE argument but again the
>> syntax is too complex for me and it did not work.
>> Is there a way to abbreviate the variables names?
>>
>> Thank you very much for your help.
>> Best wishes,
>> Luigi
>>
>>
>> CODE:::::::::
>>
>>
>> ### open plot library
>> library(lattice)
>>
>> my.data<-structure(list(
>>    column_1 = 1:120,
>>    column_2 = structure(c(
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
>> "Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>>     column_3 = structure(c(
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 0,0,0,0,0,0,0,0)),
>>      column_4 = c(
>>
>> 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.
>> 8765622,499.2899303,
>>
>> 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611
>> .486543,6205.229575,
>>
>> 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418
>> .651212,7345.712517,
>>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>>
>> 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.
>> 3543635,3167.959757,
>>
>> 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2
>> 466141,9600.963594,
>>
>> 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958
>> .495138,7224.503437,
>>
>> 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73
>> 980805,8930.784541,
>>
>> 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.26
>> 4531581,1518.610307,
>>
>> 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7
>> 034054,24043.61463,
>>
>> 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,72
>> 65.573875,
>>
>> 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795
>> .75462,30676.769,
>>
>> 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.
>> 178549,1792.679176,
>>
>> 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,1694
>> 1.865,31453.96708,
>>
>> 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.
>> 88646,26050.47191)),
>> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
>> c(NA, -120L),
>>  class = "data.frame")
>> attach(my.data)
>>
>> stripplot(my.data$copy ~
>> factor(my.data$positivity)|factor(my.data$stimulation,
>>             levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
>> "Rv2654", "Rv3879", "Rv3873","PHA")),
>>             my.data, hor=F, layout = c(8,1), scales = list(relation =
>> "same"),
>>       jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
>>       ylab=expression(bold("Copy")),
>> xlab=expression(bold("Stimulation")), main="Plot",
>>       par.settings = list(strip.background=list(col="white")),
>>             par.strip.text=list(font=2))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From smartpink111 at yahoo.com  Tue Apr 29 11:24:55 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Apr 2014 02:24:55 -0700 (PDT)
Subject: [R] Difference between comma separated values in column
In-Reply-To: <1398758337.68252.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1398758337.68252.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1398763495.72624.YahooMailNeo@web142606.mail.bf1.yahoo.com>



HI,

I guess this should be a bit faster.
#1st case
dat1$V3 <- lapply(seq_along(dat1$V2),function(i) c(dat1$V2[[i]][-1] - head(dat1$V1[[i]],-1), tail(dat1$V1[[i]],1)))
#2nd case
dat2$V3 <- unlist(lapply(seq_along(lst1[,2]),function(i) paste(c(lst1[,2][[i]][-1] - head(lst1[,1][[i]], -1), tail(lst1[,1][[i]],1)),collapse=",")))

A.K.



On Tuesday, April 29, 2014 3:58 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

It is better to show the example data using ?dput().? Here, it is not clear whether the columns are character columns or lists.
##If it is the latter case

dat1 <- data.frame(V1=I(list(1:3, c(1,2,4), c(2,3,4,5))), V2= I(list(c(3,6,5), c(7,10,9), 2:5)))
?dat1$V3 <- mapply(`c`,mapply(`-`, lapply(dat1$V2, `[`,-1), lapply(dat1$V1,head,-1)), lapply(dat1$V1,tail,1))
?dat1
#????????? V1???????? V2???????? V3
#1??? 1, 2, 3??? 3, 6, 5??? 5, 3, 3
#2??? 1, 2, 4?? 7, 10, 9??? 9, 7, 4
#3 2, 3, 4, 5 2, 3, 4, 5 1, 1, 1, 5


##If the columns are character vectors.

dat2 <- structure(list(V1 = c("1,2,3", "1,2,4", "2,3,4,5"), V2 = c("3,6,5", 
"7,10,9", "2,3,4,5")), .Names = c("V1", "V2"), row.names = c(NA, 
-3L), class = "data.frame")
?lst1 <- sapply(dat2, function(x) lapply(strsplit(x, split=","),as.numeric))
dat2$V3 <- unlist(lapply(mapply(`c`,mapply(`-`, lapply(lst1[,2],`[`, -1), lapply(lst1[,1], head,-1)), lapply(lst1[,1], tail,1)), paste, collapse=","))
?dat2
#?????? V1????? V2????? V3
#1?? 1,2,3?? 3,6,5?? 5,3,3
#2?? 1,2,4? 7,10,9?? 9,7,4
#3 2,3,4,5 2,3,4,5 1,1,1,5


A.K.


?Hi,

I have a quick question in R. I have dataframe with two columns with multiple values separated by comma.
Example:
?????????? 
??????? V1?????????? V2
1??? 1, 2, 3????? 3, 6, 5
2??? 1, 2, 4????? 7, 10, 9
3??? 2, 3, 4, 5?? 2, 3, 4, 5

I want to calculate the difference between both the column.

Expected results (suppose results are stored in V3) - it is basically subtracting (n-th) value of the column1 from? (n-th + 1) value of column2.
?????? 
??????? V3????????? 
1??? 6-1, 5-2, 3????? 
2??? 10-1, 9-2, 4??? 
3??? 3-2, 4-3, 5-4, 5

which gives??? (Last value doesn't matter)
???? 
?????? V3????????? 
1??? 5, 3, 3????? 
2??? 9, 7, 4??? 
3??? 1, 1, 1, 5

Would greatly appreciate if anyone can suggest how can I proceed?


From highstat at highstat.com  Tue Apr 29 11:45:51 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 29 Apr 2014 10:45:51 +0100
Subject: [R] Course: Data exploration, regression,
 GLM & GAM with R intro. Plymouth, UK
Message-ID: <535F74CF.2010408@highstat.com>



We would like to announce the following statistics course:

Course: Data Exploration, Regression, GLM & GAM with introduction to R
Where:  Plymouth University, Plymouth, UK
When:   7 - 11 July 2014
URL:     http://www.highstat.com/statscourse.htm

Kind regards,


Alain Zuur





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From sahinmerv at gmail.com  Tue Apr 29 08:38:52 2014
From: sahinmerv at gmail.com (=?UTF-8?B?TWVydmUgxZ5haGlu?=)
Date: Tue, 29 Apr 2014 09:38:52 +0300
Subject: [R] Simulative data production
Message-ID: <CAGSOz1uX4XUBoOV=WSd1gSuxKX+17Zv==Y7=3hHswa7tN6ak2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/b67d975f/attachment.pl>

From dilaradi21 at gmail.com  Tue Apr 29 10:46:32 2014
From: dilaradi21 at gmail.com (dila radi)
Date: Tue, 29 Apr 2014 01:46:32 -0700
Subject: [R] Replacing NA's in the data set
Message-ID: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/81254001/attachment.pl>

From josef.montag at mendelu.cz  Tue Apr 29 11:36:20 2014
From: josef.montag at mendelu.cz (Josef Montag)
Date: Tue, 29 Apr 2014 11:36:20 +0200
Subject: [R] Navigating history (arrow keys) and command completion (tab
 key) do not work
Message-ID: <CALhNhcmMeCZTfO0EOXmXjxu0RPt8bj800x68wO6S1oGM+nMz5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/30e15522/attachment.pl>

From mbressan at arpa.veneto.it  Tue Apr 29 15:06:21 2014
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Tue, 29 Apr 2014 15:06:21 +0200
Subject: [R] sum of two POSIXct objects: date and hour
Message-ID: <535FA3CD.3040107@arpa.veneto.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/00e507eb/attachment.pl>

From smartpink111 at yahoo.com  Tue Apr 29 16:34:00 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Apr 2014 07:34:00 -0700 (PDT)
Subject: [R] Replacing NA's in the data set
In-Reply-To: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>
References: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>
Message-ID: <1398782040.1467.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi Dila,
Try:
Ts1 <- Ts
Ts[,-11] <- lapply(Ts[,-11], function(x) {x[is.na(x)] <- Ts[is.na(x), 11]; x})
#or
Ts1[,-11][is.na(Ts1[,-11])] <-rep(Ts1[,11],10)[is.na(Ts1[,-11])]
?identical(Ts,Ts1)
#[1] TRUE

A.K.


On Tuesday, April 29, 2014 8:53 AM, dila radi <dilaradi21 at gmail.com> wrote:
Hi all,

I have this data set,
> dput(Ts)

structure(list(V1 = c(3, 17, 29, 12, 4.5, 1, 0.5, 0, 0, 0, 1.2,
1.8, 1.5, 0.5, 0, 47.7, 0.3, 0, 2, 0, 5.5, 8, 27.5, 69, 29, 24.5,
57.5, 40, 1, 14.5, 0, 0, 0, 0, 0, 0, 1.5, 2, 0, 0, 0, 0, 7, 29.5,
77, 11.5, 33, 38, 36, 8, 28, 11, 11, 0, 17, 0, 51, 0.5, 5, 0,
31.5, 11, 3.5, 0, 0, 0, 0, 0, 4.5, 1, 15.5, 2.5, 0, 0, 5, 0,
0, 0, 0, 0, 5, 0, 8.5, 0, 0, 0, 0, 0, 0, 13, 37.5, 3.5, 37, 2,
32.5, 2.5, 0, 65, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 105.5, 0.5, 1.5,
16.5, 5.5, 0, 0, 0, 3.5, 0, 0, 10.5, 57.5, 3, 23, 0, 3, 1, 43.5,
39.5, 1, 0, 21, 2.5, 2.5, 1.5, 30, 2, 1.5, 18.5, 17, 0, 0, 13,
0, 0, 0, 0, 5.5, 0, 0, 0, 0, 22.5, 4.5, 0, 1.5, 17, 1.5, 0.5,
2, 0, 0, 25, 24.5, 7.5, 0, 3.5, 22.5, 8.5, 8.5, 0, 0, 0, 0.5,
0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 4.5, 0, 49, 0, 2,
12, 29, 6.5, 0, 0, 0, 0, 2.5, 0, 0, 6, 0, 8.5, 8.5, 8.5, 1, 0,
0), V2 = c(4, 12, 22.5, 10.5, 19.5, 1, 0.5, 0, 0, 0, 3, 0, 0,
3, 0, 8, 0, 0, 0, 1, 2.5, 10.5, 21, 49.5, 79.5, 16, 30, 34, 0,
13.5, 1.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0.5, 3.5, 7, 4.5,
2.5, 2, 22.5, 8, 99.5, 10, 44, 0, 3.5, 0, 18.5, 0, 5, 11.5, 0,
18.5, 4.5, 0, 0, 0, 0.5, 0, 5.5, 3.5, 5.5, 87, 2, 2, 0, 1, 0,
0, 0, 0, 0, 0, 0, 13.5, 0, 0, 12, 8, 1, 0, 0, 3.5, 0, 1, 5, 0,
0.5, 0.5, 0, 0, 0, 0, 0, 1, 0, 0, 11, 0, 5.5, 0, 0, 2, 25.5,
0, 17.5, 0, 1, 0, 0, 3, 44.5, 0, 0, 0.3, 43.7, 0, 3.2, 13.5,
2, 0, 0, 0, 0, 5.8, 16.2, 0, 0, 7.3, 0, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0,
0, 14.9, 16.1, 0, 16.8, 2.2, 15.1, 92.7, 0, 0, 1.6, 36.2, NA,
NA, NA, NA, NA, NA, NA, NA, 1, 0, 0, 0, 17, 1, 0, 0, 3.5, 0.5,
25, 10.5, 28, 6.5, 0, 8, 1, 16, 0, 0, 0, 2.5, 0, 0, 61, 0, 0,
0, 8.5), V3 = c(11L, 21L, 41L, 22L, 0L, 0L, 12L, 0L, 0L, 3L,
4L, 7L, 0L, 3L, 5L, 19L, 0L, 0L, 0L, 0L, 23L, 36L, 57L, 34L,
123L, 31L, 56L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0L), V4 = c(NA, NA, NA,
NA, NA, NA, NA, NA, NA, 6.5, 0, 0, 0, 3.5, 0.5, 26, 12, 0, 1.5,
2, 6.5, 34.5, 40, 61, 179, 19, 44, 48.5, 0.5, 0, 1.5, NA, NA,
NA, NA, NA, NA, NA, NA, 0, 0.5, 0, 20, 15.5, 16, 3.5, 13, 5,
5.5, 15, 6.5, 2.5, 93.5, 1.5, 9.5, 3, 9, 0, 0, 0, 0, 2, 3.5,
0, 0, 0, 3, 0, 9.5, 7.5, 3.5, 57, 2.2, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.5, 6, 0, 0,
0.5, 0, 0, 0, 10, 0, 0, 6, 0, 0, 0, 6, 0, 6.5, 1.5, 0, 0, 32.5,
0, 0, 0, 15, 0, 0, 0, 8.5, 0, 53, 0, 27.5, 0, 12.5, 2.3, 3.2,
0, 0, 0, 1, 2, 0.5, 3, 9.5, 20.5, 12.5, 3.5, 0, 0, 0, 0, 0, 1,
0, 0, 0, 0, 0, 0, 0, 0, 104, 2.5, 0, 0, 0, 0, 42, 0, 11.5, 41,
0, 14, 0, 18, 8, 0, 0, 14, 14.5, 0, 13.5, 0, 0, 5.5, 2, 0, 1,
0, 0, 0, 0, 3.5, 0, 0, 37.5, 0, 0, 39.2, 9.8, 0, 0, 0, 0, 0,
40.5, 0, 2, 0, 0, 2, 16, 3, 0, 1, 0, 4), V5 = c(28.5, 24, 45.5,
12.5, 0, 0, 0, 10.5, 7, 0, 0, 0, 6, 0, 38, 0, 1.5, 2, 3, 10,
32.5, 132, 20.5, 190, 19, 84, 120.5, 2, 4, 12, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 9, 12, 7.5, 11, 9.5, 0, 11, 8, 12, 11, 0, 86,
0, 0, 0, 10, 0, 0, 0, 1, 5, 1, 0, 0, 0, 0, 0, 10, 49.5, 0, 36.5,
0, 0, 0, 0, 0, 0, 0, 0, 2.5, 0, 0, 0, 0, 0, 75, 4, 0, 0, 0, 0,
0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7.5, 0, 0, 9, 1, 0,
7, 0, 0, 0, 25, 8, 0, 0, 30, 0, 0, 4, 0, 0, 41, 11, 0, 20, 0,
0, 0, 0, 0, 0, 0, 57, 8, 10, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0, 0,
0, 0, 0, 6.5, 0, 0, 0, 44.5, 0, 0, 17.5, 2, 0, 0, 0, 18, 0, 0,
14.5, 0, 0, 0, 15.5, 3, 1, 0, 0, 0, 0), V6 = c(57.5, 35.5, 60,
12.5, 4, 0, 0, 6.5, 11, 5, 7.5, 4.5, 5.5, 4, 4.5, 0, 63.5, 7,
0, 14.5, 34.5, 44.5, 33.5, 229, 16, 103.5, 102, 12.5, 17, 14.5,
0, 5.5, 0, 0, 0, 0, 4, 0, 0, 0, 6, 8.5, 0, 36.5, 13, 4, 3, 4,
6, 56, 4, 27.5, 6, 0, 7, 9, 0, 6.5, 0, 0, 7.5, 6, 0, 0, 0, 0,
0, 16, 34.5, 0, 17.5, 4, 0, 0, 0, 0, 0, 0, 3.5, 0, 0, 0, 17.5,
0, 0, 88.5, 6, 0, 0, 55, 6, 4.5, 4.5, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 5.5, 0, 0, 0, 2, 4.5, 0, 0, 4.5, 0, 0, 0, 0, 1.5,
31, 21, 43.5, 0, 12, 0, 21, 31.5, 12.5, 9, 4, 0, 24.5, 17.5,
4, 0, 0, 12.5, 6, 4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 6.5, 5, 0, 4.5, 0, 0, 27.5, 0, 7.5, 0, 3, 38, 0, 44.5, 14,
0, 0, 0, 24.5, 0, 7, 0, 11.5, 9.5, 6, 0, 21.5, 0, 0, 0, 0, 10.5,
0, 0, 0, 39.5, 0, 0, 35.5, 6, 0, 0, 4.5, 6, 0, 0, 0, 0, 7, 0,
10.5, 56.5, 46, 14.5, 0, 5, 0), V7 = c(27, 0, 25.5, 37, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
0, 0.6, 2.3, 0, 0, 0, 1.8, 8.8, 4.5, 0.7, 0, 0, 0, 0, 40, 42.7,
2.7, 19.9, 9.8, 1.1, 0.7, 1.5, 0, 0, 0, 0, 0, 0, 4, 0.6, 0, 0,
69.8, 2.4, 6, 4.9, 3.1, 0.4, 1.6, 0.9, 0, 0, 0, 0, 4.9, 0.2,
0, 0, 0, 0, 0, 0, 6, 0, 0, 0.9, 1, 8.1, 12.6, 0, 0, 0, 0, 0,
0, 2.3, 8.5, 1.7, 10.4, 0, 4.9, 0, 53, 10.8, 1.2, 3.5, 0.6, 0,
26.6, 1.6, 0.8, 0, 0, 16.4, 5.4, 11.2, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 30.4, 5.5, 0, 0, 0, 0, 3, 1, 8.5, 15.7, 0.6,
13.7, 0, 6.7, 14.6, 0, 0, 0, 5.8, 0, 0, 0, 0.3, 0, 3.4, 0, 3.7,
0, 0, 0, 0, 10, 0, 0, 0, 66, 0, 0.5, 7, 0.5, 1, 0, 0, 8.5, 0,
0, 0, 0, 0, 0, 7, 17, 9, 1.5, 0, 2.5), V8 = c(135, 38, 41, 20,
0.5, 4, 8.5, 0, 20.5, 0, 0, 0, 35, 0, 0, 0, 0, 25, 6.5, 16, 65,
22, 26.5, 30, 11, 15, 31, 35, 24, 19.5, 0, 4.5, 0, 0, 0, 0, 0,
0, 0, 0, 147, 14, 14, 11, 15, 0.5, 5, 5, 10.5, 18, 5, 4.5, 11,
0, 56.5, 0.5, 0, 0.5, 0, 10.5, 26, 10, 0, 0, 0, 0, 0, 35, 96.5,
30, 95, 3, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 5.5, 0, 0, 0, 7.5,
10, 0, 0, 0, 0, 0, 5.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 5.5, 1, 0, 0, 21, 0, 0, 0, 0, 0, 0, 3, 11.5, 0, 42, 0, 11,
0, 9, 0, 0, 21, 2.5, 4, 2.5, 6, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16.5, 0, 0, 0, 0, 0, 0, 45,
39, 0, 0, 62, 17, 17.5, 5.5, 0, 4.5, 2.5, 0, 0, 0, 0, 0, 0, 0,
0, 5.5, 0, 0, 0, 0, 0, 0, 3.5, 5, 0, 20, 0, 41, 1, 0, 0, 0, 0,
4.5, 1.5, 0, 0, 3.5, 12, 0, 0.5, 0, 0, 17, 32), V9 = c(42, 78,
65.5, 22, 18, 1.5, 0.5, 4, 10.5, 5, 0, 27.5, 3.5, 4, 0, 1.5,
0, 0, 12.5, 0.5, 0, 101.5, 31.5, 30, 27, 8, 52.5, 10.5, 0.5,
11, 20.5, 0, 3, 0, 0, 0, 10.5, 0, 0, 0, 0, 4.5, 5.5, 8, 5, 5,
3, 0.5, 9, 18.5, 33, 0.5, 33, 0.5, 0, 20, 0.5, 25.5, 0.5, 0,
0, 1.5, 16.5, 7, 0.5, 0, 0, 0, 19.3, 116.9, 13.7, 47.5, 11, 0,
0, 0, 0, 0, 0, 0, 0, 0.5, 2, 2, 0, 0, 20, 18, 0, 0, 0, 1, 0,
40.5, 1.5, 1.5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
11.5, 0, 6.5, 0.5, 0, 2.5, 0, 0.5, 3.5, 21, 0, 0, 1, 11.5, 0,
0.7, 46.9, 1.7, 0.8, 0, 0, 0, 10.5, 1.1, 0, 1.5, 63.1, 1.1, 0.8,
0, 0, 0, 0, 0, 0, 34.5, 2.5, 1.5, 1, 4.5, 2, 1, 0, 0, 1, 0, 0,
0, 0, 0, 0, 60.5, 3.5, 0.5, 0.5, 0, 0, 50, 0, 50, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3.5, 47, 1.1,
0, 0, 0, 0.4, 9.3, 5.4, 0, 0, 0, 0, 0, 23.4, 2.7, 0, 6.2), V10 = c(125.5,
85.5, 24.5, 25, 2.5, 3, 14, 1, 45, 14.5, 6, 0.5, 20, 0, 0, 0,
0, 29, 11.5, 52, 74.5, 9.5, 44, 24.5, 19.5, 26.5, 21, 13, 11,
21, 12, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 7, 5.5, 11.5, 19, 17.5,
8.5, 3, 5.5, 37, 35, 0.5, 6, 0.5, 0, 5.5, 0, 3, 0, 0, 6, 5.5,
7.5, 0, 0, 0.5, 0, 9.5, 29, 144, 35.5, 62.5, 2.5, 0, 0, 0, 0,
0, 0, 0, 1.5, 0, 0.5, 0, 0, 0, 0, 0, 0, 23, 0, 0, 30, 0, 0, 2.5,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 15, 0, 0, 0, 0, 0, 0, 0,
0, 7.5, 2, 0, 0, 5, 14.5, 1.5, 1, 0, 0, 0, 0, 21, 9, 2.5, 4,
7, 0, 0, 0, 8, 1.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 59.5, 0, 40, 0, 0, 0, 145.5, 7.5, 0, 0, 11, 7, 0, 0,
52.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 9.5, 9.5,
0, 2.5, 4, 3.5, 65.5, 0, 16.5, 6, 0, 0, 15, 0, 1.5, 0, 0, 0,
0, 1, 0, 0, 0, 0, 10, 48), V11 = c(48.16666667, 34.55555556,
39.38888889, 19.27777778, 6.125, 1.3125, 4.5, 2.75, 11.75, 3.777777778,
2.411111111, 4.588888889, 7.944444444, 2, 5.333333333, 11.35555556,
8.588888889, 7, 4.111111111, 10.66666667, 27.11111111, 44.27777778,
33.5, 79.66666667, 55.88888889, 36.38888889, 57.16666667, 24.4375,
7.25, 13.25, 4.4375, 1.428571429, 1.142857143, 0, 0, 0, 2.428571429,
0.285714286, 0, 0, 21.1875, 5.75, 7.5, 15.8125, 20.1875, 5.8125,
9.875, 8.1875, 13.375, 21.4375, 26.375, 17.8125, 25.5625, 0.3125,
10.38888889, 5.4, 9.033333333, 4, 1.166666667, 2.555555556, 8.644444444,
7.144444444, 4.444444444, 0.855555556, 0.055555556, 0.055555556,
0.388888889, 7.833333333, 32.03333333, 38.4, 25.04444444, 31.48888889,
3.055555556, 0.3875, 0.7125, 0.3125, 0, 0, 0.5, 0.375, 0.8125,
0.75, 4.0625, 2.0125, 0, 21.375, 15.225, 3.55, 0.875, 11.9875,
5.825, 1.488888889, 9.844444444, 4.933333333, 4.333333333, 0.777777778,
0.388888889, 7.277777778, 0.544444444, 1.133333333, 0, 0, 0.666666667,
0.111111111, 0, 1.444444444, 3.222222222, 0.833333333, 15.83333333,
0.655555556, 0.777777778, 7.344444444, 8.455555556, 1.222222222,
2, 2.777777778, 3.333333333, 0.833333333, 0.777777778, 10.2,
17.88888889, 10.57777778, 11.65555556, 2.866666667, 10.17777778,
8, 17.26666667, 13.94444444, 6.566666667, 3.533333333, 3.844444444,
3.555555556, 6.4, 3.6, 5.4, 0.555555556, 11.22222222, 16.42222222,
5.777777778, 2, 0, 1.625, 0, 0, 0, 0.125, 5, 0.357142857, 0.214285714,
0.142857143, 0.642857143, 3.5, 0.785714286, 0.928571429, 22.48571429,
12.21428571, 0.857142857, 5.785714286, 0.285714286, 3.4375, 5.625,
28, 20.8, 10.85, 4.8875, 15.1875, 11.65, 9.975, 22.4125, 6.5625,
6.875, 5.325, 7.125, 1, 1.928571429, 2.5, 1.4, 1.642857143, 0.675,
2.6875, 3.275, 0.888888889, 0, 0, 2.944444444, 4.444444444, 2.444444444,
1.166666667, 14.5, 13.66666667, 9.666666667, 13.3, 12.03333333,
12.38888889, 1.677777778, 0.5, 5.222222222, 1.055555556, 6.988888889,
3.088888889, 0.822222222, 0.777777778, 1.333333333, 4.555555556,
10.11111111, 15.22222222, 6.155555556, 0.688888889, 3.555555556,
10.12)), .Names = c("V1", "V2", "V3", "V4", "V5", "V6", "V7",
"V8", "V9", "V10", "V11"), class = "data.frame", row.names = c(NA,
-210L))

I want to replace all NA's value in column 1 until column 10 with the
corresponding value in column 11. How to achieve this. Please help me.
Thank you.


Dila

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Tue Apr 29 16:42:39 2014
From: luca.cerone at gmail.com (Luca Cerone)
Date: Tue, 29 Apr 2014 16:42:39 +0200
Subject: [R] foreach (package) .combine option
Message-ID: <CAFnz2--GQ8xbG52=C8Xngnu9jAgonF-jqy2RjKojaYwUiGHGrg@mail.gmail.com>

Dear all,
I am having some difficulties understanding how the .combine option in
the foreach function of the "foreach" package works.

I think I understand the examples in the manual using rbind, cbind and c.

However if I write my own function (no particular purpose in mind,
just to figure out how the .combine option works):

cfun <- function(a,b) sqrt(a**2 + b**2)

I don't understand the output of the function:

For example :

x <- foreach(i=1:3, .combine='cfun') %do% seq(5)

Produces:
> x
[1] 1.732051 3.464102 5.196152 6.928203 8.660254

Now so far as I understand these are in order:

sqrt(1+1+1), sqrt(4 + 4 + 4) [ = sqrt(2**2 + 2**2 + 2**2) ], sqrt(27)
[ = sqrt(3**2 + 3**2 + 3**2)] and so on...

But really I don't understand how cfun is used to produced these
results, what is passed to a and b in this case???

Thanks a lot you all,


Cheers,
Luca


From pascalbells at libero.it  Tue Apr 29 15:45:48 2014
From: pascalbells at libero.it (pascalbells at libero.it)
Date: Tue, 29 Apr 2014 15:45:48 +0200 (CEST)
Subject: [R] dataframe
Message-ID: <1897246202.11446621398779148842.JavaMail.actor@webmail37>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/7050dc52/attachment.pl>

From mtripoli at istat.it  Tue Apr 29 16:08:07 2014
From: mtripoli at istat.it (Massimiliano Tripoli)
Date: Tue, 29 Apr 2014 16:08:07 +0200 (CEST)
Subject: [R] Replacing NA's in the data set
In-Reply-To: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>
Message-ID: <453054233.4507547.1398780487009.JavaMail.root@istat.it>


Hi,
Try this:
for (i in 1:10) Ts[is.na(Ts[,i]),i] <- Ts$V11[is.na(Ts[,i])]

Massimiliano

----- Messaggio originale -----
Da: "dila radi" <dilaradi21 at gmail.com>
A: r-help at r-project.org
Inviato: Marted?, 29 aprile 2014 10:46:32
Oggetto: [R] Replacing NA's in the data set

Hi all,

I have this data set,
> dput(Ts)

structure(list(V1 = c(3, 17, 29, 12, 4.5, 1, 0.5, 0, 0, 0, 1.2,
1.8, 1.5, 0.5, 0, 47.7, 0.3, 0, 2, 0, 5.5, 8, 27.5, 69, 29, 24.5,
57.5, 40, 1, 14.5, 0, 0, 0, 0, 0, 0, 1.5, 2, 0, 0, 0, 0, 7, 29.5,
77, 11.5, 33, 38, 36, 8, 28, 11, 11, 0, 17, 0, 51, 0.5, 5, 0,
31.5, 11, 3.5, 0, 0, 0, 0, 0, 4.5, 1, 15.5, 2.5, 0, 0, 5, 0,
0, 0, 0, 0, 5, 0, 8.5, 0, 0, 0, 0, 0, 0, 13, 37.5, 3.5, 37, 2,
32.5, 2.5, 0, 65, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 105.5, 0.5, 1.5,
16.5, 5.5, 0, 0, 0, 3.5, 0, 0, 10.5, 57.5, 3, 23, 0, 3, 1, 43.5,
39.5, 1, 0, 21, 2.5, 2.5, 1.5, 30, 2, 1.5, 18.5, 17, 0, 0, 13,
0, 0, 0, 0, 5.5, 0, 0, 0, 0, 22.5, 4.5, 0, 1.5, 17, 1.5, 0.5,
2, 0, 0, 25, 24.5, 7.5, 0, 3.5, 22.5, 8.5, 8.5, 0, 0, 0, 0.5,
0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 4.5, 0, 49, 0, 2,
12, 29, 6.5, 0, 0, 0, 0, 2.5, 0, 0, 6, 0, 8.5, 8.5, 8.5, 1, 0,
0), V2 = c(4, 12, 22.5, 10.5, 19.5, 1, 0.5, 0, 0, 0, 3, 0, 0,
3, 0, 8, 0, 0, 0, 1, 2.5, 10.5, 21, 49.5, 79.5, 16, 30, 34, 0,
13.5, 1.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0.5, 3.5, 7, 4.5,
2.5, 2, 22.5, 8, 99.5, 10, 44, 0, 3.5, 0, 18.5, 0, 5, 11.5, 0,
18.5, 4.5, 0, 0, 0, 0.5, 0, 5.5, 3.5, 5.5, 87, 2, 2, 0, 1, 0,
0, 0, 0, 0, 0, 0, 13.5, 0, 0, 12, 8, 1, 0, 0, 3.5, 0, 1, 5, 0,
0.5, 0.5, 0, 0, 0, 0, 0, 1, 0, 0, 11, 0, 5.5, 0, 0, 2, 25.5,
0, 17.5, 0, 1, 0, 0, 3, 44.5, 0, 0, 0.3, 43.7, 0, 3.2, 13.5,
2, 0, 0, 0, 0, 5.8, 16.2, 0, 0, 7.3, 0, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0,
0, 14.9, 16.1, 0, 16.8, 2.2, 15.1, 92.7, 0, 0, 1.6, 36.2, NA,
NA, NA, NA, NA, NA, NA, NA, 1, 0, 0, 0, 17, 1, 0, 0, 3.5, 0.5,
25, 10.5, 28, 6.5, 0, 8, 1, 16, 0, 0, 0, 2.5, 0, 0, 61, 0, 0,
0, 8.5), V3 = c(11L, 21L, 41L, 22L, 0L, 0L, 12L, 0L, 0L, 3L,
4L, 7L, 0L, 3L, 5L, 19L, 0L, 0L, 0L, 0L, 23L, 36L, 57L, 34L,
123L, 31L, 56L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0L), V4 = c(NA, NA, NA,
NA, NA, NA, NA, NA, NA, 6.5, 0, 0, 0, 3.5, 0.5, 26, 12, 0, 1.5,
2, 6.5, 34.5, 40, 61, 179, 19, 44, 48.5, 0.5, 0, 1.5, NA, NA,
NA, NA, NA, NA, NA, NA, 0, 0.5, 0, 20, 15.5, 16, 3.5, 13, 5,
5.5, 15, 6.5, 2.5, 93.5, 1.5, 9.5, 3, 9, 0, 0, 0, 0, 2, 3.5,
0, 0, 0, 3, 0, 9.5, 7.5, 3.5, 57, 2.2, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.5, 6, 0, 0,
0.5, 0, 0, 0, 10, 0, 0, 6, 0, 0, 0, 6, 0, 6.5, 1.5, 0, 0, 32.5,
0, 0, 0, 15, 0, 0, 0, 8.5, 0, 53, 0, 27.5, 0, 12.5, 2.3, 3.2,
0, 0, 0, 1, 2, 0.5, 3, 9.5, 20.5, 12.5, 3.5, 0, 0, 0, 0, 0, 1,
0, 0, 0, 0, 0, 0, 0, 0, 104, 2.5, 0, 0, 0, 0, 42, 0, 11.5, 41,
0, 14, 0, 18, 8, 0, 0, 14, 14.5, 0, 13.5, 0, 0, 5.5, 2, 0, 1,
0, 0, 0, 0, 3.5, 0, 0, 37.5, 0, 0, 39.2, 9.8, 0, 0, 0, 0, 0,
40.5, 0, 2, 0, 0, 2, 16, 3, 0, 1, 0, 4), V5 = c(28.5, 24, 45.5,
12.5, 0, 0, 0, 10.5, 7, 0, 0, 0, 6, 0, 38, 0, 1.5, 2, 3, 10,
32.5, 132, 20.5, 190, 19, 84, 120.5, 2, 4, 12, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 9, 12, 7.5, 11, 9.5, 0, 11, 8, 12, 11, 0, 86,
0, 0, 0, 10, 0, 0, 0, 1, 5, 1, 0, 0, 0, 0, 0, 10, 49.5, 0, 36.5,
0, 0, 0, 0, 0, 0, 0, 0, 2.5, 0, 0, 0, 0, 0, 75, 4, 0, 0, 0, 0,
0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7.5, 0, 0, 9, 1, 0,
7, 0, 0, 0, 25, 8, 0, 0, 30, 0, 0, 4, 0, 0, 41, 11, 0, 20, 0,
0, 0, 0, 0, 0, 0, 57, 8, 10, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0, 0,
0, 0, 0, 6.5, 0, 0, 0, 44.5, 0, 0, 17.5, 2, 0, 0, 0, 18, 0, 0,
14.5, 0, 0, 0, 15.5, 3, 1, 0, 0, 0, 0), V6 = c(57.5, 35.5, 60,
12.5, 4, 0, 0, 6.5, 11, 5, 7.5, 4.5, 5.5, 4, 4.5, 0, 63.5, 7,
0, 14.5, 34.5, 44.5, 33.5, 229, 16, 103.5, 102, 12.5, 17, 14.5,
0, 5.5, 0, 0, 0, 0, 4, 0, 0, 0, 6, 8.5, 0, 36.5, 13, 4, 3, 4,
6, 56, 4, 27.5, 6, 0, 7, 9, 0, 6.5, 0, 0, 7.5, 6, 0, 0, 0, 0,
0, 16, 34.5, 0, 17.5, 4, 0, 0, 0, 0, 0, 0, 3.5, 0, 0, 0, 17.5,
0, 0, 88.5, 6, 0, 0, 55, 6, 4.5, 4.5, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 5.5, 0, 0, 0, 2, 4.5, 0, 0, 4.5, 0, 0, 0, 0, 1.5,
31, 21, 43.5, 0, 12, 0, 21, 31.5, 12.5, 9, 4, 0, 24.5, 17.5,
4, 0, 0, 12.5, 6, 4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 6.5, 5, 0, 4.5, 0, 0, 27.5, 0, 7.5, 0, 3, 38, 0, 44.5, 14,
0, 0, 0, 24.5, 0, 7, 0, 11.5, 9.5, 6, 0, 21.5, 0, 0, 0, 0, 10.5,
0, 0, 0, 39.5, 0, 0, 35.5, 6, 0, 0, 4.5, 6, 0, 0, 0, 0, 7, 0,
10.5, 56.5, 46, 14.5, 0, 5, 0), V7 = c(27, 0, 25.5, 37, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
0, 0.6, 2.3, 0, 0, 0, 1.8, 8.8, 4.5, 0.7, 0, 0, 0, 0, 40, 42.7,
2.7, 19.9, 9.8, 1.1, 0.7, 1.5, 0, 0, 0, 0, 0, 0, 4, 0.6, 0, 0,
69.8, 2.4, 6, 4.9, 3.1, 0.4, 1.6, 0.9, 0, 0, 0, 0, 4.9, 0.2,
0, 0, 0, 0, 0, 0, 6, 0, 0, 0.9, 1, 8.1, 12.6, 0, 0, 0, 0, 0,
0, 2.3, 8.5, 1.7, 10.4, 0, 4.9, 0, 53, 10.8, 1.2, 3.5, 0.6, 0,
26.6, 1.6, 0.8, 0, 0, 16.4, 5.4, 11.2, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 30.4, 5.5, 0, 0, 0, 0, 3, 1, 8.5, 15.7, 0.6,
13.7, 0, 6.7, 14.6, 0, 0, 0, 5.8, 0, 0, 0, 0.3, 0, 3.4, 0, 3.7,
0, 0, 0, 0, 10, 0, 0, 0, 66, 0, 0.5, 7, 0.5, 1, 0, 0, 8.5, 0,
0, 0, 0, 0, 0, 7, 17, 9, 1.5, 0, 2.5), V8 = c(135, 38, 41, 20,
0.5, 4, 8.5, 0, 20.5, 0, 0, 0, 35, 0, 0, 0, 0, 25, 6.5, 16, 65,
22, 26.5, 30, 11, 15, 31, 35, 24, 19.5, 0, 4.5, 0, 0, 0, 0, 0,
0, 0, 0, 147, 14, 14, 11, 15, 0.5, 5, 5, 10.5, 18, 5, 4.5, 11,
0, 56.5, 0.5, 0, 0.5, 0, 10.5, 26, 10, 0, 0, 0, 0, 0, 35, 96.5,
30, 95, 3, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 5.5, 0, 0, 0, 7.5,
10, 0, 0, 0, 0, 0, 5.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 5.5, 1, 0, 0, 21, 0, 0, 0, 0, 0, 0, 3, 11.5, 0, 42, 0, 11,
0, 9, 0, 0, 21, 2.5, 4, 2.5, 6, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16.5, 0, 0, 0, 0, 0, 0, 45,
39, 0, 0, 62, 17, 17.5, 5.5, 0, 4.5, 2.5, 0, 0, 0, 0, 0, 0, 0,
0, 5.5, 0, 0, 0, 0, 0, 0, 3.5, 5, 0, 20, 0, 41, 1, 0, 0, 0, 0,
4.5, 1.5, 0, 0, 3.5, 12, 0, 0.5, 0, 0, 17, 32), V9 = c(42, 78,
65.5, 22, 18, 1.5, 0.5, 4, 10.5, 5, 0, 27.5, 3.5, 4, 0, 1.5,
0, 0, 12.5, 0.5, 0, 101.5, 31.5, 30, 27, 8, 52.5, 10.5, 0.5,
11, 20.5, 0, 3, 0, 0, 0, 10.5, 0, 0, 0, 0, 4.5, 5.5, 8, 5, 5,
3, 0.5, 9, 18.5, 33, 0.5, 33, 0.5, 0, 20, 0.5, 25.5, 0.5, 0,
0, 1.5, 16.5, 7, 0.5, 0, 0, 0, 19.3, 116.9, 13.7, 47.5, 11, 0,
0, 0, 0, 0, 0, 0, 0, 0.5, 2, 2, 0, 0, 20, 18, 0, 0, 0, 1, 0,
40.5, 1.5, 1.5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
11.5, 0, 6.5, 0.5, 0, 2.5, 0, 0.5, 3.5, 21, 0, 0, 1, 11.5, 0,
0.7, 46.9, 1.7, 0.8, 0, 0, 0, 10.5, 1.1, 0, 1.5, 63.1, 1.1, 0.8,
0, 0, 0, 0, 0, 0, 34.5, 2.5, 1.5, 1, 4.5, 2, 1, 0, 0, 1, 0, 0,
0, 0, 0, 0, 60.5, 3.5, 0.5, 0.5, 0, 0, 50, 0, 50, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3.5, 47, 1.1,
0, 0, 0, 0.4, 9.3, 5.4, 0, 0, 0, 0, 0, 23.4, 2.7, 0, 6.2), V10 = c(125.5,
85.5, 24.5, 25, 2.5, 3, 14, 1, 45, 14.5, 6, 0.5, 20, 0, 0, 0,
0, 29, 11.5, 52, 74.5, 9.5, 44, 24.5, 19.5, 26.5, 21, 13, 11,
21, 12, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 7, 5.5, 11.5, 19, 17.5,
8.5, 3, 5.5, 37, 35, 0.5, 6, 0.5, 0, 5.5, 0, 3, 0, 0, 6, 5.5,
7.5, 0, 0, 0.5, 0, 9.5, 29, 144, 35.5, 62.5, 2.5, 0, 0, 0, 0,
0, 0, 0, 1.5, 0, 0.5, 0, 0, 0, 0, 0, 0, 23, 0, 0, 30, 0, 0, 2.5,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 15, 0, 0, 0, 0, 0, 0, 0,
0, 7.5, 2, 0, 0, 5, 14.5, 1.5, 1, 0, 0, 0, 0, 21, 9, 2.5, 4,
7, 0, 0, 0, 8, 1.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 59.5, 0, 40, 0, 0, 0, 145.5, 7.5, 0, 0, 11, 7, 0, 0,
52.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 9.5, 9.5,
0, 2.5, 4, 3.5, 65.5, 0, 16.5, 6, 0, 0, 15, 0, 1.5, 0, 0, 0,
0, 1, 0, 0, 0, 0, 10, 48), V11 = c(48.16666667, 34.55555556,
39.38888889, 19.27777778, 6.125, 1.3125, 4.5, 2.75, 11.75, 3.777777778,
2.411111111, 4.588888889, 7.944444444, 2, 5.333333333, 11.35555556,
8.588888889, 7, 4.111111111, 10.66666667, 27.11111111, 44.27777778,
33.5, 79.66666667, 55.88888889, 36.38888889, 57.16666667, 24.4375,
7.25, 13.25, 4.4375, 1.428571429, 1.142857143, 0, 0, 0, 2.428571429,
0.285714286, 0, 0, 21.1875, 5.75, 7.5, 15.8125, 20.1875, 5.8125,
9.875, 8.1875, 13.375, 21.4375, 26.375, 17.8125, 25.5625, 0.3125,
10.38888889, 5.4, 9.033333333, 4, 1.166666667, 2.555555556, 8.644444444,
7.144444444, 4.444444444, 0.855555556, 0.055555556, 0.055555556,
0.388888889, 7.833333333, 32.03333333, 38.4, 25.04444444, 31.48888889,
3.055555556, 0.3875, 0.7125, 0.3125, 0, 0, 0.5, 0.375, 0.8125,
0.75, 4.0625, 2.0125, 0, 21.375, 15.225, 3.55, 0.875, 11.9875,
5.825, 1.488888889, 9.844444444, 4.933333333, 4.333333333, 0.777777778,
0.388888889, 7.277777778, 0.544444444, 1.133333333, 0, 0, 0.666666667,
0.111111111, 0, 1.444444444, 3.222222222, 0.833333333, 15.83333333,
0.655555556, 0.777777778, 7.344444444, 8.455555556, 1.222222222,
2, 2.777777778, 3.333333333, 0.833333333, 0.777777778, 10.2,
17.88888889, 10.57777778, 11.65555556, 2.866666667, 10.17777778,
8, 17.26666667, 13.94444444, 6.566666667, 3.533333333, 3.844444444,
3.555555556, 6.4, 3.6, 5.4, 0.555555556, 11.22222222, 16.42222222,
5.777777778, 2, 0, 1.625, 0, 0, 0, 0.125, 5, 0.357142857, 0.214285714,
0.142857143, 0.642857143, 3.5, 0.785714286, 0.928571429, 22.48571429,
12.21428571, 0.857142857, 5.785714286, 0.285714286, 3.4375, 5.625,
28, 20.8, 10.85, 4.8875, 15.1875, 11.65, 9.975, 22.4125, 6.5625,
6.875, 5.325, 7.125, 1, 1.928571429, 2.5, 1.4, 1.642857143, 0.675,
2.6875, 3.275, 0.888888889, 0, 0, 2.944444444, 4.444444444, 2.444444444,
1.166666667, 14.5, 13.66666667, 9.666666667, 13.3, 12.03333333,
12.38888889, 1.677777778, 0.5, 5.222222222, 1.055555556, 6.988888889,
3.088888889, 0.822222222, 0.777777778, 1.333333333, 4.555555556,
10.11111111, 15.22222222, 6.155555556, 0.688888889, 3.555555556,
10.12)), .Names = c("V1", "V2", "V3", "V4", "V5", "V6", "V7",
"V8", "V9", "V10", "V11"), class = "data.frame", row.names = c(NA,
-210L))

I want to replace all NA's value in column 1 until column 10 with the
corresponding value in column 11. How to achieve this. Please help me.
Thank you.


Dila

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
Massimiliano Tripoli 
Collaboratore T.E.R. scado il 31/12/2014 
ISTAT - DCCN - Direzione Centrale della Contabilit? Nazionale 
U.O. Contabilit? dei flussi di materia del sistema economico - CSA/C
Via Depretis, 74/B 00184 Roma 
Tel. 06.4673.3132 
E-mail: mtripoli at istat.it 


From oda412 at gmail.com  Tue Apr 29 17:05:00 2014
From: oda412 at gmail.com (Olga Albutova)
Date: Tue, 29 Apr 2014 19:05:00 +0400
Subject: [R] R in Excel
Message-ID: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/e939fc24/attachment.pl>

From rameshdas.87 at gmail.com  Tue Apr 29 16:12:05 2014
From: rameshdas.87 at gmail.com (Ramesh Das)
Date: Tue, 29 Apr 2014 19:42:05 +0530
Subject: [R] Kindly help me
Message-ID: <CAEg8v3a3J=7k_4uGbU2PtBpfS9XHPfODaZEtsnG-NS9i1sZmSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/c1d5772e/attachment.pl>

From rameshdas.87 at gmail.com  Tue Apr 29 16:14:25 2014
From: rameshdas.87 at gmail.com (Ramesh Das)
Date: Tue, 29 Apr 2014 19:44:25 +0530
Subject: [R] Kindly help me
Message-ID: <CAEg8v3ZrCXFFQ4zufYHNEWT2eCnDS3F80f5U_G63mth+mm7Vyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/2ea0a777/attachment.pl>

From jholtman at gmail.com  Tue Apr 29 17:54:38 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 29 Apr 2014 11:54:38 -0400
Subject: [R] sum of two POSIXct objects: date and hour
In-Reply-To: <535FA3CD.3040107@arpa.veneto.it>
References: <535FA3CD.3040107@arpa.veneto.it>
Message-ID: <CAAxdm-7Bew7wXqZAZT=Ag0w2cZdfat67=OEnjqzcDimTYNnyHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/df7999bd/attachment.pl>

From petr.pikal at precheza.cz  Tue Apr 29 17:58:54 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 29 Apr 2014 15:58:54 +0000
Subject: [R] R in Excel
In-Reply-To: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
References: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BCFB77@SRVEXCHMBX.precheza.cz>

Hi

I can be mistaken but isn't it a question to Microsoft help? Did you try to ask them?

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Olga Albutova
> Sent: Tuesday, April 29, 2014 5:05 PM
> To: r-help at r-project.org
> Subject: [R] R in Excel
>
> Hello!
> I need some help. I'd like to make a button in Excel which performes
> functions wrote in R. Is there is any macros to do this? I don't want
> to use RExcel.
> Thank you very much!
>
> Sincerely yours,
> Olga
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From christoph.schlaechter at gmail.com  Tue Apr 29 18:03:35 2014
From: christoph.schlaechter at gmail.com (=?UTF-8?Q?Christoph_Schl=C3=A4chter?=)
Date: Tue, 29 Apr 2014 18:03:35 +0200
Subject: [R] subset of obersevation depending on multiple conditions
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5E9EF5E@DKRDSEXC016.vestas.net>
References: <CACU-vMhjSGsUVf=RNKWdcDwv+-NGiXcq7biRBsktWSd=5o5_Eg@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5E9EF5E@DKRDSEXC016.vestas.net>
Message-ID: <CACU-vMi_rsRLw0QZR+09vCdoAKy6LRnAeDQpPcmcLeiEyLxZTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/9d76b9d3/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Apr 29 18:23:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 29 Apr 2014 09:23:16 -0700
Subject: [R] R in Excel
In-Reply-To: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
References: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
Message-ID: <e25f1318-9175-495f-ab95-f2876054fe5e@email.android.com>

Well, I suppose you might be able to use VBA to invoke a shell (command line) which could run an R script, but that would be quite restrictive.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 29, 2014 8:05:00 AM PDT, Olga Albutova <oda412 at gmail.com> wrote:
>Hello!
>I need some help. I'd like to make a button in Excel which performes
>functions wrote in R. Is there is any macros to do this? I don't want
>to
>use RExcel.
>Thank you very much!
>
>Sincerely yours,
>Olga
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Apr 29 17:59:43 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Apr 2014 08:59:43 -0700 (PDT)
Subject: [R] dataframe
In-Reply-To: <1897246202.11446621398779148842.JavaMail.actor@webmail37>
References: <1897246202.11446621398779148842.JavaMail.actor@webmail37>
Message-ID: <1398787183.29340.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

It is better to show example data using ?dput().

dat <- structure(list(row.names = 1:4, XYZ = c("sample", "sample2", 
"sample3", "sample4"), `000_001` = c("sample", "Au5", "C", "C"
), `000_002` = c("sample", "Au32", "C", "Au4"), `000_003` = c("sample", 
"Au5", "A", "AC")), .Names = c("row.names", "XYZ", "000_001", 
"000_002", "000_003"), class = "data.frame", row.names = c(NA, 
-4L))


dat[,intersect(grep("Au5", dat), grep("\\bC\\b",dat)),drop=FALSE]
#? 000_001
#1? sample
#2???? Au5
#3?????? C
#4?????? C

A.K.




On Tuesday, April 29, 2014 9:45 AM, "pascalbells at libero.it" <pascalbells at libero.it> wrote:
Hello, 
thank you for accepting me into the list.

I have the following dataframe:

?  row.names? X? ? ? ? ?  Y? ? ?  Z? ?  000_001? 000_002? 000_003
1? ? ? ? ? ? ? ? ? ? sample? ? ? ? ? ? ? ? ? ?  sample? ? sample? ?  sample
2? ? ? ? ? ? ? ? ? ? sample2? ? ? ? ? ? ? ? ?  Au5? ? ? ?  Au32? ? ?  Au5
3? ? ? ? ? ? ? ? ? ? sample3? ? ? ? ? ? ? ? ?  C? ? ? ? ? ? ? C? ? ? ? ? ?  C
4? ? ? ? ? ? ? ? ? ? ...........? 
..
..n? ? ? ? ? ? ? ? ? ? ............? ? ? ? ? ? ? ? ? ? ....? ? ? ? ? ? .......? ? ? ?  ............


I would like to select al the columns that have Au5 and C.
thank you in advance for your help,
james


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From fongchunchan at gmail.com  Tue Apr 29 18:55:36 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Tue, 29 Apr 2014 09:55:36 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CA+hbrhU7C8Epp5-7ujS0aJUT3v0v4hEmFs024z0ZSQax0LQe-w@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
	<CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
	<CAB-BZ9+mOD7m97ULPet=HHrjfuvYjdd+KJgTqDOBfn-PR_GMpw@mail.gmail.com>
	<CA+hbrhWK-L0akogvmmqj8Stz3HOiiFVDdgF3PdXvrkn1M_RRgg@mail.gmail.com>
	<CAB-BZ9JXDJJX98LR3Rm9nXyNm=cSgKMu9qYPF-AS_X9g_1uL9w@mail.gmail.com>
	<CA+hbrhU7C8Epp5-7ujS0aJUT3v0v4hEmFs024z0ZSQax0LQe-w@mail.gmail.com>
Message-ID: <CAB-BZ9LOLt4345FTMEX5fuO6GG2w-VopJnudX49AeRrKo3WUBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/5fbf096f/attachment.pl>

From JLucke at ria.buffalo.edu  Tue Apr 29 18:58:42 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Tue, 29 Apr 2014 12:58:42 -0400
Subject: [R] R in Excel
In-Reply-To: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
References: <CAMqhhM9+k4RYUBBHsZMhzoyYUptLo3T-wAY91wB1muK2tDaWLQ@mail.gmail.com>
Message-ID: <OF62D45232.2954F70A-ON85257CC9.005CA926-85257CC9.005D46B0@ria.buffalo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/7b920a11/attachment.pl>

From marongiu.luigi at gmail.com  Tue Apr 29 19:57:52 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 29 Apr 2014 18:57:52 +0100
Subject: [R] set axis limit in lattice
Message-ID: <CAMk+s2Q88uNjabzeTGiZeHE4vzWczREaB25BVFt1Bzc=epTxpA@mail.gmail.com>

Dear all,

I would like to set the axis of a figure using the max() so to have
more control on the limits of the axis -- this because in the actual
case more independent figures are generated from the same dataframe
and these must have the same axis scale.

Since the figure is generated using lattice device, the syntax is too
complicated for me: when I place the xlim=c(0,Y) in the arguments ?
where Y is obtained using max(data) ? there is no result. In basic R
this argument would work virtually in any position.

Any tip?

Best regards

Luigi

 ####CODE
### open plot library
library(lattice)
my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
"Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
 column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")

key.plot<-list(
  space="top", columns=2,
  text=list(c("Positive", "Negative"), col="black"),
  points=list(pch=c(16,1), col="black"))

datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)

X<-c(0.7, 1.3, 1.7, 2.3)

Y<-max(copy)

stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  k<-0
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
             w<-i+k
                   panel.segments(x0 = X[w], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[w+1],  y1 = datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)
   }
             }
       )


From fongchunchan at gmail.com  Tue Apr 29 20:09:45 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Tue, 29 Apr 2014 11:09:45 -0700
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CAB-BZ9LOLt4345FTMEX5fuO6GG2w-VopJnudX49AeRrKo3WUBw@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
	<CA+hbrhWOs4PyyQOUgOOawXavw-gV89PFyjDsd47=M3+1cwJz5g@mail.gmail.com>
	<CAB-BZ9+mOD7m97ULPet=HHrjfuvYjdd+KJgTqDOBfn-PR_GMpw@mail.gmail.com>
	<CA+hbrhWK-L0akogvmmqj8Stz3HOiiFVDdgF3PdXvrkn1M_RRgg@mail.gmail.com>
	<CAB-BZ9JXDJJX98LR3Rm9nXyNm=cSgKMu9qYPF-AS_X9g_1uL9w@mail.gmail.com>
	<CA+hbrhU7C8Epp5-7ujS0aJUT3v0v4hEmFs024z0ZSQax0LQe-w@mail.gmail.com>
	<CAB-BZ9LOLt4345FTMEX5fuO6GG2w-VopJnudX49AeRrKo3WUBw@mail.gmail.com>
Message-ID: <CAB-BZ9+2Myopih+AjSUbw_Cw45aeP+WsigvnYuPAHpMQ8v9pkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/d03f4c40/attachment.pl>

From jholtman at gmail.com  Tue Apr 29 20:27:10 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 29 Apr 2014 14:27:10 -0400
Subject: [R] Replacing NA's in the data set
In-Reply-To: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>
References: <CAMgoKBJDTZW8PwjNuaBX6OXfQjTyhKWNhZMHhDOpKOsGQE0XFg@mail.gmail.com>
Message-ID: <CAAxdm-6UxmmJN1AjpfOqaD3xbOyU03iB0JN8vFWxLU7-RZZ=zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/f8afacf8/attachment.pl>

From mbressan at arpa.veneto.it  Tue Apr 29 21:15:31 2014
From: mbressan at arpa.veneto.it (mbressan at arpa.veneto.it)
Date: Tue, 29 Apr 2014 21:15:31 +0200
Subject: [R] sum of two POSIXct objects: date and hour
In-Reply-To: <CAAxdm-7Bew7wXqZAZT=Ag0w2cZdfat67=OEnjqzcDimTYNnyHg@mail.gmail.com>
References: <535FA3CD.3040107@arpa.veneto.it>
	<CAAxdm-7Bew7wXqZAZT=Ag0w2cZdfat67=OEnjqzcDimTYNnyHg@mail.gmail.com>
Message-ID: <ddf4c37c923aa06878a99e60652ab76f.squirrel@89.96.234.216>

hi, thanks for your reply

the first record for my date is 2014-03-27 and for my hour is 1899-12-30
12:03:16

I got to this point by importing some data via RODBC from an access database

Now, I would like to get a single column with the date and the time that
for the first record should be equal to:

2014-03-27 12:03:16.029

and this result should be the combination of relevant information
contained in the 3 columns: "date", "hour" and "s.100"

I do not have the possibility to change the format of imported data so I
need necessarly to convert them later on...

how would you do that considering that regardless of the time zone
displacement the first column is storing the data, the second the hour and
the third the hundredth of a second


best regards

> When I read in your data, I get the following since I am in the EDT time
> zone:
>
>> df<-structure(list(date = structure(c(1395874800, 1395874800,
>> 1395874800,
> + 1395874800, 1395874800), class = c("POSIXct", "POSIXt"), tzone = ""),
> +      hour = structure(c(-2209121804, -2209121567, -2209121005,
> +      -2209118616, -2209116160), class = c("POSIXct", "POSIXt"), tzone =
> ""),
> +      s.100 = c(29L, 36L, 6L, 53L, 18L)), .Names = c("date", "hour",
> + "s.100"), row.names = c(NA, -5L), class = "data.frame")
>>
>> df
>                  date                hour s.100
> 1 2014-03-26 19:00:00 1899-12-30 06:03:16    29
> 2 2014-03-26 19:00:00 1899-12-30 06:07:13    36
> 3 2014-03-26 19:00:00 1899-12-30 06:16:35     6
> 4 2014-03-26 19:00:00 1899-12-30 06:56:24    53
> 5 2014-03-26 19:00:00 1899-12-30 07:37:20    18
>
>
> I assume your real date is probably 2014-03-27 if it supposed to be GMT.
>  And your 'hour' is funny for probably the same reason.  You can easily
> convert the hundredth of a second in the original input.
>
> Now I would really like to ask how you got to this point.  Did you
> originally read in and convert the data yourself, or is this a source that
> you do not have any control over?  If the former, then just use the
> correct
> conversion.  As shown below, if you have hundredths of a second, that will
> be converted correctly and you don't need the extra column.
>
>> x <- as.POSIXct("2014-04-29 12:00:00.345")  # decimal seconds that are
> converted
>>
>> x
> [1] "2014-04-29 12:00:00 EDT"
>> format(x, format = "%H:%M:%OS3")  # print with 3 decimals
> [1] "12:00:00.345"
>
> If you have the choice, start over again and do it correctly.  If not,
> convert the various components to the correct character format for your
> timezone, combine back together and then use the conversion shown above.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Tue, Apr 29, 2014 at 9:06 AM, Massimo Bressan
> <mbressan at arpa.veneto.it>wrote:
>
>> I have this dataframe:
>>
>> df<-structure(list(date = structure(c(1395874800, 1395874800,
>> 1395874800,
>> 1395874800, 1395874800), class = c("POSIXct", "POSIXt"), tzone = ""),
>>      hour = structure(c(-2209121804, -2209121567, -2209121005,
>>      -2209118616, -2209116160), class = c("POSIXct", "POSIXt"), tzone =
>> ""),
>>      s.100 = c(29L, 36L, 6L, 53L, 18L)), .Names = c("date", "hour",
>> "s.100"), row.names = c(NA, -5L), class = "data.frame")
>>
>>
>> and I would like to sum first two columns ("date" and "hour") so that to
>> end up with a new column, say "date_hour", storing both the information
>> about the "date" and the "hour" in one POSIXct object;
>>
>> I have been reading that POSIXct objects are a measure of seconds from a
>> given origin (1st Jan 1970), so that a possible solution is to tranform
>> the
>> column "hour" into seconds and then add it to the column "date";
>>
>> but, is there a staightforward solution for accomplishing this task?
>> I've been trying to extract from the column "hour" the digits
>> representing
>> hours, minutes and seconds and transform everything into seconds but
>> that
>> seem to me quite cumbersome approach...
>>
>> and finally, one more question: is it possible to represent hundred of
>> seconds as given in the column "s.100" of the given dataframe within the
>> same new POSIXct object "date_hour"?
>>
>>
>> thanksfor the support
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From dcarlson at tamu.edu  Tue Apr 29 22:30:52 2014
From: dcarlson at tamu.edu (dcarlson at tamu.edu)
Date: Tue, 29 Apr 2014 15:30:52 -0500
Subject: [R] Fwd: problem with kmeans
In-Reply-To: <CA+hbrhVVZnPABSoab9SUc5w-3ZoK0REVVz5OYYvMjV4vLJexZQ@mail.gmail.com>
References: <CAFkmApMcifd3v6Mm1-oAEc-7PbfRPFSJ+Kr6OoShqUEEZPtb-Q@mail.gmail.com>	<CAFkmApPAxK2FiRrtEZFHFeWjGkK57LNkh5hUvZUeE6hJKk3sQQ@mail.gmail.com>
	<CA+hbrhVVZnPABSoab9SUc5w-3ZoK0REVVz5OYYvMjV4vLJexZQ@mail.gmail.com>
Message-ID: <012e01cf63e9$ea188900$be499b00$@tamu.edu>

You really should read the instructions before complaining. The
manual page for kmeans clearly states that it works on "a
numeric matrix of data." That is not what you provided. You gave
it a distance matrix. The function pam() will work with a
distance matrix if it is properly labeled as such, but
stringdistmatrix() does not label the output as a distance
matrix:

dis <- stringdistmatrix(test, test, method = "lv")
dis
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
[,12]
 [1,]    0    2    6    6    5    2    3    2    6     5     4
5
 [2,]    2    0    4    5    5    4    4    2    4     3     4
3
 [3,]    6    4    0    1    1    7    7    5    5     3     5
3
 [4,]    6    5    1    0    2    7    8    6    6     4     5
4
 [5,]    5    5    1    2    0    6    7    6    6     4     4
4
 [6,]    2    4    7    7    6    0    1    2    7     5     5
5
 [7,]    3    4    7    8    7    1    0    2    6     5     6
5
 [8,]    2    2    5    6    6    2    2    0    5     4     5
4
 [9,]    6    4    5    6    6    7    6    5    0     2     2
2
[10,]    5    3    3    4    4    5    5    4    2     0     2
0
[11,]    4    4    5    5    4    5    6    5    2     2     0
2
[12,]    5    3    3    4    4    5    5    4    2     0     2
0

require(cluster) # Works once you have installed it.

cl <- pam(dis, 4, diss=TRUE) # Note you must tell pam() that
this is a distance matrix.

print(paste(test, "-", cl$clustering))
 [1] "hematolgy - 1"  "hemtology - 1"  "oncology - 2"   "onclogy
- 2"   
 [5] "oncolgy - 2"    "dermatolgy - 3" "dermatoloy - 3"
"dematology - 1"
 [9] "neurolog - 4"   "nerology - 4"   "neurolgy - 4"
"nerology - 4"

The only apparent error is dermatology which is combined with
hematology but if you look at row 8 of the above distance
matrix, you will see that the Levenshtein distance (the option
you chose) has the value 2 for hematology, hemtology,
dermatolgy, and dermatology. You may want to choose a distance
metric that places greater weight on the initial letter.

Peer reviewed research publications, as opposed to idle gossip,
confirm the accuracy of R. 


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Peter
Langfelder
Sent: Monday, April 28, 2014 11:44 PM
To: cassie jones
Cc: r-help at r-project.org
Subject: Re: [R] Fwd: problem with kmeans

You are using the wrong algorithm. You want Partitioning around
Medoids (PAM, function pam), not k-means. PAM is also known as
k-medoids, which is where the confusion may come from.

use

library(cluster)

cl = pam(dis, 4)

and see if you get what you want.

HTH,

Peter



On Mon, Apr 28, 2014 at 9:15 PM, cassie jones
<cassiejones26 at gmail.com> wrote:
> Dear R-users,
>
> I am trying to run kmeans on a set comprising of 100
observations. But R
> somehow can not figure out the true underlying groups,
although other
> software such as Jmp, MINITAB are producing the desired
result.
>
> Following is a brief example of what I am doing.
>
> library(stringdist)
> test=c('hematolgy','hemtology','oncology','onclogy',
> 'oncolgy','dermatolgy','dermatoloy','dematology',
> 'neurolog','nerology','neurolgy','nerology')
>
> dis=stringdistmatrix(test,test, method = "lv")
>
> set.seed(123)
> cl=kmeans(dis,4)
>
>
> grp_cl=vector('list',4)
>
> for(i in 1:4)
> {
>     grp_cl[[i]]=test[which(cl$cluster==i)]
> }
> grp_cl
>
> [[1]]
> [1] "oncology" "onclogy"
>
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
>
> [[3]]
> [1] "oncolgy"
>
> [[4]]
> [1] "hematolgy"  "hemtology"  "dermatolgy" "dermatoloy"
"dematology"
>
> In the above example, the 'test' variable consists of a set of
> terminologies with various typos and I am trying to group the
similar types
> of words based on their string distance. Unfortunately kmeans
is not able
> to replicate the following result that the other software are
able to
> produce.
> [[1]]
> [1] "oncology" "onclogy"  "oncolgy"
>
> [[2]]
> [1] "neurolog" "nerology" "neurolgy" "nerology"
>
> [[3]]
> [1] "dermatolgy" "dermatoloy" "dematology"
>
> [[4]]
> [1] "hematolgy"  "hemtology"
>
>
> Does anyone know if there is a way out, I have heard from a
lot of people
> that multivariate analysis in R does not produce the desired
result most of
> the time. Any help is really appreciated.
>
>
> Thanks in advance.
>
>
> Cassie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From tom at maladmin.com  Tue Apr 29 22:42:48 2014
From: tom at maladmin.com (Tom Wright)
Date: Tue, 29 Apr 2014 16:42:48 -0400
Subject: [R] Fast way to populate a sparse matrix
In-Reply-To: <21338.6877.979103.626514@stat.math.ethz.ch>
References: <CAKmUXV-8HnVzQgpSV50UtM6C63-3FJ6PaDCH7ZpWh=n2uqZ__g@mail.gmail.com>
	<CAFEqCdz3n1wOg6B7g401QTT+ciiPNi0FR_4fLmy0v_D-yUVHcQ@mail.gmail.com>
	<B4FDB139-2EB9-4559-903D-503EC8A93E46@collocations.de>
	<21338.6877.979103.626514@stat.math.ethz.ch>
Message-ID: <CAKmUXV_Jh_cxnG1_BCzXUp8UfcWzKKrHU+JZF5CwRDubwBW43Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/be595682/attachment.pl>

From dwinsemius at comcast.net  Tue Apr 29 22:56:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 29 Apr 2014 13:56:14 -0700
Subject: [R] Kindly help me
In-Reply-To: <CAEg8v3ZrCXFFQ4zufYHNEWT2eCnDS3F80f5U_G63mth+mm7Vyg@mail.gmail.com>
References: <CAEg8v3ZrCXFFQ4zufYHNEWT2eCnDS3F80f5U_G63mth+mm7Vyg@mail.gmail.com>
Message-ID: <910A37DE-3C3C-45CE-AC87-24EBC5AA5BBA@comcast.net>


On Apr 29, 2014, at 7:14 AM, Ramesh Das wrote:

> Dear all,
> I have a problem in installing the the package "zelig". I have window 32
> bit operating system and R- 3.0.1 version.  

There is quite of bit of missing information about your setup. Please read the Posting Guide for advice about the level of detail needed for solving problems with installation.


> "zelig' package is not
> compatible with R-3.0.1 version.

Ypu need to explain what that means. The CRAN page for Zelig seems to disagree. Error messages should be copied in fulll (as mentioned in the Posting Guide.) At a minimum we need to know where you got the package, what it's full name might be, what packages on which Zelig depends you have installed, and what code and interface you used for failed efforts.


> Please help me how to install the package
> "zelig" .

An alternate source of help might be the authors and maintainer.

> If any other package is available in replace of "zelig', kindly
> suggest me.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Tue Apr 29 23:02:28 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 29 Apr 2014 17:02:28 -0400
Subject: [R] sum of two POSIXct objects: date and hour
In-Reply-To: <ddf4c37c923aa06878a99e60652ab76f.squirrel@89.96.234.216>
References: <535FA3CD.3040107@arpa.veneto.it>
	<CAAxdm-7Bew7wXqZAZT=Ag0w2cZdfat67=OEnjqzcDimTYNnyHg@mail.gmail.com>
	<ddf4c37c923aa06878a99e60652ab76f.squirrel@89.96.234.216>
Message-ID: <CAAxdm-5SyrmdRTRLAQj1LAVAMtC-txDiMLHRAWiL_MKRbDn+jw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/9dddf6b0/attachment.pl>

From jfox at mcmaster.ca  Tue Apr 29 23:53:14 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 29 Apr 2014 17:53:14 -0400
Subject: [R] ICPSR R course in Berkeley in June 2014
Message-ID: <002301cf63f5$6cdaa700$468ff500$@mcmaster.ca>

Announcing the ICPSR Summer Program Workshop "The R Statistical Computing
Environment: The Basics and Beyond"

View this announcement in your browser: http://eepurl.com/TEGH5

The R Statistical Computing Environment: The Basics and Beyond

Dates: June 23-27, 2014
URL: http://bit.ly/1mXqVqU

Location: Berkeley, CA

Instructor: John Fox, McMaster University


About this workshop: This five-day workshop will introduce R, a free,
open-source implementation of the S language that is available for Windows,
Mac OS X, and Unix/Linux systems.

The R statistical programming language and computing environment has become
the de facto standard for writing statistical software among statisticians.
In the past few years, it has also made substantial inroads in the social
sciences. R makes routine data analysis easy and supports convenient
programming. Users of R have taken advantage of its extensibility to
contribute more than 5,000 freely available "packages" of documented R
programs and data to CRAN (the Comprehensive R Archive Network) and many
others to the Bioconductor package archive. R is also particularly capable
in the area of statistical graphics.

Each day of the workshop will combine four to five hours of lectures and
demonstrations with two to three hours of hands-on labs. We will begin with
an introduction to R, including statistical modeling in R -- in effect,
using R as a statistical package. After that, the workshop will provide the
background required to use R seriously for sophisticated data analysis,
programming, and presentation.



About the ICPSR Summer Program
The ICPSR Summer Program is internationally recognized as the preeminent
resource for basic and advanced training in social science research
methodologies and technologies.

We offer courses in research design, quantitative reasoning, statistical
methods, and data processing. Our goal is to integrate methods of
quantitative analysis within a broader context of substantive social
research.



More Information
For more information, including a complete list of courses, registration
information, and scholarships, please visit our website at
icpsr.umich.edu/sumprog. You can also contact the Summer Program at (734)
763-7400 or sumprog at icpsr.umich.edu

-------------------------------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada



---
This email is free from viruses and malware because avast! Antivirus protection is active.
http://www.avast.com


From dulcalma at bigpond.com  Wed Apr 30 01:15:52 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 30 Apr 2014 09:15:52 +1000
Subject: [R] set axis limit in lattice
In-Reply-To: <CAMk+s2Q88uNjabzeTGiZeHE4vzWczREaB25BVFt1Bzc=epTxpA@mail.gmail.com>
References: <CAMk+s2Q88uNjabzeTGiZeHE4vzWczREaB25BVFt1Bzc=epTxpA@mail.gmail.com>
Message-ID: <000601cf6400$f927dab0$eb779010$@bigpond.com>

Hi Luigi

This produces plenty of white space for the y axes

Y<-max(my.data$copy)

stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P")),
                     y= list(relation = "free")),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  k<-0
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
             w<-i+k
                   panel.segments(x0 = X[w], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[w+1],  y1 = datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)
   }
             }
       )
You could limit the y-axis to your levels       
stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P")),
                     y= list(relation = "free",
                                 limits = list(c(0, max panel 1),
                                                     c(0, max panel 2),
                                                    ...
                                                   c(0, max panel 8)),
      )),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  k<-0
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
             w<-i+k
                   panel.segments(x0 = X[w], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[w+1],  y1 = datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)
   }
             }
       )

Sorting the stimulation groups shows that some of them can be loosely grouped so reordering the factors

stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("PHA","Rv2654","CFP10","Unst.","Rv3615c", "Rv3873","ESAT6", "Rv3879")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(2,4),
       scales = list(x = list(at = c(1,2), labels = c("N","P")),
                     y= list(relation = "free")),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  k<-0
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
             w<-i+k
                   panel.segments(x0 = X[w], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[w+1],  y1 = datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)
   }
             }
       )

or using panel.groups

stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("PHA","Rv2654","CFP10","Unst.","Rv3615c", "Rv3873","ESAT6", "Rv3879")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(2,4),
       scales = list(x = list(at = c(1,2), labels = c("N","P")),
                     y= list(relation = "free")),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = panel.superpose,
       panel.groups = function(x, y, group.number, ...) {

                        panel.segments(x0= x-0.25, x1=x+0.25, y0=mean(y), y1=mean(y), lty = c(1:2)[group.number],
                        lwd=c(2:1)[group.number], col = c(1:2)[group.number])

                        panel.stripplot(x,y, ...)
             }
      )

Regards

Duncan Mackay

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi Marongiu
Sent: Wednesday, 30 April 2014 03:58
To: r-help at r-project.org
Subject: [R] set axis limit in lattice

Dear all,

I would like to set the axis of a figure using the max() so to have
more control on the limits of the axis -- this because in the actual
case more independent figures are generated from the same dataframe
and these must have the same axis scale.

Since the figure is generated using lattice device, the syntax is too
complicated for me: when I place the xlim=c(0,Y) in the arguments ?
where Y is obtained using max(data) ? there is no result. In basic R
this argument would work virtually in any position.

Any tip?

Best regards

Luigi

 ####CODE
### open plot library
library(lattice)
my.data<-structure(list(
   column_1 = 1:120,
   column_2 = structure(c(
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8,
 1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
"Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
 column_3 = structure(c(
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,0)),
     column_4 = c(
 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
 0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
.Names = c("row", "stimulation", "positivity", "copy"), row.names =
c(NA, -120L),
 class = "data.frame")

key.plot<-list(
  space="top", columns=2,
  text=list(c("Positive", "Negative"), col="black"),
  points=list(pch=c(16,1), col="black"))

datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)

X<-c(0.7, 1.3, 1.7, 2.3)

Y<-max(copy)

stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  k<-0
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
             w<-i+k
                   panel.segments(x0 = X[w], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[w+1],  y1 = datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)
   }
             }
       )

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Wed Apr 30 01:31:21 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 30 Apr 2014 09:31:21 +1000
Subject: [R] lattice plot formatting: pch, abbreviation and labels
In-Reply-To: <CAMk+s2Sb6FXVsupUS-OTNVvz29afc-nDMcHN9YuekfEWiBOfKQ@mail.gmail.com>
References: <CAMk+s2R1ic1uwNQ3yiyYBuHR1Mdt9y62Vj7q_pASFKg7HQ2vEQ@mail.gmail.com>	<002a01cf61b4$fdd47300$f97d5900$@bigpond.com>	<CAMk+s2SDJ13rQXzm_O503vYLF7nEPDVfRcXbNHwbDAzb6TB-Kg@mail.gmail.com>	<001201cf6280$b3229e00$1967da00$@bigpond.com>	<CAMk+s2R2euedW=9vMkzc4c=oYvmGOKkU8zj8Hsnpm2J-nu3Yew@mail.gmail.com>	<002201cf638d$0c04e660$240eb320$@bigpond.com>
	<CAMk+s2Sb6FXVsupUS-OTNVvz29afc-nDMcHN9YuekfEWiBOfKQ@mail.gmail.com>
Message-ID: <000801cf6403$2139cf70$63ad6e50$@bigpond.com>

Forgot to cc to list
Hi Luigi

Our emails are apparently crossing

What you are doing is referencing down ONLY to the stimulation level and not
 the stimulation level + productivity level required  for each of the N and P groups

notch<-0.3
stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
       for (i in 1:2){
          datme<-subset(datmeA, positivity==i-1)
             w<-i+k
             panel.segments(x0 = X[w], y0 =  datme[datme[,2]== levels(datme[,2])[pnl],"copy"],
                            x1 = X[w+1],  y1 = datme[datme[,2]== levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)

      panel.stripplot(x,y, ...)
   }
             }
       )
       
       for (i in 1:2){
          datme<-subset(datmeA, positivity==i-1)
             w<-i+k
             panel.segments(x0 = X[w], y0 =  datme[datme[,2]== levels(datme[,2])[pnl],"copy"],
                            x1 = X[w+1],  y1 = datme[datme[,2]== levels(datme[,2])[pnl],"copy"],lwd = 2, col = "black")
                  k=k+1

      panel.stripplot(x,y, ...)

the more lattice way is

notch<-0.3
stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = panel.superpose,
       panel.groups = function(x, y, group.number, ...) {

                        panel.segments(x0= x-notch, x1=x+notch, y0=mean(y), y1=mean(y), lty = c(1:2)[group.number],
                        lwd=c(2:1)[group.number], col = c(1:2)[group.number])

                        panel.stripplot(x,y, ...)
             }
      )

Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Wednesday, 30 April 2014 02:44
To: Duncan Mackay
Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels

Dear Duncan,
I think the solution is close by. I can now plot the segments directly
with stripplot using a vector containing the required positions; the
only problem is to generate 4 consecutive indeces using two nested
loops -- using the subtraction of the index and a number I obtained
the duplication of the values, as you can see in the second example.
Many thanks,
Luigi

X<-c(0.7, 1.3, 1.7, 2.3)
stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
   k<-i-1
             for (j in 1:2)
    {
                   panel.segments(x0 = X[k+j], y0 =  datme[datme[,2]==
levels(datme[,2])[pnl],"copy"],
                                  x1 = X[k+j+1],  y1 =
datme[datme[,2]== levels(datme[,2])[pnl],"copy"],lwd = 2, col =
c("magenta","grey"))
                   }

      panel.stripplot(x,y, ...)
   }
             }
       )



#### this approach gives duplications:
notch<-0.3
stripplot(
  copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.",
"ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
       my.data,
       group = positivity,
       hor=F,
       layout = c(8,1),
       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
       jitter.data=TRUE, pch=c(16,1), col="black",
       ylab=expression(bold("Copy")),
       xlab=expression(bold("Stimulation")),
       main="Plot",
       par.settings = list(strip.background=list(col="white")),
       par.strip.text=list(font=2),
       key = key.plot,
       panel = function(x, y, ...)
  {
            pnl = panel.number()
  for (i in 1:2){
   datme<-subset(datmeA, positivity==i-1)
   k<-i-1
             for (j in 1:2)
    {
                   panel.segments(x0 = j-notch, y0 =
datme[datme[,2]== levels(datme[,2])[pnl],"copy"],
                                  x1 = j+notch,  y1 =
datme[datme[,2]== levels(datme[,2])[pnl],"copy"],lwd = 2, col =
c("magenta","grey"))
                   }

      panel.stripplot(x,y, ...)
   }
             }
       )

On Tue, Apr 29, 2014 at 10:26 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Only minor changes needed.
>
> When you go back to a normal xyplot the rules of ratio variables apply the x-axis default in your case something like pretty(range(x)
> So the x-axis limits range from 0-1
> and the panel limits therefore are 0-1 +/- 4%
> With strip stripplot being categorical the limits are for values 1 and 2 so the top value for 2 is not being shown
> (easily seen with str(xyplot object))
>
> You missed out the assigning of groups to the segments.
> You could do this by a for loop of 1:2 or by using groups/panel.groups.
> I have not got the time to dig out the code to do it at the moment.
>
> xyplot(copy ~ positivity|stimulation, data = my.data,
>        group = factor(positivity),
>        as.table = TRUE,
>        layout = c(8,1),
>        xlim  = c(-1,2),
>        scales = list(x = list(at = c(0,1),
>                              labels = c("N","P"),
>                              rot = 0)),
>       jitter.data=TRUE,
>       pch=c(16,1),
>       col="black",
>       ylab=expression(bold("Copy")),
>       xlab=expression(bold("Stimulation")),
>       main="Plot",
>       par.settings = list(strip.background=list(col="white")),
>                                      par.strip.text=list(font=2),
>       key = list(space="top",
>                  columns=2,
>                  text=list(c("Positive", "Negative"), col="black"),
>                  points=list(pch=c(16,1), col="black")),
>       panel = function(x, y,...){
>                 pnl = panel.number()
>                 #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>                 #for (j in 1:2){
>                 #  with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
>                 #     panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
>                for (j in 1:2){
>                 panel.segments(x0 = (j-1)-0.25, y0 =  datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"], # amend to copy
>                              x1 = (j-1)+0.25,  y1 = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"copy"],
>                              lwd = 2, col = c("magenta","grey")[j])
>                 }
>
>                panel.stripplot(x,y, ...)
>             }
>       )
> If you wanted full N P then
>
>        scales = list(x = list(at = c(0,1),
>                              alternating = F,
>                              labels = c("Negative","Positive"),
>                              rot = 90)),  # rot = 0 if labels as before
>
> Duncan
>
> -----Original Message-----
> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
> Sent: Tuesday, 29 April 2014 04:34
> To: Duncan Mackay
> Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels
>
> Dear Duncan,
> sorry to pester you again with this, but probably the solution is
> getting closer. following one of your previous tips i could write the
> xyplot synthax as you suggested:
>
> library(lattice)
> my.data<-structure(list(
>    column_1 = 1:120,
>    column_2 = structure(c(
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8,
>  1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
> "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>  column_3 = structure(c(
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 0,0,0,0,0,0,0,0,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 1,1,1,1,1,1,1,1,
> 0,0,0,0,0,0,0,0)),
>      column_4 = c(
>  192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
>  2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
>  870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>  142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
>  3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
>  1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
>  208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
>  4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
>  2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
>  0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
>  97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
>  5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
>  3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
>  2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
> c(NA, -120L),
>  class = "data.frame")
>
> key.plot<-list(
>   space="top", columns=2,
>   text=list(c("Positive", "Negative"), col="black"),
>   points=list(pch=c(16,1), col="black"))
>
> datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)
>
>
> #### HERE IS THE IMPORTANT BIT ###
>
> xyplot(copy ~ positivity|stimulation,
>   my.data,
>   group = positivity,
>   hor=F,
>   as.table = TRUE,
>   layout = c(8,1),
>   scales = list(x = list(alternating = FALSE, at = c(0.2,0.8), labels
> = c("P","N"))),
>   pch=c(16,1), col="black",
>   ylab=expression(bold("Copy")),
>   xlab=expression(bold("Stimulation")),
>   main="Plot",
>   par.settings = list(strip.background=list(col="white")),
>   par.strip.text=list(font=2),
>   key = list(space="top", columns=2, text=list(c("Positive",
> "Negative"), col="black"), points=list(pch=c(16,1), col="black")),
>   panel = function(x, y, ...){
>   pnl = panel.number()
>   panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
> levels(datmeA[,2])[pnl],"ratio"],
>                               x1 = x+0.25,  y1 = datmeA[datmeA[,2]==
> levels(datmeA[,2])[pnl],"ratio"],
>      lwd = 2, col = c("magenta","grey"))
>   panel.stripplot(x,y, ...)
>                }
>        )
>
> ############################
>
> beside beign less elegant than stripplot() -- there is no jittering
> and requires the positions for the labels -- there are mainly two
> problems:
> 1. the dots are too close to the margins -- I tried to use the 'at'
> argument but it did not work
> 2. the segments are replicated -- there should be a 'panel.group'
> somewhere but I obtained a lot of errors when I tried to place it.
>
> Wouldn't be easier to use the stripplot directly, using maybe a factor
> to place the segments? I tried to place the panel.function in
> stripplot but it did not work at all...
>
> stripplot(copy ~ factor(positivity)|factor(stimulation, levels =
> c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879",
> "Rv3873","PHA")),
>        my.data,
>        group = positivity,
>        hor=F,
>        layout = c(8,1),
>        scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>        jitter.data=TRUE, pch=c(16,1), col="black",
>        ylab=expression(bold("Copy")),
>        xlab=expression(bold("Stimulation")),
>        main="Plot",
>        par.settings = list(strip.background=list(col="white")),
>        par.strip.text=list(font=2),
>        key = list(space="top",  columns=2, text=list(c("Positive",
> "Negative"), col="black"), points=list(pch=c(16,1), col="black")),
>         panel = function(x, y, ...){
>                 pnl = panel.number()
>                 panel.segments(x0 = x-0.25, y0 =  datmeA[datmeA[,2]==
> levels(datmeA[,2])[pnl],"ratio"],
>                                           x1= x+0.25,  y1 =
> datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"],
>                  lwd = 2, col = c("magenta","grey"))
>                 panel.stripplot(x,y, ...)
>                }
>        )
>
>
> Best wishes,
> Luigi
>
> On Mon, Apr 28, 2014 at 2:25 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> Hi Luigi
>>
>> Here are 2 ways of doing it.
>>
>> The first is a "cheats" way ie easy.
>>
>> The second is a substitute for the proper way who's code eludes me at the moment. I changed the lty on the ablines  as it appears confusing and as you are bolding it seems more appropriate. A better way may be to change 1 line type.
>>
>> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>>       my.data,
>>       group = positivity,
>>       hor=F,
>>       layout = c(8,1),
>>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>>       jitter.data=TRUE, pch=c(16,1), col="black",
>>       ylab=expression(bold("Copy")),
>>       xlab=expression(bold("Stimulation")),
>>       main="Plot",
>>       par.settings = list(strip.background=list(col="white")),
>>             par.strip.text=list(font=2),
>>       key = list(space="top",
>>                  columns=2,
>>                  text=list(c("Positive", "Negative"), col="black"),
>>                  points=list(pch=c(16,1), col="black")),
>>       panel = function(x, y,...){
>>               pnl = panel.number()
>>               #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>>
>>               panel.average(x, y, fun = mean, horizontal = F, lty = 3, col.line = c("red","black"), type = "l")
>>
>>               panel.stripplot(x,y, ...)
>>             }
>>       )
>>
>> stripplot(copy ~ factor(positivity)|factor(stimulation, levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654","Rv3879", "Rv3873","PHA")),
>>       my.data,
>>       group = positivity,
>>       hor=F,
>>       layout = c(8,1),
>>       scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>>       jitter.data=TRUE, pch=c(16,1), col="black",
>>       ylab=expression(bold("Copy")),
>>       xlab=expression(bold("Stimulation")),
>>       main="Plot",
>>       par.settings = list(strip.background=list(col="white")),
>>             par.strip.text=list(font=2),
>>       key = list(space="top",
>>                  columns=2,
>>                  text=list(c("Positive", "Negative"), col="black"),
>>                  points=list(pch=c(16,1), col="black")),
>>       panel = function(x, y,...){
>>                 pnl = panel.number()
>>                 #panel.abline(h = datmeA[datmeA[,2]== levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>>                 for (j in 1:2){
>>                   with(subset(datmeA, (positivity == j-1 & stimulation == levels(datmeA$stimulation)[pnl])),
>>                      panel.abline(h = copy, lwd = 1, col = c("red","black")[j], lty = 1) )
>>
>>               }
>>
>>                panel.stripplot(x,y, ...)
>>             }
>>       )
>>
>> Remember abline and panel.abline etc only take 1 line at a time so if you have more than 1 group you have 2 call it more than once
>>
>> Regards
>> Duncan
>>
>> -----Original Message-----
>> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
>> Sent: Monday, 28 April 2014 04:03
>> To: Duncan Mackay
>> Subject: Re: [R] lattice plot formatting: pch, abbreviation and labels
>>
>> Dear Duncan,
>> may I bother you a bit more with the same data set? I would like now
>> to add a segment corresponding to the median values, as we discussed
>> antecedently.
>> I have tried to use the code you wrote in the previous mails, but it
>> hasn't worked. First I have found the aggregate medians values and
>> assigned to datmeA, then pasted the code you wrote, but without
>> success. Would be possible to substitute the panel.abline with
>> panel.segments? but in this case how to tell lattice what are the
>> values for "N" or "P"?
>> Best wishes,
>> Luigi
>>
>> CODE::::
>> library(lattice)
>>
>> my.data<-structure(list(
>>    column_1 = 1:120,
>>    column_2 = structure(c(
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8,
>>  1,2,3,4,5,6,7,8), .Label = c("Unst.", "ESAT6", "CFP10", "Rv3615c",
>> "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>>     column_3 = structure(c(
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 0,0,0,0,0,0,0,0,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 1,1,1,1,1,1,1,1,
>> 0,0,0,0,0,0,0,0)),
>>      column_4 = c(
>>  192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.8765622,499.2899303,
>>  2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611.486543,6205.229575,
>>  870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418.651212,7345.712517,
>>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>>  142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.3543635,3167.959757,
>>  3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2466141,9600.963594,
>>  1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958.495138,7224.503437,
>>  208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73980805,8930.784541,
>>  4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.264531581,1518.610307,
>>  2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7034054,24043.61463,
>>  0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,7265.573875,
>>  97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795.75462,30676.769,
>>  5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.178549,1792.679176,
>>  3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,16941.865,31453.96708,
>>  2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.88646,26050.47191)),
>> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
>> c(NA, -120L),
>>  class = "data.frame")
>>
>>
>> key.plot<-list(
>>   space="top", columns=2,
>>   text=list(c("Positive", "Negative"), col="black"),
>>   points=list(pch=c(16,1), col="black"))
>>
>> datmeA <- aggregate(copy ~ positivity+stimulation, my.data, median, na.rm = T)
>>
>> stripplot(
>>       copy ~ factor(positivity)|factor(stimulation,
>>             levels = c("Unst.", "ESAT6","CFP10","Rv3615c", "Rv2654",
>> "Rv3879", "Rv3873","PHA")),
>>             group = positivity,
>>       my.data,
>>       hor=F,
>>       layout = c(8,1),
>>             scales = list(x = list(at = c(1,2), labels = c("N","P"))),
>>       jitter.data=TRUE, pch=c(16,1), col="black",
>>       ylab=expression(bold("Copy")),
>> xlab=expression(bold("Stimulation")), main="Plot",
>>       par.settings = list(strip.background=list(col="white")),
>>             par.strip.text=list(font=2),
>>       key = key.plot,
>>             panel = function(x, y){
>>               pnl = panel.number()
>>               panel.abline(h = datmeA[datmeA[,2]==
>>
>> levels(datmeA[,2])[pnl],"ratio"], col = c("red","black"), lty=3)
>>
>>               panel.stripplot(x,y, ...)
>>             }
>>       )
>>
>> On Sun, Apr 27, 2014 at 2:06 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>>> Hi Luigi
>>>
>>> You are typing things unnecessarily: do not use the attach command unless
>>> absolutely necessary - it has unfortunate consequences.
>>> It is better to use with or within.
>>> alpha is not available with some devices with bad consequences if used; its
>>> default is 1 anyway.
>>>
>>> Once you have stated a data.frame as the data object it is usually not
>>> necessary to use the data.frame$ sign in to signify column names: use the
>>> column names.
>>> data = "a data.frame" is the equivalent to with
>>>
>>> You are reordering the levels of stimulation and changing the name of 1 so I
>>> thought it was easiest to make a column stim and do things there otherwise
>>> it the relevelling could be done in the data argument using the subset
>>> argument. Then the change to "Unst" could be done by using  strip    =
>>> strip.custom(factor.levels = ...),
>>>
>>> To change for the -/+ I made a group - the easiest way.
>>> Have a look a changing the negative symbol to 20 or something else as it is
>>> hard to visualise. You may vary things with changing cex (remember to have 2
>>> values 1 for each group).
>>>
>>> If you do str(xyplot object) you will get a big print of the object and
>>> within that the x limits are shown as "0", "1" which means that the x values
>>> are 1 and 2
>>> There is a command to get these things but I have forgotten it
>>>
>>> my.data$stimulation <- factor(levels = c("Unstimulated",
>>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>>> my.data$stim <- factor(my.data$stimulation, labels = c("Unst.",
>>> "ESAT6","CFP10","Rv3615c","Rv2654", "Rv3879", "Rv3873","PHA"))
>>> my.data$pos <- ifelse(sign(my.data$copy) > 0, 2,1)
>>>
>>>   stripplot(copy ~ factor(positivity)|stim,my.data,
>>>             groups = pos,
>>>             hor = F,
>>>             layout = c(8,1),
>>>             scales = list(x = list(at = c(1,2),
>>>                                    labels = c("N","P"))),
>>>             jitter.x = TRUE,
>>>             amount = 2,
>>>             pch = c(16,1),
>>>             col = "black",
>>>             ylab = expression(bold("Copy")),
>>>             xlab = expression(bold("Stimulation")),
>>>             main="Plot",
>>>             par.settings = list(strip.background=list(col="white")),
>>> par.strip.text=list(font=2)
>>>             )
>>>
>>> Regards
>>>
>>> Duncan
>>>
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>>
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>>> Behalf Of Luigi Marongiu
>>> Sent: Sunday, 27 April 2014 02:07
>>> To: r-help at r-project.org
>>> Subject: [R] lattice plot formatting: pch, abbreviation and labels
>>>
>>> Dear all,
>>> I am trying to use the lattice plot, but the syntax is quite
>>> difficult. Specifically I have eight variables (1 to 8) each of them
>>> further subdivided in two classes (negative=0 and positive=1). I am
>>> using the stripplot() to represent these values. I would like to
>>> represent the negative and positive values with black and white dots
>>> so I have tried to use the argument pch=c(16, 1) both in the main
>>> stripplot function and embedded in the scale argument. However the
>>> resulting plot shows that some points are drawn with the pch=16 and
>>> other with pch=1 irrespective of their class.
>>> Is there a way to draw the values for the variable positivity = 0 with
>>> pch=16 and those with positivity = 1 with pch=0?
>>>
>>> In addition I would like to change the labels under the axis from 0,1
>>> to N,P. However when I placed labels=c("N", "P") or labels=list("N",
>>> "P") in the main stripplot() I did not obtained any difference and
>>> when placed within the scale argument also the -labels were modified.
>>> Is there a way to change the label 0 with N and the label 1 with P?
>>>
>>> final problem: I would like to abbreviate the "Unstimulated" box label
>>> with "Unst.". I have tried the abbreviate=TRUE argument but again the
>>> syntax is too complex for me and it did not work.
>>> Is there a way to abbreviate the variables names?
>>>
>>> Thank you very much for your help.
>>> Best wishes,
>>> Luigi
>>>
>>>
>>> CODE:::::::::
>>>
>>>
>>> ### open plot library
>>> library(lattice)
>>>
>>> my.data<-structure(list(
>>>    column_1 = 1:120,
>>>    column_2 = structure(c(
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8,
>>>  1,2,3,4,5,6,7,8), .Label = c("Unstimulated", "ESAT6", "CFP10",
>>> "Rv3615c", "Rv2654", "Rv3879", "Rv3873", "PHA"), class = "factor"),
>>>     column_3 = structure(c(
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 0,0,0,0,0,0,0,0,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 1,1,1,1,1,1,1,1,
>>> 0,0,0,0,0,0,0,0)),
>>>      column_4 = c(
>>>
>>> 192.0519108,183.6403531,53.46798757,83.60638077,69.60749873,159.4706861,256.
>>> 8765622,499.2899303,
>>>
>>> 2170.799076,1411.349719,2759.472348,2098.973397,2164.739515,1288.676574,1611
>>> .486543,6205.229575,
>>>
>>> 870.7424981,465.9967135,191.8962375,864.0937485,2962.693675,1289.259137,2418
>>> .651212,7345.712517,
>>>  0,168.1198893,674.4342961,101.1575401,47.81596237,0,0,1420.793922,
>>>
>>> 142.6871331,5.466468742,291.9564635,80.73914133,73.02239621,64.47806871,144.
>>> 3543635,3167.959757,
>>>
>>> 3164.748333,1092.634557,28733.20269,1207.87783,729.6090973,151.8706088,241.2
>>> 466141,9600.963594,
>>>
>>> 1411.718287,12569.96285,1143.254476,6317.378481,16542.27718,79.68025792,1958
>>> .495138,7224.503437,
>>>
>>> 208.4382941,69.48609769,656.691151,0.499017582,7114.910926,187.6296174,41.73
>>> 980805,8930.784541,
>>>
>>> 4.276752185,0.432300363,60.89228665,1.103924786,0.490686366,1.812993239,7.26
>>> 4531581,1518.610307,
>>>
>>> 2172.051528,595.8513744,17141.84336,589.6565971,1340.287628,117.350942,593.7
>>> 034054,24043.61463,
>>>
>>> 0,81.83292179,1539.864321,36.41722958,8.385131047,161.7647376,65.21615696,72
>>> 65.573875,
>>>
>>> 97.84753179,154.051827,0.613835842,10.06138851,45.04879285,176.8284258,18795
>>> .75462,30676.769,
>>>
>>> 5780.34957,944.2200834,2398.235596,1083.393165,2541.714557,1251.670895,1547.
>>> 178549,1792.679176,
>>>
>>> 3067.988416,8117.210173,23676.02226,8251.937547,17360.80494,18563.61561,1694
>>> 1.865,31453.96708,
>>>
>>> 2767.493803,4796.33016,12292.93705,3864.657567,9380.673835,14886.44683,8457.
>>> 88646,26050.47191)),
>>> .Names = c("row", "stimulation", "positivity", "copy"), row.names =
>>> c(NA, -120L),
>>>  class = "data.frame")
>>> attach(my.data)
>>>
>>> stripplot(my.data$copy ~
>>> factor(my.data$positivity)|factor(my.data$stimulation,
>>>             levels = c("Unstimulated", "ESAT6","CFP10","Rv3615c",
>>> "Rv2654", "Rv3879", "Rv3873","PHA")),
>>>             my.data, hor=F, layout = c(8,1), scales = list(relation =
>>> "same"),
>>>       jitter.data=TRUE, alpha=1, pch=c(16,1), col="black",
>>>       ylab=expression(bold("Copy")),
>>> xlab=expression(bold("Stimulation")), main="Plot",
>>>       par.settings = list(strip.background=list(col="white")),
>>>             par.strip.text=list(font=2))
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From holland.aggie at gmail.com  Tue Apr 29 20:46:23 2014
From: holland.aggie at gmail.com (James Holland)
Date: Tue, 29 Apr 2014 13:46:23 -0500
Subject: [R] plotGooglemaps - Problem with the legend.
Message-ID: <CABdaQ+uJy86yTAa6Hf3q8k4cse-xa5uDVMR=po02ryOjzFXoug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140429/d34420cb/attachment.pl>

From steven.vannoy at umb.edu  Tue Apr 29 21:47:30 2014
From: steven.vannoy at umb.edu (svannoy)
Date: Tue, 29 Apr 2014 12:47:30 -0700 (PDT)
Subject: [R] Extracting information from ROC??
Message-ID: <1398800850939-4689693.post@n4.nabble.com>

Hi,

I've used the ROC function from the Epi package to plot an ROC curve and
generate descriptive statistics (i.e. sensitivity, specificity, PPV, NPV)
for what ROC considers the best predictor score - this is done automatically
by ROC on the graph. What I want to do, is get these same descriptives for
other predictor scores.

Here is the code I've used:

ROC(stat=diseaseStatus, test=screenScore, cuts=c(3,4,6), PV=T)

This prints out the ROC curve. From prior exploration I know that ROC
identifies screenScore=5 as the "best" predictor score (sens=91.7%,
spec=88.9%, PPV=0.2%, NPV = 82.5%, I have a very low base rate disease).
When I use the "cuts" option, ROC adds those values to the graph (3.00,
4.00, 6.00) but does not print the descriptives for those predictor values.

I don't necessarily want them on the graph, I'm happy to just have the
descriptives for '5' on there, but I want to have access to the descriptives
for other values to build a typical table that presents the quantitative
comparison of values.

I haven't been able to figure out how to get access to those values. Also, I
have seen there are several packages capable of computing ROC stats, but I
haven't found what I want from any of them. I'm happy to use another one if
that is what you are familiar with.

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-information-from-ROC-tp4689693.html
Sent from the R help mailing list archive at Nabble.com.


From rameshdas.87 at gmail.com  Tue Apr 29 20:30:33 2014
From: rameshdas.87 at gmail.com (Ramesh Das)
Date: Wed, 30 Apr 2014 00:00:33 +0530
Subject: [R] Kindly help me
Message-ID: <CAEg8v3Y5ZEQvaHpD6o2DJGU_6kYC=wnav9+2Sp+PmVdhP=PXdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/23d23b6a/attachment.pl>

From mbressan at arpa.veneto.it  Wed Apr 30 08:36:38 2014
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Wed, 30 Apr 2014 08:36:38 +0200
Subject: [R] sum of two POSIXct objects: date and hour
In-Reply-To: <CAAxdm-5SyrmdRTRLAQj1LAVAMtC-txDiMLHRAWiL_MKRbDn+jw@mail.gmail.com>
References: <535FA3CD.3040107@arpa.veneto.it>	<CAAxdm-7Bew7wXqZAZT=Ag0w2cZdfat67=OEnjqzcDimTYNnyHg@mail.gmail.com>	<ddf4c37c923aa06878a99e60652ab76f.squirrel@89.96.234.216>
	<CAAxdm-5SyrmdRTRLAQj1LAVAMtC-txDiMLHRAWiL_MKRbDn+jw@mail.gmail.com>
Message-ID: <536099F6.1090707@arpa.veneto.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/70fe2024/attachment.pl>

From ruipbarradas at sapo.pt  Wed Apr 30 11:02:02 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 30 Apr 2014 10:02:02 +0100
Subject: [R] Kindly help me
In-Reply-To: <CAEg8v3Y5ZEQvaHpD6o2DJGU_6kYC=wnav9+2Sp+PmVdhP=PXdA@mail.gmail.com>
References: <CAEg8v3Y5ZEQvaHpD6o2DJGU_6kYC=wnav9+2Sp+PmVdhP=PXdA@mail.gmail.com>
Message-ID: <5360BC0A.3030901@sapo.pt>

Hello,

The package is Zelig, not zelig, R is case sensitive.
Try

install.packages("Zelig", dependencies = TRUE)


And can't you update your version of R? It's now R 3.1.0.

Hope this helps,

Rui Barradas

Em 29-04-2014 19:30, Ramesh Das escreveu:
> Dear all,
> I have a problem in installing the the package "zelig". I have window 32
> bit operating system and R- 3.0.1 version.  "zelig' package is not
> compatible with R-3.0.1 version. Please help me how to install the package
> "zelig" . If any other package is available in replace of "zelig', kindly
> suggest me.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wht_crl at yahoo.com  Wed Apr 30 13:41:47 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 30 Apr 2014 04:41:47 -0700
Subject: [R] position of a string in a data frame
Message-ID: <1398858107.6471.YahooMailNeo@web121504.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/42cb7e0e/attachment.pl>

From Jose-Marcio.Martins at mines-paristech.fr  Wed Apr 30 13:53:18 2014
From: Jose-Marcio.Martins at mines-paristech.fr (Jose-Marcio Martins)
Date: Wed, 30 Apr 2014 13:53:18 +0200
Subject: [R] R Cairo Installation - Cannot find cairo.h!
In-Reply-To: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
References: <CAB-BZ9J-k2+gMfWocBFy+gxABeS14Ob_27xz_jnxgKjF64YQsw@mail.gmail.com>
Message-ID: <5360E42E.1030200@mines-paristech.fr>


Hi,

On 04/28/2014 09:26 PM, Fong Chun Chan wrote:
>
> ./configure --prefix=/home/fong/usr/local
>
> I set the my CAIRO_LIBS and CAIRO_CLAGS environment variables in my
> ~/.bashrc:
>
> export CAIRO_LIBS=${HOME}/usr/local/lib
> export CAIRO_CFLAGS=${HOME}/usr/local/include

maybe

export CAIRO_LIBS=-L${HOME}/usr/local/lib
export CAIRO_CFLAGS=-I${HOME}/usr/local/include

Regards,

Jos?-Marcio


From frtog at vestas.com  Wed Apr 30 14:02:40 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 30 Apr 2014 14:02:40 +0200
Subject: [R] position of a string in a data frame
In-Reply-To: <1398858107.6471.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1398858107.6471.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C5F4B9EF@DKRDSEXC016.vestas.net>

Try

 > foo <- data.frame(oid = 1:3, functions = c("mean", "sum", "sd"), type = c(TRUE, FALSE, TRUE))

> foo
  oid functions  type
1   1      mean  TRUE
2   2       sum FALSE
3   3        sd  TRUE

> foo == "sum"
       oid functions  type
[1,] FALSE     FALSE FALSE
[2,] FALSE      TRUE FALSE
[3,] FALSE     FALSE FALSE

> which(foo == "sum", arr.ind = TRUE)
     row col
[1,]   2   2
>

But can one risk this to fail if the class of some of the columns cannot be compared to a string?????

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of carol white
> Sent: 30. april 2014 13:42
> To: r-help at stat.math.ethz.ch
> Subject: [R] position of a string in a data frame
> 
> Hi,
> It might be a primitive question but how to find the position of a string in a
> data frame? Suppose I search the word "sum" (case insensitive) in a data
> frame and it is in the 7th row, 3rd column, how to retrieve the indices 7, 3? I
> tried to use grep with tapply but it doesn't work.
> 
> Many thanks
> 
> Carol
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Apr 30 14:12:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Apr 2014 08:12:37 -0400
Subject: [R] position of a string in a data frame
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C5F4B9EF@DKRDSEXC016.vestas.net>
References: <1398858107.6471.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C5F4B9EF@DKRDSEXC016.vestas.net>
Message-ID: <5360E8B5.5010803@gmail.com>

On 30/04/2014, 8:02 AM, Frede Aakmann T?gersen wrote:
> Try
>
>   > foo <- data.frame(oid = 1:3, functions = c("mean", "sum", "sd"), type = c(TRUE, FALSE, TRUE))
>
>> foo
>    oid functions  type
> 1   1      mean  TRUE
> 2   2       sum FALSE
> 3   3        sd  TRUE
>
>> foo == "sum"
>         oid functions  type
> [1,] FALSE     FALSE FALSE
> [2,] FALSE      TRUE FALSE
> [3,] FALSE     FALSE FALSE
>
>> which(foo == "sum", arr.ind = TRUE)
>       row col
> [1,]   2   2
>>
>
> But can one risk this to fail if the class of some of the columns cannot be compared to a string?????

Yes, if some class declares that it's an error to compare it to a 
string, this could fail.

For example,

 > `==.foo` <- function(a, b) stop("don't do that")
 >
 > df <- data.frame(a=1)
 > class(df$a) <- "foo"
 > df == "abc"
Error in `==.foo`(left, right) : don't do that

The basic types allow comparison to strings.

Duncan Murdoch

>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of carol white
>> Sent: 30. april 2014 13:42
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] position of a string in a data frame
>>
>> Hi,
>> It might be a primitive question but how to find the position of a string in a
>> data frame? Suppose I search the word "sum" (case insensitive) in a data
>> frame and it is in the 7th row, 3rd column, how to retrieve the indices 7, 3? I
>> tried to use grep with tapply but it doesn't work.
>>
>> Many thanks
>>
>> Carol
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Wed Apr 30 14:29:24 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 30 Apr 2014 22:29:24 +1000
Subject: [R] position of a string in a data frame
In-Reply-To: <5360E8B5.5010803@gmail.com>
References: <1398858107.6471.YahooMailNeo@web121504.mail.ne1.yahoo.com>	<B078CDF40DFE4045AF172A8B4F68FC4857C5F4B9EF@DKRDSEXC016.vestas.net>
	<5360E8B5.5010803@gmail.com>
Message-ID: <5360ECA4.3010804@bitwrit.com.au>

How about:

testdf<-data.frame(names=c("min","max","sum"),a=1:3,b=4:6,c=c(5,7,9))
which(tolower(as.matrix(testdf)) == "sum",arr.ind=TRUE)
      row col
[1,]   3   1

as.matrix coerces all elements to the lowest (character) mode, no?
Does it unclass anything like the example below?

Jim


On 04/30/2014 10:12 PM, Duncan Murdoch wrote:
> On 30/04/2014, 8:02 AM, Frede Aakmann T?gersen wrote:
>> Try
>>
>> > foo <- data.frame(oid = 1:3, functions = c("mean", "sum", "sd"),
>> type = c(TRUE, FALSE, TRUE))
>>
>>> foo
>> oid functions type
>> 1 1 mean TRUE
>> 2 2 sum FALSE
>> 3 3 sd TRUE
>>
>>> foo == "sum"
>> oid functions type
>> [1,] FALSE FALSE FALSE
>> [2,] FALSE TRUE FALSE
>> [3,] FALSE FALSE FALSE
>>
>>> which(foo == "sum", arr.ind = TRUE)
>> row col
>> [1,] 2 2
>>>
>>
>> But can one risk this to fail if the class of some of the columns
>> cannot be compared to a string?????
>
> Yes, if some class declares that it's an error to compare it to a
> string, this could fail.
>
> For example,
>
>  > `==.foo` <- function(a, b) stop("don't do that")
>  >
>  > df <- data.frame(a=1)
>  > class(df$a) <- "foo"
>  > df == "abc"
> Error in `==.foo`(left, right) : don't do that
>
> The basic types allow comparison to strings.
>
> Duncan Murdoch
>
>>
>> Yours sincerely / Med venlig hilsen
>>
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On Behalf Of carol white
>>> Sent: 30. april 2014 13:42
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] position of a string in a data frame
>>>
>>> Hi,
>>> It might be a primitive question but how to find the position of a
>>> string in a
>>> data frame? Suppose I search the word "sum" (case insensitive) in a data
>>> frame and it is in the 7th row, 3rd column, how to retrieve the
>>> indices 7, 3? I
>>> tried to use grep with tapply but it doesn't work.
>>>
>>> Many thanks
>>>
>>> Carol
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenz at usgs.gov  Wed Apr 30 14:57:38 2014
From: lorenz at usgs.gov (Lorenz, David)
Date: Wed, 30 Apr 2014 07:57:38 -0500
Subject: [R] Simulative data production
Message-ID: <CALxY2LcxHk1ap6dqaUOveaUnNeMGJnSg3K=fY7VQsmCczKAkeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/ab909f47/attachment.pl>

From smartpink111 at yahoo.com  Wed Apr 30 15:22:00 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Apr 2014 06:22:00 -0700 (PDT)
Subject: [R] R: re:  dataframe
In-Reply-To: <1671478323.12497561398860966390.JavaMail.actor@webmail48>
References: <1671478323.12497561398860966390.JavaMail.actor@webmail48>
Message-ID: <1398864120.16878.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi James,

I guess the problem was because the columns you tried were factors.
Suppose `dat1` is your dataset (first).
library(stringr)
indx <- grep("sample", colnames(dat1))
toGrep <- read.table(text = str_trim(gsub("[sample.]", " ", colnames(dat1)[indx])), 
??? header = FALSE, stringsAsFactors = FALSE)
dat1New <- dat1? 
indx2 <- grep("^o", colnames(dat1New))
dat1New[indx2] <- lapply(dat1New[indx2], as.character)
lst1 <- lapply(seq_len(nrow(toGrep)), function(i) {
??? indx3 <- intersect(grep(toGrep[i, 1], dat1New), grep(paste0("\\b", toGrep[i, 
??????? 2], "\\b"), dat1New))
??? indx4 <- grep(paste(toGrep[i, ], collapse = "."), colnames(dat1New))
??? indx5 <- which(!seq(ncol(dat1New)) %in% c(indx, indx2))
??? dat1New[, sort(c(indx3, indx4, indx5)), drop = FALSE]
})
names(lst1) <- as.character(interaction(toGrep, sep = "."))

Here, I assumed that you wanted only the particular "sample...", column along with the subset.

?lapply(lst1,names)[[1]]
?[1] "X"??????????????????????????? "rt"????????????????????????? 
?[3] "mz"?????????????????????????? "o066_010"??????????????????? 
?[5] "o066_022"???????????????????? "o066_029"??????????????????? 
?[7] "o066_034"???????????????????? "o066_068"??????????????????? 
?[9] "o066_072"???????????????????? "o066_079"??????????????????? 
[11] "o066_081"???????????????????? "o066_086"??????????????????? 
[13] "pspectrum"??????????????????? "isotopes"??????????????????? 
[15] "adduct"?????????????????????? "mzmin"?????????????????????? 
[17] "mzmax"??????????????????????? "rtmin"?????????????????????? 
[19] "rtmax"??????????????????????? "npeaks"????????????????????? 
[21] "sample.Au5.C"???????????????? "X2W.p.value.Nanoparticle"??? 
[23] "X2W.p.value.Treatment"??????? "X2W.adj.p.value.Nanoparticle"
[25] "X2W.adj.p.value.\nTreatment"? "Metlin"????????????????????? 
[27] "HMDBtag"????????????????????? "HMDBinfo"????? 
A.K.



On Wednesday, April 30, 2014 8:29 AM, "pascalbells at libero.it" <pascalbells at libero.it> wrote:
Hi, thank you again for your help....

here is the dput:

structure(list(X = structure(c(8L, 7L, 9L, 1L), .Label = c("61/195", 
"69/954", "72/300", "73/300", "74/946", "76/611", "Nanoparticle", 
"SampleName", "Treatment"), class = "factor"), rt = c(NA, NA, 
NA, 195.09555), mz = c(NA, NA, NA, 61.00722661), o066_010 = structure(c(9L, 
7L, 8L, 2L), .Label = c("14043676.02", "14536204.77", "17652481.49", 
"5212485.416", "6731535.564", "9876651.476", "Au5", "C", "sample"
), class = "factor"), o066_019 = structure(c(9L, 7L, 8L, 3L), .Label = c
("10023255.04", 
"15073569.61", "15473173.22", "28708474.98", "5633388.668", "7154698.204", 
"Au5", "H", "sample"), class = "factor"), o066_022 = structure(c(9L, 
7L, 8L, 2L), .Label = c("10087537.1", "13846871.69", "14528006.42", 
"18458758.83", "5383022.265", "6577623.782", "Au5", "C", "sample"
), class = "factor"), o066_023 = structure(c(9L, 7L, 8L, 1L), .Label = c
("15723091.09", 
"17023369.3", "18462299.71", "4996777.375", "6987554.082", "9174926.395", 
"Au5", "L", "sample"), class = "factor"), o066_024 = structure(c(9L, 
7L, 8L, 1L), .Label = c("14367825.89", "16698747.9", "18696653.21", 
"5025690.383", "6930208.708", "9736032.197", "Au32", "M", "sample"
), class = "factor"), o066_025 = structure(c(9L, 7L, 8L, 1L), .Label = c
("14488608.39", 
"17814216.17", "18698120.65", "4950983.925", "7193018.533", "8061360.256", 
"Au32", "M", "sample"), class = "factor"), o066_029 = structure(c(9L, 
7L, 8L, 2L), .Label = c("11915681.99", "13140449.17", "16980818.81", 
"5529195.67", "7045157.096", "9792452.409", "Au5", "C", "sample"
), class = "factor"), o066_032 = structure(c(9L, 7L, 8L, 1L), .Label = c
("14598638.42", 
"17574435.2", "18133608.77", "5440291.241", "6145144.579", "6754867.22", 
"Au32", "C", "sample"), class = "factor"), o066_034 = structure(c(9L, 
7L, 8L, 1L), .Label = c("14979396.48", "18783422.61", "18944230.28", 
"5058848.793", "6240890.066", "7253951.112", "Au5", "C", "sample"
), class = "factor"), o066_039 = structure(c(9L, 7L, 8L, 1L), .Label = c
("14540874.05", 
"17997589.68", "18808525.49", "4923318.003", "4989990.142", "6943084.118", 
"Au32", "C", "sample"), class = "factor"), o066_049 = structure(c(9L, 
7L, 8L, 1L), .Label = c("13904244.76", "17285116.29", "18378290.63", 
"5578459.181", "6817168.77", "6956602.05", "Au32", "H", "sample"
), class = "factor"), o066_052 = structure(c(9L, 7L, 8L, 1L), .Label = c
("14351098.41", 
"16914393.93", "27503386.81", "6337197.417", "7047144.652", "8204323.852", 
"Au5", "H", "sample"), class = "factor"), o066_055 = structure(c(9L, 
7L, 8L, 1L), .Label = c("13906338.32", "15282046.89", "18357761.85", 
"5612493.227", "5990567.16", "6541120.91", "Au32", "L", "sample"
), class = "factor"), o066_056 = structure(c(9L, 7L, 8L, 1L), .Label = c
("13198308.2", 
"16943030.55", "24819426.73", "5794416.907", "6526930.135", "6965902.611", 
"Au5", "M", "sample"), class = "factor"), o066_057 = structure(c(9L, 
7L, 8L, 1L), .Label = c("13553932.63", "16650323.6", "23887991.99", 
"4978191.783", "6498421.044", "7482551.482", "Au5", "M", "sample"
), class = "factor"), o066_060 = structure(c(9L, 7L, 8L, 1L), .Label = c
("12757675.44", 
"14478961.76", "17693417", "5688587.416", "6278360.393", "6778930.512", 
"Au32", "C", "sample"), class = "factor"), o066_062 = structure(c(9L, 
7L, 8L, 1L), .Label = c("12566817.06", "16230428.36", "18310198.43", 
"4929894.983", "6051669.256", "6893438.406", "Au32", "C", "sample"
), class = "factor"), o066_063 = structure(c(9L, 7L, 8L, 1L), .Label = c
("12765436.23", 
"15664549.3", "18880700.09", "5012562.077", "5653516.005", "6891139.714", 
"Au5", "L", "sample"), class = "factor"), o066_068 = structure(c(9L, 
7L, 8L, 2L), .Label = c("10077274.11", "11533763.33", "11914610.67", 
"17481826.33", "5118520.628", "5722064.277", "Au5", "C", "sample"
), class = "factor"), o066_072 = structure(c(9L, 7L, 8L, 1L), .Label = c
("12506876.82", 
"15059553.41", "17963658.12", "5147251.947", "5936120.075", "6757510.158", 
"Au5", "C", "sample"), class = "factor"), o066_075 = structure(c(9L, 
7L, 8L, 1L), .Label = c("12629327.74", "14157915.9", "17676966.26", 
"5507872.857", "5772060.453", "6460845.336", "Au5", "L", "sample"
), class = "factor"), o066_077 = structure(c(9L, 7L, 8L, 1L), .Label = c
("11424841.46", 
"13873092.31", "16264095.9", "5139882.469", "5267420.049", "6093969.775", 
"Au32", "C", "sample"), class = "factor"), o066_079 = structure(c(9L, 
7L, 8L, 1L), .Label = c("11310021.96", "12817107.8", "16850943.65", 
"4790059.15", "5497826.813", "6272350.228", "Au5", "C", "sample"
), class = "factor"), o066_080 = structure(c(9L, 7L, 8L, 1L), .Label = c
("10962613.96", 
"12999912.78", "17414255.92", "5079434.424", "5790847.752", "6285463.247", 
"Au32", "C", "sample"), class = "factor"), o066_081 = structure(c(9L, 
7L, 8L, 1L), .Label = c("10716085.25", "12783977.19", "17139019.04", 
"5316270.963", "5477933.375", "5939018.303", "Au5", "C", "sample"
), class = "factor"), o066_082 = structure(c(9L, 7L, 8L, 1L), .Label = c
("11020219.13", 
"12911640.64", "17298440.71", "5292075.669", "5608730.99", "5950511.372", 
"Au32", "C", "sample"), class = "factor"), o066_084 = structure(c(9L, 
7L, 8L, 1L), .Label = c("11254185.62", "14433261.34", "17602305.5", 
"4220138.319", "4802246.445", "6580756.431", "Au32", "C", "sample"
), class = "factor"), o066_086 = structure(c(9L, 7L, 8L, 6L), .Label = c
("13251623.05", 
"17376126.66", "4975858.829", "5877369.947", "6459614.347", "9956435.681", 
"Au5", "C", "sample"), class = "factor"), o066_087 = structure(c(9L, 
7L, 8L, 1L), .Label = c("11090591.08", "12481560.98", "17685195.53", 
"4976028.139", "5729221.367", "5866020.444", "Au32", "H", "sample"
), class = "factor"), o066_090 = structure(c(9L, 7L, 8L, 1L), .Label = c
("12039292.87", 
"13766587.51", "17661480.62", "4105603.641", "4892418.995", "6364759.427", 
"Au32", "M", "sample"), class = "factor"), o066_093 = structure(c(9L, 
7L, 8L, 1L), .Label = c("11050848.78", "14300477", "17455404.65", 
"4944754.379", "5314318.706", "6132171.794", "Au32", "L", "sample"
), class = "factor"), o066_101 = structure(c(9L, 7L, 8L, 1L), .Label = c
("10569492.27", 
"12736422.09", "16216119.36", "4941484.876", "5716315.813", "5888895.838", 
"Au32", "C", "sample"), class = "factor"), o066_102 = structure(c(9L, 
7L, 8L, 1L), .Label = c("10004456.65", "13327035.46", "16746388.21", 
"4074210.702", "5464246.567", "6303763.552", "Au32", "L", "sample"
), class = "factor"), o066_103 = structure(c(9L, 7L, 8L, 1L), .Label = c
("10248532.42", 
"12683248.9", "25351553.76", "5103432.052", "6204859.229", "6370345.756", 
"Au5", "H", "sample"), class = "factor"), o066_104 = structure(c(9L, 
7L, 8L, 6L), .Label = c("14115821.79", "16849972.37", "4717878.989", 
"6440223.441", "8546766.206", "9957099.225", "Au32", "H", "sample"
), class = "factor"), o066_105 = structure(c(9L, 7L, 8L, 1L), .Label = c
("11382449.23", 
"15148302.74", "22676887.88", "5267156.789", "5970593.031", "6526962.522", 
"Au5", "M", "sample"), class = "factor"), pspectrum = c(NA, NA, 
NA, 24L), isotopes = c(NA, NA, NA, NA), adduct = structure(c(1L, 
1L, 1L, 1L), .Label = c("", "[M+H]+ 72.0781", "[M+Na]+ 51"), class = 
"factor"), 
? ? mzmin = c(NA, NA, NA, 61.00708832), mzmax = c(NA, NA, NA, 
? ? 61.00730019), rtmin = c(NA, NA, NA, 194.0899), rtmax = c(NA, 
? ? NA, NA, 196.0904), npeaks = c(NA, NA, NA, 36L), sample.Au5.C = c(NA, 
? ? NA, NA, 9L), sample.Au5.H = c(NA, NA, NA, 9L), sample.Au5.L = c(NA, 
? ? NA, NA, 3L), sample.Au32.M = c(NA, NA, NA, 3L), sample.Au32.C = c(NA, 
? ? NA, NA, 3L), sample.Au32.H = c(NA, NA, NA, 3L), sample.Au32.L = c(NA, 
? ? NA, NA, 3L), sample.Au5.M = c(NA, NA, NA, 3L), X2W.p.value.Nanoparticle = c
(NA, 
? ? NA, NA, 0.291527766), X2W.p.value.Treatment = c(NA, NA, NA, 
? ? 0.79589541), X2W.adj.p.value.Nanoparticle = c(NA, NA, NA, 
? ? 0.453622043), X2W.adj.p.value.Treatment = c(NA, NA, NA, 0.870148042
? ? ), Metlin = structure(c(1L, 1L, 1L, 2L), .Label = c("", "http://metlin.
scripps.edu/metabo_list.php?mass_min=59.95&mass_max=60.05", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=67.936&mass_max=68.
036", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=71.024&mass_max=71.
124", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=72.027&mass_max=72.
127", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=72.932&mass_max=73.
032", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=74.982&mass_max=75.
082"
? ? ), class = "factor"), HMDBtag = structure(c(1L, 1L, 1L, 1L
? ? ), .Label = c("", "HMDB00123, HMDB00925, HMDB12136"), class = "factor"), 
? ? HMDBinfo = c(NA_integer_, NA_integer_, NA_integer_, NA_integer_
? ? )), .Names = c("X", "rt", "mz", "o066_010", "o066_019", "o066_022", 
"o066_023", "o066_024", "o066_025", "o066_029", "o066_032", "o066_034", 
"o066_039", "o066_049", "o066_052", "o066_055", "o066_056", "o066_057", 
"o066_060", "o066_062", "o066_063", "o066_068", "o066_072", "o066_075", 
"o066_077", "o066_079", "o066_080", "o066_081", "o066_082", "o066_084", 
"o066_086", "o066_087", "o066_090", "o066_093", "o066_101", "o066_102", 
"o066_103", "o066_104", "o066_105", "pspectrum", "isotopes", 
"adduct", "mzmin", "mzmax", "rtmin", "rtmax", "npeaks", "sample.Au5.C", 
"sample.Au5.H", "sample.Au5.L", "sample.Au32.M", "sample.Au32.C", 
"sample.Au32.H", "sample.Au32.L", "sample.Au5.M", "X2W.p.value.Nanoparticle", 
"X2W.p.value.Treatment", "X2W.adj.p.value.Nanoparticle", "X2W.adj.p.value.
Treatment", 
"Metlin", "HMDBtag", "HMDBinfo"), row.names = c(NA, 4L), class = "data.frame")

>
??? 
I would like to arrange all the columns that match "Au5" and "C", as you can 
see below:


> dput(head(tabella,4))
structure(list(X = structure(c(8L, 7L, 9L, 1L), .Label = c("61/195", 
"69/954", "72/300", "73/300", "74/946", "76/611", "Nanoparticle", 
"SampleName", "Treatment"), class = "factor"), rt = c(NA, NA, 
NA, 195.09555), mz = c(NA, NA, NA, 61.00722661), o066_010 = structure(c(9L, 
7L, 8L, 2L), .Label = c("14043676.02", "14536204.77", "17652481.49", 
"5212485.416", "6731535.564", "9876651.476", "Au5", "C", "sample"
), class = "factor"), o066_022 = structure(c(9L, 7L, 8L, 2L), .Label = c
("10087537.1", 
"13846871.69", "14528006.42", "18458758.83", "5383022.265", "6577623.782", 
"Au5", "C", "sample"), class = "factor"), o066_029 = structure(c(9L, 
7L, 8L, 2L), .Label = c("11915681.99", "13140449.17", "16980818.81", 
"5529195.67", "7045157.096", "9792452.409", "Au5", "C", "sample"
), class = "factor"), o066_034 = structure(c(9L, 7L, 8L, 1L), .Label = c
("14979396.48", 
"18783422.61", "18944230.28", "5058848.793", "6240890.066", "7253951.112", 
"Au5", "C", "sample"), class = "factor"), o066_068 = structure(c(9L, 
7L, 8L, 2L), .Label = c("10077274.11", "11533763.33", "11914610.67", 
"17481826.33", "5118520.628", "5722064.277", "Au5", "C", "sample"
), class = "factor"), o066_072 = structure(c(9L, 7L, 8L, 1L), .Label = c
("12506876.82", 
"15059553.41", "17963658.12", "5147251.947", "5936120.075", "6757510.158", 
"Au5", "C", "sample"), class = "factor"), o066_077 = structure(c(9L, 
7L, 8L, 1L), .Label = c("11424841.46", "13873092.31", "16264095.9", 
"5139882.469", "5267420.049", "6093969.775", "Au32", "C", "sample"
), class = "factor"), o066_079 = structure(c(9L, 7L, 8L, 1L), .Label = c
("11310021.96", 
"12817107.8", "16850943.65", "4790059.15", "5497826.813", "6272350.228", 
"Au5", "C", "sample"), class = "factor"), o066_080 = structure(c(9L, 
7L, 8L, 6L), .Label = c("13251623.05", "17376126.66", "4975858.829", 
"5877369.947", "6459614.347", "9956435.681", "Au5", "C", "sample"
), class = "factor"), o066_102 = structure(c(8L, 1L, 1L, 3L), .Label = c("", 
"159", "24", "40", "6", "65", "91", "sample"), class = "factor"), 
? ? o066_103 = structure(c(2L, 1L, 1L, 1L), .Label = c("", "sample"
? ? ), class = "factor"), o066_104 = structure(c(4L, 1L, 1L, 
? ? 1L), .Label = c("", "[M+H]+ 72.0781", "[M+Na]+ 51", "sample"
? ? ), class = "factor"), o066_105 = structure(c(8L, 1L, 1L, 
? ? 2L), .Label = c("", "61.00708832", "68.9930209", "72.08063445", 
? ? "73.08397527", "73.98878773", "76.03904924", "sample"), class = 
"factor"), 
? ? pspectrum = c(NA, NA, NA, 61.00730019), isotopes = c(NA, 
? ? NA, NA, 194.0899), adduct = c(NA, NA, NA, 196.0904), mzmin = c(NA, 
? ? NA, NA, 36L), mzmax = c(NA, NA, NA, 9L), rtmin = c(NA, NA, 
? ? NA, 9L), rtmax = c(NA, NA, NA, 3L), npeaks = c(NA, NA, NA, 
? ? 3L), sample.Au5.C = c(NA, NA, NA, 3L), sample.Au5.H = c(NA, 
? ? NA, NA, 3L), sample.Au5.L = c(NA, NA, NA, 3L), sample.Au32.M = c(NA, 
? ? NA, NA, 3L), sample.Au32.C = c(NA, NA, NA, 0.291527766), 
? ? sample.Au32.H = c(NA, NA, NA, 0.79589541), sample.Au32.L = c(NA, 
? ? NA, NA, 0.453622043), sample.Au5.M = c(NA, NA, NA, 0.870148042
? ? ), X2W.p.value.Nanoparticle = structure(c(1L, 1L, 1L, 2L), .Label = c("", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=59.95&mass_max=60.
05", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=67.936&mass_max=68.
036", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=71.024&mass_max=71.
124", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=72.027&mass_max=72.
127", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=72.932&mass_max=73.
032", 
? ? "http://metlin.scripps.edu/metabo_list.php?mass_min=74.982&mass_max=75.
082"
? ? ), class = "factor"), X2W.p.value.Treatment = structure(c(1L, 
? ? 1L, 1L, 1L), .Label = c("", "HMDB00123, HMDB00925, HMDB12136"
? ? ), class = "factor"), X2W.adj.p.value.Nanoparticle = c(NA_integer_, 
? ? NA_integer_, NA_integer_, NA_integer_), X2W.adj.p.value.Treatment = c(NA, 
? ? NA, NA, NA), Metlin = c(NA, NA, NA, NA), HMDBtag = c(NA, 
? ? NA, NA, NA), HMDBinfo = c(NA, NA, NA, NA)), .Names = c("X", 
"rt", "mz", "o066_010", "o066_022", "o066_029", "o066_034", "o066_068", 
"o066_072", "o066_077", "o066_079", "o066_080", "o066_102", "o066_103", 
"o066_104", "o066_105", "pspectrum", "isotopes", "adduct", "mzmin", 
"mzmax", "rtmin", "rtmax", "npeaks", "sample.Au5.C", "sample.Au5.H", 
"sample.Au5.L", "sample.Au32.M", "sample.Au32.C", "sample.Au32.H", 
"sample.Au32.L", "sample.Au5.M", "X2W.p.value.Nanoparticle", 
"X2W.p.value.Treatment", "X2W.adj.p.value.Nanoparticle", "X2W.adj.p.value.
Treatment", 
"Metlin", "HMDBtag", "HMDBinfo"), row.names = c(NA, 4L), class = "data.frame")




I want to arrange all the columns that match with Au5 and C,? 

then Au5 and L

then Au5 and H

then Au5 and M

and so on....

and do the same with Au32....

Just reordering the columns,matching the patterns above.

But I would be happy just with Au5 and C.

Thanks a lot

James

>----Messaggio originale----
>Da: smartpink111 at yahoo.com
>Data: 30/04/2014 11.02
>A: "pascalbells at libero.it"<pascalbells at libero.it>
>Ogg: re: [R] dataframe
>
>Could you dput the dataset?
>Also,the expected result...
>
>----------
>Sent from my Nokia
>
>------Original message------
>From: pascalbells at libero.it <pascalbells at libero.it>
>To: <smartpink111 at yahoo.com>
>Date: Wednesday, April 30, 2014 9:40:06 AM GMT+0200
>Subject: R: Re: [R] dataframe
>
>thank you for your help but it doesn't work....
>
>James
>
>
>
>>----Messaggio originale----
>>Da: smartpink111 at yahoo.com
>>Data: 29/04/2014 17.59
>>A: "r-help at r-project.org"<r-help at r-project.org>
>>Cc: "pascalbells at libero.it"<pascalbells at libero.it>
>>Ogg: Re: [R] dataframe
>>
>>Hi,
>>
>>It is better to show example data using ?dput().
>>
>>dat <- structure(list(row.names = 1:4, XYZ = c("sample", "sample2", 
>>"sample3", "sample4"), `000_001` = c("sample", "Au5", "C", "C"
>>), `000_002` = c("sample", "Au32", "C", "Au4"), `000_003` = c("sample", 
>>"Au5", "A", "AC")), .Names = c("row.names", "XYZ", "000_001", 
>>"000_002", "000_003"), class = "data.frame", row.names = c(NA, 
>>-4L))
>>
>>
>>dat[,intersect(grep("Au5", dat), grep("\\bC\\b",dat)),drop=FALSE]
>>#? 000_001
>>#1? sample
>>#2???? Au5
>>#3?????? C
>>#4?????? C
>>
>>A.K.
>>
>>
>>
>>
>>On Tuesday, April 29, 2014 9:45 AM, "pascalbells at libero.it" 
><pascalbells at libero.it> wrote:
>>Hello, 
>>thank you for accepting me into the list.
>>
>>I have the following dataframe:
>>
>>?? row.names? X? ? ? ? ?? Y? ? ?? Z? ?? 000_001? 000_002? 000_003
>>1? ? ? ? ? ? ? ? ? ? sample? ? ? ? ? ? ? ? ? ?? sample? ? sample? ?? sample
>>2? ? ? ? ? ? ? ? ? ? sample2? ? ? ? ? ? ? ? ?? Au5? ? ? ?? Au32? ? ?? Au5
>>3? ? ? ? ? ? ? ? ? ? sample3? ? ? ? ? ? ? ? ?? C? ? ? ? ? ? ? C? ? ? ? ? ?? 
C
>>4? ? ? ? ? ? ? ? ? ? ..........? 
>>..
>>..

>n? ? ? ? ? ? ? ? ? ? ...........? ? ? ? ? ? ? ? ? ? ....? ? ? ? ? ? .......? ? ? ?? 
>............
>>
>>
>>I would like to select al the columns that have Au5 and C.
>>thank you in advance for your help,
>>james
>>
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
>


From smartpink111 at yahoo.com  Wed Apr 30 15:49:33 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Apr 2014 06:49:33 -0700 (PDT)
Subject: [R] R: re:  dataframe
In-Reply-To: <1398865705.74776.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <42421687.12529241398862652391.JavaMail.actor@webmail48>
	<1398865705.74776.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1398865773.6332.YahooMailNeo@web142603.mail.bf1.yahoo.com>




Hi,


In this case, you may have to use:
?dat1[sapply(dat1,function(x) any(grepl("\\bC\\b",x))) & sapply(dat1,function(x) any(grepl("Au5",x)))]
???? o066_010??? o066_022??? o066_029??? o066_034??? o066_068??? o066_072
1????? sample????? sample????? sample????? sample????? sample????? sample
2???????? Au5???????? Au5???????? Au5???????? Au5???????? Au5???????? Au5
3?????????? C?????????? C?????????? C?????????? C?????????? C?????????? C
4 14536204.77 13846871.69 13140449.17 14979396.48 11533763.33 12506876.82
???? o066_079??? o066_081??? o066_086
1????? sample????? sample????? sample
2???????? Au5???????? Au5???????? Au5
3?????????? C?????????? C?????????? C
4 11310021.96 10716085.25 9956435.681


## using all the combinations
indxNew <- read.table(text = unique(apply(dat1[2:3, grep("^o", colnames(dat1))], 
??? 2, paste, collapse = " ")), sep = "", header = FALSE, stringsAsFactors = FALSE)

lapply(seq_len(nrow(indxNew)), function(i) {
??? indx1 <- which(sapply(dat1, function(x) any(grepl(indxNew[i, 1], x))) & sapply(dat1, 
??????? function(x) any(grepl(paste0("\\b", indxNew[i, 2], "\\b"), x))))
??? dat1[indx1]
})



#You can add the other columns in the dataset as I showed in the previous email.


A.K.



On Wednesday, April 30, 2014 8:57 AM, "pascalbells at libero.it" <pascalbells at libero.it> wrote:

I've tried this one and it works:


df[sapply(df, function(x) any(grepl("Au5", x)))]



but How to write also that I want "C" too?

regards,

james



>----Messaggio originale----
>Da: smartpink111 at yahoo.com
>Data: 30/04/2014 11.02
>A: "pascalbells at libero.it"<pascalbells at libero.it>
>Ogg: re: [R] dataframe
>
>Could you dput the dataset?
>Also,the expected result...
>
>----------
>Sent from my Nokia
>
>------Original message------
>From: pascalbells at libero.it <pascalbells at libero.it>
>To: <smartpink111 at yahoo.com>
>Date: Wednesday, April 30, 2014 9:40:06 AM GMT+0200
>Subject: R: Re: [R] dataframe
>
>thank you for your help but it doesn't work....
>
>James
>
>
>
>>----Messaggio originale----
>>Da: smartpink111 at yahoo.com
>>Data: 29/04/2014 17.59
>>A: "r-help at r-project.org"<r-help at r-project.org>
>>Cc: "pascalbells at libero.it"<pascalbells at libero.it>
>>Ogg: Re: [R] dataframe
>>
>>Hi,
>>
>>It is better to show example data using ?dput().
>>
>>dat <- structure(list(row.names = 1:4, XYZ = c("sample", "sample2", 
>>"sample3", "sample4"), `000_001` = c("sample", "Au5", "C", "C"
>>), `000_002` = c("sample", "Au32", "C", "Au4"), `000_003` = c("sample", 
>>"Au5", "A", "AC")), .Names = c("row.names", "XYZ", "000_001", 
>>"000_002", "000_003"), class = "data.frame", row.names = c(NA, 
>>-4L))
>>
>>
>>dat[,intersect(grep("Au5", dat), grep("\\bC\\b",dat)),drop=FALSE]
>>#? 000_001
>>#1? sample
>>#2???? Au5
>>#3?????? C
>>#4?????? C
>>
>>A.K.
>>
>>
>>
>>
>>On Tuesday, April 29, 2014 9:45 AM, "pascalbells at libero.it" 
><pascalbells at libero.it> wrote:
>>Hello, 
>>thank you for accepting me into the list.
>>
>>I have the following dataframe:
>>
>>?? row.names? X? ? ? ? ?? Y? ? ?? Z? ?? 000_001? 000_002? 000_003
>>1? ? ? ? ? ? ? ? ? ? sample? ? ? ? ? ? ? ? ? ?? sample? ? sample? ?? sample
>>2? ? ? ? ? ? ? ? ? ? sample2? ? ? ? ? ? ? ? ?? Au5? ? ? ?? Au32? ? ?? Au5
>>3? ? ? ? ? ? ? ? ? ? sample3? ? ? ? ? ? ? ? ?? C? ? ? ? ? ? ? C? ? ? ? ? ?? 
C
>>4? ? ? ? ? ? ? ? ? ? ..........? 
>>..
>>..

>n? ? ? ? ? ? ? ? ? ? ...........? ? ? ? ? ? ? ? ? ? ....? ? ? ? ? ? .......? ? ? ?? 
>............
>>
>>
>>I would like to select al the columns that have Au5 and C.
>>thank you in advance for your help,
>>james
>>
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
>


From rameshdas.87 at gmail.com  Wed Apr 30 11:04:16 2014
From: rameshdas.87 at gmail.com (Ramesh Das)
Date: Wed, 30 Apr 2014 14:34:16 +0530
Subject: [R] Kindly help me
In-Reply-To: <5360BC0A.3030901@sapo.pt>
References: <CAEg8v3Y5ZEQvaHpD6o2DJGU_6kYC=wnav9+2Sp+PmVdhP=PXdA@mail.gmail.com>
	<5360BC0A.3030901@sapo.pt>
Message-ID: <CAEg8v3bUC==oguWdqFfj6VUV28DBQLVy0YjiTm_RJ+o5hTuUGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/03fa0642/attachment.pl>

From rameshdas.87 at gmail.com  Wed Apr 30 14:19:56 2014
From: rameshdas.87 at gmail.com (Ramesh Das)
Date: Wed, 30 Apr 2014 17:49:56 +0530
Subject: [R] systemfit package is not compatible with R-3.0.2 version.
Message-ID: <CAEg8v3bKx8M-P6z2aE_KvEPhiQ5hgDEsQ6s3wEnXQ5d4h=YyGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/9592b392/attachment.pl>

From zealotd at hotmail.com  Wed Apr 30 16:37:05 2014
From: zealotd at hotmail.com (=?iso-8859-1?B?UXVlbnRpbiBEZWxpdnLp?=)
Date: Wed, 30 Apr 2014 14:37:05 +0000
Subject: [R] SPOT package non-conformable arrays
Message-ID: <DUB118-W4228F4B4350A095D881A0A2410@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/b5ebdc42/attachment.pl>

From aragorn168b at gmail.com  Wed Apr 30 16:55:16 2014
From: aragorn168b at gmail.com (Arunkumar Srinivasan)
Date: Wed, 30 Apr 2014 16:55:16 +0200
Subject: [R] Reshape large Data Frame to new format
In-Reply-To: <003801cf47a1$df6022c0$9e206840$@tamu.edu>
References: <1395659496417-4687431.post@n4.nabble.com>
	<1395673042.25013.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<003801cf47a1$df6022c0$9e206840$@tamu.edu>
Message-ID: <CAAf756PVpGB7qcB_fXtAz16FLpHWQjfVpJMsqswA79qA99NnwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/7cedd5dd/attachment.pl>

From patzelt at g.harvard.edu  Wed Apr 30 17:02:35 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Wed, 30 Apr 2014 11:02:35 -0400
Subject: [R] Lavaan Model Specification
Message-ID: <CAB9UfhRGYu98hBicBAYYssUq1xAyU_rMqzWHSwYZUSJk_F_EVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/1de4143c/attachment.pl>

From Diana.VanDijk at eawag.ch  Wed Apr 30 17:30:37 2014
From: Diana.VanDijk at eawag.ch (Van Dijk, Diana)
Date: Wed, 30 Apr 2014 15:30:37 +0000
Subject: [R] Error in matrix: too many elements specified
Message-ID: <1BA1CBB9FD0DA74DAB2FEF47C0AD4ADFB7A80B@EE-MBX1.ee.emp-eaw.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/03df1d19/attachment.pl>

From jeremy.miles at gmail.com  Wed Apr 30 19:16:37 2014
From: jeremy.miles at gmail.com (Jeremy Miles)
Date: Wed, 30 Apr 2014 10:16:37 -0700
Subject: [R] Lavaan Model Specification
In-Reply-To: <CAB9UfhRGYu98hBicBAYYssUq1xAyU_rMqzWHSwYZUSJk_F_EVw@mail.gmail.com>
References: <CAB9UfhRGYu98hBicBAYYssUq1xAyU_rMqzWHSwYZUSJk_F_EVw@mail.gmail.com>
Message-ID: <CAMtGSxkTvuX8rA=b9Gc=+QcKnSACCgdPkcM4TME9qje0mM+MHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/54d70bda/attachment.pl>

From Scott.Waichler at pnnl.gov  Wed Apr 30 19:54:48 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Wed, 30 Apr 2014 17:54:48 +0000
Subject: [R] Using apply with more than one matrix
Message-ID: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>

Hi,

I want to apply a custom function to all the elements of one matrix.  The function uses the value in the same i,j in a second matrix.  How can I use apply() or similar function to avoid nested loops in i and j?

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA, USA


From maitra.mbox.ignored at inbox.com  Wed Apr 30 21:15:25 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Wed, 30 Apr 2014 14:15:25 -0500
Subject: [R] Using apply with more than one matrix
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
Message-ID: <20140430141525.c3bbee77edbaebdc8c0178b6@inbox.com>

Hi Scott,

You could set up a three-dimensional array and then use apply on the
desired dimension (MARGIN in apply language).

HTH!

Many thanks,
Ranjan

On Wed, 30 Apr 2014 17:54:48 +0000 "Waichler, Scott R"
<Scott.Waichler at pnnl.gov> wrote:

> Hi,
> 
> I want to apply a custom function to all the elements of one matrix.  The function uses the value in the same i,j in a second matrix.  How can I use apply() or similar function to avoid nested loops in i and j?
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From gunter.berton at gene.com  Wed Apr 30 21:17:34 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 30 Apr 2014 12:17:34 -0700
Subject: [R] Using apply with more than one matrix
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
Message-ID: <CACk-te1UR0QtEYVyzPeVeZOcCrWOWutDfxJXv_tUbBD=bENcbg@mail.gmail.com>

Scott:

Your problem specification is rather vague: What do you mean by "use"?

In general, matrices are merely vectors with a dim attribute, so if
you can do what you want with them as vectors, then that will work for
them as matrices. For example:

> m1<- matrix(1:6, nr=3)
> m2 <- matrix(11:16, nr=2)
> m2*m2
     [,1] [,2] [,3]
[1,]  121  169  225
[2,]  144  196  256

If this does not meet your needs, you will have to follow the posting
guide and provide both code and a minimal reproducible example.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Wed, Apr 30, 2014 at 10:54 AM, Waichler, Scott R
<Scott.Waichler at pnnl.gov> wrote:
> Hi,
>
> I want to apply a custom function to all the elements of one matrix.  The function uses the value in the same i,j in a second matrix.  How can I use apply() or similar function to avoid nested loops in i and j?
>
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Wed Apr 30 22:20:46 2014
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 30 Apr 2014 20:20:46 +0000
Subject: [R] R 3.1 changes to type.convert causing strings where I used to
 get numeric
Message-ID: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>

Dear R-help,

I recently upgraded to R 3.1 patched and code that ran fine previously and now giving a lot of errors because the data is coming in as strings instead of numeric.  I can fix my code to wrapping each item I want to use with as.numeric(), but that seems very inefficient.

I looked at the change list for R 3.1 and I see the first item is a change in type.convert() that seems to be causing me grief.  The suggestion is to use colClasses, but when I try to do so I get an error regarding the quotes again...

>       ann1  <- read.table(driveletter %+% "/snap/ann/snap_fyr_ann1_" %+% i %+% ".txt", header=TRUE, quote="", as.is=TRUE, colClasses='numeric')
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  scan() expected 'a real', got '"1033.7"'

Does anyone have any suggestions?


CHANGES IN R 3.1.0:
NEW FEATURES


type.convert() (and hence by default read.table()) returns a character vector or factor when representing a numeric input as a double would lose accuracy. Similarly for complex inputs.
If a file contains numeric data with unrepresentable numbers of decimal places that are intended to be read as numeric, specify colClasses in read.table() to be"numeric".


***************************************************************
This message is for the named person's use only. It may
contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message if you are not
the intended recipient.

From Scott.Waichler at pnnl.gov  Wed Apr 30 22:21:50 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Wed, 30 Apr 2014 20:21:50 +0000
Subject: [R] Using apply with more than one matrix
In-Reply-To: <CACk-te1UR0QtEYVyzPeVeZOcCrWOWutDfxJXv_tUbBD=bENcbg@mail.gmail.com>
References: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
	<CACk-te1UR0QtEYVyzPeVeZOcCrWOWutDfxJXv_tUbBD=bENcbg@mail.gmail.com>
Message-ID: <074C83DAD4825242A20B2D83FDBCB88808A16F@EX10MBOX03.pnnl.gov>

Ok, here is a toy example.  I want to use a custom function that depends on more than one matrix/array as input, and I can't figure out how to do that with apply. 

v <- c(NA, 1.5, NA, NA,
       NA, 1.1, 0.5, NA,
       NA, 1.3, 0.4, 0.9)
a1 <- array(v, dim=c(2,2,3))
m1 <- matrix(c(NA, 1.5, 2.1, NA), ncol=2, byrow=T)
m2 <- matrix(runif(n=4, min=1, max=3), ncol=2)
condition1 <- ifelse(!is.na(m1) & m1 > m2, T, F)

ans <- matrix(NA, ncol=2, nrow=2) # initialize
for(i in 1:2) {
  for(j in 1:2) {
    ind.not.na <- which(!is.na(a1[i,j,]))
    if(condition1[i,j] && length(ind.not.na) > 0) {
      ans[i,j] <- a1[i,j,ind.not.na[1]] + m2[i,j]
    }
  }
}

Scott Waichler



> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Wednesday, April 30, 2014 12:18 PM
> To: Waichler, Scott R
> Cc: r-help at r-project.org
> Subject: Re: [R] Using apply with more than one matrix
> 
> Scott:
> 
> Your problem specification is rather vague: What do you mean by "use"?
> 
> In general, matrices are merely vectors with a dim attribute, so if you
> can do what you want with them as vectors, then that will work for them as
> matrices. For example:
> 
> > m1<- matrix(1:6, nr=3)
> > m2 <- matrix(11:16, nr=2)
> > m2*m2
>      [,1] [,2] [,3]
> [1,]  121  169  225
> [2,]  144  196  256
> 
> If this does not meet your needs, you will have to follow the posting
> guide and provide both code and a minimal reproducible example.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
> On Wed, Apr 30, 2014 at 10:54 AM, Waichler, Scott R
> <Scott.Waichler at pnnl.gov> wrote:
> > Hi,
> >
> > I want to apply a custom function to all the elements of one matrix.
> The function uses the value in the same i,j in a second matrix.  How can I
> use apply() or similar function to avoid nested loops in i and j?
> >
> > Thanks,
> > Scott Waichler
> > Pacific Northwest National Laboratory
> > Richland, WA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From murdoch.duncan at gmail.com  Wed Apr 30 22:40:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Apr 2014 16:40:12 -0400
Subject: [R] R 3.1 changes to type.convert causing strings where I used
 to get numeric
In-Reply-To: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <53615FAC.5000301@gmail.com>

On 30/04/2014, 4:20 PM, Bos, Roger wrote:
> Dear R-help,
>
> I recently upgraded to R 3.1 patched and code that ran fine previously and now giving a lot of errors because the data is coming in as strings instead of numeric.  I can fix my code to wrapping each item I want to use with as.numeric(), but that seems very inefficient.
>
> I looked at the change list for R 3.1 and I see the first item is a change in type.convert() that seems to be causing me grief.  The suggestion is to use colClasses, but when I try to do so I get an error regarding the quotes again...
>
>>        ann1  <- read.table(driveletter %+% "/snap/ann/snap_fyr_ann1_" %+% i %+% ".txt", header=TRUE, quote="", as.is=TRUE, colClasses='numeric')
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>    scan() expected 'a real', got '"1033.7"'
>
> Does anyone have any suggestions?

This sounds like two separate problems.  The first is the change to 
type.convert().  That's going to be dealt with (it's already in R-devel, 
will eventually be handled in R-patched and 3.1.1).  You deserve part of 
the blame for this for never testing the pre-release version.  It would 
have been easier to fix before release, but nobody who tested then 
bothered to report it.

The second problem is one I don't recall hearing reported before.  If 
you have a .csv file containing the lines

X
"1"

then it should be readable as a .csv, because the quotes should be 
stripped.  In fact it is readable now if you *don't* specify that the 
column is numeric, and it will be converted to a numeric value. 
However, if you do use colClasses="numeric" you'll get an error.  That 
looks wrong, though it is consistent with ?read.table.

 > x <- c("X", '"1"')
 > read.csv(textConnection(x))
   X
1 1
 > read.csv(textConnection(x), colClasses="numeric")
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, 
na.strings,  :
   scan() expected 'a real', got '"1"'
 >


Duncan Murdoch

>
>
> CHANGES IN R 3.1.0:
> NEW FEATURES
>
>
> type.convert() (and hence by default read.table()) returns a character vector or factor when representing a numeric input as a double would lose accuracy. Similarly for complex inputs.
> If a file contains numeric data with unrepresentable numbers of decimal places that are intended to be read as numeric, specify colClasses in read.table() to be"numeric".
>
>
> ***************************************************************
> This message is for the named person's use only. It may
> contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message and all
> copies from your system and destroy any hard copies.  You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message if you are not
> the intended recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Apr 30 22:47:37 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Apr 2014 13:47:37 -0700
Subject: [R] systemfit package is not compatible with R-3.0.2 version.
In-Reply-To: <CAEg8v3bKx8M-P6z2aE_KvEPhiQ5hgDEsQ6s3wEnXQ5d4h=YyGg@mail.gmail.com>
References: <CAEg8v3bKx8M-P6z2aE_KvEPhiQ5hgDEsQ6s3wEnXQ5d4h=YyGg@mail.gmail.com>
Message-ID: <70B5FB88-645A-494F-823D-8D75641E7E18@comcast.net>


On Apr 30, 2014, at 5:19 AM, Ramesh Das wrote:

> Dear all,
> I am in problem for installing the package "systemfit" in R-3.0.2 version.
> The error message is showing is as mentioned below. Now there is R-3.0.2
> version is there. so kindly anyone help me to solve this problem.
> 
> 
> Warning in install.packages :
>  package ?systemfit ? is not available (for R version 3.0.2)
> Loading required package: Matrix
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>  there is no package called ?lattice?
> In addition: Warning messages:
> 1: package ?systemfit? was built under R version 3.0.3
> 2: package ?Matrix? was built under R version 3.0.3
> Error: package ?Matrix? could not be loaded

You need to learn how to install packages when your version of R is behind the current version. (Or you need to update to 3.1 and then the contributed package versions in CRAN will match.)

You also need to read the Posting guide since you have not included enough detail to offer more specific advice.


> 
> 	[[alternative HTML version deleted]]

And Rhelp is a plain text mailing list. Gmail is pretty easy to configure for plain text.

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From stefano.sofia at regione.marche.it  Wed Apr 30 23:00:16 2014
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 30 Apr 2014 21:00:16 +0000
Subject: [R] Question about rgamma when the shape and the scale are vectors,
 not scalars
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0E307DDC@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/ddc40258/attachment.pl>

From 538280 at gmail.com  Wed Apr 30 23:11:08 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 30 Apr 2014 15:11:08 -0600
Subject: [R] Question about rgamma when the shape and the scale are
 vectors, not scalars
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0E307DDC@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0E307DDC@ESINO.regionemarche.intra>
Message-ID: <CAFEqCdwX-WR3a+zqgkdfgNg_Yxt0TZStkCBQb3G3Ma+X=8rzTA@mail.gmail.com>

Your command will generate 3 random values from gamma distributions,
the first will be from a gamma with shape a[1] and scale b[1], then
the 2nd will come from a gamma with shape a[2] and scale b[2] and the
3rd will have shape a[3] and scale b[3].

On Wed, Apr 30, 2014 at 3:00 PM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear list users,
> could somebody explain to me which is the meaning of
> rgamma(3, a, b)
> when both a and b are two vectors of length 3?
> I know that a is the shape and b is the scale, but I thought that they could only be scalars.
>
> Thank you for your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dwinsemius at comcast.net  Wed Apr 30 23:20:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Apr 2014 14:20:48 -0700
Subject: [R] R 3.1 changes to type.convert causing strings where I used
	to get numeric
In-Reply-To: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <1511275D-9C83-49A6-B183-1EDD3EF9B52E@comcast.net>

I though that change in NEWS re: type.convert referenced the fact that numbers which were longer than could be represented accurately within the constraints of class numeric were now being read in as characters which would give you the option to later convert with one of the bignum packages. Your error seems to relate to decimal values being enclosed within quotes not being read in with coercion. That's a different problem, I believe.

> read.table(text="'a' '1234'", colClasses=c('character', 'numeric'))
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  scan() expected 'a real', got ''1234''

So was able to reproduce your problem fairly easily, and solve it by defining a class and a coercion method to numeric and then using as an arcument to colClasses.

>  setClass('mycharnum', representation=list('character') )
> ?setClass
> ?as
> setAs('character', 'mycharnum' , function(from) as.numeric( from) )
>       
> read.table(text="'a' '1234'", colClasses=c('character', 'mycharnum'))
  V1   V2
1  a 1234

>  str( read.table(text="'a' '1234'", colClasses=c('character', 'mycharnum')) )
'data.frame':	1 obs. of  2 variables:
 $ V1: chr "a"
 $ V2: num 1234

I'm not really sure that the representation argument is meaningful in the setClass call. I tried with bot character and numeric and go t the same output on this limited testing method.

-- 
David.

On Apr 30, 2014, at 1:20 PM, Bos, Roger wrote:

> Dear R-help,
> 
> I recently upgraded to R 3.1 patched and code that ran fine previously and now giving a lot of errors because the data is coming in as strings instead of numeric.  I can fix my code to wrapping each item I want to use with as.numeric(), but that seems very inefficient.
> 
> I looked at the change list for R 3.1 and I see the first item is a change in type.convert() that seems to be causing me grief.  The suggestion is to use colClasses, but when I try to do so I get an error regarding the quotes again...
> 
>>      ann1  <- read.table(driveletter %+% "/snap/ann/snap_fyr_ann1_" %+% i %+% ".txt", header=TRUE, quote="", as.is=TRUE, colClasses='numeric')
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>  scan() expected 'a real', got '"1033.7"'
> 
> Does anyone have any suggestions?
> 
> 
> CHANGES IN R 3.1.0:
> NEW FEATURES
> 
> 
> type.convert() (and hence by default read.table()) returns a character vector or factor when representing a numeric input as a double would lose accuracy. Similarly for complex inputs.
> If a file contains numeric data with unrepresentable numbers of decimal places that are intended to be read as numeric, specify colClasses in read.table() to be"numeric".
> 
> 
> ***************************************************************
> This message is for the named person's use only. It ma...{{dropped:20}}


From dwinsemius at comcast.net  Wed Apr 30 23:20:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Apr 2014 14:20:48 -0700
Subject: [R] R 3.1 changes to type.convert causing strings where I used
	to get numeric
In-Reply-To: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EC062F6@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <C5DF937A-CA2F-43C0-B6BE-3B8A57D13B2A@comcast.net>

I though that change in NEWS re: type.convert referenced the fact that numbers which were longer than could be represented accurately within the constraints of class numeric were now being read in as characters which would give you the option to later convert with one of the bignum packages. Your error seems to relate to decimal values being enclosed within quotes not being read in with coercion. That's a different problem, I believe.

> read.table(text="'a' '1234'", colClasses=c('character', 'numeric'))
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  scan() expected 'a real', got ''1234''

So was able to reproduce your problem fairly easily, and solve it by defining a class and a coercion method to numeric and then using as an arcument to colClasses.

>  setClass('mycharnum', representation=list('character') )
> ?setClass
> ?as
> setAs('character', 'mycharnum' , function(from) as.numeric( from) )
>       
> read.table(text="'a' '1234'", colClasses=c('character', 'mycharnum'))
  V1   V2
1  a 1234

>  str( read.table(text="'a' '1234'", colClasses=c('character', 'mycharnum')) )
'data.frame':	1 obs. of  2 variables:
 $ V1: chr "a"
 $ V2: num 1234

I'm not really sure that the representation argument is meaningful in the setClass call. I tried with bot character and numeric and go t the same output on this limited testing method.

-- 
David.

On Apr 30, 2014, at 1:20 PM, Bos, Roger wrote:

> Dear R-help,
> 
> I recently upgraded to R 3.1 patched and code that ran fine previously and now giving a lot of errors because the data is coming in as strings instead of numeric.  I can fix my code to wrapping each item I want to use with as.numeric(), but that seems very inefficient.
> 
> I looked at the change list for R 3.1 and I see the first item is a change in type.convert() that seems to be causing me grief.  The suggestion is to use colClasses, but when I try to do so I get an error regarding the quotes again...
> 
>>      ann1  <- read.table(driveletter %+% "/snap/ann/snap_fyr_ann1_" %+% i %+% ".txt", header=TRUE, quote="", as.is=TRUE, colClasses='numeric')
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>  scan() expected 'a real', got '"1033.7"'
> 
> Does anyone have any suggestions?
> 
> 
> CHANGES IN R 3.1.0:
> NEW FEATURES
> 
> 
> type.convert() (and hence by default read.table()) returns a character vector or factor when representing a numeric input as a double would lose accuracy. Similarly for complex inputs.
> If a file contains numeric data with unrepresentable numbers of decimal places that are intended to be read as numeric, specify colClasses in read.table() to be"numeric".
> 
> 
> ***************************************************************
> This message is for the named person's use only. It ma...{{dropped:20}}


From dwinsemius at comcast.net  Wed Apr 30 23:31:27 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Apr 2014 14:31:27 -0700
Subject: [R] Using apply with more than one matrix
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB88808A16F@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB88808A13C@EX10MBOX03.pnnl.gov>
	<CACk-te1UR0QtEYVyzPeVeZOcCrWOWutDfxJXv_tUbBD=bENcbg@mail.gmail.com>
	<074C83DAD4825242A20B2D83FDBCB88808A16F@EX10MBOX03.pnnl.gov>
Message-ID: <95083300-E91C-4BF3-B733-028A387ABF5C@comcast.net>


On Apr 30, 2014, at 1:21 PM, Waichler, Scott R wrote:

> Ok, here is a toy example.  I want to use a custom function that depends on more than one matrix/array as input, and I can't figure out how to do that with apply. 
> 
> v <- c(NA, 1.5, NA, NA,
>       NA, 1.1, 0.5, NA,
>       NA, 1.3, 0.4, 0.9)
> a1 <- array(v, dim=c(2,2,3))
> m1 <- matrix(c(NA, 1.5, 2.1, NA), ncol=2, byrow=T)
> m2 <- matrix(runif(n=4, min=1, max=3), ncol=2)
> condition1 <- ifelse(!is.na(m1) & m1 > m2, T, F)

Just use:

condition1 <- !is.na(m1) & m1 > m2

For the next set of operation you should heed Jim Holtman's tagline:

"What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it."


> 
> ans <- matrix(NA, ncol=2, nrow=2) # initialize
> for(i in 1:2) {
>  for(j in 1:2) {
>    ind.not.na <- which(!is.na(a1[i,j,]))
>    if(condition1[i,j] && length(ind.not.na) > 0) {
>      ans[i,j] <- a1[i,j,ind.not.na[1]] + m2[i,j]
>    }
>  }
> }

At least in the realizatiuon I used all of the entries for conditon1 were FALSE, so a better test might be to specify set.seed() to give a reproducible example.

-- 

David.


> 
> Scott Waichler
> 
> 
> 
>> -----Original Message-----
>> From: Bert Gunter [mailto:gunter.berton at gene.com]
>> Sent: Wednesday, April 30, 2014 12:18 PM
>> To: Waichler, Scott R
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Using apply with more than one matrix
>> 
>> Scott:
>> 
>> Your problem specification is rather vague: What do you mean by "use"?
>> 
>> In general, matrices are merely vectors with a dim attribute, so if you
>> can do what you want with them as vectors, then that will work for them as
>> matrices. For example:
>> 
>>> m1<- matrix(1:6, nr=3)
>>> m2 <- matrix(11:16, nr=2)
>>> m2*m2
>>     [,1] [,2] [,3]
>> [1,]  121  169  225
>> [2,]  144  196  256
>> 
>> If this does not meet your needs, you will have to follow the posting
>> guide and provide both code and a minimal reproducible example.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge is
>> certainly not wisdom."
>> H. Gilbert Welch
>> 
>> 
>> 
>> 
>> On Wed, Apr 30, 2014 at 10:54 AM, Waichler, Scott R
>> <Scott.Waichler at pnnl.gov> wrote:
>>> Hi,
>>> 
>>> I want to apply a custom function to all the elements of one matrix.
>> The function uses the value in the same i,j in a second matrix.  How can I
>> use apply() or similar function to avoid nested loops in i and j?
>>> 
>>> Thanks,
>>> Scott Waichler
>>> Pacific Northwest National Laboratory
>>> Richland, WA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From renger at vannieuwkoop.ch  Wed Apr 30 19:00:22 2014
From: renger at vannieuwkoop.ch (Renger van Nieuwkoop)
Date: Wed, 30 Apr 2014 17:00:22 +0000
Subject: [R] Problems with hmisc under WIndows 8
Message-ID: <5E17CCD4AACE3A4C8CFF411186AE81906DC409A6@ExDAG30-N1.hostallapps.net>

Hi

I use  hmisc on a Windows 9-x64 machine and it causes an error:

running command 'cd "C:\Users\Renger\AppData\Local\Temp\Rtmp4IOgfH" & pdflatex -interaction=scrollmode "C:\Users\Renger\AppData\Local\Temp\Rtmp4IOgfH\file1b9482a7388"' had status 127
It also gives an API error 2.

The file is in the directory mentioned in the error message and, in a dos window, I can change to that directory and run pdflatex on the file? without a problem.

I tried to set the working directory to ?c:\temp and the tempdir also to c:\temp, but this did not help.
The problem happens in ESS/Emacs and under RStudio.

Any idea what can be the cause? (I searched the internet, but it seems nobody has a solution).

Thanks
Renger

_________________________
Renger van Nieuwkoop
Goldiwilstrasse 16 F
3600 Thun
+41 33 221'53'05 (p)
+41 79 818'53'73  (m)
renger at vannieuwkoop.ch


From ravi.varadhan at jhu.edu  Wed Apr 30 19:48:39 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 30 Apr 2014 17:48:39 +0000
Subject: [R] A combinatorial assignment problem
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C30E2C25C1@DOM-EB-MAIL2.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140430/6062f2b5/attachment.pl>

From jzmoser at gmail.com  Wed Apr 30 22:30:34 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Wed, 30 Apr 2014 22:30:34 +0200
Subject: [R] Fitting a Mixture of Noncentral Student t Distributions to a
 one-dimensional sample
Message-ID: <53615D6A.9050503@googlemail.com>

Dear R community,

I`d like to extract the parameters of a two-component mixture 
distribution of noncentral student t distributions which was fitted to a 
one-dimensional sample.

There are many packages for R that are capable of handling mixture 
distributions in one way or another. Some in the context of a Bayesian 
framework requiring kernels. Some in a regression framework. Some in a 
nonparametric framework. ...

So far the "mixdist"-package seems to come closest to my wish. This 
package fits parametric mixtures to a sample of data. Unfortunately it 
doesn`t support the student t distribution.

I have also tried to manually set up a likelihood function as described 
here:
http://stackoverflow.com/questions/6485597/r-how-to-fit-a-large-dataset-with-a-combination-of-distributions
But the result is far from perfect.

The "gamlss.mx"-package might be helping, but originally it seems to be 
set up for another context, i.e. regression. I tried to regress my data 
on a constant and then extract the parameters for the estimated mixture 
error distribution. But the estimated parameters seem to be not directly 
accessable individually by some command (such as fit1$sigma). And there 
seem to be serious convergence problems even in pretty simple and 
nonambiguous cases (see example 2). The following syntax is my 
gamlss.mx-setup so far:


     library(gamlss.dist)
     library(gamlss.mx)
     library(MASS)

     # 1:
     data(geyser)
     plot(density(geyser$waiting) )
     fit1 <- gamlssMX(waiting~1,data=geyser,family="TF",K=2)
     fit1
     # works fine

     # 2:
     N <- 100000
     components <- sample(1:2,prob=c(0.6,0.4),size=N,replace=TRUE)
     mus <- c(3,-6)
     sds <- c(1,9)
     nus <- c(25,3)
     mixsim <- 
data.frame(rTF2(N,mu=mus[components],sigma=sds[components],nu=nus[components]))
     colnames(mixsim) <- "MCsim"
     plot(density(mixsim$MCsim) , xlim=c(-50,50))
     fit2 <- gamlssMX(MCsim~1,data=mixsim,family="TF",K=2)
     fit2
     # no convergence

With another dataset and when using the same two component densities for 
the mixture as above I ended up with negative estimates for sigma (which 
should be positive).

I would be very grateful for any advice. I`ve read through many manuals 
and vignettes today but it seems that I am nearly in the same place 
where I was this morning.
A small example for a setup that works sort of reliably would be fantastic!

Thanks a lot in advance!!
Johannes


From quijote at gmx.net  Wed Apr 30 23:06:56 2014
From: quijote at gmx.net (phil)
Date: Wed, 30 Apr 2014 14:06:56 -0700 (PDT)
Subject: [R] Tobit model with panel data
Message-ID: <1398892016204-4689760.post@n4.nabble.com>

Hi all,

I just started to work with R a couple of weeks ago. Right now I would like
to regress an independent variable on a couple of explanatory variables. The
dependent variable is left censored in the sense that all negative values
and zero are set equal to one. This is done because I want to take the
logarithm which, as you all know, is only defined for values bigger than
zero. 

However, what I don't know now is how to compute this on R. Does anybody
know how to proceed? I already checked 
http://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf
<http://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf>   but
I am not able to apply the commands shown on page 8 correctly on my data
set.

Hence, I would really appreciate if somebody could give me a step-by-step
instruction for my own dataset.



--
View this message in context: http://r.789695.n4.nabble.com/Tobit-model-with-panel-data-tp4689760.html
Sent from the R help mailing list archive at Nabble.com.


