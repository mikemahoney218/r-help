From ppurk@y@@th@2010 @ending from gm@il@com  Tue Jan  1 13:40:25 2019
From: ppurk@y@@th@2010 @ending from gm@il@com (Priyanka Purkayastha)
Date: Tue, 1 Jan 2019 18:10:25 +0530
Subject: [R] Recursive Feature Elimination with SVM
Message-ID: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>

I have a dataset (data) with 700 rows and 7000 columns. I am trying to do
recursive feature selection with the SVM model. A quick google search
helped me get a code for a recursive search with SVM. However, I am unable
to understand the first part of the code, How do I introduce my dataset in
the code?

If the dataset is a matrix, named data. Please give me an example for
recursive feature selection with SVM. Bellow is the code I got for
recursive feature search.

    svmrfeFeatureRanking = function(x,y){

    #Checking for the variables
    stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)

    n = ncol(x)
    survivingFeaturesIndexes = seq_len(n)
    featureRankedList = vector(length=n)
    rankedFeatureIndex = n

    while(length(survivingFeaturesIndexes)>0){
    #train the support vector machine
    svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
cachesize=500,
                scale=FALSE, type="C-classification", kernel="linear" )

    #compute the weight vector
    w = t(svmModel$coefs)%*%svmModel$SV

    #compute ranking criteria
    rankingCriteria = w * w

    #rank the features
    ranking = sort(rankingCriteria, index.return = TRUE)$ix

    #update feature ranked list
    featureRankedList[rankedFeatureIndex] =
survivingFeaturesIndexes[ranking[1]]
    rankedFeatureIndex = rankedFeatureIndex - 1

    #eliminate the feature with smallest ranking criterion
    (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])}
    return (featureRankedList)}



I tried taking an idea from the above code and incorporate the idea in my
code as shown below

    library(e1071)
    library(caret)

    data<- read.csv("matrix.csv", header = TRUE)

    x <- data
    y <- as.factor(data$Class)

    svmrfeFeatureRanking = function(x,y){

      #Checking for the variables
      stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)

      n = ncol(x)
      survivingFeaturesIndexes = seq_len(n)
      featureRankedList = vector(length=n)
      rankedFeatureIndex = n

      while(length(survivingFeaturesIndexes)>0){
        #train the support vector machine
        svmModel = svm(x[, survivingFeaturesIndexes], y, cross=10,cost =
10, type="C-classification", kernel="linear" )

        #compute the weight vector
        w = t(svmModel$coefs)%*%svmModel$SV

        #compute ranking criteria
        rankingCriteria = w * w

        #rank the features
        ranking = sort(rankingCriteria, index.return = TRUE)$ix

        #update feature ranked list
        featureRankedList[rankedFeatureIndex] =
survivingFeaturesIndexes[ranking[1]]
        rankedFeatureIndex = rankedFeatureIndex - 1

        #eliminate the feature with smallest ranking criterion
        (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])}

      return (featureRankedList)}

But couldn't do anything at the stage "update feature ranked list"
Please guide

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Tue Jan  1 19:12:03 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Tue, 1 Jan 2019 10:12:03 -0800
Subject: [R] Recursive Feature Elimination with SVM
In-Reply-To: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
References: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
Message-ID: <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>


On 1/1/19 4:40 AM, Priyanka Purkayastha wrote:
> I have a dataset (data) with 700 rows and 7000 columns. I am trying to do
> recursive feature selection with the SVM model. A quick google search
> helped me get a code for a recursive search with SVM. However, I am unable
> to understand the first part of the code, How do I introduce my dataset in
> the code?


Generally the "labels" is given to such a machine learning device as the 
y argument, while the "features" are passed as a matrix to the x argument.


-- 

David.

>
> If the dataset is a matrix, named data. Please give me an example for
> recursive feature selection with SVM. Bellow is the code I got for
> recursive feature search.
>
>      svmrfeFeatureRanking = function(x,y){
>
>      #Checking for the variables
>      stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
>
>      n = ncol(x)
>      survivingFeaturesIndexes = seq_len(n)
>      featureRankedList = vector(length=n)
>      rankedFeatureIndex = n
>
>      while(length(survivingFeaturesIndexes)>0){
>      #train the support vector machine
>      svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
> cachesize=500,
>                  scale=FALSE, type="C-classification", kernel="linear" )
>
>      #compute the weight vector
>      w = t(svmModel$coefs)%*%svmModel$SV
>
>      #compute ranking criteria
>      rankingCriteria = w * w
>
>      #rank the features
>      ranking = sort(rankingCriteria, index.return = TRUE)$ix
>
>      #update feature ranked list
>      featureRankedList[rankedFeatureIndex] =
> survivingFeaturesIndexes[ranking[1]]
>      rankedFeatureIndex = rankedFeatureIndex - 1
>
>      #eliminate the feature with smallest ranking criterion
>      (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])}
>      return (featureRankedList)}
>
>
>
> I tried taking an idea from the above code and incorporate the idea in my
> code as shown below
>
>      library(e1071)
>      library(caret)
>
>      data<- read.csv("matrix.csv", header = TRUE)
>
>      x <- data
>      y <- as.factor(data$Class)
>
>      svmrfeFeatureRanking = function(x,y){
>
>        #Checking for the variables
>        stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
>
>        n = ncol(x)
>        survivingFeaturesIndexes = seq_len(n)
>        featureRankedList = vector(length=n)
>        rankedFeatureIndex = n
>
>        while(length(survivingFeaturesIndexes)>0){
>          #train the support vector machine
>          svmModel = svm(x[, survivingFeaturesIndexes], y, cross=10,cost =
> 10, type="C-classification", kernel="linear" )
>
>          #compute the weight vector
>          w = t(svmModel$coefs)%*%svmModel$SV
>
>          #compute ranking criteria
>          rankingCriteria = w * w
>
>          #rank the features
>          ranking = sort(rankingCriteria, index.return = TRUE)$ix
>
>          #update feature ranked list
>          featureRankedList[rankedFeatureIndex] =
> survivingFeaturesIndexes[ranking[1]]
>          rankedFeatureIndex = rankedFeatureIndex - 1
>
>          #eliminate the feature with smallest ranking criterion
>          (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])}
>
>        return (featureRankedList)}
>
> But couldn't do anything at the stage "update feature ranked list"
> Please guide
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Tue Jan  1 22:35:54 2019
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 2 Jan 2019 10:35:54 +1300
Subject: [R] SE for all fixed factor effect in GLMM
In-Reply-To: <1cd4f0cb-b860-6662-ef2b-8435aea445fe@u-psud.fr>
References: <9f92eb28-8fc6-9a34-092a-a08757bb1d74@yahoo.fr>
 <8b093767-cc9f-8340-a49a-156a2e9aef2a@gmx.at>
 <1cd4f0cb-b860-6662-ef2b-8435aea445fe@u-psud.fr>
Message-ID: <099ed778-b89c-ef61-d707-f80490bbb7e6@auckland.ac.nz>

On 1/2/19 9:35 AM, Marc Girondot wrote:
> Hello members of the list,
> 
> I asked 3 days ago a question about "how to get the SE of all effects 
> after a glm or glmm". I post here a synthesis of the answer and a new 
> solution:
> 
> For example:
> 
> x <- rnorm(100)
> 
> y <- rnorm(100)
> 
> G <- as.factor(sample(c("A", "B", "C", "D"), 100, replace = TRUE)); G <- 
> relevel(G, "A")
> 
> 
> m <- glm(y ~ x + G)
> 
> summary(m)$coefficients
> 
> 
> No SE for A level in G category is calculated.
> 
> 
> * Here is a synthesis of the answers:
> 
> 
> 1/ The first solution was proposed by Rolf Turner 
> <r.turner at auckland.ac.nz>. It was to add a + 0 in the formula and then 
> it is possible to have the SE for the 4 levels (it works also with 
> objects obtained with lme4:lmer() ):
> 
> m1 <- glm(y ~ x + G +0)
> 
> summary(m1)$coefficients
> 
> 
> However, this solution using + 0 does not works if more than one 
> category is included. Only the levels of the first one have all the SE 
> estimated.

Well, you only asked about the setting in which there was only one 
categorical predictor.  If there are, e.g. two (say "G" and "H") try

m2 <- glm(y ~ x + G:H + 0)

I would suggest that you learn a bit about how the formula structure 
works in linear models.

cheers,

Rolf Turner

P.S.  Your use of relevel() is redundant/irrelevant in this context.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Wed Jan  2 00:29:18 2019
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 2 Jan 2019 12:29:18 +1300
Subject: [R] SE for all fixed factor effect in GLMM
In-Reply-To: <481f02cc-3d0c-bcdd-96b4-ac2ad0013e95@u-psud.fr>
References: <9f92eb28-8fc6-9a34-092a-a08757bb1d74@yahoo.fr>
 <8b093767-cc9f-8340-a49a-156a2e9aef2a@gmx.at>
 <1cd4f0cb-b860-6662-ef2b-8435aea445fe@u-psud.fr>
 <099ed778-b89c-ef61-d707-f80490bbb7e6@auckland.ac.nz>
 <481f02cc-3d0c-bcdd-96b4-ac2ad0013e95@u-psud.fr>
Message-ID: <2ad6284e-a903-6040-52a1-beb427406776@auckland.ac.nz>


Please keep communications on-list.

On 1/2/19 10:57 AM, Marc Girondot wrote:
> Le 01/01/2019 ? 22:35, Rolf Turner a ?crit?:
>> On 1/2/19 9:35 AM, Marc Girondot wrote:
>>> Hello members of the list,
>>>
>>> I asked 3 days ago a question about "how to get the SE of all effects 
>>> after a glm or glmm". I post here a synthesis of the answer and a new 
>>> solution:
>>>
>>> For example:
>>>
>>> x <- rnorm(100)
>>>
>>> y <- rnorm(100)
>>>
>>> G <- as.factor(sample(c("A", "B", "C", "D"), 100, replace = TRUE)); G 
>>> <- relevel(G, "A")
>>>
>>>
>>> m <- glm(y ~ x + G)
>>>
>>> summary(m)$coefficients
>>>
>>>
>>> No SE for A level in G category is calculated.
>>>
>>>
>>> * Here is a synthesis of the answers:
>>>
>>>
>>> 1/ The first solution was proposed by Rolf Turner 
>>> <r.turner at auckland.ac.nz>. It was to add a + 0 in the formula and 
>>> then it is possible to have the SE for the 4 levels (it works also 
>>> with objects obtained with lme4:lmer() ):
>>>
>>> m1 <- glm(y ~ x + G +0)
>>>
>>> summary(m1)$coefficients
>>>
>>>
>>> However, this solution using + 0 does not works if more than one 
>>> category is included. Only the levels of the first one have all the 
>>> SE estimated.
>>
>> Well, you only asked about the setting in which there was only one 
>> categorical predictor.? If there are, e.g. two (say "G" and "H") try
>>
>> m2 <- glm(y ~ x + G:H + 0)
>>
>> I would suggest that you learn a bit about how the formula structure 
>> works in linear models.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P.S.? Your use of relevel() is redundant/irrelevant in this context.
>>
>> R. T.
>>
> Thanks for the advises. But based on my little knowledge of formula 
> structure in linear models, A+B is not the same than A:B.

That is very true!  But I never suggested using "A+B".  In the context 
of an additive model there is *NO WAY* to make sense of parameters 
corresponding to each level of each factor.  Consequently there can be 
no way to form estimates of such parameters or of the standard errors of 
such estimates.  They cannot be made meaningful.  (This is, in effect, 
the reason for the existence of the --- rather confusing --- 
over-parametrised model.)

> The first structure used 6 parameters and the second one 14.

Well, it depends on how many levels each of A and B has!  But yes, the 
numbers of parameters will be different.  They are different models.

> Then adding 
> +0 does not solve the problem... or perhaps I am wrong ?
> 
> Thanks for your time.

For an *additive* model "+0" does indeed not solve the problem.  In this 
context the "problem" has no solution.

You might get some insight by reading about "the cell means model" in
"Linear Models" by Shayle R. Searle:

@book{searle1997,
   title={Linear Models},
   author={Searle, S.R.},
   isbn={9780471184997},
   year={1997},
   publisher={Wiley}
}

If you use the model I suggested (i.e. G:H + 0) you get an explicit 
estimate for each cell mean, and the standard errors of these estimates.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ppurk@y@@th@2010 @ending from gm@il@com  Wed Jan  2 02:31:56 2019
From: ppurk@y@@th@2010 @ending from gm@il@com (Priyanka Purkayastha)
Date: Wed, 2 Jan 2019 07:01:56 +0530
Subject: [R] Recursive Feature Elimination with SVM
In-Reply-To: <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>
References: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
 <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>
Message-ID: <CALUZZGbKSzp_paY=KVtgk4CHBQiFfUHtF-RkohUpKBe9mR3kug@mail.gmail.com>

Thankyou David.. I tried the same, I gave x as the data matrix and y as the
class label. But it returned an empty "featureRankedList". I get no output
when I try the code.

On Tue, 1 Jan 2019 at 11:42 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 1/1/19 4:40 AM, Priyanka Purkayastha wrote:
> > I have a dataset (data) with 700 rows and 7000 columns. I am trying to do
> > recursive feature selection with the SVM model. A quick google search
> > helped me get a code for a recursive search with SVM. However, I am
> unable
> > to understand the first part of the code, How do I introduce my dataset
> in
> > the code?
>
>
> Generally the "labels" is given to such a machine learning device as the
> y argument, while the "features" are passed as a matrix to the x argument.
>
>
> --
>
> David.
>
> >
> > If the dataset is a matrix, named data. Please give me an example for
> > recursive feature selection with SVM. Bellow is the code I got for
> > recursive feature search.
> >
> >      svmrfeFeatureRanking = function(x,y){
> >
> >      #Checking for the variables
> >      stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> >
> >      n = ncol(x)
> >      survivingFeaturesIndexes = seq_len(n)
> >      featureRankedList = vector(length=n)
> >      rankedFeatureIndex = n
> >
> >      while(length(survivingFeaturesIndexes)>0){
> >      #train the support vector machine
> >      svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
> > cachesize=500,
> >                  scale=FALSE, type="C-classification", kernel="linear" )
> >
> >      #compute the weight vector
> >      w = t(svmModel$coefs)%*%svmModel$SV
> >
> >      #compute ranking criteria
> >      rankingCriteria = w * w
> >
> >      #rank the features
> >      ranking = sort(rankingCriteria, index.return = TRUE)$ix
> >
> >      #update feature ranked list
> >      featureRankedList[rankedFeatureIndex] =
> > survivingFeaturesIndexes[ranking[1]]
> >      rankedFeatureIndex = rankedFeatureIndex - 1
> >
> >      #eliminate the feature with smallest ranking criterion
> >      (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])}
> >      return (featureRankedList)}
> >
> >
> >
> > I tried taking an idea from the above code and incorporate the idea in my
> > code as shown below
> >
> >      library(e1071)
> >      library(caret)
> >
> >      data<- read.csv("matrix.csv", header = TRUE)
> >
> >      x <- data
> >      y <- as.factor(data$Class)
> >
> >      svmrfeFeatureRanking = function(x,y){
> >
> >        #Checking for the variables
> >        stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> >
> >        n = ncol(x)
> >        survivingFeaturesIndexes = seq_len(n)
> >        featureRankedList = vector(length=n)
> >        rankedFeatureIndex = n
> >
> >        while(length(survivingFeaturesIndexes)>0){
> >          #train the support vector machine
> >          svmModel = svm(x[, survivingFeaturesIndexes], y, cross=10,cost =
> > 10, type="C-classification", kernel="linear" )
> >
> >          #compute the weight vector
> >          w = t(svmModel$coefs)%*%svmModel$SV
> >
> >          #compute ranking criteria
> >          rankingCriteria = w * w
> >
> >          #rank the features
> >          ranking = sort(rankingCriteria, index.return = TRUE)$ix
> >
> >          #update feature ranked list
> >          featureRankedList[rankedFeatureIndex] =
> > survivingFeaturesIndexes[ranking[1]]
> >          rankedFeatureIndex = rankedFeatureIndex - 1
> >
> >          #eliminate the feature with smallest ranking criterion
> >          (survivingFeaturesIndexes =
> survivingFeaturesIndexes[-ranking[1]])}
> >
> >        return (featureRankedList)}
> >
> > But couldn't do anything at the stage "update feature ranked list"
> > Please guide
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
-- 
Regards,

Priyanka Purkayastha, M.Tech, Ph.D.,
SERB National Postdoctoral Researcher
Genomics and Systems Biology Lab,
Department of Chemical Engineering,
Indian Institute of Technology Bombay (IITB),
Powai, Mumbai- 400076

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Wed Jan  2 06:48:49 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Tue, 1 Jan 2019 21:48:49 -0800
Subject: [R] Recursive Feature Elimination with SVM
In-Reply-To: <CALUZZGbKSzp_paY=KVtgk4CHBQiFfUHtF-RkohUpKBe9mR3kug@mail.gmail.com>
References: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
 <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>
 <CALUZZGbKSzp_paY=KVtgk4CHBQiFfUHtF-RkohUpKBe9mR3kug@mail.gmail.com>
Message-ID: <22e7f059-ca37-8420-409f-3be1b8457de6@comcast.net>


On 1/1/19 5:31 PM, Priyanka Purkayastha wrote:
> Thankyou David.. I tried the same, I gave x as the data matrix and y 
> as the class label. But it returned an empty "featureRankedList". I 
> get no output when I try the code.


If you want people to spend time on this you should post a reproducible 
example. See the Posting Guide ... and learn to post in plain text.


--

David

>
> On Tue, 1 Jan 2019 at 11:42 PM, David Winsemius 
> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     On 1/1/19 4:40 AM, Priyanka Purkayastha wrote:
>     > I have a dataset (data) with 700 rows and 7000 columns. I am
>     trying to do
>     > recursive feature selection with the SVM model. A quick google
>     search
>     > helped me get a code for a recursive search with SVM. However, I
>     am unable
>     > to understand the first part of the code, How do I introduce my
>     dataset in
>     > the code?
>
>
>     Generally the "labels" is given to such a machine learning device
>     as the
>     y argument, while the "features" are passed as a matrix to the x
>     argument.
>
>
>     -- 
>
>     David.
>
>     >
>     > If the dataset is a matrix, named data. Please give me an
>     example for
>     > recursive feature selection with SVM. Bellow is the code I got for
>     > recursive feature search.
>     >
>     >? ? ? svmrfeFeatureRanking = function(x,y){
>     >
>     >? ? ? #Checking for the variables
>     >? ? ? stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
>     >
>     >? ? ? n = ncol(x)
>     >? ? ? survivingFeaturesIndexes = seq_len(n)
>     >? ? ? featureRankedList = vector(length=n)
>     >? ? ? rankedFeatureIndex = n
>     >
>     >? ? ? while(length(survivingFeaturesIndexes)>0){
>     >? ? ? #train the support vector machine
>     >? ? ? svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
>     > cachesize=500,
>     >? ? ? ? ? ? ? ? ? scale=FALSE, type="C-classification",
>     kernel="linear" )
>     >
>     >? ? ? #compute the weight vector
>     >? ? ? w = t(svmModel$coefs)%*%svmModel$SV
>     >
>     >? ? ? #compute ranking criteria
>     >? ? ? rankingCriteria = w * w
>     >
>     >? ? ? #rank the features
>     >? ? ? ranking = sort(rankingCriteria, index.return = TRUE)$ix
>     >
>     >? ? ? #update feature ranked list
>     >? ? ? featureRankedList[rankedFeatureIndex] =
>     > survivingFeaturesIndexes[ranking[1]]
>     >? ? ? rankedFeatureIndex = rankedFeatureIndex - 1
>     >
>     >? ? ? #eliminate the feature with smallest ranking criterion
>     >? ? ? (survivingFeaturesIndexes =
>     survivingFeaturesIndexes[-ranking[1]])}
>     >? ? ? return (featureRankedList)}
>     >
>     >
>     >
>     > I tried taking an idea from the above code and incorporate the
>     idea in my
>     > code as shown below
>     >
>     >? ? ? library(e1071)
>     >? ? ? library(caret)
>     >
>     >? ? ? data<- read.csv("matrix.csv", header = TRUE)
>     >
>     >? ? ? x <- data
>     >? ? ? y <- as.factor(data$Class)
>     >
>     >? ? ? svmrfeFeatureRanking = function(x,y){
>     >
>     >? ? ? ? #Checking for the variables
>     >? ? ? ? stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
>     >
>     >? ? ? ? n = ncol(x)
>     >? ? ? ? survivingFeaturesIndexes = seq_len(n)
>     >? ? ? ? featureRankedList = vector(length=n)
>     >? ? ? ? rankedFeatureIndex = n
>     >
>     >? ? ? ? while(length(survivingFeaturesIndexes)>0){
>     >? ? ? ? ? #train the support vector machine
>     >? ? ? ? ? svmModel = svm(x[, survivingFeaturesIndexes], y,
>     cross=10,cost =
>     > 10, type="C-classification", kernel="linear" )
>     >
>     >? ? ? ? ? #compute the weight vector
>     >? ? ? ? ? w = t(svmModel$coefs)%*%svmModel$SV
>     >
>     >? ? ? ? ? #compute ranking criteria
>     >? ? ? ? ? rankingCriteria = w * w
>     >
>     >? ? ? ? ? #rank the features
>     >? ? ? ? ? ranking = sort(rankingCriteria, index.return = TRUE)$ix
>     >
>     >? ? ? ? ? #update feature ranked list
>     >? ? ? ? ? featureRankedList[rankedFeatureIndex] =
>     > survivingFeaturesIndexes[ranking[1]]
>     >? ? ? ? ? rankedFeatureIndex = rankedFeatureIndex - 1
>     >
>     >? ? ? ? ? #eliminate the feature with smallest ranking criterion
>     >? ? ? ? ? (survivingFeaturesIndexes =
>     survivingFeaturesIndexes[-ranking[1]])}
>     >
>     >? ? ? ? return (featureRankedList)}
>     >
>     > But couldn't do anything at the stage "update feature ranked list"
>     > Please guide
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Regards,
>
> Priyanka Purkayastha, M.Tech, Ph.D.,
> SERB National Postdoctoral Researcher
> Genomics and Systems Biology Lab,
> Department of Chemical Engineering,
> Indian Institute of Technology Bombay (IITB),
> Powai, Mumbai- 400076
>
>
>


From ppurk@y@@th@2010 @ending from gm@il@com  Wed Jan  2 08:13:36 2019
From: ppurk@y@@th@2010 @ending from gm@il@com (Priyanka Purkayastha)
Date: Wed, 2 Jan 2019 12:43:36 +0530
Subject: [R] Recursive Feature Elimination with SVM
In-Reply-To: <22e7f059-ca37-8420-409f-3be1b8457de6@comcast.net>
References: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
 <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>
 <CALUZZGbKSzp_paY=KVtgk4CHBQiFfUHtF-RkohUpKBe9mR3kug@mail.gmail.com>
 <22e7f059-ca37-8420-409f-3be1b8457de6@comcast.net>
Message-ID: <CALUZZGZPbX5pyx=_wk_+Dh3eUDOd2ZZeGnRfauaixcs+S08pjg@mail.gmail.com>

This is the code I tried,

library(e1071)
library(caret)
library(ROCR)

data <- read.csv("data.csv", header = TRUE)
set.seed(998)

inTraining <- createDataPartition(data$Class, p = .70, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]

while(length(data)>0){

## Building the model ####
svm.model <- svm(Class ~ ., data = training,
cross=10,metric="ROC",type="eps-regression",kernel="linear",na.action=na.omit,probability
= TRUE)
print(svm.model)


###### auc  measure #######

#prediction and ROC
svm.model$index
svm.pred <- predict(svm.model, testing, probability = TRUE)

#calculating auc
c <- as.numeric(svm.pred)
c = c - 1
pred <- prediction(c, testing$Class)
perf <- performance(pred,"tpr","fpr")
plot(perf,fpr.stop=0.1)
auc <- performance(pred, measure = "auc")
auc <- auc at y.values[[1]]
print(length(data))
print(auc)

#compute the weight vector
w = t(svm.model$coefs)%*%svm.model$SV

#compute ranking criteria
weight_matrix = w * w

#rank the features
w_transpose <- t(weight_matrix)
w2 <- as.matrix(w_transpose[order(w_transpose[,1], decreasing = FALSE),])
a <- as.matrix(w2[which(w2 == max(w2)),]) #to get the rows with minimum
values
row.names(a) -> remove
training<- data[,setdiff(colnames(data),remove)]
}

















On Wed, Jan 2, 2019 at 11:18 AM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 1/1/19 5:31 PM, Priyanka Purkayastha wrote:
> > Thankyou David.. I tried the same, I gave x as the data matrix and y
> > as the class label. But it returned an empty "featureRankedList". I
> > get no output when I try the code.
>
>
> If you want people to spend time on this you should post a reproducible
> example. See the Posting Guide ... and learn to post in plain text.
>
>
> --
>
> David
>
> >
> > On Tue, 1 Jan 2019 at 11:42 PM, David Winsemius
> > <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
> >
> >
> >     On 1/1/19 4:40 AM, Priyanka Purkayastha wrote:
> >     > I have a dataset (data) with 700 rows and 7000 columns. I am
> >     trying to do
> >     > recursive feature selection with the SVM model. A quick google
> >     search
> >     > helped me get a code for a recursive search with SVM. However, I
> >     am unable
> >     > to understand the first part of the code, How do I introduce my
> >     dataset in
> >     > the code?
> >
> >
> >     Generally the "labels" is given to such a machine learning device
> >     as the
> >     y argument, while the "features" are passed as a matrix to the x
> >     argument.
> >
> >
> >     --
> >
> >     David.
> >
> >     >
> >     > If the dataset is a matrix, named data. Please give me an
> >     example for
> >     > recursive feature selection with SVM. Bellow is the code I got for
> >     > recursive feature search.
> >     >
> >     >      svmrfeFeatureRanking = function(x,y){
> >     >
> >     >      #Checking for the variables
> >     >      stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> >     >
> >     >      n = ncol(x)
> >     >      survivingFeaturesIndexes = seq_len(n)
> >     >      featureRankedList = vector(length=n)
> >     >      rankedFeatureIndex = n
> >     >
> >     >      while(length(survivingFeaturesIndexes)>0){
> >     >      #train the support vector machine
> >     >      svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
> >     > cachesize=500,
> >     >                  scale=FALSE, type="C-classification",
> >     kernel="linear" )
> >     >
> >     >      #compute the weight vector
> >     >      w = t(svmModel$coefs)%*%svmModel$SV
> >     >
> >     >      #compute ranking criteria
> >     >      rankingCriteria = w * w
> >     >
> >     >      #rank the features
> >     >      ranking = sort(rankingCriteria, index.return = TRUE)$ix
> >     >
> >     >      #update feature ranked list
> >     >      featureRankedList[rankedFeatureIndex] =
> >     > survivingFeaturesIndexes[ranking[1]]
> >     >      rankedFeatureIndex = rankedFeatureIndex - 1
> >     >
> >     >      #eliminate the feature with smallest ranking criterion
> >     >      (survivingFeaturesIndexes =
> >     survivingFeaturesIndexes[-ranking[1]])}
> >     >      return (featureRankedList)}
> >     >
> >     >
> >     >
> >     > I tried taking an idea from the above code and incorporate the
> >     idea in my
> >     > code as shown below
> >     >
> >     >      library(e1071)
> >     >      library(caret)
> >     >
> >     >      data<- read.csv("matrix.csv", header = TRUE)
> >     >
> >     >      x <- data
> >     >      y <- as.factor(data$Class)
> >     >
> >     >      svmrfeFeatureRanking = function(x,y){
> >     >
> >     >        #Checking for the variables
> >     >        stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> >     >
> >     >        n = ncol(x)
> >     >        survivingFeaturesIndexes = seq_len(n)
> >     >        featureRankedList = vector(length=n)
> >     >        rankedFeatureIndex = n
> >     >
> >     >        while(length(survivingFeaturesIndexes)>0){
> >     >          #train the support vector machine
> >     >          svmModel = svm(x[, survivingFeaturesIndexes], y,
> >     cross=10,cost =
> >     > 10, type="C-classification", kernel="linear" )
> >     >
> >     >          #compute the weight vector
> >     >          w = t(svmModel$coefs)%*%svmModel$SV
> >     >
> >     >          #compute ranking criteria
> >     >          rankingCriteria = w * w
> >     >
> >     >          #rank the features
> >     >          ranking = sort(rankingCriteria, index.return = TRUE)$ix
> >     >
> >     >          #update feature ranked list
> >     >          featureRankedList[rankedFeatureIndex] =
> >     > survivingFeaturesIndexes[ranking[1]]
> >     >          rankedFeatureIndex = rankedFeatureIndex - 1
> >     >
> >     >          #eliminate the feature with smallest ranking criterion
> >     >          (survivingFeaturesIndexes =
> >     survivingFeaturesIndexes[-ranking[1]])}
> >     >
> >     >        return (featureRankedList)}
> >     >
> >     > But couldn't do anything at the stage "update feature ranked list"
> >     > Please guide
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Regards,
> >
> > Priyanka Purkayastha, M.Tech, Ph.D.,
> > SERB National Postdoctoral Researcher
> > Genomics and Systems Biology Lab,
> > Department of Chemical Engineering,
> > Indian Institute of Technology Bombay (IITB),
> > Powai, Mumbai- 400076
> >
> >
> >
>


-- 
Regards,

Priyanka Purkayastha, M.Tech, Ph.D.,
SERB National Postdoctoral Researcher
Genomics and Systems Biology Lab,
Department of Chemical Engineering,
Indian Institute of Technology Bombay (IITB),
Powai, Mumbai- 400076

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Jan  2 17:18:13 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 2 Jan 2019 08:18:13 -0800
Subject: [R] Recursive Feature Elimination with SVM
In-Reply-To: <CALUZZGZPbX5pyx=_wk_+Dh3eUDOd2ZZeGnRfauaixcs+S08pjg@mail.gmail.com>
References: <CALUZZGamcW0zCREF8EYyRyeqKo86tUp3VWwzq0X7tpoi4KZU5Q@mail.gmail.com>
 <ce722610-90dd-42b9-25ed-83861ef2a924@comcast.net>
 <CALUZZGbKSzp_paY=KVtgk4CHBQiFfUHtF-RkohUpKBe9mR3kug@mail.gmail.com>
 <22e7f059-ca37-8420-409f-3be1b8457de6@comcast.net>
 <CALUZZGZPbX5pyx=_wk_+Dh3eUDOd2ZZeGnRfauaixcs+S08pjg@mail.gmail.com>
Message-ID: <CAGxFJbQSgSVK2pObg1TC=MZ3Ty4sXDLtp01jPVWbzq7sHO6y2w@mail.gmail.com>

Note: **NOT** reproducible (only you have "data.csv").

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 1, 2019 at 11:14 PM Priyanka Purkayastha <
ppurkayastha2010 at gmail.com> wrote:

> This is the code I tried,
>
> library(e1071)
> library(caret)
> library(ROCR)
>
> data <- read.csv("data.csv", header = TRUE)
> set.seed(998)
>
> inTraining <- createDataPartition(data$Class, p = .70, list = FALSE)
> training <- data[ inTraining,]
> testing  <- data[-inTraining,]
>
> while(length(data)>0){
>
> ## Building the model ####
> svm.model <- svm(Class ~ ., data = training,
>
> cross=10,metric="ROC",type="eps-regression",kernel="linear",na.action=na.omit,probability
> = TRUE)
> print(svm.model)
>
>
> ###### auc  measure #######
>
> #prediction and ROC
> svm.model$index
> svm.pred <- predict(svm.model, testing, probability = TRUE)
>
> #calculating auc
> c <- as.numeric(svm.pred)
> c = c - 1
> pred <- prediction(c, testing$Class)
> perf <- performance(pred,"tpr","fpr")
> plot(perf,fpr.stop=0.1)
> auc <- performance(pred, measure = "auc")
> auc <- auc at y.values[[1]]
> print(length(data))
> print(auc)
>
> #compute the weight vector
> w = t(svm.model$coefs)%*%svm.model$SV
>
> #compute ranking criteria
> weight_matrix = w * w
>
> #rank the features
> w_transpose <- t(weight_matrix)
> w2 <- as.matrix(w_transpose[order(w_transpose[,1], decreasing = FALSE),])
> a <- as.matrix(w2[which(w2 == max(w2)),]) #to get the rows with minimum
> values
> row.names(a) -> remove
> training<- data[,setdiff(colnames(data),remove)]
> }
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> On Wed, Jan 2, 2019 at 11:18 AM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
> >
> > On 1/1/19 5:31 PM, Priyanka Purkayastha wrote:
> > > Thankyou David.. I tried the same, I gave x as the data matrix and y
> > > as the class label. But it returned an empty "featureRankedList". I
> > > get no output when I try the code.
> >
> >
> > If you want people to spend time on this you should post a reproducible
> > example. See the Posting Guide ... and learn to post in plain text.
> >
> >
> > --
> >
> > David
> >
> > >
> > > On Tue, 1 Jan 2019 at 11:42 PM, David Winsemius
> > > <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
> > >
> > >
> > >     On 1/1/19 4:40 AM, Priyanka Purkayastha wrote:
> > >     > I have a dataset (data) with 700 rows and 7000 columns. I am
> > >     trying to do
> > >     > recursive feature selection with the SVM model. A quick google
> > >     search
> > >     > helped me get a code for a recursive search with SVM. However, I
> > >     am unable
> > >     > to understand the first part of the code, How do I introduce my
> > >     dataset in
> > >     > the code?
> > >
> > >
> > >     Generally the "labels" is given to such a machine learning device
> > >     as the
> > >     y argument, while the "features" are passed as a matrix to the x
> > >     argument.
> > >
> > >
> > >     --
> > >
> > >     David.
> > >
> > >     >
> > >     > If the dataset is a matrix, named data. Please give me an
> > >     example for
> > >     > recursive feature selection with SVM. Bellow is the code I got
> for
> > >     > recursive feature search.
> > >     >
> > >     >      svmrfeFeatureRanking = function(x,y){
> > >     >
> > >     >      #Checking for the variables
> > >     >      stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> > >     >
> > >     >      n = ncol(x)
> > >     >      survivingFeaturesIndexes = seq_len(n)
> > >     >      featureRankedList = vector(length=n)
> > >     >      rankedFeatureIndex = n
> > >     >
> > >     >      while(length(survivingFeaturesIndexes)>0){
> > >     >      #train the support vector machine
> > >     >      svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 10,
> > >     > cachesize=500,
> > >     >                  scale=FALSE, type="C-classification",
> > >     kernel="linear" )
> > >     >
> > >     >      #compute the weight vector
> > >     >      w = t(svmModel$coefs)%*%svmModel$SV
> > >     >
> > >     >      #compute ranking criteria
> > >     >      rankingCriteria = w * w
> > >     >
> > >     >      #rank the features
> > >     >      ranking = sort(rankingCriteria, index.return = TRUE)$ix
> > >     >
> > >     >      #update feature ranked list
> > >     >      featureRankedList[rankedFeatureIndex] =
> > >     > survivingFeaturesIndexes[ranking[1]]
> > >     >      rankedFeatureIndex = rankedFeatureIndex - 1
> > >     >
> > >     >      #eliminate the feature with smallest ranking criterion
> > >     >      (survivingFeaturesIndexes =
> > >     survivingFeaturesIndexes[-ranking[1]])}
> > >     >      return (featureRankedList)}
> > >     >
> > >     >
> > >     >
> > >     > I tried taking an idea from the above code and incorporate the
> > >     idea in my
> > >     > code as shown below
> > >     >
> > >     >      library(e1071)
> > >     >      library(caret)
> > >     >
> > >     >      data<- read.csv("matrix.csv", header = TRUE)
> > >     >
> > >     >      x <- data
> > >     >      y <- as.factor(data$Class)
> > >     >
> > >     >      svmrfeFeatureRanking = function(x,y){
> > >     >
> > >     >        #Checking for the variables
> > >     >        stopifnot(!is.null(x) == TRUE, !is.null(y) == TRUE)
> > >     >
> > >     >        n = ncol(x)
> > >     >        survivingFeaturesIndexes = seq_len(n)
> > >     >        featureRankedList = vector(length=n)
> > >     >        rankedFeatureIndex = n
> > >     >
> > >     >        while(length(survivingFeaturesIndexes)>0){
> > >     >          #train the support vector machine
> > >     >          svmModel = svm(x[, survivingFeaturesIndexes], y,
> > >     cross=10,cost =
> > >     > 10, type="C-classification", kernel="linear" )
> > >     >
> > >     >          #compute the weight vector
> > >     >          w = t(svmModel$coefs)%*%svmModel$SV
> > >     >
> > >     >          #compute ranking criteria
> > >     >          rankingCriteria = w * w
> > >     >
> > >     >          #rank the features
> > >     >          ranking = sort(rankingCriteria, index.return = TRUE)$ix
> > >     >
> > >     >          #update feature ranked list
> > >     >          featureRankedList[rankedFeatureIndex] =
> > >     > survivingFeaturesIndexes[ranking[1]]
> > >     >          rankedFeatureIndex = rankedFeatureIndex - 1
> > >     >
> > >     >          #eliminate the feature with smallest ranking criterion
> > >     >          (survivingFeaturesIndexes =
> > >     survivingFeaturesIndexes[-ranking[1]])}
> > >     >
> > >     >        return (featureRankedList)}
> > >     >
> > >     > But couldn't do anything at the stage "update feature ranked
> list"
> > >     > Please guide
> > >     >
> > >     >       [[alternative HTML version deleted]]
> > >     >
> > >     > ______________________________________________
> > >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >     > PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-guide.html
> > >     > and provide commented, minimal, self-contained, reproducible
> code.
> > >
> > > --
> > > Regards,
> > >
> > > Priyanka Purkayastha, M.Tech, Ph.D.,
> > > SERB National Postdoctoral Researcher
> > > Genomics and Systems Biology Lab,
> > > Department of Chemical Engineering,
> > > Indian Institute of Technology Bombay (IITB),
> > > Powai, Mumbai- 400076
> > >
> > >
> > >
> >
>
>
> --
> Regards,
>
> Priyanka Purkayastha, M.Tech, Ph.D.,
> SERB National Postdoctoral Researcher
> Genomics and Systems Biology Lab,
> Department of Chemical Engineering,
> Indian Institute of Technology Bombay (IITB),
> Powai, Mumbai- 400076
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @mnicol@@ @ending from gm@il@com  Wed Jan  2 14:47:52 2019
From: @mnicol@@ @ending from gm@il@com (=?UTF-8?B?Tmljb2zDoXMgU2FuIE1hcnTDrW4=?=)
Date: Wed, 2 Jan 2019 10:47:52 -0300
Subject: [R] Function for displaying arbitrary text as in 'help'.
Message-ID: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>

Hi all,

I am looking for a function that receives some text (any text) and displays
it to the user in the same way as the 'help' function does. Unlike 'cat',
that outputs the text in the current window, the one I'm looking for should
work as 'help' that, for example, in emacs ess opens a new buffer, in the
linux terminar displays it as the more command, etc. Is there any function
that does this?

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Jan  2 17:44:42 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 2 Jan 2019 11:44:42 -0500
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
Message-ID: <2f9369b4-f275-365f-5218-c91e4b8fc879@gmail.com>

On 02/01/2019 8:47 a.m., Nicol?s San Mart?n wrote:
> Hi all,
> 
> I am looking for a function that receives some text (any text) and displays
> it to the user in the same way as the 'help' function does. Unlike 'cat',
> that outputs the text in the current window, the one I'm looking for should
> work as 'help' that, for example, in emacs ess opens a new buffer, in the
> linux terminar displays it as the more command, etc. Is there any function
> that does this?

Help is printed by the function

  utils:::print.help_files_with_topic

which is quite a long function because of all the possible ways to 
display help.  You might be able to adapt it to your own needs, though 
it won't be trivial.

Duncan Murdoch


From murdoch@dunc@n @ending from gm@il@com  Wed Jan  2 17:48:40 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 2 Jan 2019 11:48:40 -0500
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
Message-ID: <96dc30bd-1d16-d74a-b06c-f2020a09a290@gmail.com>

On 02/01/2019 8:47 a.m., Nicol?s San Mart?n wrote:
> Hi all,
> 
> I am looking for a function that receives some text (any text) and displays
> it to the user in the same way as the 'help' function does. Unlike 'cat',
> that outputs the text in the current window, the one I'm looking for should
> work as 'help' that, for example, in emacs ess opens a new buffer, in the
> linux terminar displays it as the more command, etc. Is there any function
> that does this?
> 

The file.show() function will display a text file without all the bells 
and whistles of the help system; maybe it will be good enough.

Duncan Murdoch


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jan  2 18:31:52 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Jan 2019 09:31:52 -0800
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
Message-ID: <6AFF7255-E72C-4D5E-A453-A99F3D0BF6C2@dcn.davis.ca.us>

You can probably cobble together something, but spitting large chunks of information at users when the program wants to is bad design. It would be better to make a vignette or help file in a package and put the associated code from which you had been planning to spit out that text.

On January 2, 2019 5:47:52 AM PST, "Nicol?s San Mart?n" <smnicolas at gmail.com> wrote:
>Hi all,
>
>I am looking for a function that receives some text (any text) and
>displays
>it to the user in the same way as the 'help' function does. Unlike
>'cat',
>that outputs the text in the current window, the one I'm looking for
>should
>work as 'help' that, for example, in emacs ess opens a new buffer, in
>the
>linux terminar displays it as the more command, etc. Is there any
>function
>that does this?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @mnicol@@ @ending from gm@il@com  Wed Jan  2 19:24:48 2019
From: @mnicol@@ @ending from gm@il@com (=?UTF-8?B?Tmljb2zDoXMgU2FuIE1hcnTDrW4=?=)
Date: Wed, 2 Jan 2019 15:24:48 -0300
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <96dc30bd-1d16-d74a-b06c-f2020a09a290@gmail.com>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
 <96dc30bd-1d16-d74a-b06c-f2020a09a290@gmail.com>
Message-ID: <CALVaqJwqL4_VJKLHAhxAxkkFEgxwXLFNGnqR3A9AjUvZMJ6UUA@mail.gmail.com>

Yes, the file.show() is good enough. Thanks

El mi?., 2 ene. 2019 a las 13:48, Duncan Murdoch (<murdoch.duncan at gmail.com>)
escribi?:

> On 02/01/2019 8:47 a.m., Nicol?s San Mart?n wrote:
> > Hi all,
> >
> > I am looking for a function that receives some text (any text) and
> displays
> > it to the user in the same way as the 'help' function does. Unlike 'cat',
> > that outputs the text in the current window, the one I'm looking for
> should
> > work as 'help' that, for example, in emacs ess opens a new buffer, in the
> > linux terminar displays it as the more command, etc. Is there any
> function
> > that does this?
> >
>
> The file.show() function will display a text file without all the bells
> and whistles of the help system; maybe it will be good enough.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From @mnicol@@ @ending from gm@il@com  Wed Jan  2 19:36:52 2019
From: @mnicol@@ @ending from gm@il@com (=?UTF-8?B?Tmljb2zDoXMgU2FuIE1hcnTDrW4=?=)
Date: Wed, 2 Jan 2019 15:36:52 -0300
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <6AFF7255-E72C-4D5E-A453-A99F3D0BF6C2@dcn.davis.ca.us>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
 <6AFF7255-E72C-4D5E-A453-A99F3D0BF6C2@dcn.davis.ca.us>
Message-ID: <CALVaqJx4V+JqLeKftUiL-PSVh121+VmTH_RHdLY1bZw=g6HgJw@mail.gmail.com>

In this case I am not able to store the text in a file, because it could be
modified at any time and I need to display the most recent version (I fetch
it from the internet). But I can assume that it is correctly organized for
displaying.

El mi?., 2 ene. 2019 a las 14:31, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> You can probably cobble together something, but spitting large chunks of
> information at users when the program wants to is bad design. It would be
> better to make a vignette or help file in a package and put the associated
> code from which you had been planning to spit out that text.
>
> On January 2, 2019 5:47:52 AM PST, "Nicol?s San Mart?n" <
> smnicolas at gmail.com> wrote:
> >Hi all,
> >
> >I am looking for a function that receives some text (any text) and
> >displays
> >it to the user in the same way as the 'help' function does. Unlike
> >'cat',
> >that outputs the text in the current window, the one I'm looking for
> >should
> >work as 'help' that, for example, in emacs ess opens a new buffer, in
> >the
> >linux terminar displays it as the more command, etc. Is there any
> >function
> >that does this?
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Jan  2 20:24:42 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 2 Jan 2019 14:24:42 -0500
Subject: [R] Function for displaying arbitrary text as in 'help'.
In-Reply-To: <CALVaqJx4V+JqLeKftUiL-PSVh121+VmTH_RHdLY1bZw=g6HgJw@mail.gmail.com>
References: <CALVaqJy3ehFTJRZEd-DBgt8NdOYZXCNcU43GAs22JxwU4bvrYg@mail.gmail.com>
 <6AFF7255-E72C-4D5E-A453-A99F3D0BF6C2@dcn.davis.ca.us>
 <CALVaqJx4V+JqLeKftUiL-PSVh121+VmTH_RHdLY1bZw=g6HgJw@mail.gmail.com>
Message-ID: <577fd933-a074-5ffe-7054-9c1fef1d153c@gmail.com>

On 02/01/2019 1:36 p.m., Nicol?s San Mart?n wrote:
> In this case I am not able to store the text in a file, because it could be
> modified at any time and I need to display the most recent version (I fetch
> it from the internet). But I can assume that it is correctly organized for
> displaying.

It is possible to have dynamic content in help pages.  Web pages (e.g. 
generated using R-markdown or Shiny) are even more flexible for content, 
but maybe not meeting your requirement for displaying in an ESS buffer 
or Linux terminal window.

Duncan Murdoch

> 
> El mi?., 2 ene. 2019 a las 14:31, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
> escribi?:
> 
>> You can probably cobble together something, but spitting large chunks of
>> information at users when the program wants to is bad design. It would be
>> better to make a vignette or help file in a package and put the associated
>> code from which you had been planning to spit out that text.
>>
>> On January 2, 2019 5:47:52 AM PST, "Nicol?s San Mart?n" <
>> smnicolas at gmail.com> wrote:
>>> Hi all,
>>>
>>> I am looking for a function that receives some text (any text) and
>>> displays
>>> it to the user in the same way as the 'help' function does. Unlike
>>> 'cat',
>>> that outputs the text in the current window, the one I'm looking for
>>> should
>>> work as 'help' that, for example, in emacs ess opens a new buffer, in
>>> the
>>> linux terminar displays it as the more command, etc. Is there any
>>> function
>>> that does this?
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bog@@o@chri@tofer @ending from gm@il@com  Wed Jan  2 22:46:58 2019
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Thu, 3 Jan 2019 03:16:58 +0530
Subject: [R] Failed to install RQuantLib in Ubuntu machine
Message-ID: <CA+dpOJ=iFuY9Cu0RSWipYqDjjGA_3TtaETY8KPtduB7CDT7+HQ@mail.gmail.com>

Hi,

I was trying to install RQuantLib in my Ubuntu machine which failed with
below information :

*> install.packages('RQuantLib', INSTALL_opts = c('--no-lock'))*

*Installing package into ?/usr/local/lib/R/site-library?*

*(as ?lib? is unspecified)*

*trying URL 'https://cloud.r-project.org/src/contrib/RQuantLib_0.4.7.tar.gz
<https://cloud.r-project.org/src/contrib/RQuantLib_0.4.7.tar.gz>'*

*Content type 'application/x-gzip' length 189726 bytes (185 KB)*

*==================================================*

*downloaded 185 KB*


** installing *source* package ?RQuantLib? ...*

*** package ?RQuantLib? successfully unpacked and MD5 sums checked*

*checking whether the C++ compiler works... yes*

*checking for C++ compiler default output file name... a.out*

*checking for suffix of executables... *

*checking whether we are cross compiling... no*

*checking for suffix of object files... o*

*checking whether we are using the GNU C++ compiler... yes*

*checking whether g++ accepts -g... yes*

*checking how to run the C++ preprocessor... g++ -E*

*checking whether we are using the GNU C++ compiler... (cached) yes*

*checking whether g++ accepts -g... (cached) yes*

*checking for R... yes*

*checking for quantlib-config... yes*

*checking for Boost development files... yes*

*checking for minimal Boost version... yes*

*configure: creating ./config.status*

*config.status: creating src/Makevars*

*Completed configuration and ready to build.*

*** libs*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
RcppExports.cpp -o RcppExports.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
affine.cpp -o affine.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
asian.cpp -o asian.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
barrier_binary.cpp -o barrier_binary.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
bermudan.cpp -o bermudan.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
bonds.cpp -o bonds.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
calendars.cpp -o calendars.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
curves.cpp -o curves.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
dates.cpp -o dates.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
daycounter.cpp -o daycounter.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
discount.cpp -o discount.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
hullwhite.cpp -o hullwhite.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
implieds.cpp -o implieds.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
modules.cpp -o modules.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
sabr.cpp -o sabr.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
schedule.cpp -o schedule.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
utils.cpp -o utils.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
vanilla.cpp -o vanilla.o*

*g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
-I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
-I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
zero.cpp -o zero.o*

*g++ -std=gnu++11 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o RQuantLib.so RcppExports.o affine.o asian.o
barrier_binary.o bermudan.o bonds.o calendars.o curves.o dates.o
daycounter.o discount.o hullwhite.o implieds.o modules.o sabr.o schedule.o
utils.o vanilla.o zero.o -L/usr/local/lib -lQuantLib -fopenmp
-L/usr/lib/R/lib -lR*

*installing to /usr/local/lib/R/site-library/RQuantLib/libs*

*** R*

*** data*

*** demo*

*** inst*

*** preparing package for lazy loading*

*** help*

**** installing help indices*

*** building package indices*

*** testing if installed package can be loaded*


* *** caught segfault ****

*address 0x7f57dba1d9a0, cause 'invalid permissions'*


*Traceback:*

* 1: dyn.load(file, DLLpath = DLLpath, ...)*

* 2: library.dynam(lib, package, package.lib)*

* 3: loadNamespace(package, lib.loc)*

* 4: doTryCatch(return(expr), name, parentenv, handler)*

* 5: tryCatchOne(expr, names, parentenv, handlers[[1L]])*

* 6: tryCatchList(expr, classes, parentenv, handlers)*

* 7: tryCatch({    attr(package, "LibPath") <- which.lib.loc    ns <-
loadNamespace(package, lib.loc)    env <- attachNamespace(ns, pos = pos,
deps)}, error = function(e) {    P <- if (!is.null(cc <- conditionCall(e)))
        paste(" in", deparse(cc)[1L])    else ""    msg <-
gettextf("package or namespace load failed for %s%s:\n %s",
sQuote(package), P, conditionMessage(e))    if (logical.return)
message(paste("Error:", msg), domain = NA)    else stop(msg, call. = FALSE,
domain = NA)})*

* 8: library(pkg_name, lib.loc = lib, character.only = TRUE, logical.return
= TRUE)*

* 9: withCallingHandlers(expr, packageStartupMessage = function(c)
invokeRestart("muffleMessage"))*

*10: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
character.only = TRUE, logical.return = TRUE))*

*11: doTryCatch(return(expr), name, parentenv, handler)*

*12: tryCatchOne(expr, names, parentenv, handlers[[1L]])*

*13: tryCatchList(expr, classes, parentenv, handlers)*

*14: tryCatch(expr, error = function(e) {    call <- conditionCall(e)    if
(!is.null(call)) {        if (identical(call[[1L]], quote(doTryCatch)))
        call <- sys.call(-4L)        dcall <- deparse(call)[1L]
prefix <- paste("Error in", dcall, ": ")        LONG <- 75L        msg <-
conditionMessage(e)        sm <- strsplit(msg, "\n")[[1L]]        w <- 14L
+ nchar(dcall, type = "w") + nchar(sm[1L], type = "w")        if (is.na
<http://is.na>(w))             w <- 14L + nchar(dcall, type = "b") +
nchar(sm[1L],                 type = "b")        if (w > LONG)
prefix <- paste0(prefix, "\n  ")    }    else prefix <- "Error : "    msg
<- paste0(prefix, conditionMessage(e), "\n")
.Internal(seterrmessage(msg[1L]))    if (!silent &&
identical(getOption("show.error.messages"),         TRUE)) {
cat(msg, file = outFile)        .Internal(printDeferredWarnings())    }
invisible(structure(msg, class = "try-error", condition = e))})*

*15: try(suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
  character.only = TRUE, logical.return = TRUE)))*

*16: tools:::.test_load_package("RQuantLib",
"/usr/local/lib/R/site-library")*

*An irrecoverable exception occurred. R is aborting now ...*

*Segmentation fault (core dumped)*

*ERROR: loading failed*

** removing ?/usr/local/lib/R/site-library/RQuantLib?*


*The downloaded source packages are in*

* ?/tmp/RtmpPvzBa6/downloaded_packages?*

*Warning message:*

*In install.packages("RQuantLib", INSTALL_opts = c("--no-lock")) :*

*  installation of package ?RQuantLib? had non-zero exit status*


* Below is my SessionInfo :*


> sessionInfo()

R version 3.4.4 (2018-03-15)

Platform: x86_64-pc-linux-gnu (64-bit)

Running under: Ubuntu 16.04.4 LTS


Matrix products: default

BLAS: /usr/lib/libblas/libblas.so.3.6.0

LAPACK: /usr/lib/lapack/liblapack.so.3.6.0


locale:

 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C

 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8

 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8

 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C

 [9] LC_ADDRESS=C               LC_TELEPHONE=C

[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_3.4.4 tools_3.4.4


Any help will be highly appreciated. Thank,

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Thu Jan  3 02:55:53 2019
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 3 Jan 2019 12:55:53 +1100
Subject: [R] Plotting rgb proportions in R
In-Reply-To: <CAKpKZ1z78pMsY46_ciX7=KtcL31ZGw6XXu9=v05PM7ZxeFfLDg@mail.gmail.com>
References: <CAKpKZ1zwnNcOeF8YwqNc8PxyRmhLwhS6p7CW5rORhey69KGNpg@mail.gmail.com>
 <CA+8X3fUaF_BUw9QUg3QZ57GiNAX8n+CZuRhW9kJQxVf4FEFZuQ@mail.gmail.com>
 <CAGxFJbQODiuWSL_QTeYT=sHKJnR+ZpvRca233rT4-mEXisK9_g@mail.gmail.com>
 <f858814ee44443b4a66015138a5312fb@SRVEXCHCM1302.precheza.cz>
 <CAKpKZ1z78pMsY46_ciX7=KtcL31ZGw6XXu9=v05PM7ZxeFfLDg@mail.gmail.com>
Message-ID: <CA+8X3fVhYqqL=YzGhio+q9g0vU9f1H6QZbSfsk3+FXpCd+Qr5Q@mail.gmail.com>

Hi Tasha,
Using the original sample you sent:

rgb_prop<-read.table(text="Red Green Blue pct
249 158 37 56.311
249 158 68 4.319
249 158 98 0.058
249 128 7 13.965
249 128 37 12.87
188 128 37 0.029
249 128 68 0.161
188 128 68 0.015
188 98 7 0.029
219 128 7 2.773
219 128 37 2.583
188 98 68 0.058
219 128 68 0.525
249 188 37 0.876
249 188 68 1.08
219 98 7 0.482
249 188 98 0.015
249 158 7 3.852",header=TRUE)
rgb_prop$Red<-rgb_prop$Red/255
rgb_prop$Green<-rgb_prop$Green/255
rgb_prop$Blue<-rgb_prop$Blue/255
# the matrix format forces the stacked bar display
barplot(matrix(rgb_prop$pct,ncol=1),
 col=rgb(rgb_prop[,c("Red","Green","Blue")]),beside=FALSE)

Of course you can add more stacks by increasing the number of columns in
the "x" matrix.

Jim

On Thu, Jan 3, 2019 at 3:33 AM Tasha O'Hara <tasha.eileen at gmail.com> wrote:

> I apologize for the late reply after the holidays. I really appreciate all
> the data visualization suggestions. The scatterplot works very well, but I
> do have >400 specimen with at least 5-20 colors each, so a stacked
> barchart of each specific color proportion would be most useful to show
> uniformity within each specimen. Below is an example of what I would like
> to do, but instead of generic colors, I am hoping to plot the actual RGB
> proportions for each.
> [image: image.png]
>
> On Wed, Dec 19, 2018 at 5:28 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
>> > Sent: Wednesday, December 19, 2018 5:26 AM
>> > To: Jim Lemon <drjimlemon at gmail.com>
>> > Cc: R-help <r-help at r-project.org>
>> > Subject: Re: [R] Plotting rgb proportions in R
>> >
>> > 3-d Proportions must sum to 1and are thus actually 2-d and should
>> preferaby
>> > be plotted as a ternary plot. Several r packages will do this for you,
>> e.g.
>> > package Ternary. Search "ternary plots" on rseek.org for others.
>>
>> From which I would recommend ggtern. Sometimes a bit tricky but quite
>> handy, especially when you consider some grouping.
>>
>> Cheers
>> Petr
>>
>> >
>> > -- Bert
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> and
>> > sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Tue, Dec 18, 2018 at 3:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>> >
>> > > Hi Tasha,
>> > > I may be right off the track, but you could plot RGB proportions on a
>> > > 3D plot. The easiest way I can think if would be to convert your 0-255
>> > > values to proportions:
>> > >
>> > > rgb_prop<-read.table(text="Red Green Blue pct
>> > > 249 158 37 56.311
>> > > 249 158 68 4.319
>> > > 249 158 98 0.058
>> > > 249 128 7 13.965
>> > > 249 128 37 12.87
>> > > 188 128 37 0.029
>> > > 249 128 68 0.161
>> > > 188 128 68 0.015
>> > > 188 98 7 0.029
>> > > 219 128 7 2.773
>> > > 219 128 37 2.583
>> > > 188 98 68 0.058
>> > > 219 128 68 0.525
>> > > 249 188 37 0.876
>> > > 249 188 68 1.08
>> > > 219 98 7 0.482
>> > > 249 188 98 0.015
>> > > 249 158 7 3.852",header=TRUE)
>> > > rgb_prop$Red<-rgb_prop$Red/255
>> > > rgb_prop$Green<-rgb_prop$Green/255
>> > > rgb_prop$Blue<-rgb_prop$Blue/255
>> > > library(scatterplot3d)
>> > > scatterplot3d(rgb_prop[,1:3],cex.symbols=sqrt(rgb_prop[,4]),
>> > >  color=rgb(rgb_prop[,1],rgb_prop[,2],rgb_prop[,3]),pch=19)
>> > >
>> > > then plot the RGB values on a 3D scatterplot. I have included
>> > > arguments to make the symbols the actual RGB colors that you specify
>> > > and their size proportional to the square root of the percentages.
>> > >
>> > > Jim
>> > >
>> > > On Wed, Dec 19, 2018 at 5:17 AM Tasha O'Hara <tasha.eileen at gmail.com>
>> > > wrote:
>> > > >
>> > > > Hello,
>> > > >
>> > > > I am trying to plot specific rgb color proportions of a marine
>> > > > specimen
>> > > in
>> > > > a stacked plot using R and I was looking for some help. I have
>> > > > several rgb proportions per specimen (an example of one is below).
>> > > > I've run into different examples of people using vegan or grDevices.
>> > > > Can anyone help
>> > > with
>> > > > this?
>> > > >
>> > > > Red    Green  Blue   %
>> > > > 249 158 37 56.311
>> > > > 249 158 68 4.319
>> > > > 249 158 98 0.058
>> > > > 249 128 7 13.965
>> > > > 249 128 37 12.87
>> > > > 188 128 37 0.029
>> > > > 249 128 68 0.161
>> > > > 188 128 68 0.015
>> > > > 188 98 7 0.029
>> > > > 219 128 7 2.773
>> > > > 219 128 37 2.583
>> > > > 188 98 68 0.058
>> > > > 219 128 68 0.525
>> > > > 249 188 37 0.876
>> > > > 249 188 68 1.08
>> > > > 219 98 7 0.482
>> > > > 249 188 98 0.015
>> > > > 249 158 7 3.852
>> > > >
>> > > >         [[alternative HTML version deleted]]
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>> about processing and protection of business partner?s personal data are
>> available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>

	[[alternative HTML version deleted]]


From jo@h@m@ulrich @ending from gm@il@com  Thu Jan  3 12:54:03 2019
From: jo@h@m@ulrich @ending from gm@il@com (Joshua Ulrich)
Date: Thu, 3 Jan 2019 05:54:03 -0600
Subject: [R] Failed to install RQuantLib in Ubuntu machine
In-Reply-To: <CA+dpOJ=iFuY9Cu0RSWipYqDjjGA_3TtaETY8KPtduB7CDT7+HQ@mail.gmail.com>
References: <CA+dpOJ=iFuY9Cu0RSWipYqDjjGA_3TtaETY8KPtduB7CDT7+HQ@mail.gmail.com>
Message-ID: <CAPPM_gTSAEUT6c5hxMrDRMHeVbeCKMs+vo7QAZNp1LBkZstWEw@mail.gmail.com>

The easiest way to install RQuantLib on Ubuntu is to use the
pre-compiled binaries from Michael Rutter's PPA.  See the instructions
here: https://cran.r-project.org/bin/linux/ubuntu/README.html.

You will want to install the r-cran-rquantlib package after you've
added the PPA to your sources list.

Also note that the instructions say, "The best place to report
problems with these packages or ask R questions specific to Ubuntu is
the R-SIG-Debian mailing list." So you should get better/faster help
if you post there instead of this general mailing list.

Best,
Josh

On Wed, Jan 2, 2019 at 3:47 PM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> I was trying to install RQuantLib in my Ubuntu machine which failed with
> below information :
>
> *> install.packages('RQuantLib', INSTALL_opts = c('--no-lock'))*
>
> *Installing package into ?/usr/local/lib/R/site-library?*
>
> *(as ?lib? is unspecified)*
>
> *trying URL 'https://cloud.r-project.org/src/contrib/RQuantLib_0.4.7.tar.gz
> <https://cloud.r-project.org/src/contrib/RQuantLib_0.4.7.tar.gz>'*
>
> *Content type 'application/x-gzip' length 189726 bytes (185 KB)*
>
> *==================================================*
>
> *downloaded 185 KB*
>
>
> ** installing *source* package ?RQuantLib? ...*
>
> *** package ?RQuantLib? successfully unpacked and MD5 sums checked*
>
> *checking whether the C++ compiler works... yes*
>
> *checking for C++ compiler default output file name... a.out*
>
> *checking for suffix of executables... *
>
> *checking whether we are cross compiling... no*
>
> *checking for suffix of object files... o*
>
> *checking whether we are using the GNU C++ compiler... yes*
>
> *checking whether g++ accepts -g... yes*
>
> *checking how to run the C++ preprocessor... g++ -E*
>
> *checking whether we are using the GNU C++ compiler... (cached) yes*
>
> *checking whether g++ accepts -g... (cached) yes*
>
> *checking for R... yes*
>
> *checking for quantlib-config... yes*
>
> *checking for Boost development files... yes*
>
> *checking for minimal Boost version... yes*
>
> *configure: creating ./config.status*
>
> *config.status: creating src/Makevars*
>
> *Completed configuration and ready to build.*
>
> *** libs*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> RcppExports.cpp -o RcppExports.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> affine.cpp -o affine.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> asian.cpp -o asian.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> barrier_binary.cpp -o barrier_binary.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> bermudan.cpp -o bermudan.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> bonds.cpp -o bonds.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> calendars.cpp -o calendars.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> curves.cpp -o curves.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> dates.cpp -o dates.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> daycounter.cpp -o daycounter.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> discount.cpp -o discount.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> hullwhite.cpp -o hullwhite.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> implieds.cpp -o implieds.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> modules.cpp -o modules.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> sabr.cpp -o sabr.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> schedule.cpp -o schedule.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> utils.cpp -o utils.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> vanilla.cpp -o vanilla.o*
>
> *g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG
> -I"/usr/local/lib/R/site-library/Rcpp/include"   -g -O2
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -I/usr/local/include -fpermissive -I../inst/include
> -I. -DBOOST_NO_AUTO_PTR -fopenmp -fpic  -g -O2 -fstack-protector-strong
> -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c
> zero.cpp -o zero.o*
>
> *g++ -std=gnu++11 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o RQuantLib.so RcppExports.o affine.o asian.o
> barrier_binary.o bermudan.o bonds.o calendars.o curves.o dates.o
> daycounter.o discount.o hullwhite.o implieds.o modules.o sabr.o schedule.o
> utils.o vanilla.o zero.o -L/usr/local/lib -lQuantLib -fopenmp
> -L/usr/lib/R/lib -lR*
>
> *installing to /usr/local/lib/R/site-library/RQuantLib/libs*
>
> *** R*
>
> *** data*
>
> *** demo*
>
> *** inst*
>
> *** preparing package for lazy loading*
>
> *** help*
>
> **** installing help indices*
>
> *** building package indices*
>
> *** testing if installed package can be loaded*
>
>
> * *** caught segfault ****
>
> *address 0x7f57dba1d9a0, cause 'invalid permissions'*
>
>
> *Traceback:*
>
> * 1: dyn.load(file, DLLpath = DLLpath, ...)*
>
> * 2: library.dynam(lib, package, package.lib)*
>
> * 3: loadNamespace(package, lib.loc)*
>
> * 4: doTryCatch(return(expr), name, parentenv, handler)*
>
> * 5: tryCatchOne(expr, names, parentenv, handlers[[1L]])*
>
> * 6: tryCatchList(expr, classes, parentenv, handlers)*
>
> * 7: tryCatch({    attr(package, "LibPath") <- which.lib.loc    ns <-
> loadNamespace(package, lib.loc)    env <- attachNamespace(ns, pos = pos,
> deps)}, error = function(e) {    P <- if (!is.null(cc <- conditionCall(e)))
>         paste(" in", deparse(cc)[1L])    else ""    msg <-
> gettextf("package or namespace load failed for %s%s:\n %s",
> sQuote(package), P, conditionMessage(e))    if (logical.return)
> message(paste("Error:", msg), domain = NA)    else stop(msg, call. = FALSE,
> domain = NA)})*
>
> * 8: library(pkg_name, lib.loc = lib, character.only = TRUE, logical.return
> = TRUE)*
>
> * 9: withCallingHandlers(expr, packageStartupMessage = function(c)
> invokeRestart("muffleMessage"))*
>
> *10: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
> character.only = TRUE, logical.return = TRUE))*
>
> *11: doTryCatch(return(expr), name, parentenv, handler)*
>
> *12: tryCatchOne(expr, names, parentenv, handlers[[1L]])*
>
> *13: tryCatchList(expr, classes, parentenv, handlers)*
>
> *14: tryCatch(expr, error = function(e) {    call <- conditionCall(e)    if
> (!is.null(call)) {        if (identical(call[[1L]], quote(doTryCatch)))
>         call <- sys.call(-4L)        dcall <- deparse(call)[1L]
> prefix <- paste("Error in", dcall, ": ")        LONG <- 75L        msg <-
> conditionMessage(e)        sm <- strsplit(msg, "\n")[[1L]]        w <- 14L
> + nchar(dcall, type = "w") + nchar(sm[1L], type = "w")        if (is.na
> <http://is.na>(w))             w <- 14L + nchar(dcall, type = "b") +
> nchar(sm[1L],                 type = "b")        if (w > LONG)
> prefix <- paste0(prefix, "\n  ")    }    else prefix <- "Error : "    msg
> <- paste0(prefix, conditionMessage(e), "\n")
> .Internal(seterrmessage(msg[1L]))    if (!silent &&
> identical(getOption("show.error.messages"),         TRUE)) {
> cat(msg, file = outFile)        .Internal(printDeferredWarnings())    }
> invisible(structure(msg, class = "try-error", condition = e))})*
>
> *15: try(suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
>   character.only = TRUE, logical.return = TRUE)))*
>
> *16: tools:::.test_load_package("RQuantLib",
> "/usr/local/lib/R/site-library")*
>
> *An irrecoverable exception occurred. R is aborting now ...*
>
> *Segmentation fault (core dumped)*
>
> *ERROR: loading failed*
>
> ** removing ?/usr/local/lib/R/site-library/RQuantLib?*
>
>
> *The downloaded source packages are in*
>
> * ?/tmp/RtmpPvzBa6/downloaded_packages?*
>
> *Warning message:*
>
> *In install.packages("RQuantLib", INSTALL_opts = c("--no-lock")) :*
>
> *  installation of package ?RQuantLib? had non-zero exit status*
>
>
> * Below is my SessionInfo :*
>
>
> > sessionInfo()
>
> R version 3.4.4 (2018-03-15)
>
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> Running under: Ubuntu 16.04.4 LTS
>
>
> Matrix products: default
>
> BLAS: /usr/lib/libblas/libblas.so.3.6.0
>
> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>
>
> locale:
>
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> loaded via a namespace (and not attached):
>
> [1] compiler_3.4.4 tools_3.4.4
>
>
> Any help will be highly appreciated. Thank,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2018 | www.rinfinance.com


From benoit@g@l@rne@u @ending from polymtl@c@  Thu Jan  3 15:50:22 2019
From: benoit@g@l@rne@u @ending from polymtl@c@ (Benoit Galarneau)
Date: Thu, 03 Jan 2019 14:50:22 +0000
Subject: [R] Accessing Data Frame
Message-ID: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>

Hi everyone,
I'm new to the R world.
Probably a newbie question but I am stuck with some concept with data frame.
I am following some examples in the "Hands-On Programming with R".

In short, how can I access/filter items in a data frame using a variable.

One example consists of manipulating elements from a deck of card:

> deck
     face     suit value
1   king   spades    13
2  queen   spades    12
3   jack   spades    11
4    ten   spades    10
etc.

Let's say I want to remove or filter out the first card. I know I  
could do deck[-1].

But let's say I have: topCard <- deck[1,]

topCard is then a list of 3 elements
> topCard
   face   suit value
1 king spades    13

My question is the following, how can I remove or filter out the deck  
using the topCard variable.

In my programmer's head, something similar to this should "work":
> deck[10,]
    face   suit value
10 four spades     4
> aCard <- deck[10,]
> aCard
    face   suit value
10 four spades     4
> deck[aCard]
Error in `[.default`(deck, aCard) : invalid subscript type 'list'

Wihout having to specify all elements in the logical tests.

deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==  
aCard$value,]
    face   suit value
10 four spades     4


From ruipb@rr@d@@ @ending from @@po@pt  Thu Jan  3 17:46:44 2019
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 3 Jan 2019 16:46:44 +0000
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
Message-ID: <d9510555-9090-53f1-23db-522bf5b45254@sapo.pt>

Hello,

Inline.

?s 14:50 de 03/01/2019, Benoit Galarneau escreveu:
> Hi everyone,
> I'm new to the R world.
> Probably a newbie question but I am stuck with some concept with data 
> frame.
> I am following some examples in the "Hands-On Programming with R".
> 
> In short, how can I access/filter items in a data frame using a variable.
> 
> One example consists of manipulating elements from a deck of card:
> 
>> deck
>  ??? face???? suit value
> 1?? king?? spades??? 13
> 2? queen?? spades??? 12
> 3?? jack?? spades??? 11
> 4??? ten?? spades??? 10
> etc.
> 
> Let's say I want to remove or filter out the first card. I know I could 
> do deck[-1].

No, to filter out the first card you need a comma after the -1.

deck[-1, ]    # filter the first row out
deck[-1]      # filter the first column out

> 
> But let's say I have: topCard <- deck[1,]
> 
> topCard is then a list of 3 elements
>> topCard
>  ? face?? suit value
> 1 king spades??? 13
> 
> My question is the following, how can I remove or filter out the deck 
> using the topCard variable.

merge(topCard, deck, all.x = TRUE, all.y = FALSE)

Hope this helps,

Rui Barradas


> 
> In my programmer's head, something similar to this should "work":
>> deck[10,]
>  ?? face?? suit value
> 10 four spades???? 4
>> aCard <- deck[10,]
>> aCard
>  ?? face?? suit value
> 10 four spades???? 4
>> deck[aCard]
> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
> 
> Wihout having to specify all elements in the logical tests.
> 
> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value == 
> aCard$value,]
>  ?? face?? suit value
> 10 four spades???? 4
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From i@t@z@hn @ending from gm@il@com  Thu Jan  3 17:54:51 2019
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Thu, 3 Jan 2019 11:54:51 -0500
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
Message-ID: <CA+vqiLGm3m3ms-oa3-WJncp8s4QK=MjgHv8=g7PDXYqBFVDxrg@mail.gmail.com>

Hi Benoit,

You can select rows from deck matched in aCard using

merge(deck, aCard)

Selecting rows that don't match is bit more difficult. You could do
something like

isin <- apply(mapply(function(x, y) x %in% y, deck, topCard),
               1,
               all)
deck[!isin, ]

perhaps.

Alternatively, you can use anti_join from the dplyr package:

library(dplyr)
anti_join(deck, topCard)

Best,
Ista

On Thu, Jan 3, 2019 at 10:38 AM Benoit Galarneau
<benoit.galarneau at polymtl.ca> wrote:
>
> Hi everyone,
> I'm new to the R world.
> Probably a newbie question but I am stuck with some concept with data frame.
> I am following some examples in the "Hands-On Programming with R".
>
> In short, how can I access/filter items in a data frame using a variable.
>
> One example consists of manipulating elements from a deck of card:
>
> > deck
>      face     suit value
> 1   king   spades    13
> 2  queen   spades    12
> 3   jack   spades    11
> 4    ten   spades    10
> etc.
>
> Let's say I want to remove or filter out the first card. I know I
> could do deck[-1].
>
> But let's say I have: topCard <- deck[1,]
>
> topCard is then a list of 3 elements
> > topCard
>    face   suit value
> 1 king spades    13
>
> My question is the following, how can I remove or filter out the deck
> using the topCard variable.
>
> In my programmer's head, something similar to this should "work":
> > deck[10,]
>     face   suit value
> 10 four spades     4
> > aCard <- deck[10,]
> > aCard
>     face   suit value
> 10 four spades     4
> > deck[aCard]
> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>
> Wihout having to specify all elements in the logical tests.
>
> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
> aCard$value,]
>     face   suit value
> 10 four spades     4
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From benoit@g@l@rne@u @ending from polymtl@c@  Thu Jan  3 18:15:41 2019
From: benoit@g@l@rne@u @ending from polymtl@c@ (Benoit Galarneau)
Date: Thu, 03 Jan 2019 17:15:41 +0000
Subject: [R] Accessing Data Frame
In-Reply-To: <CA+vqiLGm3m3ms-oa3-WJncp8s4QK=MjgHv8=g7PDXYqBFVDxrg@mail.gmail.com>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CA+vqiLGm3m3ms-oa3-WJncp8s4QK=MjgHv8=g7PDXYqBFVDxrg@mail.gmail.com>
Message-ID: <20190103171541.Horde.PiupzEw_trX3WDAaYTM9V75@www.imp.polymtl.ca>

You are correct, the anti_join is working fine.
However, I still find it strange there is no "quick" way to find the  
index of an item extracted from the data frame.

This works as it returns the deck without the card no 10.
aCard = deck[10,]
cardNo = which(deck$value == aCard$value & deck$suit == aCard$suit)
deck[-cardNo,]

But I'm still puzzled by the complexity of finding back the index of  
the card with the long statement.

Another approach that "works" is the following, but I still find it  
strange to depend on data frame row names to find the index:
cardNo <- as.numeric(row.names(aCard))

Apologies if the above question are strange. I'm coming C++ world with  
some bias with objects. Again, since "aCard" is extracted from the  
data frame, I assume (bias?) there would be a simple way to find back  
the item in the data frame it came frame. Some kind of indexOf() or  
similar on the container and item.

Benoit

Ista Zahn <istazahn at gmail.com> a ?crit?:

> Hi Benoit,
>
> You can select rows from deck matched in aCard using
>
> merge(deck, aCard)
>
> Selecting rows that don't match is bit more difficult. You could do
> something like
>
> isin <- apply(mapply(function(x, y) x %in% y, deck, topCard),
>                1,
>                all)
> deck[!isin, ]
>
> perhaps.
>
> Alternatively, you can use anti_join from the dplyr package:
>
> library(dplyr)
> anti_join(deck, topCard)
>
> Best,
> Ista
>
> On Thu, Jan 3, 2019 at 10:38 AM Benoit Galarneau
> <benoit.galarneau at polymtl.ca> wrote:
>>
>> Hi everyone,
>> I'm new to the R world.
>> Probably a newbie question but I am stuck with some concept with data frame.
>> I am following some examples in the "Hands-On Programming with R".
>>
>> In short, how can I access/filter items in a data frame using a variable.
>>
>> One example consists of manipulating elements from a deck of card:
>>
>> > deck
>>      face     suit value
>> 1   king   spades    13
>> 2  queen   spades    12
>> 3   jack   spades    11
>> 4    ten   spades    10
>> etc.
>>
>> Let's say I want to remove or filter out the first card. I know I
>> could do deck[-1].
>>
>> But let's say I have: topCard <- deck[1,]
>>
>> topCard is then a list of 3 elements
>> > topCard
>>    face   suit value
>> 1 king spades    13
>>
>> My question is the following, how can I remove or filter out the deck
>> using the topCard variable.
>>
>> In my programmer's head, something similar to this should "work":
>> > deck[10,]
>>     face   suit value
>> 10 four spades     4
>> > aCard <- deck[10,]
>> > aCard
>>     face   suit value
>> 10 four spades     4
>> > deck[aCard]
>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>
>> Wihout having to specify all elements in the logical tests.
>>
>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
>> aCard$value,]
>>     face   suit value
>> 10 four spades     4
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jan  3 18:27:20 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Jan 2019 09:27:20 -0800
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
Message-ID: <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>

>In my programmer's head, something similar to this should "work": ...
> deck[aCard]

There are some people who agree with you... see the data.table package, which can be made to behave like this.

Keep in mind that the aCard data frame in general may have a different set of column names or more than one row. (I would be concerned that the logic of your application was inefficiently designed if `deck` actually has the same columns as `aCard` as in your example.) Others have pointed out that data frames are typically combined using the merge function, which allows matching columns to be specified very flexibly.


On January 3, 2019 6:50:22 AM PST, Benoit Galarneau <benoit.galarneau at polymtl.ca> wrote:
>Hi everyone,
>I'm new to the R world.
>Probably a newbie question but I am stuck with some concept with data
>frame.
>I am following some examples in the "Hands-On Programming with R".
>
>In short, how can I access/filter items in a data frame using a
>variable.
>
>One example consists of manipulating elements from a deck of card:
>
>> deck
>     face     suit value
>1   king   spades    13
>2  queen   spades    12
>3   jack   spades    11
>4    ten   spades    10
>etc.
>
>Let's say I want to remove or filter out the first card. I know I  
>could do deck[-1].
>
>But let's say I have: topCard <- deck[1,]
>
>topCard is then a list of 3 elements
>> topCard
>   face   suit value
>1 king spades    13
>
>My question is the following, how can I remove or filter out the deck  
>using the topCard variable.
>
>In my programmer's head, something similar to this should "work":
>> deck[10,]
>    face   suit value
>10 four spades     4
>> aCard <- deck[10,]
>> aCard
>    face   suit value
>10 four spades     4
>> deck[aCard]
>Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>
>Wihout having to specify all elements in the logical tests.
>
>deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value == 
>
>aCard$value,]
>    face   suit value
>10 four spades     4
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jan  3 18:33:00 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Jan 2019 09:33:00 -0800
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103171541.Horde.PiupzEw_trX3WDAaYTM9V75@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CA+vqiLGm3m3ms-oa3-WJncp8s4QK=MjgHv8=g7PDXYqBFVDxrg@mail.gmail.com>
 <20190103171541.Horde.PiupzEw_trX3WDAaYTM9V75@www.imp.polymtl.ca>
Message-ID: <D7D58D47-5243-4043-8B7B-248C6DAEB884@dcn.davis.ca.us>

You would be better served to reference SQL semantics (relational identity) than Network database semantics (object identifiers) for understanding data frames. The row in `aCard` is not the same as the row in `deck`, and you should not construct your algorithms based on individual rows but rather as sets of rows.

On January 3, 2019 9:15:41 AM PST, Benoit Galarneau <benoit.galarneau at polymtl.ca> wrote:
>You are correct, the anti_join is working fine.
>However, I still find it strange there is no "quick" way to find the  
>index of an item extracted from the data frame.
>
>This works as it returns the deck without the card no 10.
>aCard = deck[10,]
>cardNo = which(deck$value == aCard$value & deck$suit == aCard$suit)
>deck[-cardNo,]
>
>But I'm still puzzled by the complexity of finding back the index of  
>the card with the long statement.
>
>Another approach that "works" is the following, but I still find it  
>strange to depend on data frame row names to find the index:
>cardNo <- as.numeric(row.names(aCard))
>
>Apologies if the above question are strange. I'm coming C++ world with 
>
>some bias with objects. Again, since "aCard" is extracted from the  
>data frame, I assume (bias?) there would be a simple way to find back  
>the item in the data frame it came frame. Some kind of indexOf() or  
>similar on the container and item.
>
>Benoit
>
>Ista Zahn <istazahn at gmail.com> a ?crit?:
>
>> Hi Benoit,
>>
>> You can select rows from deck matched in aCard using
>>
>> merge(deck, aCard)
>>
>> Selecting rows that don't match is bit more difficult. You could do
>> something like
>>
>> isin <- apply(mapply(function(x, y) x %in% y, deck, topCard),
>>                1,
>>                all)
>> deck[!isin, ]
>>
>> perhaps.
>>
>> Alternatively, you can use anti_join from the dplyr package:
>>
>> library(dplyr)
>> anti_join(deck, topCard)
>>
>> Best,
>> Ista
>>
>> On Thu, Jan 3, 2019 at 10:38 AM Benoit Galarneau
>> <benoit.galarneau at polymtl.ca> wrote:
>>>
>>> Hi everyone,
>>> I'm new to the R world.
>>> Probably a newbie question but I am stuck with some concept with
>data frame.
>>> I am following some examples in the "Hands-On Programming with R".
>>>
>>> In short, how can I access/filter items in a data frame using a
>variable.
>>>
>>> One example consists of manipulating elements from a deck of card:
>>>
>>> > deck
>>>      face     suit value
>>> 1   king   spades    13
>>> 2  queen   spades    12
>>> 3   jack   spades    11
>>> 4    ten   spades    10
>>> etc.
>>>
>>> Let's say I want to remove or filter out the first card. I know I
>>> could do deck[-1].
>>>
>>> But let's say I have: topCard <- deck[1,]
>>>
>>> topCard is then a list of 3 elements
>>> > topCard
>>>    face   suit value
>>> 1 king spades    13
>>>
>>> My question is the following, how can I remove or filter out the
>deck
>>> using the topCard variable.
>>>
>>> In my programmer's head, something similar to this should "work":
>>> > deck[10,]
>>>     face   suit value
>>> 10 four spades     4
>>> > aCard <- deck[10,]
>>> > aCard
>>>     face   suit value
>>> 10 four spades     4
>>> > deck[aCard]
>>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>>
>>> Wihout having to specify all elements in the logical tests.
>>>
>>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value
>==
>>> aCard$value,]
>>>     face   suit value
>>> 10 four spades     4
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From benoit@g@l@rne@u @ending from polymtl@c@  Thu Jan  3 18:39:44 2019
From: benoit@g@l@rne@u @ending from polymtl@c@ (Benoit Galarneau)
Date: Thu, 03 Jan 2019 17:39:44 +0000
Subject: [R] Accessing Data Frame
In-Reply-To: <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
Message-ID: <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>

Thanks for the feedback.
Point taken about the data.table package, I will take a look for sure.  
As I am new to the R programming, I'm exploring with the default  
libraries as a start.

I have various options that works like this one:

topCard <- deck[1,]
#Remove card from deck using row name
deck <- deck[!rownames(deck) %in% row.names(topCard),]

Is it recommended/safe/good practice to work on items using the item names?

Benoit

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:

>> In my programmer's head, something similar to this should "work": ...
>> deck[aCard]
>
> There are some people who agree with you... see the data.table  
> package, which can be made to behave like this.
>
> Keep in mind that the aCard data frame in general may have a  
> different set of column names or more than one row. (I would be  
> concerned that the logic of your application was inefficiently  
> designed if `deck` actually has the same columns as `aCard` as in  
> your example.) Others have pointed out that data frames are  
> typically combined using the merge function, which allows matching  
> columns to be specified very flexibly.
>
>
> On January 3, 2019 6:50:22 AM PST, Benoit Galarneau  
> <benoit.galarneau at polymtl.ca> wrote:
>> Hi everyone,
>> I'm new to the R world.
>> Probably a newbie question but I am stuck with some concept with data
>> frame.
>> I am following some examples in the "Hands-On Programming with R".
>>
>> In short, how can I access/filter items in a data frame using a
>> variable.
>>
>> One example consists of manipulating elements from a deck of card:
>>
>>> deck
>>     face     suit value
>> 1   king   spades    13
>> 2  queen   spades    12
>> 3   jack   spades    11
>> 4    ten   spades    10
>> etc.
>>
>> Let's say I want to remove or filter out the first card. I know I
>> could do deck[-1].
>>
>> But let's say I have: topCard <- deck[1,]
>>
>> topCard is then a list of 3 elements
>>> topCard
>>   face   suit value
>> 1 king spades    13
>>
>> My question is the following, how can I remove or filter out the deck
>> using the topCard variable.
>>
>> In my programmer's head, something similar to this should "work":
>>> deck[10,]
>>    face   suit value
>> 10 four spades     4
>>> aCard <- deck[10,]
>>> aCard
>>    face   suit value
>> 10 four spades     4
>>> deck[aCard]
>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>
>> Wihout having to specify all elements in the logical tests.
>>
>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
>>
>> aCard$value,]
>>    face   suit value
>> 10 four spades     4
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From ccberry @ending from uc@d@edu  Thu Jan  3 18:59:26 2019
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Thu, 3 Jan 2019 17:59:26 +0000
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
Message-ID: <AC00E39D-4E1C-4946-80BC-F7ED042CF907@ucsd.edu>

See below.

> On Jan 3, 2019, at 6:50 AM, Benoit Galarneau <benoit.galarneau at polymtl.ca> wrote:
> 
> Hi everyone,
> I'm new to the R world.
> Probably a newbie question but I am stuck with some concept with data frame.
> I am following some examples in the "Hands-On Programming with R".
> 
> In short, how can I access/filter items in a data frame using a variable.
> 
> One example consists of manipulating elements from a deck of card:
> 
>> deck
>    face     suit value
> 1   king   spades    13
> 2  queen   spades    12
> 3   jack   spades    11
> 4    ten   spades    10
> etc.
> 
> Let's say I want to remove or filter out the first card. I know I could do deck[-1].
> 
> But let's say I have: topCard <- deck[1,]
> 
> topCard is then a list of 3 elements
>> topCard
>  face   suit value
> 1 king spades    13
> 
> My question is the following, how can I remove or filter out the deck using the topCard variable.
> 
> In my programmer's head, something similar to this should "work":
>> deck[10,]
>   face   suit value
> 10 four spades     4
>> aCard <- deck[10,]
>> aCard
>   face   suit value
> 10 four spades     4
>> deck[aCard]
> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
> 
> Wihout having to specify all elements in the logical tests.
> 
> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value == aCard$value,]
>   face   suit value
> 10 four spades     4

matchRow <- Reduce( "&", mapply("==", deck, aCard, SIMPLIFY=FALSE))

deck[ !matchRow, ]

There is a little `trick' here. A "data.frame" object is a "list" object and both `deck` and `aCard` are "data.frame" objects. So using `mapply` as above operates on the successive columns of each.  


You will find many useful idioms using the *apply functions. 

As you are new to R, I recommend running the example() for each of them as well as browsing the help page.

HTH,

Chuck

From murdoch@dunc@n @ending from gm@il@com  Thu Jan  3 19:24:07 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 3 Jan 2019 13:24:07 -0500
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
 <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
Message-ID: <add186fe-4b73-c465-ae88-7b250ebcada4@gmail.com>

On 03/01/2019 12:39 p.m., Benoit Galarneau wrote:
> Thanks for the feedback.
> Point taken about the data.table package, I will take a look for sure.
> As I am new to the R programming, I'm exploring with the default
> libraries as a start.
> 
> I have various options that works like this one:
> 
> topCard <- deck[1,]
> #Remove card from deck using row name
> deck <- deck[!rownames(deck) %in% row.names(topCard),]
> 
> Is it recommended/safe/good practice to work on items using the item names?

I think the answer to "recommended or good practice" depends on your 
priorities.  If I was running a big simulation where speed really 
matters, I wouldn't do it that way:  dataframes are slow and looking for 
a name in a vector of names can be slow.  You'd get faster results using 
matrices and row indices (which can be negated to remove items, as you 
know.)  But then you have to deal with the issue that matrices can't mix 
types as your dataframe does, so your code is likely to be less clear.

If speed isn't so much of an issue but clarity is, then you really want 
to write your own small functions to do the removal, e.g.

whichCard <- function(deck, card) {
   which(deck$face == card$face & deck$suit == card$suit & deck$value = 
card$value)
}

removeCard <- function(deck, card) {
   deck[-whichCard(deck, card), ]
}

deck <- removeCard(deck, topCard)

Duncan Murdoch

> Benoit
> 
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:
> 
>>> In my programmer's head, something similar to this should "work": ...
>>> deck[aCard]
>>
>> There are some people who agree with you... see the data.table
>> package, which can be made to behave like this.
>>
>> Keep in mind that the aCard data frame in general may have a
>> different set of column names or more than one row. (I would be
>> concerned that the logic of your application was inefficiently
>> designed if `deck` actually has the same columns as `aCard` as in
>> your example.) Others have pointed out that data frames are
>> typically combined using the merge function, which allows matching
>> columns to be specified very flexibly.
>>
>>
>> On January 3, 2019 6:50:22 AM PST, Benoit Galarneau
>> <benoit.galarneau at polymtl.ca> wrote:
>>> Hi everyone,
>>> I'm new to the R world.
>>> Probably a newbie question but I am stuck with some concept with data
>>> frame.
>>> I am following some examples in the "Hands-On Programming with R".
>>>
>>> In short, how can I access/filter items in a data frame using a
>>> variable.
>>>
>>> One example consists of manipulating elements from a deck of card:
>>>
>>>> deck
>>>      face     suit value
>>> 1   king   spades    13
>>> 2  queen   spades    12
>>> 3   jack   spades    11
>>> 4    ten   spades    10
>>> etc.
>>>
>>> Let's say I want to remove or filter out the first card. I know I
>>> could do deck[-1].
>>>
>>> But let's say I have: topCard <- deck[1,]
>>>
>>> topCard is then a list of 3 elements
>>>> topCard
>>>    face   suit value
>>> 1 king spades    13
>>>
>>> My question is the following, how can I remove or filter out the deck
>>> using the topCard variable.
>>>
>>> In my programmer's head, something similar to this should "work":
>>>> deck[10,]
>>>     face   suit value
>>> 10 four spades     4
>>>> aCard <- deck[10,]
>>>> aCard
>>>     face   suit value
>>> 10 four spades     4
>>>> deck[aCard]
>>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>>
>>> Wihout having to specify all elements in the logical tests.
>>>
>>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
>>>
>>> aCard$value,]
>>>     face   suit value
>>> 10 four spades     4
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @ending from gm@il@com  Thu Jan  3 19:26:33 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 3 Jan 2019 13:26:33 -0500
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
 <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
Message-ID: <bef85396-01b6-7be1-404a-97fa51802610@gmail.com>

On 03/01/2019 12:39 p.m., Benoit Galarneau wrote:
> Thanks for the feedback.
> Point taken about the data.table package, I will take a look for sure.
> As I am new to the R programming, I'm exploring with the default
> libraries as a start.
> 
> I have various options that works like this one:
> 
> topCard <- deck[1,]
> #Remove card from deck using row name
> deck <- deck[!rownames(deck) %in% row.names(topCard),]
> 
> Is it recommended/safe/good practice to work on items using the item names?

I forgot to address "safety".  Your code above will only be safe if you 
can guarantee that topCard is always produced by subsetting the deck. 
If a user does something like

topCard <- data.frame(face = "queen", suit = "spades", value = 12)

then the rownames won't match, and removing topCard will remove the 
wrong one.

Duncan Murdoch

> 
> Benoit
> 
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:
> 
>>> In my programmer's head, something similar to this should "work": ...
>>> deck[aCard]
>>
>> There are some people who agree with you... see the data.table
>> package, which can be made to behave like this.
>>
>> Keep in mind that the aCard data frame in general may have a
>> different set of column names or more than one row. (I would be
>> concerned that the logic of your application was inefficiently
>> designed if `deck` actually has the same columns as `aCard` as in
>> your example.) Others have pointed out that data frames are
>> typically combined using the merge function, which allows matching
>> columns to be specified very flexibly.
>>
>>
>> On January 3, 2019 6:50:22 AM PST, Benoit Galarneau
>> <benoit.galarneau at polymtl.ca> wrote:
>>> Hi everyone,
>>> I'm new to the R world.
>>> Probably a newbie question but I am stuck with some concept with data
>>> frame.
>>> I am following some examples in the "Hands-On Programming with R".
>>>
>>> In short, how can I access/filter items in a data frame using a
>>> variable.
>>>
>>> One example consists of manipulating elements from a deck of card:
>>>
>>>> deck
>>>      face     suit value
>>> 1   king   spades    13
>>> 2  queen   spades    12
>>> 3   jack   spades    11
>>> 4    ten   spades    10
>>> etc.
>>>
>>> Let's say I want to remove or filter out the first card. I know I
>>> could do deck[-1].
>>>
>>> But let's say I have: topCard <- deck[1,]
>>>
>>> topCard is then a list of 3 elements
>>>> topCard
>>>    face   suit value
>>> 1 king spades    13
>>>
>>> My question is the following, how can I remove or filter out the deck
>>> using the topCard variable.
>>>
>>> In my programmer's head, something similar to this should "work":
>>>> deck[10,]
>>>     face   suit value
>>> 10 four spades     4
>>>> aCard <- deck[10,]
>>>> aCard
>>>     face   suit value
>>> 10 four spades     4
>>>> deck[aCard]
>>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>>
>>> Wihout having to specify all elements in the logical tests.
>>>
>>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
>>>
>>> aCard$value,]
>>>     face   suit value
>>> 10 four spades     4
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From benoit@g@l@rne@u @ending from polymtl@c@  Thu Jan  3 19:41:25 2019
From: benoit@g@l@rne@u @ending from polymtl@c@ (Benoit Galarneau)
Date: Thu, 03 Jan 2019 18:41:25 +0000
Subject: [R] Accessing Data Frame
In-Reply-To: <bef85396-01b6-7be1-404a-97fa51802610@gmail.com>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
 <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
 <bef85396-01b6-7be1-404a-97fa51802610@gmail.com>
Message-ID: <20190103184125.Horde.0fep40W8hzhzRgDKSd_P7ZH@www.imp.polymtl.ca>

Many thanks everyone for the rich feedback. Very impressive. I will  
digest all the information received and continue on my learning around  
R.
Benoit

Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit?:

> On 03/01/2019 12:39 p.m., Benoit Galarneau wrote:
>> Thanks for the feedback.
>> Point taken about the data.table package, I will take a look for sure.
>> As I am new to the R programming, I'm exploring with the default
>> libraries as a start.
>>
>> I have various options that works like this one:
>>
>> topCard <- deck[1,]
>> #Remove card from deck using row name
>> deck <- deck[!rownames(deck) %in% row.names(topCard),]
>>
>> Is it recommended/safe/good practice to work on items using the item names?
>
> I forgot to address "safety".  Your code above will only be safe if  
> you can guarantee that topCard is always produced by subsetting the  
> deck. If a user does something like
>
> topCard <- data.frame(face = "queen", suit = "spades", value = 12)
>
> then the rownames won't match, and removing topCard will remove the  
> wrong one.
>
> Duncan Murdoch
>
>>
>> Benoit
>>
>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:
>>
>>>> In my programmer's head, something similar to this should "work": ...
>>>> deck[aCard]
>>>
>>> There are some people who agree with you... see the data.table
>>> package, which can be made to behave like this.
>>>
>>> Keep in mind that the aCard data frame in general may have a
>>> different set of column names or more than one row. (I would be
>>> concerned that the logic of your application was inefficiently
>>> designed if `deck` actually has the same columns as `aCard` as in
>>> your example.) Others have pointed out that data frames are
>>> typically combined using the merge function, which allows matching
>>> columns to be specified very flexibly.
>>>
>>>
>>> On January 3, 2019 6:50:22 AM PST, Benoit Galarneau
>>> <benoit.galarneau at polymtl.ca> wrote:
>>>> Hi everyone,
>>>> I'm new to the R world.
>>>> Probably a newbie question but I am stuck with some concept with data
>>>> frame.
>>>> I am following some examples in the "Hands-On Programming with R".
>>>>
>>>> In short, how can I access/filter items in a data frame using a
>>>> variable.
>>>>
>>>> One example consists of manipulating elements from a deck of card:
>>>>
>>>>> deck
>>>>     face     suit value
>>>> 1   king   spades    13
>>>> 2  queen   spades    12
>>>> 3   jack   spades    11
>>>> 4    ten   spades    10
>>>> etc.
>>>>
>>>> Let's say I want to remove or filter out the first card. I know I
>>>> could do deck[-1].
>>>>
>>>> But let's say I have: topCard <- deck[1,]
>>>>
>>>> topCard is then a list of 3 elements
>>>>> topCard
>>>>   face   suit value
>>>> 1 king spades    13
>>>>
>>>> My question is the following, how can I remove or filter out the deck
>>>> using the topCard variable.
>>>>
>>>> In my programmer's head, something similar to this should "work":
>>>>> deck[10,]
>>>>    face   suit value
>>>> 10 four spades     4
>>>>> aCard <- deck[10,]
>>>>> aCard
>>>>    face   suit value
>>>> 10 four spades     4
>>>>> deck[aCard]
>>>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>>>
>>>> Wihout having to specify all elements in the logical tests.
>>>>
>>>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
>>>>
>>>> aCard$value,]
>>>>    face   suit value
>>>> 10 four spades     4
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jan  3 19:48:03 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Jan 2019 10:48:03 -0800
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
 <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
Message-ID: <87ADA06B-1780-4B7A-B465-20D5D64D4CA3@dcn.davis.ca.us>

AFAIK the intent of the designers of the data frame class was that rownames be unique and be useful for tracking the origins of records in data subsets. However, after a few merging operations the traceability becomes murky anyway and relational set theory avoids them. Neither data.table nor dplyr packages support them. In short, base R data import functions will create rownames on data frames so you should be able to depend on it as long as you stick with base R.

On January 3, 2019 9:39:44 AM PST, Benoit Galarneau <benoit.galarneau at polymtl.ca> wrote:
>Thanks for the feedback.
>Point taken about the data.table package, I will take a look for sure. 
>
>As I am new to the R programming, I'm exploring with the default  
>libraries as a start.
>
>I have various options that works like this one:
>
>topCard <- deck[1,]
>#Remove card from deck using row name
>deck <- deck[!rownames(deck) %in% row.names(topCard),]
>
>Is it recommended/safe/good practice to work on items using the item
>names?
>
>Benoit
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:
>
>>> In my programmer's head, something similar to this should "work":
>...
>>> deck[aCard]
>>
>> There are some people who agree with you... see the data.table  
>> package, which can be made to behave like this.
>>
>> Keep in mind that the aCard data frame in general may have a  
>> different set of column names or more than one row. (I would be  
>> concerned that the logic of your application was inefficiently  
>> designed if `deck` actually has the same columns as `aCard` as in  
>> your example.) Others have pointed out that data frames are  
>> typically combined using the merge function, which allows matching  
>> columns to be specified very flexibly.
>>
>>
>> On January 3, 2019 6:50:22 AM PST, Benoit Galarneau  
>> <benoit.galarneau at polymtl.ca> wrote:
>>> Hi everyone,
>>> I'm new to the R world.
>>> Probably a newbie question but I am stuck with some concept with
>data
>>> frame.
>>> I am following some examples in the "Hands-On Programming with R".
>>>
>>> In short, how can I access/filter items in a data frame using a
>>> variable.
>>>
>>> One example consists of manipulating elements from a deck of card:
>>>
>>>> deck
>>>     face     suit value
>>> 1   king   spades    13
>>> 2  queen   spades    12
>>> 3   jack   spades    11
>>> 4    ten   spades    10
>>> etc.
>>>
>>> Let's say I want to remove or filter out the first card. I know I
>>> could do deck[-1].
>>>
>>> But let's say I have: topCard <- deck[1,]
>>>
>>> topCard is then a list of 3 elements
>>>> topCard
>>>   face   suit value
>>> 1 king spades    13
>>>
>>> My question is the following, how can I remove or filter out the
>deck
>>> using the topCard variable.
>>>
>>> In my programmer's head, something similar to this should "work":
>>>> deck[10,]
>>>    face   suit value
>>> 10 four spades     4
>>>> aCard <- deck[10,]
>>>> aCard
>>>    face   suit value
>>> 10 four spades     4
>>>> deck[aCard]
>>> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
>>>
>>> Wihout having to specify all elements in the logical tests.
>>>
>>> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value
>==
>>>
>>> aCard$value,]
>>>    face   suit value
>>> 10 four spades     4
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Thu Jan  3 21:10:06 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 3 Jan 2019 12:10:06 -0800
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103171541.Horde.PiupzEw_trX3WDAaYTM9V75@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CA+vqiLGm3m3ms-oa3-WJncp8s4QK=MjgHv8=g7PDXYqBFVDxrg@mail.gmail.com>
 <20190103171541.Horde.PiupzEw_trX3WDAaYTM9V75@www.imp.polymtl.ca>
Message-ID: <CAGxFJbTeoRiD46OY7Qh9sQNh+1+vxfhf0xhOyoNP_0NZS83yvw@mail.gmail.com>

I do not know how you define "quick way," but as there is an "==" method
for data frames (see ?"==" and links therein for details), that allows the
straightforward use of basic R functionality:

## using your 'deck' and 'topCard' examples:

> deck [ apply(deck == topCard[rep(1,nrow(deck)), ],1, all),]
  face   suit value
1 king spades    13

> deck [ !apply(deck == topCard[rep(1,nrow(deck)),],1, all), ]
   face   suit value
2 queen spades    12
3  jack spades    11
4   ten spades    10

> topCard <- deck[2, ]
> deck [ !apply(deck == topCard[rep(1, nrow(deck)), ],1, all), ]
  face   suit value
1 king spades    13
3 jack spades    11
4  ten spades    10

This approach can be trivially changed to using only a subset of columns to
define the "filter."

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 3, 2019 at 9:16 AM Benoit Galarneau <benoit.galarneau at polymtl.ca>
wrote:

> You are correct, the anti_join is working fine.
> However, I still find it strange there is no "quick" way to find the
> index of an item extracted from the data frame.
>
> This works as it returns the deck without the card no 10.
> aCard = deck[10,]
> cardNo = which(deck$value == aCard$value & deck$suit == aCard$suit)
> deck[-cardNo,]
>
> But I'm still puzzled by the complexity of finding back the index of
> the card with the long statement.
>
> Another approach that "works" is the following, but I still find it
> strange to depend on data frame row names to find the index:
> cardNo <- as.numeric(row.names(aCard))
>
> Apologies if the above question are strange. I'm coming C++ world with
> some bias with objects. Again, since "aCard" is extracted from the
> data frame, I assume (bias?) there would be a simple way to find back
> the item in the data frame it came frame. Some kind of indexOf() or
> similar on the container and item.
>
> Benoit
>
> Ista Zahn <istazahn at gmail.com> a ?crit :
>
> > Hi Benoit,
> >
> > You can select rows from deck matched in aCard using
> >
> > merge(deck, aCard)
> >
> > Selecting rows that don't match is bit more difficult. You could do
> > something like
> >
> > isin <- apply(mapply(function(x, y) x %in% y, deck, topCard),
> >                1,
> >                all)
> > deck[!isin, ]
> >
> > perhaps.
> >
> > Alternatively, you can use anti_join from the dplyr package:
> >
> > library(dplyr)
> > anti_join(deck, topCard)
> >
> > Best,
> > Ista
> >
> > On Thu, Jan 3, 2019 at 10:38 AM Benoit Galarneau
> > <benoit.galarneau at polymtl.ca> wrote:
> >>
> >> Hi everyone,
> >> I'm new to the R world.
> >> Probably a newbie question but I am stuck with some concept with data
> frame.
> >> I am following some examples in the "Hands-On Programming with R".
> >>
> >> In short, how can I access/filter items in a data frame using a
> variable.
> >>
> >> One example consists of manipulating elements from a deck of card:
> >>
> >> > deck
> >>      face     suit value
> >> 1   king   spades    13
> >> 2  queen   spades    12
> >> 3   jack   spades    11
> >> 4    ten   spades    10
> >> etc.
> >>
> >> Let's say I want to remove or filter out the first card. I know I
> >> could do deck[-1].
> >>
> >> But let's say I have: topCard <- deck[1,]
> >>
> >> topCard is then a list of 3 elements
> >> > topCard
> >>    face   suit value
> >> 1 king spades    13
> >>
> >> My question is the following, how can I remove or filter out the deck
> >> using the topCard variable.
> >>
> >> In my programmer's head, something similar to this should "work":
> >> > deck[10,]
> >>     face   suit value
> >> 10 four spades     4
> >> > aCard <- deck[10,]
> >> > aCard
> >>     face   suit value
> >> 10 four spades     4
> >> > deck[aCard]
> >> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
> >>
> >> Wihout having to specify all elements in the logical tests.
> >>
> >> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
> >> aCard$value,]
> >>     face   suit value
> >> 10 four spades     4
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Fri Jan  4 02:55:20 2019
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Fri, 4 Jan 2019 14:55:20 +1300
Subject: [R] BLUPS from lme models
Message-ID: <20190104015520.GA31776@slingshot.co.nz>

The bottom of page 276 of the "Gold Book" Modern Applied Statistics by
Venables and Ripley, 4th edition, the last sentence states: 

"Random effects are set either to zero or to their BLUP values."

Am I correct in inferring from that, it amounts respectively to
removing the random term from the model, or setting it as a fixed
effect?  To get something meaningful, one needs to choose which random
effects are relevant to the topic under study? 

Thank you.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From bgunter@4567 @ending from gm@il@com  Fri Jan  4 03:37:50 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 3 Jan 2019 18:37:50 -0800
Subject: [R] BLUPS from lme models
In-Reply-To: <20190104015520.GA31776@slingshot.co.nz>
References: <20190104015520.GA31776@slingshot.co.nz>
Message-ID: <CAGxFJbT8twz7mRfS5KWc24NdYUe6bOSdFyvqvry74e1PDOGpBg@mail.gmail.com>

No.

But as this is a statistical issue and not an R programming issue, it is
off topic here. Post on stats.stackexchange.com or other statistical list
and/or spend time with web tutorials.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 3, 2019 at 5:55 PM Patrick Connolly <p_connolly at slingshot.co.nz>
wrote:

> The bottom of page 276 of the "Gold Book" Modern Applied Statistics by
> Venables and Ripley, 4th edition, the last sentence states:
>
> "Random effects are set either to zero or to their BLUP values."
>
> Am I correct in inferring from that, it amounts respectively to
> removing the random term from the model, or setting it as a fixed
> effect?  To get something meaningful, one needs to choose which random
> effects are relevant to the topic under study?
>
> Thank you.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t@@h@@eileen @ending from gm@il@com  Fri Jan  4 03:49:20 2019
From: t@@h@@eileen @ending from gm@il@com (Tasha O'Hara)
Date: Thu, 3 Jan 2019 20:49:20 -0600
Subject: [R] Plotting rgb proportions in R
In-Reply-To: <CA+8X3fVhYqqL=YzGhio+q9g0vU9f1H6QZbSfsk3+FXpCd+Qr5Q@mail.gmail.com>
References: <CAKpKZ1zwnNcOeF8YwqNc8PxyRmhLwhS6p7CW5rORhey69KGNpg@mail.gmail.com>
 <CA+8X3fUaF_BUw9QUg3QZ57GiNAX8n+CZuRhW9kJQxVf4FEFZuQ@mail.gmail.com>
 <CAGxFJbQODiuWSL_QTeYT=sHKJnR+ZpvRca233rT4-mEXisK9_g@mail.gmail.com>
 <f858814ee44443b4a66015138a5312fb@SRVEXCHCM1302.precheza.cz>
 <CAKpKZ1z78pMsY46_ciX7=KtcL31ZGw6XXu9=v05PM7ZxeFfLDg@mail.gmail.com>
 <CA+8X3fVhYqqL=YzGhio+q9g0vU9f1H6QZbSfsk3+FXpCd+Qr5Q@mail.gmail.com>
Message-ID: <CAKpKZ1wuEk01YLKNHAPRw2PT1U-cXsoj3n01OsH9A43DRfDgSQ@mail.gmail.com>

That works! Thank you so much for for help!

On Wed, Jan 2, 2019, 19:56 Jim Lemon <drjimlemon at gmail.com wrote:

> Hi Tasha,
> Using the original sample you sent:
>
> rgb_prop<-read.table(text="Red Green Blue pct
> 249 158 37 56.311
> 249 158 68 4.319
> 249 158 98 0.058
> 249 128 7 13.965
> 249 128 37 12.87
> 188 128 37 0.029
> 249 128 68 0.161
> 188 128 68 0.015
> 188 98 7 0.029
> 219 128 7 2.773
> 219 128 37 2.583
> 188 98 68 0.058
> 219 128 68 0.525
> 249 188 37 0.876
> 249 188 68 1.08
> 219 98 7 0.482
> 249 188 98 0.015
> 249 158 7 3.852",header=TRUE)
> rgb_prop$Red<-rgb_prop$Red/255
> rgb_prop$Green<-rgb_prop$Green/255
> rgb_prop$Blue<-rgb_prop$Blue/255
> # the matrix format forces the stacked bar display
> barplot(matrix(rgb_prop$pct,ncol=1),
>  col=rgb(rgb_prop[,c("Red","Green","Blue")]),beside=FALSE)
>
> Of course you can add more stacks by increasing the number of columns in
> the "x" matrix.
>
> Jim
>
> On Thu, Jan 3, 2019 at 3:33 AM Tasha O'Hara <tasha.eileen at gmail.com>
> wrote:
>
>> I apologize for the late reply after the holidays. I really appreciate
>> all the data visualization suggestions. The scatterplot works very well,
>> but I do have >400 specimen with at least 5-20 colors each, so a stacked
>> barchart of each specific color proportion would be most useful to show
>> uniformity within each specimen. Below is an example of what I would like
>> to do, but instead of generic colors, I am hoping to plot the actual RGB
>> proportions for each.
>> [image: image.png]
>>
>> On Wed, Dec 19, 2018 at 5:28 AM PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>>
>>> Hi
>>>
>>> > -----Original Message-----
>>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
>>> > Sent: Wednesday, December 19, 2018 5:26 AM
>>> > To: Jim Lemon <drjimlemon at gmail.com>
>>> > Cc: R-help <r-help at r-project.org>
>>> > Subject: Re: [R] Plotting rgb proportions in R
>>> >
>>> > 3-d Proportions must sum to 1and are thus actually 2-d and should
>>> preferaby
>>> > be plotted as a ternary plot. Several r packages will do this for you,
>>> e.g.
>>> > package Ternary. Search "ternary plots" on rseek.org for others.
>>>
>>> From which I would recommend ggtern. Sometimes a bit tricky but quite
>>> handy, especially when you consider some grouping.
>>>
>>> Cheers
>>> Petr
>>>
>>> >
>>> > -- Bert
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> and
>>> > sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Tue, Dec 18, 2018 at 3:10 PM Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>> >
>>> > > Hi Tasha,
>>> > > I may be right off the track, but you could plot RGB proportions on a
>>> > > 3D plot. The easiest way I can think if would be to convert your
>>> 0-255
>>> > > values to proportions:
>>> > >
>>> > > rgb_prop<-read.table(text="Red Green Blue pct
>>> > > 249 158 37 56.311
>>> > > 249 158 68 4.319
>>> > > 249 158 98 0.058
>>> > > 249 128 7 13.965
>>> > > 249 128 37 12.87
>>> > > 188 128 37 0.029
>>> > > 249 128 68 0.161
>>> > > 188 128 68 0.015
>>> > > 188 98 7 0.029
>>> > > 219 128 7 2.773
>>> > > 219 128 37 2.583
>>> > > 188 98 68 0.058
>>> > > 219 128 68 0.525
>>> > > 249 188 37 0.876
>>> > > 249 188 68 1.08
>>> > > 219 98 7 0.482
>>> > > 249 188 98 0.015
>>> > > 249 158 7 3.852",header=TRUE)
>>> > > rgb_prop$Red<-rgb_prop$Red/255
>>> > > rgb_prop$Green<-rgb_prop$Green/255
>>> > > rgb_prop$Blue<-rgb_prop$Blue/255
>>> > > library(scatterplot3d)
>>> > > scatterplot3d(rgb_prop[,1:3],cex.symbols=sqrt(rgb_prop[,4]),
>>> > >  color=rgb(rgb_prop[,1],rgb_prop[,2],rgb_prop[,3]),pch=19)
>>> > >
>>> > > then plot the RGB values on a 3D scatterplot. I have included
>>> > > arguments to make the symbols the actual RGB colors that you specify
>>> > > and their size proportional to the square root of the percentages.
>>> > >
>>> > > Jim
>>> > >
>>> > > On Wed, Dec 19, 2018 at 5:17 AM Tasha O'Hara <tasha.eileen at gmail.com
>>> >
>>> > > wrote:
>>> > > >
>>> > > > Hello,
>>> > > >
>>> > > > I am trying to plot specific rgb color proportions of a marine
>>> > > > specimen
>>> > > in
>>> > > > a stacked plot using R and I was looking for some help. I have
>>> > > > several rgb proportions per specimen (an example of one is below).
>>> > > > I've run into different examples of people using vegan or
>>> grDevices.
>>> > > > Can anyone help
>>> > > with
>>> > > > this?
>>> > > >
>>> > > > Red    Green  Blue   %
>>> > > > 249 158 37 56.311
>>> > > > 249 158 68 4.319
>>> > > > 249 158 98 0.058
>>> > > > 249 128 7 13.965
>>> > > > 249 128 37 12.87
>>> > > > 188 128 37 0.029
>>> > > > 249 128 68 0.161
>>> > > > 188 128 68 0.015
>>> > > > 188 98 7 0.029
>>> > > > 219 128 7 2.773
>>> > > > 219 128 37 2.583
>>> > > > 188 98 68 0.058
>>> > > > 219 128 68 0.525
>>> > > > 249 188 37 0.876
>>> > > > 249 188 68 1.08
>>> > > > 219 98 7 0.482
>>> > > > 249 188 98 0.015
>>> > > > 249 158 7 3.852
>>> > > >
>>> > > >         [[alternative HTML version deleted]]
>>> > > >
>>> > > > ______________________________________________
>>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > > PLEASE do read the posting guide
>>> > > http://www.R-project.org/posting-guide.html
>>> > > > and provide commented, minimal, self-contained, reproducible code.
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> > >
>>> >
>>> > [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>>> about processing and protection of business partner?s personal data are
>>> available on website:
>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>> documents attached to it may be confidential and are subject to the legally
>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>
>>>

	[[alternative HTML version deleted]]


From w@ngji@wei92 @ending from hotm@il@com  Fri Jan  4 05:19:47 2019
From: w@ngji@wei92 @ending from hotm@il@com (=?gb2312?B?zfUgvM7svw==?=)
Date: Fri, 4 Jan 2019 04:19:47 +0000
Subject: [R] Error in names(x) <- value: 'names' attribute must be the same
 length as the vector in gam function
Message-ID: <TY2PR06MB310294C5531DFB29737640AFC28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>

Dear R users,


I am using the *mgcv package* to model the ozone pollution concentration according to some environmental covariates. The model takes the form :

model1 <-gam(O3~s(X,Y,bs="tp",k=10)+wd+s(date,bs="cc",k=100)+district,data=mydata,family= gaussian(link ="log" ),na.action="na.omit", method="REML")

And here is the strcture of  covariates
> str(mydata)
'data.frame': 7100 obs. of  286 variables:
 $ date            : Date, format: "2016-01-01" "2016-01-01" "2016-01-01" ...
 $ O3              : num  0.0141 0.0149 0.0102 0.0159 0.0186 ...
 $ district        : Factor w/ 10 levels "bc","bh","dl",..: 1 8 7 8 2 6 4 4 10 2 ...
 $ wd              : Factor w/ 16 levels "E","ENE","ESE",..: 13 13 13 13 13 2 9 9 11 13 ...
 $ X               : num  0.389 0.365 1 0.44 0.892 ...
 $ Y               : num  0.311 0.204 0.426 0.223 0.162 ...

I am stuck on an error in R: 'names' attribute [1] must be the same length as the vector [0].

I try to find where the problem is by delete the term of "s(date,bs="cc",k=100)" from the fomular and it could work well. It seems like  there is something wrong with date field.

I'm not exactly sure how to fix this problem.  Any advice would be greatly
appreciated!
Jiawei Wang
???? Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From w@ngji@wei92 @ending from hotm@il@com  Fri Jan  4 05:55:58 2019
From: w@ngji@wei92 @ending from hotm@il@com (=?gb2312?B?zfUgvM7svw==?=)
Date: Fri, 4 Jan 2019 04:55:58 +0000
Subject: [R] Error in gam function in names(x) <- value: 'names' attribute
 must be the same length as the vector
In-Reply-To: <TY2PR06MB310214DC0B3F1C8DA41FF026C28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>
References: <TY2PR06MB310294C5531DFB29737640AFC28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>,
 <TY2PR06MB310214DC0B3F1C8DA41FF026C28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>
Message-ID: <TY2PR06MB3102C972ADDEAE7735341B6BC28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>



???? Outlook<http://aka.ms/weboutlook>

________________________________

Dear R users,


I am using the *mgcv package* to model the ozone pollution concentration according to some environmental covariates. The model takes the form :

model1 <-gam(O3~s(X,Y,bs="tp",k=10)+wd+s(date,bs="cc",k=100)+district,data=mydata,family= gaussian(link ="log" ),na.action="na.omit", method="REML")

And here is the strcture of  covariates
> str(mydata)
'data.frame': 7100 obs. of  286 variables:
 $ date            : Date, format: "2016-01-01" "2016-01-01" "2016-01-01" ...
 $ O3              : num  0.0141 0.0149 0.0102 0.0159 0.0186 ...
 $ district        : Factor w/ 10 levels "bc","bh","dl",..: 1 8 7 8 2 6 4 4 10 2 ...
 $ wd              : Factor w/ 16 levels "E","ENE","ESE",..: 13 13 13 13 13 2 9 9 11 13 ...
 $ X               : num  0.389 0.365 1 0.44 0.892 ...
 $ Y               : num  0.311 0.204 0.426 0.223 0.162 ...

I am stuck on an error in R: 'names' attribute [1] must be the same length as the vector [0].

I try to find where the problem is by delete the term of "s(date,bs="cc",k=100)" from the fomular and it could work well. It seems like  there is something wrong with date field.

I'm not exactly sure how to fix this problem.  Any advice would be greatly
appreciated!
Jiawei Wang
???? Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From li@@_1995_@ @ending from hotm@il@com  Fri Jan  4 08:41:39 2019
From: li@@_1995_@ @ending from hotm@il@com (Lisa Snel)
Date: Fri, 4 Jan 2019 07:41:39 +0000
Subject: [R] How to perform Mixed Design ANOVA on MICE imputed dataset in R?
Message-ID: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>

Hi all,

I have a question about performing a Mixed Design ANOVA in R after multiple imputation using MICE. My data is as follows:

id <- c(1,2,3,4,5,6,7,8,9,10)
group <- c(0,1,1,0,0,1,0,0,0,1)
measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
measure_2 <- c(55,88,88,55,70,62,78,66,65,92)
measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
measure_4 <- c(64,80,78,92,65,64,87,65,67,96)
measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
measure_6 <- c(70,83,80,55,73,64,91,65,91,89)
dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
dat$group <- as.factor(dat$group)

So: we have 6 repeated measurements of diastolic blood pressure (measure 1 till 6). The grouping factor is gender, which is called group. This variable is coded 1 if male and 0 if female. Before multiple imputation, we have used the following code in R:

library(reshape)
library(reshape2)
datLong <- melt(dat, id = c("id", "group"), measured = c("measure_1", "measure_2", "measure_3", "measure_4", "measure_5", "measure_6"))
datLong

colnames(datLong) <- c("ID", "Gender", "Time", "Score")
datLong
table(datLong$Time)
datLong$ID <- as.factor(datLong$ID)

library(ez)
model_mixed <- ezANOVA(data = datLong,
               dv = Value,
               wid = ID,
               within = Time,
               between = Gender,
               detailed = TRUE,
               type = 3,
               return_aov = TRUE)
model_mixed

This worked perfectly. However, our data is not complete. We have missing values, that we impute using MICE:

id <- c(1,2,3,4,5,6,7,8,9,10)
group <- c(0,1,1,0,0,1,0,0,0,1)
measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
measure_2 <- c(55,NA,88,55,70,62,78,66,65,92)
measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
measure_4 <- c(64,80,78,92,NA,NA,87,65,67,96)
measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
measure_6 <- c(70,NA,80,55,73,64,91,65,91,89)
dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
dat$group <- as.factor(dat$group)

imp_anova <- mice(dat, maxit = 0)
meth <- imp_anova$method
pred <- imp_anova$predictorMatrix
imp_anova <- mice(dat, method = meth, predictorMatrix = pred, seed = 2018, maxit = 10, m = 5)

(The imputation gives logged events, because of the made-up data and the simple imputation code e.g id used as a predictor. For my real data, the imputation was correct and valid)

Now I have the imputed dataset of class ?mids?. I have searched the internet, but I cannot find how I can perform the mixed design ANOVA on this imputed set, as I did before with the complete set using ezANOVA. Is there anyone who can and wants to help me?


Best,

Lisa

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Fri Jan  4 15:11:38 2019
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Fri, 4 Jan 2019 09:11:38 -0500
Subject: [R] 
 How to perform Mixed Design ANOVA on MICE imputed dataset in R?
In-Reply-To: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
References: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
Message-ID: <CA+vqiLHJMzqV7Xp8zprm-7EbgqnTQWorFfLyc9u7Uy+0g-S0RQ@mail.gmail.com>

Hi Lisa,

The package web page at http://stefvanbuuren.github.io/mice/ has all
the info you need to get started.

Best,
Ista

On Fri, Jan 4, 2019 at 3:29 AM Lisa Snel <lisa_1995_s at hotmail.com> wrote:
>
> Hi all,
>
> I have a question about performing a Mixed Design ANOVA in R after multiple imputation using MICE. My data is as follows:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,88,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,65,64,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,83,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> So: we have 6 repeated measurements of diastolic blood pressure (measure 1 till 6). The grouping factor is gender, which is called group. This variable is coded 1 if male and 0 if female. Before multiple imputation, we have used the following code in R:
>
> library(reshape)
> library(reshape2)
> datLong <- melt(dat, id = c("id", "group"), measured = c("measure_1", "measure_2", "measure_3", "measure_4", "measure_5", "measure_6"))
> datLong
>
> colnames(datLong) <- c("ID", "Gender", "Time", "Score")
> datLong
> table(datLong$Time)
> datLong$ID <- as.factor(datLong$ID)
>
> library(ez)
> model_mixed <- ezANOVA(data = datLong,
>                dv = Value,
>                wid = ID,
>                within = Time,
>                between = Gender,
>                detailed = TRUE,
>                type = 3,
>                return_aov = TRUE)
> model_mixed
>
> This worked perfectly. However, our data is not complete. We have missing values, that we impute using MICE:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,NA,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,NA,NA,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,NA,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> imp_anova <- mice(dat, maxit = 0)
> meth <- imp_anova$method
> pred <- imp_anova$predictorMatrix
> imp_anova <- mice(dat, method = meth, predictorMatrix = pred, seed = 2018, maxit = 10, m = 5)
>
> (The imputation gives logged events, because of the made-up data and the simple imputation code e.g id used as a predictor. For my real data, the imputation was correct and valid)
>
> Now I have the imputed dataset of class ?mids?. I have searched the internet, but I cannot find how I can perform the mixed design ANOVA on this imputed set, as I did before with the complete set using ezANOVA. Is there anyone who can and wants to help me?
>
>
> Best,
>
> Lisa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From li@@_1995_@ @ending from hotm@il@com  Fri Jan  4 15:49:43 2019
From: li@@_1995_@ @ending from hotm@il@com (Lisa Snel)
Date: Fri, 4 Jan 2019 14:49:43 +0000
Subject: [R] 
 How to perform Mixed Design ANOVA on MICE imputed dataset in R?
In-Reply-To: <CA+vqiLHJMzqV7Xp8zprm-7EbgqnTQWorFfLyc9u7Uy+0g-S0RQ@mail.gmail.com>
References: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>,
 <CA+vqiLHJMzqV7Xp8zprm-7EbgqnTQWorFfLyc9u7Uy+0g-S0RQ@mail.gmail.com>
Message-ID: <AM4PR0501MB22586874CFD42AD81530BDBCAF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>

Dear Ista,

Thank you for your response and the link you have sent me. However, I know the basic things of the MICE package (how impute, to pool and to do basic analyses), but the problem is that I cannot find anything about this specific analysis.

Best,
Lisa
________________________________
Van: Ista Zahn <istazahn at gmail.com>
Verzonden: vrijdag 4 januari 2019 15:11
Aan: Lisa Snel
CC: r-help at r-project.org
Onderwerp: Re: [R] How to perform Mixed Design ANOVA on MICE imputed dataset in R?

Hi Lisa,

The package web page at http://stefvanbuuren.github.io/mice/ has all
the info you need to get started.

Best,
Ista

On Fri, Jan 4, 2019 at 3:29 AM Lisa Snel <lisa_1995_s at hotmail.com> wrote:
>
> Hi all,
>
> I have a question about performing a Mixed Design ANOVA in R after multiple imputation using MICE. My data is as follows:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,88,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,65,64,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,83,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> So: we have 6 repeated measurements of diastolic blood pressure (measure 1 till 6). The grouping factor is gender, which is called group. This variable is coded 1 if male and 0 if female. Before multiple imputation, we have used the following code in R:
>
> library(reshape)
> library(reshape2)
> datLong <- melt(dat, id = c("id", "group"), measured = c("measure_1", "measure_2", "measure_3", "measure_4", "measure_5", "measure_6"))
> datLong
>
> colnames(datLong) <- c("ID", "Gender", "Time", "Score")
> datLong
> table(datLong$Time)
> datLong$ID <- as.factor(datLong$ID)
>
> library(ez)
> model_mixed <- ezANOVA(data = datLong,
>                dv = Value,
>                wid = ID,
>                within = Time,
>                between = Gender,
>                detailed = TRUE,
>                type = 3,
>                return_aov = TRUE)
> model_mixed
>
> This worked perfectly. However, our data is not complete. We have missing values, that we impute using MICE:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,NA,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,NA,NA,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,NA,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> imp_anova <- mice(dat, maxit = 0)
> meth <- imp_anova$method
> pred <- imp_anova$predictorMatrix
> imp_anova <- mice(dat, method = meth, predictorMatrix = pred, seed = 2018, maxit = 10, m = 5)
>
> (The imputation gives logged events, because of the made-up data and the simple imputation code e.g id used as a predictor. For my real data, the imputation was correct and valid)
>
> Now I have the imputed dataset of class ?mids?. I have searched the internet, but I cannot find how I can perform the mixed design ANOVA on this imputed set, as I did before with the complete set using ezANOVA. Is there anyone who can and wants to help me?
>
>
> Best,
>
> Lisa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Jan  4 17:06:14 2019
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 4 Jan 2019 08:06:14 -0800
Subject: [R] 
 Error in names(x) <- value: 'names' attribute must be the same
 length as the vector in gam function
In-Reply-To: <TY2PR06MB310294C5531DFB29737640AFC28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>
References: <TY2PR06MB310294C5531DFB29737640AFC28E0@TY2PR06MB3102.apcprd06.prod.outlook.com>
Message-ID: <CAF8bMcZstG+vTs-W=-VX8wYU+uEb26afj=pG=xCuT4wKL_BgtA@mail.gmail.com>

mgcv::s() does not appear to work with objects of class "Date".  E.g.,

> d <- data.frame(date=seq(as.Date("2018-12-20"),len=10,by="week"),
response=log2(1:10)%%1)
> model <- gam(data=d, response ~ s(date))
Error in names(dat) <- object$term :
  'names' attribute [1] must be the same length as the vector [0]
> traceback()
6: ExtractData(object, data, knots)
5: smooth.construct3(object, data, knots)
4: smoothCon(split$smooth.spec[[i]], data, knots, absorb.cons,
scale.penalty = scale.penalty,
       null.space.penalty = select, sparse.cons = sparse.cons,
diagonal.penalty = diagonal.penalty,
       apply.by = apply.by, modCon = modCon)
3: gam.setup(formula = list(pf = response ~ 1, pfok = 1, smooth.spec = list(
       list(term = "date", bs.dim = -1, fixed = FALSE, dim = 1L,
           p.order = NA, by = "NA", label = "s(date)", xt = NULL,
           id = NULL, sp = NULL)), fake.formula = response ~ 1 +
       date, response = "response", fake.names = "date", pred.names =
"date",
       pred.formula = ~date), pterms = response ~ 1, data = list(
       response = c(0, 0, 0.584962500721156, 0, 0.321928094887362,
       0.584962500721156, 0.807354922057604, 0, 0.169925001442312,
       0.321928094887362), date = c(17885L, 17892L, 17899L, 17906L,
       17913L, 17920L, 17927L, 17934L, 17941L, 17948L)), knots = NULL,
       sp = NULL, min.sp = NULL, H = NULL, absorb.cons = TRUE, sparse.cons
= 0,
       select = FALSE, idLinksBases = TRUE, scale.penalty = TRUE,
       paraPen = NULL, drop.intercept = FALSE)
2: do.call(gsname, list(formula = gp, pterms = pterms, data = mf,
       knots = knots, sp = sp, min.sp = min.sp, H = H, absorb.cons = TRUE,
       sparse.cons = 0, select = select, idLinksBases =
control$idLinksBases,
       scale.penalty = control$scalePenalty, paraPen = paraPen,
       drop.intercept = drop.intercept))
1: gam(data = d, response ~ s(date))

You might work around this by using as.numeric(date) instead of date.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jan 4, 2019 at 12:29 AM ? ?? <wangjiawei92 at hotmail.com> wrote:

> Dear R users,
>
>
> I am using the *mgcv package* to model the ozone pollution concentration
> according to some environmental covariates. The model takes the form :
>
> model1
> <-gam(O3~s(X,Y,bs="tp",k=10)+wd+s(date,bs="cc",k=100)+district,data=mydata,family=
> gaussian(link ="log" ),na.action="na.omit", method="REML")
>
> And here is the strcture of  covariates
> > str(mydata)
> 'data.frame': 7100 obs. of  286 variables:
>  $ date            : Date, format: "2016-01-01" "2016-01-01" "2016-01-01"
> ...
>  $ O3              : num  0.0141 0.0149 0.0102 0.0159 0.0186 ...
>  $ district        : Factor w/ 10 levels "bc","bh","dl",..: 1 8 7 8 2 6 4
> 4 10 2 ...
>  $ wd              : Factor w/ 16 levels "E","ENE","ESE",..: 13 13 13 13
> 13 2 9 9 11 13 ...
>  $ X               : num  0.389 0.365 1 0.44 0.892 ...
>  $ Y               : num  0.311 0.204 0.426 0.223 0.162 ...
>
> I am stuck on an error in R: 'names' attribute [1] must be the same length
> as the vector [0].
>
> I try to find where the problem is by delete the term of
> "s(date,bs="cc",k=100)" from the fomular and it could work well. It seems
> like  there is something wrong with date field.
>
> I'm not exactly sure how to fix this problem.  Any advice would be greatly
> appreciated!
> Jiawei Wang
> ?? Outlook<http://aka.ms/weboutlook>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jan  4 17:09:12 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 4 Jan 2019 08:09:12 -0800
Subject: [R] 
 How to perform Mixed Design ANOVA on MICE imputed dataset in R?
In-Reply-To: <AM4PR0501MB22586874CFD42AD81530BDBCAF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
References: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
 <CA+vqiLHJMzqV7Xp8zprm-7EbgqnTQWorFfLyc9u7Uy+0g-S0RQ@mail.gmail.com>
 <AM4PR0501MB22586874CFD42AD81530BDBCAF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
Message-ID: <CAGxFJbTp5rfYy_5VJXMFSv-9KDRFx=ngwVk=eQ4tpLk7=hYRwQ@mail.gmail.com>

You might wish to post on the r-sig-mixed-models list, which is
specifically devoted to mixed effects models, instead of here. You are more
likely to find both interest and expertise there.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 4, 2019 at 7:49 AM Lisa Snel <lisa_1995_s at hotmail.com> wrote:

> Dear Ista,
>
> Thank you for your response and the link you have sent me. However, I know
> the basic things of the MICE package (how impute, to pool and to do basic
> analyses), but the problem is that I cannot find anything about this
> specific analysis.
>
> Best,
> Lisa
> ________________________________
> Van: Ista Zahn <istazahn at gmail.com>
> Verzonden: vrijdag 4 januari 2019 15:11
> Aan: Lisa Snel
> CC: r-help at r-project.org
> Onderwerp: Re: [R] How to perform Mixed Design ANOVA on MICE imputed
> dataset in R?
>
> Hi Lisa,
>
> The package web page at http://stefvanbuuren.github.io/mice/ has all
> the info you need to get started.
>
> Best,
> Ista
>
> On Fri, Jan 4, 2019 at 3:29 AM Lisa Snel <lisa_1995_s at hotmail.com> wrote:
> >
> > Hi all,
> >
> > I have a question about performing a Mixed Design ANOVA in R after
> multiple imputation using MICE. My data is as follows:
> >
> > id <- c(1,2,3,4,5,6,7,8,9,10)
> > group <- c(0,1,1,0,0,1,0,0,0,1)
> > measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> > measure_2 <- c(55,88,88,55,70,62,78,66,65,92)
> > measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> > measure_4 <- c(64,80,78,92,65,64,87,65,67,96)
> > measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> > measure_6 <- c(70,83,80,55,73,64,91,65,91,89)
> > dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4,
> measure_5, measure_6)
> > dat$group <- as.factor(dat$group)
> >
> > So: we have 6 repeated measurements of diastolic blood pressure (measure
> 1 till 6). The grouping factor is gender, which is called group. This
> variable is coded 1 if male and 0 if female. Before multiple imputation, we
> have used the following code in R:
> >
> > library(reshape)
> > library(reshape2)
> > datLong <- melt(dat, id = c("id", "group"), measured = c("measure_1",
> "measure_2", "measure_3", "measure_4", "measure_5", "measure_6"))
> > datLong
> >
> > colnames(datLong) <- c("ID", "Gender", "Time", "Score")
> > datLong
> > table(datLong$Time)
> > datLong$ID <- as.factor(datLong$ID)
> >
> > library(ez)
> > model_mixed <- ezANOVA(data = datLong,
> >                dv = Value,
> >                wid = ID,
> >                within = Time,
> >                between = Gender,
> >                detailed = TRUE,
> >                type = 3,
> >                return_aov = TRUE)
> > model_mixed
> >
> > This worked perfectly. However, our data is not complete. We have
> missing values, that we impute using MICE:
> >
> > id <- c(1,2,3,4,5,6,7,8,9,10)
> > group <- c(0,1,1,0,0,1,0,0,0,1)
> > measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> > measure_2 <- c(55,NA,88,55,70,62,78,66,65,92)
> > measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> > measure_4 <- c(64,80,78,92,NA,NA,87,65,67,96)
> > measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> > measure_6 <- c(70,NA,80,55,73,64,91,65,91,89)
> > dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4,
> measure_5, measure_6)
> > dat$group <- as.factor(dat$group)
> >
> > imp_anova <- mice(dat, maxit = 0)
> > meth <- imp_anova$method
> > pred <- imp_anova$predictorMatrix
> > imp_anova <- mice(dat, method = meth, predictorMatrix = pred, seed =
> 2018, maxit = 10, m = 5)
> >
> > (The imputation gives logged events, because of the made-up data and the
> simple imputation code e.g id used as a predictor. For my real data, the
> imputation was correct and valid)
> >
> > Now I have the imputed dataset of class ?mids?. I have searched the
> internet, but I cannot find how I can perform the mixed design ANOVA on
> this imputed set, as I did before with the complete set using ezANOVA. Is
> there anyone who can and wants to help me?
> >
> >
> > Best,
> >
> > Lisa
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 @ending from gm@il@com  Fri Jan  4 19:15:16 2019
From: 538280 @ending from gm@il@com (Greg Snow)
Date: Fri, 4 Jan 2019 11:15:16 -0700
Subject: [R] Accessing Data Frame
In-Reply-To: <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
References: <20190103145022.Horde.LgsnD4JapRXrGhi78XNtJOg@www.imp.polymtl.ca>
 <CBFB58C0-6678-4D4D-B354-22B03235FFAD@dcn.davis.ca.us>
 <20190103173944.Horde._0-KOJ-TpIp-O_viaIUcf1P@www.imp.polymtl.ca>
Message-ID: <CAFEqCdzyeBav8uAUhQoUW3JUykcGELzxeXq08+KuxmoNc2qj-w@mail.gmail.com>

Here is another approach that uses only the default packages:

> onecar <- mtcars[10,]
> w <- which(duplicated(rbind(mtcars,onecar), fromLast = TRUE))
> w
[1] 10
> mtcars.subset <- mtcars[-w,]
>
>
> threecars <- mtcars[c(1,10,15),]
> w <- which(duplicated(rbind(mtcars,threecars), fromLast=TRUE))
> w
[1]  1 10 15
> mtcars.subset <- mtcars[-w, ]

This works with a subset of 1, or more than 1, but could cause
problems if you have duplicate rows in your original data frame.

If you are willing to use a non-default package then there are many
possibilities.  The anti_join function from the dplyr package has
already been mentioned, but the setdiff function from dplyr would also
work here and would be a little simpler for your example:

> library(dplyr)
> mtcars.subset2 <- setdiff(mtcars,threecars)
> identical(as.list(mtcars.subset), as.list(mtcars.subset2))
[1] TRUE

The as.list function above was to remove some attributes that were
different between the outputs.

On Thu, Jan 3, 2019 at 10:59 AM Benoit Galarneau
<benoit.galarneau at polymtl.ca> wrote:
>
> Thanks for the feedback.
> Point taken about the data.table package, I will take a look for sure.
> As I am new to the R programming, I'm exploring with the default
> libraries as a start.
>
> I have various options that works like this one:
>
> topCard <- deck[1,]
> #Remove card from deck using row name
> deck <- deck[!rownames(deck) %in% row.names(topCard),]
>
> Is it recommended/safe/good practice to work on items using the item names?
>
> Benoit
>
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit :
>
> >> In my programmer's head, something similar to this should "work": ...
> >> deck[aCard]
> >
> > There are some people who agree with you... see the data.table
> > package, which can be made to behave like this.
> >
> > Keep in mind that the aCard data frame in general may have a
> > different set of column names or more than one row. (I would be
> > concerned that the logic of your application was inefficiently
> > designed if `deck` actually has the same columns as `aCard` as in
> > your example.) Others have pointed out that data frames are
> > typically combined using the merge function, which allows matching
> > columns to be specified very flexibly.
> >
> >
> > On January 3, 2019 6:50:22 AM PST, Benoit Galarneau
> > <benoit.galarneau at polymtl.ca> wrote:
> >> Hi everyone,
> >> I'm new to the R world.
> >> Probably a newbie question but I am stuck with some concept with data
> >> frame.
> >> I am following some examples in the "Hands-On Programming with R".
> >>
> >> In short, how can I access/filter items in a data frame using a
> >> variable.
> >>
> >> One example consists of manipulating elements from a deck of card:
> >>
> >>> deck
> >>     face     suit value
> >> 1   king   spades    13
> >> 2  queen   spades    12
> >> 3   jack   spades    11
> >> 4    ten   spades    10
> >> etc.
> >>
> >> Let's say I want to remove or filter out the first card. I know I
> >> could do deck[-1].
> >>
> >> But let's say I have: topCard <- deck[1,]
> >>
> >> topCard is then a list of 3 elements
> >>> topCard
> >>   face   suit value
> >> 1 king spades    13
> >>
> >> My question is the following, how can I remove or filter out the deck
> >> using the topCard variable.
> >>
> >> In my programmer's head, something similar to this should "work":
> >>> deck[10,]
> >>    face   suit value
> >> 10 four spades     4
> >>> aCard <- deck[10,]
> >>> aCard
> >>    face   suit value
> >> 10 four spades     4
> >>> deck[aCard]
> >> Error in `[.default`(deck, aCard) : invalid subscript type 'list'
> >>
> >> Wihout having to specify all elements in the logical tests.
> >>
> >> deck[deck$face == aCard$face & deck$suit == aCard$suit & deck$value ==
> >>
> >> aCard$value,]
> >>    face   suit value
> >> 10 four spades     4
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From v@rin@@ch@ @ending from y@hoo@fr  Fri Jan  4 20:31:02 2019
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Fri, 4 Jan 2019 19:31:02 +0000 (UTC)
Subject: [R] Fit CMARS with R possible (Packages) ?
References: <841297769.20570830.1546630262854.ref@mail.yahoo.com>
Message-ID: <841297769.20570830.1546630262854@mail.yahoo.com>

Dear R-experts,

We can fit MARS regression using the packages "earth" and/or "mda" or others packages.
However, I am wondering if it is possible to fit a CMARS (Conic multivariate adaptive regression splines) using R ? 
I have googled "conic MARS with R software", I did not get anything, so Google is not my friend anymore !

If you have any solution, would be highly appreciated.

Best,


From bgunter@4567 @ending from gm@il@com  Fri Jan  4 23:16:15 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 4 Jan 2019 14:16:15 -0800
Subject: [R] Fit CMARS with R possible (Packages) ?
In-Reply-To: <841297769.20570830.1546630262854@mail.yahoo.com>
References: <841297769.20570830.1546630262854.ref@mail.yahoo.com>
 <841297769.20570830.1546630262854@mail.yahoo.com>
Message-ID: <CAGxFJbR3KBi8BQi1j9O4e5=AC0ifi0ND-vQ6BDHVoUZkJhigyA@mail.gmail.com>

rseek.org might be a better place to search if you haven't tried t
herealready. However, my minimal effort there did not turn up any R
software.  Maybe you can do better.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 4, 2019 at 11:31 AM varin sacha via R-help <r-help at r-project.org>
wrote:

> Dear R-experts,
>
> We can fit MARS regression using the packages "earth" and/or "mda" or
> others packages.
> However, I am wondering if it is possible to fit a CMARS (Conic
> multivariate adaptive regression splines) using R ?
> I have googled "conic MARS with R software", I did not get anything, so
> Google is not my friend anymore !
>
> If you have any solution, would be highly appreciated.
>
> Best,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Sat Jan  5 00:26:44 2019
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Fri, 4 Jan 2019 18:26:44 -0500
Subject: [R] Fit CMARS with R possible (Packages) ?
In-Reply-To: <CAGxFJbR3KBi8BQi1j9O4e5=AC0ifi0ND-vQ6BDHVoUZkJhigyA@mail.gmail.com>
References: <841297769.20570830.1546630262854.ref@mail.yahoo.com>
 <841297769.20570830.1546630262854@mail.yahoo.com>
 <CAGxFJbR3KBi8BQi1j9O4e5=AC0ifi0ND-vQ6BDHVoUZkJhigyA@mail.gmail.com>
Message-ID: <F5AEBA61-BB59-47E2-B17C-3CB646F36A00@me.com>

Hi,

Like Bert, I was not able to find anything built in R.

It is possible that CMARS has not yet been implemented in R, or may be in development but not yet ready for release.

I found several references to the use of MOSEK (https://www.mosek.com) along with MATLAB, but both are commercial products.

The MOSEK developers appear to have an Rmosek interface package:

  https://docs.mosek.com/8.1/rmosek/index.html

which provides access to the MOSEK functionality via R. But, it requires MOSEK...

Perhaps others with more refined knowledge will jump in. It might also be reasonable to consider contacting what appears to be a small-ish group of common authors that I came across in the search who have described the methodology (e.g. Taylan or Yerlikaya-?zkurt) to see if they are aware of any R implementations.

Regards,

Marc Schwartz


> On Jan 4, 2019, at 5:16 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> rseek.org might be a better place to search if you haven't tried t
> herealready. However, my minimal effort there did not turn up any R
> software.  Maybe you can do better.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Jan 4, 2019 at 11:31 AM varin sacha via R-help <r-help at r-project.org>
> wrote:
> 
>> Dear R-experts,
>> 
>> We can fit MARS regression using the packages "earth" and/or "mda" or
>> others packages.
>> However, I am wondering if it is possible to fit a CMARS (Conic
>> multivariate adaptive regression splines) using R ?
>> I have googled "conic MARS with R software", I did not get anything, so
>> Google is not my friend anymore !
>> 
>> If you have any solution, would be highly appreciated.
>> 
>> Best,


From D@vid@M@Smith @ending from micro@oft@com  Fri Jan  4 18:21:44 2019
From: D@vid@M@Smith @ending from micro@oft@com (David Smith (CDA))
Date: Fri, 4 Jan 2019 17:21:44 +0000
Subject: [R] Revolutions blog: December 2018 roundup
Message-ID: <DM5PR2101MB10961B9061D2607CFDB06508B98E0@DM5PR2101MB1096.namprd21.prod.outlook.com>

Happy New Year! For more than 10 years, Microsoft staff and guests have written
about R at the Revolutions blog (http://blog.revolutionanalytics.com) and every
month I post a summary of articles from the previous month of particular
interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of December:

R 3.5.2 is now available:
https://blog.revolutionanalytics.com/2018/12/r-352-announcement.html

Roundup of AI, Machine Learning and Data Science news from December 2018:
https://blog.revolutionanalytics.com/2018/12/airoundup-december-2018.html

AzureStor, a new R package to interface with Azure Storage:
https://blog.revolutionanalytics.com/2018/12/azurestor.html

How to use the "plumber" package to create an R service as a container with the
AzureContainers package:
https://blog.revolutionanalytics.com/2018/12/azurecontainers.html

How to give money to the R Foundation in support of the R project:
https://blog.revolutionanalytics.com/2018/12/support-your-tools.html

The Revolutions blog is 10 years old, and I reflect on some milestones in a talk
given at SatRDays DC:
https://blog.revolutionanalytics.com/2018/12/ten-years-of-revolutions.html

Reshama Shaikh compares gender diversity within the R and Python communities:
https://blog.revolutionanalytics.com/2018/12/women-and-r.html

AzureVM, a new package for managing virtual machines in Azure from R:
https://blog.revolutionanalytics.com/2018/12/azurevm.html

And some general interest stories (not necessarily related to R):

* Santa Claus and compliance with GDPR:
  https://blog.revolutionanalytics.com/2018/12/because-its-friday-santa-claus-gdpr.html

* A parody on the use of CGI in film:
  https://blog.revolutionanalytics.com/2018/12/because-its-friday-cgi-you-never-knew-was-cgi.html

* The story behind Fleetwood Mac's 'Go Your Own Way':
  https://blog.revolutionanalytics.com/2018/12/because-its-saturday-go-your-own-way.html

As always, thanks for the comments and please keep sending suggestions to me at
davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Cloud Advocate, Microsoft Cloud & AI Developer Relations
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From winfried@mo@er @ending from gm@il@com  Fri Jan  4 23:23:05 2019
From: winfried@mo@er @ending from gm@il@com (Winfried Moser)
Date: Fri, 4 Jan 2019 23:23:05 +0100
Subject: [R] g++ error causes non-zero exit status for package installation
Message-ID: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>

dear community,

i get a *non-zero exit status* installing the survey-package in R version
3.5.2 on ubuntu 18.04. the problem seems to be related to *g++* and/or the
package *minqa*. in the output of the installation procedure i found the
following g++ related lines:

g++ -I"/usr/share/R/include" -DNDEBUG -I"/home/winfried/rlibs/Rcpp/include"
-f
[...]
g++ -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o
minqa.so altm
[...]
g++: error: R: Datei oder Verzeichnis nicht gefunden
g++: error: version: Datei oder Verzeichnis nicht gefunden
g++: error: 3.5.2: Datei oder Verzeichnis nicht gefunden
g++: error: (2018-12-20): Datei oder Verzeichnis nicht gefunden

can someone help or point me in a direction? several packages, that i use
frequently, are conserned (survey, lme4, effects)

best, winfried

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Jan  5 14:46:15 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sat, 5 Jan 2019 05:46:15 -0800 (PST)
Subject: [R] CRAN updates
Message-ID: <alpine.LNX.2.20.1901050543570.16463@salmo.appl-ecosys.com>

   Is there a file where I can specify the repository to use when upgrading
packages rather than having R ask each time?

TIA,

Rich


From @eb@@tien@bihorel @ending from cognigencorp@com  Sat Jan  5 14:58:07 2019
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Sat, 5 Jan 2019 08:58:07 -0500 (EST)
Subject: [R] Diff'ing 2 strings
Message-ID: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>

Hi,

Does R include an equivalent of the linux diff command?

Ideally I would like to diff 2 fairly complex strings and extract the differences without having to save them on disk and using a system('diff file1 file2') command.

Thanks

Sebastien


From edd @ending from debi@n@org  Sat Jan  5 15:06:35 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 08:06:35 -0600
Subject: [R] CRAN updates
In-Reply-To: <alpine.LNX.2.20.1901050543570.16463@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1901050543570.16463@salmo.appl-ecosys.com>
Message-ID: <23600.47595.977492.172830@rob.eddelbuettel.com>


On 5 January 2019 at 05:46, Rich Shepard wrote:
|    Is there a file where I can specify the repository to use when upgrading
| packages rather than having R ask each time?

Many ways. You want to set options(repos) -- see eg help(download.packages)
and see help(Startup) for the many ways where you can do that.

The Debian packages do it for you as the question is i) silly and ii) we now
a globally valid and "best" (as in: fast, local network mirror) solution. You
can add these six lines to Rprofile.site (as Debian does) or your ~/.Rprofile
or ...

  ## We set the cloud mirror, which is 'network-close' to everybody, as default
  local({
      r <- getOption("repos")
      r["CRAN"] <- "https://cloud.r-project.org"
      options(repos = r)
  })

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd @ending from debi@n@org  Sat Jan  5 15:10:39 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 08:10:39 -0600
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
Message-ID: <23600.47839.672186.700695@rob.eddelbuettel.com>


On 4 January 2019 at 23:23, Winfried Moser wrote:
| dear community,
| 
| i get a *non-zero exit status* installing the survey-package in R version
| 3.5.2 on ubuntu 18.04. the problem seems to be related to *g++* and/or the
| package *minqa*. in the output of the installation procedure i found the
| following g++ related lines:
| 
| g++ -I"/usr/share/R/include" -DNDEBUG -I"/home/winfried/rlibs/Rcpp/include"
| -f
| [...]
| g++ -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o
| minqa.so altm
| [...]
| g++: error: R: Datei oder Verzeichnis nicht gefunden
| g++: error: version: Datei oder Verzeichnis nicht gefunden
| g++: error: 3.5.2: Datei oder Verzeichnis nicht gefunden
| g++: error: (2018-12-20): Datei oder Verzeichnis nicht gefunden
| 
| can someone help or point me in a direction? several packages, that i use
| frequently, are conserned (survey, lme4, effects)

Wrong mailing list. Please subscribe to r-sig-debian and post there.

Someone posted a similar looking error recently (in a GitHub issue I can't
find now) but we did not solve it.  Somehow the call goes funky meaning that
the values in /etc/R/Makeconf got altted or affected or corrupted. No idea
why -- thousands of people use R on Ubuntu daily, myself included.

The good new is that you can (and maybe should !) consider prebuilt
binaries. These packages are all in Ubuntu as r-cran-survey, r-cran-lme4,
r-cran-effects -- and the Rutter PPAs give you even newer version. Read the
first four paragraphs, and particularly the fourth, of

   https://cloud.r-project.org/bin/linux/ubuntu/README.html

and enjoy the availability of 4000+ r-cran-* binary packages.

I am still interested in understanding the bug report but please bring it to
r-sig-debian.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd @ending from debi@n@org  Sat Jan  5 15:12:56 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 08:12:56 -0600
Subject: [R] Failed to install RQuantLib in Ubuntu machine
In-Reply-To: <CA+dpOJ=iFuY9Cu0RSWipYqDjjGA_3TtaETY8KPtduB7CDT7+HQ@mail.gmail.com>
References: <CA+dpOJ=iFuY9Cu0RSWipYqDjjGA_3TtaETY8KPtduB7CDT7+HQ@mail.gmail.com>
Message-ID: <23600.47976.152134.165519@rob.eddelbuettel.com>


On 3 January 2019 at 03:16, Christofer Bogaso wrote:
| I was trying to install RQuantLib in my Ubuntu machine which failed with
| below information :

Try this on the shell instead:

    sudo apt-get install r-cran-rquantlib

Otherwise maybe rebuild Rcpp from inside R, or also install it from source,
or .... You have a linking error which can happen when the C++ libraries
change.  Maybe you have an older Rcpp binary package.  We can't tell from
what you posted.  In any event, easiest to use a binary as I suggest here.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Jan  5 15:54:39 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sat, 5 Jan 2019 06:54:39 -0800 (PST)
Subject: [R] CRAN updates
In-Reply-To: <23600.47595.977492.172830@rob.eddelbuettel.com>
References: <alpine.LNX.2.20.1901050543570.16463@salmo.appl-ecosys.com>
 <23600.47595.977492.172830@rob.eddelbuettel.com>
Message-ID: <alpine.LNX.2.20.1901050653490.16463@salmo.appl-ecosys.com>

On Sat, 5 Jan 2019, Dirk Eddelbuettel wrote:

> ... can add these six lines to Rprofile.site (as Debian does) or your ~/.Rprofile

Dirk,

   Thank you. I missed seeing .Rprofile when I went looking for it.

Regards,

Rich


From bgunter@4567 @ending from gm@il@com  Sat Jan  5 16:19:42 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 5 Jan 2019 07:19:42 -0800
Subject: [R] Diff'ing 2 strings
In-Reply-To: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbQyiwXkv2Y86maU-Pr6qMF9Gu_v8Qt3Kg_WQ8UX0k7=Bw@mail.gmail.com>

I do not know what you mean in your string context, as diff in Linux finds
lines in files that differ. A reproducible example -- posting guide! --
would be most useful here.

However, maybe something of the following strategy might be useful:

1. Break up your strings into lists of string "chunks" relevant for your
context via strspit() . Using "" (empty character) as the "sep" string
would break your strings into individual characters; "\n" would break it
into "lines" separated by the return
character; etc.

2. Compare your lists using e.g. lapply() and probably ?match and friends
like ?setdiff

You should also probably check out the stringr package to see if it
contains what you need. Also, if this is gene sequence related, posting on
the Bioconductor list rather than here is likely to be more fruitful.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jan 5, 2019 at 5:58 AM Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Hi,
>
> Does R include an equivalent of the linux diff command?
>
> Ideally I would like to diff 2 fairly complex strings and extract the
> differences without having to save them on disk and using a system('diff
> file1 file2') command.
>
> Thanks
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@l@xie2485 @ending from y@hoo@co@in  Sat Jan  5 16:28:18 2019
From: g@l@xie2485 @ending from y@hoo@co@in (Priya Arasu)
Date: Sat, 5 Jan 2019 15:28:18 +0000 (UTC)
Subject: [R] Merge the data from multiple text files
References: <43063892.12726432.1546702098597.ref@mail.yahoo.com>
Message-ID: <43063892.12726432.1546702098597@mail.yahoo.com>

I have multiple text files, where each file has Boolean rules.
Example of my text file 1 and 2
Text file 1:
A = not(B or C)
B = A and C
C = D
Text file 2:
A = D and E
B = not(D)

I want to merge the contents in text file as follows
A = not(B or C) and (D and E)
B = not(D) and (A and C)
C = D
Is there a code in R to merge the data from multiple text files?
Thank you
Priya?

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Sat Jan  5 18:14:09 2019
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Sat, 5 Jan 2019 09:14:09 -0800
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
Message-ID: <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>

You would get these errors ("R: file or directory not found, version: file
or directory not found...") if you had a ~/.Rprofile file containing the
line 'cat(version$version.string, sep="\n").

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Jan 5, 2019 at 1:23 AM Winfried Moser <winfried.moser at gmail.com>
wrote:

> dear community,
>
> i get a *non-zero exit status* installing the survey-package in R version
> 3.5.2 on ubuntu 18.04. the problem seems to be related to *g++* and/or the
> package *minqa*. in the output of the installation procedure i found the
> following g++ related lines:
>
> g++ -I"/usr/share/R/include" -DNDEBUG -I"/home/winfried/rlibs/Rcpp/include"
> -f
> [...]
> g++ -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o
> minqa.so altm
> [...]
> g++: error: R: Datei oder Verzeichnis nicht gefunden
> g++: error: version: Datei oder Verzeichnis nicht gefunden
> g++: error: 3.5.2: Datei oder Verzeichnis nicht gefunden
> g++: error: (2018-12-20): Datei oder Verzeichnis nicht gefunden
>
> can someone help or point me in a direction? several packages, that i use
> frequently, are conserned (survey, lme4, effects)
>
> best, winfried
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Jan  5 18:21:02 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 5 Jan 2019 09:21:02 -0800
Subject: [R] Diff'ing 2 strings
In-Reply-To: <CAGxFJbQyiwXkv2Y86maU-Pr6qMF9Gu_v8Qt3Kg_WQ8UX0k7=Bw@mail.gmail.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQyiwXkv2Y86maU-Pr6qMF9Gu_v8Qt3Kg_WQ8UX0k7=Bw@mail.gmail.com>
Message-ID: <CAGxFJbRyXGUGSriBkH+0Exb7SwimPz4SEyXMf2g1yV-s6BtLYg@mail.gmail.com>

It's the "split" string not the "sep" string, as you and probably everyone
else already realizes.
And, of course, it could be a regular expression, not literally a character
string.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jan 5, 2019 at 7:19 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I do not know what you mean in your string context, as diff in Linux finds
> lines in files that differ. A reproducible example -- posting guide! --
> would be most useful here.
>
> However, maybe something of the following strategy might be useful:
>
> 1. Break up your strings into lists of string "chunks" relevant for your
> context via strspit() . Using "" (empty character) as the "sep" string
> would break your strings into individual characters; "\n" would break it
> into "lines" separated by the return
> character; etc.
>
> 2. Compare your lists using e.g. lapply() and probably ?match and friends
> like ?setdiff
>
> You should also probably check out the stringr package to see if it
> contains what you need. Also, if this is gene sequence related, posting on
> the Bioconductor list rather than here is likely to be more fruitful.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Jan 5, 2019 at 5:58 AM Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com> wrote:
>
>> Hi,
>>
>> Does R include an equivalent of the linux diff command?
>>
>> Ideally I would like to diff 2 fairly complex strings and extract the
>> differences without having to save them on disk and using a system('diff
>> file1 file2') command.
>>
>> Thanks
>>
>> Sebastien
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From edd @ending from debi@n@org  Sat Jan  5 18:40:48 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 11:40:48 -0600
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
 <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
Message-ID: <23600.60448.842611.623129@rob.eddelbuettel.com>


On 5 January 2019 at 09:14, William Dunlap via R-help wrote:
| You would get these errors ("R: file or directory not found, version: file
| or directory not found...") if you had a ~/.Rprofile file containing the
| line 'cat(version$version.string, sep="\n").

Well spotted -- very much so. That is bound to break use within src/Makevars
and alike. If you must do something in ~/.Rprofile either make it silent, or
make it conditional based on if (interactive()) { ...that_code_here... }

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From r@chel@thomp@on @ending from @tudent@uv@@nl  Fri Jan  4 19:24:26 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Fri, 4 Jan 2019 13:24:26 -0500
Subject: [R] Mailinglist
Message-ID: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>

Dear Mr/Mrs,

This is my first time working in R studio.
I have a database of 36 participants but it has 150600 entries.
Column -         Column - Column            - Column

Participant       Activityprobe - Activity Level  - High/low/none

Participant       Screenprobe - screenon/off     -

Participant       SMSprobe etc

Participant       CallLogProbe etc.

I need a code that helps me count the activity level of all the participants
High activity level. No activity level and Low activity level.
And to help me find out for every participant what the percentages are of
all their high/no/low activity.

For screenprobe I need to count how many times the participant turned their
screen on and how many times they turned it off and the percentage of
screen on/off.

For callLog I need to count how many times each participant got called and
the percentage.

For SMS I need to count the number of SMS for each participant and their
percentage.

I also need to categorize the probes. So that my database shows all the
activity levels first, organized by none/high/low and then all the
screenprobes, organized by on and off etc...

I hope that my description is clear and that you can maybe help me.

Best,

Rachel

	[[alternative HTML version deleted]]


From n@di@t@ @ending from yorku@c@  Sat Jan  5 15:18:28 2019
From: n@di@t@ @ending from yorku@c@ (Nadia Tsvetkov)
Date: Sat, 5 Jan 2019 09:18:28 -0500
Subject: [R] Sciplot bargraph.CI err.lty not working
Message-ID: <CAHHsGLFHx4RApczM0T6Cy5urHmj60n6iV0LN_U7MhtMbbeK1WA@mail.gmail.com>

Hello,

I am plotting ordered data as a bargraph using the following code:

 bargraph.CI(response=yfac, x.factor=xfac, err.lty=0, data=test)

However, I still get error bars. In fact, err.lty=*1* or *2* or *asd *gives
the same results and no error massage even if left blank.

err.col also produces no differences in the graph, but err.width does work.

Am I doing something incorrectly or is this a bug?

data segment:
ID xfac yfac
I3A 1 4
I7A 1 6
I4A 1 7
I13C 8 1
I13D 8 7
J2A 1 2
J10A 1 6
J5A 1 7
J8A 1 7
J7A 1 7
J16D 8 1
J16A 8 1
J13C 8 2
J15A 8 2
J16A 8 3
J14C 8 7
J14B 8 7
J18C 32 2
J19A 32 2
J17C 32 4
J17A 32 5

Sincerely,

Nadia

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Sat Jan  5 20:11:33 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 5 Jan 2019 11:11:33 -0800
Subject: [R] Merge the data from multiple text files
In-Reply-To: <43063892.12726432.1546702098597@mail.yahoo.com>
References: <43063892.12726432.1546702098597.ref@mail.yahoo.com>
 <43063892.12726432.1546702098597@mail.yahoo.com>
Message-ID: <0f9400b6-ecc5-b8b4-95cc-58ed12c79884@comcast.net>


On 1/5/19 7:28 AM, Priya Arasu via R-help wrote:
> I have multiple text files, where each file has Boolean rules.
> Example of my text file 1 and 2
> Text file 1:
> A = not(B or C)
> B = A and C
> C = D
> Text file 2:
> A = D and E
> B = not(D)
>
> I want to merge the contents in text file as follows
> A = not(B or C) and (D and E)
> B = not(D) and (A and C)
> C = D
> Is there a code in R to merge the data from multiple text files?


There is a `merge` function. For this use case you would need to first 
parse your expressions so that the LHS was in one character column and 
the RHS was in another character column in each of 2 dataframes. Then 
merge on the LHS columns and `paste` matching values from the two 
columns. You will probably need to learn how to use `ifelse` and `is.na`.

> Thank you
> Priya
>
> 	[[alternative HTML version deleted]]


You also need to learn that R is a plain text mailing list and that each 
mail client has its own method for building mail in plain text.


-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd @ending from debi@n@org  Sat Jan  5 21:14:49 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 14:14:49 -0600
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <CACwq_uJbpWR66Gq4bum9Zy=EgNmAsYeJjVLhw70wp5X3Qh7TGA@mail.gmail.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
 <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
 <23600.60448.842611.623129@rob.eddelbuettel.com>
 <CACwq_uJbpWR66Gq4bum9Zy=EgNmAsYeJjVLhw70wp5X3Qh7TGA@mail.gmail.com>
Message-ID: <23601.4153.993364.590546@rob.eddelbuettel.com>


On 5 January 2019 at 20:40, Winfried Moser wrote:
| dirk & bill, you guys are incredible! the non-silent .Rprofile was the
| problem!
| making the code interactive didn't help either, only silenceing it helped!

Good to know you have it fixed.
 
| thanks so much! i assume moving to r-sig-debian is now obsolete.
| 
| ps, @dirk: adding michael rutters ppa also helped, but the packages get
| installed to R_LIBS_SITE, and not (as i am used to) to R_LIBS-USER.
| but this was only a minor inconvinience (i like to keep the packages in one
| directory).

No, it is even more fine grained:

 - r-cran-* packages always install in /usr/lib/R/site-library

 - (One exception: Base R and recommended packages go to /usr/lib/R/library )

 - local "from source" installation goes by default to /usr/local/lib/R/site-library
   
and the third part is much better for multi-user setting.  See the comments
in the file /etc/R/Renviron.site if you want to change this.

This has been our default since about 2003 or 2004 when Kurt Hornik and Fritz
Leisch convinced me of that approach in a Vienna bar. It is better.

And this discussion too belonged on r-sig-debian so let's stop here.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From winfried@mo@er @ending from gm@il@com  Sat Jan  5 20:40:09 2019
From: winfried@mo@er @ending from gm@il@com (Winfried Moser)
Date: Sat, 5 Jan 2019 20:40:09 +0100
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <23600.60448.842611.623129@rob.eddelbuettel.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
 <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
 <23600.60448.842611.623129@rob.eddelbuettel.com>
Message-ID: <CACwq_uJbpWR66Gq4bum9Zy=EgNmAsYeJjVLhw70wp5X3Qh7TGA@mail.gmail.com>

dirk & bill, you guys are incredible! the non-silent .Rprofile was the
problem!
making the code interactive didn't help either, only silenceing it helped!

thanks so much! i assume moving to r-sig-debian is now obsolete.

ps, @dirk: adding michael rutters ppa also helped, but the packages get
installed to R_LIBS_SITE, and not (as i am used to) to R_LIBS-USER.
but this was only a minor inconvinience (i like to keep the packages in one
directory).

thanks again!
winfried

Am Sa., 5. Jan. 2019 um 18:40 Uhr schrieb Dirk Eddelbuettel <edd at debian.org
>:

>
> On 5 January 2019 at 09:14, William Dunlap via R-help wrote:
> | You would get these errors ("R: file or directory not found, version:
> file
> | or directory not found...") if you had a ~/.Rprofile file containing the
> | line 'cat(version$version.string, sep="\n").
>
> Well spotted -- very much so. That is bound to break use within
> src/Makevars
> and alike. If you must do something in ~/.Rprofile either make it silent,
> or
> make it conditional based on if (interactive()) { ...that_code_here... }
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From henrik@bengt@@on @ending from gm@il@com  Sat Jan  5 22:13:25 2019
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Sat, 5 Jan 2019 13:13:25 -0800
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <23600.60448.842611.623129@rob.eddelbuettel.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
 <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
 <23600.60448.842611.623129@rob.eddelbuettel.com>
Message-ID: <CAFDcVCQLZo_GCmmw_czOkBVk8zJZPEzyvikjJ_73v+LWzAG1AA@mail.gmail.com>

On Sat, Jan 5, 2019 at 9:41 AM Dirk Eddelbuettel <edd at debian.org> wrote:
>
>
> On 5 January 2019 at 09:14, William Dunlap via R-help wrote:
> | You would get these errors ("R: file or directory not found, version: file
> | or directory not found...") if you had a ~/.Rprofile file containing the
> | line 'cat(version$version.string, sep="\n").
>
> Well spotted -- very much so. That is bound to break use within src/Makevars
> and alike. If you must do something in ~/.Rprofile either make it silent, or
> make it conditional based on if (interactive()) { ...that_code_here... }

Interesting problem.  One way to workaround this startup issue with:

  PKG_LIBS = `$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"`

used by minqa:src/Makevars
(https://r-forge.r-project.org/scm/viewvc.php/pkg/minqa/src/Makevars?view=markup&root=optimizer),
could be to use something like:

  PKG_LIBS = `Rscript -e "cat('LDFLAGS:\n')" -e "Rcpp:::LdFlags()" |
grep -A 999 "LDFLAGS:" | grep -v "LDFLAGS:"`

and analogously for src/Makevars.win.

But in the bigger picture, maybe there's room for an R/Rscript option
to silence all R startup stdout and/or stderr output?  For example,

  Rscript --quiet-startup -e "Rcpp:::LdFlags()"`

/Henrik

PS. It's probably better to output to stderr in .Rprofile, e.g. by
always using message() instead of cat(). However, that cannot be
assumed to always be the case.

>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd @ending from debi@n@org  Sat Jan  5 22:32:25 2019
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 5 Jan 2019 15:32:25 -0600
Subject: [R] 
 g++ error causes non-zero exit status for package installation
In-Reply-To: <CAFDcVCQLZo_GCmmw_czOkBVk8zJZPEzyvikjJ_73v+LWzAG1AA@mail.gmail.com>
References: <CACwq_uKMucFfb4mR4j7hdK=afkKpzVB3WBPop2GEBwODc0+Udg@mail.gmail.com>
 <CAF8bMca6emPM4NZmREnSmiSrnWRY8cuuyOc2fP3OR3gbu8NmDA@mail.gmail.com>
 <23600.60448.842611.623129@rob.eddelbuettel.com>
 <CAFDcVCQLZo_GCmmw_czOkBVk8zJZPEzyvikjJ_73v+LWzAG1AA@mail.gmail.com>
Message-ID: <23601.8809.544071.987178@rob.eddelbuettel.com>


On 5 January 2019 at 13:13, Henrik Bengtsson wrote:
| On Sat, Jan 5, 2019 at 9:41 AM Dirk Eddelbuettel <edd at debian.org> wrote:
| >
| >
| > On 5 January 2019 at 09:14, William Dunlap via R-help wrote:
| > | You would get these errors ("R: file or directory not found, version: file
| > | or directory not found...") if you had a ~/.Rprofile file containing the
| > | line 'cat(version$version.string, sep="\n").
| >
| > Well spotted -- very much so. That is bound to break use within src/Makevars
| > and alike. If you must do something in ~/.Rprofile either make it silent, or
| > make it conditional based on if (interactive()) { ...that_code_here... }
| 
| Interesting problem.  One way to workaround this startup issue with:
| 
|   PKG_LIBS = `$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"`
| 
| used by minqa:src/Makevars
| (https://r-forge.r-project.org/scm/viewvc.php/pkg/minqa/src/Makevars?view=markup&root=optimizer),

Nothing like 'Read the source, Luke!' :)

The *real* problem here is that command has been *obsolete* since early 2014
or for almost five years -- Rcpp does NOT require linking!

Hence the command is a null-op now, provided for backwards-compatibility:

     R> Rcpp:::LdFlags()
     R> 

Then again minqa has not been updated since 2014 either so there...

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dc@rl@on @ending from t@mu@edu  Sun Jan  6 00:09:21 2019
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Sat, 5 Jan 2019 23:09:21 +0000
Subject: [R] Merge the data from multiple text files
In-Reply-To: <0f9400b6-ecc5-b8b4-95cc-58ed12c79884@comcast.net>
References: <43063892.12726432.1546702098597.ref@mail.yahoo.com>
 <43063892.12726432.1546702098597@mail.yahoo.com>
 <0f9400b6-ecc5-b8b4-95cc-58ed12c79884@comcast.net>
Message-ID: <2931150f25f346249f68b5546376bff0@tamu.edu>

To expand on David W's answer, here is an approach to your example. If you have many text files, you would want to process them together rather than individually. You gave us two examples so I'll use those and read them from the console using readLines(), but you would use the same function to open the files on your computer:

> TF1 <- readLines(n=3)
A = not(B or C)
B = A and C
C = D
> 
> TF2 <- readLines(n=2)
A = D and E
B = not(D)
> 
> TF <- sort(c(TF1, TF2))
> TF
[1] "A = D and E"     "A = not(B or C)" "B = A and C"     "B = not(D)"
[5] "C = D"

Now we have combined the files into a single character vector called TF and sorted them. Next we need to parse them into the left and right hand sides. We will replace " = " with "\t" (tab) to do that:

> TF.delim <- gsub(" = ", "\t", TF)
> TF.data <- read.delim(text=TF.delim, header=FALSE, as.is=TRUE)
> colnames(TF.data) <- c("LHS", "RHS")
> print(TF.data, right=FALSE)
  LHS RHS
1 A   D and E
2 A   not(B or C)
3 B   A and C
4 B   not(D)
5 C   D

TF.data is a data frame with two columns. The tricky part is to add surrounding parentheses to rows 1 and 3 to get your example output:

> paren1 <- grepl("and", TF.data$RHS)
> paren2 <- !grepl("\\(*\\)", TF.data$RHS)
> paren <- apply(cbind(paren1, paren2), 1, all)
> TF.data$RHS[paren] <- paste0("(", TF.data$RHS[paren], ")")
> print(TF.data, right=FALSE)
  LHS RHS
1 A   (D and E)
2 A   not(B or C)
3 B   (A and C)
4 B   not(D)
5 C   D

The first three lines identify the rows that have the word "and" but do not already have parentheses. The fourth line adds the surrounding parentheses. Finally we will combine the rows that belong to the same LHS value with split and create a list:

> TF.list <- split(TF.data$RHS, TF.data$LHS)
> TF.list
$`A`
[1] "(D and E)"   "not(B or C)"

$B
[1] "(A and C)" "not(D)"   

$C
[1] "D"

> TF.and <- lapply(TF.list, paste, collapse=" and ")
> TF.final <- lapply(names(TF.and), function(x) paste(x, "=", TF.and[[x]]))
> TF.final <- do.call(rbind, TF.final)
> TF.final
     [,1]                           
[1,] "A = (D and E) and not(B or C)"
[2,] "B = (A and C) and not(D)"
[3,] "C = D"
> write(TF.final, file="TF.output.txt")

The text file "TF.output.txt" contains the three lines.

----------------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Saturday, January 5, 2019 1:12 PM
To: Priya Arasu <galaxie2485 at yahoo.co.in>; r-help at r-project.org
Subject: Re: [R] Merge the data from multiple text files


On 1/5/19 7:28 AM, Priya Arasu via R-help wrote:
> I have multiple text files, where each file has Boolean rules.
> Example of my text file 1 and 2
> Text file 1:
> A = not(B or C)
> B = A and C
> C = D
> Text file 2:
> A = D and E
> B = not(D)
>
> I want to merge the contents in text file as follows
> A = not(B or C) and (D and E)
> B = not(D) and (A and C)
> C = D
> Is there a code in R to merge the data from multiple text files?


There is a `merge` function. For this use case you would need to first 
parse your expressions so that the LHS was in one character column and 
the RHS was in another character column in each of 2 dataframes. Then 
merge on the LHS columns and `paste` matching values from the two 
columns. You will probably need to learn how to use `ifelse` and `is.na`.

> Thank you
> Priya
>
> 	[[alternative HTML version deleted]]


You also need to learn that R is a plain text mailing list and that each 
mail client has its own method for building mail in plain text.


-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jan  6 01:15:07 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 05 Jan 2019 16:15:07 -0800
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
Message-ID: <CC01AC34-E2C5-4B76-8711-5271207AF6A4@dcn.davis.ca.us>

Not really. This is R-help, not R-do-my-work-for-me. You need to make enough progress in doing your work that you can ask a focused question about how to do some step of your work in R before your query will be answerable on this mailing list. Once you have started your work you will have some code and sample data you can share with us that w can run so we can understand your question (code without data is often really confusing). Note that R is text-based, and so is this mailing list... when you allow your email program to add HTML formatting to the email you send, the formatting will get removed anyway and the plain text that remains is often not readable or R won't understand the code... so follow the Posting Guide and set your email program to send plain text to begin with.

Some useful readings are [1][2][3], and don't forget the Posting Guide mentioned in the footer of this and every posting on this mailing list. If you haven't already found an intro to R that you like, you might read [4].

Finally... please notice that RStudio provides one possible (very nice) way to interact with R, but this mailing list is indeed about R and not that specific user interface. You have to install R before RStudio can even be used, so you can always test your problem in R to be sure which program is causing your difficulty. If your question only arises when RStudio is being used then it doesn't belong here.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] https://rstudio-education.github.io/hopr/


On January 4, 2019 10:24:26 AM PST, Rachel Thompson <rachel.thompson at student.uva.nl> wrote:
>Dear Mr/Mrs,
>
>This is my first time working in R studio.
>I have a database of 36 participants but it has 150600 entries.
>Column -         Column - Column            - Column
>
>Participant       Activityprobe - Activity Level  - High/low/none
>
>Participant       Screenprobe - screenon/off     -
>
>Participant       SMSprobe etc
>
>Participant       CallLogProbe etc.
>
>I need a code that helps me count the activity level of all the
>participants
>High activity level. No activity level and Low activity level.
>And to help me find out for every participant what the percentages are
>of
>all their high/no/low activity.
>
>For screenprobe I need to count how many times the participant turned
>their
>screen on and how many times they turned it off and the percentage of
>screen on/off.
>
>For callLog I need to count how many times each participant got called
>and
>the percentage.
>
>For SMS I need to count the number of SMS for each participant and
>their
>percentage.
>
>I also need to categorize the probes. So that my database shows all the
>activity levels first, organized by none/high/low and then all the
>screenprobes, organized by on and off etc...
>
>I hope that my description is clear and that you can maybe help me.
>
>Best,
>
>Rachel
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Sun Jan  6 03:03:36 2019
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 6 Jan 2019 13:03:36 +1100
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
Message-ID: <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>

Hi Rachel,
I'll take a guess and assume that you are monitoring the mobile phones
of 36 people, adding an observation every time some specified change
of state is sensed on each device. I'll also assume that you are only
recording four types of measurement. It seems that you want to
aggregate these events for each subject over the interval or
observation (or over each day or something). I think you are going to
create a new data frame of these summaries from the one you have of
individual observations. Creating each summary doesn't look too hard,
but you will have to define more precisely what you want those
summaries to be. For instance, "I want the mean activity level for
each subject during the overall time that their mobile phone is
switched on", One you have clearly defined your goals, it probably
won't be too hard to get to them.

Jim

On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
<rachel.thompson at student.uva.nl> wrote:
>
> Dear Mr/Mrs,
>
> This is my first time working in R studio.
> I have a database of 36 participants but it has 150600 entries.
> Column -         Column - Column            - Column
>
> Participant       Activityprobe - Activity Level  - High/low/none
>
> Participant       Screenprobe - screenon/off     -
>
> Participant       SMSprobe etc
>
> Participant       CallLogProbe etc.
>
> I need a code that helps me count the activity level of all the participants
> High activity level. No activity level and Low activity level.
> And to help me find out for every participant what the percentages are of
> all their high/no/low activity.
>
> For screenprobe I need to count how many times the participant turned their
> screen on and how many times they turned it off and the percentage of
> screen on/off.
>
> For callLog I need to count how many times each participant got called and
> the percentage.
>
> For SMS I need to count the number of SMS for each participant and their
> percentage.
>
> I also need to categorize the probes. So that my database shows all the
> activity levels first, organized by none/high/low and then all the
> screenprobes, organized by on and off etc...
>
> I hope that my description is clear and that you can maybe help me.
>
> Best,
>
> Rachel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Sun Jan  6 10:12:46 2019
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 6 Jan 2019 20:12:46 +1100
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
Message-ID: <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>

Hi Rachel,
It looks to me as though the first thing you want to do is to get your
data, which you attach as images, into a data frame. If these are flat
files like CSV or TAB, you should be able to read them in with some
variant of the read.table function. If Excel, look at the various
Excel import packages. Then you can operate on the data frame by doing
things like tabulating Participant ID against the code for SMS or call
(which I assume are those 3000+ numbers). You can take the differences
in what look like POSIX time values between successive TRUE and FALSE
screen values to get the duration of screen activity and it looks like
participant activity is recorded at regular intervals. As Jeff
suggested, this is really just boring work figuring out how to extract
the events:

call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
== _id  & Valuedetailed ==3271)

using suitable logical statements and then tabulating them by
ParticipantID. If you know how to do that in SPSS, it won't be too
hard to translate the logical statements into R syntax as above. I may
have misunderstood the variable names, but I think the logic is clear.

Jim

On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
<rachel.thompson at student.uva.nl> wrote:
>
> Hi Jim,
>
> Thank you for the clarification. Since I only work in SPSS and I am from Amsterdam I have had problems with specifying what I am trying to do in this specific program and also in clear English language.
>
> I think I want to indeed aggregate these events for each subject over the observation. But in this case several observations.
> 1. I want to have a summary of how many times a specific subject got called (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
>
> In the end, I have to define percentages, so I am able to say...Subject 36 has low social interactions ( because they only got called and texted 500 times in total, while the average of all the participants is 10000 or something). I have to come up with the percentages myself and define cutoff points of what is considered low-medium-high, based on what the results of all the subjects are.
>
> I hope that I am as clear as possible .
>
>
> I feel as if I am on my way of understanding it, but since I do not clearly know, I am trying out a lot of different codes etc. and I do not know if I am doing the right thing. I indeed made a new data frame etc, but I still feel a bit lost. Do I need to make one per subject or per Probe etc..
>
>
> Thanks for your help. I hope that you can help me resolve this issue.
>
>
> Best,
>
>
> Rachel
>
>
>
>
>
>
> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Rachel,
>> I'll take a guess and assume that you are monitoring the mobile phones
>> of 36 people, adding an observation every time some specified change
>> of state is sensed on each device. I'll also assume that you are only
>> recording four types of measurement. It seems that you want to
>> aggregate these events for each subject over the interval or
>> observation (or over each day or something). I think you are going to
>> create a new data frame of these summaries from the one you have of
>> individual observations. Creating each summary doesn't look too hard,
>> but you will have to define more precisely what you want those
>> summaries to be. For instance, "I want the mean activity level for
>> each subject during the overall time that their mobile phone is
>> switched on", One you have clearly defined your goals, it probably
>> won't be too hard to get to them.
>>
>> Jim
>>
>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
>> <rachel.thompson at student.uva.nl> wrote:
>> >
>> > Dear Mr/Mrs,
>> >
>> > This is my first time working in R studio.
>> > I have a database of 36 participants but it has 150600 entries.
>> > Column -         Column - Column            - Column
>> >
>> > Participant       Activityprobe - Activity Level  - High/low/none
>> >
>> > Participant       Screenprobe - screenon/off     -
>> >
>> > Participant       SMSprobe etc
>> >
>> > Participant       CallLogProbe etc.
>> >
>> > I need a code that helps me count the activity level of all the participants
>> > High activity level. No activity level and Low activity level.
>> > And to help me find out for every participant what the percentages are of
>> > all their high/no/low activity.
>> >
>> > For screenprobe I need to count how many times the participant turned their
>> > screen on and how many times they turned it off and the percentage of
>> > screen on/off.
>> >
>> > For callLog I need to count how many times each participant got called and
>> > the percentage.
>> >
>> > For SMS I need to count the number of SMS for each participant and their
>> > percentage.
>> >
>> > I also need to categorize the probes. So that my database shows all the
>> > activity levels first, organized by none/high/low and then all the
>> > screenprobes, organized by on and off etc...
>> >
>> > I hope that my description is clear and that you can maybe help me.
>> >
>> > Best,
>> >
>> > Rachel
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From motyoc@k@ @ending from y@hoo@com  Sun Jan  6 14:16:13 2019
From: motyoc@k@ @ending from y@hoo@com (Andras Farkas)
Date: Sun, 6 Jan 2019 13:16:13 +0000 (UTC)
Subject: [R] data frame transformation
References: <1821429344.13733985.1546780573156.ref@mail.yahoo.com>
Message-ID: <1821429344.13733985.1546780573156@mail.yahoo.com>

Hello Everyone,

would you be able to assist with some expertise on how to get the following done in a way that can be applied to a data set with different dimensions and without all the line items here?

we have:

id<-c(1,1,1,2,2,2,2,3,3,4,4,4,4,5,5,5,5)#length of unique IDs may differ of course in real data set, usually in magnitude of 10000
letter<-c(sample(c("A","B","C","D","E"),3),sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),2),
? ? ? ? ? sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),4))#number of unique "letters" is less than 4000 in real data set and they are no duplicates within same ID
weight<-c(sample(c(1:30),3),sample(c(1:30),4),sample(c(1:30),2),
? ? ? ? ? sample(c(1:30),4),sample(c(1:30),4))#number of unique weights is below 50 in real data set and they are no duplicates within same ID


data<-data.frame(id=id,letter=letter,weight=weight)

#goal is to get the following transformation where a column is added for each unique letter and the weight is pulled into the column if the letter exist within the ID, otherwise NA
#so we would get datatransform like below but without the many steps described here

datatransfer<-data.frame(data,apply(data[2],2,function(x) ifelse(x=="A",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="B",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="C",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="D",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="E",data$weight,NA)))

colnames(datatransfer)<-c("id","weight","letter","A","B","C","D","E")
much appreciate the help,

thanks

Andras?


From m@illi@t@ @ending from pp@inet@fi  Sun Jan  6 16:16:21 2019
From: m@illi@t@ @ending from pp@inet@fi (K. Elo)
Date: Sun, 06 Jan 2019 17:16:21 +0200
Subject: [R] data frame transformation
In-Reply-To: <1821429344.13733985.1546780573156@mail.yahoo.com>
References: <1821429344.13733985.1546780573156.ref@mail.yahoo.com>
 <1821429344.13733985.1546780573156@mail.yahoo.com>
Message-ID: <aca680c844b7e0c528c8113266dba4242bbe551c.camel@pp.inet.fi>

Hi!

Maybe this would do the trick:

--- snip ---

library(reshape2) # Use 'reshape2'
library(dplyr)    # Use 'dplyr'

datatransfer<-data %>% mutate(letter2=letter) %>% 
  dcast(id+letter~letter2, value.var="weight")

--- snip ---

Or did I misunderstood something?

Best,

Kimmo

2019-01-06, 13:16 +0000, Andras Farkas via R-help wrote:
> Hello Everyone,
> 
> would you be able to assist with some expertise on how to get the
> following done in a way that can be applied to a data set with
> different dimensions and without all the line items here?
> 
> we have:
> 
> id<-c(1,1,1,2,2,2,2,3,3,4,4,4,4,5,5,5,5)#length of unique IDs may
> differ of course in real data set, usually in magnitude of 10000
> letter<-
> c(sample(c("A","B","C","D","E"),3),sample(c("A","B","C","D","E"),4),s
> ample(c("A","B","C","D","E"),2),
>          
> sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),4))#nu
> mber of unique "letters" is less than 4000 in real data set and they
> are no duplicates within same ID
> weight<-c(sample(c(1:30),3),sample(c(1:30),4),sample(c(1:30),2),
>           sample(c(1:30),4),sample(c(1:30),4))#number of unique
> weights is below 50 in real data set and they are no duplicates
> within same ID
> 
> 
> data<-data.frame(id=id,letter=letter,weight=weight)
> 
> #goal is to get the following transformation where a column is added
> for each unique letter and the weight is pulled into the column if
> the letter exist within the ID, otherwise NA
> #so we would get datatransform like below but without the many steps
> described here
> 
> datatransfer<-data.frame(data,apply(data[2],2,function(x)
> ifelse(x=="A",data$weight,NA)))
> datatransfer<-
> data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="B",data$weight,NA)))
> datatransfer<-
> data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="C",data$weight,NA)))
> datatransfer<-
> data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="D",data$weight,NA)))
> datatransfer<-
> data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="E",data$weight,NA)))
> 
> colnames(datatransfer)<-c("id","weight","letter","A","B","C","D","E")
> much appreciate the help,
> 
> thanks
> 
> Andras 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jan  6 17:01:47 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 06 Jan 2019 08:01:47 -0800
Subject: [R] Mailinglist
In-Reply-To: <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
Message-ID: <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>

I would not want to leave the impression that I think the task at hand is merely tedious... my point is that there are numerous steps involved and each step depends on information that has not been communicated to the list, and there is a learning curve even in knowing what to include in an email question. What I do think is that knowing enough basic R syntax to express small bits of the problem in R will be a vast improvement over attempting to use only English descriptions, and Rachel has to bridge that initial gap.

For example, some images of data were apparently sent to Jim only, yet he still does not know in what format the data file is stored, so that technique was not very effective. One way for the question to become more focused is for Rachel to study up on her own how to import data and provide us with a "dput" (see the StackOverflow discussion I referenced before) of a small sample of data. Another is for Rachel to use basic R syntax to create an anonymous data set from scratch (also outlined in the SO discussion). These approaches allow us to keep the focus of our mailing list discussion on manipulating the data into summaries. Another approach is to re-focus the question on importing data by supplying a download link to the data so we can make suggestions as to what R commands will handle this data in its raw form. In any case, we cannot leapfrog over the data to the analysis as the question stands.

Given the above, I have to wonder why Rachel hasn't simply used the tool she is familiar with... SPSS... to do this? If it is because this is an academic assignment to learn R then she should be talking to her institutional support (instructor/teaching assistant/tutoring staff) anyway since there is a no-homework policy on this list (and that avenue would have the benefit of being conducted orally and most likely in her native language).


On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Rachel,
>It looks to me as though the first thing you want to do is to get your
>data, which you attach as images, into a data frame. If these are flat
>files like CSV or TAB, you should be able to read them in with some
>variant of the read.table function. If Excel, look at the various
>Excel import packages. Then you can operate on the data frame by doing
>things like tabulating Participant ID against the code for SMS or call
>(which I assume are those 3000+ numbers). You can take the differences
>in what look like POSIX time values between successive TRUE and FALSE
>screen values to get the duration of screen activity and it looks like
>participant activity is recorded at regular intervals. As Jeff
>suggested, this is really just boring work figuring out how to extract
>the events:
>
>call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
>== _id  & Valuedetailed ==3271)
>
>using suitable logical statements and then tabulating them by
>ParticipantID. If you know how to do that in SPSS, it won't be too
>hard to translate the logical statements into R syntax as above. I may
>have misunderstood the variable names, but I think the logic is clear.
>
>Jim
>
>On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
><rachel.thompson at student.uva.nl> wrote:
>>
>> Hi Jim,
>>
>> Thank you for the clarification. Since I only work in SPSS and I am
>from Amsterdam I have had problems with specifying what I am trying to
>do in this specific program and also in clear English language.
>>
>> I think I want to indeed aggregate these events for each subject over
>the observation. But in this case several observations.
>> 1. I want to have a summary of how many times a specific subject got
>called (CallLogProbe)
>> 2. I want to have a summary of how many times a specific subject got
>a text message (SMS probe)
>> 3. I want to have a summary of how many times a specific subject
>> - Turned their screen on - True  (ScreenProbe)
>> - Or did not turn their screen on - False (ScreenProbe)
>> 4.  I want to have a summary of the activity level of a specific
>subject
>> - Activity level - none (ActivityProbe)
>> - Activity level- low     (ActivityProbe)
>> - Activity level - High  (ActivityProbe)
>>
>> I want to do this for all the 36 subjects(Participants).
>>
>> In the end, I have to define percentages, so I am able to
>say...Subject 36 has low social interactions ( because they only got
>called and texted 500 times in total, while the average of all the
>participants is 10000 or something). I have to come up with the
>percentages myself and define cutoff points of what is considered
>low-medium-high, based on what the results of all the subjects are.
>>
>> I hope that I am as clear as possible .
>>
>>
>> I feel as if I am on my way of understanding it, but since I do not
>clearly know, I am trying out a lot of different codes etc. and I do
>not know if I am doing the right thing. I indeed made a new data frame
>etc, but I still feel a bit lost. Do I need to make one per subject or
>per Probe etc..
>>
>>
>> Thanks for your help. I hope that you can help me resolve this issue.
>>
>>
>> Best,
>>
>>
>> Rachel
>>
>>
>>
>>
>>
>>
>> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
>wrote:
>>>
>>> Hi Rachel,
>>> I'll take a guess and assume that you are monitoring the mobile
>phones
>>> of 36 people, adding an observation every time some specified change
>>> of state is sensed on each device. I'll also assume that you are
>only
>>> recording four types of measurement. It seems that you want to
>>> aggregate these events for each subject over the interval or
>>> observation (or over each day or something). I think you are going
>to
>>> create a new data frame of these summaries from the one you have of
>>> individual observations. Creating each summary doesn't look too
>hard,
>>> but you will have to define more precisely what you want those
>>> summaries to be. For instance, "I want the mean activity level for
>>> each subject during the overall time that their mobile phone is
>>> switched on", One you have clearly defined your goals, it probably
>>> won't be too hard to get to them.
>>>
>>> Jim
>>>
>>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
>>> <rachel.thompson at student.uva.nl> wrote:
>>> >
>>> > Dear Mr/Mrs,
>>> >
>>> > This is my first time working in R studio.
>>> > I have a database of 36 participants but it has 150600 entries.
>>> > Column -         Column - Column            - Column
>>> >
>>> > Participant       Activityprobe - Activity Level  - High/low/none
>>> >
>>> > Participant       Screenprobe - screenon/off     -
>>> >
>>> > Participant       SMSprobe etc
>>> >
>>> > Participant       CallLogProbe etc.
>>> >
>>> > I need a code that helps me count the activity level of all the
>participants
>>> > High activity level. No activity level and Low activity level.
>>> > And to help me find out for every participant what the percentages
>are of
>>> > all their high/no/low activity.
>>> >
>>> > For screenprobe I need to count how many times the participant
>turned their
>>> > screen on and how many times they turned it off and the percentage
>of
>>> > screen on/off.
>>> >
>>> > For callLog I need to count how many times each participant got
>called and
>>> > the percentage.
>>> >
>>> > For SMS I need to count the number of SMS for each participant and
>their
>>> > percentage.
>>> >
>>> > I also need to categorize the probes. So that my database shows
>all the
>>> > activity levels first, organized by none/high/low and then all the
>>> > screenprobes, organized by on and off etc...
>>> >
>>> > I hope that my description is clear and that you can maybe help
>me.
>>> >
>>> > Best,
>>> >
>>> > Rachel
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@chel@thomp@on @ending from @tudent@uv@@nl  Sun Jan  6 17:29:50 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Sun, 6 Jan 2019 11:29:50 -0500
Subject: [R] Mailinglist
In-Reply-To: <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
Message-ID: <CAK7fGOt6O3E7FY6gbH8zOLbB442YKf6StkxCfc-_Zy3WDe3jqg@mail.gmail.com>

Hi Jim,

Thank you for your email and information
It is a CVS file which I imported in Rstudio.
I will look into what you told me and see if I am able to figure it out.

Best,

Rachel


On Sun, Jan 6, 2019 at 4:12 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Rachel,
> It looks to me as though the first thing you want to do is to get your
> data, which you attach as images, into a data frame. If these are flat
> files like CSV or TAB, you should be able to read them in with some
> variant of the read.table function. If Excel, look at the various
> Excel import packages. Then you can operate on the data frame by doing
> things like tabulating Participant ID against the code for SMS or call
> (which I assume are those 3000+ numbers). You can take the differences
> in what look like POSIX time values between successive TRUE and FALSE
> screen values to get the duration of screen activity and it looks like
> participant activity is recorded at regular intervals. As Jeff
> suggested, this is really just boring work figuring out how to extract
> the events:
>
> call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
> == _id  & Valuedetailed ==3271)
>
> using suitable logical statements and then tabulating them by
> ParticipantID. If you know how to do that in SPSS, it won't be too
> hard to translate the logical statements into R syntax as above. I may
> have misunderstood the variable names, but I think the logic is clear.
>
> Jim
>
> On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
> <rachel.thompson at student.uva.nl> wrote:
> >
> > Hi Jim,
> >
> > Thank you for the clarification. Since I only work in SPSS and I am from
> Amsterdam I have had problems with specifying what I am trying to do in
> this specific program and also in clear English language.
> >
> > I think I want to indeed aggregate these events for each subject over
> the observation. But in this case several observations.
> > 1. I want to have a summary of how many times a specific subject got
> called (CallLogProbe)
> > 2. I want to have a summary of how many times a specific subject got a
> text message (SMS probe)
> > 3. I want to have a summary of how many times a specific subject
> > - Turned their screen on - True  (ScreenProbe)
> > - Or did not turn their screen on - False (ScreenProbe)
> > 4.  I want to have a summary of the activity level of a specific subject
> > - Activity level - none (ActivityProbe)
> > - Activity level- low     (ActivityProbe)
> > - Activity level - High  (ActivityProbe)
> >
> > I want to do this for all the 36 subjects(Participants).
> >
> > In the end, I have to define percentages, so I am able to say...Subject
> 36 has low social interactions ( because they only got called and texted
> 500 times in total, while the average of all the participants is 10000 or
> something). I have to come up with the percentages myself and define cutoff
> points of what is considered low-medium-high, based on what the results of
> all the subjects are.
> >
> > I hope that I am as clear as possible .
> >
> >
> > I feel as if I am on my way of understanding it, but since I do not
> clearly know, I am trying out a lot of different codes etc. and I do not
> know if I am doing the right thing. I indeed made a new data frame etc, but
> I still feel a bit lost. Do I need to make one per subject or per Probe
> etc..
> >
> >
> > Thanks for your help. I hope that you can help me resolve this issue.
> >
> >
> > Best,
> >
> >
> > Rachel
> >
> >
> >
> >
> >
> >
> > On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Rachel,
> >> I'll take a guess and assume that you are monitoring the mobile phones
> >> of 36 people, adding an observation every time some specified change
> >> of state is sensed on each device. I'll also assume that you are only
> >> recording four types of measurement. It seems that you want to
> >> aggregate these events for each subject over the interval or
> >> observation (or over each day or something). I think you are going to
> >> create a new data frame of these summaries from the one you have of
> >> individual observations. Creating each summary doesn't look too hard,
> >> but you will have to define more precisely what you want those
> >> summaries to be. For instance, "I want the mean activity level for
> >> each subject during the overall time that their mobile phone is
> >> switched on", One you have clearly defined your goals, it probably
> >> won't be too hard to get to them.
> >>
> >> Jim
> >>
> >> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
> >> <rachel.thompson at student.uva.nl> wrote:
> >> >
> >> > Dear Mr/Mrs,
> >> >
> >> > This is my first time working in R studio.
> >> > I have a database of 36 participants but it has 150600 entries.
> >> > Column -         Column - Column            - Column
> >> >
> >> > Participant       Activityprobe - Activity Level  - High/low/none
> >> >
> >> > Participant       Screenprobe - screenon/off     -
> >> >
> >> > Participant       SMSprobe etc
> >> >
> >> > Participant       CallLogProbe etc.
> >> >
> >> > I need a code that helps me count the activity level of all the
> participants
> >> > High activity level. No activity level and Low activity level.
> >> > And to help me find out for every participant what the percentages
> are of
> >> > all their high/no/low activity.
> >> >
> >> > For screenprobe I need to count how many times the participant turned
> their
> >> > screen on and how many times they turned it off and the percentage of
> >> > screen on/off.
> >> >
> >> > For callLog I need to count how many times each participant got
> called and
> >> > the percentage.
> >> >
> >> > For SMS I need to count the number of SMS for each participant and
> their
> >> > percentage.
> >> >
> >> > I also need to categorize the probes. So that my database shows all
> the
> >> > activity levels first, organized by none/high/low and then all the
> >> > screenprobes, organized by on and off etc...
> >> >
> >> > I hope that my description is clear and that you can maybe help me.
> >> >
> >> > Best,
> >> >
> >> > Rachel
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Sun Jan  6 17:37:19 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Sun, 6 Jan 2019 11:37:19 -0500
Subject: [R] Mailinglist
In-Reply-To: <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
Message-ID: <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>

Hi Jeff,

Thanks for your email.
I am an intern from Amsterdam and I have to do an analysis in R. I spoke to
my professor in Amsterdam and my supervisor's here in Boston. But they are
to busy to help. I informed them from the start that I am not familiar with
R(Rstudio) and they told me that I would receive guidance. So since they
can not help me, I decided to share my problem online.
(It is a CVS file imported into R)

Please understand that I am new to this. I will unsubscribe to the mailing
list if my question does not belong here.

Thanks,

Rachel

On Sun, Jan 6, 2019 at 11:01 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I would not want to leave the impression that I think the task at hand is
> merely tedious... my point is that there are numerous steps involved and
> each step depends on information that has not been communicated to the
> list, and there is a learning curve even in knowing what to include in an
> email question. What I do think is that knowing enough basic R syntax to
> express small bits of the problem in R will be a vast improvement over
> attempting to use only English descriptions, and Rachel has to bridge that
> initial gap.
>
> For example, some images of data were apparently sent to Jim only, yet he
> still does not know in what format the data file is stored, so that
> technique was not very effective. One way for the question to become more
> focused is for Rachel to study up on her own how to import data and provide
> us with a "dput" (see the StackOverflow discussion I referenced before) of
> a small sample of data. Another is for Rachel to use basic R syntax to
> create an anonymous data set from scratch (also outlined in the SO
> discussion). These approaches allow us to keep the focus of our mailing
> list discussion on manipulating the data into summaries. Another approach
> is to re-focus the question on importing data by supplying a download link
> to the data so we can make suggestions as to what R commands will handle
> this data in its raw form. In any case, we cannot leapfrog over the data to
> the analysis as the question stands.
>
> Given the above, I have to wonder why Rachel hasn't simply used the tool
> she is familiar with... SPSS... to do this? If it is because this is an
> academic assignment to learn R then she should be talking to her
> institutional support (instructor/teaching assistant/tutoring staff) anyway
> since there is a no-homework policy on this list (and that avenue would
> have the benefit of being conducted orally and most likely in her native
> language).
>
>
> On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
> >Hi Rachel,
> >It looks to me as though the first thing you want to do is to get your
> >data, which you attach as images, into a data frame. If these are flat
> >files like CSV or TAB, you should be able to read them in with some
> >variant of the read.table function. If Excel, look at the various
> >Excel import packages. Then you can operate on the data frame by doing
> >things like tabulating Participant ID against the code for SMS or call
> >(which I assume are those 3000+ numbers). You can take the differences
> >in what look like POSIX time values between successive TRUE and FALSE
> >screen values to get the duration of screen activity and it looks like
> >participant activity is recorded at regular intervals. As Jeff
> >suggested, this is really just boring work figuring out how to extract
> >the events:
> >
> >call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
> >== _id  & Valuedetailed ==3271)
> >
> >using suitable logical statements and then tabulating them by
> >ParticipantID. If you know how to do that in SPSS, it won't be too
> >hard to translate the logical statements into R syntax as above. I may
> >have misunderstood the variable names, but I think the logic is clear.
> >
> >Jim
> >
> >On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
> ><rachel.thompson at student.uva.nl> wrote:
> >>
> >> Hi Jim,
> >>
> >> Thank you for the clarification. Since I only work in SPSS and I am
> >from Amsterdam I have had problems with specifying what I am trying to
> >do in this specific program and also in clear English language.
> >>
> >> I think I want to indeed aggregate these events for each subject over
> >the observation. But in this case several observations.
> >> 1. I want to have a summary of how many times a specific subject got
> >called (CallLogProbe)
> >> 2. I want to have a summary of how many times a specific subject got
> >a text message (SMS probe)
> >> 3. I want to have a summary of how many times a specific subject
> >> - Turned their screen on - True  (ScreenProbe)
> >> - Or did not turn their screen on - False (ScreenProbe)
> >> 4.  I want to have a summary of the activity level of a specific
> >subject
> >> - Activity level - none (ActivityProbe)
> >> - Activity level- low     (ActivityProbe)
> >> - Activity level - High  (ActivityProbe)
> >>
> >> I want to do this for all the 36 subjects(Participants).
> >>
> >> In the end, I have to define percentages, so I am able to
> >say...Subject 36 has low social interactions ( because they only got
> >called and texted 500 times in total, while the average of all the
> >participants is 10000 or something). I have to come up with the
> >percentages myself and define cutoff points of what is considered
> >low-medium-high, based on what the results of all the subjects are.
> >>
> >> I hope that I am as clear as possible .
> >>
> >>
> >> I feel as if I am on my way of understanding it, but since I do not
> >clearly know, I am trying out a lot of different codes etc. and I do
> >not know if I am doing the right thing. I indeed made a new data frame
> >etc, but I still feel a bit lost. Do I need to make one per subject or
> >per Probe etc..
> >>
> >>
> >> Thanks for your help. I hope that you can help me resolve this issue.
> >>
> >>
> >> Best,
> >>
> >>
> >> Rachel
> >>
> >>
> >>
> >>
> >>
> >>
> >> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >>>
> >>> Hi Rachel,
> >>> I'll take a guess and assume that you are monitoring the mobile
> >phones
> >>> of 36 people, adding an observation every time some specified change
> >>> of state is sensed on each device. I'll also assume that you are
> >only
> >>> recording four types of measurement. It seems that you want to
> >>> aggregate these events for each subject over the interval or
> >>> observation (or over each day or something). I think you are going
> >to
> >>> create a new data frame of these summaries from the one you have of
> >>> individual observations. Creating each summary doesn't look too
> >hard,
> >>> but you will have to define more precisely what you want those
> >>> summaries to be. For instance, "I want the mean activity level for
> >>> each subject during the overall time that their mobile phone is
> >>> switched on", One you have clearly defined your goals, it probably
> >>> won't be too hard to get to them.
> >>>
> >>> Jim
> >>>
> >>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
> >>> <rachel.thompson at student.uva.nl> wrote:
> >>> >
> >>> > Dear Mr/Mrs,
> >>> >
> >>> > This is my first time working in R studio.
> >>> > I have a database of 36 participants but it has 150600 entries.
> >>> > Column -         Column - Column            - Column
> >>> >
> >>> > Participant       Activityprobe - Activity Level  - High/low/none
> >>> >
> >>> > Participant       Screenprobe - screenon/off     -
> >>> >
> >>> > Participant       SMSprobe etc
> >>> >
> >>> > Participant       CallLogProbe etc.
> >>> >
> >>> > I need a code that helps me count the activity level of all the
> >participants
> >>> > High activity level. No activity level and Low activity level.
> >>> > And to help me find out for every participant what the percentages
> >are of
> >>> > all their high/no/low activity.
> >>> >
> >>> > For screenprobe I need to count how many times the participant
> >turned their
> >>> > screen on and how many times they turned it off and the percentage
> >of
> >>> > screen on/off.
> >>> >
> >>> > For callLog I need to count how many times each participant got
> >called and
> >>> > the percentage.
> >>> >
> >>> > For SMS I need to count the number of SMS for each participant and
> >their
> >>> > percentage.
> >>> >
> >>> > I also need to categorize the probes. So that my database shows
> >all the
> >>> > activity levels first, organized by none/high/low and then all the
> >>> > screenprobes, organized by on and off etc...
> >>> >
> >>> > I hope that my description is clear and that you can maybe help
> >me.
> >>> >
> >>> > Best,
> >>> >
> >>> > Rachel
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From li@t@ @ending from dewey@myzen@co@uk  Sun Jan  6 17:45:41 2019
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 6 Jan 2019 16:45:41 +0000
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
Message-ID: <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>

Dear Rachel

Not sure if this is going to help but if it is a csv file then 
read.csv() is your friend. Read the help first in case you need to 
specify what is being used for the decimal point and the separator as if 
it is from the Netherlands they may not be the default settings.

michael

On 06/01/2019 16:37, Rachel Thompson wrote:
> Hi Jeff,
> 
> Thanks for your email.
> I am an intern from Amsterdam and I have to do an analysis in R. I spoke to
> my professor in Amsterdam and my supervisor's here in Boston. But they are
> to busy to help. I informed them from the start that I am not familiar with
> R(Rstudio) and they told me that I would receive guidance. So since they
> can not help me, I decided to share my problem online.
> (It is a CVS file imported into R)
> 
> Please understand that I am new to this. I will unsubscribe to the mailing
> list if my question does not belong here.
> 
> Thanks,
> 
> Rachel
> 
> On Sun, Jan 6, 2019 at 11:01 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> I would not want to leave the impression that I think the task at hand is
>> merely tedious... my point is that there are numerous steps involved and
>> each step depends on information that has not been communicated to the
>> list, and there is a learning curve even in knowing what to include in an
>> email question. What I do think is that knowing enough basic R syntax to
>> express small bits of the problem in R will be a vast improvement over
>> attempting to use only English descriptions, and Rachel has to bridge that
>> initial gap.
>>
>> For example, some images of data were apparently sent to Jim only, yet he
>> still does not know in what format the data file is stored, so that
>> technique was not very effective. One way for the question to become more
>> focused is for Rachel to study up on her own how to import data and provide
>> us with a "dput" (see the StackOverflow discussion I referenced before) of
>> a small sample of data. Another is for Rachel to use basic R syntax to
>> create an anonymous data set from scratch (also outlined in the SO
>> discussion). These approaches allow us to keep the focus of our mailing
>> list discussion on manipulating the data into summaries. Another approach
>> is to re-focus the question on importing data by supplying a download link
>> to the data so we can make suggestions as to what R commands will handle
>> this data in its raw form. In any case, we cannot leapfrog over the data to
>> the analysis as the question stands.
>>
>> Given the above, I have to wonder why Rachel hasn't simply used the tool
>> she is familiar with... SPSS... to do this? If it is because this is an
>> academic assignment to learn R then she should be talking to her
>> institutional support (instructor/teaching assistant/tutoring staff) anyway
>> since there is a no-homework policy on this list (and that avenue would
>> have the benefit of being conducted orally and most likely in her native
>> language).
>>
>>
>> On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Rachel,
>>> It looks to me as though the first thing you want to do is to get your
>>> data, which you attach as images, into a data frame. If these are flat
>>> files like CSV or TAB, you should be able to read them in with some
>>> variant of the read.table function. If Excel, look at the various
>>> Excel import packages. Then you can operate on the data frame by doing
>>> things like tabulating Participant ID against the code for SMS or call
>>> (which I assume are those 3000+ numbers). You can take the differences
>>> in what look like POSIX time values between successive TRUE and FALSE
>>> screen values to get the duration of screen activity and it looks like
>>> participant activity is recorded at regular intervals. As Jeff
>>> suggested, this is really just boring work figuring out how to extract
>>> the events:
>>>
>>> call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
>>> == _id  & Valuedetailed ==3271)
>>>
>>> using suitable logical statements and then tabulating them by
>>> ParticipantID. If you know how to do that in SPSS, it won't be too
>>> hard to translate the logical statements into R syntax as above. I may
>>> have misunderstood the variable names, but I think the logic is clear.
>>>
>>> Jim
>>>
>>> On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
>>> <rachel.thompson at student.uva.nl> wrote:
>>>>
>>>> Hi Jim,
>>>>
>>>> Thank you for the clarification. Since I only work in SPSS and I am
>> >from Amsterdam I have had problems with specifying what I am trying to
>>> do in this specific program and also in clear English language.
>>>>
>>>> I think I want to indeed aggregate these events for each subject over
>>> the observation. But in this case several observations.
>>>> 1. I want to have a summary of how many times a specific subject got
>>> called (CallLogProbe)
>>>> 2. I want to have a summary of how many times a specific subject got
>>> a text message (SMS probe)
>>>> 3. I want to have a summary of how many times a specific subject
>>>> - Turned their screen on - True  (ScreenProbe)
>>>> - Or did not turn their screen on - False (ScreenProbe)
>>>> 4.  I want to have a summary of the activity level of a specific
>>> subject
>>>> - Activity level - none (ActivityProbe)
>>>> - Activity level- low     (ActivityProbe)
>>>> - Activity level - High  (ActivityProbe)
>>>>
>>>> I want to do this for all the 36 subjects(Participants).
>>>>
>>>> In the end, I have to define percentages, so I am able to
>>> say...Subject 36 has low social interactions ( because they only got
>>> called and texted 500 times in total, while the average of all the
>>> participants is 10000 or something). I have to come up with the
>>> percentages myself and define cutoff points of what is considered
>>> low-medium-high, based on what the results of all the subjects are.
>>>>
>>>> I hope that I am as clear as possible .
>>>>
>>>>
>>>> I feel as if I am on my way of understanding it, but since I do not
>>> clearly know, I am trying out a lot of different codes etc. and I do
>>> not know if I am doing the right thing. I indeed made a new data frame
>>> etc, but I still feel a bit lost. Do I need to make one per subject or
>>> per Probe etc..
>>>>
>>>>
>>>> Thanks for your help. I hope that you can help me resolve this issue.
>>>>
>>>>
>>>> Best,
>>>>
>>>>
>>>> Rachel
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>>>
>>>>> Hi Rachel,
>>>>> I'll take a guess and assume that you are monitoring the mobile
>>> phones
>>>>> of 36 people, adding an observation every time some specified change
>>>>> of state is sensed on each device. I'll also assume that you are
>>> only
>>>>> recording four types of measurement. It seems that you want to
>>>>> aggregate these events for each subject over the interval or
>>>>> observation (or over each day or something). I think you are going
>>> to
>>>>> create a new data frame of these summaries from the one you have of
>>>>> individual observations. Creating each summary doesn't look too
>>> hard,
>>>>> but you will have to define more precisely what you want those
>>>>> summaries to be. For instance, "I want the mean activity level for
>>>>> each subject during the overall time that their mobile phone is
>>>>> switched on", One you have clearly defined your goals, it probably
>>>>> won't be too hard to get to them.
>>>>>
>>>>> Jim
>>>>>
>>>>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
>>>>> <rachel.thompson at student.uva.nl> wrote:
>>>>>>
>>>>>> Dear Mr/Mrs,
>>>>>>
>>>>>> This is my first time working in R studio.
>>>>>> I have a database of 36 participants but it has 150600 entries.
>>>>>> Column -         Column - Column            - Column
>>>>>>
>>>>>> Participant       Activityprobe - Activity Level  - High/low/none
>>>>>>
>>>>>> Participant       Screenprobe - screenon/off     -
>>>>>>
>>>>>> Participant       SMSprobe etc
>>>>>>
>>>>>> Participant       CallLogProbe etc.
>>>>>>
>>>>>> I need a code that helps me count the activity level of all the
>>> participants
>>>>>> High activity level. No activity level and Low activity level.
>>>>>> And to help me find out for every participant what the percentages
>>> are of
>>>>>> all their high/no/low activity.
>>>>>>
>>>>>> For screenprobe I need to count how many times the participant
>>> turned their
>>>>>> screen on and how many times they turned it off and the percentage
>>> of
>>>>>> screen on/off.
>>>>>>
>>>>>> For callLog I need to count how many times each participant got
>>> called and
>>>>>> the percentage.
>>>>>>
>>>>>> For SMS I need to count the number of SMS for each participant and
>>> their
>>>>>> percentage.
>>>>>>
>>>>>> I also need to categorize the probes. So that my database shows
>>> all the
>>>>>> activity levels first, organized by none/high/low and then all the
>>>>>> screenprobes, organized by on and off etc...
>>>>>>
>>>>>> I hope that my description is clear and that you can maybe help
>>> me.
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Rachel
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@chel@thomp@on @ending from @tudent@uv@@nl  Sun Jan  6 17:46:56 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Sun, 6 Jan 2019 11:46:56 -0500
Subject: [R] Mailinglist
In-Reply-To: <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>
Message-ID: <CAK7fGOs3eEcHGAwELHoOwQPgO6zBhHm6pKsp7Lc7XuDc0VohRg@mail.gmail.com>

Hi Michael

Thanks, I'll check it out.

Best,

Rachel

On Sun, Jan 6, 2019 at 11:45 AM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Rachel
>
> Not sure if this is going to help but if it is a csv file then
> read.csv() is your friend. Read the help first in case you need to
> specify what is being used for the decimal point and the separator as if
> it is from the Netherlands they may not be the default settings.
>
> michael
>
> On 06/01/2019 16:37, Rachel Thompson wrote:
> > Hi Jeff,
> >
> > Thanks for your email.
> > I am an intern from Amsterdam and I have to do an analysis in R. I spoke
> to
> > my professor in Amsterdam and my supervisor's here in Boston. But they
> are
> > to busy to help. I informed them from the start that I am not familiar
> with
> > R(Rstudio) and they told me that I would receive guidance. So since they
> > can not help me, I decided to share my problem online.
> > (It is a CVS file imported into R)
> >
> > Please understand that I am new to this. I will unsubscribe to the
> mailing
> > list if my question does not belong here.
> >
> > Thanks,
> >
> > Rachel
> >
> > On Sun, Jan 6, 2019 at 11:01 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us
> >
> > wrote:
> >
> >> I would not want to leave the impression that I think the task at hand
> is
> >> merely tedious... my point is that there are numerous steps involved and
> >> each step depends on information that has not been communicated to the
> >> list, and there is a learning curve even in knowing what to include in
> an
> >> email question. What I do think is that knowing enough basic R syntax to
> >> express small bits of the problem in R will be a vast improvement over
> >> attempting to use only English descriptions, and Rachel has to bridge
> that
> >> initial gap.
> >>
> >> For example, some images of data were apparently sent to Jim only, yet
> he
> >> still does not know in what format the data file is stored, so that
> >> technique was not very effective. One way for the question to become
> more
> >> focused is for Rachel to study up on her own how to import data and
> provide
> >> us with a "dput" (see the StackOverflow discussion I referenced before)
> of
> >> a small sample of data. Another is for Rachel to use basic R syntax to
> >> create an anonymous data set from scratch (also outlined in the SO
> >> discussion). These approaches allow us to keep the focus of our mailing
> >> list discussion on manipulating the data into summaries. Another
> approach
> >> is to re-focus the question on importing data by supplying a download
> link
> >> to the data so we can make suggestions as to what R commands will handle
> >> this data in its raw form. In any case, we cannot leapfrog over the
> data to
> >> the analysis as the question stands.
> >>
> >> Given the above, I have to wonder why Rachel hasn't simply used the tool
> >> she is familiar with... SPSS... to do this? If it is because this is an
> >> academic assignment to learn R then she should be talking to her
> >> institutional support (instructor/teaching assistant/tutoring staff)
> anyway
> >> since there is a no-homework policy on this list (and that avenue would
> >> have the benefit of being conducted orally and most likely in her native
> >> language).
> >>
> >>
> >> On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>> Hi Rachel,
> >>> It looks to me as though the first thing you want to do is to get your
> >>> data, which you attach as images, into a data frame. If these are flat
> >>> files like CSV or TAB, you should be able to read them in with some
> >>> variant of the read.table function. If Excel, look at the various
> >>> Excel import packages. Then you can operate on the data frame by doing
> >>> things like tabulating Participant ID against the code for SMS or call
> >>> (which I assume are those 3000+ numbers). You can take the differences
> >>> in what look like POSIX time values between successive TRUE and FALSE
> >>> screen values to get the duration of screen activity and it looks like
> >>> participant activity is recorded at regular intervals. As Jeff
> >>> suggested, this is really just boring work figuring out how to extract
> >>> the events:
> >>>
> >>> call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
> >>> == _id  & Valuedetailed ==3271)
> >>>
> >>> using suitable logical statements and then tabulating them by
> >>> ParticipantID. If you know how to do that in SPSS, it won't be too
> >>> hard to translate the logical statements into R syntax as above. I may
> >>> have misunderstood the variable names, but I think the logic is clear.
> >>>
> >>> Jim
> >>>
> >>> On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
> >>> <rachel.thompson at student.uva.nl> wrote:
> >>>>
> >>>> Hi Jim,
> >>>>
> >>>> Thank you for the clarification. Since I only work in SPSS and I am
> >> >from Amsterdam I have had problems with specifying what I am trying to
> >>> do in this specific program and also in clear English language.
> >>>>
> >>>> I think I want to indeed aggregate these events for each subject over
> >>> the observation. But in this case several observations.
> >>>> 1. I want to have a summary of how many times a specific subject got
> >>> called (CallLogProbe)
> >>>> 2. I want to have a summary of how many times a specific subject got
> >>> a text message (SMS probe)
> >>>> 3. I want to have a summary of how many times a specific subject
> >>>> - Turned their screen on - True  (ScreenProbe)
> >>>> - Or did not turn their screen on - False (ScreenProbe)
> >>>> 4.  I want to have a summary of the activity level of a specific
> >>> subject
> >>>> - Activity level - none (ActivityProbe)
> >>>> - Activity level- low     (ActivityProbe)
> >>>> - Activity level - High  (ActivityProbe)
> >>>>
> >>>> I want to do this for all the 36 subjects(Participants).
> >>>>
> >>>> In the end, I have to define percentages, so I am able to
> >>> say...Subject 36 has low social interactions ( because they only got
> >>> called and texted 500 times in total, while the average of all the
> >>> participants is 10000 or something). I have to come up with the
> >>> percentages myself and define cutoff points of what is considered
> >>> low-medium-high, based on what the results of all the subjects are.
> >>>>
> >>>> I hope that I am as clear as possible .
> >>>>
> >>>>
> >>>> I feel as if I am on my way of understanding it, but since I do not
> >>> clearly know, I am trying out a lot of different codes etc. and I do
> >>> not know if I am doing the right thing. I indeed made a new data frame
> >>> etc, but I still feel a bit lost. Do I need to make one per subject or
> >>> per Probe etc..
> >>>>
> >>>>
> >>>> Thanks for your help. I hope that you can help me resolve this issue.
> >>>>
> >>>>
> >>>> Best,
> >>>>
> >>>>
> >>>> Rachel
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
> >>> wrote:
> >>>>>
> >>>>> Hi Rachel,
> >>>>> I'll take a guess and assume that you are monitoring the mobile
> >>> phones
> >>>>> of 36 people, adding an observation every time some specified change
> >>>>> of state is sensed on each device. I'll also assume that you are
> >>> only
> >>>>> recording four types of measurement. It seems that you want to
> >>>>> aggregate these events for each subject over the interval or
> >>>>> observation (or over each day or something). I think you are going
> >>> to
> >>>>> create a new data frame of these summaries from the one you have of
> >>>>> individual observations. Creating each summary doesn't look too
> >>> hard,
> >>>>> but you will have to define more precisely what you want those
> >>>>> summaries to be. For instance, "I want the mean activity level for
> >>>>> each subject during the overall time that their mobile phone is
> >>>>> switched on", One you have clearly defined your goals, it probably
> >>>>> won't be too hard to get to them.
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
> >>>>> <rachel.thompson at student.uva.nl> wrote:
> >>>>>>
> >>>>>> Dear Mr/Mrs,
> >>>>>>
> >>>>>> This is my first time working in R studio.
> >>>>>> I have a database of 36 participants but it has 150600 entries.
> >>>>>> Column -         Column - Column            - Column
> >>>>>>
> >>>>>> Participant       Activityprobe - Activity Level  - High/low/none
> >>>>>>
> >>>>>> Participant       Screenprobe - screenon/off     -
> >>>>>>
> >>>>>> Participant       SMSprobe etc
> >>>>>>
> >>>>>> Participant       CallLogProbe etc.
> >>>>>>
> >>>>>> I need a code that helps me count the activity level of all the
> >>> participants
> >>>>>> High activity level. No activity level and Low activity level.
> >>>>>> And to help me find out for every participant what the percentages
> >>> are of
> >>>>>> all their high/no/low activity.
> >>>>>>
> >>>>>> For screenprobe I need to count how many times the participant
> >>> turned their
> >>>>>> screen on and how many times they turned it off and the percentage
> >>> of
> >>>>>> screen on/off.
> >>>>>>
> >>>>>> For callLog I need to count how many times each participant got
> >>> called and
> >>>>>> the percentage.
> >>>>>>
> >>>>>> For SMS I need to count the number of SMS for each participant and
> >>> their
> >>>>>> percentage.
> >>>>>>
> >>>>>> I also need to categorize the probes. So that my database shows
> >>> all the
> >>>>>> activity levels first, organized by none/high/low and then all the
> >>>>>> screenprobes, organized by on and off etc...
> >>>>>>
> >>>>>> I hope that my description is clear and that you can maybe help
> >>> me.
> >>>>>>
> >>>>>> Best,
> >>>>>>
> >>>>>> Rachel
> >>>>>>
> >>>>>>          [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sun Jan  6 17:48:24 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sun, 6 Jan 2019 08:48:24 -0800 (PST)
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>

On Sun, 6 Jan 2019, Rachel Thompson wrote:

> I am an intern from Amsterdam and I have to do an analysis in R. I spoke
> to my professor in Amsterdam and my supervisor's here in Boston. But they
> are to busy to help. I informed them from the start that I am not familiar
> with R(Rstudio) and they told me that I would receive guidance. So since
> they can not help me, I decided to share my problem online. (It is a CVS
> file imported into R)

Rachel,

   I find it interesting that you're put in such a difficult position. I've
not followed this thread from the start so my comments might be redundant or
inappropriate.

   If you can, describe the problem. That is, what are you being asked to
find and what are the available data? This information helps us to guide you
to learning the mechanics for accomplishing your task with R.

Regards,

Rich


From ruipb@rr@d@@ @ending from @@po@pt  Sun Jan  6 18:27:18 2019
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sun, 6 Jan 2019 17:27:18 +0000
Subject: [R] Mailinglist
In-Reply-To: <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>
Message-ID: <cce3dcb5-7f53-f62c-83d2-3d56504eed5f@sapo.pt>

Hello,

In many continental European countries, such as mine, the function to 
use is

read.csv2

It defaults to

sep = ";", dec = ","

Note that these functions are in fact calls to read.table with special 
default arguments. Another default that changes is header = TRUE.
You might also want to set stringsAsFactors = FALSE since the default 
value TRUE is a common source for errors.

Hope this helps,

Rui Barradas

?s 16:45 de 06/01/2019, Michael Dewey escreveu:
> Dear Rachel
> 
> Not sure if this is going to help but if it is a csv file then 
> read.csv() is your friend. Read the help first in case you need to 
> specify what is being used for the decimal point and the separator as if 
> it is from the Netherlands they may not be the default settings.
> 
> michael
> 
> On 06/01/2019 16:37, Rachel Thompson wrote:
>> Hi Jeff,
>>
>> Thanks for your email.
>> I am an intern from Amsterdam and I have to do an analysis in R. I 
>> spoke to
>> my professor in Amsterdam and my supervisor's here in Boston. But they 
>> are
>> to busy to help. I informed them from the start that I am not familiar 
>> with
>> R(Rstudio) and they told me that I would receive guidance. So since they
>> can not help me, I decided to share my problem online.
>> (It is a CVS file imported into R)
>>
>> Please understand that I am new to this. I will unsubscribe to the 
>> mailing
>> list if my question does not belong here.
>>
>> Thanks,
>>
>> Rachel
>>
>> On Sun, Jan 6, 2019 at 11:01 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> I would not want to leave the impression that I think the task at 
>>> hand is
>>> merely tedious... my point is that there are numerous steps involved and
>>> each step depends on information that has not been communicated to the
>>> list, and there is a learning curve even in knowing what to include 
>>> in an
>>> email question. What I do think is that knowing enough basic R syntax to
>>> express small bits of the problem in R will be a vast improvement over
>>> attempting to use only English descriptions, and Rachel has to bridge 
>>> that
>>> initial gap.
>>>
>>> For example, some images of data were apparently sent to Jim only, 
>>> yet he
>>> still does not know in what format the data file is stored, so that
>>> technique was not very effective. One way for the question to become 
>>> more
>>> focused is for Rachel to study up on her own how to import data and 
>>> provide
>>> us with a "dput" (see the StackOverflow discussion I referenced 
>>> before) of
>>> a small sample of data. Another is for Rachel to use basic R syntax to
>>> create an anonymous data set from scratch (also outlined in the SO
>>> discussion). These approaches allow us to keep the focus of our mailing
>>> list discussion on manipulating the data into summaries. Another 
>>> approach
>>> is to re-focus the question on importing data by supplying a download 
>>> link
>>> to the data so we can make suggestions as to what R commands will handle
>>> this data in its raw form. In any case, we cannot leapfrog over the 
>>> data to
>>> the analysis as the question stands.
>>>
>>> Given the above, I have to wonder why Rachel hasn't simply used the tool
>>> she is familiar with... SPSS... to do this? If it is because this is an
>>> academic assignment to learn R then she should be talking to her
>>> institutional support (instructor/teaching assistant/tutoring staff) 
>>> anyway
>>> since there is a no-homework policy on this list (and that avenue would
>>> have the benefit of being conducted orally and most likely in her native
>>> language).
>>>
>>>
>>> On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com> 
>>> wrote:
>>>> Hi Rachel,
>>>> It looks to me as though the first thing you want to do is to get your
>>>> data, which you attach as images, into a data frame. If these are flat
>>>> files like CSV or TAB, you should be able to read them in with some
>>>> variant of the read.table function. If Excel, look at the various
>>>> Excel import packages. Then you can operate on the data frame by doing
>>>> things like tabulating Participant ID against the code for SMS or call
>>>> (which I assume are those 3000+ numbers). You can take the differences
>>>> in what look like POSIX time values between successive TRUE and FALSE
>>>> screen values to get the duration of screen activity and it looks like
>>>> participant activity is recorded at regular intervals. As Jeff
>>>> suggested, this is really just boring work figuring out how to extract
>>>> the events:
>>>>
>>>> call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
>>>> == _id? & Valuedetailed ==3271)
>>>>
>>>> using suitable logical statements and then tabulating them by
>>>> ParticipantID. If you know how to do that in SPSS, it won't be too
>>>> hard to translate the logical statements into R syntax as above. I may
>>>> have misunderstood the variable names, but I think the logic is clear.
>>>>
>>>> Jim
>>>>
>>>> On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
>>>> <rachel.thompson at student.uva.nl> wrote:
>>>>>
>>>>> Hi Jim,
>>>>>
>>>>> Thank you for the clarification. Since I only work in SPSS and I am
>>> >from Amsterdam I have had problems with specifying what I am trying to
>>>> do in this specific program and also in clear English language.
>>>>>
>>>>> I think I want to indeed aggregate these events for each subject over
>>>> the observation. But in this case several observations.
>>>>> 1. I want to have a summary of how many times a specific subject got
>>>> called (CallLogProbe)
>>>>> 2. I want to have a summary of how many times a specific subject got
>>>> a text message (SMS probe)
>>>>> 3. I want to have a summary of how many times a specific subject
>>>>> - Turned their screen on - True? (ScreenProbe)
>>>>> - Or did not turn their screen on - False (ScreenProbe)
>>>>> 4.? I want to have a summary of the activity level of a specific
>>>> subject
>>>>> - Activity level - none (ActivityProbe)
>>>>> - Activity level- low???? (ActivityProbe)
>>>>> - Activity level - High? (ActivityProbe)
>>>>>
>>>>> I want to do this for all the 36 subjects(Participants).
>>>>>
>>>>> In the end, I have to define percentages, so I am able to
>>>> say...Subject 36 has low social interactions ( because they only got
>>>> called and texted 500 times in total, while the average of all the
>>>> participants is 10000 or something). I have to come up with the
>>>> percentages myself and define cutoff points of what is considered
>>>> low-medium-high, based on what the results of all the subjects are.
>>>>>
>>>>> I hope that I am as clear as possible .
>>>>>
>>>>>
>>>>> I feel as if I am on my way of understanding it, but since I do not
>>>> clearly know, I am trying out a lot of different codes etc. and I do
>>>> not know if I am doing the right thing. I indeed made a new data frame
>>>> etc, but I still feel a bit lost. Do I need to make one per subject or
>>>> per Probe etc..
>>>>>
>>>>>
>>>>> Thanks for your help. I hope that you can help me resolve this issue.
>>>>>
>>>>>
>>>>> Best,
>>>>>
>>>>>
>>>>> Rachel
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
>>>> wrote:
>>>>>>
>>>>>> Hi Rachel,
>>>>>> I'll take a guess and assume that you are monitoring the mobile
>>>> phones
>>>>>> of 36 people, adding an observation every time some specified change
>>>>>> of state is sensed on each device. I'll also assume that you are
>>>> only
>>>>>> recording four types of measurement. It seems that you want to
>>>>>> aggregate these events for each subject over the interval or
>>>>>> observation (or over each day or something). I think you are going
>>>> to
>>>>>> create a new data frame of these summaries from the one you have of
>>>>>> individual observations. Creating each summary doesn't look too
>>>> hard,
>>>>>> but you will have to define more precisely what you want those
>>>>>> summaries to be. For instance, "I want the mean activity level for
>>>>>> each subject during the overall time that their mobile phone is
>>>>>> switched on", One you have clearly defined your goals, it probably
>>>>>> won't be too hard to get to them.
>>>>>>
>>>>>> Jim
>>>>>>
>>>>>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
>>>>>> <rachel.thompson at student.uva.nl> wrote:
>>>>>>>
>>>>>>> Dear Mr/Mrs,
>>>>>>>
>>>>>>> This is my first time working in R studio.
>>>>>>> I have a database of 36 participants but it has 150600 entries.
>>>>>>> Column -???????? Column - Column??????????? - Column
>>>>>>>
>>>>>>> Participant?????? Activityprobe - Activity Level? - High/low/none
>>>>>>>
>>>>>>> Participant?????? Screenprobe - screenon/off???? -
>>>>>>>
>>>>>>> Participant?????? SMSprobe etc
>>>>>>>
>>>>>>> Participant?????? CallLogProbe etc.
>>>>>>>
>>>>>>> I need a code that helps me count the activity level of all the
>>>> participants
>>>>>>> High activity level. No activity level and Low activity level.
>>>>>>> And to help me find out for every participant what the percentages
>>>> are of
>>>>>>> all their high/no/low activity.
>>>>>>>
>>>>>>> For screenprobe I need to count how many times the participant
>>>> turned their
>>>>>>> screen on and how many times they turned it off and the percentage
>>>> of
>>>>>>> screen on/off.
>>>>>>>
>>>>>>> For callLog I need to count how many times each participant got
>>>> called and
>>>>>>> the percentage.
>>>>>>>
>>>>>>> For SMS I need to count the number of SMS for each participant and
>>>> their
>>>>>>> percentage.
>>>>>>>
>>>>>>> I also need to categorize the probes. So that my database shows
>>>> all the
>>>>>>> activity levels first, organized by none/high/low and then all the
>>>>>>> screenprobes, organized by on and off etc...
>>>>>>>
>>>>>>> I hope that my description is clear and that you can maybe help
>>>> me.
>>>>>>>
>>>>>>> Best,
>>>>>>>
>>>>>>> Rachel
>>>>>>>
>>>>>>> ???????? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From bgunter@4567 @ending from gm@il@com  Sun Jan  6 18:29:47 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 6 Jan 2019 09:29:47 -0800
Subject: [R] data frame transformation
In-Reply-To: <1821429344.13733985.1546780573156@mail.yahoo.com>
References: <1821429344.13733985.1546780573156.ref@mail.yahoo.com>
 <1821429344.13733985.1546780573156@mail.yahoo.com>
Message-ID: <CAGxFJbRs5nrqM_b8TELSrBYLkbgG8SViA1twFoqKJ3rwSJ9bRg@mail.gmail.com>

Like this (using base R only)?

dat<-data.frame(id=id,letter=letter,weight=weight) # using your data

ud <- unique(dat$id)
ul = unique(dat$letter)
d <- with(dat,
          data.frame(
          letter = rep(ul, e = length(ud)),
          id = rep(ud, length(ul))
          ) )

 merge(dat[,c(2,1,3)],d, all.y = TRUE)
## resulting in:

   letter id weight
1       A  1     25
2       A  2     28
3       A  3     14
4       A  4     27
5       A  5     NA
6       B  1     13
7       B  2     14
8       B  3     NA
9       B  4     15
10      B  5      2
11      C  1     NA
12      C  2     NA
13      C  3     NA
14      C  4     NA
15      C  5     25
16      D  1     24
17      D  2     18
18      D  3     NA
19      D  4     29
20      D  5     27
21      E  1     NA
22      E  2      2
23      E  3     20
24      E  4     25
25      E  5     28


Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 6, 2019 at 5:16 AM Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Hello Everyone,
>
> would you be able to assist with some expertise on how to get the
> following done in a way that can be applied to a data set with different
> dimensions and without all the line items here?
>
> we have:
>
> id<-c(1,1,1,2,2,2,2,3,3,4,4,4,4,5,5,5,5)#length of unique IDs may differ
> of course in real data set, usually in magnitude of 10000
>
> letter<-c(sample(c("A","B","C","D","E"),3),sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),2),
>
> sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),4))#number
> of unique "letters" is less than 4000 in real data set and they are no
> duplicates within same ID
> weight<-c(sample(c(1:30),3),sample(c(1:30),4),sample(c(1:30),2),
>           sample(c(1:30),4),sample(c(1:30),4))#number of unique weights is
> below 50 in real data set and they are no duplicates within same ID
>
>
> data<-data.frame(id=id,letter=letter,weight=weight)
>
> #goal is to get the following transformation where a column is added for
> each unique letter and the weight is pulled into the column if the letter
> exist within the ID, otherwise NA
> #so we would get datatransform like below but without the many steps
> described here
>
> datatransfer<-data.frame(data,apply(data[2],2,function(x)
> ifelse(x=="A",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="B",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="C",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="D",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="E",data$weight,NA)))
>
> colnames(datatransfer)<-c("id","weight","letter","A","B","C","D","E")
> much appreciate the help,
>
> thanks
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sun Jan  6 18:44:41 2019
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 6 Jan 2019 23:14:41 +0530
Subject: [R] Webshot failed to take snapshot in Ubuntu machine
In-Reply-To: <23579.33867.614153.433173@stat.math.ethz.ch>
References: <CA+dpOJnZwhzUt=mPN+hKacuTjU71nyGggts69hvh55uyBPO5sQ@mail.gmail.com>
 <85df464f-1892-5500-799b-f5d73a61015a@yahoo.fr>
 <23579.33867.614153.433173@stat.math.ethz.ch>
Message-ID: <CA+dpOJkcgvhyifi+hf6g7qaVpCzC56_rBodzQaSYh0h0N4xuVA@mail.gmail.com>

Thanks Martin,

I reinstalled PhantomJS and now it works fine. Regards,

On Thu, Dec 20, 2018 at 5:30 PM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Marc Girondot via R-help
> >>>>>     on Tue, 18 Dec 2018 13:53:34 +0100 writes:
>
>     > Hi Christofer, I just try on MacOSX and ubuntu and it
>     > works on both:
>
>     > For ubuntu:
>     >> Sys.info()
>     >                                        sysname
>     >                                       "Linux"
>     >                                       release
>     >                           "4.15.0-42-generic"
>     >                                       version "#45-Ubuntu
>     > SMP Thu Nov 15 19:32:57 UTC 2018"
>     >                                      nodename
>     >                                "lepidochelys"
>     >                                       machine
>     >                                      "x86_64"
>
>     > Not sure what to do...
>     > Marc
>
> Hmm, if I try it (on my Linux desktop), I get
>
>   > library(webshot)
>   > url <- "
> https://www.bseindia.com/stock-share-price/asian-paints-ltd/asianpaint/500820/
> "
>   > webshot(url, 'bb.pdf')
>   PhantomJS not found. You can install it with
> webshot::install_phantomjs(). If it is installed, please make sure the
> phantomjs executable can be found via the PATH variable.
>   NULL
>
> So, it is clear this relies on extra javascript based software
> being available on your computer, *and* having that correctly in
> your PATH.
>
> On my linux system, I then did
>    webshot::install_phantomjs()
> and that downloaded things and installed a 67 Megabyte
> executable in my PATH ... which then subsequently worked.
>
> On that Linux system it did *not* work, try
>
>   system("which phantomjs")
>
> and you should see that it gets a version of 'phantomjs' on your
> computer, i.e., the one that  webshot() will then try to use and
> somehow fails.
>
> I'd recommend you run   webshot::install_phantomjs()
> which then should install a "better" version of the 'phantomjs'
> executable that then *should* work ..
>
> Let us know if this helped (or why not).
>
> Best,
> Martin Maechler
> ETH Zurich
>
>     > Le 18/12/2018 ? 13:37, Christofer Bogaso a ?crit :
>     >> Hi,
>     >>
>     >> I was using webshot package to take snapshot of a webpage
>     >> as below:
>     >>
>     >> library(webshot) webshot('
>     >>
> https://www.bseindia.com/stock-share-price/asian-paints-ltd/asianpaint/500820/
> ',
>     >> 'bb.pdf')
>     >>
>     >> However what I see is a Blank PDF file is saved.
>     >>
>     >> However if I use the same code in my windows machine it
>     >> is able to produce correct snapshot.
>     >>
>     >> Below is my system information
>     >>> Sys.info()
>     >> sysname "Linux" release "4.4.0-139-generic" version
>     >> "#165-Ubuntu SMP Wed Oct 24 10:58:50 UTC 2018" nodename
>     >> "ubuntu-s-2vcpu-4gb-blr1-01" machine "x86_64" login
>     >> "root" user "root" effective_user "root"
>     >>
>     >> Any idea what went wrong would be highly helpful.
>     >>
>     >> Thanks,
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html and provide
>     >> commented, minimal, self-contained, reproducible code.
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sun Jan  6 19:09:43 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 6 Jan 2019 10:09:43 -0800
Subject: [R] data frame transformation
In-Reply-To: <1821429344.13733985.1546780573156@mail.yahoo.com>
References: <1821429344.13733985.1546780573156.ref@mail.yahoo.com>
 <1821429344.13733985.1546780573156@mail.yahoo.com>
Message-ID: <CAGxFJbRAYFJ-aSY0AqrgqgjTjWTLL5FvPL5BNuKLE7v4DKB3-A@mail.gmail.com>

... and my reordering of column indices was unnecessary:
    merge(dat, d, all.y = TRUE)
will do.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 6, 2019 at 5:16 AM Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Hello Everyone,
>
> would you be able to assist with some expertise on how to get the
> following done in a way that can be applied to a data set with different
> dimensions and without all the line items here?
>
> we have:
>
> id<-c(1,1,1,2,2,2,2,3,3,4,4,4,4,5,5,5,5)#length of unique IDs may differ
> of course in real data set, usually in magnitude of 10000
>
> letter<-c(sample(c("A","B","C","D","E"),3),sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),2),
>
> sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),4))#number
> of unique "letters" is less than 4000 in real data set and they are no
> duplicates within same ID
> weight<-c(sample(c(1:30),3),sample(c(1:30),4),sample(c(1:30),2),
>           sample(c(1:30),4),sample(c(1:30),4))#number of unique weights is
> below 50 in real data set and they are no duplicates within same ID
>
>
> data<-data.frame(id=id,letter=letter,weight=weight)
>
> #goal is to get the following transformation where a column is added for
> each unique letter and the weight is pulled into the column if the letter
> exist within the ID, otherwise NA
> #so we would get datatransform like below but without the many steps
> described here
>
> datatransfer<-data.frame(data,apply(data[2],2,function(x)
> ifelse(x=="A",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="B",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="C",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="D",data$weight,NA)))
> datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x)
> ifelse(x=="E",data$weight,NA)))
>
> colnames(datatransfer)<-c("id","weight","letter","A","B","C","D","E")
> much appreciate the help,
>
> thanks
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Sun Jan  6 19:48:17 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Sun, 6 Jan 2019 13:48:17 -0500
Subject: [R] Mailinglist
In-Reply-To: <cce3dcb5-7f53-f62c-83d2-3d56504eed5f@sapo.pt>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <4d9b168d-92c0-5a62-f07d-d394a2c62d93@dewey.myzen.co.uk>
 <cce3dcb5-7f53-f62c-83d2-3d56504eed5f@sapo.pt>
Message-ID: <CAK7fGOvEtchqrsziOF6b57vq7ztCx75Y7uMAYFr9_=Fs9LpvLA@mail.gmail.com>

Hi Rui,

Thank you, I willl look into it.

Best,

Rachel



On Sun, Jan 6, 2019 at 12:27 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> In many continental European countries, such as mine, the function to
> use is
>
> read.csv2
>
> It defaults to
>
> sep = ";", dec = ","
>
> Note that these functions are in fact calls to read.table with special
> default arguments. Another default that changes is header = TRUE.
> You might also want to set stringsAsFactors = FALSE since the default
> value TRUE is a common source for errors.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:45 de 06/01/2019, Michael Dewey escreveu:
> > Dear Rachel
> >
> > Not sure if this is going to help but if it is a csv file then
> > read.csv() is your friend. Read the help first in case you need to
> > specify what is being used for the decimal point and the separator as if
> > it is from the Netherlands they may not be the default settings.
> >
> > michael
> >
> > On 06/01/2019 16:37, Rachel Thompson wrote:
> >> Hi Jeff,
> >>
> >> Thanks for your email.
> >> I am an intern from Amsterdam and I have to do an analysis in R. I
> >> spoke to
> >> my professor in Amsterdam and my supervisor's here in Boston. But they
> >> are
> >> to busy to help. I informed them from the start that I am not familiar
> >> with
> >> R(Rstudio) and they told me that I would receive guidance. So since they
> >> can not help me, I decided to share my problem online.
> >> (It is a CVS file imported into R)
> >>
> >> Please understand that I am new to this. I will unsubscribe to the
> >> mailing
> >> list if my question does not belong here.
> >>
> >> Thanks,
> >>
> >> Rachel
> >>
> >> On Sun, Jan 6, 2019 at 11:01 AM Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> I would not want to leave the impression that I think the task at
> >>> hand is
> >>> merely tedious... my point is that there are numerous steps involved
> and
> >>> each step depends on information that has not been communicated to the
> >>> list, and there is a learning curve even in knowing what to include
> >>> in an
> >>> email question. What I do think is that knowing enough basic R syntax
> to
> >>> express small bits of the problem in R will be a vast improvement over
> >>> attempting to use only English descriptions, and Rachel has to bridge
> >>> that
> >>> initial gap.
> >>>
> >>> For example, some images of data were apparently sent to Jim only,
> >>> yet he
> >>> still does not know in what format the data file is stored, so that
> >>> technique was not very effective. One way for the question to become
> >>> more
> >>> focused is for Rachel to study up on her own how to import data and
> >>> provide
> >>> us with a "dput" (see the StackOverflow discussion I referenced
> >>> before) of
> >>> a small sample of data. Another is for Rachel to use basic R syntax to
> >>> create an anonymous data set from scratch (also outlined in the SO
> >>> discussion). These approaches allow us to keep the focus of our mailing
> >>> list discussion on manipulating the data into summaries. Another
> >>> approach
> >>> is to re-focus the question on importing data by supplying a download
> >>> link
> >>> to the data so we can make suggestions as to what R commands will
> handle
> >>> this data in its raw form. In any case, we cannot leapfrog over the
> >>> data to
> >>> the analysis as the question stands.
> >>>
> >>> Given the above, I have to wonder why Rachel hasn't simply used the
> tool
> >>> she is familiar with... SPSS... to do this? If it is because this is an
> >>> academic assignment to learn R then she should be talking to her
> >>> institutional support (instructor/teaching assistant/tutoring staff)
> >>> anyway
> >>> since there is a no-homework policy on this list (and that avenue would
> >>> have the benefit of being conducted orally and most likely in her
> native
> >>> language).
> >>>
> >>>
> >>> On January 6, 2019 1:12:46 AM PST, Jim Lemon <drjimlemon at gmail.com>
> >>> wrote:
> >>>> Hi Rachel,
> >>>> It looks to me as though the first thing you want to do is to get your
> >>>> data, which you attach as images, into a data frame. If these are flat
> >>>> files like CSV or TAB, you should be able to read them in with some
> >>>> variant of the read.table function. If Excel, look at the various
> >>>> Excel import packages. Then you can operate on the data frame by doing
> >>>> things like tabulating Participant ID against the code for SMS or call
> >>>> (which I assume are those 3000+ numbers). You can take the differences
> >>>> in what look like POSIX time values between successive TRUE and FALSE
> >>>> screen values to get the duration of screen activity and it looks like
> >>>> participant activity is recorded at regular intervals. As Jeff
> >>>> suggested, this is really just boring work figuring out how to extract
> >>>> the events:
> >>>>
> >>>> call_indices<-which(Probetype == xxxxxxCallLogProbe & ValueSpecified
> >>>> == _id  & Valuedetailed ==3271)
> >>>>
> >>>> using suitable logical statements and then tabulating them by
> >>>> ParticipantID. If you know how to do that in SPSS, it won't be too
> >>>> hard to translate the logical statements into R syntax as above. I may
> >>>> have misunderstood the variable names, but I think the logic is clear.
> >>>>
> >>>> Jim
> >>>>
> >>>> On Sun, Jan 6, 2019 at 4:07 PM Rachel Thompson
> >>>> <rachel.thompson at student.uva.nl> wrote:
> >>>>>
> >>>>> Hi Jim,
> >>>>>
> >>>>> Thank you for the clarification. Since I only work in SPSS and I am
> >>> >from Amsterdam I have had problems with specifying what I am trying to
> >>>> do in this specific program and also in clear English language.
> >>>>>
> >>>>> I think I want to indeed aggregate these events for each subject over
> >>>> the observation. But in this case several observations.
> >>>>> 1. I want to have a summary of how many times a specific subject got
> >>>> called (CallLogProbe)
> >>>>> 2. I want to have a summary of how many times a specific subject got
> >>>> a text message (SMS probe)
> >>>>> 3. I want to have a summary of how many times a specific subject
> >>>>> - Turned their screen on - True  (ScreenProbe)
> >>>>> - Or did not turn their screen on - False (ScreenProbe)
> >>>>> 4.  I want to have a summary of the activity level of a specific
> >>>> subject
> >>>>> - Activity level - none (ActivityProbe)
> >>>>> - Activity level- low     (ActivityProbe)
> >>>>> - Activity level - High  (ActivityProbe)
> >>>>>
> >>>>> I want to do this for all the 36 subjects(Participants).
> >>>>>
> >>>>> In the end, I have to define percentages, so I am able to
> >>>> say...Subject 36 has low social interactions ( because they only got
> >>>> called and texted 500 times in total, while the average of all the
> >>>> participants is 10000 or something). I have to come up with the
> >>>> percentages myself and define cutoff points of what is considered
> >>>> low-medium-high, based on what the results of all the subjects are.
> >>>>>
> >>>>> I hope that I am as clear as possible .
> >>>>>
> >>>>>
> >>>>> I feel as if I am on my way of understanding it, but since I do not
> >>>> clearly know, I am trying out a lot of different codes etc. and I do
> >>>> not know if I am doing the right thing. I indeed made a new data frame
> >>>> etc, but I still feel a bit lost. Do I need to make one per subject or
> >>>> per Probe etc..
> >>>>>
> >>>>>
> >>>>> Thanks for your help. I hope that you can help me resolve this issue.
> >>>>>
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>>
> >>>>> Rachel
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Sat, Jan 5, 2019 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>> Hi Rachel,
> >>>>>> I'll take a guess and assume that you are monitoring the mobile
> >>>> phones
> >>>>>> of 36 people, adding an observation every time some specified change
> >>>>>> of state is sensed on each device. I'll also assume that you are
> >>>> only
> >>>>>> recording four types of measurement. It seems that you want to
> >>>>>> aggregate these events for each subject over the interval or
> >>>>>> observation (or over each day or something). I think you are going
> >>>> to
> >>>>>> create a new data frame of these summaries from the one you have of
> >>>>>> individual observations. Creating each summary doesn't look too
> >>>> hard,
> >>>>>> but you will have to define more precisely what you want those
> >>>>>> summaries to be. For instance, "I want the mean activity level for
> >>>>>> each subject during the overall time that their mobile phone is
> >>>>>> switched on", One you have clearly defined your goals, it probably
> >>>>>> won't be too hard to get to them.
> >>>>>>
> >>>>>> Jim
> >>>>>>
> >>>>>> On Sun, Jan 6, 2019 at 5:39 AM Rachel Thompson
> >>>>>> <rachel.thompson at student.uva.nl> wrote:
> >>>>>>>
> >>>>>>> Dear Mr/Mrs,
> >>>>>>>
> >>>>>>> This is my first time working in R studio.
> >>>>>>> I have a database of 36 participants but it has 150600 entries.
> >>>>>>> Column -         Column - Column            - Column
> >>>>>>>
> >>>>>>> Participant       Activityprobe - Activity Level  - High/low/none
> >>>>>>>
> >>>>>>> Participant       Screenprobe - screenon/off     -
> >>>>>>>
> >>>>>>> Participant       SMSprobe etc
> >>>>>>>
> >>>>>>> Participant       CallLogProbe etc.
> >>>>>>>
> >>>>>>> I need a code that helps me count the activity level of all the
> >>>> participants
> >>>>>>> High activity level. No activity level and Low activity level.
> >>>>>>> And to help me find out for every participant what the percentages
> >>>> are of
> >>>>>>> all their high/no/low activity.
> >>>>>>>
> >>>>>>> For screenprobe I need to count how many times the participant
> >>>> turned their
> >>>>>>> screen on and how many times they turned it off and the percentage
> >>>> of
> >>>>>>> screen on/off.
> >>>>>>>
> >>>>>>> For callLog I need to count how many times each participant got
> >>>> called and
> >>>>>>> the percentage.
> >>>>>>>
> >>>>>>> For SMS I need to count the number of SMS for each participant and
> >>>> their
> >>>>>>> percentage.
> >>>>>>>
> >>>>>>> I also need to categorize the probes. So that my database shows
> >>>> all the
> >>>>>>> activity levels first, organized by none/high/low and then all the
> >>>>>>> screenprobes, organized by on and off etc...
> >>>>>>>
> >>>>>>> I hope that my description is clear and that you can maybe help
> >>>> me.
> >>>>>>>
> >>>>>>> Best,
> >>>>>>>
> >>>>>>> Rachel
> >>>>>>>
> >>>>>>>          [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Sun Jan  6 19:49:15 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Sun, 6 Jan 2019 13:49:15 -0500
Subject: [R] Mailinglist
In-Reply-To: <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
Message-ID: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>

Hi Rich,

I really feel lost at this point.
I need a code that helps me count the phone activity level(high/low/none),
the screen activity (on/off) and the amount calls and SMS of each subject.

1. I want to have a summary of how many times a specific subject got called
(CallLogProbe)
2. I want to have a summary of how many times a specific subject got a text
message (SMS probe)
3. I want to have a summary of how many times a specific subject
- Turned their screen on - True  (ScreenProbe)
- Or did not turn their screen on - False (ScreenProbe)
4.  I want to have a summary of the activity level of a specific subject
- Activity level - none (ActivityProbe)
- Activity level- low     (ActivityProbe)
- Activity level - High  (ActivityProbe)

I want to do this for all the 36 subjects(Participants).
In the end, I have to define the percentages and cutoff points of what is
considered low-medium-high, based on what the results of all the subjects
are. So I am able to see if a specific subject has low social interaction
etc.

I have tried a lot, with the help of youtube etc. But I feel as if I am
trying a lot of things but without clearly knowing if it is the right step.
I have a csv file, but I need to look into what Jeff said about the guides.
So I am able to share it.

Best.


On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Sun, 6 Jan 2019, Rachel Thompson wrote:
>
> > I am an intern from Amsterdam and I have to do an analysis in R. I spoke
> > to my professor in Amsterdam and my supervisor's here in Boston. But they
> > are to busy to help. I informed them from the start that I am not
> familiar
> > with R(Rstudio) and they told me that I would receive guidance. So since
> > they can not help me, I decided to share my problem online. (It is a CVS
> > file imported into R)
>
> Rachel,
>
>    I find it interesting that you're put in such a difficult position. I've
> not followed this thread from the start so my comments might be redundant
> or
> inappropriate.
>
>    If you can, describe the problem. That is, what are you being asked to
> find and what are the available data? This information helps us to guide
> you
> to learning the mechanics for accomplishing your task with R.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h@@@n@diw@n @ending from gm@il@com  Sun Jan  6 20:09:08 2019
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Sun, 6 Jan 2019 11:09:08 -0800
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
Message-ID: <CAP+bYWAU2MqjuLOVL8=uMV-BrG++W6GR6ubfL_G+Aq8VAf=FBQ@mail.gmail.com>

Maybe you could put the CSV in a gist or something? -- H

On Sun, 6 Jan 2019 at 10:58, Rachel Thompson <rachel.thompson at student.uva.nl>
wrote:

> Hi Rich,
>
> I really feel lost at this point.
> I need a code that helps me count the phone activity level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each subject.
>
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of what is
> considered low-medium-high, based on what the results of all the subjects
> are. So I am able to see if a specific subject has low social interaction
> etc.
>
> I have tried a lot, with the help of youtube etc. But I feel as if I am
> trying a lot of things but without clearly knowing if it is the right step.
> I have a csv file, but I need to look into what Jeff said about the guides.
> So I am able to share it.
>
> Best.
>
>
> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> >
> > > I am an intern from Amsterdam and I have to do an analysis in R. I
> spoke
> > > to my professor in Amsterdam and my supervisor's here in Boston. But
> they
> > > are to busy to help. I informed them from the start that I am not
> > familiar
> > > with R(Rstudio) and they told me that I would receive guidance. So
> since
> > > they can not help me, I decided to share my problem online. (It is a
> CVS
> > > file imported into R)
> >
> > Rachel,
> >
> >    I find it interesting that you're put in such a difficult position.
> I've
> > not followed this thread from the start so my comments might be redundant
> > or
> > inappropriate.
> >
> >    If you can, describe the problem. That is, what are you being asked to
> > find and what are the available data? This information helps us to guide
> > you
> > to learning the mechanics for accomplishing your task with R.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sun Jan  6 20:22:22 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sun, 6 Jan 2019 11:22:22 -0800 (PST)
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1901061114530.6912@salmo.appl-ecosys.com>

On Sun, 6 Jan 2019, Rachel Thompson wrote:

> I need a code that helps me count the phone activity level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each subject.
>
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of what is
> considered low-medium-high, based on what the results of all the subjects
> are. So I am able to see if a specific subject has low social interaction
> etc.

Rachel,

   Those more experienced with R than am I will probably offer their
thoughts, too.

   It looks to me that you want counts of various parameters for each
participant, and perhaps groups of participants. When I read this I see SQL
SELECT count() statements on database tables, not descriptive or explanatory
statistical results.

   Not knowing your computer's OS or whether there is a relational database
magagement system installed I can't offer specific suggestions. A database
would provide counts of each *Probe as well as combinations. If you want to
go that route contact me off the mail list and I'll suggest mail lists for
help if you use Microsoft products as I know only PostgreSQL and SQLite.

Regards,

Rich


From rmh @ending from temple@edu  Sun Jan  6 20:48:15 2019
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Sun, 6 Jan 2019 14:48:15 -0500
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
Message-ID: <CAGx1TMA77OUt9O9nAkLzq1cBMs-BfJ3uEakxr3vVtZEMwDZNiQ@mail.gmail.com>

Questions like this
1. I want to have a summary of how many times a specific subject got called
(CallLogProbe)

suggest that you should look at the table function.  See
?table
and run the examples.
They show how to get one-way frequency tables and two-way contingency
tables.

If you have followup questions for the list, you can use the examples in
?table as your starting point.
That way you don't need to worry about sharing your own data.


On Sun, Jan 6, 2019 at 1:59 PM Rachel Thompson <
rachel.thompson at student.uva.nl> wrote:

> Hi Rich,
>
> I really feel lost at this point.
> I need a code that helps me count the phone activity level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each subject.
>
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of what is
> considered low-medium-high, based on what the results of all the subjects
> are. So I am able to see if a specific subject has low social interaction
> etc.
>
> I have tried a lot, with the help of youtube etc. But I feel as if I am
> trying a lot of things but without clearly knowing if it is the right step.
> I have a csv file, but I need to look into what Jeff said about the guides.
> So I am able to share it.
>
> Best.
>
>
> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> >
> > > I am an intern from Amsterdam and I have to do an analysis in R. I
> spoke
> > > to my professor in Amsterdam and my supervisor's here in Boston. But
> they
> > > are to busy to help. I informed them from the start that I am not
> > familiar
> > > with R(Rstudio) and they told me that I would receive guidance. So
> since
> > > they can not help me, I decided to share my problem online. (It is a
> CVS
> > > file imported into R)
> >
> > Rachel,
> >
> >    I find it interesting that you're put in such a difficult position.
> I've
> > not followed this thread from the start so my comments might be redundant
> > or
> > inappropriate.
> >
> >    If you can, describe the problem. That is, what are you being asked to
> > find and what are the available data? This information helps us to guide
> > you
> > to learning the mechanics for accomplishing your task with R.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ro@lin@ump @ending from gm@il@com  Mon Jan  7 06:23:42 2019
From: ro@lin@ump @ending from gm@il@com (roslinazairimah zakaria)
Date: Mon, 7 Jan 2019 13:23:42 +0800
Subject: [R] Need help for logical expression
Message-ID: <CANTvJZK-i_e01Nvfxmwagi+DGd6Bf9_10FVsfjR+rVa67P9vow@mail.gmail.com>

Dear all,

I just have a simple problem here.

I generate a sample data as follows:
set.seed(123456)
r1 <- sample(1:100,100 ,replace=T)
r2 <- sample(1:100,100 ,replace=T)
r3 <- sample(1:100,100 ,replace=T)

R <- cbind(r1,r2,r3); head(R)
> R <- cbind(r1,r2,r3); head(R)
     r1 r2 r3
[1,] 80  4 20
[2,] 76 66 14
[3,] 40 32 87
[4,] 35 19 24
[5,] 37 63 12
[6,] 20 52 42
sum_r <- rowSums(R)
all_pct <- round(R/sum_r*100,0); head(all_pct)
> all_pct <- round(R/sum_r*100,0); head(all_pct)
     r1 r2 r3
[1,] 77  4 19
[2,] 49 42  9
[3,] 25 20 55
[4,] 45 24 31
[5,] 33 56 11
[6,] 18 46 37

I would like to count how many of all_pct data satisfy this condition as
follows:

dt_all <- ifelse(all_pct[,1] >= 45 & all_pct[,1] > all_pct[,2] &
all_pct[,1] > all_pct[,3], 1, 0)

Note that data of all_pct[,1] >= 45  and at the same time greater
than all_pct[,2] and all_pct[,3].

How do I count how many satisfy the conditions?

-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jan  7 06:36:35 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 6 Jan 2019 21:36:35 -0800 (PST)
Subject: [R] Need help for logical expression
In-Reply-To: <CANTvJZK-i_e01Nvfxmwagi+DGd6Bf9_10FVsfjR+rVa67P9vow@mail.gmail.com>
References: <CANTvJZK-i_e01Nvfxmwagi+DGd6Bf9_10FVsfjR+rVa67P9vow@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1901062133520.30472@pedal.dcn.davis.ca.us>

See below

On Mon, 7 Jan 2019, roslinazairimah zakaria wrote:

> Dear all,
>
> I just have a simple problem here.
>
> I generate a sample data as follows:
> set.seed(123456)
> r1 <- sample(1:100,100 ,replace=T)
> r2 <- sample(1:100,100 ,replace=T)
> r3 <- sample(1:100,100 ,replace=T)
>
> R <- cbind(r1,r2,r3); head(R)
>> R <- cbind(r1,r2,r3); head(R)
>     r1 r2 r3
> [1,] 80  4 20
> [2,] 76 66 14
> [3,] 40 32 87
> [4,] 35 19 24
> [5,] 37 63 12
> [6,] 20 52 42
> sum_r <- rowSums(R)
> all_pct <- round(R/sum_r*100,0); head(all_pct)
>> all_pct <- round(R/sum_r*100,0); head(all_pct)
>     r1 r2 r3
> [1,] 77  4 19
> [2,] 49 42  9
> [3,] 25 20 55
> [4,] 45 24 31
> [5,] 33 56 11
> [6,] 18 46 37
>
> I would like to count how many of all_pct data satisfy this condition as
> follows:
>
> dt_all <- ifelse(all_pct[,1] >= 45 & all_pct[,1] > all_pct[,2] &
> all_pct[,1] > all_pct[,3], 1, 0)
>
> Note that data of all_pct[,1] >= 45  and at the same time greater
> than all_pct[,2] and all_pct[,3].
>
> How do I count how many satisfy the conditions?

sum( dt_all )

Did I misunderstand?

>
> -- 
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
> 	[[alternative HTML version deleted]]

HTML email will eventually impede others trying to understand your code... 
the sooner you stop posting HTML the better.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From m@illi@t@ @ending from pp@inet@fi  Mon Jan  7 07:27:43 2019
From: m@illi@t@ @ending from pp@inet@fi (K. Elo)
Date: Mon, 07 Jan 2019 08:27:43 +0200
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
Message-ID: <92cf4a95349db0c2633cbfef2b27204083e95b14.camel@pp.inet.fi>

Hi!

Not having a data chunk prevents me from testing abit, but maybe you
should take a look on:

?table
?xtabs

to start with.

But as already suggested by other users, a small data set would be of
great help :)

HTH,
Kimmo

su, 2019-01-06 kello 13:49 -0500, Rachel Thompson kirjoitti:
> Hi Rich,
> 
> I really feel lost at this point.
> I need a code that helps me count the phone activity
> level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each
> subject.
> 
> 1. I want to have a summary of how many times a specific subject got
> called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got
> a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific
> subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
> 
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of
> what is
> considered low-medium-high, based on what the results of all the
> subjects
> are. So I am able to see if a specific subject has low social
> interaction
> etc.
> 
> I have tried a lot, with the help of youtube etc. But I feel as if I
> am
> trying a lot of things but without clearly knowing if it is the right
> step.
> I have a csv file, but I need to look into what Jeff said about the
> guides.
> So I am able to share it.
> 
> Best.
> 
> 
> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <
> rshepard at appl-ecosys.com>
> wrote:
> 
> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > 
> > > I am an intern from Amsterdam and I have to do an analysis in R.
> > > I spoke
> > > to my professor in Amsterdam and my supervisor's here in Boston.
> > > But they
> > > are to busy to help. I informed them from the start that I am not
> > 
> > familiar
> > > with R(Rstudio) and they told me that I would receive guidance.
> > > So since
> > > they can not help me, I decided to share my problem online. (It
> > > is a CVS
> > > file imported into R)
> > 
> > Rachel,
> > 
> >    I find it interesting that you're put in such a difficult
> > position. I've
> > not followed this thread from the start so my comments might be
> > redundant
> > or
> > inappropriate.
> > 
> >    If you can, describe the problem. That is, what are you being
> > asked to
> > find and what are the available data? This information helps us to
> > guide
> > you
> > to learning the mechanics for accomplishing your task with R.
> > 
> > Regards,
> > 
> > Rich
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@pik@l @ending from prechez@@cz  Mon Jan  7 09:56:21 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 7 Jan 2019 08:56:21 +0000
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
Message-ID: <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>

Hi Rachel.

You already have got several suggestions, but results depend on structure of your data. The best way from your side would be just copy a part of your data directly to email and preferable way is to use "dput".

Assuming your data already transfered to R are called "mydata".

You can just copy otput of

dput(mydata[1:30,])

to your next mail.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rachel Thompson
> Sent: Sunday, January 6, 2019 7:49 PM
> To: Rich Shepard <rshepard at appl-ecosys.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Mailinglist
>
> Hi Rich,
>
> I really feel lost at this point.
> I need a code that helps me count the phone activity level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each subject.
>
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of what is
> considered low-medium-high, based on what the results of all the subjects
> are. So I am able to see if a specific subject has low social interaction
> etc.
>
> I have tried a lot, with the help of youtube etc. But I feel as if I am
> trying a lot of things but without clearly knowing if it is the right step.
> I have a csv file, but I need to look into what Jeff said about the guides.
> So I am able to share it.
>
> Best.
>
>
> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> >
> > > I am an intern from Amsterdam and I have to do an analysis in R. I spoke
> > > to my professor in Amsterdam and my supervisor's here in Boston. But they
> > > are to busy to help. I informed them from the start that I am not
> > familiar
> > > with R(Rstudio) and they told me that I would receive guidance. So since
> > > they can not help me, I decided to share my problem online. (It is a CVS
> > > file imported into R)
> >
> > Rachel,
> >
> >    I find it interesting that you're put in such a difficult position. I've
> > not followed this thread from the start so my comments might be redundant
> > or
> > inappropriate.
> >
> >    If you can, describe the problem. That is, what are you being asked to
> > find and what are the available data? This information helps us to guide
> > you
> > to learning the mechanics for accomplishing your task with R.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@pik@l @ending from prechez@@cz  Mon Jan  7 10:03:10 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 7 Jan 2019 09:03:10 +0000
Subject: [R] Mailinglist
In-Reply-To: <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
Message-ID: <012dda73d2894339af6cb82759b650fa@SRVEXCHCM1302.precheza.cz>

And depending on your further intentions with data, functions ave or aggregate could also be worth to check.

Cheers
Petr

>
> Hi Rachel.
>
> You already have got several suggestions, but results depend on structure of
> your data. The best way from your side would be just copy a part of your data
> directly to email and preferable way is to use "dput".
>
> Assuming your data already transfered to R are called "mydata".
>
> You can just copy otput of
>
> dput(mydata[1:30,])
>
> to your next mail.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rachel
> > Thompson
> > Sent: Sunday, January 6, 2019 7:49 PM
> > To: Rich Shepard <rshepard at appl-ecosys.com>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] Mailinglist
> >
> > Hi Rich,
> >
> > I really feel lost at this point.
> > I need a code that helps me count the phone activity
> > level(high/low/none), the screen activity (on/off) and the amount calls and
> SMS of each subject.
> >
> > 1. I want to have a summary of how many times a specific subject got
> > called
> > (CallLogProbe)
> > 2. I want to have a summary of how many times a specific subject got a
> > text message (SMS probe) 3. I want to have a summary of how many times
> > a specific subject
> > - Turned their screen on - True  (ScreenProbe)
> > - Or did not turn their screen on - False (ScreenProbe) 4.  I want to
> > have a summary of the activity level of a specific subject
> > - Activity level - none (ActivityProbe)
> > - Activity level- low     (ActivityProbe)
> > - Activity level - High  (ActivityProbe)
> >
> > I want to do this for all the 36 subjects(Participants).
> > In the end, I have to define the percentages and cutoff points of what
> > is considered low-medium-high, based on what the results of all the
> > subjects are. So I am able to see if a specific subject has low social
> > interaction etc.
> >
> > I have tried a lot, with the help of youtube etc. But I feel as if I
> > am trying a lot of things but without clearly knowing if it is the right step.
> > I have a csv file, but I need to look into what Jeff said about the guides.
> > So I am able to share it.
> >
> > Best.
> >
> >
> > On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard
> > <rshepard at appl-ecosys.com>
> > wrote:
> >
> > > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > >
> > > > I am an intern from Amsterdam and I have to do an analysis in R. I
> > > > spoke to my professor in Amsterdam and my supervisor's here in
> > > > Boston. But they are to busy to help. I informed them from the
> > > > start that I am not
> > > familiar
> > > > with R(Rstudio) and they told me that I would receive guidance. So
> > > > since they can not help me, I decided to share my problem online.
> > > > (It is a CVS file imported into R)
> > >
> > > Rachel,
> > >
> > >    I find it interesting that you're put in such a difficult
> > > position. I've not followed this thread from the start so my
> > > comments might be redundant or inappropriate.
> > >
> > >    If you can, describe the problem. That is, what are you being
> > > asked to find and what are the available data? This information
> > > helps us to guide you to learning the mechanics for accomplishing
> > > your task with R.
> > >
> > > Regards,
> > >
> > > Rich
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-
> ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
> a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
> https://www.precheza.cz/01-dovetek/ | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From h@@@n@diw@n @ending from gm@il@com  Mon Jan  7 10:03:00 2019
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Mon, 7 Jan 2019 01:03:00 -0800
Subject: [R] Mailinglist
In-Reply-To: <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAP+bYWBc=c1dKumXqFT5ziJ3eHmzifE=fQ_8og+UK=EOARBj3g@mail.gmail.com>

dput(sample(mydata, n=25)) is probably going to be more representative. -- H

On Mon, 7 Jan 2019 at 00:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi Rachel.
>
> You already have got several suggestions, but results depend on structure
> of your data. The best way from your side would be just copy a part of your
> data directly to email and preferable way is to use "dput".
>
> Assuming your data already transfered to R are called "mydata".
>
> You can just copy otput of
>
> dput(mydata[1:30,])
>
> to your next mail.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rachel Thompson
> > Sent: Sunday, January 6, 2019 7:49 PM
> > To: Rich Shepard <rshepard at appl-ecosys.com>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] Mailinglist
> >
> > Hi Rich,
> >
> > I really feel lost at this point.
> > I need a code that helps me count the phone activity
> level(high/low/none),
> > the screen activity (on/off) and the amount calls and SMS of each
> subject.
> >
> > 1. I want to have a summary of how many times a specific subject got
> called
> > (CallLogProbe)
> > 2. I want to have a summary of how many times a specific subject got a
> text
> > message (SMS probe)
> > 3. I want to have a summary of how many times a specific subject
> > - Turned their screen on - True  (ScreenProbe)
> > - Or did not turn their screen on - False (ScreenProbe)
> > 4.  I want to have a summary of the activity level of a specific subject
> > - Activity level - none (ActivityProbe)
> > - Activity level- low     (ActivityProbe)
> > - Activity level - High  (ActivityProbe)
> >
> > I want to do this for all the 36 subjects(Participants).
> > In the end, I have to define the percentages and cutoff points of what is
> > considered low-medium-high, based on what the results of all the subjects
> > are. So I am able to see if a specific subject has low social interaction
> > etc.
> >
> > I have tried a lot, with the help of youtube etc. But I feel as if I am
> > trying a lot of things but without clearly knowing if it is the right
> step.
> > I have a csv file, but I need to look into what Jeff said about the
> guides.
> > So I am able to share it.
> >
> > Best.
> >
> >
> > On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
> > wrote:
> >
> > > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > >
> > > > I am an intern from Amsterdam and I have to do an analysis in R. I
> spoke
> > > > to my professor in Amsterdam and my supervisor's here in Boston. But
> they
> > > > are to busy to help. I informed them from the start that I am not
> > > familiar
> > > > with R(Rstudio) and they told me that I would receive guidance. So
> since
> > > > they can not help me, I decided to share my problem online. (It is a
> CVS
> > > > file imported into R)
> > >
> > > Rachel,
> > >
> > >    I find it interesting that you're put in such a difficult position.
> I've
> > > not followed this thread from the start so my comments might be
> redundant
> > > or
> > > inappropriate.
> > >
> > >    If you can, describe the problem. That is, what are you being asked
> to
> > > find and what are the available data? This information helps us to
> guide
> > > you
> > > to learning the mechanics for accomplishing your task with R.
> > >
> > > Regards,
> > >
> > > Rich
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From motyoc@k@ @ending from y@hoo@com  Mon Jan  7 11:29:05 2019
From: motyoc@k@ @ending from y@hoo@com (Andras Farkas)
Date: Mon, 7 Jan 2019 10:29:05 +0000 (UTC)
Subject: [R] data frame transformation
In-Reply-To: <CAGxFJbRAYFJ-aSY0AqrgqgjTjWTLL5FvPL5BNuKLE7v4DKB3-A@mail.gmail.com>
References: <1821429344.13733985.1546780573156.ref@mail.yahoo.com>
 <1821429344.13733985.1546780573156@mail.yahoo.com>
 <CAGxFJbRAYFJ-aSY0AqrgqgjTjWTLL5FvPL5BNuKLE7v4DKB3-A@mail.gmail.com>
Message-ID: <784298106.14142525.1546856945341@mail.yahoo.com>

Thanks Bert this will do...
Andras

Sent from Yahoo Mail on Android 
 
  On Sun, Jan 6, 2019 at 1:09 PM, Bert Gunter<bgunter.4567 at gmail.com> wrote:   ... and my reordering of column indices was unnecessary:??? merge(dat, d, all.y = TRUE)will do.
Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 6, 2019 at 5:16 AM Andras Farkas via R-help <r-help at r-project.org> wrote:

Hello Everyone,

would you be able to assist with some expertise on how to get the following done in a way that can be applied to a data set with different dimensions and without all the line items here?

we have:

id<-c(1,1,1,2,2,2,2,3,3,4,4,4,4,5,5,5,5)#length of unique IDs may differ of course in real data set, usually in magnitude of 10000
letter<-c(sample(c("A","B","C","D","E"),3),sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),2),
? ? ? ? ? sample(c("A","B","C","D","E"),4),sample(c("A","B","C","D","E"),4))#number of unique "letters" is less than 4000 in real data set and they are no duplicates within same ID
weight<-c(sample(c(1:30),3),sample(c(1:30),4),sample(c(1:30),2),
? ? ? ? ? sample(c(1:30),4),sample(c(1:30),4))#number of unique weights is below 50 in real data set and they are no duplicates within same ID


data<-data.frame(id=id,letter=letter,weight=weight)

#goal is to get the following transformation where a column is added for each unique letter and the weight is pulled into the column if the letter exist within the ID, otherwise NA
#so we would get datatransform like below but without the many steps described here

datatransfer<-data.frame(data,apply(data[2],2,function(x) ifelse(x=="A",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="B",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="C",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="D",data$weight,NA)))
datatransfer<-data.frame(datatransfer,apply(datatransfer[2],2,function(x) ifelse(x=="E",data$weight,NA)))

colnames(datatransfer)<-c("id","weight","letter","A","B","C","D","E")
much appreciate the help,

thanks

Andras?

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  

	[[alternative HTML version deleted]]


From li@@_1995_@ @ending from hotm@il@com  Mon Jan  7 13:11:34 2019
From: li@@_1995_@ @ending from hotm@il@com (Lisa Snel)
Date: Mon, 7 Jan 2019 12:11:34 +0000
Subject: [R] 
 How to perform Mixed Design ANOVA on MICE imputed dataset in R?
In-Reply-To: <CAGxFJbTp5rfYy_5VJXMFSv-9KDRFx=ngwVk=eQ4tpLk7=hYRwQ@mail.gmail.com>
References: <AM4PR0501MB225867957487A2EB9D3EDC84AF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>
 <CA+vqiLHJMzqV7Xp8zprm-7EbgqnTQWorFfLyc9u7Uy+0g-S0RQ@mail.gmail.com>
 <AM4PR0501MB22586874CFD42AD81530BDBCAF8E0@AM4PR0501MB2258.eurprd05.prod.outlook.com>,
 <CAGxFJbTp5rfYy_5VJXMFSv-9KDRFx=ngwVk=eQ4tpLk7=hYRwQ@mail.gmail.com>
Message-ID: <AM4PR0501MB22582FE05DF8811F9F7BF247AF890@AM4PR0501MB2258.eurprd05.prod.outlook.com>

Dear Bert,

Thank you for the tip, I am going to try it there!

Best,
Lisa
________________________________
Van: Bert Gunter <bgunter.4567 at gmail.com>
Verzonden: vrijdag 4 januari 2019 17:09
Aan: Lisa Snel
CC: Ista Zahn; r-help at r-project.org
Onderwerp: Re: [R] How to perform Mixed Design ANOVA on MICE imputed dataset in R?

You might wish to post on the r-sig-mixed-models list, which is specifically devoted to mixed effects models, instead of here. You are more likely to find both interest and expertise there.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 4, 2019 at 7:49 AM Lisa Snel <lisa_1995_s at hotmail.com<mailto:lisa_1995_s at hotmail.com>> wrote:
Dear Ista,

Thank you for your response and the link you have sent me. However, I know the basic things of the MICE package (how impute, to pool and to do basic analyses), but the problem is that I cannot find anything about this specific analysis.

Best,
Lisa
________________________________
Van: Ista Zahn <istazahn at gmail.com<mailto:istazahn at gmail.com>>
Verzonden: vrijdag 4 januari 2019 15:11
Aan: Lisa Snel
CC: r-help at r-project.org<mailto:r-help at r-project.org>
Onderwerp: Re: [R] How to perform Mixed Design ANOVA on MICE imputed dataset in R?

Hi Lisa,

The package web page at http://stefvanbuuren.github.io/mice/ has all
the info you need to get started.

Best,
Ista

On Fri, Jan 4, 2019 at 3:29 AM Lisa Snel <lisa_1995_s at hotmail.com<mailto:lisa_1995_s at hotmail.com>> wrote:
>
> Hi all,
>
> I have a question about performing a Mixed Design ANOVA in R after multiple imputation using MICE. My data is as follows:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,88,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,65,64,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,83,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> So: we have 6 repeated measurements of diastolic blood pressure (measure 1 till 6). The grouping factor is gender, which is called group. This variable is coded 1 if male and 0 if female. Before multiple imputation, we have used the following code in R:
>
> library(reshape)
> library(reshape2)
> datLong <- melt(dat, id = c("id", "group"), measured = c("measure_1", "measure_2", "measure_3", "measure_4", "measure_5", "measure_6"))
> datLong
>
> colnames(datLong) <- c("ID", "Gender", "Time", "Score")
> datLong
> table(datLong$Time)
> datLong$ID <- as.factor(datLong$ID)
>
> library(ez)
> model_mixed <- ezANOVA(data = datLong,
>                dv = Value,
>                wid = ID,
>                within = Time,
>                between = Gender,
>                detailed = TRUE,
>                type = 3,
>                return_aov = TRUE)
> model_mixed
>
> This worked perfectly. However, our data is not complete. We have missing values, that we impute using MICE:
>
> id <- c(1,2,3,4,5,6,7,8,9,10)
> group <- c(0,1,1,0,0,1,0,0,0,1)
> measure_1 <- c(60,80,90,54,60,61,77,67,88,90)
> measure_2 <- c(55,NA,88,55,70,62,78,66,65,92)
> measure_3 <- c(58,88,85,56,68,62,89,62,70,99)
> measure_4 <- c(64,80,78,92,NA,NA,87,65,67,96)
> measure_5 <- c(64,85,80,65,74,69,90,65,70,99)
> measure_6 <- c(70,NA,80,55,73,64,91,65,91,89)
> dat <- data.frame(id, group, measure_1, measure_2, measure_3, measure_4, measure_5, measure_6)
> dat$group <- as.factor(dat$group)
>
> imp_anova <- mice(dat, maxit = 0)
> meth <- imp_anova$method
> pred <- imp_anova$predictorMatrix
> imp_anova <- mice(dat, method = meth, predictorMatrix = pred, seed = 2018, maxit = 10, m = 5)
>
> (The imputation gives logged events, because of the made-up data and the simple imputation code e.g id used as a predictor. For my real data, the imputation was correct and valid)
>
> Now I have the imputed dataset of class ?mids?. I have searched the internet, but I cannot find how I can perform the mixed design ANOVA on this imputed set, as I did before with the complete set using ezANOVA. Is there anyone who can and wants to help me?
>
>
> Best,
>
> Lisa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@rongiu@luigi @ending from gm@il@com  Mon Jan  7 13:26:20 2019
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Mon, 7 Jan 2019 13:26:20 +0100
Subject: [R] error in plotting model from kernlab
Message-ID: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>

Dear all,
I have a set of data in this form:
> str <data>
'data.frame': 1574 obs. of  14 variables:
 $ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934 3999 ...
 $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
 $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
 $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
 $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK" "Astro
2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
 $ ori.ct: num  0 33.5 0 0 0 ...
 $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
 $ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004 ...
 $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
 $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
 $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
 $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
 $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
 $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
from which I have selected two numerical variables correspondig to x
and y in a Cartesian plane and one outcome variable (z):
> df = subset(t.data, select = c(mr, fcn, cons))
>  df$cons = factor(c("negative", "positive"))
> head(df)
      mr   fcn     cons
1 -0.002 44.54 negative
2  0.109 36.74 positive
3  0.002  6.78 negative
4  0.000 43.09 positive
5  0.001 44.87 negative
6  0.006  2.82 positive

I created an SVM the method with the KERNLAB package with:
> mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "." but the outcome is the same
            data = df,
            type = "C-bsvc",
            kernel = "rbfdot",
            kpar = "automatic",
            C = 10,
            prob.model = TRUE)

> mod
Support Vector Machine object of class "ksvm"

SV type: C-bsvc  (classification)
 parameter : cost C = 10

Gaussian Radial Basis kernel function.
 Hyperparameter : sigma =  42.0923201429106

Number of Support Vectors : 1439

Objective Function Value : -12873.45
Training error : 0.39263
Probability model included.

First of all, I am not sure if the model worked because 1439 support
vectors out of 1574 data points means that over 90% of the data is
required to fix the hyperplane. this does not look like a model but a
patch. Secondly, the prediction is rubbish -- but this is another
story -- and when I try to create a confusion table of the processed
data I get:
>  pred = predict(mod, df, type = "probabilities")
>  acc = table(pred, df$cons)
Error in table(pred, df$cons) : all arguments must have the same length
which again is weird since mod, df and df$cons are made from the same dataframe.

Coming to the actual error, I tried to plot the model with:
> plot(mod, data = df)
> kernlab::plot(mod, data = df)
but I get this error:

Error in .local(x, ...) :
  Only plots of classification ksvm objects supported

Would you know what I am missing?
Thank you
-- 
Best regards,
Luigi


From g@l@xie2485 @ending from y@hoo@co@in  Mon Jan  7 13:49:04 2019
From: g@l@xie2485 @ending from y@hoo@co@in (Priya Arasu)
Date: Mon, 7 Jan 2019 12:49:04 +0000 (UTC)
Subject: [R] Merge the data from multiple text files
References: <1954244071.13510682.1546865344431.ref@mail.yahoo.com>
Message-ID: <1954244071.13510682.1546865344431@mail.yahoo.com>

Thank you David Winsemius and David L Carlson.?
@David L Carlson, Thank you for the code. I have one more issue, while merging the files. Please advice.For example
In text file 1:
A = not(B or C)B = A and CC = D
In text file 2:
A = not(C or D) and (D and E)

So when I merge using your code, it merges A = not(B or C) and (D and E). How do I merge A as A= not(B or C or D) and (D and E) ???I also have duplicates like A= not(B or C) and not (C or D) instead as A= not(B or C or D)?ThanksPriya 

    On Sunday, 6 January 2019 4:39 AM, David L Carlson <dcarlson at tamu.edu> wrote:
 

 To expand on David W's answer, here is an approach to your example. If you have many text files, you would want to process them together rather than individually. You gave us two examples so I'll use those and read them from the console using readLines(), but you would use the same function to open the files on your computer:

> TF1 <- readLines(n=3)
A = not(B or C)
B = A and C
C = D
> 
> TF2 <- readLines(n=2)
A = D and E
B = not(D)
> 
> TF <- sort(c(TF1, TF2))
> TF
[1] "A = D and E"? ? "A = not(B or C)" "B = A and C"? ? "B = not(D)"
[5] "C = D"

Now we have combined the files into a single character vector called TF and sorted them. Next we need to parse them into the left and right hand sides. We will replace " = " with "\t" (tab) to do that:

> TF.delim <- gsub(" = ", "\t", TF)
> TF.data <- read.delim(text=TF.delim, header=FALSE, as.is=TRUE)
> colnames(TF.data) <- c("LHS", "RHS")
> print(TF.data, right=FALSE)
? LHS RHS
1 A? D and E
2 A? not(B or C)
3 B? A and C
4 B? not(D)
5 C? D

TF.data is a data frame with two columns. The tricky part is to add surrounding parentheses to rows 1 and 3 to get your example output:

> paren1 <- grepl("and", TF.data$RHS)
> paren2 <- !grepl("\\(*\\)", TF.data$RHS)
> paren <- apply(cbind(paren1, paren2), 1, all)
> TF.data$RHS[paren] <- paste0("(", TF.data$RHS[paren], ")")
> print(TF.data, right=FALSE)
? LHS RHS
1 A? (D and E)
2 A? not(B or C)
3 B? (A and C)
4 B? not(D)
5 C? D

The first three lines identify the rows that have the word "and" but do not already have parentheses. The fourth line adds the surrounding parentheses. Finally we will combine the rows that belong to the same LHS value with split and create a list:

> TF.list <- split(TF.data$RHS, TF.data$LHS)
> TF.list
$`A`
[1] "(D and E)"? "not(B or C)"

$B
[1] "(A and C)" "not(D)"? 

$C
[1] "D"

> TF.and <- lapply(TF.list, paste, collapse=" and ")
> TF.final <- lapply(names(TF.and), function(x) paste(x, "=", TF.and[[x]]))
> TF.final <- do.call(rbind, TF.final)
> TF.final
? ? [,1]? ? ? ? ? ? ? ? ? ? ? ? ? 
[1,] "A = (D and E) and not(B or C)"
[2,] "B = (A and C) and not(D)"
[3,] "C = D"
> write(TF.final, file="TF.output.txt")

The text file "TF.output.txt" contains the three lines.

----------------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Saturday, January 5, 2019 1:12 PM

Subject: Re: [R] Merge the data from multiple text files


On 1/5/19 7:28 AM, Priya Arasu via R-help wrote:
> I have multiple text files, where each file has Boolean rules.
> Example of my text file 1 and 2
> Text file 1:
> A = not(B or C)
> B = A and C
> C = D
> Text file 2:
> A = D and E
> B = not(D)
>
> I want to merge the contents in text file as follows
> A = not(B or C) and (D and E)
> B = not(D) and (A and C)
> C = D
> Is there a code in R to merge the data from multiple text files?


There is a `merge` function. For this use case you would need to first 
parse your expressions so that the LHS was in one character column and 
the RHS was in another character column in each of 2 dataframes. Then 
merge on the LHS columns and `paste` matching values from the two 
columns. You will probably need to learn how to use `ifelse` and `is.na`.

> Thank you
> Priya
>
> ??? [[alternative HTML version deleted]]


You also need to learn that R is a plain text mailing list and that each 
mail client has its own method for building mail in plain text.


-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From high@t@t @ending from high@t@t@com  Mon Jan  7 15:37:56 2019
From: high@t@t @ending from high@t@t@com (Highland Statistics Ltd)
Date: Mon, 7 Jan 2019 06:37:56 -0800
Subject: [R] Two statistics courses in Lisbon
Message-ID: <5a29d28e-7408-4915-cba5-19f3adb6b452@highstat.com>

Apologies for cross-posting

We would like to announce the following two statistics course in Lisbon.

Course: Data exploration, regression, GLM & GAM with introduction to R
Where:? Lisbon, Portugal.
When:?? 18-22 February 2019
Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2019/Flyer2019_02Lisbon_RGG.pdf


Course: Introduction to GAM and GAMM with R.
Where:? Lisbon, Portugal.
When:?? 25 February 2019 - 1 March 2019
Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2019/Flyer2019_02Lisbon_GAMM_V3.pdf

Kind regards,


Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jan  7 17:47:48 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 07 Jan 2019 08:47:48 -0800
Subject: [R] error in plotting model from kernlab
In-Reply-To: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
References: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
Message-ID: <048CE786-3666-4A13-9858-8FCF37ECF4BB@dcn.davis.ca.us>

a) When re-posting a question, whether on the same or different forums, it is best practice (netiquette) to link to or reply to the earlier question. [1]

b) Note the guidance in the Posting Guide:

For questions about functions in standard packages distributed with R (see the FAQ?Add-on packages in R), ask questions on R-help.
If the question relates to a?contributed package?, e.g., one downloaded from CRAN, try contacting the package maintainer first. You can also use?find("functionname")?and?packageDescription("packagename")?to find this information.?Only?send such questions to R-help or R-devel if you get no reply or need further assistance. This applies to both requests for help and to bug reports.

You have not communicated whether you have followed this recommendation.

[1] https://stat.ethz.ch/pipermail/r-help/2018-December/461010.html

On January 7, 2019 4:26:20 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Dear all,
>I have a set of data in this form:
>> str <data>
>'data.frame': 1574 obs. of  14 variables:
>$ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934 3999
>...
> $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
> $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
> $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
> $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK" "Astro
>2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
> $ ori.ct: num  0 33.5 0 0 0 ...
> $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
>$ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004
>...
> $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
> $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
> $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
> $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
> $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
> $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
>from which I have selected two numerical variables correspondig to x
>and y in a Cartesian plane and one outcome variable (z):
>> df = subset(t.data, select = c(mr, fcn, cons))
>>  df$cons = factor(c("negative", "positive"))
>> head(df)
>      mr   fcn     cons
>1 -0.002 44.54 negative
>2  0.109 36.74 positive
>3  0.002  6.78 negative
>4  0.000 43.09 positive
>5  0.001 44.87 negative
>6  0.006  2.82 positive
>
>I created an SVM the method with the KERNLAB package with:
>> mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "." but
>the outcome is the same
>            data = df,
>            type = "C-bsvc",
>            kernel = "rbfdot",
>            kpar = "automatic",
>            C = 10,
>            prob.model = TRUE)
>
>> mod
>Support Vector Machine object of class "ksvm"
>
>SV type: C-bsvc  (classification)
> parameter : cost C = 10
>
>Gaussian Radial Basis kernel function.
> Hyperparameter : sigma =  42.0923201429106
>
>Number of Support Vectors : 1439
>
>Objective Function Value : -12873.45
>Training error : 0.39263
>Probability model included.
>
>First of all, I am not sure if the model worked because 1439 support
>vectors out of 1574 data points means that over 90% of the data is
>required to fix the hyperplane. this does not look like a model but a
>patch. Secondly, the prediction is rubbish -- but this is another
>story -- and when I try to create a confusion table of the processed
>data I get:
>>  pred = predict(mod, df, type = "probabilities")
>>  acc = table(pred, df$cons)
>Error in table(pred, df$cons) : all arguments must have the same length
>which again is weird since mod, df and df$cons are made from the same
>dataframe.
>
>Coming to the actual error, I tried to plot the model with:
>> plot(mod, data = df)
>> kernlab::plot(mod, data = df)
>but I get this error:
>
>Error in .local(x, ...) :
>  Only plots of classification ksvm objects supported
>
>Would you know what I am missing?
>Thank you

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jan  7 18:04:11 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 07 Jan 2019 09:04:11 -0800
Subject: [R] Merge the data from multiple text files
In-Reply-To: <1954244071.13510682.1546865344431@mail.yahoo.com>
References: <1954244071.13510682.1546865344431.ref@mail.yahoo.com>
 <1954244071.13510682.1546865344431@mail.yahoo.com>
Message-ID: <96D9E736-DF08-4F19-99EE-B1B39C190414@dcn.davis.ca.us>

I think it is rather presumptuous of you to think that anyone is going to write an expression optimizer for some unspecified language on the R-help mailing list. I am sure that such tasks can be handled in R, but it is non-trivial and the background needed would be very off-topic here.

On January 7, 2019 4:49:04 AM PST, Priya Arasu via R-help <r-help at r-project.org> wrote:
>Thank you David Winsemius and David L Carlson.?
>@David L Carlson, Thank you for the code. I have one more issue, while
>merging the files. Please advice.For example
>In text file 1:
>A = not(B or C)B = A and CC = D
>In text file 2:
>A = not(C or D) and (D and E)
>
>So when I merge using your code, it merges A = not(B or C) and (D and
>E). How do I merge A as A= not(B or C or D) and (D and E) ???I also
>have duplicates like A= not(B or C) and not (C or D) instead as A=
>not(B or C or D)?ThanksPriya 
>
>On Sunday, 6 January 2019 4:39 AM, David L Carlson <dcarlson at tamu.edu>
>wrote:
> 
>
>To expand on David W's answer, here is an approach to your example. If
>you have many text files, you would want to process them together
>rather than individually. You gave us two examples so I'll use those
>and read them from the console using readLines(), but you would use the
>same function to open the files on your computer:
>
>> TF1 <- readLines(n=3)
>A = not(B or C)
>B = A and C
>C = D
>> 
>> TF2 <- readLines(n=2)
>A = D and E
>B = not(D)
>> 
>> TF <- sort(c(TF1, TF2))
>> TF
>[1] "A = D and E"? ? "A = not(B or C)" "B = A and C"? ? "B = not(D)"
>[5] "C = D"
>
>Now we have combined the files into a single character vector called TF
>and sorted them. Next we need to parse them into the left and right
>hand sides. We will replace " = " with "\t" (tab) to do that:
>
>> TF.delim <- gsub(" = ", "\t", TF)
>> TF.data <- read.delim(text=TF.delim, header=FALSE, as.is=TRUE)
>> colnames(TF.data) <- c("LHS", "RHS")
>> print(TF.data, right=FALSE)
>? LHS RHS
>1 A? D and E
>2 A? not(B or C)
>3 B? A and C
>4 B? not(D)
>5 C? D
>
>TF.data is a data frame with two columns. The tricky part is to add
>surrounding parentheses to rows 1 and 3 to get your example output:
>
>> paren1 <- grepl("and", TF.data$RHS)
>> paren2 <- !grepl("\\(*\\)", TF.data$RHS)
>> paren <- apply(cbind(paren1, paren2), 1, all)
>> TF.data$RHS[paren] <- paste0("(", TF.data$RHS[paren], ")")
>> print(TF.data, right=FALSE)
>? LHS RHS
>1 A? (D and E)
>2 A? not(B or C)
>3 B? (A and C)
>4 B? not(D)
>5 C? D
>
>The first three lines identify the rows that have the word "and" but do
>not already have parentheses. The fourth line adds the surrounding
>parentheses. Finally we will combine the rows that belong to the same
>LHS value with split and create a list:
>
>> TF.list <- split(TF.data$RHS, TF.data$LHS)
>> TF.list
>$`A`
>[1] "(D and E)"? "not(B or C)"
>
>$B
>[1] "(A and C)" "not(D)"? 
>
>$C
>[1] "D"
>
>> TF.and <- lapply(TF.list, paste, collapse=" and ")
>> TF.final <- lapply(names(TF.and), function(x) paste(x, "=",
>TF.and[[x]]))
>> TF.final <- do.call(rbind, TF.final)
>> TF.final
>? ? [,1]? ? ? ? ? ? ? ? ? ? ? ? ? 
>[1,] "A = (D and E) and not(B or C)"
>[2,] "B = (A and C) and not(D)"
>[3,] "C = D"
>> write(TF.final, file="TF.output.txt")
>
>The text file "TF.output.txt" contains the three lines.
>
>----------------------------------------------
>David L. Carlson
>Department of Anthropology
>Texas A&M University
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
>Winsemius
>Sent: Saturday, January 5, 2019 1:12 PM
>
>Subject: Re: [R] Merge the data from multiple text files
>
>
>On 1/5/19 7:28 AM, Priya Arasu via R-help wrote:
>> I have multiple text files, where each file has Boolean rules.
>> Example of my text file 1 and 2
>> Text file 1:
>> A = not(B or C)
>> B = A and C
>> C = D
>> Text file 2:
>> A = D and E
>> B = not(D)
>>
>> I want to merge the contents in text file as follows
>> A = not(B or C) and (D and E)
>> B = not(D) and (A and C)
>> C = D
>> Is there a code in R to merge the data from multiple text files?
>
>
>There is a `merge` function. For this use case you would need to first 
>parse your expressions so that the LHS was in one character column and 
>the RHS was in another character column in each of 2 dataframes. Then 
>merge on the LHS columns and `paste` matching values from the two 
>columns. You will probably need to learn how to use `ifelse` and
>`is.na`.
>
>> Thank you
>> Priya
>>
>> ??? [[alternative HTML version deleted]]
>
>
>You also need to learn that R is a plain text mailing list and that
>each 
>mail client has its own method for building mail in plain text.

-- 
Sent from my phone. Please excuse my brevity.


From dc@rl@on @ending from t@mu@edu  Mon Jan  7 19:49:27 2019
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 7 Jan 2019 18:49:27 +0000
Subject: [R] Merge the data from multiple text files
In-Reply-To: <96D9E736-DF08-4F19-99EE-B1B39C190414@dcn.davis.ca.us>
References: <1954244071.13510682.1546865344431.ref@mail.yahoo.com>
 <1954244071.13510682.1546865344431@mail.yahoo.com>
 <96D9E736-DF08-4F19-99EE-B1B39C190414@dcn.davis.ca.us>
Message-ID: <81c4140ca203420fb5dfc2e6b1be296e@tamu.edu>

Thank you. I couldn't have said it better myself. It would probably be simpler if you process the lines first to remove duplicates and break compound statements into simple statements. Even then it will be a challenge to not end up with statements that are internally contradictory, e.g. (A and B) and not(B).

David C

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, January 7, 2019 11:04 AM
To: Priya Arasu <galaxie2485 at yahoo.co.in>; Priya Arasu via R-help <r-help at r-project.org>; David L Carlson <dcarlson at tamu.edu>; David Winsemius <dwinsemius at comcast.net>; r-help at r-project.org
Subject: Re: [R] Merge the data from multiple text files

I think it is rather presumptuous of you to think that anyone is going to write an expression optimizer for some unspecified language on the R-help mailing list. I am sure that such tasks can be handled in R, but it is non-trivial and the background needed would be very off-topic here.

On January 7, 2019 4:49:04 AM PST, Priya Arasu via R-help <r-help at r-project.org> wrote:
>Thank you David Winsemius and David L Carlson.?
>@David L Carlson, Thank you for the code. I have one more issue, while
>merging the files. Please advice.For example
>In text file 1:
>A = not(B or C)B = A and CC = D
>In text file 2:
>A = not(C or D) and (D and E)
>
>So when I merge using your code, it merges A = not(B or C) and (D and
>E). How do I merge A as A= not(B or C or D) and (D and E) ???I also
>have duplicates like A= not(B or C) and not (C or D) instead as A=
>not(B or C or D)?ThanksPriya 
>
>On Sunday, 6 January 2019 4:39 AM, David L Carlson <dcarlson at tamu.edu>
>wrote:
> 
>
>To expand on David W's answer, here is an approach to your example. If
>you have many text files, you would want to process them together
>rather than individually. You gave us two examples so I'll use those
>and read them from the console using readLines(), but you would use the
>same function to open the files on your computer:
>
>> TF1 <- readLines(n=3)
>A = not(B or C)
>B = A and C
>C = D
>> 
>> TF2 <- readLines(n=2)
>A = D and E
>B = not(D)
>> 
>> TF <- sort(c(TF1, TF2))
>> TF
>[1] "A = D and E"? ? "A = not(B or C)" "B = A and C"? ? "B = not(D)"
>[5] "C = D"
>
>Now we have combined the files into a single character vector called TF
>and sorted them. Next we need to parse them into the left and right
>hand sides. We will replace " = " with "\t" (tab) to do that:
>
>> TF.delim <- gsub(" = ", "\t", TF)
>> TF.data <- read.delim(text=TF.delim, header=FALSE, as.is=TRUE)
>> colnames(TF.data) <- c("LHS", "RHS")
>> print(TF.data, right=FALSE)
>? LHS RHS
>1 A? D and E
>2 A? not(B or C)
>3 B? A and C
>4 B? not(D)
>5 C? D
>
>TF.data is a data frame with two columns. The tricky part is to add
>surrounding parentheses to rows 1 and 3 to get your example output:
>
>> paren1 <- grepl("and", TF.data$RHS)
>> paren2 <- !grepl("\\(*\\)", TF.data$RHS)
>> paren <- apply(cbind(paren1, paren2), 1, all)
>> TF.data$RHS[paren] <- paste0("(", TF.data$RHS[paren], ")")
>> print(TF.data, right=FALSE)
>? LHS RHS
>1 A? (D and E)
>2 A? not(B or C)
>3 B? (A and C)
>4 B? not(D)
>5 C? D
>
>The first three lines identify the rows that have the word "and" but do
>not already have parentheses. The fourth line adds the surrounding
>parentheses. Finally we will combine the rows that belong to the same
>LHS value with split and create a list:
>
>> TF.list <- split(TF.data$RHS, TF.data$LHS)
>> TF.list
>$`A`
>[1] "(D and E)"? "not(B or C)"
>
>$B
>[1] "(A and C)" "not(D)"? 
>
>$C
>[1] "D"
>
>> TF.and <- lapply(TF.list, paste, collapse=" and ")
>> TF.final <- lapply(names(TF.and), function(x) paste(x, "=",
>TF.and[[x]]))
>> TF.final <- do.call(rbind, TF.final)
>> TF.final
>? ? [,1]? ? ? ? ? ? ? ? ? ? ? ? ? 
>[1,] "A = (D and E) and not(B or C)"
>[2,] "B = (A and C) and not(D)"
>[3,] "C = D"
>> write(TF.final, file="TF.output.txt")
>
>The text file "TF.output.txt" contains the three lines.
>
>----------------------------------------------
>David L. Carlson
>Department of Anthropology
>Texas A&M University
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
>Winsemius
>Sent: Saturday, January 5, 2019 1:12 PM
>
>Subject: Re: [R] Merge the data from multiple text files
>
>
>On 1/5/19 7:28 AM, Priya Arasu via R-help wrote:
>> I have multiple text files, where each file has Boolean rules.
>> Example of my text file 1 and 2
>> Text file 1:
>> A = not(B or C)
>> B = A and C
>> C = D
>> Text file 2:
>> A = D and E
>> B = not(D)
>>
>> I want to merge the contents in text file as follows
>> A = not(B or C) and (D and E)
>> B = not(D) and (A and C)
>> C = D
>> Is there a code in R to merge the data from multiple text files?
>
>
>There is a `merge` function. For this use case you would need to first 
>parse your expressions so that the LHS was in one character column and 
>the RHS was in another character column in each of 2 dataframes. Then 
>merge on the LHS columns and `paste` matching values from the two 
>columns. You will probably need to learn how to use `ifelse` and
>`is.na`.
>
>> Thank you
>> Priya
>>
>> ??? [[alternative HTML version deleted]]
>
>
>You also need to learn that R is a plain text mailing list and that
>each 
>mail client has its own method for building mail in plain text.

-- 
Sent from my phone. Please excuse my brevity.

From m@rongiu@luigi @ending from gm@il@com  Mon Jan  7 20:09:11 2019
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Mon, 7 Jan 2019 20:09:11 +0100
Subject: [R] error in plotting model from kernlab
In-Reply-To: <048CE786-3666-4A13-9858-8FCF37ECF4BB@dcn.davis.ca.us>
References: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
 <048CE786-3666-4A13-9858-8FCF37ECF4BB@dcn.davis.ca.us>
Message-ID: <CAMk+s2RtjrkryYc1hJ9R4GB2epQC4A3P7UPPxX2tXHYhF7TjdA@mail.gmail.com>

Sorry but I don't understand the questions. I sent this question to
R-help, not to an individual. I will use the REPLY TO ALL function
when replying, apologies if I missed before. The question is related
to an R package so I placed to the R community.

On Mon, Jan 7, 2019 at 5:47 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> a) When re-posting a question, whether on the same or different forums, it is best practice (netiquette) to link to or reply to the earlier question. [1]
>
> b) Note the guidance in the Posting Guide:
>
> For questions about functions in standard packages distributed with R (see the FAQ Add-on packages in R), ask questions on R-help.
> If the question relates to a contributed package , e.g., one downloaded from CRAN, try contacting the package maintainer first. You can also use find("functionname") and packageDescription("packagename") to find this information. Only send such questions to R-help or R-devel if you get no reply or need further assistance. This applies to both requests for help and to bug reports.
>
> You have not communicated whether you have followed this recommendation.
>
> [1] https://stat.ethz.ch/pipermail/r-help/2018-December/461010.html
>
> On January 7, 2019 4:26:20 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >Dear all,
> >I have a set of data in this form:
> >> str <data>
> >'data.frame': 1574 obs. of  14 variables:
> >$ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934 3999
> >...
> > $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
> > $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
> > $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
> > $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK" "Astro
> >2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
> > $ ori.ct: num  0 33.5 0 0 0 ...
> > $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
> >$ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004
> >...
> > $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
> > $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
> > $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
> > $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
> > $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
> > $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
> >from which I have selected two numerical variables correspondig to x
> >and y in a Cartesian plane and one outcome variable (z):
> >> df = subset(t.data, select = c(mr, fcn, cons))
> >>  df$cons = factor(c("negative", "positive"))
> >> head(df)
> >      mr   fcn     cons
> >1 -0.002 44.54 negative
> >2  0.109 36.74 positive
> >3  0.002  6.78 negative
> >4  0.000 43.09 positive
> >5  0.001 44.87 negative
> >6  0.006  2.82 positive
> >
> >I created an SVM the method with the KERNLAB package with:
> >> mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "." but
> >the outcome is the same
> >            data = df,
> >            type = "C-bsvc",
> >            kernel = "rbfdot",
> >            kpar = "automatic",
> >            C = 10,
> >            prob.model = TRUE)
> >
> >> mod
> >Support Vector Machine object of class "ksvm"
> >
> >SV type: C-bsvc  (classification)
> > parameter : cost C = 10
> >
> >Gaussian Radial Basis kernel function.
> > Hyperparameter : sigma =  42.0923201429106
> >
> >Number of Support Vectors : 1439
> >
> >Objective Function Value : -12873.45
> >Training error : 0.39263
> >Probability model included.
> >
> >First of all, I am not sure if the model worked because 1439 support
> >vectors out of 1574 data points means that over 90% of the data is
> >required to fix the hyperplane. this does not look like a model but a
> >patch. Secondly, the prediction is rubbish -- but this is another
> >story -- and when I try to create a confusion table of the processed
> >data I get:
> >>  pred = predict(mod, df, type = "probabilities")
> >>  acc = table(pred, df$cons)
> >Error in table(pred, df$cons) : all arguments must have the same length
> >which again is weird since mod, df and df$cons are made from the same
> >dataframe.
> >
> >Coming to the actual error, I tried to plot the model with:
> >> plot(mod, data = df)
> >> kernlab::plot(mod, data = df)
> >but I get this error:
> >
> >Error in .local(x, ...) :
> >  Only plots of classification ksvm objects supported
> >
> >Would you know what I am missing?
> >Thank you
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Best regards,
Luigi


From v@rin@@ch@ @ending from y@hoo@fr  Mon Jan  7 21:28:45 2019
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Mon, 7 Jan 2019 20:28:45 +0000 (UTC)
Subject: [R] Fit CMARS with R possible (Packages) ?
In-Reply-To: <F5AEBA61-BB59-47E2-B17C-3CB646F36A00@me.com>
References: <841297769.20570830.1546630262854.ref@mail.yahoo.com>
 <841297769.20570830.1546630262854@mail.yahoo.com>
 <CAGxFJbR3KBi8BQi1j9O4e5=AC0ifi0ND-vQ6BDHVoUZkJhigyA@mail.gmail.com>
 <F5AEBA61-BB59-47E2-B17C-3CB646F36A00@me.com>
Message-ID: <2037023136.22868054.1546892925219@mail.yahoo.com>

Dear Bert, Dear Marc,

Many thanks for your feedbacks.

Best,






Le samedi 5 janvier 2019 ? 00:26:47 UTC+1, Marc Schwartz <marc_schwartz at me.com> a ?crit : 





Hi,

Like Bert, I was not able to find anything built in R.

It is possible that CMARS has not yet been implemented in R, or may be in development but not yet ready for release.

I found several references to the use of MOSEK (https://www.mosek.com) along with MATLAB, but both are commercial products.

The MOSEK developers appear to have an Rmosek interface package:

? https://docs.mosek.com/8.1/rmosek/index.html

which provides access to the MOSEK functionality via R. But, it requires MOSEK...

Perhaps others with more refined knowledge will jump in. It might also be reasonable to consider contacting what appears to be a small-ish group of common authors that I came across in the search who have described the methodology (e.g. Taylan or Yerlikaya-?zkurt) to see if they are aware of any R implementations.

Regards,

Marc Schwartz


> On Jan 4, 2019, at 5:16 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> rseek.org might be a better place to search if you haven't tried t
> herealready. However, my minimal effort there did not turn up any R
> software.? Maybe you can do better.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Jan 4, 2019 at 11:31 AM varin sacha via R-help <r-help at r-project.org>
> wrote:
> 
>> Dear R-experts,
>> 
>> We can fit MARS regression using the packages "earth" and/or "mda" or
>> others packages.
>> However, I am wondering if it is possible to fit a CMARS (Conic
>> multivariate adaptive regression splines) using R ?
>> I have googled "conic MARS with R software", I did not get anything, so
>> Google is not my friend anymore !
>> 
>> If you have any solution, would be highly appreciated.
>> 
>> Best,


From v@rin@@ch@ @ending from y@hoo@fr  Tue Jan  8 00:35:42 2019
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Mon, 7 Jan 2019 23:35:42 +0000 (UTC)
Subject: [R] mgcv : 3-way interaction and 3D-plots ?
References: <1762425263.20633289.1546904142187.ref@mail.yahoo.com>
Message-ID: <1762425263.20633289.1546904142187@mail.yahoo.com>

Dear R-experts,

I have fitted a model with 2-way and 3-way interactions. 
I would like, for the 3-way interaction (year,age,by=education), to obtain 3D-plots. How could I do that ?

Many thanks for your response.

Here is the reproducible example:

############# 
install.packages("ISLR")

library(ISLR)

install.packages("mgcv")

library(mgcv)

mod1<-gam(wage ~education+s(age,bs="ps")+year+te(age,year,bs="ps")+s(year,bs="ps",by=education,m=1)+te(year,age,by=education,bs=rep("ps",2)),data=Wage)

plot(mod1)
#############


From dwin@emiu@ @ending from comc@@t@net  Tue Jan  8 01:59:00 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 7 Jan 2019 16:59:00 -0800
Subject: [R] mgcv : 3-way interaction and 3D-plots ?
In-Reply-To: <1762425263.20633289.1546904142187@mail.yahoo.com>
References: <1762425263.20633289.1546904142187.ref@mail.yahoo.com>
 <1762425263.20633289.1546904142187@mail.yahoo.com>
Message-ID: <db4db4b4-82ab-1976-908d-618df3957cc8@comcast.net>


On 1/7/19 3:35 PM, varin sacha via R-help wrote:
> Dear R-experts,
>
> I have fitted a model with 2-way and 3-way interactions.
> I would like, for the 3-way interaction (year,age,by=education), to obtain 3D-plots. How could I do that ?

Forget ggplot2. It has ignored this sort of visualization effort. Use 
lattice or base plotting methods.


In order to plot a 2way interaction one needs a pseudo-3way plot 
(`wireframe`) or a single `levelplot`. For display of a 3way interaction 
in lattice (given the human minds inability to "see" in 4 dimensions) 
you will need to specify levels for one of the variables to display 
slices perhaps using multiple displays of 2way "sub-interactions" 
calculated ad meaningul levels of the variable you choose to slive 
with.? I'm not sure what the "native" plotting method for pkg:mgcv might 
be. I suspect it was base graphics,; if so, look at ?persp and ?contour.

-- 

David

>
> Many thanks for your response.
>
> Here is the reproducible example:
>
> #############
> install.packages("ISLR")
>
> library(ISLR)
>
> install.packages("mgcv")
>
> library(mgcv)
>
> mod1<-gam(wage ~education+s(age,bs="ps")+year+te(age,year,bs="ps")+s(year,bs="ps",by=education,m=1)+te(year,age,by=education,bs=rep("ps",2)),data=Wage)
>
> plot(mod1)
> #############
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @ending from temple@edu  Tue Jan  8 04:25:04 2019
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Mon, 7 Jan 2019 22:25:04 -0500
Subject: [R] mgcv : 3-way interaction and 3D-plots ?
In-Reply-To: <db4db4b4-82ab-1976-908d-618df3957cc8@comcast.net>
References: <1762425263.20633289.1546904142187.ref@mail.yahoo.com>
 <1762425263.20633289.1546904142187@mail.yahoo.com>
 <db4db4b4-82ab-1976-908d-618df3957cc8@comcast.net>
Message-ID: <CAGx1TMC8z1xE0n0qXXG-+o4zgO4RnTWv5+1h5MTVrdOXdfGXJQ@mail.gmail.com>

## Here is an example using the 3-way interaction plot from the HH package


install.packages("HH") ## if necessary

## The HH package supports the book
## Statistical Analysis and Data Display
##    Richard M. Heiberger and Burt Holland
## http://www.springer.com/us/book/9781493921218

library(HH)
## find the pathname of the R script file dsgn.R containing this example
HHscriptnames(13)
## open the file dsgn.R in your favorite editor.


## Then run

## chunk 2,
## chunk 3, Figure 13.1
## chunk 4  Table 13.1
## chunk 7  Figure 13.3  three-way interactions

## Rows of the array of panels are                  current
## Columns of the array of panels are               n.treats
## differently colored boxes within each panel are  minutes
##
## In this example the 3-way interaction is not significant.
## For a hint of what one could see, compare the panel "60.cycle x 3"
## with "60.cycle x 6".  In "60.cycle x 3", the red box at minutes=5 is
## higher than the other three boxes.  In "60.cycle x 6", the red box at
## minutes=5 is lower than the other boxes.


## Illustrate a minimalist form of this call.
## Create a dataset with simple variable names Y, A, B, C
mydata <- data.frame(Y=cc176$y.adj,
                     A=unpositioned(cc176$minutes),
                     B=cc176$n.treats,
                     C=cc176$current)

## A is an ordinary factor, minutes is a positioned factor, see
?HH::position
## We use xyplot() here, not bwplot(), because bwplot() doesn't handle
"positioned" factors.

## The minimalist form of this call is
useOuterStrips(
xyplot(Y ~ A | B + C, data=mydata,
       groups=A,
       panel=panel.bwplot.superpose, ## take control of colors of the boxes
       horizontal=FALSE,
       between=list(x=1, y=1))
)


On Mon, Jan 7, 2019 at 7:59 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 1/7/19 3:35 PM, varin sacha via R-help wrote:
> > Dear R-experts,
> >
> > I have fitted a model with 2-way and 3-way interactions.
> > I would like, for the 3-way interaction (year,age,by=education), to
> obtain 3D-plots. How could I do that ?
>
> Forget ggplot2. It has ignored this sort of visualization effort. Use
> lattice or base plotting methods.
>
>
> In order to plot a 2way interaction one needs a pseudo-3way plot
> (`wireframe`) or a single `levelplot`. For display of a 3way interaction
> in lattice (given the human minds inability to "see" in 4 dimensions)
> you will need to specify levels for one of the variables to display
> slices perhaps using multiple displays of 2way "sub-interactions"
> calculated ad meaningul levels of the variable you choose to slive
> with.  I'm not sure what the "native" plotting method for pkg:mgcv might
> be. I suspect it was base graphics,; if so, look at ?persp and ?contour.
>
> --
>
> David
>
> >
> > Many thanks for your response.
> >
> > Here is the reproducible example:
> >
> > #############
> > install.packages("ISLR")
> >
> > library(ISLR)
> >
> > install.packages("mgcv")
> >
> > library(mgcv)
> >
> > mod1<-gam(wage
> ~education+s(age,bs="ps")+year+te(age,year,bs="ps")+s(year,bs="ps",by=education,m=1)+te(year,age,by=education,bs=rep("ps",2)),data=Wage)
> >
> > plot(mod1)
> > #############
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nichol@@@wr@y @ending from ntlworld@com  Tue Jan  8 10:28:44 2019
From: nichol@@@wr@y @ending from ntlworld@com (Nick Wray)
Date: Tue, 8 Jan 2019 09:28:44 +0000 (GMT)
Subject: [R] Why does R do this?
Message-ID: <1393253038.882313.1546939724327@mail2.virginmedia.com>

y<-c(1,2,3)
z<-which(y>3)
z
y<-y[-z]
y

In the work I'm doing I often have this situation and have to make sure that I condition on z being non-zero as y is now numeric(0) rather than the set c(1,2,3).  Why does R do this?  Wouldn't it be more sensible for R to simply leave the host set unchanged if there are no elements to take out?

Any thoughts?

Thanks, Nick Wray
	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Tue Jan  8 11:19:50 2019
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 8 Jan 2019 11:19:50 +0100
Subject: [R] Why does R do this?
In-Reply-To: <1393253038.882313.1546939724327@mail2.virginmedia.com>
References: <1393253038.882313.1546939724327@mail2.virginmedia.com>
Message-ID: <CAJuCY5yDu2O1YM+KeR8uDNrcAd650cBP7r0Oqif6w4w1qOST+Q@mail.gmail.com>

Dear Nick,

The best solution is not to use which() but directy use the logical test.
This will work in case the condition is always FALSE and which() returns a
integer(0). And it is much faster too.
z <- y > 3
y[!z]

library(microbenchmark)
microbenchmark(
  y[!y > 3],
  y[-which(y > 3)]
)

Best regards,




ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 8 jan. 2019 om 10:29 schreef Nick Wray via R-help <
r-help at r-project.org>:

> y<-c(1,2,3)
> z<-which(y>3)
> z
> y<-y[-z]
> y
>
> In the work I'm doing I often have this situation and have to make sure
> that I condition on z being non-zero as y is now numeric(0) rather than the
> set c(1,2,3).  Why does R do this?  Wouldn't it be more sensible for R to
> simply leave the host set unchanged if there are no elements to take out?
>
> Any thoughts?
>
> Thanks, Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Tue Jan  8 11:27:24 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 8 Jan 2019 10:27:24 +0000
Subject: [R] Why does R do this?
In-Reply-To: <1393253038.882313.1546939724327@mail2.virginmedia.com>
References: <1393253038.882313.1546939724327@mail2.virginmedia.com>
Message-ID: <979e15c6fd4449539a7b974db003c2c3@SRVEXCHCM1302.precheza.cz>

Hi

It is documented behaviour.

"An empty index selects all values: this is most often used to replace all the entries but keep the attributes."

so I presume that changing it could break huge amount of code. The only workaround could be to check "z" before using it for indexing.

e.g.
> if(length(z)==0) z <- length(y) + 1
> y[-z]
[1] 1 2 3
>
Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Nick Wray via R-
> help
> Sent: Tuesday, January 8, 2019 10:29 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] Why does R do this?
>
> y<-c(1,2,3)
> z<-which(y>3)
> z
> y<-y[-z]
> y
>
> In the work I'm doing I often have this situation and have to make sure that I
> condition on z being non-zero as y is now numeric(0) rather than the set
> c(1,2,3).  Why does R do this?  Wouldn't it be more sensible for R to simply
> leave the host set unchanged if there are no elements to take out?
>
> Any thoughts?
>
> Thanks, Nick Wray
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From murdoch@dunc@n @ending from gm@il@com  Tue Jan  8 12:54:43 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 8 Jan 2019 06:54:43 -0500
Subject: [R] Why does R do this?
In-Reply-To: <1393253038.882313.1546939724327@mail2.virginmedia.com>
References: <1393253038.882313.1546939724327@mail2.virginmedia.com>
Message-ID: <8ed2949e-314f-ef92-1982-1de5e31bed99@gmail.com>

On 08/01/2019 4:28 a.m., Nick Wray via R-help wrote:
> y<-c(1,2,3)
> z<-which(y>3)

At this point z is a vector with no entries in it.

> z
> y<-y[-z]

-z is the same vector.  So y[z] and y[-z] are the same.

> y
> 
> In the work I'm doing I often have this situation and have to make sure that I condition on z being non-zero as y is now numeric(0) rather than the set c(1,2,3).  Why does R do this?  Wouldn't it be more sensible for R to simply leave the host set unchanged if there are no elements to take out?

No, it wouldn't.  You asked for no entries, so you get no entries.

Follow Thierry's advice, and don't use which() unless you really need a 
vector of indices, and are prepared for an empty one.

Duncan Murdoch


From @mn@@rol@hi @ending from gm@il@com  Tue Jan  8 11:38:37 2019
From: @mn@@rol@hi @ending from gm@il@com (S. Mahmoud Nasrollahi)
Date: Tue, 8 Jan 2019 11:38:37 +0100
Subject: [R] Question
Message-ID: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>

Dear colleague
I have got a problem during working with some package in R and in
spite of trying with R help, internet and any other resources I could
not succeed. Indeed when I what to install some function like bwplot,
boxplot,  xyplot I receive this sort of messages:
 Warning in install.packages :
  package ?xyplot? is not available (for R version 3.5.2)
Do you know how I can solve that?


-- 
S. M. Nasrollahi
Postdoctoral Researcher
French National Institute for Agricultural Research
 Unite? Mixte de Recherches sur les Herbivores,
 63122 St Gene`s Champanelle, France
sayyed-mahmoud.nasrollahi at inra.fr
Tel: +9826132248082
Fax: +9826132246752


From meri@m@nef @ending from gm@il@com  Tue Jan  8 15:08:11 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Tue, 8 Jan 2019 08:08:11 -0600
Subject: [R] Warning message: NAs introduced by coercion
Message-ID: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>

Dear all,

I have a .csv file called df4. (15752 obs. of 264 variables).
I apply this code but couldn't continue further other analyses, a warning
message keeps coming up. Then, I want to determine max and min
similarity values,
heat map plot, cluster...etc

> require(SNPRelate)
> library(gdsfmt)
> myd <- read.csv(file = "df4.csv", header = TRUE)
> names(myd)[-1]
myd[,1]
> myd[1:10, 1:10]
 # the data must be 0,1,2 with 3 as missing so you have r
> sample.id <- names(myd)[-1]
> snp.id <- myd[,1]
> snp.position <- 1:length(snp.id) # not needed for ibs
> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
# genotype data must have - in 3
> genod <- myd[,-1]
> genod[is.na(genod)] <- 3
> genod[genod=="0"] <- 0
> genod[genod=="1"] <- 2
> genod[1:10,1:10]
> genod <- as.matrix(genod)
> class(genod) <- "numeric"


*Warning message:In class(genod) <- "numeric" : NAs introduced by coercion*

Maybe I could illustrate more with details so I can be more specific?
Please, let me know.

I would appreciate your help.
Thanks,
Meriam

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Tue Jan  8 15:48:00 2019
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 8 Jan 2019 09:48:00 -0500
Subject: [R] Question
In-Reply-To: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
Message-ID: <CAM_vjunPUsRvHnqKZHXJQH_mxDOZVA+06k-7hg4jm1miyM5ANQ@mail.gmail.com>

xyplot is not a package, it is a function within the lattice package, which
should already be installed.

library(lattice) # load the package from the R library
?xyplot # look at the help for the function

The others are also functions, not packages.

Sarah

On Tue, Jan 8, 2019 at 9:15 AM S. Mahmoud Nasrollahi <smnasrolahi at gmail.com>
wrote:

> Dear colleague
> I have got a problem during working with some package in R and in
> spite of trying with R help, internet and any other resources I could
> not succeed. Indeed when I what to install some function like bwplot,
> boxplot,  xyplot I receive this sort of messages:
>  Warning in install.packages :
>   package ?xyplot? is not available (for R version 3.5.2)
> Do you know how I can solve that?
>
>
> --
> S. M. Nasrollahi
> Postdoctoral Researcher
> French National Institute for Agricultural Research
>  Unite? Mixte de Recherches sur les Herbivores,
>  63122 St Gene`s Champanelle, France
> sayyed-mahmoud.nasrollahi at inra.fr
> Tel: +9826132248082
> Fax: +9826132246752
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Tue Jan  8 16:02:17 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 8 Jan 2019 15:02:17 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
Message-ID: <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> Sent: Tuesday, January 8, 2019 3:08 PM
> To: r-help at r-project.org
> Subject: [R] Warning message: NAs introduced by coercion
>
> Dear all,
>
> I have a .csv file called df4. (15752 obs. of 264 variables).
> I apply this code but couldn't continue further other analyses, a warning
> message keeps coming up. Then, I want to determine max and min
> similarity values,
> heat map plot, cluster...etc
>
> > require(SNPRelate)
> > library(gdsfmt)
> > myd <- read.csv(file = "df4.csv", header = TRUE)
> > names(myd)[-1]
> myd[,1]
> > myd[1:10, 1:10]
>  # the data must be 0,1,2 with 3 as missing so you have r
> > sample.id <- names(myd)[-1]
> > snp.id <- myd[,1]
> > snp.position <- 1:length(snp.id) # not needed for ibs
> > snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> # genotype data must have - in 3
> > genod <- myd[,-1]
> > genod[is.na(genod)] <- 3
> > genod[genod=="0"] <- 0
> > genod[genod=="1"] <- 2
> > genod[1:10,1:10]
> > genod <- as.matrix(genod)

matrix can have only one type of data so you probaly changed it to character by such construction.

> > class(genod) <- "numeric"

This tries to change all "numeric" values to numbers but if it cannot it sets it to NA.

something like

> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa
> ir <-head(iris)
> irm <- as.matrix(ir)
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> class(irm) <- "numeric"
Warning message:
In class(irm) <- "numeric" : NAs introduced by coercion
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2      NA
2          4.9         3.0          1.4         0.2      NA
3          4.7         3.2          1.3         0.2      NA
4          4.6         3.1          1.5         0.2      NA
5          5.0         3.6          1.4         0.2      NA
6          5.4         3.9          1.7         0.4      NA
>

Cheers
Petr


>
>
> *Warning message:In class(genod) <- "numeric" : NAs introduced by coercion*
>
> Maybe I could illustrate more with details so I can be more specific?
> Please, let me know.
>
> I would appreciate your help.
> Thanks,
> Meriam
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@pik@l @ending from prechez@@cz  Tue Jan  8 16:12:01 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 8 Jan 2019 15:12:01 +0000
Subject: [R] error in plotting model from kernlab
In-Reply-To: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
References: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
Message-ID: <beac7d2de6e74d508561723caf1cc936@SRVEXCHCM1302.precheza.cz>

Hi

I cannot help you with kernlab

> >  pred = predict(mod, df, type = "probabilities")
> >  acc = table(pred, df$cons)
> Error in table(pred, df$cons) : all arguments must have the same length
> which again is weird since mod, df and df$cons are made from the same
> dataframe.

Why not check length of those objects?

length(pred)
length(df$cons)

> > plot(mod, data = df)
> > kernlab::plot(mod, data = df)
> but I get this error:
>
> Error in .local(x, ...) :
>   Only plots of classification ksvm objects supported
>

seems to me selfexplanatory. What did maintainer said about it?

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Monday, January 7, 2019 1:26 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] error in plotting model from kernlab
>
> Dear all,
> I have a set of data in this form:
> > str <data>
> 'data.frame': 1574 obs. of  14 variables:
>  $ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934 3999
> ...
>  $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
>  $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
>  $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
>  $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK" "Astro
> 2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
>  $ ori.ct: num  0 33.5 0 0 0 ...
>  $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
>  $ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004 ...
>  $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
>  $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
>  $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
>  $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
>  $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
>  $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
> from which I have selected two numerical variables correspondig to x
> and y in a Cartesian plane and one outcome variable (z):
> > df = subset(t.data, select = c(mr, fcn, cons))
> >  df$cons = factor(c("negative", "positive"))
> > head(df)
>       mr   fcn     cons
> 1 -0.002 44.54 negative
> 2  0.109 36.74 positive
> 3  0.002  6.78 negative
> 4  0.000 43.09 positive
> 5  0.001 44.87 negative
> 6  0.006  2.82 positive
>
> I created an SVM the method with the KERNLAB package with:
> > mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "." but the
> outcome is the same
>             data = df,
>             type = "C-bsvc",
>             kernel = "rbfdot",
>             kpar = "automatic",
>             C = 10,
>             prob.model = TRUE)
>
> > mod
> Support Vector Machine object of class "ksvm"
>
> SV type: C-bsvc  (classification)
>  parameter : cost C = 10
>
> Gaussian Radial Basis kernel function.
>  Hyperparameter : sigma =  42.0923201429106
>
> Number of Support Vectors : 1439
>
> Objective Function Value : -12873.45
> Training error : 0.39263
> Probability model included.
>
> First of all, I am not sure if the model worked because 1439 support
> vectors out of 1574 data points means that over 90% of the data is
> required to fix the hyperplane. this does not look like a model but a
> patch. Secondly, the prediction is rubbish -- but this is another
> story -- and when I try to create a confusion table of the processed
> data I get:
> >  pred = predict(mod, df, type = "probabilities")
> >  acc = table(pred, df$cons)
> Error in table(pred, df$cons) : all arguments must have the same length
> which again is weird since mod, df and df$cons are made from the same
> dataframe.
>
> Coming to the actual error, I tried to plot the model with:
> > plot(mod, data = df)
> > kernlab::plot(mod, data = df)
> but I get this error:
>
> Error in .local(x, ...) :
>   Only plots of classification ksvm objects supported
>
> Would you know what I am missing?
> Thank you
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From r@chel@thomp@on @ending from @tudent@uv@@nl  Tue Jan  8 16:23:35 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Tue, 8 Jan 2019 10:23:35 -0500
Subject: [R] Mailinglist
In-Reply-To: <CAGx1TMA77OUt9O9nAkLzq1cBMs-BfJ3uEakxr3vVtZEMwDZNiQ@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <CAGx1TMA77OUt9O9nAkLzq1cBMs-BfJ3uEakxr3vVtZEMwDZNiQ@mail.gmail.com>
Message-ID: <CAK7fGOvOiiRrQ0-oQnoO2-oxtHnMtzg_-KWEHc-brBX1w+JNow@mail.gmail.com>

Hi

Thank you for your help and suggestions!
I have tried a few things and ask help from lots of people online!

My problem is that I am not able to share the database! I tried to recreate
one but I wasn't successful.
So I found a way to analyze each subject individually, but I do not know
how to perform the same steps for all of the subjects at once.
But I just wanted to share what I did, since you tried to help me!

This is what I did.

I stored all the column names in a vector named "Names"

names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")



colnames(gmoji_passivedata)=names



I used this code to find the number of participants in the dataset



length(unique(gmoji_passivedata$participants))

The number of participants is 44



I used this code to find the unique ID for every participant



library(plyr)

> count(gmoji_passivedata,?participants")

From the dataset, I selected one participant ""U_..."

I used subset data



participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")





With the table code

table(p1$probetype) I found the counts of all the different values of the
probe type column



edu.mit.media.funf.probe.builtin.ActivityProbe

                                                                      16167

edu.mit.media.funf.probe.builtin.BluetoothProbe

                                                                      405

  edu.mit.media.funf.probe.builtin.CallLogProbe

                                                                      1427

   edu.mit.media.funf.probe.builtin.ScreenProbe

                                                                      1791

     edu.mit.media.funf.probe.builtin.WifiProbe

                                                                       5386



The count for the call log probe for the selected participant is 1427



There was only one participant with sms probe for the rest of the
participant the count of sms probe is 0



For the screen probe and activity probe I found the total count (1791 and
16167)



For screen probe, I used a subset code and set the value detailed column to
false and true



screenon_false=subset(p1,valuedetailed=="False") (this participant 875)

screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)



and for activity probe to none, low and high to find the required values



activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)

activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)

activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)





I did this for each participant


Best,


Rachel

On Sun, Jan 6, 2019 at 2:48 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> Questions like this
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
>
> suggest that you should look at the table function.  See
> ?table
> and run the examples.
> They show how to get one-way frequency tables and two-way contingency
> tables.
>
> If you have followup questions for the list, you can use the examples in
> ?table as your starting point.
> That way you don't need to worry about sharing your own data.
>
>
> On Sun, Jan 6, 2019 at 1:59 PM Rachel Thompson <
> rachel.thompson at student.uva.nl> wrote:
>
>> Hi Rich,
>>
>> I really feel lost at this point.
>> I need a code that helps me count the phone activity level(high/low/none),
>> the screen activity (on/off) and the amount calls and SMS of each subject.
>>
>> 1. I want to have a summary of how many times a specific subject got
>> called
>> (CallLogProbe)
>> 2. I want to have a summary of how many times a specific subject got a
>> text
>> message (SMS probe)
>> 3. I want to have a summary of how many times a specific subject
>> - Turned their screen on - True  (ScreenProbe)
>> - Or did not turn their screen on - False (ScreenProbe)
>> 4.  I want to have a summary of the activity level of a specific subject
>> - Activity level - none (ActivityProbe)
>> - Activity level- low     (ActivityProbe)
>> - Activity level - High  (ActivityProbe)
>>
>> I want to do this for all the 36 subjects(Participants).
>> In the end, I have to define the percentages and cutoff points of what is
>> considered low-medium-high, based on what the results of all the subjects
>> are. So I am able to see if a specific subject has low social interaction
>> etc.
>>
>> I have tried a lot, with the help of youtube etc. But I feel as if I am
>> trying a lot of things but without clearly knowing if it is the right
>> step.
>> I have a csv file, but I need to look into what Jeff said about the
>> guides.
>> So I am able to share it.
>>
>> Best.
>>
>>
>> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
>> wrote:
>>
>> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
>> >
>> > > I am an intern from Amsterdam and I have to do an analysis in R. I
>> spoke
>> > > to my professor in Amsterdam and my supervisor's here in Boston. But
>> they
>> > > are to busy to help. I informed them from the start that I am not
>> > familiar
>> > > with R(Rstudio) and they told me that I would receive guidance. So
>> since
>> > > they can not help me, I decided to share my problem online. (It is a
>> CVS
>> > > file imported into R)
>> >
>> > Rachel,
>> >
>> >    I find it interesting that you're put in such a difficult position.
>> I've
>> > not followed this thread from the start so my comments might be
>> redundant
>> > or
>> > inappropriate.
>> >
>> >    If you can, describe the problem. That is, what are you being asked
>> to
>> > find and what are the available data? This information helps us to guide
>> > you
>> > to learning the mechanics for accomplishing your task with R.
>> >
>> > Regards,
>> >
>> > Rich
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Tue Jan  8 16:23:43 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Tue, 8 Jan 2019 10:23:43 -0500
Subject: [R] Mailinglist
In-Reply-To: <92cf4a95349db0c2633cbfef2b27204083e95b14.camel@pp.inet.fi>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <92cf4a95349db0c2633cbfef2b27204083e95b14.camel@pp.inet.fi>
Message-ID: <CAK7fGOsatLagDVVhiOQocM+BZKF6iq1VpiTAWPz2bb4JtVwpjQ@mail.gmail.com>

Hi

Thank you for your help and suggestions!
I have tried a few things and ask help from lots of people online!

My problem is that I am not able to share the database! I tried to recreate
one but I wasn't successful.
So I found a way to analyze each subject individually, but I do not know
how to perform the same steps for all of the subjects at once.
But I just wanted to share what I did, since you tried to help me!

This is what I did.

I stored all the column names in a vector named "Names"

names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")



colnames(gmoji_passivedata)=names



I used this code to find the number of participants in the dataset



length(unique(gmoji_passivedata$participants))

The number of participants is 44



I used this code to find the unique ID for every participant



library(plyr)

> count(gmoji_passivedata,?participants")

From the dataset, I selected one participant ""U_..."

I used subset data



participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")





With the table code

table(p1$probetype) I found the counts of all the different values of the
probe type column



edu.mit.media.funf.probe.builtin.ActivityProbe

                                                                      16167

edu.mit.media.funf.probe.builtin.BluetoothProbe

                                                                      405

  edu.mit.media.funf.probe.builtin.CallLogProbe

                                                                      1427

   edu.mit.media.funf.probe.builtin.ScreenProbe

                                                                      1791

     edu.mit.media.funf.probe.builtin.WifiProbe

                                                                       5386



The count for the call log probe for the selected participant is 1427



There was only one participant with sms probe for the rest of the
participant the count of sms probe is 0



For the screen probe and activity probe I found the total count (1791 and
16167)



For screen probe, I used a subset code and set the value detailed column to
false and true



screenon_false=subset(p1,valuedetailed=="False") (this participant 875)

screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)



and for activity probe to none, low and high to find the required values



activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)

activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)

activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)





I did this for each participant


Best,


Rachel

On Mon, Jan 7, 2019 at 1:28 AM K. Elo <maillists at pp.inet.fi> wrote:

> Hi!
>
> Not having a data chunk prevents me from testing abit, but maybe you
> should take a look on:
>
> ?table
> ?xtabs
>
> to start with.
>
> But as already suggested by other users, a small data set would be of
> great help :)
>
> HTH,
> Kimmo
>
> su, 2019-01-06 kello 13:49 -0500, Rachel Thompson kirjoitti:
> > Hi Rich,
> >
> > I really feel lost at this point.
> > I need a code that helps me count the phone activity
> > level(high/low/none),
> > the screen activity (on/off) and the amount calls and SMS of each
> > subject.
> >
> > 1. I want to have a summary of how many times a specific subject got
> > called
> > (CallLogProbe)
> > 2. I want to have a summary of how many times a specific subject got
> > a text
> > message (SMS probe)
> > 3. I want to have a summary of how many times a specific subject
> > - Turned their screen on - True  (ScreenProbe)
> > - Or did not turn their screen on - False (ScreenProbe)
> > 4.  I want to have a summary of the activity level of a specific
> > subject
> > - Activity level - none (ActivityProbe)
> > - Activity level- low     (ActivityProbe)
> > - Activity level - High  (ActivityProbe)
> >
> > I want to do this for all the 36 subjects(Participants).
> > In the end, I have to define the percentages and cutoff points of
> > what is
> > considered low-medium-high, based on what the results of all the
> > subjects
> > are. So I am able to see if a specific subject has low social
> > interaction
> > etc.
> >
> > I have tried a lot, with the help of youtube etc. But I feel as if I
> > am
> > trying a lot of things but without clearly knowing if it is the right
> > step.
> > I have a csv file, but I need to look into what Jeff said about the
> > guides.
> > So I am able to share it.
> >
> > Best.
> >
> >
> > On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <
> > rshepard at appl-ecosys.com>
> > wrote:
> >
> > > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > >
> > > > I am an intern from Amsterdam and I have to do an analysis in R.
> > > > I spoke
> > > > to my professor in Amsterdam and my supervisor's here in Boston.
> > > > But they
> > > > are to busy to help. I informed them from the start that I am not
> > >
> > > familiar
> > > > with R(Rstudio) and they told me that I would receive guidance.
> > > > So since
> > > > they can not help me, I decided to share my problem online. (It
> > > > is a CVS
> > > > file imported into R)
> > >
> > > Rachel,
> > >
> > >    I find it interesting that you're put in such a difficult
> > > position. I've
> > > not followed this thread from the start so my comments might be
> > > redundant
> > > or
> > > inappropriate.
> > >
> > >    If you can, describe the problem. That is, what are you being
> > > asked to
> > > find and what are the available data? This information helps us to
> > > guide
> > > you
> > > to learning the mechanics for accomplishing your task with R.
> > >
> > > Regards,
> > >
> > > Rich
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Tue Jan  8 16:23:58 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Tue, 8 Jan 2019 10:23:58 -0500
Subject: [R] Mailinglist
In-Reply-To: <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAK7fGOvJh1vFJOT7AshqkEwyF21uMRNerDPxEpuUT3HiJ6cbgA@mail.gmail.com>

Hi

Thank you for your help and suggestions!
I have tried a few things and ask help from lots of people online!

My problem is that I am not able to share the database! I tried to recreate
one but I wasn't successful.
So I found a way to analyze each subject individually, but I do not know
how to perform the same steps for all of the subjects at once.
But I just wanted to share what I did, since you tried to help me!

This is what I did.

I stored all the column names in a vector named "Names"

names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")



colnames(gmoji_passivedata)=names



I used this code to find the number of participants in the dataset



length(unique(gmoji_passivedata$participants))

The number of participants is 44



I used this code to find the unique ID for every participant



library(plyr)

> count(gmoji_passivedata,?participants")

From the dataset, I selected one participant ""U_..."

I used subset data



participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")





With the table code

table(p1$probetype) I found the counts of all the different values of the
probe type column



edu.mit.media.funf.probe.builtin.ActivityProbe

                                                                      16167

edu.mit.media.funf.probe.builtin.BluetoothProbe

                                                                      405

  edu.mit.media.funf.probe.builtin.CallLogProbe

                                                                      1427

   edu.mit.media.funf.probe.builtin.ScreenProbe

                                                                      1791

     edu.mit.media.funf.probe.builtin.WifiProbe

                                                                       5386



The count for the call log probe for the selected participant is 1427



There was only one participant with sms probe for the rest of the
participant the count of sms probe is 0



For the screen probe and activity probe I found the total count (1791 and
16167)



For screen probe, I used a subset code and set the value detailed column to
false and true



screenon_false=subset(p1,valuedetailed=="False") (this participant 875)

screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)



and for activity probe to none, low and high to find the required values



activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)

activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)

activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)





I did this for each participant


Best,


Rachel

On Mon, Jan 7, 2019 at 3:56 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi Rachel.
>
> You already have got several suggestions, but results depend on structure
> of your data. The best way from your side would be just copy a part of your
> data directly to email and preferable way is to use "dput".
>
> Assuming your data already transfered to R are called "mydata".
>
> You can just copy otput of
>
> dput(mydata[1:30,])
>
> to your next mail.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rachel Thompson
> > Sent: Sunday, January 6, 2019 7:49 PM
> > To: Rich Shepard <rshepard at appl-ecosys.com>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] Mailinglist
> >
> > Hi Rich,
> >
> > I really feel lost at this point.
> > I need a code that helps me count the phone activity
> level(high/low/none),
> > the screen activity (on/off) and the amount calls and SMS of each
> subject.
> >
> > 1. I want to have a summary of how many times a specific subject got
> called
> > (CallLogProbe)
> > 2. I want to have a summary of how many times a specific subject got a
> text
> > message (SMS probe)
> > 3. I want to have a summary of how many times a specific subject
> > - Turned their screen on - True  (ScreenProbe)
> > - Or did not turn their screen on - False (ScreenProbe)
> > 4.  I want to have a summary of the activity level of a specific subject
> > - Activity level - none (ActivityProbe)
> > - Activity level- low     (ActivityProbe)
> > - Activity level - High  (ActivityProbe)
> >
> > I want to do this for all the 36 subjects(Participants).
> > In the end, I have to define the percentages and cutoff points of what is
> > considered low-medium-high, based on what the results of all the subjects
> > are. So I am able to see if a specific subject has low social interaction
> > etc.
> >
> > I have tried a lot, with the help of youtube etc. But I feel as if I am
> > trying a lot of things but without clearly knowing if it is the right
> step.
> > I have a csv file, but I need to look into what Jeff said about the
> guides.
> > So I am able to share it.
> >
> > Best.
> >
> >
> > On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
> > wrote:
> >
> > > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > >
> > > > I am an intern from Amsterdam and I have to do an analysis in R. I
> spoke
> > > > to my professor in Amsterdam and my supervisor's here in Boston. But
> they
> > > > are to busy to help. I informed them from the start that I am not
> > > familiar
> > > > with R(Rstudio) and they told me that I would receive guidance. So
> since
> > > > they can not help me, I decided to share my problem online. (It is a
> CVS
> > > > file imported into R)
> > >
> > > Rachel,
> > >
> > >    I find it interesting that you're put in such a difficult position.
> I've
> > > not followed this thread from the start so my comments might be
> redundant
> > > or
> > > inappropriate.
> > >
> > >    If you can, describe the problem. That is, what are you being asked
> to
> > > find and what are the available data? This information helps us to
> guide
> > > you
> > > to learning the mechanics for accomplishing your task with R.
> > >
> > > Regards,
> > >
> > > Rich
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]


From r@chel@thomp@on @ending from @tudent@uv@@nl  Tue Jan  8 16:24:10 2019
From: r@chel@thomp@on @ending from @tudent@uv@@nl (Rachel Thompson)
Date: Tue, 8 Jan 2019 10:24:10 -0500
Subject: [R] Mailinglist
In-Reply-To: <CAP+bYWBc=c1dKumXqFT5ziJ3eHmzifE=fQ_8og+UK=EOARBj3g@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
 <CAP+bYWBc=c1dKumXqFT5ziJ3eHmzifE=fQ_8og+UK=EOARBj3g@mail.gmail.com>
Message-ID: <CAK7fGOt7N+_r4LTt4Y+zSwg7S4trvX5O1LxP7YywWdikSGzKOA@mail.gmail.com>

Hi

Thank you for your help and suggestions!
I have tried a few things and ask help from lots of people online!

My problem is that I am not able to share the database! I tried to recreate
one but I wasn't successful.
So I found a way to analyze each subject individually, but I do not know
how to perform the same steps for all of the subjects at once.
But I just wanted to share what I did, since you tried to help me!

This is what I did.

I stored all the column names in a vector named "Names"

names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")



colnames(gmoji_passivedata)=names



I used this code to find the number of participants in the dataset



length(unique(gmoji_passivedata$participants))

The number of participants is 44



I used this code to find the unique ID for every participant



library(plyr)

> count(gmoji_passivedata,?participants")

From the dataset, I selected one participant ""U_..."

I used subset data



participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")





With the table code

table(p1$probetype) I found the counts of all the different values of the
probe type column



edu.mit.media.funf.probe.builtin.ActivityProbe

                                                                      16167

edu.mit.media.funf.probe.builtin.BluetoothProbe

                                                                      405

  edu.mit.media.funf.probe.builtin.CallLogProbe

                                                                      1427

   edu.mit.media.funf.probe.builtin.ScreenProbe

                                                                      1791

     edu.mit.media.funf.probe.builtin.WifiProbe

                                                                       5386



The count for the call log probe for the selected participant is 1427



There was only one participant with sms probe for the rest of the
participant the count of sms probe is 0



For the screen probe and activity probe I found the total count (1791 and
16167)



For screen probe, I used a subset code and set the value detailed column to
false and true



screenon_false=subset(p1,valuedetailed=="False") (this participant 875)

screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)



and for activity probe to none, low and high to find the required values



activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)

activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)

activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)





I did this for each participant


Best,


Rachel

On Mon, Jan 7, 2019 at 4:07 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> dput(sample(mydata, n=25)) is probably going to be more representative. --
> H
>
> On Mon, 7 Jan 2019 at 00:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi Rachel.
> >
> > You already have got several suggestions, but results depend on structure
> > of your data. The best way from your side would be just copy a part of
> your
> > data directly to email and preferable way is to use "dput".
> >
> > Assuming your data already transfered to R are called "mydata".
> >
> > You can just copy otput of
> >
> > dput(mydata[1:30,])
> >
> > to your next mail.
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rachel
> Thompson
> > > Sent: Sunday, January 6, 2019 7:49 PM
> > > To: Rich Shepard <rshepard at appl-ecosys.com>
> > > Cc: r-help mailing list <r-help at r-project.org>
> > > Subject: Re: [R] Mailinglist
> > >
> > > Hi Rich,
> > >
> > > I really feel lost at this point.
> > > I need a code that helps me count the phone activity
> > level(high/low/none),
> > > the screen activity (on/off) and the amount calls and SMS of each
> > subject.
> > >
> > > 1. I want to have a summary of how many times a specific subject got
> > called
> > > (CallLogProbe)
> > > 2. I want to have a summary of how many times a specific subject got a
> > text
> > > message (SMS probe)
> > > 3. I want to have a summary of how many times a specific subject
> > > - Turned their screen on - True  (ScreenProbe)
> > > - Or did not turn their screen on - False (ScreenProbe)
> > > 4.  I want to have a summary of the activity level of a specific
> subject
> > > - Activity level - none (ActivityProbe)
> > > - Activity level- low     (ActivityProbe)
> > > - Activity level - High  (ActivityProbe)
> > >
> > > I want to do this for all the 36 subjects(Participants).
> > > In the end, I have to define the percentages and cutoff points of what
> is
> > > considered low-medium-high, based on what the results of all the
> subjects
> > > are. So I am able to see if a specific subject has low social
> interaction
> > > etc.
> > >
> > > I have tried a lot, with the help of youtube etc. But I feel as if I am
> > > trying a lot of things but without clearly knowing if it is the right
> > step.
> > > I have a csv file, but I need to look into what Jeff said about the
> > guides.
> > > So I am able to share it.
> > >
> > > Best.
> > >
> > >
> > > On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com
> >
> > > wrote:
> > >
> > > > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> > > >
> > > > > I am an intern from Amsterdam and I have to do an analysis in R. I
> > spoke
> > > > > to my professor in Amsterdam and my supervisor's here in Boston.
> But
> > they
> > > > > are to busy to help. I informed them from the start that I am not
> > > > familiar
> > > > > with R(Rstudio) and they told me that I would receive guidance. So
> > since
> > > > > they can not help me, I decided to share my problem online. (It is
> a
> > CVS
> > > > > file imported into R)
> > > >
> > > > Rachel,
> > > >
> > > >    I find it interesting that you're put in such a difficult
> position.
> > I've
> > > > not followed this thread from the start so my comments might be
> > redundant
> > > > or
> > > > inappropriate.
> > > >
> > > >    If you can, describe the problem. That is, what are you being
> asked
> > to
> > > > find and what are the available data? This information helps us to
> > guide
> > > > you
> > > > to learning the mechanics for accomplishing your task with R.
> > > >
> > > > Regards,
> > > >
> > > > Rich
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data are
> > available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> legally
> > binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> OpenPGP:
> https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> from my mobile device
> Envoye de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From meri@m@nef @ending from gm@il@com  Tue Jan  8 16:35:43 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Tue, 8 Jan 2019 09:35:43 -0600
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>

I see...
Here's a portion of what my data looks like (csv file attached).
I run again and here are the results:

df4 <- read.csv(file = "mydata.csv", header = TRUE)

> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"

> myd[,1][1]  3  4  5  6  8 10


> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2

> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
[1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
[2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
[3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
[4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
[5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
[6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"

> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)

 marker X88 X9 X17 X25
[1,]     NA   0  3   3   3
[2,]     NA   2  0   3   0
[3,]     NA   0  0   0   0
[4,]     NA   0  0   3   0
[5,]     NA   3  3   3   3
[6,]     NA   0  0   0   0

> class(genod2) <- "numeric"> class(genod2)[1] "matrix"

> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
  is.matrix(genmat) is not TRUE

Thanks,
Meriam

On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> see in line
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> > Sent: Tuesday, January 8, 2019 3:08 PM
> > To: r-help at r-project.org
> > Subject: [R] Warning message: NAs introduced by coercion
> >
> > Dear all,
> >
> > I have a .csv file called df4. (15752 obs. of 264 variables).
> > I apply this code but couldn't continue further other analyses, a warning
> > message keeps coming up. Then, I want to determine max and min
> > similarity values,
> > heat map plot, cluster...etc
> >
> > > require(SNPRelate)
> > > library(gdsfmt)
> > > myd <- read.csv(file = "df4.csv", header = TRUE)
> > > names(myd)[-1]
> > myd[,1]
> > > myd[1:10, 1:10]
> >  # the data must be 0,1,2 with 3 as missing so you have r
> > > sample.id <- names(myd)[-1]
> > > snp.id <- myd[,1]
> > > snp.position <- 1:length(snp.id) # not needed for ibs
> > > snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > > snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> > # genotype data must have - in 3
> > > genod <- myd[,-1]
> > > genod[is.na(genod)] <- 3
> > > genod[genod=="0"] <- 0
> > > genod[genod=="1"] <- 2
> > > genod[1:10,1:10]
> > > genod <- as.matrix(genod)
>
> matrix can have only one type of data so you probaly changed it to
> character by such construction.
>
> > > class(genod) <- "numeric"
>
> This tries to change all "numeric" values to numbers but if it cannot it
> sets it to NA.
>
> something like
>
> > head(iris)
>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> 1          5.1         3.5          1.4         0.2  setosa
> 2          4.9         3.0          1.4         0.2  setosa
> 3          4.7         3.2          1.3         0.2  setosa
> 4          4.6         3.1          1.5         0.2  setosa
> 5          5.0         3.6          1.4         0.2  setosa
> 6          5.4         3.9          1.7         0.4  setosa
> > ir <-head(iris)
> > irm <- as.matrix(ir)
> > head(irm)
>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> > class(irm) <- "numeric"
> Warning message:
> In class(irm) <- "numeric" : NAs introduced by coercion
> > head(irm)
>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> 1          5.1         3.5          1.4         0.2      NA
> 2          4.9         3.0          1.4         0.2      NA
> 3          4.7         3.2          1.3         0.2      NA
> 4          4.6         3.1          1.5         0.2      NA
> 5          5.0         3.6          1.4         0.2      NA
> 6          5.4         3.9          1.7         0.4      NA
> >
>
> Cheers
> Petr
>
>
> >
> >
> > *Warning message:In class(genod) <- "numeric" : NAs introduced by
> coercion*
> >
> > Maybe I could illustrate more with details so I can be more specific?
> > Please, let me know.
> >
> > I would appreciate your help.
> > Thanks,
> > Meriam
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

-- 
*Meriam Nefzaoui*
*MSc. in Plant Breeding and Genetics*
*Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil*

From m@rongiu@luigi @ending from gm@il@com  Tue Jan  8 16:40:05 2019
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Tue, 8 Jan 2019 16:40:05 +0100
Subject: [R] error in plotting model from kernlab
In-Reply-To: <beac7d2de6e74d508561723caf1cc936@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
 <beac7d2de6e74d508561723caf1cc936@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2Q=C5an1--GJO18FaRb22+s7QeML79QpO-2vFfDg6JiZg@mail.gmail.com>

Hi,
the maintainer hasn't answered yet. The problem with 'acc' is that yes
the objects are not of the same length but they should be: according
to the manual, ' table(pred, df$cons)' would return a 2x2 matrix of
the results. This is not the case, so there is a problem with the
model -- that is why there is no plotting either -- even if an object
of class ksvm had been created.

On Tue, Jan 8, 2019 at 4:12 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> I cannot help you with kernlab
>
> > >  pred = predict(mod, df, type = "probabilities")
> > >  acc = table(pred, df$cons)
> > Error in table(pred, df$cons) : all arguments must have the same length
> > which again is weird since mod, df and df$cons are made from the same
> > dataframe.
>
> Why not check length of those objects?
>
> length(pred)
> length(df$cons)
>
> > > plot(mod, data = df)
> > > kernlab::plot(mod, data = df)
> > but I get this error:
> >
> > Error in .local(x, ...) :
> >   Only plots of classification ksvm objects supported
> >
>
> seems to me selfexplanatory. What did maintainer said about it?
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Monday, January 7, 2019 1:26 PM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] error in plotting model from kernlab
> >
> > Dear all,
> > I have a set of data in this form:
> > > str <data>
> > 'data.frame': 1574 obs. of  14 variables:
> >  $ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934 3999
> > ...
> >  $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
> >  $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
> >  $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
> >  $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK" "Astro
> > 2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
> >  $ ori.ct: num  0 33.5 0 0 0 ...
> >  $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
> >  $ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004 ...
> >  $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
> >  $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
> >  $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
> >  $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
> >  $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
> >  $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
> > from which I have selected two numerical variables correspondig to x
> > and y in a Cartesian plane and one outcome variable (z):
> > > df = subset(t.data, select = c(mr, fcn, cons))
> > >  df$cons = factor(c("negative", "positive"))
> > > head(df)
> >       mr   fcn     cons
> > 1 -0.002 44.54 negative
> > 2  0.109 36.74 positive
> > 3  0.002  6.78 negative
> > 4  0.000 43.09 positive
> > 5  0.001 44.87 negative
> > 6  0.006  2.82 positive
> >
> > I created an SVM the method with the KERNLAB package with:
> > > mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "." but the
> > outcome is the same
> >             data = df,
> >             type = "C-bsvc",
> >             kernel = "rbfdot",
> >             kpar = "automatic",
> >             C = 10,
> >             prob.model = TRUE)
> >
> > > mod
> > Support Vector Machine object of class "ksvm"
> >
> > SV type: C-bsvc  (classification)
> >  parameter : cost C = 10
> >
> > Gaussian Radial Basis kernel function.
> >  Hyperparameter : sigma =  42.0923201429106
> >
> > Number of Support Vectors : 1439
> >
> > Objective Function Value : -12873.45
> > Training error : 0.39263
> > Probability model included.
> >
> > First of all, I am not sure if the model worked because 1439 support
> > vectors out of 1574 data points means that over 90% of the data is
> > required to fix the hyperplane. this does not look like a model but a
> > patch. Secondly, the prediction is rubbish -- but this is another
> > story -- and when I try to create a confusion table of the processed
> > data I get:
> > >  pred = predict(mod, df, type = "probabilities")
> > >  acc = table(pred, df$cons)
> > Error in table(pred, df$cons) : all arguments must have the same length
> > which again is weird since mod, df and df$cons are made from the same
> > dataframe.
> >
> > Coming to the actual error, I tried to plot the model with:
> > > plot(mod, data = df)
> > > kernlab::plot(mod, data = df)
> > but I get this error:
> >
> > Error in .local(x, ...) :
> >   Only plots of classification ksvm objects supported
> >
> > Would you know what I am missing?
> > Thank you
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>


-- 
Best regards,
Luigi


From rmh @ending from temple@edu  Tue Jan  8 17:32:47 2019
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 8 Jan 2019 11:32:47 -0500
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOvOiiRrQ0-oQnoO2-oxtHnMtzg_-KWEHc-brBX1w+JNow@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <CAGx1TMA77OUt9O9nAkLzq1cBMs-BfJ3uEakxr3vVtZEMwDZNiQ@mail.gmail.com>
 <CAK7fGOvOiiRrQ0-oQnoO2-oxtHnMtzg_-KWEHc-brBX1w+JNow@mail.gmail.com>
Message-ID: <CAGx1TMD+Q01LaUCv7g0bLoS8hvHj-a5W1S1TFg_uX=vrrgPUGA@mail.gmail.com>

please post a sample dataset based on
mydata <- rbind[participant1[1:3,], participant2[1:4,], participant3[1:5,])

I think mydata at this point is anonymized enough that you can post
it.  Verify with whomever, though.
You might want to change those random U* names of the participants to
c("A","B","C")

post dput(mydata) to the list, in the body of the email.

I think this and the details you posted today will enable one of us to
give you a much simpler script, or maybe even function, to process
your full dataset.
Please confirm that participant1 and p1 are the same object.

Rich

That

On Tue, Jan 8, 2019 at 10:23 AM Rachel Thompson
<rachel.thompson at student.uva.nl> wrote:
>
> Hi
>
> Thank you for your help and suggestions!
> I have tried a few things and ask help from lots of people online!
>
> My problem is that I am not able to share the database! I tried to recreate one but I wasn't successful.
> So I found a way to analyze each subject individually, but I do not know how to perform the same steps for all of the subjects at once.
> But I just wanted to share what I did, since you tried to help me!
>
> This is what I did.
>
> I stored all the column names in a vector named "Names"
>
> names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")
>
>
>
> colnames(gmoji_passivedata)=names
>
>
>
> I used this code to find the number of participants in the dataset
>
>
>
> length(unique(gmoji_passivedata$participants))
>
> The number of participants is 44
>
>
>
> I used this code to find the unique ID for every participant
>
>
>
> library(plyr)
>
> > count(gmoji_passivedata,?participants")
>
> From the dataset, I selected one participant ""U_..."
>
> I used subset data
>
>
>
> participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")
>
>
>
>
>
> With the table code
>
> table(p1$probetype) I found the counts of all the different values of the probe type column
>
>
>
> edu.mit.media.funf.probe.builtin.ActivityProbe
>
>                                                                       16167
>
> edu.mit.media.funf.probe.builtin.BluetoothProbe
>
>                                                                       405
>
>   edu.mit.media.funf.probe.builtin.CallLogProbe
>
>                                                                       1427
>
>    edu.mit.media.funf.probe.builtin.ScreenProbe
>
>                                                                       1791
>
>      edu.mit.media.funf.probe.builtin.WifiProbe
>
>                                                                        5386
>
>
>
> The count for the call log probe for the selected participant is 1427
>
>
>
> There was only one participant with sms probe for the rest of the participant the count of sms probe is 0
>
>
>
> For the screen probe and activity probe I found the total count (1791 and 16167)
>
>
>
> For screen probe, I used a subset code and set the value detailed column to false and true
>
>
>
> screenon_false=subset(p1,valuedetailed=="False") (this participant 875)
>
> screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)
>
>
>
> and for activity probe to none, low and high to find the required values
>
>
>
> activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)
>
> activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)
>
> activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)
>
>
>
>
>
> I did this for each participant
>
>
> Best,
>
>
> Rachel
>
>
> On Sun, Jan 6, 2019 at 2:48 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> Questions like this
>> 1. I want to have a summary of how many times a specific subject got called
>> (CallLogProbe)
>>
>> suggest that you should look at the table function.  See
>> ?table
>> and run the examples.
>> They show how to get one-way frequency tables and two-way contingency tables.
>>
>> If you have followup questions for the list, you can use the examples in ?table as your starting point.
>> That way you don't need to worry about sharing your own data.
>>
>>
>> On Sun, Jan 6, 2019 at 1:59 PM Rachel Thompson <rachel.thompson at student.uva.nl> wrote:
>>>
>>> Hi Rich,
>>>
>>> I really feel lost at this point.
>>> I need a code that helps me count the phone activity level(high/low/none),
>>> the screen activity (on/off) and the amount calls and SMS of each subject.
>>>
>>> 1. I want to have a summary of how many times a specific subject got called
>>> (CallLogProbe)
>>> 2. I want to have a summary of how many times a specific subject got a text
>>> message (SMS probe)
>>> 3. I want to have a summary of how many times a specific subject
>>> - Turned their screen on - True  (ScreenProbe)
>>> - Or did not turn their screen on - False (ScreenProbe)
>>> 4.  I want to have a summary of the activity level of a specific subject
>>> - Activity level - none (ActivityProbe)
>>> - Activity level- low     (ActivityProbe)
>>> - Activity level - High  (ActivityProbe)
>>>
>>> I want to do this for all the 36 subjects(Participants).
>>> In the end, I have to define the percentages and cutoff points of what is
>>> considered low-medium-high, based on what the results of all the subjects
>>> are. So I am able to see if a specific subject has low social interaction
>>> etc.
>>>
>>> I have tried a lot, with the help of youtube etc. But I feel as if I am
>>> trying a lot of things but without clearly knowing if it is the right step.
>>> I have a csv file, but I need to look into what Jeff said about the guides.
>>> So I am able to share it.
>>>
>>> Best.
>>>
>>>
>>> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com>
>>> wrote:
>>>
>>> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
>>> >
>>> > > I am an intern from Amsterdam and I have to do an analysis in R. I spoke
>>> > > to my professor in Amsterdam and my supervisor's here in Boston. But they
>>> > > are to busy to help. I informed them from the start that I am not
>>> > familiar
>>> > > with R(Rstudio) and they told me that I would receive guidance. So since
>>> > > they can not help me, I decided to share my problem online. (It is a CVS
>>> > > file imported into R)
>>> >
>>> > Rachel,
>>> >
>>> >    I find it interesting that you're put in such a difficult position. I've
>>> > not followed this thread from the start so my comments might be redundant
>>> > or
>>> > inappropriate.
>>> >
>>> >    If you can, describe the problem. That is, what are you being asked to
>>> > find and what are the available data? This information helps us to guide
>>> > you
>>> > to learning the mechanics for accomplishing your task with R.
>>> >
>>> > Regards,
>>> >
>>> > Rich
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From li@t@ @ending from dewey@myzen@co@uk  Tue Jan  8 18:28:35 2019
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 8 Jan 2019 17:28:35 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
Message-ID: <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>

Dear Meriam

Your csv file did not come through as attachments are stripped unless of 
certain types and you post is very hard to read since you are posting in 
HTML. Try renaming the file to ????.txt and set your mailer to send 
plain text then people may be able to help you better.

Michael

On 08/01/2019 15:35, N Meriam wrote:
> I see...
> Here's a portion of what my data looks like (csv file attached).
> I run again and here are the results:
> 
> df4 <- read.csv(file = "mydata.csv", header = TRUE)
> 
>> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"
> 
>> myd[,1][1]  3  4  5  6  8 10
> 
> 
>> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2
> 
>> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
> [1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
> [2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
> [3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
> [4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
> [5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
> [6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"
> 
>> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)
> 
>   marker X88 X9 X17 X25
> [1,]     NA   0  3   3   3
> [2,]     NA   2  0   3   0
> [3,]     NA   0  0   0   0
> [4,]     NA   0  0   3   0
> [5,]     NA   3  3   3   3
> [6,]     NA   0  0   0   0
> 
>> class(genod2) <- "numeric"> class(genod2)[1] "matrix"
> 
>> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
>    is.matrix(genmat) is not TRUE
> 
> Thanks,
> Meriam
> 
> On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>>
>> see in line
>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
>>> Sent: Tuesday, January 8, 2019 3:08 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Warning message: NAs introduced by coercion
>>>
>>> Dear all,
>>>
>>> I have a .csv file called df4. (15752 obs. of 264 variables).
>>> I apply this code but couldn't continue further other analyses, a warning
>>> message keeps coming up. Then, I want to determine max and min
>>> similarity values,
>>> heat map plot, cluster...etc
>>>
>>>> require(SNPRelate)
>>>> library(gdsfmt)
>>>> myd <- read.csv(file = "df4.csv", header = TRUE)
>>>> names(myd)[-1]
>>> myd[,1]
>>>> myd[1:10, 1:10]
>>>   # the data must be 0,1,2 with 3 as missing so you have r
>>>> sample.id <- names(myd)[-1]
>>>> snp.id <- myd[,1]
>>>> snp.position <- 1:length(snp.id) # not needed for ibs
>>>> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
>>>> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
>>> # genotype data must have - in 3
>>>> genod <- myd[,-1]
>>>> genod[is.na(genod)] <- 3
>>>> genod[genod=="0"] <- 0
>>>> genod[genod=="1"] <- 2
>>>> genod[1:10,1:10]
>>>> genod <- as.matrix(genod)
>>
>> matrix can have only one type of data so you probaly changed it to
>> character by such construction.
>>
>>>> class(genod) <- "numeric"
>>
>> This tries to change all "numeric" values to numbers but if it cannot it
>> sets it to NA.
>>
>> something like
>>
>>> head(iris)
>>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> 1          5.1         3.5          1.4         0.2  setosa
>> 2          4.9         3.0          1.4         0.2  setosa
>> 3          4.7         3.2          1.3         0.2  setosa
>> 4          4.6         3.1          1.5         0.2  setosa
>> 5          5.0         3.6          1.4         0.2  setosa
>> 6          5.4         3.9          1.7         0.4  setosa
>>> ir <-head(iris)
>>> irm <- as.matrix(ir)
>>> head(irm)
>>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
>> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
>> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
>> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
>> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
>> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
>>> class(irm) <- "numeric"
>> Warning message:
>> In class(irm) <- "numeric" : NAs introduced by coercion
>>> head(irm)
>>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> 1          5.1         3.5          1.4         0.2      NA
>> 2          4.9         3.0          1.4         0.2      NA
>> 3          4.7         3.2          1.3         0.2      NA
>> 4          4.6         3.1          1.5         0.2      NA
>> 5          5.0         3.6          1.4         0.2      NA
>> 6          5.4         3.9          1.7         0.4      NA
>>>
>>
>> Cheers
>> Petr
>>
>>
>>>
>>>
>>> *Warning message:In class(genod) <- "numeric" : NAs introduced by
>> coercion*
>>>
>>> Maybe I could illustrate more with details so I can be more specific?
>>> Please, let me know.
>>>
>>> I would appreciate your help.
>>> Thanks,
>>> Meriam
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>> about processing and protection of business partner?s personal data are
>> available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@hep@rd @ending from @ppl-eco@y@@com  Tue Jan  8 18:50:08 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 8 Jan 2019 09:50:08 -0800 (PST)
Subject: [R] Question
In-Reply-To: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>

On Tue, 8 Jan 2019, S. Mahmoud Nasrollahi wrote:

> I have got a problem during working with some package in R and in spite of
> trying with R help, internet and any other resources I could not succeed.
> Indeed when I what to install some function like bwplot, boxplot, xyplot I
> receive this sort of messages: Warning in install.packages : package
> ?xyplot? is not available (for R version 3.5.2) Do you know how I can
> solve that?

   Yep. Those plots are part of the lattice package. You can install lattice
(and latticeExtra if you want) with

> installpkg("lattice")

Happy plotting,

Rich


From m@ri@eugeni@u @ending from gm@il@com  Tue Jan  8 16:41:03 2019
From: m@ri@eugeni@u @ending from gm@il@com (=?UTF-8?Q?Maria_Eugenia_Utg=C3=A9s?=)
Date: Tue, 8 Jan 2019 12:41:03 -0300
Subject: [R] External validation for a hurdle model (pscl)
Message-ID: <CAGj5wfmeEF9AbLyzNYU=pQ1YT6GR0sqUdtSh_9ytSu24Z9zLkw@mail.gmail.com>

Hi R-list,
We have constructed a hurdle model some time ago.
Now we were able to gather new data in the same city (38 new sites), and
want to do an external validation to see if the model still performs ok.
All the books and lectures I have read say its the best validation option
but...
I have made a (simple) search, but it seems that as having new data for a
model is rare, have not found anything with the depth enough so as to
reproduce it/adapt it to hurdle models.

I have predicted the probability for non-zero counts
nonzero <- 1 - predict(final, newdata = datosnuevos, type = "prob")[, 1]

and the predicted mean from the count component
countmean <- predict(final, newdata = datosnuevos, type = "count")

I understand that "newdata" is taking into account the new values for the
independent variables (environmental variables), is it?

So, I have to compare the predicted values of y (calculated with the new
values of the environmental variables) with the new observed values.

That would be using the model (constructed with the old values), having as
input the new variables, and having as output a "new" prediction, to be
contrasted with the "new" observed y.

These comparison would be by means of AUC, correct classification, and/or
what other options? Results of the external validation would just be a % of
correct predicted values? plots?

Need some guidance, sorry if the explanation was "basic" but needed to
write it in my own words so as not to miss any detail.

Thank you very much in advance,

Mar?a Eugenia Utg?s

CeNDIE-ANLIS
Buenos Aires
Argentina
a

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Jan  8 19:46:39 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 8 Jan 2019 10:46:39 -0800
Subject: [R] Question
In-Reply-To: <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
 <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>

I think it's ?install.packages

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 8, 2019 at 9:50 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Tue, 8 Jan 2019, S. Mahmoud Nasrollahi wrote:
>
> > I have got a problem during working with some package in R and in spite
> of
> > trying with R help, internet and any other resources I could not succeed.
> > Indeed when I what to install some function like bwplot, boxplot, xyplot
> I
> > receive this sort of messages: Warning in install.packages : package
> > ?xyplot? is not available (for R version 3.5.2) Do you know how I can
> > solve that?
>
>    Yep. Those plots are part of the lattice package. You can install
> lattice
> (and latticeExtra if you want) with
>
> > installpkg("lattice")
>
> Happy plotting,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Jan  8 19:50:14 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 8 Jan 2019 10:50:14 -0800
Subject: [R] External validation for a hurdle model (pscl)
In-Reply-To: <CAGj5wfmeEF9AbLyzNYU=pQ1YT6GR0sqUdtSh_9ytSu24Z9zLkw@mail.gmail.com>
References: <CAGj5wfmeEF9AbLyzNYU=pQ1YT6GR0sqUdtSh_9ytSu24Z9zLkw@mail.gmail.com>
Message-ID: <CAGxFJbTP+Tu56=N1abe8euK8SH6AtvS3LAD7eCXuRChYhfJZUA@mail.gmail.com>

This list is (mostly) about R programming. Your query is (mostly) about
statistics. So you should post on a statistics site like
stats.stackexchange.com
not here; I am pretty sure you'll receive lots of answers there.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 8, 2019 at 10:18 AM Maria Eugenia Utg?s <mariaeugeniau at gmail.com>
wrote:

> Hi R-list,
> We have constructed a hurdle model some time ago.
> Now we were able to gather new data in the same city (38 new sites), and
> want to do an external validation to see if the model still performs ok.
> All the books and lectures I have read say its the best validation option
> but...
> I have made a (simple) search, but it seems that as having new data for a
> model is rare, have not found anything with the depth enough so as to
> reproduce it/adapt it to hurdle models.
>
> I have predicted the probability for non-zero counts
> nonzero <- 1 - predict(final, newdata = datosnuevos, type = "prob")[, 1]
>
> and the predicted mean from the count component
> countmean <- predict(final, newdata = datosnuevos, type = "count")
>
> I understand that "newdata" is taking into account the new values for the
> independent variables (environmental variables), is it?
>
> So, I have to compare the predicted values of y (calculated with the new
> values of the environmental variables) with the new observed values.
>
> That would be using the model (constructed with the old values), having as
> input the new variables, and having as output a "new" prediction, to be
> contrasted with the "new" observed y.
>
> These comparison would be by means of AUC, correct classification, and/or
> what other options? Results of the external validation would just be a % of
> correct predicted values? plots?
>
> Need some guidance, sorry if the explanation was "basic" but needed to
> write it in my own words so as not to miss any detail.
>
> Thank you very much in advance,
>
> Mar?a Eugenia Utg?s
>
> CeNDIE-ANLIS
> Buenos Aires
> Argentina
> a
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ppurk@y@@th@2010 @ending from gm@il@com  Tue Jan  8 19:54:10 2019
From: ppurk@y@@th@2010 @ending from gm@il@com (Priyanka Purkayastha)
Date: Wed, 9 Jan 2019 00:24:10 +0530
Subject: [R] Recursive feature elimination keeping the weights constant
Message-ID: <CALUZZGa8Hqo=bP=b21OLhsyOuHmFdzZb=O4Mg59BdBPBF1gUSQ@mail.gmail.com>

Dear All,

I am trying to build a model by doing recursive elimination of weights one
by one.

This is the example matrix

ID 885038 885039 885040 885041 885042 885043         Label
weights 0.000236 0.004591 0.00017 0.018113 0.000238 0.006537 N/A
1267359 2 0 0 0 0 1 1
1295720 0 0 0 0 0 1 1
1295721 0 0 0 0 0 1 1
1295723 0 0 0 0 0 1 0
1295724 0 0 0 1 0 1 0
1296724 0 0 0 1 0 1 0
12957243 0 0 0 0 0 1 0
12957424 0 0 0 1 0 1 0
12967244 0 0 0 1 0 1 0
12673529 2 0 0 0 0 1 1
1295720 0 0 0 0 0 1 1
12957221 0 0 0 0 0 1 1
Bellow is the code I have written to eliminate minimum rows of weights one
by one and build SVM model.

library(e1071)
library(caret)
library(gplots)
library(ROCR)

data <- read.csv("data.csv", header = TRUE)
rownames(data) <- data[,1]
data<-data[,-1]

for (k in 1:ncol(data))
  {
  rowMin = which.min(data[1,])
  data = data[-rowMin,]
  data = data[-1,]

  inTraining <- createDataPartition(data$Class, p = .70, list = FALSE)
  training <- data[ inTraining,]
  testing  <- data[-inTraining,]

  ## Building the model ####
  svm.model <- svm(Label ~ ., data = training,
cross=10,metric="ROC",type="eps-regression",kernel="linear",na.action=na.omit,probability
= TRUE)

  #prediction and ROC
  svm.model$index
  svm.pred <- predict(svm.model, testing, probability = TRUE)

  #calculating auc
  c <- as.numeric(svm.pred)
  c = c - 1
  pred <- prediction(c, testing$Label)
  perf <- performance(pred,"tpr","fpr")
  plot(perf,fpr.stop=0.1)
  auc <- performance(pred, measure = "auc")
  auc <- auc at y.values[[1]]
  print(paste(ncol(data),colnames(data)[rowMin],auc))

  }

I want my output, like

number of columns, colname with minimum weight, AUC
5 , 885039, 0.67

But I get the following error
Error in svm.default(x, y, scale = scale, ..., na.action = na.action) :
  ?cross? cannot exceed the number of observations!
In addition: Warning message:
In svm.default(x, y, scale = scale, ..., na.action = na.action) :
  Variable(s) ?X885039? and ?X885040? and ?X885042? and ?X885043? constant.
Cannot scale data.

I

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Tue Jan  8 19:56:57 2019
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Tue, 8 Jan 2019 13:56:57 -0500
Subject: [R] Question
In-Reply-To: <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
 <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
 <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
Message-ID: <CC6CD9D3-A348-47BC-9974-63E55A8CDCA8@me.com>

Guys,

lattice is a "recommended" package, which means that it is installed by default with any standard R installation.

Thus, all that is required, as Sarah noted in an earlier reply, is either:

  library(lattice)

or 

  require(lattice)

depending upon preference.

latticeExtra, on the other hand, is a third party package that would need to be installed separately, if desired.

Regards,

Marc Schwartz


> On Jan 8, 2019, at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I think it's ?install.packages
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Jan 8, 2019 at 9:50 AM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
> 
>> On Tue, 8 Jan 2019, S. Mahmoud Nasrollahi wrote:
>> 
>>> I have got a problem during working with some package in R and in spite
>> of
>>> trying with R help, internet and any other resources I could not succeed.
>>> Indeed when I what to install some function like bwplot, boxplot, xyplot
>> I
>>> receive this sort of messages: Warning in install.packages : package
>>> ?xyplot? is not available (for R version 3.5.2) Do you know how I can
>>> solve that?
>> 
>>   Yep. Those plots are part of the lattice package. You can install
>> lattice
>> (and latticeExtra if you want) with
>> 
>>> installpkg("lattice")
>> 
>> Happy plotting,
>> 
>> Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Tue Jan  8 20:08:23 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 8 Jan 2019 11:08:23 -0800 (PST)
Subject: [R] Question
In-Reply-To: <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
 <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
 <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1901081107420.22432@salmo.appl-ecosys.com>

On Tue, 8 Jan 2019, Bert Gunter wrote:

> I think it's ?install.packages

Bert,

   Of course it is. My apologies to the original poster.

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Tue Jan  8 20:09:22 2019
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Tue, 8 Jan 2019 11:09:22 -0800 (PST)
Subject: [R] Question
In-Reply-To: <CC6CD9D3-A348-47BC-9974-63E55A8CDCA8@me.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
 <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
 <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
 <CC6CD9D3-A348-47BC-9974-63E55A8CDCA8@me.com>
Message-ID: <alpine.LNX.2.20.1901081108440.22432@salmo.appl-ecosys.com>

On Tue, 8 Jan 2019, Marc Schwartz wrote:

> lattice is a "recommended" package, which means that it is installed by
> default with any standard R installation.

Marc,

   Thanks for the reminder.

Regards,

Rich


From meri@m@nef @ending from gm@il@com  Tue Jan  8 20:37:50 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Tue, 8 Jan 2019 13:37:50 -0600
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
 <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>
Message-ID: <CAL1He1+knqhTz31JrfK-Wq3rxJ332QFUV1p3OcqQ2RXPY4TkKQ@mail.gmail.com>

Here's a portion of what my data looks like (text file format attached).
When running in R, it gives me this:

> df4 <- read.csv(file = "mydata.csv", header = TRUE)
> require(SNPRelate)
> library(gdsfmt)
> myd <- df4
> myd <- df4
> names(myd)[-1]
[1] "marker" "X88"    "X9"     "X17"    "X25"
> myd[,1]
[1]  3  4  5  6  8 10
# the data must be 0,1,2 with 3 as missing so you have r
> sample.id <- names(myd)[-1]
> snp.id <- myd[,1]
> snp.position <- 1:length(snp.id) # not needed for ibs
> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
# genotype data must have - in 3
> genod <- myd[,-1]
> genod[is.na(genod)] <- 3
> genod[genod=="0"] <- 0
> genod[genod=="1"] <- 2
> genod2 <- as.matrix(genod)
> head(genod2)
         marker                                             X88   X9
 X17   X25
[1,]  "100023173|F|0-47:G>A-47:G>A"     "0"    "3"    "3"     "3"
[2,]  "1043336|F|0-7:A>G-7:A>G"             "2"    "0"    "3"     "0"
[3,]  "1212218|F|0-49:A>G-49:A>G"         "0"    "0"    "0"     "0"
[4,]  "1019554|F|0-14:T>C-14:T>C"           "0"   "0"    "3"     "0"
[5,]  "100024550|F|0-16:G>A-16:G>A"     "3"    "3"    "3"     "3"
[6,]  "1106702|F|0-8:C>A-8:C>A"              "0"   "0"     "0"     "0"
> class(genod2) <- "numeric"
Warning message: In class(genod2) <- "numeric" : NAs introduced by coercion
> head(genod2)
        marker   X88  X9   X17  X25
[1,]     NA         0      3     3       3
[2,]     NA         2      0     3       0
[3,]     NA         0      0     0       0
[4,]     NA         0      0     3       0
[5,]     NA         3      3     3       3
[6,]     NA         0      0     0       0
> class(genod2) <- "numeric"
> class(genod2)
[1] "matrix"
# read data
> filn <-"simTunesian.gds"
> snpgdsCreateGeno(filn, genmat = genod,
+                  sample.id = sample.id, snp.id = snp.id,
+                  snp.chromosome = snp.chromosome,
+                  snp.position = snp.position,
+                  snp.allele = snp.allele, snpfirstdim=TRUE)
Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,
 :   is.matrix(genmat) is not TRUE

Can't find a solution to my problem...my guess is that the problem
comes from converting the column 'marker' factor to numerical.

Best,
Meriam

On Tue, Jan 8, 2019 at 11:28 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> Dear Meriam
>
> Your csv file did not come through as attachments are stripped unless of
> certain types and you post is very hard to read since you are posting in
> HTML. Try renaming the file to ????.txt and set your mailer to send
> plain text then people may be able to help you better.
>
> Michael
>
> On 08/01/2019 15:35, N Meriam wrote:
> > I see...
> > Here's a portion of what my data looks like (csv file attached).
> > I run again and here are the results:
> >
> > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> >
> >> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"
> >
> >> myd[,1][1]  3  4  5  6  8 10
> >
> >
> >> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2
> >
> >> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
> > [1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
> > [2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
> > [3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
> > [4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
> > [5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
> > [6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"
> >
> >> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)
> >
> >   marker X88 X9 X17 X25
> > [1,]     NA   0  3   3   3
> > [2,]     NA   2  0   3   0
> > [3,]     NA   0  0   0   0
> > [4,]     NA   0  0   3   0
> > [5,]     NA   3  3   3   3
> > [6,]     NA   0  0   0   0
> >
> >> class(genod2) <- "numeric"> class(genod2)[1] "matrix"
> >
> >> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
> >    is.matrix(genmat) is not TRUE
> >
> > Thanks,
> > Meriam
> >
> > On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> >> Hi
> >>
> >> see in line
> >>
> >>> -----Original Message-----
> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> >>> Sent: Tuesday, January 8, 2019 3:08 PM
> >>> To: r-help at r-project.org
> >>> Subject: [R] Warning message: NAs introduced by coercion
> >>>
> >>> Dear all,
> >>>
> >>> I have a .csv file called df4. (15752 obs. of 264 variables).
> >>> I apply this code but couldn't continue further other analyses, a warning
> >>> message keeps coming up. Then, I want to determine max and min
> >>> similarity values,
> >>> heat map plot, cluster...etc
> >>>
> >>>> require(SNPRelate)
> >>>> library(gdsfmt)
> >>>> myd <- read.csv(file = "df4.csv", header = TRUE)
> >>>> names(myd)[-1]
> >>> myd[,1]
> >>>> myd[1:10, 1:10]
> >>>   # the data must be 0,1,2 with 3 as missing so you have r
> >>>> sample.id <- names(myd)[-1]
> >>>> snp.id <- myd[,1]
> >>>> snp.position <- 1:length(snp.id) # not needed for ibs
> >>>> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> >>>> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> >>> # genotype data must have - in 3
> >>>> genod <- myd[,-1]
> >>>> genod[is.na(genod)] <- 3
> >>>> genod[genod=="0"] <- 0
> >>>> genod[genod=="1"] <- 2
> >>>> genod[1:10,1:10]
> >>>> genod <- as.matrix(genod)
> >>
> >> matrix can have only one type of data so you probaly changed it to
> >> character by such construction.
> >>
> >>>> class(genod) <- "numeric"
> >>
> >> This tries to change all "numeric" values to numbers but if it cannot it
> >> sets it to NA.
> >>
> >> something like
> >>
> >>> head(iris)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1          5.1         3.5          1.4         0.2  setosa
> >> 2          4.9         3.0          1.4         0.2  setosa
> >> 3          4.7         3.2          1.3         0.2  setosa
> >> 4          4.6         3.1          1.5         0.2  setosa
> >> 5          5.0         3.6          1.4         0.2  setosa
> >> 6          5.4         3.9          1.7         0.4  setosa
> >>> ir <-head(iris)
> >>> irm <- as.matrix(ir)
> >>> head(irm)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
> >> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
> >> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
> >> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
> >> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
> >> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> >>> class(irm) <- "numeric"
> >> Warning message:
> >> In class(irm) <- "numeric" : NAs introduced by coercion
> >>> head(irm)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1          5.1         3.5          1.4         0.2      NA
> >> 2          4.9         3.0          1.4         0.2      NA
> >> 3          4.7         3.2          1.3         0.2      NA
> >> 4          4.6         3.1          1.5         0.2      NA
> >> 5          5.0         3.6          1.4         0.2      NA
> >> 6          5.4         3.9          1.7         0.4      NA
> >>>
> >>
> >> Cheers
> >> Petr
> >>
> >>
> >>>
> >>>
> >>> *Warning message:In class(genod) <- "numeric" : NAs introduced by
> >> coercion*
> >>>
> >>> Maybe I could illustrate more with details so I can be more specific?
> >>> Please, let me know.
> >>>
> >>> I would appreciate your help.
> >>> Thanks,
> >>> Meriam
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> >> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> >> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> >> about processing and protection of business partner?s personal data are
> >> available on website:
> >> https://www.precheza.cz/en/personal-data-protection-principles/
> >> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> >> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> >> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> >> documents attached to it may be confidential and are subject to the legally
> >> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >>
> >>
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mydata.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190108/e922ba8a/attachment.txt>

From tring @ending from gvdnet@dk  Tue Jan  8 20:48:37 2019
From: tring @ending from gvdnet@dk (Troels Ring)
Date: Tue, 8 Jan 2019 20:48:37 +0100
Subject: [R] objects are masked _by_ '.GlobalEnv'
Message-ID: <12a2301d4a78b$262775c0$72766140$@gvdnet.dk>

Dear friends - this is really a question I'm sorry about since it doesn't
follow the requirements. I have made a R package via RStudio and it causes
problems when I try to load some data from within the package. I'm on
windows, R version 3.5.1 (2018-07-02). 

 

When I am in the directory with the package project (also with plain R)

 

> data(Schell)

> library(chaRBAL)

 

Attaches package: 'chaRBAL'    my translation from Danish

 

The following objects are masked _by_ '.GlobalEnv':

 

    Na, TOTAL, WA

 

#  BUT: the  values are correct from data(Schell):

 

> Na

[1] 0.008 0.024 0.044 0.064 0.082 0.098 0.114 0.128 0.142 0.154 0.166 0.176
0.188 0.198 0.206 0.214 0.224 0.232

[19] 0.242 0.252 0.264 0.278 0.292 0.310 0.330 0.348 0.364 0.374 0.384 0.390

> TOTAL

       [,1]  [,2]

[1,] 0.004 0.098

[2,] 0.012 0.094

[3,] 0.022 0.089

[4,] 0.032 0.084

[5,] 0.041 0.079

----25 more so

> WA

$`buffs`

$`buffs`[[1]]

[1] "Phos"

 

$`buffs`[[2]]

[1] "Cit"

 

 

$KA

$KA[[1]]

[1] 6.918310e-03 6.165950e-08 4.786301e-13

 

$KA[[2]]

[1] 7.413102e-04 1.737801e-05 3.981072e-07

 

# Which is all OK

# But when now I make the same call again

 

 

> data(Schell)

ls()

# [1] "Alb"   "Ca"    "Cl"    "K"     "Lact"  "Mg"    "Na"    "PCO2"  "S1"


#[10] "TOTAL" "WA"   

 

TOTAL

#      [,1]   [,2]   [,3]

#   [1,] 0.0267 0.0267 0.0267

#   [2,] 0.0200 0.0200 0.0200

 

# which is wrong and belongs to another included dataset. How did that
happen to be caught in globalenvironment, how can I avoid that and get rid
# of it?

 

I can see I need to know more about environments. What do you think happens?

 

All best wishes

Troels Ring, MD

Aalborg


	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jan  8 20:48:57 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 08 Jan 2019 11:48:57 -0800
Subject: [R] Question
In-Reply-To: <CC6CD9D3-A348-47BC-9974-63E55A8CDCA8@me.com>
References: <CABngTRZj1=e8YCq7WR-10Fx1ENeAVbhTjRLSRx5okw7KcRJCAQ@mail.gmail.com>
 <alpine.LNX.2.20.1901080946460.14656@salmo.appl-ecosys.com>
 <CAGxFJbTYEciXwLASrAmfMPkre99=NkGHKL2K4RT2XUkLCQdSzg@mail.gmail.com>
 <CC6CD9D3-A348-47BC-9974-63E55A8CDCA8@me.com>
Message-ID: <CBED9078-1C60-4189-A567-526D22878105@dcn.davis.ca.us>

Er, just keep it simple, Marc... give one option:

library(lattice)

If you _ever_ use require() without acting upon the return value then you are setting yourself or someone else up for confusing missing objects errors someday for no good reason. This _isn't_ just personal preference... by choosing to use the require function you are taking responsibility for the case where that package is missing, and by ignoring the return value you are immediately abdicating that responsibility. Let the error appear where it makes sense by using the library function in the first place.

On January 8, 2019 10:56:57 AM PST, Marc Schwartz via R-help <r-help at r-project.org> wrote:
>Guys,
>
>lattice is a "recommended" package, which means that it is installed by
>default with any standard R installation.
>
>Thus, all that is required, as Sarah noted in an earlier reply, is
>either:
>
>  library(lattice)
>
>or 
>
>  require(lattice)
>
>depending upon preference.
>
>latticeExtra, on the other hand, is a third party package that would
>need to be installed separately, if desired.
>
>Regards,
>
>Marc Schwartz
>
>
>> On Jan 8, 2019, at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> 
>> I think it's ?install.packages
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming
>along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Tue, Jan 8, 2019 at 9:50 AM Rich Shepard
><rshepard at appl-ecosys.com>
>> wrote:
>> 
>>> On Tue, 8 Jan 2019, S. Mahmoud Nasrollahi wrote:
>>> 
>>>> I have got a problem during working with some package in R and in
>spite
>>> of
>>>> trying with R help, internet and any other resources I could not
>succeed.
>>>> Indeed when I what to install some function like bwplot, boxplot,
>xyplot
>>> I
>>>> receive this sort of messages: Warning in install.packages :
>package
>>>> ?xyplot? is not available (for R version 3.5.2) Do you know how I
>can
>>>> solve that?
>>> 
>>>   Yep. Those plots are part of the lattice package. You can install
>>> lattice
>>> (and latticeExtra if you want) with
>>> 
>>>> installpkg("lattice")
>>> 
>>> Happy plotting,
>>> 
>>> Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dc@rl@on @ending from t@mu@edu  Tue Jan  8 21:00:54 2019
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 8 Jan 2019 20:00:54 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1+knqhTz31JrfK-Wq3rxJ332QFUV1p3OcqQ2RXPY4TkKQ@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
 <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>
 <CAL1He1+knqhTz31JrfK-Wq3rxJ332QFUV1p3OcqQ2RXPY4TkKQ@mail.gmail.com>
Message-ID: <4993bca4bda64a479fdd6e9ff1b7f5de@tamu.edu>

Your attached file is not a .csv file since the field are not separated by commas (just rename the mydata.csv to mydata.txt).

The command "genod2 <- as.matrix(genod)" created a character matrix from the data frame genod.  When you try to force genod2 to numeric, the marker column becomes NAs which is probably not what you want.

The error message is because you passed genod (a data frame) to the snpgdsCreateGeno() function not genod2 (the matrix you created from genod).

------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of N Meriam
Sent: Tuesday, January 8, 2019 1:38 PM
To: Michael Dewey <lists at dewey.myzen.co.uk>
Cc: r-help at r-project.org
Subject: Re: [R] Warning message: NAs introduced by coercion

Here's a portion of what my data looks like (text file format attached).
When running in R, it gives me this:

> df4 <- read.csv(file = "mydata.csv", header = TRUE)
> require(SNPRelate)
> library(gdsfmt)
> myd <- df4
> myd <- df4
> names(myd)[-1]
[1] "marker" "X88"    "X9"     "X17"    "X25"
> myd[,1]
[1]  3  4  5  6  8 10
# the data must be 0,1,2 with 3 as missing so you have r
> sample.id <- names(myd)[-1]
> snp.id <- myd[,1]
> snp.position <- 1:length(snp.id) # not needed for ibs
> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
# genotype data must have - in 3
> genod <- myd[,-1]
> genod[is.na(genod)] <- 3
> genod[genod=="0"] <- 0
> genod[genod=="1"] <- 2
> genod2 <- as.matrix(genod)
> head(genod2)
         marker                                             X88   X9
 X17   X25
[1,]  "100023173|F|0-47:G>A-47:G>A"     "0"    "3"    "3"     "3"
[2,]  "1043336|F|0-7:A>G-7:A>G"             "2"    "0"    "3"     "0"
[3,]  "1212218|F|0-49:A>G-49:A>G"         "0"    "0"    "0"     "0"
[4,]  "1019554|F|0-14:T>C-14:T>C"           "0"   "0"    "3"     "0"
[5,]  "100024550|F|0-16:G>A-16:G>A"     "3"    "3"    "3"     "3"
[6,]  "1106702|F|0-8:C>A-8:C>A"              "0"   "0"     "0"     "0"
> class(genod2) <- "numeric"
Warning message: In class(genod2) <- "numeric" : NAs introduced by coercion
> head(genod2)
        marker   X88  X9   X17  X25
[1,]     NA         0      3     3       3
[2,]     NA         2      0     3       0
[3,]     NA         0      0     0       0
[4,]     NA         0      0     3       0
[5,]     NA         3      3     3       3
[6,]     NA         0      0     0       0
> class(genod2) <- "numeric"
> class(genod2)
[1] "matrix"
# read data
> filn <-"simTunesian.gds"
> snpgdsCreateGeno(filn, genmat = genod,
+                  sample.id = sample.id, snp.id = snp.id,
+                  snp.chromosome = snp.chromosome,
+                  snp.position = snp.position,
+                  snp.allele = snp.allele, snpfirstdim=TRUE)
Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,
 :   is.matrix(genmat) is not TRUE

Can't find a solution to my problem...my guess is that the problem
comes from converting the column 'marker' factor to numerical.

Best,
Meriam

On Tue, Jan 8, 2019 at 11:28 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> Dear Meriam
>
> Your csv file did not come through as attachments are stripped unless of
> certain types and you post is very hard to read since you are posting in
> HTML. Try renaming the file to ????.txt and set your mailer to send
> plain text then people may be able to help you better.
>
> Michael
>
> On 08/01/2019 15:35, N Meriam wrote:
> > I see...
> > Here's a portion of what my data looks like (csv file attached).
> > I run again and here are the results:
> >
> > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> >
> >> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"
> >
> >> myd[,1][1]  3  4  5  6  8 10
> >
> >
> >> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2
> >
> >> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
> > [1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
> > [2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
> > [3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
> > [4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
> > [5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
> > [6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"
> >
> >> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)
> >
> >   marker X88 X9 X17 X25
> > [1,]     NA   0  3   3   3
> > [2,]     NA   2  0   3   0
> > [3,]     NA   0  0   0   0
> > [4,]     NA   0  0   3   0
> > [5,]     NA   3  3   3   3
> > [6,]     NA   0  0   0   0
> >
> >> class(genod2) <- "numeric"> class(genod2)[1] "matrix"
> >
> >> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
> >    is.matrix(genmat) is not TRUE
> >
> > Thanks,
> > Meriam
> >
> > On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> >> Hi
> >>
> >> see in line
> >>
> >>> -----Original Message-----
> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> >>> Sent: Tuesday, January 8, 2019 3:08 PM
> >>> To: r-help at r-project.org
> >>> Subject: [R] Warning message: NAs introduced by coercion
> >>>
> >>> Dear all,
> >>>
> >>> I have a .csv file called df4. (15752 obs. of 264 variables).
> >>> I apply this code but couldn't continue further other analyses, a warning
> >>> message keeps coming up. Then, I want to determine max and min
> >>> similarity values,
> >>> heat map plot, cluster...etc
> >>>
> >>>> require(SNPRelate)
> >>>> library(gdsfmt)
> >>>> myd <- read.csv(file = "df4.csv", header = TRUE)
> >>>> names(myd)[-1]
> >>> myd[,1]
> >>>> myd[1:10, 1:10]
> >>>   # the data must be 0,1,2 with 3 as missing so you have r
> >>>> sample.id <- names(myd)[-1]
> >>>> snp.id <- myd[,1]
> >>>> snp.position <- 1:length(snp.id) # not needed for ibs
> >>>> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> >>>> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> >>> # genotype data must have - in 3
> >>>> genod <- myd[,-1]
> >>>> genod[is.na(genod)] <- 3
> >>>> genod[genod=="0"] <- 0
> >>>> genod[genod=="1"] <- 2
> >>>> genod[1:10,1:10]
> >>>> genod <- as.matrix(genod)
> >>
> >> matrix can have only one type of data so you probaly changed it to
> >> character by such construction.
> >>
> >>>> class(genod) <- "numeric"
> >>
> >> This tries to change all "numeric" values to numbers but if it cannot it
> >> sets it to NA.
> >>
> >> something like
> >>
> >>> head(iris)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1          5.1         3.5          1.4         0.2  setosa
> >> 2          4.9         3.0          1.4         0.2  setosa
> >> 3          4.7         3.2          1.3         0.2  setosa
> >> 4          4.6         3.1          1.5         0.2  setosa
> >> 5          5.0         3.6          1.4         0.2  setosa
> >> 6          5.4         3.9          1.7         0.4  setosa
> >>> ir <-head(iris)
> >>> irm <- as.matrix(ir)
> >>> head(irm)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
> >> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
> >> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
> >> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
> >> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
> >> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> >>> class(irm) <- "numeric"
> >> Warning message:
> >> In class(irm) <- "numeric" : NAs introduced by coercion
> >>> head(irm)
> >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> >> 1          5.1         3.5          1.4         0.2      NA
> >> 2          4.9         3.0          1.4         0.2      NA
> >> 3          4.7         3.2          1.3         0.2      NA
> >> 4          4.6         3.1          1.5         0.2      NA
> >> 5          5.0         3.6          1.4         0.2      NA
> >> 6          5.4         3.9          1.7         0.4      NA
> >>>
> >>
> >> Cheers
> >> Petr
> >>
> >>
> >>>
> >>>
> >>> *Warning message:In class(genod) <- "numeric" : NAs introduced by
> >> coercion*
> >>>
> >>> Maybe I could illustrate more with details so I can be more specific?
> >>> Please, let me know.
> >>>
> >>> I would appreciate your help.
> >>> Thanks,
> >>> Meriam
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> >> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> >> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> >> about processing and protection of business partner?s personal data are
> >> available on website:
> >> https://www.precheza.cz/en/personal-data-protection-principles/
> >> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> >> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> >> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> >> documents attached to it may be confidential and are subject to the legally
> >> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >>
> >>
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil

From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jan  8 21:08:21 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 08 Jan 2019 12:08:21 -0800
Subject: [R] External validation for a hurdle model (pscl)
In-Reply-To: <CAGxFJbTP+Tu56=N1abe8euK8SH6AtvS3LAD7eCXuRChYhfJZUA@mail.gmail.com>
References: <CAGj5wfmeEF9AbLyzNYU=pQ1YT6GR0sqUdtSh_9ytSu24Z9zLkw@mail.gmail.com>
 <CAGxFJbTP+Tu56=N1abe8euK8SH6AtvS3LAD7eCXuRChYhfJZUA@mail.gmail.com>
Message-ID: <41B961DE-B038-4792-99BA-431145031F3D@dcn.davis.ca.us>

That said, the gist of the OP's outline is correct, and the main reason to look elsewhere is to get more thorough advice on what statistical concerns should be addressed than would be on topic here.

One comment: reviewing plots of differences versus various independent variables for systematic biases is a task R is particularly well suited for, but discovering which plots highlight issues with your model or data takes familiarity with your data (explore) and with theory (which you learn elsewhere) and with R (which we can help with if you have more specific questions).

On January 8, 2019 10:50:14 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>This list is (mostly) about R programming. Your query is (mostly) about
>statistics. So you should post on a statistics site like
>stats.stackexchange.com
>not here; I am pretty sure you'll receive lots of answers there.
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Tue, Jan 8, 2019 at 10:18 AM Maria Eugenia Utg?s
><mariaeugeniau at gmail.com>
>wrote:
>
>> Hi R-list,
>> We have constructed a hurdle model some time ago.
>> Now we were able to gather new data in the same city (38 new sites),
>and
>> want to do an external validation to see if the model still performs
>ok.
>> All the books and lectures I have read say its the best validation
>option
>> but...
>> I have made a (simple) search, but it seems that as having new data
>for a
>> model is rare, have not found anything with the depth enough so as to
>> reproduce it/adapt it to hurdle models.
>>
>> I have predicted the probability for non-zero counts
>> nonzero <- 1 - predict(final, newdata = datosnuevos, type = "prob")[,
>1]
>>
>> and the predicted mean from the count component
>> countmean <- predict(final, newdata = datosnuevos, type = "count")
>>
>> I understand that "newdata" is taking into account the new values for
>the
>> independent variables (environmental variables), is it?
>>
>> So, I have to compare the predicted values of y (calculated with the
>new
>> values of the environmental variables) with the new observed values.
>>
>> That would be using the model (constructed with the old values),
>having as
>> input the new variables, and having as output a "new" prediction, to
>be
>> contrasted with the "new" observed y.
>>
>> These comparison would be by means of AUC, correct classification,
>and/or
>> what other options? Results of the external validation would just be
>a % of
>> correct predicted values? plots?
>>
>> Need some guidance, sorry if the explanation was "basic" but needed
>to
>> write it in my own words so as not to miss any detail.
>>
>> Thank you very much in advance,
>>
>> Mar?a Eugenia Utg?s
>>
>> CeNDIE-ANLIS
>> Buenos Aires
>> Argentina
>> a
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jan  8 21:28:04 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 08 Jan 2019 12:28:04 -0800
Subject: [R] objects are masked _by_ '.GlobalEnv'
In-Reply-To: <12a2301d4a78b$262775c0$72766140$@gvdnet.dk>
References: <12a2301d4a78b$262775c0$72766140$@gvdnet.dk>
Message-ID: <A38B8685-CBD8-45B3-9E24-009F484C8899@dcn.davis.ca.us>

There is a mailing list for questions about packages... see the Posting Guide.

On January 8, 2019 11:48:37 AM PST, Troels Ring <tring at gvdnet.dk> wrote:
>Dear friends - this is really a question I'm sorry about since it
>doesn't
>follow the requirements. I have made a R package via RStudio and it
>causes
>problems when I try to load some data from within the package. I'm on
>windows, R version 3.5.1 (2018-07-02). 
>
> 
>
>When I am in the directory with the package project (also with plain R)
>
> 
>
>> data(Schell)
>
>> library(chaRBAL)
>
> 
>
>Attaches package: 'chaRBAL'    my translation from Danish
>
> 
>
>The following objects are masked _by_ '.GlobalEnv':
>
> 
>
>    Na, TOTAL, WA
>
> 
>
>#  BUT: the  values are correct from data(Schell):
>
> 
>
>> Na
>
>[1] 0.008 0.024 0.044 0.064 0.082 0.098 0.114 0.128 0.142 0.154 0.166
>0.176
>0.188 0.198 0.206 0.214 0.224 0.232
>
>[19] 0.242 0.252 0.264 0.278 0.292 0.310 0.330 0.348 0.364 0.374 0.384
>0.390
>
>> TOTAL
>
>       [,1]  [,2]
>
>[1,] 0.004 0.098
>
>[2,] 0.012 0.094
>
>[3,] 0.022 0.089
>
>[4,] 0.032 0.084
>
>[5,] 0.041 0.079
>
>----25 more so
>
>> WA
>
>$`buffs`
>
>$`buffs`[[1]]
>
>[1] "Phos"
>
> 
>
>$`buffs`[[2]]
>
>[1] "Cit"
>
> 
>
> 
>
>$KA
>
>$KA[[1]]
>
>[1] 6.918310e-03 6.165950e-08 4.786301e-13
>
> 
>
>$KA[[2]]
>
>[1] 7.413102e-04 1.737801e-05 3.981072e-07
>
> 
>
># Which is all OK
>
># But when now I make the same call again
>
> 
>
> 
>
>> data(Schell)
>
>ls()
>
># [1] "Alb"   "Ca"    "Cl"    "K"     "Lact"  "Mg"    "Na"    "PCO2" 
>"S1"
>
>
>#[10] "TOTAL" "WA"   
>
> 
>
>TOTAL
>
>#      [,1]   [,2]   [,3]
>
>#   [1,] 0.0267 0.0267 0.0267
>
>#   [2,] 0.0200 0.0200 0.0200
>
> 
>
># which is wrong and belongs to another included dataset. How did that
>happen to be caught in globalenvironment, how can I avoid that and get
>rid
># of it?
>
> 
>
>I can see I need to know more about environments. What do you think
>happens?
>
> 
>
>All best wishes
>
>Troels Ring, MD
>
>Aalborg
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From meri@m@nef @ending from gm@il@com  Tue Jan  8 22:43:32 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Tue, 8 Jan 2019 15:43:32 -0600
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <4993bca4bda64a479fdd6e9ff1b7f5de@tamu.edu>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
 <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>
 <CAL1He1+knqhTz31JrfK-Wq3rxJ332QFUV1p3OcqQ2RXPY4TkKQ@mail.gmail.com>
 <4993bca4bda64a479fdd6e9ff1b7f5de@tamu.edu>
Message-ID: <CAL1He1KrGmdJczHdNBMSMYLmHumiFyZ82rYgBbdwZFYmX3eaFQ@mail.gmail.com>

Yes, sorry. I attached the file once again.
Well, still getting the same warning.

> class(genod) <- "numeric"
Warning message:
In class(genod) <- "numeric" : NAs introduced by coercion
> class(genod)
[1] "matrix"

Then, I run the following code and it gives this:

> filn <-"simTunesian.gds"
> snpgdsCreateGeno(filn, genmat = genod,
+                  sample.id = sample.id, snp.id = snp.id,
+                  snp.chromosome = snp.chromosome,
+                  snp.position = snp.position,
+                  snp.allele = snp.allele, snpfirstdim=TRUE)
> # calculate similarity matrix
> # Open the GDS file
> (genofile <- snpgdsOpen(filn))
File: C:\Users\DELL\Documents\TEST\simTunesian.gds (1.4M)
+    [  ] *
|--+ sample.id   { Str8 363 ZIP_ra(42.5%), 755B }
|--+ snp.id   { Int32 15752 ZIP_ra(35.1%), 21.6K }
|--+ snp.position   { Int32 15752 ZIP_ra(34.7%), 21.3K }
|--+ snp.chromosome   { Float64 15752 ZIP_ra(0.18%), 230B }
|--+ snp.allele   { Str8 15752 ZIP_ra(0.16%), 108B }
\--+ genotype   { Bit2 15752x363, 1.4M } *
> ibs <- snpgdsIBS(genofile, remove.monosnp = FALSE, num.thread=1)
Identity-By-State (IBS) analysis on genotypes:
Excluding 0 SNP on non-autosomes
Working space: 363 samples, 15,752 SNPs
    using 1 (CPU) core
IBS:    the sum of all selected genotypes (0,1,2) = 3658952
Tue Jan 08 15:38:00 2019    (internal increment: 42880)
[==================================================] 100%, completed in 0s
Tue Jan 08 15:38:00 2019    Done.
> # maximum similarity value
> max(ibs$ibs)
[1] NaN
> # minimum similarity value
> min(ibs$ibs)
[1] NaN

As you can see, I can't continue my analysis (heat map plot,
clustering with hclust) because values are NaN.


On Tue, Jan 8, 2019 at 2:01 PM David L Carlson <dcarlson at tamu.edu> wrote:
>
> Your attached file is not a .csv file since the field are not separated by commas (just rename the mydata.csv to mydata.txt).
>
> The command "genod2 <- as.matrix(genod)" created a character matrix from the data frame genod.  When you try to force genod2 to numeric, the marker column becomes NAs which is probably not what you want.
>
> The error message is because you passed genod (a data frame) to the snpgdsCreateGeno() function not genod2 (the matrix you created from genod).
>
> ------------------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of N Meriam
> Sent: Tuesday, January 8, 2019 1:38 PM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org
> Subject: Re: [R] Warning message: NAs introduced by coercion
>
> Here's a portion of what my data looks like (text file format attached).
> When running in R, it gives me this:
>
> > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> > require(SNPRelate)
> > library(gdsfmt)
> > myd <- df4
> > myd <- df4
> > names(myd)[-1]
> [1] "marker" "X88"    "X9"     "X17"    "X25"
> > myd[,1]
> [1]  3  4  5  6  8 10
> # the data must be 0,1,2 with 3 as missing so you have r
> > sample.id <- names(myd)[-1]
> > snp.id <- myd[,1]
> > snp.position <- 1:length(snp.id) # not needed for ibs
> > snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> # genotype data must have - in 3
> > genod <- myd[,-1]
> > genod[is.na(genod)] <- 3
> > genod[genod=="0"] <- 0
> > genod[genod=="1"] <- 2
> > genod2 <- as.matrix(genod)
> > head(genod2)
>          marker                                             X88   X9
>  X17   X25
> [1,]  "100023173|F|0-47:G>A-47:G>A"     "0"    "3"    "3"     "3"
> [2,]  "1043336|F|0-7:A>G-7:A>G"             "2"    "0"    "3"     "0"
> [3,]  "1212218|F|0-49:A>G-49:A>G"         "0"    "0"    "0"     "0"
> [4,]  "1019554|F|0-14:T>C-14:T>C"           "0"   "0"    "3"     "0"
> [5,]  "100024550|F|0-16:G>A-16:G>A"     "3"    "3"    "3"     "3"
> [6,]  "1106702|F|0-8:C>A-8:C>A"              "0"   "0"     "0"     "0"
> > class(genod2) <- "numeric"
> Warning message: In class(genod2) <- "numeric" : NAs introduced by coercion
> > head(genod2)
>         marker   X88  X9   X17  X25
> [1,]     NA         0      3     3       3
> [2,]     NA         2      0     3       0
> [3,]     NA         0      0     0       0
> [4,]     NA         0      0     3       0
> [5,]     NA         3      3     3       3
> [6,]     NA         0      0     0       0
> > class(genod2) <- "numeric"
> > class(genod2)
> [1] "matrix"
> # read data
> > filn <-"simTunesian.gds"
> > snpgdsCreateGeno(filn, genmat = genod,
> +                  sample.id = sample.id, snp.id = snp.id,
> +                  snp.chromosome = snp.chromosome,
> +                  snp.position = snp.position,
> +                  snp.allele = snp.allele, snpfirstdim=TRUE)
> Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,
>  :   is.matrix(genmat) is not TRUE
>
> Can't find a solution to my problem...my guess is that the problem
> comes from converting the column 'marker' factor to numerical.
>
> Best,
> Meriam
>
> On Tue, Jan 8, 2019 at 11:28 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> >
> > Dear Meriam
> >
> > Your csv file did not come through as attachments are stripped unless of
> > certain types and you post is very hard to read since you are posting in
> > HTML. Try renaming the file to ????.txt and set your mailer to send
> > plain text then people may be able to help you better.
> >
> > Michael
> >
> > On 08/01/2019 15:35, N Meriam wrote:
> > > I see...
> > > Here's a portion of what my data looks like (csv file attached).
> > > I run again and here are the results:
> > >
> > > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> > >
> > >> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"
> > >
> > >> myd[,1][1]  3  4  5  6  8 10
> > >
> > >
> > >> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2
> > >
> > >> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
> > > [1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
> > > [2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
> > > [3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
> > > [4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
> > > [5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
> > > [6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"
> > >
> > >> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)
> > >
> > >   marker X88 X9 X17 X25
> > > [1,]     NA   0  3   3   3
> > > [2,]     NA   2  0   3   0
> > > [3,]     NA   0  0   0   0
> > > [4,]     NA   0  0   3   0
> > > [5,]     NA   3  3   3   3
> > > [6,]     NA   0  0   0   0
> > >
> > >> class(genod2) <- "numeric"> class(genod2)[1] "matrix"
> > >
> > >> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
> > >    is.matrix(genmat) is not TRUE
> > >
> > > Thanks,
> > > Meriam
> > >
> > > On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >
> > >> Hi
> > >>
> > >> see in line
> > >>
> > >>> -----Original Message-----
> > >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> > >>> Sent: Tuesday, January 8, 2019 3:08 PM
> > >>> To: r-help at r-project.org
> > >>> Subject: [R] Warning message: NAs introduced by coercion
> > >>>
> > >>> Dear all,
> > >>>
> > >>> I have a .csv file called df4. (15752 obs. of 264 variables).
> > >>> I apply this code but couldn't continue further other analyses, a warning
> > >>> message keeps coming up. Then, I want to determine max and min
> > >>> similarity values,
> > >>> heat map plot, cluster...etc
> > >>>
> > >>>> require(SNPRelate)
> > >>>> library(gdsfmt)
> > >>>> myd <- read.csv(file = "df4.csv", header = TRUE)
> > >>>> names(myd)[-1]
> > >>> myd[,1]
> > >>>> myd[1:10, 1:10]
> > >>>   # the data must be 0,1,2 with 3 as missing so you have r
> > >>>> sample.id <- names(myd)[-1]
> > >>>> snp.id <- myd[,1]
> > >>>> snp.position <- 1:length(snp.id) # not needed for ibs
> > >>>> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > >>>> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> > >>> # genotype data must have - in 3
> > >>>> genod <- myd[,-1]
> > >>>> genod[is.na(genod)] <- 3
> > >>>> genod[genod=="0"] <- 0
> > >>>> genod[genod=="1"] <- 2
> > >>>> genod[1:10,1:10]
> > >>>> genod <- as.matrix(genod)
> > >>
> > >> matrix can have only one type of data so you probaly changed it to
> > >> character by such construction.
> > >>
> > >>>> class(genod) <- "numeric"
> > >>
> > >> This tries to change all "numeric" values to numbers but if it cannot it
> > >> sets it to NA.
> > >>
> > >> something like
> > >>
> > >>> head(iris)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1          5.1         3.5          1.4         0.2  setosa
> > >> 2          4.9         3.0          1.4         0.2  setosa
> > >> 3          4.7         3.2          1.3         0.2  setosa
> > >> 4          4.6         3.1          1.5         0.2  setosa
> > >> 5          5.0         3.6          1.4         0.2  setosa
> > >> 6          5.4         3.9          1.7         0.4  setosa
> > >>> ir <-head(iris)
> > >>> irm <- as.matrix(ir)
> > >>> head(irm)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
> > >> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
> > >> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
> > >> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
> > >> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
> > >> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> > >>> class(irm) <- "numeric"
> > >> Warning message:
> > >> In class(irm) <- "numeric" : NAs introduced by coercion
> > >>> head(irm)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1          5.1         3.5          1.4         0.2      NA
> > >> 2          4.9         3.0          1.4         0.2      NA
> > >> 3          4.7         3.2          1.3         0.2      NA
> > >> 4          4.6         3.1          1.5         0.2      NA
> > >> 5          5.0         3.6          1.4         0.2      NA
> > >> 6          5.4         3.9          1.7         0.4      NA
> > >>>
> > >>
> > >> Cheers
> > >> Petr
> > >>
> > >>
> > >>>
> > >>>
> > >>> *Warning message:In class(genod) <- "numeric" : NAs introduced by
> > >> coercion*
> > >>>
> > >>> Maybe I could illustrate more with details so I can be more specific?
> > >>> Please, let me know.
> > >>>
> > >>> I would appreciate your help.
> > >>> Thanks,
> > >>> Meriam
> > >>>
> > >>> [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > >> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > >> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > >> about processing and protection of business partner?s personal data are
> > >> available on website:
> > >> https://www.precheza.cz/en/personal-data-protection-principles/
> > >> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > >> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > >> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > >> documents attached to it may be confidential and are subject to the legally
> > >> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > >>
> > >>
> > >
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
>
>
>
> --
> Meriam Nefzaoui
> MSc. in Plant Breeding and Genetics
> Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mydata.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190108/f3673ccf/attachment.txt>

From meri@m@nef @ending from gm@il@com  Tue Jan  8 23:40:16 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Tue, 8 Jan 2019 16:40:16 -0600
Subject: [R] R help: circular dendrogram
Message-ID: <CAL1He1LY0LPOt91W9DXbEaScKpyOthBe7VVX_GqmKVxcaEPi=g@mail.gmail.com>

Dear all,

I generated a circular dendrogram with R (see attached). I have a
total of 360 landraces.
What I want to do next is generate a different color for each cluster
and also generate colors to show the country/region.
I don't know if it's also possible to put a code number (associated
with each landrace) in front of each ramification.
I want to have an explicit dendrogram.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.pdf
Type: application/pdf
Size: 33471 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190108/54181da5/attachment.pdf>

From petr@pik@l @ending from prechez@@cz  Wed Jan  9 08:15:06 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 9 Jan 2019 07:15:06 +0000
Subject: [R] error in plotting model from kernlab
In-Reply-To: <CAMk+s2Q=C5an1--GJO18FaRb22+s7QeML79QpO-2vFfDg6JiZg@mail.gmail.com>
References: <CAMk+s2RAWnxBDQOW83aamJX2ZNhD7G7vZJ-Yd26V16gci2T_Sg@mail.gmail.com>
 <beac7d2de6e74d508561723caf1cc936@SRVEXCHCM1302.precheza.cz>
 <CAMk+s2Q=C5an1--GJO18FaRb22+s7QeML79QpO-2vFfDg6JiZg@mail.gmail.com>
Message-ID: <d9f987e7e9164836b2c4559a665596f7@SRVEXCHCM1302.precheza.cz>

Hi

As I said I have no experience with kernlab but I can read in manual:

"probabilities matrix of class probabilities (one column for each class and one row for each input)"

from which I understand that  pred is matrix, which should have the same number of rows as df$cons but several columns. And matrix is a vector with dimensions what means that it is column times longer than df$cons, hence it is longer than df$cons.

Plotting error suggeststs that ksvc object has to be classification object and
>             type = "C-bsvc",
is not the same as "C-svc".

Cheers
Petr

> -----Original Message-----
> From: Luigi Marongiu <marongiu.luigi at gmail.com>
> Sent: Tuesday, January 8, 2019 4:40 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] error in plotting model from kernlab
>
> Hi,
> the maintainer hasn't answered yet. The problem with 'acc' is that yes the
> objects are not of the same length but they should be: according to the manual,
> ' table(pred, df$cons)' would return a 2x2 matrix of the results. This is not the
> case, so there is a problem with the model -- that is why there is no plotting
> either -- even if an object of class ksvm had been created.
>
> On Tue, Jan 8, 2019 at 4:12 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi
> >
> > I cannot help you with kernlab
> >
> > > >  pred = predict(mod, df, type = "probabilities")  acc =
> > > > table(pred, df$cons)
> > > Error in table(pred, df$cons) : all arguments must have the same
> > > length which again is weird since mod, df and df$cons are made from
> > > the same dataframe.
> >
> > Why not check length of those objects?
> >
> > length(pred)
> > length(df$cons)
> >
> > > > plot(mod, data = df)
> > > > kernlab::plot(mod, data = df)
> > > but I get this error:
> > >
> > > Error in .local(x, ...) :
> > >   Only plots of classification ksvm objects supported
> > >
> >
> > seems to me selfexplanatory. What did maintainer said about it?
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi
> > > Marongiu
> > > Sent: Monday, January 7, 2019 1:26 PM
> > > To: r-help <r-help at r-project.org>
> > > Subject: [R] error in plotting model from kernlab
> > >
> > > Dear all,
> > > I have a set of data in this form:
> > > > str <data>
> > > 'data.frame': 1574 obs. of  14 variables:
> > >  $ serial: int  12751 14157 7226 15663 11088 10464 1003 10427 11934
> > > 3999 ...
> > >  $ plate : int  43 46 22 50 38 37 3 37 41 11 ...
> > >  $ well  : int  79 333 314 303 336 96 235 59 30 159 ...
> > >  $ sample: int  266 295 151 327 231 218 21 218 249 84 ...
> > >  $ target: chr  "HEV 2-AI5IQWR" "Dientamoeba fragilis-AIHSPMK"
> > > "Astro
> > > 2 Liu-AI20UKB" "C difficile GDH-AIS086J" ...
> > >  $ ori.ct: num  0 33.5 0 0 0 ...
> > >  $ ct.out: int  0 1 0 0 0 0 0 1 0 0 ...
> > >  $ mr    : num  -0.002 0.109 0.002 0 0.001 0.006 0.015 0.119 0.003 0.004 ...
> > >  $ fcn   : num  44.54 36.74 6.78 43.09 44.87 ...
> > >  $ mr.out: int  0 1 0 0 0 0 0 1 0 0 ...
> > >  $ oper.a: int  0 1 0 0 0 0 0 1 0 0 ...
> > >  $ oper.b: int  0 1 0 0 0 0 0 1 0 0 ...
> > >  $ oper.c: int  0 1 0 0 0 0 0 1 0 0 ...
> > >  $ cons  : int  0 1 0 0 0 0 0 1 0 0 ...
> > > from which I have selected two numerical variables correspondig to x
> > > and y in a Cartesian plane and one outcome variable (z):
> > > > df = subset(t.data, select = c(mr, fcn, cons))  df$cons =
> > > > factor(c("negative", "positive"))
> > > > head(df)
> > >       mr   fcn     cons
> > > 1 -0.002 44.54 negative
> > > 2  0.109 36.74 positive
> > > 3  0.002  6.78 negative
> > > 4  0.000 43.09 positive
> > > 5  0.001 44.87 negative
> > > 6  0.006  2.82 positive
> > >
> > > I created an SVM the method with the KERNLAB package with:
> > > > mod = ksvm(cons ~ mr+fcn, # i prefer it to the more canonical "."
> > > > but the
> > > outcome is the same
> > >             data = df,
> > >             type = "C-bsvc",
> > >             kernel = "rbfdot",
> > >             kpar = "automatic",
> > >             C = 10,
> > >             prob.model = TRUE)
> > >
> > > > mod
> > > Support Vector Machine object of class "ksvm"
> > >
> > > SV type: C-bsvc  (classification)
> > >  parameter : cost C = 10
> > >
> > > Gaussian Radial Basis kernel function.
> > >  Hyperparameter : sigma =  42.0923201429106
> > >
> > > Number of Support Vectors : 1439
> > >
> > > Objective Function Value : -12873.45 Training error : 0.39263
> > > Probability model included.
> > >
> > > First of all, I am not sure if the model worked because 1439 support
> > > vectors out of 1574 data points means that over 90% of the data is
> > > required to fix the hyperplane. this does not look like a model but
> > > a patch. Secondly, the prediction is rubbish -- but this is another
> > > story -- and when I try to create a confusion table of the processed
> > > data I get:
> > > >  pred = predict(mod, df, type = "probabilities")  acc =
> > > > table(pred, df$cons)
> > > Error in table(pred, df$cons) : all arguments must have the same
> > > length which again is weird since mod, df and df$cons are made from
> > > the same dataframe.
> > >
> > > Coming to the actual error, I tried to plot the model with:
> > > > plot(mod, data = df)
> > > > kernlab::plot(mod, data = df)
> > > but I get this error:
> > >
> > > Error in .local(x, ...) :
> > >   Only plots of classification ksvm objects supported
> > >
> > > Would you know what I am missing?
> > > Thank you
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
>
>
> --
> Best regards,
> Luigi
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@pik@l @ending from prechez@@cz  Wed Jan  9 09:39:10 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 9 Jan 2019 08:39:10 +0000
Subject: [R] Mailinglist
In-Reply-To: <CAK7fGOvJh1vFJOT7AshqkEwyF21uMRNerDPxEpuUT3HiJ6cbgA@mail.gmail.com>
References: <CAK7fGOuy8BeRmLW_qiEXwbpTHG5ztCEAgUBexFA4R+wM3vgMnw@mail.gmail.com>
 <CA+8X3fVzneH2eOjkM4GUB10PaHARLz7gU3yc2uWjSskP6RtuFw@mail.gmail.com>
 <CAK7fGOtr5ddWO=Xat+8bCF_+i_CM8uAg4NpQ45u+x4z8M95=vg@mail.gmail.com>
 <CA+8X3fW+zQSccjKUVSQnZk1utUzvFY3o2tB2_DPZzd5K7pCXng@mail.gmail.com>
 <3B22A233-9F2F-4B55-9C35-A24350173789@dcn.davis.ca.us>
 <CAK7fGOsLPGf0nF5GX+pckVRa5obw9P+5B-adgGJ7qrez=x-biw@mail.gmail.com>
 <alpine.LNX.2.20.1901060844260.6912@salmo.appl-ecosys.com>
 <CAK7fGOu==H8bLSznBGBmtfzg5zR2fAOOksoJiTeOwV3RbVOxig@mail.gmail.com>
 <72e0ff066c2c4941bd562c419a2081e9@SRVEXCHCM1302.precheza.cz>
 <CAK7fGOvJh1vFJOT7AshqkEwyF21uMRNerDPxEpuUT3HiJ6cbgA@mail.gmail.com>
Message-ID: <b68298d200264dc0be295cdf72a9ecf9@SRVEXCHCM1302.precheza.cz>

Hm

If I understand from your description correctly, probably aggregate could do it.

with(gmoji_passivedata, aggregate(value, list(probetype, participants), length)

However posting part of your dataset, as Richard suggested, would clear the matter.

Devil is in details, you probably intend to elaborate your results further and it is always good to have appropriately structured results.

Cheers
Petr

From: Rachel Thompson <rachel.thompson at student.uva.nl>
Sent: Tuesday, January 8, 2019 4:24 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Mailinglist

Hi

Thank you for your help and suggestions!
I have tried a few things and ask help from lots of people online!

My problem is that I am not able to share the database! I tried to recreate one but I wasn't successful.
So I found a way to analyze each subject individually, but I do not know how to perform the same steps for all of the subjects at once.
But I just wanted to share what I did, since you tried to help me!

This is what I did.
I stored all the column names in a vector named "Names"
names=c("participants","id","participantid","key","probetype","time","timespecific","value","valuespecified","valuedetailed","period","periodspecified")

colnames(gmoji_passivedata)=names

I used this code to find the number of participants in the dataset

length(unique(gmoji_passivedata$participants))
The number of participants is 44

I used this code to find the unique ID for every participant

library(plyr)
> count(gmoji_passivedata,?participants")
From the dataset, I selected one participant ""U_..."
I used subset data

participant1=subset(gmoji_passivedata,participants=="U_0139cf62_e615_41f7_a4cc_878c0490c510")


With the table code
table(p1$probetype) I found the counts of all the different values of the probe type column

edu.mit.media.funf.probe.builtin.ActivityProbe
                                                                      16167
edu.mit.media.funf.probe.builtin.BluetoothProbe
                                                                      405
  edu.mit.media.funf.probe.builtin.CallLogProbe
                                                                      1427
   edu.mit.media.funf.probe.builtin.ScreenProbe
                                                                      1791
     edu.mit.media.funf.probe.builtin.WifiProbe
                                                                       5386

The count for the call log probe for the selected participant is 1427

There was only one participant with sms probe for the rest of the participant the count of sms probe is 0

For the screen probe and activity probe I found the total count (1791 and 16167)

For screen probe, I used a subset code and set the value detailed column to false and true

screenon_false=subset(p1,valuedetailed=="False") (this participant 875)
screenon_true=subset(p1,valuedetailed=="True")   (this participant 916)

and for activity probe to none, low and high to find the required values

activity_none=subset(p1,valuedetailed=="none")   (this participant 12900)
activity_low=subset(p1,valuedetailed=="low")     (this participant 1050)
activity_high=subset(p1,valuedetailed=="high")   (this participant 2217)


I did this for each participant

Best,

Rachel

On Mon, Jan 7, 2019 at 3:56 AM PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi Rachel.

You already have got several suggestions, but results depend on structure of your data. The best way from your side would be just copy a part of your data directly to email and preferable way is to use "dput".

Assuming your data already transfered to R are called "mydata".

You can just copy otput of

dput(mydata[1:30,])

to your next mail.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Rachel Thompson
> Sent: Sunday, January 6, 2019 7:49 PM
> To: Rich Shepard <rshepard at appl-ecosys.com<mailto:rshepard at appl-ecosys.com>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Mailinglist
>
> Hi Rich,
>
> I really feel lost at this point.
> I need a code that helps me count the phone activity level(high/low/none),
> the screen activity (on/off) and the amount calls and SMS of each subject.
>
> 1. I want to have a summary of how many times a specific subject got called
> (CallLogProbe)
> 2. I want to have a summary of how many times a specific subject got a text
> message (SMS probe)
> 3. I want to have a summary of how many times a specific subject
> - Turned their screen on - True  (ScreenProbe)
> - Or did not turn their screen on - False (ScreenProbe)
> 4.  I want to have a summary of the activity level of a specific subject
> - Activity level - none (ActivityProbe)
> - Activity level- low     (ActivityProbe)
> - Activity level - High  (ActivityProbe)
>
> I want to do this for all the 36 subjects(Participants).
> In the end, I have to define the percentages and cutoff points of what is
> considered low-medium-high, based on what the results of all the subjects
> are. So I am able to see if a specific subject has low social interaction
> etc.
>
> I have tried a lot, with the help of youtube etc. But I feel as if I am
> trying a lot of things but without clearly knowing if it is the right step.
> I have a csv file, but I need to look into what Jeff said about the guides.
> So I am able to share it.
>
> Best.
>
>
> On Sun, Jan 6, 2019 at 11:51 AM Rich Shepard <rshepard at appl-ecosys.com<mailto:rshepard at appl-ecosys.com>>
> wrote:
>
> > On Sun, 6 Jan 2019, Rachel Thompson wrote:
> >
> > > I am an intern from Amsterdam and I have to do an analysis in R. I spoke
> > > to my professor in Amsterdam and my supervisor's here in Boston. But they
> > > are to busy to help. I informed them from the start that I am not
> > familiar
> > > with R(Rstudio) and they told me that I would receive guidance. So since
> > > they can not help me, I decided to share my problem online. (It is a CVS
> > > file imported into R)
> >
> > Rachel,
> >
> >    I find it interesting that you're put in such a difficult position. I've
> > not followed this thread from the start so my comments might be redundant
> > or
> > inappropriate.
> >
> >    If you can, describe the problem. That is, what are you being asked to
> > find and what are the available data? This information helps us to guide
> > you
> > to learning the mechanics for accomplishing your task with R.
> >
> > Regards,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Jan  9 09:57:38 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 9 Jan 2019 08:57:38 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
Message-ID: <a3a1aae8534f41aab579884f16489fb1@SRVEXCHCM1302.precheza.cz>

Hm,

you should use dput for sharing data but my suggestion was correct.

You converted genod to genod2 by as.matrix what changed it to ?character? matrix as matrix is able to hold only one type of data. By trying to change it to numeric, all numbers are changed to numeric and what cannot be changed is simply converted to NA (with polite warning).

You should read documentation to
snpgdsCreateGeno
as it requires matrix as an input and maybe also pay attention to the basic documents like R-intro which would teach you difference between matrix and data frame (chapter 3).

Cheers
Petr


From: N Meriam <meriam.nef at gmail.com>
Sent: Tuesday, January 8, 2019 4:36 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Warning message: NAs introduced by coercion

I see...
Here's a portion of what my data looks like (csv file attached).
I run again and here are the results:


df4 <- read.csv(file = "mydata.csv", header = TRUE)

> require(SNPRelate)

> library(gdsfmt)

> myd <- df4

> myd <- df4

> names(myd)[-1]

[1] "marker" "X88"    "X9"     "X17"    "X25"

> myd[,1]

[1]  3  4  5  6  8 10



> # the data must be 0,1,2 with 3 as missing so you have r

> sample.id<http://sample.id> <- names(myd)[-1]

> snp.id<http://snp.id> <- myd[,1]

> snp.position <- 1:length(snp.id<http://snp.id>) # not needed for ibs

> snp.chromosome <- rep(1, each=length(snp.id<http://snp.id>)) # not needed for ibs

> snp.allele <- rep("A/G", length(snp.id<http://snp.id>)) # not needed for ibs

> # genotype data must have - in 3

> genod <- myd[,-1]

> genod[is.na<http://is.na>(genod)] <- 3

> genod[genod=="0"] <- 0

> genod[genod=="1"] <- 2

> genod2 <- as.matrix(genod)

> head(genod2)

     marker                        X88 X9  X17 X25

[1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"

[2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"

[3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"

[4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"

[5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"

[6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"



> class(genod2) <- "numeric"

Warning message:

In class(genod2) <- "numeric" : NAs introduced by coercion

> head(genod2)

 marker X88 X9 X17 X25

[1,]     NA   0  3   3   3

[2,]     NA   2  0   3   0

[3,]     NA   0  0   0   0

[4,]     NA   0  0   3   0

[5,]     NA   3  3   3   3

[6,]     NA   0  0   0   0

> class(genod2) <- "numeric"

> class(genod2)

[1] "matrix"

> # read data

> filn <-"simTunesian.gds"

> snpgdsCreateGeno(filn, genmat = genod,

+                  sample.id<http://sample.id> = sample.id<http://sample.id>, snp.id<http://snp.id> = snp.id<http://snp.id>,

+                  snp.chromosome = snp.chromosome,

+                  snp.position = snp.position,

+                  snp.allele = snp.allele, snpfirstdim=TRUE)

Error in snpgdsCreateGeno(filn, genmat = genod, sample.id<http://sample.id> = sample.id<http://sample.id>,  :

  is.matrix(genmat) is not TRUE
Thanks,
Meriam

On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

see in line

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of N Meriam
> Sent: Tuesday, January 8, 2019 3:08 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Warning message: NAs introduced by coercion
>
> Dear all,
>
> I have a .csv file called df4. (15752 obs. of 264 variables).
> I apply this code but couldn't continue further other analyses, a warning
> message keeps coming up. Then, I want to determine max and min
> similarity values,
> heat map plot, cluster...etc
>
> > require(SNPRelate)
> > library(gdsfmt)
> > myd <- read.csv(file = "df4.csv", header = TRUE)
> > names(myd)[-1]
> myd[,1]
> > myd[1:10, 1:10]
>  # the data must be 0,1,2 with 3 as missing so you have r
> > sample.id<http://sample.id> <- names(myd)[-1]
> > snp.id<http://snp.id> <- myd[,1]
> > snp.position <- 1:length(snp.id<http://snp.id>) # not needed for ibs
> > snp.chromosome <- rep(1, each=length(snp.id<http://snp.id>)) # not needed for ibs
> > snp.allele <- rep("A/G", length(snp.id<http://snp.id>)) # not needed for ibs
> # genotype data must have - in 3
> > genod <- myd[,-1]
> > genod[is.na<http://is.na>(genod)] <- 3
> > genod[genod=="0"] <- 0
> > genod[genod=="1"] <- 2
> > genod[1:10,1:10]
> > genod <- as.matrix(genod)

matrix can have only one type of data so you probaly changed it to character by such construction.

> > class(genod) <- "numeric"

This tries to change all "numeric" values to numbers but if it cannot it sets it to NA.

something like

> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa
> ir <-head(iris)
> irm <- as.matrix(ir)
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> class(irm) <- "numeric"
Warning message:
In class(irm) <- "numeric" : NAs introduced by coercion
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2      NA
2          4.9         3.0          1.4         0.2      NA
3          4.7         3.2          1.3         0.2      NA
4          4.6         3.1          1.5         0.2      NA
5          5.0         3.6          1.4         0.2      NA
6          5.4         3.9          1.7         0.4      NA
>

Cheers
Petr


>
>
> *Warning message:In class(genod) <- "numeric" : NAs introduced by coercion*
>
> Maybe I could illustrate more with details so I can be more specific?
> Please, let me know.
>
> I would appreciate your help.
> Thanks,
> Meriam
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


--
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil


	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Jan  9 10:03:34 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 9 Jan 2019 09:03:34 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
Message-ID: <31d15fa2d18e4e02991fea4dcd19ea7e@SRVEXCHCM1302.precheza.cz>

And as you use bioconductor related package you probably could get better answers in specialised biconductor help

https://www.bioconductor.org/help/

Cheers
Petr

From: N Meriam <meriam.nef at gmail.com>
Sent: Tuesday, January 8, 2019 4:36 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Warning message: NAs introduced by coercion

I see...
Here's a portion of what my data looks like (csv file attached).
I run again and here are the results:


df4 <- read.csv(file = "mydata.csv", header = TRUE)

> require(SNPRelate)

> library(gdsfmt)

> myd <- df4

> myd <- df4

> names(myd)[-1]

[1] "marker" "X88"    "X9"     "X17"    "X25"

> myd[,1]

[1]  3  4  5  6  8 10



> # the data must be 0,1,2 with 3 as missing so you have r

> sample.id<http://sample.id> <- names(myd)[-1]

> snp.id<http://snp.id> <- myd[,1]

> snp.position <- 1:length(snp.id<http://snp.id>) # not needed for ibs

> snp.chromosome <- rep(1, each=length(snp.id<http://snp.id>)) # not needed for ibs

> snp.allele <- rep("A/G", length(snp.id<http://snp.id>)) # not needed for ibs

> # genotype data must have - in 3

> genod <- myd[,-1]

> genod[is.na<http://is.na>(genod)] <- 3

> genod[genod=="0"] <- 0

> genod[genod=="1"] <- 2

> genod2 <- as.matrix(genod)

> head(genod2)

     marker                        X88 X9  X17 X25

[1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"

[2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"

[3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"

[4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"

[5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"

[6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"



> class(genod2) <- "numeric"

Warning message:

In class(genod2) <- "numeric" : NAs introduced by coercion

> head(genod2)

 marker X88 X9 X17 X25

[1,]     NA   0  3   3   3

[2,]     NA   2  0   3   0

[3,]     NA   0  0   0   0

[4,]     NA   0  0   3   0

[5,]     NA   3  3   3   3

[6,]     NA   0  0   0   0

> class(genod2) <- "numeric"

> class(genod2)

[1] "matrix"

> # read data

> filn <-"simTunesian.gds"

> snpgdsCreateGeno(filn, genmat = genod,

+                  sample.id<http://sample.id> = sample.id<http://sample.id>, snp.id<http://snp.id> = snp.id<http://snp.id>,

+                  snp.chromosome = snp.chromosome,

+                  snp.position = snp.position,

+                  snp.allele = snp.allele, snpfirstdim=TRUE)

Error in snpgdsCreateGeno(filn, genmat = genod, sample.id<http://sample.id> = sample.id<http://sample.id>,  :

  is.matrix(genmat) is not TRUE
Thanks,
Meriam

On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

see in line

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of N Meriam
> Sent: Tuesday, January 8, 2019 3:08 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Warning message: NAs introduced by coercion
>
> Dear all,
>
> I have a .csv file called df4. (15752 obs. of 264 variables).
> I apply this code but couldn't continue further other analyses, a warning
> message keeps coming up. Then, I want to determine max and min
> similarity values,
> heat map plot, cluster...etc
>
> > require(SNPRelate)
> > library(gdsfmt)
> > myd <- read.csv(file = "df4.csv", header = TRUE)
> > names(myd)[-1]
> myd[,1]
> > myd[1:10, 1:10]
>  # the data must be 0,1,2 with 3 as missing so you have r
> > sample.id<http://sample.id> <- names(myd)[-1]
> > snp.id<http://snp.id> <- myd[,1]
> > snp.position <- 1:length(snp.id<http://snp.id>) # not needed for ibs
> > snp.chromosome <- rep(1, each=length(snp.id<http://snp.id>)) # not needed for ibs
> > snp.allele <- rep("A/G", length(snp.id<http://snp.id>)) # not needed for ibs
> # genotype data must have - in 3
> > genod <- myd[,-1]
> > genod[is.na<http://is.na>(genod)] <- 3
> > genod[genod=="0"] <- 0
> > genod[genod=="1"] <- 2
> > genod[1:10,1:10]
> > genod <- as.matrix(genod)

matrix can have only one type of data so you probaly changed it to character by such construction.

> > class(genod) <- "numeric"

This tries to change all "numeric" values to numbers but if it cannot it sets it to NA.

something like

> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa
> ir <-head(iris)
> irm <- as.matrix(ir)
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> class(irm) <- "numeric"
Warning message:
In class(irm) <- "numeric" : NAs introduced by coercion
> head(irm)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2      NA
2          4.9         3.0          1.4         0.2      NA
3          4.7         3.2          1.3         0.2      NA
4          4.6         3.1          1.5         0.2      NA
5          5.0         3.6          1.4         0.2      NA
6          5.4         3.9          1.7         0.4      NA
>

Cheers
Petr


>
>
> *Warning message:In class(genod) <- "numeric" : NAs introduced by coercion*
>
> Maybe I could illustrate more with details so I can be more specific?
> Please, let me know.
>
> I would appreciate your help.
> Thanks,
> Meriam
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


--
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil


	[[alternative HTML version deleted]]


From h@medh@@eli @ending from gm@il@com  Wed Jan  9 12:16:54 2019
From: h@medh@@eli @ending from gm@il@com (Hamed Ha)
Date: Wed, 9 Jan 2019 11:16:54 +0000
Subject: [R] Why does R do this? (Duncan Murdoch)
Message-ID: <CAAC89xe4TmNuQ8uKjnFZCqtZijbzR3u4net+xZkvHXL75FLGpg@mail.gmail.com>

Well, your question looks quite interesting to me.

*which *function normally returns a non-negative *integer *and if fails
to find the case, then returns integer(0) that is an integer with the zero
length. Logically it returns the right answer. Then, doing an operation on
nothing is pointless, however in mathematics, the complementary of nothing
is everything. Then you do not expect R to return the entire integer set! ;)


If you still like to use which, I advise you write a little function like
which0() that inherits the properties of *which *and checks for the special
cases.


Hamed.






Message: 1
Date: Tue, 8 Jan 2019 06:54:43 -0500
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: Nick Wray <nicholas.wray at ntlworld.com>, r-help
        <r-help at r-project.org>
Subject: Re: [R] Why does R do this?
Message-ID: <8ed2949e-314f-ef92-1982-1de5e31bed99 at gmail.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

On 08/01/2019 4:28 a.m., Nick Wray via R-help wrote:
> y<-c(1,2,3)
> z<-which(y>3)

At this point z is a vector with no entries in it.

> z
> y<-y[-z]

-z is the same vector.  So y[z] and y[-z] are the same.

> y
>
> In the work I'm doing I often have this situation and have to make sure
that I condition on z being non-zero as y is now numeric(0) rather than the
set c(1,2,3).  Why does R do this?  Wouldn't it be more sensible for R to
simply leave the host set unchanged if there are no elements to take out?

No, it wouldn't.  You asked for no entries, so you get no entries.

Follow Thierry's advice, and don't use which() unless you really need a
vector of indices, and are prepared for an empty one.

Duncan Murdoch

	[[alternative HTML version deleted]]


From m@ri@eugeni@u @ending from gm@il@com  Wed Jan  9 15:34:24 2019
From: m@ri@eugeni@u @ending from gm@il@com (=?UTF-8?Q?Maria_Eugenia_Utg=C3=A9s?=)
Date: Wed, 9 Jan 2019 11:34:24 -0300
Subject: [R] External validation for a hurdle model (pscl)
In-Reply-To: <41B961DE-B038-4792-99BA-431145031F3D@dcn.davis.ca.us>
References: <CAGj5wfmeEF9AbLyzNYU=pQ1YT6GR0sqUdtSh_9ytSu24Z9zLkw@mail.gmail.com>
 <CAGxFJbTP+Tu56=N1abe8euK8SH6AtvS3LAD7eCXuRChYhfJZUA@mail.gmail.com>
 <41B961DE-B038-4792-99BA-431145031F3D@dcn.davis.ca.us>
Message-ID: <CAGj5wfmpv3TYvqo4msxUxh=yjhSwjk187bXurtT8pZmDKgg3Vg@mail.gmail.com>

Hi Jeff,
Yes, my question is more general perhaps
Not about R programming, data exploration, or statistical theory.
Just that in modelling texts external validation is set as "panacea" but
"unreacheable", so they explain other methods as cross validation,
bootstrapping, etc.
Here I have new data for a previously constructed model (and already
internally validated by bootstrapping), but have not found how to correctly
and sufficiently make the external validation and by which means (all ends
in just a plot? a % of correct classification?)

El mar., 8 ene. 2019 a las 17:08, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> That said, the gist of the OP's outline is correct, and the main reason to
> look elsewhere is to get more thorough advice on what statistical concerns
> should be addressed than would be on topic here.
>
> One comment: reviewing plots of differences versus various independent
> variables for systematic biases is a task R is particularly well suited
> for, but discovering which plots highlight issues with your model or data
> takes familiarity with your data (explore) and with theory (which you learn
> elsewhere) and with R (which we can help with if you have more specific
> questions).
>
> On January 8, 2019 10:50:14 AM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >This list is (mostly) about R programming. Your query is (mostly) about
> >statistics. So you should post on a statistics site like
> >stats.stackexchange.com
> >not here; I am pretty sure you'll receive lots of answers there.
> >
> >Cheers,
> >Bert
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Tue, Jan 8, 2019 at 10:18 AM Maria Eugenia Utg?s
> ><mariaeugeniau at gmail.com>
> >wrote:
> >
> >> Hi R-list,
> >> We have constructed a hurdle model some time ago.
> >> Now we were able to gather new data in the same city (38 new sites),
> >and
> >> want to do an external validation to see if the model still performs
> >ok.
> >> All the books and lectures I have read say its the best validation
> >option
> >> but...
> >> I have made a (simple) search, but it seems that as having new data
> >for a
> >> model is rare, have not found anything with the depth enough so as to
> >> reproduce it/adapt it to hurdle models.
> >>
> >> I have predicted the probability for non-zero counts
> >> nonzero <- 1 - predict(final, newdata = datosnuevos, type = "prob")[,
> >1]
> >>
> >> and the predicted mean from the count component
> >> countmean <- predict(final, newdata = datosnuevos, type = "count")
> >>
> >> I understand that "newdata" is taking into account the new values for
> >the
> >> independent variables (environmental variables), is it?
> >>
> >> So, I have to compare the predicted values of y (calculated with the
> >new
> >> values of the environmental variables) with the new observed values.
> >>
> >> That would be using the model (constructed with the old values),
> >having as
> >> input the new variables, and having as output a "new" prediction, to
> >be
> >> contrasted with the "new" observed y.
> >>
> >> These comparison would be by means of AUC, correct classification,
> >and/or
> >> what other options? Results of the external validation would just be
> >a % of
> >> correct predicted values? plots?
> >>
> >> Need some guidance, sorry if the explanation was "basic" but needed
> >to
> >> write it in my own words so as not to miss any detail.
> >>
> >> Thank you very much in advance,
> >>
> >> Mar?a Eugenia Utg?s
> >>
> >> CeNDIE-ANLIS
> >> Buenos Aires
> >> Argentina
> >> a
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Wed Jan  9 20:23:26 2019
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Wed, 9 Jan 2019 19:23:26 +0000
Subject: [R] Warning message: NAs introduced by coercion
In-Reply-To: <CAL1He1KrGmdJczHdNBMSMYLmHumiFyZ82rYgBbdwZFYmX3eaFQ@mail.gmail.com>
References: <CAL1He1K3mLndn_UmYpdphN4BTRKyCTr4opWMFnmeVJGdW9TRSg@mail.gmail.com>
 <b8c335f067da4bb59242a92f68401de6@SRVEXCHCM1302.precheza.cz>
 <CAL1He1+mzdBi7OD2k1ajfjr5nhCiK6J6vrEETZyZJVGsA=5yeA@mail.gmail.com>
 <1ead8adf-db08-6a39-beb3-a946c46d7ce6@dewey.myzen.co.uk>
 <CAL1He1+knqhTz31JrfK-Wq3rxJ332QFUV1p3OcqQ2RXPY4TkKQ@mail.gmail.com>
 <4993bca4bda64a479fdd6e9ff1b7f5de@tamu.edu>
 <CAL1He1KrGmdJczHdNBMSMYLmHumiFyZ82rYgBbdwZFYmX3eaFQ@mail.gmail.com>
Message-ID: <dc31b87bb0a64e84ad22085fa50333e3@tamu.edu>

Now you have pushed a numeric matrix to the function with a column of missing values. No wonder you do not get any results. 

David C

-----Original Message-----
From: N Meriam [mailto:meriam.nef at gmail.com] 
Sent: Tuesday, January 8, 2019 3:44 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Michael Dewey <lists at dewey.myzen.co.uk>; r-help at r-project.org
Subject: Re: [R] Warning message: NAs introduced by coercion

Yes, sorry. I attached the file once again.
Well, still getting the same warning.

> class(genod) <- "numeric"
Warning message:
In class(genod) <- "numeric" : NAs introduced by coercion
> class(genod)
[1] "matrix"

Then, I run the following code and it gives this:

> filn <-"simTunesian.gds"
> snpgdsCreateGeno(filn, genmat = genod,
+                  sample.id = sample.id, snp.id = snp.id,
+                  snp.chromosome = snp.chromosome,
+                  snp.position = snp.position,
+                  snp.allele = snp.allele, snpfirstdim=TRUE)
> # calculate similarity matrix
> # Open the GDS file
> (genofile <- snpgdsOpen(filn))
File: C:\Users\DELL\Documents\TEST\simTunesian.gds (1.4M)
+    [  ] *
|--+ sample.id   { Str8 363 ZIP_ra(42.5%), 755B }
|--+ snp.id   { Int32 15752 ZIP_ra(35.1%), 21.6K }
|--+ snp.position   { Int32 15752 ZIP_ra(34.7%), 21.3K }
|--+ snp.chromosome   { Float64 15752 ZIP_ra(0.18%), 230B }
|--+ snp.allele   { Str8 15752 ZIP_ra(0.16%), 108B }
\--+ genotype   { Bit2 15752x363, 1.4M } *
> ibs <- snpgdsIBS(genofile, remove.monosnp = FALSE, num.thread=1)
Identity-By-State (IBS) analysis on genotypes:
Excluding 0 SNP on non-autosomes
Working space: 363 samples, 15,752 SNPs
    using 1 (CPU) core
IBS:    the sum of all selected genotypes (0,1,2) = 3658952
Tue Jan 08 15:38:00 2019    (internal increment: 42880)
[==================================================] 100%, completed in 0s
Tue Jan 08 15:38:00 2019    Done.
> # maximum similarity value
> max(ibs$ibs)
[1] NaN
> # minimum similarity value
> min(ibs$ibs)
[1] NaN

As you can see, I can't continue my analysis (heat map plot,
clustering with hclust) because values are NaN.


On Tue, Jan 8, 2019 at 2:01 PM David L Carlson <dcarlson at tamu.edu> wrote:
>
> Your attached file is not a .csv file since the field are not separated by commas (just rename the mydata.csv to mydata.txt).
>
> The command "genod2 <- as.matrix(genod)" created a character matrix from the data frame genod.  When you try to force genod2 to numeric, the marker column becomes NAs which is probably not what you want.
>
> The error message is because you passed genod (a data frame) to the snpgdsCreateGeno() function not genod2 (the matrix you created from genod).
>
> ------------------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of N Meriam
> Sent: Tuesday, January 8, 2019 1:38 PM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org
> Subject: Re: [R] Warning message: NAs introduced by coercion
>
> Here's a portion of what my data looks like (text file format attached).
> When running in R, it gives me this:
>
> > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> > require(SNPRelate)
> > library(gdsfmt)
> > myd <- df4
> > myd <- df4
> > names(myd)[-1]
> [1] "marker" "X88"    "X9"     "X17"    "X25"
> > myd[,1]
> [1]  3  4  5  6  8 10
> # the data must be 0,1,2 with 3 as missing so you have r
> > sample.id <- names(myd)[-1]
> > snp.id <- myd[,1]
> > snp.position <- 1:length(snp.id) # not needed for ibs
> > snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> # genotype data must have - in 3
> > genod <- myd[,-1]
> > genod[is.na(genod)] <- 3
> > genod[genod=="0"] <- 0
> > genod[genod=="1"] <- 2
> > genod2 <- as.matrix(genod)
> > head(genod2)
>          marker                                             X88   X9
>  X17   X25
> [1,]  "100023173|F|0-47:G>A-47:G>A"     "0"    "3"    "3"     "3"
> [2,]  "1043336|F|0-7:A>G-7:A>G"             "2"    "0"    "3"     "0"
> [3,]  "1212218|F|0-49:A>G-49:A>G"         "0"    "0"    "0"     "0"
> [4,]  "1019554|F|0-14:T>C-14:T>C"           "0"   "0"    "3"     "0"
> [5,]  "100024550|F|0-16:G>A-16:G>A"     "3"    "3"    "3"     "3"
> [6,]  "1106702|F|0-8:C>A-8:C>A"              "0"   "0"     "0"     "0"
> > class(genod2) <- "numeric"
> Warning message: In class(genod2) <- "numeric" : NAs introduced by coercion
> > head(genod2)
>         marker   X88  X9   X17  X25
> [1,]     NA         0      3     3       3
> [2,]     NA         2      0     3       0
> [3,]     NA         0      0     0       0
> [4,]     NA         0      0     3       0
> [5,]     NA         3      3     3       3
> [6,]     NA         0      0     0       0
> > class(genod2) <- "numeric"
> > class(genod2)
> [1] "matrix"
> # read data
> > filn <-"simTunesian.gds"
> > snpgdsCreateGeno(filn, genmat = genod,
> +                  sample.id = sample.id, snp.id = snp.id,
> +                  snp.chromosome = snp.chromosome,
> +                  snp.position = snp.position,
> +                  snp.allele = snp.allele, snpfirstdim=TRUE)
> Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,
>  :   is.matrix(genmat) is not TRUE
>
> Can't find a solution to my problem...my guess is that the problem
> comes from converting the column 'marker' factor to numerical.
>
> Best,
> Meriam
>
> On Tue, Jan 8, 2019 at 11:28 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> >
> > Dear Meriam
> >
> > Your csv file did not come through as attachments are stripped unless of
> > certain types and you post is very hard to read since you are posting in
> > HTML. Try renaming the file to ????.txt and set your mailer to send
> > plain text then people may be able to help you better.
> >
> > Michael
> >
> > On 08/01/2019 15:35, N Meriam wrote:
> > > I see...
> > > Here's a portion of what my data looks like (csv file attached).
> > > I run again and here are the results:
> > >
> > > df4 <- read.csv(file = "mydata.csv", header = TRUE)
> > >
> > >> require(SNPRelate)> library(gdsfmt)> myd <- df4> myd <- df4> names(myd)[-1][1] "marker" "X88"    "X9"     "X17"    "X25"
> > >
> > >> myd[,1][1]  3  4  5  6  8 10
> > >
> > >
> > >> # the data must be 0,1,2 with 3 as missing so you have r> sample.id <- names(myd)[-1]> snp.id <- myd[,1]> snp.position <- 1:length(snp.id) # not needed for ibs> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs> # genotype data must have - in 3> genod <- myd[,-1]> genod[is.na(genod)] <- 3> genod[genod=="0"] <- 0> genod[genod=="1"] <- 2
> > >
> > >> genod2 <- as.matrix(genod)> head(genod2)     marker                        X88 X9  X17 X25
> > > [1,] "100023173|F|0-47:G>A-47:G>A" "0" "3" "3" "3"
> > > [2,] "1043336|F|0-7:A>G-7:A>G"     "2" "0" "3" "0"
> > > [3,] "1212218|F|0-49:A>G-49:A>G"   "0" "0" "0" "0"
> > > [4,] "1019554|F|0-14:T>C-14:T>C"   "0" "0" "3" "0"
> > > [5,] "100024550|F|0-16:G>A-16:G>A" "3" "3" "3" "3"
> > > [6,] "1106702|F|0-8:C>A-8:C>A"     "0" "0" "0" "0"
> > >
> > >> class(genod2) <- "numeric"Warning message:In class(genod2) <- "numeric" : NAs introduced by coercion> head(genod2)
> > >
> > >   marker X88 X9 X17 X25
> > > [1,]     NA   0  3   3   3
> > > [2,]     NA   2  0   3   0
> > > [3,]     NA   0  0   0   0
> > > [4,]     NA   0  0   3   0
> > > [5,]     NA   3  3   3   3
> > > [6,]     NA   0  0   0   0
> > >
> > >> class(genod2) <- "numeric"> class(genod2)[1] "matrix"
> > >
> > >> # read data > filn <-"simTunesian.gds"> snpgdsCreateGeno(filn, genmat = genod,+                  sample.id = sample.id, snp.id = snp.id,+                  snp.chromosome = snp.chromosome,+                  snp.position = snp.position,+                  snp.allele = snp.allele, snpfirstdim=TRUE)Error in snpgdsCreateGeno(filn, genmat = genod, sample.id = sample.id,  :
> > >    is.matrix(genmat) is not TRUE
> > >
> > > Thanks,
> > > Meriam
> > >
> > > On Tue, Jan 8, 2019 at 9:02 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >
> > >> Hi
> > >>
> > >> see in line
> > >>
> > >>> -----Original Message-----
> > >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of N Meriam
> > >>> Sent: Tuesday, January 8, 2019 3:08 PM
> > >>> To: r-help at r-project.org
> > >>> Subject: [R] Warning message: NAs introduced by coercion
> > >>>
> > >>> Dear all,
> > >>>
> > >>> I have a .csv file called df4. (15752 obs. of 264 variables).
> > >>> I apply this code but couldn't continue further other analyses, a warning
> > >>> message keeps coming up. Then, I want to determine max and min
> > >>> similarity values,
> > >>> heat map plot, cluster...etc
> > >>>
> > >>>> require(SNPRelate)
> > >>>> library(gdsfmt)
> > >>>> myd <- read.csv(file = "df4.csv", header = TRUE)
> > >>>> names(myd)[-1]
> > >>> myd[,1]
> > >>>> myd[1:10, 1:10]
> > >>>   # the data must be 0,1,2 with 3 as missing so you have r
> > >>>> sample.id <- names(myd)[-1]
> > >>>> snp.id <- myd[,1]
> > >>>> snp.position <- 1:length(snp.id) # not needed for ibs
> > >>>> snp.chromosome <- rep(1, each=length(snp.id)) # not needed for ibs
> > >>>> snp.allele <- rep("A/G", length(snp.id)) # not needed for ibs
> > >>> # genotype data must have - in 3
> > >>>> genod <- myd[,-1]
> > >>>> genod[is.na(genod)] <- 3
> > >>>> genod[genod=="0"] <- 0
> > >>>> genod[genod=="1"] <- 2
> > >>>> genod[1:10,1:10]
> > >>>> genod <- as.matrix(genod)
> > >>
> > >> matrix can have only one type of data so you probaly changed it to
> > >> character by such construction.
> > >>
> > >>>> class(genod) <- "numeric"
> > >>
> > >> This tries to change all "numeric" values to numbers but if it cannot it
> > >> sets it to NA.
> > >>
> > >> something like
> > >>
> > >>> head(iris)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1          5.1         3.5          1.4         0.2  setosa
> > >> 2          4.9         3.0          1.4         0.2  setosa
> > >> 3          4.7         3.2          1.3         0.2  setosa
> > >> 4          4.6         3.1          1.5         0.2  setosa
> > >> 5          5.0         3.6          1.4         0.2  setosa
> > >> 6          5.4         3.9          1.7         0.4  setosa
> > >>> ir <-head(iris)
> > >>> irm <- as.matrix(ir)
> > >>> head(irm)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1 "5.1"        "3.5"       "1.4"        "0.2"       "setosa"
> > >> 2 "4.9"        "3.0"       "1.4"        "0.2"       "setosa"
> > >> 3 "4.7"        "3.2"       "1.3"        "0.2"       "setosa"
> > >> 4 "4.6"        "3.1"       "1.5"        "0.2"       "setosa"
> > >> 5 "5.0"        "3.6"       "1.4"        "0.2"       "setosa"
> > >> 6 "5.4"        "3.9"       "1.7"        "0.4"       "setosa"
> > >>> class(irm) <- "numeric"
> > >> Warning message:
> > >> In class(irm) <- "numeric" : NAs introduced by coercion
> > >>> head(irm)
> > >>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > >> 1          5.1         3.5          1.4         0.2      NA
> > >> 2          4.9         3.0          1.4         0.2      NA
> > >> 3          4.7         3.2          1.3         0.2      NA
> > >> 4          4.6         3.1          1.5         0.2      NA
> > >> 5          5.0         3.6          1.4         0.2      NA
> > >> 6          5.4         3.9          1.7         0.4      NA
> > >>>
> > >>
> > >> Cheers
> > >> Petr
> > >>
> > >>
> > >>>
> > >>>
> > >>> *Warning message:In class(genod) <- "numeric" : NAs introduced by
> > >> coercion*
> > >>>
> > >>> Maybe I could illustrate more with details so I can be more specific?
> > >>> Please, let me know.
> > >>>
> > >>> I would appreciate your help.
> > >>> Thanks,
> > >>> Meriam
> > >>>
> > >>> [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > >> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > >> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > >> about processing and protection of business partner?s personal data are
> > >> available on website:
> > >> https://www.precheza.cz/en/personal-data-protection-principles/
> > >> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > >> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > >> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > >> documents attached to it may be confidential and are subject to the legally
> > >> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > >>
> > >>
> > >
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
>
>
>
> --
> Meriam Nefzaoui
> MSc. in Plant Breeding and Genetics
> Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil

From @eb@@tien@bihorel @ending from cognigencorp@com  Wed Jan  9 20:42:45 2019
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Wed, 9 Jan 2019 14:42:45 -0500 (EST)
Subject: [R] Diff'ing 2 strings
In-Reply-To: <CAGxFJbQyiwXkv2Y86maU-Pr6qMF9Gu_v8Qt3Kg_WQ8UX0k7=Bw@mail.gmail.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQyiwXkv2Y86maU-Pr6qMF9Gu_v8Qt3Kg_WQ8UX0k7=Bw@mail.gmail.com>
Message-ID: <147124240.3950631.1547062965415.JavaMail.zimbra@cognigencorp.com>

Thanks 

Sorry my mention of "fairly complex strings" was indeed a bit vague, indeed. My code is building strings that contain \n characters so something that could be thought about as multiline strings. 

For comparing these strings, I was hoping to use something like the linux diff command which is smart enough to recognize these line chunks you mentioned and not just to a simple line-by-line comparison. 

I saw a few thread mentioning ?adist. I will look into that. 

Sebastien 


From: "Bert Gunter" <bgunter.4567 at gmail.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: "R-help" <r-help at r-project.org> 
Sent: Saturday, January 5, 2019 10:19:42 AM 
Subject: Re: [R] Diff'ing 2 strings 

I do not know what you mean in your string context, as diff in Linux finds lines in files that differ. A reproducible example -- posting guide! -- would be most useful here. 

However, maybe something of the following strategy might be useful: 

1. Break up your strings into lists of string "chunks" relevant for your context via strspit() . Using "" (empty character) as the "sep" string would break your strings into individual characters; "\n" would break it into "lines" separated by the return 
character; etc. 

2. Compare your lists using e.g. lapply() and probably ?match and friends like ?setdiff 

You should also probably check out the stringr package to see if it contains what you need. Also, if this is gene sequence related, posting on the Bioconductor list rather than here is likely to be more fruitful. 

Cheers, 
Bert 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 


On Sat, Jan 5, 2019 at 5:58 AM Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 


Hi, 

Does R include an equivalent of the linux diff command? 

Ideally I would like to diff 2 fairly complex strings and extract the differences without having to save them on disk and using a system('diff file1 file2') command. 

Thanks 

Sebastien 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]


From J@Hillier @ending from lboro@@c@uk  Wed Jan  9 23:55:04 2019
From: J@Hillier @ending from lboro@@c@uk (John Hillier)
Date: Wed, 9 Jan 2019 22:55:04 +0000
Subject: [R] Resampling 1 time series at another set of (known) irregularly
 spaced times
Message-ID: <DB6PR0401MB2311AA006C006775C3ADD033A18B0@DB6PR0401MB2311.eurprd04.prod.outlook.com>

Dear All,


I would appreciate a quick pointer in the right direction (e.g. www page I could look at, or indicator of which function within a package).


The problem: I have a regular time series of values x at times t (i.e. t, x). I would like to sample them at irregular, known times - this is a second time series (T).


I can move these data between formats as required (i.e. file, vector, matrix, ts etc ....)


I have been searching around for a while and found many packages to regularise time-series (e.g. xts, lubricate, ..... ), but not the reverse as I want to.


Before you ask, I know it might seem a bit odd, but it is necessary for the particular question I'm asking.


Thank you for your time,


John


-------------------------
Work days: Mon-Thurs
Web page: <http://homepages.lboro.ac.uk/~gyjh5/> <http://www.lboro.ac.uk/departments/geography/staff/john-hillier/> http://www.lboro.ac.uk/departments/geography/staff/john-hillier/
Latest research: http://publications.lboro.ac.uk/publications/all/collated/gyjh5.html<https://lb-public.lboro.ac.uk/cgi-bin/personcite?username=gyjh5&dobranding=1&hits=10>

Dr John Hillier
Senior Lecturer & NERC Knowledge Exchange Fellow (Insurance Sector)
Geography and Environment
Loughborough University
01509 223727

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jan 10 00:17:14 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 09 Jan 2019 15:17:14 -0800
Subject: [R] 
 Resampling 1 time series at another set of (known) irregularly
 spaced times
In-Reply-To: <DB6PR0401MB2311AA006C006775C3ADD033A18B0@DB6PR0401MB2311.eurprd04.prod.outlook.com>
References: <DB6PR0401MB2311AA006C006775C3ADD033A18B0@DB6PR0401MB2311.eurprd04.prod.outlook.com>
Message-ID: <6F93C8DC-EBB1-40A6-A72F-CB769CF8A3C2@dcn.davis.ca.us>

The key to accomplishing this is to clarify how you want to address selecting values between the existing points, but there are many base R functions and packages that address this problem. In general the methods fall into two categories: interpolation and smoothing. Interpolation includes piecewise linear interpolation, splines, last-observation-carried-forward, and  first-order-extrapolation, all of which yield the same values of applied only at the original independent values. Smoothing methods such as regression, loess, kriging, and kernel interpolation may not have this identity property but you don't need unique input values at each independent variable value either.

Read some Task Views, e.g.

https://cran.r-project.org/web/views/NumericalMathematics.html

https://cran.r-project.org/web/views/TimeSeries.html

https://cran.r-project.org/web/views/MissingData.html



On January 9, 2019 2:55:04 PM PST, John Hillier <J.Hillier at lboro.ac.uk> wrote:
>Dear All,
>
>
>I would appreciate a quick pointer in the right direction (e.g. www
>page I could look at, or indicator of which function within a package).
>
>
>The problem: I have a regular time series of values x at times t (i.e.
>t, x). I would like to sample them at irregular, known times - this is
>a second time series (T).
>
>
>I can move these data between formats as required (i.e. file, vector,
>matrix, ts etc ....)
>
>
>I have been searching around for a while and found many packages to
>regularise time-series (e.g. xts, lubricate, ..... ), but not the
>reverse as I want to.
>
>
>Before you ask, I know it might seem a bit odd, but it is necessary for
>the particular question I'm asking.
>
>
>Thank you for your time,
>
>
>John
>
>
>-------------------------
>Work days: Mon-Thurs
>Web page: <http://homepages.lboro.ac.uk/~gyjh5/>
><http://www.lboro.ac.uk/departments/geography/staff/john-hillier/>
>http://www.lboro.ac.uk/departments/geography/staff/john-hillier/
>Latest research:
>http://publications.lboro.ac.uk/publications/all/collated/gyjh5.html<https://lb-public.lboro.ac.uk/cgi-bin/personcite?username=gyjh5&dobranding=1&hits=10>
>
>Dr John Hillier
>Senior Lecturer & NERC Knowledge Exchange Fellow (Insurance Sector)
>Geography and Environment
>Loughborough University
>01509 223727
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Thu Jan 10 00:37:01 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 9 Jan 2019 15:37:01 -0800
Subject: [R] 
 Resampling 1 time series at another set of (known) irregularly
 spaced times
In-Reply-To: <6F93C8DC-EBB1-40A6-A72F-CB769CF8A3C2@dcn.davis.ca.us>
References: <DB6PR0401MB2311AA006C006775C3ADD033A18B0@DB6PR0401MB2311.eurprd04.prod.outlook.com>
 <6F93C8DC-EBB1-40A6-A72F-CB769CF8A3C2@dcn.davis.ca.us>
Message-ID: <CAGxFJbRDwPN=Kz9ts62DDyojX-drc-eW1Y5MwoecFcaRx=ULtg@mail.gmail.com>

John:

Clarification: Do you mean you just want an "irregular" subset of your
*given* data values/times, or do you want times randomly over the series
duration for which you will construct values, which is what Jeff described.

The former is trivial: see ?sample with the "replace" argument = FALSE :
you're actually just sampling from the integer vector of time indices here,
so sample.int would even do. For the latter, I would presume you could use
?runif to sample arbitrary times over the time series duration and then
follow Jeff's suggestions to fill in values for these times using methods
to which he referred you.

Or have I misunderstood completely?

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 9, 2019 at 3:17 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The key to accomplishing this is to clarify how you want to address
> selecting values between the existing points, but there are many base R
> functions and packages that address this problem. In general the methods
> fall into two categories: interpolation and smoothing. Interpolation
> includes piecewise linear interpolation, splines,
> last-observation-carried-forward, and  first-order-extrapolation, all of
> which yield the same values of applied only at the original independent
> values. Smoothing methods such as regression, loess, kriging, and kernel
> interpolation may not have this identity property but you don't need unique
> input values at each independent variable value either.
>
> Read some Task Views, e.g.
>
> https://cran.r-project.org/web/views/NumericalMathematics.html
>
> https://cran.r-project.org/web/views/TimeSeries.html
>
> https://cran.r-project.org/web/views/MissingData.html
>
>
>
> On January 9, 2019 2:55:04 PM PST, John Hillier <J.Hillier at lboro.ac.uk>
> wrote:
> >Dear All,
> >
> >
> >I would appreciate a quick pointer in the right direction (e.g. www
> >page I could look at, or indicator of which function within a package).
> >
> >
> >The problem: I have a regular time series of values x at times t (i.e.
> >t, x). I would like to sample them at irregular, known times - this is
> >a second time series (T).
> >
> >
> >I can move these data between formats as required (i.e. file, vector,
> >matrix, ts etc ....)
> >
> >
> >I have been searching around for a while and found many packages to
> >regularise time-series (e.g. xts, lubricate, ..... ), but not the
> >reverse as I want to.
> >
> >
> >Before you ask, I know it might seem a bit odd, but it is necessary for
> >the particular question I'm asking.
> >
> >
> >Thank you for your time,
> >
> >
> >John
> >
> >
> >-------------------------
> >Work days: Mon-Thurs
> >Web page: <http://homepages.lboro.ac.uk/~gyjh5/>
> ><http://www.lboro.ac.uk/departments/geography/staff/john-hillier/>
> >http://www.lboro.ac.uk/departments/geography/staff/john-hillier/
> >Latest research:
> >http://publications.lboro.ac.uk/publications/all/collated/gyjh5.html<
> https://lb-public.lboro.ac.uk/cgi-bin/personcite?username=gyjh5&dobranding=1&hits=10
> >
> >
> >Dr John Hillier
> >Senior Lecturer & NERC Knowledge Exchange Fellow (Insurance Sector)
> >Geography and Environment
> >Loughborough University
> >01509 223727
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tr@xpl@yer @ending from gm@il@com  Thu Jan 10 08:35:15 2019
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 10 Jan 2019 08:35:15 +0100
Subject: [R] Diff'ing 2 strings
In-Reply-To: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>

On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com wrote:

> Hi,
>
> Does R include an equivalent of the linux diff command?
>

yes.
?rdiff

/martin

	[[alternative HTML version deleted]]


From gerrit@eichner @ending from m@th@uni-gie@@en@de  Thu Jan 10 09:22:10 2019
From: gerrit@eichner @ending from m@th@uni-gie@@en@de (Gerrit Eichner)
Date: Thu, 10 Jan 2019 09:22:10 +0100
Subject: [R] Diff'ing 2 strings
In-Reply-To: <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
Message-ID: <3bbae57e-ed87-371d-e698-fed0d169a7cd@math.uni-giessen.de>

Don't you mean ?Rdiff ?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 10.01.2019 um 08:35 schrieb Martin M?ller Skarbiniks Pedersen:
> On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com wrote:
> 
>> Hi,
>>
>> Does R include an equivalent of the linux diff command?
>>
> 
> yes.
> ?rdiff
> 
> /martin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tring @ending from gvdnet@dk  Thu Jan 10 09:28:22 2019
From: tring @ending from gvdnet@dk (Troels Ring)
Date: Thu, 10 Jan 2019 09:28:22 +0100
Subject: [R] Diff'ing 2 strings
In-Reply-To: hUsmgESzrtXDihUsngEmgS
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 hUsmgESzrtXDihUsngEmgS
Message-ID: <000001d4a8be$7661a3b0$6324eb10$@gvdnet.dk>

?Rdiff perhaps??
Troels

-----Oprindelig meddelelse-----
Fra: R-help <r-help-bounces at r-project.org> P? vegne af Martin M?ller
Skarbiniks Pedersen
Sendt: 10. januar 2019 08:35
Til: Sebastien Bihorel <sebastien.bihorel at cognigencorp.com>
Cc: R mailing list <r-help at r-project.org>
Emne: Re: [R] Diff'ing 2 strings

On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com wrote:

> Hi,
>
> Does R include an equivalent of the linux diff command?
>

yes.
?rdiff

/martin

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tr@xpl@yer @ending from gm@il@com  Thu Jan 10 12:21:27 2019
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 10 Jan 2019 12:21:27 +0100
Subject: [R] Diff'ing 2 strings
In-Reply-To: <3bbae57e-ed87-371d-e698-fed0d169a7cd@math.uni-giessen.de>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <3bbae57e-ed87-371d-e698-fed0d169a7cd@math.uni-giessen.de>
Message-ID: <CAGAA5bdQL_gFocSbbXEH-qBzeAJyzoJ0CPTyoav=2L0HbEYbnA@mail.gmail.com>

On Thu, 10 Jan 2019 at 09:23, Gerrit Eichner <
gerrit.eichner at math.uni-giessen.de> wrote:

> Don't you mean ?Rdiff ?
>
>
Oh yes.
The unix/linux command diff uses the rdiff-algorithme and it seems that
Rdiff in R uses the exactly same algorithme.

Regards
Martin

	[[alternative HTML version deleted]]


From J@Hillier @ending from lboro@@c@uk  Thu Jan 10 12:27:11 2019
From: J@Hillier @ending from lboro@@c@uk (John Hillier)
Date: Thu, 10 Jan 2019 11:27:11 +0000
Subject: [R] 
 Resampling 1 time series at another set of (known) irregularly
 spaced times
In-Reply-To: <CAGxFJbRDwPN=Kz9ts62DDyojX-drc-eW1Y5MwoecFcaRx=ULtg@mail.gmail.com>
References: <DB6PR0401MB2311AA006C006775C3ADD033A18B0@DB6PR0401MB2311.eurprd04.prod.outlook.com>
 <6F93C8DC-EBB1-40A6-A72F-CB769CF8A3C2@dcn.davis.ca.us>,
 <CAGxFJbRDwPN=Kz9ts62DDyojX-drc-eW1Y5MwoecFcaRx=ULtg@mail.gmail.com>
Message-ID: <DB6PR0401MB2311998075A289CE3F80E9C5A1840@DB6PR0401MB2311.eurprd04.prod.outlook.com>

Thank you Jeff and Bert,


You provided the pointer to reliable starting place that I needed after my initial searching.  I now better understand the terminology/approach used in R for this sort of thing. The answer is indeed trivial when you know how e.g. use the 'xout' option in approx().


Now I've got my eye-in, and I have been able to do similar in a range of other packages/functions.


Thank you!


John


p.s. - For the record, some more detail clarifying question and answer.


# A regular time series
s1 <- as.data.frame(c(0,1,2,3,4,5,6,7,8,9,10))
s1[,2] <- c(0,0.1,0.2,0.3,0.4,0.5,0.4,0.3,0.2,0.4,0)
names(s1)[1] <- "t"
names(s1)[2] <- "x"

# irregular, known times to sample this at
s2 <- as.data.frame(c(0.3,2.1,2.6,4,6.5,8.8,9.3))
names(s2)[1] <- "T"


# Solution - e.g. for approx() in RBase use the 'xout' option.

# approx(x, y, xout, method="linear", n=50, yleft, yright, rule=1, f=0)

out <- approx(s1[,1],s1[,2],s2[,1], method="linear")

out$x[]

out$y[]


-------------------------
Work days: Mon-Thurs
Web page: <http://homepages.lboro.ac.uk/~gyjh5/> <http://www.lboro.ac.uk/departments/geography/staff/john-hillier/> http://www.lboro.ac.uk/departments/geography/staff/john-hillier/
Latest research: http://publications.lboro.ac.uk/publications/all/collated/gyjh5.html<https://lb-public.lboro.ac.uk/cgi-bin/personcite?username=gyjh5&dobranding=1&hits=10>

Dr John Hillier
Senior Lecturer & NERC Knowledge Exchange Fellow (Insurance Sector)
Geography and Environment
Loughborough University
01509 223727
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 09 January 2019 23:37:01
To: Jeff Newmiller
Cc: R-help; John Hillier
Subject: Re: [R] Resampling 1 time series at another set of (known) irregularly spaced times

John:

Clarification: Do you mean you just want an "irregular" subset of your *given* data values/times, or do you want times randomly over the series duration for which you will construct values, which is what Jeff described.

The former is trivial: see ?sample with the "replace" argument = FALSE : you're actually just sampling from the integer vector of time indices here, so sample.int<http://sample.int> would even do. For the latter, I would presume you could use ?runif to sample arbitrary times over the time series duration and then follow Jeff's suggestions to fill in values for these times using methods to which he referred you.

Or have I misunderstood completely?

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 9, 2019 at 3:17 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:
The key to accomplishing this is to clarify how you want to address selecting values between the existing points, but there are many base R functions and packages that address this problem. In general the methods fall into two categories: interpolation and smoothing. Interpolation includes piecewise linear interpolation, splines, last-observation-carried-forward, and  first-order-extrapolation, all of which yield the same values of applied only at the original independent values. Smoothing methods such as regression, loess, kriging, and kernel interpolation may not have this identity property but you don't need unique input values at each independent variable value either.

Read some Task Views, e.g.

https://cran.r-project.org/web/views/NumericalMathematics.html

https://cran.r-project.org/web/views/TimeSeries.html

https://cran.r-project.org/web/views/MissingData.html



On January 9, 2019 2:55:04 PM PST, John Hillier <J.Hillier at lboro.ac.uk<mailto:J.Hillier at lboro.ac.uk>> wrote:
>Dear All,
>
>
>I would appreciate a quick pointer in the right direction (e.g. www
>page I could look at, or indicator of which function within a package).
>
>
>The problem: I have a regular time series of values x at times t (i.e.
>t, x). I would like to sample them at irregular, known times - this is
>a second time series (T).
>
>
>I can move these data between formats as required (i.e. file, vector,
>matrix, ts etc ....)
>
>
>I have been searching around for a while and found many packages to
>regularise time-series (e.g. xts, lubricate, ..... ), but not the
>reverse as I want to.
>
>
>Before you ask, I know it might seem a bit odd, but it is necessary for
>the particular question I'm asking.
>
>
>Thank you for your time,
>
>
>John
>
>
>-------------------------
>Work days: Mon-Thurs
>Web page: <http://homepages.lboro.ac.uk/~gyjh5/>
><http://www.lboro.ac.uk/departments/geography/staff/john-hillier/>
>http://www.lboro.ac.uk/departments/geography/staff/john-hillier/
>Latest research:
>http://publications.lboro.ac.uk/publications/all/collated/gyjh5.html<https://lb-public.lboro.ac.uk/cgi-bin/personcite?username=gyjh5&dobranding=1&hits=10>
>
>Dr John Hillier
>Senior Lecturer & NERC Knowledge Exchange Fellow (Insurance Sector)
>Geography and Environment
>Loughborough University
>01509 223727
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @ending from comc@@t@net  Wed Jan  9 20:29:22 2019
From: mcg@rvey@bern@rd @ending from comc@@t@net (Bernard McGarvey)
Date: Wed, 9 Jan 2019 14:29:22 -0500 (EST)
Subject: [R] User Interfaces for R
Message-ID: <278398401.281602.1547062163024@connect.xfinity.com>

I want to create an R application that includes a user interface where the user inputs values etc and then can run R calculations and get results back on the user interface. I was hoping that an easy to use GUI package exists.


Can anyone point me to such an easy to use package to create GUIs for R?


Thanks in advance for any help.



Lion Bernard McGarvey

Director, Fort Myers Beach Lions Foundation, Inc.

Retired (Lilly Engineering Fellow).



	[[alternative HTML version deleted]]


From zeny@@t@t @ending from gm@il@com  Thu Jan 10 11:34:30 2019
From: zeny@@t@t @ending from gm@il@com (Naznin Sultana)
Date: Thu, 10 Jan 2019 16:34:30 +0600
Subject: [R] Seeking help for using optim for MLE in R
Message-ID: <CAHp8JvAw98W-qyC1ckmZmRyU94T20wyMGNV6zX5-0SDVg_FxBA@mail.gmail.com>

Hi, I am writing a program for MLE of parameters of multinomial distribution
using optim.But when I run the program outside of a function it gives me the
likelihood value, but when using it for optim function it gives the error
message "Error in X %*% beta : non-conformable arguments".
If X, and beta are non-conformable how it gives values.
My data has first three columns of three dependent variables and rest of the
colums indicating X (indep vars).
Please help me out. Here goes my program for k1 categories of multinomial
distribution:

#data is the data which consists of three dependent varaible in first three
columns and rest of the columns represent covariates.


k1<- length(unique(data[,1]))
p<- ncol(data)-3
beta0 <-matrix(-.00001,nrow=k1-1,ncol=(p+1)) # starting value
beta <-as.matrix(beta0)
beta <-as.matrix(t(beta))




## likelihood for y1

multin.lik<- function(beta,data) ##beta is a matrix of beta's of order
((p+1)*(k-1))
                {
                        nr<- nrow(data)
                        nc<- ncol(data)

                        y1<- data[,1]
                        y1<- as.matrix(y1,ncol=1)

                        X<-as.matrix(cbind(1,data[,4:nc])) #matrix of order
((n*(p+1)))
covariates; 1 is added for intercept

                        LL<- exp(X%*%beta) #LL is of order (n*(k-1))
                        L<- as.matrix(cbind(1,LL))  #L is of order (n*k); 1
is added for ref
category, L0, L1, L2
                        pi<- t(apply(L,1, function(i) i/sum(i)))


                        lgl<- 0
                        for (i in 1:nr)
                                {
                                        if (y1[i]==0) {lgl[i]<-
log(pi[i,1])}
                                        else if (y1[i]==1) {lgl[i]<-
log(pi[i,2])}
                                        else lgl[i]<- log(pi[i,3])
                                lgl
                                }
                        lgL<- sum(lgl)
                        return(-lgL)
                }


## parameter estimates
abc <-optim(beta, multin.lik,data=data,method="SANN",hessian=T)

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Thu Jan 10 15:59:12 2019
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Thu, 10 Jan 2019 16:59:12 +0200
Subject: [R] User Interfaces for R
In-Reply-To: <278398401.281602.1547062163024@connect.xfinity.com>
References: <278398401.281602.1547062163024@connect.xfinity.com>
Message-ID: <CAGgJW76g37rDdopN9gR6gJar3bu4y6qQEzB1sQumuubh8XneLg@mail.gmail.com>

Shiny (from RStudio - and free)
A wonderful tool. And the app is accessed via the user's browser.

On Thu, Jan 10, 2019 at 4:18 PM Bernard McGarvey <
mcgarvey.bernard at comcast.net> wrote:

> I want to create an R application that includes a user interface where the
> user inputs values etc and then can run R calculations and get results back
> on the user interface. I was hoping that an easy to use GUI package exists.
>
>
> Can anyone point me to such an easy to use package to create GUIs for R?
>
>
> Thanks in advance for any help.
>
>
>
> Lion Bernard McGarvey
>
> Director, Fort Myers Beach Lions Foundation, Inc.
>
> Retired (Lilly Engineering Fellow).
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pjmiller_57 @ending from y@hoo@com  Thu Jan 10 16:00:45 2019
From: pjmiller_57 @ending from y@hoo@com (Paul Miller)
Date: Thu, 10 Jan 2019 15:00:45 +0000 (UTC)
Subject: [R] Running list of drugs taken and dropped (via Reduce and
 accumulate = TRUE or by other means)
In-Reply-To: <mailman.353172.1.1547118002.60835.r-help@r-project.org>
References: <mailman.353172.1.1547118002.60835.r-help@r-project.org>
Message-ID: <1437053605.9401019.1547132445763@mail.yahoo.com>

Hello All,

Would like to keep a running total of what drugs cancer patients have taken and what drugs have been dropped. Searched the Internet and found a way to cumulatively paste a series of drug names. Am having trouble figuring out how to make the paste conditional though. 

Below is some sample data and code. I'd like to get the paste in the "taken" column to add a drug only when change = 1. I'd also like to get the paste in the "dropped" column to add a drug only when change = -1. 

Thanks,

Paul


sample_data <-
? structure(
??? list(
????? PTNO = c(82320L, 82320L, 82320L),
????? change = c(1, 1, -1),
????? drug = c("cetuximab", "docetaxel", "cetuximab")),
??? class = c("tbl_df", "tbl", "data.frame"),
??? row.names = c(NA, -3L)
? ) %>%
? mutate(
??? taken = Reduce(function(x1, x2) paste(x1, x2, sep = ", "), drug, accumulate = TRUE),
??? dropped = Reduce(function(x1, x2) paste(x1, x2, sep = ", "), drug, accumulate = TRUE)
? )


From @yekirin @ending from gm@il@com  Sat Jan  5 22:43:00 2019
From: @yekirin @ending from gm@il@com (Stanislav Syekirin)
Date: Sat, 5 Jan 2019 22:43:00 +0100
Subject: [R] [R-pkgs] New package readABF for reading Axon Binary Files
Message-ID: <CAO5UwgaeADkYcpma1ew=8w5wWS8ouRRPMcJmw+QmCTjZhG1tBA@mail.gmail.com>

A new package called readABF for reading .abf, a binary format (or rather a
family of related binary formats) used by software like Axon pClamp, is
available.

CRAN: https://cran.r-project.org/package=readABF
GitHub: https://github.com/Zabolekar/readABF

We greatly appreciate any feedback.

Best regards
Stanislav Syekirin

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @eb@@tien@bihorel @ending from cognigencorp@com  Thu Jan 10 16:35:42 2019
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Thu, 10 Jan 2019 10:35:42 -0500 (EST)
Subject: [R] Diff'ing 2 strings
In-Reply-To: <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
Message-ID: <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>

From which the diffobj package? 


From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: "R mailing list" <r-help at r-project.org> 
Sent: Thursday, January 10, 2019 2:35:15 AM 
Subject: Re: [R] Diff'ing 2 strings 



On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] wrote: 


Hi, 

Does R include an equivalent of the linux diff command? 




yes. 
?rdiff 

/martin 


	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Jan 10 16:44:42 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 10 Jan 2019 07:44:42 -0800
Subject: [R] Seeking help for using optim for MLE in R
In-Reply-To: <CAHp8JvAw98W-qyC1ckmZmRyU94T20wyMGNV6zX5-0SDVg_FxBA@mail.gmail.com>
References: <CAHp8JvAw98W-qyC1ckmZmRyU94T20wyMGNV6zX5-0SDVg_FxBA@mail.gmail.com>
Message-ID: <CAGxFJbSUy7xw_ZaeVna5wTr6_6xTVvWdT0G3Nj12eAfB8FEixA@mail.gmail.com>

Probably: don't do this.

Use the nnet package (and there may well be others) to fit multinomial
regression. See here for a tutorial:

https://rpubs.com/rslbliss/r_logistic_ws

Cheers,
Bert


On Thu, Jan 10, 2019 at 6:18 AM Naznin Sultana <zeny.stat at gmail.com> wrote:

> Hi, I am writing a program for MLE of parameters of multinomial
> distribution
> using optim.But when I run the program outside of a function it gives me
> the
> likelihood value, but when using it for optim function it gives the error
> message "Error in X %*% beta : non-conformable arguments".
> If X, and beta are non-conformable how it gives values.
> My data has first three columns of three dependent variables and rest of
> the
> colums indicating X (indep vars).
> Please help me out. Here goes my program for k1 categories of multinomial
> distribution:
>
> #data is the data which consists of three dependent varaible in first three
> columns and rest of the columns represent covariates.
>
>
> k1<- length(unique(data[,1]))
> p<- ncol(data)-3
> beta0 <-matrix(-.00001,nrow=k1-1,ncol=(p+1)) # starting value
> beta <-as.matrix(beta0)
> beta <-as.matrix(t(beta))
>
>
>
>
> ## likelihood for y1
>
> multin.lik<- function(beta,data) ##beta is a matrix of beta's of order
> ((p+1)*(k-1))
>                 {
>                         nr<- nrow(data)
>                         nc<- ncol(data)
>
>                         y1<- data[,1]
>                         y1<- as.matrix(y1,ncol=1)
>
>                         X<-as.matrix(cbind(1,data[,4:nc])) #matrix of order
> ((n*(p+1)))
> covariates; 1 is added for intercept
>
>                         LL<- exp(X%*%beta) #LL is of order (n*(k-1))
>                         L<- as.matrix(cbind(1,LL))  #L is of order (n*k); 1
> is added for ref
> category, L0, L1, L2
>                         pi<- t(apply(L,1, function(i) i/sum(i)))
>
>
>                         lgl<- 0
>                         for (i in 1:nr)
>                                 {
>                                         if (y1[i]==0) {lgl[i]<-
> log(pi[i,1])}
>                                         else if (y1[i]==1) {lgl[i]<-
> log(pi[i,2])}
>                                         else lgl[i]<- log(pi[i,3])
>                                 lgl
>                                 }
>                         lgL<- sum(lgl)
>                         return(-lgL)
>                 }
>
>
> ## parameter estimates
> abc <-optim(beta, multin.lik,data=data,method="SANN",hessian=T)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jan 10 16:49:15 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Jan 2019 07:49:15 -0800
Subject: [R] Diff'ing 2 strings
In-Reply-To: <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
Message-ID: <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>

Just type

?Rdiff

it is in the preinstalled packages that come with R.

On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:
>From which the diffobj package? 
>
>
>From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> 
>To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
>Cc: "R mailing list" <r-help at r-project.org> 
>Sent: Thursday, January 10, 2019 2:35:15 AM 
>Subject: Re: [R] Diff'ing 2 strings 
>
>
>
>On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
>mailto:sebastien.bihorel at cognigencorp.com |
>sebastien.bihorel at cognigencorp.com ] wrote: 
>
>
>Hi, 
>
>Does R include an equivalent of the linux diff command? 
>
>
>
>
>yes. 
>?rdiff 
>
>/martin 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @eb@@tien@bihorel @ending from cognigencorp@com  Thu Jan 10 17:38:34 2019
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Thu, 10 Jan 2019 11:38:34 -0500 (EST)
Subject: [R] Diff'ing 2 strings
In-Reply-To: <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
 <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
Message-ID: <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>

Yep, I did. Got nothing. It does not come with R 3.4.3, which is the version I can use.

R CMD Rdiff comes with this version, but it is a shell command not a R function. It is meant for diff'ing R output.


----- Original Message -----
From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
To: r-help at r-project.org, "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
Cc: "R mailing list" <r-help at r-project.org>
Sent: Thursday, January 10, 2019 10:49:15 AM
Subject: Re: [R] Diff'ing 2 strings

Just type

?Rdiff

it is in the preinstalled packages that come with R.

On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:
>From which the diffobj package? 
>
>
>From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> 
>To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
>Cc: "R mailing list" <r-help at r-project.org> 
>Sent: Thursday, January 10, 2019 2:35:15 AM 
>Subject: Re: [R] Diff'ing 2 strings 
>
>
>
>On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
>mailto:sebastien.bihorel at cognigencorp.com |
>sebastien.bihorel at cognigencorp.com ] wrote: 
>
>
>Hi, 
>
>Does R include an equivalent of the linux diff command? 
>
>
>
>
>yes. 
>?rdiff 
>
>/martin 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdunl@p @ending from tibco@com  Thu Jan 10 17:48:59 2019
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Thu, 10 Jan 2019 08:48:59 -0800
Subject: [R] Diff'ing 2 strings
In-Reply-To: <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
 <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
 <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAF8bMcbx29dC9FR09N-UPEVmOqikzknfTuk6=2CXod_HeJhWMg@mail.gmail.com>

> args(tools::Rdiff)
function (from, to, useDiff = FALSE, forEx = FALSE, nullPointers = TRUE,
    Log = FALSE)
NULL
> version$version.string
[1] "R version 3.4.3 (2017-11-30)"

(The 'tools' package is not attached by default, so use ::.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 10, 2019 at 8:39 AM Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Yep, I did. Got nothing. It does not come with R 3.4.3, which is the
> version I can use.
>
> R CMD Rdiff comes with this version, but it is a shell command not a R
> function. It is meant for diff'ing R output.
>
>
> ----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: r-help at r-project.org, "Sebastien Bihorel" <
> sebastien.bihorel at cognigencorp.com>, "Martin M?ller Skarbiniks Pedersen" <
> traxplayer at gmail.com>
> Cc: "R mailing list" <r-help at r-project.org>
> Sent: Thursday, January 10, 2019 10:49:15 AM
> Subject: Re: [R] Diff'ing 2 strings
>
> Just type
>
> ?Rdiff
>
> it is in the preinstalled packages that come with R.
>
> On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com> wrote:
> >From which the diffobj package?
> >
> >
> >From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
> >To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
> >Cc: "R mailing list" <r-help at r-project.org>
> >Sent: Thursday, January 10, 2019 2:35:15 AM
> >Subject: Re: [R] Diff'ing 2 strings
> >
> >
> >
> >On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
> >mailto:sebastien.bihorel at cognigencorp.com |
> >sebastien.bihorel at cognigencorp.com ] wrote:
> >
> >
> >Hi,
> >
> >Does R include an equivalent of the linux diff command?
> >
> >
> >
> >
> >yes.
> >?rdiff
> >
> >/martin
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Thu Jan 10 17:43:14 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 10 Jan 2019 11:43:14 -0500
Subject: [R] Diff'ing 2 strings
In-Reply-To: <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
 <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
 <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
Message-ID: <2b9519d1-b481-206c-4b1b-1cb8871e13f4@gmail.com>

On 10/01/2019 11:38 a.m., Sebastien Bihorel wrote:
> Yep, I did. Got nothing. It does not come with R 3.4.3, which is the version I can use.
> 
> R CMD Rdiff comes with this version, but it is a shell command not a R function. It is meant for diff'ing R output.

It's in the tools package, so ?tools::Rdiff should get what you want 
even in that version.  But as you note, it isn't a general purpose diff 
for character vectors, it is targeted at comparing R output files.

Duncan Murdoch

> 
> 
> ----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: r-help at r-project.org, "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
> Cc: "R mailing list" <r-help at r-project.org>
> Sent: Thursday, January 10, 2019 10:49:15 AM
> Subject: Re: [R] Diff'ing 2 strings
> 
> Just type
> 
> ?Rdiff
> 
> it is in the preinstalled packages that come with R.
> 
> On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:
>>From which the diffobj package? 
>>
>>
>> From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
>> To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
>> Cc: "R mailing list" <r-help at r-project.org>
>> Sent: Thursday, January 10, 2019 2:35:15 AM
>> Subject: Re: [R] Diff'ing 2 strings
>>
>>
>>
>> On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
>> mailto:sebastien.bihorel at cognigencorp.com |
>> sebastien.bihorel at cognigencorp.com ] wrote:
>>
>>
>> Hi,
>>
>> Does R include an equivalent of the linux diff command?
>>
>>
>>
>>
>> yes.
>> ?rdiff
>>
>> /martin
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Thu Jan 10 17:48:42 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 10 Jan 2019 08:48:42 -0800
Subject: [R] Diff'ing 2 strings
In-Reply-To: <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
 <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
 <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbSh32iMcJH114DRhbnn=F=wFaq+QiZd0PHb6MCfxp2baw@mail.gmail.com>

It's the same thing. From ?Rdiff:

"Given two *R* output files, compute differences ignoring headers, footers
and some other differences."

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 10, 2019 at 8:39 AM Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Yep, I did. Got nothing. It does not come with R 3.4.3, which is the
> version I can use.
>
> R CMD Rdiff comes with this version, but it is a shell command not a R
> function. It is meant for diff'ing R output.
>
>
> ----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: r-help at r-project.org, "Sebastien Bihorel" <
> sebastien.bihorel at cognigencorp.com>, "Martin M?ller Skarbiniks Pedersen" <
> traxplayer at gmail.com>
> Cc: "R mailing list" <r-help at r-project.org>
> Sent: Thursday, January 10, 2019 10:49:15 AM
> Subject: Re: [R] Diff'ing 2 strings
>
> Just type
>
> ?Rdiff
>
> it is in the preinstalled packages that come with R.
>
> On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com> wrote:
> >From which the diffobj package?
> >
> >
> >From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
> >To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
> >Cc: "R mailing list" <r-help at r-project.org>
> >Sent: Thursday, January 10, 2019 2:35:15 AM
> >Subject: Re: [R] Diff'ing 2 strings
> >
> >
> >
> >On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
> >mailto:sebastien.bihorel at cognigencorp.com |
> >sebastien.bihorel at cognigencorp.com ] wrote:
> >
> >
> >Hi,
> >
> >Does R include an equivalent of the linux diff command?
> >
> >
> >
> >
> >yes.
> >?rdiff
> >
> >/martin
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Thu Jan 10 17:54:12 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 10 Jan 2019 08:54:12 -0800
Subject: [R] Running list of drugs taken and dropped (via Reduce and
 accumulate = TRUE or by other means)
In-Reply-To: <1437053605.9401019.1547132445763@mail.yahoo.com>
References: <mailman.353172.1.1547118002.60835.r-help@r-project.org>
 <1437053605.9401019.1547132445763@mail.yahoo.com>
Message-ID: <5b1e2215-fa4e-edcb-3d23-f2cdedd7e3d9@comcast.net>


On 1/10/19 7:00 AM, Paul Miller via R-help wrote:
> Hello All,
>
> Would like to keep a running total of what drugs cancer patients have taken and what drugs have been dropped. Searched the Internet and found a way to cumulatively paste a series of drug names. Am having trouble figuring out how to make the paste conditional though.
>
> Below is some sample data and code. I'd like to get the paste in the "taken" column to add a drug only when change = 1. I'd also like to get the paste in the "dropped" column to add a drug only when change = -1.


You apparently expect us to have pkg:dplyr loaded. The appropriate code 
for that would be `library(dplyr)` at the initiation of the example. 
Unlike StackOverflow there is no universal expectation in Rhelp of that 
preparation.

The `Reduce` function could probably be used if you were willing to 
rework two columns into a list that had a sequence of 2 two-element 
lists but it's not the first choice for handling this data situation. 
Instead consider using `mapply` or perhaps `by`. You are also going to 
need to wrap this approach in a programming structure that allows a 
patient-focused result to be computed, either `lapply( split( ... `? or 
its equivalent in the hadleyverse:? `%>% group_by(...`

In the hadleyverse context, you should probably learn to use the purrr 
function `map2` for the two-column conditional processing.


-- 

David.

>
> Thanks,
>
> Paul
>
>
> sample_data <-
>  ? structure(
>  ??? list(
>  ????? PTNO = c(82320L, 82320L, 82320L),
>  ????? change = c(1, 1, -1),
>  ????? drug = c("cetuximab", "docetaxel", "cetuximab")),
>  ??? class = c("tbl_df", "tbl", "data.frame"),
>  ??? row.names = c(NA, -3L)
>  ? ) %>%
>  ? mutate(
>  ??? taken = Reduce(function(x1, x2) paste(x1, x2, sep = ", "), drug, accumulate = TRUE),
>  ??? dropped = Reduce(function(x1, x2) paste(x1, x2, sep = ", "), drug, accumulate = TRUE)
>  ? )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @eb@@tien@bihorel @ending from cognigencorp@com  Thu Jan 10 18:18:48 2019
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Thu, 10 Jan 2019 12:18:48 -0500 (EST)
Subject: [R] Diff'ing 2 strings
In-Reply-To: <2b9519d1-b481-206c-4b1b-1cb8871e13f4@gmail.com>
References: <238788969.3775664.1546696687146.JavaMail.zimbra@cognigencorp.com>
 <CAGAA5befSekEVgG-ty0LbKzHD2h3J-wS3=3wpTRB=r+UsLjtpw@mail.gmail.com>
 <1537914030.3979716.1547134542318.JavaMail.zimbra@cognigencorp.com>
 <55D802DB-115E-48CF-8D4F-04CB33127D52@dcn.davis.ca.us>
 <1170282572.3983786.1547138314564.JavaMail.zimbra@cognigencorp.com>
 <2b9519d1-b481-206c-4b1b-1cb8871e13f4@gmail.com>
Message-ID: <1830184636.3985497.1547140728350.JavaMail.zimbra@cognigencorp.com>


Thanks for the clarification.

----- Original Message -----
From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
Cc: r-help at r-project.org
Sent: Thursday, January 10, 2019 11:43:14 AM
Subject: Re: [R] Diff'ing 2 strings

On 10/01/2019 11:38 a.m., Sebastien Bihorel wrote:
> Yep, I did. Got nothing. It does not come with R 3.4.3, which is the version I can use.
> 
> R CMD Rdiff comes with this version, but it is a shell command not a R function. It is meant for diff'ing R output.

It's in the tools package, so ?tools::Rdiff should get what you want 
even in that version.  But as you note, it isn't a general purpose diff 
for character vectors, it is targeted at comparing R output files.

Duncan Murdoch

> 
> 
> ----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: r-help at r-project.org, "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
> Cc: "R mailing list" <r-help at r-project.org>
> Sent: Thursday, January 10, 2019 10:49:15 AM
> Subject: Re: [R] Diff'ing 2 strings
> 
> Just type
> 
> ?Rdiff
> 
> it is in the preinstalled packages that come with R.
> 
> On January 10, 2019 7:35:42 AM PST, Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:
>>From which the diffobj package? 
>>
>>
>> From: "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com>
>> To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
>> Cc: "R mailing list" <r-help at r-project.org>
>> Sent: Thursday, January 10, 2019 2:35:15 AM
>> Subject: Re: [R] Diff'ing 2 strings
>>
>>
>>
>> On Sat, Jan 5, 2019, 14:58 Sebastien Bihorel < [
>> mailto:sebastien.bihorel at cognigencorp.com |
>> sebastien.bihorel at cognigencorp.com ] wrote:
>>
>>
>> Hi,
>>
>> Does R include an equivalent of the linux diff command?
>>
>>
>>
>>
>> yes.
>> ?rdiff
>>
>> /martin
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From krylov@r00t @ending from gm@il@com  Thu Jan 10 22:25:33 2019
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Fri, 11 Jan 2019 00:25:33 +0300
Subject: [R] User Interfaces for R
In-Reply-To: <278398401.281602.1547062163024@connect.xfinity.com>
References: <278398401.281602.1547062163024@connect.xfinity.com>
Message-ID: <20190111002533.5f7dd3eb@Tarkus>

On Wed, 9 Jan 2019 14:29:22 -0500 (EST)
Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:

> Can anyone point me to such an easy to use package to create GUIs for
> R?

If you want a traditional approach, a lot of R installations have
Tcl/Tk support built in (i.e. capabilities('tcltk') is TRUE). This
means that you can run library(tcltk) and call Tk functions to display
interactive windows almost everywhere.

This toolkit requires some knowledge of Tk [*] and may not look
particularly nice on some platforms, but is probably already included
in most R installations and has low resource footprint. There is a set
of slides [**] that might help you start using Tk, its widgets and
geometry managers.

R commander (Rcmdr, [***]) package has been developed using Tk.

The book Programming Graphical User Interfaces in R by Michael
Lawrence and John Verzani (ISBN 9781439856826) describes the major R
packages for GUI programming: RGtk2, qtbase, Tcl/Tk, and gWidgets.

-- 
Best regards,
Ivan

[*] https://www.tcl.tk/man/tcl8.6/TkCmd/contents.htm

[**]
https://uwaterloo.ca/statistics-and-actuarial-science/sites/ca.statistics-and-actuarial-science/files/uploads/files/rtcltk_tcl.pdf
https://uwaterloo.ca/statistics-and-actuarial-science/sites/ca.statistics-and-actuarial-science/files/uploads/files/rtcltk_geometry.pdf

[***] https://rcommander.com/


From mcg@rvey@bern@rd @ending from comc@@t@net  Thu Jan 10 22:39:45 2019
From: mcg@rvey@bern@rd @ending from comc@@t@net (Bernard Comcast)
Date: Thu, 10 Jan 2019 16:39:45 -0500
Subject: [R] Reading an excel file
Message-ID: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>

What is the best way to read in data of any type from an Excel 2016 .xlsx file?

Thanks

Bernard
Sent from my iPhone so please excuse the spelling!"

From h@@@n@diw@n @ending from gm@il@com  Thu Jan 10 22:43:11 2019
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Thu, 10 Jan 2019 13:43:11 -0800
Subject: [R] Reading an excel file
In-Reply-To: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
References: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
Message-ID: <CAP+bYWAUgvuzJhSsjQPikxCvqWrw+3h75L1+9n4=EdQT_nUkXQ@mail.gmail.com>

 https://cran.r-project.org/web/packages/xlsx/xlsx.pdf

You'll need the JDK (>= 1.6) -- H

On Thu, 10 Jan 2019 at 13:40, Bernard Comcast <mcgarvey.bernard at comcast.net>
wrote:

> What is the best way to read in data of any type from an Excel 2016 .xlsx
> file?
>
> Thanks
>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Jan 10 22:57:55 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 10 Jan 2019 13:57:55 -0800
Subject: [R] Reading an excel file
In-Reply-To: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
References: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
Message-ID: <CAGxFJbTZ_PXji2oguHO1_oFwMpP=m4Ocs7vjF9OM+31a+k=WqQ@mail.gmail.com>

Don't!

Well, I know that being a wiseguy is not helpful, but this "advice" is
actually not entirely unhelpful. Search on "input Excel file" or similar on
rseek.org to bring up many links, including the readxl package, tutorials,
the R data import/export manual, etc. However, excel files are notoriously
"unstructured," and you would probably be better off converting your data
in tabular form to a .csv or .txt file and reading in from there (using
read.table, read.csv, etc.) . The linked references (and advice from others
with more experience) should be consulted for details.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 10, 2019 at 1:40 PM Bernard Comcast <
mcgarvey.bernard at comcast.net> wrote:

> What is the best way to read in data of any type from an Excel 2016 .xlsx
> file?
>
> Thanks
>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @lk@uffm @ending from f@@tm@il@fm  Thu Jan 10 23:14:52 2019
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Thu, 10 Jan 2019 23:14:52 +0100
Subject: [R] Reading an excel file
In-Reply-To: <CAP+bYWAUgvuzJhSsjQPikxCvqWrw+3h75L1+9n4=EdQT_nUkXQ@mail.gmail.com>
References: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
 <CAP+bYWAUgvuzJhSsjQPikxCvqWrw+3h75L1+9n4=EdQT_nUkXQ@mail.gmail.com>
Message-ID: <1547158492.2345010.1631345504.26853439@webmail.messagingengine.com>

read.xlsx() works well if the xlsx-file has not too much joined cells. Particularly in the latter case I would recommend to convert the xlsx-file into csv format and then read.csv().

Greetings
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Do, 10. Jan 2019, um 22:43, schrieb Hasan Diwan:
>  https://cran.r-project.org/web/packages/xlsx/xlsx.pdf
> 
> You'll need the JDK (>= 1.6) -- H
> 
> On Thu, 10 Jan 2019 at 13:40, Bernard Comcast <mcgarvey.bernard at comcast.net>
> wrote:
> 
> > What is the best way to read in data of any type from an Excel 2016 .xlsx
> > file?
> >
> > Thanks
> >
> > Bernard
> > Sent from my iPhone so please excuse the spelling!"
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> -- 
> OpenPGP:
> https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> 
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
> from my mobile device
> Envoye de mon portable
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@herry8 @ending from comc@@t@net  Thu Jan 10 23:41:06 2019
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Thu, 10 Jan 2019 17:41:06 -0500
Subject: [R] Reading an excel file
In-Reply-To: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
References: <957B0329-3547-4A47-B27B-2738B8E5CC00@comcast.net>
Message-ID: <5C37CA02.1030707@comcast.net>

The way I have done it in the past is to convert to an CSV file. One 
advantage of this approach is that should my
r script accidental write to the file, my original Excel file is not 
damaged.

Bob Sherry

On 1/10/2019 4:39 PM, Bernard Comcast wrote:
> What is the best way to read in data of any type from an Excel 2016 .xlsx file?
>
> Thanks
>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tonight@thenight @ending from gm@il@com  Fri Jan 11 00:03:03 2019
From: tonight@thenight @ending from gm@il@com (Sam Albers)
Date: Thu, 10 Jan 2019 15:03:03 -0800
Subject: [R] (no subject)
Message-ID: <CADkXsV0+2q5ZCg4vekrSqRGOQsQdaY5bJG0PJt-MJmtBUgOSdA@mail.gmail.com>

Hello all,

I am experience some issues with building a package that we are
hosting on GitHub. The package itself is quite large.  It is a data
package with a bunch of spatial files stored as .rds files.

The repo is located here: https://github.com/bcgov/bcmaps.rdata

If we clone that package to local machine via:
git clone https://github.com/bcgov/bcmaps.rdata

The first oddity is that the package installs successfully using this:

$ R CMD INSTALL "./bcmaps.rdata"

But fails when I try to build the package:

$ R CMD build "./bcmaps.rdata"
* checking for file './bcmaps.rdata/DESCRIPTION' ... OK
* preparing 'bcmaps.rdata':
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files and shell scripts
* checking for empty or unneeded directories
* looking to see if a 'data/datalist' file should be added
Warning in gzfile(file, "rb") :
  cannot open compressed file 'bcmaps.rdata', probable reason
'Permission denied'
Error in gzfile(file, "rb") : cannot open the connection
Execution halted


The second oddity is that if I remove the . from the Package name in
the DESCRIPTION file, the build proceeds smoothly:

$ R CMD build "./bcmaps.rdata"
* checking for file './bcmaps.rdata/DESCRIPTION' ... OK
* preparing 'bcmapsrdata':
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files and shell scripts
* checking for empty or unneeded directories
* looking to see if a 'data/datalist' file should be added
* building 'bcmapsrdata_0.2.0.tar.gz'

I am assuming that R CMD install builds the package internally so I
find it confusing that I am not able to build it myself. Similarly
confusing is the lack of a . in the package name indicative of
anything?

Does anyone have any idea what's going on here? Am I missing something obvious?

Thanks in advance,

Sam


From bgunter@4567 @ending from gm@il@com  Fri Jan 11 00:30:42 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 10 Jan 2019 15:30:42 -0800
Subject: [R] (no subject)
In-Reply-To: <CADkXsV0+2q5ZCg4vekrSqRGOQsQdaY5bJG0PJt-MJmtBUgOSdA@mail.gmail.com>
References: <CADkXsV0+2q5ZCg4vekrSqRGOQsQdaY5bJG0PJt-MJmtBUgOSdA@mail.gmail.com>
Message-ID: <CAGxFJbQm+C_7cf7nPgak+9_OKsatoMdxv9HJOzFM+b+GZUUYmw@mail.gmail.com>

Please post on R-package-devel, not here. That list is specifically devoted
to such issues. This list is about R programming help.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 10, 2019 at 3:06 PM Sam Albers <tonightsthenight at gmail.com>
wrote:

> Hello all,
>
> I am experience some issues with building a package that we are
> hosting on GitHub. The package itself is quite large.  It is a data
> package with a bunch of spatial files stored as .rds files.
>
> The repo is located here: https://github.com/bcgov/bcmaps.rdata
>
> If we clone that package to local machine via:
> git clone https://github.com/bcgov/bcmaps.rdata
>
> The first oddity is that the package installs successfully using this:
>
> $ R CMD INSTALL "./bcmaps.rdata"
>
> But fails when I try to build the package:
>
> $ R CMD build "./bcmaps.rdata"
> * checking for file './bcmaps.rdata/DESCRIPTION' ... OK
> * preparing 'bcmaps.rdata':
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files and shell scripts
> * checking for empty or unneeded directories
> * looking to see if a 'data/datalist' file should be added
> Warning in gzfile(file, "rb") :
>   cannot open compressed file 'bcmaps.rdata', probable reason
> 'Permission denied'
> Error in gzfile(file, "rb") : cannot open the connection
> Execution halted
>
>
> The second oddity is that if I remove the . from the Package name in
> the DESCRIPTION file, the build proceeds smoothly:
>
> $ R CMD build "./bcmaps.rdata"
> * checking for file './bcmaps.rdata/DESCRIPTION' ... OK
> * preparing 'bcmapsrdata':
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files and shell scripts
> * checking for empty or unneeded directories
> * looking to see if a 'data/datalist' file should be added
> * building 'bcmapsrdata_0.2.0.tar.gz'
>
> I am assuming that R CMD install builds the package internally so I
> find it confusing that I am not able to build it myself. Similarly
> confusing is the lack of a . in the package name indicative of
> anything?
>
> Does anyone have any idea what's going on here? Am I missing something
> obvious?
>
> Thanks in advance,
>
> Sam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Fri Jan 11 01:25:30 2019
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 10 Jan 2019 19:25:30 -0500
Subject: [R] User Interfaces for R
In-Reply-To: <20190111002533.5f7dd3eb@Tarkus>
References: <278398401.281602.1547062163024@connect.xfinity.com>
 <20190111002533.5f7dd3eb@Tarkus>
Message-ID: <9dda148a-0a9b-30d8-9895-cb6d75fbfa50@gmail.com>

On 10/01/2019 4:25 p.m., Ivan Krylov wrote:
> On Wed, 9 Jan 2019 14:29:22 -0500 (EST)
> Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:
> 
>> Can anyone point me to such an easy to use package to create GUIs for
>> R?
> 
> If you want a traditional approach, a lot of R installations have
> Tcl/Tk support built in (i.e. capabilities('tcltk') is TRUE). This
> means that you can run library(tcltk) and call Tk functions to display
> interactive windows almost everywhere.
> 
> This toolkit requires some knowledge of Tk [*] and may not look
> particularly nice on some platforms, but is probably already included
> in most R installations and has low resource footprint. There is a set
> of slides [**] that might help you start using Tk, its widgets and
> geometry managers.
> 
> R commander (Rcmdr, [***]) package has been developed using Tk.
> 
> The book Programming Graphical User Interfaces in R by Michael
> Lawrence and John Verzani (ISBN 9781439856826) describes the major R
> packages for GUI programming: RGtk2, qtbase, Tcl/Tk, and gWidgets.
> 

That book was published in 2012, and things have moved on since then. 
Eric's suggestion of Shiny is newer, and is a really well-designed 
system.  A fairly steep learning curve, but worth it.

Duncan Murdoch


From wjh1518 @ending from ht@co@kr  Fri Jan 11 09:13:59 2019
From: wjh1518 @ending from ht@co@kr (=?utf-8?B?7Jqw7KeA7Z2s?=)
Date: Fri, 11 Jan 2019 17:13:59 +0900
Subject: [R] importing data error question
Message-ID: <136d383d-b052-4ab8-a9fb-1172db5c3e64@ht.co.kr>

Hi I'm jihee and I have a question about error... 

I'm using R 3.5.2 and tried to use Rcmdr package. 

and using FactoMineR and SensoMineR to analyze sensory data through PCA 

but i can't import excel data with Rcmdr. 

it has this messege : 

Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :?
 ? [tcl] bad Macintosh file type "?*?" 

what is wrong with my R??? T_T 

Thanks for your help. 

jihee.
	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Fri Jan 11 11:07:51 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 11 Jan 2019 10:07:51 +0000
Subject: [R] importing data error question
In-Reply-To: <136d383d-b052-4ab8-a9fb-1172db5c3e64@ht.co.kr>
References: <136d383d-b052-4ab8-a9fb-1172db5c3e64@ht.co.kr>
Message-ID: <5d151d9b2d21469f85442981a31904aa@SRVEXCHCM1302.precheza.cz>

Hi

I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.

So without some additional info from your side (at least used commands) you hardly get any reasonable answer.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> Sent: Friday, January 11, 2019 9:14 AM
> To: r-help at R-project.org
> Subject: [R] importing data error question
>
> Hi I'm jihee and I have a question about error...
>
> I'm using R 3.5.2 and tried to use Rcmdr package.
>
> and using FactoMineR and SensoMineR to analyze sensory data through PCA
>
> but i can't import excel data with Rcmdr.
>
> it has this messege :
>
> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>    [tcl] bad Macintosh file type "?*?"
>
> what is wrong with my R??? T_T
>
> Thanks for your help.
>
> jihee.
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From krylov@r00t @ending from gm@il@com  Fri Jan 11 11:14:41 2019
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Fri, 11 Jan 2019 13:14:41 +0300
Subject: [R] User Interfaces for R
In-Reply-To: <9dda148a-0a9b-30d8-9895-cb6d75fbfa50@gmail.com>
References: <278398401.281602.1547062163024@connect.xfinity.com>
 <20190111002533.5f7dd3eb@Tarkus>
 <9dda148a-0a9b-30d8-9895-cb6d75fbfa50@gmail.com>
Message-ID: <20190111131441.0602e0ad@trisector>

On Thu, 10 Jan 2019 19:25:30 -0500
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> Eric's suggestion of Shiny is newer, and is a really well-designed 
> system.  A fairly steep learning curve, but worth it.

I understand the need for progress and I really like Shiny's API - it
feels very declarative and easy to write, and I don't care about the
presentation as long as it gets the job done - but all things have
their use cases, which is why I waited a bit before suggesting tcltk
and emphasised its low resource footprint and portability.

For example, an undergraduate student I work with has a laptop with
just 2 gigabytes of RAM. Now, of course there is a lot you can do in R
with that amount of memory - I had to make do with less until late 2016
- but the moment he launches a browser, it pages everything else out.
For him, using Shiny would be extremely slow if not impossible to use.
This is something browsers should be fixing and not the fault of Shiny,
but I can't ignore it either way. (And 2G is not the limit: the renderer
process of browser-based[*] Skype client has somehow managed to
allocate 5G of memory on the machine I'm typing this message on.)

Also, personally, I would prefer not to launch an asynchronous web
server and transfer large files from my computer back to my
computer (but into /tmp)[**] for something as simple as what could be
accomplished with tcltk::tk_choose.files().

But those issues (and things like requiring an Internet connection to
render TeX-style math[***]) aside, Shiny is really a fine and modern
user interface package, and should be preferred if you have the
resources.

Feel free to stop me if you think I'm engaging in off-topic here.

-- 
Best regards,
Ivan

[*] https://electronjs.org/apps/skype: "Electron accomplishes [building
cross-platform desktop applications with HTML, CSS, and JavaScript]
by combining Chromium and Node.js into a single runtime"

[**] https://shiny.rstudio.com/reference/shiny/latest/fileInput.html:
"The path to a temp file that contains the data that was uploaded."

[***] https://rdrr.io/cran/shiny/src/R/shinyui.R#sym-withMathJax: does
MathJax license require referencing https://mathjax.rstudio.com instead
of bundling it together with Shiny, like the rest of JavaScript
libraries are?


From jfox @ending from mcm@@ter@c@  Fri Jan 11 14:48:38 2019
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 11 Jan 2019 13:48:38 +0000
Subject: [R] importing data error question
In-Reply-To: <11813_1547201321_x0BA8ed5027678_5d151d9b2d21469f85442981a31904aa@SRVEXCHCM1302.precheza.cz>
References: <136d383d-b052-4ab8-a9fb-1172db5c3e64@ht.co.kr>
 <11813_1547201321_x0BA8ed5027678_5d151d9b2d21469f85442981a31904aa@SRVEXCHCM1302.precheza.cz>
Message-ID: <83815BA1-D8B8-4000-AA23-6708DF99AB14@mcmaster.ca>

Dear Petr and jihee,

The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 

So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?

Best,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> 
> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
>> Sent: Friday, January 11, 2019 9:14 AM
>> To: r-help at R-project.org
>> Subject: [R] importing data error question
>> 
>> Hi I'm jihee and I have a question about error...
>> 
>> I'm using R 3.5.2 and tried to use Rcmdr package.
>> 
>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
>> 
>> but i can't import excel data with Rcmdr.
>> 
>> it has this messege :
>> 
>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>   [tcl] bad Macintosh file type "?*?"
>> 
>> what is wrong with my R??? T_T
>> 
>> Thanks for your help.
>> 
>> jihee.
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From meri@m@nef @ending from gm@il@com  Thu Jan 10 21:34:22 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Thu, 10 Jan 2019 14:34:22 -0600
Subject: [R] Overlapping legend in a circular dendrogram
Message-ID: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>

Dear all,

I run the following code and I get this graphic (Imageattached). What
should I change in my code in order to adjust the overlapping objects?

load("hc1.rda")
library(cluster)
library(ape)
library(dendextend)
library(circlize)
library(RColorBrewer)

labels = hc1$labels
n = length(labels)
dend = as.dendrogram(hc1)
markcountry=as.data.frame(markcountry1)
#Country colors
groupCodes=as.character(as.factor(markcountry[,2]))
colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
names(colorCodes)=unique(groupCodes)
labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]

#Region colors
groupCodesR=as.character(as.factor(markcountry[,3]))
colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
names(colorCodesR)=unique(groupCodesR)

circos.par(cell.padding = c(0, 0, 0, 0))
circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
max_height = attr(dend, "height")  # maximum height of the trees

#Region graphics
circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
  circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
}, bg.border = NA)

#labels graphics
circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
                       panel.fun = function(x, y) {

                           circos.text(1:361-0.5,
rep(0.5,361),labels(dend), adj = c(0, 0.5),
                                       facing = "clockwise", niceFacing =
TRUE,
                                       col = labels_colors(dend), cex =
0.45)

                       })
dend = color_branches(dend, k = 6, col = 1:6)

#Dendrogram graphics
circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
                       track.height = 0.4, panel.fun = function(x, y) {
                         circos.dendrogram(dend, max_height = 0.55)
                       })
legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)

Thanks,
Meriam

From gregd @ending from gn@@pc@org  Fri Jan 11 12:56:21 2019
From: gregd @ending from gn@@pc@org (Greg Dropkin)
Date: Fri, 11 Jan 2019 11:56:21 -0000 (GMT)
Subject: [R] bsts posterior distributions
Message-ID: <47437.10.254.253.3.1547207781.squirrel@sqmail.gn.apc.org>

hello

I couldn't find previous posts to answer this, but please point me to any.

I am trying to understand bsts, starting with no regressors

Here is code which appears to mimic bsts, producing graphs similar to the
model plot, but gives a rather different posterior distribution for the
parameters. I may misunderstand SdPrior, or perhaps the differences are
with mcmc.

Thanks for any help

Greg

###

library(bsts)
library(Boom)
library(mcmc)

#simulate some data

y<-rep(NA,50)

y[1]=1
y[2]=1
s=2
set.seed(5)
for (k in 1:48)
{
y[2+k]=y[1+k]+0.1*y[k]+s*rnorm(1)
}
plot(1:50,y[1:50],main=paste("seed =",j))

#bsts model

ss<-AddLocalLevel(list(),y)
mod1<-bsts(y,state.specification=ss,niter=1000)
plot(mod1)

#reproduce the plot using mod1$state.contributions

par(mfrow=c(1,2))
plot(1:50,y,col="blue",ylim=c(-12,8),main="quantiles of
mod1$state.contributions")
for (i in 1:99)
{
qi<-qin<-rep(NA,50)
tj<-1:50
for (j in 1:50)
{
qi[j]<-quantile(mod1$state.con[501:1000,1,j],(i-0.5)/100)
qin[j]<-quantile(mod1$state.con[501:1000,1,j],(i+1-0.5)/100)
}
polygon(c(tj,rev(tj)),c(qi[1:50],rev(qin[1:50])),col=rgb(0,0,0,45*dnorm(i,mean=50,sd=18)),border=FALSE)
}
plot(mod1,ylim=c(-12,8),main="plot(mod1)")
par(mfrow=c(1,1))

#the state specification is based on sd(y)

sd(y)
ss

#the likelihood, using the kalman filter, as a function of the error sd's

kal<-function(par)
{
a<-par[1]
b<-par[2]

H=matrix(1,1,1)
F=matrix(1,1,1)
#1-dimensional state
N=50
dim(y)=c(1,N)

xe<-ye<-ze<-matrix(NA,1,N)
w<-rnorm(1)
xe[,1]<-1
ye[,1]<-H%*%xe[,1]
ze[,1]<-y[,1]-ye[,1]

P<-K<-array(data=NA,dim=c(N,1,1))
#P[1,,] initial guess
P[1,,]<-1
K[1,,]<-1
xe[1,1]<-1

for (i in 1:(N-1))
{
P[i+1,,]<-F%*%P[i,,]%*%t(F)+a^2
K[i+1,,]<-P[i+1,,]%*%t(H)%*%solve(b^2+H%*%P[i+1,,]%*%t(H))
xe[1,i+1]<-F%*%xe[,i]+K[i+1,,]%*%(y[,i+1]-H%*%F%*%xe[,i])
P[i+1,,]<-(diag(1,1)-K[i+1,,]%*%H)%*%P[i+1,,]
}

-1/2*log(b^2)-1/2*sum(((y[1,]-xe[1,])/b)^2)
}

#independent priors on a and b
#bsts uses sd(y) to set both priors.
#for a (ss[[1]]$sigma.prior) it uses SdPrior with
#$prior.guess 0.04600655, $prior.df 0.01, $initial.value 0.04600655,
$upper.limit 4.600655
#for b (mod1$prior) it uses SdPrior with
#$prior.guess 4.600655, $prior.df 0.01, $initial.value 4.600655,
$upper.limit 5.520786

#try an inverse gamma prior (on a^2, then converted to a prior on a)

lpr1<-function(a)
{
v=0.01
ifelse((a<=0)|a>sd(y),-Inf,-(v/2+1)*log(a^2)-v*(sd(y)/100)^2/(2*a^2)+1/2*log(a^2))
}

lpr2<-function(b)
{
v=0.01
ifelse((b<=0)|b>1.2*sd(y),-Inf,-(v/2+1)*log(b^2)-v*(sd(y))^2/(2*b^2)+1/2*log(b^2))
}

lpost1<-function(par)
{
a<-par[1]
b<-par[2]
lpr1(a)+lpr2(b)+kal(par)
}

nlpost1<-function(par) -lpost1(par)

pop<-optim(c(2,1),nlpost1)
pop<-optim(pop$par,nlpost1,hessian=T)
pop

lpost1m<-function(par) lpost1(par+pop$par)
nlpost1m<-function(par) -lpost1m(par)
pop1m<-optim(c(0,0),nlpost1m)
pop1m<-optim(pop1m$par,nlpost1m,hessian=T)
pop1m

sc<-chol(pop1m$hess)
sd<-diag(sc)
nb=5000
#with batches, spacing, ~5 min run
outm<-metrop(lpost1m,1e-2*sd,nb,blen=5,nspac=5)
samm<-outm$batch
dim(samm)
acf(samm)
samm<-thin(samm,5)
dim(samm)
acf(samm)
par(mfrow=c(2,1))
plot(samm[501:1000,1],type="l")
plot(samm[501:1000,2],type="l")
par(mfrow=c(1,1))

#plot kalman using samm from lpost1m

ax<-samm[501:1000,1]+pop$par[1]
bx<-samm[501:1000,2]+pop$par[2]

state<-matrix(NA,500,50)

for (j in 1:500)
{
a<-ax[j]
b<-bx[j]

H=matrix(1,1,1)
F=matrix(1,1,1)
N=50
dim(y)=c(1,N)

xe<-ye<-ze<-matrix(NA,1,N)
xe[,1]<-1
ye[,1]<-H%*%xe[,1]
ze[,1]<-y[,1]-ye[,1]

P<-K<-array(data=NA,dim=c(N,1,1))
P[1,,]<-0
for (i in 1:(N-1))
{
P[i+1,,]<-F%*%P[i,,]%*%t(F)+a^2
K[i+1,,]<-P[i+1,,]%*%t(H)%*%solve(b^2+H%*%P[i+1,,]%*%t(H))
P[i+1,,]<-(diag(1,1)-K[i+1,,]%*%H)%*%P[i+1,,]
xe[1,i+1]<-F%*%xe[,i]+K[i+1,,]%*%(y[,i+1]-H%*%F%*%xe[,i])
}

P[1,,]<-P[2,,]
state[j,]<-rnorm(N,xe[1,1:N],P[1:N,,]^0.5)
}

par(mfrow=c(1,2))
plot(1:N,y,col="blue",ylim=c(-12,8))
for (i in 1:99)
{
qi<-qin<-rep(NA,N)
tj<-1:N
for (k in 1:N)
{
qi[k]<-quantile(state[,k],(i-0.5)/100)
qin[k]<-quantile(state[,k],(i+1-0.5)/100)
}
polygon(c(tj,rev(tj)),c(qi[1:N],rev(qin[1:N])),col=rgb(0,0,0,45*dnorm(i,mean=50,sd=18)),border=FALSE)
}
plot(mod1,ylim=c(-12,8))
par(mfrow=c(1,1))

#very plausible, but

mean(ax)
mean(mod1$sigma.level[501:1000])

mean(bx)
mean(mod1$sigma.obs[501:1000])

par(mfrow=c(1,2))
qqplot(ax,mod1$sigma.level[501:1000])
lines(ax,ax,col="red")
qqplot(bx,mod1$sigma.obs[501:1000])
lines(bx,bx,col="red")
par(mfrow=c(1,1))

#ax not sampling sigma.level
#bx not quite sampling sigma.obs


From meri@m@nef @ending from gm@il@com  Fri Jan 11 16:08:31 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Fri, 11 Jan 2019 09:08:31 -0600
Subject: [R] Fwd:  Overlapping legend in a circular dendrogram
In-Reply-To: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
References: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
Message-ID: <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>

Dear all,

I run the following code and I get this graphic (pdf attached). What should
I change in my code in order to adjust the overlapping objects?

load("hc1.rda")
library(cluster)
library(ape)
library(dendextend)
library(circlize)
library(RColorBrewer)

labels = hc1$labels
n = length(labels)
dend = as.dendrogram(hc1)
markcountry=as.data.frame(markcountry1)
#Country colors
groupCodes=as.character(as.factor(markcountry[,2]))
colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
names(colorCodes)=unique(groupCodes)
labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]

#Region colors
groupCodesR=as.character(as.factor(markcountry[,3]))
colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
names(colorCodesR)=unique(groupCodesR)

circos.par(cell.padding = c(0, 0, 0, 0))
circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
max_height = attr(dend, "height")  # maximum height of the trees

#Region graphics
circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
  circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
}, bg.border = NA)

#labels graphics
circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
                       panel.fun = function(x, y) {

                           circos.text(1:361-0.5,
rep(0.5,361),labels(dend), adj = c(0, 0.5),
                                       facing = "clockwise", niceFacing =
TRUE,
                                       col = labels_colors(dend), cex =
0.45)

                       })
dend = color_branches(dend, k = 6, col = 1:6)

#Dendrogram graphics
circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
                       track.height = 0.4, panel.fun = function(x, y) {
                         circos.dendrogram(dend, max_height = 0.55)
                       })
legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)

Thanks,
Meriam

-------------- next part --------------
A non-text attachment was scrubbed...
Name: dendro.pdf
Type: application/pdf
Size: 124582 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190111/c2c2e8ea/attachment.pdf>

From @iegfried@koe@tlmeier @ending from gm@il@com  Fri Jan 11 15:25:31 2019
From: @iegfried@koe@tlmeier @ending from gm@il@com (=?UTF-8?Q?Siegfried_K=c3=b6stlmeier?=)
Date: Fri, 11 Jan 2019 15:25:31 +0100
Subject: [R] [R-pkgs] New package qrandom: True random numbers
Message-ID: <bb46e0cb-9326-f7de-c118-043d18b543b8@gmail.com>

Hi everyone,
I would like to introduce a new package for R which is available on CRAN
now:

qrandom: True Random Numbers using the ANU Quantum Random Numbers Server

Note:
(1) This package generates true random numbers and can be used as an
alternative for RANDOM.ORG.
(2) There is absolutely no limit on how many true random numbers one may
retrieve.
(3) A sequence up to 100,000 true random integers or hexadecimal numbers
per single request is possible and data is whether a sequence, uniform
distribution or normal distribution.

Description:
It provides an interface to the ANU Quantum Random Number Generator
<https://qrng.anu.edu.au/index.php> provided by the Australian National
University. True random numbers are generated in real-time by measuring
the quantum fluctuations of the vacuum. The electromagnetic field of the
vacuum exhibits random fluctuations in phase and amplitude at all
frequencies. By carefully measuring these fluctuations, one is able to
generate ultra-high bandwidth random numbers. The quantum Random Number
Generator is based on the papers by Symul et al., (2011)
<https://doi.org/10.1063/1.3597793> and Haw, et al. (2015)
<https://doi.org/10.1103/PhysRevApplied.3.054004>. The package offers
functions to retrieve a sequence of random integers or hexadecimals and
true random samples from a normal or uniform distribution.

The R package is available via
https://cran.r-project.org/web/packages/qrandom/index.html
If you like to access the developmental version:
https://github.com/skoestlmeier/qrandom

Best regards,
Siegfried K?stlmeier (Ph.D. student in Finance at the University of
Regensburg)

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From mcg@rvey@bern@rd @ending from comc@@t@net  Fri Jan 11 19:40:44 2019
From: mcg@rvey@bern@rd @ending from comc@@t@net (Bernard McGarvey)
Date: Fri, 11 Jan 2019 13:40:44 -0500 (EST)
Subject: [R] loading the xlsx library
Message-ID: <1661340430.327833.1547232045654@connect.xfinity.com>

When I load the library xlsx with the command


library("xlsx")


I get the error message:


> library("xlsx")
Error: package or namespace load failed for ?xlsx?:
.onLoad failed in loadNamespace() for 'rJava', details:
call: fun(libname, pkgname)
error: JAVA_HOME cannot be determined from the Registry
>


Does anyone have any idea what the issue is?


Thanks


Lion Bernard McGarvey

Director, Fort Myers Beach Lions Foundation, Inc.

Retired (Lilly Engineering Fellow).



	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jan 11 21:37:18 2019
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 11 Jan 2019 12:37:18 -0800
Subject: [R] loading the xlsx library
In-Reply-To: <1661340430.327833.1547232045654@connect.xfinity.com>
References: <1661340430.327833.1547232045654@connect.xfinity.com>
Message-ID: <17AC247F-108D-4A56-9178-DB41CA66A3EA@dcn.davis.ca.us>

Failure to read the installation notes for the package. You have to get Java working on your computer.

https://cran.r-project.org/web/packages/xlsx/index.html

On January 11, 2019 10:40:44 AM PST, Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:
>When I load the library xlsx with the command
>
>
>library("xlsx")
>
>
>I get the error message:
>
>
>> library("xlsx")
>Error: package or namespace load failed for ?xlsx?:
>.onLoad failed in loadNamespace() for 'rJava', details:
>call: fun(libname, pkgname)
>error: JAVA_HOME cannot be determined from the Registry
>>
>
>
>Does anyone have any idea what the issue is?
>
>
>Thanks
>
>
>Lion Bernard McGarvey
>
>Director, Fort Myers Beach Lions Foundation, Inc.
>
>Retired (Lilly Engineering Fellow).
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From meri@m@nef @ending from gm@il@com  Fri Jan 11 21:38:37 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Fri, 11 Jan 2019 14:38:37 -0600
Subject: [R] Fwd:  Overlapping legend in a circular dendrogram
In-Reply-To: <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
References: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
 <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
Message-ID: <CAL1He1JpiTCw0YxkY0h1BGOtCHdO9KE9K0s5fZ=LoL4fWMad5w@mail.gmail.com>

Hi, I'm facing some issues when generationg a circular dendrogram.
The labels on the left which are my countries are overlapping with the
circular dendrogram (middle). Same happens with the labels (regions)
located on the right.
I run the following code and I'd like to know what should be changed
in my code in order to avoid that.

load("hc1.rda")
library(cluster)
library(ape)
library(dendextend)
library(circlize)
library(RColorBrewer)

labels = hc1$labels
n = length(labels)
dend = as.dendrogram(hc1)
markcountry=as.data.frame(markcountry1)
#Country colors
groupCodes=as.character(as.factor(markcountry[,2]))
colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
names(colorCodes)=unique(groupCodes)
labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]

#Region colors
groupCodesR=as.character(as.factor(markcountry[,3]))
colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
names(colorCodesR)=unique(groupCodesR)

circos.par(cell.padding = c(0, 0, 0, 0))
circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
max_height = attr(dend, "height")  # maximum height of the trees

#Region graphics
circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
  circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
}, bg.border = NA)

#labels graphics
circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
                       panel.fun = function(x, y) {

                           circos.text(1:361-0.5,
rep(0.5,361),labels(dend), adj = c(0, 0.5),
                                       facing = "clockwise", niceFacing = TRUE,
                                       col = labels_colors(dend), cex = 0.45)

                       })
dend = color_branches(dend, k = 6, col = 1:6)

#Dendrogram graphics
circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
                       track.height = 0.4, panel.fun = function(x, y) {
                         circos.dendrogram(dend, max_height = 0.55)
                       })
legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)

Cheers,
Myriam


From bgunter@4567 @ending from gm@il@com  Fri Jan 11 22:03:46 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 11 Jan 2019 13:03:46 -0800
Subject: [R] Fwd: Overlapping legend in a circular dendrogram
In-Reply-To: <CAL1He1JpiTCw0YxkY0h1BGOtCHdO9KE9K0s5fZ=LoL4fWMad5w@mail.gmail.com>
References: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
 <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
 <CAL1He1JpiTCw0YxkY0h1BGOtCHdO9KE9K0s5fZ=LoL4fWMad5w@mail.gmail.com>
Message-ID: <CAGxFJbTfa4H99TaUXZ=ei0wCZYuns1R0pbWWmsZLPwOZY+dJQQ@mail.gmail.com>

This is the 3rd time you've posted this. Please stop re-posting!

Your question is specialized and involved, and you have failed to provide a
reproducible example/data. We are not obliged to respond.

You may do better contacting the maintainer, found by ?maintainer, as
recommended by the posting guide for specialized queries such as this.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 11, 2019 at 12:47 PM N Meriam <meriam.nef at gmail.com> wrote:

> Hi, I'm facing some issues when generationg a circular dendrogram.
> The labels on the left which are my countries are overlapping with the
> circular dendrogram (middle). Same happens with the labels (regions)
> located on the right.
> I run the following code and I'd like to know what should be changed
> in my code in order to avoid that.
>
> load("hc1.rda")
> library(cluster)
> library(ape)
> library(dendextend)
> library(circlize)
> library(RColorBrewer)
>
> labels = hc1$labels
> n = length(labels)
> dend = as.dendrogram(hc1)
> markcountry=as.data.frame(markcountry1)
> #Country colors
> groupCodes=as.character(as.factor(markcountry[,2]))
> colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
> names(colorCodes)=unique(groupCodes)
> labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]
>
> #Region colors
> groupCodesR=as.character(as.factor(markcountry[,3]))
> colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
> names(colorCodesR)=unique(groupCodesR)
>
> circos.par(cell.padding = c(0, 0, 0, 0))
> circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
> max_height = attr(dend, "height")  # maximum height of the trees
>
> #Region graphics
> circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
>   circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
> colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
> }, bg.border = NA)
>
> #labels graphics
> circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
>                        panel.fun = function(x, y) {
>
>                            circos.text(1:361-0.5,
> rep(0.5,361),labels(dend), adj = c(0, 0.5),
>                                        facing = "clockwise", niceFacing =
> TRUE,
>                                        col = labels_colors(dend), cex =
> 0.45)
>
>                        })
> dend = color_branches(dend, k = 6, col = 1:6)
>
> #Dendrogram graphics
> circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
>                        track.height = 0.4, panel.fun = function(x, y) {
>                          circos.dendrogram(dend, max_height = 0.55)
>                        })
>
> legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
>
> legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)
>
> Cheers,
> Myriam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From meri@m@nef @ending from gm@il@com  Fri Jan 11 22:10:39 2019
From: meri@m@nef @ending from gm@il@com (N Meriam)
Date: Fri, 11 Jan 2019 15:10:39 -0600
Subject: [R] Fwd: Overlapping legend in a circular dendrogram
In-Reply-To: <CAGxFJbTfa4H99TaUXZ=ei0wCZYuns1R0pbWWmsZLPwOZY+dJQQ@mail.gmail.com>
References: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
 <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
 <CAL1He1JpiTCw0YxkY0h1BGOtCHdO9KE9K0s5fZ=LoL4fWMad5w@mail.gmail.com>
 <CAGxFJbTfa4H99TaUXZ=ei0wCZYuns1R0pbWWmsZLPwOZY+dJQQ@mail.gmail.com>
Message-ID: <CAL1He1+uHDdHNmnNDUKA6bVgTu4N=ESD=XpgLPHPChW3PR9iug@mail.gmail.com>

Yes I know. Sorry if I reposted this but it's simply because I've
received an email mentioning that the file was too big that's why I
modified my question and reposted it.
I don't want to oblige anyone to respond. I really thought the issue
was my file (too big so nobody received it).

Thanks for your understanding,
Best Myriam

On Fri, Jan 11, 2019 at 3:03 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> This is the 3rd time you've posted this. Please stop re-posting!
>
> Your question is specialized and involved, and you have failed to provide a reproducible example/data. We are not obliged to respond.
>
> You may do better contacting the maintainer, found by ?maintainer, as recommended by the posting guide for specialized queries such as this.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jan 11, 2019 at 12:47 PM N Meriam <meriam.nef at gmail.com> wrote:
>>
>> Hi, I'm facing some issues when generationg a circular dendrogram.
>> The labels on the left which are my countries are overlapping with the
>> circular dendrogram (middle). Same happens with the labels (regions)
>> located on the right.
>> I run the following code and I'd like to know what should be changed
>> in my code in order to avoid that.
>>
>> load("hc1.rda")
>> library(cluster)
>> library(ape)
>> library(dendextend)
>> library(circlize)
>> library(RColorBrewer)
>>
>> labels = hc1$labels
>> n = length(labels)
>> dend = as.dendrogram(hc1)
>> markcountry=as.data.frame(markcountry1)
>> #Country colors
>> groupCodes=as.character(as.factor(markcountry[,2]))
>> colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
>> names(colorCodes)=unique(groupCodes)
>> labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]
>>
>> #Region colors
>> groupCodesR=as.character(as.factor(markcountry[,3]))
>> colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
>> names(colorCodesR)=unique(groupCodesR)
>>
>> circos.par(cell.padding = c(0, 0, 0, 0))
>> circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
>> max_height = attr(dend, "height")  # maximum height of the trees
>>
>> #Region graphics
>> circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
>>   circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
>> colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
>> }, bg.border = NA)
>>
>> #labels graphics
>> circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
>>                        panel.fun = function(x, y) {
>>
>>                            circos.text(1:361-0.5,
>> rep(0.5,361),labels(dend), adj = c(0, 0.5),
>>                                        facing = "clockwise", niceFacing = TRUE,
>>                                        col = labels_colors(dend), cex = 0.45)
>>
>>                        })
>> dend = color_branches(dend, k = 6, col = 1:6)
>>
>> #Dendrogram graphics
>> circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
>>                        track.height = 0.4, panel.fun = function(x, y) {
>>                          circos.dendrogram(dend, max_height = 0.55)
>>                        })
>> legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
>> legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)
>>
>> Cheers,
>> Myriam
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil


From ruipb@rr@d@@ @ending from @@po@pt  Fri Jan 11 22:33:07 2019
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 11 Jan 2019 21:33:07 +0000
Subject: [R] loading the xlsx library
In-Reply-To: <17AC247F-108D-4A56-9178-DB41CA66A3EA@dcn.davis.ca.us>
References: <1661340430.327833.1547232045654@connect.xfinity.com>
 <17AC247F-108D-4A56-9178-DB41CA66A3EA@dcn.davis.ca.us>
Message-ID: <c8d9e037-24ae-6406-e942-2098e13216a1@sapo.pt>

Hello,

Also, sometimes it's about R/Java versions. If you have Java 32 bits you 
need R 32 bits. And the same for 64b.

Hope this helps,

Rui Barradas

?s 20:37 de 11/01/2019, Jeff Newmiller escreveu:
> Failure to read the installation notes for the package. You have to get Java working on your computer.
> 
> https://cran.r-project.org/web/packages/xlsx/index.html
> 
> On January 11, 2019 10:40:44 AM PST, Bernard McGarvey <mcgarvey.bernard at comcast.net> wrote:
>> When I load the library xlsx with the command
>>
>>
>> library("xlsx")
>>
>>
>> I get the error message:
>>
>>
>>> library("xlsx")
>> Error: package or namespace load failed for ?xlsx?:
>> .onLoad failed in loadNamespace() for 'rJava', details:
>> call: fun(libname, pkgname)
>> error: JAVA_HOME cannot be determined from the Registry
>>>
>>
>>
>> Does anyone have any idea what the issue is?
>>
>>
>> Thanks
>>
>>
>> Lion Bernard McGarvey
>>
>> Director, Fort Myers Beach Lions Foundation, Inc.
>>
>> Retired (Lilly Engineering Fellow).
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jo@ecl@udio@f@ri@ @ending from gm@il@com  Sat Jan 12 02:37:38 2019
From: jo@ecl@udio@f@ri@ @ending from gm@il@com (Jose Claudio Faria)
Date: Fri, 11 Jan 2019 22:37:38 -0300
Subject: [R] Tinn-R: new web site
Message-ID: <CAN+Emd91q4-KKMyYsmPAh6eVTg3_rzZ03eKSKzaWaK_YKq7f5A@mail.gmail.com>

Dears,

The Tinn-R project has a new web page:
http://nbcgib.uesc.br/tinnr/en/index.php

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Sat Jan 12 03:49:29 2019
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sat, 12 Jan 2019 13:49:29 +1100
Subject: [R] Fwd: Overlapping legend in a circular dendrogram
In-Reply-To: <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
References: <CAL1He1KLnsF+BmyLwf+cqpkbiPgcQv8ELCpqvvHTbmzB3Ptunw@mail.gmail.com>
 <CAL1He1LVhXyxXEbX6OWrVz84FtjDFnCfr6ooXcRRZwfPkhrRbA@mail.gmail.com>
Message-ID: <CA+8X3fWdJPyiBtc83+gqWscOA-rXD-itsJGO=2eCecVmnKSu0g@mail.gmail.com>

Hi Meriam,
I don't have the packages loaded that you use, but a first guess would
be to start a wider device. For example, the default x11 device is
7x7, so:

x11(width=10)

would give you a rectangular output device that might move the columns
of labels outward. The same applies for any other device, just
explicitly open the wider device before you run your code.

Jim

On Sat, Jan 12, 2019 at 3:29 AM N Meriam <meriam.nef at gmail.com> wrote:
>
> Dear all,
>
> I run the following code and I get this graphic (pdf attached). What should
> I change in my code in order to adjust the overlapping objects?
>
> load("hc1.rda")
> library(cluster)
> library(ape)
> library(dendextend)
> library(circlize)
> library(RColorBrewer)
>
> labels = hc1$labels
> n = length(labels)
> dend = as.dendrogram(hc1)
> markcountry=as.data.frame(markcountry1)
> #Country colors
> groupCodes=as.character(as.factor(markcountry[,2]))
> colorCodes=rainbow(length(unique(groupCodes))) #c("blue","red")
> names(colorCodes)=unique(groupCodes)
> labels_colors(dend) <- colorCodes[groupCodes][order.dendrogram(dend)]
>
> #Region colors
> groupCodesR=as.character(as.factor(markcountry[,3]))
> colorCodesR=rainbow(length(unique(groupCodesR))) #c("blue","red")
> names(colorCodesR)=unique(groupCodesR)
>
> circos.par(cell.padding = c(0, 0, 0, 0))
> circos.initialize(factors = "foo", xlim = c(1, n)) # only one sector
> max_height = attr(dend, "height")  # maximum height of the trees
>
> #Region graphics
> circos.trackPlotRegion(ylim = c(0, 1.5), panel.fun = function(x, y) {
>   circos.rect(1:361-0.5, rep(0.5, 361), 1:361-0.1, rep(0.8,361), col =
> colorCodesR[groupCodesR][order.dendrogram(dend)], border = NA)
> }, bg.border = NA)
>
> #labels graphics
> circos.trackPlotRegion(ylim = c(0, 0.5), bg.border = NA,
>                        panel.fun = function(x, y) {
>
>                            circos.text(1:361-0.5,
> rep(0.5,361),labels(dend), adj = c(0, 0.5),
>                                        facing = "clockwise", niceFacing =
> TRUE,
>                                        col = labels_colors(dend), cex =
> 0.45)
>
>                        })
> dend = color_branches(dend, k = 6, col = 1:6)
>
> #Dendrogram graphics
> circos.trackPlotRegion(ylim = c(0, max_height), bg.border = NA,
>                        track.height = 0.4, panel.fun = function(x, y) {
>                          circos.dendrogram(dend, max_height = 0.55)
>                        })
> legend("left",names(colorCodes),col=colorCodes,text.col=colorCodes,bty="n",pch=15,cex=0.8)
> legend("right",names(colorCodesR),col=colorCodesR,text.col=colorCodesR,bty="n",pch=15,cex=0.35)
>
> Thanks,
> Meriam
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@iliP@dpo@t @ending from gm@il@com  Sat Jan 12 10:18:13 2019
From: m@iliP@dpo@t @ending from gm@il@com (Medic)
Date: Sat, 12 Jan 2019 12:18:13 +0300
Subject: [R] SURVDIFF()
Message-ID: <CAH6117K2NOGdb9DFuJ_6q51Z54998ZkAzYZg8F5TV5Lur5fWQw@mail.gmail.com>

How to note (in code) a few (!) adjusting covariates for cox
regression. I had an example for one covariate, and tried (according
to my own understanding) two variantes of code  (pls, see below), and
got ... a different p-value. What is the right code? Many thanks!!!

(1)
survdiff (Surv(survt,status)~clinic+strata(prison, dose, gender),data=addicts)
N Observed Expected (O-E)^2/E (O-E)^2/V
clinic=1 163      122    106.2      2.35        14
clinic=2  75       28     43.8      5.70        14
Chisq= 14  on 1 degrees of freedom, p= 2e-04

(2)
survdiff (Surv(survt,status)~clinic+strata(prison+dose+gender),data=addicts)
N Observed Expected (O-E)^2/E (O-E)^2/V
clinic=1 163      122    106.2      2.35      12.1
clinic=2  75       28     43.8      5.69      12.1
Chisq= 12.1  on 1 degrees of freedom, p= 5e-04


From erne@t@hec @ending from gm@il@com  Sat Jan 12 09:23:25 2019
From: erne@t@hec @ending from gm@il@com (Ernest Han)
Date: Sat, 12 Jan 2019 16:23:25 +0800
Subject: [R] NA rows appeared in data.frame
Message-ID: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>

Dear All,

After replacing some values in a data.frame, NAs rows have appeared
and cannot be removed. I have googled these issues and found that
several people have encountered it. Solutions in stackoverflow seem to
provide work-arounds but does not remove it from the data.frame.
Therefore, I am turning to experts in this community for help.

The code is as follows,

> t1 <- iris
> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA
> t1[t1$Petal.Width == 2.0, ]
      Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
NA              NA          NA           NA          NA      <NA>
NA.1            NA          NA           NA          NA      <NA>
NA.2            NA          NA           NA          NA      <NA>
NA.3            NA          NA           NA          NA      <NA>
111            6.5         3.2          5.1           2 virginica
114            5.7         2.5          5.0           2 virginica
NA.4            NA          NA           NA          NA      <NA>
122            5.6         2.8          4.9           2 virginica
123            7.7         2.8          6.7           2 virginica
NA.5            NA          NA           NA          NA      <NA>
NA.6            NA          NA           NA          NA      <NA>
NA.7            NA          NA           NA          NA      <NA>
NA.8            NA          NA           NA          NA      <NA>
132            7.9         3.8          6.4           2 virginica
NA.9            NA          NA           NA          NA      <NA>
NA.10           NA          NA           NA          NA      <NA>
148            6.5         3.0          5.2           2 virginica
NA.11           NA          NA           NA          NA      <NA>

## Twelve values were replaced, twelve NA rows appeared.

### MISC INFO ###
> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-apple-darwin16.5.0 (64-bit)
Running under: macOS  10.14.2

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0
> Sys.getlocale()
[1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"


Thank you,
Ernest


From ruipb@rr@d@@ @ending from @@po@pt  Sat Jan 12 12:54:51 2019
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 12 Jan 2019 11:54:51 +0000
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
Message-ID: <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>

Hello,

You have to test for NA. Some (12) of the values of t1$Petal.Width are 
NA therefore t1$Petal.Width == 2.0 alone returns 12 NA values.

t1[t1$Petal.Width == 2.0 & !is.na(t1$Petal.Width == 2.0), ]

Or use which(t1$Petal.Width == 2.0).

t1[which(t1$Petal.Width == 2.0), ]


Hope this helps,

Rui Barradas

?s 08:23 de 12/01/2019, Ernest Han escreveu:
> Dear All,
> 
> After replacing some values in a data.frame, NAs rows have appeared
> and cannot be removed. I have googled these issues and found that
> several people have encountered it. Solutions in stackoverflow seem to
> provide work-arounds but does not remove it from the data.frame.
> Therefore, I am turning to experts in this community for help.
> 
> The code is as follows,
> 
>> t1 <- iris
>> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA
>> t1[t1$Petal.Width == 2.0, ]
>        Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> NA              NA          NA           NA          NA      <NA>
> NA.1            NA          NA           NA          NA      <NA>
> NA.2            NA          NA           NA          NA      <NA>
> NA.3            NA          NA           NA          NA      <NA>
> 111            6.5         3.2          5.1           2 virginica
> 114            5.7         2.5          5.0           2 virginica
> NA.4            NA          NA           NA          NA      <NA>
> 122            5.6         2.8          4.9           2 virginica
> 123            7.7         2.8          6.7           2 virginica
> NA.5            NA          NA           NA          NA      <NA>
> NA.6            NA          NA           NA          NA      <NA>
> NA.7            NA          NA           NA          NA      <NA>
> NA.8            NA          NA           NA          NA      <NA>
> 132            7.9         3.8          6.4           2 virginica
> NA.9            NA          NA           NA          NA      <NA>
> NA.10           NA          NA           NA          NA      <NA>
> 148            6.5         3.0          5.2           2 virginica
> NA.11           NA          NA           NA          NA      <NA>
> 
> ## Twelve values were replaced, twelve NA rows appeared.
> 
> ### MISC INFO ###
>> sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-apple-darwin16.5.0 (64-bit)
> Running under: macOS  10.14.2
> 
> Matrix products: default
> BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0 tools_3.4.0
>> Sys.getlocale()
> [1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"
> 
> 
> Thank you,
> Ernest
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From v@rin@@ch@ @ending from y@hoo@fr  Sat Jan 12 14:36:47 2019
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Sat, 12 Jan 2019 13:36:47 +0000 (UTC)
Subject: [R] mgcv : 3-way interaction and 3D-plots ?
In-Reply-To: <CAGx1TMC8z1xE0n0qXXG-+o4zgO4RnTWv5+1h5MTVrdOXdfGXJQ@mail.gmail.com>
References: <1762425263.20633289.1546904142187.ref@mail.yahoo.com>
 <1762425263.20633289.1546904142187@mail.yahoo.com>
 <db4db4b4-82ab-1976-908d-618df3957cc8@comcast.net>
 <CAGx1TMC8z1xE0n0qXXG-+o4zgO4RnTWv5+1h5MTVrdOXdfGXJQ@mail.gmail.com>
Message-ID: <1994453517.27173093.1547300207819@mail.yahoo.com>

David, Richard,

Many thanks for your responses.




Le mardi 8 janvier 2019 ? 04:25:19 UTC+1, Richard M. Heiberger <rmh at temple.edu> a ?crit : 





## Here is an example using the 3-way interaction plot from the HH package


install.packages("HH") ## if necessary

## The HH package supports the book
## Statistical Analysis and Data Display
##? ? Richard M. Heiberger and Burt Holland
## http://www.springer.com/us/book/9781493921218

library(HH)
## find the pathname of the R script file dsgn.R containing this example
HHscriptnames(13)
## open the file dsgn.R in your favorite editor.


## Then run

## chunk 2,?
## chunk 3, Figure 13.1
## chunk 4? Table 13.1
## chunk 7? Figure 13.3? three-way interactions

## Rows of the array of panels are? ? ? ? ? ? ? ? ? current
## Columns of the array of panels are? ? ? ? ? ? ? ?n.treats
## differently colored boxes within each panel are? minutes
##?
## In this example the 3-way interaction is not significant.
## For a hint of what one could see, compare the panel "60.cycle x 3"
## with "60.cycle x 6".? In "60.cycle x 3", the red box at minutes=5 is
## higher than the other three boxes.? In "60.cycle x 6", the red box at
## minutes=5 is lower than the other boxes.


## Illustrate a minimalist form of this call.
## Create a dataset with simple variable names Y, A, B, C
mydata <- data.frame(Y=cc176$y.adj,
? ? ? ? ? ? ? ? ? ? ?A=unpositioned(cc176$minutes),
? ? ? ? ? ? ? ? ? ? ?B=cc176$n.treats,
? ? ? ? ? ? ? ? ? ? ?C=cc176$current)

## A is an ordinary factor, minutes is a positioned factor, see ?HH::position
## We use xyplot() here, not bwplot(), because bwplot() doesn't handle "positioned" factors.

## The minimalist form of this call is
useOuterStrips(
xyplot(Y ~ A | B + C, data=mydata,
? ? ? ?groups=A,
? ? ? ?panel=panel.bwplot.superpose, ## take control of colors of the boxes
? ? ? ?horizontal=FALSE,
? ? ? ?between=list(x=1, y=1))
)


On Mon, Jan 7, 2019 at 7:59 PM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On 1/7/19 3:35 PM, varin sacha via R-help wrote:
>> Dear R-experts,
>>
>> I have fitted a model with 2-way and 3-way interactions.
>> I would like, for the 3-way interaction (year,age,by=education), to obtain 3D-plots. How could I do that ?
> 
> Forget ggplot2. It has ignored this sort of visualization effort. Use 
> lattice or base plotting methods.
> 
> 
> In order to plot a 2way interaction one needs a pseudo-3way plot 
> (`wireframe`) or a single `levelplot`. For display of a 3way interaction 
> in lattice (given the human minds inability to "see" in 4 dimensions) 
> you will need to specify levels for one of the variables to display 
> slices perhaps using multiple displays of 2way "sub-interactions" 
> calculated ad meaningul levels of the variable you choose to slive 
> with.? I'm not sure what the "native" plotting method for pkg:mgcv might 
> be. I suspect it was base graphics,; if so, look at ?persp and ?contour.
> 
> -- 
> 
> David
> 
>>
>> Many thanks for your response.
>>
>> Here is the reproducible example:
>>
>> #############
>> install.packages("ISLR")
>>
>> library(ISLR)
>>
>> install.packages("mgcv")
>>
>> library(mgcv)
>>
>> mod1<-gam(wage ~education+s(age,bs="ps")+year+te(age,year,bs="ps")+s(year,bs="ps",by=education,m=1)+te(year,age,by=education,bs=rep("ps",2)),data=Wage)
>>
>> plot(mod1)
>> #############
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From v@rin@@ch@ @ending from y@hoo@fr  Sat Jan 12 15:22:41 2019
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Sat, 12 Jan 2019 14:22:41 +0000 (UTC)
Subject: [R] Visreg package : Legend to large and 3 ways-interactions
 possible ?
References: <1730987174.27234354.1547302961364.ref@mail.yahoo.com>
Message-ID: <1730987174.27234354.1547302961364@mail.yahoo.com>

Dear R-experts,

The reproducible example is below.

I am trying to use the visreg package for 2 ways-interactions and for 3 ways-interactions.
For 2 ways-interactions, everything goes fine except that the legend on the top (2.HS Grad ; 3. Some College ; 4. College Grad) is not entire/complete, because written too large, I would like to make it smaller to be able to read the entire legend. Is it possible ?

My 2nd question: I am wondering if it is possible to plot 3 ways-interactions using visreg : "year" ; "age"; "education" ?

Many thanks for your time

############# 

install.packages("ISLR")

library(ISLR)

install.packages("visreg")

library(visreg)

install.packages("mgcv")

library(mgcv)

mod1<-gam(wage ~education+s(age,bs="ps")+year+te(age,year,bs="ps")+s(year,bs="ps",by=education,m=1)+te(year,age,by=education,bs=rep("ps",2)),data=Wage)

visreg(mod1, "year", by="education",partial=FALSE,overlay=TRUE)

 ############# 
?


From dwin@emiu@ @ending from comc@@t@net  Sat Jan 12 18:15:43 2019
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 12 Jan 2019 09:15:43 -0800
Subject: [R] SURVDIFF()
In-Reply-To: <CAH6117K2NOGdb9DFuJ_6q51Z54998ZkAzYZg8F5TV5Lur5fWQw@mail.gmail.com>
References: <CAH6117K2NOGdb9DFuJ_6q51Z54998ZkAzYZg8F5TV5Lur5fWQw@mail.gmail.com>
Message-ID: <84cb14bc-5524-faf8-6f84-c79ef8ddb014@comcast.net>


On 1/12/19 1:18 AM, Medic wrote:
> How to note (in code) a few (!) adjusting covariates for cox
> regression. I had an example for one covariate, and tried (according
> to my own understanding) two variantes of code  (pls, see below), and
> got ... a different p-value. What is the right code? Many thanks!!!
>
> (1)
> survdiff (Surv(survt,status)~clinic+strata(prison, dose, gender),data=addicts)
> N Observed Expected (O-E)^2/E (O-E)^2/V
> clinic=1 163      122    106.2      2.35        14
> clinic=2  75       28     43.8      5.70        14
> Chisq= 14  on 1 degrees of freedom, p= 2e-04
>
> (2)
> survdiff (Surv(survt,status)~clinic+strata(prison+dose+gender),data=addicts)
> N Observed Expected (O-E)^2/E (O-E)^2/V
> clinic=1 163      122    106.2      2.35      12.1
> clinic=2  75       28     43.8      5.69      12.1
> Chisq= 12.1  on 1 degrees of freedom, p= 5e-04


Read the help page:


> ?strata
>
>
> Usage
>
> strata(..., na.group=FALSE, shortlabel, sep=', ')
> Arguments
>
> ...
> any number of variables. All must be the same length.
>
So the function is documented to accept a list of variable names, but 
_not_ as accepting a formula. So I read the help page as endorsing your 
first option. Since you didn't include a suitable dataset for testing I 
borrowed the ovarian dataframe and checked to see whether the sum of 
variables submitted with a "+" sign was being calculated and can confirm 
that it is:


 >? coxph(Surv(futime, fustat) ~ age + strata(I(rx+ecog.ps)), data=ovarian)
Call:
coxph(formula = Surv(futime, fustat) ~ age + strata(I(rx + ecog.ps)),
 ??? data = ovarian)

 ?????? coef exp(coef) se(coef)???? z?????? p
age 0.11942?? 1.12684? 0.04528 2.637 0.00836

Likelihood ratio test=9.48? on 1 df, p=0.002073
n= 26, number of events= 12
 >? coxph(Surv(futime, fustat) ~ age + strata( rx+ecog.ps) , data=ovarian)
Call:
coxph(formula = Surv(futime, fustat) ~ age + strata(rx + ecog.ps),
 ??? data = ovarian)

 ?????? coef exp(coef) se(coef)???? z?????? p
age 0.11942?? 1.12684? 0.04528 2.637 0.00836

-- 

David.


From wewol@ki @ending from gm@il@com  Sat Jan 12 18:55:30 2019
From: wewol@ki @ending from gm@il@com (Witold E Wolski)
Date: Sat, 12 Jan 2019 18:55:30 +0100
Subject: [R] randomForest out of bag prediction
Message-ID: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>

Hello,

I am just not sure what the predict.RandomForest function is doing...
I confused.

I would expect the predictions for these 2 function calls to predict the same:
```{r}
diachp.rf <- randomForest(quality~.,data=data,ntree=50, importance=TRUE)

ypred_oob <- predict(diachp.rf)
dataX <- data %>% select(-quality) # remove response.
ypred <- predict( diachp.rf, dataX )

ypred_oob == ypred
```
These are both out of bag predictions but ypred and ypred_oob are
actually they are very different.

> table(ypred_oob , data$quality)

ypred_oob    0    1
        0 1324  346
        1  493 2837
> table(ypred , data$quality)

ypred    0    1
    0 1817    0
    1    0 3183

What I find even more disturbing is that 100% accuracy for ypred.
Would you agree that this is rather unexpected?

regards
Witek
-- 
Witold Eryk Wolski


From m@iliP@dpo@t @ending from gm@il@com  Sat Jan 12 19:08:44 2019
From: m@iliP@dpo@t @ending from gm@il@com (Medic)
Date: Sat, 12 Jan 2019 21:08:44 +0300
Subject: [R] SURVDIFF()
Message-ID: <CAH6117Kg1Z0C=oBOMsREW=ZuPPxs+U5pAwhRQ5PA0YWH+x4qOA@mail.gmail.com>

Dear David,
you are (as always) come to the rescue!
With your wonderful pedagogical talent of explanation!
Many thanks for the support!
My warmest and sincere wishes for the new year!


From bgunter@4567 @ending from gm@il@com  Sat Jan 12 19:16:21 2019
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 12 Jan 2019 10:16:21 -0800
Subject: [R] randomForest out of bag prediction
In-Reply-To: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
References: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
Message-ID: <CAGxFJbR7Chit3Mxnj7C-jJ=+xom9byv0ToR=u--Sn-pUEuaAyw@mail.gmail.com>

Off topic.
But see here:
https://stats.stackexchange.com/questions/61405/random-forest-and-prediction

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jan 12, 2019 at 9:56 AM Witold E Wolski <wewolski at gmail.com> wrote:

> Hello,
>
> I am just not sure what the predict.RandomForest function is doing...
> I confused.
>
> I would expect the predictions for these 2 function calls to predict the
> same:
> ```{r}
> diachp.rf <- randomForest(quality~.,data=data,ntree=50, importance=TRUE)
>
> ypred_oob <- predict(diachp.rf)
> dataX <- data %>% select(-quality) # remove response.
> ypred <- predict( diachp.rf, dataX )
>
> ypred_oob == ypred
> ```
> These are both out of bag predictions but ypred and ypred_oob are
> actually they are very different.
>
> > table(ypred_oob , data$quality)
>
> ypred_oob    0    1
>         0 1324  346
>         1  493 2837
> > table(ypred , data$quality)
>
> ypred    0    1
>     0 1817    0
>     1    0 3183
>
> What I find even more disturbing is that 100% accuracy for ypred.
> Would you agree that this is rather unexpected?
>
> regards
> Witek
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From peter@l@ngfelder @ending from gm@il@com  Sat Jan 12 19:56:33 2019
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Sat, 12 Jan 2019 10:56:33 -0800
Subject: [R] randomForest out of bag prediction
In-Reply-To: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
References: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
Message-ID: <CA+hbrhUGQbo31iyRfxtYxunmrKc6qv-MYQ6Ds1gkYJkUbLoHHg@mail.gmail.com>

See inline.

On Sat, Jan 12, 2019 at 9:56 AM Witold E Wolski <wewolski at gmail.com> wrote:

> ypred_oob <- predict(diachp.rf)

AFAIK these are, indeed, the out-of-bag predictions.

> dataX <- data %>% select(-quality) # remove response.
> ypred <- predict( diachp.rf, dataX )

These are not out of bag predictions. dataX is interpreted as new data
(argument newdata), and it is assumed to contain entirely new
observations. Each observation in dataX is fed through all of the
trees and the predictions are then pooled. There is no out-of-bag here
- all of the new data observations are assumed to be independent of
the training set.

>
> What I find even more disturbing is that 100% accuracy for ypred.
> Would you agree that this is rather unexpected?

It is expected (and not disturbing) l if your training set had enough
variables (or signal) to create trees that fit the training data
perfectly.

HTH,

Peter


From m@yermich@el79 @ending from gm@il@com  Sat Jan 12 19:16:18 2019
From: m@yermich@el79 @ending from gm@il@com (Michael Mayer)
Date: Sat, 12 Jan 2019 19:16:18 +0100
Subject: [R] randomForest out of bag prediction
In-Reply-To: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
References: <CAAjnpdjhFDAWrD9Pssewhss046vdFYdgPg7Crk7kYwoLqKBu6w@mail.gmail.com>
Message-ID: <5c3a2ef3.1c69fb81.23ae.3a74@mx.google.com>


predict(diachp.rf, dataX) returns the in-sample predictions, not the OOB predictions. The response variable ?quality? is only used during model fit, not during prediction. 

Since in-sample predictions of random forests are typically grossly overfitted by construction, extremely high accuracies are not unexpected.

Gesendet von Mail f?r Windows 10

Von: Witold E Wolski
Gesendet: Samstag, 12. Januar 2019 18:56
An: r-help at r-project.org
Betreff: [R] randomForest out of bag prediction

Hello,

I am just not sure what the predict.RandomForest function is doing...
I confused.

I would expect the predictions for these 2 function calls to predict the same:
```{r}
diachp.rf <- randomForest(quality~.,data=data,ntree=50, importance=TRUE)

ypred_oob <- predict(diachp.rf)
dataX <- data %>% select(-quality) # remove response.
ypred <- predict( diachp.rf, dataX )

ypred_oob == ypred
```
These are both out of bag predictions but ypred and ypred_oob are
actually they are very different.

> table(ypred_oob , data$quality)

ypred_oob    0    1
        0 1324  346
        1  493 2837
> table(ypred , data$quality)

ypred    0    1
    0 1817    0
    1    0 3183

What I find even more disturbing is that 100% accuracy for ypred.
Would you agree that this is rather unexpected?

regards
Witek
-- 
Witold Eryk Wolski

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @xel@urbiz @ending from gm@il@com  Sun Jan 13 22:17:37 2019
From: @xel@urbiz @ending from gm@il@com (Axel Urbiz)
Date: Sun, 13 Jan 2019 16:17:37 -0500
Subject: [R] mgcv::bam with monotonic constraints
Message-ID: <CAAyVsXLggXC6M9CqFX-0QW_f_UkTRUXt43zofPVY8Bak8P9hfg@mail.gmail.com>

Dear List,

I need to fit a GAM to a large dataset (`mgcv::bam` does this), but
ensuring that some covariates have a monotonic relation with the response.

`mgcv::mono.con` with `mgcv::pcls` seem to do this, but only for
`mgcv::gam` (not mgcv::bam)?

I'd really appreciate any pointers!

Regards,
Axel.

	[[alternative HTML version deleted]]


From wjh1518 @ending from ht@co@kr  Mon Jan 14 03:28:21 2019
From: wjh1518 @ending from ht@co@kr (=?utf-8?B?7Jqw7KeA7Z2s?=)
Date: Mon, 14 Jan 2019 11:28:21 +0900
Subject: [R] FW: Re:  importing data error question
Message-ID: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>

From:  "???" <wjh1518 at ht.co.kr> 

Sent: Monday, January 14, 2019 9:40:26 AM 

To:"Fox, John" <jfox at mcmaster.ca> 

Subject:Re: [R] importing data error question 

Thanks for your replies. 

I'm using windows 7, I loaded FactoMineR, SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically) 

This problem occurred when I select Data > Import data > From Excel file. 

I checked FactoMineR and SensoMineR packages are loaded and using.. 

From:  "Fox, John" <jfox at mcmaster.ca> 

Sent: Friday, January 11, 2019 10:48:38 PM 

To:"PIKAL Petr" <petr.pikal at precheza.cz> 

Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org> 

Subject:Re: [R] importing data error question 

? Dear Petr and jihee,

 The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 

 So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?

 Best,
 John

 -------------------------------------------------
 John Fox, Professor Emeritus
 McMaster University
 Hamilton, Ontario, Canada
 Web: http::/socserv.mcmaster.ca/jfox

 > On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 > 
 > Hi
 > 
 > I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
 > 
 > So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
 > 
 > Cheers
 > Petr
 > 
 >> -----Original Message-----
 >> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
 >> Sent: Friday, January 11, 2019 9:14 AM
 >> To: r-help at R-project.org
 >> Subject: [R] importing data error question
 >> 
 >> Hi I'm jihee and I have a question about error...
 >> 
 >> I'm using R 3.5.2 and tried to use Rcmdr package.
 >> 
 >> and using FactoMineR and SensoMineR to analyze sensory data through PCA
 >> 
 >> but i can't import excel data with Rcmdr.
 >> 
 >> it has this messege :
 >> 
 >> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
 >> [tcl] bad Macintosh file type "?*?"
 >> 
 >> what is wrong with my R??? T_T
 >> 
 >> Thanks for your help.
 >> 
 >> jihee.
 >> [[alternative HTML version deleted]]
 >> 
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
 > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
 > 
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.

 	 ??? ??? / ??????   

 	e-mail  	wjh1518 at ht.co.kr  	Dir 	  	Mobile 	   

 	???? 	www.ht.co.kr  	???? 	www.facebook.com/haitaico   

 	Address 	????? ??? ???? 72? 3 (???) ??????(?) 04352               

 	 ???? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
 ??The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Mon Jan 14 09:24:59 2019
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 14 Jan 2019 08:24:59 +0000
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
 <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>
Message-ID: <c3122b1f567847f995637a95d4362a51@SRVEXCHCM1302.precheza.cz>

Hi

If you want to remove rows with NA values from your data you could use

?complete.cases

or

t2 <- t1[!is.na(t1$Petal.Width),]

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> Sent: Saturday, January 12, 2019 12:55 PM
> To: Ernest Han <ernest.hec at gmail.com>; r-help at r-project.org
> Subject: Re: [R] NA rows appeared in data.frame
>
> Hello,
>
> You have to test for NA. Some (12) of the values of t1$Petal.Width are NA
> therefore t1$Petal.Width == 2.0 alone returns 12 NA values.
>
> t1[t1$Petal.Width == 2.0 & !is.na(t1$Petal.Width == 2.0), ]
>
> Or use which(t1$Petal.Width == 2.0).
>
> t1[which(t1$Petal.Width == 2.0), ]
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:23 de 12/01/2019, Ernest Han escreveu:
> > Dear All,
> >
> > After replacing some values in a data.frame, NAs rows have appeared
> > and cannot be removed. I have googled these issues and found that
> > several people have encountered it. Solutions in stackoverflow seem to
> > provide work-arounds but does not remove it from the data.frame.
> > Therefore, I am turning to experts in this community for help.
> >
> > The code is as follows,
> >
> >> t1 <- iris
> >> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA t1[t1$Petal.Width ==
> >> 2.0, ]
> >        Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> > NA              NA          NA           NA          NA      <NA>
> > NA.1            NA          NA           NA          NA      <NA>
> > NA.2            NA          NA           NA          NA      <NA>
> > NA.3            NA          NA           NA          NA      <NA>
> > 111            6.5         3.2          5.1           2 virginica
> > 114            5.7         2.5          5.0           2 virginica
> > NA.4            NA          NA           NA          NA      <NA>
> > 122            5.6         2.8          4.9           2 virginica
> > 123            7.7         2.8          6.7           2 virginica
> > NA.5            NA          NA           NA          NA      <NA>
> > NA.6            NA          NA           NA          NA      <NA>
> > NA.7            NA          NA           NA          NA      <NA>
> > NA.8            NA          NA           NA          NA      <NA>
> > 132            7.9         3.8          6.4           2 virginica
> > NA.9            NA          NA           NA          NA      <NA>
> > NA.10           NA          NA           NA          NA      <NA>
> > 148            6.5         3.0          5.2           2 virginica
> > NA.11           NA          NA           NA          NA      <NA>
> >
> > ## Twelve values were replaced, twelve NA rows appeared.
> >
> > ### MISC INFO ###
> >> sessionInfo()
> > R version 3.4.0 (2017-04-21)
> > Platform: x86_64-apple-darwin16.5.0 (64-bit) Running under: macOS
> > 10.14.2
> >
> > Matrix products: default
> > BLAS:
> > /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/
> > vecLib.framework/Versions/A/libBLAS.dylib
> > LAPACK:
> > /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/
> > vecLib.framework/Versions/A/libLAPACK.dylib
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_3.4.0 tools_3.4.0
> >> Sys.getlocale()
> > [1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"
> >
> >
> > Thank you,
> > Ernest
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ericjberger @ending from gm@il@com  Mon Jan 14 09:41:06 2019
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 14 Jan 2019 10:41:06 +0200
Subject: [R] CRAN package NlcOptim query
In-Reply-To: <436554644.16933243.1547454674292@mail.yahoo.com>
References: <afe5c2e520d942adbcceff37f7ea7a01@INW20010891.ADRES.HSBC>
 <2000317032.1615237.1543918890940@mail.yahoo.com>
 <456046261.2086478.1544523285070@mail.yahoo.com>
 <CAGgJW75Xo-XOZO2qOniUseaLaM591F7DJGsVN56=F5Eors3xkg@mail.gmail.com>
 <1691260324.2450334.1544597054487@mail.yahoo.com>
 <436554644.16933243.1547454674292@mail.yahoo.com>
Message-ID: <CAGgJW75nPMiuVyGmAgJiYecZazzvxTRY0DzLVBs77K=28J2tJA@mail.gmail.com>

Aveek,
Did you try contacting the package maintainer as Hans suggested?



On Mon, Jan 14, 2019 at 10:31 AM aveek <aveekm at yahoo.co.in> wrote:

> Hello,
>
> Can anyone plz help with the below problem?
>
> Thanks,
> Aveek
>
> Sent from Yahoo Mail on Android
> <https://go.onelink.me/107872968?pid=InProduct&c=Global_Internal_YGrowth_AndroidEmailSig__AndroidUsers&af_wl=ym&af_sub1=Internal&af_sub2=Global_YGrowth&af_sub3=EmailSignature>
>
> On Wed, Dec 12, 2018 at 12:14 PM, aveek
> <aveekm at yahoo.co.in> wrote:
>
> Hello Eric,
>
> Thanks for your response and suggestions.
>
> I have used dput() on the R objects - sharing below so that it is possible
> for anyone to recreate the situation.
>
> I have still kept it as a 9*9 matrix but for simplicity we now only have 2
> equality and 2 non equality constraints.
>
> Thanks again for your help.
>
> InputTM
>
> structure(c(0.813231189406663, 0.0199464964676128, 0.00100552815128915,
>
> 0.000465771436428336, 0.000736922016196076, 0.00203037431732662,
>
> 0.000596998285890709, 0.0011699714577823, 0, 0.103116692172408,
>
> 0.751775368068589, 0.0160957427707042, 0.00285542569941823,
> 0.0020295541916448,
>
> 0.00954562743564027, 0.00173399818906894, 0.00292299139663608,
>
> 0, 0.0481959576543631, 0.177032393868544, 0.811609524051149,
>
> 0.146703962329218, 0.0698423269415636, 0.168241524872922,
> 0.0505757280338206,
>
> 0.0324917017565673, 0, 0.026504623193874, 0.038430496838613,
>
> 0.134709744786799, 0.758322716164413, 0.176013939161559, 0.234265359508999,
>
> 0.108188555487004, 0.0476663548325017, 0, 0.00520614395937929,
>
> 0.00868690292550468, 0.0223895752360805, 0.0581458712447338,
>
> 0.681496895121054, 0.0733970775224908, 0.0508491985259732,
> 0.0268876385360338,
>
> 0, 0.000749001395622802, 0.00181690494827145, 0.00317194515883476,
>
> 0.00705434604769267, 0.0211989316284324, 0.464732208379131,
> 0.0165146818291576,
>
> 0.00721872506710652, 0, 0.000960493069403903, 0.00138444384054219,
>
> 0.00703528202498607, 0.0163983255053438, 0.0301780379843763,
>
> 0.0280699612529658, 0.491157627745315, 0.0235353949469527, 0,
>
> 0.00112628575287418, 0.000477300396419488, 0.00223238360574478,
>
> 0.00521558462566306, 0.00925149338117537, 0.00878272484051914,
>
> 0.163654071683595, 0.611806567272906, 0, 0.000909613395411595,
>
> 0.000449692645903539, 0.00175027421441265, 0.00483799694708872,
>
> 0.00925189957399783, 0.0109351418700064, 0.116729140220175,
> 0.246300654733514,
>
> 1), .Dim = c(9L, 9L))
>
>
>
>
>
> Constr_new
>
> structure(c(1, 0, -1, 1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(2L,
>
> 81L), .Dimnames = list(NULL, c("X11", "X12", "X13", "X14", "X15",
>
> "X16", "X17", "X18", "X19", "X21", "X22", "X23", "X24", "X25",
>
> "X26", "X27", "X28", "X29", "X31", "X32", "X33", "X34", "X35",
>
> "X36", "X37", "X38", "X39", "X41", "X42", "X43", "X44", "X45",
>
> "X46", "X47", "X48", "X49", "X51", "X52", "X53", "X54", "X55",
>
> "X56", "X57", "X58", "X59", "X61", "X62", "X63", "X64", "X65",
>
> "X66", "X67", "X68", "X69", "X71", "X72", "X73", "X74", "X75",
>
> "X76", "X77", "X78", "X79", "X81", "X82", "X83", "X84", "X85",
>
> "X86", "X87", "X88", "X89", "X91", "X92", "X93", "X94", "X95",
>
> "X96", "X97", "X98", "X99")))
>
>
>
>
>
> x_than0
>
> c(1e-04, 1e-04)
>
>
>
> aeq2
>
> structure(list(X1 = c(1, 0), X2 = c(1, 0), X3 = c(1, 0), X4 = c(1,
>
> 0), X5 = c(1, 0), X6 = c(1, 0), X7 = c(1, 0), X8 = c(1, 0), X9 = c(1,
>
> 0), X10 = c(0, 1), X11 = c(0, 1), X12 = c(0, 1), X13 = c(0, 1
>
> ), X14 = c(0, 1), X15 = c(0, 1), X16 = c(0, 1), X17 = c(0, 1),
>
>     X18 = c(0, 1), X19 = c(0, 0), X20 = c(0, 0), X21 = c(0, 0
>
>     ), X22 = c(0, 0), X23 = c(0, 0), X24 = c(0, 0), X25 = c(0,
>
>     0), X26 = c(0, 0), X27 = c(0, 0), X28 = c(0, 0), X29 = c(0,
>
>     0), X30 = c(0, 0), X31 = c(0, 0), X32 = c(0, 0), X33 = c(0,
>
>     0), X34 = c(0, 0), X35 = c(0, 0), X36 = c(0, 0), X37 = c(0,
>
>     0), X38 = c(0, 0), X39 = c(0, 0), X40 = c(0, 0), X41 = c(0,
>
>     0), X42 = c(0, 0), X43 = c(0, 0), X44 = c(0, 0), X45 = c(0,
>
>     0), X46 = c(0, 0), X47 = c(0, 0), X48 = c(0, 0), X49 = c(0,
>
>     0), X50 = c(0, 0), X51 = c(0, 0), X52 = c(0, 0), X53 = c(0,
>
>     0), X54 = c(0, 0), X55 = c(0, 0), X56 = c(0, 0), X57 = c(0,
>
>     0), X58 = c(0, 0), X59 = c(0, 0), X60 = c(0, 0), X61 = c(0,
>
>     0), X62 = c(0, 0), X63 = c(0, 0), X64 = c(0, 0), X65 = c(0,
>
>     0), X66 = c(0, 0), X67 = c(0, 0), X68 = c(0, 0), X69 = c(0,
>
>     0), X70 = c(0, 0), X71 = c(0, 0), X72 = c(0, 0), X73 = c(0,
>
>     0), X74 = c(0, 0), X75 = c(0, 0), X76 = c(0, 0), X77 = c(0,
>
>     0), X78 = c(0, 0), X79 = c(0, 0), X80 = c(0, 0), X81 = c(0,
>
>     0)), .Names = c("X1", "X2", "X3", "X4", "X5", "X6", "X7",
>
> "X8", "X9", "X10", "X11", "X12", "X13", "X14", "X15", "X16",
>
> "X17", "X18", "X19", "X20", "X21", "X22", "X23", "X24", "X25",
>
> "X26", "X27", "X28", "X29", "X30", "X31", "X32", "X33", "X34",
>
> "X35", "X36", "X37", "X38", "X39", "X40", "X41", "X42", "X43",
>
> "X44", "X45", "X46", "X47", "X48", "X49", "X50", "X51", "X52",
>
> "X53", "X54", "X55", "X56", "X57", "X58", "X59", "X60", "X61",
>
> "X62", "X63", "X64", "X65", "X66", "X67", "X68", "X69", "X70",
>
> "X71", "X72", "X73", "X74", "X75", "X76", "X77", "X78", "X79",
>
> "X80", "X81"), row.names = 1:2, class = "data.frame")
>
>
>
> beq2
>
> c(1, 1)
>
>
> Regards,
>
> Aveek
>
> Sent from Yahoo Mail on Android
> <https://go.onelink.me/107872968?pid=InProduct&c=Global_Internal_YGrowth_AndroidEmailSig__AndroidUsers&af_wl=ym&af_sub1=Internal&af_sub2=Global_YGrowth&af_sub3=EmailSignature>
>
> On Tue, Dec 11, 2018 at 6:25 PM, Eric Berger
> <ericjberger at gmail.com> wrote:
> Hi Aveek,
> 1. This is an "all-text" mailing list. Your attachment did not come
> through.
>     You can check out the posting guide (see the link at the bottom of
> your email)
>      and/or
>      use dput(...) on your structures and paste them into your email so
> that members of the list can try to reproduce the problem.
> 2. One way to check out whether you are using a package correctly is to
> try a tiny example that you can calculate by hand, and see if you can
> reproduce the solution via the package.
>     e.g. instead of a 9x9 matrix (hence 81 dimensional problem in your
> case), try a 2x2 matrix with maybe just one or two constraints.
>
> HTH,
> Eric
>
> On Tue, Dec 11, 2018 at 1:18 PM aveek via R-help <r-help at r-project.org>
> wrote:
>
> Hi All,
> I am facing an issue with an optimization problem which I am trying to
> solve using NlcOptim package in R. I have tried reaching out to the package
> maintainer but not received any response, hence posting this here.
>
>
> Below is the code snippet I am using:
>
>
>
> #Optimization
>
>   obj_F <- function(vect_mat){
>
>     return (sum((c(InputTM) - vect_mat)^2))
>
>   }
>
>
>
>   numel = nrow(InputTM)*ncol(InputTM)
>
>   opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new, B=-x_than0,
> Aeq=as.matrix(aeq2), Beq=beq2, lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX =
> 0)
>
>
>
> I am attaching in the email the data being used as function arguments.
>
>
>
> Input_TM is a 9*9 matrix
>
> Constr_new is a 120*81 matrix
>
> x_than0 is a 120*1 matrix
>
> aeq2 is a 17*81 matrix
>
> beq2 is a 17*1 matrix
>
>
>
> Below is the error I am getting :
>
>
>
> R>   opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new,
> B=-x_than0, Aeq=as.matrix(aeq2), Beq=beq2,
> lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX = 0)
>
> Error in as.matrix(A %*% Xtarget) - matrix(B, ncol = 1) :
>
>   non-conformable arrays
>
> Calls: solnl -> rbind -> rbind
>
> In addition: Warning message:
>
> In rbind(rbind(lbright, ubright), B) :
>
>   number of columns of result is not a multiple of vector length (arg 2)
>
> Calls: solnl -> rbind
>
>
>
> Enter a frame number, or 0 to exit
>
>
>
> 1: solnl(X = c(InputTM), objfun = obj_F, A = -constr_new, B = -x_than0,
> Aeq = as.matrix(aeq2), Beq = beq2, lb =
>
> 2: rbind(rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A
> %*% Xtarget) - matrix(B, ncol = 1)), a
>
> 3: rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A %*%
> Xtarget) - matrix(B, ncol = 1))
>
>
>
>
>
>
>
> Can you kindly help with this? I am mostly sure that the constraint
> matrices have been correctly formulated. Am I going wrong with the way I am
> specifying the arguments?
>
> Thanks a lot for any help any of you can offer.
>
>
>
> Thanks and Regards,
>
> Aveek Mukhopadhyay
>
>
>
>
>
> <!--#yiv2239857533 _filtered #yiv2239857533 {font-family:"Cambria
> Math";panose-1:2 4 5 3 5 4 6 3 2 4;} _filtered #yiv2239857533
> {font-family:Calibri;panose-1:2 15 5 2 2 2 4 3 2 4;} _filtered
> #yiv2239857533 {font-family:"Lucida Console";panose-1:2 11 6 9 4 5 4 2 2
> 4;}#yiv2239857533 #yiv2239857533 p.yiv2239857533MsoNormal, #yiv2239857533
> li.yiv2239857533MsoNormal, #yiv2239857533 div.yiv2239857533MsoNormal
> {margin:0in;margin-bottom:.0001pt;font-size:11.0pt;font-family:"Calibri",
> sans-serif;}#yiv2239857533 a:link, #yiv2239857533
> span.yiv2239857533MsoHyperlink
> {color:#0563C1;text-decoration:underline;}#yiv2239857533 a:visited,
> #yiv2239857533 span.yiv2239857533MsoHyperlinkFollowed
> {color:#954F72;text-decoration:underline;}#yiv2239857533 pre
> {margin:0in;margin-bottom:.0001pt;font-size:10.0pt;font-family:"Courier
> New";}#yiv2239857533 span.yiv2239857533HTMLPreformattedChar
> {font-family:"Courier New";}#yiv2239857533 span.yiv2239857533EmailStyle19
> {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533
> span.yiv2239857533gnkrckgcmsb {}#yiv2239857533
> span.yiv2239857533gnkrckgcmrb {}#yiv2239857533
> span.yiv2239857533gnkrckgcasb {}#yiv2239857533
> span.yiv2239857533gnkrckgcgsb {}#yiv2239857533
> span.yiv2239857533EmailStyle24 {font-family:"Calibri",
> sans-serif;color:#1F497D;}#yiv2239857533 span.yiv2239857533EmailStyle25
> {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533
> .yiv2239857533MsoChpDefault {font-size:10.0pt;} _filtered #yiv2239857533
> {margin:1.0in 1.0in 1.0in 1.0in;}#yiv2239857533
> div.yiv2239857533WordSection1 {}-->
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From i@vi@@er @ending from uv@@nl  Thu Jan 10 11:43:20 2019
From: i@vi@@er @ending from uv@@nl (Ingmar Visser)
Date: Thu, 10 Jan 2019 11:43:20 +0100
Subject: [R] [R-pkgs] standard errors in depmixS4 beta version 1.4 on r-forge
Message-ID: <CABmqZHOBdG0hpdPAvw5AcmBK8HmPQeme8OeTKzi3QFvp=m9NvA@mail.gmail.com>

The new 1.4 version of depmixS4 has an important (and much requested!) new
feature: the possibility to request standard errors of estimated parameters
through the use of a finite differences approximation of the hessian. As
this is a critical feature we appreciate your comments and feedback when
using the beta version of this package available from r-forge:
https://r-forge.r-project.org/R/?group_id=148
which can be installed using:
*install.packages("depmixS4", repos="http://R-Forge.R-project.org
<http://R-Forge.R-project.org>")*

As soon as enough testing has been done and we are confident about the
robustness of this new functionality we will post the package to CRAN.

Happy mixing, Ingmar Visser & Maarten Speekenbrink

Ingmar Visser
Universitair Hoofddocent ontwikkelingspsychologie | Directeur College
Psychologie
Afdeling Psychologie | Faculteit Maatschappij- en Gedragswetenschappen |
Universiteit van Amsterdam
Bezoek | Nieuwe Achtergracht 129B | Kamer G 1.18
Post | Postbus 15933 | 1001 NK Amsterdam
Pakketpost | Valckenierstraat 59 | 1018 XE Amsterdam
T: +31205256723 | M: +31647260824 | e: i.visser at uva.nl

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From S@Elli@on @ending from LGCGroup@com  Mon Jan 14 11:25:09 2019
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Mon, 14 Jan 2019 10:25:09 +0000
Subject: [R] Tinn-R: new web site
In-Reply-To: <CAN+Emd91q4-KKMyYsmPAh6eVTg3_rzZ03eKSKzaWaK_YKq7f5A@mail.gmail.com>
References: <CAN+Emd91q4-KKMyYsmPAh6eVTg3_rzZ03eKSKzaWaK_YKq7f5A@mail.gmail.com>
Message-ID: <a8b9503d2e7c4e659c37a8ecc23da55c@GBDCVPEXC08.corp.lgc-group.com>

> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jose
> Claudio Faria
> 
> The Tinn-R project has a new web page:
> http://nbcgib.uesc.br/tinnr/en/index.php
> 


Thanks for this - and thanks, also, for maintaining Tinn-R and keeping it available as free software. The effort is much appreciated.

Steve Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S@Elli@on @ending from LGCGroup@com  Mon Jan 14 11:51:40 2019
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Mon, 14 Jan 2019 10:51:40 +0000
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
Message-ID: <ce79ef9cd5034e92b9cf529268d84f54@GBDCVPEXC08.corp.lgc-group.com>

> After replacing some values in a data.frame, NAs rows have appeared
> and cannot be removed. 
I'm not clear why you say 'cannot be removed', which sounds quite a bit stronger than 'I couldn't ...'. 
The example you gave returned new NA rows because your logical test included NAs (Petal.Width == 2.0 returns NA for all of the NA petal widths, and an NA in indexing returns an NA row). 
But 'cannot be removed' sounded to me as if you've read somewhere that it's impossible, or that you've tried something that should work and didn't; if you meant either of those you'll have to say what the problem was.

In the mean time: 
If you want to remove rows containing _any_ NAs, see ?complete.cases  and use something like
t1[complete.cases(t1),]

If you want to remove rows that are _all_ NA, you may need something like

subset(t1, apply(t1, 1, function(x) !all(is.na(x))))
(or the equivalent '[' usage)

and, as an aside, using '==' for floating point numbers is not generally safe; for example
> sqrt(2)^2 == 2.0
[1] FALSE

See R FAQ 7.31 for details of why '==' is bad for floating point, if you haven't already.


S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ernest Han
> Sent: 12 January 2019 08:23
> To: r-help at r-project.org
> Subject: [R] NA rows appeared in data.frame
> 
> Dear All,
> 
> After replacing some values in a data.frame, NAs rows have appeared
> and cannot be removed. I have googled these issues and found that
> several people have encountered it. Solutions in stackoverflow seem to
> provide work-arounds but does not remove it from the data.frame.
> Therefore, I am turning to experts in this community for help.
> 
> The code is as follows,
> 
> > t1 <- iris
> > t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA
> > t1[t1$Petal.Width == 2.0, ]
>       Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> NA              NA          NA           NA          NA      <NA>
> NA.1            NA          NA           NA          NA      <NA>
> NA.2            NA          NA           NA          NA      <NA>
> NA.3            NA          NA           NA          NA      <NA>
> 111            6.5         3.2          5.1           2 virginica
> 114            5.7         2.5          5.0           2 virginica
> NA.4            NA          NA           NA          NA      <NA>
> 122            5.6         2.8          4.9           2 virginica
> 123            7.7         2.8          6.7           2 virginica
> NA.5            NA          NA           NA          NA      <NA>
> NA.6            NA          NA           NA          NA      <NA>
> NA.7            NA          NA           NA          NA      <NA>
> NA.8            NA          NA           NA          NA      <NA>
> 132            7.9         3.8          6.4           2 virginica
> NA.9            NA          NA           NA          NA      <NA>
> NA.10           NA          NA           NA          NA      <NA>
> 148            6.5         3.0          5.2           2 virginica
> NA.11           NA          NA           NA          NA      <NA>
> 
> ## Twelve values were replaced, twelve NA rows appeared.
> 
> ### MISC INFO ###
> > sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-apple-darwin16.5.0 (64-bit)
> Running under: macOS  10.14.2
> 
> Matrix products: default
> BLAS:
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Framewor
> ks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK:
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Framewor
> ks/vecLib.framework/Versions/A/libLAPACK.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0 tools_3.4.0
> > Sys.getlocale()
> [1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-
> 8"
> 
> 
> Thank you,
> Ernest
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ptit_bleu @ending from y@hoo@fr  Mon Jan 14 13:14:22 2019
From: ptit_bleu @ending from y@hoo@fr (lionel sicot)
Date: Mon, 14 Jan 2019 12:14:22 +0000 (UTC)
Subject: [R] Extrapolate x values from a defined y sequence
References: <1791435523.28573483.1547468062931.ref@mail.yahoo.com>
Message-ID: <1791435523.28573483.1547468062931@mail.yahoo.com>

Hello,
I have two sets of measurement :with the same x sequence :x1<-1:10y1<-c(5,4.6,4.4,4.2,4,3.8,3.7,3.6,3,1)
x2<-1:10y2<-c(5,4.8,4.6,4.4,4.1,4,3.8,3.6,2.8,1)
I would like to sum these two curves in terms of x for a given sequence of y (for example : y<-c(5,4.5,4,3.5,3,2.5,2,1.5,1)), that is to determine for each y, an x1' from x1 and an x2' from x2 corresponding to y so that I can plot y as a function of (x1'+x2').
I hope it is clear enough.
I think I can do it with a loop an some non-conventional R script (I'm not a computer scientist) but i'm pretty sure that there is an elegant way to do it with R.
It will be very kind if someone can give me some R functions to do it.Thanks in advance,Ptit Bleu.




	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Jan 14 14:02:33 2019
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 14 Jan 2019 15:02:33 +0200
Subject: [R] Extrapolate x values from a defined y sequence
In-Reply-To: <1791435523.28573483.1547468062931@mail.yahoo.com>
References: <1791435523.28573483.1547468062931.ref@mail.yahoo.com>
 <1791435523.28573483.1547468062931@mail.yahoo.com>
Message-ID: <CAGgJW74P3ECnGHo9089YpEu1J1Wo5kK9uhhZ0o2r9_PBXUKjYg@mail.gmail.com>

Hi Lionel,
Your choice of variable names is a bit odd (the roles of x and y seem to be
reversed from the usual.)
Assuming that you are looking for linear interpolation (in spite of the
subject of your email),
does the following give you what you need?

u1 <- approx(x=y1,y=x1,xout=y)
u2 <- approx(x=y2,y=x2,xout=y)
v   <- u1$y + u2$y

# At this point v is the sequence  x1+x2 and y is as you specified it.
# v
# [1]  2.00000  6.00000 11.00000 16.29167 17.75000 18.41667 18.94444
19.47222 20.00000
# y
# [1] 5.0 4.5 4.0 3.5 3.0 2.5 2.0 1.5 1.0

HTH,
Eric



On Mon, Jan 14, 2019 at 2:16 PM lionel sicot via R-help <
r-help at r-project.org> wrote:

> Hello,
> I have two sets of measurement :with the same x sequence
> :x1<-1:10y1<-c(5,4.6,4.4,4.2,4,3.8,3.7,3.6,3,1)
> x2<-1:10y2<-c(5,4.8,4.6,4.4,4.1,4,3.8,3.6,2.8,1)
> I would like to sum these two curves in terms of x for a given sequence of
> y (for example : y<-c(5,4.5,4,3.5,3,2.5,2,1.5,1)), that is to determine for
> each y, an x1' from x1 and an x2' from x2 corresponding to y so that I can
> plot y as a function of (x1'+x2').
> I hope it is clear enough.
> I think I can do it with a loop an some non-conventional R script (I'm not
> a computer scientist) but i'm pretty sure that there is an elegant way to
> do it with R.
> It will be very kind if someone can give me some R functions to do
> it.Thanks in advance,Ptit Bleu.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @veekm @ending from y@hoo@co@in  Mon Jan 14 09:31:14 2019
From: @veekm @ending from y@hoo@co@in (aveek)
Date: Mon, 14 Jan 2019 08:31:14 +0000 (UTC)
Subject: [R] CRAN package NlcOptim query
In-Reply-To: <1691260324.2450334.1544597054487@mail.yahoo.com>
References: <afe5c2e520d942adbcceff37f7ea7a01@INW20010891.ADRES.HSBC>
 <2000317032.1615237.1543918890940@mail.yahoo.com>
 <456046261.2086478.1544523285070@mail.yahoo.com>
 <CAGgJW75Xo-XOZO2qOniUseaLaM591F7DJGsVN56=F5Eors3xkg@mail.gmail.com>
 <1691260324.2450334.1544597054487@mail.yahoo.com>
Message-ID: <436554644.16933243.1547454674292@mail.yahoo.com>

Hello,
Can anyone plz help with the below problem??
Thanks,Aveek

Sent from Yahoo Mail on Android 
 
  On Wed, Dec 12, 2018 at 12:14 PM, aveek<aveekm at yahoo.co.in> wrote:   
Hello Eric,

Thanks for your response and suggestions.?

I have used dput() on the R objects - sharing below so that it is possible for anyone to recreate the situation.

I have still kept it as a 9*9 matrix but for simplicity we now only have 2 equality and 2 non equality constraints.

Thanks again for your help.

InputTM


structure(c(0.813231189406663, 0.0199464964676128, 0.00100552815128915,

0.000465771436428336, 0.000736922016196076, 0.00203037431732662,

0.000596998285890709, 0.0011699714577823, 0, 0.103116692172408,

0.751775368068589, 0.0160957427707042, 0.00285542569941823, 0.0020295541916448,

0.00954562743564027, 0.00173399818906894, 0.00292299139663608,

0, 0.0481959576543631, 0.177032393868544, 0.811609524051149,

0.146703962329218, 0.0698423269415636, 0.168241524872922, 0.0505757280338206,

0.0324917017565673, 0, 0.026504623193874, 0.038430496838613,

0.134709744786799, 0.758322716164413, 0.176013939161559, 0.234265359508999,

0.108188555487004, 0.0476663548325017, 0, 0.00520614395937929,

0.00868690292550468, 0.0223895752360805, 0.0581458712447338,

0.681496895121054, 0.0733970775224908, 0.0508491985259732, 0.0268876385360338,

0, 0.000749001395622802, 0.00181690494827145, 0.00317194515883476,

0.00705434604769267, 0.0211989316284324, 0.464732208379131, 0.0165146818291576,

0.00721872506710652, 0, 0.000960493069403903, 0.00138444384054219,

0.00703528202498607, 0.0163983255053438, 0.0301780379843763,

0.0280699612529658, 0.491157627745315, 0.0235353949469527, 0,

0.00112628575287418, 0.000477300396419488, 0.00223238360574478,

0.00521558462566306, 0.00925149338117537, 0.00878272484051914,

0.163654071683595, 0.611806567272906, 0, 0.000909613395411595,

0.000449692645903539, 0.00175027421441265, 0.00483799694708872,

0.00925189957399783, 0.0109351418700064, 0.116729140220175, 0.246300654733514,

1), .Dim = c(9L, 9L))

?

?

Constr_new

structure(c(1, 0, -1, 1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(2L,

81L), .Dimnames = list(NULL, c("X11", "X12", "X13", "X14", "X15",

"X16", "X17", "X18", "X19", "X21", "X22", "X23", "X24", "X25",

"X26", "X27", "X28", "X29", "X31", "X32", "X33", "X34", "X35",

"X36", "X37", "X38", "X39", "X41", "X42", "X43", "X44", "X45",

"X46", "X47", "X48", "X49", "X51", "X52", "X53", "X54", "X55",

"X56", "X57", "X58", "X59", "X61", "X62", "X63", "X64", "X65",

"X66", "X67", "X68", "X69", "X71", "X72", "X73", "X74", "X75",

"X76", "X77", "X78", "X79", "X81", "X82", "X83", "X84", "X85",

"X86", "X87", "X88", "X89", "X91", "X92", "X93", "X94", "X95",

"X96", "X97", "X98", "X99")))

?

?

x_than0

c(1e-04, 1e-04)

?

aeq2

structure(list(X1 = c(1, 0), X2 = c(1, 0), X3 = c(1, 0), X4 = c(1,

0), X5 = c(1, 0), X6 = c(1, 0), X7 = c(1, 0), X8 = c(1, 0), X9 = c(1,

0), X10 = c(0, 1), X11 = c(0, 1), X12 = c(0, 1), X13 = c(0, 1

), X14 = c(0, 1), X15 = c(0, 1), X16 = c(0, 1), X17 = c(0, 1),

????X18 = c(0, 1), X19 = c(0, 0), X20 = c(0, 0), X21 = c(0, 0

??? ), X22 = c(0, 0), X23 = c(0, 0), X24 = c(0, 0), X25 = c(0,

????0), X26 = c(0, 0), X27 = c(0, 0), X28 = c(0, 0), X29 = c(0,

????0), X30 = c(0, 0), X31 = c(0, 0), X32 = c(0, 0), X33 = c(0,

????0), X34 = c(0, 0), X35 = c(0, 0), X36 = c(0, 0), X37 = c(0,

????0), X38 = c(0, 0), X39 = c(0, 0), X40 = c(0, 0), X41 = c(0,

????0), X42 = c(0, 0), X43 = c(0, 0), X44 = c(0, 0), X45 = c(0,

????0), X46 = c(0, 0), X47 = c(0, 0), X48 = c(0, 0), X49 = c(0,

????0), X50 = c(0, 0), X51 = c(0, 0), X52 = c(0, 0), X53 = c(0,

????0), X54 = c(0, 0), X55 = c(0, 0), X56 = c(0, 0), X57 = c(0,

????0), X58 = c(0, 0), X59 = c(0, 0), X60 = c(0, 0), X61 = c(0,

????0), X62 = c(0, 0), X63 = c(0, 0), X64 = c(0, 0), X65 = c(0,

????0), X66 = c(0, 0), X67 = c(0, 0), X68 = c(0, 0), X69 = c(0,

????0), X70 = c(0, 0), X71 = c(0, 0), X72 = c(0, 0), X73 = c(0,

????0), X74 = c(0, 0), X75 = c(0, 0), X76 = c(0, 0), X77 = c(0,

????0), X78 = c(0, 0), X79 = c(0, 0), X80 = c(0, 0), X81 = c(0,

????0)), .Names = c("X1", "X2", "X3", "X4", "X5", "X6", "X7",

"X8", "X9", "X10", "X11", "X12", "X13", "X14", "X15", "X16",

"X17", "X18", "X19", "X20", "X21", "X22", "X23", "X24", "X25",

"X26", "X27", "X28", "X29", "X30", "X31", "X32", "X33", "X34",

"X35", "X36", "X37", "X38", "X39", "X40", "X41", "X42", "X43",

"X44", "X45", "X46", "X47", "X48", "X49", "X50", "X51", "X52",

"X53", "X54", "X55", "X56", "X57", "X58", "X59", "X60", "X61",

"X62", "X63", "X64", "X65", "X66", "X67", "X68", "X69", "X70",

"X71", "X72", "X73", "X74", "X75", "X76", "X77", "X78", "X79",

"X80", "X81"), row.names = 1:2, class = "data.frame")

?

beq2

c(1, 1)




Regards,

Aveek

Sent from Yahoo Mail on Android 
 
  On Tue, Dec 11, 2018 at 6:25 PM, Eric Berger<ericjberger at gmail.com> wrote:   Hi Aveek,1. This is an "all-text" mailing list. Your attachment did not come through.?? ? You can check out the posting guide (see the link at the bottom of your email)?? ? ?and/or??? ? ?use dput(...) on your structures and paste them into your email so that members of the list can try to reproduce the problem.2. One way to check out whether you are using a package correctly is to try a tiny example that you can calculate by hand, and see if you can reproduce the solution via the package.? ? e.g. instead of a 9x9 matrix (hence 81 dimensional problem in your case), try a 2x2 matrix with maybe just one or two constraints.?
HTH,Eric
On Tue, Dec 11, 2018 at 1:18 PM aveek via R-help <r-help at r-project.org> wrote:

Hi All,
I am facing an issue with an optimization problem which I am trying to solve using NlcOptim package in R. I have tried reaching out to the package maintainer but not received any response, hence posting this here.?


Below is the code snippet I am using:

??

#Optimization

? obj_F <- function(vect_mat){

??? return (sum((c(InputTM) - vect_mat)^2))

? }

? 

??numel = nrow(InputTM)*ncol(InputTM)

? opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new, B=-x_than0, Aeq=as.matrix(aeq2), Beq=beq2, lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX = 0)

??

I am attaching in the email the data being used as function arguments.

??

Input_TM is a 9*9 matrix

Constr_new is a 120*81 matrix

x_than0 is a 120*1 matrix

aeq2 is a 17*81 matrix

beq2 is a 17*1 matrix

??

Below is the error I am getting :

??

R> ??opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new, B=-x_than0, Aeq=as.matrix(aeq2), Beq=beq2, lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX = 0)

Error in as.matrix(A %*% Xtarget) - matrix(B, ncol = 1) :

??non-conformable arrays

Calls: solnl -> rbind -> rbind

In addition: Warning message:

In rbind(rbind(lbright, ubright), B) :

? number of columns of result is not a multiple of vector length (arg 2)

Calls: solnl -> rbind

??

Enter a frame number, or 0 to exit??

??

1: solnl(X = c(InputTM), objfun = obj_F, A = -constr_new, B = -x_than0, Aeq = as.matrix(aeq2), Beq = beq2, lb =

2: rbind(rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A %*% Xtarget) - matrix(B, ncol = 1)), a

3: rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A %*% Xtarget) - matrix(B, ncol = 1))

??

??

??

Can you kindly help with this? I am mostly sure that the constraint matrices have been correctly formulated. Am I going wrong with the way I am specifying the arguments?

Thanks a lot for any help any of you can offer.

??

Thanks and Regards,

Aveek Mukhopadhyay




<!--#yiv2239857533 _filtered #yiv2239857533 {font-family:"Cambria Math";panose-1:2 4 5 3 5 4 6 3 2 4;} _filtered #yiv2239857533 {font-family:Calibri;panose-1:2 15 5 2 2 2 4 3 2 4;} _filtered #yiv2239857533 {font-family:"Lucida Console";panose-1:2 11 6 9 4 5 4 2 2 4;}#yiv2239857533 #yiv2239857533 p.yiv2239857533MsoNormal, #yiv2239857533 li.yiv2239857533MsoNormal, #yiv2239857533 div.yiv2239857533MsoNormal {margin:0in;margin-bottom:.0001pt;font-size:11.0pt;font-family:"Calibri", sans-serif;}#yiv2239857533 a:link, #yiv2239857533 span.yiv2239857533MsoHyperlink {color:#0563C1;text-decoration:underline;}#yiv2239857533 a:visited, #yiv2239857533 span.yiv2239857533MsoHyperlinkFollowed {color:#954F72;text-decoration:underline;}#yiv2239857533 pre {margin:0in;margin-bottom:.0001pt;font-size:10.0pt;font-family:"Courier New";}#yiv2239857533 span.yiv2239857533HTMLPreformattedChar {font-family:"Courier New";}#yiv2239857533 span.yiv2239857533EmailStyle19 {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533 span.yiv2239857533gnkrckgcmsb {}#yiv2239857533 span.yiv2239857533gnkrckgcmrb {}#yiv2239857533 span.yiv2239857533gnkrckgcasb {}#yiv2239857533 span.yiv2239857533gnkrckgcgsb {}#yiv2239857533 span.yiv2239857533EmailStyle24 {font-family:"Calibri", sans-serif;color:#1F497D;}#yiv2239857533 span.yiv2239857533EmailStyle25 {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533 .yiv2239857533MsoChpDefault {font-size:10.0pt;} _filtered #yiv2239857533 {margin:1.0in 1.0in 1.0in 1.0in;}#yiv2239857533 div.yiv2239857533WordSection1 {}-->? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
  

	[[alternative HTML version deleted]]


From @veekm @ending from y@hoo@co@in  Mon Jan 14 10:36:26 2019
From: @veekm @ending from y@hoo@co@in (aveek)
Date: Mon, 14 Jan 2019 09:36:26 +0000 (UTC)
Subject: [R] CRAN package NlcOptim query
In-Reply-To: <CAGgJW75nPMiuVyGmAgJiYecZazzvxTRY0DzLVBs77K=28J2tJA@mail.gmail.com>
References: <afe5c2e520d942adbcceff37f7ea7a01@INW20010891.ADRES.HSBC>
 <2000317032.1615237.1543918890940@mail.yahoo.com>
 <456046261.2086478.1544523285070@mail.yahoo.com>
 <CAGgJW75Xo-XOZO2qOniUseaLaM591F7DJGsVN56=F5Eors3xkg@mail.gmail.com>
 <1691260324.2450334.1544597054487@mail.yahoo.com>
 <436554644.16933243.1547454674292@mail.yahoo.com>
 <CAGgJW75nPMiuVyGmAgJiYecZazzvxTRY0DzLVBs77K=28J2tJA@mail.gmail.com>
Message-ID: <137525674.17012951.1547458586022@mail.yahoo.com>

Hi Eric,
Yes, in fact I did mention in my 1st email that I am posting this here as the package maintainer did not respond even after a couple of emails.
Thanks,Aveek

Sent from Yahoo Mail on Android 
 
  On Mon, Jan 14, 2019 at 2:11 PM, Eric Berger<ericjberger at gmail.com> wrote:   Aveek,Did you try contacting the package maintainer as Hans suggested?


On Mon, Jan 14, 2019 at 10:31 AM aveek <aveekm at yahoo.co.in> wrote:

Hello,
Can anyone plz help with the below problem??
Thanks,Aveek

Sent from Yahoo Mail on Android 
 
  On Wed, Dec 12, 2018 at 12:14 PM, aveek<aveekm at yahoo.co.in> wrote:   
Hello Eric,

Thanks for your response and suggestions.?

I have used dput() on the R objects - sharing below so that it is possible for anyone to recreate the situation.

I have still kept it as a 9*9 matrix but for simplicity we now only have 2 equality and 2 non equality constraints.

Thanks again for your help.

InputTM


structure(c(0.813231189406663, 0.0199464964676128, 0.00100552815128915,

0.000465771436428336, 0.000736922016196076, 0.00203037431732662,

0.000596998285890709, 0.0011699714577823, 0, 0.103116692172408,

0.751775368068589, 0.0160957427707042, 0.00285542569941823, 0.0020295541916448,

0.00954562743564027, 0.00173399818906894, 0.00292299139663608,

0, 0.0481959576543631, 0.177032393868544, 0.811609524051149,

0.146703962329218, 0.0698423269415636, 0.168241524872922, 0.0505757280338206,

0.0324917017565673, 0, 0.026504623193874, 0.038430496838613,

0.134709744786799, 0.758322716164413, 0.176013939161559, 0.234265359508999,

0.108188555487004, 0.0476663548325017, 0, 0.00520614395937929,

0.00868690292550468, 0.0223895752360805, 0.0581458712447338,

0.681496895121054, 0.0733970775224908, 0.0508491985259732, 0.0268876385360338,

0, 0.000749001395622802, 0.00181690494827145, 0.00317194515883476,

0.00705434604769267, 0.0211989316284324, 0.464732208379131, 0.0165146818291576,

0.00721872506710652, 0, 0.000960493069403903, 0.00138444384054219,

0.00703528202498607, 0.0163983255053438, 0.0301780379843763,

0.0280699612529658, 0.491157627745315, 0.0235353949469527, 0,

0.00112628575287418, 0.000477300396419488, 0.00223238360574478,

0.00521558462566306, 0.00925149338117537, 0.00878272484051914,

0.163654071683595, 0.611806567272906, 0, 0.000909613395411595,

0.000449692645903539, 0.00175027421441265, 0.00483799694708872,

0.00925189957399783, 0.0109351418700064, 0.116729140220175, 0.246300654733514,

1), .Dim = c(9L, 9L))

?

?

Constr_new

structure(c(1, 0, -1, 1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(2L,

81L), .Dimnames = list(NULL, c("X11", "X12", "X13", "X14", "X15",

"X16", "X17", "X18", "X19", "X21", "X22", "X23", "X24", "X25",

"X26", "X27", "X28", "X29", "X31", "X32", "X33", "X34", "X35",

"X36", "X37", "X38", "X39", "X41", "X42", "X43", "X44", "X45",

"X46", "X47", "X48", "X49", "X51", "X52", "X53", "X54", "X55",

"X56", "X57", "X58", "X59", "X61", "X62", "X63", "X64", "X65",

"X66", "X67", "X68", "X69", "X71", "X72", "X73", "X74", "X75",

"X76", "X77", "X78", "X79", "X81", "X82", "X83", "X84", "X85",

"X86", "X87", "X88", "X89", "X91", "X92", "X93", "X94", "X95",

"X96", "X97", "X98", "X99")))

?

?

x_than0

c(1e-04, 1e-04)

?

aeq2

structure(list(X1 = c(1, 0), X2 = c(1, 0), X3 = c(1, 0), X4 = c(1,

0), X5 = c(1, 0), X6 = c(1, 0), X7 = c(1, 0), X8 = c(1, 0), X9 = c(1,

0), X10 = c(0, 1), X11 = c(0, 1), X12 = c(0, 1), X13 = c(0, 1

), X14 = c(0, 1), X15 = c(0, 1), X16 = c(0, 1), X17 = c(0, 1),

????X18 = c(0, 1), X19 = c(0, 0), X20 = c(0, 0), X21 = c(0, 0

??? ), X22 = c(0, 0), X23 = c(0, 0), X24 = c(0, 0), X25 = c(0,

????0), X26 = c(0, 0), X27 = c(0, 0), X28 = c(0, 0), X29 = c(0,

????0), X30 = c(0, 0), X31 = c(0, 0), X32 = c(0, 0), X33 = c(0,

????0), X34 = c(0, 0), X35 = c(0, 0), X36 = c(0, 0), X37 = c(0,

????0), X38 = c(0, 0), X39 = c(0, 0), X40 = c(0, 0), X41 = c(0,

????0), X42 = c(0, 0), X43 = c(0, 0), X44 = c(0, 0), X45 = c(0,

????0), X46 = c(0, 0), X47 = c(0, 0), X48 = c(0, 0), X49 = c(0,

????0), X50 = c(0, 0), X51 = c(0, 0), X52 = c(0, 0), X53 = c(0,

????0), X54 = c(0, 0), X55 = c(0, 0), X56 = c(0, 0), X57 = c(0,

????0), X58 = c(0, 0), X59 = c(0, 0), X60 = c(0, 0), X61 = c(0,

????0), X62 = c(0, 0), X63 = c(0, 0), X64 = c(0, 0), X65 = c(0,

????0), X66 = c(0, 0), X67 = c(0, 0), X68 = c(0, 0), X69 = c(0,

????0), X70 = c(0, 0), X71 = c(0, 0), X72 = c(0, 0), X73 = c(0,

????0), X74 = c(0, 0), X75 = c(0, 0), X76 = c(0, 0), X77 = c(0,

????0), X78 = c(0, 0), X79 = c(0, 0), X80 = c(0, 0), X81 = c(0,

????0)), .Names = c("X1", "X2", "X3", "X4", "X5", "X6", "X7",

"X8", "X9", "X10", "X11", "X12", "X13", "X14", "X15", "X16",

"X17", "X18", "X19", "X20", "X21", "X22", "X23", "X24", "X25",

"X26", "X27", "X28", "X29", "X30", "X31", "X32", "X33", "X34",

"X35", "X36", "X37", "X38", "X39", "X40", "X41", "X42", "X43",

"X44", "X45", "X46", "X47", "X48", "X49", "X50", "X51", "X52",

"X53", "X54", "X55", "X56", "X57", "X58", "X59", "X60", "X61",

"X62", "X63", "X64", "X65", "X66", "X67", "X68", "X69", "X70",

"X71", "X72", "X73", "X74", "X75", "X76", "X77", "X78", "X79",

"X80", "X81"), row.names = 1:2, class = "data.frame")

?

beq2

c(1, 1)




Regards,

Aveek

Sent from Yahoo Mail on Android 
 
  On Tue, Dec 11, 2018 at 6:25 PM, Eric Berger<ericjberger at gmail.com> wrote:   Hi Aveek,1. This is an "all-text" mailing list. Your attachment did not come through.?? ? You can check out the posting guide (see the link at the bottom of your email)?? ? ?and/or??? ? ?use dput(...) on your structures and paste them into your email so that members of the list can try to reproduce the problem.2. One way to check out whether you are using a package correctly is to try a tiny example that you can calculate by hand, and see if you can reproduce the solution via the package.? ? e.g. instead of a 9x9 matrix (hence 81 dimensional problem in your case), try a 2x2 matrix with maybe just one or two constraints.?
HTH,Eric
On Tue, Dec 11, 2018 at 1:18 PM aveek via R-help <r-help at r-project.org> wrote:

Hi All,
I am facing an issue with an optimization problem which I am trying to solve using NlcOptim package in R. I have tried reaching out to the package maintainer but not received any response, hence posting this here.?


Below is the code snippet I am using:

??

#Optimization

? obj_F <- function(vect_mat){

??? return (sum((c(InputTM) - vect_mat)^2))

? }

? 

??numel = nrow(InputTM)*ncol(InputTM)

? opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new, B=-x_than0, Aeq=as.matrix(aeq2), Beq=beq2, lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX = 0)

??

I am attaching in the email the data being used as function arguments.

??

Input_TM is a 9*9 matrix

Constr_new is a 120*81 matrix

x_than0 is a 120*1 matrix

aeq2 is a 17*81 matrix

beq2 is a 17*1 matrix

??

Below is the error I am getting :

??

R> ??opt_vect = solnl(X=c(InputTM), objfun=obj_F, A=-constr_new, B=-x_than0, Aeq=as.matrix(aeq2), Beq=beq2, lb=c(rep(0,numel)),ub=c(rep(1,numel)),tolX = 0)

Error in as.matrix(A %*% Xtarget) - matrix(B, ncol = 1) :

??non-conformable arrays

Calls: solnl -> rbind -> rbind

In addition: Warning message:

In rbind(rbind(lbright, ubright), B) :

? number of columns of result is not a multiple of vector length (arg 2)

Calls: solnl -> rbind

??

Enter a frame number, or 0 to exit??

??

1: solnl(X = c(InputTM), objfun = obj_F, A = -constr_new, B = -x_than0, Aeq = as.matrix(aeq2), Beq = beq2, lb =

2: rbind(rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A %*% Xtarget) - matrix(B, ncol = 1)), a

3: rbind(rbind(Aeq %*% Xtarget - Beq, as.matrix(nceq)), as.matrix(A %*% Xtarget) - matrix(B, ncol = 1))

??

??

??

Can you kindly help with this? I am mostly sure that the constraint matrices have been correctly formulated. Am I going wrong with the way I am specifying the arguments?

Thanks a lot for any help any of you can offer.

??

Thanks and Regards,

Aveek Mukhopadhyay




<!--#yiv2239857533 _filtered #yiv2239857533 {font-family:"Cambria Math";panose-1:2 4 5 3 5 4 6 3 2 4;} _filtered #yiv2239857533 {font-family:Calibri;panose-1:2 15 5 2 2 2 4 3 2 4;} _filtered #yiv2239857533 {font-family:"Lucida Console";panose-1:2 11 6 9 4 5 4 2 2 4;}#yiv2239857533 #yiv2239857533 p.yiv2239857533MsoNormal, #yiv2239857533 li.yiv2239857533MsoNormal, #yiv2239857533 div.yiv2239857533MsoNormal {margin:0in;margin-bottom:.0001pt;font-size:11.0pt;font-family:"Calibri", sans-serif;}#yiv2239857533 a:link, #yiv2239857533 span.yiv2239857533MsoHyperlink {color:#0563C1;text-decoration:underline;}#yiv2239857533 a:visited, #yiv2239857533 span.yiv2239857533MsoHyperlinkFollowed {color:#954F72;text-decoration:underline;}#yiv2239857533 pre {margin:0in;margin-bottom:.0001pt;font-size:10.0pt;font-family:"Courier New";}#yiv2239857533 span.yiv2239857533HTMLPreformattedChar {font-family:"Courier New";}#yiv2239857533 span.yiv2239857533EmailStyle19 {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533 span.yiv2239857533gnkrckgcmsb {}#yiv2239857533 span.yiv2239857533gnkrckgcmrb {}#yiv2239857533 span.yiv2239857533gnkrckgcasb {}#yiv2239857533 span.yiv2239857533gnkrckgcgsb {}#yiv2239857533 span.yiv2239857533EmailStyle24 {font-family:"Calibri", sans-serif;color:#1F497D;}#yiv2239857533 span.yiv2239857533EmailStyle25 {font-family:"Calibri", sans-serif;color:windowtext;}#yiv2239857533 .yiv2239857533MsoChpDefault {font-size:10.0pt;} _filtered #yiv2239857533 {margin:1.0in 1.0in 1.0in 1.0in;}#yiv2239857533 div.yiv2239857533WordSection1 {}-->? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
  

  

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Mon Jan 14 15:15:36 2019
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Mon, 14 Jan 2019 14:15:36 +0000
Subject: [R] importing data error question
In-Reply-To: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
Message-ID: <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>

Dear jihee,

> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
> 
>  
>  
> From: "???" <wjh1518 at ht.co.kr>
> Sent: Monday, January 14, 2019 9:40:26 AM
> To:"Fox, John" <jfox at mcmaster.ca>
> Subject:Re: [R] importing data error question
>  
>  
> Thanks for your replies.
>  
> I'm using windows 7, I loaded FactoMineR,

You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.

> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
> This problem occurred when I select Data > Import data > From Excel file.
> I checked FactoMineR and SensoMineR packages are loaded and using..

You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.

Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 

It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?

Best,
 John

>  
>  
>  
> From: "Fox, John" <jfox at mcmaster.ca>
> Sent: Friday, January 11, 2019 10:48:38 PM
> To:"PIKAL Petr" <petr.pikal at precheza.cz>
> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
> Subject:Re: [R] importing data error question
>  
>  
> Dear Petr and jihee,
> 
> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
> 
> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
> 
> Best,
> John
> 
> -------------------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: http::/socserv.mcmaster.ca/jfox
> 
> > On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > 
> > Hi
> > 
> > I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> > 
> > So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> > 
> > Cheers
> > Petr
> > 
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> >> Sent: Friday, January 11, 2019 9:14 AM
> >> To: r-help at R-project.org
> >> Subject: [R] importing data error question
> >> 
> >> Hi I'm jihee and I have a question about error...
> >> 
> >> I'm using R 3.5.2 and tried to use Rcmdr package.
> >> 
> >> and using FactoMineR and SensoMineR to analyze sensory data through PCA
> >> 
> >> but i can't import excel data with Rcmdr.
> >> 
> >> it has this messege :
> >> 
> >> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> >> [tcl] bad Macintosh file type "?*?"
> >> 
> >> what is wrong with my R??? T_T
> >> 
> >> Thanks for your help.
> >> 
> >> jihee.
> >> [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 


From wjm1 @ending from c@@@columbi@@edu  Mon Jan 14 23:28:53 2019
From: wjm1 @ending from c@@@columbi@@edu (William Michels)
Date: Mon, 14 Jan 2019 14:28:53 -0800
Subject: [R] loading the xlsx library
In-Reply-To: <c8d9e037-24ae-6406-e942-2098e13216a1@sapo.pt>
References: <1661340430.327833.1547232045654@connect.xfinity.com>
 <17AC247F-108D-4A56-9178-DB41CA66A3EA@dcn.davis.ca.us>
 <c8d9e037-24ae-6406-e942-2098e13216a1@sapo.pt>
Message-ID: <CAA99HCy46POstFNUTazsZZ9hxj+U52UdoogeH1pzXQr=CX52xQ@mail.gmail.com>

Hello Bernard,

You might consider using the "readxl" package, which (from the package
description), "Works on Windows, Mac and Linux without external
dependencies."

 https://CRAN.R-project.org/package=readxl

HTH, Bill.

William Michels, Ph.D.


From wjh1518 @ending from ht@co@kr  Tue Jan 15 03:00:48 2019
From: wjh1518 @ending from ht@co@kr (=?utf-8?B?7Jqw7KeA7Z2s?=)
Date: Tue, 15 Jan 2019 11:00:48 +0900
Subject: [R] importing data error question
In-Reply-To: <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
Message-ID: <5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>

You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 

--> no, I never said i was using a Mac. 

You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 

--> sessionInfo()
 R version 3.5.2 (2018-12-20)
 Platform: x86_64-w64-mingw32/x64 (64-bit)
 Running under: Windows 7 x64 (build 7601) Service Pack 1

 Matrix products: default

 locale:
 [1] LC_COLLATE=Korean_Korea.949? LC_CTYPE=Korean_Korea.949? ?
 [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C? ? ? ? ? ? ? ??
 [5] LC_TIME=Korean_Korea.949? ??

 attached base packages:
 [1] tcltk? ? ?splines? ?stats? ? ?graphics? grDevices utils? ? ?datasets? methods??
 [9] base? ? ?

 other attached packages:
 ?[1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0??
 ?[3] Rcmdr_2.5-1? ? ? ? ? ? ? ? ? ? effects_4.1-0? ? ? ? ? ? ? ? ?
 ?[5] RcmdrMisc_2.5-1? ? ? ? ? ? ? ? sandwich_2.5-0? ? ? ? ? ? ? ??
 ?[7] car_3.0-2? ? ? ? ? ? ? ? ? ? ? carData_3.0-2? ? ? ? ? ? ? ? ?
 ?[9] SensoMineR_1.23? ? ? ? ? ? ? ? FactoMineR_1.41? ? ? ? ? ? ? ?

 loaded via a namespace (and not attached):
 ?[1] gtools_3.8.1? ? ? ? ?Formula_1.2-3? ? ? ? latticeExtra_0.6-28?
 ?[4] cellranger_1.1.0? ? ?pillar_1.3.1? ? ? ? ?backports_1.1.3? ? ?
 ?[7] lattice_0.20-38? ? ? digest_0.6.18? ? ? ? RColorBrewer_1.1-2??
 [10] checkmate_1.8.5? ? ? minqa_1.2.4? ? ? ? ? colorspace_1.3-2? ??
 [13] survey_3.35? ? ? ? ? htmltools_0.3.6? ? ? Matrix_1.2-15? ? ? ?
 [16] plyr_1.8.4? ? ? ? ? ?pkgconfig_2.0.2? ? ? haven_2.0.0? ? ? ? ?
 [19] scales_1.0.0? ? ? ? ?openxlsx_4.1.0? ? ? ?rio_0.5.16? ? ? ? ??
 [22] lme4_1.1-19? ? ? ? ? htmlTable_1.13.1? ? ?tibble_1.4.2? ? ? ??
 [25] relimp_1.0-5? ? ? ? ?ggplot2_3.1.0? ? ? ? nnet_7.3-12? ? ? ? ?
 [28] lazyeval_0.2.1? ? ? ?survival_2.43-3? ? ? magrittr_1.5? ? ? ??
 [31] crayon_1.3.4? ? ? ? ?readxl_1.2.0? ? ? ? ?nlme_3.1-137? ? ? ??
 [34] MASS_7.3-51.1? ? ? ? forcats_0.3.0? ? ? ? foreign_0.8-71? ? ??
 [37] class_7.3-14? ? ? ? ?tools_3.5.2? ? ? ? ? data.table_1.11.8? ?
 [40] hms_0.4.2? ? ? ? ? ? tcltk2_1.2-11? ? ? ? stringr_1.3.1? ? ? ?
 [43] munsell_0.5.0? ? ? ? cluster_2.0.7-1? ? ? zip_1.0.0? ? ? ? ? ?
 [46] flashClust_1.01-2? ? compiler_3.5.2? ? ? ?e1071_1.7-0? ? ? ? ?
 [49] rlang_0.3.1? ? ? ? ? grid_3.5.2? ? ? ? ? ?nloptr_1.2.1? ? ? ??
 [52] rstudioapi_0.9.0? ? ?htmlwidgets_1.3? ? ? leaps_3.0? ? ? ? ? ?
 [55] base64enc_0.1-3? ? ? gtable_0.2.0? ? ? ? ?abind_1.4-5? ? ? ? ?
 [58] curl_3.2? ? ? ? ? ? ?reshape2_1.4.3? ? ? ?AlgDesign_1.1-7.3? ?
 [61] gridExtra_2.3? ? ? ? zoo_1.8-4? ? ? ? ? ? knitr_1.21? ? ? ? ??
 [64] nortest_1.0-4? ? ? ? Hmisc_4.1-1? ? ? ? ? KernSmooth_2.23-15??
 [67] stringi_1.2.4? ? ? ? Rcpp_1.0.0? ? ? ? ? ?rpart_4.1-13? ? ? ??
 [70] acepack_1.4.1? ? ? ? scatterplot3d_0.3-41 xfun_0.4? ? ? ? ? ??

This was the status that I tried to import Excel data. 

Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?? 

--> I tried without plug-in packages, but It didn't work. 

 It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 

--> I don't know what is plain-text data file..... 

i'll try R with English. 

From:  "Fox, John" <jfox at mcmaster.ca> 

Sent: Monday, January 14, 2019 11:15:36 PM 

To:"???" <wjh1518 at ht.co.kr> 

Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 

Subject:Re: [R] importing data error question 

?  Dear jihee,

  > On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
  > 
  > 
  > 
  > From: "???" <wjh1518 at ht.co.kr>
  > Sent: Monday, January 14, 2019 9:40:26 AM
  > To:"Fox, John" <jfox at mcmaster.ca>
  > Subject:Re: [R] importing data error question
  > 
  > 
  > Thanks for your replies.
  > 
  > I'm using windows 7, I loaded FactoMineR,

 You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.

  > SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
  > This problem occurred when I select Data > Import data > From Excel file.
  > I checked FactoMineR and SensoMineR packages are loaded and using..

  You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.

  Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 

  It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?

  Best,
  John

  > 
  > 
  > 
  > From: "Fox, John" <jfox at mcmaster.ca>
  > Sent: Friday, January 11, 2019 10:48:38 PM
  > To:"PIKAL Petr" <petr.pikal at precheza.cz>
  > Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
  > Subject:Re: [R] importing data error question
  > 
  > 
  > Dear Petr and jihee,
  > 
  > The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
  > 
  > So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
  > 
  > Best,
  > John
  > 
  > -------------------------------------------------
  > John Fox, Professor Emeritus
  > McMaster University
  > Hamilton, Ontario, Canada
  > Web: http::/socserv.mcmaster.ca/jfox
  > 
  > > On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
  > > 
  > > Hi
  > > 
  > > I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
  > > 
  > > So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
  > > 
  > > Cheers
  > > Petr
  > > 
  > >> -----Original Message-----
  > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
  > >> Sent: Friday, January 11, 2019 9:14 AM
  > >> To: r-help at R-project.org
  > >> Subject: [R] importing data error question
  > >> 
  > >> Hi I'm jihee and I have a question about error...
  > >> 
  > >> I'm using R 3.5.2 and tried to use Rcmdr package.
  > >> 
  > >> and using FactoMineR and SensoMineR to analyze sensory data through PCA
  > >> 
  > >> but i can't import excel data with Rcmdr.
  > >> 
  > >> it has this messege :
  > >> 
  > >> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
  > >> [tcl] bad Macintosh file type "?*?"
  > >> 
  > >> what is wrong with my R??? T_T
  > >> 
  > >> Thanks for your help.
  > >> 
  > >> jihee.
  > >> [[alternative HTML version deleted]]
  > >> 
  > >> ______________________________________________
  > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
  > >> https://stat.ethz.ch/mailman/listinfo/r-help
  > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
  > >> and provide commented, minimal, self-contained, reproducible code.
  > > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
  > > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
  > > 
  > > ______________________________________________
  > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
  > > https://stat.ethz.ch/mailman/listinfo/r-help
  > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
  > > and provide commented, minimal, self-contained, reproducible code.
  > 
  > 
  > 
  > 
  > ??? ??? / ??????
  > e-mailwjh1518 at ht.co.krDirMobile
  > ????www.ht.co.kr????www.facebook.com/haitaico
  > Address????? ??? ???? 72? 3 (???) ??????(?) 04352
  > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
  > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
  > 
  > 
  > 
  > 
  > ??? ??? / ??????
  > e-mailwjh1518 at ht.co.krDirMobile
  > ????www.ht.co.kr????www.facebook.com/haitaico
  > Address????? ??? ???? 72? 3 (???) ??????(?) 04352
  > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
  > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Tue Jan 15 05:36:44 2019
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Tue, 15 Jan 2019 04:36:44 +0000
Subject: [R] importing data error question
In-Reply-To: <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
Message-ID: <06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>

Dear jihee,

> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> 
> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
> 
> --> no, I never said i was using a Mac. 

Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.

> 
> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
> 
> --> sessionInfo()
> R version 3.5.2 (2018-12-20)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=Korean_Korea.949  LC_CTYPE=Korean_Korea.949   
> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C                
> [5] LC_TIME=Korean_Korea.949    
> 
> attached base packages:
> [1] tcltk     splines   stats     graphics  grDevices utils     datasets  methods  
> [9] base     
> 
> other attached packages:
>  [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
>  [3] Rcmdr_2.5-1                    effects_4.1-0                 
>  [5] RcmdrMisc_2.5-1                sandwich_2.5-0                
>  [7] car_3.0-2                      carData_3.0-2                 
>  [9] SensoMineR_1.23                FactoMineR_1.41               
> 
> loaded via a namespace (and not attached):
>  [1] gtools_3.8.1         Formula_1.2-3        latticeExtra_0.6-28 
>  [4] cellranger_1.1.0     pillar_1.3.1         backports_1.1.3     
>  [7] lattice_0.20-38      digest_0.6.18        RColorBrewer_1.1-2  
> [10] checkmate_1.8.5      minqa_1.2.4          colorspace_1.3-2    
> [13] survey_3.35          htmltools_0.3.6      Matrix_1.2-15       
> [16] plyr_1.8.4           pkgconfig_2.0.2      haven_2.0.0         
> [19] scales_1.0.0         openxlsx_4.1.0       rio_0.5.16          
> [22] lme4_1.1-19          htmlTable_1.13.1     tibble_1.4.2        
> [25] relimp_1.0-5         ggplot2_3.1.0        nnet_7.3-12         
> [28] lazyeval_0.2.1       survival_2.43-3      magrittr_1.5        
> [31] crayon_1.3.4         readxl_1.2.0         nlme_3.1-137        
> [34] MASS_7.3-51.1        forcats_0.3.0        foreign_0.8-71      
> [37] class_7.3-14         tools_3.5.2          data.table_1.11.8   
> [40] hms_0.4.2            tcltk2_1.2-11        stringr_1.3.1       
> [43] munsell_0.5.0        cluster_2.0.7-1      zip_1.0.0           
> [46] flashClust_1.01-2    compiler_3.5.2       e1071_1.7-0         
> [49] rlang_0.3.1          grid_3.5.2           nloptr_1.2.1        
> [52] rstudioapi_0.9.0     htmlwidgets_1.3      leaps_3.0           
> [55] base64enc_0.1-3      gtable_0.2.0         abind_1.4-5         
> [58] curl_3.2             reshape2_1.4.3       AlgDesign_1.1-7.3   
> [61] gridExtra_2.3        zoo_1.8-4            knitr_1.21          
> [64] nortest_1.0-4        Hmisc_4.1-1          KernSmooth_2.23-15  
> [67] stringi_1.2.4        Rcpp_1.0.0           rpart_4.1-13        
> [70] acepack_1.4.1        scatterplot3d_0.3-41 xfun_0.4            
> 
> This was the status that I tried to import Excel data. 

These packages seem up-to-date.

> 
> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
> 
> --> I tried without plug-in packages, but It didn't work. 

OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.

> 
> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
> 
> --> I don't know what is plain-text data file..... 

A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.

> 
> i'll try R with English. 

I'm curious to see what happens.

Best,
 John

> 
> From:  "Fox, John" <jfox at mcmaster.ca> 
> 
> Sent: Monday, January 14, 2019 11:15:36 PM 
> 
> To:"???" <wjh1518 at ht.co.kr> 
> 
> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
> 
> Subject:Re: [R] importing data error question 
> 
>    Dear jihee,
> 
>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
>> 
>> 
>> 
>> From: "???" <wjh1518 at ht.co.kr>
>> Sent: Monday, January 14, 2019 9:40:26 AM
>> To:"Fox, John" <jfox at mcmaster.ca>
>> Subject:Re: [R] importing data error question
>> 
>> 
>> Thanks for your replies.
>> 
>> I'm using windows 7, I loaded FactoMineR,
> 
> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
> 
>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
>> This problem occurred when I select Data > Import data > From Excel file.
>> I checked FactoMineR and SensoMineR packages are loaded and using..
> 
>  You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
> 
>  Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
> 
>  It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
> 
>  Best,
>  John
> 
>> 
>> 
>> 
>> From: "Fox, John" <jfox at mcmaster.ca>
>> Sent: Friday, January 11, 2019 10:48:38 PM
>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
>> Subject:Re: [R] importing data error question
>> 
>> 
>> Dear Petr and jihee,
>> 
>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
>> 
>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
>> 
>> Best,
>> John
>> 
>> -------------------------------------------------
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: http::/socserv.mcmaster.ca/jfox
>> 
>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>> 
>>> Hi
>>> 
>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
>>> 
>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
>>> 
>>> Cheers
>>> Petr
>>> 
>>>> -----Original Message-----
>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
>>>> Sent: Friday, January 11, 2019 9:14 AM
>>>> To: r-help at R-project.org
>>>> Subject: [R] importing data error question
>>>> 
>>>> Hi I'm jihee and I have a question about error...
>>>> 
>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
>>>> 
>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
>>>> 
>>>> but i can't import excel data with Rcmdr.
>>>> 
>>>> it has this messege :
>>>> 
>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>>> [tcl] bad Macintosh file type "?*?"
>>>> 
>>>> what is wrong with my R??? T_T
>>>> 
>>>> Thanks for your help.
>>>> 
>>>> jihee.
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> ??? ??? / ??????
>> e-mailwjh1518 at ht.co.krDirMobile
>> ????www.ht.co.kr????www.facebook.com/haitaico
>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
>> 
>> 
>> 
>> 
>> ??? ??? / ??????
>> e-mailwjh1518 at ht.co.krDirMobile
>> ????www.ht.co.kr????www.facebook.com/haitaico
>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @igbert @ending from wiwi@hu-berlin@de  Tue Jan 15 09:52:49 2019
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Tue, 15 Jan 2019 09:52:49 +0100
Subject: [R] do.call, browser and traceback
In-Reply-To: <f8e6ff050602231139l5fece06bmcf40d7887b9df207@mail.gmail.com>
References: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
 <Pine.LNX.4.64.0602231857360.10209@gannet.stats.ox.ac.uk>
 <f8e6ff050602231139l5fece06bmcf40d7887b9df207@mail.gmail.com>
Message-ID: <8fe244cc-f48f-bad1-413e-a74706b60444@wiwi.hu-berlin.de>

Hi,

I run in the same problem, as discussed in 2006. Is there any solution 
by now?

Sigbert

Am 23.02.06 um 20:39 schrieb hadley wickham:
>> Did you mean that?  Both are errors.  Perhaps
>>
>> f <- function(...) browser()
>> do.call(f, mtcars)
> 
> Sorry, yes, that is what I meant.
> 
>> What is being used is
>>
>>          Rprintf("Called from: ");
>>          PrintValueRec(cptr->call,rho);
>>
>> in src/main/main.c.  We could certainly allow an option to limit the
>> deparse length, but I have to say that quite often the useful information
>> is well down the list of arguments.  There is currently no user control.
> 
> It would be nice to have some user control - I find the first 100
> characters or so is usually sufficient, especially when the real
> problem is further down the stack.  It is a real pain when you have
> used do.call with a 10,000 row dataframe - and then it is basically
> impossible to find the problem by manual inspection anyway.  Even
> limiting to 1000 characters would be a big improvement.
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From hwborcher@ @ending from gm@il@com  Tue Jan 15 12:48:22 2019
From: hwborcher@ @ending from gm@il@com (Hans W Borchers)
Date: Tue, 15 Jan 2019 12:48:22 +0100
Subject: [R] CRAN package NlcOptim query
In-Reply-To: <CAML4n3P0w_fb+51vPco5Lv9R80iVMjsDL4MtWLCNo6=Ly+Qtkw@mail.gmail.com>
References: <CAML4n3P0w_fb+51vPco5Lv9R80iVMjsDL4MtWLCNo6=Ly+Qtkw@mail.gmail.com>
Message-ID: <CAML4n3PW1RsVxWRq8VHvYCauhcWu+NrBZVR3ipg0WoqV1NU7zw@mail.gmail.com>

To be corrected:
`Constr_new` with a capital letter;
`aeq2` is a list, should be a matrix.

As I said last month, you can yourself combine inequality constraints
with bounds constraints as follows:

    myA <- rbind(-Constr_new, diag(-1,numel), diag(1,numel))
    myB <- c(-x_than0, rep(0,numel), rep(1,numel))

and `solnl` will return a result like this:

    sol <- NlcOptim::solnl(X = c(InputTM), objfun = obj_F, A = myA, B = myB,
                           Aeq = as.matrix(aeq2), Beq = beq2)
    c(sol$par)
    [1] 0.8310997170, 0.0378150241, ..., 0.2463006547, 1.0000000000
    sol$fn
    [1] 0.00421616

I will write to the maintainer asking about why this example does not
work --  supplying functioning code, maybe that will trigger a
response.

Hans Werner

Please note: You are sending e-mail in HTML format which makes it
almost impossible to use as code in the R console.

On Wed, Dec 12, 2018 at 12:45 PM Hans W Borchers <hwborchers at gmail.com> wrote:
>
> This is still not complete: `x_than0` is missing.
> `Constr_new` is written with a capital 'C'.
> And aeq2 is a list of column vectors, not a matrix.
> Setting the tolerance to 0 does not seem to be a good idea.
>
> Making aeq2 a matrix and adding `x_than0 <- matrix(c(1, 1))`, then
>
>     aeq2 <- as.matrix(aeq2)
>     x_than0 <- matrix(c(1, 1))
>
>     NlcOptim::solnl(X=c(InputTM), objfun=obj_F, A=-Constr_new, B=-x_than0,
>                 Aeq=as.matrix(aeq2), Beq=beq2,
>                 lb=c(rep(0,numel)),ub=c(rep(1,numel)), tolX = 0)
>
> will indeed return in the same error, while it runs without error if you
> either leave out the inequality constraints or the bounds constraints. So
> I guess there may be a bug when the function internally combines these
> constraints and the bounds.
>
> You could / should write to the maintainer. I know he is very responsive.
>
> For the moment, you can combine the bounds constraints and the lower and
> upper bounds yourself:
>
>     myA <- rbind(-Constr_new, diag(-1,numel), diag(1,numel))
>     myB <- c(-x_than0, rep(0,numel), rep(1,numel))
>
>     NlcOptim::solnl(X=c(InputTM), objfun=obj_F, A=myA, B=myB,
>                     Aeq=as.matrix(aeq2), Beq=beq2)
>
> returns "constraints are inconsistent, no solution!", but that may be the
> case because I don't know your `x_than` value.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 15 17:35:51 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 15 Jan 2019 08:35:51 -0800
Subject: [R] [R-sig-ME] Calculating F values for lme function
In-Reply-To: <91a67ac76c3d1abbb3d76f5fa5853e0c@ucr.ac.cr>
References: <b576d62b04e705c87c535aaa372352d1@ucr.ac.cr>
 <06823a0dae02c1d88c331ae1ecf2e403@ucr.ac.cr>
 <38D362F2-9510-4E20-A995-4EDB8417321C@dcn.davis.ca.us>
 <91a67ac76c3d1abbb3d76f5fa5853e0c@ucr.ac.cr>
Message-ID: <D02BF4F3-2A81-4C67-885C-07CBE2EE2CC7@dcn.davis.ca.us>

You should use Reply-All to make sure the discussion continues to include the mailing list.

Have you looked at the help for lme?

lme is non-trivial, so it may take some reading. I only have a few of the references listed in the help file, and none with me at the moment.

On January 15, 2019 7:36:22 AM PST, RICARDO ALVARADO BARRANTES <RICARDO.ALVARADO at ucr.ac.cr> wrote:
>Thanks for your response, however my understandig of all this
>programming is very limited. Is there any source where I can read about
>F calculation for those models? 
>
>Thanks for your time 
>
>Ricardo 
>
>El 14-01-2019 16:47, Jeff Newmiller escribi?:
>
>> Fortunately, nlme is open source [1 [1]][2 [2]], so you can follow
>along in as much detail as you like.
>> 
>> Note that capitalization matters in R... NLME is not correct.
>> 
>> [1]  https://github.com/cran/nlme/blob/master/R/lme.R
>> [2] https://cran.r-project.org/package=nlme
>> 
>> On January 14, 2019 1:59:29 PM PST, RICARDO ALVARADO BARRANTES
><RICARDO.ALVARADO at ucr.ac.cr> wrote: 
>> 
>>> I have a question related to the funcion LME in the library NLME.  I
>>> would like to understand how the F values are calculated, since the
>>> output only shows the degrees of freedom but doen't show the sums of
>>> squares involved in those calculations. 
>>> 
>>> Thanks for your attention. 
>>> 
>>> Ricardo
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>  
>
>Links:
>------
>[1] https://github.com/cran/nlme/blob/master/R/lme.R
>[2] https://cran.r-project.org/package=nlme

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 15 18:42:49 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 15 Jan 2019 09:42:49 -0800
Subject: [R] [R-sig-ME] Calculating F values for lme function
In-Reply-To: <D02BF4F3-2A81-4C67-885C-07CBE2EE2CC7@dcn.davis.ca.us>
References: <b576d62b04e705c87c535aaa372352d1@ucr.ac.cr>
 <06823a0dae02c1d88c331ae1ecf2e403@ucr.ac.cr>
 <38D362F2-9510-4E20-A995-4EDB8417321C@dcn.davis.ca.us>
 <91a67ac76c3d1abbb3d76f5fa5853e0c@ucr.ac.cr>
 <D02BF4F3-2A81-4C67-885C-07CBE2EE2CC7@dcn.davis.ca.us>
Message-ID: <CAGxFJbTYN_G3gdqJyY-DyU6bZPrecqEz2TZgxqmOfNxMWDp9iA@mail.gmail.com>

Ricardo:
You may do better posting on the r-sig-mixed-models list, which is
specifically devoted to such topics.

FWIW, re calculating F-values for mixed effects models, I think many say:
don't.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 15, 2019 at 8:36 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You should use Reply-All to make sure the discussion continues to include
> the mailing list.
>
> Have you looked at the help for lme?
>
> lme is non-trivial, so it may take some reading. I only have a few of the
> references listed in the help file, and none with me at the moment.
>
> On January 15, 2019 7:36:22 AM PST, RICARDO ALVARADO BARRANTES <
> RICARDO.ALVARADO at ucr.ac.cr> wrote:
> >Thanks for your response, however my understandig of all this
> >programming is very limited. Is there any source where I can read about
> >F calculation for those models?
> >
> >Thanks for your time
> >
> >Ricardo
> >
> >El 14-01-2019 16:47, Jeff Newmiller escribi?:
> >
> >> Fortunately, nlme is open source [1 [1]][2 [2]], so you can follow
> >along in as much detail as you like.
> >>
> >> Note that capitalization matters in R... NLME is not correct.
> >>
> >> [1]  https://github.com/cran/nlme/blob/master/R/lme.R
> >> [2] https://cran.r-project.org/package=nlme
> >>
> >> On January 14, 2019 1:59:29 PM PST, RICARDO ALVARADO BARRANTES
> ><RICARDO.ALVARADO at ucr.ac.cr> wrote:
> >>
> >>> I have a question related to the funcion LME in the library NLME.  I
> >>> would like to understand how the F values are calculated, since the
> >>> output only shows the degrees of freedom but doen't show the sums of
> >>> squares involved in those calculations.
> >>>
> >>> Thanks for your attention.
> >>>
> >>> Ricardo
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> >Links:
> >------
> >[1] https://github.com/cran/nlme/blob/master/R/lme.R
> >[2] https://cran.r-project.org/package=nlme
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |uc@m1968 @end|ng |rom gm@||@com  Tue Jan 15 19:26:02 2019
From: |uc@m1968 @end|ng |rom gm@||@com (Luca Meyer)
Date: Tue, 15 Jan 2019 19:26:02 +0100
Subject: [R] Banner using R
Message-ID: <684F7FA0-5E9C-4852-86C3-3F25671B2398@gmail.com>

Hi,

I am a bit rusty with R programming and I would appreciate some assistance with the following.

I have a dataset like:

Data <- data.frame(v1 = c('A', 'B' ,'B' ,'A', 'B'), v2 =c('A', 'B', 'A', 'A', 'B'), v3 = c('A', 'A', 'A', 'A', 'A?))

How can I get a banner of the sort?

Count	v1	v2	v3	TOT
A		2	3	5	10
B		3	2	0	5

I have tried with xtabs and expss but I do not seem to get what I need...

Thanks,

Luca


From pd@|gd @end|ng |rom gm@||@com  Tue Jan 15 19:41:25 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 15 Jan 2019 19:41:25 +0100
Subject: [R] [R-sig-ME] Calculating F values for lme function
In-Reply-To: <CAGxFJbTYN_G3gdqJyY-DyU6bZPrecqEz2TZgxqmOfNxMWDp9iA@mail.gmail.com>
References: <b576d62b04e705c87c535aaa372352d1@ucr.ac.cr>
 <06823a0dae02c1d88c331ae1ecf2e403@ucr.ac.cr>
 <38D362F2-9510-4E20-A995-4EDB8417321C@dcn.davis.ca.us>
 <91a67ac76c3d1abbb3d76f5fa5853e0c@ucr.ac.cr>
 <D02BF4F3-2A81-4C67-885C-07CBE2EE2CC7@dcn.davis.ca.us>
 <CAGxFJbTYN_G3gdqJyY-DyU6bZPrecqEz2TZgxqmOfNxMWDp9iA@mail.gmail.com>
Message-ID: <A68AF45F-2ACC-441B-BA5C-2C40F6636F5A@gmail.com>

Or at least don't do it with lme() because it basically gets them wrong (I believe even its author agrees). The situation is rather better with lme4 and the pbkrtest package, although one should always be wary of low denominator DF cases because, even at the best of times, results rely heavily on assumptions of normal distribution.

-pd

> On 15 Jan 2019, at 18:42 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Ricardo:
> You may do better posting on the r-sig-mixed-models list, which is
> specifically devoted to such topics.
> 
> FWIW, re calculating F-values for mixed effects models, I think many say:
> don't.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Jan 15, 2019 at 8:36 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> You should use Reply-All to make sure the discussion continues to include
>> the mailing list.
>> 
>> Have you looked at the help for lme?
>> 
>> lme is non-trivial, so it may take some reading. I only have a few of the
>> references listed in the help file, and none with me at the moment.
>> 
>> On January 15, 2019 7:36:22 AM PST, RICARDO ALVARADO BARRANTES <
>> RICARDO.ALVARADO at ucr.ac.cr> wrote:
>>> Thanks for your response, however my understandig of all this
>>> programming is very limited. Is there any source where I can read about
>>> F calculation for those models?
>>> 
>>> Thanks for your time
>>> 
>>> Ricardo
>>> 
>>> El 14-01-2019 16:47, Jeff Newmiller escribi?:
>>> 
>>>> Fortunately, nlme is open source [1 [1]][2 [2]], so you can follow
>>> along in as much detail as you like.
>>>> 
>>>> Note that capitalization matters in R... NLME is not correct.
>>>> 
>>>> [1]  https://github.com/cran/nlme/blob/master/R/lme.R
>>>> [2] https://cran.r-project.org/package=nlme
>>>> 
>>>> On January 14, 2019 1:59:29 PM PST, RICARDO ALVARADO BARRANTES
>>> <RICARDO.ALVARADO at ucr.ac.cr> wrote:
>>>> 
>>>>> I have a question related to the funcion LME in the library NLME.  I
>>>>> would like to understand how the F values are calculated, since the
>>>>> output only shows the degrees of freedom but doen't show the sums of
>>>>> squares involved in those calculations.
>>>>> 
>>>>> Thanks for your attention.
>>>>> 
>>>>> Ricardo
>>>>> 
>>>>> [[alternative HTML version deleted]]
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> Links:
>>> ------
>>> [1] https://github.com/cran/nlme/blob/master/R/lme.R
>>> [2] https://cran.r-project.org/package=nlme
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From g||ddec@ @end|ng |rom @c|ence@oregon@t@te@edu  Tue Jan 15 19:42:19 2019
From: g||ddec@ @end|ng |rom @c|ence@oregon@t@te@edu (Caroline)
Date: Tue, 15 Jan 2019 10:42:19 -0800
Subject: [R] Nested mixed effectts question
Message-ID: <718BB1FC-093A-4153-B692-2A771738FCF5@science.oregonstate.edu>

Hi,

I am helping a friend with an analysis for a study where she sampled wrack biomass in 15 different sites across three years. At each site, she sampled from three different transects. She is trying to estimate the effect of year*site on biomass while accounting for the nested nature (site/transcet) and repeated measure study design. 

wrack.biomass ~ year * site + (1 | site/trans)

However she gets the following warning messages:
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Hessian is numerically singular: parameters are not uniquely determined

And her model output is: 

> summary(wrackbio)
Linear mixed model fit by REML 
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: (actual.mean.biomass.m2.50.m.transect) ~ year * site + (1 | site/trans)
   Data: wrack_resp_allyrs_transname

REML criterion at convergence: 691

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.3292 -0.2624 -0.0270  0.1681  3.8024 

Random effects:
 Groups     Name        Variance Std.Dev.
 trans:site (Intercept)  0.0000  0.0000  
 site       (Intercept)  0.5531  0.7437  
 Residual               94.6453  9.7286  
Number of obs: 132, groups:  trans:site, 44; site, 15

Fixed effects:
                    Estimate Std. Error         df t value Pr(>|t|)    
(Intercept)        9.692e+00  5.666e+00  1.119e-04   1.711    0.999    
year2016           1.256e+01  7.943e+00  8.700e+01   1.582    0.117    
year2017           2.395e+00  7.943e+00  8.700e+01   0.302    0.764    
siteCL             5.672e+01  8.013e+00  1.119e-04   7.079    0.999    
siteDO            -4.315e+00  8.013e+00  1.119e-04  -0.539    0.999    
siteFL             7.872e+00  8.013e+00  1.119e-04   0.982    0.999    
siteFS            -7.619e+00  8.013e+00  1.119e-04  -0.951    0.999    
siteGH             4.369e+00  8.013e+00  1.119e-04   0.545    0.999    
siteLB            -3.747e+00  8.013e+00  1.119e-04  -0.468    0.999    
siteLBP           -5.298e+00  8.943e+00  1.736e-04  -0.592    0.999    
siteNB            -2.953e+00  8.013e+00  1.119e-04  -0.369    1.000    
siteNS             1.005e+00  8.013e+00  1.119e-04   0.125    1.000    
sitePC            -5.238e+00  8.013e+00  1.119e-04  -0.654    0.999    
siteSB            -7.649e+00  8.013e+00  1.119e-04  -0.955    0.999    
siteSILT          -4.734e+00  8.013e+00  1.119e-04  -0.591    0.999    
siteSL            -7.890e+00  8.013e+00  1.119e-04  -0.985    0.999    
siteUD            -8.230e+00  8.013e+00  1.119e-04  -1.027    0.999    
year2016:siteCL   -6.359e+01  1.123e+01  8.700e+01  -5.660 1.91e-07 ***
year2017:siteCL   -5.210e+01  1.123e+01  8.700e+01  -4.638 1.23e-05 ***
year2016:siteDO   -1.550e+01  1.123e+01  8.700e+01  -1.380    0.171    
year2017:siteDO   -3.022e+00  1.123e+01  8.700e+01  -0.269    0.789    
year2016:siteFL   -7.522e+00  1.123e+01  8.700e+01  -0.670    0.505    
year2017:siteFL   -1.167e+01  1.123e+01  8.700e+01  -1.039    0.302    
year2016:siteFS   -1.391e+01  1.123e+01  8.700e+01  -1.238    0.219    
year2017:siteFS   -2.170e+00  1.123e+01  8.700e+01  -0.193    0.847    
year2016:siteGH   -9.135e+00  1.123e+01  8.700e+01  -0.813    0.418    
year2017:siteGH   -4.031e+00  1.123e+01  8.700e+01  -0.359    0.721    
year2016:siteLB   -8.668e+00  1.123e+01  8.700e+01  -0.772    0.442    
year2017:siteLB   -1.530e+00  1.123e+01  8.700e+01  -0.136    0.892    
year2016:siteLBP  -5.336e+00  1.256e+01  8.700e+01  -0.425    0.672    
year2017:siteLBP  -1.826e+00  1.256e+01  8.700e+01  -0.145    0.885    
year2016:siteNB   -7.999e+00  1.123e+01  8.700e+01  -0.712    0.478    
year2017:siteNB   -5.645e+00  1.123e+01  8.700e+01  -0.502    0.617    
year2016:siteNS   -8.871e+00  1.123e+01  8.700e+01  -0.790    0.432    
year2017:siteNS   -3.443e+00  1.123e+01  8.700e+01  -0.306    0.760    
year2016:sitePC   -1.603e+01  1.123e+01  8.700e+01  -1.427    0.157    
year2017:sitePC   -2.955e+00  1.123e+01  8.700e+01  -0.263    0.793    
year2016:siteSB   -1.316e+01  1.123e+01  8.700e+01  -1.171    0.245    
year2017:siteSB   -3.220e+00  1.123e+01  8.700e+01  -0.287    0.775    
year2016:siteSILT -1.616e+01  1.123e+01  8.700e+01  -1.438    0.154    
year2017:siteSILT -2.497e-01  1.123e+01  8.700e+01  -0.022    0.982    
year2016:siteSL   -1.004e+01  1.123e+01  8.700e+01  -0.894    0.374    
year2017:siteSL    1.123e+00  1.123e+01  8.700e+01   0.100    0.921    
year2016:siteUD   -1.345e+01  1.123e+01  8.700e+01  -1.197    0.235    
year2017:siteUD    3.810e+00  1.123e+01  8.700e+01   0.339    0.735    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation matrix not shown by default, as p = 45 > 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it

convergence code: 0
unable to evaluate scaled gradient
 Hessian is numerically singular: parameters are not uniquely determined

Is the model unable to converge because her dataset is too small to include an interaction term or is stemming from issues of model structure?

Thanks! 

Caroline








	[[alternative HTML version deleted]]


From dc@r|@on @end|ng |rom t@mu@edu  Tue Jan 15 19:45:01 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 15 Jan 2019 18:45:01 +0000
Subject: [R] Banner using R
In-Reply-To: <684F7FA0-5E9C-4852-86C3-3F25671B2398@gmail.com>
References: <684F7FA0-5E9C-4852-86C3-3F25671B2398@gmail.com>
Message-ID: <29e1f72fd32045f8a02b51cbecf4c672@tamu.edu>

You need to read the data without converting to factors:

> Data <- data.frame(v1 = c('A', 'B' ,'B' ,'A', 'B'), v2 =c('A', 'B', 'A', 'A', 'B'), 
+      v3 = c('A', 'A', 'A', 'A', 'A'), stringsAsFactors=FALSE)

Then you need to stack it:

> Data.stack <- stack(Data)
> str(Data.stack)
'data.frame':   15 obs. of  2 variables:
 $ values: chr  "A" "B" "B" "A" ...
 $ ind   : Factor w/ 3 levels "v1","v2","v3": 1 1 1 1 1 2 2 2 2 2 ...

Then table (or xtabs) will work:

> Data.tbl <- table(Data.stack)
> addmargins(Data.tbl, 2)
      ind
values v1 v2 v3 Sum
     A  2  3  5  10
     B  3  2  0   5

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luca Meyer
Sent: Tuesday, January 15, 2019 12:26 PM
To: r-help at r-project.org
Subject: [R] Banner using R

Hi,

I am a bit rusty with R programming and I would appreciate some assistance with the following.

I have a dataset like:

Data <- data.frame(v1 = c('A', 'B' ,'B' ,'A', 'B'), v2 =c('A', 'B', 'A', 'A', 'B'), v3 = c('A', 'A', 'A', 'A', 'A?))

How can I get a banner of the sort?

Count	v1	v2	v3	TOT
A		2	3	5	10
B		3	2	0	5

I have tried with xtabs and expss but I do not seem to get what I need...

Thanks,

Luca

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu  Tue Jan 15 20:51:16 2019
From: ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu (Emily Wan)
Date: Tue, 15 Jan 2019 14:51:16 -0500
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
Message-ID: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>

Hi -
I am working with R on a Window Server 2012 R2 - I had originally installed
R (v3.5.1) in September/October 2018 and have used multiple packages
without incident. However, last week, when attempting to install additional
packages (using install.packages() or Bioconductor's BiocManager::install()
wrapper), I kept on receiving the following error message:

Error in if (any(diff)) { : missing value where TRUE/FALSE needed

I have searched the prior threads on this topic (including the issue
reported with R v3.4.0 which required a patch), rebooted my server, and
actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still receiving
the same error message when I attempt to install *any* package.
Please let me know what additional details I can provide to assist with
troubleshooting. Thank you.

-- 
The information in this e-mail is intended only for the ...{{dropped:18}}


From r@vc0805 @end|ng |rom gm@||@com  Tue Jan 15 22:01:11 2019
From: r@vc0805 @end|ng |rom gm@||@com (Rick Van Camp)
Date: Tue, 15 Jan 2019 16:01:11 -0500
Subject: [R] Rserve - Request assistance with installation,
 confirmation thereof and starting (R 3.5.1 on 64-bit Win7 Pro)
Message-ID: <CAE5uQe8st6zGUz=2AJ60+Q34cs5xY5m9SZ5LwPiwPCgyQHWppQ@mail.gmail.com>

Hello,

I am attempting to install two R packages with specific version numbers.
These are Rserve_1.8-0.zip and MASS_7.3-45.zip.  As the file extension
suggests, I am installing packages from local zipfiles in the GUI Packages
menu.  R Console displays positive feedback when MASS is loaded in this
manner:

*> utils:::menuInstallLocal()*

package ?MASS? successfully unpacked and MD5 sums checked

The R Console does not display any message when I attempt to install Rserve
in the same manner.  What does this indicate about Rserve being installed
successfully?  I was only provided instructions to install these two
packages. No mention is made af loading them and this is feasible as Rserve
can run without R being open.

Further, I recently located two discussion threads indicating Rserve
requires a configuration file and this is created by the user.  These
threads refer the reader to three files: 1) Rserve.exe, 2) Rserve.dll, and
3) Rserve_d.exe and instructs these should be placed into the same
directory where R.dll is located (This is the bin directory on my
installation: R.home("bin")).  Next, it instructs readers to create the
file "Rserv.cfg" and provide the desired arguments such port number.

Here is my result of sessionInfo()

*> sessionInfo()*

R version 3.5.1 (2018-07-02)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1


Matrix products: default


locale:

[1] LC_COLLATE=English_United States.1252

[2] LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252

[4] LC_NUMERIC=C

[5] LC_TIME=English_United States.1252


attached base packages:

[1] stats graphics grDevices utils datasets methods base


loaded via a namespace (and not attached):

[1] compiler_3.5.1 tools_3.5.1


Please let me know if you need anything else regarding my installation of
R.  Since I have been unable to accomplish this task, I have not saved a
workspace.


Thank you.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 15 22:51:52 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 15 Jan 2019 13:51:52 -0800
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
In-Reply-To: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
References: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
Message-ID: <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>

Please ask questions about Bioconductor on the Bioconductor forum [1].

Chances are that you need to re-install Bioconductor because packages are installed in two-digit version-specific libraries... e.g. R 3.4 and R 3.5 do not share packages.

[1] https://support.bioconductor.org

On January 15, 2019 11:51:16 AM PST, Emily Wan <reesw at channing.harvard.edu> wrote:
>Hi -
>I am working with R on a Window Server 2012 R2 - I had originally
>installed
>R (v3.5.1) in September/October 2018 and have used multiple packages
>without incident. However, last week, when attempting to install
>additional
>packages (using install.packages() or Bioconductor's
>BiocManager::install()
>wrapper), I kept on receiving the following error message:
>
>Error in if (any(diff)) { : missing value where TRUE/FALSE needed
>
>I have searched the prior threads on this topic (including the issue
>reported with R v3.4.0 which required a patch), rebooted my server, and
>actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still
>receiving
>the same error message when I attempt to install *any* package.
>Please let me know what additional details I can provide to assist with
>troubleshooting. Thank you.

-- 
Sent from my phone. Please excuse my brevity.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jan 16 08:29:06 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 16 Jan 2019 07:29:06 +0000
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <CAF7DXDRt2LcdVujj5ie-JTSOqfDyyiguayJnqvvVn=ZLXD8BZA@mail.gmail.com>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
 <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>
 <c3122b1f567847f995637a95d4362a51@SRVEXCHCM1302.precheza.cz>
 <CAF7DXDRt2LcdVujj5ie-JTSOqfDyyiguayJnqvvVn=ZLXD8BZA@mail.gmail.com>
Message-ID: <a3bb47ad6dd54a909a65a7fd0b992eb1@SRVEXCHCM1302.precheza.cz>

Hi

You put NA to some variable in 150 rows. So you do not have "mysterious" NA rows in your file. If you want to select anything based on column with NA values you have to perform your selection using which (as Rui suggested).

It is documented in help page, although it is probably rather less comprehensible (maybe some example added to help page could be useful).
-----
NAs in indexing

When extracting, a numerical, logical or character NA index picks an unknown element and so returns NA in the corresponding element of a logical, integer, numeric, complex or character result, and NULL for a list. (It returns 00 for a raw result.)
-----
I believe that this behaviour has some reason, because you compare 2 to NA and NA is basically "I do not know". So it could be 2 and therefore also rows with NA are returned. If I am wrong, I hope R gurus will correct me.

You said you want to remove rows with NA values, therefore I suggested complete.cases function. After this you end with object stripped from rows with NA values so with less rows.

I would be rather cautious with word "errorneous". I remember old days when Excel considered empty cells as zeros and gave "errorneous" calculations but I believe that it was pretty sensible from accountant point of view as empty cell means 0.

In almost all cases, analysis in R give you correct results, you just need to tell R how to apply function to object with NA values.
> mean(t1$Petal.Width)
[1] NA
> mean(t1$Petal.Width, na.rm=T)
[1] 1.147101
>

Cheers
Petr


> -----Original Message-----
> From: Ernest Han <ernest.hec at gmail.com>
> Sent: Wednesday, January 16, 2019 3:27 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] NA rows appeared in data.frame
>
> Dear Rui and Petr,
>
> Thank you for taking time and effort to help.
>
> Rui's solution is an effective workaround so that I can continue to work with
> the data. However, the appearance of these NA rows (with NA
> rownames) is clearly errorneous (possibly a bug behaviour due to R base code).
> What I am interested is a solution that removes these NA rows.
>
> The reasons is because (1) prior to the NA assignment, one does not need to
> test for NA value. (2) Besides, sometimes these NA values are needed as part of
> the data to indicate that the missing data.
>
> > t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA
>
> Petr's solution is also not apt in my case, because it removes 12 rows that have
> NA values in "Petal.Width". I would like a solution that keeps the 150 rows, but
> not the mysterious 12 rows with all NA values in all columns.

Now I am puzzled what do you really want?

with your example and my suggestion you get

t1 <- iris
t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA
t2 <- t1[!is.na(t1$Petal.Width),]
t2[t2$Petal.Width == 2.0, ]
    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
111          6.5         3.2          5.1           2 virginica
114          5.7         2.5          5.0           2 virginica
122          5.6         2.8          4.9           2 virginica
123          7.7         2.8          6.7           2 virginica
132          7.9         3.8          6.4           2 virginica
148          6.5         3.0          5.2           2 virginica
>

> dim(t2)
[1] 138   5
> dim(t1)
[1] 150   5
>

>
> Once again, I appreciate your suggestions and I am hoping that this 'errorneous'
> behaviour has a fix.
>
> Cheers,
> Ernest
>
> On Mon, Jan 14, 2019 at 4:25 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi
> >
> > If you want to remove rows with NA values from your data you could use
> >
> > ?complete.cases
> >
> > or
> >
> > t2 <- t1[!is.na(t1$Petal.Width),]
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui
> > > Barradas
> > > Sent: Saturday, January 12, 2019 12:55 PM
> > > To: Ernest Han <ernest.hec at gmail.com>; r-help at r-project.org
> > > Subject: Re: [R] NA rows appeared in data.frame
> > >
> > > Hello,
> > >
> > > You have to test for NA. Some (12) of the values of t1$Petal.Width
> > > are NA therefore t1$Petal.Width == 2.0 alone returns 12 NA values.
> > >
> > > t1[t1$Petal.Width == 2.0 & !is.na(t1$Petal.Width == 2.0), ]
> > >
> > > Or use which(t1$Petal.Width == 2.0).
> > >
> > > t1[which(t1$Petal.Width == 2.0), ]
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 08:23 de 12/01/2019, Ernest Han escreveu:
> > > > Dear All,
> > > >
> > > > After replacing some values in a data.frame, NAs rows have
> > > > appeared and cannot be removed. I have googled these issues and
> > > > found that several people have encountered it. Solutions in
> > > > stackoverflow seem to provide work-arounds but does not remove it from
> the data.frame.
> > > > Therefore, I am turning to experts in this community for help.
> > > >
> > > > The code is as follows,
> > > >
> > > >> t1 <- iris
> > > >> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA t1[t1$Petal.Width ==
> > > >> 2.0, ]
> > > >        Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> > > > NA              NA          NA           NA          NA      <NA>
> > > > NA.1            NA          NA           NA          NA      <NA>
> > > > NA.2            NA          NA           NA          NA      <NA>
> > > > NA.3            NA          NA           NA          NA      <NA>
> > > > 111            6.5         3.2          5.1           2 virginica
> > > > 114            5.7         2.5          5.0           2 virginica
> > > > NA.4            NA          NA           NA          NA      <NA>
> > > > 122            5.6         2.8          4.9           2 virginica
> > > > 123            7.7         2.8          6.7           2 virginica
> > > > NA.5            NA          NA           NA          NA      <NA>
> > > > NA.6            NA          NA           NA          NA      <NA>
> > > > NA.7            NA          NA           NA          NA      <NA>
> > > > NA.8            NA          NA           NA          NA      <NA>
> > > > 132            7.9         3.8          6.4           2 virginica
> > > > NA.9            NA          NA           NA          NA      <NA>
> > > > NA.10           NA          NA           NA          NA      <NA>
> > > > 148            6.5         3.0          5.2           2 virginica
> > > > NA.11           NA          NA           NA          NA      <NA>
> > > >
> > > > ## Twelve values were replaced, twelve NA rows appeared.
> > > >
> > > > ### MISC INFO ###
> > > >> sessionInfo()
> > > > R version 3.4.0 (2017-04-21)
> > > > Platform: x86_64-apple-darwin16.5.0 (64-bit) Running under: macOS
> > > > 10.14.2
> > > >
> > > > Matrix products: default
> > > > BLAS:
> > > > /System/Library/Frameworks/Accelerate.framework/Versions/A/Framewo
> > > > rks/ vecLib.framework/Versions/A/libBLAS.dylib
> > > > LAPACK:
> > > > /System/Library/Frameworks/Accelerate.framework/Versions/A/Framewo
> > > > rks/ vecLib.framework/Versions/A/libLAPACK.dylib
> > > >
> > > > locale:
> > > > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > > >
> > > > attached base packages:
> > > > [1] stats     graphics  grDevices utils     datasets  methods   base
> > > >
> > > > loaded via a namespace (and not attached):
> > > > [1] compiler_3.4.0 tools_3.4.0
> > > >> Sys.getlocale()
> > > > [1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-
> 8"
> > > >
> > > >
> > > > Thank you,
> > > > Ernest
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From erne@t@hec @end|ng |rom gm@||@com  Wed Jan 16 03:27:19 2019
From: erne@t@hec @end|ng |rom gm@||@com (Ernest Han)
Date: Wed, 16 Jan 2019 10:27:19 +0800
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <c3122b1f567847f995637a95d4362a51@SRVEXCHCM1302.precheza.cz>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
 <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>
 <c3122b1f567847f995637a95d4362a51@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAF7DXDRt2LcdVujj5ie-JTSOqfDyyiguayJnqvvVn=ZLXD8BZA@mail.gmail.com>

Dear Rui and Petr,

Thank you for taking time and effort to help.

Rui's solution is an effective workaround so that I can continue to
work with the data. However, the appearance of these NA rows (with NA
rownames) is clearly errorneous (possibly a bug behaviour due to R
base code). What I am interested is a solution that removes these NA
rows.

The reasons is because (1) prior to the NA assignment, one does not
need to test for NA value. (2) Besides, sometimes these NA values are
needed as part of the data to indicate that the missing data.

> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA

Petr's solution is also not apt in my case, because it removes 12 rows
that have NA values in "Petal.Width". I would like a solution that
keeps the 150 rows, but not the mysterious 12 rows with all NA values
in all columns.

Once again, I appreciate your suggestions and I am hoping that this
'errorneous' behaviour has a fix.

Cheers,
Ernest

On Mon, Jan 14, 2019 at 4:25 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> If you want to remove rows with NA values from your data you could use
>
> ?complete.cases
>
> or
>
> t2 <- t1[!is.na(t1$Petal.Width),]
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> > Sent: Saturday, January 12, 2019 12:55 PM
> > To: Ernest Han <ernest.hec at gmail.com>; r-help at r-project.org
> > Subject: Re: [R] NA rows appeared in data.frame
> >
> > Hello,
> >
> > You have to test for NA. Some (12) of the values of t1$Petal.Width are NA
> > therefore t1$Petal.Width == 2.0 alone returns 12 NA values.
> >
> > t1[t1$Petal.Width == 2.0 & !is.na(t1$Petal.Width == 2.0), ]
> >
> > Or use which(t1$Petal.Width == 2.0).
> >
> > t1[which(t1$Petal.Width == 2.0), ]
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 08:23 de 12/01/2019, Ernest Han escreveu:
> > > Dear All,
> > >
> > > After replacing some values in a data.frame, NAs rows have appeared
> > > and cannot be removed. I have googled these issues and found that
> > > several people have encountered it. Solutions in stackoverflow seem to
> > > provide work-arounds but does not remove it from the data.frame.
> > > Therefore, I am turning to experts in this community for help.
> > >
> > > The code is as follows,
> > >
> > >> t1 <- iris
> > >> t1[t1$Petal.Width==1.8, "Petal.Width"] <- NA t1[t1$Petal.Width ==
> > >> 2.0, ]
> > >        Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> > > NA              NA          NA           NA          NA      <NA>
> > > NA.1            NA          NA           NA          NA      <NA>
> > > NA.2            NA          NA           NA          NA      <NA>
> > > NA.3            NA          NA           NA          NA      <NA>
> > > 111            6.5         3.2          5.1           2 virginica
> > > 114            5.7         2.5          5.0           2 virginica
> > > NA.4            NA          NA           NA          NA      <NA>
> > > 122            5.6         2.8          4.9           2 virginica
> > > 123            7.7         2.8          6.7           2 virginica
> > > NA.5            NA          NA           NA          NA      <NA>
> > > NA.6            NA          NA           NA          NA      <NA>
> > > NA.7            NA          NA           NA          NA      <NA>
> > > NA.8            NA          NA           NA          NA      <NA>
> > > 132            7.9         3.8          6.4           2 virginica
> > > NA.9            NA          NA           NA          NA      <NA>
> > > NA.10           NA          NA           NA          NA      <NA>
> > > 148            6.5         3.0          5.2           2 virginica
> > > NA.11           NA          NA           NA          NA      <NA>
> > >
> > > ## Twelve values were replaced, twelve NA rows appeared.
> > >
> > > ### MISC INFO ###
> > >> sessionInfo()
> > > R version 3.4.0 (2017-04-21)
> > > Platform: x86_64-apple-darwin16.5.0 (64-bit) Running under: macOS
> > > 10.14.2
> > >
> > > Matrix products: default
> > > BLAS:
> > > /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/
> > > vecLib.framework/Versions/A/libBLAS.dylib
> > > LAPACK:
> > > /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/
> > > vecLib.framework/Versions/A/libLAPACK.dylib
> > >
> > > locale:
> > > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > >
> > > attached base packages:
> > > [1] stats     graphics  grDevices utils     datasets  methods   base
> > >
> > > loaded via a namespace (and not attached):
> > > [1] compiler_3.4.0 tools_3.4.0
> > >> Sys.getlocale()
> > > [1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"
> > >
> > >
> > > Thank you,
> > > Ernest
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>


From m@||km@h23 @end|ng |rom gm@||@com  Wed Jan 16 10:11:42 2019
From: m@||km@h23 @end|ng |rom gm@||@com (Mahnoor Malik)
Date: Wed, 16 Jan 2019 14:11:42 +0500
Subject: [R] Operator Overloading in R
Message-ID: <CABiDw9j2qJp9jr5UhT_S1A+Fiok3PE-TnAtW6_bcf2G04Ozm0g@mail.gmail.com>

I am using R6 class and I have to do operator overloading (+ ,-,*) for a
custom data type . What will be the necessary steps ? I am totally confused
as to what should I do in order to implement this .

Thanks

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Jan 16 15:08:41 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 16 Jan 2019 16:08:41 +0200
Subject: [R] Operator Overloading in R
In-Reply-To: <CABiDw9j2qJp9jr5UhT_S1A+Fiok3PE-TnAtW6_bcf2G04Ozm0g@mail.gmail.com>
References: <CABiDw9j2qJp9jr5UhT_S1A+Fiok3PE-TnAtW6_bcf2G04Ozm0g@mail.gmail.com>
Message-ID: <CAGgJW765mq1xA_VEGqghfjnVARcuaj+93BR4rpc3brv+wqkm4w@mail.gmail.com>

I have experience with R6 classes but I have not used operator overloading
with them.
Out of curiosity I did a quick search and found this link which provides a
step by step (I am not claiming it is the only way)
https://stackoverflow.com/questions/49463235/arithmetic-operators-overload-for-r6classes-in-r

HTH,
Eric


On Wed, Jan 16, 2019 at 4:01 PM Mahnoor Malik <malikmah23 at gmail.com> wrote:

> I am using R6 class and I have to do operator overloading (+ ,-,*) for a
> custom data type . What will be the necessary steps ? I am totally confused
> as to what should I do in order to implement this .
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Jan 16 17:59:03 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 16 Jan 2019 16:59:03 +0000
Subject: [R] importing data error question
In-Reply-To: <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
Message-ID: <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>

Dear jihee,

I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:

I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.

I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.

I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.

Thank you for reporting this issue.

John

> On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear jihee,
> 
>> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
>> 
>> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
>> 
>> --> no, I never said i was using a Mac. 
> 
> Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
> 
>> 
>> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
>> 
>> --> sessionInfo()
>> R version 3.5.2 (2018-12-20)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>> 
>> Matrix products: default
>> 
>> locale:
>> [1] LC_COLLATE=Korean_Korea.949  LC_CTYPE=Korean_Korea.949   
>> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C                
>> [5] LC_TIME=Korean_Korea.949    
>> 
>> attached base packages:
>> [1] tcltk     splines   stats     graphics  grDevices utils     datasets  methods  
>> [9] base     
>> 
>> other attached packages:
>> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
>> [3] Rcmdr_2.5-1                    effects_4.1-0                 
>> [5] RcmdrMisc_2.5-1                sandwich_2.5-0                
>> [7] car_3.0-2                      carData_3.0-2                 
>> [9] SensoMineR_1.23                FactoMineR_1.41               
>> 
>> loaded via a namespace (and not attached):
>> [1] gtools_3.8.1         Formula_1.2-3        latticeExtra_0.6-28 
>> [4] cellranger_1.1.0     pillar_1.3.1         backports_1.1.3     
>> [7] lattice_0.20-38      digest_0.6.18        RColorBrewer_1.1-2  
>> [10] checkmate_1.8.5      minqa_1.2.4          colorspace_1.3-2    
>> [13] survey_3.35          htmltools_0.3.6      Matrix_1.2-15       
>> [16] plyr_1.8.4           pkgconfig_2.0.2      haven_2.0.0         
>> [19] scales_1.0.0         openxlsx_4.1.0       rio_0.5.16          
>> [22] lme4_1.1-19          htmlTable_1.13.1     tibble_1.4.2        
>> [25] relimp_1.0-5         ggplot2_3.1.0        nnet_7.3-12         
>> [28] lazyeval_0.2.1       survival_2.43-3      magrittr_1.5        
>> [31] crayon_1.3.4         readxl_1.2.0         nlme_3.1-137        
>> [34] MASS_7.3-51.1        forcats_0.3.0        foreign_0.8-71      
>> [37] class_7.3-14         tools_3.5.2          data.table_1.11.8   
>> [40] hms_0.4.2            tcltk2_1.2-11        stringr_1.3.1       
>> [43] munsell_0.5.0        cluster_2.0.7-1      zip_1.0.0           
>> [46] flashClust_1.01-2    compiler_3.5.2       e1071_1.7-0         
>> [49] rlang_0.3.1          grid_3.5.2           nloptr_1.2.1        
>> [52] rstudioapi_0.9.0     htmlwidgets_1.3      leaps_3.0           
>> [55] base64enc_0.1-3      gtable_0.2.0         abind_1.4-5         
>> [58] curl_3.2             reshape2_1.4.3       AlgDesign_1.1-7.3   
>> [61] gridExtra_2.3        zoo_1.8-4            knitr_1.21          
>> [64] nortest_1.0-4        Hmisc_4.1-1          KernSmooth_2.23-15  
>> [67] stringi_1.2.4        Rcpp_1.0.0           rpart_4.1-13        
>> [70] acepack_1.4.1        scatterplot3d_0.3-41 xfun_0.4            
>> 
>> This was the status that I tried to import Excel data. 
> 
> These packages seem up-to-date.
> 
>> 
>> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
>> 
>> --> I tried without plug-in packages, but It didn't work. 
> 
> OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
> 
>> 
>> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
>> 
>> --> I don't know what is plain-text data file..... 
> 
> A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
> 
>> 
>> i'll try R with English. 
> 
> I'm curious to see what happens.
> 
> Best,
> John
> 
>> 
>> From:  "Fox, John" <jfox at mcmaster.ca> 
>> 
>> Sent: Monday, January 14, 2019 11:15:36 PM 
>> 
>> To:"???" <wjh1518 at ht.co.kr> 
>> 
>> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
>> 
>> Subject:Re: [R] importing data error question 
>> 
>>   Dear jihee,
>> 
>>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
>>> 
>>> 
>>> 
>>> From: "???" <wjh1518 at ht.co.kr>
>>> Sent: Monday, January 14, 2019 9:40:26 AM
>>> To:"Fox, John" <jfox at mcmaster.ca>
>>> Subject:Re: [R] importing data error question
>>> 
>>> 
>>> Thanks for your replies.
>>> 
>>> I'm using windows 7, I loaded FactoMineR,
>> 
>> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
>> 
>>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
>>> This problem occurred when I select Data > Import data > From Excel file.
>>> I checked FactoMineR and SensoMineR packages are loaded and using..
>> 
>> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
>> 
>> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
>> 
>> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
>> 
>> Best,
>> John
>> 
>>> 
>>> 
>>> 
>>> From: "Fox, John" <jfox at mcmaster.ca>
>>> Sent: Friday, January 11, 2019 10:48:38 PM
>>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
>>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
>>> Subject:Re: [R] importing data error question
>>> 
>>> 
>>> Dear Petr and jihee,
>>> 
>>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
>>> 
>>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
>>> 
>>> Best,
>>> John
>>> 
>>> -------------------------------------------------
>>> John Fox, Professor Emeritus
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> Web: http::/socserv.mcmaster.ca/jfox
>>> 
>>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>> 
>>>> Hi
>>>> 
>>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
>>>> 
>>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
>>>> 
>>>> Cheers
>>>> Petr
>>>> 
>>>>> -----Original Message-----
>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
>>>>> Sent: Friday, January 11, 2019 9:14 AM
>>>>> To: r-help at R-project.org
>>>>> Subject: [R] importing data error question
>>>>> 
>>>>> Hi I'm jihee and I have a question about error...
>>>>> 
>>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
>>>>> 
>>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
>>>>> 
>>>>> but i can't import excel data with Rcmdr.
>>>>> 
>>>>> it has this messege :
>>>>> 
>>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>>>> [tcl] bad Macintosh file type "?*?"
>>>>> 
>>>>> what is wrong with my R??? T_T
>>>>> 
>>>>> Thanks for your help.
>>>>> 
>>>>> jihee.
>>>>> [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> ??? ??? / ??????
>>> e-mailwjh1518 at ht.co.krDirMobile
>>> ????www.ht.co.kr????www.facebook.com/haitaico
>>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
>>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
>>> 
>>> 
>>> 
>>> 
>>> ??? ??? / ??????
>>> e-mailwjh1518 at ht.co.krDirMobile
>>> ????www.ht.co.kr????www.facebook.com/haitaico
>>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
>>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu  Wed Jan 16 18:48:12 2019
From: ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu (Emily Wan)
Date: Wed, 16 Jan 2019 12:48:12 -0500
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
In-Reply-To: <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>
References: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
 <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>
Message-ID: <CABAC6SbHfqmz0g=0uurxMkVnp9S9yO=E3bxo+tnze1ZQigtVWw@mail.gmail.com>

Hi Jeff -
I do not think the issue is Bioconductor (which is why I had posted the
inquiry on this forum - but as an aside, I do have the latest version of
Bioconductor (3.8)).   As an example, when I attempt to use the generic
install.packages() function, I receive the same error message. I have
included an example below (along with the sessionInfo):

> install.packages('stringr')
Installing package into ?~/My Documents/R/win-library/3.5?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
also installing the dependencies ?glue?, ?magrittr?
trying URL '
https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/glue_1.3.0.zip'
Content type 'application/zip' length 108591 bytes (106 KB)
downloaded 106 KB
trying URL '
https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/magrittr_1.5.zip
'
Content type 'application/zip' length 155452 bytes (151 KB)
downloaded 151 KB
trying URL '
https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/stringr_1.3.1.zip
'
Content type 'application/zip' length 194247 bytes (189 KB)
downloaded 189 KB
Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server 2012 R2 x64 (build 9600)
Matrix products: default
locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
loaded via a namespace (and not attached):
[1] compiler_3.5.2 tools_3.5.2
>
Please let me know what additional information is needed - many thanks.

On Tue, Jan 15, 2019 at 4:51 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please ask questions about Bioconductor on the Bioconductor forum [1].
>
> Chances are that you need to re-install Bioconductor because packages are
> installed in two-digit version-specific libraries... e.g. R 3.4 and R 3.5
> do not share packages.
>
> [1] https://support.bioconductor.org
>
> On January 15, 2019 11:51:16 AM PST, Emily Wan <reesw at channing.harvard.edu>
> wrote:
> >Hi -
> >I am working with R on a Window Server 2012 R2 - I had originally
> >installed
> >R (v3.5.1) in September/October 2018 and have used multiple packages
> >without incident. However, last week, when attempting to install
> >additional
> >packages (using install.packages() or Bioconductor's
> >BiocManager::install()
> >wrapper), I kept on receiving the following error message:
> >
> >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> >
> >I have searched the prior threads on this topic (including the issue
> >reported with R v3.4.0 which required a patch), rebooted my server, and
> >actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still
> >receiving
> >the same error message when I attempt to install *any* package.
> >Please let me know what additional details I can provide to assist with
> >troubleshooting. Thank you.
>
> --
> Sent from my phone. Please excuse my brevity.
>

-- 
The information in this e-mail is intended only for the ...{{dropped:18}}


From mer|@m@ne| @end|ng |rom gm@||@com  Wed Jan 16 20:00:07 2019
From: mer|@m@ne| @end|ng |rom gm@||@com (N Meriam)
Date: Wed, 16 Jan 2019 13:00:07 -0600
Subject: [R] =?utf-8?q?R_help=3A_fviz=5Fnbclust=E2=80=99_is_not_available?=
	=?utf-8?q?_=28for_R_version_3=2E5=2E2=29?=
Message-ID: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>

Hello,
I'm struggling to install a function called "fviz_nbclus".

My code is the following:
pkgs <- c("factoextra",  "NbClust")
install.packages(pkgs)
library(factoextra)
library(NbClust)
# Standardize the data
load("df4.rda")
library(FunCluster)

install.packages("fviz_nbclust")
#fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss", "gap_stat"))

Installing package into ?C:/Users/DELL/Documents/R/win-library/3.5?
(as ?lib? is unspecified)
Warning in install.packages :
  package ?fviz_nbclust? is not available (for R version 3.5.2)

Best,
Meriam


From pd@|gd @end|ng |rom gm@||@com  Wed Jan 16 20:04:38 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 16 Jan 2019 20:04:38 +0100
Subject: [R] NA rows appeared in data.frame
In-Reply-To: <a3bb47ad6dd54a909a65a7fd0b992eb1@SRVEXCHCM1302.precheza.cz>
References: <CAF7DXDQXr=s1yevv9jhSBJZaBZuzzA_Psw6w3YD6p1uJyqdVOQ@mail.gmail.com>
 <da1fb6e3-479c-3358-0636-880137e91268@sapo.pt>
 <c3122b1f567847f995637a95d4362a51@SRVEXCHCM1302.precheza.cz>
 <CAF7DXDRt2LcdVujj5ie-JTSOqfDyyiguayJnqvvVn=ZLXD8BZA@mail.gmail.com>
 <a3bb47ad6dd54a909a65a7fd0b992eb1@SRVEXCHCM1302.precheza.cz>
Message-ID: <1CA56AB3-BA1E-4CAC-B57C-D2EA911F61B1@gmail.com>

There is some logic to getting something that you don't know what is when you don't know whether you want it or not. It is certainly more informative than not getting anything, just like if you indexed with FALSE.

However, a more straightforward argument is that when you use integer indexing as a lookup table, as in

color <- c("red","blue")[gender]

then clearly you want NA if gender is NA. The rest then follows from coercion rules: NA is by default mode "logical" and much confusion could happen if x[NA]!=x[NA_integer], for instance x[c(1,NA)] != c(x[1], x[NA]).

-pd

> On 16 Jan 2019, at 08:29 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> I believe that this behaviour has some reason, because you compare 2 to NA and NA is basically "I do not know". So it could be 2 and therefore also rows with NA are returned. If I am wrong, I hope R gurus will correct me.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 16 20:04:54 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 16 Jan 2019 11:04:54 -0800
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
In-Reply-To: <CABAC6SbHfqmz0g=0uurxMkVnp9S9yO=E3bxo+tnze1ZQigtVWw@mail.gmail.com>
References: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
 <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>
 <CABAC6SbHfqmz0g=0uurxMkVnp9S9yO=E3bxo+tnze1ZQigtVWw@mail.gmail.com>
Message-ID: <EDB994F7-4E15-4C0F-8D23-EA2B6FDAF673@dcn.davis.ca.us>

I don't know specifically where that error comes from... but I can think of two possible directions to go:

1) If you have ever run R as Administrator then you may need to delete your personal library (?~/My Documents/R/win-library/3.5?) and reload all packages NOT using Run As Administrator. Any files created by R using those security credentials may impede the function of R when run without those credentials.

2) There have previously been reports that this error arises from the installed.packages function that is invoked by install.packages. This could be related to (1) above or be unrelated. You might confirm on this discussion thread whether this function runs okay for you.

For future reference, use CRAN packages for examples on this mailing list to clarify that the problem is relevant here.

On January 16, 2019 9:48:12 AM PST, Emily Wan <reesw at channing.harvard.edu> wrote:
>Hi Jeff -
>I do not think the issue is Bioconductor (which is why I had posted the
>inquiry on this forum - but as an aside, I do have the latest version
>of
>Bioconductor (3.8)).   As an example, when I attempt to use the generic
>install.packages() function, I receive the same error message. I have
>included an example below (along with the sessionInfo):
>
>> install.packages('stringr')
>Installing package into ?~/My Documents/R/win-library/3.5?
>(as ?lib? is unspecified)
>--- Please select a CRAN mirror for use in this session ---
>also installing the dependencies ?glue?, ?magrittr?
>trying URL '
>https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/glue_1.3.0.zip'
>Content type 'application/zip' length 108591 bytes (106 KB)
>downloaded 106 KB
>trying URL '
>https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/magrittr_1.5.zip
>'
>Content type 'application/zip' length 155452 bytes (151 KB)
>downloaded 151 KB
>trying URL '
>https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/stringr_1.3.1.zip
>'
>Content type 'application/zip' length 194247 bytes (189 KB)
>downloaded 189 KB
>Error in if (any(diff)) { : missing value where TRUE/FALSE needed
>> sessionInfo()
>R version 3.5.2 (2018-12-20)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows Server 2012 R2 x64 (build 9600)
>Matrix products: default
>locale:
>[1] LC_COLLATE=English_United States.1252
>[2] LC_CTYPE=English_United States.1252
>[3] LC_MONETARY=English_United States.1252
>[4] LC_NUMERIC=C
>[5] LC_TIME=English_United States.1252
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>loaded via a namespace (and not attached):
>[1] compiler_3.5.2 tools_3.5.2
>>
>Please let me know what additional information is needed - many thanks.
>
>On Tue, Jan 15, 2019 at 4:51 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Please ask questions about Bioconductor on the Bioconductor forum
>[1].
>>
>> Chances are that you need to re-install Bioconductor because packages
>are
>> installed in two-digit version-specific libraries... e.g. R 3.4 and R
>3.5
>> do not share packages.
>>
>> [1] https://support.bioconductor.org
>>
>> On January 15, 2019 11:51:16 AM PST, Emily Wan
><reesw at channing.harvard.edu>
>> wrote:
>> >Hi -
>> >I am working with R on a Window Server 2012 R2 - I had originally
>> >installed
>> >R (v3.5.1) in September/October 2018 and have used multiple packages
>> >without incident. However, last week, when attempting to install
>> >additional
>> >packages (using install.packages() or Bioconductor's
>> >BiocManager::install()
>> >wrapper), I kept on receiving the following error message:
>> >
>> >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
>> >
>> >I have searched the prior threads on this topic (including the issue
>> >reported with R v3.4.0 which required a patch), rebooted my server,
>and
>> >actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still
>> >receiving
>> >the same error message when I attempt to install *any* package.
>> >Please let me know what additional details I can provide to assist
>with
>> >troubleshooting. Thank you.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Jan 16 20:15:09 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 16 Jan 2019 14:15:09 -0500
Subject: [R] 
	=?utf-8?q?R_help=3A_fviz=5Fnbclust=E2=80=99_is_not_available?=
	=?utf-8?q?_=28for_R_version_3=2E5=2E2=29?=
In-Reply-To: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
References: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
Message-ID: <CAM_vjunh+rmyiA-JJ11WV=PY1H7450Awmuj8reRt8v1YoM7zrw@mail.gmail.com>

Hi,

fviz_nbclust is a function within the package factoextra. Once you
have installed the package and loaded it, you do not need to
explicitly install the function.

You probably also don't need FunCluster - I think you may be confusing
that package with the FUNcluster argument to the fviz_nbclust
function.

Do take a look at
?fviz_nbclust
for help and a working example.

library(factoextra)
library(NbClust)
# Standardize the data
load("df4.rda")
fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss", "gap_stat"))

Sarah

On Wed, Jan 16, 2019 at 2:00 PM N Meriam <meriam.nef at gmail.com> wrote:
>
> Hello,
> I'm struggling to install a function called "fviz_nbclus".
>
> My code is the following:
> pkgs <- c("factoextra",  "NbClust")
> install.packages(pkgs)
> library(factoextra)
> library(NbClust)
> # Standardize the data
> load("df4.rda")
> library(FunCluster)
>
> install.packages("fviz_nbclust")
> #fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss", "gap_stat"))
>
> Installing package into ?C:/Users/DELL/Documents/R/win-library/3.5?
> (as ?lib? is unspecified)
> Warning in install.packages :
>   package ?fviz_nbclust? is not available (for R version 3.5.2)
>
> Best,
> Meriam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 16 20:22:22 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 16 Jan 2019 11:22:22 -0800
Subject: [R] 
 =?utf-8?q?R_help=3A_fviz=5Fnbclust=E2=80=99_is_not_available?=
 =?utf-8?q?_=28for_R_version_3=2E5=2E2=29?=
In-Reply-To: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
References: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
Message-ID: <C7F85E53-FEAC-4DA7-B0CA-DCD5431B79A8@dcn.davis.ca.us>

Concept 1: You don't install functions... you install packages that have functions in them. There is a function fviz_nbclust in factoextra.

Concept 2: Once a package is installed, you do NOT have to install it again, e.g. every time you want to do that analysis. Making the installation part of your script is not advised.

Concept 3: Typically we do use the library function with a package name at the beginning of every session where we want to use functions from that package. However, that is optional... you could also just invoke the function directly using factoextra::fviz_nbclust(...blahblah...). Having the library function shortens this and if the package is not installed it provides a clear error message that can be a reminder to the user to install the package.

Execute your code line by line and solve the first error you encounter by examining the error message and reviewing what that line of code is designed to do.

On January 16, 2019 11:00:07 AM PST, N Meriam <meriam.nef at gmail.com> wrote:
>Hello,
>I'm struggling to install a function called "fviz_nbclus".
>
>My code is the following:
>pkgs <- c("factoextra",  "NbClust")
>install.packages(pkgs)
>library(factoextra)
>library(NbClust)
># Standardize the data
>load("df4.rda")
>library(FunCluster)
>
>install.packages("fviz_nbclust")
>#fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss",
>"gap_stat"))
>
>Installing package into ?C:/Users/DELL/Documents/R/win-library/3.5?
>(as ?lib? is unspecified)
>Warning in install.packages :
>  package ?fviz_nbclust? is not available (for R version 3.5.2)
>
>Best,
>Meriam
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Jan 16 20:41:57 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 16 Jan 2019 11:41:57 -0800
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
In-Reply-To: <EDB994F7-4E15-4C0F-8D23-EA2B6FDAF673@dcn.davis.ca.us>
References: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
 <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>
 <CABAC6SbHfqmz0g=0uurxMkVnp9S9yO=E3bxo+tnze1ZQigtVWw@mail.gmail.com>
 <EDB994F7-4E15-4C0F-8D23-EA2B6FDAF673@dcn.davis.ca.us>
Message-ID: <CAFDcVCSoP5r=UbNaG-sVbdqA=6Dr0=tuSjvV6nv4hAQPqGa0dw@mail.gmail.com>

Immediately after you get that error:

Error in if (any(diff)) { : missing value where TRUE/FALSE needed

what does

> traceback()

output?  (I suspect this error occurs in tools:::checkMD5sums() used
to assert that the package files are correctly downloaded).  Also,
going forward, let's try with a single package installed, e.g.
install.packages("glue").   Does that also give an error?

/Henrik


On Wed, Jan 16, 2019 at 11:10 AM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> I don't know specifically where that error comes from... but I can think of two possible directions to go:
>
> 1) If you have ever run R as Administrator then you may need to delete your personal library (?~/My Documents/R/win-library/3.5?) and reload all packages NOT using Run As Administrator. Any files created by R using those security credentials may impede the function of R when run without those credentials.
>
> 2) There have previously been reports that this error arises from the installed.packages function that is invoked by install.packages. This could be related to (1) above or be unrelated. You might confirm on this discussion thread whether this function runs okay for you.
>
> For future reference, use CRAN packages for examples on this mailing list to clarify that the problem is relevant here.
>
> On January 16, 2019 9:48:12 AM PST, Emily Wan <reesw at channing.harvard.edu> wrote:
> >Hi Jeff -
> >I do not think the issue is Bioconductor (which is why I had posted the
> >inquiry on this forum - but as an aside, I do have the latest version
> >of
> >Bioconductor (3.8)).   As an example, when I attempt to use the generic
> >install.packages() function, I receive the same error message. I have
> >included an example below (along with the sessionInfo):
> >
> >> install.packages('stringr')
> >Installing package into ?~/My Documents/R/win-library/3.5?
> >(as ?lib? is unspecified)
> >--- Please select a CRAN mirror for use in this session ---
> >also installing the dependencies ?glue?, ?magrittr?
> >trying URL '
> >https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/glue_1.3.0.zip'
> >Content type 'application/zip' length 108591 bytes (106 KB)
> >downloaded 106 KB
> >trying URL '
> >https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/magrittr_1.5.zip
> >'
> >Content type 'application/zip' length 155452 bytes (151 KB)
> >downloaded 151 KB
> >trying URL '
> >https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/stringr_1.3.1.zip
> >'
> >Content type 'application/zip' length 194247 bytes (189 KB)
> >downloaded 189 KB
> >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> >> sessionInfo()
> >R version 3.5.2 (2018-12-20)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >Running under: Windows Server 2012 R2 x64 (build 9600)
> >Matrix products: default
> >locale:
> >[1] LC_COLLATE=English_United States.1252
> >[2] LC_CTYPE=English_United States.1252
> >[3] LC_MONETARY=English_United States.1252
> >[4] LC_NUMERIC=C
> >[5] LC_TIME=English_United States.1252
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
> >loaded via a namespace (and not attached):
> >[1] compiler_3.5.2 tools_3.5.2
> >>
> >Please let me know what additional information is needed - many thanks.
> >
> >On Tue, Jan 15, 2019 at 4:51 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Please ask questions about Bioconductor on the Bioconductor forum
> >[1].
> >>
> >> Chances are that you need to re-install Bioconductor because packages
> >are
> >> installed in two-digit version-specific libraries... e.g. R 3.4 and R
> >3.5
> >> do not share packages.
> >>
> >> [1] https://support.bioconductor.org
> >>
> >> On January 15, 2019 11:51:16 AM PST, Emily Wan
> ><reesw at channing.harvard.edu>
> >> wrote:
> >> >Hi -
> >> >I am working with R on a Window Server 2012 R2 - I had originally
> >> >installed
> >> >R (v3.5.1) in September/October 2018 and have used multiple packages
> >> >without incident. However, last week, when attempting to install
> >> >additional
> >> >packages (using install.packages() or Bioconductor's
> >> >BiocManager::install()
> >> >wrapper), I kept on receiving the following error message:
> >> >
> >> >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> >> >
> >> >I have searched the prior threads on this topic (including the issue
> >> >reported with R v3.4.0 which required a patch), rebooted my server,
> >and
> >> >actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still
> >> >receiving
> >> >the same error message when I attempt to install *any* package.
> >> >Please let me know what additional details I can provide to assist
> >with
> >> >troubleshooting. Thank you.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mer|@m@ne| @end|ng |rom gm@||@com  Wed Jan 16 20:48:03 2019
From: mer|@m@ne| @end|ng |rom gm@||@com (N Meriam)
Date: Wed, 16 Jan 2019 13:48:03 -0600
Subject: [R] 
	=?utf-8?q?R_help=3A_fviz=5Fnbclust=E2=80=99_is_not_available?=
	=?utf-8?q?_=28for_R_version_3=2E5=2E2=29?=
In-Reply-To: <C7F85E53-FEAC-4DA7-B0CA-DCD5431B79A8@dcn.davis.ca.us>
References: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
 <C7F85E53-FEAC-4DA7-B0CA-DCD5431B79A8@dcn.davis.ca.us>
Message-ID: <CAL1He1+fDOiV6-V1JuvK8CCoJaE-NVGPkEuvu-=idTX2BCBfMg@mail.gmail.com>

Thanks for your valuable clarifications.
I tried all the steps again but the problem remains.
In fact,  "fviz_nbclust" is a function inside the package "factoextra".
I run each step very carefully but the problem remains...It doesn't
make sense because I have installed factoextra.

This warning appears:
could not find function "fviz_nbclust"

On Wed, Jan 16, 2019 at 1:22 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Concept 1: You don't install functions... you install packages that have functions in them. There is a function fviz_nbclust in factoextra.
>
> Concept 2: Once a package is installed, you do NOT have to install it again, e.g. every time you want to do that analysis. Making the installation part of your script is not advised.
>
> Concept 3: Typically we do use the library function with a package name at the beginning of every session where we want to use functions from that package. However, that is optional... you could also just invoke the function directly using factoextra::fviz_nbclust(...blahblah...). Having the library function shortens this and if the package is not installed it provides a clear error message that can be a reminder to the user to install the package.
>
> Execute your code line by line and solve the first error you encounter by examining the error message and reviewing what that line of code is designed to do.
>
> On January 16, 2019 11:00:07 AM PST, N Meriam <meriam.nef at gmail.com> wrote:
> >Hello,
> >I'm struggling to install a function called "fviz_nbclus".
> >
> >My code is the following:
> >pkgs <- c("factoextra",  "NbClust")
> >install.packages(pkgs)
> >library(factoextra)
> >library(NbClust)
> ># Standardize the data
> >load("df4.rda")
> >library(FunCluster)
> >
> >install.packages("fviz_nbclust")
> >#fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss",
> >"gap_stat"))
> >
> >Installing package into ?C:/Users/DELL/Documents/R/win-library/3.5?
> >(as ?lib? is unspecified)
> >Warning in install.packages :
> >  package ?fviz_nbclust? is not available (for R version 3.5.2)
> >
> >Best,
> >Meriam
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Meriam Nefzaoui
MSc. in Plant Breeding and Genetics
Universidade Federal Rural de Pernambuco (UFRPE) - Recife, Brazil


From ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu  Wed Jan 16 21:31:12 2019
From: ree@w @end|ng |rom ch@nn|ng@h@rv@rd@edu (Emily Wan)
Date: Wed, 16 Jan 2019 15:31:12 -0500
Subject: [R] Error with install.packages using R v 3.5.1 and 3.5.2
In-Reply-To: <CAFDcVCSoP5r=UbNaG-sVbdqA=6Dr0=tuSjvV6nv4hAQPqGa0dw@mail.gmail.com>
References: <CABAC6SYWCxKwtDVKqrW+Gh6itj-vPQ4c8sGRTZitB=FokH4NdA@mail.gmail.com>
 <8B55112E-C516-4D19-B243-4309D667EACA@dcn.davis.ca.us>
 <CABAC6SbHfqmz0g=0uurxMkVnp9S9yO=E3bxo+tnze1ZQigtVWw@mail.gmail.com>
 <EDB994F7-4E15-4C0F-8D23-EA2B6FDAF673@dcn.davis.ca.us>
 <CAFDcVCSoP5r=UbNaG-sVbdqA=6Dr0=tuSjvV6nv4hAQPqGa0dw@mail.gmail.com>
Message-ID: <CABAC6SaQ93gBMGOU9=ndqqJ4c76Mg=XVSx2E_XGhXCBjCq+PVA@mail.gmail.com>

Henrik and Jeff -
Thank you both for your thoughts and helpful suggestions on this problem -
a colleague and I did some forensics on this end and discovered the issue
was related to a combination of 1) slow network connections and 2) having
my personal library installed on a different server from where R was
installed.  When we reassigned the libPath() to the "local drive" (same
virtual machine that R was installed on - after getting write permissions
for that drive), the issue was resolved.
Thank you both for your responses!

On Wed, Jan 16, 2019 at 2:42 PM Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> Immediately after you get that error:
>
> Error in if (any(diff)) { : missing value where TRUE/FALSE needed
>
> what does
>
> > traceback()
>
> output?  (I suspect this error occurs in tools:::checkMD5sums() used
> to assert that the package files are correctly downloaded).  Also,
> going forward, let's try with a single package installed, e.g.
> install.packages("glue").   Does that also give an error?
>
> /Henrik
>
>
> On Wed, Jan 16, 2019 at 11:10 AM Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> >
> > I don't know specifically where that error comes from... but I can think
> of two possible directions to go:
> >
> > 1) If you have ever run R as Administrator then you may need to delete
> your personal library (?~/My Documents/R/win-library/3.5?) and reload all
> packages NOT using Run As Administrator. Any files created by R using those
> security credentials may impede the function of R when run without those
> credentials.
> >
> > 2) There have previously been reports that this error arises from the
> installed.packages function that is invoked by install.packages. This could
> be related to (1) above or be unrelated. You might confirm on this
> discussion thread whether this function runs okay for you.
> >
> > For future reference, use CRAN packages for examples on this mailing
> list to clarify that the problem is relevant here.
> >
> > On January 16, 2019 9:48:12 AM PST, Emily Wan <
> reesw at channing.harvard.edu> wrote:
> > >Hi Jeff -
> > >I do not think the issue is Bioconductor (which is why I had posted the
> > >inquiry on this forum - but as an aside, I do have the latest version
> > >of
> > >Bioconductor (3.8)).   As an example, when I attempt to use the generic
> > >install.packages() function, I receive the same error message. I have
> > >included an example below (along with the sessionInfo):
> > >
> > >> install.packages('stringr')
> > >Installing package into ?~/My Documents/R/win-library/3.5?
> > >(as ?lib? is unspecified)
> > >--- Please select a CRAN mirror for use in this session ---
> > >also installing the dependencies ?glue?, ?magrittr?
> > >trying URL '
> > >
> https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/glue_1.3.0.zip
> '
> > >Content type 'application/zip' length 108591 bytes (106 KB)
> > >downloaded 106 KB
> > >trying URL '
> > >
> https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/magrittr_1.5.zip
> > >'
> > >Content type 'application/zip' length 155452 bytes (151 KB)
> > >downloaded 151 KB
> > >trying URL '
> > >
> https://cran.revolutionanalytics.com/bin/windows/contrib/3.5/stringr_1.3.1.zip
> > >'
> > >Content type 'application/zip' length 194247 bytes (189 KB)
> > >downloaded 189 KB
> > >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> > >> sessionInfo()
> > >R version 3.5.2 (2018-12-20)
> > >Platform: x86_64-w64-mingw32/x64 (64-bit)
> > >Running under: Windows Server 2012 R2 x64 (build 9600)
> > >Matrix products: default
> > >locale:
> > >[1] LC_COLLATE=English_United States.1252
> > >[2] LC_CTYPE=English_United States.1252
> > >[3] LC_MONETARY=English_United States.1252
> > >[4] LC_NUMERIC=C
> > >[5] LC_TIME=English_United States.1252
> > >attached base packages:
> > >[1] stats     graphics  grDevices utils     datasets  methods   base
> > >loaded via a namespace (and not attached):
> > >[1] compiler_3.5.2 tools_3.5.2
> > >>
> > >Please let me know what additional information is needed - many thanks.
> > >
> > >On Tue, Jan 15, 2019 at 4:51 PM Jeff Newmiller
> > ><jdnewmil at dcn.davis.ca.us>
> > >wrote:
> > >
> > >> Please ask questions about Bioconductor on the Bioconductor forum
> > >[1].
> > >>
> > >> Chances are that you need to re-install Bioconductor because packages
> > >are
> > >> installed in two-digit version-specific libraries... e.g. R 3.4 and R
> > >3.5
> > >> do not share packages.
> > >>
> > >> [1] https://support.bioconductor.org
> > >>
> > >> On January 15, 2019 11:51:16 AM PST, Emily Wan
> > ><reesw at channing.harvard.edu>
> > >> wrote:
> > >> >Hi -
> > >> >I am working with R on a Window Server 2012 R2 - I had originally
> > >> >installed
> > >> >R (v3.5.1) in September/October 2018 and have used multiple packages
> > >> >without incident. However, last week, when attempting to install
> > >> >additional
> > >> >packages (using install.packages() or Bioconductor's
> > >> >BiocManager::install()
> > >> >wrapper), I kept on receiving the following error message:
> > >> >
> > >> >Error in if (any(diff)) { : missing value where TRUE/FALSE needed
> > >> >
> > >> >I have searched the prior threads on this topic (including the issue
> > >> >reported with R v3.4.0 which required a patch), rebooted my server,
> > >and
> > >> >actually uninstalled R v3.5.1 and upgraded to v3.5.2 but am still
> > >> >receiving
> > >> >the same error message when I attempt to install *any* package.
> > >> >Please let me know what additional details I can provide to assist
> > >with
> > >> >troubleshooting. Thank you.
> > >>
> > >> --
> > >> Sent from my phone. Please excuse my brevity.
> > >>
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

-- 
The information in this e-mail is intended only for the ...{{dropped:18}}


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 16 21:27:31 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 16 Jan 2019 12:27:31 -0800
Subject: [R] 
 =?utf-8?q?R_help=3A_fviz=5Fnbclust=E2=80=99_is_not_available?=
 =?utf-8?q?_=28for_R_version_3=2E5=2E2=29?=
In-Reply-To: <CAL1He1+fDOiV6-V1JuvK8CCoJaE-NVGPkEuvu-=idTX2BCBfMg@mail.gmail.com>
References: <CAL1He1LL=NGnoL-FQHkderQVwSz5EWv-FhNZ8eBKEkxNjafKnQ@mail.gmail.com>
 <C7F85E53-FEAC-4DA7-B0CA-DCD5431B79A8@dcn.davis.ca.us>
 <CAL1He1+fDOiV6-V1JuvK8CCoJaE-NVGPkEuvu-=idTX2BCBfMg@mail.gmail.com>
Message-ID: <90172534-AF46-4F3A-9D3D-135DC3C9303E@dcn.davis.ca.us>

Indeed, if you repeat the code you provided before then the problem will not go away because you are not using the knowledge we have given you. You need to show us what you are trying differently based on the explanations provided on the mailing list. If you don't do this then we cannot move forward to more specific answers.

As a reminder:

> Execute your code line by line and solve the first error you
>encounter by examining the error message and reviewing what that line
>of code is designed to do.

On January 16, 2019 11:48:03 AM PST, N Meriam <meriam.nef at gmail.com> wrote:
>Thanks for your valuable clarifications.
>I tried all the steps again but the problem remains.
>In fact,  "fviz_nbclust" is a function inside the package "factoextra".
>I run each step very carefully but the problem remains...It doesn't
>make sense because I have installed factoextra.
>
>This warning appears:
>could not find function "fviz_nbclust"
>
>On Wed, Jan 16, 2019 at 1:22 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Concept 1: You don't install functions... you install packages that
>have functions in them. There is a function fviz_nbclust in factoextra.
>>
>> Concept 2: Once a package is installed, you do NOT have to install it
>again, e.g. every time you want to do that analysis. Making the
>installation part of your script is not advised.
>>
>> Concept 3: Typically we do use the library function with a package
>name at the beginning of every session where we want to use functions
>from that package. However, that is optional... you could also just
>invoke the function directly using
>factoextra::fviz_nbclust(...blahblah...). Having the library function
>shortens this and if the package is not installed it provides a clear
>error message that can be a reminder to the user to install the
>package.
>>
>> Execute your code line by line and solve the first error you
>encounter by examining the error message and reviewing what that line
>of code is designed to do.
>>
>> On January 16, 2019 11:00:07 AM PST, N Meriam <meriam.nef at gmail.com>
>wrote:
>> >Hello,
>> >I'm struggling to install a function called "fviz_nbclus".
>> >
>> >My code is the following:
>> >pkgs <- c("factoextra",  "NbClust")
>> >install.packages(pkgs)
>> >library(factoextra)
>> >library(NbClust)
>> ># Standardize the data
>> >load("df4.rda")
>> >library(FunCluster)
>> >
>> >install.packages("fviz_nbclust")
>> >#fviz_nbclust(df4, FUNcluster, method = c("silhouette", "wss",
>> >"gap_stat"))
>> >
>> >Installing package into ?C:/Users/DELL/Documents/R/win-library/3.5?
>> >(as ?lib? is unspecified)
>> >Warning in install.packages :
>> >  package ?fviz_nbclust? is not available (for R version 3.5.2)
>> >
>> >Best,
>> >Meriam
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Thu Jan 17 00:50:00 2019
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 16 Jan 2019 18:50:00 -0500
Subject: [R] R Companion to Linear Statistical Models by KNNL
Message-ID: <CAE9stmc2-qhNNjsjON00roNnMSx9vuChY7S5h=B7G4=RfoejdA@mail.gmail.com>

Dear All:


I am wondering if there is An R Companion to Linear Statistical Models
*by  *Kutner, Nachtsheim, Neter, and Li. Any help would be appreciated.


with many thanks

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 17 01:08:39 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 16 Jan 2019 16:08:39 -0800
Subject: [R] R Companion to Linear Statistical Models by KNNL
In-Reply-To: <CAE9stmc2-qhNNjsjON00roNnMSx9vuChY7S5h=B7G4=RfoejdA@mail.gmail.com>
References: <CAE9stmc2-qhNNjsjON00roNnMSx9vuChY7S5h=B7G4=RfoejdA@mail.gmail.com>
Message-ID: <CAGxFJbRnKMUJTR5a3mohMcyVuSp_XEYx1Xb-ed=rM5Mp_0_Pkg@mail.gmail.com>

See here for relevant comments:

https://stats.stackexchange.com/questions/64406/r-code-for-kutner-et-als-applied-linear-statistical-models


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 16, 2019 at 3:51 PM AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All:
>
>
> I am wondering if there is An R Companion to Linear Statistical Models
> *by  *Kutner, Nachtsheim, Neter, and Li. Any help would be appreciated.
>
>
> with many thanks
>
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From KW@m@e @end|ng |rom kemr|-we||come@org  Thu Jan 17 01:29:18 2019
From: KW@m@e @end|ng |rom kemr|-we||come@org (Kevin Wamae)
Date: Thu, 17 Jan 2019 00:29:18 +0000
Subject: [R] create groups from data with duplicates,
 such that each group has a duplicate represented once
Message-ID: <F9045ADB-02A9-4EAF-AD1B-89307ECCDDC3@kemri-wellcome.org>

Hi, I have a sequencing run with ~3000 samples (attached dataset). The samples were initially tagged and amplified by PCR in duplicate. The tags used range from MID01 to MID26.

MID01-MID13 were used for pair 1 while MID14-MID26 were used for pair 2. The tags are re-used to allow samples to be pooled.

The pooling process will involve mixing samples with MID01-26 into the first group, the next group samples with MID01-26 into the second group and so on.

I'm hoping to get an R script that can create these groups such that for each group, any of the Tags appears only once. An example is shown below.

ID

TagA

TagB

group

180

MID03

MID10

group1

181

MID04

MID06

group1

182

MID05

MID07

group1

183

MID03

MID09

group2

184

MID04

MID10

group2

185

MID05

MID06

group2

186

MID01

MID06

group3

187

MID02

MID07

group3

188

MID03

MID08

group3



______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

From reichm@@j m@iii@g oii sbcgiob@i@@et  Thu Jan 17 01:31:15 2019
From: reichm@@j m@iii@g oii sbcgiob@i@@et (reichm@@j m@iii@g oii sbcgiob@i@@et)
Date: Wed, 16 Jan 2019 18:31:15 -0600
Subject: [R] Confusion Table
Message-ID: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>

R-Help

 

R-Help community is there an simple straight forward way  of changing my
confusion table output to list "Yes" before "No" rather than "No" before
"Yes" - R default.

 

# Making predictions on the test set.

tst_pred <- ifelse(predict(model_glm, newdata = default_tst, type =
"response") > 0.5, "Yes", "No")

tst_tab <- table(predicted = tst_pred, actual = default_tst$default)

tst_tab

 

##                    actual

## predicted   No  Yes

##          No  4817  113

##          Yes      18    52

 

Jeff


	[[alternative HTML version deleted]]


From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Jan 17 01:48:03 2019
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Wed, 16 Jan 2019 16:48:03 -0800
Subject: [R] Confusion Table
In-Reply-To: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
References: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
Message-ID: <CA+hbrhULm_jhFh_JU1Hqu0Rg_yxc6Sv7zXwnaHFL=J57seyqMQ@mail.gmail.com>

The lazy way is to do

tst_tab = tst_tab[c(2,1), c(2,1)]

The less lazy way is something like

tst_tab <- table(predicted = factor(tst_pred, levels = c("Yes",
"No")),  actual = factor(default_tst$default, levels = c("Yes",
"No")))

Peter

On Wed, Jan 16, 2019 at 4:39 PM <reichmanj at sbcglobal.net> wrote:
>
> R-Help
>
>
>
> R-Help community is there an simple straight forward way  of changing my
> confusion table output to list "Yes" before "No" rather than "No" before
> "Yes" - R default.
>
>
>
> # Making predictions on the test set.
>
> tst_pred <- ifelse(predict(model_glm, newdata = default_tst, type =
> "response") > 0.5, "Yes", "No")
>
> tst_tab <- table(predicted = tst_pred, actual = default_tst$default)
>
> tst_tab
>
>
>
> ##                    actual
>
> ## predicted   No  Yes
>
> ##          No  4817  113
>
> ##          Yes      18    52
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 17 01:48:51 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 16 Jan 2019 16:48:51 -0800
Subject: [R] Confusion Table
In-Reply-To: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
References: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
Message-ID: <436430CB-4F2F-40E4-BE28-CE2A8A4C1FE8@dcn.davis.ca.us>

If you turn your character variable into a factor and specify the levels argument, you can control the sequence in which any discrete values are presented.

tst_pred <- factor( tst_pred, levels=c("No","Yes") )

On January 16, 2019 4:31:15 PM PST, reichmanj at sbcglobal.net wrote:
>R-Help
>
> 
>
>R-Help community is there an simple straight forward way  of changing
>my
>confusion table output to list "Yes" before "No" rather than "No"
>before
>"Yes" - R default.
>
> 
>
># Making predictions on the test set.
>
>tst_pred <- ifelse(predict(model_glm, newdata = default_tst, type =
>"response") > 0.5, "Yes", "No")
>
>tst_tab <- table(predicted = tst_pred, actual = default_tst$default)
>
>tst_tab
>
> 
>
>##                    actual
>
>## predicted   No  Yes
>
>##          No  4817  113
>
>##          Yes      18    52
>
> 
>
>Jeff
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From reichm@@j m@iii@g oii sbcgiob@i@@et  Thu Jan 17 02:49:45 2019
From: reichm@@j m@iii@g oii sbcgiob@i@@et (reichm@@j m@iii@g oii sbcgiob@i@@et)
Date: Wed, 16 Jan 2019 19:49:45 -0600
Subject: [R] Confusion Table
In-Reply-To: <CA+hbrhULm_jhFh_JU1Hqu0Rg_yxc6Sv7zXwnaHFL=J57seyqMQ@mail.gmail.com>
References: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
 <CA+hbrhULm_jhFh_JU1Hqu0Rg_yxc6Sv7zXwnaHFL=J57seyqMQ@mail.gmail.com>
Message-ID: <000d01d4ae06$ee9ab4a0$cbd01de0$@sbcglobal.net>

That's easy enough 

Thanks

-----Original Message-----
From: Peter Langfelder <peter.langfelder at gmail.com> 
Sent: Wednesday, January 16, 2019 6:48 PM
To: reichmanj at sbcglobal.net
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] Confusion Table

The lazy way is to do

tst_tab = tst_tab[c(2,1), c(2,1)]

The less lazy way is something like

tst_tab <- table(predicted = factor(tst_pred, levels = c("Yes", "No")),  actual = factor(default_tst$default, levels = c("Yes",
"No")))

Peter

On Wed, Jan 16, 2019 at 4:39 PM <reichmanj at sbcglobal.net> wrote:
>
> R-Help
>
>
>
> R-Help community is there an simple straight forward way  of changing 
> my confusion table output to list "Yes" before "No" rather than "No" 
> before "Yes" - R default.
>
>
>
> # Making predictions on the test set.
>
> tst_pred <- ifelse(predict(model_glm, newdata = default_tst, type =
> "response") > 0.5, "Yes", "No")
>
> tst_tab <- table(predicted = tst_pred, actual = default_tst$default)
>
> tst_tab
>
>
>
> ##                    actual
>
> ## predicted   No  Yes
>
> ##          No  4817  113
>
> ##          Yes      18    52
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reichm@@j m@iii@g oii sbcgiob@i@@et  Thu Jan 17 02:50:11 2019
From: reichm@@j m@iii@g oii sbcgiob@i@@et (reichm@@j m@iii@g oii sbcgiob@i@@et)
Date: Wed, 16 Jan 2019 19:50:11 -0600
Subject: [R] Confusion Table
In-Reply-To: <436430CB-4F2F-40E4-BE28-CE2A8A4C1FE8@dcn.davis.ca.us>
References: <000801d4adfb$f5356220$dfa02660$@sbcglobal.net>
 <436430CB-4F2F-40E4-BE28-CE2A8A4C1FE8@dcn.davis.ca.us>
Message-ID: <000e01d4ae06$fc6b6340$f54229c0$@sbcglobal.net>

Ah yes - thank you

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, January 16, 2019 6:49 PM
To: r-help at r-project.org; reichmanj at sbcglobal.net
Subject: Re: [R] Confusion Table

If you turn your character variable into a factor and specify the levels argument, you can control the sequence in which any discrete values are presented.

tst_pred <- factor( tst_pred, levels=c("No","Yes") )

On January 16, 2019 4:31:15 PM PST, reichmanj at sbcglobal.net wrote:
>R-Help
>
> 
>
>R-Help community is there an simple straight forward way  of changing 
>my confusion table output to list "Yes" before "No" rather than "No"
>before
>"Yes" - R default.
>
> 
>
># Making predictions on the test set.
>
>tst_pred <- ifelse(predict(model_glm, newdata = default_tst, type =
>"response") > 0.5, "Yes", "No")
>
>tst_tab <- table(predicted = tst_pred, actual = default_tst$default)
>
>tst_tab
>
> 
>
>##                    actual
>
>## predicted   No  Yes
>
>##          No  4817  113
>
>##          Yes      18    52
>
> 
>
>Jeff
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jan 17 02:59:44 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 17 Jan 2019 01:59:44 +0000
Subject: [R] importing data error question
In-Reply-To: <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
 <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
Message-ID: <4003829E-5D14-4798-A45D-BF85DA42EF20@mcmaster.ca>

Dear Jihee,

Probably the easiest way to change the language to English temporarily in R is to enter the command

	Sys.setenv(LANGUAGE="en")

at the R command prompt prior to loading the Rcmdr package.

I hope that this helps,
 John


> On Jan 16, 2019, at 7:02 PM, ??? <wjh1518 at ht.co.kr> wrote:
> 
> Thanks for your help!
>  
> I was having trouble with finding how to use english...
>  
> Even though I try to use english language, I couldn't change language of R commander. (it is still korean)
>  
> Sorry but.. do you know how to change language of "R commander"? I have no idea why it doesn't change.
>  
> Best,
> Jihee
>  
> From: "Fox, John" <jfox at mcmaster.ca>
> Sent: Thursday, January 17, 2019 1:59:03 AM
> To:"???" <wjh1518 at ht.co.kr>
> Cc:"r-help at r-project.org" <r-help at r-project.org>
> Subject:Re: [R] importing data error question
>  
>  
> Dear jihee,
> 
> I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:
> 
> I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.
> 
> I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.
> 
> I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.
> 
> Thank you for reporting this issue.
> 
> John
> 
> > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > 
> > Dear jihee,
> > 
> >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> >> 
> >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
> >> 
> >> --> no, I never said i was using a Mac. 
> > 
> > Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
> > 
> >> 
> >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
> >> 
> >> --> sessionInfo()
> >> R version 3.5.2 (2018-12-20)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >> Running under: Windows 7 x64 (build 7601) Service Pack 1
> >> 
> >> Matrix products: default
> >> 
> >> locale:
> >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949  
> >> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C  
> >> [5] LC_TIME=Korean_Korea.949  
> >> 
> >> attached base packages:
> >> [1] tcltk splines stats graphics grDevices utils datasets methods  
> >> [9] base  
> >> 
> >> other attached packages:
> >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
> >> [3] Rcmdr_2.5-1 effects_4.1-0  
> >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0  
> >> [7] car_3.0-2 carData_3.0-2  
> >> [9] SensoMineR_1.23 FactoMineR_1.41  
> >> 
> >> loaded via a namespace (and not attached):
> >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28 
> >> [4] cellranger_1.1.0 pillar_1.3.1 backports_1.1.3  
> >> [7] lattice_0.20-38 digest_0.6.18 RColorBrewer_1.1-2  
> >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2  
> >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15  
> >> [16] plyr_1.8.4 pkgconfig_2.0.2 haven_2.0.0  
> >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16  
> >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2  
> >> [25] relimp_1.0-5 ggplot2_3.1.0 nnet_7.3-12  
> >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5  
> >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137  
> >> [34] MASS_7.3-51.1 forcats_0.3.0 foreign_0.8-71  
> >> [37] class_7.3-14 tools_3.5.2 data.table_1.11.8  
> >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1  
> >> [43] munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0  
> >> [46] flashClust_1.01-2 compiler_3.5.2 e1071_1.7-0  
> >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1  
> >> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0  
> >> [55] base64enc_0.1-3 gtable_0.2.0 abind_1.4-5  
> >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3  
> >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21  
> >> [64] nortest_1.0-4 Hmisc_4.1-1 KernSmooth_2.23-15  
> >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13  
> >> [70] acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4  
> >> 
> >> This was the status that I tried to import Excel data. 
> > 
> > These packages seem up-to-date.
> > 
> >> 
> >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
> >> 
> >> --> I tried without plug-in packages, but It didn't work. 
> > 
> > OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
> > 
> >> 
> >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
> >> 
> >> --> I don't know what is plain-text data file..... 
> > 
> > A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
> > 
> >> 
> >> i'll try R with English. 
> > 
> > I'm curious to see what happens.
> > 
> > Best,
> > John
> > 
> >> 
> >> From: "Fox, John" <jfox at mcmaster.ca> 
> >> 
> >> Sent: Monday, January 14, 2019 11:15:36 PM 
> >> 
> >> To:"???" <wjh1518 at ht.co.kr> 
> >> 
> >> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
> >> 
> >> Subject:Re: [R] importing data error question 
> >> 
> >> Dear jihee,
> >> 
> >>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
> >>> 
> >>> 
> >>> 
> >>> From: "???" <wjh1518 at ht.co.kr>
> >>> Sent: Monday, January 14, 2019 9:40:26 AM
> >>> To:"Fox, John" <jfox at mcmaster.ca>
> >>> Subject:Re: [R] importing data error question
> >>> 
> >>> 
> >>> Thanks for your replies.
> >>> 
> >>> I'm using windows 7, I loaded FactoMineR,
> >> 
> >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
> >> 
> >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
> >>> This problem occurred when I select Data > Import data > From Excel file.
> >>> I checked FactoMineR and SensoMineR packages are loaded and using..
> >> 
> >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
> >> 
> >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
> >> 
> >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
> >> 
> >> Best,
> >> John
> >> 
> >>> 
> >>> 
> >>> 
> >>> From: "Fox, John" <jfox at mcmaster.ca>
> >>> Sent: Friday, January 11, 2019 10:48:38 PM
> >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
> >>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
> >>> Subject:Re: [R] importing data error question
> >>> 
> >>> 
> >>> Dear Petr and jihee,
> >>> 
> >>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
> >>> 
> >>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
> >>> 
> >>> Best,
> >>> John
> >>> 
> >>> -------------------------------------------------
> >>> John Fox, Professor Emeritus
> >>> McMaster University
> >>> Hamilton, Ontario, Canada
> >>> Web: http::/socserv.mcmaster.ca/jfox
> >>> 
> >>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >>>> 
> >>>> Hi
> >>>> 
> >>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> >>>> 
> >>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> >>>> 
> >>>> Cheers
> >>>> Petr
> >>>> 
> >>>>> -----Original Message-----
> >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> >>>>> Sent: Friday, January 11, 2019 9:14 AM
> >>>>> To: r-help at R-project.org
> >>>>> Subject: [R] importing data error question
> >>>>> 
> >>>>> Hi I'm jihee and I have a question about error...
> >>>>> 
> >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
> >>>>> 
> >>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
> >>>>> 
> >>>>> but i can't import excel data with Rcmdr.
> >>>>> 
> >>>>> it has this messege :
> >>>>> 
> >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> >>>>> [tcl] bad Macintosh file type "?*?"
> >>>>> 
> >>>>> what is wrong with my R??? T_T
> >>>>> 
> >>>>> Thanks for your help.
> >>>>> 
> >>>>> jihee.
> >>>>> [[alternative HTML version deleted]]
> >>>>> 
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >>>> 
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>> 
> >>> 
> >>> 
> >>> 
> >>> ??? ??? / ??????
> >>> e-mailwjh1518 at ht.co.krDirMobile
> >>> ????www.ht.co.kr????www.facebook.com/haitaico
> >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> >>> 
> >>> 
> >>> 
> >>> 
> >>> ??? ??? / ??????
> >>> e-mailwjh1518 at ht.co.krDirMobile
> >>> ????www.ht.co.kr????www.facebook.com/haitaico
> >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
> >> [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jan 17 06:09:52 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 17 Jan 2019 05:09:52 +0000
Subject: [R] importing data error question
In-Reply-To: <7b06b392-2611-411a-ba0e-4edd2a8f1045@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
 <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
 <4003829E-5D14-4798-A45D-BF85DA42EF20@mcmaster.ca>
 <7b06b392-2611-411a-ba0e-4edd2a8f1045@ht.co.kr>
Message-ID: <7188EC66-9F43-41BA-9EA7-D1C573508304@mcmaster.ca>

Dear Jihee,

This appears to be a different problem. You were  apparently able to access the spreadsheet file, but the R Commander didn't find a suitable worksheet in it.

Try downloading and reading the file at <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>. If that works, send me privately (i.e., directly) your Excel spreadsheet file and I'll take a look at it.

Best,
 John

> On Jan 16, 2019, at 9:49 PM, ??? <wjh1518 at ht.co.kr> wrote:
> 
> Dear John,
>  
> now i can use english thank you very much!!
>  
> um.. but nothing's changed... with that {r} message at R Markdown.
>  
> There's no dataset.
>  
> i tried both .xls and .xlsx .
>  
>  
> Jihee
>  
>  
>  
> <fbe6254214d94e74b98569b08bb3bf07.png>
>  
>  
>  
> From: "Fox, John" <jfox at mcmaster.ca>
> Sent: Thursday, January 17, 2019 10:59:44 AM
> To:"???" <wjh1518 at ht.co.kr>
> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> Subject:Re: [R] importing data error question
>  
>  
> Dear Jihee,
> 
> Probably the easiest way to change the language to English temporarily in R is to enter the command
> 
> Sys.setenv(LANGUAGE="en")
> 
> at the R command prompt prior to loading the Rcmdr package.
> 
> I hope that this helps,
> John
> 
> 
> > On Jan 16, 2019, at 7:02 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > 
> > Thanks for your help!
> >  
> > I was having trouble with finding how to use english...
> >  
> > Even though I try to use english language, I couldn't change language of R commander. (it is still korean)
> >  
> > Sorry but.. do you know how to change language of "R commander"? I have no idea why it doesn't change.
> >  
> > Best,
> > Jihee
> >  
> > From: "Fox, John" <jfox at mcmaster.ca>
> > Sent: Thursday, January 17, 2019 1:59:03 AM
> > To:"???" <wjh1518 at ht.co.kr>
> > Cc:"r-help at r-project.org" <r-help at r-project.org>
> > Subject:Re: [R] importing data error question
> >  
> >  
> > Dear jihee,
> > 
> > I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:
> > 
> > I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.
> > 
> > I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.
> > 
> > I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.
> > 
> > Thank you for reporting this issue.
> > 
> > John
> > 
> > > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > > 
> > > Dear jihee,
> > > 
> > >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > >> 
> > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
> > >> 
> > >> --> no, I never said i was using a Mac. 
> > > 
> > > Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
> > > 
> > >> 
> > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
> > >> 
> > >> --> sessionInfo()
> > >> R version 3.5.2 (2018-12-20)
> > >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> > >> Running under: Windows 7 x64 (build 7601) Service Pack 1
> > >> 
> > >> Matrix products: default
> > >> 
> > >> locale:
> > >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949  
> > >> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C  
> > >> [5] LC_TIME=Korean_Korea.949  
> > >> 
> > >> attached base packages:
> > >> [1] tcltk splines stats graphics grDevices utils datasets methods  
> > >> [9] base  
> > >> 
> > >> other attached packages:
> > >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
> > >> [3] Rcmdr_2.5-1 effects_4.1-0  
> > >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0  
> > >> [7] car_3.0-2 carData_3.0-2  
> > >> [9] SensoMineR_1.23 FactoMineR_1.41  
> > >> 
> > >> loaded via a namespace (and not attached):
> > >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28 
> > >> [4] cellranger_1.1.0 pillar_1.3.1 backports_1.1.3  
> > >> [7] lattice_0.20-38 digest_0.6.18 RColorBrewer_1.1-2  
> > >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2  
> > >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15  
> > >> [16] plyr_1.8.4 pkgconfig_2.0.2 haven_2.0.0  
> > >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16  
> > >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2  
> > >> [25] relimp_1.0-5 ggplot2_3.1.0 nnet_7.3-12  
> > >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5  
> > >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137  
> > >> [34] MASS_7.3-51.1 forcats_0.3.0 foreign_0.8-71  
> > >> [37] class_7.3-14 tools_3.5.2 data.table_1.11.8  
> > >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1  
> > >> [43] munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0  
> > >> [46] flashClust_1.01-2 compiler_3.5.2 e1071_1.7-0  
> > >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1  
> > >> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0  
> > >> [55] base64enc_0.1-3 gtable_0.2.0 abind_1.4-5  
> > >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3  
> > >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21  
> > >> [64] nortest_1.0-4 Hmisc_4.1-1 KernSmooth_2.23-15  
> > >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13  
> > >> [70] acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4  
> > >> 
> > >> This was the status that I tried to import Excel data. 
> > > 
> > > These packages seem up-to-date.
> > > 
> > >> 
> > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
> > >> 
> > >> --> I tried without plug-in packages, but It didn't work. 
> > > 
> > > OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
> > > 
> > >> 
> > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
> > >> 
> > >> --> I don't know what is plain-text data file..... 
> > > 
> > > A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
> > > 
> > >> 
> > >> i'll try R with English. 
> > > 
> > > I'm curious to see what happens.
> > > 
> > > Best,
> > > John
> > > 
> > >> 
> > >> From: "Fox, John" <jfox at mcmaster.ca> 
> > >> 
> > >> Sent: Monday, January 14, 2019 11:15:36 PM 
> > >> 
> > >> To:"???" <wjh1518 at ht.co.kr> 
> > >> 
> > >> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
> > >> 
> > >> Subject:Re: [R] importing data error question 
> > >> 
> > >> Dear jihee,
> > >> 
> > >>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > >>> 
> > >>> 
> > >>> 
> > >>> From: "???" <wjh1518 at ht.co.kr>
> > >>> Sent: Monday, January 14, 2019 9:40:26 AM
> > >>> To:"Fox, John" <jfox at mcmaster.ca>
> > >>> Subject:Re: [R] importing data error question
> > >>> 
> > >>> 
> > >>> Thanks for your replies.
> > >>> 
> > >>> I'm using windows 7, I loaded FactoMineR,
> > >> 
> > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
> > >> 
> > >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
> > >>> This problem occurred when I select Data > Import data > From Excel file.
> > >>> I checked FactoMineR and SensoMineR packages are loaded and using..
> > >> 
> > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
> > >> 
> > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
> > >> 
> > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
> > >> 
> > >> Best,
> > >> John
> > >> 
> > >>> 
> > >>> 
> > >>> 
> > >>> From: "Fox, John" <jfox at mcmaster.ca>
> > >>> Sent: Friday, January 11, 2019 10:48:38 PM
> > >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
> > >>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
> > >>> Subject:Re: [R] importing data error question
> > >>> 
> > >>> 
> > >>> Dear Petr and jihee,
> > >>> 
> > >>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
> > >>> 
> > >>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
> > >>> 
> > >>> Best,
> > >>> John
> > >>> 
> > >>> -------------------------------------------------
> > >>> John Fox, Professor Emeritus
> > >>> McMaster University
> > >>> Hamilton, Ontario, Canada
> > >>> Web: http::/socserv.mcmaster.ca/jfox
> > >>> 
> > >>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >>>> 
> > >>>> Hi
> > >>>> 
> > >>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> > >>>> 
> > >>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> > >>>> 
> > >>>> Cheers
> > >>>> Petr
> > >>>> 
> > >>>>> -----Original Message-----
> > >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> > >>>>> Sent: Friday, January 11, 2019 9:14 AM
> > >>>>> To: r-help at R-project.org
> > >>>>> Subject: [R] importing data error question
> > >>>>> 
> > >>>>> Hi I'm jihee and I have a question about error...
> > >>>>> 
> > >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
> > >>>>> 
> > >>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
> > >>>>> 
> > >>>>> but i can't import excel data with Rcmdr.
> > >>>>> 
> > >>>>> it has this messege :
> > >>>>> 
> > >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> > >>>>> [tcl] bad Macintosh file type "?*?"
> > >>>>> 
> > >>>>> what is wrong with my R??? T_T
> > >>>>> 
> > >>>>> Thanks for your help.
> > >>>>> 
> > >>>>> jihee.
> > >>>>> [[alternative HTML version deleted]]
> > >>>>> 
> > >>>>> ______________________________________________
> > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > >>>> 
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>> 
> > >>> 
> > >>> 
> > >>> 
> > >>> ??? ??? / ??????
> > >>> e-mailwjh1518 at ht.co.krDirMobile
> > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > >>> 
> > >>> 
> > >>> 
> > >>> 
> > >>> ??? ??? / ??????
> > >>> e-mailwjh1518 at ht.co.krDirMobile
> > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
> > >> [[alternative HTML version deleted]]
> > >> 
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> >  
> > 
> > 
> > ??? ??? / ??????
> > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> 
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 17 09:55:59 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 17 Jan 2019 08:55:59 +0000
Subject: [R] create groups from data with duplicates,
 such that each group has a duplicate represented once
In-Reply-To: <F9045ADB-02A9-4EAF-AD1B-89307ECCDDC3@kemri-wellcome.org>
References: <F9045ADB-02A9-4EAF-AD1B-89307ECCDDC3@kemri-wellcome.org>
Message-ID: <84bca04cf78841bdbf99b6d81f0bb463@SRVEXCHCM1302.precheza.cz>

Hi

Instead of attachment which is usually removed you should use dput

Something like output from
dput(head(yourdata,30))

To remove duplicate values see

unique or duplicated

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Wamae
> Sent: Thursday, January 17, 2019 1:29 AM
> To: r-help at r-project.org
> Subject: [R] create groups from data with duplicates, such that each group has
> a duplicate represented once
>
> Hi, I have a sequencing run with ~3000 samples (attached dataset). The
> samples were initially tagged and amplified by PCR in duplicate. The tags used
> range from MID01 to MID26.
>
> MID01-MID13 were used for pair 1 while MID14-MID26 were used for pair 2.
> The tags are re-used to allow samples to be pooled.
>
> The pooling process will involve mixing samples with MID01-26 into the first
> group, the next group samples with MID01-26 into the second group and so on.
>
> I'm hoping to get an R script that can create these groups such that for each
> group, any of the Tags appears only once. An example is shown below.
>
> ID
>
> TagA
>
> TagB
>
> group
>
> 180
>
> MID03
>
> MID10
>
> group1
>
> 181
>
> MID04
>
> MID06
>
> group1
>
> 182
>
> MID05
>
> MID07
>
> group1
>
> 183
>
> MID03
>
> MID09
>
> group2
>
> 184
>
> MID04
>
> MID10
>
> group2
>
> 185
>
> MID05
>
> MID06
>
> group2
>
> 186
>
> MID01
>
> MID06
>
> group3
>
> 187
>
> MID02
>
> MID07
>
> group3
>
> 188
>
> MID03
>
> MID08
>
> group3
>
>
>
> ___________________________________________________________________
> ___
>
> This e-mail contains information which is confidential. It is intended only for
> the use of the named recipient. If you have received this e-mail in error, please
> let us know by replying to the sender, and immediately delete it from your
> system.  Please note, that in these circumstances, the use, disclosure,
> distribution or copying of this information is strictly prohibited. KEMRI-
> Wellcome Trust Programme cannot accept any responsibility for the  accuracy
> or completeness of this message as it has been transmitted over a public
> network. Although the Programme has taken reasonable precautions to ensure
> no viruses are present in emails, it cannot accept responsibility for any loss or
> damage arising from the use of the email or attachments. Any views expressed
> in this message are those of the individual sender, except where the sender
> specifically states them to be the views of KEMRI-Wellcome Trust Programme.
> ___________________________________________________________________
> ___
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From KW@m@e @end|ng |rom kemr|-we||come@org  Thu Jan 17 12:53:11 2019
From: KW@m@e @end|ng |rom kemr|-we||come@org (Kevin Wamae)
Date: Thu, 17 Jan 2019 11:53:11 +0000
Subject: [R] create groups from data with duplicates,
 such that each group has a duplicate represented once
In-Reply-To: <84bca04cf78841bdbf99b6d81f0bb463@SRVEXCHCM1302.precheza.cz>
References: <F9045ADB-02A9-4EAF-AD1B-89307ECCDDC3@kemri-wellcome.org>
 <84bca04cf78841bdbf99b6d81f0bb463@SRVEXCHCM1302.precheza.cz>
Message-ID: <1C6D62E4-7240-4848-9544-C557D7ADD66A@kemri-wellcome.org>

Dear Petr, thank you for the guidance.

A colleague managed to solve it....

I'll definitely use "dput" for future postings.

Regards
------------------
Kevin Wamae

?On 17/01/2019, 03:57, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

    Hi
    
    Instead of attachment which is usually removed you should use dput
    
    Something like output from
    dput(head(yourdata,30))
    
    To remove duplicate values see
    
    unique or duplicated
    
    Cheers
    Petr
    
    > -----Original Message-----
    > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Wamae
    > Sent: Thursday, January 17, 2019 1:29 AM
    > To: r-help at r-project.org
    > Subject: [R] create groups from data with duplicates, such that each group has
    > a duplicate represented once
    >
    > Hi, I have a sequencing run with ~3000 samples (attached dataset). The
    > samples were initially tagged and amplified by PCR in duplicate. The tags used
    > range from MID01 to MID26.
    >
    > MID01-MID13 were used for pair 1 while MID14-MID26 were used for pair 2.
    > The tags are re-used to allow samples to be pooled.
    >
    > The pooling process will involve mixing samples with MID01-26 into the first
    > group, the next group samples with MID01-26 into the second group and so on.
    >
    > I'm hoping to get an R script that can create these groups such that for each
    > group, any of the Tags appears only once. An example is shown below.
    >
    > ID
    >
    > TagA
    >
    > TagB
    >
    > group
    >
    > 180
    >
    > MID03
    >
    > MID10
    >
    > group1
    >
    > 181
    >
    > MID04
    >
    > MID06
    >
    > group1
    >
    > 182
    >
    > MID05
    >
    > MID07
    >
    > group1
    >
    > 183
    >
    > MID03
    >
    > MID09
    >
    > group2
    >
    > 184
    >
    > MID04
    >
    > MID10
    >
    > group2
    >
    > 185
    >
    > MID05
    >
    > MID06
    >
    > group2
    >
    > 186
    >
    > MID01
    >
    > MID06
    >
    > group3
    >
    > 187
    >
    > MID02
    >
    > MID07
    >
    > group3
    >
    > 188
    >
    > MID03
    >
    > MID08
    >
    > group3
    >
    >
    >
    > ___________________________________________________________________
    > ___
    >
    > This e-mail contains information which is confidential. It is intended only for
    > the use of the named recipient. If you have received this e-mail in error, please
    > let us know by replying to the sender, and immediately delete it from your
    > system.  Please note, that in these circumstances, the use, disclosure,
    > distribution or copying of this information is strictly prohibited. KEMRI-
    > Wellcome Trust Programme cannot accept any responsibility for the  accuracy
    > or completeness of this message as it has been transmitted over a public
    > network. Although the Programme has taken reasonable precautions to ensure
    > no viruses are present in emails, it cannot accept responsibility for any loss or
    > damage arising from the use of the email or attachments. Any views expressed
    > in this message are those of the individual sender, except where the sender
    > specifically states them to be the views of KEMRI-Wellcome Trust Programme.
    > ___________________________________________________________________
    > ___
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
    D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
    
    


______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

From @kouret@ @end|ng |rom gm@||@com  Thu Jan 17 10:25:09 2019
From: @kouret@ @end|ng |rom gm@||@com (Alexandros Kouretsis)
Date: Thu, 17 Jan 2019 11:25:09 +0200
Subject: [R] RW: Banner using R (Alexandros Kouretsis)
Message-ID: <CAA1Oq-2eZ30w24iAk2Rk_fABW9_vyiMjLiOkF8Yx_sALY__3dQ@mail.gmail.com>

This might be slightly tricky. You can use factor levels and table to take
into account that B is missing from the third column. Just introducing
dplyr library for piping.

library(dplyr)

Data <- data.frame(v1 = c('A', 'B' ,'B' ,'A', 'B'), v2 = c('A', 'B', 'A',
'A', 'B'), v3 = c('A', 'A', 'A', 'A', 'A'))

lvls <- lapply(Data, unique) %>% unlist %>% unique

c_counts <- lapply(Data, function(x){
  levels(x) <- lvls
  x %>% table
})

ag_data <- do.call(cbind, counts)
TOT <- apply(ag_data, 1, sum)

ag_data <- cbind(Count = lvls, ag_data %>% data.frame, TOT)

	[[alternative HTML version deleted]]


From c@|um@po|w@rt @end|ng |rom nh@@net  Thu Jan 17 14:33:45 2019
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Thu, 17 Jan 2019 13:33:45 +0000
Subject: [R] I can't get seq to behave how I think it should
Message-ID: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>

I am using seq with the expression seq(1.4, 2.1, by=0.001) to create a sequence of references from 1.4 to 2.1 in 0.001 increments.  They appear to be created correctly.  They have a related pair of data which for the purposes of this we will call val.  I'm interested in the content on the row with seq = 1.8. But I can't seem to get it returned.  I can get other values but not 1.8!  yet looking at row 401 there is nothing to indicate an issue

> a = 1.4
> b = 2.1
> seq = seq(a, b, by=0.001)
> val = ceiling(seq * 50)
> s=data.frame(seq, val)
> s$val[seq==1.799]
[1] 90
> s$val[s$seq==1.8]
numeric(0)
> s$val[seq==1.8]
numeric(0)
> s$val[s$seq==1.800]
numeric(0)
> s$val[s$seq==1.801]
[1] 91
> head(s[s$seq>1.798,])
      seq val
400 1.799  90
401 1.800  90
402 1.801  91
403 1.802  91
404 1.803  91
405 1.804  91


Can anyone explain what's going on here and how I would correctly find the content of row 401 by using an expression to equal the seq column?





********************************************************************************************************************

This message may contain confidential information. If yo...{{dropped:19}}


From btupper @end|ng |rom b|ge|ow@org  Thu Jan 17 14:43:21 2019
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 17 Jan 2019 08:43:21 -0500
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
Message-ID: <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>

Hi,

This looks like a floating point reality bump - see 

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f <https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>

You can use other methods to finding your row - I would opt for findInterval()

> lut = seq(1.4, 2.1, by=0.001)
> findInterval(1.8, lut)
[1] 401

findInterval() uses a rapid search to find the index in the look up table (lut) that is just less than  or equal to the search value (in your example 1.8).

Cheers,
Ben

> On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
> 
> I am using seq with the expression seq(1.4, 2.1, by=0.001) to create a sequence of references from 1.4 to 2.1 in 0.001 increments.  They appear to be created correctly.  They have a related pair of data which for the purposes of this we will call val.  I'm interested in the content on the row with seq = 1.8. But I can't seem to get it returned.  I can get other values but not 1.8!  yet looking at row 401 there is nothing to indicate an issue
> 
>> a = 1.4
>> b = 2.1
>> seq = seq(a, b, by=0.001)
>> val = ceiling(seq * 50)
>> s=data.frame(seq, val)
>> s$val[seq==1.799]
> [1] 90
>> s$val[s$seq==1.8]
> numeric(0)
>> s$val[seq==1.8]
> numeric(0)
>> s$val[s$seq==1.800]
> numeric(0)
>> s$val[s$seq==1.801]
> [1] 91
>> head(s[s$seq>1.798,])
>      seq val
> 400 1.799  90
> 401 1.800  90
> 402 1.801  91
> 403 1.802  91
> 404 1.803  91
> 405 1.804  91
> 
> 
> Can anyone explain what's going on here and how I would correctly find the content of row 401 by using an expression to equal the seq column?
> 
> 
> 
> 
> 
> ********************************************************************************************************************
> 
> This message may contain confidential information. If ...{{dropped:25}}


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 17 14:52:39 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 17 Jan 2019 13:52:39 +0000
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
Message-ID: <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>

Hi

Or you could use rounding.
which(round(lut, 3)==1.8)
[1] 401

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
> Sent: Thursday, January 17, 2019 2:43 PM
> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST) <calum.polwart at nhs.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] I can't get seq to behave how I think it should
>
> Hi,
>
> This looks like a floating point reality bump - see
>
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-
> these-numbers-are-equal_003f <https://cran.r-project.org/doc/FAQ/R-
> FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
>
> You can use other methods to finding your row - I would opt for findInterval()
>
> > lut = seq(1.4, 2.1, by=0.001)
> > findInterval(1.8, lut)
> [1] 401
>
> findInterval() uses a rapid search to find the index in the look up table (lut) that
> is just less than  or equal to the search value (in your example 1.8).
>
> Cheers,
> Ben
>
> > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
> DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
> wrote:
> >
> > I am using seq with the expression seq(1.4, 2.1, by=0.001) to create a
> > sequence of references from 1.4 to 2.1 in 0.001 increments.  They
> > appear to be created correctly.  They have a related pair of data
> > which for the purposes of this we will call val.  I'm interested in
> > the content on the row with seq = 1.8. But I can't seem to get it
> > returned.  I can get other values but not 1.8!  yet looking at row 401
> > there is nothing to indicate an issue
> >
> >> a = 1.4
> >> b = 2.1
> >> seq = seq(a, b, by=0.001)
> >> val = ceiling(seq * 50)
> >> s=data.frame(seq, val)
> >> s$val[seq==1.799]
> > [1] 90
> >> s$val[s$seq==1.8]
> > numeric(0)
> >> s$val[seq==1.8]
> > numeric(0)
> >> s$val[s$seq==1.800]
> > numeric(0)
> >> s$val[s$seq==1.801]
> > [1] 91
> >> head(s[s$seq>1.798,])
> >      seq val
> > 400 1.799  90
> > 401 1.800  90
> > 402 1.801  91
> > 403 1.802  91
> > 404 1.803  91
> > 405 1.804  91
> >
> >
> > Can anyone explain what's going on here and how I would correctly find the
> content of row 401 by using an expression to equal the seq column?
> >
> >
> >
> >
> >
> >
> *******************************************************************
> ***
> > **********************************************
> >
> > This message may contain confidential information. If
> > ...{{dropped:25}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From c@|um@po|w@rt @end|ng |rom nh@@net  Thu Jan 17 14:56:02 2019
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Thu, 17 Jan 2019 13:56:02 +0000
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
Message-ID: <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>

Thanks guys.

I've used Petr's method and its working for me.

If the data had been from a calculation I'd have rounded it... just didn't expect seq to break it!

C

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
Sent: 17 January 2019 13:53
To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST)
Cc: r-help at r-project.org
Subject: RE: [R] I can't get seq to behave how I think it should

Hi

Or you could use rounding.
which(round(lut, 3)==1.8)
[1] 401

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
> Sent: Thursday, January 17, 2019 2:43 PM
> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST)
> <calum.polwart at nhs.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] I can't get seq to behave how I think it should
>
> Hi,
>
> This looks like a floating point reality bump - see
>
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-
> these-numbers-are-equal_003f <https://cran.r-project.org/doc/FAQ/R-
> FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
>
> You can use other methods to finding your row - I would opt for
> findInterval()
>
> > lut = seq(1.4, 2.1, by=0.001)
> > findInterval(1.8, lut)
> [1] 401
>
> findInterval() uses a rapid search to find the index in the look up
> table (lut) that is just less than  or equal to the search value (in your example 1.8).
>
> Cheers,
> Ben
>
> > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
> DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
> wrote:
> >
> > I am using seq with the expression seq(1.4, 2.1, by=0.001) to create
> > a sequence of references from 1.4 to 2.1 in 0.001 increments.  They
> > appear to be created correctly.  They have a related pair of data
> > which for the purposes of this we will call val.  I'm interested in
> > the content on the row with seq = 1.8. But I can't seem to get it
> > returned.  I can get other values but not 1.8!  yet looking at row
> > 401 there is nothing to indicate an issue
> >
> >> a = 1.4
> >> b = 2.1
> >> seq = seq(a, b, by=0.001)
> >> val = ceiling(seq * 50)
> >> s=data.frame(seq, val)
> >> s$val[seq==1.799]
> > [1] 90
> >> s$val[s$seq==1.8]
> > numeric(0)
> >> s$val[seq==1.8]
> > numeric(0)
> >> s$val[s$seq==1.800]
> > numeric(0)
> >> s$val[s$seq==1.801]
> > [1] 91
> >> head(s[s$seq>1.798,])
> >      seq val
> > 400 1.799  90
> > 401 1.800  90
> > 402 1.801  91
> > 403 1.802  91
> > 404 1.803  91
> > 405 1.804  91
> >
> >
> > Can anyone explain what's going on here and how I would correctly
> > find the
> content of row 401 by using an expression to equal the seq column?
> >
> >
> >
> >
> >
> >
> *******************************************************************
> ***
> > **********************************************
> >
> > This message may contain confidential information. If
> > ...{{dropped:25}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/



********************************************************************************************************************

This message may contain confidential information. If you are not the intended recipient please inform the
sender that you have received the message in error before deleting it.
Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.

NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.

For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 17 15:30:13 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 17 Jan 2019 14:30:13 +0000
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
 <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
Message-ID: <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>

Hi

It is not seq problem, it is floating point numbers representation in finit precision problem. Ben pointed to it and you could learn about it from FAQ 7.31.

Cheers
Petr

> -----Original Message-----
> From: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST) <calum.polwart at nhs.net>
> Sent: Thursday, January 17, 2019 2:56 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; Ben Tupper <btupper at bigelow.org>
> Cc: r-help at r-project.org
> Subject: RE: [R] I can't get seq to behave how I think it should
>
> Thanks guys.
>
> I've used Petr's method and its working for me.
>
> If the data had been from a calculation I'd have rounded it... just didn't expect
> seq to break it!
>
> C
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 17 January 2019 13:53
> To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST)
> Cc: r-help at r-project.org
> Subject: RE: [R] I can't get seq to behave how I think it should
>
> Hi
>
> Or you could use rounding.
> which(round(lut, 3)==1.8)
> [1] 401
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
> > Sent: Thursday, January 17, 2019 2:43 PM
> > To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST)
> > <calum.polwart at nhs.net>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] I can't get seq to behave how I think it should
> >
> > Hi,
> >
> > This looks like a floating point reality bump - see
> >
> > https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-
> > these-numbers-are-equal_003f <https://cran.r-project.org/doc/FAQ/R-
> > FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
> >
> > You can use other methods to finding your row - I would opt for
> > findInterval()
> >
> > > lut = seq(1.4, 2.1, by=0.001)
> > > findInterval(1.8, lut)
> > [1] 401
> >
> > findInterval() uses a rapid search to find the index in the look up
> > table (lut) that is just less than  or equal to the search value (in your example
> 1.8).
> >
> > Cheers,
> > Ben
> >
> > > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
> > DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
> > wrote:
> > >
> > > I am using seq with the expression seq(1.4, 2.1, by=0.001) to create
> > > a sequence of references from 1.4 to 2.1 in 0.001 increments.  They
> > > appear to be created correctly.  They have a related pair of data
> > > which for the purposes of this we will call val.  I'm interested in
> > > the content on the row with seq = 1.8. But I can't seem to get it
> > > returned.  I can get other values but not 1.8!  yet looking at row
> > > 401 there is nothing to indicate an issue
> > >
> > >> a = 1.4
> > >> b = 2.1
> > >> seq = seq(a, b, by=0.001)
> > >> val = ceiling(seq * 50)
> > >> s=data.frame(seq, val)
> > >> s$val[seq==1.799]
> > > [1] 90
> > >> s$val[s$seq==1.8]
> > > numeric(0)
> > >> s$val[seq==1.8]
> > > numeric(0)
> > >> s$val[s$seq==1.800]
> > > numeric(0)
> > >> s$val[s$seq==1.801]
> > > [1] 91
> > >> head(s[s$seq>1.798,])
> > >      seq val
> > > 400 1.799  90
> > > 401 1.800  90
> > > 402 1.801  91
> > > 403 1.802  91
> > > 404 1.803  91
> > > 405 1.804  91
> > >
> > >
> > > Can anyone explain what's going on here and how I would correctly
> > > find the
> > content of row 401 by using an expression to equal the seq column?
> > >
> > >
> > >
> > >
> > >
> > >
> >
> *******************************************************************
> > ***
> > > **********************************************
> > >
> > > This message may contain confidential information. If
> > > ...{{dropped:25}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-
> ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
> a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
> https://www.precheza.cz/01-dovetek/ | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>
>
> *******************************************************************
> *************************************************
>
> This message may contain confidential information. If you are not the intended
> recipient please inform the sender that you have received the message in error
> before deleting it.
> Please do not disclose, copy or distribute information in this e-mail or take any
> action in relation to its contents. To do so is strictly prohibited and may be
> unlawful. Thank you for your co-operation.
>
> NHSmail is the secure email and directory service available for all NHS staff in
> England and Scotland. NHSmail is approved for exchanging patient data and
> other sensitive information with NHSmail and other accredited email services.
>
> For more information and to find out how you can switch,
> https://portal.nhs.net/help/joiningnhsmail

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From c@|um@po|w@rt @end|ng |rom nh@@net  Thu Jan 17 15:56:48 2019
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Thu, 17 Jan 2019 14:56:48 +0000
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
 <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
 <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>
Message-ID: <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>

Well I get the issue with finite precision. As in SQRT(2) * SQRT(2) is not 2.

What surprised me was that seq(1.4, 2.1, by=0.001) starts at 1.3999999999999999 and not 1.4!


-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
Sent: 17 January 2019 14:30
To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST); Ben Tupper
Cc: r-help at r-project.org
Subject: RE: [R] I can't get seq to behave how I think it should

Hi

It is not seq problem, it is floating point numbers representation in finit precision problem. Ben pointed to it and you could learn about it from FAQ 7.31.

Cheers
Petr

> -----Original Message-----
> From: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION
> TRUST) <calum.polwart at nhs.net>
> Sent: Thursday, January 17, 2019 2:56 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; Ben Tupper
> <btupper at bigelow.org>
> Cc: r-help at r-project.org
> Subject: RE: [R] I can't get seq to behave how I think it should
>
> Thanks guys.
>
> I've used Petr's method and its working for me.
>
> If the data had been from a calculation I'd have rounded it... just
> didn't expect seq to break it!
>
> C
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 17 January 2019 13:53
> To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST)
> Cc: r-help at r-project.org
> Subject: RE: [R] I can't get seq to behave how I think it should
>
> Hi
>
> Or you could use rounding.
> which(round(lut, 3)==1.8)
> [1] 401
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
> > Sent: Thursday, January 17, 2019 2:43 PM
> > To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
> FOUNDATION TRUST)
> > <calum.polwart at nhs.net>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] I can't get seq to behave how I think it should
> >
> > Hi,
> >
> > This looks like a floating point reality bump - see
> >
> > https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-thin
> > k- these-numbers-are-equal_003f
> > <https://cran.r-project.org/doc/FAQ/R-
> > FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
> >
> > You can use other methods to finding your row - I would opt for
> > findInterval()
> >
> > > lut = seq(1.4, 2.1, by=0.001)
> > > findInterval(1.8, lut)
> > [1] 401
> >
> > findInterval() uses a rapid search to find the index in the look up
> > table (lut) that is just less than  or equal to the search value (in
> > your example
> 1.8).
> >
> > Cheers,
> > Ben
> >
> > > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
> > DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
> > wrote:
> > >
> > > I am using seq with the expression seq(1.4, 2.1, by=0.001) to
> > > create a sequence of references from 1.4 to 2.1 in 0.001
> > > increments.  They appear to be created correctly.  They have a
> > > related pair of data which for the purposes of this we will call
> > > val.  I'm interested in the content on the row with seq = 1.8. But
> > > I can't seem to get it returned.  I can get other values but not
> > > 1.8!  yet looking at row
> > > 401 there is nothing to indicate an issue
> > >
> > >> a = 1.4
> > >> b = 2.1
> > >> seq = seq(a, b, by=0.001)
> > >> val = ceiling(seq * 50)
> > >> s=data.frame(seq, val)
> > >> s$val[seq==1.799]
> > > [1] 90
> > >> s$val[s$seq==1.8]
> > > numeric(0)
> > >> s$val[seq==1.8]
> > > numeric(0)
> > >> s$val[s$seq==1.800]
> > > numeric(0)
> > >> s$val[s$seq==1.801]
> > > [1] 91
> > >> head(s[s$seq>1.798,])
> > >      seq val
> > > 400 1.799  90
> > > 401 1.800  90
> > > 402 1.801  91
> > > 403 1.802  91
> > > 404 1.803  91
> > > 405 1.804  91
> > >
> > >
> > > Can anyone explain what's going on here and how I would correctly
> > > find the
> > content of row 401 by using an expression to equal the seq column?
> > >
> > >
> > >
> > >
> > >
> > >
> >
> *******************************************************************
> > ***
> > > **********************************************
> > >
> > > This message may contain confidential information. If
> > > ...{{dropped:25}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady- ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
> https://www.precheza.cz/01-dovetek/ | This email and any documents
> attached to it may be confidential and are subject to the legally
> binding
> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>
>
> *******************************************************************
> *************************************************
>
> This message may contain confidential information. If you are not the
> intended recipient please inform the sender that you have received the
> message in error before deleting it.
> Please do not disclose, copy or distribute information in this e-mail
> or take any action in relation to its contents. To do so is strictly
> prohibited and may be unlawful. Thank you for your co-operation.
>
> NHSmail is the secure email and directory service available for all
> NHS staff in England and Scotland. NHSmail is approved for exchanging
> patient data and other sensitive information with NHSmail and other accredited email services.
>
> For more information and to find out how you can switch,
> https://portal.nhs.net/help/joiningnhsmail

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/



********************************************************************************************************************

This message may contain confidential information. If you are not the intended recipient please inform the
sender that you have received the message in error before deleting it.
Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.

NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.

For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jan 17 16:02:42 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 17 Jan 2019 15:02:42 +0000
Subject: [R] importing data error question
In-Reply-To: <26540c28-b125-44e4-a048-8e82ecca6fa5@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
 <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
 <4003829E-5D14-4798-A45D-BF85DA42EF20@mcmaster.ca>
 <7b06b392-2611-411a-ba0e-4edd2a8f1045@ht.co.kr>
 <7188EC66-9F43-41BA-9EA7-D1C573508304@mcmaster.ca>
 <26540c28-b125-44e4-a048-8e82ecca6fa5@ht.co.kr>
Message-ID: <C30A504E-590F-470E-BCCE-5E5E0C3990EF@mcmaster.ca>

Dear Jihee,

Your latest attempt has gotten farther than the previous one but has produced a different error. The command to read the data set was generated properly. You can see whether the data set was in fact read by typing prestige (the name you gave to the data set) at the > command prompt in the R console. Assuming that the data set was read, an error occurred when the Rcmdr tried to make it the active data set. I'm afraid that I don't understand how this could happen because this procedure works correctly for me and for others. The underlying code is invoked whenever the Rcmdr reads a dara set.

I suggest that you try two additional things:

(1) I noticed that you loaded the FactoMineR and SensoMineR plug-ins. Try again without loading these plug-ins.

(2) Download and try reading the plain-text data file from <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>, using "Data > Import data > From text file, clipboard, or URL"; you can take all of the defaults in the resulting dialog box.

If neither of these works then I'm afraid that I'm out of ideas. There's something peculiar about your R installation that I can't detect.

Best,
 John



> On Jan 17, 2019, at 12:24 AM, ??? <wjh1518 at ht.co.kr> wrote:
> 
> Dear John,
>  
> I tried with your file. R commander could read the file but there's still no active dataset....
>  
> Anyway I'll send my file, too
>  
> Jihee
>  
> <528c421a382d426895f6446b32fbc6f0.png>
>  
> From: "Fox, John" <jfox at mcmaster.ca>
> Sent: Thursday, January 17, 2019 2:09:52 PM
> To:"???" <wjh1518 at ht.co.kr>
> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> Subject:Re: [R] importing data error question
>  
>  
> Dear Jihee,
> 
> This appears to be a different problem. You were apparently able to access the spreadsheet file, but the R Commander didn't find a suitable worksheet in it.
> 
> Try downloading and reading the file at <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>. If that works, send me privately (i.e., directly) your Excel spreadsheet file and I'll take a look at it.
> 
> Best,
> John
> 
> > On Jan 16, 2019, at 9:49 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > 
> > Dear John,
> >  
> > now i can use english thank you very much!!
> >  
> > um.. but nothing's changed... with that {r} message at R Markdown.
> >  
> > There's no dataset.
> >  
> > i tried both .xls and .xlsx .
> >  
> >  
> > Jihee
> >  
> >  
> >  
> > <fbe6254214d94e74b98569b08bb3bf07.png>
> >  
> >  
> >  
> > From: "Fox, John" <jfox at mcmaster.ca>
> > Sent: Thursday, January 17, 2019 10:59:44 AM
> > To:"???" <wjh1518 at ht.co.kr>
> > Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> > Subject:Re: [R] importing data error question
> >  
> >  
> > Dear Jihee,
> > 
> > Probably the easiest way to change the language to English temporarily in R is to enter the command
> > 
> > Sys.setenv(LANGUAGE="en")
> > 
> > at the R command prompt prior to loading the Rcmdr package.
> > 
> > I hope that this helps,
> > John
> > 
> > 
> > > On Jan 16, 2019, at 7:02 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > 
> > > Thanks for your help!
> > >  
> > > I was having trouble with finding how to use english...
> > >  
> > > Even though I try to use english language, I couldn't change language of R commander. (it is still korean)
> > >  
> > > Sorry but.. do you know how to change language of "R commander"? I have no idea why it doesn't change.
> > >  
> > > Best,
> > > Jihee
> > >  
> > > From: "Fox, John" <jfox at mcmaster.ca>
> > > Sent: Thursday, January 17, 2019 1:59:03 AM
> > > To:"???" <wjh1518 at ht.co.kr>
> > > Cc:"r-help at r-project.org" <r-help at r-project.org>
> > > Subject:Re: [R] importing data error question
> > >  
> > >  
> > > Dear jihee,
> > > 
> > > I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:
> > > 
> > > I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.
> > > 
> > > I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.
> > > 
> > > I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.
> > > 
> > > Thank you for reporting this issue.
> > > 
> > > John
> > > 
> > > > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > > > 
> > > > Dear jihee,
> > > > 
> > > >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > >> 
> > > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
> > > >> 
> > > >> --> no, I never said i was using a Mac. 
> > > > 
> > > > Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
> > > > 
> > > >> 
> > > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
> > > >> 
> > > >> --> sessionInfo()
> > > >> R version 3.5.2 (2018-12-20)
> > > >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> > > >> Running under: Windows 7 x64 (build 7601) Service Pack 1
> > > >> 
> > > >> Matrix products: default
> > > >> 
> > > >> locale:
> > > >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949  
> > > >> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C  
> > > >> [5] LC_TIME=Korean_Korea.949  
> > > >> 
> > > >> attached base packages:
> > > >> [1] tcltk splines stats graphics grDevices utils datasets methods  
> > > >> [9] base  
> > > >> 
> > > >> other attached packages:
> > > >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
> > > >> [3] Rcmdr_2.5-1 effects_4.1-0  
> > > >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0  
> > > >> [7] car_3.0-2 carData_3.0-2  
> > > >> [9] SensoMineR_1.23 FactoMineR_1.41  
> > > >> 
> > > >> loaded via a namespace (and not attached):
> > > >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28 
> > > >> [4] cellranger_1.1.0 pillar_1.3.1 backports_1.1.3  
> > > >> [7] lattice_0.20-38 digest_0.6.18 RColorBrewer_1.1-2  
> > > >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2  
> > > >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15  
> > > >> [16] plyr_1.8.4 pkgconfig_2.0.2 haven_2.0.0  
> > > >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16  
> > > >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2  
> > > >> [25] relimp_1.0-5 ggplot2_3.1.0 nnet_7.3-12  
> > > >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5  
> > > >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137  
> > > >> [34] MASS_7.3-51.1 forcats_0.3.0 foreign_0.8-71  
> > > >> [37] class_7.3-14 tools_3.5.2 data.table_1.11.8  
> > > >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1  
> > > >> [43] munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0  
> > > >> [46] flashClust_1.01-2 compiler_3.5.2 e1071_1.7-0  
> > > >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1  
> > > >> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0  
> > > >> [55] base64enc_0.1-3 gtable_0.2.0 abind_1.4-5  
> > > >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3  
> > > >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21  
> > > >> [64] nortest_1.0-4 Hmisc_4.1-1 KernSmooth_2.23-15  
> > > >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13  
> > > >> [70] acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4  
> > > >> 
> > > >> This was the status that I tried to import Excel data. 
> > > > 
> > > > These packages seem up-to-date.
> > > > 
> > > >> 
> > > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
> > > >> 
> > > >> --> I tried without plug-in packages, but It didn't work. 
> > > > 
> > > > OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
> > > > 
> > > >> 
> > > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
> > > >> 
> > > >> --> I don't know what is plain-text data file..... 
> > > > 
> > > > A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
> > > > 
> > > >> 
> > > >> i'll try R with English. 
> > > > 
> > > > I'm curious to see what happens.
> > > > 
> > > > Best,
> > > > John
> > > > 
> > > >> 
> > > >> From: "Fox, John" <jfox at mcmaster.ca> 
> > > >> 
> > > >> Sent: Monday, January 14, 2019 11:15:36 PM 
> > > >> 
> > > >> To:"???" <wjh1518 at ht.co.kr> 
> > > >> 
> > > >> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
> > > >> 
> > > >> Subject:Re: [R] importing data error question 
> > > >> 
> > > >> Dear jihee,
> > > >> 
> > > >>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> From: "???" <wjh1518 at ht.co.kr>
> > > >>> Sent: Monday, January 14, 2019 9:40:26 AM
> > > >>> To:"Fox, John" <jfox at mcmaster.ca>
> > > >>> Subject:Re: [R] importing data error question
> > > >>> 
> > > >>> 
> > > >>> Thanks for your replies.
> > > >>> 
> > > >>> I'm using windows 7, I loaded FactoMineR,
> > > >> 
> > > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
> > > >> 
> > > >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
> > > >>> This problem occurred when I select Data > Import data > From Excel file.
> > > >>> I checked FactoMineR and SensoMineR packages are loaded and using..
> > > >> 
> > > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
> > > >> 
> > > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
> > > >> 
> > > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
> > > >> 
> > > >> Best,
> > > >> John
> > > >> 
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> From: "Fox, John" <jfox at mcmaster.ca>
> > > >>> Sent: Friday, January 11, 2019 10:48:38 PM
> > > >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
> > > >>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
> > > >>> Subject:Re: [R] importing data error question
> > > >>> 
> > > >>> 
> > > >>> Dear Petr and jihee,
> > > >>> 
> > > >>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
> > > >>> 
> > > >>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
> > > >>> 
> > > >>> Best,
> > > >>> John
> > > >>> 
> > > >>> -------------------------------------------------
> > > >>> John Fox, Professor Emeritus
> > > >>> McMaster University
> > > >>> Hamilton, Ontario, Canada
> > > >>> Web: http::/socserv.mcmaster.ca/jfox
> > > >>> 
> > > >>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > > >>>> 
> > > >>>> Hi
> > > >>>> 
> > > >>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> > > >>>> 
> > > >>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> > > >>>> 
> > > >>>> Cheers
> > > >>>> Petr
> > > >>>> 
> > > >>>>> -----Original Message-----
> > > >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> > > >>>>> Sent: Friday, January 11, 2019 9:14 AM
> > > >>>>> To: r-help at R-project.org
> > > >>>>> Subject: [R] importing data error question
> > > >>>>> 
> > > >>>>> Hi I'm jihee and I have a question about error...
> > > >>>>> 
> > > >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
> > > >>>>> 
> > > >>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
> > > >>>>> 
> > > >>>>> but i can't import excel data with Rcmdr.
> > > >>>>> 
> > > >>>>> it has this messege :
> > > >>>>> 
> > > >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> > > >>>>> [tcl] bad Macintosh file type "?*?"
> > > >>>>> 
> > > >>>>> what is wrong with my R??? T_T
> > > >>>>> 
> > > >>>>> Thanks for your help.
> > > >>>>> 
> > > >>>>> jihee.
> > > >>>>> [[alternative HTML version deleted]]
> > > >>>>> 
> > > >>>>> ______________________________________________
> > > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >>>>> and provide commented, minimal, self-contained, reproducible code.
> > > >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > > >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > > >>>> 
> > > >>>> ______________________________________________
> > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >>>> and provide commented, minimal, self-contained, reproducible code.
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> ??? ??? / ??????
> > > >>> e-mailwjh1518 at ht.co.krDirMobile
> > > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> 
> > > >>> ??? ??? / ??????
> > > >>> e-mailwjh1518 at ht.co.krDirMobile
> > > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
> > > >> [[alternative HTML version deleted]]
> > > >> 
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > 
> > >  
> > > 
> > > 
> > > ??? ??? / ??????
> > > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > 
> > 
> >  
> > 
> > 
> > ??? ??? / ??????
> > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> 
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> <mass2.xlsx>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 17 16:06:09 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Jan 2019 07:06:09 -0800
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
 <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
 <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>
 <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>
Message-ID: <3FC5675B-E4F2-442C-A4A9-E69473E3F303@dcn.davis.ca.us>

... then you still don't understand. Perhaps you might find [1] helpful. Also, adding a floating point representation of 0.001 to 1.4 for 400 times does not yield the same approximation of 1.8 that you get by directly converting the string "1.8" that you typed into your R interpreter.

[1] https://www.exploringbinary.com/why-0-point-1-does-not-exist-in-floating-point/

On January 17, 2019 6:56:48 AM PST, "POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help" <r-help at r-project.org> wrote:
>Well I get the issue with finite precision. As in SQRT(2) * SQRT(2) is
>not 2.
>
>What surprised me was that seq(1.4, 2.1, by=0.001) starts at
>1.3999999999999999 and not 1.4!
>
>
>-----Original Message-----
>From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
>Sent: 17 January 2019 14:30
>To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST);
>Ben Tupper
>Cc: r-help at r-project.org
>Subject: RE: [R] I can't get seq to behave how I think it should
>
>Hi
>
>It is not seq problem, it is floating point numbers representation in
>finit precision problem. Ben pointed to it and you could learn about it
>from FAQ 7.31.
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION
>> TRUST) <calum.polwart at nhs.net>
>> Sent: Thursday, January 17, 2019 2:56 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; Ben Tupper
>> <btupper at bigelow.org>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] I can't get seq to behave how I think it should
>>
>> Thanks guys.
>>
>> I've used Petr's method and its working for me.
>>
>> If the data had been from a calculation I'd have rounded it... just
>> didn't expect seq to break it!
>>
>> C
>>
>> -----Original Message-----
>> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
>> Sent: 17 January 2019 13:53
>> To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>> FOUNDATION TRUST)
>> Cc: r-help at r-project.org
>> Subject: RE: [R] I can't get seq to behave how I think it should
>>
>> Hi
>>
>> Or you could use rounding.
>> which(round(lut, 3)==1.8)
>> [1] 401
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
>> > Sent: Thursday, January 17, 2019 2:43 PM
>> > To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>> FOUNDATION TRUST)
>> > <calum.polwart at nhs.net>
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] I can't get seq to behave how I think it should
>> >
>> > Hi,
>> >
>> > This looks like a floating point reality bump - see
>> >
>> >
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-thin
>> > k- these-numbers-are-equal_003f
>> > <https://cran.r-project.org/doc/FAQ/R-
>> > FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
>> >
>> > You can use other methods to finding your row - I would opt for
>> > findInterval()
>> >
>> > > lut = seq(1.4, 2.1, by=0.001)
>> > > findInterval(1.8, lut)
>> > [1] 401
>> >
>> > findInterval() uses a rapid search to find the index in the look up
>> > table (lut) that is just less than  or equal to the search value
>(in
>> > your example
>> 1.8).
>> >
>> > Cheers,
>> > Ben
>> >
>> > > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
>> > DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
>> > wrote:
>> > >
>> > > I am using seq with the expression seq(1.4, 2.1, by=0.001) to
>> > > create a sequence of references from 1.4 to 2.1 in 0.001
>> > > increments.  They appear to be created correctly.  They have a
>> > > related pair of data which for the purposes of this we will call
>> > > val.  I'm interested in the content on the row with seq = 1.8.
>But
>> > > I can't seem to get it returned.  I can get other values but not
>> > > 1.8!  yet looking at row
>> > > 401 there is nothing to indicate an issue
>> > >
>> > >> a = 1.4
>> > >> b = 2.1
>> > >> seq = seq(a, b, by=0.001)
>> > >> val = ceiling(seq * 50)
>> > >> s=data.frame(seq, val)
>> > >> s$val[seq==1.799]
>> > > [1] 90
>> > >> s$val[s$seq==1.8]
>> > > numeric(0)
>> > >> s$val[seq==1.8]
>> > > numeric(0)
>> > >> s$val[s$seq==1.800]
>> > > numeric(0)
>> > >> s$val[s$seq==1.801]
>> > > [1] 91
>> > >> head(s[s$seq>1.798,])
>> > >      seq val
>> > > 400 1.799  90
>> > > 401 1.800  90
>> > > 402 1.801  91
>> > > 403 1.802  91
>> > > 404 1.803  91
>> > > 405 1.804  91
>> > >
>> > >
>> > > Can anyone explain what's going on here and how I would correctly
>> > > find the
>> > content of row 401 by using an expression to equal the seq column?
>> > >
>> > >
>> > >
>> > >
>> > >
>> > >
>> >
>> *******************************************************************
>> > ***
>> > > **********************************************
>> > >
>> > > This message may contain confidential information. If
>> > > ...{{dropped:25}}
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>> https://www.precheza.cz/zasady- ochrany-osobnich-udaju/ | Information
>> about processing and protection of business partner?s personal data
>are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>odpov?dnosti:
>> https://www.precheza.cz/01-dovetek/ | This email and any documents
>> attached to it may be confidential and are subject to the legally
>> binding
>> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>>
>> *******************************************************************
>> *************************************************
>>
>> This message may contain confidential information. If you are not the
>> intended recipient please inform the sender that you have received
>the
>> message in error before deleting it.
>> Please do not disclose, copy or distribute information in this e-mail
>> or take any action in relation to its contents. To do so is strictly
>> prohibited and may be unlawful. Thank you for your co-operation.
>>
>> NHSmail is the secure email and directory service available for all
>> NHS staff in England and Scotland. NHSmail is approved for exchanging
>> patient data and other sensitive information with NHSmail and other
>accredited email services.
>>
>> For more information and to find out how you can switch,
>> https://portal.nhs.net/help/joiningnhsmail
>
>Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>about processing and protection of business partner?s personal data are
>available on website:
>https://www.precheza.cz/en/personal-data-protection-principles/
>D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>documents attached to it may be confidential and are subject to the
>legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>
>
>********************************************************************************************************************
>
>This message may contain confidential information. If you are not the
>intended recipient please inform the
>sender that you have received the message in error before deleting it.
>Please do not disclose, copy or distribute information in this e-mail
>or take any action in relation to its contents. To do so is strictly
>prohibited and may be unlawful. Thank you for your co-operation.
>
>NHSmail is the secure email and directory service available for all NHS
>staff in England and Scotland. NHSmail is approved for exchanging
>patient data and other sensitive information with NHSmail and other
>accredited email services.
>
>For more information and to find out how you can switch,
>https://portal.nhs.net/help/joiningnhsmail
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From pd@|gd @end|ng |rom gm@||@com  Thu Jan 17 17:52:11 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 17 Jan 2019 17:52:11 +0100
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
 <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
 <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>
 <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>
Message-ID: <44920D65-6826-44F1-AEDD-922A813E38E3@gmail.com>



> On 17 Jan 2019, at 15:56 , POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
> 
> Well I get the issue with finite precision. As in SQRT(2) * SQRT(2) is not 2.

As Jeff indicates, you also need to get that just like 3rds and 7ths cannot be represented exactly in base 10, 5ths and 10ths cannot be represented exactly in base 2 (only powers of 1/2 and their multiples can).

Specifically, 1.4 decimal is 1.0110011001100.... binary

-pd

> 
> What surprised me was that seq(1.4, 2.1, by=0.001) starts at 1.3999999999999999 and not 1.4!
> 
> 
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 17 January 2019 14:30
> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST); Ben Tupper
> Cc: r-help at r-project.org
> Subject: RE: [R] I can't get seq to behave how I think it should
> 
> Hi
> 
> It is not seq problem, it is floating point numbers representation in finit precision problem. Ben pointed to it and you could learn about it from FAQ 7.31.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION
>> TRUST) <calum.polwart at nhs.net>
>> Sent: Thursday, January 17, 2019 2:56 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; Ben Tupper
>> <btupper at bigelow.org>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] I can't get seq to behave how I think it should
>> 
>> Thanks guys.
>> 
>> I've used Petr's method and its working for me.
>> 
>> If the data had been from a calculation I'd have rounded it... just
>> didn't expect seq to break it!
>> 
>> C
>> 
>> -----Original Message-----
>> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
>> Sent: 17 January 2019 13:53
>> To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>> FOUNDATION TRUST)
>> Cc: r-help at r-project.org
>> Subject: RE: [R] I can't get seq to behave how I think it should
>> 
>> Hi
>> 
>> Or you could use rounding.
>> which(round(lut, 3)==1.8)
>> [1] 401
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
>>> Sent: Thursday, January 17, 2019 2:43 PM
>>> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>> FOUNDATION TRUST)
>>> <calum.polwart at nhs.net>
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] I can't get seq to behave how I think it should
>>> 
>>> Hi,
>>> 
>>> This looks like a floating point reality bump - see
>>> 
>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-thin
>>> k- these-numbers-are-equal_003f
>>> <https://cran.r-project.org/doc/FAQ/R-
>>> FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
>>> 
>>> You can use other methods to finding your row - I would opt for
>>> findInterval()
>>> 
>>>> lut = seq(1.4, 2.1, by=0.001)
>>>> findInterval(1.8, lut)
>>> [1] 401
>>> 
>>> findInterval() uses a rapid search to find the index in the look up
>>> table (lut) that is just less than  or equal to the search value (in
>>> your example
>> 1.8).
>>> 
>>> Cheers,
>>> Ben
>>> 
>>>> On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
>>> DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
>>> wrote:
>>>> 
>>>> I am using seq with the expression seq(1.4, 2.1, by=0.001) to
>>>> create a sequence of references from 1.4 to 2.1 in 0.001
>>>> increments.  They appear to be created correctly.  They have a
>>>> related pair of data which for the purposes of this we will call
>>>> val.  I'm interested in the content on the row with seq = 1.8. But
>>>> I can't seem to get it returned.  I can get other values but not
>>>> 1.8!  yet looking at row
>>>> 401 there is nothing to indicate an issue
>>>> 
>>>>> a = 1.4
>>>>> b = 2.1
>>>>> seq = seq(a, b, by=0.001)
>>>>> val = ceiling(seq * 50)
>>>>> s=data.frame(seq, val)
>>>>> s$val[seq==1.799]
>>>> [1] 90
>>>>> s$val[s$seq==1.8]
>>>> numeric(0)
>>>>> s$val[seq==1.8]
>>>> numeric(0)
>>>>> s$val[s$seq==1.800]
>>>> numeric(0)
>>>>> s$val[s$seq==1.801]
>>>> [1] 91
>>>>> head(s[s$seq>1.798,])
>>>>     seq val
>>>> 400 1.799  90
>>>> 401 1.800  90
>>>> 402 1.801  91
>>>> 403 1.802  91
>>>> 404 1.803  91
>>>> 405 1.804  91
>>>> 
>>>> 
>>>> Can anyone explain what's going on here and how I would correctly
>>>> find the
>>> content of row 401 by using an expression to equal the seq column?
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>> 
>> *******************************************************************
>>> ***
>>>> **********************************************
>>>> 
>>>> This message may contain confidential information. If
>>>> ...{{dropped:25}}
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>> https://www.precheza.cz/zasady- ochrany-osobnich-udaju/ | Information
>> about processing and protection of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
>> https://www.precheza.cz/01-dovetek/ | This email and any documents
>> attached to it may be confidential and are subject to the legally
>> binding
>> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>> 
>> 
>> 
>> *******************************************************************
>> *************************************************
>> 
>> This message may contain confidential information. If you are not the
>> intended recipient please inform the sender that you have received the
>> message in error before deleting it.
>> Please do not disclose, copy or distribute information in this e-mail
>> or take any action in relation to its contents. To do so is strictly
>> prohibited and may be unlawful. Thank you for your co-operation.
>> 
>> NHSmail is the secure email and directory service available for all
>> NHS staff in England and Scotland. NHSmail is approved for exchanging
>> patient data and other sensitive information with NHSmail and other accredited email services.
>> 
>> For more information and to find out how you can switch,
>> https://portal.nhs.net/help/joiningnhsmail
> 
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> 
> 
> 
> ********************************************************************************************************************
> 
> This message may contain confidential information. If you are not the intended recipient please inform the
> sender that you have received the message in error before deleting it.
> Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.
> 
> NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.
> 
> For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mer|@m@ne| @end|ng |rom gm@||@com  Thu Jan 17 17:57:51 2019
From: mer|@m@ne| @end|ng |rom gm@||@com (N Meriam)
Date: Thu, 17 Jan 2019 10:57:51 -0600
Subject: [R] R: estimating genotyping error rate
Message-ID: <CAL1He1Lr8Oy68WoUYYSxJ3EnUXX92Tufm-jk3GBxL=oy7W+E6w@mail.gmail.com>

Hello,
I have SNP data from genotyping.
I would like to estimate the error rate between replicated samples using R.
How can I proceed?

Thanks
Meriam


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 17 18:34:59 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 17 Jan 2019 09:34:59 -0800
Subject: [R] R: estimating genotyping error rate
In-Reply-To: <CAL1He1Lr8Oy68WoUYYSxJ3EnUXX92Tufm-jk3GBxL=oy7W+E6w@mail.gmail.com>
References: <CAL1He1Lr8Oy68WoUYYSxJ3EnUXX92Tufm-jk3GBxL=oy7W+E6w@mail.gmail.com>
Message-ID: <CAGxFJbQjqXZTurK4owAT-aWSjauSUVopWhiK++YaFJbwzMsCJQ@mail.gmail.com>

"How can I proceed?"

-- By doing your own homework about appropriate methodology and software
instead of asking others to do it for you.

-- and by posting as necessary on the appropriate website, which is most
likely Bioconductor Help, not here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 17, 2019 at 9:03 AM N Meriam <meriam.nef at gmail.com> wrote:

> Hello,
> I have SNP data from genotyping.
> I would like to estimate the error rate between replicated samples using R.
> How can I proceed?
>
> Thanks
> Meriam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 17 19:21:54 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Jan 2019 10:21:54 -0800
Subject: [R] R: estimating genotyping error rate
In-Reply-To: <CAGxFJbQjqXZTurK4owAT-aWSjauSUVopWhiK++YaFJbwzMsCJQ@mail.gmail.com>
References: <CAL1He1Lr8Oy68WoUYYSxJ3EnUXX92Tufm-jk3GBxL=oy7W+E6w@mail.gmail.com>
 <CAGxFJbQjqXZTurK4owAT-aWSjauSUVopWhiK++YaFJbwzMsCJQ@mail.gmail.com>
Message-ID: <8BB76213-AE45-4262-8F30-9EEBD566F956@dcn.davis.ca.us>

I would say that you may well be asking the wrong question in the right mailing list. Your discipline-specific jargon is impeding communication... you need to know what specific steps you want to take using R. A good reason to start your line of questioning on the Bioconductor forum is that there may already be packages that wrap up your tasks at the high level where you are currently thinking... or not. Which is all another way to say essentially what Bert said... except that you may find yourself back here soon with a question about R rather than "SNP data" if they regard this as too easy to need a package.

One fairly reliable way to know that your question is ready for this list is that you can get the ball rolling with a reproducible example written in R [1][2][3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On January 17, 2019 9:34:59 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>"How can I proceed?"
>
>-- By doing your own homework about appropriate methodology and
>software
>instead of asking others to do it for you.
>
>-- and by posting as necessary on the appropriate website, which is
>most
>likely Bioconductor Help, not here.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Jan 17, 2019 at 9:03 AM N Meriam <meriam.nef at gmail.com> wrote:
>
>> Hello,
>> I have SNP data from genotyping.
>> I would like to estimate the error rate between replicated samples
>using R.
>> How can I proceed?
>>
>> Thanks
>> Meriam
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Jan 17 19:32:08 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (ProfJCNash)
Date: Thu, 17 Jan 2019 13:32:08 -0500
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <44920D65-6826-44F1-AEDD-922A813E38E3@gmail.com>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
 <4e1d4743b13b48f6aca67b06d21f5d49@NH-SLPEX171.AD1.NHS.NET>
 <16244f3c0ecd4e2395778bf95a9e0825@SRVEXCHCM1302.precheza.cz>
 <40bb229d75d74e72950f92a2aef4adfe@NH-SLPEX171.AD1.NHS.NET>
 <44920D65-6826-44F1-AEDD-922A813E38E3@gmail.com>
Message-ID: <06be4bc0-ae86-1d69-3fd1-5adab0b8da92@gmail.com>

As one of the approximately 30 names on the 1985 IEEE 754 standard, I
should be first to comment about representations. However, a quite
large fraction of the computers I've owned or used were decimal beasts.
This doesn't remove all the issues, of course, but some of these
input-output conversions would be avoided. I rather doubt we'll ever
see an R version for decimal arithmetic, since there'd be a lot of
awkwardness with comparing with the usual version, and a lot of the test
comparisons would likely fail. On the other hand, it might serve as a
reminder that IEEE arithmetic, while a great step in computation, is not
the only possibility and does not eliminate all the difficulties with
finite precision arithmetic.

Best, JN




On 2019-01-17 11:52 a.m., peter dalgaard wrote:
> 
> 
>> On 17 Jan 2019, at 15:56 , POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
>>
>> Well I get the issue with finite precision. As in SQRT(2) * SQRT(2) is not 2.
> 
> As Jeff indicates, you also need to get that just like 3rds and 7ths cannot be represented exactly in base 10, 5ths and 10ths cannot be represented exactly in base 2 (only powers of 1/2 and their multiples can).
> 
> Specifically, 1.4 decimal is 1.0110011001100.... binary
> 
> -pd
> 
>>
>> What surprised me was that seq(1.4, 2.1, by=0.001) starts at 1.3999999999999999 and not 1.4!
>>
>>
>> -----Original Message-----
>> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
>> Sent: 17 January 2019 14:30
>> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST); Ben Tupper
>> Cc: r-help at r-project.org
>> Subject: RE: [R] I can't get seq to behave how I think it should
>>
>> Hi
>>
>> It is not seq problem, it is floating point numbers representation in finit precision problem. Ben pointed to it and you could learn about it from FAQ 7.31.
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION
>>> TRUST) <calum.polwart at nhs.net>
>>> Sent: Thursday, January 17, 2019 2:56 PM
>>> To: PIKAL Petr <petr.pikal at precheza.cz>; Ben Tupper
>>> <btupper at bigelow.org>
>>> Cc: r-help at r-project.org
>>> Subject: RE: [R] I can't get seq to behave how I think it should
>>>
>>> Thanks guys.
>>>
>>> I've used Petr's method and its working for me.
>>>
>>> If the data had been from a calculation I'd have rounded it... just
>>> didn't expect seq to break it!
>>>
>>> C
>>>
>>> -----Original Message-----
>>> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
>>> Sent: 17 January 2019 13:53
>>> To: Ben Tupper; POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>>> FOUNDATION TRUST)
>>> Cc: r-help at r-project.org
>>> Subject: RE: [R] I can't get seq to behave how I think it should
>>>
>>> Hi
>>>
>>> Or you could use rounding.
>>> which(round(lut, 3)==1.8)
>>> [1] 401
>>>
>>> Cheers
>>> Petr
>>>
>>>> -----Original Message-----
>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
>>>> Sent: Thursday, January 17, 2019 2:43 PM
>>>> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
>>> FOUNDATION TRUST)
>>>> <calum.polwart at nhs.net>
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] I can't get seq to behave how I think it should
>>>>
>>>> Hi,
>>>>
>>>> This looks like a floating point reality bump - see
>>>>
>>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-thin
>>>> k- these-numbers-are-equal_003f
>>>> <https://cran.r-project.org/doc/FAQ/R-
>>>> FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
>>>>
>>>> You can use other methods to finding your row - I would opt for
>>>> findInterval()
>>>>
>>>>> lut = seq(1.4, 2.1, by=0.001)
>>>>> findInterval(1.8, lut)
>>>> [1] 401
>>>>
>>>> findInterval() uses a rapid search to find the index in the look up
>>>> table (lut) that is just less than  or equal to the search value (in
>>>> your example
>>> 1.8).
>>>>
>>>> Cheers,
>>>> Ben
>>>>
>>>>> On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
>>>> DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
>>>> wrote:
>>>>>
>>>>> I am using seq with the expression seq(1.4, 2.1, by=0.001) to
>>>>> create a sequence of references from 1.4 to 2.1 in 0.001
>>>>> increments.  They appear to be created correctly.  They have a
>>>>> related pair of data which for the purposes of this we will call
>>>>> val.  I'm interested in the content on the row with seq = 1.8. But
>>>>> I can't seem to get it returned.  I can get other values but not
>>>>> 1.8!  yet looking at row
>>>>> 401 there is nothing to indicate an issue
>>>>>
>>>>>> a = 1.4
>>>>>> b = 2.1
>>>>>> seq = seq(a, b, by=0.001)
>>>>>> val = ceiling(seq * 50)
>>>>>> s=data.frame(seq, val)
>>>>>> s$val[seq==1.799]
>>>>> [1] 90
>>>>>> s$val[s$seq==1.8]
>>>>> numeric(0)
>>>>>> s$val[seq==1.8]
>>>>> numeric(0)
>>>>>> s$val[s$seq==1.800]
>>>>> numeric(0)
>>>>>> s$val[s$seq==1.801]
>>>>> [1] 91
>>>>>> head(s[s$seq>1.798,])
>>>>>     seq val
>>>>> 400 1.799  90
>>>>> 401 1.800  90
>>>>> 402 1.801  91
>>>>> 403 1.802  91
>>>>> 404 1.803  91
>>>>> 405 1.804  91
>>>>>
>>>>>
>>>>> Can anyone explain what's going on here and how I would correctly
>>>>> find the
>>>> content of row 401 by using an expression to equal the seq column?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>> *******************************************************************
>>>> ***
>>>>> **********************************************
>>>>>
>>>>> This message may contain confidential information. If
>>>>> ...{{dropped:25}}
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>>> https://www.precheza.cz/zasady- ochrany-osobnich-udaju/ | Information
>>> about processing and protection of business partner?s personal data are available on website:
>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
>>> https://www.precheza.cz/01-dovetek/ | This email and any documents
>>> attached to it may be confidential and are subject to the legally
>>> binding
>>> disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>
>>>
>>>
>>> *******************************************************************
>>> *************************************************
>>>
>>> This message may contain confidential information. If you are not the
>>> intended recipient please inform the sender that you have received the
>>> message in error before deleting it.
>>> Please do not disclose, copy or distribute information in this e-mail
>>> or take any action in relation to its contents. To do so is strictly
>>> prohibited and may be unlawful. Thank you for your co-operation.
>>>
>>> NHSmail is the secure email and directory service available for all
>>> NHS staff in England and Scotland. NHSmail is approved for exchanging
>>> patient data and other sensitive information with NHSmail and other accredited email services.
>>>
>>> For more information and to find out how you can switch,
>>> https://portal.nhs.net/help/joiningnhsmail
>>
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>>
>> ********************************************************************************************************************
>>
>> This message may contain confidential information. If you are not the intended recipient please inform the
>> sender that you have received the message in error before deleting it.
>> Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.
>>
>> NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.
>>
>> For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From m@|||P@dpo@t @end|ng |rom gm@||@com  Thu Jan 17 20:39:00 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Thu, 17 Jan 2019 22:39:00 +0300
Subject: [R] Kaplan-Meier plot
Message-ID: <CAH6117JDcuTFSdZHhihr9rrDuyAr+19jdW0VBe2TksFEa6GTDA@mail.gmail.com>

According to the guidelines (if I'm not mistaken), the code below is
sufficient (without any specification) to give Kaplan-Meier curves with
censored data markings on Kaplan-Meier curves. But in my case censored data
don't appears on the curves?!

library(survival)
mydata<-read.csv (file="C:/mydata/mydata.csv", header=TRUE, sep=";" )
# Sic! The separator in my csv file is ";"

dput (mydata, "dputmydata.r")
#attached

Y <- Surv (mydata$time, mydata$status == 2)
# 2 -- encodes event

km <- survfit (Y~mydata$stage)

plot (km)

From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan 17 20:45:42 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 17 Jan 2019 11:45:42 -0800
Subject: [R] Kaplan-Meier plot
In-Reply-To: <CAH6117JDcuTFSdZHhihr9rrDuyAr+19jdW0VBe2TksFEa6GTDA@mail.gmail.com>
References: <CAH6117JDcuTFSdZHhihr9rrDuyAr+19jdW0VBe2TksFEa6GTDA@mail.gmail.com>
Message-ID: <CAGxFJbSy1PHa6+5SApagrxXks0LSaHtHY4-5uZuckRJXdyk3EA@mail.gmail.com>

Have you consulted ?plot.survfit ? There are examples for KM plots there.

Also, obvious question: Have you specfied the censoring properly in your
data and fit?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 17, 2019 at 11:39 AM Medic <mailiPadpost at gmail.com> wrote:

> According to the guidelines (if I'm not mistaken), the code below is
> sufficient (without any specification) to give Kaplan-Meier curves with
> censored data markings on Kaplan-Meier curves. But in my case censored data
> don't appears on the curves?!
>
> library(survival)
> mydata<-read.csv (file="C:/mydata/mydata.csv", header=TRUE, sep=";" )
> # Sic! The separator in my csv file is ";"
>
> dput (mydata, "dputmydata.r")
> #attached
>
> Y <- Surv (mydata$time, mydata$status == 2)
> # 2 -- encodes event
>
> km <- survfit (Y~mydata$stage)
>
> plot (km)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From L@H@m@ @end|ng |rom |eed@@@c@uk  Thu Jan 17 15:55:18 2019
From: L@H@m@ @end|ng |rom |eed@@@c@uk (Layik Hama)
Date: Thu, 17 Jan 2019 14:55:18 +0000
Subject: [R] Potential R bug in identical
Message-ID: <AM3PR03MB0965B60A0DA7E803EFB2CEAADA830@AM3PR03MB0965.eurprd03.prod.outlook.com>

Hi,


My first email to r-help and as I am not sure about the issue, I wanted to ask for help first.

The comments under this thread <https://github.com/ropensci/stats19/pull/83> outline a particular string from a dataset which seems to be read by R on Windows differently to Linux and MacOS and also to bash on Ubuntu Bionic. There seems to be some weird and unidentifiable (to me) characters in front of the `Accidents_Index` column name there causing the length to be 17 rather than 14 characters.


I have inspected the string as best as I could and cannot see why we see the output from a Windows machine.


Is it an issue in `read.table()`?


Thanks


---

Layik Hama
Research Fellow

Leeds Institute for Data Analytics
Room 11.70, Worsley Building,
University of Leeds

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jan 17 21:33:27 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 17 Jan 2019 15:33:27 -0500
Subject: [R] Kaplan-Meier plot
In-Reply-To: <CAGxFJbSy1PHa6+5SApagrxXks0LSaHtHY4-5uZuckRJXdyk3EA@mail.gmail.com>
References: <CAH6117JDcuTFSdZHhihr9rrDuyAr+19jdW0VBe2TksFEa6GTDA@mail.gmail.com>
 <CAGxFJbSy1PHa6+5SApagrxXks0LSaHtHY4-5uZuckRJXdyk3EA@mail.gmail.com>
Message-ID: <C0538768-C298-40D6-853B-925AF722D13D@me.com>

Hi,

Just to emphasize Bert's e-mail with a hint, the 'mark.time' argument for plot.survfit() is FALSE by default.

Regards,

Marc Schwartz


> On Jan 17, 2019, at 2:45 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Have you consulted ?plot.survfit ? There are examples for KM plots there.
> 
> Also, obvious question: Have you specfied the censoring properly in your
> data and fit?
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jan 17, 2019 at 11:39 AM Medic <mailiPadpost at gmail.com> wrote:
> 
>> According to the guidelines (if I'm not mistaken), the code below is
>> sufficient (without any specification) to give Kaplan-Meier curves with
>> censored data markings on Kaplan-Meier curves. But in my case censored data
>> don't appears on the curves?!
>> 
>> library(survival)
>> mydata<-read.csv (file="C:/mydata/mydata.csv", header=TRUE, sep=";" )
>> # Sic! The separator in my csv file is ";"
>> 
>> dput (mydata, "dputmydata.r")
>> #attached
>> 
>> Y <- Surv (mydata$time, mydata$status == 2)
>> # 2 -- encodes event
>> 
>> km <- survfit (Y~mydata$stage)
>> 
>> plot (km)


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Jan 17 21:40:32 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 17 Jan 2019 23:40:32 +0300
Subject: [R] Potential R bug in identical
In-Reply-To: <AM3PR03MB0965B60A0DA7E803EFB2CEAADA830@AM3PR03MB0965.eurprd03.prod.outlook.com>
References: <AM3PR03MB0965B60A0DA7E803EFB2CEAADA830@AM3PR03MB0965.eurprd03.prod.outlook.com>
Message-ID: <20190117234032.2ea59905@Tarkus>

On Thu, 17 Jan 2019 14:55:18 +0000
Layik Hama <L.Hama at leeds.ac.uk> wrote:

> There seems to be some weird and unidentifiable (to me) characters in
> front of the `Accidents_Index` column name there causing the length
> to be 17 rather than 14 characters.

Repeating the reproduction steps described at the linked pull request,

$ curl -o acc2017.zip
http://data.dft.gov.uk.s3.amazonaws.com/road-accidents-safety-data/dftRoadSafetyData_Accidents_2017.zip
$ unzip acc2017.zip
$ head -n 1 Acc.csv | hd | head -n 2
00000000  ef bb bf 41 63 63 69 64  65 6e 74 5f 49 6e 64 65  |...Accident_Inde|
00000010  78 2c 4c 6f 63 61 74 69  6f 6e 5f 45 61 73 74 69  |x,Location_Easti|

The document begins with a U+FEFF BYTE ORDER MARK, encoded in UTF-8.
Not sure which encoding R chooses on Windows by default, but
explicitly passing encoding="UTF-8" (or is it fileEncoding?) might
help decode it as such. (Sorry, cannot test my advice on Windows right
now.)

-- 
Best regards,
Ivan


From m@|||P@dpo@t @end|ng |rom gm@||@com  Thu Jan 17 22:06:16 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Fri, 18 Jan 2019 00:06:16 +0300
Subject: [R] Thanks! Re:  Kaplan-Meier plot
Message-ID: <CAH6117KZWOa=-EEbyoq1uw28nz5jMFka7sX+jva7=w8SQwP+kw@mail.gmail.com>

Bert Gunter:
"Have you consulted ?plot.survfit ? "

Marc Schwartz
"The 'mark.time' argument for plot.survfit() is FALSE by default."

Great thanks, Bert, for explanation in which documentation to view information!
Thank you very much, Marc!
Yes, specification required:
plot (km, mark.time=TRUE)
for the appearance censored data on the Kaplan-Meier plot!


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Jan 17 22:32:05 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 18 Jan 2019 00:32:05 +0300
Subject: [R] Potential R bug in identical
In-Reply-To: <AM3PR03MB0965A639F613DE9139A90319DA830@AM3PR03MB0965.eurprd03.prod.outlook.com>
References: <AM3PR03MB0965B60A0DA7E803EFB2CEAADA830@AM3PR03MB0965.eurprd03.prod.outlook.com>
 <20190117234032.2ea59905@Tarkus>
 <AM3PR03MB0965A639F613DE9139A90319DA830@AM3PR03MB0965.eurprd03.prod.outlook.com>
Message-ID: <20190118003205.095c0979@Tarkus>

On Thu, 17 Jan 2019 21:05:07 +0000
Layik Hama <L.Hama at leeds.ac.uk> wrote:

> Why would `identical(str, "Accident_Index", ignore.case = TRUE)`
> behave differently on Linux/MacOS vs Windows?

Because str is different from "Accident_Index" on Windows: it was
decoded from bytes to characters according to different rules when file
was read.

Default encoding for files being read is specified by 'encoding'
options. On both Windows and Linux I get:

> options('encoding')
$encoding
[1] "native.enc"

For which ?file says (in section "Encoding"):

>> ?""? and ?"native.enc"? both mean the ?native? encoding, that is the
>> internal encoding of the current locale and hence no translation is
>> done.

Linux version of R has a UTF-8 locale (AFAIK, macOS does too) and
decodes the files as UTF-8 by default:

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

locale:
 [1] LC_CTYPE=ru_RU.utf8       LC_NUMERIC=C             
 [3] LC_TIME=ru_RU.utf8        LC_COLLATE=ru_RU.utf8    
 [5] LC_MONETARY=ru_RU.utf8    LC_MESSAGES=ru_RU.utf8   
 [7] LC_PAPER=ru_RU.utf8       LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=ru_RU.utf8 LC_IDENTIFICATION=C    

While on Windows R uses a single-byte encoding dependent on the locale:

> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Russian_Russia.1251  LC_CTYPE=Russian_Russia.1251   
[3] LC_MONETARY=Russian_Russia.1251 LC_NUMERIC=C                   
[5] LC_TIME=Russian_Russia.1251    

> readLines('test.txt')[1]
[1] "???Accident_Index"
> nchar(readLines('test.txt')[1])
[1] 17

R on Windows can be explicitly told to decode the file as UTF-8:

> nchar(readLines(file('test.txt',encoding='UTF-8'))[1])
[1] 15

The first character of the string is the invisible byte order mark.
Thankfully, there is an easy fix for that, too. ?file additionally
says:

>> As from R 3.0.0 the encoding ?"UTF-8-BOM"? is accepted for
>> reading and will remove a Byte Order Mark if present (which it
>> often is for files and webpages generated by Microsoft applications).

So this is how we get the 14-character column name we'd wanted:

> nchar(readLines(file('test.txt',encoding='UTF-8-BOM'))[1])
[1] 14

For our original task, this means:

> names(read.csv('Acc.csv'))[1] # might produce incorrect results
[1] "?.?Accident_Index"
> names(read.csv('Acc.csv', fileEncoding='UTF-8-BOM'))[1] # correct
[1] "Accident_Index"

-- 
Best regards,
Ivan


From kyd@v|ddoy|e @end|ng |rom gm@||@com  Thu Jan 17 23:32:51 2019
From: kyd@v|ddoy|e @end|ng |rom gm@||@com (David Doyle)
Date: Thu, 17 Jan 2019 16:32:51 -0600
Subject: [R] Colors on box plots in ggplot
Message-ID: <CACftpvrMeVo4GwCZorZtK2hkrfr32rnvD31_RgSyOst+uqS4Hw@mail.gmail.com>

Hello,

I'm trying to set different boxes to different colors the following page
shows
http://www.sthda.com/english/wiki/ggplot2-box-plot-quick-start-guide-r-software-and-data-visualization


I've tried the code
ToothGrowth$dose <- as.factor(ToothGrowth$dose)
head(ToothGrowth)
library(ggplot2)
# Basic box plot
p <- ggplot(ToothGrowth, aes(x=dose, y=len))  +
  geom_boxplot()
p+scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))
p

But still can not get the colors to show up.  I'm sure it is something
simple I'm doing wrong and would appreciate help.

Thank you in advance
David

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jan 18 00:03:00 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Jan 2019 15:03:00 -0800
Subject: [R] Colors on box plots in ggplot
In-Reply-To: <CACftpvrMeVo4GwCZorZtK2hkrfr32rnvD31_RgSyOst+uqS4Hw@mail.gmail.com>
References: <CACftpvrMeVo4GwCZorZtK2hkrfr32rnvD31_RgSyOst+uqS4Hw@mail.gmail.com>
Message-ID: <88AC0349-9F22-4523-8287-7BF3BCE4011B@dcn.davis.ca.us>

I see you creating a variable p, evaluating and printing a modified version of that variable, and then printing that variable (presumably overwriting the first plot). Are you executing your code one line at a time when troubleshooting?

On January 17, 2019 2:32:51 PM PST, David Doyle <kydaviddoyle at gmail.com> wrote:
>Hello,
>
>I'm trying to set different boxes to different colors the following
>page
>shows
>http://www.sthda.com/english/wiki/ggplot2-box-plot-quick-start-guide-r-software-and-data-visualization
>
>
>I've tried the code
>ToothGrowth$dose <- as.factor(ToothGrowth$dose)
>head(ToothGrowth)
>library(ggplot2)
># Basic box plot
>p <- ggplot(ToothGrowth, aes(x=dose, y=len))  +
>  geom_boxplot()
>p+scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))
>p
>
>But still can not get the colors to show up.  I'm sure it is something
>simple I'm doing wrong and would appreciate help.
>
>Thank you in advance
>David
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j@me@d@re26 @end|ng |rom gm@||@com  Fri Jan 18 00:07:57 2019
From: j@me@d@re26 @end|ng |rom gm@||@com (James Dare)
Date: Fri, 18 Jan 2019 12:07:57 +1300
Subject: [R] Fwd: Custom legend in ggplot - stat_summary shape and geom_bar
 fill
In-Reply-To: <mailman.353299.150.1547765692.8486.r-help@r-project.org>
References: <mailman.353299.150.1547765692.8486.r-help@r-project.org>
Message-ID: <CAAY6qm5jXf1iL59rjfwOD=5usDLQ5tRtTamFaOx1Evkrd50V_w@mail.gmail.com>

Hi Everyone,

I am spending far to much time on this problem.  Every post I read gets me
closer to a solution,  but I am still not quite there.

I am trying to create a bar plot similar to the one below:

<http://r.789695.n4.nabble.com/file/t124289/Desired_Output.png>

My code is as follows:

q92 <- function(x) {quantile(x,probs=0.92,na.rm = TRUE)}

ggplot(River_Df, aes(x= reorder(Name, ECOLI, FUN = q92, order=TRUE),
y=ECOLI))+
  geom_bar(stat="summary",fun.y="median",aes(colour = "Median"),
fill="#2eb82e")+
  stat_summary(fun.y=q92, geom ="point",size=3, shape=18,aes(colour ="95th
Percentile"),show_guide = FALSE)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  xlab(paste("Monitored River Sites
",format(min(River_Df$Time),"%Y"),"-",format(max(River_Df$Time),"%Y"),sep=""))+
  ylab("E. coli (cfu/100mL)")

As you can see, I end up with two legend items, '95th Percentile' and
'Median'.  However, I would like the '95th Percentile' item to be a darkred
diamond with no background.

Any ideas how to do this?  The dataset is attached below:

Datafile.csv <http://r.789695.n4.nabble.com/file/t124289/Datafile.csv>

Thanks in advance for your help.

James

	[[alternative HTML version deleted]]


From L@H@m@ @end|ng |rom |eed@@@c@uk  Thu Jan 17 22:05:07 2019
From: L@H@m@ @end|ng |rom |eed@@@c@uk (Layik Hama)
Date: Thu, 17 Jan 2019 21:05:07 +0000
Subject: [R] Potential R bug in identical
In-Reply-To: <20190117234032.2ea59905@Tarkus>
References: <AM3PR03MB0965B60A0DA7E803EFB2CEAADA830@AM3PR03MB0965.eurprd03.prod.outlook.com>,
 <20190117234032.2ea59905@Tarkus>
Message-ID: <AM3PR03MB0965A639F613DE9139A90319DA830@AM3PR03MB0965.eurprd03.prod.outlook.com>

Ivan,


Thank you for digging into the string. I can confirm that the `hexdump` shows extra characters on bash, too.


The question would then be:


Why would `identical(str, "Accident_Index", ignore.case = TRUE)` behave differently on Linux/MacOS vs Windows?


Thanks


---

Layik Hama
Research Fellow

Leeds Institute for Data Analytics
Room 11.70, Worsley Building,
University of Leeds
________________________________
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: 17 January 2019 20:40:32
To: Layik Hama
Cc: r-help at r-project.org
Subject: Re: [R] Potential R bug in identical

On Thu, 17 Jan 2019 14:55:18 +0000
Layik Hama <L.Hama at leeds.ac.uk> wrote:

> There seems to be some weird and unidentifiable (to me) characters in
> front of the `Accidents_Index` column name there causing the length
> to be 17 rather than 14 characters.

Repeating the reproduction steps described at the linked pull request,

$ curl -o acc2017.zip
http://data.dft.gov.uk.s3.amazonaws.com/road-accidents-safety-data/dftRoadSafetyData_Accidents_2017.zip
$ unzip acc2017.zip
$ head -n 1 Acc.csv | hd | head -n 2
00000000  ef bb bf 41 63 63 69 64  65 6e 74 5f 49 6e 64 65  |...Accident_Inde|
00000010  78 2c 4c 6f 63 61 74 69  6f 6e 5f 45 61 73 74 69  |x,Location_Easti|

The document begins with a U+FEFF BYTE ORDER MARK, encoded in UTF-8.
Not sure which encoding R chooses on Windows by default, but
explicitly passing encoding="UTF-8" (or is it fileEncoding?) might
help decode it as such. (Sorry, cannot test my advice on Windows right
now.)

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Jan 18 12:33:51 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 18 Jan 2019 12:33:51 +0100
Subject: [R] Nested mixed effectts question
In-Reply-To: <8297ff28-e5b3-a4a6-7b90-60766dec4168@mpi.nl>
References: <mailman.353252.1.1547636401.26680.r-help@r-project.org>
 <8297ff28-e5b3-a4a6-7b90-60766dec4168@mpi.nl>
Message-ID: <ce4a82cb-71b3-7aff-7b38-19b58263dfe1@mpi.nl>

(once again with the list)

Hi Caroline,

This question is probably better suited to r-sig-mixed-models
(https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models). Some things
are hard to tell without better understanding your design (I am not an
ecologist/relevant type of biologist), but I'll give it a go.

I suspect that your model is over-parameterized. It's very rare to see a
factor occur both as a fixed effect and as a grouping variable (the
stuff behind the | ) in the random effects.

If you don't care about particular sites but rather only the general
pattern across sites, then I would start with the model:

wrack.biomass ~ year  + (1 + year | site/trans)

This treats site as a known source of variance, but not one that you
care about estimating particular effects for. You can still extract
predictions for them, i.e. the BLUPs, via coef(wrackbio), but their
theoretical interpretation is a bit different than the other option below.

If you do care about particular sites, I would use the model

# if your transects are uniquely labeled across sites
wrack.biomass ~ year * site + (1 | trans)
# if the transect labels are only unique within sites
wrack.biomass ~ year * site + (1 | sites:trans)

This will give you fixed effects as in your model, but models the
transects as a source of repetition and hence variance due to that
grouping. The choice of exact specification depends on the labeling in
your dataset; the sites:trans just guarantees unique labelling. The
random effect in this case would estimate the average variance across
all sites due to transects.

Best,
Phillip




On 16/01/19 12:00, r-help-request at r-project.org wrote:
> Send R-help mailing list submissions to

> Today's Topics:
>
>    6. Nested mixed effectts question (Caroline)
> ----------------------------------------------------------------------
> Hi,
>
> I am helping a friend with an analysis for a study where she sampled
wrack biomass in 15 different sites across three years. At each site,
she sampled from three different transects. She is trying to estimate
the effect of year*site on biomass while accounting for the nested
nature (site/transcet) and repeated measure study design.
>
> wrack.biomass ~ year * site + (1 | site/trans)
>
> However she gets the following warning messages:
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>    Hessian is numerically singular: parameters are not uniquely determined
>
> And her model output is:
>
>> summary(wrackbio)
> Linear mixed model fit by REML
> t-tests use  Satterthwaite approximations to degrees of freedom
['lmerMod']
> Formula: (actual.mean.biomass.m2.50.m.transect) ~ year * site + (1 |
site/trans)
>    Data: wrack_resp_allyrs_transname
>
> REML criterion at convergence: 691
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.3292 -0.2624 -0.0270  0.1681  3.8024
>
> Random effects:
>  Groups     Name        Variance Std.Dev.
>  trans:site (Intercept)  0.0000  0.0000
>  site       (Intercept)  0.5531  0.7437
>  Residual               94.6453  9.7286
> Number of obs: 132, groups:  trans:site, 44; site, 15
>
> Fixed effects:
>                     Estimate Std. Error         df t value Pr(>|t|)
> (Intercept)        9.692e+00  5.666e+00  1.119e-04   1.711    0.999
> year2016           1.256e+01  7.943e+00  8.700e+01   1.582    0.117
> year2017           2.395e+00  7.943e+00  8.700e+01   0.302    0.764
> siteCL             5.672e+01  8.013e+00  1.119e-04   7.079    0.999
> siteDO            -4.315e+00  8.013e+00  1.119e-04  -0.539    0.999
> siteFL             7.872e+00  8.013e+00  1.119e-04   0.982    0.999
> siteFS            -7.619e+00  8.013e+00  1.119e-04  -0.951    0.999
> siteGH             4.369e+00  8.013e+00  1.119e-04   0.545    0.999
> siteLB            -3.747e+00  8.013e+00  1.119e-04  -0.468    0.999
> siteLBP           -5.298e+00  8.943e+00  1.736e-04  -0.592    0.999
> siteNB            -2.953e+00  8.013e+00  1.119e-04  -0.369    1.000
> siteNS             1.005e+00  8.013e+00  1.119e-04   0.125    1.000
> sitePC            -5.238e+00  8.013e+00  1.119e-04  -0.654    0.999
> siteSB            -7.649e+00  8.013e+00  1.119e-04  -0.955    0.999
> siteSILT          -4.734e+00  8.013e+00  1.119e-04  -0.591    0.999
> siteSL            -7.890e+00  8.013e+00  1.119e-04  -0.985    0.999
> siteUD            -8.230e+00  8.013e+00  1.119e-04  -1.027    0.999
> year2016:siteCL   -6.359e+01  1.123e+01  8.700e+01  -5.660 1.91e-07 ***
> year2017:siteCL   -5.210e+01  1.123e+01  8.700e+01  -4.638 1.23e-05 ***
> year2016:siteDO   -1.550e+01  1.123e+01  8.700e+01  -1.380    0.171
> year2017:siteDO   -3.022e+00  1.123e+01  8.700e+01  -0.269    0.789
> year2016:siteFL   -7.522e+00  1.123e+01  8.700e+01  -0.670    0.505
> year2017:siteFL   -1.167e+01  1.123e+01  8.700e+01  -1.039    0.302
> year2016:siteFS   -1.391e+01  1.123e+01  8.700e+01  -1.238    0.219
> year2017:siteFS   -2.170e+00  1.123e+01  8.700e+01  -0.193    0.847
> year2016:siteGH   -9.135e+00  1.123e+01  8.700e+01  -0.813    0.418
> year2017:siteGH   -4.031e+00  1.123e+01  8.700e+01  -0.359    0.721
> year2016:siteLB   -8.668e+00  1.123e+01  8.700e+01  -0.772    0.442
> year2017:siteLB   -1.530e+00  1.123e+01  8.700e+01  -0.136    0.892
> year2016:siteLBP  -5.336e+00  1.256e+01  8.700e+01  -0.425    0.672
> year2017:siteLBP  -1.826e+00  1.256e+01  8.700e+01  -0.145    0.885
> year2016:siteNB   -7.999e+00  1.123e+01  8.700e+01  -0.712    0.478
> year2017:siteNB   -5.645e+00  1.123e+01  8.700e+01  -0.502    0.617
> year2016:siteNS   -8.871e+00  1.123e+01  8.700e+01  -0.790    0.432
> year2017:siteNS   -3.443e+00  1.123e+01  8.700e+01  -0.306    0.760
> year2016:sitePC   -1.603e+01  1.123e+01  8.700e+01  -1.427    0.157
> year2017:sitePC   -2.955e+00  1.123e+01  8.700e+01  -0.263    0.793
> year2016:siteSB   -1.316e+01  1.123e+01  8.700e+01  -1.171    0.245
> year2017:siteSB   -3.220e+00  1.123e+01  8.700e+01  -0.287    0.775
> year2016:siteSILT -1.616e+01  1.123e+01  8.700e+01  -1.438    0.154
> year2017:siteSILT -2.497e-01  1.123e+01  8.700e+01  -0.022    0.982
> year2016:siteSL   -1.004e+01  1.123e+01  8.700e+01  -0.894    0.374
> year2017:siteSL    1.123e+00  1.123e+01  8.700e+01   0.100    0.921
> year2016:siteUD   -1.345e+01  1.123e+01  8.700e+01  -1.197    0.235
> year2017:siteUD    3.810e+00  1.123e+01  8.700e+01   0.339    0.735
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation matrix not shown by default, as p = 45 > 12.
> Use print(x, correlation=TRUE)  or
>     vcov(x)        if you need it
>
> convergence code: 0
> unable to evaluate scaled gradient
>  Hessian is numerically singular: parameters are not uniquely determined
>
> Is the model unable to converge because her dataset is too small to
include an interaction term or is stemming from issues of model structure?
>
> Thanks!
>
> Caroline
>


From S@E|||@on @end|ng |rom LGCGroup@com  Fri Jan 18 12:47:38 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 18 Jan 2019 11:47:38 +0000
Subject: [R] Colors on box plots in ggplot
In-Reply-To: <CACftpvrMeVo4GwCZorZtK2hkrfr32rnvD31_RgSyOst+uqS4Hw@mail.gmail.com>
References: <CACftpvrMeVo4GwCZorZtK2hkrfr32rnvD31_RgSyOst+uqS4Hw@mail.gmail.com>
Message-ID: <1a2e191c28784a5aaf8c29101707c3e6@GBDCVPEXC08.corp.lgc-group.com>



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> I'm trying to set different boxes to different colors the following page
> shows


> http://www.sthda.com/english/wiki/ggplot2-box-plot-quick-start-guide-r-
> software-and-data-visualization
> 
> 
> I've tried the code
> ToothGrowth$dose <- as.factor(ToothGrowth$dose)
> head(ToothGrowth)
> library(ggplot2)
> # Basic box plot
> p <- ggplot(ToothGrowth, aes(x=dose, y=len))  +
>   geom_boxplot()
> p+scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))
> p

You have not mapped an aesthetic to colour, so the scale (which applies to an aesthetic) is not being used at all.

Try    
( p <- ggplot(ToothGrowth, aes(x=dose, y=len))  + geom_boxplot(aes(colour=dose)) )

which uses default colours. Once you have an aes  mapping you can change the scale, so 
 (     p + scale_colour_manual(values = c("red", "blue", "green")) )

gives you the colour ordering you want.

(     p + scale_colour_manual(values = c("red", "blue", "green"), guide=FALSE) )
also removes the redundant colour key.



S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Jan 18 13:02:09 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 18 Jan 2019 12:02:09 +0000
Subject: [R] Printing a list of simultaneous equations
Message-ID: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>

I am trying to print a list of equations in an easily readable form. At this time all I can get is  a series of characters enclosed in quotation marks rather than equations with numbers and equal signs. What I get is


    y     equalsigns x   z
eq1 "0.5" "="        "1" "2"
eq2 "4"   "="        "2" "3"


When what I want is

          y         x   z

eq1  0.5  =  1   2
eq2  4.0  =  2   3


I am enclosing my R code below:

# Create matrix of  coefficients of independent variables.
a  <- matrix(c(1,2,2,3),nrow=c(2,2),byrow=TRUE)
dimnames(a)<-list(c("eq1","eq2"),c("x","z"))
cat("Matrix of independent variables\n")
a

# Create vector of dependent variables.
b <- matrix(c(0.5,4.0),nrow=c(2,1))

dimnames(b)<-list(c("eq1","eq2"),c("y"))
cat("Vector of dependent variables","\n")
b

cat("System of equations to be solved")
equalsigns <- c("=","=")
cbind(b,equalsigns,a)




Thank you,

John





John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From ru|@@domgz @end|ng |rom gm@||@com  Fri Jan 18 10:56:54 2019
From: ru|@@domgz @end|ng |rom gm@||@com (=?UTF-8?Q?Rula_Dom=C3=ADnguez?=)
Date: Fri, 18 Jan 2019 10:56:54 +0100
Subject: [R] A priori contrast for binomial GLM
Message-ID: <CAKR01-CeG3uuj=6MXKXtvjWbN_4Fr6BWfxgNm5tuY5ftBmpkyA@mail.gmail.com>

Hello to everyone,

after much reading I decided to write because I cannot find a solution to
my question.

I already did a priori contrasts before for a continuous variable with
normal distribution. Now I have another variable (burrow), which is
binomial, and I can do the GLM for it. But when I do the a priori
contrasts, it has no result in the cases where all data are 0 (is not that
there are no data, they are just all 0 in a category (treat 30-30), and I
want to compare this with others that have ones).
 Data sructure is like this:

>head(burrow)
  date day treat psu  sp  burrow
1    3   0 30-30  36    B      0
2    3   0 30-30  36    B      0
3    3   0 15-30  36    B      1
4    3   0 15-30  36    B      1
5    3   0 15-30  36    B      1
6    3   0 10-25  36    B      1

My model is this:
>model4B2<-glm(burrow~ treat, family=binomial(link="logit"), data=D4B)

And I did the contrast like this:

>require(multcomp)
#Test contrastes 30 vs all (there are 4 categories to compare)
k3010R1<-matrix(c(3,-1,-1,-1),1)
k3010R1
t3010<-glht(model4B3.2,linfct=k3010R1)
summary(t3010)

But is not working and I am sure it should work.

Could it be because my explanatory variable is cathegorical?
Or is just not possible to do contrasts for binomial when you have all 0 in
some cathegory?

Thank you in advance,

-- 
Rula Dom?nguez Fern?ndez
PhD Student
*Departamento de Ecolox?a e Biolox?a Animal*
*Faculdade de Ciencias do Mar*
*Universidade de Vigo*

www.researchgate.net/profile/Rula_Dominguez
<https://www.researchgate.net/profile/Rula_Dominguez3>
EcoCost
<https://ecocost.webs.uvigo.es/index.php?option=com_content&view=article&id=9&Itemid=164&lang=gl>
M?vil: +34 646521205

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jan 18 15:09:26 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 18 Jan 2019 14:09:26 +0000
Subject: [R] importing data error question
In-Reply-To: <ca804188-575b-449d-85af-9bbdfdac7624@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
 <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
 <4003829E-5D14-4798-A45D-BF85DA42EF20@mcmaster.ca>
 <7b06b392-2611-411a-ba0e-4edd2a8f1045@ht.co.kr>
 <7188EC66-9F43-41BA-9EA7-D1C573508304@mcmaster.ca>
 <26540c28-b125-44e4-a048-8e82ecca6fa5@ht.co.kr>
 <C30A504E-590F-470E-BCCE-5E5E0C3990EF@mcmaster.ca>
 <ca804188-575b-449d-85af-9bbdfdac7624@ht.co.kr>
Message-ID: <8D55A433-F63A-4CB0-A5E5-B316AE87BDB5@mcmaster.ca>

Dear Jihee,

> On Jan 17, 2019, at 7:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> 
> Dear John,
>  
> (1) I noticed that you loaded the FactoMineR and SensoMineR plug-ins. Try again without loading these plug-ins.
> not worked :(
>  
> <e6a62b753f314ee6a71b3092789009f2.png>

OK. I don't understand why that doesn't work. There is likely some peculiarity in your system, but I have no idea what it is, and I can't think what else I might do without access to your computer.

>  
>  
> (2) Download and try reading the plain-text data file from <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>, using "Data > Import data > From text file, clipboard, or URL"; you can take all of the defaults in the resulting dialog box.
>  
> I think importing is working but I can't view data set. it says ERROR: DATA FRAME TOO WIDE
>  
> <ed5dee194ad648af865b37703567d20a.png>

You tried to read the Excel file Prestige.xlsx as if it were a plain-text file, which produces nonsense. This was my fault: I sent the wrong link; the correct file is at <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.txt>.

Best,
 John

>  
>  
>  
> I have no idea neither. ;(
> I might give up from now,,,,,,
>  
>  
> Thanks again!
>  
> Best,
> Jihee
>  
>  
>  
> From: "Fox, John" <jfox at mcmaster.ca>
> Sent: Friday, January 18, 2019 12:02:42 AM
> To:"???" <wjh1518 at ht.co.kr>
> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> Subject:Re: [R] importing data error question
>  
>  
> Dear Jihee,
> 
> Your latest attempt has gotten farther than the previous one but has produced a different error. The command to read the data set was generated properly. You can see whether the data set was in fact read by typing prestige (the name you gave to the data set) at the > command prompt in the R console. Assuming that the data set was read, an error occurred when the Rcmdr tried to make it the active data set. I'm afraid that I don't understand how this could happen because this procedure works correctly for me and for others. The underlying code is invoked whenever the Rcmdr reads a dara set.
> 
> I suggest that you try two additional things:
> 
> (1) I noticed that you loaded the FactoMineR and SensoMineR plug-ins. Try again without loading these plug-ins.
> 
> (2) Download and try reading the plain-text data file from <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>, using "Data > Import data > From text file, clipboard, or URL"; you can take all of the defaults in the resulting dialog box.
> 
> If neither of these works then I'm afraid that I'm out of ideas. There's something peculiar about your R installation that I can't detect.
> 
> Best,
> John
> 
> 
> 
> > On Jan 17, 2019, at 12:24 AM, ??? <wjh1518 at ht.co.kr> wrote:
> > 
> > Dear John,
> >  
> > I tried with your file. R commander could read the file but there's still no active dataset....
> >  
> > Anyway I'll send my file, too
> >  
> > Jihee
> >  
> > <528c421a382d426895f6446b32fbc6f0.png>
> >  
> > From: "Fox, John" <jfox at mcmaster.ca>
> > Sent: Thursday, January 17, 2019 2:09:52 PM
> > To:"???" <wjh1518 at ht.co.kr>
> > Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> > Subject:Re: [R] importing data error question
> >  
> >  
> > Dear Jihee,
> > 
> > This appears to be a different problem. You were apparently able to access the spreadsheet file, but the R Commander didn't find a suitable worksheet in it.
> > 
> > Try downloading and reading the file at <https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/Prestige.xlsx>. If that works, send me privately (i.e., directly) your Excel spreadsheet file and I'll take a look at it.
> > 
> > Best,
> > John
> > 
> > > On Jan 16, 2019, at 9:49 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > 
> > > Dear John,
> > >  
> > > now i can use english thank you very much!!
> > >  
> > > um.. but nothing's changed... with that {r} message at R Markdown.
> > >  
> > > There's no dataset.
> > >  
> > > i tried both .xls and .xlsx .
> > >  
> > >  
> > > Jihee
> > >  
> > >  
> > >  
> > > <fbe6254214d94e74b98569b08bb3bf07.png>
> > >  
> > >  
> > >  
> > > From: "Fox, John" <jfox at mcmaster.ca>
> > > Sent: Thursday, January 17, 2019 10:59:44 AM
> > > To:"???" <wjh1518 at ht.co.kr>
> > > Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
> > > Subject:Re: [R] importing data error question
> > >  
> > >  
> > > Dear Jihee,
> > > 
> > > Probably the easiest way to change the language to English temporarily in R is to enter the command
> > > 
> > > Sys.setenv(LANGUAGE="en")
> > > 
> > > at the R command prompt prior to loading the Rcmdr package.
> > > 
> > > I hope that this helps,
> > > John
> > > 
> > > 
> > > > On Jan 16, 2019, at 7:02 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > > 
> > > > Thanks for your help!
> > > >  
> > > > I was having trouble with finding how to use english...
> > > >  
> > > > Even though I try to use english language, I couldn't change language of R commander. (it is still korean)
> > > >  
> > > > Sorry but.. do you know how to change language of "R commander"? I have no idea why it doesn't change.
> > > >  
> > > > Best,
> > > > Jihee
> > > >  
> > > > From: "Fox, John" <jfox at mcmaster.ca>
> > > > Sent: Thursday, January 17, 2019 1:59:03 AM
> > > > To:"???" <wjh1518 at ht.co.kr>
> > > > Cc:"r-help at r-project.org" <r-help at r-project.org>
> > > > Subject:Re: [R] importing data error question
> > > >  
> > > >  
> > > > Dear jihee,
> > > > 
> > > > I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:
> > > > 
> > > > I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.
> > > > 
> > > > I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.
> > > > 
> > > > I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.
> > > > 
> > > > Thank you for reporting this issue.
> > > > 
> > > > John
> > > > 
> > > > > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > > > > 
> > > > > Dear jihee,
> > > > > 
> > > > >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > > >> 
> > > > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
> > > > >> 
> > > > >> --> no, I never said i was using a Mac. 
> > > > > 
> > > > > Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
> > > > > 
> > > > >> 
> > > > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
> > > > >> 
> > > > >> --> sessionInfo()
> > > > >> R version 3.5.2 (2018-12-20)
> > > > >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> > > > >> Running under: Windows 7 x64 (build 7601) Service Pack 1
> > > > >> 
> > > > >> Matrix products: default
> > > > >> 
> > > > >> locale:
> > > > >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949  
> > > > >> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C  
> > > > >> [5] LC_TIME=Korean_Korea.949  
> > > > >> 
> > > > >> attached base packages:
> > > > >> [1] tcltk splines stats graphics grDevices utils datasets methods  
> > > > >> [9] base  
> > > > >> 
> > > > >> other attached packages:
> > > > >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  
> > > > >> [3] Rcmdr_2.5-1 effects_4.1-0  
> > > > >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0  
> > > > >> [7] car_3.0-2 carData_3.0-2  
> > > > >> [9] SensoMineR_1.23 FactoMineR_1.41  
> > > > >> 
> > > > >> loaded via a namespace (and not attached):
> > > > >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28 
> > > > >> [4] cellranger_1.1.0 pillar_1.3.1 backports_1.1.3  
> > > > >> [7] lattice_0.20-38 digest_0.6.18 RColorBrewer_1.1-2  
> > > > >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2  
> > > > >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15  
> > > > >> [16] plyr_1.8.4 pkgconfig_2.0.2 haven_2.0.0  
> > > > >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16  
> > > > >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2  
> > > > >> [25] relimp_1.0-5 ggplot2_3.1.0 nnet_7.3-12  
> > > > >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5  
> > > > >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137  
> > > > >> [34] MASS_7.3-51.1 forcats_0.3.0 foreign_0.8-71  
> > > > >> [37] class_7.3-14 tools_3.5.2 data.table_1.11.8  
> > > > >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1  
> > > > >> [43] munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0  
> > > > >> [46] flashClust_1.01-2 compiler_3.5.2 e1071_1.7-0  
> > > > >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1  
> > > > >> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0  
> > > > >> [55] base64enc_0.1-3 gtable_0.2.0 abind_1.4-5  
> > > > >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3  
> > > > >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21  
> > > > >> [64] nortest_1.0-4 Hmisc_4.1-1 KernSmooth_2.23-15  
> > > > >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13  
> > > > >> [70] acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4  
> > > > >> 
> > > > >> This was the status that I tried to import Excel data. 
> > > > > 
> > > > > These packages seem up-to-date.
> > > > > 
> > > > >> 
> > > > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response?  
> > > > >> 
> > > > >> --> I tried without plug-in packages, but It didn't work. 
> > > > > 
> > > > > OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
> > > > > 
> > > > >> 
> > > > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
> > > > >> 
> > > > >> --> I don't know what is plain-text data file..... 
> > > > > 
> > > > > A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
> > > > > 
> > > > >> 
> > > > >> i'll try R with English. 
> > > > > 
> > > > > I'm curious to see what happens.
> > > > > 
> > > > > Best,
> > > > > John
> > > > > 
> > > > >> 
> > > > >> From: "Fox, John" <jfox at mcmaster.ca> 
> > > > >> 
> > > > >> Sent: Monday, January 14, 2019 11:15:36 PM 
> > > > >> 
> > > > >> To:"???" <wjh1518 at ht.co.kr> 
> > > > >> 
> > > > >> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
> > > > >> 
> > > > >> Subject:Re: [R] importing data error question 
> > > > >> 
> > > > >> Dear jihee,
> > > > >> 
> > > > >>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> From: "???" <wjh1518 at ht.co.kr>
> > > > >>> Sent: Monday, January 14, 2019 9:40:26 AM
> > > > >>> To:"Fox, John" <jfox at mcmaster.ca>
> > > > >>> Subject:Re: [R] importing data error question
> > > > >>> 
> > > > >>> 
> > > > >>> Thanks for your replies.
> > > > >>> 
> > > > >>> I'm using windows 7, I loaded FactoMineR,
> > > > >> 
> > > > >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
> > > > >> 
> > > > >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
> > > > >>> This problem occurred when I select Data > Import data > From Excel file.
> > > > >>> I checked FactoMineR and SensoMineR packages are loaded and using..
> > > > >> 
> > > > >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
> > > > >> 
> > > > >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
> > > > >> 
> > > > >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
> > > > >> 
> > > > >> Best,
> > > > >> John
> > > > >> 
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> From: "Fox, John" <jfox at mcmaster.ca>
> > > > >>> Sent: Friday, January 11, 2019 10:48:38 PM
> > > > >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
> > > > >>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
> > > > >>> Subject:Re: [R] importing data error question
> > > > >>> 
> > > > >>> 
> > > > >>> Dear Petr and jihee,
> > > > >>> 
> > > > >>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
> > > > >>> 
> > > > >>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
> > > > >>> 
> > > > >>> Best,
> > > > >>> John
> > > > >>> 
> > > > >>> -------------------------------------------------
> > > > >>> John Fox, Professor Emeritus
> > > > >>> McMaster University
> > > > >>> Hamilton, Ontario, Canada
> > > > >>> Web: http::/socserv.mcmaster.ca/jfox
> > > > >>> 
> > > > >>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > > > >>>> 
> > > > >>>> Hi
> > > > >>>> 
> > > > >>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
> > > > >>>> 
> > > > >>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
> > > > >>>> 
> > > > >>>> Cheers
> > > > >>>> Petr
> > > > >>>> 
> > > > >>>>> -----Original Message-----
> > > > >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
> > > > >>>>> Sent: Friday, January 11, 2019 9:14 AM
> > > > >>>>> To: r-help at R-project.org
> > > > >>>>> Subject: [R] importing data error question
> > > > >>>>> 
> > > > >>>>> Hi I'm jihee and I have a question about error...
> > > > >>>>> 
> > > > >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
> > > > >>>>> 
> > > > >>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
> > > > >>>>> 
> > > > >>>>> but i can't import excel data with Rcmdr.
> > > > >>>>> 
> > > > >>>>> it has this messege :
> > > > >>>>> 
> > > > >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> > > > >>>>> [tcl] bad Macintosh file type "?*?"
> > > > >>>>> 
> > > > >>>>> what is wrong with my R??? T_T
> > > > >>>>> 
> > > > >>>>> Thanks for your help.
> > > > >>>>> 
> > > > >>>>> jihee.
> > > > >>>>> [[alternative HTML version deleted]]
> > > > >>>>> 
> > > > >>>>> ______________________________________________
> > > > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >>>>> and provide commented, minimal, self-contained, reproducible code.
> > > > >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > > > >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > > > >>>> 
> > > > >>>> ______________________________________________
> > > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >>>> and provide commented, minimal, self-contained, reproducible code.
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> ??? ??? / ??????
> > > > >>> e-mailwjh1518 at ht.co.krDirMobile
> > > > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > > > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> 
> > > > >>> ??? ??? / ??????
> > > > >>> e-mailwjh1518 at ht.co.krDirMobile
> > > > >>> ????www.ht.co.kr????www.facebook.com/haitaico
> > > > >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > > >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > > >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
> > > > >> [[alternative HTML version deleted]]
> > > > >> 
> > > > >> ______________________________________________
> > > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > >> and provide commented, minimal, self-contained, reproducible code.
> > > > > 
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > 
> > > >  
> > > > 
> > > > 
> > > > ??? ??? / ??????
> > > > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > > > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > > > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > > 
> > > 
> > >  
> > > 
> > > 
> > > ??? ??? / ??????
> > > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > 
> > 
> >  
> > 
> > 
> > ??? ??? / ??????
> > e-mail	wjh1518 at ht.co.kr	Dir	Mobile	
> > ????	www.ht.co.kr	????	www.facebook.com/haitaico
> > Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
> > ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
> > The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
> > <mass2.xlsx>
> 
> 
>  
> 
> 	
> ??? ??? / ??????
> e-mail	wjh1518 at ht.co.kr	Dir		Mobile	
> ????	www.ht.co.kr	????	www.facebook.com/haitaico
> Address	????? ??? ???? 72? 3 (???) ??????(?) 04352
>   ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
>   The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 


From S@E|||@on @end|ng |rom LGCGroup@com  Fri Jan 18 15:52:15 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 18 Jan 2019 14:52:15 +0000
Subject: [R] Printing a list of simultaneous equations
In-Reply-To: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
References: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
Message-ID: <2df1d10d91224916be9afa2737f301b2@GBDCVPEXC08.corp.lgc-group.com>

You can drop the quote marks by calling print() explicitly with quote=FALSE, by using as.data.frame round your cbind, or - perhaps best - by constructing your output matrix as a data frame in the first place.  (print.data.frame defaults to quote=FALSE). And if you suppress name checking in a data.frame call you can get away with a space for variable names:

a  <- data.frame(y=c(c(0.5,4.0)), " "="=",x=c(1,2), z=c(2,3),  
	row.names=sprintf("eq%d", 1:2), check.names=FALSE)

a


Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From g||ddec@ @end|ng |rom @c|ence@oregon@t@te@edu  Fri Jan 18 16:01:52 2019
From: g||ddec@ @end|ng |rom @c|ence@oregon@t@te@edu (Caroline)
Date: Fri, 18 Jan 2019 07:01:52 -0800
Subject: [R] Nested mixed effectts question
In-Reply-To: <ce4a82cb-71b3-7aff-7b38-19b58263dfe1@mpi.nl>
References: <mailman.353252.1.1547636401.26680.r-help@r-project.org>
 <8297ff28-e5b3-a4a6-7b90-60766dec4168@mpi.nl>
 <ce4a82cb-71b3-7aff-7b38-19b58263dfe1@mpi.nl>
Message-ID: <41FA8C26-EEF8-4EB5-9DAF-D851AF6DDBAA@science.oregonstate.edu>

Great! Your suggestions made perfect sense and worked well. Thank you so much. 

> On Jan 18, 2019, at 3:33 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> (once again with the list)
> 
> Hi Caroline,
> 
> This question is probably better suited to r-sig-mixed-models
> (https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models). Some things
> are hard to tell without better understanding your design (I am not an
> ecologist/relevant type of biologist), but I'll give it a go.
> 
> I suspect that your model is over-parameterized. It's very rare to see a
> factor occur both as a fixed effect and as a grouping variable (the
> stuff behind the | ) in the random effects.
> 
> If you don't care about particular sites but rather only the general
> pattern across sites, then I would start with the model:
> 
> wrack.biomass ~ year  + (1 + year | site/trans)
> 
> This treats site as a known source of variance, but not one that you
> care about estimating particular effects for. You can still extract
> predictions for them, i.e. the BLUPs, via coef(wrackbio), but their
> theoretical interpretation is a bit different than the other option below.
> 
> If you do care about particular sites, I would use the model
> 
> # if your transects are uniquely labeled across sites
> wrack.biomass ~ year * site + (1 | trans)
> # if the transect labels are only unique within sites
> wrack.biomass ~ year * site + (1 | sites:trans)
> 
> This will give you fixed effects as in your model, but models the
> transects as a source of repetition and hence variance due to that
> grouping. The choice of exact specification depends on the labeling in
> your dataset; the sites:trans just guarantees unique labelling. The
> random effect in this case would estimate the average variance across
> all sites due to transects.
> 
> Best,
> Phillip
> 
> 
> 
> 
> On 16/01/19 12:00, r-help-request at r-project.org wrote:
>> Send R-help mailing list submissions to
> 
>> Today's Topics:
>> 
>>   6. Nested mixed effectts question (Caroline)
>> ----------------------------------------------------------------------
>> Hi,
>> 
>> I am helping a friend with an analysis for a study where she sampled
> wrack biomass in 15 different sites across three years. At each site,
> she sampled from three different transects. She is trying to estimate
> the effect of year*site on biomass while accounting for the nested
> nature (site/transcet) and repeated measure study design.
>> 
>> wrack.biomass ~ year * site + (1 | site/trans)
>> 
>> However she gets the following warning messages:
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>  unable to evaluate scaled gradient
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Hessian is numerically singular: parameters are not uniquely determined
>> 
>> And her model output is:
>> 
>>> summary(wrackbio)
>> Linear mixed model fit by REML
>> t-tests use  Satterthwaite approximations to degrees of freedom
> ['lmerMod']
>> Formula: (actual.mean.biomass.m2.50.m.transect) ~ year * site + (1 |
> site/trans)
>>   Data: wrack_resp_allyrs_transname
>> 
>> REML criterion at convergence: 691
>> 
>> Scaled residuals:
>>    Min      1Q  Median      3Q     Max
>> -3.3292 -0.2624 -0.0270  0.1681  3.8024
>> 
>> Random effects:
>> Groups     Name        Variance Std.Dev.
>> trans:site (Intercept)  0.0000  0.0000
>> site       (Intercept)  0.5531  0.7437
>> Residual               94.6453  9.7286
>> Number of obs: 132, groups:  trans:site, 44; site, 15
>> 
>> Fixed effects:
>>                    Estimate Std. Error         df t value Pr(>|t|)
>> (Intercept)        9.692e+00  5.666e+00  1.119e-04   1.711    0.999
>> year2016           1.256e+01  7.943e+00  8.700e+01   1.582    0.117
>> year2017           2.395e+00  7.943e+00  8.700e+01   0.302    0.764
>> siteCL             5.672e+01  8.013e+00  1.119e-04   7.079    0.999
>> siteDO            -4.315e+00  8.013e+00  1.119e-04  -0.539    0.999
>> siteFL             7.872e+00  8.013e+00  1.119e-04   0.982    0.999
>> siteFS            -7.619e+00  8.013e+00  1.119e-04  -0.951    0.999
>> siteGH             4.369e+00  8.013e+00  1.119e-04   0.545    0.999
>> siteLB            -3.747e+00  8.013e+00  1.119e-04  -0.468    0.999
>> siteLBP           -5.298e+00  8.943e+00  1.736e-04  -0.592    0.999
>> siteNB            -2.953e+00  8.013e+00  1.119e-04  -0.369    1.000
>> siteNS             1.005e+00  8.013e+00  1.119e-04   0.125    1.000
>> sitePC            -5.238e+00  8.013e+00  1.119e-04  -0.654    0.999
>> siteSB            -7.649e+00  8.013e+00  1.119e-04  -0.955    0.999
>> siteSILT          -4.734e+00  8.013e+00  1.119e-04  -0.591    0.999
>> siteSL            -7.890e+00  8.013e+00  1.119e-04  -0.985    0.999
>> siteUD            -8.230e+00  8.013e+00  1.119e-04  -1.027    0.999
>> year2016:siteCL   -6.359e+01  1.123e+01  8.700e+01  -5.660 1.91e-07 ***
>> year2017:siteCL   -5.210e+01  1.123e+01  8.700e+01  -4.638 1.23e-05 ***
>> year2016:siteDO   -1.550e+01  1.123e+01  8.700e+01  -1.380    0.171
>> year2017:siteDO   -3.022e+00  1.123e+01  8.700e+01  -0.269    0.789
>> year2016:siteFL   -7.522e+00  1.123e+01  8.700e+01  -0.670    0.505
>> year2017:siteFL   -1.167e+01  1.123e+01  8.700e+01  -1.039    0.302
>> year2016:siteFS   -1.391e+01  1.123e+01  8.700e+01  -1.238    0.219
>> year2017:siteFS   -2.170e+00  1.123e+01  8.700e+01  -0.193    0.847
>> year2016:siteGH   -9.135e+00  1.123e+01  8.700e+01  -0.813    0.418
>> year2017:siteGH   -4.031e+00  1.123e+01  8.700e+01  -0.359    0.721
>> year2016:siteLB   -8.668e+00  1.123e+01  8.700e+01  -0.772    0.442
>> year2017:siteLB   -1.530e+00  1.123e+01  8.700e+01  -0.136    0.892
>> year2016:siteLBP  -5.336e+00  1.256e+01  8.700e+01  -0.425    0.672
>> year2017:siteLBP  -1.826e+00  1.256e+01  8.700e+01  -0.145    0.885
>> year2016:siteNB   -7.999e+00  1.123e+01  8.700e+01  -0.712    0.478
>> year2017:siteNB   -5.645e+00  1.123e+01  8.700e+01  -0.502    0.617
>> year2016:siteNS   -8.871e+00  1.123e+01  8.700e+01  -0.790    0.432
>> year2017:siteNS   -3.443e+00  1.123e+01  8.700e+01  -0.306    0.760
>> year2016:sitePC   -1.603e+01  1.123e+01  8.700e+01  -1.427    0.157
>> year2017:sitePC   -2.955e+00  1.123e+01  8.700e+01  -0.263    0.793
>> year2016:siteSB   -1.316e+01  1.123e+01  8.700e+01  -1.171    0.245
>> year2017:siteSB   -3.220e+00  1.123e+01  8.700e+01  -0.287    0.775
>> year2016:siteSILT -1.616e+01  1.123e+01  8.700e+01  -1.438    0.154
>> year2017:siteSILT -2.497e-01  1.123e+01  8.700e+01  -0.022    0.982
>> year2016:siteSL   -1.004e+01  1.123e+01  8.700e+01  -0.894    0.374
>> year2017:siteSL    1.123e+00  1.123e+01  8.700e+01   0.100    0.921
>> year2016:siteUD   -1.345e+01  1.123e+01  8.700e+01  -1.197    0.235
>> year2017:siteUD    3.810e+00  1.123e+01  8.700e+01   0.339    0.735
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation matrix not shown by default, as p = 45 > 12.
>> Use print(x, correlation=TRUE)  or
>>    vcov(x)        if you need it
>> 
>> convergence code: 0
>> unable to evaluate scaled gradient
>> Hessian is numerically singular: parameters are not uniquely determined
>> 
>> Is the model unable to converge because her dataset is too small to
> include an interaction term or is stemming from issues of model structure?
>> 
>> Thanks!
>> 
>> Caroline
>> 
> 


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jan 18 16:05:20 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 18 Jan 2019 07:05:20 -0800
Subject: [R] Printing a list of simultaneous equations
In-Reply-To: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
References: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
Message-ID: <6D080B47-8595-4653-A5FC-A8C37AEABA6C@dcn.davis.ca.us>

Don't use the default print method then. When you type an expression alone at the console it uses a print function to convert the result to characters for output. The default print method for matrices of character uses quotes to show the exact contents of each character string.

Convert the matrix to a single string using  paste for each line, then paste the lines together with newlines, then cat the string to the console. You will probably find that converting the individual elements into strings with uniform string length (using sprintf?) as you add them into the matrix makes the final output look better.

On January 18, 2019 4:02:09 AM PST, "Sorkin, John" <jsorkin at som.umaryland.edu> wrote:
>I am trying to print a list of equations in an easily readable form. At
>this time all I can get is  a series of characters enclosed in
>quotation marks rather than equations with numbers and equal signs.
>What I get is
>
>
>    y     equalsigns x   z
>eq1 "0.5" "="        "1" "2"
>eq2 "4"   "="        "2" "3"
>
>
>When what I want is
>
>          y         x   z
>
>eq1  0.5  =  1   2
>eq2  4.0  =  2   3
>
>
>I am enclosing my R code below:
>
># Create matrix of  coefficients of independent variables.
>a  <- matrix(c(1,2,2,3),nrow=c(2,2),byrow=TRUE)
>dimnames(a)<-list(c("eq1","eq2"),c("x","z"))
>cat("Matrix of independent variables\n")
>a
>
># Create vector of dependent variables.
>b <- matrix(c(0.5,4.0),nrow=c(2,1))
>
>dimnames(b)<-list(c("eq1","eq2"),c("y"))
>cat("Vector of dependent variables","\n")
>b
>
>cat("System of equations to be solved")
>equalsigns <- c("=","=")
>cbind(b,equalsigns,a)
>
>
>
>
>Thank you,
>
>John
>
>
>
>
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wjh1518 @end|ng |rom ht@co@kr  Thu Jan 17 01:02:18 2019
From: wjh1518 @end|ng |rom ht@co@kr (=?utf-8?B?7Jqw7KeA7Z2s?=)
Date: Thu, 17 Jan 2019 09:02:18 +0900
Subject: [R] importing data error question
In-Reply-To: <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
Message-ID: <82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>

Thanks for your help! 

I was having trouble with finding how to use english... 

Even though I try to use english language, I couldn't change language of R commander. (it is still korean) 

Sorry but.. do you know how to change language of "R commander"? I have no idea why it doesn't change. 

Best, 

Jihee 

From:  "Fox, John" <jfox at mcmaster.ca> 

Sent: Thursday, January 17, 2019 1:59:03 AM 

To:"???" <wjh1518 at ht.co.kr> 

Cc:"r-help at r-project.org" <r-help at r-project.org> 

Subject:Re: [R] importing data error question 

? Dear jihee,

 I've looked into this problem further, using my Mac where it's easier to temporarily change languages and character sets than on Windows, and I discovered the following:

 I was able to duplicate your problem with importing Excel files when working in Korean. There's a similar problem with the import SAS b7dat files but not with the other file-import dialogs.

 I observed a similar problem when working in Chinese (LANG="zh") but not in simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with non-Latin character sets. There is no problem in English, Spanish (es), or French (fr), and I didn't check the other languages into which the Rcmdr is translated.

 I think that the problem originates in the Korean and Chinese translation files and I'll contact the translators to see whether they can fix it.

 Thank you for reporting this issue.

 John

 > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
 > 
 > Dear jihee,
 > 
 >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
 >> 
 >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters. 
 >> 
 >> --> no, I never said i was using a Mac. 
 > 
 > Sorry, I guess I got that from the error message you originally reported, which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems peculiar that it would occur on a Windows system.
 > 
 >> 
 >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command. 
 >> 
 >> --> sessionInfo()
 >> R version 3.5.2 (2018-12-20)
 >> Platform: x86_64-w64-mingw32/x64 (64-bit)
 >> Running under: Windows 7 x64 (build 7601) Service Pack 1
 >> 
 >> Matrix products: default
 >> 
 >> locale:
 >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949 
 >> [3] LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C 
 >> [5] LC_TIME=Korean_Korea.949 
 >> 
 >> attached base packages:
 >> [1] tcltk splines stats graphics grDevices utils datasets methods 
 >> [9] base 
 >> 
 >> other attached packages:
 >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0 
 >> [3] Rcmdr_2.5-1 effects_4.1-0 
 >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0 
 >> [7] car_3.0-2 carData_3.0-2 
 >> [9] SensoMineR_1.23 FactoMineR_1.41 
 >> 
 >> loaded via a namespace (and not attached):
 >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28 
 >> [4] cellranger_1.1.0 pillar_1.3.1 backports_1.1.3 
 >> [7] lattice_0.20-38 digest_0.6.18 RColorBrewer_1.1-2 
 >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2 
 >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15 
 >> [16] plyr_1.8.4 pkgconfig_2.0.2 haven_2.0.0 
 >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16 
 >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2 
 >> [25] relimp_1.0-5 ggplot2_3.1.0 nnet_7.3-12 
 >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5 
 >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137 
 >> [34] MASS_7.3-51.1 forcats_0.3.0 foreign_0.8-71 
 >> [37] class_7.3-14 tools_3.5.2 data.table_1.11.8 
 >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1 
 >> [43] munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0 
 >> [46] flashClust_1.01-2 compiler_3.5.2 e1071_1.7-0 
 >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1 
 >> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0 
 >> [55] base64enc_0.1-3 gtable_0.2.0 abind_1.4-5 
 >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3 
 >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21 
 >> [64] nortest_1.0-4 Hmisc_4.1-1 KernSmooth_2.23-15 
 >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13 
 >> [70] acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4 
 >> 
 >> This was the status that I tried to import Excel data. 
 > 
 > These packages seem up-to-date.
 > 
 >> 
 >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
 >> 
 >> --> I tried without plug-in packages, but It didn't work. 
 > 
 > OK, so you tried the setup that works for me and, I assume from the lack of similar error reports, for others.
 > 
 >> 
 >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file? 
 >> 
 >> --> I don't know what is plain-text data file..... 
 > 
 > A plain-text data file could, e.g., be created from an Excel file by exporting a worksheet as a .csv (comma-separated-values) file; you could read this into the Rcmdr via Data > Import data > from text file, specifying the field separator as commas.
 > 
 >> 
 >> i'll try R with English. 
 > 
 > I'm curious to see what happens.
 > 
 > Best,
 > John
 > 
 >> 
 >> From: "Fox, John" <jfox at mcmaster.ca> 
 >> 
 >> Sent: Monday, January 14, 2019 11:15:36 PM 
 >> 
 >> To:"???" <wjh1518 at ht.co.kr> 
 >> 
 >> Cc:"<r-help at r-project.org>" <r-help at R-project.org></r-help at r-project.org> 
 >> 
 >> Subject:Re: [R] importing data error question 
 >> 
 >> Dear jihee,
 >> 
 >>> On Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
 >>> 
 >>> 
 >>> 
 >>> From: "???" <wjh1518 at ht.co.kr>
 >>> Sent: Monday, January 14, 2019 9:40:26 AM
 >>> To:"Fox, John" <jfox at mcmaster.ca>
 >>> Subject:Re: [R] importing data error question
 >>> 
 >>> 
 >>> Thanks for your replies.
 >>> 
 >>> I'm using windows 7, I loaded FactoMineR,
 >> 
 >> You said previously that you were using a Mac, so I'm surprised that you now say that you're using Windows. I don't have a Windows 7 system, but I can confirm that importing from Excel files works perfectly fine under Windows 10, as I just verified, and I'd be surprised if the Windows version matters.
 >> 
 >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR, Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other required packages that downloaded automatically)
 >>> This problem occurred when I select Data > Import data > From Excel file.
 >>> I checked FactoMineR and SensoMineR packages are loaded and using..
 >> 
 >> You still haven't reported the versions of R, the Rcmdr package, and the other packages that you're using. The easiest way to do this is to show the output of the sessionInfo() command.
 >> 
 >> Also, have you tried importing an Excel file in the Rcmdr *without* the two plug-in packages loaded, as I suggested in my original response? 
 >> 
 >> It occurs to me that the problem may be produced by using the Rcmdr under R with a non-Latin set, but if that were the case I would have expected the problem to have surfaced earlier. Did you try reading another kind of file, such as a plain-text data file?
 >> 
 >> Best,
 >> John
 >> 
 >>> 
 >>> 
 >>> 
 >>> From: "Fox, John" <jfox at mcmaster.ca>
 >>> Sent: Friday, January 11, 2019 10:48:38 PM
 >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>
 >>> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-project.org>
 >>> Subject:Re: [R] importing data error question
 >>> 
 >>> 
 >>> Dear Petr and jihee,
 >>> 
 >>> The Rcmdr can import Excel files, and as I just verified, it can do so on a Mac listing files of all types (*) in the open-file dialog box (which is the default). 
 >>> 
 >>> So, as Petr suggests, more information is required to help you, including the versions of macOS, R, and all packages you have loaded. In particular, does the problem occur when you try to read the Excel file *without* FactoMineR and SensoMineR loaded? Also, when the does problem occur -- immediately when you select Data > Import data > From Excel file, or at some other point?
 >>> 
 >>> Best,
 >>> John
 >>> 
 >>> -------------------------------------------------
 >>> John Fox, Professor Emeritus
 >>> McMaster University
 >>> Hamilton, Ontario, Canada
 >>> Web: http::/socserv.mcmaster.ca/jfox
 >>> 
 >>>> On Jan 11, 2019, at 5:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 >>>> 
 >>>> Hi
 >>>> 
 >>>> I do not use Rcmdr but from documentation it seems to me that it does not have much to do with importing data from Excel.
 >>>> 
 >>>> So without some additional info from your side (at least used commands) you hardly get any reasonable answer.
 >>>> 
 >>>> Cheers
 >>>> Petr
 >>>> 
 >>>>> -----Original Message-----
 >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
 >>>>> Sent: Friday, January 11, 2019 9:14 AM
 >>>>> To: r-help at R-project.org
 >>>>> Subject: [R] importing data error question
 >>>>> 
 >>>>> Hi I'm jihee and I have a question about error...
 >>>>> 
 >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
 >>>>> 
 >>>>> and using FactoMineR and SensoMineR to analyze sensory data through PCA
 >>>>> 
 >>>>> but i can't import excel data with Rcmdr.
 >>>>> 
 >>>>> it has this messege :
 >>>>> 
 >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
 >>>>> [tcl] bad Macintosh file type "?*?"
 >>>>> 
 >>>>> what is wrong with my R??? T_T
 >>>>> 
 >>>>> Thanks for your help.
 >>>>> 
 >>>>> jihee.
 >>>>> [[alternative HTML version deleted]]
 >>>>> 
 >>>>> ______________________________________________
 >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >>>>> and provide commented, minimal, self-contained, reproducible code.
 >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
 >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
 >>>> 
 >>>> ______________________________________________
 >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >>>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >>>> and provide commented, minimal, self-contained, reproducible code.
 >>> 
 >>> 
 >>> 
 >>> 
 >>> ??? ??? / ??????
 >>> e-mailwjh1518 at ht.co.krDirMobile
 >>> ????www.ht.co.kr????www.facebook.com/haitaico
 >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
 >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
 >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately 
 >>> 
 >>> 
 >>> 
 >>> 
 >>> ??? ??? / ??????
 >>> e-mailwjh1518 at ht.co.krDirMobile
 >>> ????www.ht.co.kr????www.facebook.com/haitaico
 >>> Address????? ??? ???? 72? 3 (???) ??????(?) 04352
 >>> ?? ??? ??? ????? ?? ???, ?????? ? ??????? ?? ??? ???? ?? ??? ?? ??? ??? ?? ????, ???? ?? ???? ?? ? ????. ? ??? ??? ??? ?? ?? ??? ???? ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ? ??? ?? ??? ??, ????? ????? ? ??? ?? ???? ??? ????.
 >>> The above message is intended solely for the named addressee and may contain trade secret. Industrial technology or privileged and confidential information otherwise protected under applicable law including the Unfair Competition Prevention and Trade Secret Protection Act. Any unauthorized dissemination, distribution, copying or use of the information contained in this communication is strictly prohibited. If you have received this communication in error, please notify the sender by email and delete this communication immediately
 >> [[alternative HTML version deleted]]
 >> 
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 > 
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jan 18 16:47:35 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 18 Jan 2019 16:47:35 +0100
Subject: [R] I can't get seq to behave how I think it should
In-Reply-To: <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
References: <dd26db9ab1e84938b0bfcfc2f9937c3d@NH-SLPEX171.AD1.NHS.NET>
 <58AC30B7-C28A-4B52-9676-F560D0E3103F@bigelow.org>
 <58ee033d4e694809bb4ccc373c106138@SRVEXCHCM1302.precheza.cz>
Message-ID: <23617.62743.516639.380142@stat.math.ethz.ch>

>>>>> PIKAL Petr 
>>>>>     on Thu, 17 Jan 2019 13:52:39 +0000 writes:

    > Hi
    > Or you could use rounding.

yes.

    > which(round(lut, 3)==1.8)
    > [1] 401

no!   This may work accidentally here, but in principle still
suffers for the same reasons as
the infamous FAQ 7.31 "Why doesn?t R think these numbers are equal?"
(link below) gives.

To be sure you should round to *integer*s (or other multiples of
2 ^{-k}, k \in {0,1,...,31}).

1.8 is not exactly representable as a (double precision)
floating point number in binary representation.
Your example here works because the rounding typically happens
to end up with the same binary repr ... this all relies on too
many details to be recommendable.

Martin Maechler
ETH Zurich and R Core team


    >> -----Original Message-----
    >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Tupper
    >> Sent: Thursday, January 17, 2019 2:43 PM
    >> To: POLWART, Calum (COUNTY DURHAM AND DARLINGTON NHS
    >> FOUNDATION TRUST) <calum.polwart at nhs.net>
    >> Cc: r-help at r-project.org
    >> Subject: Re: [R] I can't get seq to behave how I think it should
    >> 
    >> Hi,
    >> 
    >> This looks like a floating point reality bump - see
    >> 
    >> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-
    >> these-numbers-are-equal_003f <https://cran.r-project.org/doc/FAQ/R-
    >> FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f>
    >> 
    >> You can use other methods to finding your row - I would opt for findInterval()
    >> 
    >> > lut = seq(1.4, 2.1, by=0.001)
    >> > findInterval(1.8, lut)
    >> [1] 401
    >> 
    >> findInterval() uses a rapid search to find the index in the look up table (lut) that
    >> is just less than  or equal to the search value (in your example 1.8).
    >> 
    >> Cheers,
    >> Ben
    >> 
    >> > On Jan 17, 2019, at 8:33 AM, POLWART, Calum (COUNTY DURHAM AND
    >> DARLINGTON NHS FOUNDATION TRUST) via R-help <r-help at r-project.org>
    >> wrote:
    >> >
    >> > I am using seq with the expression seq(1.4, 2.1, by=0.001) to create a
    >> > sequence of references from 1.4 to 2.1 in 0.001 increments.  They
    >> > appear to be created correctly.  They have a related pair of data
    >> > which for the purposes of this we will call val.  I'm interested in
    >> > the content on the row with seq = 1.8. But I can't seem to get it
    >> > returned.  I can get other values but not 1.8!  yet looking at row 401
    >> > there is nothing to indicate an issue
    >> >
    >> >> a = 1.4
    >> >> b = 2.1
    >> >> seq = seq(a, b, by=0.001)
    >> >> val = ceiling(seq * 50)
    >> >> s=data.frame(seq, val)
    >> >> s$val[seq==1.799]
    >> > [1] 90
    >> >> s$val[s$seq==1.8]
    >> > numeric(0)
    >> >> s$val[seq==1.8]
    >> > numeric(0)
    >> >> s$val[s$seq==1.800]
    >> > numeric(0)
    >> >> s$val[s$seq==1.801]
    >> > [1] 91
    >> >> head(s[s$seq>1.798,])
    >> >      seq val
    >> > 400 1.799  90
    >> > 401 1.800  90
    >> > 402 1.801  91
    >> > 403 1.802  91
    >> > 404 1.803  91
    >> > 405 1.804  91
    >> >
    >> >
    >> > Can anyone explain what's going on here and how I would correctly find the
    >> content of row 401 by using an expression to equal the seq column?
    >> >
    >> >
    >> >
    >> >
    >> >
    >> >
    >> *******************************************************************
    >> ***
    >> > **********************************************
    >> >
    >> > This message may contain confidential information. If
    >> > ...{{dropped:25}}
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
    > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Jan 18 16:51:33 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 18 Jan 2019 15:51:33 +0000
Subject: [R] Printing a list of simultaneous equations
In-Reply-To: <2df1d10d91224916be9afa2737f301b2@GBDCVPEXC08.corp.lgc-group.com>
References: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>,
 <2df1d10d91224916be9afa2737f301b2@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <BYAPR03MB4725CB7B184C68DAD3B8A966E29C0@BYAPR03MB4725.namprd03.prod.outlook.com>

Steve,

Thank you,

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: S Ellison <S.Ellison at LGCGroup.com>
Sent: Friday, January 18, 2019 9:52 AM
To: Sorkin, John; r-help at r-project.org
Subject: RE: Printing a list of simultaneous equations

You can drop the quote marks by calling print() explicitly with quote=FALSE, by using as.data.frame round your cbind, or - perhaps best - by constructing your output matrix as a data frame in the first place.  (print.data.frame defaults to quote=FALSE). And if you suppress name checking in a data.frame call you can get away with a space for variable names:

a  <- data.frame(y=c(c(0.5,4.0)), " "="=",x=c(1,2), z=c(2,3),
        row.names=sprintf("eq%d", 1:2), check.names=FALSE)

a


Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:11}}


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jan 18 16:51:38 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 18 Jan 2019 15:51:38 +0000
Subject: [R] importing data error question
In-Reply-To: <29928_1547826273_x0IFiWKu026796_82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
References: <ad5ba62f-5cc6-49db-8009-1f4d8a03ca53@ht.co.kr>
 <92DD508D-8528-4EA2-B9B0-F5C67DE353E6@mcmaster.ca>
 <25423_1547520154_x0F2gXMc017573_5f0d9fb8-b27d-48b6-be60-5642031aee30@ht.co.kr>
 <25820_1547527022_x0F4b1GR032038_06CB2EC5-3CEE-4EAF-A1E3-C149F6361412@mcmaster.ca>
 <45D4F3AA-2B3A-47D3-8444-DDC73AC6A5B7@mcmaster.ca>
 <29928_1547826273_x0IFiWKu026796_82a702f8-2d11-4e93-a6e8-e5f7f2e9ddf0@ht.co.kr>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836A53356@FHSDB2D11-2.csu.mcmaster.ca>

Dear Jihee,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ???
> Sent: Wednesday, January 16, 2019 7:02 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] importing data error question
> 
> Thanks for your help!
> 
> I was having trouble with finding how to use english...
> 
> Even though I try to use english language, I couldn't change language of R
> commander. (it is still korean)
> 
> Sorry but.. do you know how to change language of "R commander"? I have
> no idea why it doesn't change.

But the screenshots you sent in previous messages *did* show the Rcmdr in English, so you apparently successfully changed the language, I assume via the command Sys.setenv(LANGUAGE="en") that I suggested.

John

> 
> Best,
> 
> Jihee
> 
> From:  "Fox, John" <jfox at mcmaster.ca>
> 
> Sent: Thursday, January 17, 2019 1:59:03 AM
> 
> To:"???" <wjh1518 at ht.co.kr>
> 
> Cc:"r-help at r-project.org" <r-help at r-project.org>
> 
> Subject:Re: [R] importing data error question
> 
> ? Dear jihee,
> 
>  I've looked into this problem further, using my Mac where it's easier to
> temporarily change languages and character sets than on Windows, and I
> discovered the following:
> 
>  I was able to duplicate your problem with importing Excel files when working
> in Korean. There's a similar problem with the import SAS b7dat files but not
> with the other file-import dialogs.
> 
>  I observed a similar problem when working in Chinese (LANG="zh") but not in
> simplified Chinese (zh_CN) or Japanese (ja), so the problem isn't simply with
> non-Latin character sets. There is no problem in English, Spanish (es), or
> French (fr), and I didn't check the other languages into which the Rcmdr is
> translated.
> 
>  I think that the problem originates in the Korean and Chinese translation files
> and I'll contact the translators to see whether they can fix it.
> 
>  Thank you for reporting this issue.
> 
>  John
> 
>  > On Jan 14, 2019, at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
>  >
>  > Dear jihee,
>  >
>  >> On Jan 14, 2019, at 9:00 PM, ??? <wjh1518 at ht.co.kr> wrote:
>  >>
>  >> You said previously that you were using a Mac, so I'm surprised that you
> now say that you're using Windows. I don't have a Windows 7 system, but I
> can confirm that importing from Excel files works perfectly fine under
> Windows 10, as I just verified, and I'd be surprised if the Windows version
> matters.
>  >>
>  >> --> no, I never said i was using a Mac.
>  >
>  > Sorry, I guess I got that from the error message you originally reported,
> which was "Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> [tcl] bad Macintosh file type "?*?"." I've never seen that error and it seems
> peculiar that it would occur on a Windows system.
>  >
>  >>
>  >> You still haven't reported the versions of R, the Rcmdr package, and the
> other packages that you're using. The easiest way to do this is to show the
> output of the sessionInfo() command.
>  >>
>  >> --> sessionInfo()
>  >> R version 3.5.2 (2018-12-20)
>  >> Platform: x86_64-w64-mingw32/x64 (64-bit)  >> Running under: Windows
> 7 x64 (build 7601) Service Pack 1  >>  >> Matrix products: default  >>  >>
> locale:
>  >> [1] LC_COLLATE=Korean_Korea.949 LC_CTYPE=Korean_Korea.949  >> [3]
> LC_MONETARY=Korean_Korea.949 LC_NUMERIC=C  >> [5]
> LC_TIME=Korean_Korea.949  >>  >> attached base packages:
>  >> [1] tcltk splines stats graphics grDevices utils datasets methods  >> [9] base
> >>  >> other attached packages:
>  >> [1] RcmdrPlugin.SensoMineR_1.11-01 RcmdrPlugin.FactoMineR_1.6-0  >>
> [3] Rcmdr_2.5-1 effects_4.1-0  >> [5] RcmdrMisc_2.5-1 sandwich_2.5-0  >> [7]
> car_3.0-2 carData_3.0-2  >> [9] SensoMineR_1.23 FactoMineR_1.41  >>  >>
> loaded via a namespace (and not attached):
>  >> [1] gtools_3.8.1 Formula_1.2-3 latticeExtra_0.6-28  >> [4] cellranger_1.1.0
> pillar_1.3.1 backports_1.1.3  >> [7] lattice_0.20-38 digest_0.6.18
> RColorBrewer_1.1-2  >> [10] checkmate_1.8.5 minqa_1.2.4 colorspace_1.3-2
> >> [13] survey_3.35 htmltools_0.3.6 Matrix_1.2-15  >> [16] plyr_1.8.4
> pkgconfig_2.0.2 haven_2.0.0  >> [19] scales_1.0.0 openxlsx_4.1.0 rio_0.5.16
> >> [22] lme4_1.1-19 htmlTable_1.13.1 tibble_1.4.2  >> [25] relimp_1.0-5
> ggplot2_3.1.0 nnet_7.3-12  >> [28] lazyeval_0.2.1 survival_2.43-3 magrittr_1.5
> >> [31] crayon_1.3.4 readxl_1.2.0 nlme_3.1-137  >> [34] MASS_7.3-51.1
> forcats_0.3.0 foreign_0.8-71  >> [37] class_7.3-14 tools_3.5.2
> data.table_1.11.8  >> [40] hms_0.4.2 tcltk2_1.2-11 stringr_1.3.1  >> [43]
> munsell_0.5.0 cluster_2.0.7-1 zip_1.0.0  >> [46] flashClust_1.01-2
> compiler_3.5.2 e1071_1.7-0  >> [49] rlang_0.3.1 grid_3.5.2 nloptr_1.2.1  >>
> [52] rstudioapi_0.9.0 htmlwidgets_1.3 leaps_3.0  >> [55] base64enc_0.1-3
> gtable_0.2.0 abind_1.4-5  >> [58] curl_3.2 reshape2_1.4.3 AlgDesign_1.1-7.3
> >> [61] gridExtra_2.3 zoo_1.8-4 knitr_1.21  >> [64] nortest_1.0-4 Hmisc_4.1-1
> KernSmooth_2.23-15  >> [67] stringi_1.2.4 Rcpp_1.0.0 rpart_4.1-13  >> [70]
> acepack_1.4.1 scatterplot3d_0.3-41 xfun_0.4  >>  >> This was the status that I
> tried to import Excel data.
>  >
>  > These packages seem up-to-date.
>  >
>  >>
>  >> Also, have you tried importing an Excel file in the Rcmdr *without* the two
> plug-in packages loaded, as I suggested in my original response?
>  >>
>  >> --> I tried without plug-in packages, but It didn't work.
>  >
>  > OK, so you tried the setup that works for me and, I assume from the lack of
> similar error reports, for others.
>  >
>  >>
>  >> It occurs to me that the problem may be produced by using the Rcmdr
> under R with a non-Latin set, but if that were the case I would have expected
> the problem to have surfaced earlier. Did you try reading another kind of file,
> such as a plain-text data file?
>  >>
>  >> --> I don't know what is plain-text data file.....
>  >
>  > A plain-text data file could, e.g., be created from an Excel file by exporting a
> worksheet as a .csv (comma-separated-values) file; you could read this into
> the Rcmdr via Data > Import data > from text file, specifying the field
> separator as commas.
>  >
>  >>
>  >> i'll try R with English.
>  >
>  > I'm curious to see what happens.
>  >
>  > Best,
>  > John
>  >
>  >>
>  >> From: "Fox, John" <jfox at mcmaster.ca>  >>  >> Sent: Monday, January 14,
> 2019 11:15:36 PM  >>  >> To:"???" <wjh1518 at ht.co.kr>  >>  >> Cc:"<r-
> help at r-project.org>" <r-help at R-project.org></r-help at r-project.org>
>  >>
>  >> Subject:Re: [R] importing data error question  >>  >> Dear jihee,  >>  >>> On
> Jan 13, 2019, at 9:28 PM, ??? <wjh1518 at ht.co.kr> wrote:
>  >>>
>  >>>
>  >>>
>  >>> From: "???" <wjh1518 at ht.co.kr>
>  >>> Sent: Monday, January 14, 2019 9:40:26 AM  >>> To:"Fox, John"
> <jfox at mcmaster.ca>  >>> Subject:Re: [R] importing data error question  >>>
> >>>  >>> Thanks for your replies.
>  >>>
>  >>> I'm using windows 7, I loaded FactoMineR,  >>  >> You said previously
> that you were using a Mac, so I'm surprised that you now say that you're using
> Windows. I don't have a Windows 7 system, but I can confirm that importing
> from Excel files works perfectly fine under Windows 10, as I just verified, and
> I'd be surprised if the Windows version matters.
>  >>
>  >>> SensoMineR and then Rcmdr. (Downloaded FacroMineR, SensoMineR,
> Rcmdr, Rcmdrplugin.FactomineR, Rcmdrplugin.SensomineR and other
> required packages that downloaded automatically)  >>> This problem
> occurred when I select Data > Import data > From Excel file.
>  >>> I checked FactoMineR and SensoMineR packages are loaded and using..
>  >>
>  >> You still haven't reported the versions of R, the Rcmdr package, and the
> other packages that you're using. The easiest way to do this is to show the
> output of the sessionInfo() command.
>  >>
>  >> Also, have you tried importing an Excel file in the Rcmdr *without* the two
> plug-in packages loaded, as I suggested in my original response?
>  >>
>  >> It occurs to me that the problem may be produced by using the Rcmdr
> under R with a non-Latin set, but if that were the case I would have expected
> the problem to have surfaced earlier. Did you try reading another kind of file,
> such as a plain-text data file?
>  >>
>  >> Best,
>  >> John
>  >>
>  >>>
>  >>>
>  >>>
>  >>> From: "Fox, John" <jfox at mcmaster.ca>  >>> Sent: Friday, January 11,
> 2019 10:48:38 PM  >>> To:"PIKAL Petr" <petr.pikal at precheza.cz>  >>>
> Cc:"???" <wjh1518 at ht.co.kr>; "r-help at R-project.org" <r-help at r-
> project.org>  >>> Subject:Re: [R] importing data error question  >>>  >>>  >>>
> Dear Petr and jihee,  >>>  >>> The Rcmdr can import Excel files, and as I just
> verified, it can do so on a Mac listing files of all types (*) in the open-file dialog
> box (which is the default).
>  >>>
>  >>> So, as Petr suggests, more information is required to help you, including
> the versions of macOS, R, and all packages you have loaded. In particular,
> does the problem occur when you try to read the Excel file *without*
> FactoMineR and SensoMineR loaded? Also, when the does problem occur --
> immediately when you select Data > Import data > From Excel file, or at some
> other point?
>  >>>
>  >>> Best,
>  >>> John
>  >>>
>  >>> -------------------------------------------------
>  >>> John Fox, Professor Emeritus
>  >>> McMaster University
>  >>> Hamilton, Ontario, Canada
>  >>> Web: http::/socserv.mcmaster.ca/jfox  >>>  >>>> On Jan 11, 2019, at 5:07
> AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>  >>>>
>  >>>> Hi
>  >>>>
>  >>>> I do not use Rcmdr but from documentation it seems to me that it does
> not have much to do with importing data from Excel.
>  >>>>
>  >>>> So without some additional info from your side (at least used
> commands) you hardly get any reasonable answer.
>  >>>>
>  >>>> Cheers
>  >>>> Petr
>  >>>>
>  >>>>> -----Original Message-----
>  >>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of ???
>  >>>>> Sent: Friday, January 11, 2019 9:14 AM  >>>>> To: r-help at R-
> project.org  >>>>> Subject: [R] importing data error question  >>>>>  >>>>> Hi
> I'm jihee and I have a question about error...
>  >>>>>
>  >>>>> I'm using R 3.5.2 and tried to use Rcmdr package.
>  >>>>>
>  >>>>> and using FactoMineR and SensoMineR to analyze sensory data
> through PCA  >>>>>  >>>>> but i can't import excel data with Rcmdr.
>  >>>>>
>  >>>>> it has this messege :
>  >>>>>
>  >>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>  >>>>> [tcl] bad Macintosh file type "?*?"
>  >>>>>
>  >>>>> what is wrong with my R??? T_T
>  >>>>>
>  >>>>> Thanks for your help.
>  >>>>>
>  >>>>> jihee.
>  >>>>> [[alternative HTML version deleted]]  >>>>>  >>>>>
> ______________________________________________
>  >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>  >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
>  >>>>> and provide commented, minimal, self-contained, reproducible code.
>  >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website: https://www.precheza.cz/en/personal-data-protection-
> principles/
>  >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>  >>>>
>  >>>> ______________________________________________
>  >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>  >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
>  >>>> and provide commented, minimal, self-contained, reproducible code.
>  >>>
>  >>>
>  >>>
>  >>>
>  >>> ??? ??? / ??????
>  >>> e-mailwjh1518 at ht.co.krDirMobile
>  >>> ????www.ht.co.kr????www.facebook.com/haitaico
>  >>> Address????? ??? ???? 72? 3 (???)
> ??????(?) 04352  >>> ?? ??? ??? ????? ??
> ???, ?????? ? ??????? ?? ??? ???? ??
> ??? ?? ??? ??? ?? ????, ???? ?? ???? ??
> ? ????. ? ??? ??? ??? ?? ?? ??? ????
> ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ?
> ??? ?? ??? ??, ????? ????? ? ??? ??
> ???? ??? ????.
>  >>> The above message is intended solely for the named addressee and may
> contain trade secret. Industrial technology or privileged and confidential
> information otherwise protected under applicable law including the Unfair
> Competition Prevention and Trade Secret Protection Act. Any unauthorized
> dissemination, distribution, copying or use of the information contained in
> this communication is strictly prohibited. If you have received this
> communication in error, please notify the sender by email and delete this
> communication immediately  >>>  >>>  >>>  >>>  >>> ??? ??? /
> ??????  >>> e-mailwjh1518 at ht.co.krDirMobile  >>>
> ????www.ht.co.kr????www.facebook.com/haitaico
>  >>> Address????? ??? ???? 72? 3 (???)
> ??????(?) 04352  >>> ?? ??? ??? ????? ??
> ???, ?????? ? ??????? ?? ??? ???? ??
> ??? ?? ??? ??? ?? ????, ???? ?? ???? ??
> ? ????. ? ??? ??? ??? ?? ?? ??? ????
> ?3??? ??, ??, ?? ?? ???? ?? ??? ?????. ?
> ??? ?? ??? ??, ????? ????? ? ??? ??
> ???? ??? ????.
>  >>> The above message is intended solely for the named addressee and may
> contain trade secret. Industrial technology or privileged and confidential
> information otherwise protected under applicable law including the Unfair
> Competition Prevention and Trade Secret Protection Act. Any unauthorized
> dissemination, distribution, copying or use of the information contained in
> this communication is strictly prohibited. If you have received this
> communication in error, please notify the sender by email and delete this
> communication immediately  >> [[alternative HTML version deleted]]  >>  >>
> ______________________________________________
>  >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  >>
> https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
>  >> and provide commented, minimal, self-contained, reproducible code.
>  >
>  > ______________________________________________
>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  >
> https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
>  > and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Jan 18 17:14:52 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 18 Jan 2019 16:14:52 +0000
Subject: [R] A priori contrast for binomial GLM
In-Reply-To: <CAKR01-CeG3uuj=6MXKXtvjWbN_4Fr6BWfxgNm5tuY5ftBmpkyA@mail.gmail.com>
References: <CAKR01-CeG3uuj=6MXKXtvjWbN_4Fr6BWfxgNm5tuY5ftBmpkyA@mail.gmail.com>
Message-ID: <27ebbc29-be5e-81e0-7998-68fb81bd497c@dewey.myzen.co.uk>

Dear Rula

That is really a statistical question not one for this list but the 
answer is that the fact that they are all zero for that category 
explains it. Search on-line for separation for more details.

Michael

On 18/01/2019 09:56, Rula Dom?nguez wrote:
> Hello to everyone,
> 
> after much reading I decided to write because I cannot find a solution to
> my question.
> 
> I already did a priori contrasts before for a continuous variable with
> normal distribution. Now I have another variable (burrow), which is
> binomial, and I can do the GLM for it. But when I do the a priori
> contrasts, it has no result in the cases where all data are 0 (is not that
> there are no data, they are just all 0 in a category (treat 30-30), and I
> want to compare this with others that have ones).
>   Data sructure is like this:
> 
>> head(burrow)
>    date day treat psu  sp  burrow
> 1    3   0 30-30  36    B      0
> 2    3   0 30-30  36    B      0
> 3    3   0 15-30  36    B      1
> 4    3   0 15-30  36    B      1
> 5    3   0 15-30  36    B      1
> 6    3   0 10-25  36    B      1
> 
> My model is this:
>> model4B2<-glm(burrow~ treat, family=binomial(link="logit"), data=D4B)
> 
> And I did the contrast like this:
> 
>> require(multcomp)
> #Test contrastes 30 vs all (there are 4 categories to compare)
> k3010R1<-matrix(c(3,-1,-1,-1),1)
> k3010R1
> t3010<-glht(model4B3.2,linfct=k3010R1)
> summary(t3010)
> 
> But is not working and I am sure it should work.
> 
> Could it be because my explanatory variable is cathegorical?
> Or is just not possible to do contrasts for binomial when you have all 0 in
> some cathegory?
> 
> Thank you in advance,
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From hwborcher@ @end|ng |rom gm@||@com  Fri Jan 18 19:57:53 2019
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Fri, 18 Jan 2019 19:57:53 +0100
Subject: [R] CRAN package NlcOptim query
In-Reply-To: <CAML4n3PW1RsVxWRq8VHvYCauhcWu+NrBZVR3ipg0WoqV1NU7zw@mail.gmail.com>
References: <CAML4n3P0w_fb+51vPco5Lv9R80iVMjsDL4MtWLCNo6=Ly+Qtkw@mail.gmail.com>
 <CAML4n3PW1RsVxWRq8VHvYCauhcWu+NrBZVR3ipg0WoqV1NU7zw@mail.gmail.com>
Message-ID: <CAML4n3On24abOj7yjgbtM52aMWP04UHWJ8wtKAzOSTyAQaLG6A@mail.gmail.com>

The maintainer of the *NlcOptim* package told me that he has fixed the
problem and already submitted a new version to CRAN. Thanks, XianYan,
for this prompt reaction.


From jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com  Sat Jan 19 01:55:27 2019
From: jo@ec|@ud|o@|@r|@ @end|ng |rom gm@||@com (Jose Claudio Faria)
Date: Fri, 18 Jan 2019 21:55:27 -0300
Subject: [R] Tinn-R: new website under https protocol
Message-ID: <CAN+Emd-RszZ2rd0JKxKwZ-bTCX8Evnk-iH_JE66py-5+6gQrxA@mail.gmail.com>

Dears,

The Tinn-R projetc has a new website under the https protocol:
https://nbcgib.uesc.br/tinnr/en/

Best,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

If you have software to deal with statistics, you have arms;
if you have good software, you have arms and legs;
if you have software like R, you have arms, legs and wings...
the height of your flight depends only on you!

	[[alternative HTML version deleted]]


From |r|end|y @end|ng |rom yorku@c@  Sat Jan 19 19:14:59 2019
From: |r|end|y @end|ng |rom yorku@c@ (Michael Friendly)
Date: Sat, 19 Jan 2019 13:14:59 -0500
Subject: [R] Printing a list of simultaneous equations
In-Reply-To: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
References: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
Message-ID: <018fea12-5978-c4b5-5e77-1187161d446e@yorku.ca>

John-

Don't try to forge a new wheel, when you can get one ready made
and it might fit your wagon.

Check out the `matlib` package on CRAN and devel on github: 
https://github.com/friendly/matlib

install.packages("matlib")
library(matlib)
A <- matrix(c(1,2,3, -1, 2, 1), 3, 2)
b <- c(2,1,3)
showEqn(A, b)

 > showEqn(A, b)
1*x1 - 1*x2  =  2
2*x1 + 2*x2  =  1
3*x1 + 1*x2  =  3
 >
sound like what you want.  Various vignettes illustrate this, also 
showing how to plot linear equations in 2D, 3D.

browseVignettes("matlib")


On 1/18/2019 7:02 AM, Sorkin, John wrote:
> I am trying to print a list of equations in an easily readable form. At this time all I can get is  a series of characters enclosed in quotation marks rather than equations with numbers and equal signs. What I get is
> 
> 
>      y     equalsigns x   z
> eq1 "0.5" "="        "1" "2"
> eq2 "4"   "="        "2" "3"
> 
> 
> When what I want is
> 
>            y         x   z
> 
> eq1  0.5  =  1   2
> eq2  4.0  =  2   3
> 
> 
> I am enclosing my R code below:
> 
> # Create matrix of  coefficients of independent variables.
> a  <- matrix(c(1,2,2,3),nrow=c(2,2),byrow=TRUE)
> dimnames(a)<-list(c("eq1","eq2"),c("x","z"))
> cat("Matrix of independent variables\n")
> a
> 
> # Create vector of dependent variables.
> b <- matrix(c(0.5,4.0),nrow=c(2,1))
> 
> dimnames(b)<-list(c("eq1","eq2"),c("y"))
> cat("Vector of dependent variables","\n")
> b
> 
> cat("System of equations to be solved")
> equalsigns <- c("=","=")
> cbind(b,equalsigns,a)
> 
> 
> 
> 
> Thank you,
> 
> John
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 	[[alternative HTML version deleted]]
> 


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, ASA Statistical Graphics Section
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca  |  @datavisFriendly
Toronto, ONT  M3J 1P3 CANADA


From |r|end|y @end|ng |rom yorku@c@  Sat Jan 19 19:18:27 2019
From: |r|end|y @end|ng |rom yorku@c@ (Michael Friendly)
Date: Sat, 19 Jan 2019 13:18:27 -0500
Subject: [R] 
 Tinn-R: new website under https protocol / fortune nomination
In-Reply-To: <CAN+Emd-RszZ2rd0JKxKwZ-bTCX8Evnk-iH_JE66py-5+6gQrxA@mail.gmail.com>
References: <CAN+Emd-RszZ2rd0JKxKwZ-bTCX8Evnk-iH_JE66py-5+6gQrxA@mail.gmail.com>
Message-ID: <fef30da2-a95c-5cb6-6100-7eaa906a298d@yorku.ca>

Body parts might be debated, but this seems like a fortune nomination.
-M

On 1/18/2019 7:55 PM, Jose Claudio Faria wrote:
> If you have software to deal with statistics, you have arms;
> if you have good software, you have arms and legs;
> if you have software like R, you have arms, legs and wings...
> the height of your flight depends only on you!


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, ASA Statistical Graphics Section
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca  |  @datavisFriendly
Toronto, ONT  M3J 1P3 CANADA


From torbett@ydney@ @end|ng |rom gm@||@com  Sat Jan 19 22:42:19 2019
From: torbett@ydney@ @end|ng |rom gm@||@com (Sydney Torbett)
Date: Sat, 19 Jan 2019 16:42:19 -0500
Subject: [R] Opening R
Message-ID: <51A6AA5F-41DB-4255-9418-884986B1295E@gmail.com>

Hello!  I have a Dell XPS laptop that runs windows and once I download and install R, keeping all defaults, when I try to open the application that?s on my desktop, a notification just pops up prompting a re-installation process.  I can?t actually get inside R and I?ve followed all of the directions properly to install it so why is this happening?  Here are some pictures to hopefully help you understand the situation a little better.
1. Installing R

-------------- next part --------------

2. Set Up Complete

-------------- next part --------------

3. My teacher?s post explaining that once I double-click on R, that image should pop up.

-------------- next part --------------

4. What actually happens when I double-click R on my desktop (leads me through the installation process again).

-------------- next part --------------

Sent from my iPhone

From peter@w@|tm@n @end|ng |rom gm@||@com  Sun Jan 20 02:22:49 2019
From: peter@w@|tm@n @end|ng |rom gm@||@com (Peter Waltman)
Date: Sat, 19 Jan 2019 20:22:49 -0500
Subject: [R] Was there a change to R ver. 3.5.2 so that it now treats
 warnings during installs as errors?
Message-ID: <CAGqygPpfZWo3o24TMSzvvoJitWuXSUG3BRaH-PtePrUjAkLYDw@mail.gmail.com>

I'm trying to install a devel package called gGnome (
https://github.com/mskilab/gGnome). One of its dependencies is another
package from the same group, called gTrack, which causes several warning
messages to be generated because it overloads a couple of functions that
are part of other packages that gTrack is dependent upon.  The specific
warnings are provided below.  During the lazy-loading step of gGnome's
install, gTrack is loaded, and when these warnings come up, they are
converted to errors, causing the install to fail. This behavior is new to
version 3.5.2, as I've been able to successfully install these packages
with R versions 3.5.0 and 3.5.1. Is there a workaround for this for version
3.5.2?

Thanks!

Error message during gGnome install:

> install_github('mskilab/gGnome')
Downloading GitHub repo mskilab/gGnome at master
Skipping 3 packages not available: GenomicRanges, rtracklayer,
VariantAnnotation
?  checking for file
?/tmp/Rtmp4hnMMO/remotes7fb938cd0553/mskilab-gGnome-81f661e/DESCRIPTION? ...
?  preparing ?gGnome?:
?  checking DESCRIPTION meta-information ...
?  checking for LF line-endings in source and make files and shell scripts
?  checking for empty or unneeded directories
   Removed empty directory ?gGnome/inst/extdata/gTrack.js?
?  building ?gGnome_0.1.tar.gz?

* installing *source* package ?gGnome? ...
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package or namespace load failed for ?gTrack?:
* (converted from warning)* multiple methods tables found for ?seqinfo<-?
Error : package ?gTrack? could not be loaded
ERROR: lazy loading failed for package ?gGnome?
* removing ?/home/waltman/bin/R/3.5.2/lib/R/library/gGnome?
Error in i.p(...) :
  (converted from warning) installation of package
?/tmp/Rtmp4hnMMO/file7fb929638ed8/gGnome_0.1.tar.gz? had non-zero exit
status


warning from gTrack when it is loaded:

Attaching package: ?gTrack?

The following object is masked from ?package:GenomicRanges?:

    seqinfo<-

The following object is masked from ?package:GenomeInfoDb?:

    seqinfo<-

Warning message:
multiple methods tables found for ?seqinfo<-?

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sun Jan 20 10:00:21 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 20 Jan 2019 11:00:21 +0200
Subject: [R] Opening R
In-Reply-To: <51A6AA5F-41DB-4255-9418-884986B1295E@gmail.com>
References: <51A6AA5F-41DB-4255-9418-884986B1295E@gmail.com>
Message-ID: <CAGgJW768hFk+uGHr3kPHU4emsXiGfwPR7dsgpmHMXtCc5Ag4bA@mail.gmail.com>

Hi Sydney,
This mailing list is a text-only list so your pictures are not coming
through.
I am guessing that you are clicking on the setup (installation) program and
not on R.
That would explain why you are being led to the installation process again.

You can try to search for another desktop icon that may be R.
Or search for the program R.exe.
Another possibility is to download RStudio which is a complete environment
(IDE) for
working with R.

I hope that helps,
Eric

On Sun, Jan 20, 2019 at 10:43 AM Sydney Torbett <torbettsydneya at gmail.com>
wrote:

> Hello!  I have a Dell XPS laptop that runs windows and once I download and
> install R, keeping all defaults, when I try to open the application that?s
> on my desktop, a notification just pops up prompting a re-installation
> process.  I can?t actually get inside R and I?ve followed all of the
> directions properly to install it so why is this happening?  Here are some
> pictures to hopefully help you understand the situation a little better.
> 1. Installing R
>
> 2. Set Up Complete
>
> 3. My teacher?s post explaining that once I double-click on R, that image
> should pop up.
>
> 4. What actually happens when I double-click R on my desktop (leads me
> through the installation process again).
>
> Sent from my iPhone______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 20 12:58:24 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 20 Jan 2019 06:58:24 -0500
Subject: [R] Was there a change to R ver. 3.5.2 so that it now treats
 warnings during installs as errors?
In-Reply-To: <CAGqygPpfZWo3o24TMSzvvoJitWuXSUG3BRaH-PtePrUjAkLYDw@mail.gmail.com>
References: <CAGqygPpfZWo3o24TMSzvvoJitWuXSUG3BRaH-PtePrUjAkLYDw@mail.gmail.com>
Message-ID: <957dbbbf-38a9-98a4-699a-23f00525beff@gmail.com>

On 19/01/2019 8:22 p.m., Peter Waltman wrote:
> I'm trying to install a devel package called gGnome (
> https://github.com/mskilab/gGnome). One of its dependencies is another
> package from the same group, called gTrack, which causes several warning
> messages to be generated because it overloads a couple of functions that
> are part of other packages that gTrack is dependent upon.  The specific
> warnings are provided below.  During the lazy-loading step of gGnome's
> install, gTrack is loaded, and when these warnings come up, they are
> converted to errors, causing the install to fail. This behavior is new to
> version 3.5.2, as I've been able to successfully install these packages
> with R versions 3.5.0 and 3.5.1. Is there a workaround for this for version
> 3.5.2?
> 
> Thanks!
> 
> Error message during gGnome install:
> 
>> install_github('mskilab/gGnome')
> Downloading GitHub repo mskilab/gGnome at master
> Skipping 3 packages not available: GenomicRanges, rtracklayer,
> VariantAnnotation
> ?  checking for file
> ?/tmp/Rtmp4hnMMO/remotes7fb938cd0553/mskilab-gGnome-81f661e/DESCRIPTION? ...
> ?  preparing ?gGnome?:
> ?  checking DESCRIPTION meta-information ...
> ?  checking for LF line-endings in source and make files and shell scripts
> ?  checking for empty or unneeded directories
>     Removed empty directory ?gGnome/inst/extdata/gTrack.js?
> ?  building ?gGnome_0.1.tar.gz?
> 
> * installing *source* package ?gGnome? ...
> ** R
> ** inst
> ** byte-compile and prepare package for lazy loading
> Error: package or namespace load failed for ?gTrack?:
> * (converted from warning)* multiple methods tables found for ?seqinfo<-?
> Error : package ?gTrack? could not be loaded
> ERROR: lazy loading failed for package ?gGnome?
> * removing ?/home/waltman/bin/R/3.5.2/lib/R/library/gGnome?
> Error in i.p(...) :
>    (converted from warning) installation of package
> ?/tmp/Rtmp4hnMMO/file7fb929638ed8/gGnome_0.1.tar.gz? had non-zero exit
> status

That message indicates that options("warn") is 2 or higher when the 
warning occurs.  What is its setting before you start the install?

Duncan Murdoch


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Sun Jan 20 13:29:19 2019
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Sun, 20 Jan 2019 12:29:19 +0000
Subject: [R] Was there a change to R ver. 3.5.2 so that it now treats
 warnings during installs as errors?
In-Reply-To: <957dbbbf-38a9-98a4-699a-23f00525beff@gmail.com>
References: <CAGqygPpfZWo3o24TMSzvvoJitWuXSUG3BRaH-PtePrUjAkLYDw@mail.gmail.com>
 <957dbbbf-38a9-98a4-699a-23f00525beff@gmail.com>
Message-ID: <DM6PR05MB52128C7C620A7DFA4B8DA18AF99E0@DM6PR05MB5212.namprd05.prod.outlook.com>

Looks like you're using remotes::install_github(), which in turn uses remotes::install().

The README

  https://github.com/r-lib/remotes/blob/254c67ed6502e092a316553f2a44f04b0e595b64/README.md

says "Setting R_REMOTES_NO_ERRORS_FROM_WARNINGS=true avoids stopping the installation for warning messages. Warnings usually mean installation errors, so by default remotes stops for a warning. However, sometimes other warnings might happen, that could be ignored by setting this environment variable.

So I'd guess

  Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = TRUE)

before installing the package would address this problem.

Martin Morgan

?On 1/20/19, 6:58 AM, "R-help on behalf of Duncan Murdoch" <r-help-bounces at r-project.org on behalf of murdoch.duncan at gmail.com> wrote:

    On 19/01/2019 8:22 p.m., Peter Waltman wrote:
    > I'm trying to install a devel package called gGnome (
    > https://github.com/mskilab/gGnome). One of its dependencies is another
    > package from the same group, called gTrack, which causes several warning
    > messages to be generated because it overloads a couple of functions that
    > are part of other packages that gTrack is dependent upon.  The specific
    > warnings are provided below.  During the lazy-loading step of gGnome's
    > install, gTrack is loaded, and when these warnings come up, they are
    > converted to errors, causing the install to fail. This behavior is new to
    > version 3.5.2, as I've been able to successfully install these packages
    > with R versions 3.5.0 and 3.5.1. Is there a workaround for this for version
    > 3.5.2?
    > 
    > Thanks!
    > 
    > Error message during gGnome install:
    > 
    >> install_github('mskilab/gGnome')
    > Downloading GitHub repo mskilab/gGnome at master
    > Skipping 3 packages not available: GenomicRanges, rtracklayer,
    > VariantAnnotation
    > ?  checking for file
    > ?/tmp/Rtmp4hnMMO/remotes7fb938cd0553/mskilab-gGnome-81f661e/DESCRIPTION? ...
    > ?  preparing ?gGnome?:
    > ?  checking DESCRIPTION meta-information ...
    > ?  checking for LF line-endings in source and make files and shell scripts
    > ?  checking for empty or unneeded directories
    >     Removed empty directory ?gGnome/inst/extdata/gTrack.js?
    > ?  building ?gGnome_0.1.tar.gz?
    > 
    > * installing *source* package ?gGnome? ...
    > ** R
    > ** inst
    > ** byte-compile and prepare package for lazy loading
    > Error: package or namespace load failed for ?gTrack?:
    > * (converted from warning)* multiple methods tables found for ?seqinfo<-?
    > Error : package ?gTrack? could not be loaded
    > ERROR: lazy loading failed for package ?gGnome?
    > * removing ?/home/waltman/bin/R/3.5.2/lib/R/library/gGnome?
    > Error in i.p(...) :
    >    (converted from warning) installation of package
    > ?/tmp/Rtmp4hnMMO/file7fb929638ed8/gGnome_0.1.tar.gz? had non-zero exit
    > status
    
    That message indicates that options("warn") is 2 or higher when the 
    warning occurs.  What is its setting before you start the install?
    
    Duncan Murdoch
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    

From peter@w@|tm@n @end|ng |rom gm@||@com  Sun Jan 20 14:26:56 2019
From: peter@w@|tm@n @end|ng |rom gm@||@com (Peter Waltman)
Date: Sun, 20 Jan 2019 08:26:56 -0500
Subject: [R] Was there a change to R ver. 3.5.2 so that it now treats
 warnings during installs as errors?
In-Reply-To: <DM6PR05MB52128C7C620A7DFA4B8DA18AF99E0@DM6PR05MB5212.namprd05.prod.outlook.com>
References: <CAGqygPpfZWo3o24TMSzvvoJitWuXSUG3BRaH-PtePrUjAkLYDw@mail.gmail.com>
 <957dbbbf-38a9-98a4-699a-23f00525beff@gmail.com>
 <DM6PR05MB52128C7C620A7DFA4B8DA18AF99E0@DM6PR05MB5212.namprd05.prod.outlook.com>
Message-ID: <CAGqygPo99xeq5ioP+7O_xiua_xv8RoK8vgO_REGEKcFwC2xRAQ@mail.gmail.com>

Fantastic - that was it! Thanks so much!

On Sun, Jan 20, 2019 at 7:29 AM Martin Morgan <mtmorgan.bioc at gmail.com>
wrote:

> Looks like you're using remotes::install_github(), which in turn uses
> remotes::install().
>
> The README
>
>
> https://github.com/r-lib/remotes/blob/254c67ed6502e092a316553f2a44f04b0e595b64/README.md
>
> says "Setting R_REMOTES_NO_ERRORS_FROM_WARNINGS=true avoids stopping the
> installation for warning messages. Warnings usually mean installation
> errors, so by default remotes stops for a warning. However, sometimes other
> warnings might happen, that could be ignored by setting this environment
> variable.
>
> So I'd guess
>
>   Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = TRUE)
>
> before installing the package would address this problem.
>
> Martin Morgan
>
> ?On 1/20/19, 6:58 AM, "R-help on behalf of Duncan Murdoch" <
> r-help-bounces at r-project.org on behalf of murdoch.duncan at gmail.com> wrote:
>
>     On 19/01/2019 8:22 p.m., Peter Waltman wrote:
>     > I'm trying to install a devel package called gGnome (
>     > https://github.com/mskilab/gGnome). One of its dependencies is
> another
>     > package from the same group, called gTrack, which causes several
> warning
>     > messages to be generated because it overloads a couple of functions
> that
>     > are part of other packages that gTrack is dependent upon.  The
> specific
>     > warnings are provided below.  During the lazy-loading step of
> gGnome's
>     > install, gTrack is loaded, and when these warnings come up, they are
>     > converted to errors, causing the install to fail. This behavior is
> new to
>     > version 3.5.2, as I've been able to successfully install these
> packages
>     > with R versions 3.5.0 and 3.5.1. Is there a workaround for this for
> version
>     > 3.5.2?
>     >
>     > Thanks!
>     >
>     > Error message during gGnome install:
>     >
>     >> install_github('mskilab/gGnome')
>     > Downloading GitHub repo mskilab/gGnome at master
>     > Skipping 3 packages not available: GenomicRanges, rtracklayer,
>     > VariantAnnotation
>     > ?  checking for file
>     >
> ?/tmp/Rtmp4hnMMO/remotes7fb938cd0553/mskilab-gGnome-81f661e/DESCRIPTION? ...
>     > ?  preparing ?gGnome?:
>     > ?  checking DESCRIPTION meta-information ...
>     > ?  checking for LF line-endings in source and make files and shell
> scripts
>     > ?  checking for empty or unneeded directories
>     >     Removed empty directory ?gGnome/inst/extdata/gTrack.js?
>     > ?  building ?gGnome_0.1.tar.gz?
>     >
>     > * installing *source* package ?gGnome? ...
>     > ** R
>     > ** inst
>     > ** byte-compile and prepare package for lazy loading
>     > Error: package or namespace load failed for ?gTrack?:
>     > * (converted from warning)* multiple methods tables found for
> ?seqinfo<-?
>     > Error : package ?gTrack? could not be loaded
>     > ERROR: lazy loading failed for package ?gGnome?
>     > * removing ?/home/waltman/bin/R/3.5.2/lib/R/library/gGnome?
>     > Error in i.p(...) :
>     >    (converted from warning) installation of package
>     > ?/tmp/Rtmp4hnMMO/file7fb929638ed8/gGnome_0.1.tar.gz? had non-zero
> exit
>     > status
>
>     That message indicates that options("warn") is 2 or higher when the
>     warning occurs.  What is its setting before you start the install?
>
>     Duncan Murdoch
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From or|o|eb@|t|more @end|ng |rom gm@||@com  Sun Jan 20 15:02:15 2019
From: or|o|eb@|t|more @end|ng |rom gm@||@com (Adrian Johnson)
Date: Sun, 20 Jan 2019 09:02:15 -0500
Subject: [R] data transformation
Message-ID: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>

Dear group,
My question, perhaps is more of a statistical question using R
I have a data matrix ( 400 x 400 normally distributed) with data
points ranging from -1 to +1..
For certain clustering algorithms, I suspect the tight data range is
not helping resolving the clusters.

Is there a way to transform the data something similar to logit, where
I dont lose normality of the data and yet I can better expand the data
ranges.

Thanks
Adrian


From or|o|eb@|t|more @end|ng |rom gm@||@com  Sun Jan 20 17:08:14 2019
From: or|o|eb@|t|more @end|ng |rom gm@||@com (Adrian Johnson)
Date: Sun, 20 Jan 2019 11:08:14 -0500
Subject: [R] data transformation
In-Reply-To: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
References: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
Message-ID: <CAL2fYnP5ig-cW3w0hxUj39OrHU99wjYSKXrb32YhjaOpjW0g1g@mail.gmail.com>

I apologize,  I forgot to mention another key operation.
in my matrix -1 to <0 has a different meaning while values between >0
to 1 has a different set of meaning.  So If I do logit transformation
some of the positives becomes negative (values < 0.5 etc.). In such
case, the resulting transformed matrix is incorrect.

I want to transform numbers ranging from -1 to <0   and numbers
between >0 and 1 independently.

Thanks


From dc@r|@on @end|ng |rom t@mu@edu  Sun Jan 20 19:20:25 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Sun, 20 Jan 2019 18:20:25 +0000
Subject: [R] data transformation
In-Reply-To: <CAL2fYnP5ig-cW3w0hxUj39OrHU99wjYSKXrb32YhjaOpjW0g1g@mail.gmail.com>
References: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
 <CAL2fYnP5ig-cW3w0hxUj39OrHU99wjYSKXrb32YhjaOpjW0g1g@mail.gmail.com>
Message-ID: <bd1a1f6024bb49209b12e00e85da2864@tamu.edu>

I don't think you have given us enough information. For example, is the 500x500 matrix a distance matrix or does it represent 500 columns of information about 500 rows of observations? If a distance matrix, how is distance being measured? You clarification suggests it may be a distance matrix of correlation coefficients? If distance has different meanings between -1 and 0 and 0 and +1, getting interpretable results from cluster analysis will be difficult, but it is not clear what you mean by that.

-------------------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian Johnson
Sent: Sunday, January 20, 2019 8:02 AM
To: r-help <r-help at r-project.org>
Subject: [R] data transformation

Dear group,
My question, perhaps is more of a statistical question using R
I have a data matrix ( 400 x 400 normally distributed) with data
points ranging from -1 to +1..
For certain clustering algorithms, I suspect the tight data range is
not helping resolving the clusters.

Is there a way to transform the data something similar to logit, where
I dont lose normality of the data and yet I can better expand the data
ranges.

Thanks
Adrian

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian Johnson
Sent: Sunday, January 20, 2019 10:08 AM
To: r-help <r-help at r-project.org>
Subject: Re: [R] data transformation

I apologize,  I forgot to mention another key operation.
in my matrix -1 to <0 has a different meaning while values between >0
to 1 has a different set of meaning.  So If I do logit transformation
some of the positives becomes negative (values < 0.5 etc.). In such
case, the resulting transformed matrix is incorrect.

I want to transform numbers ranging from -1 to <0   and numbers
between >0 and 1 independently.

Thanks

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Sun Jan 20 19:26:13 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sun, 20 Jan 2019 13:26:13 -0500
Subject: [R] data transformation
In-Reply-To: <CAL2fYnP5ig-cW3w0hxUj39OrHU99wjYSKXrb32YhjaOpjW0g1g@mail.gmail.com>
References: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
 <CAL2fYnP5ig-cW3w0hxUj39OrHU99wjYSKXrb32YhjaOpjW0g1g@mail.gmail.com>
Message-ID: <CAGx1TMCFY9ECdGLdJSLOoAfX9bRnSt013XarJDJUQk_3esDJJg@mail.gmail.com>

this might work for you

newy <- sign(oldy)*f(abs(oldy))

where f() is a monotonic transformation, perhaps a power function.

On Sun, Jan 20, 2019 at 11:08 AM Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
>
> I apologize,  I forgot to mention another key operation.
> in my matrix -1 to <0 has a different meaning while values between >0
> to 1 has a different set of meaning.  So If I do logit transformation
> some of the positives becomes negative (values < 0.5 etc.). In such
> case, the resulting transformed matrix is incorrect.
>
> I want to transform numbers ranging from -1 to <0   and numbers
> between >0 and 1 independently.
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Sun Jan 20 19:36:04 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Sun, 20 Jan 2019 18:36:04 +0000
Subject: [R] Opening R
In-Reply-To: <CAGgJW768hFk+uGHr3kPHU4emsXiGfwPR7dsgpmHMXtCc5Ag4bA@mail.gmail.com>
References: <51A6AA5F-41DB-4255-9418-884986B1295E@gmail.com>
 <CAGgJW768hFk+uGHr3kPHU4emsXiGfwPR7dsgpmHMXtCc5Ag4bA@mail.gmail.com>
Message-ID: <5fe683a3b7ac4fb886cdc8c7fd0418cf@tamu.edu>

Files with .png extensions generally make it through the list so, this attachment should survive. It shows the icons for R on Windows. The first is the icon for the R installation software, the second and third are the icons for the 64bit and 32 bit versions of R respectively. These icons may be in Start menu, not on the desktop.

---------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric Berger
Sent: Sunday, January 20, 2019 3:00 AM
To: Sydney Torbett <torbettsydneya at gmail.com>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Opening R

Hi Sydney,
This mailing list is a text-only list so your pictures are not coming
through.
I am guessing that you are clicking on the setup (installation) program and
not on R.
That would explain why you are being led to the installation process again.

You can try to search for another desktop icon that may be R.
Or search for the program R.exe.
Another possibility is to download RStudio which is a complete environment
(IDE) for
working with R.

I hope that helps,
Eric

On Sun, Jan 20, 2019 at 10:43 AM Sydney Torbett <torbettsydneya at gmail.com>
wrote:

> Hello!  I have a Dell XPS laptop that runs windows and once I download and
> install R, keeping all defaults, when I try to open the application that?s
> on my desktop, a notification just pops up prompting a re-installation
> process.  I can?t actually get inside R and I?ve followed all of the
> directions properly to install it so why is this happening?  Here are some
> pictures to hopefully help you understand the situation a little better.
> 1. Installing R
>
> 2. Set Up Complete
>
> 3. My teacher?s post explaining that once I double-click on R, that image
> should pop up.
>
> 4. What actually happens when I double-click R on my desktop (leads me
> through the installation process again).
>
> Sent from my iPhone______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: IconsR.PNG
Type: image/png
Size: 7777 bytes
Desc: IconsR.PNG
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190120/e1708299/attachment.png>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 20 19:44:54 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 20 Jan 2019 10:44:54 -0800
Subject: [R] data transformation
In-Reply-To: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
References: <CAL2fYnO6pLOnySkxyLiQ6NLusYjmcKR-ZfbVGLFA+9jhKKaepA@mail.gmail.com>
Message-ID: <D5AD8BA8-3375-48E9-B47B-C2ADEB6468DC@dcn.davis.ca.us>

There is no "perhaps" about it. Nonsense phrases like "similar to logit, where I dont [sic] lose normality of the data" that lead into off-topic discussions of why one introduces transformations in the first place are perfect examples of why questions like this belong on a statistical theory discussion forum like StackExchange rather than here where the topic is the R language.

On January 20, 2019 6:02:15 AM PST, Adrian Johnson <oriolebaltimore at gmail.com> wrote:
>Dear group,
>My question, perhaps is more of a statistical question using R
>I have a data matrix ( 400 x 400 normally distributed) with data
>points ranging from -1 to +1..
>For certain clustering algorithms, I suspect the tight data range is
>not helping resolving the clusters.
>
>Is there a way to transform the data something similar to logit, where
>I dont lose normality of the data and yet I can better expand the data
>ranges.
>
>Thanks
>Adrian
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 20 20:05:07 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 20 Jan 2019 11:05:07 -0800
Subject: [R] Opening R
In-Reply-To: <5fe683a3b7ac4fb886cdc8c7fd0418cf@tamu.edu>
References: <51A6AA5F-41DB-4255-9418-884986B1295E@gmail.com>
 <CAGgJW768hFk+uGHr3kPHU4emsXiGfwPR7dsgpmHMXtCc5Ag4bA@mail.gmail.com>
 <5fe683a3b7ac4fb886cdc8c7fd0418cf@tamu.edu>
Message-ID: <C658DCB0-28AF-4678-89D7-AB17A3A3998B@dcn.davis.ca.us>

I don't see any attachments. I agree with Eric... depending on images in questions posed here is an unreliable strategy.

Re: pop-up messages regarding re-installation on Windows... I have never seen that occur with R, but I have seen it with other programs years ago. There are settings that Windows can apply that make newer versions of Windows behave as though they were older versions while running a specific program. As long as you are installing a current version of R downloaded from a valid CRAN mirror I don't think this compatibility feature should be triggered by R, so my recommendation would be to completely uninstall R and re-install a freshly retrieved copy. I would also warn against using any special Administrator privileges during install... if you are prompted by Windows about installing software then agree, but I would not expect you to have to take other special steps when running the setup program. 

On January 20, 2019 10:36:04 AM PST, David L Carlson <dcarlson at tamu.edu> wrote:
>Files with .png extensions generally make it through the list so, this
>attachment should survive. It shows the icons for R on Windows. The
>first is the icon for the R installation software, the second and third
>are the icons for the 64bit and 32 bit versions of R respectively.
>These icons may be in Start menu, not on the desktop.
>
>---------------------------------------
>David L. Carlson
>Department of Anthropology
>Texas A&M University
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
>Berger
>Sent: Sunday, January 20, 2019 3:00 AM
>To: Sydney Torbett <torbettsydneya at gmail.com>
>Cc: R mailing list <r-help at r-project.org>
>Subject: Re: [R] Opening R
>
>Hi Sydney,
>This mailing list is a text-only list so your pictures are not coming
>through.
>I am guessing that you are clicking on the setup (installation) program
>and
>not on R.
>That would explain why you are being led to the installation process
>again.
>
>You can try to search for another desktop icon that may be R.
>Or search for the program R.exe.
>Another possibility is to download RStudio which is a complete
>environment
>(IDE) for
>working with R.
>
>I hope that helps,
>Eric
>
>On Sun, Jan 20, 2019 at 10:43 AM Sydney Torbett
><torbettsydneya at gmail.com>
>wrote:
>
>> Hello!  I have a Dell XPS laptop that runs windows and once I
>download and
>> install R, keeping all defaults, when I try to open the application
>that?s
>> on my desktop, a notification just pops up prompting a
>re-installation
>> process.  I can?t actually get inside R and I?ve followed all of the
>> directions properly to install it so why is this happening?  Here are
>some
>> pictures to hopefully help you understand the situation a little
>better.
>> 1. Installing R
>>
>> 2. Set Up Complete
>>
>> 3. My teacher?s post explaining that once I double-click on R, that
>image
>> should pop up.
>>
>> 4. What actually happens when I double-click R on my desktop (leads
>me
>> through the installation process again).
>>
>> Sent from my iPhone______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Mon Jan 21 16:24:26 2019
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Mon, 21 Jan 2019 15:24:26 +0000 (UTC)
Subject: [R] Prediction model in Shiny App
References: <1996398435.1815464.1548084266081.ref@mail.yahoo.com>
Message-ID: <1996398435.1815464.1548084266081@mail.yahoo.com>

Hi everyone,

I'm new in trying Shiny app in R and for the following question I need your help. I have a Random Forest model built with Caret Package on iris data set and then with Shiny I need a UI which I can upload a .csv file as the test set and give it to the trained model and then see what is the prediction on the test set in UI. Here is the model:

      

  
     > library(caret)
     > library(shiny)
     > data("iris")
     >model <- train(Species~., data=iris, trControl=train_control, method="nb")



and the code for ui and server


     > ui = fluidPage( 
 
     titlePanel("Prediction with Random Forest"), 
     sidebarLayout(position = "right", 
     sidebarPanel(fileInput('datafile', 'Choose CSV file', 
     accept=c('text/csv', 'text/comma-separated-values,text/plain'))), 
     mainPanel(textOutput("Pred"))), 
     textOutput(outputId = 'Pred') 

     )


     >  server = function (input,output) { 

     mydata <- reactive({ 

     inFile <- input$datafile 

      if (is.null(inFile)) 
      return(NULL) 

      tbl <- read.csv(inFile$datapath, header=input$header, sep=input$sep,  dec = input$dec) 

     return(tbl) 
      }) 
     pred=reactive({predict(model,tbl())}) 

    output$Pred <- renderPrint(pred()) 

    } 
    > 
   >     shinyApp(ui=ui,server=server)


so I want to read the .csv file, give it to the model and then show the class of the test set in UI.
Thanks for any help.

Elahe


From S@E|||@on @end|ng |rom LGCGroup@com  Mon Jan 21 16:31:24 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Mon, 21 Jan 2019 15:31:24 +0000
Subject: [R] Printing a list of simultaneous equations
In-Reply-To: <018fea12-5978-c4b5-5e77-1187161d446e@yorku.ca>
References: <BYAPR03MB4725D3F1F55F32C120B1E9BBE29C0@BYAPR03MB4725.namprd03.prod.outlook.com>
 <018fea12-5978-c4b5-5e77-1187161d446e@yorku.ca>
Message-ID: <bdd6ff87b796422da17478ce848c40bd@GBDCVPEXC08.corp.lgc-group.com>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Friendly
> Check out the `matlib` package on CRAN and devel on github:


Very nice! Thanks for the pointer.

Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From therne@u @end|ng |rom m@yo@edu  Mon Jan 21 18:51:42 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Mon, 21 Jan 2019 11:51:42 -0600
Subject: [R] adding a hex sticker to a package
Message-ID: <871ab4$avfemr@ironport10.mayo.edu>

I've created a hex sticker for survival.? How should that be added to the package 
directory??? It's temporarily in man/figures on the github page.

Terry T.

(Actually, the idea was from Ryan Lennon. I liked it, and we found someone with actual 
graphical skills to execute it. )

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jan 21 21:04:48 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 21 Jan 2019 12:04:48 -0800
Subject: [R] adding a hex sticker to a package
In-Reply-To: <871ab4$avfemr@ironport10.mayo.edu>
References: <871ab4$avfemr@ironport10.mayo.edu>
Message-ID: <CAGxFJbRShc_UJtzPcJy9q8fQ_rt1b8UxnBySxUqwc2wuGcF4BQ@mail.gmail.com>

Better posted on r-package-devel list, no?

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 21, 2019 at 9:52 AM Therneau, Terry M., Ph.D. via R-help <
r-help at r-project.org> wrote:

> I've created a hex sticker for survival.  How should that be added to the
> package
> directory?   It's temporarily in man/figures on the github page.
>
> Terry T.
>
> (Actually, the idea was from Ryan Lennon. I liked it, and we found someone
> with actual
> graphical skills to execute it. )
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jan 21 23:18:57 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 21 Jan 2019 22:18:57 +0000
Subject: [R] adding a hex sticker to a package
In-Reply-To: <5072_1548093127_x0LHq6DR008125_871ab4$avfemr@ironport10.mayo.edu>
References: <5072_1548093127_x0LHq6DR008125_871ab4$avfemr@ironport10.mayo.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836A5F9F3@FHSDB2D11-2.csu.mcmaster.ca>

Dear Terry,

I added a hex sticker to the effects package, and there will be one in the next versions of the car and Rcmdr packages. I put a pdf with the hex sticker in install/docs, and display it with the function effectsHexsticker(); see ?effectsHexsticker. I imagine that there are other ways to do this as well.

Best,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Therneau,
> Terry M., Ph.D. via R-help
> Sent: Monday, January 21, 2019 12:52 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] adding a hex sticker to a package
> 
> I've created a hex sticker for survival.? How should that be added to the
> package directory??? It's temporarily in man/figures on the github page.
> 
> Terry T.
> 
> (Actually, the idea was from Ryan Lennon. I liked it, and we found someone
> with actual graphical skills to execute it. )
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@@@pdx @end|ng |rom gm@||@com  Tue Jan 22 02:25:27 2019
From: r@@@pdx @end|ng |rom gm@||@com (Richard Sherman)
Date: Mon, 21 Jan 2019 17:25:27 -0800
Subject: [R] Choropleth using ggplot2
Message-ID: <896D6794-ACDF-44CF-9CA0-6C12AA627588@gmail.com>

Hello all,

I am trying to plot a simple choropleth, something I?ve done a while ago using rworldmap and also (if I recall correctly) ggplot2, but I am failing to draw the map at all and failing (I think) to merge my data properly with the shapefile. Thank you for help with a basic question. I?d like to know what is wrong with what I?m doing here.

I posted this to r-sig-geo but received no responses. 

My R script is 

library(ggplot2)
library(rgdal)
library(plyr)

# get shapefile for world map
download.file("https://opendata.arcgis.com/datasets/252471276c9941729543be8789e06e12_0.zip", destfile = "countries.zip?)

# get world bank maternal mortality data
download.file("http://api.worldbank.org/v2/en/indicator/SH.STA.MMRT?downloadformat=csv", destfile = "mmr.zip?)

# get csv file with concordance between ISO-2-alpha and ISO-3-alpha country codes
download.file("https://raw.githubusercontent.com/rsspdx/mmr/master/iso_2_iso_3.csv", destfile = "iso_2_iso_3.csv?)

# unzip the zipped files
mmr.files <- unzip("mmr.zip")
unzip("countries.zip?)

# read in maternal mortality data and fix it up
mmr.data <- read.csv(mmr.files[2], skip = 3, stringsAsFactors = FALSE)
mmr.data.name <- mmr.data$Country.Name
mmr.data.code <- mmr.data$Country.Code
mmr.data.mmr <- mmr.data$X2015
mmr.data.df <- as.data.frame(cbind(mmr.data.name, mmr.data.code, mmr.data.mmr))
names(mmr.data.df) <- c("Country.Name", "Country.Code", "mmr?)

# read in the shapefile
world.map <- readOGR(dsn=".", layer = "UIA_World_Countries_Boundaries")

# --------- possibly I should be doing this ------------
#
# world.map at data$id <- rownames(world.map at data)
# world.map.df <- fortify(world.map)
#
# -------------------------------------------------------

#------or perhaps I need to merge the data into a slot of the shapefile
#------but I can?t recall (or never knew?) how to do that

# get ISO2 country codes
iso_2_iso_3 <- read.csv("iso_2_iso_3.csv?)

# ISO2 in this file is called ISO in the shapefile, create ISO variable
# then merge into mmr.data
iso_2_iso_3$ISO <- iso_2_iso_3$ISO2
mmr.data.df <- merge(iso_2_iso_3, mmr.data.df, by.x="ISO3", by.y="Country.Code?)

# merge maternal mortality data into shapefile
mmr <- merge(world.map, mmr.data.df, by = "ISO")
mmr <- fortify(mmr)
str(mmr)

# ---------create a map, not working
map <- ggplot(data = mmr, aes(x = long, y = lat, group = group))

# ---------look at the map, obviously not working
map + geom_polygon(fill = mmr$mmr)


From myr|@m@croze07 @end|ng |rom gm@||@com  Tue Jan 22 02:28:07 2019
From: myr|@m@croze07 @end|ng |rom gm@||@com (Myriam Croze)
Date: Tue, 22 Jan 2019 10:28:07 +0900
Subject: [R] Mismatch distribution
Message-ID: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>

Hello!

I need your help. I am trying to calculate the pairwise differences between
sequences from several fasta files.
I would like for each of my DNA alignments (fasta files), calculate the
pairwise differences and then:
- 1. Combine all the data of each file to have one file and one histogram
(mismatch distribution)
- 2. calculate the mean for each difference for all the file and again make
a mismatch distribution plot

Here the script that I wrote:

library("pegas")
> library("seqinr")
> library("ggplot2")
>
>

> Files <- list.files(pattern="fas")
> nb_files <- length(Files)
>
>
> for (i in 1:nb_files) {
>         Dist <-  as.numeric(dist.gene(read.dna(Files[i], "fasta"), method
> = "pairwise",
>                            pairwise.deletion = FALSE, variance = FALSE))
>
>         Data <- merge(Data, Dist, by=c("x"), all=T)
>     }
>


> hist(Data, prob=TRUE)
> lines(density(Data), col="blue", lwd=2)
>

However, the script does not work and I do not know what to change to make
it working.
Thanks in advance for your help.

Myriam

-- 
Myriam Croze, PhD
Post-doctorante
Division of EcoScience,
Ewha Womans University
Seoul, South Korea

Email: myriam.croze07 at gmail.com

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 22 03:08:50 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 21 Jan 2019 18:08:50 -0800
Subject: [R] Mismatch distribution
In-Reply-To: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>
References: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>
Message-ID: <CAGxFJbQ=C73cCOWcUvd1C2wduJG54w0d1djEgRy9qTJBrAe-9Q@mail.gmail.com>

"Do not work" does not work (in providing sufficient info). See the Posting
guide  linked below for how to post an intelligible question.

HOWEVER, I suspect you would do better posting on te Bioconductor list
where they are much more likely to know what "fasta" files look like and
might even have software already developed to do what you want. You could
well be trying to reinvent wheels.

Cheers,
Bert


On Mon, Jan 21, 2019 at 5:35 PM Myriam Croze <myriam.croze07 at gmail.com>
wrote:

> Hello!
>
> I need your help. I am trying to calculate the pairwise differences between
> sequences from several fasta files.
> I would like for each of my DNA alignments (fasta files), calculate the
> pairwise differences and then:
> - 1. Combine all the data of each file to have one file and one histogram
> (mismatch distribution)
> - 2. calculate the mean for each difference for all the file and again make
> a mismatch distribution plot
>
> Here the script that I wrote:
>
> library("pegas")
> > library("seqinr")
> > library("ggplot2")
> >
> >
>
> > Files <- list.files(pattern="fas")
> > nb_files <- length(Files)
> >
> >
> > for (i in 1:nb_files) {
> >         Dist <-  as.numeric(dist.gene(read.dna(Files[i], "fasta"), method
> > = "pairwise",
> >                            pairwise.deletion = FALSE, variance = FALSE))
> >
> >         Data <- merge(Data, Dist, by=c("x"), all=T)
> >     }
> >
>
>
> > hist(Data, prob=TRUE)
> > lines(density(Data), col="blue", lwd=2)
> >
>
> However, the script does not work and I do not know what to change to make
> it working.
> Thanks in advance for your help.
>
> Myriam
>
> --
> Myriam Croze, PhD
> Post-doctorante
> Division of EcoScience,
> Ewha Womans University
> Seoul, South Korea
>
> Email: myriam.croze07 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Jan 22 03:52:09 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 22 Jan 2019 02:52:09 +0000
Subject: [R] Mismatch distribution
In-Reply-To: <CAGxFJbQ=C73cCOWcUvd1C2wduJG54w0d1djEgRy9qTJBrAe-9Q@mail.gmail.com>
References: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>
 <CAGxFJbQ=C73cCOWcUvd1C2wduJG54w0d1djEgRy9qTJBrAe-9Q@mail.gmail.com>
Message-ID: <09404E50-0776-47F0-9CE7-FE3E78414C38@utoronto.ca>

Myriam -

This is the right list in principle, all the packages you use are CRAN packages, not Bioconductor.

However I am at a loss as to how you wrote your code: both pegas and seqinr have "read.<something>()" functions, but neither has read.dna(); similarly both pegas and seqinr have "dist.<something>()" functions, but neither has dist.gene(). Did you just extrapolate those function names and parameters from other function calls?

In any case: please start from a minimal, reproducible example that comes close to what you are trying to achieve, then post again. Here are the three URLs we usually recommend to get things started. Use a small number of small example files, don't nest your expressions until you are sure they produce what you think they do, and take it step by step.

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
http://adv-r.had.co.nz/Reproducibility.html
https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

Cheers,
B

-



> On 2019-01-21, at 21:08, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> "Do not work" does not work (in providing sufficient info). See the Posting
> guide  linked below for how to post an intelligible question.
> 
> HOWEVER, I suspect you would do better posting on te Bioconductor list
> where they are much more likely to know what "fasta" files look like and
> might even have software already developed to do what you want. You could
> well be trying to reinvent wheels.
> 
> Cheers,
> Bert
> 
> 
> On Mon, Jan 21, 2019 at 5:35 PM Myriam Croze <myriam.croze07 at gmail.com>
> wrote:
> 
>> Hello!
>> 
>> I need your help. I am trying to calculate the pairwise differences between
>> sequences from several fasta files.
>> I would like for each of my DNA alignments (fasta files), calculate the
>> pairwise differences and then:
>> - 1. Combine all the data of each file to have one file and one histogram
>> (mismatch distribution)
>> - 2. calculate the mean for each difference for all the file and again make
>> a mismatch distribution plot
>> 
>> Here the script that I wrote:
>> 
>> library("pegas")
>>> library("seqinr")
>>> library("ggplot2")
>>> 
>>> 
>> 
>>> Files <- list.files(pattern="fas")
>>> nb_files <- length(Files)
>>> 
>>> 
>>> for (i in 1:nb_files) {
>>>        Dist <-  as.numeric(dist.gene(read.dna(Files[i], "fasta"), method
>>> = "pairwise",
>>>                           pairwise.deletion = FALSE, variance = FALSE))
>>> 
>>>        Data <- merge(Data, Dist, by=c("x"), all=T)
>>>    }
>>> 
>> 
>> 
>>> hist(Data, prob=TRUE)
>>> lines(density(Data), col="blue", lwd=2)
>>> 
>> 
>> However, the script does not work and I do not know what to change to make
>> it working.
>> Thanks in advance for your help.
>> 
>> Myriam
>> 
>> --
>> Myriam Croze, PhD
>> Post-doctorante
>> Division of EcoScience,
>> Ewha Womans University
>> Seoul, South Korea
>> 
>> Email: myriam.croze07 at gmail.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From myr|@m@croze07 @end|ng |rom gm@||@com  Tue Jan 22 04:27:38 2019
From: myr|@m@croze07 @end|ng |rom gm@||@com (Myriam Croze)
Date: Tue, 22 Jan 2019 12:27:38 +0900
Subject: [R] Mismatch distribution
In-Reply-To: <09404E50-0776-47F0-9CE7-FE3E78414C38@utoronto.ca>
References: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>
 <CAGxFJbQ=C73cCOWcUvd1C2wduJG54w0d1djEgRy9qTJBrAe-9Q@mail.gmail.com>
 <09404E50-0776-47F0-9CE7-FE3E78414C38@utoronto.ca>
Message-ID: <CAMKaf37iVg_swK5J0j2Pheuqhwj2fCYMwb9q7s6uLY7LVzYCXg@mail.gmail.com>

Thanks for your answer.

First, concerning the function read.dna and dist.gene, they come from the
package ape which is downloaded with pegas.

Here the code that I did for one sequence and which works:

##Code
Seqs1 <- "file1.fas"
Seqs2 <- read.dna(Seqs1, "fasta")

Dist <- dist.gene(Seqs2, method = "pairwise", pairwise.deletion = FALSE,
variance = FALSE)
Dist2 <- as.numeric(Dist)

hist(Dist2, prob=TRUE)
##

And then the code for several files:

#######
Files <- list.files(pattern="fas")
nb_files <- length(Files)
Data1 <- as.numeric()

for (i in 1:nb_files) {
  Seqs <- read.dna(Files[i], "fasta")

  Dist <- dist.gene(Seqs, method = "pairwise", pairwise.deletion = FALSE,
variance = FALSE)
  Dist <-  as.numeric(Dist)

  Data1 <- merge(Data1, Dist)
    }

hist(Data1, prob=TRUE)
########

In the last code, the file Data1 (where I want all the data from the 3
files) is empty at the end. I guess something is missing in this last step
or maybe should I use another function.

Cheers,
Myriam

Le mar. 22 janv. 2019 ? 11:52, Boris Steipe <boris.steipe at utoronto.ca> a
?crit :

> Myriam -
>
> This is the right list in principle, all the packages you use are CRAN
> packages, not Bioconductor.
>
> However I am at a loss as to how you wrote your code: both pegas and
> seqinr have "read.<something>()" functions, but neither has read.dna();
> similarly both pegas and seqinr have "dist.<something>()" functions, but
> neither has dist.gene(). Did you just extrapolate those function names and
> parameters from other function calls?
>
> In any case: please start from a minimal, reproducible example that comes
> close to what you are trying to achieve, then post again. Here are the
> three URLs we usually recommend to get things started. Use a small number
> of small example files, don't nest your expressions until you are sure they
> produce what you think they do, and take it step by step.
>
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> http://adv-r.had.co.nz/Reproducibility.html
> https://cran.r-project.org/web/packages/reprex/index.html (read the
> vignette)
>
> Cheers,
> B
>
> -
>
>
>
> > On 2019-01-21, at 21:08, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > "Do not work" does not work (in providing sufficient info). See the
> Posting
> > guide  linked below for how to post an intelligible question.
> >
> > HOWEVER, I suspect you would do better posting on te Bioconductor list
> > where they are much more likely to know what "fasta" files look like and
> > might even have software already developed to do what you want. You could
> > well be trying to reinvent wheels.
> >
> > Cheers,
> > Bert
> >
> >
> > On Mon, Jan 21, 2019 at 5:35 PM Myriam Croze <myriam.croze07 at gmail.com>
> > wrote:
> >
> >> Hello!
> >>
> >> I need your help. I am trying to calculate the pairwise differences
> between
> >> sequences from several fasta files.
> >> I would like for each of my DNA alignments (fasta files), calculate the
> >> pairwise differences and then:
> >> - 1. Combine all the data of each file to have one file and one
> histogram
> >> (mismatch distribution)
> >> - 2. calculate the mean for each difference for all the file and again
> make
> >> a mismatch distribution plot
> >>
> >> Here the script that I wrote:
> >>
> >> library("pegas")
> >>> library("seqinr")
> >>> library("ggplot2")
> >>>
> >>>
> >>
> >>> Files <- list.files(pattern="fas")
> >>> nb_files <- length(Files)
> >>>
> >>>
> >>> for (i in 1:nb_files) {
> >>>        Dist <-  as.numeric(dist.gene(read.dna(Files[i], "fasta"),
> method
> >>> = "pairwise",
> >>>                           pairwise.deletion = FALSE, variance = FALSE))
> >>>
> >>>        Data <- merge(Data, Dist, by=c("x"), all=T)
> >>>    }
> >>>
> >>
> >>
> >>> hist(Data, prob=TRUE)
> >>> lines(density(Data), col="blue", lwd=2)
> >>>
> >>
> >> However, the script does not work and I do not know what to change to
> make
> >> it working.
> >> Thanks in advance for your help.
> >>
> >> Myriam
> >>
> >> --
> >> Myriam Croze, PhD
> >> Post-doctorante
> >> Division of EcoScience,
> >> Ewha Womans University
> >> Seoul, South Korea
> >>
> >> Email: myriam.croze07 at gmail.com
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Myriam Croze, PhD
Post-doctorante
Division of EcoScience,
Ewha Womans University
Seoul, South Korea

Email: myriam.croze07 at gmail.com

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Jan 22 05:32:11 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 22 Jan 2019 04:32:11 +0000
Subject: [R] Mismatch distribution
In-Reply-To: <CAMKaf37iVg_swK5J0j2Pheuqhwj2fCYMwb9q7s6uLY7LVzYCXg@mail.gmail.com>
References: <CAMKaf36AUqH-_xYX=siLaRQAF-f1Reg5ny0r0QBEhuKsdUcMOg@mail.gmail.com>
 <CAGxFJbQ=C73cCOWcUvd1C2wduJG54w0d1djEgRy9qTJBrAe-9Q@mail.gmail.com>
 <09404E50-0776-47F0-9CE7-FE3E78414C38@utoronto.ca>
 <CAMKaf37iVg_swK5J0j2Pheuqhwj2fCYMwb9q7s6uLY7LVzYCXg@mail.gmail.com>
Message-ID: <33FFD367-EA4D-4E4E-9DEE-A9C567AF2DA9@utoronto.ca>

Your "file1.fas" contains one sequence?
I can't see how that would work to produce a distance matrix. 

Please show the output of:
str(Seqs2)

------

You need to understand what a distance matrix is, and what merge() does. Consider:

x <- data.frame(l1 = c("a", "a", "g"),
                l2 = c("g", "g", "t"),
                l3 = c("t", "c", "t"),
                stringsAsFactors = FALSE)
rownames(x) <- c("s1", "s2", "s3")
(myDist <- ape::dist.gene(x))

   s1 s2
s2  1   
s3  2  3

- this means s1/s2 have 1 difference,  agt vs agc;
             s1/s3 have 2 differences, agt vs gtt;
             s2/s3 have 3 differences, agc vs gtt;

The values are the lower triangle of a square matrix, perhaps easier to understand if we write the full matrix:

   s1 s2 s3
s1  0
s2  1  0    
s3  2  3  0

The values in the diagonal are always zero (d(a, a) == 0); and the values in the upper triangle are the same as in the lower triangle (d(a, b) == d(b, a)) So we don't store them separately. TLDR: a distance object stores the pairwise distances of n objects as n*(n-1)/2 numbers. 

merge() would try to coerce the distance matrices to data frames, then combine them based on shared row- or column names. That won't make sense. This won't be meaningful if there are shared names, and it won't work if there are no shared names. 

But you don't need merged objects since you are merely producing histograms of the individual distances. Dump the numbers into a vector, then c() the vectors. If I understand correctly what your input data actually is, and what you are trying to do, I would write it as:

fileNames <- list.files(pattern = "\\.fas$")

dVec <- numeric()
for (myFile in fileNames) {
  dMat <- ape::dist.gene(ape::read.dna(myFile, format = "fasta"))
  dVec <-  c(dVec, as.vector(dMat))
}

hist(dVec, prob=TRUE)


--
B.





> On 2019-01-21, at 22:27, Myriam Croze <myriam.croze07 at gmail.com> wrote:
> 
> Thanks for your answer.
> 
> First, concerning the function read.dna and dist.gene, they come from the package ape which is downloaded with pegas.
> 
> Here the code that I did for one sequence and which works:
> 
> ##Code
> Seqs1 <- "file1.fas"
> Seqs2 <- read.dna(Seqs1, "fasta")
> 
> Dist <- dist.gene(Seqs2, method = "pairwise", pairwise.deletion = FALSE, variance = FALSE)
> Dist2 <- as.numeric(Dist)
> 
> hist(Dist2, prob=TRUE)
> ##
> 
> And then the code for several files:
> 
> #######
> Files <- list.files(pattern="fas")
> nb_files <- length(Files)
> Data1 <- as.numeric()
> 
> for (i in 1:nb_files) {
>   Seqs <- read.dna(Files[i], "fasta")  
>   
>   Dist <- dist.gene(Seqs, method = "pairwise", pairwise.deletion = FALSE, variance = FALSE)
>   Dist <-  as.numeric(Dist)
>  
>   Data1 <- merge(Data1, Dist)
>     }
> 
> hist(Data1, prob=TRUE)
> ########
> 
> In the last code, the file Data1 (where I want all the data from the 3 files) is empty at the end. I guess something is missing in this last step or maybe should I use another function.
> 
> Cheers,
> Myriam
> 
> Le mar. 22 janv. 2019 ? 11:52, Boris Steipe <boris.steipe at utoronto.ca> a ?crit :
> Myriam -
> 
> This is the right list in principle, all the packages you use are CRAN packages, not Bioconductor.
> 
> However I am at a loss as to how you wrote your code: both pegas and seqinr have "read.<something>()" functions, but neither has read.dna(); similarly both pegas and seqinr have "dist.<something>()" functions, but neither has dist.gene(). Did you just extrapolate those function names and parameters from other function calls?
> 
> In any case: please start from a minimal, reproducible example that comes close to what you are trying to achieve, then post again. Here are the three URLs we usually recommend to get things started. Use a small number of small example files, don't nest your expressions until you are sure they produce what you think they do, and take it step by step.
> 
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> http://adv-r.had.co.nz/Reproducibility.html
> https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
> 
> Cheers,
> B
> 
> -
> 
> 
> 
> > On 2019-01-21, at 21:08, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > 
> > "Do not work" does not work (in providing sufficient info). See the Posting
> > guide  linked below for how to post an intelligible question.
> > 
> > HOWEVER, I suspect you would do better posting on te Bioconductor list
> > where they are much more likely to know what "fasta" files look like and
> > might even have software already developed to do what you want. You could
> > well be trying to reinvent wheels.
> > 
> > Cheers,
> > Bert
> > 
> > 
> > On Mon, Jan 21, 2019 at 5:35 PM Myriam Croze <myriam.croze07 at gmail.com>
> > wrote:
> > 
> >> Hello!
> >> 
> >> I need your help. I am trying to calculate the pairwise differences between
> >> sequences from several fasta files.
> >> I would like for each of my DNA alignments (fasta files), calculate the
> >> pairwise differences and then:
> >> - 1. Combine all the data of each file to have one file and one histogram
> >> (mismatch distribution)
> >> - 2. calculate the mean for each difference for all the file and again make
> >> a mismatch distribution plot
> >> 
> >> Here the script that I wrote:
> >> 
> >> library("pegas")
> >>> library("seqinr")
> >>> library("ggplot2")
> >>> 
> >>> 
> >> 
> >>> Files <- list.files(pattern="fas")
> >>> nb_files <- length(Files)
> >>> 
> >>> 
> >>> for (i in 1:nb_files) {
> >>>        Dist <-  as.numeric(dist.gene(read.dna(Files[i], "fasta"), method
> >>> = "pairwise",
> >>>                           pairwise.deletion = FALSE, variance = FALSE))
> >>> 
> >>>        Data <- merge(Data, Dist, by=c("x"), all=T)
> >>>    }
> >>> 
> >> 
> >> 
> >>> hist(Data, prob=TRUE)
> >>> lines(density(Data), col="blue", lwd=2)
> >>> 
> >> 
> >> However, the script does not work and I do not know what to change to make
> >> it working.
> >> Thanks in advance for your help.
> >> 
> >> Myriam
> >> 
> >> --
> >> Myriam Croze, PhD
> >> Post-doctorante
> >> Division of EcoScience,
> >> Ewha Womans University
> >> Seoul, South Korea
> >> 
> >> Email: myriam.croze07 at gmail.com
> >> 
> >>        [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >> 
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Myriam Croze, PhD
> Post-doctorante
> Division of EcoScience,
> Ewha Womans University
> Seoul, South Korea
> 
> Email: myriam.croze07 at gmail.com


From @eb@@t|@n@h@we||@ @end|ng |rom gm@||@com  Tue Jan 22 03:56:17 2019
From: @eb@@t|@n@h@we||@ @end|ng |rom gm@||@com (Sebastian Heyneman)
Date: Mon, 21 Jan 2019 18:56:17 -0800
Subject: [R] R: plot partial effects
Message-ID: <CAD7vWdXA4ib-JdntRaMuvBk-wW=Br9tM80wLG+vY+QG5cm5+7A@mail.gmail.com>

Dear All:


I tried to replicate a case study described by Prof. Harrell in Chapter 7 of

his Regression Modeling Strategies book, but failed on using plot to

reproduce partial effects diagram in figure 7.9,  Following is the code:


rm(list=ls())

library(Hmisc)


getHdata(counties)

counties$older <- counties$age6574 + counties$age75

label(counties$older) <- '% age >= 65, 1990'

counties$pdensity <- log10(counties$pop.density+1)

label(counties$pdensity) <- 'log 10 of 1992 pop per 1990 miles^2'


dd <- datadist(counties)

options(datadist='dd')


f <- ols(democrat ~ rcs(pdensity,4) + rcs(pop.change,3) + rcs(older,3) +

crime + rcs(college,5)

         + rcs(income,4) + rcs(college,5) %ia% rcs(income,4) + rcs(farm,3) +

rcs(white,5) +

         rcs(turnout,3), data=counties)

f

plot(f, ylim = c(20,70))


and the error message reads as:


Error in match.arg(type) :
  'arg' should be one of ?ordinary?, ?score?, ?dfbeta?, ?dfbetas?,
?dffit?, ?dffits?, ?hat?, ?hscore?



Does anyone have a clue?


Regards,

Sebastian

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Jan 22 14:20:35 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 22 Jan 2019 13:20:35 +0000
Subject: [R] large number of scrollable histograms....
Message-ID: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am a day trader based in INDIA. I use R for my research.

I have about 200 vectors whose histograms I need to inspect. I have to compare them simultaneously.

I know methods whereby you can plot multiple histograms on one screen. However, you can clearly view only 4 to 5  histograms in one screen.

Is there a way to construct a long list of all the 100 histograms that can be scrollable (like you scroll up or down the R console) both downwards and upwards? Any package to that effect?

I would be highly grateful, also, if you can offer any suggestions or "out of the box" ideas to simultaneously compare all the 100 histograms.

very many thanks for your help and support..
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jan 22 14:49:02 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 22 Jan 2019 13:49:02 +0000
Subject: [R] large number of scrollable histograms....
In-Reply-To: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>

Hi

what about to create all histograms in pdf device?

see
?pdf

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
> Sent: Tuesday, January 22, 2019 2:21 PM
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] large number of scrollable histograms....
>
> dear members,
>                             I am a day trader based in INDIA. I use R for my research.
>
> I have about 200 vectors whose histograms I need to inspect. I have to
> compare them simultaneously.
>
> I know methods whereby you can plot multiple histograms on one screen.
> However, you can clearly view only 4 to 5  histograms in one screen.
>
> Is there a way to construct a long list of all the 100 histograms that can be
> scrollable (like you scroll up or down the R console) both downwards and
> upwards? Any package to that effect?
>
> I would be highly grateful, also, if you can offer any suggestions or "out of the
> box" ideas to simultaneously compare all the 100 histograms.
>
> very many thanks for your help and support..
> yours sincerely,
> AKSHAY M KULKARNI
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From er|cjberger @end|ng |rom gm@||@com  Tue Jan 22 14:59:05 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 22 Jan 2019 15:59:05 +0200
Subject: [R] large number of scrollable histograms....
In-Reply-To: <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW75ytAaDhn4hTvtJNwBe2nCRJ7nuCzYCmoeNeG-ss2ptFg@mail.gmail.com>

Another alternative is to use ggplot2 to create the various plots, then put
them into
a list and use cowplot::plot_grid to plot the grid of plots with a
specified number of
rows and columns. Here's some pseudo code to give you the general idea

Step 1: generate the plots and put them into a list
for ( i in 1:(nrow*ncol) )
   pL[[ i ]] <- ggplot( ... )

Step 2: display the plots in a grid
print( cowplot::plot_grid( plotlist=pL, nrow=nrow, ncol=ncol ) )

On Tue, Jan 22, 2019 at 3:49 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> what about to create all histograms in pdf device?
>
> see
> ?pdf
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
> > Sent: Tuesday, January 22, 2019 2:21 PM
> > To: R help Mailing list <r-help at r-project.org>
> > Subject: [R] large number of scrollable histograms....
> >
> > dear members,
> >                             I am a day trader based in INDIA. I use R
> for my research.
> >
> > I have about 200 vectors whose histograms I need to inspect. I have to
> > compare them simultaneously.
> >
> > I know methods whereby you can plot multiple histograms on one screen.
> > However, you can clearly view only 4 to 5  histograms in one screen.
> >
> > Is there a way to construct a long list of all the 100 histograms that
> can be
> > scrollable (like you scroll up or down the R console) both downwards and
> > upwards? Any package to that effect?
> >
> > I would be highly grateful, also, if you can offer any suggestions or
> "out of the
> > box" ideas to simultaneously compare all the 100 histograms.
> >
> > very many thanks for your help and support..
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Tue Jan 22 15:09:07 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Tue, 22 Jan 2019 15:09:07 +0100
Subject: [R] large number of scrollable histograms....
In-Reply-To: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 (akshay kulkarni's message of "Tue, 22 Jan 2019 13:20:35 +0000")
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <87bm48okcc.fsf@enricoschumann.net>

>>>>> "akshay" == akshay kulkarni <akshay_e4 at hotmail.com> writes:

    akshay> dear members,

    akshay> I am a day trader based in INDIA. I use R for my research.

    akshay> I have about 200 vectors whose histograms I need to
    akshay> inspect. I have to compare them simultaneously.

    akshay> I know methods whereby you can plot multiple histograms on
    akshay> one screen. However, you can clearly view only 4 to 5
    akshay> histograms in one screen.

    akshay> Is there a way to construct a long list of all the 100
    akshay> histograms that can be scrollable (like you scroll up or
    akshay> down the R console) both downwards and upwards? Any package
    akshay> to that effect?

    akshay> I would be highly grateful, also, if you can offer any
    akshay> suggestions or "out of the box" ideas to simultaneously
    akshay> compare all the 100 histograms.

    akshay> very many thanks for your help and support..
    akshay> yours sincerely,
    akshay> AKSHAY M KULKARNI

Just two thoughts:

1) You could plot all histograms into one pdf and
   scroll the PDF.

2) Do you need histograms? Boxplots for instance need
   less space (and if you sort the input data by
   median, say, they often help much better to see
   differences between samples); or use similar plots such
   as quartile plots
   (e.g. https://cran.r-project.org/web/packages/NMOF/vignettes/qTableEx.pdf ).

kind regards
     Enrico


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 22 17:10:14 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 22 Jan 2019 08:10:14 -0800
Subject: [R] large number of scrollable histograms....
In-Reply-To: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CD9907F9-7E0E-494E-8727-1CE34B4D8F58@dcn.davis.ca.us>

You can use knitr (child documents) with rmarkdown to generate an html file containing many htmlwidgets. There are many htmlwidgets you can choose from, see [1]. You can also use htmlwidgets with shiny if you prefer, though I don't know if you can get the many plots simultaneously with shiny.

Some htmlwidgets even support linkage between the plots, so if you scroll or zoom through the x-axis on one, the others can adjust similarly.

[1] http://gallery.htmlwidgets.org

On January 22, 2019 5:20:35 AM PST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>             I am a day trader based in INDIA. I use R for my research.
>
>I have about 200 vectors whose histograms I need to inspect. I have to
>compare them simultaneously.
>
>I know methods whereby you can plot multiple histograms on one screen.
>However, you can clearly view only 4 to 5  histograms in one screen.
>
>Is there a way to construct a long list of all the 100 histograms that
>can be scrollable (like you scroll up or down the R console) both
>downwards and upwards? Any package to that effect?
>
>I would be highly grateful, also, if you can offer any suggestions or
>"out of the box" ideas to simultaneously compare all the 100
>histograms.
>
>very many thanks for your help and support..
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Jan 23 07:37:45 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 23 Jan 2019 12:07:45 +0530
Subject: [R] Unable to compute Confidence Intervals from output from MARSS
 package
Message-ID: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>

Dear All,

I am trying to use this package --->
https://cran.r-project.org/web/packages/MARSS/index.html
I am reading this book which shows some examples based on the above package
---> https://nwfsc-timeseries.github.io/atsa-labs/

In a few words, the incantation MARSS(...) estimates the parameters and
MARSSparamCIs should return the confidence intervals. My problem is that
MARSSparamCIs returns this  error :-

> MARSSparamCIs(fit)
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero
>

### This page and the next page, explains the jargon used :
https://nwfsc-timeseries.github.io/atsa-labs/sec-dlm-example-of-a-univariate-dlm.html

### Here is a MWE to recreate the error :-

# This is a Time Varying Parameters regression
# Here a is fixed and b is doing a RW.

x1 <- rnorm(1000)
b <- cumsum(rnorm(1000, sd = sqrt(.6)))
y <- 1 + b*x1 + rnorm(1000)

Z = array(NA,c(1,2,1000))
Z[1,1,]  = rep(1,1000)
Z[1,2,] = x1

mod2.list = list ( B = matrix(c(1,0,0,1),nrow = 2 , byrow = T), U  =
matrix(0,2,1),
    Q = matrix(list(0,0,0,"s2b"),2,2), Z= Z, A = matrix(0), R = matrix("r"))

fit = MARSS(as.vector(y), model = mod2.list,inits =
list(x0=matrix(0,nrow=2,ncol=1)))

MARSSparamsCIs(fit)

# The above will give this error :
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From kt1572757 @end|ng |rom gm@||@com  Wed Jan 23 03:54:14 2019
From: kt1572757 @end|ng |rom gm@||@com (Kelly Thompson)
Date: Tue, 22 Jan 2019 18:54:14 -0800
Subject: [R] calculating quintile values of numeric data?
Message-ID: <CAHfBD2fEiLV3z6opKODBBBw_V5pvNZXoUCW+S9UTFcthU-HX5g@mail.gmail.com>

I?d like to take numeric data, and calculate numeric ?quintiles? with
integer values in from 1 ? 5 , with values in the lowest 20% of values
having a value of 1, the >20 - <= 40% of values having a value of 2,
the >40% - <=60% of values having a value of 3, etc.

How can I use quantcut, or another function, to do this?


Thanks!


Ex.

x <- c(1:10)

I want:
myquintilefunction (x, q=5, na.rm=T) to return a vector with values:
1,1,2,2,3,3,4,4,5,5

Thanks!


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 23 07:59:46 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 22 Jan 2019 22:59:46 -0800
Subject: [R] calculating quintile values of numeric data?
In-Reply-To: <CAHfBD2fEiLV3z6opKODBBBw_V5pvNZXoUCW+S9UTFcthU-HX5g@mail.gmail.com>
References: <CAHfBD2fEiLV3z6opKODBBBw_V5pvNZXoUCW+S9UTFcthU-HX5g@mail.gmail.com>
Message-ID: <A4D0ED05-6CF7-4260-B6FA-6F4D2CEB194A@dcn.davis.ca.us>

?range
?findInterval

On January 22, 2019 6:54:14 PM PST, Kelly Thompson <kt1572757 at gmail.com> wrote:
>I?d like to take numeric data, and calculate numeric ?quintiles? with
>integer values in from 1 ? 5 , with values in the lowest 20% of values
>having a value of 1, the >20 - <= 40% of values having a value of 2,
>the >40% - <=60% of values having a value of 3, etc.
>
>How can I use quantcut, or another function, to do this?
>
>
>Thanks!
>
>
>Ex.
>
>x <- c(1:10)
>
>I want:
>myquintilefunction (x, q=5, na.rm=T) to return a vector with values:
>1,1,2,2,3,3,4,4,5,5
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Wed Jan 23 08:01:14 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Wed, 23 Jan 2019 07:01:14 +0000
Subject: [R] large number of scrollable histograms....
In-Reply-To: <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
Message-ID: <SL2P216MB00916767AEEB5D97DC0577DEC8990@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear pikal,
                    Thanks for the suggestion....
I have checked ?pdf.  The syntax is:


> pdf("sample.pdf", 7, 5)
> hist(vector1)
> dev.off()

So, I surmise that instead of one hist function in the second line, if I include multiple histograms through a loop, it would write ALL histograms to sample.pdf (something like this):


> pdf("sample.pdf", 7, 5)
> histlist
> dev.off()

> histlist <- function(){ for( i in 1:length(L)){histlist[[i]] <- hist(L[[i]]}; return(histlist)}


Am I right? Would this pdf document(sample.pdf)  be scrollable?



very many thanks for your time....
yours sincerely,
AKSHAY M KULKARNI

________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: Tuesday, January 22, 2019 7:19 PM
To: akshay kulkarni; R help Mailing list
Subject: RE: large number of scrollable histograms....

Hi

what about to create all histograms in pdf device?

see
?pdf

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
> Sent: Tuesday, January 22, 2019 2:21 PM
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] large number of scrollable histograms....
>
> dear members,
>                             I am a day trader based in INDIA. I use R for my research.
>
> I have about 200 vectors whose histograms I need to inspect. I have to
> compare them simultaneously.
>
> I know methods whereby you can plot multiple histograms on one screen.
> However, you can clearly view only 4 to 5  histograms in one screen.
>
> Is there a way to construct a long list of all the 100 histograms that can be
> scrollable (like you scroll up or down the R console) both downwards and
> upwards? Any package to that effect?
>
> I would be highly grateful, also, if you can offer any suggestions or "out of the
> box" ideas to simultaneously compare all the 100 histograms.
>
> very many thanks for your help and support..
> yours sincerely,
> AKSHAY M KULKARNI
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From @kouret@ @end|ng |rom gm@||@com  Wed Jan 23 09:35:43 2019
From: @kouret@ @end|ng |rom gm@||@com (Alexandros Kouretsis)
Date: Wed, 23 Jan 2019 10:35:43 +0200
Subject: [R] calculating quintile values of numeric data? Alexandros
 Kouretsis
Message-ID: <CAA1Oq-3WbooTHv4YDd-9xGi5+-gOrDUVPeeMR+WkB6NHjt+MdQ@mail.gmail.com>

cut can do the job

q_prob <- seq(0, 1, 0.2)
cut(x, breaks = quantile(x, probs = q_prob), include.lowest = T , labels =
1:5)

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jan 23 09:46:41 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 23 Jan 2019 08:46:41 +0000
Subject: [R] large number of scrollable histograms....
In-Reply-To: <SL2P216MB00916767AEEB5D97DC0577DEC8990@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
 <SL2P216MB00916767AEEB5D97DC0577DEC8990@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <8ab1fbedd56d457591c60d5089b13460@SRVEXCHCM1302.precheza.cz>

Hi

Yes, you should get multipage pdf, each page populated by single call to plot function.

However I am not sur if your proposal with function will work.

I usually do simply



pdf("sample.pdf", 7, 5)

for (i in 1:n) {

hist(L[[i]])

}

dev.off()

Cheers
Petr

From: akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Wednesday, January 23, 2019 8:01 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; R help Mailing list <r-help at r-project.org>
Subject: Re: large number of scrollable histograms....

dear pikal,
                    Thanks for the suggestion....
I have checked ?pdf.  The syntax is:


> pdf("sample.pdf", 7, 5)

> hist(vector1)

> dev.off()
So, I surmise that instead of one hist function in the second line, if I include multiple histograms through a loop, it would write ALL histograms to sample.pdf (something like this):


> pdf("sample.pdf", 7, 5)

> histlist

> dev.off()

> histlist <- function(){ for( i in 1:length(L)){histlist[[i]] <- hist(L[[i]]}; return(histlist)}



Am I right? Would this pdf document(sample.pdf)  be scrollable?



very many thanks for your time....
yours sincerely,
AKSHAY M KULKARNI

________________________________
From: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Sent: Tuesday, January 22, 2019 7:19 PM
To: akshay kulkarni; R help Mailing list
Subject: RE: large number of scrollable histograms....

Hi

what about to create all histograms in pdf device?

see
?pdf

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of akshay kulkarni
> Sent: Tuesday, January 22, 2019 2:21 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] large number of scrollable histograms....
>
> dear members,
>                             I am a day trader based in INDIA. I use R for my research.
>
> I have about 200 vectors whose histograms I need to inspect. I have to
> compare them simultaneously.
>
> I know methods whereby you can plot multiple histograms on one screen.
> However, you can clearly view only 4 to 5  histograms in one screen.
>
> Is there a way to construct a long list of all the 100 histograms that can be
> scrollable (like you scroll up or down the R console) both downwards and
> upwards? Any package to that effect?
>
> I would be highly grateful, also, if you can offer any suggestions or "out of the
> box" ideas to simultaneously compare all the 100 histograms.
>
> very many thanks for your help and support..
> yours sincerely,
> AKSHAY M KULKARNI
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jan 23 10:53:01 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 23 Jan 2019 12:53:01 +0300
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
Message-ID: <20190123125301.7e3e43b7@trisector>

Hi!

I needed to generalize a loss function being optimized inside another
function, so I made it a function argument with a default value. It
worked without problems, but later I noticed that the inner function,
despite being defined in the function arguments, somehow closes over a
variable belonging to the outer function, which is defined later.

Example:

outside <- function(inside = function() print(secret)) {
	secret <- 'secret'
	inside()
}
outside()

I'm used to languages that have both lambdas and variable declaration
(like perl5 -Mstrict or C++11), so I was a bit surprised.

Does this work because R looks up the variable by name late enough at
runtime for the `secret` variable to exist in the parent environment of
the `inside` function? Can I rely on it? Is this considered bad style? 
Should I rewrite it (and how)?

-- 
Best regards,
Ivan


From jttk|m @end|ng |rom goog|em@||@com  Wed Jan 23 11:27:04 2019
From: jttk|m @end|ng |rom goog|em@||@com (Jan T Kim)
Date: Wed, 23 Jan 2019 10:27:04 +0000
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <20190123125301.7e3e43b7@trisector>
References: <20190123125301.7e3e43b7@trisector>
Message-ID: <20190123102703.GF9992@paftolwp3a>

Hi Ivan & All,

R's scoping system basically goes to all environments along the call
stack when trying to resolve an unbound variable, see the language
definition [1], section 4.3.4, and perhaps also 2.1.5.

Generally, unbound variables should be used with care. It's a bit
difficult to decide whether and how the code should be rewritten,
I'd say that depends on the underlying intentions / purposes. As it
is, the code could be simplified to just

    print("secret");

but that's probably missing the point.

Best regards, Jan


[1] https://cran.r-project.org/doc/manuals/r-release/R-lang.html

On Wed, Jan 23, 2019 at 12:53:01PM +0300, Ivan Krylov wrote:
> Hi!
> 
> I needed to generalize a loss function being optimized inside another
> function, so I made it a function argument with a default value. It
> worked without problems, but later I noticed that the inner function,
> despite being defined in the function arguments, somehow closes over a
> variable belonging to the outer function, which is defined later.
> 
> Example:
> 
> outside <- function(inside = function() print(secret)) {
> 	secret <- 'secret'
> 	inside()
> }
> outside()
> 
> I'm used to languages that have both lambdas and variable declaration
> (like perl5 -Mstrict or C++11), so I was a bit surprised.
> 
> Does this work because R looks up the variable by name late enough at
> runtime for the `secret` variable to exist in the parent environment of
> the `inside` function? Can I rely on it? Is this considered bad style? 
> Should I rewrite it (and how)?
> 
> -- 
> Best regards,
> Ivan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Wed Jan 23 12:18:22 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Wed, 23 Jan 2019 11:18:22 +0000
Subject: [R] large number of scrollable histograms....
In-Reply-To: <8ab1fbedd56d457591c60d5089b13460@SRVEXCHCM1302.precheza.cz>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
 <SL2P216MB00916767AEEB5D97DC0577DEC8990@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <8ab1fbedd56d457591c60d5089b13460@SRVEXCHCM1302.precheza.cz>
Message-ID: <SL2P216MB0091AA06F4D4C897D64DC45DC8990@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear pikal,
                    Thanks a lot.....!!!!!!!!!!!!!!

very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: Wednesday, January 23, 2019 2:16 PM
To: akshay kulkarni; R help Mailing list
Subject: RE: large number of scrollable histograms....


Hi



Yes, you should get multipage pdf, each page populated by single call to plot function.



However I am not sur if your proposal with function will work.



I usually do simply



pdf("sample.pdf", 7, 5)

for (i in 1:n) {

hist(L[[i]])

}

dev.off()



Cheers

Petr



From: akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Wednesday, January 23, 2019 8:01 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; R help Mailing list <r-help at r-project.org>
Subject: Re: large number of scrollable histograms....



dear pikal,

                    Thanks for the suggestion....

I have checked ?pdf.  The syntax is:



> pdf("sample.pdf", 7, 5)

> hist(vector1)

> dev.off()

So, I surmise that instead of one hist function in the second line, if I include multiple histograms through a loop, it would write ALL histograms to sample.pdf (something like this):



> pdf("sample.pdf", 7, 5)

> histlist

> dev.off()

> histlist <- function(){ for( i in 1:length(L)){histlist[[i]] <- hist(L[[i]]}; return(histlist)}





Am I right? Would this pdf document(sample.pdf)  be scrollable?







very many thanks for your time....

yours sincerely,

AKSHAY M KULKARNI



________________________________

From: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Sent: Tuesday, January 22, 2019 7:19 PM
To: akshay kulkarni; R help Mailing list
Subject: RE: large number of scrollable histograms....



Hi

what about to create all histograms in pdf device?

see
?pdf

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of akshay kulkarni
> Sent: Tuesday, January 22, 2019 2:21 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] large number of scrollable histograms....
>
> dear members,
>                             I am a day trader based in INDIA. I use R for my research.
>
> I have about 200 vectors whose histograms I need to inspect. I have to
> compare them simultaneously.
>
> I know methods whereby you can plot multiple histograms on one screen.
> However, you can clearly view only 4 to 5  histograms in one screen.
>
> Is there a way to construct a long list of all the 100 histograms that can be
> scrollable (like you scroll up or down the R console) both downwards and
> upwards? Any package to that effect?
>
> I would be highly grateful, also, if you can offer any suggestions or "out of the
> box" ideas to simultaneously compare all the 100 histograms.
>
> very many thanks for your help and support..
> yours sincerely,
> AKSHAY M KULKARNI
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jan 23 15:49:15 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 23 Jan 2019 14:49:15 +0000
Subject: [R] large number of scrollable histograms....
In-Reply-To: <CAGgJW75ytAaDhn4hTvtJNwBe2nCRJ7nuCzYCmoeNeG-ss2ptFg@mail.gmail.com>
References: <SL2P216MB009162845BE8908415304615C8980@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <0ec652976d3246a78bd86ac148c0445b@SRVEXCHCM1302.precheza.cz>
 <CAGgJW75ytAaDhn4hTvtJNwBe2nCRJ7nuCzYCmoeNeG-ss2ptFg@mail.gmail.com>
Message-ID: <BN7PR02MB50734F57FE89BF88DA806E33EA990@BN7PR02MB5073.namprd02.prod.outlook.com>

Hi akshay Kulkarni, I just worked through this great tutorial the other day, hope this helps!

WHP

https://www.r-bloggers.com/how-to-combine-multiple-ggplot-plots-to-make-publication-ready-plots/



From: R-help <r-help-bounces at r-project.org> On Behalf Of Eric Berger
Sent: Tuesday, January 22, 2019 8:59 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] large number of scrollable histograms....

Another alternative is to use ggplot2 to create the various plots, then put
them into
a list and use cowplot::plot_grid to plot the grid of plots with a
specified number of
rows and columns. Here's some pseudo code to give you the general idea

Step 1: generate the plots and put them into a list
for ( i in 1:(nrow*ncol) )
pL[[ i ]] <- ggplot( ... )

Step 2: display the plots in a grid
print( cowplot::plot_grid( plotlist=pL, nrow=nrow, ncol=ncol ) )

On Tue, Jan 22, 2019 at 3:49 PM PIKAL Petr <mailto:petr.pikal at precheza.cz> wrote:

> Hi
>
> what about to create all histograms in pdf device?
>
> see
> ?pdf
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
> > Sent: Tuesday, January 22, 2019 2:21 PM
> > To: R help Mailing list <mailto:r-help at r-project.org>
> > Subject: [R] large number of scrollable histograms....
> >
> > dear members,
> > I am a day trader based in INDIA. I use R
> for my research.
> >
> > I have about 200 vectors whose histograms I need to inspect. I have to
> > compare them simultaneously.
> >
> > I know methods whereby you can plot multiple histograms on one screen.
> > However, you can clearly view only 4 to 5 histograms in one screen.
> >
> > Is there a way to construct a long list of all the 100 histograms that
> can be
> > scrollable (like you scroll up or down the R console) both downwards and
> > upwards? Any package to that effect?
> >
> > I would be highly grateful, also, if you can offer any suggestions or
> "out of the
> > box" ideas to simultaneously compare all the 100 histograms.
> >
> > very many thanks for your help and support..
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

[[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 23 15:56:25 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Jan 2019 09:56:25 -0500
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <20190123125301.7e3e43b7@trisector>
References: <20190123125301.7e3e43b7@trisector>
Message-ID: <fc41f3a2-dff3-ec52-8181-a6eb936abf5c@gmail.com>

On 23/01/2019 4:53 a.m., Ivan Krylov wrote:
> Hi!
> 
> I needed to generalize a loss function being optimized inside another
> function, so I made it a function argument with a default value. It
> worked without problems, but later I noticed that the inner function,
> despite being defined in the function arguments, somehow closes over a
> variable belonging to the outer function, which is defined later.
> 
> Example:
> 
> outside <- function(inside = function() print(secret)) {
> 	secret <- 'secret'
> 	inside()
> }
> outside()
> 
> I'm used to languages that have both lambdas and variable declaration
> (like perl5 -Mstrict or C++11), so I was a bit surprised.

Defaults of variables are evaluated in the evaluation frame of the call.
So the inside() function is created in the evaluation frame, and it's 
environment will be that frame.

When it is called it will create a new evaluation frame (empty in your 
example), with a parent being its environment, i.e. the evaluation frame 
from when it was created, so it will be able to see your secret variable.

If it made an assignment to secret using standard "<-" assignment, it 
would create a new variable in its own evaluation frame, but if it used 
superassignment "<<-", it would modify the original secret variable.

> 
> Does this work because R looks up the variable by name late enough at
> runtime for the `secret` variable to exist in the parent environment of
> the `inside` function? Can I rely on it? Is this considered bad style?
> Should I rewrite it (and how)?

I would consider it bad style if the inside() function had anything 
other than a trivial definition as in your example.  However, in my 
opinion it would be fine to write it as

  outside <- function(inside = defaultInsideFn) {
     defaultInsideFn <- function() print(secret)
     secret <- 'secret'
     inside()
  }

which is essentially equivalent, other than having a shorter header on 
the outside() function.

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 23 16:02:00 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Jan 2019 10:02:00 -0500
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <20190123102703.GF9992@paftolwp3a>
References: <20190123125301.7e3e43b7@trisector>
 <20190123102703.GF9992@paftolwp3a>
Message-ID: <44f3abe1-09f5-5828-994b-fd2ff8f36ff8@gmail.com>

On 23/01/2019 5:27 a.m., Jan T Kim wrote:
> Hi Ivan & All,
> 
> R's scoping system basically goes to all environments along the call
> stack when trying to resolve an unbound variable, see the language
> definition [1], section 4.3.4, and perhaps also 2.1.5.

You are misinterpreting that section.  It's not the call stack that is 
searched, it's the chain of environments that starts with the evaluation 
frame of the current function.  Those are very different.  For example,


g <- function() {
   print(secret)
}

f <- function() {
   secret <- "secret"
   g()
}

would fail, because even though secret is defined in the caller of g() 
and is therefore in the call stack, that's irrelevant:  it's not in g's 
evaluation frame (which has no variables) or its parent (which is the 
global environment if those definitions were evaluated there).

Duncan Murdoch

> 
> Generally, unbound variables should be used with care. It's a bit
> difficult to decide whether and how the code should be rewritten,
> I'd say that depends on the underlying intentions / purposes. As it
> is, the code could be simplified to just
> 
>      print("secret");
> 
> but that's probably missing the point.
> 
> Best regards, Jan
> 
> 
> [1] https://cran.r-project.org/doc/manuals/r-release/R-lang.html
> 
> On Wed, Jan 23, 2019 at 12:53:01PM +0300, Ivan Krylov wrote:
>> Hi!
>>
>> I needed to generalize a loss function being optimized inside another
>> function, so I made it a function argument with a default value. It
>> worked without problems, but later I noticed that the inner function,
>> despite being defined in the function arguments, somehow closes over a
>> variable belonging to the outer function, which is defined later.
>>
>> Example:
>>
>> outside <- function(inside = function() print(secret)) {
>> 	secret <- 'secret'
>> 	inside()
>> }
>> outside()
>>
>> I'm used to languages that have both lambdas and variable declaration
>> (like perl5 -Mstrict or C++11), so I was a bit surprised.
>>
>> Does this work because R looks up the variable by name late enough at
>> runtime for the `secret` variable to exist in the parent environment of
>> the `inside` function? Can I rely on it? Is this considered bad style?
>> Should I rewrite it (and how)?
>>
>> -- 
>> Best regards,
>> Ivan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dc@r|@on @end|ng |rom t@mu@edu  Wed Jan 23 16:19:58 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Wed, 23 Jan 2019 15:19:58 +0000
Subject: [R] calculating quintile values of numeric data?
In-Reply-To: <A4D0ED05-6CF7-4260-B6FA-6F4D2CEB194A@dcn.davis.ca.us>
References: <CAHfBD2fEiLV3z6opKODBBBw_V5pvNZXoUCW+S9UTFcthU-HX5g@mail.gmail.com>
 <A4D0ED05-6CF7-4260-B6FA-6F4D2CEB194A@dcn.davis.ca.us>
Message-ID: <e109193694484b559f09471a5e3bf12e@tamu.edu>

Also quantile() and cut(). The only tricky part is making sure the minimum and maximum values are included.

> set.seed(42)
> x <- rnorm(100, 25, 3)
> bks <- quantile(x, prob=c(0, .2, .4, .6, .8, 1))
> y <- cut(x, breaks=bks, labels=1:5, include.lowest=TRUE)
> table(y)
y
 1  2  3  4  5 
20 20 20 20 20
> z <- findInterval(x, bks, all.inside=TRUE)
> table(z)
z
 1  2  3  4  5 
20 20 20 20 20

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Wednesday, January 23, 2019 1:00 AM
To: r-help at r-project.org; Kelly Thompson <kt1572757 at gmail.com>
Subject: Re: [R] calculating quintile values of numeric data?

?range
?findInterval

On January 22, 2019 6:54:14 PM PST, Kelly Thompson <kt1572757 at gmail.com> wrote:
>I?d like to take numeric data, and calculate numeric ?quintiles? with
>integer values in from 1 ? 5 , with values in the lowest 20% of values
>having a value of 1, the >20 - <= 40% of values having a value of 2,
>the >40% - <=60% of values having a value of 3, etc.
>
>How can I use quantcut, or another function, to do this?
>
>
>Thanks!
>
>
>Ex.
>
>x <- c(1:10)
>
>I want:
>myquintilefunction (x, q=5, na.rm=T) to return a vector with values:
>1,1,2,2,3,3,4,4,5,5
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From @|ek@@ndre@g@v@@he||@hv||| @end|ng |rom |||@un|@edu@ge  Wed Jan 23 11:17:53 2019
From: @|ek@@ndre@g@v@@he||@hv||| @end|ng |rom |||@un|@edu@ge (Aleksandre Gavashelishvili)
Date: Wed, 23 Jan 2019 15:17:53 +0500
Subject: [R] Vectorizing a for-loop for cross-validation in R
Message-ID: <CAHyGbpaBQjzDNAC4Ynrm6cDZxKes3Sz=POPq6GytrWP7MKQxdA@mail.gmail.com>

I'm trying to speed up a script that otherwise takes days to handle larger
data sets. So, is there a way to completely vectorize or paralellize the
following script:

                *# k-fold cross validation*

df <- trees # a data frame 'trees' from R.
df <- df[sample(nrow(df)), ] # randomly shuffles the data.
k <- 10 # Number of folds. Note k=nrow(df) in the leave-one-out cross
validation.
folds <- cut(seq(from=1, to=nrow(df)), breaks=k, labels=FALSE) # creates
unique numbers for k equally size folds.
df$ID <- folds # adds fold IDs.
df[paste("pred", 1:3, sep="")] <- NA # adds multiple columns "pred1"
"pred2" "pred3" to speed up the following loop.

library(mgcv)

for(i in 1:k) {
  # looping for different models:
  m1 <- gam(Volume ~ s(Height), data=df, subset=(ID != i))
  m2 <- gam(Volume ~ s(Girth), data=df, subset=(ID != i))
  m3 <- gam(Volume ~ s(Girth) + s(Height), data=df, subset=(ID != i))

  # looping for predictions:
  df[df$ID==i, "pred1"] <- predict(m1, df[df$ID==i, ], type="response")
  df[df$ID==i, "pred2"] <- predict(m2, df[df$ID==i, ], type="response")
  df[df$ID==i, "pred3"] <- predict(m3, df[df$ID==i, ], type="response")
}

# calculating residuals:
df$res1 <- with(df, Volume - pred1)
df$res2 <- with(df, Volume - pred2)
df$res3 <- with(df, Volume - pred3)

Model <- paste("m", 1:3, sep="") # creates a vector of model names.

# creating a vector of mean-square errors (MSE):
MSE <- with(df, c(
  sum(res1^2) / nrow(df),
  sum(res2^2) / nrow(df),
  sum(res3^2) / nrow(df)
))

model.mse <- data.frame(Model, MSE) # creates a data frame of model names
and mean-square errors.
model.mse <- model.mse[order(model.mse$MSE), ] # rearranges the previous
data frame in order of increasing mean-square errors.

I'd appreciate any help. This code takes several days if run on >=30,000
different GAM models and 3 predictors. Could you please help with
re-writing the script into sapply() or foreach()/doParallel format?

Thanks
Lexo

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Wed Jan 23 18:13:52 2019
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 23 Jan 2019 12:13:52 -0500
Subject: [R] Packages
Message-ID: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>

Dear All:

After installing the packages "car" and "alr3", I got the following error
messages:


> library(car)
Error in library(car) : there is no package called ?car?

> library(alr3)
Error in library(alr3) : there is no package called ?alr3?

any helps would be appreciated.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 23 18:20:20 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Jan 2019 12:20:20 -0500
Subject: [R] Packages
In-Reply-To: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>
References: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>
Message-ID: <f64b9f4e-f122-2650-6207-9cf528d71aa3@gmail.com>

On 23/01/2019 12:13 p.m., AbouEl-Makarim Aboueissa wrote:
> Dear All:
> 
> After installing the packages "car" and "alr3", I got the following error
> messages:
> 
> 
>> library(car)
> Error in library(car) : there is no package called ?car?
> 
>> library(alr3)
> Error in library(alr3) : there is no package called ?alr3?
> 
> any helps would be appreciated.
> 

You need to show us the messages you received when you installed them. 
The usual cause of problems like this is that you don't have write 
permission on the default location, and R has chosen an alternate; then 
when you try to attach the packages, you haven't told R to look in the 
alternate location.

Duncan Murdoch


From jttk|m @end|ng |rom goog|em@||@com  Wed Jan 23 18:20:49 2019
From: jttk|m @end|ng |rom goog|em@||@com (Jan T Kim)
Date: Wed, 23 Jan 2019 17:20:49 +0000
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <44f3abe1-09f5-5828-994b-fd2ff8f36ff8@gmail.com>
References: <20190123125301.7e3e43b7@trisector>
 <20190123102703.GF9992@paftolwp3a>
 <44f3abe1-09f5-5828-994b-fd2ff8f36ff8@gmail.com>
Message-ID: <20190123172048.GG9992@paftolwp3a>

Hi Duncan,

On Wed, Jan 23, 2019 at 10:02:00AM -0500, Duncan Murdoch wrote:
> On 23/01/2019 5:27 a.m., Jan T Kim wrote:
> >Hi Ivan & All,
> >
> >R's scoping system basically goes to all environments along the call
> >stack when trying to resolve an unbound variable, see the language
> >definition [1], section 4.3.4, and perhaps also 2.1.5.
> 
> You are misinterpreting that section.  It's not the call stack that is
> searched, it's the chain of environments that starts with the evaluation
> frame of the current function.  Those are very different.

yes -- I meant the environment chain but mistakenly wrote "call stack",
sorry. Thanks for pointing this out.

Best regards, Jan


> For example,
> 
> 
> g <- function() {
>   print(secret)
> }
> 
> f <- function() {
>   secret <- "secret"
>   g()
> }
> 
> would fail, because even though secret is defined in the caller of g() and
> is therefore in the call stack, that's irrelevant:  it's not in g's
> evaluation frame (which has no variables) or its parent (which is the global
> environment if those definitions were evaluated there).
> 
> Duncan Murdoch
> 
> >
> >Generally, unbound variables should be used with care. It's a bit
> >difficult to decide whether and how the code should be rewritten,
> >I'd say that depends on the underlying intentions / purposes. As it
> >is, the code could be simplified to just
> >
> >     print("secret");
> >
> >but that's probably missing the point.
> >
> >Best regards, Jan
> >
> >
> >[1] https://cran.r-project.org/doc/manuals/r-release/R-lang.html
> >
> >On Wed, Jan 23, 2019 at 12:53:01PM +0300, Ivan Krylov wrote:
> >>Hi!
> >>
> >>I needed to generalize a loss function being optimized inside another
> >>function, so I made it a function argument with a default value. It
> >>worked without problems, but later I noticed that the inner function,
> >>despite being defined in the function arguments, somehow closes over a
> >>variable belonging to the outer function, which is defined later.
> >>
> >>Example:
> >>
> >>outside <- function(inside = function() print(secret)) {
> >>	secret <- 'secret'
> >>	inside()
> >>}
> >>outside()
> >>
> >>I'm used to languages that have both lambdas and variable declaration
> >>(like perl5 -Mstrict or C++11), so I was a bit surprised.
> >>
> >>Does this work because R looks up the variable by name late enough at
> >>runtime for the `secret` variable to exist in the parent environment of
> >>the `inside` function? Can I rely on it? Is this considered bad style?
> >>Should I rewrite it (and how)?
> >>
> >>-- 
> >>Best regards,
> >>Ivan
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Wed Jan 23 18:27:44 2019
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 23 Jan 2019 12:27:44 -0500
Subject: [R] Packages
In-Reply-To: <f64b9f4e-f122-2650-6207-9cf528d71aa3@gmail.com>
References: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>
 <f64b9f4e-f122-2650-6207-9cf528d71aa3@gmail.com>
Message-ID: <CAE9stmdkMOE+0cH=H2+6XGaNfAh9RVB3_xApC_ri8SckzKdB-A@mail.gmail.com>

here is the messages I got when I install the "car" package:

> install.packages("car")
Installing package into ?C:/Users/aaboueissa/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
also installing the dependency ?rio?


  There are binary versions available but the source versions are later:
    binary source needs_compilation
rio 0.5.10 0.5.16             FALSE
car  3.0-0  3.0-2             FALSE

installing the source packages ?rio?, ?car?

trying URL 'https://cran.case.edu/src/contrib/rio_0.5.16.tar.gz'
Content type 'application/x-gzip' length 420489 bytes (410 KB)
downloaded 410 KB

trying URL 'https://cran.case.edu/src/contrib/car_3.0-2.tar.gz'
Content type 'application/x-gzip' length 447952 bytes (437 KB)
downloaded 437 KB

* installing *source* package 'rio' ...
** package 'rio' successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called 'Rcpp'
ERROR: lazy loading failed for package 'rio'
* removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/rio'
ERROR: dependency 'rio' is not available for package 'car'
* removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/car'

The downloaded source packages are in

?C:\Users\aaboueissa\AppData\Local\Temp\RtmpK0MQ8V\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l
"C:\Users\aaboueissa\Documents\R\win-library\3.3"
C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/rio_0.5.16.tar.gz'
had status 1
2: In install.packages("car") :
  installation of package ?rio? had non-zero exit status
3: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l
"C:\Users\aaboueissa\Documents\R\win-library\3.3"
C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/car_3.0-2.tar.gz'
had status 1
4: In install.packages("car") :
  installation of package ?car? had non-zero exit status


______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Wed, Jan 23, 2019 at 12:20 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/01/2019 12:13 p.m., AbouEl-Makarim Aboueissa wrote:
> > Dear All:
> >
> > After installing the packages "car" and "alr3", I got the following error
> > messages:
> >
> >
> >> library(car)
> > Error in library(car) : there is no package called ?car?
> >
> >> library(alr3)
> > Error in library(alr3) : there is no package called ?alr3?
> >
> > any helps would be appreciated.
> >
>
> You need to show us the messages you received when you installed them.
> The usual cause of problems like this is that you don't have write
> permission on the default location, and R has chosen an alternate; then
> when you try to attach the packages, you haven't told R to look in the
> alternate location.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From tg@77m @end|ng |rom y@hoo@com  Wed Jan 23 18:34:52 2019
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Wed, 23 Jan 2019 17:34:52 +0000 (UTC)
Subject: [R] read_xl question
References: <1653570142.498507.1548264892168.ref@mail.yahoo.com>
Message-ID: <1653570142.498507.1548264892168@mail.yahoo.com>


Colleagues,

?I have a workbook which has 3 worksheets

I need to extract data from two specific cells from one ofthose worksheets.

?

I can use read_excel to do this for one file.

data<-read_excel("C:/Desktop/Excel_raw_data/0020-49785 8768.xls",

????????????????????sheet="Flow Data",range=("b9:c10"))

?

How can I do this for all my Excel files in the directory?

?

I can get the list of Excel files using: files =list.files(pattern="*.xls")

But I?m not sure where to go from here.

Some guidance would be appreciated.

?

All the best

?Thomas Subia

Thomas Subia

	[[alternative HTML version deleted]]


From n|u|tz @end|ng |rom gm@||@com  Wed Jan 23 19:16:23 2019
From: n|u|tz @end|ng |rom gm@||@com (Neal Fultz)
Date: Wed, 23 Jan 2019 10:16:23 -0800
Subject: [R] Packages
In-Reply-To: <CAE9stmdkMOE+0cH=H2+6XGaNfAh9RVB3_xApC_ri8SckzKdB-A@mail.gmail.com>
References: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>
 <f64b9f4e-f122-2650-6207-9cf528d71aa3@gmail.com>
 <CAE9stmdkMOE+0cH=H2+6XGaNfAh9RVB3_xApC_ri8SckzKdB-A@mail.gmail.com>
Message-ID: <CAL9B2veCMZVjGWZrk8VMaU86DqezxAaz6WAmo89S6SNXBvYvRA@mail.gmail.com>

I'd recommend you upgrade to R version 3.5.2, the version you have is quite
out of date.

On Wed, Jan 23, 2019 at 9:42 AM AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> here is the messages I got when I install the "car" package:
>
> > install.packages("car")
> Installing package into ?C:/Users/aaboueissa/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> also installing the dependency ?rio?
>
>
>   There are binary versions available but the source versions are later:
>     binary source needs_compilation
> rio 0.5.10 0.5.16             FALSE
> car  3.0-0  3.0-2             FALSE
>
> installing the source packages ?rio?, ?car?
>
> trying URL 'https://cran.case.edu/src/contrib/rio_0.5.16.tar.gz'
> Content type 'application/x-gzip' length 420489 bytes (410 KB)
> downloaded 410 KB
>
> trying URL 'https://cran.case.edu/src/contrib/car_3.0-2.tar.gz'
> Content type 'application/x-gzip' length 447952 bytes (437 KB)
> downloaded 437 KB
>
> * installing *source* package 'rio' ...
> ** package 'rio' successfully unpacked and MD5 sums checked
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called 'Rcpp'
> ERROR: lazy loading failed for package 'rio'
> * removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/rio'
> ERROR: dependency 'rio' is not available for package 'car'
> * removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/car'
>
> The downloaded source packages are in
>
> ?C:\Users\aaboueissa\AppData\Local\Temp\RtmpK0MQ8V\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l
> "C:\Users\aaboueissa\Documents\R\win-library\3.3"
>
> C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/rio_0.5.16.tar.gz'
> had status 1
> 2: In install.packages("car") :
>   installation of package ?rio? had non-zero exit status
> 3: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l
> "C:\Users\aaboueissa\Documents\R\win-library\3.3"
>
> C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/car_3.0-2.tar.gz'
> had status 1
> 4: In install.packages("car") :
>   installation of package ?car? had non-zero exit status
>
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>
>
> On Wed, Jan 23, 2019 at 12:20 PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 23/01/2019 12:13 p.m., AbouEl-Makarim Aboueissa wrote:
> > > Dear All:
> > >
> > > After installing the packages "car" and "alr3", I got the following
> error
> > > messages:
> > >
> > >
> > >> library(car)
> > > Error in library(car) : there is no package called ?car?
> > >
> > >> library(alr3)
> > > Error in library(alr3) : there is no package called ?alr3?
> > >
> > > any helps would be appreciated.
> > >
> >
> > You need to show us the messages you received when you installed them.
> > The usual cause of problems like this is that you don't have write
> > permission on the default location, and R has chosen an alternate; then
> > when you try to attach the packages, you haven't told R to look in the
> > alternate location.
> >
> > Duncan Murdoch
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom uc@d@edu  Wed Jan 23 19:34:14 2019
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Wed, 23 Jan 2019 18:34:14 +0000
Subject: [R] Vectorizing a for-loop for cross-validation in R
In-Reply-To: <CAHyGbpaBQjzDNAC4Ynrm6cDZxKes3Sz=POPq6GytrWP7MKQxdA@mail.gmail.com>
References: <CAHyGbpaBQjzDNAC4Ynrm6cDZxKes3Sz=POPq6GytrWP7MKQxdA@mail.gmail.com>
Message-ID: <48B26F2C-AEFF-4C7E-B39B-50A816428D87@ucsd.edu>

See inline.

> On Jan 23, 2019, at 2:17 AM, Aleksandre Gavashelishvili <aleksandre.gavashelishvili at iliauni.edu.ge> wrote:
> 
> I'm trying to speed up a script that otherwise takes days to handle larger
> data sets. So, is there a way to completely vectorize or paralellize the
> following script:
> 
>                *# k-fold cross validation*
> 
> df <- trees # a data frame 'trees' from R.
> df <- df[sample(nrow(df)), ] # randomly shuffles the data.
> k <- 10 # Number of folds. Note k=nrow(df) in the leave-one-out cross
> validation.
> folds <- cut(seq(from=1, to=nrow(df)), breaks=k, labels=FALSE) # creates
> unique numbers for k equally size folds.
> df$ID <- folds # adds fold IDs.
> df[paste("pred", 1:3, sep="")] <- NA # adds multiple columns "pred1"
> "pred2" "pred3" to speed up the following loop.
> 
> library(mgcv)
> 

Rprof()

replicate(100, {


> for(i in 1:k) {
>  # looping for different models:
>  m1 <- gam(Volume ~ s(Height), data=df, subset=(ID != i))
>  m2 <- gam(Volume ~ s(Girth), data=df, subset=(ID != i))
>  m3 <- gam(Volume ~ s(Girth) + s(Height), data=df, subset=(ID != i))
> 
>  # looping for predictions:
>  df[df$ID==i, "pred1"] <- predict(m1, df[df$ID==i, ], type="response")
>  df[df$ID==i, "pred2"] <- predict(m2, df[df$ID==i, ], type="response")
>  df[df$ID==i, "pred3"] <- predict(m3, df[df$ID==i, ], type="response")
> }
> 

})

Rprof(NULL)

summaryRprof()

## read ?Rprof to get a sense of what it does

## read the summary to determine where time is being spent.

## the result was surprising to me. YMMV.

## there may be redundancies that you can eliminate by 
##  - doing the setup within gam() one time and saving it
##  - calling the worker functions by modifying the setup 
##    in a loop or function and saving the results


> # calculating residuals:
> df$res1 <- with(df, Volume - pred1)
> df$res2 <- with(df, Volume - pred2)
> df$res3 <- with(df, Volume - pred3)
> 
> Model <- paste("m", 1:3, sep="") # creates a vector of model names.
> 
> # creating a vector of mean-square errors (MSE):
> MSE <- with(df, c(
>  sum(res1^2) / nrow(df),
>  sum(res2^2) / nrow(df),
>  sum(res3^2) / nrow(df)
> ))
> 
> model.mse <- data.frame(Model, MSE) # creates a data frame of model names
> and mean-square errors.
> model.mse <- model.mse[order(model.mse$MSE), ] # rearranges the previous
> data frame in order of increasing mean-square errors.
> 
> I'd appreciate any help. This code takes several days if run on >=30,000
> different GAM models and 3 predictors. Could you please help with
> re-writing the script into sapply() or foreach()/doParallel format?
> 

This is something you should learn to do. It is pretty standard practice. Use the body of your for loop as the body of a function, add arguments, and create a suitable return value. The something like

	lapply( 1:k, your.loop.body.function, other.arg1, other.arg2, ...)

should work.  If it does, then parallel::mclapply(...) should also work.

HTH,

Chuck

 

From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jan 23 19:44:03 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Jan 2019 13:44:03 -0500
Subject: [R] Packages
In-Reply-To: <CAE9stmdkMOE+0cH=H2+6XGaNfAh9RVB3_xApC_ri8SckzKdB-A@mail.gmail.com>
References: <CAE9stmf-EdfehZxWRmXsk3TsbPxhYVYs5oYt6_YfXrX3c5QT7w@mail.gmail.com>
 <f64b9f4e-f122-2650-6207-9cf528d71aa3@gmail.com>
 <CAE9stmdkMOE+0cH=H2+6XGaNfAh9RVB3_xApC_ri8SckzKdB-A@mail.gmail.com>
Message-ID: <c1ba940f-b196-2199-7260-7389bb62c370@gmail.com>

On 23/01/2019 12:27 p.m., AbouEl-Makarim Aboueissa wrote:
> here is the messages I got when I install the "car" package:

You didn't install it, you got errors during the install.

I'm not sure why there was no attempt to install Rcpp (which was 
required by rio, see the error message).  Perhaps the mirror you used 
doesn't have it?  I'd recommend using the cloud.r-project.org mirror 
rather than a local one in almost any case.

In any case, Neal's advice to update R is likely to make your life a lot 
easier.

Duncan Murdoch

> 
>  > install.packages("car")
> Installing package into ?C:/Users/aaboueissa/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> also installing the dependency ?rio?
> 
> 
>  ? There are binary versions available but the source versions are later:
>  ? ? binary source needs_compilation
> rio 0.5.10 0.5.16? ? ? ? ? ? ?FALSE
> car? 3.0-0? 3.0-2? ? ? ? ? ? ?FALSE
> 
> installing the source packages ?rio?, ?car?
> 
> trying URL 'https://cran.case.edu/src/contrib/rio_0.5.16.tar.gz'
> Content type 'application/x-gzip' length 420489 bytes (410 KB)
> downloaded 410 KB
> 
> trying URL 'https://cran.case.edu/src/contrib/car_3.0-2.tar.gz'
> Content type 'application/x-gzip' length 447952 bytes (437 KB)
> downloaded 437 KB
> 
> * installing *source* package 'rio' ...
> ** package 'rio' successfully unpacked and MD5 sums checked
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), 
> versionCheck = vI[[j]]) :
>  ? there is no package called 'Rcpp'
> ERROR: lazy loading failed for package 'rio'
> * removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/rio'
> ERROR: dependency 'rio' is not available for package 'car'
> * removing 'C:/Users/aaboueissa/Documents/R/win-library/3.3/car'
> 
> The downloaded source packages are in
>          
> ?C:\Users\aaboueissa\AppData\Local\Temp\RtmpK0MQ8V\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l 
> "C:\Users\aaboueissa\Documents\R\win-library\3.3" 
> C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/rio_0.5.16.tar.gz' 
> had status 1
> 2: In install.packages("car") :
>  ? installation of package ?rio? had non-zero exit status
> 3: running command '"C:/PROGRA~1/R/R-33~1.2/bin/x64/R" CMD INSTALL -l 
> "C:\Users\aaboueissa\Documents\R\win-library\3.3" 
> C:\Users\AABOUE~1\AppData\Local\Temp\RtmpK0MQ8V/downloaded_packages/car_3.0-2.tar.gz' 
> had status 1
> 4: In install.packages("car") :
>  ? installation of package ?car? had non-zero exit status
> 
> 
> ______________________
> 
> *AbouEl-Makarim Aboueissa, PhD
> *
> *
> *
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
> *Department of Mathematics and Statistics
> *
> *University of Southern Maine*
> 
> 
> 
> On Wed, Jan 23, 2019 at 12:20 PM Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 23/01/2019 12:13 p.m., AbouEl-Makarim Aboueissa wrote:
>      > Dear All:
>      >
>      > After installing the packages "car" and "alr3", I got the
>     following error
>      > messages:
>      >
>      >
>      >> library(car)
>      > Error in library(car) : there is no package called ?car?
>      >
>      >> library(alr3)
>      > Error in library(alr3) : there is no package called ?alr3?
>      >
>      > any helps would be appreciated.
>      >
> 
>     You need to show us the messages you received when you installed them.
>     The usual cause of problems like this is that you don't have write
>     permission on the default location, and R has chosen an alternate; then
>     when you try to attach the packages, you haven't told R to look in the
>     alternate location.
> 
>     Duncan Murdoch
>


From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jan 23 19:45:34 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 23 Jan 2019 18:45:34 +0000
Subject: [R] 
 Unable to compute Confidence Intervals from output from MARSS
 package
In-Reply-To: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>
References: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>
Message-ID: <BN7PR02MB5073AF3A8E93FE8DA2AE6DFDEA990@BN7PR02MB5073.namprd02.prod.outlook.com>

sessionInfo()
#R version 3.5.2 (2018-12-20)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

Hello Ashim. I am not familiar with the MARSS pkg, however, I am always interested in following many of these R-Help questions and often run them for my own edification.

I ran your script and it appears to have run successfully, however, when I (naively) use the suggested "# Use MARSSparamCIs to compute CIs and bias estimates." below as you did I get a different error.

# I GET THIS ERROR
#Error in MARSSparamsCIs(fit) : could not find function "MARSSparamsCIs"

After further googling I find that I was (as suspected) incorrect in using " MARSSparamsCIs" as a function on fit or maybe not, take a look at this URL

https://rdrr.io/cran/MARSS/man/MARSSparamCIs.html

I'm not sure how to proceed but this is interesting to follow, thank you.

WHP

x1 <- rnorm(1000)
View(x1)#----------------------Just curious
plot(x1)#----------------------Just curious
b <- cumsum(rnorm(1000, sd = sqrt(.6)))
plot(b)#----------------------Just curious
y <- 1 + b*x1 + rnorm(1000)
plot(y)#----------------------Just curious

Z = array(NA,c(1,2,1000))
Z[1,1,] = rep(1,1000)
Z[1,2,] = x1

mod2.list = list ( B = matrix(c(1,0,0,1),nrow = 2 , byrow = T),
                   U = matrix(0,2,1),
                   Q = matrix(list(0,0,0,"s2b"),2,2),
                   Z= Z, A = matrix(0), R = matrix("r"))
View(mod2.list)
#print(mod2.list)

str(mod2.list)#---------------------------------KNOW THY DATA
#List of 6
# $ B: num [1:2, 1:2] 1 0 0 1
# $ U: num [1:2, 1] 0 0
# $ Q:List of 4
# ..$ : num 0
# ..$ : num 0
# ..$ : num 0
# ..$ : chr "s2b"
# ..- attr(*, "dim")= int [1:2] 2 2
# $ Z: num [1, 1:2, 1:1000] 1 1.2 1 1.04 1 ...
# $ A: num [1, 1] 0
# $ R: chr [1, 1] "r"

fit = MARSS(as.vector(y), model = mod2.list,inits = list(x0=matrix(0,nrow=2,ncol=1)))
#Success! abstol and log-log tests passed at 27 iterations.
# Alert: conv.test.slope.tol is 0.5.
# Test with smaller values (<0.1) to ensure convergence.
#
# MARSS fit is
# Estimation method: kem
# Convergence test: conv.test.slope.tol = 0.5, abstol = 0.001
# Estimation converged in 27 iterations.
# Log-likelihood: -1758.409
# AIC: 3524.818   AICc: 3524.858
#
# Estimate
# R.r      1.026
# Q.s2b    0.606
# x0.X1    0.999
# x0.X2   -1.025
# Initial states (x0) defined at t=0
#
# Standard errors have not been calculated.
# Use MARSSparamCIs to compute CIs and bias estimates.

MARSSparamsCIs(fit)
#I GET THIS ERROR
#Error in MARSSparamsCIs(fit) : could not find function "MARSSparamsCIs"


#NOT THIS ERROR
# The above will give this error :
#Error in MARSSharveyobsFI(MLEobj) : replacement has length zero



WHP


From: R-help <r-help-bounces at r-project.org> On Behalf Of Ashim Kapoor
Sent: Wednesday, January 23, 2019 1:38 AM
To: r-help at r-project.org
Subject: [R] Unable to compute Confidence Intervals from output from MARSS package

Dear All,

I am trying to use this package --->
https://cran.r-project.org/web/packages/MARSS/index.html
I am reading this book which shows some examples based on the above package
---> https://nwfsc-timeseries.github.io/atsa-labs/

In a few words, the incantation MARSS(...) estimates the parameters and
MARSSparamCIs should return the confidence intervals. My problem is that
MARSSparamCIs returns this error :-

> MARSSparamCIs(fit)
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero
>

### This page and the next page, explains the jargon used :
https://nwfsc-timeseries.github.io/atsa-labs/sec-dlm-example-of-a-univariate-dlm.html

### Here is a MWE to recreate the error :-

# This is a Time Varying Parameters regression
# Here a is fixed and b is doing a RW.

x1 <- rnorm(1000)
b <- cumsum(rnorm(1000, sd = sqrt(.6)))
y <- 1 + b*x1 + rnorm(1000)

Z = array(NA,c(1,2,1000))
Z[1,1,] = rep(1,1000)
Z[1,2,] = x1

mod2.list = list ( B = matrix(c(1,0,0,1),nrow = 2 , byrow = T), U =
matrix(0,2,1),
Q = matrix(list(0,0,0,"s2b"),2,2), Z= Z, A = matrix(0), R = matrix("r"))

fit = MARSS(as.vector(y), model = mod2.list,inits =
list(x0=matrix(0,nrow=2,ncol=1)))

MARSSparamsCIs(fit)

# The above will give this error :
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero

Best Regards,
Ashim

[[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jan 23 20:19:08 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 23 Jan 2019 19:19:08 +0000
Subject: [R] 
 Unable to compute Confidence Intervals from output from MARSS
 package
In-Reply-To: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>
References: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>
Message-ID: <BN7PR02MB507371A8C12D9C18B6CEF3CAEA990@BN7PR02MB5073.namprd02.prod.outlook.com>


Ashim.

I see where I was mistaken, using MARSSparamsCIs(fit) <--Somehow I got an s in between param & Cis.

I now get new error similarly as you, my apologies.

final <- MARSSparamCIs(fit)
Error in dpari[time.varying] <- dparmat(MLEobj, time.varying, t = t) :   replacement has length zero

WHP

From: R-help <r-help-bounces at r-project.org> On Behalf Of Ashim Kapoor
Sent: Wednesday, January 23, 2019 1:38 AM
To: r-help at r-project.org
Subject: [R] Unable to compute Confidence Intervals from output from MARSS package

Dear All,

I am trying to use this package --->
https://cran.r-project.org/web/packages/MARSS/index.html
I am reading this book which shows some examples based on the above package
---> https://nwfsc-timeseries.github.io/atsa-labs/

In a few words, the incantation MARSS(...) estimates the parameters and
MARSSparamCIs should return the confidence intervals. My problem is that
MARSSparamCIs returns this error :-

> MARSSparamCIs(fit)
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero
>

### This page and the next page, explains the jargon used :
https://nwfsc-timeseries.github.io/atsa-labs/sec-dlm-example-of-a-univariate-dlm.html

### Here is a MWE to recreate the error :-

# This is a Time Varying Parameters regression
# Here a is fixed and b is doing a RW.

x1 <- rnorm(1000)
b <- cumsum(rnorm(1000, sd = sqrt(.6)))
y <- 1 + b*x1 + rnorm(1000)

Z = array(NA,c(1,2,1000))
Z[1,1,] = rep(1,1000)
Z[1,2,] = x1

mod2.list = list ( B = matrix(c(1,0,0,1),nrow = 2 , byrow = T), U =
matrix(0,2,1),
Q = matrix(list(0,0,0,"s2b"),2,2), Z= Z, A = matrix(0), R = matrix("r"))

fit = MARSS(as.vector(y), model = mod2.list,inits =
list(x0=matrix(0,nrow=2,ncol=1)))

MARSSparamsCIs(fit)

# The above will give this error :
Error in MARSSharveyobsFI(MLEobj) : replacement has length zero

Best Regards,
Ashim

[[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From er|cjberger @end|ng |rom gm@||@com  Wed Jan 23 20:37:56 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 23 Jan 2019 21:37:56 +0200
Subject: [R] Vectorizing a for-loop for cross-validation in R
In-Reply-To: <48B26F2C-AEFF-4C7E-B39B-50A816428D87@ucsd.edu>
References: <CAHyGbpaBQjzDNAC4Ynrm6cDZxKes3Sz=POPq6GytrWP7MKQxdA@mail.gmail.com>
 <48B26F2C-AEFF-4C7E-B39B-50A816428D87@ucsd.edu>
Message-ID: <CAGgJW75hz4y1gX6UHnBn=5M2x6OsB3m6OrRoGWE6Hm8wRLRDJg@mail.gmail.com>

Charles writes about saving execution time by eliminating redundancies.
If you see redundancies related to calling a time-consuming function
multiple times with the same arguments, a very easy way to speed up your
program is to memoise the functions using the package memoise.

HTH,
Eric




On Wed, Jan 23, 2019 at 8:34 PM Berry, Charles <ccberry at ucsd.edu> wrote:

> See inline.
>
> > On Jan 23, 2019, at 2:17 AM, Aleksandre Gavashelishvili <
> aleksandre.gavashelishvili at iliauni.edu.ge> wrote:
> >
> > I'm trying to speed up a script that otherwise takes days to handle
> larger
> > data sets. So, is there a way to completely vectorize or paralellize the
> > following script:
> >
> >                *# k-fold cross validation*
> >
> > df <- trees # a data frame 'trees' from R.
> > df <- df[sample(nrow(df)), ] # randomly shuffles the data.
> > k <- 10 # Number of folds. Note k=nrow(df) in the leave-one-out cross
> > validation.
> > folds <- cut(seq(from=1, to=nrow(df)), breaks=k, labels=FALSE) # creates
> > unique numbers for k equally size folds.
> > df$ID <- folds # adds fold IDs.
> > df[paste("pred", 1:3, sep="")] <- NA # adds multiple columns "pred1"
> > "pred2" "pred3" to speed up the following loop.
> >
> > library(mgcv)
> >
>
> Rprof()
>
> replicate(100, {
>
>
> > for(i in 1:k) {
> >  # looping for different models:
> >  m1 <- gam(Volume ~ s(Height), data=df, subset=(ID != i))
> >  m2 <- gam(Volume ~ s(Girth), data=df, subset=(ID != i))
> >  m3 <- gam(Volume ~ s(Girth) + s(Height), data=df, subset=(ID != i))
> >
> >  # looping for predictions:
> >  df[df$ID==i, "pred1"] <- predict(m1, df[df$ID==i, ], type="response")
> >  df[df$ID==i, "pred2"] <- predict(m2, df[df$ID==i, ], type="response")
> >  df[df$ID==i, "pred3"] <- predict(m3, df[df$ID==i, ], type="response")
> > }
> >
>
> })
>
> Rprof(NULL)
>
> summaryRprof()
>
> ## read ?Rprof to get a sense of what it does
>
> ## read the summary to determine where time is being spent.
>
> ## the result was surprising to me. YMMV.
>
> ## there may be redundancies that you can eliminate by
> ##  - doing the setup within gam() one time and saving it
> ##  - calling the worker functions by modifying the setup
> ##    in a loop or function and saving the results
>
>
> > # calculating residuals:
> > df$res1 <- with(df, Volume - pred1)
> > df$res2 <- with(df, Volume - pred2)
> > df$res3 <- with(df, Volume - pred3)
> >
> > Model <- paste("m", 1:3, sep="") # creates a vector of model names.
> >
> > # creating a vector of mean-square errors (MSE):
> > MSE <- with(df, c(
> >  sum(res1^2) / nrow(df),
> >  sum(res2^2) / nrow(df),
> >  sum(res3^2) / nrow(df)
> > ))
> >
> > model.mse <- data.frame(Model, MSE) # creates a data frame of model names
> > and mean-square errors.
> > model.mse <- model.mse[order(model.mse$MSE), ] # rearranges the previous
> > data frame in order of increasing mean-square errors.
> >
> > I'd appreciate any help. This code takes several days if run on >=30,000
> > different GAM models and 3 predictors. Could you please help with
> > re-writing the script into sapply() or foreach()/doParallel format?
> >
>
> This is something you should learn to do. It is pretty standard practice.
> Use the body of your for loop as the body of a function, add arguments, and
> create a suitable return value. The something like
>
>         lapply( 1:k, your.loop.body.function, other.arg1, other.arg2, ...)
>
> should work.  If it does, then parallel::mclapply(...) should also work.
>
> HTH,
>
> Chuck
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |@t@z@hn @end|ng |rom gm@||@com  Wed Jan 23 23:31:37 2019
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Wed, 23 Jan 2019 17:31:37 -0500
Subject: [R] read_xl question
In-Reply-To: <1653570142.498507.1548264892168@mail.yahoo.com>
References: <1653570142.498507.1548264892168.ref@mail.yahoo.com>
 <1653570142.498507.1548264892168@mail.yahoo.com>
Message-ID: <CA+vqiLGs9wBVkyMei_BoWpTHzcPDncg7PLBGE7eeHL8dOiytVw@mail.gmail.com>

Something like

files <- list.files(pattern="*.xls", full.names = TRUE)
data <- lapply(files, read_excel, sheet="Flow Data", range=("b9:c10"))

should do it.

--Ista

On Wed, Jan 23, 2019 at 12:42 PM Thomas Subia via R-help
<r-help at r-project.org> wrote:
>
>
> Colleagues,
>
>  I have a workbook which has 3 worksheets
>
> I need to extract data from two specific cells from one ofthose worksheets.
>
>
>
> I can use read_excel to do this for one file.
>
> data<-read_excel("C:/Desktop/Excel_raw_data/0020-49785 8768.xls",
>
>                     sheet="Flow Data",range=("b9:c10"))
>
>
>
> How can I do this for all my Excel files in the directory?
>
>
>
> I can get the list of Excel files using: files =list.files(pattern="*.xls")
>
> But I?m not sure where to go from here.
>
> Some guidance would be appreciated.
>
>
>
> All the best
>
>  Thomas Subia
>
> Thomas Subia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@k@hho||y @end|ng |rom gm@||@com  Thu Jan 24 00:12:26 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Wed, 23 Jan 2019 17:12:26 -0600
Subject: [R] Error "sufficient values in manual scale. 10 needed but only 7
 provided"
Message-ID: <CAM9Qe4iFeGvaO0cJT_cRLJ9HbWe6NSu+YKDso-i_2kqL8G8D_Q@mail.gmail.com>

Hi Dear all;

I am getting the "sufficient values in manual scale. 10 needed but only 7
provided." problem when running the followings. Your help is highly
appreciated.

Regards,
Greg

p2<-p1+scale_color_manual(name="Diseases",
labels=c("Myocardial Infarction", "Coronary artery disease", "Stroke",
"Hypertension", "Depression Anxiety Emotional Problems",  "Circulatory
Problems", "Diabetes"),

values=c("Myocardial Infarction"="red",  "Coronary artery
disease"="purple","Stroke"="darkgreen",
 "Hypertension"="orange",  "Depression Anxiety Emotional
Problems"="darkblue",
 "Circulatory  Problems"="darkred","Diabetes"="blue"))

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 24 01:46:41 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 23 Jan 2019 16:46:41 -0800
Subject: [R] 
 Error "sufficient values in manual scale. 10 needed but only 7
 provided"
In-Reply-To: <CAM9Qe4iFeGvaO0cJT_cRLJ9HbWe6NSu+YKDso-i_2kqL8G8D_Q@mail.gmail.com>
References: <CAM9Qe4iFeGvaO0cJT_cRLJ9HbWe6NSu+YKDso-i_2kqL8G8D_Q@mail.gmail.com>
Message-ID: <C87A7A63-81E0-44D0-BBB8-05428B8778BB@dcn.davis.ca.us>

Problem is in your data not matching your values, but you did not share your data. Try using the unique() function to see what values you have in your data.

I will say that when I want to assign discrete colors I always start by converting my character column in the data frame to a factor and specify the order I want to see the levels presented in that conversion step. Then the colors only need to be specified in that same order and I don't need to keep repeating the labels in multiple places.

library(ggplot2)

mpg$classf <- factor( mpg$class
???????????????????, levels = c( "2seater"
???????????????????????????????, "subcompact"
???????????????????????????????, "compact"
???????????????????????????????, "midsize"
???????????????????????????????, "minivan"
???????????????????????????????, "suv"
???????????????????????????????, "pickup" 
???????????????????????????????) 
???????????????????)

class_colours <- rainbow( length( levels( mpg$classf ) ) )
ggplot( mpg, aes( x = classf, y = cty, colour=classf ) ) +
?geom_boxplot() +
?scale_colour_manual( name="Class", values = class_colours )




On January 23, 2019 3:12:26 PM PST, greg holly <mak.hholly at gmail.com> wrote:
>Hi Dear all;
>
>I am getting the "sufficient values in manual scale. 10 needed but only
>7
>provided." problem when running the followings. Your help is highly
>appreciated.
>
>Regards,
>Greg
>
>p2<-p1+scale_color_manual(name="Diseases",
>labels=c("Myocardial Infarction", "Coronary artery disease", "Stroke",
>"Hypertension", "Depression Anxiety Emotional Problems",  "Circulatory
>Problems", "Diabetes"),
>
>values=c("Myocardial Infarction"="red",  "Coronary artery
>disease"="purple","Stroke"="darkgreen",
> "Hypertension"="orange",  "Depression Anxiety Emotional
>Problems"="darkblue",
> "Circulatory  Problems"="darkred","Diabetes"="blue"))
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@k@hho||y @end|ng |rom gm@||@com  Thu Jan 24 04:43:20 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Wed, 23 Jan 2019 21:43:20 -0600
Subject: [R] 
 Error "sufficient values in manual scale. 10 needed but only 7
 provided"
In-Reply-To: <C87A7A63-81E0-44D0-BBB8-05428B8778BB@dcn.davis.ca.us>
References: <CAM9Qe4iFeGvaO0cJT_cRLJ9HbWe6NSu+YKDso-i_2kqL8G8D_Q@mail.gmail.com>
 <C87A7A63-81E0-44D0-BBB8-05428B8778BB@dcn.davis.ca.us>
Message-ID: <CAM9Qe4hkN7p5tMravh6+=2-rMFzTn7bwxhPrTGzmKnfs9BWMeQ@mail.gmail.com>

Hi Jeff;

I figured out the problem. I do apologize to you and members in the list to
bother you with this simple problem.

Regards,
Greg

On Wed, Jan 23, 2019 at 6:46 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Problem is in your data not matching your values, but you did not share
> your data. Try using the unique() function to see what values you have in
> your data.
>
> I will say that when I want to assign discrete colors I always start by
> converting my character column in the data frame to a factor and specify
> the order I want to see the levels presented in that conversion step. Then
> the colors only need to be specified in that same order and I don't need to
> keep repeating the labels in multiple places.
>
> library(ggplot2)
>
> mpg$classf <- factor( mpg$class
>                    , levels = c( "2seater"
>                                , "subcompact"
>                                , "compact"
>                                , "midsize"
>                                , "minivan"
>                                , "suv"
>                                , "pickup"
>                                )
>                    )
>
> class_colours <- rainbow( length( levels( mpg$classf ) ) )
> ggplot( mpg, aes( x = classf, y = cty, colour=classf ) ) +
>  geom_boxplot() +
>  scale_colour_manual( name="Class", values = class_colours )
>
>
>
>
> On January 23, 2019 3:12:26 PM PST, greg holly <mak.hholly at gmail.com>
> wrote:
> >Hi Dear all;
> >
> >I am getting the "sufficient values in manual scale. 10 needed but only
> >7
> >provided." problem when running the followings. Your help is highly
> >appreciated.
> >
> >Regards,
> >Greg
> >
> >p2<-p1+scale_color_manual(name="Diseases",
> >labels=c("Myocardial Infarction", "Coronary artery disease", "Stroke",
> >"Hypertension", "Depression Anxiety Emotional Problems",  "Circulatory
> >Problems", "Diabetes"),
> >
> >values=c("Myocardial Infarction"="red",  "Coronary artery
> >disease"="purple","Stroke"="darkgreen",
> > "Hypertension"="orange",  "Depression Anxiety Emotional
> >Problems"="darkblue",
> > "Circulatory  Problems"="darkred","Diabetes"="blue"))
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Jan 24 05:11:48 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 24 Jan 2019 09:41:48 +0530
Subject: [R] 
 Unable to compute Confidence Intervals from output from MARSS
 package
In-Reply-To: <BN7PR02MB507371A8C12D9C18B6CEF3CAEA990@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <CAC8=1epqv3p08ONpizaovKzfdDG2u739j5o9p2kB+1_U6p4YhA@mail.gmail.com>
 <BN7PR02MB507371A8C12D9C18B6CEF3CAEA990@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CAC8=1eoyCYNeuUG0ToOzA3i8mvu=kyHf5_gB3mZWdpxKOt4Emg@mail.gmail.com>

Dear Bill,

Appreciate all your effort. I hope some one here can respond to this query.

Many thanks,
Ashim




On Thu, Jan 24, 2019 at 12:49 AM Bill Poling <Bill.Poling at zelis.com> wrote:

>
> Ashim.
>
> I see where I was mistaken, using MARSSparamsCIs(fit) <--Somehow I got an
> s in between param & Cis.
>
> I now get new error similarly as you, my apologies.
>
> final <- MARSSparamCIs(fit)
> Error in dpari[time.varying] <- dparmat(MLEobj, time.varying, t = t) :
>  replacement has length zero
>
> WHP
>
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ashim Kapoor
> Sent: Wednesday, January 23, 2019 1:38 AM
> To: r-help at r-project.org
> Subject: [R] Unable to compute Confidence Intervals from output from MARSS
> package
>
> Dear All,
>
> I am trying to use this package --->
> https://cran.r-project.org/web/packages/MARSS/index.html
> I am reading this book which shows some examples based on the above package
> ---> https://nwfsc-timeseries.github.io/atsa-labs/
>
> In a few words, the incantation MARSS(...) estimates the parameters and
> MARSSparamCIs should return the confidence intervals. My problem is that
> MARSSparamCIs returns this error :-
>
> > MARSSparamCIs(fit)
> Error in MARSSharveyobsFI(MLEobj) : replacement has length zero
> >
>
> ### This page and the next page, explains the jargon used :
>
> https://nwfsc-timeseries.github.io/atsa-labs/sec-dlm-example-of-a-univariate-dlm.html
>
> ### Here is a MWE to recreate the error :-
>
> # This is a Time Varying Parameters regression
> # Here a is fixed and b is doing a RW.
>
> x1 <- rnorm(1000)
> b <- cumsum(rnorm(1000, sd = sqrt(.6)))
> y <- 1 + b*x1 + rnorm(1000)
>
> Z = array(NA,c(1,2,1000))
> Z[1,1,] = rep(1,1000)
> Z[1,2,] = x1
>
> mod2.list = list ( B = matrix(c(1,0,0,1),nrow = 2 , byrow = T), U =
> matrix(0,2,1),
> Q = matrix(list(0,0,0,"s2b"),2,2), Z= Z, A = matrix(0), R = matrix("r"))
>
> fit = MARSS(as.vector(y), model = mod2.list,inits =
> list(x0=matrix(0,nrow=2,ncol=1)))
>
> MARSSparamsCIs(fit)
>
> # The above will give this error :
> Error in MARSSharveyobsFI(MLEobj) : replacement has length zero
>
> Best Regards,
> Ashim
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> Confidentiality Notice This message is sent from Zelis. This transmission
> may contain information which is privileged and confidential and is
> intended for the personal and confidential use of the named recipient only.
> Such information may be protected by applicable State and Federal laws from
> this disclosure or unauthorized use. If the reader of this message is not
> the intended recipient, or the employee or agent responsible for delivering
> the message to the intended recipient, you are hereby notified that any
> disclosure, review, discussion, copying, or taking any action in reliance
> on the contents of this transmission is strictly prohibited. If you have
> received this transmission in error, please contact the sender immediately.
> Zelis, 2018.
>
>
>

	[[alternative HTML version deleted]]


From @|ek@@ndre@g@v@@he||@hv||| @end|ng |rom |||@un|@edu@ge  Thu Jan 24 07:50:24 2019
From: @|ek@@ndre@g@v@@he||@hv||| @end|ng |rom |||@un|@edu@ge (Aleksandre Gavashelishvili)
Date: Thu, 24 Jan 2019 11:50:24 +0500
Subject: [R] Vectorizing a for-loop for cross-validation in R
In-Reply-To: <CAGgJW75hz4y1gX6UHnBn=5M2x6OsB3m6OrRoGWE6Hm8wRLRDJg@mail.gmail.com>
References: <CAHyGbpaBQjzDNAC4Ynrm6cDZxKes3Sz=POPq6GytrWP7MKQxdA@mail.gmail.com>
 <48B26F2C-AEFF-4C7E-B39B-50A816428D87@ucsd.edu>
 <CAGgJW75hz4y1gX6UHnBn=5M2x6OsB3m6OrRoGWE6Hm8wRLRDJg@mail.gmail.com>
Message-ID: <CAHyGbpYHWW0CT0LESr75Be2uZeS_Ag3iO1s=o--1w0bbs3o7sg@mail.gmail.com>

Before posting on the r-help list I did run Rprof(). In my posting I asked
for help with re-writing the specific script into sapply() or
foreach()/doParallel format.

Thanks anyway for your time and suggestions,
Lexo

On Thu, Jan 24, 2019 at 12:38 AM Eric Berger <ericjberger at gmail.com> wrote:

> Charles writes about saving execution time by eliminating redundancies.
> If you see redundancies related to calling a time-consuming function
> multiple times with the same arguments, a very easy way to speed up your
> program is to memoise the functions using the package memoise.
>
> HTH,
> Eric
>
>
>
>
> On Wed, Jan 23, 2019 at 8:34 PM Berry, Charles <ccberry at ucsd.edu> wrote:
>
>> See inline.
>>
>> > On Jan 23, 2019, at 2:17 AM, Aleksandre Gavashelishvili <
>> aleksandre.gavashelishvili at iliauni.edu.ge> wrote:
>> >
>> > I'm trying to speed up a script that otherwise takes days to handle
>> larger
>> > data sets. So, is there a way to completely vectorize or paralellize the
>> > following script:
>> >
>> >                *# k-fold cross validation*
>> >
>> > df <- trees # a data frame 'trees' from R.
>> > df <- df[sample(nrow(df)), ] # randomly shuffles the data.
>> > k <- 10 # Number of folds. Note k=nrow(df) in the leave-one-out cross
>> > validation.
>> > folds <- cut(seq(from=1, to=nrow(df)), breaks=k, labels=FALSE) # creates
>> > unique numbers for k equally size folds.
>> > df$ID <- folds # adds fold IDs.
>> > df[paste("pred", 1:3, sep="")] <- NA # adds multiple columns "pred1"
>> > "pred2" "pred3" to speed up the following loop.
>> >
>> > library(mgcv)
>> >
>>
>> Rprof()
>>
>> replicate(100, {
>>
>>
>> > for(i in 1:k) {
>> >  # looping for different models:
>> >  m1 <- gam(Volume ~ s(Height), data=df, subset=(ID != i))
>> >  m2 <- gam(Volume ~ s(Girth), data=df, subset=(ID != i))
>> >  m3 <- gam(Volume ~ s(Girth) + s(Height), data=df, subset=(ID != i))
>> >
>> >  # looping for predictions:
>> >  df[df$ID==i, "pred1"] <- predict(m1, df[df$ID==i, ], type="response")
>> >  df[df$ID==i, "pred2"] <- predict(m2, df[df$ID==i, ], type="response")
>> >  df[df$ID==i, "pred3"] <- predict(m3, df[df$ID==i, ], type="response")
>> > }
>> >
>>
>> })
>>
>> Rprof(NULL)
>>
>> summaryRprof()
>>
>> ## read ?Rprof to get a sense of what it does
>>
>> ## read the summary to determine where time is being spent.
>>
>> ## the result was surprising to me. YMMV.
>>
>> ## there may be redundancies that you can eliminate by
>> ##  - doing the setup within gam() one time and saving it
>> ##  - calling the worker functions by modifying the setup
>> ##    in a loop or function and saving the results
>>
>>
>> > # calculating residuals:
>> > df$res1 <- with(df, Volume - pred1)
>> > df$res2 <- with(df, Volume - pred2)
>> > df$res3 <- with(df, Volume - pred3)
>> >
>> > Model <- paste("m", 1:3, sep="") # creates a vector of model names.
>> >
>> > # creating a vector of mean-square errors (MSE):
>> > MSE <- with(df, c(
>> >  sum(res1^2) / nrow(df),
>> >  sum(res2^2) / nrow(df),
>> >  sum(res3^2) / nrow(df)
>> > ))
>> >
>> > model.mse <- data.frame(Model, MSE) # creates a data frame of model
>> names
>> > and mean-square errors.
>> > model.mse <- model.mse[order(model.mse$MSE), ] # rearranges the previous
>> > data frame in order of increasing mean-square errors.
>> >
>> > I'd appreciate any help. This code takes several days if run on >=30,000
>> > different GAM models and 3 predictors. Could you please help with
>> > re-writing the script into sapply() or foreach()/doParallel format?
>> >
>>
>> This is something you should learn to do. It is pretty standard practice.
>> Use the body of your for loop as the body of a function, add arguments, and
>> create a suitable return value. The something like
>>
>>         lapply( 1:k, your.loop.body.function, other.arg1, other.arg2, ...)
>>
>> should work.  If it does, then parallel::mclapply(...) should also work.
>>
>> HTH,
>>
>> Chuck
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Jan 24 15:39:49 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 24 Jan 2019 17:39:49 +0300
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <fc41f3a2-dff3-ec52-8181-a6eb936abf5c@gmail.com>
References: <20190123125301.7e3e43b7@trisector>
 <fc41f3a2-dff3-ec52-8181-a6eb936abf5c@gmail.com>
Message-ID: <20190124173901.7881f386@parabola>

Dear Jan & Duncan,

Thanks for your replies!

On Wed, 23 Jan 2019 09:56:25 -0500
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> Defaults of variables are evaluated in the evaluation frame of the
> call. So the inside() function is created in the evaluation frame,
> and it's environment will be that frame.
 
> When it is called it will create a new evaluation frame (empty in
> your example), with a parent being its environment, i.e. the
> evaluation frame from when it was created, so it will be able to see
> your secret variable.

Nice explanation about closures in R inheriting not only their
explicitly captured variables, but whole environments of evaluation
(not stack) frames where they have been created.

> in my opinion it would be fine to write it as
> 
>   outside <- function(inside = defaultInsideFn) {
>      defaultInsideFn <- function() print(secret)
>      secret <- 'secret'
>      inside()
>   }

I like this idea; I'm going to use it.

-- 
Best regards,
Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 24 15:53:20 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 24 Jan 2019 06:53:20 -0800
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <20190124173901.7881f386@parabola>
References: <20190123125301.7e3e43b7@trisector>
 <fc41f3a2-dff3-ec52-8181-a6eb936abf5c@gmail.com>
 <20190124173901.7881f386@parabola>
Message-ID: <FDD4F76C-769B-4676-82BA-E194753A2C51@dcn.davis.ca.us>

My objection to this design pattern is that this gives the default implementation of inside an ability that cannot be altered using functions provided by the caller. You might think this is what you want now but it has the potential to render the code unreusable in the future, which renders the whole idea of making inside an argument to outside pointless. It would be better to also make secret an argument to outside instead of a local variable or to give up on supplying the inside function as an argument.

On January 24, 2019 6:39:49 AM PST, Ivan Krylov <krylov.r00t at gmail.com> wrote:
>Dear Jan & Duncan,
>
>Thanks for your replies!
>
>On Wed, 23 Jan 2019 09:56:25 -0500
>Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> Defaults of variables are evaluated in the evaluation frame of the
>> call. So the inside() function is created in the evaluation frame,
>> and it's environment will be that frame.
> 
>> When it is called it will create a new evaluation frame (empty in
>> your example), with a parent being its environment, i.e. the
>> evaluation frame from when it was created, so it will be able to see
>> your secret variable.
>
>Nice explanation about closures in R inheriting not only their
>explicitly captured variables, but whole environments of evaluation
>(not stack) frames where they have been created.
>
>> in my opinion it would be fine to write it as
>> 
>>   outside <- function(inside = defaultInsideFn) {
>>      defaultInsideFn <- function() print(secret)
>>      secret <- 'secret'
>>      inside()
>>   }
>
>I like this idea; I'm going to use it.

-- 
Sent from my phone. Please excuse my brevity.


From Oyv|nd@L@ng@rud @end|ng |rom @@b@no  Wed Jan 23 23:10:32 2019
From: Oyv|nd@L@ng@rud @end|ng |rom @@b@no (=?iso-8859-1?Q?Langsrud=2C_=D8yvind?=)
Date: Wed, 23 Jan 2019 22:10:32 +0000
Subject: [R] [R-pkgs] MANOVA for collinear responses with rotation testing
 (ffmanova) + Synthetic data (RegSDC)
Message-ID: <20190124080515.0576E503@hypatia.math.ethz.ch>

Hi,

Package ffmanova originally released on CRAN in 2006 has now been updated to Version 1.0. It has been a stable working horse and the changes are cosmetic.

Package RegSDC (Version: 0.2.0) is a new package on CRAN. The two packages are theoretically related and both make use of conditioned multivariate normal simulations - rotation testing in ffmanova and synthetic data generation in RegSDC.

Package ffmanova is mainly meant as a package for multivariate responses, but it also involves a general contribution to ANOVA testing in linear models. The approach to sums of squares (Type II*) is invariant to scale changes of continuous variables and pitfalls are avoided. Try to run code below.


ffmanova: Fifty-Fifty MANOVA

General linear modeling with multiple responses (MANCOVA). An overall p-value for each model term is calculated by the 50-50 MANOVA method by Langsrud (2002) <https://10.1111/1467-9884.00320>, which handles collinear responses. Rotation testing, described by Langsrud (2005) <https://10.1007/s11222-005-4789-5>, is used to compute adjusted single response p-values according to familywise error rates and false discovery rates (FDR). The approach to FDR is described in the appendix of Moen et al. (2005) <https://10.1128/AEM.71.4.2086-2094.2005>. Unbalanced designs are handled by Type II sums of squares as argued in Langsrud (2003) <https://10.1023/A:1023260610025>. Furthermore, the Type II philosophy is extended to continuous design variables as described in Langsrud et al. (2007) <https://10.1080/02664760701594246>. This means that the method is invariant to scale changes and that common pitfalls are avoided.


RegSDC: Information Preserving Regression-Based Tools for Statistical Disclosure Control

Information Preserving Regression-Based Tools for Statistical Disclosure Control
Implementation of the methods described in the paper with the above title: Langsrud, ?. (2019) <https://10.1007/s11222-018-9848-9>. Open view-only version at <https://rdcu.be/bfeWQ>. The package can be used to generate synthetic or hybrid continuous microdata, and the relationship to the original data can be controlled in several ways.


Best,
?yvind Langsrud


set.seed(123)
z <- 1:9
x <- c(0, 0, 0, 10, 10, 10, 1, 1, 1)
y <- rnorm(9)/10 + x  # y depends strongly on x
z100 <- z + 100  # change of scale (origin)
x100 <- x + 100  # change of scale (origin)
library(car)  # Anova with type II as default
library(ffmanova)

# Type III depends on scale
Anova(lm(y ~ factor(x) * z), type = 3)
Anova(lm(y ~ factor(x) * z100), type = 3)

# Even Type II depends on scale
Anova(lm(y ~ x + I(x^2)), type = 2)
Anova(lm(y ~ x100 + I(x100^2)), type = 2)

# Type II* within ffmanova is invariant
ffmanova(y ~ x100 + I(x100^2))
ffmanova(y ~ z * (x100 + I(x100^2)))

# Type I for comparison
anova(lm(y ~ x100 + I(x100^2)))  # same as ffmanova
anova(lm(y ~ z * (x100 + I(x100^2))))  # but here z is significant

	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From reichm@@j m@iii@g oii sbcgiob@i@@et  Fri Jan 25 04:51:05 2019
From: reichm@@j m@iii@g oii sbcgiob@i@@et (reichm@@j m@iii@g oii sbcgiob@i@@et)
Date: Thu, 24 Jan 2019 21:51:05 -0600
Subject: [R] Tukey Test
Message-ID: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>

R-Help

 

There is an R library that will perform a Tukey test which prints out the
Tukey groups (A, B, C, etc) and I don't recall the library. It was
agriculture or something like that. 

 

And is there a library that will product the Tukey, Bonferonni, Scheffe, and
Dunnett comparison tables?

 

Jeff Reichmqn


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 25 05:04:10 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 24 Jan 2019 20:04:10 -0800
Subject: [R] Tukey Test
In-Reply-To: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
References: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
Message-ID: <CAGxFJbSC6SDW_pE5cTfNXeSKZ3EKkawiWyK35rZjnL3Zw8xHyA@mail.gmail.com>

In the age of google, Search!

e.g. on "tukey test" at rseek.org

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 24, 2019 at 7:51 PM <reichmanj at sbcglobal.net> wrote:

> R-Help
>
>
>
> There is an R library that will perform a Tukey test which prints out the
> Tukey groups (A, B, C, etc) and I don't recall the library. It was
> agriculture or something like that.
>
>
>
> And is there a library that will product the Tukey, Bonferonni, Scheffe,
> and
> Dunnett comparison tables?
>
>
>
> Jeff Reichmqn
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Jan 25 05:11:19 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 25 Jan 2019 17:11:19 +1300
Subject: [R] [FORGED]  Tukey Test
In-Reply-To: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
References: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
Message-ID: <824c5c95-2d35-8c62-7b76-f0ff332ddd03@auckland.ac.nz>


On 1/25/19 4:51 PM, reichmanj at sbcglobal.net wrote:

> R-Help
> 
>   
> 
> There is an R library that will perform a Tukey test ...

<SNIP>

Surely you mean *package*.

cheers,

Rolf Turner

P.S. You are probably thinking of the agricolae *package*.  There is 
also the TukeyC package, which might be relevant.  Likewise the multcomp 
package.  And of course there is the TukeyHSD() function in the default 
package "stats".

GIYF.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rmh @end|ng |rom temp|e@edu  Fri Jan 25 06:00:10 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 25 Jan 2019 00:00:10 -0500
Subject: [R] [FORGED] Tukey Test
In-Reply-To: <824c5c95-2d35-8c62-7b76-f0ff332ddd03@auckland.ac.nz>
References: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
 <824c5c95-2d35-8c62-7b76-f0ff332ddd03@auckland.ac.nz>
Message-ID: <CAGx1TMAS82B5tkUqA745why6ecsAiQWxoA-+YC7mD5+HA5KpoA@mail.gmail.com>

and the mmcplot in the HH package which plots the results from the
multcomp package.

On Thu, Jan 24, 2019 at 11:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On 1/25/19 4:51 PM, reichmanj at sbcglobal.net wrote:
>
> > R-Help
> >
> >
> >
> > There is an R library that will perform a Tukey test ...
>
> <SNIP>
>
> Surely you mean *package*.
>
> cheers,
>
> Rolf Turner
>
> P.S. You are probably thinking of the agricolae *package*.  There is
> also the TukeyC package, which might be relevant.  Likewise the multcomp
> package.  And of course there is the TukeyHSD() function in the default
> package "stats".
>
> GIYF.
>
> R. T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Jan 25 08:57:40 2019
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 25 Jan 2019 02:57:40 -0500
Subject: [R] Tukey Test
In-Reply-To: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
References: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
Message-ID: <CAE9stmdfzY_UeCJZyrAvYi_eWRE8NOVtnPk8AJtvJmLfo956fQ@mail.gmail.com>

check this:

https://www.r-graph-gallery.com/84-tukey-test/

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Jan 24, 2019 at 10:51 PM <reichmanj at sbcglobal.net> wrote:

> R-Help
>
>
>
> There is an R library that will perform a Tukey test which prints out the
> Tukey groups (A, B, C, etc) and I don't recall the library. It was
> agriculture or something like that.
>
>
>
> And is there a library that will product the Tukey, Bonferonni, Scheffe,
> and
> Dunnett comparison tables?
>
>
>
> Jeff Reichmqn
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Jan 25 09:10:40 2019
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 25 Jan 2019 03:10:40 -0500
Subject: [R] Tukey Test
In-Reply-To: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
References: <000501d4b461$3367e020$9a37a060$@sbcglobal.net>
Message-ID: <CAE9stmdPjt6PUh_2fvY0Cc4xab0YvbAbTCj4+h-ukjEAGmfddw@mail.gmail.com>

how about this one too?

https://www.r-bloggers.com/anova-and-tukeys-test-on-r/


abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Jan 24, 2019 at 10:51 PM <reichmanj at sbcglobal.net> wrote:

> R-Help
>
>
>
> There is an R library that will perform a Tukey test which prints out the
> Tukey groups (A, B, C, etc) and I don't recall the library. It was
> agriculture or something like that.
>
>
>
> And is there a library that will product the Tukey, Bonferonni, Scheffe,
> and
> Dunnett comparison tables?
>
>
>
> Jeff Reichmqn
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Jan 25 10:30:48 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 25 Jan 2019 09:30:48 +0000
Subject: [R] lm model......
Message-ID: <SL2P216MB00910E135E07AE2076920BB2C89B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am a day trader based in INDIA. I use R for my research.

I have simple question: Does the predict() function in R in linear regression model take into account the residuals?
Or it just calculates the new value from the fitted coefficients of the formula,  as got from the lm model?

I could have looked into the code of predict() function but I thought I could get more insightful answer from experts in this mailing list...

very many thanks for your time and effort....
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Jan 25 14:32:19 2019
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Fri, 25 Jan 2019 13:32:19 +0000 (UTC)
Subject: [R] [FORGED]  Tukey Test
References: <2098952172.1049419.1548423139204.ref@mail.yahoo.com>
Message-ID: <2098952172.1049419.1548423139204@mail.yahoo.com>

Rolf

That's it the aricolae "package". Thank you.

Jeff
--------------------------------------------
On Thu, 1/24/19, Rolf Turner <r.turner at auckland.ac.nz> wrote:

 Subject: Re: [FORGED] [R] Tukey Test
 To: reichmanj at sbcglobal.net
 Cc: r-help at r-project.org
 Date: Thursday, January 24, 2019, 10:11 PM


 On 1/25/19 4:51 PM, reichmanj at sbcglobal.net
 wrote:

 > R-Help
 > 
 >?  
 > 
 > There is an R
 library that will perform a Tukey test ...

 <SNIP>

 Surely you mean *package*.

 cheers,

 Rolf Turner

 P.S. You are probably thinking of the agricolae
 *package*.? There is 
 also the TukeyC
 package, which might be relevant.? Likewise the multcomp

 package.? And of course there is the
 TukeyHSD() function in the default 
 package
 "stats".

 GIYF.

 R. T.

 -- 
 Honorary Research Fellow
 Department of Statistics
 University of Auckland
 Phone:
 +64-9-373-7599 ext. 88276


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Fri Jan 25 14:45:21 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Fri, 25 Jan 2019 14:45:21 +0100
Subject: [R] Purr and Basic Functional Programming Tasks
Message-ID: <20190125134521.rtsy7te2nsbcs5x5@chicca2>

Dear All,
I am making my baby steps with the tidyverse purr package and I am
stuck with some probably trivial tasks.
Consider the following data set


zz<-list(structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001, 
2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(22393349.081, 
23000574.372, 21682040.898, 21671102.853, 34361300.338, 35297814.942, 
34745691.204, 35878883.117, 11967951.257, 12297240.57, 13063650.306, 
14207780.264), relation = c("EU28-Algeria", "EU28-Algeria", "EU28-Algeria", 
"EU28-Algeria", "World-Algeria", "World-Algeria", "World-Algeria", 
"World-Algeria", "Extra EU28-Algeria", "Extra EU28-Algeria", 
"Extra EU28-Algeria", "Extra EU28-Algeria"), g_rate = c(0.736046372770467, 
0.0271163231905857, -0.0573261107603093, -0.000504474880914325, 
0.614846575418334, 0.0272549232650638, -0.0156418673197543,    0.0326138831530727, 
0.428272657063707, 0.0275142592018328, 0.0623237165799383, 0.0875811837579971
)), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
)), structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001, 
2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(9233346.648, 7869288.171, 
7271485.687, 6395999.102, 21393949.287, 19851236.26, 19449339.887, 
16055014.309, 12160602.639, 11981948.089, 12177854.2, 9659015.207
), relation = c("EU28-Egypt", "EU28-Egypt", "EU28-Egypt", "EU28-Egypt", 
"World-Egypt", "World-Egypt", "World-Egypt", "World-Egypt", "Extra EU28-Egypt", 
"Extra EU28-Egypt", "Extra EU28-Egypt", "Extra EU28-Egypt"), 
g_rate = c(0.0970653722744164, -0.147731751985664, -0.0759665259436081, 
-0.120399959882366, 0.124744629514854, -0.0721097823643728, 
-0.0202454077789513, -0.174521376957825, 0.146712116047648, 
-0.0146912579338002, 0.0163501051368976, -0.206837670383671
)), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
)))

I am capable of doing very simple stuff with maps for instance taking the iteratively the mean of a certain column

map(zz, function(x) mean(x$tot_i))

or filtering the values of the years

map(zz, function(x) filter(x, year==2000))

however, I bang my head against the wall as soon as I want to add a bit of complexity. For instance

1)    I want to iteratively group the data in zz by relation and summarise them by taking the average of tot_i and

2)    Given a list of years

    ll<-list(c(2000, 2001), c(2001, 2003))

I would like to filter the two elements of the zz list according to the years listed in ll.

I would then have plenty of other operations to carry out on the data, but already understanding 1 and 2 would take me a long way from where I am stuck now.

Any suggestion is welcome.
Cheers

Lorenzo


From jho|tm@n @end|ng |rom gm@||@com  Fri Jan 25 16:42:26 2019
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 25 Jan 2019 07:42:26 -0800
Subject: [R] Purr and Basic Functional Programming Tasks
In-Reply-To: <20190125134521.rtsy7te2nsbcs5x5@chicca2>
References: <20190125134521.rtsy7te2nsbcs5x5@chicca2>
Message-ID: <CAAxdm-6niK-2ha_gtbXfrEg8TVnThoPudFxHunsRaECgFYzF6g@mail.gmail.com>

Does this answer the first question?

> rel <- map(zz, function(x){
+   group_by(x, relation) %>% summarise(tot = mean(tot_i))
+ })
> rel
[[1]]
# A tibble: 3 x 2
  relation                 tot
  <chr>                  <dbl>
1 EU28-Algeria       22186767.
2 Extra EU28-Algeria 12884156.
3 World-Algeria      35070922.

[[2]]
# A tibble: 3 x 2
  relation               tot
  <chr>                <dbl>
1 EU28-Egypt        7692530.
2 Extra EU28-Egypt 11494855.
3 World-Egypt      19187385.

>

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Fri, Jan 25, 2019 at 5:45 AM Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I am making my baby steps with the tidyverse purr package and I am
> stuck with some probably trivial tasks.
> Consider the following data set
>
>
> zz<-list(structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(22393349.081,
> 23000574.372, 21682040.898, 21671102.853, 34361300.338, 35297814.942,
> 34745691.204, 35878883.117, 11967951.257, 12297240.57, 13063650.306,
> 14207780.264), relation = c("EU28-Algeria", "EU28-Algeria",
> "EU28-Algeria",
> "EU28-Algeria", "World-Algeria", "World-Algeria", "World-Algeria",
> "World-Algeria", "Extra EU28-Algeria", "Extra EU28-Algeria",
> "Extra EU28-Algeria", "Extra EU28-Algeria"), g_rate = c(0.736046372770467,
> 0.0271163231905857, -0.0573261107603093, -0.000504474880914325,
> 0.614846575418334, 0.0272549232650638, -0.0156418673197543,
> 0.0326138831530727,
> 0.428272657063707, 0.0275142592018328, 0.0623237165799383,
> 0.0875811837579971
> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
> )), structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(9233346.648, 7869288.171,
> 7271485.687, 6395999.102, 21393949.287, 19851236.26, 19449339.887,
> 16055014.309, 12160602.639, 11981948.089, 12177854.2, 9659015.207
> ), relation = c("EU28-Egypt", "EU28-Egypt", "EU28-Egypt", "EU28-Egypt",
> "World-Egypt", "World-Egypt", "World-Egypt", "World-Egypt", "Extra
> EU28-Egypt",
> "Extra EU28-Egypt", "Extra EU28-Egypt", "Extra EU28-Egypt"),
> g_rate = c(0.0970653722744164, -0.147731751985664, -0.0759665259436081,
> -0.120399959882366, 0.124744629514854, -0.0721097823643728,
> -0.0202454077789513, -0.174521376957825, 0.146712116047648,
> -0.0146912579338002, 0.0163501051368976, -0.206837670383671
> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
> )))
>
> I am capable of doing very simple stuff with maps for instance taking the
> iteratively the mean of a certain column
>
> map(zz, function(x) mean(x$tot_i))
>
> or filtering the values of the years
>
> map(zz, function(x) filter(x, year==2000))
>
> however, I bang my head against the wall as soon as I want to add a bit of
> complexity. For instance
>
> 1)    I want to iteratively group the data in zz by relation and summarise
> them by taking the average of tot_i and
>
> 2)    Given a list of years
>
>     ll<-list(c(2000, 2001), c(2001, 2003))
>
> I would like to filter the two elements of the zz list according to the
> years listed in ll.
>
> I would then have plenty of other operations to carry out on the data, but
> already understanding 1 and 2 would take me a long way from where I am
> stuck now.
>
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jho|tm@n @end|ng |rom gm@||@com  Fri Jan 25 16:46:50 2019
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 25 Jan 2019 07:46:50 -0800
Subject: [R] Purr and Basic Functional Programming Tasks
In-Reply-To: <20190125134521.rtsy7te2nsbcs5x5@chicca2>
References: <20190125134521.rtsy7te2nsbcs5x5@chicca2>
Message-ID: <CAAxdm-5SXywDsRWdD5cZSn9afvzyNhUCDrVnq5daoOW-OPrz-g@mail.gmail.com>

Try this for the second question:

> years <- map2(zz,
+               list(c(2000, 2001), c(2001, 2003)),
+               ~ filter(.x, year %in% .y)
+ )
> years
[[1]]
# A tibble: 6 x 4
   year     tot_i relation           g_rate
  <dbl>     <dbl> <chr>               <dbl>
1  2000 22393349. EU28-Algeria       0.736
2  2001 23000574. EU28-Algeria       0.0271
3  2000 34361300. World-Algeria      0.615
4  2001 35297815. World-Algeria      0.0273
5  2000 11967951. Extra EU28-Algeria 0.428
6  2001 12297241. Extra EU28-Algeria 0.0275

[[2]]
# A tibble: 6 x 4
   year     tot_i relation          g_rate
  <dbl>     <dbl> <chr>              <dbl>
1  2001  7869288. EU28-Egypt       -0.148
2  2003  6395999. EU28-Egypt       -0.120
3  2001 19851236. World-Egypt      -0.0721
4  2003 16055014. World-Egypt      -0.175
5  2001 11981948. Extra EU28-Egypt -0.0147
6  2003  9659015. Extra EU28-Egypt -0.207

>

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Fri, Jan 25, 2019 at 5:45 AM Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I am making my baby steps with the tidyverse purr package and I am
> stuck with some probably trivial tasks.
> Consider the following data set
>
>
> zz<-list(structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(22393349.081,
> 23000574.372, 21682040.898, 21671102.853, 34361300.338, 35297814.942,
> 34745691.204, 35878883.117, 11967951.257, 12297240.57, 13063650.306,
> 14207780.264), relation = c("EU28-Algeria", "EU28-Algeria",
> "EU28-Algeria",
> "EU28-Algeria", "World-Algeria", "World-Algeria", "World-Algeria",
> "World-Algeria", "Extra EU28-Algeria", "Extra EU28-Algeria",
> "Extra EU28-Algeria", "Extra EU28-Algeria"), g_rate = c(0.736046372770467,
> 0.0271163231905857, -0.0573261107603093, -0.000504474880914325,
> 0.614846575418334, 0.0272549232650638, -0.0156418673197543,
> 0.0326138831530727,
> 0.428272657063707, 0.0275142592018328, 0.0623237165799383,
> 0.0875811837579971
> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
> )), structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(9233346.648, 7869288.171,
> 7271485.687, 6395999.102, 21393949.287, 19851236.26, 19449339.887,
> 16055014.309, 12160602.639, 11981948.089, 12177854.2, 9659015.207
> ), relation = c("EU28-Egypt", "EU28-Egypt", "EU28-Egypt", "EU28-Egypt",
> "World-Egypt", "World-Egypt", "World-Egypt", "World-Egypt", "Extra
> EU28-Egypt",
> "Extra EU28-Egypt", "Extra EU28-Egypt", "Extra EU28-Egypt"),
> g_rate = c(0.0970653722744164, -0.147731751985664, -0.0759665259436081,
> -0.120399959882366, 0.124744629514854, -0.0721097823643728,
> -0.0202454077789513, -0.174521376957825, 0.146712116047648,
> -0.0146912579338002, 0.0163501051368976, -0.206837670383671
> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
> )))
>
> I am capable of doing very simple stuff with maps for instance taking the
> iteratively the mean of a certain column
>
> map(zz, function(x) mean(x$tot_i))
>
> or filtering the values of the years
>
> map(zz, function(x) filter(x, year==2000))
>
> however, I bang my head against the wall as soon as I want to add a bit of
> complexity. For instance
>
> 1)    I want to iteratively group the data in zz by relation and summarise
> them by taking the average of tot_i and
>
> 2)    Given a list of years
>
>     ll<-list(c(2000, 2001), c(2001, 2003))
>
> I would like to filter the two elements of the zz list according to the
> years listed in ll.
>
> I would then have plenty of other operations to carry out on the data, but
> already understanding 1 and 2 would take me a long way from where I am
> stuck now.
>
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@k@hho||y @end|ng |rom gm@||@com  Fri Jan 25 18:58:04 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Fri, 25 Jan 2019 11:58:04 -0600
Subject: [R] positive deviance plot for Binomial distribution
Message-ID: <CAM9Qe4iW+xkUhFjCnsZPFChgZ_RpWko8cP1_MLTkpNvPq0nfyQ@mail.gmail.com>

Hi Dear all;

I have binomially distributed data (a small portion is given below) and I
would like to create a distribution plot for positive deviance with
"Probability of results" at Y axis and "percentage of outcome" at the
x-axis. I wondered anyone knows the name of R  library for this.

Regards,

Greg

provider outcome observation
1               14            27
2                11           33
3                9             17

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Jan 26 14:39:20 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 26 Jan 2019 16:39:20 +0300
Subject: [R] Function in default parameter value closing over variables
 defined later in the enclosing function
In-Reply-To: <FDD4F76C-769B-4676-82BA-E194753A2C51@dcn.davis.ca.us>
References: <20190123125301.7e3e43b7@trisector>
 <fc41f3a2-dff3-ec52-8181-a6eb936abf5c@gmail.com>
 <20190124173901.7881f386@parabola>
 <FDD4F76C-769B-4676-82BA-E194753A2C51@dcn.davis.ca.us>
Message-ID: <20190126163920.550389b9@parabola>

On Thu, 24 Jan 2019 06:53:20 -0800
Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> It would be better to also make secret an argument to outside instead
> of a local variable or to give up on supplying the inside function as
> an argument.

This was in a small, mostly self-contained one-off script that tested
different design of experiment approaches with simulated datasets.

Actually, I should move the "secret" variable to the global level,
together with other global settings like the dataset size and noise
level. There it's accessible to both any functions that might be
interested in it and the user who might want to change it, after all.

-- 
Best regards,
Ivan


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Jan 26 22:15:21 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 27 Jan 2019 02:45:21 +0530
Subject: [R] TIme Zone error
Message-ID: <CA+dpOJnxUtmzLTQA9y=hNoNtZUUpjsCvLbSim1JAKn_UTuVUmw@mail.gmail.com>

Hi,

I want to set a specific Timezone for my R environment, with below syntax:

> Sys.getenv("Asia/Calcutta")

[1] ""

>
But it sets to some blank timezone.

I checked with OlsonNames(), to see available zones for R, where I found
"Asia/Calcutta" available.

I idea why R failed to set timezone properly?

Thanks for your time.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Sat Jan 26 22:40:29 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 26 Jan 2019 13:40:29 -0800
Subject: [R] TIme Zone error
In-Reply-To: <CA+dpOJnxUtmzLTQA9y=hNoNtZUUpjsCvLbSim1JAKn_UTuVUmw@mail.gmail.com>
References: <CA+dpOJnxUtmzLTQA9y=hNoNtZUUpjsCvLbSim1JAKn_UTuVUmw@mail.gmail.com>
Message-ID: <CAF8bMcbrYXungOZUuTPRoFyLiqD5VY74UBocCDPGOdWh8dGpeg@mail.gmail.com>

> Sys.setenv(TZ="US/Eastern")
> as.POSIXlt("2019-01-26 01:19")
[1] "2019-01-26 01:19:00 EST"
> Sys.setenv(TZ="Asia/Calcutta")
> as.POSIXlt("2019-01-26 01:19")
[1] "2019-01-26 01:19:00 IST"

(Sys.getenv("Asia/Calcutta") returns the value of the environment variable
"Asia/Calcutta".  It does not set a value.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Jan 26, 2019 at 1:15 PM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I want to set a specific Timezone for my R environment, with below syntax:
>
> > Sys.getenv("Asia/Calcutta")
>
> [1] ""
>
> >
> But it sets to some blank timezone.
>
> I checked with OlsonNames(), to see available zones for R, where I found
> "Asia/Calcutta" available.
>
> I idea why R failed to set timezone properly?
>
> Thanks for your time.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jan 26 23:44:44 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 26 Jan 2019 14:44:44 -0800
Subject: [R] TIme Zone error
In-Reply-To: <CA+dpOJnxUtmzLTQA9y=hNoNtZUUpjsCvLbSim1JAKn_UTuVUmw@mail.gmail.com>
References: <CA+dpOJnxUtmzLTQA9y=hNoNtZUUpjsCvLbSim1JAKn_UTuVUmw@mail.gmail.com>
Message-ID: <88CFCB4B-A33A-454B-B4E9-FA954024F947@dcn.davis.ca.us>

Read the help file

?as.POSIXct

"" as time zone is not an error.

On January 26, 2019 1:15:21 PM PST, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>I want to set a specific Timezone for my R environment, with below
>syntax:
>
>> Sys.getenv("Asia/Calcutta")
>
>[1] ""
>
>>
>But it sets to some blank timezone.
>
>I checked with OlsonNames(), to see available zones for R, where I
>found
>"Asia/Calcutta" available.
>
>I idea why R failed to set timezone properly?
>
>Thanks for your time.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From e@@w|ek @end|ng |rom gm@||@com  Sun Jan 27 03:32:58 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sat, 26 Jan 2019 21:32:58 -0500
Subject: [R] Create a new list from selected items in another list
Message-ID: <CA+ZkTxvm5p5_ex0AYLa64OgcAQKgxD4zvMtpPL9+cGxCPKVaSw@mail.gmail.com>

Hi All--

I have a list which contain variables 0s at the end of each vector on
the isit. I want to create a new list with only numbers > 0.
It seems simple, but i tried several option, none of which worked.

CCC <-  list(A=c(1,2,3,0,0,0,0), B=c(2,3,4,5,0,0,0,0,0,0))

for (i in 1:length(CCC)) {
  for(j in 1:length(CCC[[i]])){
    if(CCC[[i]][j]>0)
    BBB[[i]][j] <- CCC[[i]][j] #BBB <- AAA
    }
}
 desired output is
$A
[1] 1 2 3

$B
[1] 2 3 4 5

Thanks-EK


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 27 04:10:56 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 26 Jan 2019 19:10:56 -0800
Subject: [R] Create a new list from selected items in another list
In-Reply-To: <CA+ZkTxvm5p5_ex0AYLa64OgcAQKgxD4zvMtpPL9+cGxCPKVaSw@mail.gmail.com>
References: <CA+ZkTxvm5p5_ex0AYLa64OgcAQKgxD4zvMtpPL9+cGxCPKVaSw@mail.gmail.com>
Message-ID: <48368B80-591B-4E43-AF78-5328161D842D@dcn.davis.ca.us>

BBB <- lapply( CCC, function( v ) v[ 0<v ] )

On January 26, 2019 6:32:58 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
>Hi All--
>
>I have a list which contain variables 0s at the end of each vector on
>the isit. I want to create a new list with only numbers > 0.
>It seems simple, but i tried several option, none of which worked.
>
>CCC <-  list(A=c(1,2,3,0,0,0,0), B=c(2,3,4,5,0,0,0,0,0,0))
>
>for (i in 1:length(CCC)) {
>  for(j in 1:length(CCC[[i]])){
>    if(CCC[[i]][j]>0)
>    BBB[[i]][j] <- CCC[[i]][j] #BBB <- AAA
>    }
>}
> desired output is
>$A
>[1] 1 2 3
>
>$B
>[1] 2 3 4 5
>
>Thanks-EK
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Sun Jan 27 16:25:17 2019
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Sun, 27 Jan 2019 16:25:17 +0100
Subject: [R] cumulative data monthly
Message-ID: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>

Dear all,

I have a set of data with has hourly value:

# ID
# Lo
# L
# Q
Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
.....
.....

I was able to read it,  create my-own data frame and to plot the total
cumulative function.
This is basically what I have done:

dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
na.strings="-999",skip = 6)
colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC", "RAD",
"CC","FOG")

dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d %H:%M"))


P <- cumsum(dati$PREC)
plot(dati$DATAORA, P)

I would like to select the data according to an starting and ending date.
In addition, I would like to plot the monthly and not the total one.
I mean, I would like to have a cumulative plot for each month of the
selected year.

I am struggling with "ddply" but probably it is the wrong way.

Could someone help me?  Really Really thanks,


Diego

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 27 16:41:20 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Jan 2019 07:41:20 -0800
Subject: [R] cumulative data monthly
In-Reply-To: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
Message-ID: <25969886-A8C2-4545-A518-CE1219D7AFE4@dcn.davis.ca.us>

Are you looking for a plot where each point represents a month? Or a plot  where each point represents the accumulated precipitation so far that month? The latter seems closer to your computations so far, but doesn't seem like a typical way to present precipitation data...

On January 27, 2019 7:25:17 AM PST, Diego Avesani <diego.avesani at gmail.com> wrote:
>Dear all,
>
>I have a set of data with has hourly value:
>
># ID
># Lo
># L
># Q
>Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
>yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
>2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
>2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
>2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
>2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
>.....
>.....
>
>I was able to read it,  create my-own data frame and to plot the total
>cumulative function.
>This is basically what I have done:
>
>dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
>na.strings="-999",skip = 6)
>colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC",
>"RAD",
>"CC","FOG")
>
>dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
>%H:%M"))
>
>
>P <- cumsum(dati$PREC)
>plot(dati$DATAORA, P)
>
>I would like to select the data according to an starting and ending
>date.
>In addition, I would like to plot the monthly and not the total one.
>I mean, I would like to have a cumulative plot for each month of the
>selected year.
>
>I am struggling with "ddply" but probably it is the wrong way.
>
>Could someone help me?  Really Really thanks,
>
>
>Diego
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jan 27 19:03:44 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 27 Jan 2019 18:03:44 +0000
Subject: [R] cumulative data monthly
In-Reply-To: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
Message-ID: <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>

Hello,

See if the following can get you started.
It uses package CRAN zoo, function as.yearmon.

dati$MES <- zoo::as.yearmon(dati$DATAORA)
PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)

plot(dati$DATAORA, PMES)


Hope this helps,

Rui Barradas

?s 15:25 de 27/01/2019, Diego Avesani escreveu:
> Dear all,
> 
> I have a set of data with has hourly value:
> 
> # ID
> # Lo
> # L
> # Q
> Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
> yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
> 2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
> 2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
> 2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
> 2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
> .....
> .....
> 
> I was able to read it,  create my-own data frame and to plot the total
> cumulative function.
> This is basically what I have done:
> 
> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
> na.strings="-999",skip = 6)
> colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC", "RAD",
> "CC","FOG")
> 
> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d %H:%M"))
> 
> 
> P <- cumsum(dati$PREC)
> plot(dati$DATAORA, P)
> 
> I would like to select the data according to an starting and ending date.
> In addition, I would like to plot the monthly and not the total one.
> I mean, I would like to have a cumulative plot for each month of the
> selected year.
> 
> I am struggling with "ddply" but probably it is the wrong way.
> 
> Could someone help me?  Really Really thanks,
> 
> 
> Diego
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 27 21:37:54 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Jan 2019 12:37:54 -0800
Subject: [R] cumulative data monthly
In-Reply-To: <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
Message-ID: <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>

Very succinct, Rui!

One warning to Diego.... automatic data recorders tend to use the local standard timezone year-round. R by default assumes that timestamps converted from character to POSIXct using the current timezone on your computer... which may not be in the same zone that the logger was in but even more commonly the computer follows daylight savings time. This leads to NAs showing up in your converted timestamps in spring and duplicated values in autumn as the data are misinterpreted. The easiest solution can be to use

Sys.setenv( TZ="GMT" )

though if you need the actual timezone you can use a zone name of the form "Etc/GMT+5" (5 hrs west of GMT).

Note that Rui's solution will only work correctly near the month transition if you pretend the data timezone is GMT or UTC. (Technically these are different so your mileage may vary but most implementations treat them as identical and I have not encountered any cases where they differ.)

On January 27, 2019 10:03:44 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>See if the following can get you started.
>It uses package CRAN zoo, function as.yearmon.
>
>dati$MES <- zoo::as.yearmon(dati$DATAORA)
>PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
>
>plot(dati$DATAORA, PMES)
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 15:25 de 27/01/2019, Diego Avesani escreveu:
>> Dear all,
>> 
>> I have a set of data with has hourly value:
>> 
>> # ID
>> # Lo
>> # L
>> # Q
>> Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
>> yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
>> 2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
>> 2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
>> 2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
>> 2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
>> .....
>> .....
>> 
>> I was able to read it,  create my-own data frame and to plot the
>total
>> cumulative function.
>> This is basically what I have done:
>> 
>> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
>> na.strings="-999",skip = 6)
>> colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC",
>"RAD",
>> "CC","FOG")
>> 
>> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
>%H:%M"))
>> 
>> 
>> P <- cumsum(dati$PREC)
>> plot(dati$DATAORA, P)
>> 
>> I would like to select the data according to an starting and ending
>date.
>> In addition, I would like to plot the monthly and not the total one.
>> I mean, I would like to have a cumulative plot for each month of the
>> selected year.
>> 
>> I am struggling with "ddply" but probably it is the wrong way.
>> 
>> Could someone help me?  Really Really thanks,
>> 
>> 
>> Diego
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Sun Jan 27 23:09:38 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Sun, 27 Jan 2019 23:09:38 +0100
Subject: [R] Purr and Basic Functional Programming Tasks
In-Reply-To: <CAAxdm-5SXywDsRWdD5cZSn9afvzyNhUCDrVnq5daoOW-OPrz-g@mail.gmail.com>
References: <20190125134521.rtsy7te2nsbcs5x5@chicca2>
 <CAAxdm-5SXywDsRWdD5cZSn9afvzyNhUCDrVnq5daoOW-OPrz-g@mail.gmail.com>
Message-ID: <20190127220938.jr55bme3m26mo3hh@masha>

Dear Jim,
Thanks a lot for your stellar replies!
They address my questions perfectly.
Cheers

Lorenzo


On Fri, Jan 25, 2019 at 07:46:50AM -0800, jim holtman wrote:
>Try this for the second question:
>
>> years <- map2(zz,
>+               list(c(2000, 2001), c(2001, 2003)),
>+               ~ filter(.x, year %in% .y)
>+ )
>> years
>[[1]]
># A tibble: 6 x 4
>   year     tot_i relation           g_rate
>  <dbl>     <dbl> <chr>               <dbl>
>1  2000 22393349. EU28-Algeria       0.736
>2  2001 23000574. EU28-Algeria       0.0271
>3  2000 34361300. World-Algeria      0.615
>4  2001 35297815. World-Algeria      0.0273
>5  2000 11967951. Extra EU28-Algeria 0.428
>6  2001 12297241. Extra EU28-Algeria 0.0275
>
>[[2]]
># A tibble: 6 x 4
>   year     tot_i relation          g_rate
>  <dbl>     <dbl> <chr>              <dbl>
>1  2001  7869288. EU28-Egypt       -0.148
>2  2003  6395999. EU28-Egypt       -0.120
>3  2001 19851236. World-Egypt      -0.0721
>4  2003 16055014. World-Egypt      -0.175
>5  2001 11981948. Extra EU28-Egypt -0.0147
>6  2003  9659015. Extra EU28-Egypt -0.207
>
>>
>
>Jim Holtman
>*Data Munger Guru*
>
>
>*What is the problem that you are trying to solve?Tell me what you want to
>do, not how you want to do it.*
>
>
>On Fri, Jan 25, 2019 at 5:45 AM Lorenzo Isella <lorenzo.isella at gmail.com>
>wrote:
>
>> Dear All,
>> I am making my baby steps with the tidyverse purr package and I am
>> stuck with some probably trivial tasks.
>> Consider the following data set
>>
>>
>> zz<-list(structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
>> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(22393349.081,
>> 23000574.372, 21682040.898, 21671102.853, 34361300.338, 35297814.942,
>> 34745691.204, 35878883.117, 11967951.257, 12297240.57, 13063650.306,
>> 14207780.264), relation = c("EU28-Algeria", "EU28-Algeria",
>> "EU28-Algeria",
>> "EU28-Algeria", "World-Algeria", "World-Algeria", "World-Algeria",
>> "World-Algeria", "Extra EU28-Algeria", "Extra EU28-Algeria",
>> "Extra EU28-Algeria", "Extra EU28-Algeria"), g_rate = c(0.736046372770467,
>> 0.0271163231905857, -0.0573261107603093, -0.000504474880914325,
>> 0.614846575418334, 0.0272549232650638, -0.0156418673197543,
>> 0.0326138831530727,
>> 0.428272657063707, 0.0275142592018328, 0.0623237165799383,
>> 0.0875811837579971
>> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
>> )), structure(list(year = c(2000, 2001, 2002, 2003, 2000, 2001,
>> 2002, 2003, 2000, 2001, 2002, 2003), tot_i = c(9233346.648, 7869288.171,
>> 7271485.687, 6395999.102, 21393949.287, 19851236.26, 19449339.887,
>> 16055014.309, 12160602.639, 11981948.089, 12177854.2, 9659015.207
>> ), relation = c("EU28-Egypt", "EU28-Egypt", "EU28-Egypt", "EU28-Egypt",
>> "World-Egypt", "World-Egypt", "World-Egypt", "World-Egypt", "Extra
>> EU28-Egypt",
>> "Extra EU28-Egypt", "Extra EU28-Egypt", "Extra EU28-Egypt"),
>> g_rate = c(0.0970653722744164, -0.147731751985664, -0.0759665259436081,
>> -0.120399959882366, 0.124744629514854, -0.0721097823643728,
>> -0.0202454077789513, -0.174521376957825, 0.146712116047648,
>> -0.0146912579338002, 0.0163501051368976, -0.206837670383671
>> )), row.names = c(NA, -12L), class = c("tbl_df", "tbl", "data.frame"
>> )))
>>
>> I am capable of doing very simple stuff with maps for instance taking the
>> iteratively the mean of a certain column
>>
>> map(zz, function(x) mean(x$tot_i))
>>
>> or filtering the values of the years
>>
>> map(zz, function(x) filter(x, year==2000))
>>
>> however, I bang my head against the wall as soon as I want to add a bit of
>> complexity. For instance
>>
>> 1)    I want to iteratively group the data in zz by relation and summarise
>> them by taking the average of tot_i and
>>
>> 2)    Given a list of years
>>
>>     ll<-list(c(2000, 2001), c(2001, 2003))
>>
>> I would like to filter the two elements of the zz list according to the
>> years listed in ll.
>>
>> I would then have plenty of other operations to carry out on the data, but
>> already understanding 1 and 2 would take me a long way from where I am
>> stuck now.
>>
>> Any suggestion is welcome.
>> Cheers
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Sun Jan 27 23:11:28 2019
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Sun, 27 Jan 2019 23:11:28 +0100
Subject: [R] cumulative data monthly
In-Reply-To: <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
 <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
Message-ID: <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>

Dear  Jeff, Dear Rui, Dear all,

I will try Rui's solution as soon as possible.
If I could ask:
As a first step, I would like to follow Jeff's suggestion. I will represent
the precipitation data with a cumulative distribution, one for each year.
This follow that I would like to select the starting date and the ending
date properly form dati$DATA in order to perform the cumulative function.

Could you help me on that.

Again, really really thanks

Diego



On Sun, 27 Jan 2019 at 21:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Very succinct, Rui!
>
> One warning to Diego.... automatic data recorders tend to use the local
> standard timezone year-round. R by default assumes that timestamps
> converted from character to POSIXct using the current timezone on your
> computer... which may not be in the same zone that the logger was in but
> even more commonly the computer follows daylight savings time. This leads
> to NAs showing up in your converted timestamps in spring and duplicated
> values in autumn as the data are misinterpreted. The easiest solution can
> be to use
>
> Sys.setenv( TZ="GMT" )
>
> though if you need the actual timezone you can use a zone name of the form
> "Etc/GMT+5" (5 hrs west of GMT).
>
> Note that Rui's solution will only work correctly near the month
> transition if you pretend the data timezone is GMT or UTC. (Technically
> these are different so your mileage may vary but most implementations treat
> them as identical and I have not encountered any cases where they differ.)
>
> On January 27, 2019 10:03:44 AM PST, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >Hello,
> >
> >See if the following can get you started.
> >It uses package CRAN zoo, function as.yearmon.
> >
> >dati$MES <- zoo::as.yearmon(dati$DATAORA)
> >PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
> >
> >plot(dati$DATAORA, PMES)
> >
> >
> >Hope this helps,
> >
> >Rui Barradas
> >
> >?s 15:25 de 27/01/2019, Diego Avesani escreveu:
> >> Dear all,
> >>
> >> I have a set of data with has hourly value:
> >>
> >> # ID
> >> # Lo
> >> # L
> >> # Q
> >> Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
> >> yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
> >> 2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
> >> 2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
> >> 2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
> >> 2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
> >> .....
> >> .....
> >>
> >> I was able to read it,  create my-own data frame and to plot the
> >total
> >> cumulative function.
> >> This is basically what I have done:
> >>
> >> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
> >> na.strings="-999",skip = 6)
> >> colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC",
> >"RAD",
> >> "CC","FOG")
> >>
> >> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
> >%H:%M"))
> >>
> >>
> >> P <- cumsum(dati$PREC)
> >> plot(dati$DATAORA, P)
> >>
> >> I would like to select the data according to an starting and ending
> >date.
> >> In addition, I would like to plot the monthly and not the total one.
> >> I mean, I would like to have a cumulative plot for each month of the
> >> selected year.
> >>
> >> I am struggling with "ddply" but probably it is the wrong way.
> >>
> >> Could someone help me?  Really Really thanks,
> >>
> >>
> >> Diego
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 28 02:40:15 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Jan 2019 17:40:15 -0800 (PST)
Subject: [R] cumulative data monthly
In-Reply-To: <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
 <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
 <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1901271728480.64040@pedal.dcn.davis.ca.us>

I have no idea what you mean when you say "select starting date and ending 
date properly form [sic] datai$DATA". For one thing there is no column 
called DATA, and for another I don't know what starting dates and ending 
dates you might be interested in. If you need help to subset by time, 
perhaps you should ask a question about that instead.

Here is a reproducible example of making monthly data and manipulating it 
using artificial data:

###############
library(zoo)
Sys.setenv( TZ = "GMT" )
set.seed(42)
dati <- data.frame( DATAORA = as.POSIXct( "2012-01-01" )
                             + as.difftime( seq( 0, 365*3*24
                                          ), units="hours" )
                   )
# terrible simulation of precipitation
dati$PREC <- 0.1 * trunc( 50 * rbeta( nrow( dati ), 1, 80 ) )
dati$ym <- as.yearmon( dati$DATAORA )
# aggregate usually reduces the number of rows given to it
datim <- aggregate( list( PREC = dati$PREC ) # data to summarize
                   , dati[ , "ym", drop=FALSE ] # columns to group on
                   , FUN = sum  # calculation on data
                   )
plot(PREC ~ ym, data=datim) # This is how I would usually look at it
as.year <- function(x) floor( as.numeric( x ) ) # from help file on as.yearmon
datim$y <- as.year( datim$ym )
# ave typically does not change the number of rows given to it
datim$PMES <- ave( datim$PREC, datim$y, FUN = cumsum)
plot(PMES ~ ym, data=datim) # My guess as to what you asked for?
###############

On Sun, 27 Jan 2019, Diego Avesani wrote:

> Dear? Jeff, Dear Rui, Dear all,
> 
> I will try Rui's solution as soon as possible.
> If I could ask:
> As a first step, I would like to follow Jeff's suggestion. I will represent the precipitation data with a cumulative
> distribution, one for each year.
> This follow that I would like to select the starting date and the ending date properly form dati$DATA in order to
> perform the cumulative function.
> 
> Could you help me on that.
> 
> Again, really really thanks
> 
> Diego
> 
> 
> 
> On Sun, 27 Jan 2019 at 21:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>       Very succinct, Rui!
>
>       One warning to Diego.... automatic data recorders tend to use the local standard timezone year-round. R by
>       default assumes that timestamps converted from character to POSIXct using the current timezone on your
>       computer... which may not be in the same zone that the logger was in but even more commonly the computer
>       follows daylight savings time. This leads to NAs showing up in your converted timestamps in spring and
>       duplicated values in autumn as the data are misinterpreted. The easiest solution can be to use
>
>       Sys.setenv( TZ="GMT" )
>
>       though if you need the actual timezone you can use a zone name of the form "Etc/GMT+5" (5 hrs west of GMT).
>
>       Note that Rui's solution will only work correctly near the month transition if you pretend the data timezone
>       is GMT or UTC. (Technically these are different so your mileage may vary but most implementations treat them
>       as identical and I have not encountered any cases where they differ.)
>
>       On January 27, 2019 10:03:44 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>       >Hello,
>       >
>       >See if the following can get you started.
>       >It uses package CRAN zoo, function as.yearmon.
>       >
>       >dati$MES <- zoo::as.yearmon(dati$DATAORA)
>       >PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
>       >
>       >plot(dati$DATAORA, PMES)
>       >
>       >
>       >Hope this helps,
>       >
>       >Rui Barradas
>       >
>       >?s 15:25 de 27/01/2019, Diego Avesani escreveu:
>       >> Dear all,
>       >>
>       >> I have a set of data with has hourly value:
>       >>
>       >> # ID
>       >> # Lo
>       >> # L
>       >> # Q
>       >> Time,? ? T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
>       >> yyyy-mm-dd hh:mm,? ??C,? %, hPa, ?N,? m/s, mm/h,W/m?,? %,-
>       >> 2012-01-01 06:00, -0.1,100, 815,313,? 2.6,? 0.0,? ?0,? 0,0
>       >> 2012-01-01 07:00, -1.2, 93, 814,314,? 4.8,? 0.0,? ?0,? 0,0
>       >> 2012-01-01 08:00,? 1.7, 68, 815,308,? 7.5,? 0.0,? 41, 11,0
>       >> 2012-01-01 09:00,? 2.4, 65, 815,308,? 7.4,? 0.0, 150, 33,0
>       >> .....
>       >> .....
>       >>
>       >> I was able to read it,? create my-own data frame and to plot the
>       >total
>       >> cumulative function.
>       >> This is basically what I have done:
>       >>
>       >> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
>       >> na.strings="-999",skip = 6)
>       >> colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10", "PREC",
>       >"RAD",
>       >> "CC","FOG")
>       >>
>       >> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
>       >%H:%M"))
>       >>
>       >>
>       >> P <- cumsum(dati$PREC)
>       >> plot(dati$DATAORA, P)
>       >>
>       >> I would like to select the data according to an starting and ending
>       >date.
>       >> In addition, I would like to plot the monthly and not the total one.
>       >> I mean, I would like to have a cumulative plot for each month of the
>       >> selected year.
>       >>
>       >> I am struggling with "ddply" but probably it is the wrong way.
>       >>
>       >> Could someone help me?? Really Really thanks,
>       >>
>       >>
>       >> Diego
>       >>
>       >>? ? ? [[alternative HTML version deleted]]
>       >>
>       >> ______________________________________________
>       >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>       >> https://stat.ethz.ch/mailman/listinfo/r-help
>       >> PLEASE do read the posting guide
>       >http://www.R-project.org/posting-guide.html
>       >> and provide commented, minimal, self-contained, reproducible code.
>       >>
>       >
>       >______________________________________________
>       >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>       >https://stat.ethz.ch/mailman/listinfo/r-help
>       >PLEASE do read the posting guide
>       >http://www.R-project.org/posting-guide.html
>       >and provide commented, minimal, self-contained, reproducible code.
>
>       --
>       Sent from my phone. Please excuse my brevity.
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 28 03:20:23 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Jan 2019 18:20:23 -0800 (PST)
Subject: [R] positive deviance plot for Binomial distribution
In-Reply-To: <CAM9Qe4iW+xkUhFjCnsZPFChgZ_RpWko8cP1_MLTkpNvPq0nfyQ@mail.gmail.com>
References: <CAM9Qe4iW+xkUhFjCnsZPFChgZ_RpWko8cP1_MLTkpNvPq0nfyQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1901271812180.64040@pedal.dcn.davis.ca.us>

I haven't found much call to mess with this, but I think the built-in 
"glm" function could do it. You might have to reformulate the inputs to 
outcome/observation (ratio) and outcome+observation (weight) to get glm to 
accept it [1]... but I am not sure.  What I am somewhat more sure of is 
that your description sounds an awful lot like a q-q plot which is one of 
the standard outputs when you plot a regression model.

[1] 
https://stats.stackexchange.com/questions/322038/input-format-for-binomial-glm-in-r


On Fri, 25 Jan 2019, greg holly wrote:

> Hi Dear all;
>
> I have binomially distributed data (a small portion is given below) and I
> would like to create a distribution plot for positive deviance with
> "Probability of results" at Y axis and "percentage of outcome" at the
> x-axis. I wondered anyone knows the name of R  library for this.
>
> Regards,
>
> Greg
>
> provider outcome observation
> 1               14            27
> 2                11           33
> 3                9             17
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Fri Jan 25 17:36:41 2019
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Fri, 25 Jan 2019 17:36:41 +0100
Subject: [R] how to run a multinomial logistic regression with fixed effects
Message-ID: <CABZtLWxO_NLWjRU1cByj9gPoLQ6g9cW2+CubLxW9HWE+L3McPg@mail.gmail.com>

Dear list users,
I am looking for a R package implementing a multinomial logistic
regression with fixed effects (Chamberlain 1980, Review of Economic
Studies 47: 225?238).

Over the years, a number of questions have been asked in the R help
and in stack-related websites in order to find how to use this model
in a fixed-effects framework.

In some cases, it was suggested to use existing routines, mainly
nnet::multinom and mlogit::mlogit. However, this doesn?t look like a
viable solution, because these packages are not exactly designed for
this task. Perhaps unsurprisingly, I was not able to find any working
example that can serve my purpose.

Others have suggested to use a Poisson transformation. This is
discussed for example in a working paper on the arxiv
https://arxiv.org/pdf/1707.08538.pdf. However, I found no useful
guides to implement this approach in R.

Finally, many have been addressed to packages using Bayesian
estimation strategies.

I was wondering if anyone in this list can provide an example or any
resource that I can use to begin working on this model using R.
Let me stress that I am not interested in working with Bayesian methods.

My data looks like this:

set.seed(123)
# number of observations
n <- 100
# number of possible choice
possible_choice <- letters[1:4]
# number of years
years <- 3
# individual characteristics
x1 <- runif(n * 3, 5.0, 70.5)
x2 <- sample(1:n^2, n * 3, replace = F)
# actual choice at time 1
actual_choice_year_1 <- possible_choice[sample(1:4, n, replace = T,
prob = rep(1/4, 4))]
actual_choice_year_2 <- possible_choice[sample(1:4, n, replace = T,
prob = c(0.4, 0.3, 0.2, 0.1))]
actual_choice_year_3 <- possible_choice[sample(1:4, n, replace = T,
prob = c(0.2, 0.5, 0.2, 0.1))]
# create long dataset
df <- data.frame(choice = c(actual_choice_year_1,
actual_choice_year_2, actual_choice_year_3),
           x1 = x1, x2 = x2,
           individual_fixed_effect = as.character(rep(1:n, years)),
           time_fixed_effect = as.character(rep(1:years, each = n)),
           stringsAsFactors = F)

Ideally, what I would like to estimate is a formula of the kind

formula("choice ~ x1 + x2 + individual_fixed_effect + time_fixed_effect")

To this purpose, I have tried to use the package mlogit. Consequenly,
following the vignette of this package I have rearranged my data as

library(mlogit)
# create wide dataset
data_mlogit <- mlogit.data(df, id.var = "individual_fixed_effect",
            group.var = "time_fixed_effect",
            choice = "choice",
            shape = "wide")

This allow me to run a multinomial logit regression without fixed
effects by typing

# formula
formula_mlogit <- formula("choice ~ 1| x1 + x2")
# run multinomial regression
fit <- mlogit(formula_mlogit, data_mlogit)
summary(fit)

Apparently, in order to include fixed effects and use a panel
estimation strategy, one should set the argument panel equal to TRUE
in the function mlogit.
However, according to the help of this function, this argument is
evaluated only if another argument, rpar, is not NULL.

The argument rpar is used to set the distribution of random variables
in the model specification. Unfortunately, no random variables are
included in my specification, hence I have no parameters to use in
rpar. As a result, mlogit seems not the best choice in this context.
On stackexchange, a possible solution was proposed few years ago
https://stats.stackexchange.com/questions/51148/unable-to-provide-random-parameter-with-mlogit
However, I don't understand how to actually implement it.

Regards,
Valerio Leone Sciabolazza, Ph.D.
Department of Business and Economics
University of Naples, Parthenope.
valerio.leonesciabolazza at uniparthenope.it
www.valerioleonesciabolazza.com

P.s.
Recently, Stata provided a package (femlogit) for the estimation of
this model with fixed effects.


From j@b@y@t194 @end|ng |rom gm@||@com  Sat Jan 26 07:07:18 2019
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Sat, 26 Jan 2019 09:37:18 +0330
Subject: [R] Extract the coordinates of a Polylines
Message-ID: <CANTxAmKurP05q8kWq_fSoRyPhNm2G7pUB-34bUD4oxOO0z8uKg@mail.gmail.com>

Dear R users;
I am trying to extract the X and Y coordinates of a polylines along with
Elevation data. I have extracted the Elevations as Z, but I do not know how
to extract the X and Y of these Elevations. Is it possible to extract X and
Y of the Elevation and create a data frame with three variables?

line = readOGR("E:/......../Topo.shp")
Z = line at data$Elevation

Sincerely.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From h@|||e@k@me@ch @end|ng |rom gm@||@com  Sun Jan 27 18:08:02 2019
From: h@|||e@k@me@ch @end|ng |rom gm@||@com (Hallie Kamesch)
Date: Sun, 27 Jan 2019 11:08:02 -0600
Subject: [R] troubleshooting data structure to run krippendorff's alpha
Message-ID: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>

Hi -
I'm trying to run Krippendorff's alpha for data consisting of 4 subjects
rated on 6 events each by three raters.  The ratings are interval ratio
scale data.

I've rearranged my data into a 3 x 24  of ratersXevents. (per this
discussion on CrossValidated: (
https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144)
).

This is the code I've used:
library(irr)
dat <- read.csv(file.choose(), header = TRUE)
head(dat)
kripp.alpha(dat, method=c("ratio"))
#### error message: Error in sort.list(y) : 'x' must be atomic for
'sort.list'
Have you called 'sort' on a list?
kripp.alpha(dat,"ratio")
#### error message: Error in sort.list(y) : 'x' must be atomic for
'sort.list'
Have you called 'sort' on a list?

I read rhelp on sort, but I'm still confused.  Please help!
Thank you!

PS
I arranged my data in that matrix based upon this comment and response from
the CrossValidated posting forum (
https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144),
but my question above was rejected there.

	[[alternative HTML version deleted]]


From bhub@ne@wordh@k@| @end|ng |rom gm@||@com  Mon Jan 28 01:29:27 2019
From: bhub@ne@wordh@k@| @end|ng |rom gm@||@com (Bhubaneswor Dhakal)
Date: Mon, 28 Jan 2019 13:29:27 +1300
Subject: [R] Requested r code and references for doing network analysis with
 experimental data
Message-ID: <CAD5R06TRXDBEnUU3s-k7tMG33W-HzAHEjFpvzfcw9DoHMCwxBw@mail.gmail.com>

Hi R support group

I have an experimental data of a network analysis problem. One group is
treated and another is controlled (untreated). The response of the
treatment of three factors are measured in ordinal scale and the other two
factors in continuous scale.

I am looking for R code which account the experimental effect in the
network analysis result I would also like some reading materials to know
approaches and issues in such analysis. Can you please send them to me?

-- 
Thank you.
Best Wishes.
B.Dhakal

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Jan 28 08:11:39 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 28 Jan 2019 07:11:39 +0000
Subject: [R] 
 Requested r code and references for doing network analysis with
 experimental data
In-Reply-To: <CAD5R06TRXDBEnUU3s-k7tMG33W-HzAHEjFpvzfcw9DoHMCwxBw@mail.gmail.com>
References: <CAD5R06TRXDBEnUU3s-k7tMG33W-HzAHEjFpvzfcw9DoHMCwxBw@mail.gmail.com>
Message-ID: <71aae2a893814136b46bf16abb9471cd@SRVEXCHCM1302.precheza.cz>

Hi

Well, I tried google and this

https://www.jessesadler.com/post/network-analysis-with-r/

seems to provide some insights.

If it is not appropriate to your situation, you should be more specific.

Cheers
Petr

BTW, what is factor in continuous scale? I am almost sure that factors are discrete variables.

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bhubaneswor
> Dhakal
> Sent: Monday, January 28, 2019 1:29 AM
> To: r-help at r-project.org
> Subject: [R] Requested r code and references for doing network analysis with
> experimental data
>
> Hi R support group
>
> I have an experimental data of a network analysis problem. One group is
> treated and another is controlled (untreated). The response of the treatment of
> three factors are measured in ordinal scale and the other two factors in
> continuous scale.
>
> I am looking for R code which account the experimental effect in the network
> analysis result I would also like some reading materials to know approaches
> and issues in such analysis. Can you please send them to me?
>
> --
> Thank you.
> Best Wishes.
> B.Dhakal
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 28 08:25:23 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Jan 2019 23:25:23 -0800
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
Message-ID: <7F1DD59C-A612-4ED2-9432-81B6C9310EA3@dcn.davis.ca.us>

I don't understand most of what you wrote, but when you say "matrix" you are mistaken. A matrix is NOT the same thing as a data frame, which is what you get when you call read.csv(). Read 

RShowDoc("R-intro")

Sections 5 and 6... A data frame is a list of column vectors, while a matrix is a vector with a dimension attribute.

You can use the as.matrix function to convert a data frame to a matrix.

On January 27, 2019 9:08:02 AM PST, Hallie Kamesch <hallie.kamesch at gmail.com> wrote:
>Hi -
>I'm trying to run Krippendorff's alpha for data consisting of 4
>subjects
>rated on 6 events each by three raters.  The ratings are interval ratio
>scale data.
>
>I've rearranged my data into a 3 x 24  of ratersXevents. (per this
>discussion on CrossValidated: (
>https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144)
>).
>
>This is the code I've used:
>library(irr)
>dat <- read.csv(file.choose(), header = TRUE)
>head(dat)
>kripp.alpha(dat, method=c("ratio"))
>#### error message: Error in sort.list(y) : 'x' must be atomic for
>'sort.list'
>Have you called 'sort' on a list?
>kripp.alpha(dat,"ratio")
>#### error message: Error in sort.list(y) : 'x' must be atomic for
>'sort.list'
>Have you called 'sort' on a list?
>
>I read rhelp on sort, but I'm still confused.  Please help!
>Thank you!
>
>PS
>I arranged my data in that matrix based upon this comment and response
>from
>the CrossValidated posting forum (
>https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144),
>but my question above was rejected there.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Mon Jan 28 09:25:21 2019
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Mon, 28 Jan 2019 09:25:21 +0100
Subject: [R] cumulative data monthly
In-Reply-To: <alpine.BSF.2.00.1901271728480.64040@pedal.dcn.davis.ca.us>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
 <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
 <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>
 <alpine.BSF.2.00.1901271728480.64040@pedal.dcn.davis.ca.us>
Message-ID: <CAG8o1y5vFVX+Jwziu6NVCZCaUUNT0WBwVPBmytQuEdBAgpQNZA@mail.gmail.com>

Dear Jeff, Dear Rui, Dear all,

Forget about the monthly things. I was trying to do two things at the same
time.
I try to explain myself. Thanks for your time and I really appreciate your
help.

I have  a long file with hourly precipitation from 2000 to 2018. I would
like to select only on e year or even half of a year and plot the
cumulative precipitation of it in order to compare it with the simulation
data that I have.

So far I was able only to read all the file:
dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
na.strings="-999",skip = 6)

and to plot the entire cumulative:
P <- cumsum(dati$PREC)
plot(dati$DATAORA, P)

How can I choose only, for example, 2013 in order to have P?
thanks again


Diego



On Mon, 28 Jan 2019 at 02:36, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I have no idea what you mean when you say "select starting date and ending
> date properly form [sic] datai$DATA". For one thing there is no column
> called DATA, and for another I don't know what starting dates and ending
> dates you might be interested in. If you need help to subset by time,
> perhaps you should ask a question about that instead.
>
> Here is a reproducible example of making monthly data and manipulating it
> using artificial data:
>
> ###############
> library(zoo)
> Sys.setenv( TZ = "GMT" )
> set.seed(42)
> dati <- data.frame( DATAORA = as.POSIXct( "2012-01-01" )
>                              + as.difftime( seq( 0, 365*3*24
>                                           ), units="hours" )
>                    )
> # terrible simulation of precipitation
> dati$PREC <- 0.1 * trunc( 50 * rbeta( nrow( dati ), 1, 80 ) )
> dati$ym <- as.yearmon( dati$DATAORA )
> # aggregate usually reduces the number of rows given to it
> datim <- aggregate( list( PREC = dati$PREC ) # data to summarize
>                    , dati[ , "ym", drop=FALSE ] # columns to group on
>                    , FUN = sum  # calculation on data
>                    )
> plot(PREC ~ ym, data=datim) # This is how I would usually look at it
> as.year <- function(x) floor( as.numeric( x ) ) # from help file on
> as.yearmon
> datim$y <- as.year( datim$ym )
> # ave typically does not change the number of rows given to it
> datim$PMES <- ave( datim$PREC, datim$y, FUN = cumsum)
> plot(PMES ~ ym, data=datim) # My guess as to what you asked for?
> ###############
>
> On Sun, 27 Jan 2019, Diego Avesani wrote:
>
> > Dear  Jeff, Dear Rui, Dear all,
> >
> > I will try Rui's solution as soon as possible.
> > If I could ask:
> > As a first step, I would like to follow Jeff's suggestion. I will
> represent the precipitation data with a cumulative
> > distribution, one for each year.
> > This follow that I would like to select the starting date and the ending
> date properly form dati$DATA in order to
> > perform the cumulative function.
> >
> > Could you help me on that.
> >
> > Again, really really thanks
> >
> > Diego
> >
> >
> >
> > On Sun, 27 Jan 2019 at 21:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >       Very succinct, Rui!
> >
> >       One warning to Diego.... automatic data recorders tend to use the
> local standard timezone year-round. R by
> >       default assumes that timestamps converted from character to
> POSIXct using the current timezone on your
> >       computer... which may not be in the same zone that the logger was
> in but even more commonly the computer
> >       follows daylight savings time. This leads to NAs showing up in
> your converted timestamps in spring and
> >       duplicated values in autumn as the data are misinterpreted. The
> easiest solution can be to use
> >
> >       Sys.setenv( TZ="GMT" )
> >
> >       though if you need the actual timezone you can use a zone name of
> the form "Etc/GMT+5" (5 hrs west of GMT).
> >
> >       Note that Rui's solution will only work correctly near the month
> transition if you pretend the data timezone
> >       is GMT or UTC. (Technically these are different so your mileage
> may vary but most implementations treat them
> >       as identical and I have not encountered any cases where they
> differ.)
> >
> >       On January 27, 2019 10:03:44 AM PST, Rui Barradas <
> ruipbarradas at sapo.pt> wrote:
> >       >Hello,
> >       >
> >       >See if the following can get you started.
> >       >It uses package CRAN zoo, function as.yearmon.
> >       >
> >       >dati$MES <- zoo::as.yearmon(dati$DATAORA)
> >       >PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
> >       >
> >       >plot(dati$DATAORA, PMES)
> >       >
> >       >
> >       >Hope this helps,
> >       >
> >       >Rui Barradas
> >       >
> >       >?s 15:25 de 27/01/2019, Diego Avesani escreveu:
> >       >> Dear all,
> >       >>
> >       >> I have a set of data with has hourly value:
> >       >>
> >       >> # ID
> >       >> # Lo
> >       >> # L
> >       >> # Q
> >       >> Time,    T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
> >       >> yyyy-mm-dd hh:mm,   ?C,  %, hPa, ?N,  m/s, mm/h,W/m?,  %,-
> >       >> 2012-01-01 06:00, -0.1,100, 815,313,  2.6,  0.0,   0,  0,0
> >       >> 2012-01-01 07:00, -1.2, 93, 814,314,  4.8,  0.0,   0,  0,0
> >       >> 2012-01-01 08:00,  1.7, 68, 815,308,  7.5,  0.0,  41, 11,0
> >       >> 2012-01-01 09:00,  2.4, 65, 815,308,  7.4,  0.0, 150, 33,0
> >       >> .....
> >       >> .....
> >       >>
> >       >> I was able to read it,  create my-own data frame and to plot the
> >       >total
> >       >> cumulative function.
> >       >> This is basically what I have done:
> >       >>
> >       >> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
> >       >> na.strings="-999",skip = 6)
> >       >> colnames(dati)=c("DATAORA","T", "RH","PSFC","DIR","VEL10",
> "PREC",
> >       >"RAD",
> >       >> "CC","FOG")
> >       >>
> >       >> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
> >       >%H:%M"))
> >       >>
> >       >>
> >       >> P <- cumsum(dati$PREC)
> >       >> plot(dati$DATAORA, P)
> >       >>
> >       >> I would like to select the data according to an starting and
> ending
> >       >date.
> >       >> In addition, I would like to plot the monthly and not the total
> one.
> >       >> I mean, I would like to have a cumulative plot for each month
> of the
> >       >> selected year.
> >       >>
> >       >> I am struggling with "ddply" but probably it is the wrong way.
> >       >>
> >       >> Could someone help me?  Really Really thanks,
> >       >>
> >       >>
> >       >> Diego
> >       >>
> >       >>      [[alternative HTML version deleted]]
> >       >>
> >       >> ______________________________________________
> >       >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >       >> https://stat.ethz.ch/mailman/listinfo/r-help
> >       >> PLEASE do read the posting guide
> >       >http://www.R-project.org/posting-guide.html
> >       >> and provide commented, minimal, self-contained, reproducible
> code.
> >       >>
> >       >
> >       >______________________________________________
> >       >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >       >https://stat.ethz.ch/mailman/listinfo/r-help
> >       >PLEASE do read the posting guide
> >       >http://www.R-project.org/posting-guide.html
> >       >and provide commented, minimal, self-contained, reproducible code.
> >
> >       --
> >       Sent from my phone. Please excuse my brevity.
> >
> >
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 28 09:33:45 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 28 Jan 2019 08:33:45 +0000
Subject: [R] cumulative data monthly
In-Reply-To: <CAG8o1y5vFVX+Jwziu6NVCZCaUUNT0WBwVPBmytQuEdBAgpQNZA@mail.gmail.com>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
 <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
 <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>
 <alpine.BSF.2.00.1901271728480.64040@pedal.dcn.davis.ca.us>
 <CAG8o1y5vFVX+Jwziu6NVCZCaUUNT0WBwVPBmytQuEdBAgpQNZA@mail.gmail.com>
Message-ID: <09e35430-1734-c6af-350b-103143b5a945@sapo.pt>

Hello,

With on?bjects of class "Date" or "POSIXt", POSIXct" you can do

lubridate::year(date_obj)

to extract the year. Then aggregate by it.

Hope this helps,

Rui Barradas

?s 08:25 de 28/01/2019, Diego Avesani escreveu:
> Dear Jeff, Dear Rui, Dear all,
> 
> Forget about the monthly things. I was trying to do two things at the 
> same time.
> I try to explain myself. Thanks for your time and I really appreciate 
> your help.
> 
> I have? a long file with hourly precipitation from 2000 to 2018. I would 
> like to select only on e year or even half of a year and plot the 
> cumulative precipitation of it in order to compare it with the 
> simulation data that I have.
> 
> So far I was able only to read all the file:
> dati <- read.csv(file="116.txt", header=FALSE, sep="," , 
> na.strings="-999",skip = 6)
> 
> and to plot the entire cumulative:
> P <- cumsum(dati$PREC)
> plot(dati$DATAORA, P)
> 
> How can I choose only, for example, 2013 in order to have P?
> thanks again
> 
> 
> Diego
> 
> 
> 
> On Mon, 28 Jan 2019 at 02:36, Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
> <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
> 
>     I have no idea what you mean when you say "select starting date and
>     ending
>     date properly form [sic] datai$DATA". For one thing there is no column
>     called DATA, and for another I don't know what starting dates and
>     ending
>     dates you might be interested in. If you need help to subset by time,
>     perhaps you should ask a question about that instead.
> 
>     Here is a reproducible example of making monthly data and
>     manipulating it
>     using artificial data:
> 
>     ###############
>     library(zoo)
>     Sys.setenv( TZ = "GMT" )
>     set.seed(42)
>     dati <- data.frame( DATAORA = as.POSIXct( "2012-01-01" )
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?+ as.difftime( seq( 0, 365*3*24
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ), units="hours" )
>      ? ? ? ? ? ? ? ? ? ?)
>     # terrible simulation of precipitation
>     dati$PREC <- 0.1 * trunc( 50 * rbeta( nrow( dati ), 1, 80 ) )
>     dati$ym <- as.yearmon( dati$DATAORA )
>     # aggregate usually reduces the number of rows given to it
>     datim <- aggregate( list( PREC = dati$PREC ) # data to summarize
>      ? ? ? ? ? ? ? ? ? ?, dati[ , "ym", drop=FALSE ] # columns to group on
>      ? ? ? ? ? ? ? ? ? ?, FUN = sum? # calculation on data
>      ? ? ? ? ? ? ? ? ? ?)
>     plot(PREC ~ ym, data=datim) # This is how I would usually look at it
>     as.year <- function(x) floor( as.numeric( x ) ) # from help file on
>     as.yearmon
>     datim$y <- as.year( datim$ym )
>     # ave typically does not change the number of rows given to it
>     datim$PMES <- ave( datim$PREC, datim$y, FUN = cumsum)
>     plot(PMES ~ ym, data=datim) # My guess as to what you asked for?
>     ###############
> 
>     On Sun, 27 Jan 2019, Diego Avesani wrote:
> 
>      > Dear? Jeff, Dear Rui, Dear all,
>      >
>      > I will try Rui's solution as soon as possible.
>      > If I could ask:
>      > As a first step, I would like to follow Jeff's suggestion. I will
>     represent the precipitation data with a cumulative
>      > distribution, one for each year.
>      > This follow that I would like to select the starting date and the
>     ending date properly form dati$DATA in order to
>      > perform the cumulative function.
>      >
>      > Could you help me on that.
>      >
>      > Again, really really thanks
>      >
>      > Diego
>      >
>      >
>      >
>      > On Sun, 27 Jan 2019 at 21:37, Jeff Newmiller
>     <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>      >? ? ? ?Very succinct, Rui!
>      >
>      >? ? ? ?One warning to Diego.... automatic data recorders tend to
>     use the local standard timezone year-round. R by
>      >? ? ? ?default assumes that timestamps converted from character to
>     POSIXct using the current timezone on your
>      >? ? ? ?computer... which may not be in the same zone that the
>     logger was in but even more commonly the computer
>      >? ? ? ?follows daylight savings time. This leads to NAs showing up
>     in your converted timestamps in spring and
>      >? ? ? ?duplicated values in autumn as the data are misinterpreted.
>     The easiest solution can be to use
>      >
>      >? ? ? ?Sys.setenv( TZ="GMT" )
>      >
>      >? ? ? ?though if you need the actual timezone you can use a zone
>     name of the form "Etc/GMT+5" (5 hrs west of GMT).
>      >
>      >? ? ? ?Note that Rui's solution will only work correctly near the
>     month transition if you pretend the data timezone
>      >? ? ? ?is GMT or UTC. (Technically these are different so your
>     mileage may vary but most implementations treat them
>      >? ? ? ?as identical and I have not encountered any cases where
>     they differ.)
>      >
>      >? ? ? ?On January 27, 2019 10:03:44 AM PST, Rui Barradas
>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>      >? ? ? ?>Hello,
>      >? ? ? ?>
>      >? ? ? ?>See if the following can get you started.
>      >? ? ? ?>It uses package CRAN zoo, function as.yearmon.
>      >? ? ? ?>
>      >? ? ? ?>dati$MES <- zoo::as.yearmon(dati$DATAORA)
>      >? ? ? ?>PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
>      >? ? ? ?>
>      >? ? ? ?>plot(dati$DATAORA, PMES)
>      >? ? ? ?>
>      >? ? ? ?>
>      >? ? ? ?>Hope this helps,
>      >? ? ? ?>
>      >? ? ? ?>Rui Barradas
>      >? ? ? ?>
>      >? ? ? ?>?s 15:25 de 27/01/2019, Diego Avesani escreveu:
>      >? ? ? ?>> Dear all,
>      >? ? ? ?>>
>      >? ? ? ?>> I have a set of data with has hourly value:
>      >? ? ? ?>>
>      >? ? ? ?>> # ID
>      >? ? ? ?>> # Lo
>      >? ? ? ?>> # L
>      >? ? ? ?>> # Q
>      >? ? ? ?>> Time,? ? T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
>      >? ? ? ?>> yyyy-mm-dd hh:mm,? ??C,? %, hPa, ?N,? m/s, mm/h,W/m?,? %,-
>      >? ? ? ?>> 2012-01-01 06:00, -0.1,100, 815,313,? 2.6,? 0.0,? ?0,? 0,0
>      >? ? ? ?>> 2012-01-01 07:00, -1.2, 93, 814,314,? 4.8,? 0.0,? ?0,? 0,0
>      >? ? ? ?>> 2012-01-01 08:00,? 1.7, 68, 815,308,? 7.5,? 0.0,? 41, 11,0
>      >? ? ? ?>> 2012-01-01 09:00,? 2.4, 65, 815,308,? 7.4,? 0.0, 150, 33,0
>      >? ? ? ?>> .....
>      >? ? ? ?>> .....
>      >? ? ? ?>>
>      >? ? ? ?>> I was able to read it,? create my-own data frame and to
>     plot the
>      >? ? ? ?>total
>      >? ? ? ?>> cumulative function.
>      >? ? ? ?>> This is basically what I have done:
>      >? ? ? ?>>
>      >? ? ? ?>> dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
>      >? ? ? ?>> na.strings="-999",skip = 6)
>      >? ? ? ?>> colnames(dati)=c("DATAORA","T",
>     "RH","PSFC","DIR","VEL10", "PREC",
>      >? ? ? ?>"RAD",
>      >? ? ? ?>> "CC","FOG")
>      >? ? ? ?>>
>      >? ? ? ?>>
>     dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
>      >? ? ? ?>%H:%M"))
>      >? ? ? ?>>
>      >? ? ? ?>>
>      >? ? ? ?>> P <- cumsum(dati$PREC)
>      >? ? ? ?>> plot(dati$DATAORA, P)
>      >? ? ? ?>>
>      >? ? ? ?>> I would like to select the data according to an starting
>     and ending
>      >? ? ? ?>date.
>      >? ? ? ?>> In addition, I would like to plot the monthly and not
>     the total one.
>      >? ? ? ?>> I mean, I would like to have a cumulative plot for each
>     month of the
>      >? ? ? ?>> selected year.
>      >? ? ? ?>>
>      >? ? ? ?>> I am struggling with "ddply" but probably it is the
>     wrong way.
>      >? ? ? ?>>
>      >? ? ? ?>> Could someone help me?? Really Really thanks,
>      >? ? ? ?>>
>      >? ? ? ?>>
>      >? ? ? ?>> Diego
>      >? ? ? ?>>
>      >? ? ? ?>>? ? ? [[alternative HTML version deleted]]
>      >? ? ? ?>>
>      >? ? ? ?>> ______________________________________________
>      >? ? ? ?>> R-help at r-project.org <mailto:R-help at r-project.org>
>     mailing list -- To UNSUBSCRIBE and more, see
>      >? ? ? ?>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? ?>> PLEASE do read the posting guide
>      >? ? ? ?>http://www.R-project.org/posting-guide.html
>      >? ? ? ?>> and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? ?>>
>      >? ? ? ?>
>      >? ? ? ?>______________________________________________
>      >? ? ? ?>R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>      >? ? ? ?>https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? ?>PLEASE do read the posting guide
>      >? ? ? ?>http://www.R-project.org/posting-guide.html
>      >? ? ? ?>and provide commented, minimal, self-contained,
>     reproducible code.
>      >
>      >? ? ? ?--
>      >? ? ? ?Sent from my phone. Please excuse my brevity.
>      >
>      >
>      >
> 
>     ---------------------------------------------------------------------------
>     Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? ?.....? ? ? ?.....? Go
>     Live...
>     DCN:<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>   
>      ? ? Basics: ##.#.? ? ? ?##.#.? Live Go...
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Live:? ?OO#.. Dead: OO#.. 
>     Playing
>     Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? ?#.O#.? with
>     /Software/Embedded Controllers)? ? ? ? ? ? ? ?.OO#.? ? ? ?.OO#. 
>     rocks...1k
>     ---------------------------------------------------------------------------
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Jan 28 10:36:13 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 28 Jan 2019 20:36:13 +1100
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
Message-ID: <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>

Hi Halllie,
As Jeff noted, a data frame is not a matrix (it is a variety of list),
so that looks like your problem.

hkdf<-data.frame(sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE),
 sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE))
library(irr)
kripp.alpha(hkdf)
kripp.alpha(as.matrix(hkdf))

Jim

On Mon, Jan 28, 2019 at 6:04 PM Hallie Kamesch <hallie.kamesch at gmail.com> wrote:
>
> Hi -
> I'm trying to run Krippendorff's alpha for data consisting of 4 subjects
> rated on 6 events each by three raters.  The ratings are interval ratio
> scale data.
>
> I've rearranged my data into a 3 x 24  of ratersXevents. (per this
> discussion on CrossValidated: (
> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144)
> ).
>
> This is the code I've used:
> library(irr)
> dat <- read.csv(file.choose(), header = TRUE)
> head(dat)
> kripp.alpha(dat, method=c("ratio"))
> #### error message: Error in sort.list(y) : 'x' must be atomic for
> 'sort.list'
> Have you called 'sort' on a list?
> kripp.alpha(dat,"ratio")
> #### error message: Error in sort.list(y) : 'x' must be atomic for
> 'sort.list'
> Have you called 'sort' on a list?
>
> I read rhelp on sort, but I'm still confused.  Please help!
> Thank you!
>
> PS
> I arranged my data in that matrix based upon this comment and response from
> the CrossValidated posting forum (
> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144),
> but my question above was rejected there.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From J@rom||@Fro@@@rd @end|ng |rom un|ge@ch  Mon Jan 28 03:07:44 2019
From: J@rom||@Fro@@@rd @end|ng |rom un|ge@ch (Jaromil Frossard)
Date: Mon, 28 Jan 2019 02:07:44 +0000
Subject: [R] [R-pkgs] permuco: permutation tests and multiple comparisons.
Message-ID: <94c8e48ca3944046a7e0936151bb58ad@unige.ch>

Hello everyone,

We present you the permuco package, which has 2 main purposes: PERmutation tests and MUltiple COmparisons.

First, the package has functions for permutation tests for parameters in linear models with nuisance variables. Several permutation methods exist in the literature to reduce the effect of nuisance variables and the permuco package allows to use them for t statistics in regression model, F tests in type 3 ANOVA, and F tests in repeated measures ANOVA. The 2 functions aovperm() and lmperm() perform these tests and their usage is similar to the parametric counterpart aov() and lm().

Secondly, it uses multiple comparisons procedures with permutation tests to compare signals time by time. This problem is common when analysing electroencephalography (or fMRI) data where the response variables are EEG signals recorded for each experimental setting. In these experiments, the number of tests is equal to the number of time points of the signal which is typically in the thousands. The permuco package implements the state-of-the-art multiple comparisons procedures which uses permutations, like the cluster-mass test or the threshold-free cluster-enhancement. These procedures are powerful when the effects appear in clusters and they will control the family wise error rate (FWER) under the null hypothesis.

All these procedures are explained and exemplified in detail in a vignette.

We are waiting for your feedback in order to improve the next releases of permuco.

Olivier Renaud & Jaromil Frossard

University of Geneva

URL:
https://CRAN.R-project.org/package=permuco
Maintainer:
jaromil.frossard at unige.ch<mailto:jaromil.frossard at unige.ch>

<mailto:jaromil.frossard at unige.ch>


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 28 12:27:12 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 28 Jan 2019 11:27:12 +0000
Subject: [R] cumulative data monthly
In-Reply-To: <CAG8o1y5uQxZWzSNMYNV4WzNi=UjeV_BPf0pETK9qSezsj=L=xw@mail.gmail.com>
References: <CAG8o1y5V48WUkHUyE6Hzz64vMGnffbN8aRHzZFWOHC_8qngXHg@mail.gmail.com>
 <bff0ef56-28fd-ce73-d0ca-23d64323fa02@sapo.pt>
 <01F5C214-91FB-4076-91F3-7FBAA908CAB0@dcn.davis.ca.us>
 <CAG8o1y5xSgtZsdXccw=D+Ro6mN+b_JHqgKY9YxqebFBHyc3KUA@mail.gmail.com>
 <alpine.BSF.2.00.1901271728480.64040@pedal.dcn.davis.ca.us>
 <CAG8o1y5vFVX+Jwziu6NVCZCaUUNT0WBwVPBmytQuEdBAgpQNZA@mail.gmail.com>
 <09e35430-1734-c6af-350b-103143b5a945@sapo.pt>
 <CAG8o1y5uQxZWzSNMYNV4WzNi=UjeV_BPf0pETK9qSezsj=L=xw@mail.gmail.com>
Message-ID: <43d62b82-4d7b-3e2a-c879-04a70f748d65@sapo.pt>

Hello,

Please click <reply all> to keep this threaded.

What I was trying to say is to do something along the lines of

Y <- lubridate::year(dati$DATAORA)
Y2013 <- Y[Y == 2013]
PY2013 <- ave(dati$PREC, Y2013, FUN = cumsum)

plot(dati$DATAORA, PY2013)


Hope this helps,

Rui Barradas

?s 08:57 de 28/01/2019, Diego Avesani escreveu:
> Dear Rui,
> 
> thanks a lot but I am quite new with R
> 
> I have done this:
> dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d %H:%M"))
> 
> Could you please specify what I have to do with lubridate?
> Really Really thanks,
> 
> Diego
> 
> 
> 
> On Mon, 28 Jan 2019 at 09:33, Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     With on?bjects of class "Date" or "POSIXt", POSIXct" you can do
> 
>     lubridate::year(date_obj)
> 
>     to extract the year. Then aggregate by it.
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 08:25 de 28/01/2019, Diego Avesani escreveu:
>      > Dear Jeff, Dear Rui, Dear all,
>      >
>      > Forget about the monthly things. I was trying to do two things at
>     the
>      > same time.
>      > I try to explain myself. Thanks for your time and I really
>     appreciate
>      > your help.
>      >
>      > I have? a long file with hourly precipitation from 2000 to 2018.
>     I would
>      > like to select only on e year or even half of a year and plot the
>      > cumulative precipitation of it in order to compare it with the
>      > simulation data that I have.
>      >
>      > So far I was able only to read all the file:
>      > dati <- read.csv(file="116.txt", header=FALSE, sep="," ,
>      > na.strings="-999",skip = 6)
>      >
>      > and to plot the entire cumulative:
>      > P <- cumsum(dati$PREC)
>      > plot(dati$DATAORA, P)
>      >
>      > How can I choose only, for example, 2013 in order to have P?
>      > thanks again
>      >
>      >
>      > Diego
>      >
>      >
>      >
>      > On Mon, 28 Jan 2019 at 02:36, Jeff Newmiller
>     <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>
>      > <mailto:jdnewmil at dcn.davis.ca.us
>     <mailto:jdnewmil at dcn.davis.ca.us>>> wrote:
>      >
>      >? ? ?I have no idea what you mean when you say "select starting
>     date and
>      >? ? ?ending
>      >? ? ?date properly form [sic] datai$DATA". For one thing there is
>     no column
>      >? ? ?called DATA, and for another I don't know what starting dates and
>      >? ? ?ending
>      >? ? ?dates you might be interested in. If you need help to subset
>     by time,
>      >? ? ?perhaps you should ask a question about that instead.
>      >
>      >? ? ?Here is a reproducible example of making monthly data and
>      >? ? ?manipulating it
>      >? ? ?using artificial data:
>      >
>      >? ? ?###############
>      >? ? ?library(zoo)
>      >? ? ?Sys.setenv( TZ = "GMT" )
>      >? ? ?set.seed(42)
>      >? ? ?dati <- data.frame( DATAORA = as.POSIXct( "2012-01-01" )
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?+ as.difftime( seq( 0, 365*3*24
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ), units="hours" )
>      >? ? ? ? ? ? ? ? ? ? ? ? ?)
>      >? ? ?# terrible simulation of precipitation
>      >? ? ?dati$PREC <- 0.1 * trunc( 50 * rbeta( nrow( dati ), 1, 80 ) )
>      >? ? ?dati$ym <- as.yearmon( dati$DATAORA )
>      >? ? ?# aggregate usually reduces the number of rows given to it
>      >? ? ?datim <- aggregate( list( PREC = dati$PREC ) # data to summarize
>      >? ? ? ? ? ? ? ? ? ? ? ? ?, dati[ , "ym", drop=FALSE ] # columns to
>     group on
>      >? ? ? ? ? ? ? ? ? ? ? ? ?, FUN = sum? # calculation on data
>      >? ? ? ? ? ? ? ? ? ? ? ? ?)
>      >? ? ?plot(PREC ~ ym, data=datim) # This is how I would usually
>     look at it
>      >? ? ?as.year <- function(x) floor( as.numeric( x ) ) # from help
>     file on
>      >? ? ?as.yearmon
>      >? ? ?datim$y <- as.year( datim$ym )
>      >? ? ?# ave typically does not change the number of rows given to it
>      >? ? ?datim$PMES <- ave( datim$PREC, datim$y, FUN = cumsum)
>      >? ? ?plot(PMES ~ ym, data=datim) # My guess as to what you asked for?
>      >? ? ?###############
>      >
>      >? ? ?On Sun, 27 Jan 2019, Diego Avesani wrote:
>      >
>      >? ? ? > Dear? Jeff, Dear Rui, Dear all,
>      >? ? ? >
>      >? ? ? > I will try Rui's solution as soon as possible.
>      >? ? ? > If I could ask:
>      >? ? ? > As a first step, I would like to follow Jeff's suggestion.
>     I will
>      >? ? ?represent the precipitation data with a cumulative
>      >? ? ? > distribution, one for each year.
>      >? ? ? > This follow that I would like to select the starting date
>     and the
>      >? ? ?ending date properly form dati$DATA in order to
>      >? ? ? > perform the cumulative function.
>      >? ? ? >
>      >? ? ? > Could you help me on that.
>      >? ? ? >
>      >? ? ? > Again, really really thanks
>      >? ? ? >
>      >? ? ? > Diego
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > On Sun, 27 Jan 2019 at 21:37, Jeff Newmiller
>      >? ? ?<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>
>     <mailto:jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>>
>     wrote:
>      >? ? ? >? ? ? ?Very succinct, Rui!
>      >? ? ? >
>      >? ? ? >? ? ? ?One warning to Diego.... automatic data recorders
>     tend to
>      >? ? ?use the local standard timezone year-round. R by
>      >? ? ? >? ? ? ?default assumes that timestamps converted from
>     character to
>      >? ? ?POSIXct using the current timezone on your
>      >? ? ? >? ? ? ?computer... which may not be in the same zone that the
>      >? ? ?logger was in but even more commonly the computer
>      >? ? ? >? ? ? ?follows daylight savings time. This leads to NAs
>     showing up
>      >? ? ?in your converted timestamps in spring and
>      >? ? ? >? ? ? ?duplicated values in autumn as the data are
>     misinterpreted.
>      >? ? ?The easiest solution can be to use
>      >? ? ? >
>      >? ? ? >? ? ? ?Sys.setenv( TZ="GMT" )
>      >? ? ? >
>      >? ? ? >? ? ? ?though if you need the actual timezone you can use a
>     zone
>      >? ? ?name of the form "Etc/GMT+5" (5 hrs west of GMT).
>      >? ? ? >
>      >? ? ? >? ? ? ?Note that Rui's solution will only work correctly
>     near the
>      >? ? ?month transition if you pretend the data timezone
>      >? ? ? >? ? ? ?is GMT or UTC. (Technically these are different so your
>      >? ? ?mileage may vary but most implementations treat them
>      >? ? ? >? ? ? ?as identical and I have not encountered any cases where
>      >? ? ?they differ.)
>      >? ? ? >
>      >? ? ? >? ? ? ?On January 27, 2019 10:03:44 AM PST, Rui Barradas
>      >? ? ?<ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>     <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>> wrote:
>      >? ? ? >? ? ? ?>Hello,
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>See if the following can get you started.
>      >? ? ? >? ? ? ?>It uses package CRAN zoo, function as.yearmon.
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>dati$MES <- zoo::as.yearmon(dati$DATAORA)
>      >? ? ? >? ? ? ?>PMES <- ave(dati$PREC, dati$MES, FUN = cumsum)
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>plot(dati$DATAORA, PMES)
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>Hope this helps,
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>Rui Barradas
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>?s 15:25 de 27/01/2019, Diego Avesani escreveu:
>      >? ? ? >? ? ? ?>> Dear all,
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> I have a set of data with has hourly value:
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> # ID
>      >? ? ? >? ? ? ?>> # Lo
>      >? ? ? >? ? ? ?>> # L
>      >? ? ? >? ? ? ?>> # Q
>      >? ? ? >? ? ? ?>> Time,? ? T, RH,PSFC,DIR,VEL10, PREC, RAD, CC,FOG
>      >? ? ? >? ? ? ?>> yyyy-mm-dd hh:mm,? ??C,? %, hPa, ?N,? m/s,
>     mm/h,W/m?,? %,-
>      >? ? ? >? ? ? ?>> 2012-01-01 06:00, -0.1,100, 815,313,? 2.6,? 0.0, 
>      ?0,? 0,0
>      >? ? ? >? ? ? ?>> 2012-01-01 07:00, -1.2, 93, 814,314,? 4.8,? 0.0, 
>      ?0,? 0,0
>      >? ? ? >? ? ? ?>> 2012-01-01 08:00,? 1.7, 68, 815,308,? 7.5,? 0.0, 
>     41, 11,0
>      >? ? ? >? ? ? ?>> 2012-01-01 09:00,? 2.4, 65, 815,308,? 7.4,? 0.0,
>     150, 33,0
>      >? ? ? >? ? ? ?>> .....
>      >? ? ? >? ? ? ?>> .....
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> I was able to read it,? create my-own data frame
>     and to
>      >? ? ?plot the
>      >? ? ? >? ? ? ?>total
>      >? ? ? >? ? ? ?>> cumulative function.
>      >? ? ? >? ? ? ?>> This is basically what I have done:
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> dati <- read.csv(file="116.txt", header=FALSE,
>     sep="," ,
>      >? ? ? >? ? ? ?>> na.strings="-999",skip = 6)
>      >? ? ? >? ? ? ?>> colnames(dati)=c("DATAORA","T",
>      >? ? ?"RH","PSFC","DIR","VEL10", "PREC",
>      >? ? ? >? ? ? ?>"RAD",
>      >? ? ? >? ? ? ?>> "CC","FOG")
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>>
>      >? ? ?dati$DATAORA<-as.POSIXct(strptime(dati$DATAORA,format="%Y-%m-%d
>      >? ? ? >? ? ? ?>%H:%M"))
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> P <- cumsum(dati$PREC)
>      >? ? ? >? ? ? ?>> plot(dati$DATAORA, P)
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> I would like to select the data according to an
>     starting
>      >? ? ?and ending
>      >? ? ? >? ? ? ?>date.
>      >? ? ? >? ? ? ?>> In addition, I would like to plot the monthly and not
>      >? ? ?the total one.
>      >? ? ? >? ? ? ?>> I mean, I would like to have a cumulative plot
>     for each
>      >? ? ?month of the
>      >? ? ? >? ? ? ?>> selected year.
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> I am struggling with "ddply" but probably it is the
>      >? ? ?wrong way.
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> Could someone help me?? Really Really thanks,
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> Diego
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>>? ? ? [[alternative HTML version deleted]]
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>> ______________________________________________
>      >? ? ? >? ? ? ?>> R-help at r-project.org
>     <mailto:R-help at r-project.org> <mailto:R-help at r-project.org
>     <mailto:R-help at r-project.org>>
>      >? ? ?mailing list -- To UNSUBSCRIBE and more, see
>      >? ? ? >? ? ? ?>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? >? ? ? ?>> PLEASE do read the posting guide
>      >? ? ? >? ? ? ?>http://www.R-project.org/posting-guide.html
>      >? ? ? >? ? ? ?>> and provide commented, minimal, self-contained,
>      >? ? ?reproducible code.
>      >? ? ? >? ? ? ?>>
>      >? ? ? >? ? ? ?>
>      >? ? ? >? ? ? ?>______________________________________________
>      >? ? ? >? ? ? ?>R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing
>      >? ? ?list -- To UNSUBSCRIBE and more, see
>      >? ? ? >? ? ? ?>https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? >? ? ? ?>PLEASE do read the posting guide
>      >? ? ? >? ? ? ?>http://www.R-project.org/posting-guide.html
>      >? ? ? >? ? ? ?>and provide commented, minimal, self-contained,
>      >? ? ?reproducible code.
>      >? ? ? >
>      >? ? ? >? ? ? ?--
>      >? ? ? >? ? ? ?Sent from my phone. Please excuse my brevity.
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >
>      >   
>      ?---------------------------------------------------------------------------
>      >? ? ?Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? ?.....     
>      ?.....? Go
>      >? ? ?Live...
>      >? ? ?DCN:<jdnewmil at dcn.davis.ca.us
>     <mailto:jdnewmil at dcn.davis.ca.us> <mailto:jdnewmil at dcn.davis.ca.us
>     <mailto:jdnewmil at dcn.davis.ca.us>>>
>      >? ? ? ? ? Basics: ##.#.? ? ? ?##.#.? Live Go...
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Live:? ?OO#.. Dead:
>     OO#..
>      >? ? ?Playing
>      >? ? ?Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.     
>      ?#.O#.? with
>      >? ? ?/Software/Embedded Controllers)? ? ? ? ? ? ? ?.OO#.? ? ? ?.OO#.
>      >? ? ?rocks...1k
>      >   
>      ?---------------------------------------------------------------------------
>      >
>


From rhe|p @end|ng |rom krueger-|@m||y@de  Mon Jan 28 12:43:15 2019
From: rhe|p @end|ng |rom krueger-|@m||y@de (Knut Krueger)
Date: Mon, 28 Jan 2019 12:43:15 +0100
Subject: [R] duplicates including first occurrence
Message-ID: <476e6b4b-d2d4-0a0a-b1d3-7833a82bfcf1@krueger-family.de>

Ho to all

i get the  results

mtcars[duplicated(mtcars$wt,fromLast=TRUE),]
Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4
Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4


mtcars[duplicated(mtcars$wt),]

Merc 280      19.2   6 167.6 123 3.92 3.44 18.3  1  0    4    4
Merc 280C     17.8   6 167.6 123 3.92 3.44 18.9  1  0    4    4
Maserati Bora 15.0   8 301.0 335 3.54 3.57 14.6  0  1    5    8


The first occurrence is missing - is there any possibility to get

Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4
Merc 280C         17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4
Duster 360    14.3   8  360 245 3.21 3.57 15.84  0  0    3    4
Maserati Bora 15.0   8  301 335 3.54 3.57 14.60  0  1    5    8


Kind regards Knut


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 28 12:51:37 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 28 Jan 2019 11:51:37 +0000
Subject: [R] duplicates including first occurrence
In-Reply-To: <476e6b4b-d2d4-0a0a-b1d3-7833a82bfcf1@krueger-family.de>
References: <476e6b4b-d2d4-0a0a-b1d3-7833a82bfcf1@krueger-family.de>
Message-ID: <10fa4e79-fa37-77cd-1077-6b9fc93f88ed@sapo.pt>

Hello,

Simply OR (|) both conditions.

mtcars[duplicated(mtcars$wt) | duplicated(mtcars$wt,fromLast=TRUE),]
#                   mpg cyl  disp  hp drat   wt  qsec vs am gear carb
#Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
#Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4
#Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4
#Merc 280C         17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4
#Maserati Bora     15.0   8 301.0 335 3.54 3.57 14.60  0  1    5    8


Hope this helps,

Rui Barradas

?s 11:43 de 28/01/2019, Knut Krueger via R-help escreveu:
> Ho to all
> 
> i get the? results
> 
> mtcars[duplicated(mtcars$wt,fromLast=TRUE),]
> Hornet Sportabout 18.7?? 8 360.0 175 3.15 3.44 17.02? 0? 0??? 3??? 2
> Duster 360??????? 14.3?? 8 360.0 245 3.21 3.57 15.84? 0? 0??? 3??? 4
> Merc 280????????? 19.2?? 6 167.6 123 3.92 3.44 18.30? 1? 0??? 4??? 4
> 
> 
> mtcars[duplicated(mtcars$wt),]
> 
> Merc 280????? 19.2?? 6 167.6 123 3.92 3.44 18.3? 1? 0??? 4??? 4
> Merc 280C???? 17.8?? 6 167.6 123 3.92 3.44 18.9? 1? 0??? 4??? 4
> Maserati Bora 15.0?? 8 301.0 335 3.54 3.57 14.6? 0? 1??? 5??? 8
> 
> 
> The first occurrence is missing - is there any possibility to get
> 
> Hornet Sportabout 18.7?? 8 360.0 175 3.15 3.44 17.02? 0? 0??? 3??? 2
> Merc 280????????? 19.2?? 6 167.6 123 3.92 3.44 18.30? 1? 0??? 4??? 4
> Merc 280C???????? 17.8?? 6 167.6 123 3.92 3.44 18.90? 1? 0??? 4??? 4
> Duster 360??? 14.3?? 8? 360 245 3.21 3.57 15.84? 0? 0??? 3??? 4
> Maserati Bora 15.0?? 8? 301 335 3.54 3.57 14.60? 0? 1??? 5??? 8
> 
> 
> Kind regards Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jan 28 17:00:02 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 28 Jan 2019 08:00:02 -0800
Subject: [R] duplicates including first occurrence
In-Reply-To: <10fa4e79-fa37-77cd-1077-6b9fc93f88ed@sapo.pt>
References: <476e6b4b-d2d4-0a0a-b1d3-7833a82bfcf1@krueger-family.de>
 <10fa4e79-fa37-77cd-1077-6b9fc93f88ed@sapo.pt>
Message-ID: <CAGxFJbRLXajo04G8=3N6K6zs9KJvCpbVM91nfZNynqu3TcnF_g@mail.gmail.com>

... Alternatively(but probably less efficient):

## the indexing logical vector
with(mtcars, wt %in% wt[duplicated(wt)] )

cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 28, 2019 at 3:53 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Simply OR (|) both conditions.
>
> mtcars[duplicated(mtcars$wt) | duplicated(mtcars$wt,fromLast=TRUE),]
> #                   mpg cyl  disp  hp drat   wt  qsec vs am gear carb
> #Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
> #Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4
> #Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4
> #Merc 280C         17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4
> #Maserati Bora     15.0   8 301.0 335 3.54 3.57 14.60  0  1    5    8
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:43 de 28/01/2019, Knut Krueger via R-help escreveu:
> > Ho to all
> >
> > i get the  results
> >
> > mtcars[duplicated(mtcars$wt,fromLast=TRUE),]
> > Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
> > Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4
> > Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4
> >
> >
> > mtcars[duplicated(mtcars$wt),]
> >
> > Merc 280      19.2   6 167.6 123 3.92 3.44 18.3  1  0    4    4
> > Merc 280C     17.8   6 167.6 123 3.92 3.44 18.9  1  0    4    4
> > Maserati Bora 15.0   8 301.0 335 3.54 3.57 14.6  0  1    5    8
> >
> >
> > The first occurrence is missing - is there any possibility to get
> >
> > Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2
> > Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4
> > Merc 280C         17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4
> > Duster 360    14.3   8  360 245 3.21 3.57 15.84  0  0    3    4
> > Maserati Bora 15.0   8  301 335 3.54 3.57 14.60  0  1    5    8
> >
> >
> > Kind regards Knut
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@k@hho||y @end|ng |rom gm@||@com  Mon Jan 28 17:16:17 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 28 Jan 2019 10:16:17 -0600
Subject: [R] positive deviance plot for Binomial distribution
In-Reply-To: <alpine.BSF.2.00.1901271812180.64040@pedal.dcn.davis.ca.us>
References: <CAM9Qe4iW+xkUhFjCnsZPFChgZ_RpWko8cP1_MLTkpNvPq0nfyQ@mail.gmail.com>
 <alpine.BSF.2.00.1901271812180.64040@pedal.dcn.davis.ca.us>
Message-ID: <CAM9Qe4gRsePbk2H=kUC5bYi-_1wcQAiG5vSZiFx_japYAk_4_w@mail.gmail.com>

Hi Jeff;

Thanks so much for this. I would try to reformulate what you suggested.
Your help is highly appreciated

Regards,
Greg



On Sun, Jan 27, 2019 at 8:16 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I haven't found much call to mess with this, but I think the built-in
> "glm" function could do it. You might have to reformulate the inputs to
> outcome/observation (ratio) and outcome+observation (weight) to get glm to
> accept it [1]... but I am not sure.  What I am somewhat more sure of is
> that your description sounds an awful lot like a q-q plot which is one of
> the standard outputs when you plot a regression model.
>
> [1]
>
> https://stats.stackexchange.com/questions/322038/input-format-for-binomial-glm-in-r
>
>
> On Fri, 25 Jan 2019, greg holly wrote:
>
> > Hi Dear all;
> >
> > I have binomially distributed data (a small portion is given below) and I
> > would like to create a distribution plot for positive deviance with
> > "Probability of results" at Y axis and "percentage of outcome" at the
> > x-axis. I wondered anyone knows the name of R  library for this.
> >
> > Regards,
> >
> > Greg
> >
> > provider outcome observation
> > 1               14            27
> > 2                11           33
> > 3                9             17
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Jan 28 19:41:54 2019
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 28 Jan 2019 19:41:54 +0100
Subject: [R] Randomization Test
Message-ID: <CAC8ss32K6KNVYUgiJmmw6UParhgjyQJAp9t8q2CdMjKakzHOrg@mail.gmail.com>

Dear Contributors,

I conducting epoch analysis. I tried to test the significance of my
result using randomization test.

Since I have 71 events, I randomly selected another 71 events, making
sure that none of the dates in the random events corresponds with the
ones in the real event.

Following the code I found here
(https://www.uvm.edu/~dhowell/StatPages/R/RandomizationTestsWithR/Random2Sample/TwoIndependentSamplesR.html),
I combined these two data set and used them to generate another 5000
events. I then plotted the graph of the mean differences for the 5000
randomly generated events. On the graph, I indicated the region of the
mean difference between the real 71 epoch and the randomly selected 71
epoch.

Since the two tail test shows that the mean difference falls at the
extreme of the randomly selected events, I concluded that my result is
statistically significant.



I am attaching the graph to assistance you in you suggestions.

I can attach both my code and the real and randomly generated events
if you ask for it.

My request is that you help me to understand if I am on the right
track or no. This is the first time I am doing this and except the
experts decide, I am not quite sure whether I am right or not.

Many thanks for your kind concern.

Best
Ogbos

From h@|||e@k@me@ch @end|ng |rom gm@||@com  Mon Jan 28 20:21:05 2019
From: h@|||e@k@me@ch @end|ng |rom gm@||@com (Hallie Kamesch)
Date: Mon, 28 Jan 2019 13:21:05 -0600
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
 <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>
Message-ID: <134463C5-39A8-401D-A914-0341133C1F7D@gmail.com>

Hi all, 
Thank you for your responses. You are correct that it is not a matrix. I used the incorrect term. 
I meant I put my data in a spreadsheet with three rows and 24 columns. 

Sent from my iPhone

> On Jan 28, 2019, at 3:36 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Halllie,
> As Jeff noted, a data frame is not a matrix (it is a variety of list),
> so that looks like your problem.
> 
> hkdf<-data.frame(sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE),
> sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE))
> library(irr)
> kripp.alpha(hkdf)
> kripp.alpha(as.matrix(hkdf))
> 
> Jim
> 
>> On Mon, Jan 28, 2019 at 6:04 PM Hallie Kamesch <hallie.kamesch at gmail.com> wrote:
>> 
>> Hi -
>> I'm trying to run Krippendorff's alpha for data consisting of 4 subjects
>> rated on 6 events each by three raters.  The ratings are interval ratio
>> scale data.
>> 
>> I've rearranged my data into a 3 x 24  of ratersXevents. (per this
>> discussion on CrossValidated: (
>> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144)
>> ).
>> 
>> This is the code I've used:
>> library(irr)
>> dat <- read.csv(file.choose(), header = TRUE)
>> head(dat)
>> kripp.alpha(dat, method=c("ratio"))
>> #### error message: Error in sort.list(y) : 'x' must be atomic for
>> 'sort.list'
>> Have you called 'sort' on a list?
>> kripp.alpha(dat,"ratio")
>> #### error message: Error in sort.list(y) : 'x' must be atomic for
>> 'sort.list'
>> Have you called 'sort' on a list?
>> 
>> I read rhelp on sort, but I'm still confused.  Please help!
>> Thank you!
>> 
>> PS
>> I arranged my data in that matrix based upon this comment and response from
>> the CrossValidated posting forum (
>> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144),
>> but my question above was rejected there.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @|@n|00 @end|ng |rom comc@@t@net  Mon Jan 28 22:05:03 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Mon, 28 Jan 2019 14:05:03 -0700
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
Message-ID: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>

Hi,

I recently learned of the existence of R through a physicist friend who 
uses it in his research. I've used Octave for a decade, and C for 35 
years, but would like to learn R. These all have advantages and 
disadvantages for certain tasks, but as I'm new to R I hardly know how 
to evaluate them. Any suggestions?

Thanks!

---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Jan 29 00:20:46 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 29 Jan 2019 12:20:46 +1300
Subject: [R] 
 [FORGED]  Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
Message-ID: <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>


On 1/29/19 10:05 AM, Alan Feuerbacher wrote:

> Hi,
> 
> I recently learned of the existence of R through a physicist friend who 
> uses it in his research. I've used Octave for a decade, and C for 35 
> years, but would like to learn R. These all have advantages and 
> disadvantages for certain tasks, but as I'm new to R I hardly know how 
> to evaluate them. Any suggestions?

* C is fast, but with a syntax that is (to my mind) virtually
   incomprehensible.  (You probably think differently about this.)

* In C, you essentially have to roll your own for all tasks; in R,
   practically anything (well ...) that you want to do has already
   been programmed up.  CRAN is a wonderful resource, and there's more
   on github.

* The syntax of R meshes beautifully with *my* thought patterns; YMMV.

* Why not just bog in and try R out?  It's free, it's readily available,
   and there are a number of good online tutorials.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ggrothend|eck @end|ng |rom gm@||@com  Tue Jan 29 00:32:49 2019
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Mon, 28 Jan 2019 18:32:49 -0500
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
Message-ID: <CAP01uR=3gt4JLmcwd4DkMwW+H-RbXzqsxzS1k+8dkE1A7Wycug@mail.gmail.com>

R has many similarities to Octave.  Have a look at:

https://cran.r-project.org/doc/contrib/R-and-octave.txt
https://CRAN.R-project.org/package=matconv

On Mon, Jan 28, 2019 at 4:58 PM Alan Feuerbacher <alanf00 at comcast.net> wrote:
>
> Hi,
>
> I recently learned of the existence of R through a physicist friend who
> uses it in his research. I've used Octave for a decade, and C for 35
> years, but would like to learn R. These all have advantages and
> disadvantages for certain tasks, but as I'm new to R I hardly know how
> to evaluate them. Any suggestions?
>
> Thanks!
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From @|@n|00 @end|ng |rom comc@@t@net  Tue Jan 29 01:00:07 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Mon, 28 Jan 2019 17:00:07 -0700
Subject: [R] 
 [FORGED]  Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
Message-ID: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>

On 1/28/2019 4:20 PM, Rolf Turner wrote:
> 
> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
> 
>> Hi,
>>
>> I recently learned of the existence of R through a physicist friend 
>> who uses it in his research. I've used Octave for a decade, and C for 
>> 35 years, but would like to learn R. These all have advantages and 
>> disadvantages for certain tasks, but as I'm new to R I hardly know how 
>> to evaluate them. Any suggestions?
> 
> * C is fast, but with a syntax that is (to my mind) virtually
>  ? incomprehensible.? (You probably think differently about this.)

I've been doing it long enough that I have little problem with it, 
except for pointers. :-)

> * In C, you essentially have to roll your own for all tasks; in R,
>  ? practically anything (well ...) that you want to do has already
>  ? been programmed up.? CRAN is a wonderful resource, and there's more
>  ? on github.
 >
> * The syntax of R meshes beautifully with *my* thought patterns; YMMV.
> 
> * Why not just bog in and try R out?? It's free, it's readily available,
>  ? and there are a number of good online tutorials.

I just installed R on my Linux Fedora system, so I'll do that.

I wonder if you'd care to comment on my little project that prompted 
this? As part of another project, I wanted to model population growth 
starting from a handful of starting individuals. This is exponential in 
the long run, of course, but I wanted to see how a few basic parameters 
affected the outcome. Using Octave, I modeled a single person as a 
"cell", which in Octave has a good deal of overhead. The program 
basically looped over the entire population, and updated each person 
according to the parameters, which included random statistical 
variations. So when the total population reached, say 10,000, and an 
update time of 1 day, the program had to execute 10,000 x 365 update 
operations for each year of growth. For large populations, say 100,000, 
the program did not return even after 24 hours of run time.

So I switched to C, and used its "struct" declaration and an array of 
structs to model the population. This allowed the program to complete in 
under a minute as opposed to 24 hours+. So in line with your comments, C 
is far more efficient than Octave.

How do you think R would fare in this simulation?

Alan


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 29 01:17:08 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 28 Jan 2019 16:17:08 -0800
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
Message-ID: <CAGxFJbSLqnoi9JBw9hvHuaMEkqV5rh8vZRxcyXZdETyhLcdsAg@mail.gmail.com>

I would say your question is foolish -- you disagree no doubt! -- because
the point of using R (or Octave or C++) is to take advantage of the
packages (= "libraries" in some languages; a library is something different
in R) it (or they) offers to simplify your task. Many of R's libraries are
written in C (or Fortran) an thus **are** fast as well as having
task-appropriate functionality and UI's .

So I think instead of pursuing this discussion you would do well to search.
I find rseek.org to be especially good for this sort of thing. Searching
there on "demography" brought up what appeared to be many appropriate hits
-- including the "demography" package! -- which you could then examine to
see whether and to what extent they provide the functionality you seek.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 28, 2019 at 4:00 PM Alan Feuerbacher <alanf00 at comcast.net>
wrote:

> On 1/28/2019 4:20 PM, Rolf Turner wrote:
> >
> > On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
> >
> >> Hi,
> >>
> >> I recently learned of the existence of R through a physicist friend
> >> who uses it in his research. I've used Octave for a decade, and C for
> >> 35 years, but would like to learn R. These all have advantages and
> >> disadvantages for certain tasks, but as I'm new to R I hardly know how
> >> to evaluate them. Any suggestions?
> >
> > * C is fast, but with a syntax that is (to my mind) virtually
> >    incomprehensible.  (You probably think differently about this.)
>
> I've been doing it long enough that I have little problem with it,
> except for pointers. :-)
>
> > * In C, you essentially have to roll your own for all tasks; in R,
> >    practically anything (well ...) that you want to do has already
> >    been programmed up.  CRAN is a wonderful resource, and there's more
> >    on github.
>  >
> > * The syntax of R meshes beautifully with *my* thought patterns; YMMV.
> >
> > * Why not just bog in and try R out?  It's free, it's readily available,
> >    and there are a number of good online tutorials.
>
> I just installed R on my Linux Fedora system, so I'll do that.
>
> I wonder if you'd care to comment on my little project that prompted
> this? As part of another project, I wanted to model population growth
> starting from a handful of starting individuals. This is exponential in
> the long run, of course, but I wanted to see how a few basic parameters
> affected the outcome. Using Octave, I modeled a single person as a
> "cell", which in Octave has a good deal of overhead. The program
> basically looped over the entire population, and updated each person
> according to the parameters, which included random statistical
> variations. So when the total population reached, say 10,000, and an
> update time of 1 day, the program had to execute 10,000 x 365 update
> operations for each year of growth. For large populations, say 100,000,
> the program did not return even after 24 hours of run time.
>
> So I switched to C, and used its "struct" declaration and an array of
> structs to model the population. This allowed the program to complete in
> under a minute as opposed to 24 hours+. So in line with your comments, C
> is far more efficient than Octave.
>
> How do you think R would fare in this simulation?
>
> Alan
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Tue Jan 29 01:20:14 2019
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Mon, 28 Jan 2019 19:20:14 -0500
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
Message-ID: <CAP01uR=NttgpYsCL1-1td2C4oF8Kn+1ss+fbnJ0cfHHsV3Rpug@mail.gmail.com>

This would be a suitable application for NetLogo.  The R package
RNetLogo provides an interface.  In a few lines of code you get a
simulation with graphics.

On Mon, Jan 28, 2019 at 7:00 PM Alan Feuerbacher <alanf00 at comcast.net> wrote:
>
> On 1/28/2019 4:20 PM, Rolf Turner wrote:
> >
> > On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
> >
> >> Hi,
> >>
> >> I recently learned of the existence of R through a physicist friend
> >> who uses it in his research. I've used Octave for a decade, and C for
> >> 35 years, but would like to learn R. These all have advantages and
> >> disadvantages for certain tasks, but as I'm new to R I hardly know how
> >> to evaluate them. Any suggestions?
> >
> > * C is fast, but with a syntax that is (to my mind) virtually
> >    incomprehensible.  (You probably think differently about this.)
>
> I've been doing it long enough that I have little problem with it,
> except for pointers. :-)
>
> > * In C, you essentially have to roll your own for all tasks; in R,
> >    practically anything (well ...) that you want to do has already
> >    been programmed up.  CRAN is a wonderful resource, and there's more
> >    on github.
>  >
> > * The syntax of R meshes beautifully with *my* thought patterns; YMMV.
> >
> > * Why not just bog in and try R out?  It's free, it's readily available,
> >    and there are a number of good online tutorials.
>
> I just installed R on my Linux Fedora system, so I'll do that.
>
> I wonder if you'd care to comment on my little project that prompted
> this? As part of another project, I wanted to model population growth
> starting from a handful of starting individuals. This is exponential in
> the long run, of course, but I wanted to see how a few basic parameters
> affected the outcome. Using Octave, I modeled a single person as a
> "cell", which in Octave has a good deal of overhead. The program
> basically looped over the entire population, and updated each person
> according to the parameters, which included random statistical
> variations. So when the total population reached, say 10,000, and an
> update time of 1 day, the program had to execute 10,000 x 365 update
> operations for each year of growth. For large populations, say 100,000,
> the program did not return even after 24 hours of run time.
>
> So I switched to C, and used its "struct" declaration and an array of
> structs to model the population. This allowed the program to complete in
> under a minute as opposed to 24 hours+. So in line with your comments, C
> is far more efficient than Octave.
>
> How do you think R would fare in this simulation?
>
> Alan
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdun|@p @end|ng |rom t|bco@com  Tue Jan 29 02:07:41 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 28 Jan 2019 17:07:41 -0800
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
Message-ID: <CAF8bMcaW5HnDukAczPAgO6KrUimb7euU8Kd0awzDnkaZd4U5LA@mail.gmail.com>

S (R's predecessor) was designed by and for data analysts.  R generally
follows that tradition.  I think that simulations such as yours are not its
strength, although it can make analyzing (graphically and numerically) the
results of the simulation fun.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Jan 28, 2019 at 4:00 PM Alan Feuerbacher <alanf00 at comcast.net>
wrote:

> On 1/28/2019 4:20 PM, Rolf Turner wrote:
> >
> > On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
> >
> >> Hi,
> >>
> >> I recently learned of the existence of R through a physicist friend
> >> who uses it in his research. I've used Octave for a decade, and C for
> >> 35 years, but would like to learn R. These all have advantages and
> >> disadvantages for certain tasks, but as I'm new to R I hardly know how
> >> to evaluate them. Any suggestions?
> >
> > * C is fast, but with a syntax that is (to my mind) virtually
> >    incomprehensible.  (You probably think differently about this.)
>
> I've been doing it long enough that I have little problem with it,
> except for pointers. :-)
>
> > * In C, you essentially have to roll your own for all tasks; in R,
> >    practically anything (well ...) that you want to do has already
> >    been programmed up.  CRAN is a wonderful resource, and there's more
> >    on github.
>  >
> > * The syntax of R meshes beautifully with *my* thought patterns; YMMV.
> >
> > * Why not just bog in and try R out?  It's free, it's readily available,
> >    and there are a number of good online tutorials.
>
> I just installed R on my Linux Fedora system, so I'll do that.
>
> I wonder if you'd care to comment on my little project that prompted
> this? As part of another project, I wanted to model population growth
> starting from a handful of starting individuals. This is exponential in
> the long run, of course, but I wanted to see how a few basic parameters
> affected the outcome. Using Octave, I modeled a single person as a
> "cell", which in Octave has a good deal of overhead. The program
> basically looped over the entire population, and updated each person
> according to the parameters, which included random statistical
> variations. So when the total population reached, say 10,000, and an
> update time of 1 day, the program had to execute 10,000 x 365 update
> operations for each year of growth. For large populations, say 100,000,
> the program did not return even after 24 hours of run time.
>
> So I switched to C, and used its "struct" declaration and an array of
> structs to model the population. This allowed the program to complete in
> under a minute as opposed to 24 hours+. So in line with your comments, C
> is far more efficient than Octave.
>
> How do you think R would fare in this simulation?
>
> Alan
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 29 03:51:04 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Jan 2019 18:51:04 -0800
Subject: [R] 
 [FORGED]  Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
Message-ID: <24250968-5B39-4CEC-8649-406716F9780E@dcn.davis.ca.us>

If you forge on with your preconceptions of how such a simulation should be implemented then you will be able to reproduce your failure just as spectacularly using R as you did using Octave. It is crucial to employ vectorization of your algorithms if you want good performance with either Octave or R. That vectorization may either be over time or over separate simulations.

I am running simulations of a million cases of power plant performance over 25 years in about a minute. I know someone who used R to simulate a CFD river flow problem in a class in a few minutes, while others using Fortran or Matlab were struggling to get comparable runs completed in many hours. I believe the difference was in how the data were structured and manipulated more than the language that was being used. I think the strong capabilities for presenting results using R makes using it advantageous over Octave, though.

If your problems truly need a compiled language, the Rcpp package lets you mix C++ with R quite easily and then you get the best of both worlds. (C and Fortran are supported, but they are a bit more finicky to setup than C++).

On January 28, 2019 4:00:07 PM PST, Alan Feuerbacher <alanf00 at comcast.net> wrote:
>On 1/28/2019 4:20 PM, Rolf Turner wrote:
>> 
>> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>> 
>>> Hi,
>>>
>>> I recently learned of the existence of R through a physicist friend 
>>> who uses it in his research. I've used Octave for a decade, and C
>for 
>>> 35 years, but would like to learn R. These all have advantages and 
>>> disadvantages for certain tasks, but as I'm new to R I hardly know
>how 
>>> to evaluate them. Any suggestions?
>> 
>> * C is fast, but with a syntax that is (to my mind) virtually
>>  ? incomprehensible.? (You probably think differently about this.)
>
>I've been doing it long enough that I have little problem with it, 
>except for pointers. :-)
>
>> * In C, you essentially have to roll your own for all tasks; in R,
>>  ? practically anything (well ...) that you want to do has already
>>  ? been programmed up.? CRAN is a wonderful resource, and there's
>more
>>  ? on github.
> >
>> * The syntax of R meshes beautifully with *my* thought patterns;
>YMMV.
>> 
>> * Why not just bog in and try R out?? It's free, it's readily
>available,
>>  ? and there are a number of good online tutorials.
>
>I just installed R on my Linux Fedora system, so I'll do that.
>
>I wonder if you'd care to comment on my little project that prompted 
>this? As part of another project, I wanted to model population growth 
>starting from a handful of starting individuals. This is exponential in
>
>the long run, of course, but I wanted to see how a few basic parameters
>
>affected the outcome. Using Octave, I modeled a single person as a 
>"cell", which in Octave has a good deal of overhead. The program 
>basically looped over the entire population, and updated each person 
>according to the parameters, which included random statistical 
>variations. So when the total population reached, say 10,000, and an 
>update time of 1 day, the program had to execute 10,000 x 365 update 
>operations for each year of growth. For large populations, say 100,000,
>
>the program did not return even after 24 hours of run time.
>
>So I switched to C, and used its "struct" declaration and an array of 
>structs to model the population. This allowed the program to complete
>in 
>under a minute as opposed to 24 hours+. So in line with your comments,
>C 
>is far more efficient than Octave.
>
>How do you think R would fare in this simulation?
>
>Alan
>
>
>---
>This email has been checked for viruses by Avast antivirus software.
>https://www.avast.com/antivirus
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@tteo@|@@|o|o @end|ng |rom gm@||@com  Mon Jan 28 13:08:08 2019
From: m@tteo@|@@|o|o @end|ng |rom gm@||@com (Matteo Fasiolo)
Date: Mon, 28 Jan 2019 13:08:08 +0100
Subject: [R] [R-pkgs] mgcViz: scalable ggplot2 visualisations for mgcv
Message-ID: <CAC_0WE9WJDzXFXwwnc_tvYfea6+RX3_8QA+7hBqG8smZp0RZrg@mail.gmail.com>

Dear useRs,

 I am pleased to announce the publication of mgcViz 0.1.3 on CRAN:
https://cran.r-project.org/web/packages/mgcViz/index.html

mgcViz is an extension of mgcv, and provides a layered ggplot2-based
visualisation framework for GAM models. In addition to layered smooth effect
plots, mgcViz offers:
- new scalable methods for model building and checking;
- interactive 3D visualisations via the rgl package;
- methods for approximate Bayesian posterior simulation.

For examples see the articles on mgcViz's website:
https://mfasiolo.github.io/mgcViz/
while for more details on the underlying methods see:
https://arxiv.org/abs/1809.10632

The package is also available on github:
https://github.com/mfasiolo/mgcViz
so feel free to send comments, criticisms and feature requests via Github
issues.

Matteo Fasiolo

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From chr|@t|@n@henn|g @end|ng |rom un|bo@|t  Mon Jan 28 16:58:59 2019
From: chr|@t|@n@henn|g @end|ng |rom un|bo@|t (Christian Martin Hennig)
Date: Mon, 28 Jan 2019 15:58:59 +0000
Subject: [R] R package installation error
Message-ID: <9356b271-7184-53eb-3394-77b477301dc2@unibo.it>

Hi there,

I'm running R version 3.5.2 on Linux Mint. I try install.packages("hierfstat") and get this:

** byte-compile and prepare package for lazy loading

Error in rbind(info, getNamespaceInfo(env, "S3methods")) :

number of columns of matrices must match (see arg 2)

ERROR: lazy loading failed for package ?hierfstat?"

As far as I can see on CRAN, all should be fine with that package. Can anybody tell me what's wrong here?

Thanks,

Christian

--
Christian Hennig
Dipartimento di Scienze Statistiche "Paolo Fortunati",
Universita di Bologna, phone +39 05120 98163
christian.hennig at unibo.it<mailto:christian.hennig at unibo.it>
currently on leave from UCL; UCL email still works

	[[alternative HTML version deleted]]


From m@k@hho||y @end|ng |rom gm@||@com  Mon Jan 28 17:37:06 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Mon, 28 Jan 2019 10:37:06 -0600
Subject: [R] graphs SAS and R
Message-ID: <CAM9Qe4jjc2ESW6dLz=eR4EwHRB7qsV+OvyGG_d2KmsqRmFTLYw@mail.gmail.com>



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Medpage-Guide-to-Biostatistics.pdf
Type: application/pdf
Size: 389348 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190128/0d29b281/attachment-0002.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Nice_graphsmro1.pdf
Type: application/pdf
Size: 5654503 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190128/0d29b281/attachment-0003.pdf>

From ngxxx262 @end|ng |rom umn@edu  Tue Jan 29 00:39:46 2019
From: ngxxx262 @end|ng |rom umn@edu (Weiwen Ng, MPH)
Date: Mon, 28 Jan 2019 17:39:46 -0600
Subject: [R] Recommendations for a package capable of doing latent class
 regression with mixed indicator types
Message-ID: <CAB7px-a6+tZXkr9Pt0DBVUa9GQwmrcsoSpZ-ayvNRTUQYcXK9A@mail.gmail.com>

Dear R users,

Does anyone have a recommendation for an R package that can:

   1. Handle mixed types of indicators (in my case, both binary and
   Gaussian)
   2. Fit a latent class regression (i.e. use observed covariates to
   predict latent class membership)?
   3. Incorporate programs to do things like profile plots of class
   characteristics?

I'm aware of 3 packages that can do some of what I want. The depmixS4
package does 1 and 2, but doesn't appear to have native graphing
facilities. poLCA does 2 and 3, but it only takes binary and ordinal
indicators. flexmix appears to do 1 and 3, but it doesn't appear to perform
latent class regression.

I've done all 3 of the above in Stata 15, and I'm actually much more
proficient in Stata, but I will have some trouble accessing that program
for this project thanks to institutional changes (long story, don't want to
explain, but I could access that software if there's no R alternative). I
would like to know if I've missed any packages in my survey, or if I'm
misreading the capabilities of the packages, or if graphing is easier than
I think it is.

Thanks,

Weiwen Ng, MPH

University of Minnesota

School of Public Health

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jan 29 08:33:46 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 28 Jan 2019 23:33:46 -0800
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
Message-ID: <3384bdbc-23bc-afc2-65c5-0ed0778de4ff@comcast.net>


On 1/28/19 4:00 PM, Alan Feuerbacher wrote:
> On 1/28/2019 4:20 PM, Rolf Turner wrote:
>>
>> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>>
>>> Hi,
>>>
>>> I recently learned of the existence of R through a physicist friend 
>>> who uses it in his research. I've used Octave for a decade, and C 
>>> for 35 years, but would like to learn R. These all have advantages 
>>> and disadvantages for certain tasks, but as I'm new to R I hardly 
>>> know how to evaluate them. Any suggestions?
>> >
> snpped
>> * The syntax of R meshes beautifully with *my* thought patterns; YMMV.
>>
>> * Why not just bog in and try R out?? It's free, it's readily available,
>> ?? and there are a number of good online tutorials.
>
> I just installed R on my Linux Fedora system, so I'll do that.
>
> I wonder if you'd care to comment on my little project that prompted 
> this? As part of another project, I wanted to model population growth 
> starting from a handful of starting individuals. This is exponential 
> in the long run, of course, but I wanted to see how a few basic 
> parameters affected the outcome. Using Octave, I modeled a single 
> person as a "cell", which in Octave has a good deal of overhead. The 
> program basically looped over the entire population, and updated each 
> person according to the parameters, which included random statistical 
> variations. So when the total population reached, say 10,000, and an 
> update time of 1 day, the program had to execute 10,000 x 365 update 
> operations for each year of growth. For large populations, say 
> 100,000, the program did not return even after 24 hours of run time.
>
> So I switched to C, and used its "struct" declaration and an array of 
> structs to model the population. This allowed the program to complete 
> in under a minute as opposed to 24 hours+. So in line with your 
> comments, C is far more efficient than Octave.
>
> How do you think R would fare in this simulation?
>
This sounds like a problem that would fit into a stochastic differential 
equation.? There are at least three packages in CRAN (and I suspect a 
few more) that will handle simulations of stochastic differential 
equations. Bert's suggestion to use Rseek should serve you well.


-- 

David.


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jan 29 09:06:41 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 29 Jan 2019 08:06:41 +0000
Subject: [R] Your input
In-Reply-To: <CAD5R06ScrU7kYnSaKVtpRwt=3CW-grxSQ=cKpQ8JwnA9ucytZA@mail.gmail.com>
References: <CAD5R06ScrU7kYnSaKVtpRwt=3CW-grxSQ=cKpQ8JwnA9ucytZA@mail.gmail.com>
Message-ID: <454b8d934da74fc08d44d643fd8e026f@SRVEXCHCM1302.precheza.cz>

Hm.


  1.  You should always keep your responses to R helplist, others could have different views.
  2.  Error is quite clear to me, deptest2 is not numeric.

If it was you would not observe such error.
> temp <- bl[,-1]
> cor(temp)
          spolej     dehtv     dehta      dinp
spolej 1.0000000 0.7234237 0.4205311 0.4310729
dehtv  0.7234237 1.0000000 0.8743103 0.8766513
dehta  0.4205311 0.8743103 1.0000000 0.9975101
dinp   0.4310729 0.8766513 0.9975101 1.0000000
> cor(bl)
Error in cor(bl) : 'x' must be numeric
> lapply(bl,is.numeric)
$`sarze`
[1] FALSE
$spolej
[1] TRUE
$dehtv
[1] TRUE
$dehta
[1] TRUE
$dinp
[1] TRUE


  1.  Attaching Excel data is pointless. What matters is your objects in R, which you could easily inspect by
?str or head(yourobject)


  1.  For R objects exchange through this list
?dput is the only reasonable way.


  1.  You definitely do not know R basics and want to do highly sophisticated analysis. Spending few hours reading R intro could save you much time and headache.

Sorry, I could not help you with network analysis as I do not know anything about it.

Cheers
Petr

From: Bhubaneswor Dhakal <bhubaneswordhakal at gmail.com>
Sent: Tuesday, January 29, 2019 12:32 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Your input

Hi Petr

1. I read your online material but could not figure out the r code to get network result to compare between control and treatment groups. Can you please specify the code?

2. I used many types of r code to get correlation matrix of some observation missing data but non of them worked. But every time I run r study, I get the following error message:

Error in cor(deptest2, use = "complete.obs") : 'x' must be numeric

Can you please advise me where is the problem?
1.  corMat<-cor(mydata2, use= "complete.obs")
2. corMat<-cor(mydata2, use= "all.obs")
3. corMat<-cor(mydata2, use= "pairwise.complete.obs")
4. corMat<-cor(mydata2, use= "na or pairwise.complete.obs")
A sample of my data is attached. I have excluded serial ID and treatment ID in the data. Every alternative row is treated and the another row is control.

I would be indebted if you provide me help to resolve the TWO problems?-
Thank you.
Best Wishes.
Bhubaneswor Dhakal




Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Tue Jan 29 16:11:14 2019
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Tue, 29 Jan 2019 10:11:14 -0500
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <CAP01uR=3gt4JLmcwd4DkMwW+H-RbXzqsxzS1k+8dkE1A7Wycug@mail.gmail.com>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <CAP01uR=3gt4JLmcwd4DkMwW+H-RbXzqsxzS1k+8dkE1A7Wycug@mail.gmail.com>
Message-ID: <CAP01uRkSoP5kPeYDBrOaYiC7R4JUrMtRDgiCNmVWrw-Atz8NCg@mail.gmail.com>

Two additional comments:

- depending on the nature of your problem you may be able to get an
analytic solution using branching processes. I found this approach
successful when I once had to model stem cell growth.

- in addition to NetLogo another alternative to R would be the Julia
language which is motivated to some degree by Octave but is actually
quite different and is particularly suitable in terms of performance
for iterative computations where one iteration depends on the prior
one.

On Mon, Jan 28, 2019 at 6:32 PM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> R has many similarities to Octave.  Have a look at:
>
> https://cran.r-project.org/doc/contrib/R-and-octave.txt
> https://CRAN.R-project.org/package=matconv
>
> On Mon, Jan 28, 2019 at 4:58 PM Alan Feuerbacher <alanf00 at comcast.net> wrote:
> >
> > Hi,
> >
> > I recently learned of the existence of R through a physicist friend who
> > uses it in his research. I've used Octave for a decade, and C for 35
> > years, but would like to learn R. These all have advantages and
> > disadvantages for certain tasks, but as I'm new to R I hardly know how
> > to evaluate them. Any suggestions?
> >
> > Thanks!
> >
> > ---
> > This email has been checked for viruses by Avast antivirus software.
> > https://www.avast.com/antivirus
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From |@h@rre|| @end|ng |rom vumc@org  Tue Jan 29 17:24:25 2019
From: |@h@rre|| @end|ng |rom vumc@org (Harrell, Frank E)
Date: Tue, 29 Jan 2019 16:24:25 +0000
Subject: [R] [R-pkgs] Significant Update to Hmisc Package
In-Reply-To: <DM5PR1201MB0009361609C41F4B7B3A891E87970@DM5PR1201MB0009.namprd12.prod.outlook.com>
References: <DM5PR1201MB0009361609C41F4B7B3A891E87970@DM5PR1201MB0009.namprd12.prod.outlook.com>
Message-ID: <DM5PR1201MB000998F27B394AB4A6037C6987970@DM5PR1201MB0009.namprd12.prod.outlook.com>



There have been a significant number of bug fixes and updates to the Hmisc package.  See the following for the list of changes: https://cran.r-project.org/web/packages/Hmisc/NEWS

cran.r-project.org<https://cran.r-project.org/web/packages/Hmisc/NEWS>
cran.r-project.org
Changes in version 4.1-1 (2018-01-03)) * describe: quit rounding values when = 20 distinct values no matter how far apart any two values are spaced.https ...




________________________________
Frank E Harrell Jr      Professor       School of Medicine

        Department of Biostatistics             Vanderbilt University


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From h@|||e@k@me@ch @end|ng |rom gm@||@com  Tue Jan 29 17:56:17 2019
From: h@|||e@k@me@ch @end|ng |rom gm@||@com (Hallie Kamesch)
Date: Tue, 29 Jan 2019 10:56:17 -0600
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <134463C5-39A8-401D-A914-0341133C1F7D@gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
 <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>
 <134463C5-39A8-401D-A914-0341133C1F7D@gmail.com>
Message-ID: <CACp+zAsn1bL2VeZDRC5k8A1VXmi8FLX-cXfaH+A0Tmtd29M_RQ@mail.gmail.com>

Thank you Jim, for the code, and thank you Jeff for the tutorial PDF.  I've
read through the sections and I appreciate the help.
I'm in way over my head - I don't even understand enough of the vocabulary
to ask my question correctly.
Jim, in your code, I ended up with an entry of 4 observations of 6
variables. I understand how that happened now since I read your code - that
helped very much.
My only problem, that I can't figure out, is how to make it so I have 3
raters with 4 observations of 6 variables.
I really am trying to educate myself enough to not waste your time:  I've
?data.frame, ?sample, ?matrix, ?$names, ?attributes, etc... I read the
sections in Jeff's PDF, and the tutorials on datamentor, I'm just not
finding how to do this. I'm sorry this is such a newbie question.
thank you for your time,
hallie

On Mon, Jan 28, 2019 at 1:21 PM Hallie Kamesch <hallie.kamesch at gmail.com>
wrote:

> Hi all,
> Thank you for your responses. You are correct that it is not a matrix. I
> used the incorrect term.
> I meant I put my data in a spreadsheet with three rows and 24 columns.
>
> Sent from my iPhone
>
> > On Jan 28, 2019, at 3:36 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Halllie,
> > As Jeff noted, a data frame is not a matrix (it is a variety of list),
> > so that looks like your problem.
> >
> >
> hkdf<-data.frame(sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE),
> > sample(3:5,4,TRUE),sample(1:3,4,TRUE),sample(2:4,4,TRUE))
> > library(irr)
> > kripp.alpha(hkdf)
> > kripp.alpha(as.matrix(hkdf))
> >
> > Jim
> >
> >> On Mon, Jan 28, 2019 at 6:04 PM Hallie Kamesch <
> hallie.kamesch at gmail.com> wrote:
> >>
> >> Hi -
> >> I'm trying to run Krippendorff's alpha for data consisting of 4 subjects
> >> rated on 6 events each by three raters.  The ratings are interval ratio
> >> scale data.
> >>
> >> I've rearranged my data into a 3 x 24  of ratersXevents. (per this
> >> discussion on CrossValidated: (
> >>
> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144
> )
> >> ).
> >>
> >> This is the code I've used:
> >> library(irr)
> >> dat <- read.csv(file.choose(), header = TRUE)
> >> head(dat)
> >> kripp.alpha(dat, method=c("ratio"))
> >> #### error message: Error in sort.list(y) : 'x' must be atomic for
> >> 'sort.list'
> >> Have you called 'sort' on a list?
> >> kripp.alpha(dat,"ratio")
> >> #### error message: Error in sort.list(y) : 'x' must be atomic for
> >> 'sort.list'
> >> Have you called 'sort' on a list?
> >>
> >> I read rhelp on sort, but I'm still confused.  Please help!
> >> Thank you!
> >>
> >> PS
> >> I arranged my data in that matrix based upon this comment and response
> from
> >> the CrossValidated posting forum (
> >>
> https://stats.stackexchange.com/questions/255164/inter-rater-reliability-for-binomial-repeated-ratings-from-two-or-more-raters/256144#256144
> ),
> >> but my question above was rejected there.
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r|ch@rd@k@ev@n@ @end|ng |rom n@@@@gov  Tue Jan 29 18:17:23 2019
From: r|ch@rd@k@ev@n@ @end|ng |rom n@@@@gov (Evans, Richard K. (GRC-H000))
Date: Tue, 29 Jan 2019 17:17:23 +0000
Subject: [R] how to ref data directly from bls.gov using their api
Message-ID: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0FD3CB4E@NDJSMBX203.ndc.nasa.gov>

Hello, 

I'd like to generate my own plots of various labor statistics using live data available at https://www.bls.gov/bls/api_features.htm

This is 10% an R question and 90 % a bls.gov api query question.  Please forgive me for making this request here but I would be truly grateful for anyone here on the R mailinglist who can show me how to write a line of R code that "fetches" the raw data anew from the bls.gov website every time it runs. 

Truest Thanks,
/Rich


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 29 19:24:32 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 29 Jan 2019 10:24:32 -0800
Subject: [R] how to ref data directly from bls.gov using their api
In-Reply-To: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0FD3CB4E@NDJSMBX203.ndc.nasa.gov>
References: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0FD3CB4E@NDJSMBX203.ndc.nasa.gov>
Message-ID: <CAGxFJbQ981-Py048FCBB0xGvqWc+MRqmp8_gyEdtyQokEYtnbA@mail.gmail.com>

Please search on "Bureau of Labor Statistics" at rseek.org.  You will find
several packages and other resources there for doing what you want.

-- Ber

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 29, 2019 at 9:21 AM Evans, Richard K. (GRC-H000) via R-help <
r-help at r-project.org> wrote:

> Hello,
>
> I'd like to generate my own plots of various labor statistics using live
> data available at https://www.bls.gov/bls/api_features.htm
>
> This is 10% an R question and 90 % a bls.gov api query question.  Please
> forgive me for making this request here but I would be truly grateful for
> anyone here on the R mailinglist who can show me how to write a line of R
> code that "fetches" the raw data anew from the bls.gov website every time
> it runs.
>
> Truest Thanks,
> /Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhub@ne@wordh@k@| @end|ng |rom gm@||@com  Tue Jan 29 23:36:31 2019
From: bhub@ne@wordh@k@| @end|ng |rom gm@||@com (Bhubaneswor Dhakal)
Date: Wed, 30 Jan 2019 11:36:31 +1300
Subject: [R] R code for fixed effect multinomial logistic regression and
 experimental data
In-Reply-To: <CAD5R06S-=pjnsKp-BxjOKzOqrf2KyYOeNJ5WHNtfM0wAj91r_A@mail.gmail.com>
References: <mailman.353419.1.1548673201.62367.r-help@r-project.org>
 <CAD5R06S-=pjnsKp-BxjOKzOqrf2KyYOeNJ5WHNtfM0wAj91r_A@mail.gmail.com>
Message-ID: <CAD5R06RJYEWu=AGg94s6SbmCDXpVZN9JmPxv0bZ_xvfysvpAPg@mail.gmail.com>

Hi R support group team

I would like to contribute on two issues posted last days:

1. Addressing question by Valerio [Valerio Leone Sciabolazza <
sciabolazza at gmail.com>]: [R] how to run a multinomial logistic regression
with fixed effects.
Application of fixed effect multinomial logistic regression (FE MNLR) has
many drawbacks as explained in literatures. This could be a reason that R
experts did not work on FE MNLR.
Useful references:
A. Green 2013.  15 Panel Data Models for Discrete Choice.
http://people.stern.nyu.edu/wgreene/Econometrics/Greene-PanelDataModelsforDiscreteChoice.pdf
B.  Xavier D?Haultf?uille and Alessandro Iaria 2015. A Convenient Method
for the Estimation of the Multinomial Logit Model with Fixed Effects.

2. Solutions my posts: a. Regarding my experimental data dealing problem in
R, I separately developed network graphs of treated and untreated
groups which made me easier to compare and understand the intervention
effect difference. b. Regarding my missing data handling problem, console
script accounted the missing data issue but I had forgoten filling "NA" in
a box of Rstudio while importing data.

Thanks for your attempt to resolve my R programing problem.
Cheers

B. Dhakal

	[[alternative HTML version deleted]]


From heckendor| @end|ng |rom |euph@n@@de  Tue Jan 29 20:50:06 2019
From: heckendor| @end|ng |rom |euph@n@@de (Hanna Heckendorf)
Date: Tue, 29 Jan 2019 20:50:06 +0100
Subject: [R] Help: mediation with multiply imputed data
Message-ID: <8015806a-7d5b-2649-1898-7a6a31fe074c@leuphana.de>

Hello R Users,

I want to conduct a parallel mediation analysis using bias corrected 
bootstrapping with multiply imputed data.

I already installed the package bmem, but to me it seems that I can only 
calculate the mediation model when calculating the multiple imputations 
at the same time.

The problem ist that I already imputed data and conducted some analyses 
with that data. Moreover I included some variables in my imputation 
model that I will not use in the mediation analysis. Therefore I don't 
want to impute again.

Do you maybe know how I could do the mediation analysis (preferably with 
bootstrapping) on multiply imputed datasets?

Any help is greatly appreciated.


Thank you very much,

Sincerly, Hanna

-- 
Hanna Heckendorf, M.Sc. Psych.

Leuphana University of L?neburg
Department of Health Psychology
Institute of Psychology
Universit?tsallee 1, C1.113
21335 L?neburg - Germany
Fon +49.4131.677-2721


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 03:27:42 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Tue, 29 Jan 2019 19:27:42 -0700
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <CAGxFJbSLqnoi9JBw9hvHuaMEkqV5rh8vZRxcyXZdETyhLcdsAg@mail.gmail.com>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
 <CAGxFJbSLqnoi9JBw9hvHuaMEkqV5rh8vZRxcyXZdETyhLcdsAg@mail.gmail.com>
Message-ID: <cb73cea9-2210-9ff6-f93b-2db91280419a@comcast.net>

On 1/28/2019 5:17 PM, Bert Gunter wrote:
> I would say your question is foolish -- you disagree no doubt! -- 
> because the point of using R (or Octave or C++) is to take advantage of 
> the packages (= "libraries" in some languages; a library is something 
> different in R) it (or they) offers to simplify your task. Many of R's 
> libraries are written in C (or Fortran) an thus **are** fast as well as 
> having task-appropriate functionality and UI's .

Yes, I'm well aware of the libraries in Octave. But so far as I was able 
to see, none of them fit my needs. I used Octave at first because I'm 
familiar with it. But far from an expert.

> So I think instead of pursuing this discussion you would do well to 
> search. I find rseek.org <http://rseek.org> to be especially good for 
> this sort of thing. Searching there on "demography" brought up what 
> appeared to be many appropriate hits -- including the "demography" 
> package! -- which you could then examine to see whether and to what 
> extent they provide the functionality you seek.

I looked over the demography package, and it indeed appears to do what I 
want. But it seems to be far more complicated than my simple problem, 
and has a large learning curve.

Alan

> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Jan 28, 2019 at 4:00 PM Alan Feuerbacher <alanf00 at comcast.net 
> <mailto:alanf00 at comcast.net>> wrote:
> 
>     On 1/28/2019 4:20 PM, Rolf Turner wrote:
>      >
>      > On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>      >
>      >> Hi,
>      >>
>      >> I recently learned of the existence of R through a physicist friend
>      >> who uses it in his research. I've used Octave for a decade, and
>     C for
>      >> 35 years, but would like to learn R. These all have advantages and
>      >> disadvantages for certain tasks, but as I'm new to R I hardly
>     know how
>      >> to evaluate them. Any suggestions?
>      >
>      > * C is fast, but with a syntax that is (to my mind) virtually
>      >? ? incomprehensible.? (You probably think differently about this.)
> 
>     I've been doing it long enough that I have little problem with it,
>     except for pointers. :-)
> 
>      > * In C, you essentially have to roll your own for all tasks; in R,
>      >? ? practically anything (well ...) that you want to do has already
>      >? ? been programmed up.? CRAN is a wonderful resource, and there's
>     more
>      >? ? on github.
>      ?>
>      > * The syntax of R meshes beautifully with *my* thought patterns;
>     YMMV.
>      >
>      > * Why not just bog in and try R out?? It's free, it's readily
>     available,
>      >? ? and there are a number of good online tutorials.
> 
>     I just installed R on my Linux Fedora system, so I'll do that.
> 
>     I wonder if you'd care to comment on my little project that prompted
>     this? As part of another project, I wanted to model population growth
>     starting from a handful of starting individuals. This is exponential in
>     the long run, of course, but I wanted to see how a few basic parameters
>     affected the outcome. Using Octave, I modeled a single person as a
>     "cell", which in Octave has a good deal of overhead. The program
>     basically looped over the entire population, and updated each person
>     according to the parameters, which included random statistical
>     variations. So when the total population reached, say 10,000, and an
>     update time of 1 day, the program had to execute 10,000 x 365 update
>     operations for each year of growth. For large populations, say 100,000,
>     the program did not return even after 24 hours of run time.
> 
>     So I switched to C, and used its "struct" declaration and an array of
>     structs to model the population. This allowed the program to
>     complete in
>     under a minute as opposed to 24 hours+. So in line with your
>     comments, C
>     is far more efficient than Octave.
> 
>     How do you think R would fare in this simulation?
> 
>     Alan
> 
> 
>     ---
>     This email has been checked for viruses by Avast antivirus software.
>     https://www.avast.com/antivirus
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 03:32:31 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Tue, 29 Jan 2019 19:32:31 -0700
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <CAF8bMcaW5HnDukAczPAgO6KrUimb7euU8Kd0awzDnkaZd4U5LA@mail.gmail.com>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
 <CAF8bMcaW5HnDukAczPAgO6KrUimb7euU8Kd0awzDnkaZd4U5LA@mail.gmail.com>
Message-ID: <dd4d3554-bd30-8644-a8f0-c7448b13d491@comcast.net>

On 1/28/2019 6:07 PM, William Dunlap wrote:
> S (R's predecessor) was designed by and for data analysts.? R generally 
> follows that tradition.? I think that simulations such as yours are not 
> its strength, although it can make analyzing (graphically and 
> numerically) the results of the simulation fun.

At this point I think you're right on all counts.

Alan

> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> 
> On Mon, Jan 28, 2019 at 4:00 PM Alan Feuerbacher <alanf00 at comcast.net 
> <mailto:alanf00 at comcast.net>> wrote:
> 
>     On 1/28/2019 4:20 PM, Rolf Turner wrote:
>      >
>      > On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>      >
>      >> Hi,
>      >>
>      >> I recently learned of the existence of R through a physicist friend
>      >> who uses it in his research. I've used Octave for a decade, and
>     C for
>      >> 35 years, but would like to learn R. These all have advantages and
>      >> disadvantages for certain tasks, but as I'm new to R I hardly
>     know how
>      >> to evaluate them. Any suggestions?
>      >
>      > * C is fast, but with a syntax that is (to my mind) virtually
>      >? ? incomprehensible.? (You probably think differently about this.)
> 
>     I've been doing it long enough that I have little problem with it,
>     except for pointers. :-)
> 
>      > * In C, you essentially have to roll your own for all tasks; in R,
>      >? ? practically anything (well ...) that you want to do has already
>      >? ? been programmed up.? CRAN is a wonderful resource, and there's
>     more
>      >? ? on github.
>      ?>
>      > * The syntax of R meshes beautifully with *my* thought patterns;
>     YMMV.
>      >
>      > * Why not just bog in and try R out?? It's free, it's readily
>     available,
>      >? ? and there are a number of good online tutorials.
> 
>     I just installed R on my Linux Fedora system, so I'll do that.
> 
>     I wonder if you'd care to comment on my little project that prompted
>     this? As part of another project, I wanted to model population growth
>     starting from a handful of starting individuals. This is exponential in
>     the long run, of course, but I wanted to see how a few basic parameters
>     affected the outcome. Using Octave, I modeled a single person as a
>     "cell", which in Octave has a good deal of overhead. The program
>     basically looped over the entire population, and updated each person
>     according to the parameters, which included random statistical
>     variations. So when the total population reached, say 10,000, and an
>     update time of 1 day, the program had to execute 10,000 x 365 update
>     operations for each year of growth. For large populations, say 100,000,
>     the program did not return even after 24 hours of run time.
> 
>     So I switched to C, and used its "struct" declaration and an array of
>     structs to model the population. This allowed the program to
>     complete in
>     under a minute as opposed to 24 hours+. So in line with your
>     comments, C
>     is far more efficient than Octave.
> 
>     How do you think R would fare in this simulation?
> 
>     Alan
> 
> 
>     ---
>     This email has been checked for viruses by Avast antivirus software.
>     https://www.avast.com/antivirus
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan 30 03:01:40 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 30 Jan 2019 13:01:40 +1100
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <CACp+zAsn1bL2VeZDRC5k8A1VXmi8FLX-cXfaH+A0Tmtd29M_RQ@mail.gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
 <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>
 <134463C5-39A8-401D-A914-0341133C1F7D@gmail.com>
 <CACp+zAsn1bL2VeZDRC5k8A1VXmi8FLX-cXfaH+A0Tmtd29M_RQ@mail.gmail.com>
Message-ID: <CA+8X3fWe=ajn+wmzyjSJfVwboRr1zv2gZ5wLJmdKdmWj-fdq5Q@mail.gmail.com>

Hi Hallie,
If I understand your email correctly, you have four repeated
observations by the three raters of the same six variables. This is a
tougher problem and I can't solve it at the moment. I'll return to
this later and see if I can offer a solution.


Jim

On Wed, Jan 30, 2019 at 3:56 AM Hallie Kamesch <hallie.kamesch at gmail.com> wrote:
>
> Thank you Jim, for the code, and thank you Jeff for the tutorial PDF.  I've read through the sections and I appreciate the help.
> I'm in way over my head - I don't even understand enough of the vocabulary to ask my question correctly.
> Jim, in your code, I ended up with an entry of 4 observations of 6 variables. I understand how that happened now since I read your code - that helped very much.
> My only problem, that I can't figure out, is how to make it so I have 3 raters with 4 observations of 6 variables.
> I really am trying to educate myself enough to not waste your time:  I've ?data.frame, ?sample, ?matrix, ?$names, ?attributes, etc... I read the sections in Jeff's PDF, and the tutorials on datamentor, I'm just not finding how to do this. I'm sorry this is such a newbie question.
> thank you for your time,
> hallie
>


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan 30 04:01:25 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 30 Jan 2019 14:01:25 +1100
Subject: [R] troubleshooting data structure to run krippendorff's alpha
In-Reply-To: <CA+8X3fWe=ajn+wmzyjSJfVwboRr1zv2gZ5wLJmdKdmWj-fdq5Q@mail.gmail.com>
References: <CACp+zAu47H46-8e826MmJTZkhYuKqYWtVTcR-jUpZW+LWGDuDQ@mail.gmail.com>
 <CA+8X3fXB5L=nH6z5QRZJ2mj+8gOPUba66NaUVa_qX+0vnAnBUg@mail.gmail.com>
 <134463C5-39A8-401D-A914-0341133C1F7D@gmail.com>
 <CACp+zAsn1bL2VeZDRC5k8A1VXmi8FLX-cXfaH+A0Tmtd29M_RQ@mail.gmail.com>
 <CA+8X3fWe=ajn+wmzyjSJfVwboRr1zv2gZ5wLJmdKdmWj-fdq5Q@mail.gmail.com>
Message-ID: <CA+8X3fUACGiFhBTn7_+KeE=Rmidot05ASYWM9WM3-fRkYx5tTQ@mail.gmail.com>

Hi Hallie,
I tried both the "cccUst" and "cccvc" functions in the "cccrm"
package. While I can get what looks like sensible statistics with the
following example, I am not sure that it can be interpreted as you
wish. For one thing, it assumes that the concordance will be the same
on all variables. I was not able to get a statistic on each variable
separately. Perhaps someone who is more familiar with the package can
offer better advice. Also, check the "hkdf" data frame to ensure that
it looks like your data.

hkdf<-data.frame(rater=rep(1:3,each=24),occasion=rep(rep(1:4,each=6),3),
 var=rep(rep(1:6,4),3),obs=runif(72))
library(cccrm)
cccUst(hkdf,"obs","rater","occasion")
cccvc(hkdf,"obs","rater","occasion")

Jim

On Wed, Jan 30, 2019 at 1:01 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Hallie,
> If I understand your email correctly, you have four repeated
> observations by the three raters of the same six variables. This is a
> tougher problem and I can't solve it at the moment. I'll return to
> this later and see if I can offer a solution.
>
>
> Jim


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 04:08:31 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Tue, 29 Jan 2019 20:08:31 -0700
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <24250968-5B39-4CEC-8649-406716F9780E@dcn.davis.ca.us>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
 <24250968-5B39-4CEC-8649-406716F9780E@dcn.davis.ca.us>
Message-ID: <235c61aa-b59c-1a9c-c5d3-ffa0614d7a65@comcast.net>

On 1/28/2019 7:51 PM, Jeff Newmiller wrote:
> If you forge on with your preconceptions of how such a simulation should be implemented then you will be able to reproduce your failure just as spectacularly using R as you did using Octave.

I think I've come to the same conclusion. :-)

> It is crucial to employ vectorization of your algorithms if you want good performance with either Octave or R. That vectorization may either be over time or over separate simulations.

Please explain further, if you don't mind. My background is not in 
programming, but in analog microchip circuit design (I'm now retired). 
Thus I'm a user of circuit simulators, not a programmer of them. Also, 
I'm running this stuff on my home computers, either Linux or Windows 
machines.

> I am running simulations of a million cases of power plant performance over 25 years in about a minute. I know someone who used R to simulate a CFD river flow problem in a class in a few minutes, while others using Fortran or Matlab were struggling to get comparable runs completed in many hours. I believe the difference was in how the data were structured and manipulated more than the language that was being used. I think the strong capabilities for presenting results using R makes using it advantageous over Octave, though.

After my failed attempt at using Octave, I realized that most likely the 
main contributing factor was that I was not able to figure out an 
efficient data structure to model one person. But C lent itself 
perfectly to my idea of how to go about programming my simulation. So 
here's a simplified pseudocode sort of example of what I did:

To model a single reproducing woman I used this C construct:

typedef struct woman {
   int isAlive;
   int isPregnant;
   double age;
   . . .
} WOMAN;

Then I allocated memory for a big array of these things, using the C 
malloc() function, which gave me the equivalent of this statement:

WOMAN women[NWOMEN];  /* An array of NWOMEN woman-structs */

After some initialization I set up two loops:

for( j=0; j<numberOfYears; j++) {
   for(i=1; i< numberOfWomen; i++) {
     updateWomen();
   }
}

The function updateWomen() figures out things like whether the woman 
becomes pregnant or gives birth on a given day, dies, etc.

I added other refinements that are not relevant here, such as random 
variations of various parameters, using the GNU Scientific Library 
random number generator functions.

If you can suggest a data construct in R or Octave that does something 
like this, and uses your idea of vectorization, I'd like to hear it. I'd 
like to implement it and compare results with my C implementation.

> If your problems truly need a compiled language, the Rcpp package lets you mix C++ with R quite easily and then you get the best of both worlds. (C and Fortran are supported, but they are a bit more finicky to setup than C++).

I don't know the answer to that, but perhaps you can help decide.

Alan


> On January 28, 2019 4:00:07 PM PST, Alan Feuerbacher <alanf00 at comcast.net> wrote:
>> On 1/28/2019 4:20 PM, Rolf Turner wrote:
>>>
>>> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>>>
>>>> Hi,
>>>>
>>>> I recently learned of the existence of R through a physicist friend
>>>> who uses it in his research. I've used Octave for a decade, and C
>> for
>>>> 35 years, but would like to learn R. These all have advantages and
>>>> disadvantages for certain tasks, but as I'm new to R I hardly know
>> how
>>>> to evaluate them. Any suggestions?
>>>
>>> * C is fast, but with a syntax that is (to my mind) virtually
>>>   ? incomprehensible.? (You probably think differently about this.)
>>
>> I've been doing it long enough that I have little problem with it,
>> except for pointers. :-)
>>
>>> * In C, you essentially have to roll your own for all tasks; in R,
>>>   ? practically anything (well ...) that you want to do has already
>>>   ? been programmed up.? CRAN is a wonderful resource, and there's
>> more
>>>   ? on github.
>>>
>>> * The syntax of R meshes beautifully with *my* thought patterns;
>> YMMV.
>>>
>>> * Why not just bog in and try R out?? It's free, it's readily
>> available,
>>>   ? and there are a number of good online tutorials.
>>
>> I just installed R on my Linux Fedora system, so I'll do that.
>>
>> I wonder if you'd care to comment on my little project that prompted
>> this? As part of another project, I wanted to model population growth
>> starting from a handful of starting individuals. This is exponential in
>>
>> the long run, of course, but I wanted to see how a few basic parameters
>>
>> affected the outcome. Using Octave, I modeled a single person as a
>> "cell", which in Octave has a good deal of overhead. The program
>> basically looped over the entire population, and updated each person
>> according to the parameters, which included random statistical
>> variations. So when the total population reached, say 10,000, and an
>> update time of 1 day, the program had to execute 10,000 x 365 update
>> operations for each year of growth. For large populations, say 100,000,
>>
>> the program did not return even after 24 hours of run time.
>>
>> So I switched to C, and used its "struct" declaration and an array of
>> structs to model the population. This allowed the program to complete
>> in
>> under a minute as opposed to 24 hours+. So in line with your comments,
>> C
>> is far more efficient than Octave.
>>
>> How do you think R would fare in this simulation?
>>
>> Alan
>>
>>
>> ---
>> This email has been checked for viruses by Avast antivirus software.
>> https://www.avast.com/antivirus
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 04:12:49 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Tue, 29 Jan 2019 20:12:49 -0700
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <CAP01uRkSoP5kPeYDBrOaYiC7R4JUrMtRDgiCNmVWrw-Atz8NCg@mail.gmail.com>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <CAP01uR=3gt4JLmcwd4DkMwW+H-RbXzqsxzS1k+8dkE1A7Wycug@mail.gmail.com>
 <CAP01uRkSoP5kPeYDBrOaYiC7R4JUrMtRDgiCNmVWrw-Atz8NCg@mail.gmail.com>
Message-ID: <297c3a4e-f36d-b8f9-5909-f64bd2d23e05@comcast.net>

On 1/29/2019 8:11 AM, Gabor Grothendieck wrote:
> Two additional comments:
> 
> - depending on the nature of your problem you may be able to get an
> analytic solution using branching processes. I found this approach
> successful when I once had to model stem cell growth.

That sounds very interesting! Please see my reply to Jeff Newmiller. Not 
being a mathematician, I have no clue how to go about this but would be 
very interested to learn.

> - in addition to NetLogo another alternative to R would be the Julia
> language which is motivated to some degree by Octave but is actually
> quite different and is particularly suitable in terms of performance
> for iterative computations where one iteration depends on the prior
> one.

Given my response to Jeff Newmiller, do your comments still apply?

Alan


> On Mon, Jan 28, 2019 at 6:32 PM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>>
>> R has many similarities to Octave.  Have a look at:
>>
>> https://cran.r-project.org/doc/contrib/R-and-octave.txt
>> https://CRAN.R-project.org/package=matconv
>>
>> On Mon, Jan 28, 2019 at 4:58 PM Alan Feuerbacher <alanf00 at comcast.net> wrote:
>>>
>>> Hi,
>>>
>>> I recently learned of the existence of R through a physicist friend who
>>> uses it in his research. I've used Octave for a decade, and C for 35
>>> years, but would like to learn R. These all have advantages and
>>> disadvantages for certain tasks, but as I'm new to R I hardly know how
>>> to evaluate them. Any suggestions?
>>>
>>> Thanks!
>>>
>>> ---
>>> This email has been checked for viruses by Avast antivirus software.
>>> https://www.avast.com/antivirus
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
> 
> 
>


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 04:18:56 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Tue, 29 Jan 2019 20:18:56 -0700
Subject: [R] how to ref data directly from bls.gov using their api
In-Reply-To: <CAGxFJbQ981-Py048FCBB0xGvqWc+MRqmp8_gyEdtyQokEYtnbA@mail.gmail.com>
References: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0FD3CB4E@NDJSMBX203.ndc.nasa.gov>
 <CAGxFJbQ981-Py048FCBB0xGvqWc+MRqmp8_gyEdtyQokEYtnbA@mail.gmail.com>
Message-ID: <7698ff0b-219c-b099-e206-ce24463644bb@comcast.net>

On 1/29/2019 11:24 AM, Bert Gunter wrote:
> Please search on "Bureau of Labor Statistics" at rseek.org.  You will find
> several packages and other resources there for doing what you want.

Wow! Thanks!

Again most likely severe overkill for my simple need.

Alan

> -- Ber
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Jan 29, 2019 at 9:21 AM Evans, Richard K. (GRC-H000) via R-help <
> r-help at r-project.org> wrote:
> 
>> Hello,
>>
>> I'd like to generate my own plots of various labor statistics using live
>> data available at https://www.bls.gov/bls/api_features.htm
>>
>> This is 10% an R question and 90 % a bls.gov api query question.  Please
>> forgive me for making this request here but I would be truly grateful for
>> anyone here on the R mailinglist who can show me how to write a line of R
>> code that "fetches" the raw data anew from the bls.gov website every time
>> it runs.
>>
>> Truest Thanks,
>> /Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan 30 07:50:03 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 29 Jan 2019 22:50:03 -0800 (PST)
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <235c61aa-b59c-1a9c-c5d3-ffa0614d7a65@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
 <24250968-5B39-4CEC-8649-406716F9780E@dcn.davis.ca.us>
 <235c61aa-b59c-1a9c-c5d3-ffa0614d7a65@comcast.net>
Message-ID: <alpine.BSF.2.00.1901292221200.83151@pedal.dcn.davis.ca.us>

On Tue, 29 Jan 2019, Alan Feuerbacher wrote:

> On 1/28/2019 7:51 PM, Jeff Newmiller wrote:
>> If you forge on with your preconceptions of how such a simulation should be 
>> implemented then you will be able to reproduce your failure just as 
>> spectacularly using R as you did using Octave.
>
> I think I've come to the same conclusion. :-)
>
>> It is crucial to employ vectorization of your algorithms if you want good 
>> performance with either Octave or R. That vectorization may either be over 
>> time or over separate simulations.
>
> Please explain further, if you don't mind. My background is not in 
> programming, but in analog microchip circuit design (I'm now retired). Thus 
> I'm a user of circuit simulators, not a programmer of them. Also, I'm running 
> this stuff on my home computers, either Linux or Windows machines.
>
>> I am running simulations of a million cases of power plant performance over 
>> 25 years in about a minute. I know someone who used R to simulate a CFD 
>> river flow problem in a class in a few minutes, while others using Fortran 
>> or Matlab were struggling to get comparable runs completed in many hours. I 
>> believe the difference was in how the data were structured and manipulated 
>> more than the language that was being used. I think the strong capabilities 
>> for presenting results using R makes using it advantageous over Octave, 
>> though.
>
> After my failed attempt at using Octave, I realized that most likely the main 
> contributing factor was that I was not able to figure out an efficient data 
> structure to model one person. But C lent itself perfectly to my idea of how 
> to go about programming my simulation. So here's a simplified pseudocode sort 
> of example of what I did:

Don't model one person... model an array of people.

> To model a single reproducing woman I used this C construct:
>
> typedef struct woman {
>  int isAlive;
>  int isPregnant;
>  double age;
>  . . .
> } WOMAN;

# e.g.
Nwomen <- 100
women <- data.frame( isAlive = rep( TRUE, Nwomen )
                    , isPregnant = rep( FALSE, Nwomen )
                    , age = rep( 20, Nwomen )
                    )

> Then I allocated memory for a big array of these things, using the C malloc() 
> function, which gave me the equivalent of this statement:
>
> WOMAN women[NWOMEN];  /* An array of NWOMEN woman-structs */
>
> After some initialization I set up two loops:
>
> for( j=0; j<numberOfYears; j++) {
>  for(i=1; i< numberOfWomen; i++) {
>    updateWomen();
>  }
> }

for ( j in seq.int( numberOfYears ) {
   # let vectorized data storage automatically handle the other for loop
   women <- updateWomen( women )
}

> The function updateWomen() figures out things like whether the woman becomes 
> pregnant or gives birth on a given day, dies, etc.

You can use your "fixed size" allocation strategy with flags indicating 
whether specific rows are in use, or you can only work with valid rows and 
add rows as needed for children... best to compute a logical vector that 
identifies all of the birthing mothers as a subset of the data frame, and 
build a set of children rows using the birthing mothers data frame as 
input, and then rbind the new rows to the updated women dataframe as 
appropriate. The most clear approach for individual decision calculations 
is the use of the vectorized "ifelse" function, though under certain 
circumstances putting an indexed subset on the left side of an assignment 
can modify memory "in place" (the functional-programming restriction 
against this is probably a foreign idea to a dyed-in-the-wool C 
programmer, but R usually prevents you from modifying the variable that 
was input to a function, automatically making a local copy of the input as 
needed in order to prevent such backwash into the caller's context).

> I added other refinements that are not relevant here, such as random 
> variations of various parameters, using the GNU Scientific Library random 
> number generator functions.

R has quite sophisticated random number generation by default.

> If you can suggest a data construct in R or Octave that does something like 
> this, and uses your idea of vectorization, I'd like to hear it. I'd like to 
> implement it and compare results with my C implementation.
>
>> If your problems truly need a compiled language, the Rcpp package lets you 
>> mix C++ with R quite easily and then you get the best of both worlds. (C 
>> and Fortran are supported, but they are a bit more finicky to setup than 
>> C++).
>
> I don't know the answer to that, but perhaps you can help decide.
>
> Alan
>
>
>> On January 28, 2019 4:00:07 PM PST, Alan Feuerbacher <alanf00 at comcast.net> 
>> wrote:
>>> On 1/28/2019 4:20 PM, Rolf Turner wrote:
>>>> 
>>>> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>>>> 
>>>>> Hi,
>>>>> 
>>>>> I recently learned of the existence of R through a physicist friend
>>>>> who uses it in his research. I've used Octave for a decade, and C
>>> for
>>>>> 35 years, but would like to learn R. These all have advantages and
>>>>> disadvantages for certain tasks, but as I'm new to R I hardly know
>>> how
>>>>> to evaluate them. Any suggestions?
>>>> 
>>>> * C is fast, but with a syntax that is (to my mind) virtually
>>>>   ? incomprehensible.? (You probably think differently about this.)
>>> 
>>> I've been doing it long enough that I have little problem with it,
>>> except for pointers. :-)
>>> 
>>>> * In C, you essentially have to roll your own for all tasks; in R,
>>>>   ? practically anything (well ...) that you want to do has already
>>>>   ? been programmed up.? CRAN is a wonderful resource, and there's
>>> more
>>>>   ? on github.
>>>> 
>>>> * The syntax of R meshes beautifully with *my* thought patterns;
>>> YMMV.
>>>> 
>>>> * Why not just bog in and try R out?? It's free, it's readily
>>> available,
>>>>   ? and there are a number of good online tutorials.
>>> 
>>> I just installed R on my Linux Fedora system, so I'll do that.
>>> 
>>> I wonder if you'd care to comment on my little project that prompted
>>> this? As part of another project, I wanted to model population growth
>>> starting from a handful of starting individuals. This is exponential in
>>> 
>>> the long run, of course, but I wanted to see how a few basic parameters
>>> 
>>> affected the outcome. Using Octave, I modeled a single person as a
>>> "cell", which in Octave has a good deal of overhead. The program
>>> basically looped over the entire population, and updated each person
>>> according to the parameters, which included random statistical
>>> variations. So when the total population reached, say 10,000, and an
>>> update time of 1 day, the program had to execute 10,000 x 365 update
>>> operations for each year of growth. For large populations, say 100,000,
>>> 
>>> the program did not return even after 24 hours of run time.
>>> 
>>> So I switched to C, and used its "struct" declaration and an array of
>>> structs to model the population. This allowed the program to complete
>>> in
>>> under a minute as opposed to 24 hours+. So in line with your comments,
>>> C
>>> is far more efficient than Octave.
>>> 
>>> How do you think R would fare in this simulation?
>>> 
>>> Alan
>>> 
>>> 
>>> ---
>>> This email has been checked for viruses by Avast antivirus software.
>>> https://www.avast.com/antivirus
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Wed Jan 30 11:15:44 2019
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Wed, 30 Jan 2019 10:15:44 +0000 (UTC)
Subject: [R] create a network for a small text df
References: <1870388490.241973.1548843344984.ref@mail.yahoo.com>
Message-ID: <1870388490.241973.1548843344984@mail.yahoo.com>

Hi all,

I have a small dataframe and I would like to show in a network plot how words are related to the word "problem" with arrows (keeping the order of the words in sentences).
Here's the df:

     
     dput(df) 
     structure(list(text = structure(c(1L, 7L, 3L, 4L, 5L, 6L, 2L), .Label = c("account block solv problem", 
     "exactly problem morning", "investigate similar problem", "matched problem control vec",      "problem also accour yesterday", "same problem jj ", "same problem uk" 
      ), class = "factor")), class = "data.frame", row.names = c(NA, 
    -7L))

So far I have tried plotting each row a a network as following:


    
  library(igraph)
  net=graph(c("account","block","block","solve","solve","problem"))
  plot(net)

but I will end up having 7 plots, is there a better way?
thanks for any help.
Elahe.


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Jan 30 15:44:19 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 30 Jan 2019 15:44:19 +0100
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
Message-ID: <CAGAA5bfa8yz-1rPZ==7KgJvGNJ8keo7SHwNnYqhy6EFJ8MXVsA@mail.gmail.com>

On Mon, 28 Jan 2019 at 22:58, Alan Feuerbacher <alanf00 at comcast.net> wrote:

[...]

> These all have advantages and
> disadvantages for certain tasks, but as I'm new to R I hardly know how
> to evaluate them. Any suggestions?

If you have one-hour left, you
can download  pdf file (8 pages total)
"Getting started in R"
from http://ilustat.com/shared/Getting-Started-in-R.pdf

And then try running the code used in the examples.

Regards
Martin

	[[alternative HTML version deleted]]


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 17:16:52 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Wed, 30 Jan 2019 09:16:52 -0700
Subject: [R] [FORGED] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <alpine.BSF.2.00.1901292221200.83151@pedal.dcn.davis.ca.us>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <8b2f75fe-4979-e4ad-b86f-4c9a50a93271@auckland.ac.nz>
 <bb0af392-125a-5a53-96a5-ab825756ee28@comcast.net>
 <24250968-5B39-4CEC-8649-406716F9780E@dcn.davis.ca.us>
 <235c61aa-b59c-1a9c-c5d3-ffa0614d7a65@comcast.net>
 <alpine.BSF.2.00.1901292221200.83151@pedal.dcn.davis.ca.us>
Message-ID: <9685ab60-6b80-1c59-9077-9f622650a66f@comcast.net>

On 1/29/2019 11:50 PM, Jeff Newmiller wrote:

Thanks very much for providing these coding examples! I think this is a 
good way to learn some R.

Alan

> On Tue, 29 Jan 2019, Alan Feuerbacher wrote:
> 
>> On 1/28/2019 7:51 PM, Jeff Newmiller wrote:
>>> If you forge on with your preconceptions of how such a simulation 
>>> should be implemented then you will be able to reproduce your failure 
>>> just as spectacularly using R as you did using Octave.
>>
>> I think I've come to the same conclusion. :-)
>>
>>> It is crucial to employ vectorization of your algorithms if you want 
>>> good performance with either Octave or R. That vectorization may 
>>> either be over time or over separate simulations.
>>
>> Please explain further, if you don't mind. My background is not in 
>> programming, but in analog microchip circuit design (I'm now retired). 
>> Thus I'm a user of circuit simulators, not a programmer of them. Also, 
>> I'm running this stuff on my home computers, either Linux or Windows 
>> machines.
>>
>>> I am running simulations of a million cases of power plant 
>>> performance over 25 years in about a minute. I know someone who used 
>>> R to simulate a CFD river flow problem in a class in a few minutes, 
>>> while others using Fortran or Matlab were struggling to get 
>>> comparable runs completed in many hours. I believe the difference was 
>>> in how the data were structured and manipulated more than the 
>>> language that was being used. I think the strong capabilities for 
>>> presenting results using R makes using it advantageous over Octave, 
>>> though.
>>
>> After my failed attempt at using Octave, I realized that most likely 
>> the main contributing factor was that I was not able to figure out an 
>> efficient data structure to model one person. But C lent itself 
>> perfectly to my idea of how to go about programming my simulation. So 
>> here's a simplified pseudocode sort of example of what I did:
> 
> Don't model one person... model an array of people.
> 
>> To model a single reproducing woman I used this C construct:
>>
>> typedef struct woman {
>> ?int isAlive;
>> ?int isPregnant;
>> ?double age;
>> ?. . .
>> } WOMAN;
> 
> # e.g.
> Nwomen <- 100
> women <- data.frame( isAlive = rep( TRUE, Nwomen )
>  ?????????????????? , isPregnant = rep( FALSE, Nwomen )
>  ?????????????????? , age = rep( 20, Nwomen )
>  ?????????????????? )
> 
>> Then I allocated memory for a big array of these things, using the C 
>> malloc() function, which gave me the equivalent of this statement:
>>
>> WOMAN women[NWOMEN];? /* An array of NWOMEN woman-structs */
>>
>> After some initialization I set up two loops:
>>
>> for( j=0; j<numberOfYears; j++) {
>> ?for(i=1; i< numberOfWomen; i++) {
>> ?? updateWomen();
>> ?}
>> }
> 
> for ( j in seq.int( numberOfYears ) {
>  ? # let vectorized data storage automatically handle the other for loop
>  ? women <- updateWomen( women )
> }
> 
>> The function updateWomen() figures out things like whether the woman 
>> becomes pregnant or gives birth on a given day, dies, etc.
> 
> You can use your "fixed size" allocation strategy with flags indicating 
> whether specific rows are in use, or you can only work with valid rows 
> and add rows as needed for children... best to compute a logical vector 
> that identifies all of the birthing mothers as a subset of the data 
> frame, and build a set of children rows using the birthing mothers data 
> frame as input, and then rbind the new rows to the updated women 
> dataframe as appropriate. The most clear approach for individual 
> decision calculations is the use of the vectorized "ifelse" function, 
> though under certain circumstances putting an indexed subset on the left 
> side of an assignment can modify memory "in place" (the 
> functional-programming restriction against this is probably a foreign 
> idea to a dyed-in-the-wool C programmer, but R usually prevents you from 
> modifying the variable that was input to a function, automatically 
> making a local copy of the input as needed in order to prevent such 
> backwash into the caller's context).
> 
>> I added other refinements that are not relevant here, such as random 
>> variations of various parameters, using the GNU Scientific Library 
>> random number generator functions.
> 
> R has quite sophisticated random number generation by default.
> 
>> If you can suggest a data construct in R or Octave that does something 
>> like this, and uses your idea of vectorization, I'd like to hear it. 
>> I'd like to implement it and compare results with my C implementation.
>>
>>> If your problems truly need a compiled language, the Rcpp package 
>>> lets you mix C++ with R quite easily and then you get the best of 
>>> both worlds. (C and Fortran are supported, but they are a bit more 
>>> finicky to setup than C++).
>>
>> I don't know the answer to that, but perhaps you can help decide.
>>
>> Alan
>>
>>
>>> On January 28, 2019 4:00:07 PM PST, Alan Feuerbacher 
>>> <alanf00 at comcast.net> wrote:
>>>> On 1/28/2019 4:20 PM, Rolf Turner wrote:
>>>>>
>>>>> On 1/29/19 10:05 AM, Alan Feuerbacher wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I recently learned of the existence of R through a physicist friend
>>>>>> who uses it in his research. I've used Octave for a decade, and C
>>>> for
>>>>>> 35 years, but would like to learn R. These all have advantages and
>>>>>> disadvantages for certain tasks, but as I'm new to R I hardly know
>>>> how
>>>>>> to evaluate them. Any suggestions?
>>>>>
>>>>> * C is fast, but with a syntax that is (to my mind) virtually
>>>>> ? ? incomprehensible.? (You probably think differently about this.)
>>>>
>>>> I've been doing it long enough that I have little problem with it,
>>>> except for pointers. :-)
>>>>
>>>>> * In C, you essentially have to roll your own for all tasks; in R,
>>>>> ? ? practically anything (well ...) that you want to do has already
>>>>> ? ? been programmed up.? CRAN is a wonderful resource, and there's
>>>> more
>>>>> ? ? on github.
>>>>>
>>>>> * The syntax of R meshes beautifully with *my* thought patterns;
>>>> YMMV.
>>>>>
>>>>> * Why not just bog in and try R out?? It's free, it's readily
>>>> available,
>>>>> ? ? and there are a number of good online tutorials.
>>>>
>>>> I just installed R on my Linux Fedora system, so I'll do that.
>>>>
>>>> I wonder if you'd care to comment on my little project that prompted
>>>> this? As part of another project, I wanted to model population growth
>>>> starting from a handful of starting individuals. This is exponential in
>>>>
>>>> the long run, of course, but I wanted to see how a few basic parameters
>>>>
>>>> affected the outcome. Using Octave, I modeled a single person as a
>>>> "cell", which in Octave has a good deal of overhead. The program
>>>> basically looped over the entire population, and updated each person
>>>> according to the parameters, which included random statistical
>>>> variations. So when the total population reached, say 10,000, and an
>>>> update time of 1 day, the program had to execute 10,000 x 365 update
>>>> operations for each year of growth. For large populations, say 100,000,
>>>>
>>>> the program did not return even after 24 hours of run time.
>>>>
>>>> So I switched to C, and used its "struct" declaration and an array of
>>>> structs to model the population. This allowed the program to complete
>>>> in
>>>> under a minute as opposed to 24 hours+. So in line with your comments,
>>>> C
>>>> is far more efficient than Octave.
>>>>
>>>> How do you think R would fare in this simulation?
>>>>
>>>> Alan
>>>>
>>>>
>>>> ---
>>>> This email has been checked for viruses by Avast antivirus software.
>>>> https://www.avast.com/antivirus
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller??????????????????????? The???? .....?????? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>??????? Basics: ##.#.?????? ##.#.? Live Go...
>  ????????????????????????????????????? Live:?? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries??????????? O.O#.?????? #.O#.? with
> /Software/Embedded Controllers)?????????????? .OO#.?????? .OO#.? rocks...1k
> ---------------------------------------------------------------------------


From @|@n|00 @end|ng |rom comc@@t@net  Wed Jan 30 17:27:31 2019
From: @|@n|00 @end|ng |rom comc@@t@net (Alan Feuerbacher)
Date: Wed, 30 Jan 2019 09:27:31 -0700
Subject: [R] Newbie Question on R versus Matlab/Octave versus C
In-Reply-To: <CAGAA5bfa8yz-1rPZ==7KgJvGNJ8keo7SHwNnYqhy6EFJ8MXVsA@mail.gmail.com>
References: <eafdc33a-61ce-03b8-2e02-3a467eda2d84@comcast.net>
 <CAGAA5bfa8yz-1rPZ==7KgJvGNJ8keo7SHwNnYqhy6EFJ8MXVsA@mail.gmail.com>
Message-ID: <8d1f7c72-30a8-baeb-c360-6d6011fbc518@comcast.net>

On 1/30/2019 7:44 AM, Martin M?ller Skarbiniks Pedersen wrote:
> On Mon, 28 Jan 2019 at 22:58, Alan Feuerbacher <alanf00 at comcast.net 
> <mailto:alanf00 at comcast.net>> wrote:
> 
> [...]
> 
>  > These all have advantages and
>  > disadvantages for certain tasks, but as I'm new to R I hardly know how
>  > to evaluate them. Any suggestions?
> 
> If you have one-hour left, you
> can download? pdf file (8 pages total)
> "Getting started in R"
> from http://ilustat.com/shared/Getting-Started-in-R.pdf
> 
> And then try running the code used in the examples.

Downloaded and in my pipeline.

Thanks!

Alan

---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Jan 30 19:50:20 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 30 Jan 2019 13:50:20 -0500
Subject: [R] Setting xreg parameter to generate forecasts of mlp models
Message-ID: <CAMOcQfMfE_OWw3_Ffpt=3idO5WPDSrZXstbNDNV0JFhps+1g3A@mail.gmail.com>

Dear friends,

Hope you are all doing great. So far, I?ve been able to generate forecasts
using R?s mlp function (which allows fitting of multiple layer perceptron
models to time series data).

I basically fitted an mlp model and then tried to use the forecast function
with the xreg parameter to do the forecasts.

Here the details of what I am working with for better reference:

R version: R version 3.5.1 (2018-07-02) -- "Feather Spray"

Packages used:
library(forecast)
library(glmnet)
library(neuralnet)
library(nnfor)
library(tseries)
library(lubridate)

This is my training data: (my exogenous variable is the one called
FuelPrice)

structure(list(TransitDate = structure(c(134L, 105L, 219L, 20L,
248L, 190L, 162L, 48L, 332L, 304L, 276L, 76L, 135L, 106L, 220L,
21L, 249L, 191L, 163L, 49L, 333L, 305L, 277L, 77L, 136L, 107L,
221L, 22L, 250L, 192L, 164L, 50L, 334L, 306L, 278L, 78L, 137L,
108L, 222L, 23L, 251L, 193L, 165L, 51L, 335L, 307L, 279L, 79L,
138L, 109L, 223L, 24L, 252L, 194L, 166L, 52L, 336L, 308L, 280L,
80L, 139L, 110L, 224L, 25L, 253L, 195L, 167L, 53L, 337L, 309L,
281L, 81L, 140L, 111L, 225L, 26L, 254L, 196L, 168L, 54L, 338L,
310L, 282L, 82L, 141L, 112L, 226L, 27L, 255L, 197L, 169L, 55L,
339L, 311L, 283L, 83L, 142L, 113L, 227L, 28L, 256L, 198L, 170L,
56L, 340L, 312L, 284L, 84L, 143L, 114L, 228L, 29L, 257L, 199L,
171L, 57L, 341L, 313L, 285L, 85L, 115L, 86L, 200L, 1L, 229L,
172L, 144L, 30L, 314L, 286L, 258L, 58L, 116L, 87L, 201L, 2L,
230L, 173L, 145L, 31L, 315L, 287L, 259L, 59L, 117L, 88L, 202L,
3L, 231L, 174L, 146L, 32L, 316L, 288L, 260L, 60L, 118L, 89L,
203L, 4L, 232L, 175L, 147L, 33L, 317L, 289L, 261L, 61L, 119L,
90L, 204L, 5L, 233L, 176L, 148L, 34L, 318L, 290L, 262L, 62L,
120L, 91L, 205L, 6L, 234L, 177L, 149L, 35L, 319L, 291L, 263L,
63L, 121L, 92L, 206L, 7L, 235L, 178L, 150L, 36L, 320L, 292L,
264L, 64L, 122L, 93L, 207L, 8L, 236L, 179L, 151L, 37L, 321L,
293L, 265L, 65L, 123L, 94L, 208L, 9L, 237L, 180L, 152L, 38L,
322L, 294L, 266L, 66L, 124L, 95L, 209L, 10L, 238L, 181L, 153L,
39L, 323L, 295L, 267L, 67L, 125L, 96L, 210L, 11L, 239L, 182L,
154L, 40L, 324L, 296L, 268L, 68L, 126L, 97L, 211L, 12L, 240L,
183L, 155L, 41L, 325L, 297L, 269L, 69L, 127L, 98L, 212L, 13L,
241L, 184L, 156L, 42L, 326L, 298L, 270L, 70L, 128L, 99L, 213L,
14L, 242L, 185L, 157L, 43L, 327L, 299L, 271L, 71L, 129L, 100L,
214L, 15L, 243L, 186L, 158L, 44L, 328L, 300L, 272L, 72L, 130L,
101L, 215L, 16L, 244L, 187L, 159L, 45L, 329L, 301L, 273L, 73L,
131L, 102L, 216L, 17L, 245L, 188L, 160L, 46L, 330L, 302L, 274L,
74L, 132L, 103L, 217L, 18L, 246L, 189L, 161L, 47L, 331L, 303L,
275L, 75L, 133L, 104L, 218L, 19L, 247L), .Label = c("1-Apr-00",
"1-Apr-01", "1-Apr-02", "1-Apr-03", "1-Apr-04", "1-Apr-05", "1-Apr-06",
"1-Apr-07", "1-Apr-08", "1-Apr-09", "1-Apr-10", "1-Apr-11", "1-Apr-12",
"1-Apr-13", "1-Apr-14", "1-Apr-15", "1-Apr-16", "1-Apr-17", "1-Apr-18",
"1-Apr-90", "1-Apr-91", "1-Apr-92", "1-Apr-93", "1-Apr-94", "1-Apr-95",
"1-Apr-96", "1-Apr-97", "1-Apr-98", "1-Apr-99", "1-Aug-00", "1-Aug-01",
"1-Aug-02", "1-Aug-03", "1-Aug-04", "1-Aug-05", "1-Aug-06", "1-Aug-07",
"1-Aug-08", "1-Aug-09", "1-Aug-10", "1-Aug-11", "1-Aug-12", "1-Aug-13",
"1-Aug-14", "1-Aug-15", "1-Aug-16", "1-Aug-17", "1-Aug-90", "1-Aug-91",
"1-Aug-92", "1-Aug-93", "1-Aug-94", "1-Aug-95", "1-Aug-96", "1-Aug-97",
"1-Aug-98", "1-Aug-99", "1-Dec-00", "1-Dec-01", "1-Dec-02", "1-Dec-03",
"1-Dec-04", "1-Dec-05", "1-Dec-06", "1-Dec-07", "1-Dec-08", "1-Dec-09",
"1-Dec-10", "1-Dec-11", "1-Dec-12", "1-Dec-13", "1-Dec-14", "1-Dec-15",
"1-Dec-16", "1-Dec-17", "1-Dec-90", "1-Dec-91", "1-Dec-92", "1-Dec-93",
"1-Dec-94", "1-Dec-95", "1-Dec-96", "1-Dec-97", "1-Dec-98", "1-Dec-99",
"1-Feb-00", "1-Feb-01", "1-Feb-02", "1-Feb-03", "1-Feb-04", "1-Feb-05",
"1-Feb-06", "1-Feb-07", "1-Feb-08", "1-Feb-09", "1-Feb-10", "1-Feb-11",
"1-Feb-12", "1-Feb-13", "1-Feb-14", "1-Feb-15", "1-Feb-16", "1-Feb-17",
"1-Feb-18", "1-Feb-90", "1-Feb-91", "1-Feb-92", "1-Feb-93", "1-Feb-94",
"1-Feb-95", "1-Feb-96", "1-Feb-97", "1-Feb-98", "1-Feb-99", "1-Jan-00",
"1-Jan-01", "1-Jan-02", "1-Jan-03", "1-Jan-04", "1-Jan-05", "1-Jan-06",
"1-Jan-07", "1-Jan-08", "1-Jan-09", "1-Jan-10", "1-Jan-11", "1-Jan-12",
"1-Jan-13", "1-Jan-14", "1-Jan-15", "1-Jan-16", "1-Jan-17", "1-Jan-18",
"1-Jan-90", "1-Jan-91", "1-Jan-92", "1-Jan-93", "1-Jan-94", "1-Jan-95",
"1-Jan-96", "1-Jan-97", "1-Jan-98", "1-Jan-99", "1-Jul-00", "1-Jul-01",
"1-Jul-02", "1-Jul-03", "1-Jul-04", "1-Jul-05", "1-Jul-06", "1-Jul-07",
"1-Jul-08", "1-Jul-09", "1-Jul-10", "1-Jul-11", "1-Jul-12", "1-Jul-13",
"1-Jul-14", "1-Jul-15", "1-Jul-16", "1-Jul-17", "1-Jul-90", "1-Jul-91",
"1-Jul-92", "1-Jul-93", "1-Jul-94", "1-Jul-95", "1-Jul-96", "1-Jul-97",
"1-Jul-98", "1-Jul-99", "1-Jun-00", "1-Jun-01", "1-Jun-02", "1-Jun-03",
"1-Jun-04", "1-Jun-05", "1-Jun-06", "1-Jun-07", "1-Jun-08", "1-Jun-09",
"1-Jun-10", "1-Jun-11", "1-Jun-12", "1-Jun-13", "1-Jun-14", "1-Jun-15",
"1-Jun-16", "1-Jun-17", "1-Jun-90", "1-Jun-91", "1-Jun-92", "1-Jun-93",
"1-Jun-94", "1-Jun-95", "1-Jun-96", "1-Jun-97", "1-Jun-98", "1-Jun-99",
"1-Mar-00", "1-Mar-01", "1-Mar-02", "1-Mar-03", "1-Mar-04", "1-Mar-05",
"1-Mar-06", "1-Mar-07", "1-Mar-08", "1-Mar-09", "1-Mar-10", "1-Mar-11",
"1-Mar-12", "1-Mar-13", "1-Mar-14", "1-Mar-15", "1-Mar-16", "1-Mar-17",
"1-Mar-18", "1-Mar-90", "1-Mar-91", "1-Mar-92", "1-Mar-93", "1-Mar-94",
"1-Mar-95", "1-Mar-96", "1-Mar-97", "1-Mar-98", "1-Mar-99", "1-May-00",
"1-May-01", "1-May-02", "1-May-03", "1-May-04", "1-May-05", "1-May-06",
"1-May-07", "1-May-08", "1-May-09", "1-May-10", "1-May-11", "1-May-12",
"1-May-13", "1-May-14", "1-May-15", "1-May-16", "1-May-17", "1-May-18",
"1-May-90", "1-May-91", "1-May-92", "1-May-93", "1-May-94", "1-May-95",
"1-May-96", "1-May-97", "1-May-98", "1-May-99", "1-Nov-00", "1-Nov-01",
"1-Nov-02", "1-Nov-03", "1-Nov-04", "1-Nov-05", "1-Nov-06", "1-Nov-07",
"1-Nov-08", "1-Nov-09", "1-Nov-10", "1-Nov-11", "1-Nov-12", "1-Nov-13",
"1-Nov-14", "1-Nov-15", "1-Nov-16", "1-Nov-17", "1-Nov-90", "1-Nov-91",
"1-Nov-92", "1-Nov-93", "1-Nov-94", "1-Nov-95", "1-Nov-96", "1-Nov-97",
"1-Nov-98", "1-Nov-99", "1-Oct-00", "1-Oct-01", "1-Oct-02", "1-Oct-03",
"1-Oct-04", "1-Oct-05", "1-Oct-06", "1-Oct-07", "1-Oct-08", "1-Oct-09",
"1-Oct-10", "1-Oct-11", "1-Oct-12", "1-Oct-13", "1-Oct-14", "1-Oct-15",
"1-Oct-16", "1-Oct-17", "1-Oct-90", "1-Oct-91", "1-Oct-92", "1-Oct-93",
"1-Oct-94", "1-Oct-95", "1-Oct-96", "1-Oct-97", "1-Oct-98", "1-Oct-99",
"1-Sep-00", "1-Sep-01", "1-Sep-02", "1-Sep-03", "1-Sep-04", "1-Sep-05",
"1-Sep-06", "1-Sep-07", "1-Sep-08", "1-Sep-09", "1-Sep-10", "1-Sep-11",
"1-Sep-12", "1-Sep-13", "1-Sep-14", "1-Sep-15", "1-Sep-16", "1-Sep-17",
"1-Sep-90", "1-Sep-91", "1-Sep-92", "1-Sep-93", "1-Sep-94", "1-Sep-95",
"1-Sep-96", "1-Sep-97", "1-Sep-98", "1-Sep-99"), class = "factor"),
    Transits = c(98L, 80L, 95L, 89L, 92L, 96L, 86L, 98L, 84L,
    90L, 95L, 90L, 99L, 85L, 91L, 90L, 88L, 97L, 93L, 97L, 87L,
    92L, 87L, 86L, 85L, 82L, 90L, 89L, 101L, 94L, 92L, 109L,
    101L, 103L, 96L, 89L, 102L, 87L, 101L, 100L, 99L, 101L, 98L,
    101L, 90L, 106L, 90L, 99L, 105L, 91L, 96L, 91L, 96L, 93L,
    101L, 105L, 98L, 110L, 100L, 101L, 106L, 99L, 111L, 114L,
    112L, 113L, 120L, 105L, 111L, 114L, 111L, 118L, 115L, 108L,
    120L, 119L, 120L, 118L, 117L, 121L, 111L, 114L, 107L, 121L,
    109L, 106L, 116L, 105L, 119L, 120L, 123L, 126L, 117L, 127L,
    128L, 132L, 138L, 120L, 132L, 134L, 136L, 144L, 152L, 155L,
    146L, 155L, 138L, 141L, 146L, 123L, 133L, 123L, 137L, 133L,
    143L, 132L, 126L, 134L, 129L, 138L, 134L, 132L, 139L, 130L,
    152L, 150L, 153L, 161L, 152L, 154L, 154L, 138L, 149L, 137L,
    144L, 146L, 152L, 140L, 151L, 168L, 148L, 157L, 152L, 153L,
    166L, 157L, 156L, 166L, 168L, 179L, 188L, 190L, 185L, 184L,
    185L, 202L, 191L, 175L, 197L, 187L, 195L, 204L, 218L, 220L,
    212L, 220L, 211L, 221L, 204L, 196L, 209L, 205L, 217L, 211L,
    212L, 224L, 206L, 225L, 206L, 219L, 232L, 220L, 242L, 241L,
    261L, 252L, 261L, 269L, 251L, 264L, 261L, 266L, 274L, 236L,
    270L, 263L, 276L, 276L, 300L, 303L, 301L, 318L, 294L, 308L,
    308L, 269L, 303L, 302L, 318L, 282L, 311L, 305L, 304L, 309L,
    298L, 295L, 295L, 281L, 280L, 287L, 313L, 276L, 296L, 307L,
    307L, 309L, 287L, 286L, 290L, 261L, 285L, 279L, 286L, 284L,
    267L, 271L, 259L, 268L, 243L, 242L, 237L, 208L, 250L, 237L,
    267L, 257L, 276L, 277L, 269L, 282L, 264L, 270L, 270L, 251L,
    272L, 271L, 288L, 266L, 283L, 266L, 270L, 282L, 272L, 264L,
    269L, 253L, 269L, 283L, 288L, 275L, 301L, 292L, 283L, 287L,
    261L, 265L, 269L, 234L, 251L, 261L, 262L, 249L, 256L, 255L,
    253L, 253L, 233L, 234L, 235L, 217L, 244L, 232L, 261L, 236L,
    252L, 242L, 252L, 251L, 230L, 240L, 254L, 226L, 267L, 245L,
    263L, 261L, 286L, 281L, 265L, 274L, 250L, 260L, 265L, 242L,
    251L, 249L, 251L, 247L, 248L, 234L, 206L, 219L, 194L, 218L,
    209L, 192L, 207L, 200L, 208L, 208L, 209L, 213L, 216L, 219L,
    195L, 217L, 217L, 197L, 210L, 211L, 229L), FuelPrice = c(106.2962963,
    95.80555556, 91.23703704, 85.83101852, 82.15277778, 66.95,
    72.78888889, 123.9444444, 137.8055556, 149.6527778, 142.9777778,
    143.9282407, 158.20625, 102.7791667, 74.96833333, 74.06666667,
    77.825, 76.76458333, 78.446875, 77.33, 76.28472222, 80.45138889,
    87.44166667, 77.05, 66.845, 65.91666667, 70.875, 78.13541667,
    85.585, 89.8875, 93.805, 96.71875, 98.10625, 103.645, 97.3375,
    81.59375, 80.665, 82, 84.4875, 86.335, 85.23125, 77.4875,
    69.375, 72.16875, 70.6875, 72.155, 65.4875, 60.725, 69.25,
    76.24375, 75.16875, 78.985, 88.5, 92.7375, 101.68, 101.5375,
    84.57, 92.075, 98.9875, 97.549, 104.05, 105.0375, 107.355,
    109.13125, 112.55, 102.68, 89.325, 87.4, 89.385, 93.7625,
    96.1125, 109.46, 115.7125, 108.4125, 111.06, 116.4125, 108.49,
    95.25, 99.1125, 103.19, 117.725, 129.375, 124.64, 124.175,
    117.26, 103.775, 97.1375, 97.45, 98.63, 98.575, 98.8625,
    103.38, 105.525, 111.8, 112.5, 94.64375, 80.35, 70.2875,
    68.5, 80.2625, 78.37, 70.2375, 69.49, 65.55, 70.8875, 78.28,
    73.275, 63.275, 66.136, 61.2, 66.925, 79.97, 84.5375, 86.2625,
    97.52, 117.825, 125.7, 136.52, 137.5, 137.91, 137.5375, 142.3375,
    161.04, 144.2, 146.95, 160.35, 150.7375, 145.45, 162.55,
    173.2, 161.4, 141.93, 126.5625, 133.5375, 134.4, 128.8875,
    136.5875, 131.66, 128.4, 134.62, 142.4875, 125.6625, 108.15,
    111.4270833, 112.875, 114.4791667, 130.1083333, 151.5729167,
    153.5333333, 149.6458333, 153.34375, 160.725, 172.475, 168.15625,
    147.65, 156.6770833, 186.6333333, 199.7708333, 180.59375,
    158.1145833, 155.7083333, 162.8854167, 181.8645833, 172.2916667,
    159.8020833, 166.1583333, 164.8020833, 158.1666667, 165.8,
    166.4375, 165.0104167, 172.1583333, 188.1354167, 181.3645833,
    180.5416667, 187.7291667, 185.2291667, 210.125, 185.4166667,
    176.1333333, 188.4270833, 197.4479167, 224.75, 262.0166667,
    259.2083333, 257.1458333, 263.55, 274.7604167, 316.7583333,
    312.5, 291.90625, 289.1166667, 311.3645833, 322.6145833,
    327.375, 343.8104167, 347.53125, 328.9583333, 340.3229167,
    336.21875, 299.65, 288.1770833, 281.3854167, 283.075, 269.0848115,
    293.6611771, 306.037149, 332.2265119, 348.3577214, 352.4784017,
    380.0569654, 378.3900648, 391.8031857, 425.3555616, 497.6723369,
    478.389556, 472.9277721, 468.7605749, 513.636037, 526.8660164,
    574.4350103, 634.5420791, 723.7430698, 682.4256674, 598.350616,
    436.4950719, 251.2828542, 231.6342402, 259.3991786, 265.2687372,
    259.7176591, 289.5685318, 345.4262834, 403.2597536, 407.2184805,
    445.5154004, 436.5097536, 444.1123203, 479.7510267, 467.6647844,
    481.161807, 466.013347, 469.0002567, 484.7790554, 462.4086242,
    446.6830082, 445.9609856, 454.1185832, 447.362423, 474.3616667,
    493.6333333, 507.7695833, 535.071875, 600.5708333, 642.528125,
    673.0433333, 653.39375, 662.5119792, 670.9591667, 660.3786458,
    660.23125, 660.9192708, 681.3197917, 662.8329167, 707.9286458,
    725.3364583, 739.5675, 725.7286458, 681.8526042, 599.7833333,
    611.5536458, 661.4755365, 667.1883047, 648.13125, 623.67897,
    616.3776824, 634.486588, 658.5445279, 634.0532189, 614.5563725,
    606.2872146, 606.1289954, 609.5603248, 615.9174014, 618.5638489,
    615.0463415, 608.7503722, 615.1243797, 614.0424242, 616.316838,
    610.4884319, 603.2643979, 603.8573298, 609.691, 600.1080163,
    592.0074792, 576.779661, 511.1634006, 454.6536765, 365.6265015,
    292.1762048, 342.7007576, 333.6017802, 336.7719298, 370.0886452,
    360.3370968, 316.5678457, 255.5741051, 249.9473684, 246.452381,
    229.0865385, 184.9615385, 155.6425339, 161.2596154, 176.7019231,
    191.7991453, 228.8461538, 245.875, 249.4307692, 241.2403846,
    258.3384615, 285.6689977, 276.8942308, 323.1230769, 337.7115385,
    326.7980769, 309.2574519, 314.3772894, 309.9615385, 299.1490385,
    308.4807692, 316.7596154, 333.7692308, 340.9807692, 373.3173077,
    371.4692308, 395.0576923, 379.6442308, 372.9192308, 393.9711538,
    440.5865385)), class = "data.frame", row.names = c(NA, -341L
))

#Now, since the mlp() function needs a ts object as an input, I did:

TransitSeries <- ts(CarTransitData$Transits, start=c(1990,1),
end=c(2018,5), frequency=12)

TransitModel <- mlp(TransitSeries)

# I then worked with the regressor (FuelPrice):

FuelPriceSeries <- ts(CarTransitData$FuelPrice, start=c(1990,1),
end=c(2018,5), frequency=12)

FuelModel <- mlp(FuelPriceSeries)

# Then generated the forecasts for FuelPrice:

FuelForecast <- forecast(FuelModel, h=12)

# Finally, I  try to generate the forecasts:

Forecast1 <- forecast(TransitModel, h=48, xreg=FuelForecast)

and I get the error:

Error in if (length(xreg.lags) != x.n) { : argument is of length zero

I need help on how to incorporate the xreg argument to generate forecasts
for mlp models.

Any help will be greatly appreciated,

Cheers,

Paul

	[[alternative HTML version deleted]]


From n|cho|@@@wr@y @end|ng |rom nt|wor|d@com  Wed Jan 30 20:17:03 2019
From: n|cho|@@@wr@y @end|ng |rom nt|wor|d@com (Nick Wray)
Date: Wed, 30 Jan 2019 19:17:03 +0000 (GMT)
Subject: [R] periodicity
Message-ID: <246360024.383419.1548875823601@mail2.virginmedia.com>

I've found references on websites to an R function "periodicity", but there's no such built-in function as far as I can see in R studio.  I can't find reference to it being part of any package either.  Can anyone help with this?

Thanks, Nick Wray
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Jan 30 20:24:11 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 30 Jan 2019 14:24:11 -0500
Subject: [R] periodicity
In-Reply-To: <246360024.383419.1548875823601@mail2.virginmedia.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
Message-ID: <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>

Hi Nick,

A quick look on rseek.org didn't turn anything up. It would help to
know what websites you're referring to - they might be loading custom
code.

Sarah

On Wed, Jan 30, 2019 at 2:17 PM Nick Wray via R-help
<r-help at r-project.org> wrote:
>
> I've found references on websites to an R function "periodicity", but there's no such built-in function as far as I can see in R studio.  I can't find reference to it being part of any package either.  Can anyone help with this?
>
> Thanks, Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From wdun|@p @end|ng |rom t|bco@com  Wed Jan 30 20:24:20 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 30 Jan 2019 11:24:20 -0800
Subject: [R] periodicity
In-Reply-To: <246360024.383419.1548875823601@mail2.virginmedia.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
Message-ID: <CAF8bMcZ3ZaHLTc1_FMxGpijX7Vcv538+OuqeNA7E4GT5EHaKxg@mail.gmail.com>

Search with https://rseek.org

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jan 30, 2019 at 11:17 AM Nick Wray via R-help <r-help at r-project.org>
wrote:

> I've found references on websites to an R function "periodicity", but
> there's no such built-in function as far as I can see in R studio.  I can't
> find reference to it being part of any package either.  Can anyone help
> with this?
>
> Thanks, Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 30 20:27:23 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 30 Jan 2019 11:27:23 -0800
Subject: [R] periodicity
In-Reply-To: <246360024.383419.1548875823601@mail2.virginmedia.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
Message-ID: <CAGxFJbQ7DWfQUM_eRRd40ET8XMGQUG1ZccVuZzRRh47feATwRg@mail.gmail.com>

Ummm... ???

A google search on "R function periodicity" immediately brought up the xts
package and others.

and RStudio is **NOT** R. It's an IDE for R (and there are others).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 30, 2019 at 11:17 AM Nick Wray via R-help <r-help at r-project.org>
wrote:

> I've found references on websites to an R function "periodicity", but
> there's no such built-in function as far as I can see in R studio.  I can't
> find reference to it being part of any package either.  Can anyone help
> with this?
>
> Thanks, Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Wed Jan 30 20:31:19 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 30 Jan 2019 14:31:19 -0500
Subject: [R] periodicity
In-Reply-To: <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
 <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
Message-ID: <A6CAB32B-9BA4-423F-99C6-BC9B9AA02159@me.com>

Hi,

A quick Google search using "R periodicity" turned up the 'xts' package on CRAN:

  https://cran.r-project.org/web/packages/xts/index.html

Regards,

Marc Schwartz


> On Jan 30, 2019, at 2:24 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi Nick,
> 
> A quick look on rseek.org didn't turn anything up. It would help to
> know what websites you're referring to - they might be loading custom
> code.
> 
> Sarah
> 
> On Wed, Jan 30, 2019 at 2:17 PM Nick Wray via R-help
> <r-help at r-project.org> wrote:
>> 
>> I've found references on websites to an R function "periodicity", but there's no such built-in function as far as I can see in R studio.  I can't find reference to it being part of any package either.  Can anyone help with this?
>> 
>> Thanks, Nick Wray
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Sarah Goslee (she/her)
> http://www.numberwright.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdun|@p @end|ng |rom t|bco@com  Wed Jan 30 20:47:03 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 30 Jan 2019 11:47:03 -0800
Subject: [R] periodicity
In-Reply-To: <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
 <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
Message-ID: <CAF8bMcb6V-_8EhBKFWtob4NqhbeY1XfMKgnJdkDod80cEaDeCQ@mail.gmail.com>

Searching for 'periodicity' on rseek.org gives, several items from the top,

*periodicity* function | *R* Documentation
<https://www.rdocumentation.org/packages/xts/versions/0.11-2/topics/periodicity>
https://www.rdocumentation.org/packages/xts/.../0.11.../*periodicity*
Estimate the *periodicity* of a time-series-like object by calculating the
median time between observations in days.
LabeledFunctionDocumentation

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jan 30, 2019 at 11:27 AM Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi Nick,
>
> A quick look on rseek.org didn't turn anything up. It would help to
> know what websites you're referring to - they might be loading custom
> code.
>
> Sarah
>
> On Wed, Jan 30, 2019 at 2:17 PM Nick Wray via R-help
> <r-help at r-project.org> wrote:
> >
> > I've found references on websites to an R function "periodicity", but
> there's no such built-in function as far as I can see in R studio.  I can't
> find reference to it being part of any package either.  Can anyone help
> with this?
> >
> > Thanks, Nick Wray
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 30 20:34:21 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 30 Jan 2019 11:34:21 -0800
Subject: [R] periodicity
In-Reply-To: <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
References: <246360024.383419.1548875823601@mail2.virginmedia.com>
 <CAM_vjum6TyQ+mjwzEob59iytf+MOi2nGNnF6oPVs8HGq8StNiw@mail.gmail.com>
Message-ID: <CAGxFJbSkBq4taXrJYAdtQU9u2i4nrK-WJjW7mzpzJpuKD1h8kA@mail.gmail.com>

All:

https://rdrr.io/  and Rdocumentation.org

Seems to be good places for finding info on specific R functions.


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 30, 2019 at 11:27 AM Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi Nick,
>
> A quick look on rseek.org didn't turn anything up. It would help to
> know what websites you're referring to - they might be loading custom
> code.
>
> Sarah
>
> On Wed, Jan 30, 2019 at 2:17 PM Nick Wray via R-help
> <r-help at r-project.org> wrote:
> >
> > I've found references on websites to an R function "periodicity", but
> there's no such built-in function as far as I can see in R studio.  I can't
> find reference to it being part of any package either.  Can anyone help
> with this?
> >
> > Thanks, Nick Wray
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jan 31 19:05:29 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 31 Jan 2019 10:05:29 -0800
Subject: [R] Extract the coordinates of a Polylines
In-Reply-To: <CANTxAm+o1dCKiPc7wdHO9jVB=frN4h=2E5-iq4zT7ARoKNG_XA@mail.gmail.com>
References: <CANTxAmKurP05q8kWq_fSoRyPhNm2G7pUB-34bUD4oxOO0z8uKg@mail.gmail.com>
 <CANTxAm+o1dCKiPc7wdHO9jVB=frN4h=2E5-iq4zT7ARoKNG_XA@mail.gmail.com>
Message-ID: <b16cc562-cb80-09b1-18d1-d4d5ae2b9d01@comcast.net>


On 1/30/19 7:12 AM, javad bayat wrote:
> Dear all;
> Back to my previous question, I am trying to add X and Y coordinates 
> to every row of the data.
>
> topo = 
> readOGR("E:/New/Modelling_Water/MIKE/BathyMetry/GIS_Armator/Chitgar_Topo.shp")#Read 
> shape file of the topo as polylines
> plot(topo)
> cords = topo at lines[[1]]@Lines[[1]]@coords###Extracting X and Y 
> coordinates of the polylines of topo
>
> head(topo at data)
> ? FID_? ? ?Entity? ? ? ?Layer Color? ?Linetype Elevation
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.0
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.5
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.5
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.5
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.5
> ? ? 0 LWPolyline C-TOPO-MAJR? ? ?9 Continuous? ? 1258.5


I did a google-search on "lwpolyline" and it appears to be a structure 
that is created with AutoCAD. So it's unlikely that people who are 
primarily users of R's spatial data structures will know how rgdal 
(which is a layer on top of GDAL) will have implemented the importation 
of such a structure into R. You should instead provide the output of 
`dput (head(topo at data) )` if you want more informed comments.


David.

>
> How can I do this.
> Sincerely.
>
> On Sat, Jan 26, 2019 at 9:37 AM javad bayat <j.bayat194 at gmail.com 
> <mailto:j.bayat194 at gmail.com>> wrote:
>
>     Dear R users;
>     I am trying to extract the X and Y coordinates of a polylines
>     along with Elevation data. I have extracted the Elevations as Z,
>     but I do not know how to extract the X and Y of these Elevations.
>     Is it possible to extract X and Y of the Elevation and create a
>     data frame with three variables?
>
>     line = readOGR("E:/......../Topo.shp")
>     Z = line at data$Elevation
>
>     Sincerely.
>
>     -- 
>     Best Regards
>     Javad Bayat
>     M.Sc. Environment Engineering
>     Alternative Mail: bayat194 at yahoo.com <mailto:bayat194 at yahoo.com>
>
>
>
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com <mailto:bayat194 at yahoo.com>

	[[alternative HTML version deleted]]


From @ndrew@beet @end|ng |rom no@@@gov  Thu Jan 31 16:31:30 2019
From: @ndrew@beet @end|ng |rom no@@@gov (Andy Beet)
Date: Thu, 31 Jan 2019 10:31:30 -0500
Subject: [R] nlme::gls potential bug
Message-ID: <385070db-1b30-5329-9b39-5c31c14f858e@noaa.gov>

Hi there,


I have been using the nlme::gls package created in R to fit a pretty 
simple model (linear with AR error)

y(t) = beta*x(t) + e(t)? ??? ??? ??? where e(t) ~ rho*e(t-1) + Z(t) ?? 
 ??? and Z(t)~ N(0,sig^2)

I call the R routine

glsObj <- nlme::gls(y ~ x -1, data=data, correlation = 
nlme::corAR1(form= ~x), method="ML")

All seems fine.


In addition, I have also coded the likelihood myself and maximized it 
for beta, rho and sigma.

I get the exact same estimates of beta and rho, (as nlme::gls) but the 
estimate of sigma is not the same and i can not figure out why.

The maximum likelihood estimator for sigma under this model is

sig^2 = (( 1-rho^2)u(1)^2 + sum((u(t)- rho*u(t-1))^2)/n

where the sum is t=2,...,n and

u(t) = y(t) - X(t)*beta


I have read the mixed-effects models in S and S-Plus book (nlme::gls 
code is based directly on this) and this problem is specified on page 
204 eq (5.5). I have also calculated sigma based on (5.7) -after the 
transformation documented (5.2) -and i do not get the same value as 
either the package or my implementation.

Any advice would be most welcomed. Is there a bug in the estimation of 
sigma in this package?

Thanks

Andy

-- 
Andy Beet
Ecosystem Dynamics & Assessment Branch
Northeast Fisheries Science Center
NOAA Fisheries Service
166 Water Street
Woods Hole, MA 02543
tel: 508-495-2073


	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Wed Jan 30 16:12:08 2019
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Wed, 30 Jan 2019 18:42:08 +0330
Subject: [R] Extract the coordinates of a Polylines
In-Reply-To: <CANTxAmKurP05q8kWq_fSoRyPhNm2G7pUB-34bUD4oxOO0z8uKg@mail.gmail.com>
References: <CANTxAmKurP05q8kWq_fSoRyPhNm2G7pUB-34bUD4oxOO0z8uKg@mail.gmail.com>
Message-ID: <CANTxAm+o1dCKiPc7wdHO9jVB=frN4h=2E5-iq4zT7ARoKNG_XA@mail.gmail.com>

Dear all;
Back to my previous question, I am trying to add X and Y coordinates to
every row of the data.

topo =
readOGR("E:/New/Modelling_Water/MIKE/BathyMetry/GIS_Armator/Chitgar_Topo.shp")#Read
shape file of the topo as polylines
plot(topo)
cords = topo at lines[[1]]@Lines[[1]]@coords###Extracting X and Y coordinates
of the polylines of topo

head(topo at data)
  FID_     Entity       Layer Color   Linetype Elevation
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.0
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.5
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.5
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.5
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.5
    0 LWPolyline C-TOPO-MAJR     9 Continuous    1258.5

How can I do this.
Sincerely.

On Sat, Jan 26, 2019 at 9:37 AM javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I am trying to extract the X and Y coordinates of a polylines along with
> Elevation data. I have extracted the Elevations as Z, but I do not know how
> to extract the X and Y of these Elevations. Is it possible to extract X and
> Y of the Elevation and create a data frame with three variables?
>
> line = readOGR("E:/......../Topo.shp")
> Z = line at data$Elevation
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>


-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From wh|tney@cory @end|ng |rom gm@||@com  Wed Jan 30 15:43:04 2019
From: wh|tney@cory @end|ng |rom gm@||@com (Cory Whitney)
Date: Wed, 30 Jan 2019 15:43:04 +0100
Subject: [R] [R-pkgs] ethnobotanyR v0.1.3
Message-ID: <FF905256-DACF-4AD9-84E9-F5063FF058AA@gmail.com>

Many ethnobotanists are calculating indices and performing quantitative analysis with excel. Not any more! Now they can use the ethnobotanyR package to calculate common quantitative ethnobotany indices to assess the cultural significance of plant species based on informant consensus. The package closely follows two papers, one by Tardio and Pardo-de-Santayana (2008) and another by Whitney et al. (2018).

The CRAN page for the ethnobotanyR package
https://cran.r-project.org/web/packages/ethnobotanyR/index.html

A vignette that describes it i ethnobotanyR greater detail:
https://cran.r-project.org/web/packages/ethnobotanyR/vignettes/ethnobotanyr_vignette.html

The main papers behind ethnobotanyR: 

Tardio, J., and M. Pardo-de-Santayana, 2008. Cultural Importance Indices: A Comparative Analysis Based on the Useful Wild Plants of Southern Cantabria (Northern Spain) 1. Economic Botany, 62(1), 24-39. https://doi.org/10.1007/s12231-007-9004-5.

Whitney, C. W., Bahati, J., and Gebauer, J. (2018), Ethnobotany and agrobiodiversity; valuation of plants in the homegardens of southwestern Uganda. Ethnobiology Letters, 9(2), 90-100. https://doi.org/10.14237/ebl.9.2.2018.503

The future of ethnobotanyR: 
The package will be constantly updated with new functions and methods. If you have ideas, suggestions, metrics or methods that you would like to include please contact the package maintainer Cory Whitney <whitney.cory at gmail.com>

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


