From roundsjeremiah at gmail.com  Thu Sep  1 00:04:25 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Wed, 31 Aug 2016 15:04:25 -0700
Subject: [R] Time format lagging issue
In-Reply-To: <D3EC9D33.184DAB%macqueen1@llnl.gov>
References: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>
	<D3EC9D33.184DAB%macqueen1@llnl.gov>
Message-ID: <CAOjnRsb-6w=mZ8AFnWcwc0pBD4+ijCfA-+wiq0OokmYt49Td=A@mail.gmail.com>

Building on Don's example here is something that looks a lot like what I do
every day:
Sys.setenv(TZ="UTC")
mydf <- data.frame(t1=c('2011-12-31-22-30', '2011-12-31-23-30'))
library(lubridate)
mydf$timestamp = lubridate::ymd_hm(mydf$t1)
mydf$t2 = mydf$timestamp - period(minute=30)



On Wed, Aug 31, 2016 at 2:44 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Try following this example:
>
> mydf <- data.frame(t1=c('201112312230', '201112312330'))
> tmp1 <- as.POSIXct(mydf$t1, format='%Y%m%d%H%M')
> tmp2 <- tmp1 - 30*60
> mydf$t2 <- format(tmp2, '%Y%m%d%H%M')
>
> It can be made into a single line, but I used intermediate variables tmp1
> and tmp2 so that it would be easier to follow.
>
> Base R is more than adequate for this task.
>
> Please get rid of the asterisks in your next email. The just get in the
> way. Learn how to send plain text email, not HTML email. Please.
>
>
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 8/31/16, 9:07 AM, "R-help on behalf of Bhaskar Mitra"
> <r-help-bounces at r-project.org on behalf of bhaskar.kolkata at gmail.com>
> wrote:
>
> >Hello Everyone,
> >
> >I am trying a shift the time series in a dataframe (df) by 30 minutes . My
> >current format looks something like this :
> >
> >
> >
> >*df$$Time 1*
> >
> >
> >*201112312230*
> >
> >*201112312300*
> >
> >*201112312330*
> >
> >
> >
> >*I am trying to add an additional column of time (df$Time 2) next to  Time
> >1 by lagging it by ? 30minutes. Something like this :*
> >
> >
> >*df$Time1                   **df$$Time2*
> >
> >
> >*201112312230          **201112312200*
> >
> >*201112312300          **201112312230*
> >
> >*201112312330          **201112312300*
> >
> >*201112312330          *
> >
> >
> >
> >
> >
> >*Based on some of the suggestions available, I have tried this option *
> >
> >
> >
> >*require(zoo)*
> >
> >*df1$Time2  <- lag(df1$Time1, -1, na.pad = TRUE)*
> >
> >*View(df1)*
> >
> >
> >
> >*This does not however give me the desired result. I would appreciate any
> >suggestions/advice in this regard.*
> >
> >
> >*Thanks,*
> >
> >*Bhaskar*
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Sep  1 00:09:26 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 31 Aug 2016 15:09:26 -0700
Subject: [R] Time format lagging issue
In-Reply-To: <D3EC9D33.184DAB%macqueen1@llnl.gov>
References: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>
	<D3EC9D33.184DAB%macqueen1@llnl.gov>
Message-ID: <CAF8bMcY-s9com=ON+COWihd7PaW245bwgR-4eXDRtEZ5MTi5mg@mail.gmail.com>

That
  tmp1 - 30*60
can also be done as
  tmp1 - as.difftime(30, units="mins")
so you don't have to remember that the internal representation of POSIXct
is seconds since the start of 1970.  You can choose from the following
equivalent expressions.
  tmp1 - as.difftime(0.5, units="hours")
  tmp1 - as.difftime(1/2 * 1/24, units="days")
  tmp1 - as.difftime(30*60, units="secs")
  tmp1 - as.difftime(1/2 * 1/24 * 1/7, units="weeks")


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 31, 2016 at 2:44 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Try following this example:
>
> mydf <- data.frame(t1=c('201112312230', '201112312330'))
> tmp1 <- as.POSIXct(mydf$t1, format='%Y%m%d%H%M')
> tmp2 <- tmp1 - 30*60
> mydf$t2 <- format(tmp2, '%Y%m%d%H%M')
>
> It can be made into a single line, but I used intermediate variables tmp1
> and tmp2 so that it would be easier to follow.
>
> Base R is more than adequate for this task.
>
> Please get rid of the asterisks in your next email. The just get in the
> way. Learn how to send plain text email, not HTML email. Please.
>
>
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 8/31/16, 9:07 AM, "R-help on behalf of Bhaskar Mitra"
> <r-help-bounces at r-project.org on behalf of bhaskar.kolkata at gmail.com>
> wrote:
>
> >Hello Everyone,
> >
> >I am trying a shift the time series in a dataframe (df) by 30 minutes . My
> >current format looks something like this :
> >
> >
> >
> >*df$$Time 1*
> >
> >
> >*201112312230*
> >
> >*201112312300*
> >
> >*201112312330*
> >
> >
> >
> >*I am trying to add an additional column of time (df$Time 2) next to  Time
> >1 by lagging it by ? 30minutes. Something like this :*
> >
> >
> >*df$Time1                   **df$$Time2*
> >
> >
> >*201112312230          **201112312200*
> >
> >*201112312300          **201112312230*
> >
> >*201112312330          **201112312300*
> >
> >*201112312330          *
> >
> >
> >
> >
> >
> >*Based on some of the suggestions available, I have tried this option *
> >
> >
> >
> >*require(zoo)*
> >
> >*df1$Time2  <- lag(df1$Time1, -1, na.pad = TRUE)*
> >
> >*View(df1)*
> >
> >
> >
> >*This does not however give me the desired result. I would appreciate any
> >suggestions/advice in this regard.*
> >
> >
> >*Thanks,*
> >
> >*Bhaskar*
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Sep  1 00:28:49 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 31 Aug 2016 15:28:49 -0700
Subject: [R] Looping through different groups of variables in models
In-Reply-To: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>
References: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>
Message-ID: <CAGxFJbQ6Df7aXk4S21emw46KxWaD528uQGQDRaznqcRq8Omrqw@mail.gmail.com>

Kai:

1. I think that this is a very bad idea, statistically, if I
understand you correctly. Generally, your model should incorporate all
groups, time points, and conditions together, not individually.

2. But plotting results in "small multiples" -- aka "trellis plots"
may be useful. This is done in ggplot through "faceting" which you
could read up on and try (I use lattice, not ggplot, to do this sort
of thing, so can't help with code).

3. However, I think your question is mostly statistical in nature
(define "elegant"), and if so, is off topic here. You might therefore
try stats.stackexchange.com instead to get ideas on how to approach
your data, solicit other opinions on whether what you want to do makes
sense (and if not, what else), etc. Or, perhaps better yet, consult a
local statistical resource.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 31, 2016 at 2:58 PM, Kai Mx <govokai at gmail.com> wrote:
> Hi all,
>
> I am having trouble wrapping my head around a probably simple issue:
>
> After using the reshape package, I have a melted dataframe with the columns
> group (factor), time (int), condition (factor), value(int).
>
> These are experimental data. The data were obtained from different
> treatment groups (group) under different conditions at different time
> points.
>
> I would now like to perform ANOVA, boxplots and calculate means to compare
> groups for all combinations of conditions and time points with something
> like
>
> fit <- lm(value~group, data=[subset of data with combination of
> condition/timepoint])
> summary (fit)
> p <- ggplot([subset of data with combination of condition/timepoint],
> aes(x= group, y=value)) + geom_boxplot ()
> print (p)
> tapply ([subset of data with combination of condition/timepoint]$value,
> subset of data with combination of condition/timepoint]$group, mean)
>
> How can I loop through these combinations and output the data in an elegant
> way?
>
> Thanks so much!
>
> Best,
>
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Sep  1 00:39:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 1 Sep 2016 08:39:07 +1000
Subject: [R] Looping through different groups of variables in models
In-Reply-To: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>
References: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>
Message-ID: <CA+8X3fX=fjxhmVsbd8Unog_XJBstX3j_XBUge0393P8bun_ROg@mail.gmail.com>

Hi Kai,
Perhaps something like this:

kmdf<-data.frame(group=rep(c("exp","cont"),each=50),
 time=factor(rep(1:5,20)),
 condition=rep(rep(c("hot","cold"),each=25),2),
 value=sample(100:200,100))
for(timeindx in levels(kmdf$time)) {
 for(condindx in levels(kmdf$condition)) {
  cat("Time",timeindx,"Condition",condindx,"\n")
  subdat<-kmdf[kmdf$time == timeindx & kmdf$condition == condindx,]
  fit<-lm(value~group,subdat)
  print(summary(fit))
  plot(subdat$group,subdat$value)
  by(subdat$value,subdat$group,mean)
 }
}

Getting elegant output is another matter. Have a look at packages
meant to produce fancier R output.

Jim


On Thu, Sep 1, 2016 at 7:58 AM, Kai Mx <govokai at gmail.com> wrote:
> Hi all,
>
> I am having trouble wrapping my head around a probably simple issue:
>
> After using the reshape package, I have a melted dataframe with the columns
> group (factor), time (int), condition (factor), value(int).
>
> These are experimental data. The data were obtained from different
> treatment groups (group) under different conditions at different time
> points.
>
> I would now like to perform ANOVA, boxplots and calculate means to compare
> groups for all combinations of conditions and time points with something
> like
>
> fit <- lm(value~group, data=[subset of data with combination of
> condition/timepoint])
> summary (fit)
> p <- ggplot([subset of data with combination of condition/timepoint],
> aes(x= group, y=value)) + geom_boxplot ()
> print (p)
> tapply ([subset of data with combination of condition/timepoint]$value,
> subset of data with combination of condition/timepoint]$group, mean)
>
> How can I loop through these combinations and output the data in an elegant
> way?
>
> Thanks so much!
>
> Best,
>
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marna.wagley at gmail.com  Thu Sep  1 01:35:29 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Wed, 31 Aug 2016 16:35:29 -0700
Subject: [R] How can I add text in plot and x axis of figures created in
	ggplot2?
Message-ID: <CAMwU6B0zCcLAN7ScAg=+qaxF2CkgaagWBrVfPwMuBV9bMifoig@mail.gmail.com>

Hi R users,
I have created four figures using ggplot2, but I am having trouble  to add
"r2=XXX, p=XX" value on the upper left in each figure and also unit of X
axis of each figure are different. I was also trying to write following  :
1.  "rainfall (mm/year") on X axix for fig A.
2. "temp (degree Celsius)" on X axis for fig B
3.  "distance (m)" on X axis for fig C
4.  "survival Proba(%) on X axis for fig D

I am wondering how I can create the figures with the above information

Thank you for your help in advance

Sincerely,

Marna

following code and the example I have used.

dat<-structure(list(x = c(0.31, 0.04, 0.1, 0.54, 0.03, 0.86, 0.97,

0.4, 0.62, 0.3, 0.44, 0.51, 0.03, 0.12, 0.79, 0.3, 0.22, 0.66,

0.75, 0.45), y = c(0.38, 0.61, 0.16, 0.06, 0.42, 0.67, 0.85,

0.11, 0.79, 0.21, 0.84, 0.95, 0.3, 0.47, 0.79, 0.2, 0.34, 0.21,

0.62, 0.25), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,

2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("A",

"B", "C", "D"), class = "factor")), .Names = c("x", "y", "group"

), class = "data.frame", row.names = c(NA, -20L))


gp<-ggplot(data=dat, aes(x=x, y=y))

Gp<-gp + geom_point(size=1, col="blue")

Gp<-Gp+ stat_smooth(method="lm", level=0.99, col="black",formula=y~poly(x,1
))+

coord_cartesian(ylim=c(0, 1))+theme_bw()+

theme(axis.text.y = element_text(angle = 90, vjust = 0))+

ylab <http://docs.ggplot2.org/0.9.2.1/labs.html>*(*"My Y"*)+*theme(
axis.text.x = element_text(size=8))

Gp+ facet_wrap(~group,ncol=5, scales="free_x")

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Thu Sep  1 05:34:41 2016
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 31 Aug 2016 20:34:41 -0700
Subject: [R] Need advice on linear programming in R
Message-ID: <CACdH2ZYhVh_4xNyEbjwq_9QDJnyOW07v_=ZZ+E_hhdLbU7ZzKQ@mail.gmail.com>

Greetings.  A subset of a problem that the group I work with turns out to be
an optimization problem, in the sense of linear programming.

We've looked at several approaches to this but haven't found one that seems to
be the right fit.  I'm looking for some guidance in finding an R package that
does what we want in an acceptable time.

Here's a toy example.  We start with a matrix, called "gMat1" (historical
reasons):

> gMat1 <- matrix(c(3, 6, 9, 5, 9, 5), nrow=3)
> print(gMat1)
     [,1] [,2]
[1,]    3    5
[2,]    6    9
[3,]    9    5

The goal is to add the contents of one column of each row to one of two bins
(in general the number of bins equals the number of columns) such that the
minimum number in each bin is maximized.  An example follows.

In the toy example, the possibilities can be enumerated simply:

> allChoices <- expand.grid(rep(list(1:ncol(gMat1)), nrow(gMat1)))
> print(allChoices)
  Var1 Var2 Var3
1    1    1    1
2    2    1    1
3    1    2    1
4    2    2    1
5    1    1    2
6    2    1    2
7    1    2    2
8    2    2    2

For example, with the first choice, (1, 1, 1), column 1, hence, bin 1, is
selected for all three rows, giving a result for the two bins of:

    18   0

For the second choice, (2, 1, 1), the '2' in the first position selects the
contents of column 2 for bin 2.  The remaining (1, 1) select the (6, 9) in the
first column and assign those to bin 1:

    15   5

The result is a set of "binSums" corresponding to the each of the set of
possible choices:

> print(binSums)
     [,1] [,2]
[1,]   18    0
[2,]   15    5
[3,]   12    9
[4,]    9   14
[5,]    9    5
[6,]    6   10
[7,]    3   14
[8,]    0   19

Having generated the sums, the goal is to pick the row that has the largest
minimum and map that back to the original choice.  In the toy example, both
rows 3 and 4 satisfy that criterion ('9' is the minimum in each, and '9' is
bigger than the minima in the other 6 rows -- 0, 3, 5, 6).

In the real case there are potentially thousands of rows and columns, so
eye-balling is not an option.  And, in fact, using "expand.grid" isn't even an
option to generate the original choices.

We've tried some ad hoc approaches that seem to work tolerably well.  Here's
one that we *might* have considered, if we *could* have generated the
"allChoices/binSums":

> bsVar <- apply(binSums, 1, var)
> locBestVar <- which(bsVar == min(bsVar))
> allChoices[locBestVar, ]
  Var1 Var2 Var3
3    1    2    1

But there was a feeling within the group that we didn't have a solid-enough
foundation using the ad hoc approaches.  Hence, we asked for help from an
expert in Operations Research.  He was able to solve a problem of realistic
size in more or less no time at all using the "GAMS" software:

    https://www.gams.com/

Unfortunately, GAMS is not free software, and we are hoping to produce an R
package that is freely distributable.  The next suggestion was to use Gurobi:

    http://www.gurobi.com/

which is evidently free for academic use but not otherwise.  Better, but still
not perfect.  (And I couldn't use the free version of Gurobi while working
from home, as it didn't consider my home network to be associated with an
academic institution -- which of course it isn't).

Finally, we tried:

    Rglpk_solve_LP

from the R package "Rglpk":

    https://cran.r-project.org/web/packages/Rglpk/index.html

This satisfied the licensing constraints, but we were unable to produce a
result in a "finite" amount of time.  By this I mean that we ran the Rglpk
software on a problem with 200 rows and 20 columns on the latest Mac Pro with
64GB of memory, and it didn't finish overnight.  A realistic problem would
have at least 10000 rows and 50 columns.  (This admittedly might simply have
been a consequence of our unfamiliarity with the package. Suggestions
welcome.) To be clear, this process is not something we'd be doing once in
order to build the package.  This is something an end user would have to do
every time he/she ran our package.

If you've managed to read this far and have any suggestions as to how we might
proceed, please send them my way.  Thanks.

-- Mike


From pdalgd at gmail.com  Thu Sep  1 10:14:00 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 1 Sep 2016 10:14:00 +0200
Subject: [R] GLM output problem
In-Reply-To: <CAGxFJbS-d2VQPqsTX2irhL2D9BWLgtUocyO8i3QuSfnvPtjfLg@mail.gmail.com>
References: <CAEPvLrzCHUtF4+Tuj4ai83cp0u6+oyeY1wVP+fXBmSx6rh2omQ@mail.gmail.com>
	<CAGxFJbS-d2VQPqsTX2irhL2D9BWLgtUocyO8i3QuSfnvPtjfLg@mail.gmail.com>
Message-ID: <A144CFC9-407F-4476-BEC2-63191C92A187@gmail.com>

>> And use the parameters returned by GLM to contruct an equation for the
>> regression model:
>> 
>> model.eq = -0.446078 + 0.267673*x - 0.014577*I(x^2)
> 
> ## Not what I got with your data. I got:
> 
> Coefficients:
> (Intercept)            x       I(x^2)
>   -18.5750       5.0403      -0.2845
> 
> 
> I suspect you had some other x,y variables lying around when you
> defined your model.


More likely, the family= specification got lost and gaussian family implied:

> glm(model)

Call:  glm(formula = model)

Coefficients:
(Intercept)            x       I(x^2)  
   -0.44608      0.26767     -0.01458  

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Sep  1 10:24:24 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 1 Sep 2016 10:24:24 +0200
Subject: [R] Need advice on linear programming in R
In-Reply-To: <CACdH2ZYhVh_4xNyEbjwq_9QDJnyOW07v_=ZZ+E_hhdLbU7ZzKQ@mail.gmail.com>
References: <CACdH2ZYhVh_4xNyEbjwq_9QDJnyOW07v_=ZZ+E_hhdLbU7ZzKQ@mail.gmail.com>
Message-ID: <4725E47F-4CB1-4D18-898C-DF05AD49A13F@gmail.com>


> On 01 Sep 2016, at 05:34 , Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
> 
> Greetings.  A subset of a problem that the group I work with turns out to be
> an optimization problem, in the sense of linear programming.
> 
> We've looked at several approaches to this but haven't found one that seems to
> be the right fit.  I'm looking for some guidance in finding an R package that
> does what we want in an acceptable time.
> 

Possibly a completely useless piece of advice, but have you checked the CRAN Task View:

https://cran.r-project.org/web/views/Optimization.html#MathematicalProgrammingSolvers

?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jmhannon.ucdavis at gmail.com  Thu Sep  1 10:35:19 2016
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Thu, 1 Sep 2016 01:35:19 -0700
Subject: [R] Need advice on linear programming in R
In-Reply-To: <4725E47F-4CB1-4D18-898C-DF05AD49A13F@gmail.com>
References: <CACdH2ZYhVh_4xNyEbjwq_9QDJnyOW07v_=ZZ+E_hhdLbU7ZzKQ@mail.gmail.com>
	<4725E47F-4CB1-4D18-898C-DF05AD49A13F@gmail.com>
Message-ID: <CACdH2ZZFaZoMgqY+jy7Ne2db5Y6v8-tZSXPyRh6TD=tLmn=3Qw@mail.gmail.com>

Thanks, Peter.  Not useless at all, but I'm somewhat overwhelmed by
the choices.  I'll have a closer look at some of them.

-- Mike


On Thu, Sep 1, 2016 at 1:24 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 01 Sep 2016, at 05:34 , Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
>>
>> Greetings.  A subset of a problem that the group I work with turns out to be
>> an optimization problem, in the sense of linear programming.
>>
>> We've looked at several approaches to this but haven't found one that seems to
>> be the right fit.  I'm looking for some guidance in finding an R package that
>> does what we want in an acceptable time.
>>
>
> Possibly a completely useless piece of advice, but have you checked the CRAN Task View:
>
> https://cran.r-project.org/web/views/Optimization.html#MathematicalProgrammingSolvers
>
> ?
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From mlscmahe at gmail.com  Thu Sep  1 12:24:26 2016
From: mlscmahe at gmail.com (MLSC)
Date: Thu, 1 Sep 2016 13:24:26 +0300
Subject: [R] Error while running Vegas function in cpvSNP package
Message-ID: <CACboDEr9FytgCX53A1x2dEp6o3oh3KXAy16VmdCVNZTytEr59A@mail.gmail.com>

Hello Sir,

When I try to run vegas() function, I come across below errors, can
somebody help me in fixing this issue?

> test<-vegas(snpsGSC, gr,ldMat,1000,correction=TRUE,seed=NULL,
verbose=FALSE)
Warning: coercing ldMatrix from data.frame to matrix.
Error in validObject(.Object) :
  invalid class ?VEGASResultCollection? object: members must all be
'VEGASResult' classes
> test<-vegas(gs2, gr,ldMat,1000,correction=TRUE,seed=NULL, verbose=FALSE)
Warning: coercing ldMatrix from data.frame to matrix.
Error in validObject(.Object) :
  invalid class ?VEGASResultCollection? object: members must all be
'VEGASResult' classes


Please find structure of objects used inside vegas(), below


> class(gs2)
[1] "GeneSetCollection"
attr(,"package")
[1] "GSEABase"
> gs2
GeneSetCollection
  names: NA (1 total)
  unique identifiers: 730005, 23755, ..., 23762 (8 total)
  types in collection:
    geneIdType: NullIdentifier (1 total)
    collectionType: NullCollection (1 total)
> snpsGSC
GeneSetCollection
  names: NA (1 total)
  unique identifiers: rs9608956, rs6518694, ..., rs2240176 (117 total)
  types in collection:
    geneIdType: AnnotationIdentifier (1 total)
    collectionType: NullCollection (1 total)
> gr
GRanges object with 10357 ranges and 6 metadata columns:
          seqnames               ranges strand   |         P         SNP
             <Rle>            <IRanges>  <Rle>   | <numeric> <character>
      [1]    chr22 [16114244, 16114244]      *   |    0.9298  rs12157537
      [2]    chr22 [16494187, 16494187]      *   |    0.2571   rs8142331
      [3]    chr22 [16855618, 16855618]      *   |    0.3743   rs5747010
      [4]    chr22 [17012935, 17012935]      *   |    0.1005   rs9604821
      [5]    chr22 [17057138, 17057138]      *   |    0.5120   rs5746647
      ...      ...                  ...    ... ...       ...         ...
  [10353]    chr22 [51171693, 51171693]      *   |    0.6500    rs756638
  [10354]    chr22 [51175626, 51175626]      *   |    0.5235   rs3810648
  [10355]    chr22 [51178090, 51178090]      *   |    0.2008   rs2285395
  [10356]    chr22 [51181759, 51181759]      *   |    0.4858  rs13056621
  [10357]    chr22 [51211392, 51211392]      *   |    0.2952   rs3888396
           Position Chromosome     Start       End
          <integer>   <factor> <integer> <integer>
      [1]  16114244      chr22  16114244  16114244
      [2]  16494187      chr22  16494187  16494187
      [3]  16855618      chr22  16855618  16855618
      [4]  17012935      chr22  17012935  17012935
      [5]  17057138      chr22  17057138  17057138
      ...       ...        ...       ...       ...
  [10353]  51171693      chr22  51171693  51171693
  [10354]  51175626      chr22  51175626  51175626
  [10355]  51178090      chr22  51178090  51178090
  [10356]  51181759      chr22  51181759  51181759
  [10357]  51211392      chr22  51211392  51211392
  -------
  seqinfo: 1 sequence from an unspecified genome; no seqlengths

>ldMat
               rs756638    rs3810648    rs2285395   rs13056621    rs3888396
rs133433   2.302381e-04 1.593234e-03 1.745740e-03 3.279513e-03 1.135283e-03
rs4645824  3.435556e-04 2.872766e-03 6.350416e-05 9.143595e-04 2.032939e-03
rs12165592 1.164639e-04 6.331347e-03 1.911289e-03 2.124385e-03 7.972265e-04
rs2413348  1.148297e-04 4.106582e-03 1.857187e-03 9.805785e-04 5.707284e-04
rs5755729  6.863351e-04 7.718787e-04 1.794326e-04 9.102677e-05 1.835078e-05
rs5755730  6.606449e-04 1.817608e-03 2.795217e-04 2.912946e-04 1.582141e-03
rs738207   3.193647e-03 1.833686e-06 2.162108e-06 1.377696e-03 3.024123e-03
rs28528068 5.097169e-04 9.289022e-05 8.253080e-05 9.775527e-06 4.618146e-04
rs9610304  2.185120e-05 1.753900e-03 3.760546e-04 4.235130e-06 7.791331e-04
rs5999844  1.511305e-04 5.263161e-05 1.594619e-04 3.668878e-04 9.886630e-05
rs8136332  1.466643e-04 6.929900e-04 1.128017e-05 1.327246e-03 3.758860e-04
rs909704   9.107431e-05 6.988505e-05 8.734125e-04 6.070963e-04 1.666259e-05
rs10483191 1.563958e-04 6.843857e-04 1.050799e-05 1.289273e-03 3.944796e-04
rs880211   7.008708e-05 3.167541e-03 6.418652e-04 2.483367e-04 1.344723e-03
rs1107498  1.888331e-04 2.733062e-03 6.233536e-04 3.931746e-04 1.341147e-03
rs5999855  3.143964e-05 5.473455e-03 1.166912e-03 4.374772e-03 2.152193e-03
rs9610308  1.579521e-05 5.385714e-06 1.199517e-06 3.337275e-03 4.705493e-04
rs713968   1.125728e-03 2.431651e-05 7.292905e-05 9.684127e-04 6.402607e-05
rs139059   2.946244e-04 2.765441e-04 2.785183e-06 7.474786e-04 3.190005e-04
 [ reached getOption("max.print") -- omitted 4981 rows ]

Please find session info below,
> sessionInfo()
R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu/64 (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats4    parallel  stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
 [1] TxDb.Hsapiens.UCSC.hg18.knownGene_3.2.2
 [2] VariantAnnotation_1.16.4
 [3] Rsamtools_1.22.0
 [4] Biostrings_2.38.4
 [5] XVector_0.10.0
 [6] SummarizedExperiment_1.0.2
 [7] biomaRt_2.26.1
 [8] snpStats_1.20.0
 [9] Matrix_1.2-6
[10] survival_2.39-5
[11] genetics_1.3.8.1
[12] mvtnorm_1.0-5
[13] gtools_3.5.0
[14] gdata_2.17.0
[15] combinat_0.0-8
[16] MultiPhen_2.0.1
[17] meta_4.5-0
[18] epitools_0.5-7
[19] abind_1.4-5
[20] MASS_7.3-45
[21] BiocInstaller_1.20.3
[22] TxDb.Hsapiens.UCSC.hg19.knownGene_3.2.2
[23] cpvSNP_1.2.0
[24] GSEABase_1.32.0
[25] graph_1.48.0
[26] annotate_1.48.0
[27] XML_3.98-1.4
[28] GenomicFeatures_1.22.13
[29] AnnotationDbi_1.32.3
[30] Biobase_2.30.0
[31] GenomicRanges_1.22.4
[32] GenomeInfoDb_1.6.3
[33] IRanges_2.4.8
[34] S4Vectors_0.8.11
[35] BiocGenerics_0.16.1

loaded via a namespace (and not attached):
 [1] splines_3.2.4           lattice_0.20-33         colorspace_1.2-6
 [4] rtracklayer_1.30.4      HardyWeinberg_1.5.6     DBI_0.5
 [7] BiocParallel_1.4.3      RColorBrewer_1.1-2      lambda.r_1.1.9
[10] plyr_1.8.4              zlibbioc_1.16.0         munsell_0.4.3
[13] gtable_0.2.0            futile.logger_1.4.3     caTools_1.17.1
[16] Rcpp_0.12.6             KernSmooth_2.23-15      xtable_1.8-2
[19] corpcor_1.6.8           BSgenome_1.38.0         scales_0.4.0
[22] gplots_3.0.1            ggplot2_2.1.0           grid_3.2.4
[25] tools_3.2.4             bitops_1.0-6            RCurl_1.95-4.8
[28] RSQLite_1.0.0           mice_2.25               futile.options_1.0.0
[31] rpart_4.1-10            GenomicAlignments_1.6.3 nnet_7.3-12
>

Thanking you in anticipation.

Regards,
Prashantha

	[[alternative HTML version deleted]]


From govokai at gmail.com  Thu Sep  1 13:01:26 2016
From: govokai at gmail.com (Kai Mx)
Date: Thu, 1 Sep 2016 13:01:26 +0200
Subject: [R] Looping through different groups of variables in models
In-Reply-To: <CADv2QyEF3yv7zX-0Znv1R_8Xo=NHVeJ3KvqBGFcG3UkBW_er+w@mail.gmail.com>
References: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>
	<CADv2QyEF3yv7zX-0Znv1R_8Xo=NHVeJ3KvqBGFcG3UkBW_er+w@mail.gmail.com>
Message-ID: <CAHOWgNX73bBw-HRs2QYyT6Zwd_ArM37i-Ur5=Y0uGrYDXbDSDg@mail.gmail.com>

Thanks so much everybody, especially to Dennis. I didn't really occur to me
that I could put the models into a list. I have used dplyr for simple data
transformations and will definitely look into it.

On Thu, Sep 1, 2016 at 8:10 AM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
>
> See inline.
>
> On Wed, Aug 31, 2016 at 2:58 PM, Kai Mx <govokai at gmail.com> wrote:
> > Hi all,
> >
> > I am having trouble wrapping my head around a probably simple issue:
> >
> > After using the reshape package, I have a melted dataframe with the
> columns
> > group (factor), time (int), condition (factor), value(int).
> >
> > These are experimental data. The data were obtained from different
> > treatment groups (group) under different conditions at different time
> > points.
> >
> > I would now like to perform ANOVA, boxplots and calculate means to
> compare
> > groups for all combinations of conditions and time points with something
> > like
> >
> > fit <- lm(value~group, data=[subset of data with combination of
> > condition/timepoint])
> > summary (fit)
> > p <- ggplot([subset of data with combination of condition/timepoint],
> > aes(x= group, y=value)) + geom_boxplot ()
> > print (p)
> > tapply ([subset of data with combination of condition/timepoint]$value,
> > subset of data with combination of condition/timepoint]$group, mean)
>
> There is a traditional approach to this class of problem and an
> evolving 'modern' approach. The traditional approach is to use
> lapply() to produce a list of model objects (one per subgroup); the
> more recent approach is to take advantage of the pipeline operations
> enabled by the magrittr package, e.g.,via the dplyr and tidyr
> packages.  Related packages are purrr and broom; the former applies
> functional programming ideas to map a function recursively across a
> list, while the latter focuses on converting information from model
> objects into data frames that are more compatible with dplyr and
> friends.A package released to CRAN within the past couple of days,
> modelr, adds a few bells and whistles (e.g., bootstrap regression,
> adding columns of predicted values or residuals to a data frame), but
> you don't need it for your immediate purposes.
>
> Below is a generic approach to solving the types of problems you
> described above, which is the best one can do in the absence of a
> reproducible example. Therefore, if this doesn't work out of the box,
> you'll have to fix your data. (I won't do it for you, sorry.)
>
> You could do something like what you have in mind in plyr as follows,
> where md is a surrogate for the name of your melted data frame:
>
> library(plyr)
> L <- dlply(md, .(condition, time), function(d) lm(value ~ group, data = d))
>
> This would produce a list of models, one per condition * time
> combination. You could then use do.call() or another plyr function to
> extract elements of interest from the list, which generally would
> require that you write one or more (anonymous) functions to extract
> the information of interest. A similar approach can be used to
> generate a list of ggplots. It's cleaner if you put your code into
> functions and have it return the output you want, but you have to be
> careful about the form of the input and output - for dlply(), you want
> a function that takes a data frame as input. If you just want the
> plots printed, you could write a function to do that for a single plot
> (again with a data frame as input) and then use the d_ply() function
> in plyr to print them en masse, but it would generally make more sense
> to write them to files, so you'd probably be better off writing a
> function that ends with a ggsave() call and call d_ply(). [Note: the _
> is used when your function creates a side effect, such as printing or
> saving a plot object - it returns nothing to the R console.]
>
> As for the numeric summaries,
>
> ddply(md, .(condition, time, group), function(d) mean(d$value, na.rm =
> TRUE))
>
> would work. The advantage of plyr (and its successor, dplyr) is that
> you can pass arbitrary functions as the third argument as long as the
> input is a data frame and the output is a data frame (or something
> that can be coerced to a data frame). This is more robust than
> tapply().
>
> Comment: plyr/reshape2 is a good starter package combination as it
> teaches you the value of the split-apply-combine approach to data
> analysis, but it can be (very) slow. The dplyr/tidyr package
> combination is faster, more computationally efficient version of
> plyr::ddply() and reshape2 and is recommended for use, although you
> have to learn a somewhat different approach to R programming in the
> process. If you're fairly new to R, that shouldn't matter much.
>
> There has been a lot of work in the last year or two to improve the
> flow of programming for tasks such as recursive plotting or model
> fitting. The dplyr and tidyr packages are meant to be replacements for
> plyr and reshape[2], respectively; both are written by Hadley Wickham.
> These packages extensively use operators created by Stephan Bache in
> the magrittr package, particularly %>%, the pipeline operator, and .,
> the current data object operator. %>% is read as "then": its purpose
> is to take a data frame object as input and return the result of an
> operation on the data (i.e., a function call) as a data frame.
> Repeated application results in a chain of operations that establishes
> a programming flow and has the nice side effect of producing more
> readable, better organized code.
>
> There are some beautiful advantages to this approach to programming,
> but there are also some challenges, particularly when attempting to
> write functions in dplyr. At this point, you don't need to worry about
> it. The analogy to plyr::dlply() is dplyr::do(), which applies a
> function to each subgroup of data defined by the grouping variables.
> Related packages for modeling include broom (highly recommended) and
> perhaps modelr, although the latter is probably not relevant for your
> particular problem. OTOH, broom is certainly relevant.
>
> The most important functions in dplyr are "verbs" that apply a
> specific action to the input data:
>
> * group_by()   defines grouping variables, applies the "split" aspect
> of split-apply-combine
> * filter()     selects rows either by index or by logical expression
> * select()  selects variables (columns) either by column number or name
> * arrange()    sorts rows by value with respect to one or more
> grouping variables
> * mutate()     defines new variables or modifies existing ones
> * summarise()   applies a one-number summary function to a variable
>
> These are referred to as "one-table verbs". Functions that are
> "two-table" verbs are typically used to produce joins of two tables.
>
> The broom package is designed to summarize the output from model
> objects into data frames. The two primary functions are tidy(), which
> returns a summary data frame of the model coefficients, and glance(),
> which returns a vector of summary statistics (e.g, r^2, RMSE)
> associated with the model. The advantage is that the functions are
> designed to work in a dplyr data pipeline and can be used to combine
> the results from a list of model fits.
>
> Here's a template to pull off the model fitting exercise in dplyr,
> tidyr and broom. (Note: dplyr has many of the same functions as plyr,
> so if you need to load both, load plyr first and then load dplyr.)
>
> library(dplyr)
> library(tidyr)
> library(broom)
>
> ## Return an object that is effectively a list of models
> mods <- md %>%
>               group_by(condition, time) %>%
>               do(mod = lm(value ~ group, data = .)    # mod is an
> object of class lm
>
> # Note:   . is a placeholder for the current data
>
> # Now access tidy summaries of the models using broom - see its
> documentation
> # for details
> mods %>% tidy(mod, conf.int = TRUE)
> mods %>% glance(mod)
>
>
> For the ggplots, something like the following would apply:
>
> md %>% group_by(condition, time) %>%    # splits the data into subgroups
>                ggplot(., aes(x = group, y = value)) +
>                    geom_boxplot() +
>                    ggsave(paste(paste(group, value, sep = "_"), "png",
> sep = "."))
>
>
> The equivalent of tapply() in dplyr is a summarise() function:
>
> md %>% group_by(condition, time, group) %>%
>                summarise(mean = mean(value, na.rm = TRUE))
>
> Several variations of summarise() are present in dplyr which give it a
> great deal of flexibility; e.g., summarise_each() applies the same
> function to a set of variables or allows multiple functions to be
> applied to one or more variables:
>
> md %>% group_by(condition, time, group) %>%
>               summarise_at(vars(value), funs(mean, sd, min, max),  na.rm =
> TRUE)
>
>
> If you [intend to] use R on a regular basis and commonly encounter the
> types of problems you've described here, I'd strongly suggest that you
> look carefully into dplyr and friends. If you have the time, I'd also
> suggest looking into the data.table package, which is usually a bit
> faster than dplyr. It does many of the same types of tasks; recently,
> Hadley recently released the dtplyr package which allows data.table
> objects to be passed through the pipeline and allows use of data.table
> code in the pipeline. The combination of the two is powerful.
>
> Comment: Bert Gunter's advice about modeling the data en masse is
> important, because it allows one to investigate potential interactions
> and relationships that you cannot do with data subsets. His cautions
> should not be ignored. OTOH, sometimes data is intentionally
> segregated and listwise modeling/summarization is appropriate. I don't
> know which of these situations applies to you, but you need to
> consider the implications of sub-analyses carefully.
>
> Sorry for the length of this missive, but I hope it is of some help to you.
>
> Dennis
> >
> > How can I loop through these combinations and output the data in an
> elegant
> > way?
> >
> > Thanks so much!
> >
> > Best,
> >
> > Kai
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Sep  1 15:45:56 2016
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 1 Sep 2016 05:45:56 -0800
Subject: [R] How can I add text in plot and x axis of figures created in
 ggplot2?
In-Reply-To: <CAMwU6B0zCcLAN7ScAg=+qaxF2CkgaagWBrVfPwMuBV9bMifoig@mail.gmail.com>
Message-ID: <22B3E84266B.00000687jrkrideau@inbox.com>

Hi Marna,

Thanks for providing the data and code. However there is a problem with the code and I wondered if something got garbled in transmission.

Below is the code that was in my mailbox
==================================================
ylab <http://docs.ggplot2.org/0.9.2.1/labs.html>*(*"My Y"*)+*theme(
axis.text.x = element_text(size=8))
=================================================
Clearly not functioning code

Am I correct in assuming that what it originally looked like was :
==============================================
ylab("http://docs.ggplot2.org/0.9.2.1/labs.html") +
       theme(axis.text.x = element_text(size=8))
==============================================
?

It looks like you are sending mail in HTML and that can badly mangle code and data layouts. Please send an messages to R-help in plain text.  

I don't use facet_wrap() enough to know if what you want to do is doable but I am a bit dubious. 

I wonder if you have considered creating 4 independent graphs and using grid.Extra or grid.arrange to get the results you want.?

Sorry not to be of more help

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marna.wagley at gmail.com
> Sent: Wed, 31 Aug 2016 16:35:29 -0700
> To: r-help at r-project.org
> Subject: [R] How can I add text in plot and x axis of figures created in
> ggplot2?
> 
> Hi R users,
> I have created four figures using ggplot2, but I am having trouble  to
> add
> "r2=XXX, p=XX" value on the upper left in each figure and also unit of X
> axis of each figure are different. I was also trying to write following
> :
> 1.  "rainfall (mm/year") on X axix for fig A.
> 2. "temp (degree Celsius)" on X axis for fig B
> 3.  "distance (m)" on X axis for fig C
> 4.  "survival Proba(%) on X axis for fig D
> 
> I am wondering how I can create the figures with the above information
> 
> Thank you for your help in advance
> 
> Sincerely,
> 
> Marna
> 
> following code and the example I have used.
> 
> dat<-structure(list(x = c(0.31, 0.04, 0.1, 0.54, 0.03, 0.86, 0.97,
> 
> 0.4, 0.62, 0.3, 0.44, 0.51, 0.03, 0.12, 0.79, 0.3, 0.22, 0.66,
> 
> 0.75, 0.45), y = c(0.38, 0.61, 0.16, 0.06, 0.42, 0.67, 0.85,
> 
> 0.11, 0.79, 0.21, 0.84, 0.95, 0.3, 0.47, 0.79, 0.2, 0.34, 0.21,
> 
> 0.62, 0.25), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 
> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("A",
> 
> "B", "C", "D"), class = "factor")), .Names = c("x", "y", "group"
> 
> ), class = "data.frame", row.names = c(NA, -20L))
> 
> 
> gp<-ggplot(data=dat, aes(x=x, y=y))
> 
> Gp<-gp + geom_point(size=1, col="blue")
> 
> Gp<-Gp+ stat_smooth(method="lm", level=0.99,
> col="black",formula=y~poly(x,1
> ))+
> 
> coord_cartesian(ylim=c(0, 1))+theme_bw()+
> 
> theme(axis.text.y = element_text(angle = 90, vjust = 0))+
> 
> ylab <http://docs.ggplot2.org/0.9.2.1/labs.html>*(*"My Y"*)+*theme(
> axis.text.x = element_text(size=8))
> 
> Gp+ facet_wrap(~group,ncol=5, scales="free_x")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From ulrik.stervbo at gmail.com  Thu Sep  1 16:00:55 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 01 Sep 2016 14:00:55 +0000
Subject: [R] How can I add text in plot and x axis of figures created in
	ggplot2?
In-Reply-To: <22B3E84266B.00000687jrkrideau@inbox.com>
References: <CAMwU6B0zCcLAN7ScAg=+qaxF2CkgaagWBrVfPwMuBV9bMifoig@mail.gmail.com>
	<22B3E84266B.00000687jrkrideau@inbox.com>
Message-ID: <CAKVAULND_MqrZkhOfZVdTmU0ES8Xh=upxk0B1j_baMH5apbaNg@mail.gmail.com>

Hi Marna,

when you use facet there is just one X-axis title and one Y-axis title. As
an alternative you can create several plots and put them into one using the
package gridExtra.

As for adding text you can use geom_text and extract the x, y coordinates
from your data. When I add text, I usually create a separate data.frame
which in addition to the text I want to add and the positions also contains
indications of the global aesthetic and the facet column

Hope this helps
Ulrik

On Thu, 1 Sep 2016 at 15:48 John Kane <jrkrideau at inbox.com> wrote:

> Hi Marna,
>
> Thanks for providing the data and code. However there is a problem with
> the code and I wondered if something got garbled in transmission.
>
> Below is the code that was in my mailbox
> ==================================================
> ylab <http://docs.ggplot2.org/0.9.2.1/labs.html>*(*"My Y"*)+*theme(
> axis.text.x = element_text(size=8))
> =================================================
> Clearly not functioning code
>
> Am I correct in assuming that what it originally looked like was :
> ==============================================
> ylab("http://docs.ggplot2.org/0.9.2.1/labs.html") +
>        theme(axis.text.x = element_text(size=8))
> ==============================================
> ?
>
> It looks like you are sending mail in HTML and that can badly mangle code
> and data layouts. Please send an messages to R-help in plain text.
>
> I don't use facet_wrap() enough to know if what you want to do is doable
> but I am a bit dubious.
>
> I wonder if you have considered creating 4 independent graphs and using
> grid.Extra or grid.arrange to get the results you want.?
>
> Sorry not to be of more help
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: marna.wagley at gmail.com
> > Sent: Wed, 31 Aug 2016 16:35:29 -0700
> > To: r-help at r-project.org
> > Subject: [R] How can I add text in plot and x axis of figures created in
> > ggplot2?
> >
> > Hi R users,
> > I have created four figures using ggplot2, but I am having trouble  to
> > add
> > "r2=XXX, p=XX" value on the upper left in each figure and also unit of X
> > axis of each figure are different. I was also trying to write following
> > :
> > 1.  "rainfall (mm/year") on X axix for fig A.
> > 2. "temp (degree Celsius)" on X axis for fig B
> > 3.  "distance (m)" on X axis for fig C
> > 4.  "survival Proba(%) on X axis for fig D
> >
> > I am wondering how I can create the figures with the above information
> >
> > Thank you for your help in advance
> >
> > Sincerely,
> >
> > Marna
> >
> > following code and the example I have used.
> >
> > dat<-structure(list(x = c(0.31, 0.04, 0.1, 0.54, 0.03, 0.86, 0.97,
> >
> > 0.4, 0.62, 0.3, 0.44, 0.51, 0.03, 0.12, 0.79, 0.3, 0.22, 0.66,
> >
> > 0.75, 0.45), y = c(0.38, 0.61, 0.16, 0.06, 0.42, 0.67, 0.85,
> >
> > 0.11, 0.79, 0.21, 0.84, 0.95, 0.3, 0.47, 0.79, 0.2, 0.34, 0.21,
> >
> > 0.62, 0.25), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >
> > 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("A",
> >
> > "B", "C", "D"), class = "factor")), .Names = c("x", "y", "group"
> >
> > ), class = "data.frame", row.names = c(NA, -20L))
> >
> >
> > gp<-ggplot(data=dat, aes(x=x, y=y))
> >
> > Gp<-gp + geom_point(size=1, col="blue")
> >
> > Gp<-Gp+ stat_smooth(method="lm", level=0.99,
> > col="black",formula=y~poly(x,1
> > ))+
> >
> > coord_cartesian(ylim=c(0, 1))+theme_bw()+
> >
> > theme(axis.text.y = element_text(angle = 90, vjust = 0))+
> >
> > ylab <http://docs.ggplot2.org/0.9.2.1/labs.html>*(*"My Y"*)+*theme(
> > axis.text.x = element_text(size=8))
> >
> > Gp+ facet_wrap(~group,ncol=5, scales="free_x")
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lisa-marie.kindler at ducatihamburg.de  Thu Sep  1 00:25:42 2016
From: lisa-marie.kindler at ducatihamburg.de (Lisa Ducati HH)
Date: Thu, 1 Sep 2016 00:25:42 +0200
Subject: [R] R-Studio+Commander
Message-ID: <47C7F038-E84D-4C40-998C-8B8D549296C2@ducatihamburg.de>

> Hello,
> 
> I would like to Know if i can install r on my iPad Air 2? Is this possible?
> 
> Regards Lisa-Marie Kindler

Von meinem iPhone gesendet
	[[alternative HTML version deleted]]


From abdoulayesar at gmail.com  Thu Sep  1 14:10:06 2016
From: abdoulayesar at gmail.com (Abdoulaye SARR)
Date: Thu, 1 Sep 2016 12:10:06 +0000
Subject: [R] problem writing .bil files in netcdf
Message-ID: <9B68B493-7492-4CB6-A5C5-72C724E4483E@gmail.com>

Dear List,

I have daily rainfall data in .bil format and can get info of the file using rgdal:

> library(rgdal)
> GDALinfo("/1981/v2p19810101.bil")
rows        1600 
columns     1500 
bands       1 
lower left origin.x        -20 
lower left origin.y        -40 
res.x       0.05 
res.y       0.05 
ysign       -1 
oblique.x   0 
oblique.y   0 
driver      EHdr 
projection  NA 

How can I read all daily file and write them as netcdf files and concatenate as one yearly file and also avoid boundary pixels alter rainfall values.

Best regards,

Eus


From andersonaed at gmail.com  Thu Sep  1 14:13:25 2016
From: andersonaed at gmail.com (Anderson Eduardo)
Date: Thu, 1 Sep 2016 09:13:25 -0300
Subject: [R] GLM output problem
In-Reply-To: <A144CFC9-407F-4476-BEC2-63191C92A187@gmail.com>
References: <CAEPvLrzCHUtF4+Tuj4ai83cp0u6+oyeY1wVP+fXBmSx6rh2omQ@mail.gmail.com>
	<CAGxFJbS-d2VQPqsTX2irhL2D9BWLgtUocyO8i3QuSfnvPtjfLg@mail.gmail.com>
	<A144CFC9-407F-4476-BEC2-63191C92A187@gmail.com>
Message-ID: <CAEPvLrz9x4WZWqMgAuZSr0aGpWuXy-g3nnCLV0RBJ7sZENnv0Q@mail.gmail.com>

Embarrassing but that's true. I wrote 'binamial' instead of 'binomial'. I
tried now with the correct spelling and everything is ok, in fact.


> summary(GLM)

Call:
glm(formula = model, family = binomial(link = logit))

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -18.5750    10.7646  -1.726   0.0844 .
x             5.0403     2.7757   1.816   0.0694 .
I(x^2)       -0.2845     0.1558  -1.826   0.0679 .



Thank you all.

Anderson Eduardo


2016-09-01 5:14 GMT-03:00 peter dalgaard <pdalgd at gmail.com>:

> >> And use the parameters returned by GLM to contruct an equation for the
> >> regression model:
> >>
> >> model.eq = -0.446078 + 0.267673*x - 0.014577*I(x^2)
> >
> > ## Not what I got with your data. I got:
> >
> > Coefficients:
> > (Intercept)            x       I(x^2)
> >   -18.5750       5.0403      -0.2845
> >
> >
> > I suspect you had some other x,y variables lying around when you
> > defined your model.
>
>
> More likely, the family= specification got lost and gaussian family
> implied:
>
> > glm(model)
>
> Call:  glm(formula = model)
>
> Coefficients:
> (Intercept)            x       I(x^2)
>    -0.44608      0.26767     -0.01458
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


-- 
Anderson A. Eduardo
------------------------------------------------------------------------------
Lattes <http://lattes.cnpq.br/3826166230581311> | Researcher ID
<http://orcid.org/0000-0001-8045-8043> | Google Acad?mico
<https://scholar.google.com.br/citations?user=oOUjq9IAAAAJ&hl=pt-BR> | Site
<http://andersonaireseduardo.xpg.uol.com.br/>
------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Sep  1 16:44:32 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 1 Sep 2016 10:44:32 -0400
Subject: [R] Same code on Mac?
In-Reply-To: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
References: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
Message-ID: <CAM_vju=qnDsa3E0L77da84+VMG=5i_7VCDc82g6vS26TjPJzFw@mail.gmail.com>

On Wed, Aug 31, 2016 at 4:25 PM, Tom Mosca <tom at vims.edu> wrote:
> Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?
>
>
>
> Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.
>


There's an official FAQ for Mac, just as there is for Windows.
https://cran.r-project.org/faqs.html
There's also a Mac-specific email help list.
https://www.r-project.org/mail.html

Most R code will run as well or better on Mac. All of the OS problems
I've run into tend to be problems with Windows. It's a bit harder to
get some geospatial stuff working on Mac, but that's unlikely to be a
problem with your elementary stats students.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Thu Sep  1 16:53:16 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 01 Sep 2016 09:53:16 -0500
Subject: [R] R-Studio+Commander
In-Reply-To: <47C7F038-E84D-4C40-998C-8B8D549296C2@ducatihamburg.de>
References: <47C7F038-E84D-4C40-998C-8B8D549296C2@ducatihamburg.de>
Message-ID: <C72098BE-F191-4FAE-BA4E-62DAE508F7C3@me.com>


> On Aug 31, 2016, at 5:25 PM, Lisa Ducati HH <lisa-marie.kindler at ducatihamburg.de> wrote:
> 
>> Hello,
>> 
>> I would like to Know if i can install r on my iPad Air 2? Is this possible?
>> 
>> Regards Lisa-Marie Kindler


Not directly and if you search the archives (use rseek.org and search for "iPad" or "iPhone"), there have been a variety of posts on why over the years, such as:

  https://stat.ethz.ch/pipermail/r-help/2010-June/240901.html

unless you "jailbreak" your device.

That being said, there may be options via third party technologies to run an R instance remotely from a server and/or via desktop VM clients that can run on mobile devices (e.g. Parallels). A Google search brings up some links from the RStudio support forums and you may want to search those separately.

Regards,

Marc Schwartz


From bgunter.4567 at gmail.com  Thu Sep  1 17:09:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Sep 2016 08:09:46 -0700
Subject: [R] Off topic,
	but hopefully not totally irrelevant: on MS Excel and genomics
Message-ID: <CAGxFJbScOSM7Y_7TgWPwF2urqmBWmHErE8bHYvK-XJ27_FBrCw@mail.gmail.com>

http://www.sciencemag.org/news/sifter/one-five-genetics-papers-contains-errors-thanks-microsoft-excel

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From rbaer at atsu.edu  Thu Sep  1 17:30:18 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 1 Sep 2016 10:30:18 -0500
Subject: [R] Same code on Mac?
In-Reply-To: <CAM_vju=qnDsa3E0L77da84+VMG=5i_7VCDc82g6vS26TjPJzFw@mail.gmail.com>
References: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
	<CAM_vju=qnDsa3E0L77da84+VMG=5i_7VCDc82g6vS26TjPJzFw@mail.gmail.com>
Message-ID: <a9f8e598-2099-5a9e-4e10-8cf13eae164a@atsu.edu>

On 9/1/2016 9:44 AM, Sarah Goslee wrote:
> On Wed, Aug 31, 2016 at 4:25 PM, Tom Mosca <tom at vims.edu> wrote:
>> Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?
>>
>> Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.
>>
>
> There's an official FAQ for Mac, just as there is for Windows.
> https://cran.r-project.org/faqs.html
> There's also a Mac-specific email help list.
> https://www.r-project.org/mail.html
>
> Most R code will run as well or better on Mac. All of the OS problems
> I've run into tend to be problems with Windows. It's a bit harder to
> get some geospatial stuff working on Mac, but that's unlikely to be a
> problem with your elementary stats students.
Sarah has pointed you at some Mac support, but some additional advice as 
to the student audience.   [I live in a Windows world most of the time 
and a Ubuntu world the rest of the time, so I have minimal knowledg of 
OSX].    Having students install RStudio has really helped because it 
brings cross-platform commonality here and there.

The biggest problems I've run into with beginning statistics students 
are the issues related to getting them connected to our network and/or 
reading in textbook datasets located on that network.  Differences in 
handling of line endings on text files. However, if you do ground work 
to show them how to do some basic basic things early, they can support 
themselves with these things. The commands will work the same

For text files I often have (Windows) students copy data to the 
clipboard and use a command like  x <- read.table(file = 'clipboard', 
sep = '\t', header = TRUE)  so we can work through some statistical 
tests or graphing.   This won't work on a Mac.  An equivalent 
formulation that is helpful on the Mac is x <- read.table(file = 
pipe('pbpaste'), sep = '\t', header = TRUE)

Other than that, I think you'll find R extremely OS agnostic in a 
teaching environment.

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From bretschr at xs4all.nl  Thu Sep  1 17:34:51 2016
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Thu, 1 Sep 2016 17:34:51 +0200
Subject: [R] Same code on Mac?
In-Reply-To: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
References: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
Message-ID: <B5AB0D95-98CE-490F-9782-AD34F9DBFD38@xs4all.nl>

Dear Tom Mosca,

Re:

> Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?
> 
> 
> 
> Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.
> 


Some commands are platform-dependent though, such as opening the standard graphics window [quartz() vs windows()].
This needn't be a problem, since in R a script can sense on which platform it is running.
Some years ago I wrote a platform-sensing graphics routine, reproduced below.
This might help to prevent problems with simple graphics demos, and can no doubt be extended to other commands.

Success, and
Best regards,


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl




#  function PIgraph.r
#  Platform-Independent graphics init
#  determines platform (Windows or Mac) then chooses device type
#  F. Bretschneider; 04-08-2009
#  ====================

PIgraph <- function(w,h) if(.Platform$OS.type == "windows") windows(w=w, h=h) else quartz(w=w, h=h)

#  example application
x=-3:3
y=x^2
PIgraph(8,6)
plot(x,y, type = 'o')


From sarah.goslee at gmail.com  Thu Sep  1 17:50:52 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 1 Sep 2016 11:50:52 -0400
Subject: [R] Same code on Mac?
In-Reply-To: <B5AB0D95-98CE-490F-9782-AD34F9DBFD38@xs4all.nl>
References: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
	<B5AB0D95-98CE-490F-9782-AD34F9DBFD38@xs4all.nl>
Message-ID: <CAM_vju=z1tzUz537d6zzgVP8cGr=z_c2E982RD_+sLsiXZc9Gw@mail.gmail.com>

R already contains platform-independent code to open a graphics
device: dev.new()
The device thus created is specified in options(), but by default is
appropriate for the current platform.

It's good practice to use this function instead of calling quartz()
directly so that your code can be run on other systems.

Sarah

On Thu, Sep 1, 2016 at 11:34 AM, Franklin Bretschneider
<bretschr at xs4all.nl> wrote:
> Dear Tom Mosca,
>
> Re:
>
>> Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?
>>
>>
>>
>> Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.
>>
>
>
> Some commands are platform-dependent though, such as opening the standard graphics window [quartz() vs windows()].
> This needn't be a problem, since in R a script can sense on which platform it is running.
> Some years ago I wrote a platform-sensing graphics routine, reproduced below.
> This might help to prevent problems with simple graphics demos, and can no doubt be extended to other commands.
>
> Success, and
> Best regards,
>
>
> Franklin Bretschneider
> Dept of Biology
> Utrecht University
> bretschr at xs4all.nl
>
>
>
>
> #  function PIgraph.r
> #  Platform-Independent graphics init
> #  determines platform (Windows or Mac) then chooses device type
> #  F. Bretschneider; 04-08-2009
> #  ====================
>
> PIgraph <- function(w,h) if(.Platform$OS.type == "windows") windows(w=w, h=h) else quartz(w=w, h=h)
>
> #  example application
> x=-3:3
> y=x^2
> PIgraph(8,6)
> plot(x,y, type = 'o')
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From Kristina.Loderer at psy.lmu.de  Thu Sep  1 18:52:16 2016
From: Kristina.Loderer at psy.lmu.de (Kristina Loderer)
Date: Thu, 01 Sep 2016 18:52:16 +0200
Subject: [R] robumeta package - error
Message-ID: <57C878E0020000D900041FBD@f11-gwia-1.fak11.uni-muenchen.de>

Dear all,

I am trying to fit a simple (intercept-only) meta-analytic model using
the robumeta package using the following code: 
 anx_cont_mean<-robu(formula = es_fisher ~ 1, var.eff.size =
variance_fisher, studynum = study_ID, modelweights = "CORR", rho = 0.8,
small=TRUE, data = anxiety_control)

When I try to run this model, the following error message pops up: 
Error in solve.default(sumXWX) : 
  system is computationally singular: reciprocal condition number = 0

What exactly does this mean in the context of meta-analysis? I haven't
been able to find any answers.

Thank you,
Kristina


-----------------------------------------
Kristina Loderer
Ludwig-Maximilians-Universit?t M?nchen
Department Psychologie
Leopoldstr. 13
D-80802 M?nchen

Telefon: +49 (89) 2180-6047
Email: Kristina.Loderer at psy.lmu.de

-----------------------------------------


From tud53239 at temple.edu  Thu Sep  1 21:00:52 2016
From: tud53239 at temple.edu (Lauren N. Spirko)
Date: Thu, 1 Sep 2016 15:00:52 -0400
Subject: [R] Extract baseline from prop.odds function in timereg package
Message-ID: <CAELDw+0B+k5a0SPPQNT8SaJbo7AEntHJ4TM10J31iVHCZW9S=A@mail.gmail.com>

Hi everyone!

I am using the prop.odds() function in the timereg package.  I am trying to
extract the estimated baseline value, G(t), described in the package
documentation.

Does anyone know how this baseline value can be extracted from the output?

Thanks in advance for your help!

Lauren

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Sep  1 22:37:28 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 1 Sep 2016 15:37:28 -0500
Subject: [R] Improving function that estimates regressions for all
 variables specified
In-Reply-To: <CALdB+JH6QBnjP6jLgcVM7YhBHiAbkBh=E_+3sqY=TWqKPTuvew@mail.gmail.com>
References: <CALdB+JH6QBnjP6jLgcVM7YhBHiAbkBh=E_+3sqY=TWqKPTuvew@mail.gmail.com>
Message-ID: <CAN5YmCE=bmNgVY4DE1UNbT7w5BAG6FUFs-CLP4uhMsLjBX-pew@mail.gmail.com>

You may be able find someone else's function that already does you want.
For example the dredge() function of the MuMIn package.

http://rpackages.ianhowson.com/cran/MuMIn/man/MuMIn-package.html

Jean

On Fri, Aug 26, 2016 at 1:11 PM, Jorge Cimentada <cimentadaj at gmail.com>
wrote:

> Hi, I'd like some feedback on how to make this function more "quicker and
> parsimonious".
>
> I normally run several regressions like this:
> y ~ x1
> y ~ x1 + x2
> y ~ x1 + x2 +xn
>
> Instead, I created a function in which I specify y, x1 and x2 and the
> function automatically generates:
> y ~ x1
> y ~ x1 + x2
> y ~ x1 + x2 +xn
>
> This is the function:
>
> models <- function(dv, covariates, data) {
>     dv <- paste(dv, "~ 1")
>     combinations <- lapply(1:length(covariates), function(i) seq(1:i))
>     formulas <- lapply(combinations, function(p) x <-
> as.formula(paste(c(dv, covariates[p]), collapse=" + ")))
>     results <- lapply(formulas, function(o) lm(o, data=data))
>     return(results)
> }
>
> And an example:
> models("mpg",c("cyl","disp","hp","am"), mtcars)
>
> I'm concerned about the time that it takes when using other regression
> models, such as those with the survey package(I know these models are heavy
> and take time) but I'm sure that the function has room for improvement.
>
> I'd also like to specify the variables as a formula. I managed to do it but
> I get different results when using things like scale() for predictors.
>
> Formula version of the function:
> models2 <- function(formula, data) {
>     dv <- paste(all.vars(formula)[1], " ~ 1")
>     covariates <- all.vars(formula)[-1]
>     combinations <- lapply(1:length(covariates), function(i) seq(1:i))
>     lfo <- lapply(combinations, function(p) x <- as.formula(paste(c(dv,
> covariates[p]), collapse=" + ")))
>     results <- lapply(lfo, function(o) lm(o, data=data))
>     return(results)
> }
>
> models("mpg",c("cyl","scale(disp)"), mtcars)
>
> models2(mpg ~ cyl + scale(disp), mtcars)
>
> See the difference between the disp variables?
>
> Any feedback is appreciated!
>
>
> *Jorge Cimentada*
> *Ph.D. Candidate*
> Dpt. Ci?ncies Pol?tiques i Socials
> Ramon Trias Fargas, 25-27 | 08005 Barcelona
>
> Office 24.331
> [Tel.] 697 382 009www.jorgecimentada.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Sep  1 22:41:37 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 1 Sep 2016 15:41:37 -0500
Subject: [R] Adding multiple polygons to a Leaflet map
In-Reply-To: <CAOoXFWOhoeFSh_pSJEJbjVbqYKkzh2+YkCeFsjEEc_49cSU4AA@mail.gmail.com>
References: <CAOoXFWOhoeFSh_pSJEJbjVbqYKkzh2+YkCeFsjEEc_49cSU4AA@mail.gmail.com>
Message-ID: <CAN5YmCEDKZo2KFtmw-xA40zupRyKDPGeiJti3LK+pJ9Gdq_mEQ@mail.gmail.com>

It is hard to troubleshoot without the data.  Can you provide the data, for
example using the dput() function, or can you replicate the issue with some
simplified version of code that we can run?

Jean

On Tue, Aug 30, 2016 at 11:26 AM, Kevin Haynes <khaynes17 at gmail.com> wrote:

> Hi everyone - I'd like to add multiple polygons to a leaflet map. I don't
> get any errors when running this code, but it'll only display the second
> choro layer - the citizenship rate one. Here's my code below. Any thoughts?
> Here's the map right now:http://rpubs.com/khaynes17/205217
>   #map
>
>   la_trad_school_perf_map_layers <- leaflet(lac_schools) %>%
>     addProviderTiles("CartoDB.Positron") %>%
>     setView(-118.4, 34.05, zoom = 9) %>%
>     addCircleMarkers(
>       radius = 3,
>       color = ~pal(metandabove_mth),
>       stroke= FALSE, fillOpacity = 0.5,
>       group="14-15 Proficiency Rates - Math"
>     ) %>%
>     addPolygons(data = income_merged,
>       fillColor = ~pal_income(MedianIncome_2014),
>       color = "#b2aeae",
>       fillOpacity = 0.5,
>       weight = 1,
>       smoothFactor = 0.2,
>       popup = popup_income,
>       group="Median Income - 2014")%>%
>     addPolygons(data = cit_merged,
>       fillColor = ~pal_cit(non_citizenship_rate),
>       color = "#b2aeae",
>       fillOpacity = 0.5,
>       weight = 1,
>       smoothFactor = 0.2,
>       popup = popup_cit,
>       group="Non-U.S. Citizen - 2014")%>%
>    addLayersControl(
>      baseGroups=c("Median Income - 2014", "Non-U.S. Citizen - 2014"),
>      overlayGroups=c("14-15 Proficiency Rates - Math"),
>      options = layersControlOptions(collapsed = FALSE)
>    )
>   la_trad_school_perf_map_layers
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Fri Sep  2 00:30:40 2016
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Thu, 1 Sep 2016 15:30:40 -0700
Subject: [R] Need advice on linear programming in R
In-Reply-To: <trinity-0c2c0308-7dab-4004-8a61-dfb991933916-1472722392385@3capp-gmx-bs02>
References: <CACdH2ZYhVh_4xNyEbjwq_9QDJnyOW07v_=ZZ+E_hhdLbU7ZzKQ@mail.gmail.com>
	<trinity-0c2c0308-7dab-4004-8a61-dfb991933916-1472722392385@3capp-gmx-bs02>
Message-ID: <CACdH2Za3vWhW78iUMja20xsNweRjGmROZD3XEj55oUzTfxuByQ@mail.gmail.com>

Thanks, Florian.  That looks very useful.

-- Mike

On Thu, Sep 1, 2016 at 2:33 AM, Florian Schwendinger
<FlorianSchwendinger at gmx.at> wrote:
> You could try ROI
> <https://cran.r-project.org/web/packages/ROI/index.html>
> you write the model once and can use several solver, therefore
> you could just try which solver performs best (uses a low amount of
> memory) for your given problem.
>
> solver overview:
> <http://roi.r-forge.r-project.org/jekyll/update/2016/06/17/new_roi_version.html>
>
> simple LP example:
> <http://roi.r-forge.r-project.org/examples/lp.html>
>
> Best,
> Florian
>
> Gesendet: Donnerstag, 01. September 2016 um 05:34 Uhr
> Von: "Michael Hannon" <jmhannon.ucdavis at gmail.com>
> An: "R help" <r-help at r-project.org>
> Betreff: [R] Need advice on linear programming in R
> Greetings. A subset of a problem that the group I work with turns out to be
> an optimization problem, in the sense of linear programming.
>
> We've looked at several approaches to this but haven't found one that seems
> to
> be the right fit. I'm looking for some guidance in finding an R package that
> does what we want in an acceptable time.
>
> Here's a toy example. We start with a matrix, called "gMat1" (historical
> reasons):
>
>> gMat1 <- matrix(c(3, 6, 9, 5, 9, 5), nrow=3)
>> print(gMat1)
> [,1] [,2]
> [1,] 3 5
> [2,] 6 9
> [3,] 9 5
>
> The goal is to add the contents of one column of each row to one of two bins
> (in general the number of bins equals the number of columns) such that the
> minimum number in each bin is maximized. An example follows.
>
> In the toy example, the possibilities can be enumerated simply:
>
>> allChoices <- expand.grid(rep(list(1:ncol(gMat1)), nrow(gMat1)))
>> print(allChoices)
> Var1 Var2 Var3
> 1 1 1 1
> 2 2 1 1
> 3 1 2 1
> 4 2 2 1
> 5 1 1 2
> 6 2 1 2
> 7 1 2 2
> 8 2 2 2
>
> For example, with the first choice, (1, 1, 1), column 1, hence, bin 1, is
> selected for all three rows, giving a result for the two bins of:
>
> 18 0
>
> For the second choice, (2, 1, 1), the '2' in the first position selects the
> contents of column 2 for bin 2. The remaining (1, 1) select the (6, 9) in
> the
> first column and assign those to bin 1:
>
> 15 5
>
> The result is a set of "binSums" corresponding to the each of the set of
> possible choices:
>
>> print(binSums)
> [,1] [,2]
> [1,] 18 0
> [2,] 15 5
> [3,] 12 9
> [4,] 9 14
> [5,] 9 5
> [6,] 6 10
> [7,] 3 14
> [8,] 0 19
>
> Having generated the sums, the goal is to pick the row that has the largest
> minimum and map that back to the original choice. In the toy example, both
> rows 3 and 4 satisfy that criterion ('9' is the minimum in each, and '9' is
> bigger than the minima in the other 6 rows -- 0, 3, 5, 6).
>
> In the real case there are potentially thousands of rows and columns, so
> eye-balling is not an option. And, in fact, using "expand.grid" isn't even
> an
> option to generate the original choices.
>
> We've tried some ad hoc approaches that seem to work tolerably well. Here's
> one that we *might* have considered, if we *could* have generated the
> "allChoices/binSums":
>
>> bsVar <- apply(binSums, 1, var)
>> locBestVar <- which(bsVar == min(bsVar))
>> allChoices[locBestVar, ]
> Var1 Var2 Var3
> 3 1 2 1
>
> But there was a feeling within the group that we didn't have a solid-enough
> foundation using the ad hoc approaches. Hence, we asked for help from an
> expert in Operations Research. He was able to solve a problem of realistic
> size in more or less no time at all using the "GAMS" software:
>
> https://www.gams.com/
>
> Unfortunately, GAMS is not free software, and we are hoping to produce an R
> package that is freely distributable. The next suggestion was to use Gurobi:
>
> http://www.gurobi.com/
>
> which is evidently free for academic use but not otherwise. Better, but
> still
> not perfect. (And I couldn't use the free version of Gurobi while working
> from home, as it didn't consider my home network to be associated with an
> academic institution -- which of course it isn't).
>
> Finally, we tried:
>
> Rglpk_solve_LP
>
> from the R package "Rglpk":
>
> https://cran.r-project.org/web/packages/Rglpk/index.html
>
> This satisfied the licensing constraints, but we were unable to produce a
> result in a "finite" amount of time. By this I mean that we ran the Rglpk
> software on a problem with 200 rows and 20 columns on the latest Mac Pro
> with
> 64GB of memory, and it didn't finish overnight. A realistic problem would
> have at least 10000 rows and 50 columns. (This admittedly might simply have
> been a consequence of our unfamiliarity with the package. Suggestions
> welcome.) To be clear, this process is not something we'd be doing once in
> order to build the package. This is something an end user would have to do
> every time he/she ran our package.
>
> If you've managed to read this far and have any suggestions as to how we
> might
> proceed, please send them my way. Thanks.
>
> -- Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Fri Sep  2 00:38:42 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Sep 2016 08:38:42 +1000
Subject: [R] Same code on Mac?
In-Reply-To: <CAM_vju=z1tzUz537d6zzgVP8cGr=z_c2E982RD_+sLsiXZc9Gw@mail.gmail.com>
References: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>
	<B5AB0D95-98CE-490F-9782-AD34F9DBFD38@xs4all.nl>
	<CAM_vju=z1tzUz537d6zzgVP8cGr=z_c2E982RD_+sLsiXZc9Gw@mail.gmail.com>
Message-ID: <CA+8X3fV5TXGi-eLDVNcxx6Fu9GkJ5ivJ0TfdyCsOQX=qsmB_vw@mail.gmail.com>

Sometimes the problem stems from chronic exposure to user interfaces.
Yesterday I prepared some material for a Mac user's presentation and
said,

"This text file tells you the names of the files you need for the presentation"

the response was,

"Can I click on it?"

I deleted all the files in the directory apart from the necessary ones
and crossed my fingers.

Jim


On Fri, Sep 2, 2016 at 1:50 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> R already contains platform-independent code to open a graphics
> device: dev.new()
> The device thus created is specified in options(), but by default is
> appropriate for the current platform.
>
> It's good practice to use this function instead of calling quartz()
> directly so that your code can be run on other systems.
>
> Sarah
>
> On Thu, Sep 1, 2016 at 11:34 AM, Franklin Bretschneider
> <bretschr at xs4all.nl> wrote:
>> Dear Tom Mosca,
>>
>> Re:
>>
>>> Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?
>>>
>>>
>>>
>>> Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.
>>>
>>
>>
>> Some commands are platform-dependent though, such as opening the standard graphics window [quartz() vs windows()].
>> This needn't be a problem, since in R a script can sense on which platform it is running.
>> Some years ago I wrote a platform-sensing graphics routine, reproduced below.
>> This might help to prevent problems with simple graphics demos, and can no doubt be extended to other commands.
>>
>> Success, and
>> Best regards,
>>
>>
>> Franklin Bretschneider
>> Dept of Biology
>> Utrecht University
>> bretschr at xs4all.nl
>>
>>
>>
>>
>> #  function PIgraph.r
>> #  Platform-Independent graphics init
>> #  determines platform (Windows or Mac) then chooses device type
>> #  F. Bretschneider; 04-08-2009
>> #  ====================
>>
>> PIgraph <- function(w,h) if(.Platform$OS.type == "windows") windows(w=w, h=h) else quartz(w=w, h=h)
>>
>> #  example application
>> x=-3:3
>> y=x^2
>> PIgraph(8,6)
>> plot(x,y, type = 'o')
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Fri Sep  2 04:33:50 2016
From: hannah.hlx at gmail.com (li li)
Date: Thu, 1 Sep 2016 22:33:50 -0400
Subject: [R] plot with different symbols and colors according to the
 factor levels
In-Reply-To: <BY2PR16MB0197E73E71DABB12F078B726F7E00@BY2PR16MB0197.namprd16.prod.outlook.com>
References: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>
	<alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
	<BY2PR16MB0197E73E71DABB12F078B726F7E00@BY2PR16MB0197.namprd16.prod.outlook.com>
Message-ID: <CAHLnndapH++ZjHCerSmdv1y_1d4ytLV6f3V2uRBRG2pMLhnLfg@mail.gmail.com>

Thank you all.
   Hanna

2016-08-30 16:55 GMT-04:00 Paulo Moniz <pmoniz7 at hotmail.com>:

> Obter o Outlook para Android <https://aka.ms/ghei36>
>
>
>
> On Tue, Aug 30, 2016 at 2:41 PM -0300, "Clint Bowman" <clint at ecy.wa.gov>
> wrote:
>
> Hanna,
>
> lili<-read.table("lili.txt",header=T)  # don't forget to label the row
> number if it's in your data
>
> with(lili,plot(y,conc,pch=sample,col=sample))
>
> Clint
>
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>          USPS:           PO Box 47600, Olympia, WA 98504-7600
>          Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Tue, 30 Aug 2016, li li wrote:
>
> > Hi all,
> > I have the following data. I want to plot the data (y ~ conc)
> > with different symbols and colors corresponding to different levels of
> the
> > factor sample.
> > I could create a column with color and pch and then do the plot, but I am
> > sure there are much better ways.
> > Can anyone make suggestions?
> >  Hanna
> >
> >
> >
> >   y         conc sample
> > 1  33 20.000000000      1
> > 2  33  5.000000000      1
> > 3  35  1.250000000      1
> > 4  43  0.312500000      1
> > 5  58  0.078125000      1
> > 6  54  0.019531250      1
> > 7  57  0.004882812      1
> > 8  57  0.001220703      1
> > 9  32 20.000000000      1
> > 10 32  5.000000000      1
> > 11 34  1.250000000      1
> > 12 52  0.312500000      1
> > 13 57  0.078125000      1
> > 14 58  0.019531250      1
> > 15 59  0.004882812      1
> > 16 50  0.001220703      1
> > 17 34 20.000000000      2
> > 18 34  5.000000000      2
> > 19 38  1.250000000      2
> > 20 53  0.312500000      2
> > 21 57  0.078125000      2
> > 22 57  0.019531250      2
> > 23 57  0.004882812      2
> > 24 52  0.001220703      2
> > 25 34 20.000000000      2
> > 26 33  5.000000000      2
> > 27 36  1.250000000      2
> > 28 48  0.312500000      2
> > 29 58  0.078125000      2
> > 30 57  0.019531250      2
> > 31 58  0.004882812      2
> > 32 53  0.001220703      2
> > 33 34 20.000000000      2
> > 34 35  5.000000000      2
> > 35 37  1.250000000      2
> > 36 49  0.312500000      2
> > 37 55  0.078125000      2
> > 38 59  0.019531250      2
> > 39 57  0.004882812      2
> > 40 54  0.001220703      2
> > 41 36 20.000000000      3
> > 42 33  5.000000000      3
> > 43 36  1.250000000      3
> > 44 51  0.312500000      3
> > 45 57  0.078125000      3
> > 46 57  0.019531250      3
> > 47 59  0.004882812      3
> > 48 56  0.001220703      3
> > 49 33 20.000000000      3
> > 50 32  5.000000000      3
> > 51 35  1.250000000      3
> > 52 47  0.312500000      3
> > 53 57  0.078125000      3
> > 54 56  0.019531250      3
> > 55 57  0.004882812      3
> > 56 53  0.001220703      3
> > 57 33 20.000000000      3
> > 58 34  5.000000000      3
> > 59 38  1.250000000      3
> > 60 52  0.312500000      3
> > 61 56  0.078125000      3
> > 62 61  0.019531250      3
> > 63 56  0.004882812      3
> > 64 55  0.001220703      3
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Fri Sep  2 04:41:49 2016
From: hannah.hlx at gmail.com (li li)
Date: Thu, 1 Sep 2016 22:41:49 -0400
Subject: [R] plot.drm in "drc" package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503AD93@SRVEXCHMBX.precheza.cz>
References: <CAHLnndYX_6JS4k3kBC-M+dqN_qkDH1-k3wJUmggqVR3Huf3+YQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503AD93@SRVEXCHMBX.precheza.cz>
Message-ID: <CAHLnndZYrqeHohkqPwmsK66VYii+EEec6Q1GW_ucYO24nsPxVg@mail.gmail.com>

Thanks Petr for the reply.
When I run "plot(mod, type="all",log="x")", the tickmarks of the x axix
include (0.02, 0.1, 1,10).
But the log(Dose) should be less than 4.
Anyway, I think there is something missing in the plot.drm function.

   Hanna

2016-08-31 7:41 GMT-04:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> Thanks for code.
> see in line
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of li li
> > Sent: Tuesday, August 30, 2016 5:07 PM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] plot.drm in "drc" package
> >
> > Hi all,
> >   I am trying to use the drc package to fit 4L curve.
> > I am so confused about the plot.drm function in the drc package.
> > Particularly, I am confused about the scale of the xaxis in the plots
> generated
> > using the plot.drm function. See the example below:
> >
> > ## generate data and fit the model
> > dose <- rep(50*2^(-(0:11)),3)
> > dose
> > d <- 100
> > c <- 1
> > b <- 1
> > e <- 1.6
> > y <- rnorm(length(dose))+ c+ (d-c)/(1+exp(b*(log(dose)-log(e))))
> > library(drc)
> > mod <- drm(y~dose, fct = LL.4())
> > summary(mod)
> >
> > Now I plot the data and the fitted curve with the plot.drm using the code
> > below and get the figure 1 below.
> >
> >
> > ##obtaining figure 1
> > plot(mod, type="all",log="x")
> >
> >
> > Next I plot the raw data and add the curve by extracting the estimate of
> the
> > parameters.
> >
> > ##extract parameters
> > para <- mod$fit$par
> > bhat<- para[1]
> > chat <- para[2]
> > dhat <- para[3]
> > ehat <- para[4]
> >
> > ##plot figure 2
> > plot(log(dose),y)
> > points(log(50*2^(-(0:11))),  chat +
> > (dhat-chat)/(1+exp(bhat*(log(50*2^(-(0:11)))-log(ehat)))), type="l")
> >
> > My question is regarding the figure 1 generated by the plot.drm.
> > The x axis is the not the log scale of the doses. I checked the package
> manual,
>                                              ^^^^^^^^^^^
> Well I am either missing something obvios but when I tried
>
> plot(mod, type="all",log="x")
>
> I got x axis with log scaling. Actually the result is the same as
>
> plot(mod, type="all")
>
> If you want x axis to be in original range you need to put empty string
>
> plot(mod, type="all",log="")
>
> Cheers
> Petr
>
> > it says the default is log base 10. But it is not true in this case.
> > Does some have some insight on the correct usage of the plot.drm
> function.
> >
> > Thanks much in advance.
> >   Hanna
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From hagyropoylos_21 at yahoo.gr  Thu Sep  1 22:54:45 2016
From: hagyropoylos_21 at yahoo.gr (Harris Agiropoulos)
Date: Thu, 1 Sep 2016 23:54:45 +0300
Subject: [R] : Extra loops in order to fill in a 3D table
In-Reply-To: <CAN5YmCEDKZo2KFtmw-xA40zupRyKDPGeiJti3LK+pJ9Gdq_mEQ@mail.gmail.com>
References: <CAOoXFWOhoeFSh_pSJEJbjVbqYKkzh2+YkCeFsjEEc_49cSU4AA@mail.gmail.com>
	<CAN5YmCEDKZo2KFtmw-xA40zupRyKDPGeiJti3LK+pJ9Gdq_mEQ@mail.gmail.com>
Message-ID: <3015F93F-74AE-4045-970B-E0B364929984@yahoo.gr>

Hello all,

I would like to have two or maybe three extra ?for?. One for changing beta_x with values 0.00 and 0.20 and the others for changing phi_x and phi_y with values 0.00, 0.30, 0.90.
Does anyone know how to implement this?

library(MASS)
library(forecast) 
library(lmtest)
library("dyn")
library(nlme)
mysummary <- function(betax,npar=TRUE,print=TRUE) {
  options(scipen=999)
  set.seed(1234)
  par(mfrow=c(1,2))
  rep<-10
  n<-100
  sigma<-1
  mx<-0.8
  my<-0.8
  theta_y<-2
  theta_x<-2
  beta_x<-0.00
  beta_y<-betax
  phi_x<-0.00
  phi_y<-0.00
  break1<-n/2
  break2<-n/2
  break3<-n/5
  break4<-n/5
  vhta<-c(NA,rep)
  alpha<-c(NA,rep)
  da.wa<-c(NA,rep)
  tau0<-c(NA,rep)
  tau<-c(NA,rep)
  p_val<-c(NA,rep)
  vhta2<-c(NA,rep)
  tau2<-c(NA,rep)
  tau3<-c(NA,rep)
  tau4<-c(NA,rep)
  tau5<-c(NA,rep)
  tau6<-c(NA,rep)
  p_val2<-c(NA,rep)
  time<-c(1:n)
  for (i in 1:rep)
  {
    t <- c(1:n) # specifying the time
    dummy <- as.numeric(ifelse(t <= break1, 0, 1)) # specifying the dummy for trend break at T = 40
    dummy2 <- as.numeric(ifelse(t <= break2, 0, 1)) # specifying the dummy for trend break at T = 80
    dummy3 <- as.numeric(ifelse(t <= break3, 0, 1)) # specifying the dummy for trend break at T = 20
    dummy4 <- as.numeric(ifelse(t <= break4, 0, 1)) # specifying the dummy for trend break at T = 70
    z<-w<-rnorm(n,sd=sigma)
    for (t in 2:n) z[t]<-phi_y*z[t-1]+w[t]
    Time<-1:n
    ar1_1 <- ts(my + beta_y*Time - theta_y*dummy + z) #- theta_y*(Time-dummy2)*dummy2 + z) # This is the trend stationary model with break in trend
    y <- ts(my + beta_y*Time - theta_y*dummy) #- theta_y*(Time-dummy2)*dummy2) # This is just the trend line that we see in "red" in the plot below
    plot(ar1_1, main = "Simulated series with breaks at T = 40,80")
    lines(y, col = "red") ## Plotting a sample of the model that we have simulated
    ## Now we will simulate the sample data above 1000 times and check for unit roots for each of these samples ##
    g<-s<-rnorm(n,sd=sigma)
    for (t in 2:n) g[t]<-phi_x*g[t-1]+s[t]
    Time<-1:n
    ar1_2 <- ts(mx + beta_x*Time - theta_x*dummy3 +g) #- theta_x*(Time-dummy4)*dummy4 + g) # This is the trend stationary model with break in trend
    x <- ts(mx + beta_x*Time - theta_x*dummy3) #- theta_x*(Time-dummy4)*dummy4) # This is just the trend line that we see in "red" in the plot below
    plot(ar1_2, main = "Simulated series with breaks at T = 20,70")
    lines(x, col = "red") # Plotting a sample of the model that we have simulated
    lmold.r<-lm(ar1_1 ~ ar1_2)
    lm.r<-lm(ar1_1 ~ Time + ar1_2)
    Data<-data.frame(ar1_1, ar1_2, Time)
    fglm.r<-gls(ar1_1 ~ Time + ar1_2, Data, corAR1(0.9,form = ~ 1,TRUE))
    fglm2.r<-gls(ar1_1 ~ Time + ar1_2, Data, corAR1(0.5,form = ~ 1,TRUE))
    fglm3.r<-gls(ar1_1 ~ Time + ar1_2, Data, corAR1(0.3,form = ~ 1,TRUE))
    fglm4.r<-gls(ar1_1 ~ Time + ar1_2, Data, corAR1())
    fglm5.r<-gls(ar1_1 ~ Time + ar1_2, Data, weights = varIdent(form =~ 1))
    tau0[i]<-coef(summary(lmold.r))["ar1_2","t value"] #simple linear regression 
    tau[i]<-coef(summary(lm.r))["ar1_2","t value"] #simple linear regression with trend
    tau2[i]<-summary(fglm.r)$tTable["ar1_2","t-value"] #GLS with rho = 0.9
    tau3[i]<-summary(fglm2.r)$tTable["ar1_2","t-value"] #GLS with rho = 0.5
    tau4[i]<-summary(fglm3.r)$tTable["ar1_2","t-value"] #GLS with rho = 0.3
    tau5[i]<-summary(fglm4.r)$tTable["ar1_2","t-value"] #GLS with rho_hut
    tau6[i]<-summary(fglm5.r)$tTable["ar1_2","t-value"] #GLS with variance power
  }
  tau0
  tau
  tau2
  tau3
  tau4
  tau5
  tau6
  ti0<-sum(abs(tau0) > 1.96)
  ti<-sum(abs(tau) > 1.96)
  ti2<-sum(abs(tau2) > 1.96)
  ti3<-sum(abs(tau3) > 1.96)
  ti4<-sum(abs(tau4) > 1.96)
  ti5<-sum(abs(tau5) > 1.96)
  ti6<-sum(abs(tau6) > 1.96)
  results<-cbind(c(t0=ti0,t=ti,t5=ti5,t4=ti4,t3=ti3,t2=ti2,t6=ti6))
  results
  
}

betax<-c(0.00,0.20)
x<-sapply(betax,mysummary)
x


	[[alternative HTML version deleted]]


From littleho_song at yahoo.com  Thu Sep  1 21:47:27 2016
From: littleho_song at yahoo.com (Yucheng Song)
Date: Thu, 1 Sep 2016 19:47:27 +0000 (UTC)
Subject: [R] readBin documentation error
References: <257667955.71463.1472759247865.ref@mail.yahoo.com>
Message-ID: <257667955.71463.1472759247865@mail.yahoo.com>

Hi, ?In the help or readBin, there is an "int", but actually there is no int(), do you mean some other types? ?In fact, numeric() is kind of misleading, what does it mean?
what Either an object whose mode will give the mode of the vector to be read, or a character vector of length one describing the mode: one of "numeric", "double", "integer", "int", "logical", "complex", "character", "raw".
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep  2 10:10:01 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 2 Sep 2016 08:10:01 +0000
Subject: [R] plot.drm in "drc" package
In-Reply-To: <CAHLnndZYrqeHohkqPwmsK66VYii+EEec6Q1GW_ucYO24nsPxVg@mail.gmail.com>
References: <CAHLnndYX_6JS4k3kBC-M+dqN_qkDH1-k3wJUmggqVR3Huf3+YQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503AD93@SRVEXCHMBX.precheza.cz>
	<CAHLnndZYrqeHohkqPwmsK66VYii+EEec6Q1GW_ucYO24nsPxVg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B246@SRVEXCHMBX.precheza.cz>

Hi

I do not consider myself as an expert in drc.

AFAIK in drc plotting you plot response against actual dose.

You have 3 options
Plot dose values in non log axis
plot(mod, type="all", log="")

Plot dose values in log axis
plot(mod, type="all", log="x")

or plot log(dose) values in non log axis
plot(log(dose),y)
which is not used in plot.drc

The fourth option
plot(log(dose),y, log="x")
discards dose values below zero from plot.

So my opinion is that plotting with dose is better option just because in log(dose) you get negative values and it is not easy to decipher what dose is -0.6931472.

Cheers
Petr



From: li li [mailto:hannah.hlx at gmail.com]
Sent: Friday, September 2, 2016 4:42 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] plot.drm in "drc" package

Thanks Petr for the reply.
When I run "plot(mod, type="all",log="x")", the tickmarks of the x axix include (0.02, 0.1, 1,10).
But the log(Dose) should be less than 4.
Anyway, I think there is something missing in the plot.drm function.

   Hanna

2016-08-31 7:41 GMT-04:00 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:
Hi

Thanks for code.
see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of li li
> Sent: Tuesday, August 30, 2016 5:07 PM
> To: r-help <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] plot.drm in "drc" package
>
> Hi all,
>   I am trying to use the drc package to fit 4L curve.
> I am so confused about the plot.drm function in the drc package.
> Particularly, I am confused about the scale of the xaxis in the plots generated
> using the plot.drm function. See the example below:
>
> ## generate data and fit the model
> dose <- rep(50*2^(-(0:11)),3)
> dose
> d <- 100
> c <- 1
> b <- 1
> e <- 1.6
> y <- rnorm(length(dose))+ c+ (d-c)/(1+exp(b*(log(dose)-log(e))))
> library(drc)
> mod <- drm(y~dose, fct = LL.4())
> summary(mod)
>
> Now I plot the data and the fitted curve with the plot.drm using the code
> below and get the figure 1 below.
>
>
> ##obtaining figure 1
> plot(mod, type="all",log="x")
>
>
> Next I plot the raw data and add the curve by extracting the estimate of the
> parameters.
>
> ##extract parameters
> para <- mod$fit$par
> bhat<- para[1]
> chat <- para[2]
> dhat <- para[3]
> ehat <- para[4]
>
> ##plot figure 2
> plot(log(dose),y)
> points(log(50*2^(-(0:11))),  chat +
> (dhat-chat)/(1+exp(bhat*(log(50*2^(-(0:11)))-log(ehat)))), type="l")
>
> My question is regarding the figure 1 generated by the plot.drm.
> The x axis is the not the log scale of the doses. I checked the package manual,
                                             ^^^^^^^^^^^
Well I am either missing something obvios but when I tried

plot(mod, type="all",log="x")

I got x axis with log scaling. Actually the result is the same as

plot(mod, type="all")

If you want x axis to be in original range you need to put empty string

plot(mod, type="all",log="")

Cheers
Petr

> it says the default is log base 10. But it is not true in this case.
> Does some have some insight on the correct usage of the plot.drm function.
>
> Thanks much in advance.
>   Hanna
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Sep  2 12:31:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Sep 2016 20:31:55 +1000
Subject: [R] readBin documentation error
In-Reply-To: <257667955.71463.1472759247865@mail.yahoo.com>
References: <257667955.71463.1472759247865.ref@mail.yahoo.com>
	<257667955.71463.1472759247865@mail.yahoo.com>
Message-ID: <CA+8X3fUHge56DPHy+S7swKFdxsQJQZPpWtAUntC4VLvzOYpGCw@mail.gmail.com>

Hi Yucheng,
Have a look at "An Introduction to R" (get there with "help.start()"), section :

3.1 Intrinsic attributes: mode and length

The distinction between numeric and integer modes in R may not be
obvious, but it is important at times.

Jim


On Fri, Sep 2, 2016 at 5:47 AM, Yucheng Song via R-help
<r-help at r-project.org> wrote:
> Hi,  In the help or readBin, there is an "int", but actually there is no int(), do you mean some other types?  In fact, numeric() is kind of misleading, what does it mean?
> what Either an object whose mode will give the mode of the vector to be read, or a character vector of length one describing the mode: one of "numeric", "double", "integer", "int", "logical", "complex", "character", "raw".
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Fri Sep  2 13:01:04 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 2 Sep 2016 12:01:04 +0100
Subject: [R] robumeta package - error
In-Reply-To: <57C878E0020000D900041FBD@f11-gwia-1.fak11.uni-muenchen.de>
References: <57C878E0020000D900041FBD@f11-gwia-1.fak11.uni-muenchen.de>
Message-ID: <e0c344bf-425f-ee71-892b-39305958d23e@dewey.myzen.co.uk>

Dear Kristina

I do not use that package so cannot offer any direct help but

1 - can you fit the model with any other combination of parameters?
2 - what happens if you vary rho?
3 - if your data-set is small and not confidential can you share it, 
otherwise can you show us str(anxiety_control) or 
summary(anxiety_control) preferable without any variables you are not 
using in this model?
4 - there is a robust option in Wolfgang Viechtbauer's metafor package 
which might help although I am not sure how equivalent the analysis 
approaches are.

On 01/09/2016 17:52, Kristina Loderer wrote:
> Dear all,
>
> I am trying to fit a simple (intercept-only) meta-analytic model using
> the robumeta package using the following code:
>  anx_cont_mean<-robu(formula = es_fisher ~ 1, var.eff.size =
> variance_fisher, studynum = study_ID, modelweights = "CORR", rho = 0.8,
> small=TRUE, data = anxiety_control)
>
> When I try to run this model, the following error message pops up:
> Error in solve.default(sumXWX) :
>   system is computationally singular: reciprocal condition number = 0
>
> What exactly does this mean in the context of meta-analysis? I haven't
> been able to find any answers.
>
> Thank you,
> Kristina
>
>
> -----------------------------------------
> Kristina Loderer
> Ludwig-Maximilians-Universit?t M?nchen
> Department Psychologie
> Leopoldstr. 13
> D-80802 M?nchen
>
> Telefon: +49 (89) 2180-6047
> Email: Kristina.Loderer at psy.lmu.de
>
> -----------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From govokai at gmail.com  Fri Sep  2 13:03:20 2016
From: govokai at gmail.com (Kai Mx)
Date: Fri, 2 Sep 2016 13:03:20 +0200
Subject: [R] workflow getting UTF-8 csv in and out of R on Mac (spreadsheet
	editor)
Message-ID: <CAHOWgNUFwak1tzxbuREr47LEQ1Mv_-h=5yT=JMXLaG7b0oC02A@mail.gmail.com>

Hi all,

I am hoping for some advice on how to handle UTF-8 spreadsheet files in a
Mac environment - sort of off-topic, but still relevant for hopefully a
bunch of people.

I am using R on Mac OS 10.10. Sometimes I have the urge to actually look at
a large spreadsheet on the big screen or make some changes to the tables.
Since most of my colleagues live in the M$ Excel - world I tend to use
Excel 2011 as well. However, Excel does not handle UTF-8 (which I like
because of different system locales).
So I actually do a write.csv with file-encoding in macroman, but even then
Excel won't just open it and I will have to work my way through the
import-dialogue.

The other way around, it's even worse. I save the spreadsheet as macroman,
iconv it to utf-8 and then read.csv it to R.

It works, but it's just really messy. Is there a (preferably light-weight)
csv-spreadsheet Editor for Mac OS that you use? Open-Office? I would like
NOT to actually buy another Excel version. However, for collaboration, a
xls-export would be phenomenal.

Thanks!

Kai

	[[alternative HTML version deleted]]


From erich.neuwirth at univie.ac.at  Fri Sep  2 13:10:12 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 2 Sep 2016 13:10:12 +0200
Subject: [R] workflow getting UTF-8 csv in and out of R on Mac
	(spreadsheet editor)
In-Reply-To: <CAHOWgNUFwak1tzxbuREr47LEQ1Mv_-h=5yT=JMXLaG7b0oC02A@mail.gmail.com>
References: <CAHOWgNUFwak1tzxbuREr47LEQ1Mv_-h=5yT=JMXLaG7b0oC02A@mail.gmail.com>
Message-ID: <5115CFE6-9CAC-4750-9BA8-04B635498863@univie.ac.at>

read_excel in Hadley?s readxl package
should handle your encoding problems.
Writing Excel files on a Mac, however, still is somewhat messy.

And you probably should post this kind of question on r-sig-mac



On 02 Sep 2016, at 13:03, Kai Mx <govokai at gmail.com> wrote:
> 
> Hi all,
> 
> I am hoping for some advice on how to handle UTF-8 spreadsheet files in a
> Mac environment - sort of off-topic, but still relevant for hopefully a
> bunch of people.
> 
> I am using R on Mac OS 10.10. Sometimes I have the urge to actually look at
> a large spreadsheet on the big screen or make some changes to the tables.
> Since most of my colleagues live in the M$ Excel - world I tend to use
> Excel 2011 as well. However, Excel does not handle UTF-8 (which I like
> because of different system locales).
> So I actually do a write.csv with file-encoding in macroman, but even then
> Excel won't just open it and I will have to work my way through the
> import-dialogue.
> 
> The other way around, it's even worse. I save the spreadsheet as macroman,
> iconv it to utf-8 and then read.csv it to R.
> 
> It works, but it's just really messy. Is there a (preferably light-weight)
> csv-spreadsheet Editor for Mac OS that you use? Open-Office? I would like
> NOT to actually buy another Excel version. However, for collaboration, a
> xls-export would be phenomenal.
> 
> Thanks!
> 
> Kai
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160902/4c6a9ca4/attachment.bin>

From jrkrideau at inbox.com  Fri Sep  2 16:10:24 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 2 Sep 2016 06:10:24 -0800
Subject: [R] Off topic,
 but hopefully not totally irrelevant: on MS  Excel and genomics
In-Reply-To: <CAGxFJbScOSM7Y_7TgWPwF2urqmBWmHErE8bHYvK-XJ27_FBrCw@mail.gmail.com>
Message-ID: <2F7D3DD6B64.0000056Bjrkrideau@inbox.com>

Over the last few years I came to the conclusion that using a spreadsheet for anything more complicated than my shopping list was madness.
 I am now reconsidering my position on shopping lists.

Thanks Bert. I have a small collection of spreadsheet errors that have been  published here and there and this is a great addition.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bgunter.4567 at gmail.com
> Sent: Thu, 1 Sep 2016 08:09:46 -0700
> To: r-help at r-project.org
> Subject: [R] Off topic, but hopefully not totally irrelevant: on MS Excel
> and genomics
> 
> http://www.sciencemag.org/news/sifter/one-five-genetics-papers-contains-errors-thanks-microsoft-excel
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Fri Sep  2 16:25:23 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 2 Sep 2016 06:25:23 -0800
Subject: [R] workflow getting UTF-8 csv in and out of R on Mac
 (spreadsheet editor)
In-Reply-To: <CAHOWgNUFwak1tzxbuREr47LEQ1Mv_-h=5yT=JMXLaG7b0oC02A@mail.gmail.com>
Message-ID: <2F9EBD7C922.00000598jrkrideau@inbox.com>

An alternative to Erich Neuwirth's solution might be to use Apache OpenOffice or the (roughly) equivalent LibreOffice. I routinely use UTF-8 with these.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: govokai at gmail.com
> Sent: Fri, 2 Sep 2016 13:03:20 +0200
> To: r-help at r-project.org
> Subject: [R] workflow getting UTF-8 csv in and out of R on Mac
> (spreadsheet editor)
> 
> Hi all,
> 
> I am hoping for some advice on how to handle UTF-8 spreadsheet files in a
> Mac environment - sort of off-topic, but still relevant for hopefully a
> bunch of people.
> 
> I am using R on Mac OS 10.10. Sometimes I have the urge to actually look
> at
> a large spreadsheet on the big screen or make some changes to the tables.
> Since most of my colleagues live in the M$ Excel - world I tend to use
> Excel 2011 as well. However, Excel does not handle UTF-8 (which I like
> because of different system locales).
> So I actually do a write.csv with file-encoding in macroman, but even
> then
> Excel won't just open it and I will have to work my way through the
> import-dialogue.
> 
> The other way around, it's even worse. I save the spreadsheet as
> macroman,
> iconv it to utf-8 and then read.csv it to R.
> 
> It works, but it's just really messy. Is there a (preferably
> light-weight)
> csv-spreadsheet Editor for Mac OS that you use? Open-Office? I would like
> NOT to actually buy another Excel version. However, for collaboration, a
> xls-export would be phenomenal.
> 
> Thanks!
> 
> Kai
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From john.archie.mckown at gmail.com  Fri Sep  2 16:26:22 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 2 Sep 2016 09:26:22 -0500
Subject: [R] Off topic,
 but hopefully not totally irrelevant: on MS Excel and genomics
In-Reply-To: <2F7D3DD6B64.0000056Bjrkrideau@inbox.com>
References: <CAGxFJbScOSM7Y_7TgWPwF2urqmBWmHErE8bHYvK-XJ27_FBrCw@mail.gmail.com>
	<2F7D3DD6B64.0000056Bjrkrideau@inbox.com>
Message-ID: <CAAJSdjgvm1n14Q_=7VJvsfB78TzrTYHyTjm_ou9f3bkDL-U_xQ@mail.gmail.com>

On Fri, Sep 2, 2016 at 9:10 AM, John Kane <jrkrideau at inbox.com> wrote:

> Over the last few years I came to the conclusion that using a spreadsheet
> for anything more complicated than my shopping list was madness.
>  I am now reconsidering my position on shopping lists.
>

?I got a real laugh out of that one! When used for the purpose of their
ancestors, they are an excellent tool. A screwdriver is an excellent tool.
But you can't use it alone to build a submarine.
https://www.cs.umd.edu/class/spring2002/cmsc434-0101/MUIseum/applications/spreadsheethistory1.html
?



>
> Thanks Bert. I have a small collection of spreadsheet errors that have
> been  published here and there and this is a great addition.
>
> John Kane
> Kingston ON Canada
>


-- 
Unix: Some say the learning curve is steep, but you only have to climb it
once. -- Karl Lehenbauer
Unicode: http://xkcd.com/1726/

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Sep  2 16:29:49 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 02 Sep 2016 14:29:49 +0000
Subject: [R] Off topic,
 but hopefully not totally irrelevant: on MS Excel and genomics
In-Reply-To: <2F7D3DD6B64.0000056Bjrkrideau@inbox.com>
References: <CAGxFJbScOSM7Y_7TgWPwF2urqmBWmHErE8bHYvK-XJ27_FBrCw@mail.gmail.com>
	<2F7D3DD6B64.0000056Bjrkrideau@inbox.com>
Message-ID: <CAAcGz9_p8zaCREz2GZ_CrFnu0-h1U7L3pKtDP18_BufA7h2ttg@mail.gmail.com>

On Sat, 3 Sep 2016 at 00:13 John Kane <jrkrideau at inbox.com> wrote:

> Over the last few years I came to the conclusion that using a spreadsheet
> for anything more complicated than my shopping list was madness.
>  I am now reconsidering my position on shopping lists.
>
> Thanks Bert. I have a small collection of spreadsheet errors that have
> been  published here and there and this is a great addition.
>
>
Yes, thanks Bert - I'm a bit surprised it go that far! When I saw (in 2003)
that Excel auto-mangled dates with no way to undo it - even if I'd
accidentally opened a CSV - that was it. I still shop with a scribbled
scrap of paper that I usually lose before I need it.

We still need spreadsheets though (IMO) and this looks promising:

http://comma-chameleon.io/

Also Jenny Bryan's wonderful work in this area deserves attention:

https://github.com/rsheets

I think dplyr-via-RSQLite linked SQLite back-end with a DT flexdashboards
front-end would be a useful project for R. (Just in case someone's looking
for something to do, all the pieces are there.)

Cheers, Mike.

John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: bgunter.4567 at gmail.com
> > Sent: Thu, 1 Sep 2016 08:09:46 -0700
> > To: r-help at r-project.org
> > Subject: [R] Off topic, but hopefully not totally irrelevant: on MS Excel
> > and genomics
> >
> >
> http://www.sciencemag.org/news/sifter/one-five-genetics-papers-contains-errors-thanks-microsoft-excel
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Sep  2 17:09:43 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 02 Sep 2016 15:09:43 +0000
Subject: [R] problem writing .bil files in netcdf
In-Reply-To: <9B68B493-7492-4CB6-A5C5-72C724E4483E@gmail.com>
References: <9B68B493-7492-4CB6-A5C5-72C724E4483E@gmail.com>
Message-ID: <CAAcGz9_v8UOic5Rc5yNCuCsQaRupr6WY=5cLQ4hEuUcM-jT=TQ@mail.gmail.com>

On Fri, 2 Sep 2016 at 00:43 Abdoulaye SARR <abdoulayesar at gmail.com> wrote:

> Dear List,
>
> I have daily rainfall data in .bil format and can get info of the file
> using rgdal:
>
> > library(rgdal)
> > GDALinfo("/1981/v2p19810101.bil")
> rows        1600
> columns     1500
> bands       1
> lower left origin.x        -20
> lower left origin.y        -40
> res.x       0.05
> res.y       0.05
> ysign       -1
> oblique.x   0
> oblique.y   0
> driver      EHdr
> projection  NA
>
> How can I read all daily file and write them as netcdf files and
> concatenate as one yearly file and also avoid boundary pixels alter
> rainfall values.
>
>
Hi,

You can read the single .bil and write it to NetCDF with raster (and the
rgdal and ncdf4) package:

 library(raster)
r <- raster("/1981/v2p19810101.bil")
writeRaster(r, "v2p19810101.nc")

But, if you read in multi .bil files and build a multilayer raster, i.e.

st <- stack(list.files("/1981", pattern = "bil$", full.names = TRUE))

you *can* write it out to NetCDF, very similar to above with writeRaster,
but I think it will generate a variable (an netcdf array) for each layer.

To really write to .nc in a specific way you'll need to delve into the
standard tools in ncdf4, to create a file, create
variables/dimensions/attributes, and then populate the variable, in this
case probably one 3rd-level slice for each .bil. That might be better done
at the command line, say with nco (the "nc operators"). There are
copy-create idioms which is probably the way to go if you have a template
data file or CDF specification.

There may be some higher level tools in other packages on CRAN, check the
reverse depends/imports/suggests on CRAN for ncdf4. Also you should explore
RNetCDF which has an independent implementation.

 (raster really blitzes the field in terms of high-level tools here, but it
has limits, with writing NetCDF *in specific ways* being one of them. GDAL
has similar limitations, since it sees the world in this
"array-as-2d-bands" way).

HTH, at least a little.

Cheers, Mike.

Best regards,
>
> Eus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Fri Sep  2 16:02:16 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 2 Sep 2016 09:02:16 -0500
Subject: [R] workflow getting UTF-8 csv in and out of R on Mac
 (spreadsheet editor)
In-Reply-To: <5115CFE6-9CAC-4750-9BA8-04B635498863@univie.ac.at>
References: <CAHOWgNUFwak1tzxbuREr47LEQ1Mv_-h=5yT=JMXLaG7b0oC02A@mail.gmail.com>
	<5115CFE6-9CAC-4750-9BA8-04B635498863@univie.ac.at>
Message-ID: <CABdHhvELHfyp00H+hnoE2bWwh_G1JYrE8HErtjAHkE_DHzLo6w@mail.gmail.com>

You can use readr::write_excel_csv() which adds a BOM that forces excel to
read as UTF-8.

Hadley

On Friday, September 2, 2016, Erich Neuwirth <erich.neuwirth at univie.ac.at>
wrote:

> read_excel in Hadley?s readxl package
> should handle your encoding problems.
> Writing Excel files on a Mac, however, still is somewhat messy.
>
> And you probably should post this kind of question on r-sig-mac
>
>
>
> On 02 Sep 2016, at 13:03, Kai Mx <govokai at gmail.com <javascript:;>> wrote:
> >
> > Hi all,
> >
> > I am hoping for some advice on how to handle UTF-8 spreadsheet files in a
> > Mac environment - sort of off-topic, but still relevant for hopefully a
> > bunch of people.
> >
> > I am using R on Mac OS 10.10. Sometimes I have the urge to actually look
> at
> > a large spreadsheet on the big screen or make some changes to the tables.
> > Since most of my colleagues live in the M$ Excel - world I tend to use
> > Excel 2011 as well. However, Excel does not handle UTF-8 (which I like
> > because of different system locales).
> > So I actually do a write.csv with file-encoding in macroman, but even
> then
> > Excel won't just open it and I will have to work my way through the
> > import-dialogue.
> >
> > The other way around, it's even worse. I save the spreadsheet as
> macroman,
> > iconv it to utf-8 and then read.csv it to R.
> >
> > It works, but it's just really messy. Is there a (preferably
> light-weight)
> > csv-spreadsheet Editor for Mac OS that you use? Open-Office? I would like
> > NOT to actually buy another Excel version. However, for collaboration, a
> > xls-export would be phenomenal.
> >
> > Thanks!
> >
> > Kai
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
http://hadley.nz

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Fri Sep  2 19:02:49 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 2 Sep 2016 13:02:49 -0400
Subject: [R] Improve code efficient with do.call, rbind and split contruction
Message-ID: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>

Dear list,

I have the following line of code to extract the last line of the split
data and put them back together.

do.call(rbind,lapply(split(simout.s1,simout.s1[c('SID','DOSENO')]),function(x)x[nrow(x),]))

the problem is when  have a huge dataset, it takes too long to run.
(actually it's > 3 hours and it's still running).

The dataset is pretty big. I have 200,000 unique SID and 4 DOSENO, so
totally 800,000 split dataset. Is there anyway to speed it up? Thanks.

Jun

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Sep  2 19:51:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Sep 2016 10:51:11 -0700
Subject: [R] Improve code efficient with do.call,
	rbind and split contruction
In-Reply-To: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
Message-ID: <CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>

This is the sort of thing that dplyr or the data.table packages can
probably do elegantly and efficiently. So you might consider looking
at them. But as I use neither, let me suggest a base R solution. As
you supplied no data for a reproducible example, I'll make up my own
and hopefully I have understood you correctly. If not, maybe someone
else will get it straight. Anyway...

The "trick" is to use tapply() to select the necessary row indices of
your data frame and forget about all the do.call and rbind stuff. e.g.

> set.seed(1001)
> df <- data.frame(f =factor(sample(LETTERS[1:4],100,rep=TRUE)),
+                  g <- factor(sample(letters[1:6],100,rep=TRUE)),
+                  y = runif(100))
>
> ix <- seq_len(nrow(df))
>
> ix <- with(df,tapply(ix,list(f,g),function(x)x[length(x)]))
> ix
   a  b   c  d  e  f
A 94 69 100 59 80 87
B 89 57  65 90 75 88
C 85 92  86 95 97 62
D 47 73  72 74 99 96

## ix can now be used as an index into df as:
df[ix,]

This should help somewhat, but you still have to contend with the
tapply() loop at the interpreted level. I'll leave speed comparisons
to you.

Cheers,
Bert

## Note: if, in fact, your data frame is arranged in a regular way
with, e.g. your SID, DOSENO groups all of the same size and together,
then you can calculate the indices you want directly and skip the
tapply business.I'm assuming this is not the case... Again, no data...





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 2, 2016 at 10:02 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Dear list,
>
> I have the following line of code to extract the last line of the split
> data and put them back together.
>
> do.call(rbind,lapply(split(simout.s1,simout.s1[c('SID','DOSENO')]),function(x)x[nrow(x),]))
>
> the problem is when  have a huge dataset, it takes too long to run.
> (actually it's > 3 hours and it's still running).
>
> The dataset is pretty big. I have 200,000 unique SID and 4 DOSENO, so
> totally 800,000 split dataset. Is there anyway to speed it up? Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri Sep  2 19:57:02 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 2 Sep 2016 18:57:02 +0100
Subject: [R] Improve code efficient with do.call,
 rbind and split contruction
In-Reply-To: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
Message-ID: <20160902185702.Horde.gPsj6xh_iG3TFhVHCu1CTe8@mail.sapo.pt>

Hello,

Try ?aggregate, it's probably faster.
With a made up data.frame, since you haven't provided us with a dataset,

simout.s1 <- data.frame(SID = rep(LETTERS[1:2], 10),
		DOSENO = rep(letters[1:4], each = 5),
		value = rnorm(20))

res2 <- aggregate(simout.s1$value, list(simout.s1$SID,  
simout.s1$DOSENO), function(x)x[NROW(x)])
names(res2) <- names(simout.s1)


Use dput to post a data example. Something like the following.

dput(head(simout.s1, 50))  #paste the output of this in your next mail


Hope this helps,

Rui Barradas



Citando Jun Shen <jun.shen.ut at gmail.com>:

> Dear list,
>
> I have the following line of code to extract the last line of the split
> data and put them back together.
>
> do.call(rbind,lapply(split(simout.s1,simout.s1[c('SID','DOSENO')]),function(x)x[nrow(x),]))
>
> the problem is when  have a huge dataset, it takes too long to run.
> (actually it's > 3 hours and it's still running).
>
> The dataset is pretty big. I have 200,000 unique SID and 4 DOSENO, so
> totally 800,000 split dataset. Is there anyway to speed it up? Thanks.
>
> Jun
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Fri Sep  2 20:37:26 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 2 Sep 2016 14:37:26 -0400
Subject: [R] Improve code efficient with do.call,
	rbind and split contruction
In-Reply-To: <CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
	<CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
Message-ID: <CAMCXXmon0L6deFx=F=RkAbYxjtc7_h4Xh_vtO8ThGG5h3FtcTQ@mail.gmail.com>

Hi Bert,

This is the best method I have seen this year! do.call, rbind has just gone
to museum :)

It took ~30 second to get the results. You deserve a medal!!!!

Jun

On Fri, Sep 2, 2016 at 1:51 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is the sort of thing that dplyr or the data.table packages can
> probably do elegantly and efficiently. So you might consider looking
> at them. But as I use neither, let me suggest a base R solution. As
> you supplied no data for a reproducible example, I'll make up my own
> and hopefully I have understood you correctly. If not, maybe someone
> else will get it straight. Anyway...
>
> The "trick" is to use tapply() to select the necessary row indices of
> your data frame and forget about all the do.call and rbind stuff. e.g.
>
> > set.seed(1001)
> > df <- data.frame(f =factor(sample(LETTERS[1:4],100,rep=TRUE)),
> +                  g <- factor(sample(letters[1:6],100,rep=TRUE)),
> +                  y = runif(100))
> >
> > ix <- seq_len(nrow(df))
> >
> > ix <- with(df,tapply(ix,list(f,g),function(x)x[length(x)]))
> > ix
>    a  b   c  d  e  f
> A 94 69 100 59 80 87
> B 89 57  65 90 75 88
> C 85 92  86 95 97 62
> D 47 73  72 74 99 96
>
> ## ix can now be used as an index into df as:
> df[ix,]
>
> This should help somewhat, but you still have to contend with the
> tapply() loop at the interpreted level. I'll leave speed comparisons
> to you.
>
> Cheers,
> Bert
>
> ## Note: if, in fact, your data frame is arranged in a regular way
> with, e.g. your SID, DOSENO groups all of the same size and together,
> then you can calculate the indices you want directly and skip the
> tapply business.I'm assuming this is not the case... Again, no data...
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Sep 2, 2016 at 10:02 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> > Dear list,
> >
> > I have the following line of code to extract the last line of the split
> > data and put them back together.
> >
> > do.call(rbind,lapply(split(simout.s1,simout.s1[c('SID','
> DOSENO')]),function(x)x[nrow(x),]))
> >
> > the problem is when  have a huge dataset, it takes too long to run.
> > (actually it's > 3 hours and it's still running).
> >
> > The dataset is pretty big. I have 200,000 unique SID and 4 DOSENO, so
> > totally 800,000 split dataset. Is there anyway to speed it up? Thanks.
> >
> > Jun
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Fri Sep  2 20:50:34 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Fri, 2 Sep 2016 11:50:34 -0700
Subject: [R] Improve code efficient with do.call,
 rbind and split contruction
In-Reply-To: <CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
	<CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1609021145150.862@charles-berrys-macbook.local>

On Fri, 2 Sep 2016, Bert Gunter wrote:
[snip]
>
> The "trick" is to use tapply() to select the necessary row indices of
> your data frame and forget about all the do.call and rbind stuff. e.g.
>

I agree the way to go is "select the necessary row indices" but I get 
there a different way. See below.

>> set.seed(1001)
>> df <- data.frame(f =factor(sample(LETTERS[1:4],100,rep=TRUE)),
> +                  g <- factor(sample(letters[1:6],100,rep=TRUE)),
> +                  y = runif(100))
>>
>> ix <- seq_len(nrow(df))
>>
>> ix <- with(df,tapply(ix,list(f,g),function(x)x[length(x)]))
>> ix
>   a  b   c  d  e  f
> A 94 69 100 59 80 87
> B 89 57  65 90 75 88
> C 85 92  86 95 97 62
> D 47 73  72 74 99 96


   jx <- which( !duplicated( df[,c("f","g")], fromLast=TRUE ))

   xtabs(jx~f+g,df[jx,]) ## Show equivalence to Bert's `ix'

    g
f     a   b   c   d   e   f
   A  94  69 100  59  80  87
   B  89  57  65  90  75  88
   C  85  92  86  95  97  62
   D  47  73  72  74  99  96


Chuck


From jfca283 at gmail.com  Fri Sep  2 21:04:22 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Fri, 2 Sep 2016 16:04:22 -0300
Subject: [R] svytable: How do i create a table informing a third variable?
Message-ID: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>

Hello
Im analyzing a survey and i need to obtain some statistics per groups.
Im able to create a table with sex and age. However, if i want to know how
much income earns the population by sex and age, i can't.
Im loading the dataset as describe the line below
NN <- svydesign(ids = ~1, data = encuesta, weights = fact)
Some simple table i can create
table(svytable(~age+sex,design=NN))
But im not able to handle the same tabulate referencing a income variable,
in this case, wage.
Can you help me?
Thanks for your replies and time.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Sep  2 22:48:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Sep 2016 13:48:06 -0700
Subject: [R] Improve code efficient with do.call,
	rbind and split contruction
In-Reply-To: <alpine.OSX.2.20.1609021145150.862@charles-berrys-macbook.local>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
	<CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
	<alpine.OSX.2.20.1609021145150.862@charles-berrys-macbook.local>
Message-ID: <CAGxFJbQo-XLcP=iN3SK3=4sQSR6Q0059pbDemjnr=LKZScKRbg@mail.gmail.com>

Chuck:

I think this is quite clever. But note that the which() is
unnecessary: logical indicing suffices, e.g.

df[!duplicated(df[,c("f","g")],fromLast = TRUE),]

I thought that your approach would be faster because it moves
comparisons from the tapply() to C code. But I was wrong. e.g. for 1e6
rows:

> set.seed(1001)
> df <- data.frame(f =factor(sample(LETTERS[1:4],1e6,rep=TRUE)),
                   +                 g
=factor(sample(letters[1:6],1e6,rep=TRUE)),
                   +                 y = runif(1e6))

##using duplicated()
 > system.time(z <-df[!duplicated(df[,c("f","g")],fromLast = TRUE),])
user  system elapsed
0.175   0.008   0.183

## Using tapply()
 > system.time(
    + {ix <- seq_len(nrow(df));
    + z <- df[with(df,tapply(ix,list(f,g),function(x)x[length(x)])),]
    + })
user  system elapsed
0.025   0.003   0.028


This illustrates the faultiness of my "intuition."  A guess would be
that the subscripting to get the factor combinations and
duplicated.data.frame method takes the extra time.

Anyway...

Best,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 2, 2016 at 11:50 AM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> On Fri, 2 Sep 2016, Bert Gunter wrote:
> [snip]
>>
>>
>> The "trick" is to use tapply() to select the necessary row indices of
>> your data frame and forget about all the do.call and rbind stuff. e.g.
>>
>
> I agree the way to go is "select the necessary row indices" but I get there
> a different way. See below.
>
>>> set.seed(1001)
>>> df <- data.frame(f =factor(sample(LETTERS[1:4],100,rep=TRUE)),
>>
>> +                  g <- factor(sample(letters[1:6],100,rep=TRUE)),
>> +                  y = runif(100))
>>>
>>>
>>> ix <- seq_len(nrow(df))
>>>
>>> ix <- with(df,tapply(ix,list(f,g),function(x)x[length(x)]))
>>> ix
>>
>>   a  b   c  d  e  f
>> A 94 69 100 59 80 87
>> B 89 57  65 90 75 88
>> C 85 92  86 95 97 62
>> D 47 73  72 74 99 96
>
>
>
>   jx <- which( !duplicated( df[,c("f","g")], fromLast=TRUE ))
>
>   xtabs(jx~f+g,df[jx,]) ## Show equivalence to Bert's `ix'
>
>    g
> f     a   b   c   d   e   f
>   A  94  69 100  59  80  87
>   B  89  57  65  90  75  88
>   C  85  92  86  95  97  62
>   D  47  73  72  74  99  96
>
>
> Chuck
>
>


From ajdamico at gmail.com  Sat Sep  3 01:24:29 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 2 Sep 2016 19:24:29 -0400
Subject: [R] svytable: How do i create a table informing a third
	variable?
In-Reply-To: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>
References: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>
Message-ID: <CAOwvMDwOtnZChkZBocZSLuDT747OAO7NuOFsZJW=ndceDVMm3Q@mail.gmail.com>

# mean
svymean( ~ income_variable , NN )
svyby( ~ income_variable , ~ age + sex , NN , svymean )

# median
svyquantile( ~ income_variable , NN )
svyby( ~ income_variable , ~ age + sex , NN , svyquantile , 0.5 )




On Fri, Sep 2, 2016 at 3:04 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
wrote:

> Hello
> Im analyzing a survey and i need to obtain some statistics per groups.
> Im able to create a table with sex and age. However, if i want to know how
> much income earns the population by sex and age, i can't.
> Im loading the dataset as describe the line below
> NN <- svydesign(ids = ~1, data = encuesta, weights = fact)
> Some simple table i can create
> table(svytable(~age+sex,design=NN))
> But im not able to handle the same tabulate referencing a income variable,
> in this case, wage.
> Can you help me?
> Thanks for your replies and time.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Sat Sep  3 03:08:59 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Fri, 2 Sep 2016 22:08:59 -0300
Subject: [R] svytable: How do i create a table informing a third
	variable?
In-Reply-To: <CAOwvMDwOtnZChkZBocZSLuDT747OAO7NuOFsZJW=ndceDVMm3Q@mail.gmail.com>
References: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>
	<CAOwvMDwOtnZChkZBocZSLuDT747OAO7NuOFsZJW=ndceDVMm3Q@mail.gmail.com>
Message-ID: <CALBYkjJ-a=PZKcAGUPmiJ9o1+UwOVAEFq1==Wr-S2wWxBYaCOA@mail.gmail.com>

Thanks a lot. Your code does the trick.
One last question:
The tabulate produced is showing every cross in just one column.
I mean, it presents the region by order and sex=1, and then again the
region but by sex==2.
Can i list or present as this:
             sex1         sex2
region1  323.      3434..
...
regionN 123..  432..

and ignoring the remaining info (standar errors or se in this case)?
Again, thanks Anthony. Really.





On Fri, Sep 2, 2016 at 8:24 PM, Anthony Damico <ajdamico at gmail.com> wrote:

> # mean
> svymean( ~ income_variable , NN )
> svyby( ~ income_variable , ~ age + sex , NN , svymean )
>
> # median
> svyquantile( ~ income_variable , NN )
> svyby( ~ income_variable , ~ age + sex , NN , svyquantile , 0.5 )
>
>
>
>
> On Fri, Sep 2, 2016 at 3:04 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
> wrote:
>
>> Hello
>> Im analyzing a survey and i need to obtain some statistics per groups.
>> Im able to create a table with sex and age. However, if i want to know how
>> much income earns the population by sex and age, i can't.
>> Im loading the dataset as describe the line below
>> NN <- svydesign(ids = ~1, data = encuesta, weights = fact)
>> Some simple table i can create
>> table(svytable(~age+sex,design=NN))
>> But im not able to handle the same tabulate referencing a income variable,
>> in this case, wage.
>> Can you help me?
>> Thanks for your replies and time.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From littleho_song at yahoo.com  Sat Sep  3 03:24:54 2016
From: littleho_song at yahoo.com (Yucheng Song)
Date: Sat, 3 Sep 2016 01:24:54 +0000 (UTC)
Subject: [R] readBin documentation error
In-Reply-To: <CA+8X3fUHge56DPHy+S7swKFdxsQJQZPpWtAUntC4VLvzOYpGCw@mail.gmail.com>
References: <257667955.71463.1472759247865.ref@mail.yahoo.com>
	<257667955.71463.1472759247865@mail.yahoo.com>
	<CA+8X3fUHge56DPHy+S7swKFdxsQJQZPpWtAUntC4VLvzOYpGCw@mail.gmail.com>
Message-ID: <970594655.765872.1472865895018@mail.yahoo.com>

Thanks for the reply. What I meant was that there is no int(), if you do a ?readBin, you will find it there. 

    On Friday, September 2, 2016 6:31 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Yucheng,
Have a look at "An Introduction to R" (get there with "help.start()"), section :

3.1 Intrinsic attributes: mode and length

The distinction between numeric and integer modes in R may not be
obvious, but it is important at times.

Jim


On Fri, Sep 2, 2016 at 5:47 AM, Yucheng Song via R-help
<r-help at r-project.org> wrote:
> Hi,? In the help or readBin, there is an "int", but actually there is no int(), do you mean some other types?? In fact, numeric() is kind of misleading, what does it mean?
> what Either an object whose mode will give the mode of the vector to be read, or a character vector of length one describing the mode: one of "numeric", "double", "integer", "int", "logical", "complex", "character", "raw".
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Sep  3 09:56:02 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 3 Sep 2016 09:56:02 +0200
Subject: [R] readBin documentation error
In-Reply-To: <970594655.765872.1472865895018@mail.yahoo.com>
References: <257667955.71463.1472759247865.ref@mail.yahoo.com>
	<257667955.71463.1472759247865@mail.yahoo.com>
	<CA+8X3fUHge56DPHy+S7swKFdxsQJQZPpWtAUntC4VLvzOYpGCw@mail.gmail.com>
	<970594655.765872.1472865895018@mail.yahoo.com>
Message-ID: <1212CB61-639C-4B7F-8309-C03BE6C7A90D@gmail.com>


> On 03 Sep 2016, at 03:24 , Yucheng Song via R-help <r-help at r-project.org> wrote:
> 
> Thanks for the reply. What I meant was that there is no int(), if you do a ?readBin, you will find it there. 

Not as far as I can tell:

    what: Either an object whose mode will give the mode of the vector
          to be read, or a character vector of length one describing
          the mode: one of ?"numeric"?, ?"double"?, ?"integer"?,
          ?"int"?, ?"logical"?, ?"complex"?, ?"character"?, ?"raw"?.

Note: Either...or...

I.e., you can use a character string (==vector of length one) 

readBin(zz, "int", 8, size = 1) 

and you can use an object of the desired mode

readBin(zz, integer(), ...) or equivalently readBin(zz, 0L, ...)

but there is no implication that each of the possible character strings have a corresponding function. It is not clear why we allow  both "int" and "integer" here, but there is no reason to expect int() to exist.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Sat Sep  3 11:23:51 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 3 Sep 2016 05:23:51 -0400
Subject: [R] readBin documentation error
In-Reply-To: <1212CB61-639C-4B7F-8309-C03BE6C7A90D@gmail.com>
References: <257667955.71463.1472759247865.ref@mail.yahoo.com>
	<257667955.71463.1472759247865@mail.yahoo.com>
	<CA+8X3fUHge56DPHy+S7swKFdxsQJQZPpWtAUntC4VLvzOYpGCw@mail.gmail.com>
	<970594655.765872.1472865895018@mail.yahoo.com>
	<1212CB61-639C-4B7F-8309-C03BE6C7A90D@gmail.com>
Message-ID: <2659e395-4f62-e337-704d-46774bfcb001@gmail.com>

On 03/09/2016 3:56 AM, peter dalgaard wrote:
>
>> On 03 Sep 2016, at 03:24 , Yucheng Song via R-help <r-help at r-project.org> wrote:
>>
>> Thanks for the reply. What I meant was that there is no int(), if you do a ?readBin, you will find it there.
>
> Not as far as I can tell:
>
>     what: Either an object whose mode will give the mode of the vector
>           to be read, or a character vector of length one describing
>           the mode: one of ?"numeric"?, ?"double"?, ?"integer"?,
>           ?"int"?, ?"logical"?, ?"complex"?, ?"character"?, ?"raw"?.
>
> Note: Either...or...
>
> I.e., you can use a character string (==vector of length one)
>
> readBin(zz, "int", 8, size = 1)
>
> and you can use an object of the desired mode
>
> readBin(zz, integer(), ...) or equivalently readBin(zz, 0L, ...)
>
> but there is no implication that each of the possible character strings have a corresponding function.

> It is not clear why we allow  both "int" and "integer" here, but there is no reason to expect int() to exist.


Partial matching isn't allowed on the names (because a length one 
character vector implies 'what = "character"' unless it happens to 
contain one of those strings), so this is a way to allow a common 
readable abbreviation.

Duncan Murdoch


From bgunter.4567 at gmail.com  Sat Sep  3 19:41:49 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 3 Sep 2016 10:41:49 -0700
Subject: [R] Improve code efficient with do.call,
	rbind and split contruction
In-Reply-To: <CAGxFJbQo-XLcP=iN3SK3=4sQSR6Q0059pbDemjnr=LKZScKRbg@mail.gmail.com>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
	<CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
	<alpine.OSX.2.20.1609021145150.862@charles-berrys-macbook.local>
	<CAGxFJbQo-XLcP=iN3SK3=4sQSR6Q0059pbDemjnr=LKZScKRbg@mail.gmail.com>
Message-ID: <CAGxFJbSoUzbTXV1znJduFOQmB0MpgU4pe6_STBsTAV8Rd-g=mw@mail.gmail.com>

Chuck et. al.:

As I said previously, my intuition about the relative efficiency of
tapply() and duplicated() in the context of this thread was wrong. But
I wondered exactly how and to what extent. So I've fooled around a bit
more and think I understand. Using the example I gave, the key is to
replace the duplicated.data.frame method and the inner data.frame
subscripting with the duplicated.default method via with() and the
interaction() function (paste() -ing instead takes extra time):

> system.time(z <-with(df,df[!duplicated(interaction(f,g),fromLast = TRUE),]))
   user  system elapsed
  0.039   0.006   0.045
>
> system.time(
+   {ix <- seq_len(nrow(df));
+    z <- with(df,df[tapply(ix,list(f,g),function(x)x[length(x)]),])
+    })
   user  system elapsed
  0.025   0.005   0.029


tapply() still appears slightly more efficient (which is still
surprising to me), but only slightly.


Hope this is informative.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 2, 2016 at 1:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Chuck:
>
> I think this is quite clever. But note that the which() is
> unnecessary: logical indicing suffices, e.g.
>
> df[!duplicated(df[,c("f","g")],fromLast = TRUE),]
>
> I thought that your approach would be faster because it moves
> comparisons from the tapply() to C code. But I was wrong. e.g. for 1e6
> rows:
>
>> set.seed(1001)
>> df <- data.frame(f =factor(sample(LETTERS[1:4],1e6,rep=TRUE)),
>                    +                 g
> =factor(sample(letters[1:6],1e6,rep=TRUE)),
>                    +                 y = runif(1e6))
>
> ##using duplicated()
>  > system.time(z <-df[!duplicated(df[,c("f","g")],fromLast = TRUE),])
> user  system elapsed
> 0.175   0.008   0.183
>
> ## Using tapply()
>  > system.time(
>     + {ix <- seq_len(nrow(df));
>     + z <- df[with(df,tapply(ix,list(f,g),function(x)x[length(x)])),]
>     + })
> user  system elapsed
> 0.025   0.003   0.028
>
>
> This illustrates the faultiness of my "intuition."  A guess would be
> that the subscripting to get the factor combinations and
> duplicated.data.frame method takes the extra time.
>
> Anyway...
>
> Best,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Sep 2, 2016 at 11:50 AM, Charles C. Berry <ccberry at ucsd.edu> wrote:
>> On Fri, 2 Sep 2016, Bert Gunter wrote:
>> [snip]
>>>
>>>
>>> The "trick" is to use tapply() to select the necessary row indices of
>>> your data frame and forget about all the do.call and rbind stuff. e.g.
>>>
>>
>> I agree the way to go is "select the necessary row indices" but I get there
>> a different way. See below.
>>
>>>> set.seed(1001)
>>>> df <- data.frame(f =factor(sample(LETTERS[1:4],100,rep=TRUE)),
>>>
>>> +                  g <- factor(sample(letters[1:6],100,rep=TRUE)),
>>> +                  y = runif(100))
>>>>
>>>>
>>>> ix <- seq_len(nrow(df))
>>>>
>>>> ix <- with(df,tapply(ix,list(f,g),function(x)x[length(x)]))
>>>> ix
>>>
>>>   a  b   c  d  e  f
>>> A 94 69 100 59 80 87
>>> B 89 57  65 90 75 88
>>> C 85 92  86 95 97 62
>>> D 47 73  72 74 99 96
>>
>>
>>
>>   jx <- which( !duplicated( df[,c("f","g")], fromLast=TRUE ))
>>
>>   xtabs(jx~f+g,df[jx,]) ## Show equivalence to Bert's `ix'
>>
>>    g
>> f     a   b   c   d   e   f
>>   A  94  69 100  59  80  87
>>   B  89  57  65  90  75  88
>>   C  85  92  86  95  97  62
>>   D  47  73  72  74  99  96
>>
>>
>> Chuck
>>
>>


From ccberry at ucsd.edu  Sun Sep  4 01:16:44 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Sat, 3 Sep 2016 16:16:44 -0700
Subject: [R] Improve code efficient with do.call,
 rbind and split contruction
In-Reply-To: <CAGxFJbSoUzbTXV1znJduFOQmB0MpgU4pe6_STBsTAV8Rd-g=mw@mail.gmail.com>
References: <CAMCXXmrZ+K2kzmkkz8Lw52n9SK89VzwXcxX5OD3wBENoKw7J3A@mail.gmail.com>
	<CAGxFJbSrOZZ7462r1znxbuN4Y_i2O-UvU=MUOcKmtx6JXMFnNA@mail.gmail.com>
	<alpine.OSX.2.20.1609021145150.862@charles-berrys-macbook.local>
	<CAGxFJbQo-XLcP=iN3SK3=4sQSR6Q0059pbDemjnr=LKZScKRbg@mail.gmail.com>
	<CAGxFJbSoUzbTXV1znJduFOQmB0MpgU4pe6_STBsTAV8Rd-g=mw@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1609031548430.1012@charles-berrys-macbook.local>

On Sat, 3 Sep 2016, Bert Gunter wrote:

> Chuck et. al.:
>
> As I said previously, my intuition about the relative efficiency of
> tapply() and duplicated() in the context of this thread was wrong.

My `intuition' was wrong, too.

But tapply() uses split() which runs quite fast. So not a big surprise, 
but if you look thru tapply() you'll notice it is well crafted in other 
ways. In particular, the way the `f' arg of split is constructed makes a 
big difference in timing (using a for loop to build up a mixed radix 
number). In fact interaction(f,g) needs about 3 times the time of 
tapply(f,list(f,g)) for just building an index.

Thanks for following up.

Best,

Chuck


From dwinsemius at comcast.net  Sun Sep  4 03:06:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 3 Sep 2016 18:06:54 -0700
Subject: [R] svytable: How do i create a table informing a third
	variable?
In-Reply-To: <CALBYkjJ-a=PZKcAGUPmiJ9o1+UwOVAEFq1==Wr-S2wWxBYaCOA@mail.gmail.com>
References: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>
	<CAOwvMDwOtnZChkZBocZSLuDT747OAO7NuOFsZJW=ndceDVMm3Q@mail.gmail.com>
	<CALBYkjJ-a=PZKcAGUPmiJ9o1+UwOVAEFq1==Wr-S2wWxBYaCOA@mail.gmail.com>
Message-ID: <FF02CE18-4559-4790-A04E-F6048EA7ACD2@comcast.net>


> On Sep 2, 2016, at 6:08 PM, Juan Ceccarelli Arias <jfca283 at gmail.com> wrote:
> 
> Thanks a lot. Your code does the trick.
> One last question:
> The tabulate produced is showing every cross in just one column.
> I mean, it presents the region by order and sex=1, and then again the
> region but by sex==2.
> Can i list or present as this:
>             sex1         sex2
> region1  323.      3434..
> ...
> regionN 123..  432..
> 
> and ignoring the remaining info (standar errors or se in this case)?
> Again, thanks Anthony. Really.
> 
(Anthony's probably asleep.)

This doesn't ignore the se's but that could be easily done by omitting that column from the data argument:

From the examples on the help page for svymean:

> svyby( ~ mobility , ~ stype + comp.imp , dclus1 , svymean )
      stype comp.imp mobility        se
E.No      E       No 19.71875  1.347583
H.No      H       No 13.14286  0.740017
M.No      M       No 14.81818  2.960618
E.Yes     E      Yes 17.28571  1.536158
H.Yes     H      Yes 35.14286 16.570001
M.Yes     M      Yes 13.71429  2.628573

apimeans1 <- svyby( ~ mobility , ~ stype + comp.imp , dclus1 , svymean )

> reshape(apimeans1, idvar='stype', direction="wide", timevar="comp.imp")
     stype mobility.No    se.No mobility.Yes    se.Yes
E.No     E    19.71875 1.347583     17.28571  1.536158
H.No     H    13.14286 0.740017     35.14286 16.570001
M.No     M    14.81818 2.960618     13.71429  2.628573

-- 
David.

> 
> 
> 
> 
> On Fri, Sep 2, 2016 at 8:24 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> 
>> # mean
>> svymean( ~ income_variable , NN )
>> svyby( ~ income_variable , ~ age + sex , NN , svymean )
>> 
>> # median
>> svyquantile( ~ income_variable , NN )
>> svyby( ~ income_variable , ~ age + sex , NN , svyquantile , 0.5 )
>> 
>> 
>> 
>> 
>> On Fri, Sep 2, 2016 at 3:04 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
>> wrote:
>> 
>>> Hello
>>> Im analyzing a survey and i need to obtain some statistics per groups.
>>> Im able to create a table with sex and age. However, if i want to know how
>>> much income earns the population by sex and age, i can't.
>>> Im loading the dataset as describe the line below
>>> NN <- svydesign(ids = ~1, data = encuesta, weights = fact)
>>> Some simple table i can create
>>> table(svytable(~age+sex,design=NN))
>>> But im not able to handle the same tabulate referencing a income variable,
>>> in this case, wage.
>>> Can you help me?
>>> Thanks for your replies and time.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfca283 at gmail.com  Sun Sep  4 03:23:48 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Sat, 3 Sep 2016 22:23:48 -0300
Subject: [R] svytable: How do i create a table informing a third
	variable?
In-Reply-To: <FF02CE18-4559-4790-A04E-F6048EA7ACD2@comcast.net>
References: <CALBYkj+eyEaiGtnGXT4r6kj6rTTpJvRcJ0RGB9Lp+fP55CFzig@mail.gmail.com>
	<CAOwvMDwOtnZChkZBocZSLuDT747OAO7NuOFsZJW=ndceDVMm3Q@mail.gmail.com>
	<CALBYkjJ-a=PZKcAGUPmiJ9o1+UwOVAEFq1==Wr-S2wWxBYaCOA@mail.gmail.com>
	<FF02CE18-4559-4790-A04E-F6048EA7ACD2@comcast.net>
Message-ID: <CALBYkjJAMx=nHivqSEr+nuiLLUMv15mVD5YMH69ExgsVMJw5EQ@mail.gmail.com>

Your help was everything i needed it.
Please, declare this topic as solved.
And thanks again.

On Sat, Sep 3, 2016 at 10:06 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 2, 2016, at 6:08 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
> wrote:
> >
> > Thanks a lot. Your code does the trick.
> > One last question:
> > The tabulate produced is showing every cross in just one column.
> > I mean, it presents the region by order and sex=1, and then again the
> > region but by sex==2.
> > Can i list or present as this:
> >             sex1         sex2
> > region1  323.      3434..
> > ...
> > regionN 123..  432..
> >
> > and ignoring the remaining info (standar errors or se in this case)?
> > Again, thanks Anthony. Really.
> >
> (Anthony's probably asleep.)
>
> This doesn't ignore the se's but that could be easily done by omitting
> that column from the data argument:
>
> From the examples on the help page for svymean:
>
> > svyby( ~ mobility , ~ stype + comp.imp , dclus1 , svymean )
>       stype comp.imp mobility        se
> E.No      E       No 19.71875  1.347583
> H.No      H       No 13.14286  0.740017
> M.No      M       No 14.81818  2.960618
> E.Yes     E      Yes 17.28571  1.536158
> H.Yes     H      Yes 35.14286 16.570001
> M.Yes     M      Yes 13.71429  2.628573
>
> apimeans1 <- svyby( ~ mobility , ~ stype + comp.imp , dclus1 , svymean )
>
> > reshape(apimeans1, idvar='stype', direction="wide", timevar="comp.imp")
>      stype mobility.No    se.No mobility.Yes    se.Yes
> E.No     E    19.71875 1.347583     17.28571  1.536158
> H.No     H    13.14286 0.740017     35.14286 16.570001
> M.No     M    14.81818 2.960618     13.71429  2.628573
>
> --
> David.
>
> >
> >
> >
> >
> > On Fri, Sep 2, 2016 at 8:24 PM, Anthony Damico <ajdamico at gmail.com>
> wrote:
> >
> >> # mean
> >> svymean( ~ income_variable , NN )
> >> svyby( ~ income_variable , ~ age + sex , NN , svymean )
> >>
> >> # median
> >> svyquantile( ~ income_variable , NN )
> >> svyby( ~ income_variable , ~ age + sex , NN , svyquantile , 0.5 )
> >>
> >>
> >>
> >>
> >> On Fri, Sep 2, 2016 at 3:04 PM, Juan Ceccarelli Arias <
> jfca283 at gmail.com>
> >> wrote:
> >>
> >>> Hello
> >>> Im analyzing a survey and i need to obtain some statistics per groups.
> >>> Im able to create a table with sex and age. However, if i want to know
> how
> >>> much income earns the population by sex and age, i can't.
> >>> Im loading the dataset as describe the line below
> >>> NN <- svydesign(ids = ~1, data = encuesta, weights = fact)
> >>> Some simple table i can create
> >>> table(svytable(~age+sex,design=NN))
> >>> But im not able to handle the same tabulate referencing a income
> variable,
> >>> in this case, wage.
> >>> Can you help me?
> >>> Thanks for your replies and time.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bailster at hotmail.com  Sun Sep  4 03:43:45 2016
From: bailster at hotmail.com (Bailey Hewitt)
Date: Sun, 4 Sep 2016 01:43:45 +0000
Subject: [R] Creating a loop with code from the mblm package
Message-ID: <YQBPR01MB01135F2D2F0B326ECF1E3ECDD9E40@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>

Hello,


I am a novice in coding in R and have come across an error I am having a hard time fixing. I am trying to use the mblm package to run a Theil-Sen linear model. The code for this function is:

mblm(Y ~ X, dataframe, repeated = FALSE)

My goal is to put this into a loop so that I can calculate the Theil-Sen slope of each column in my csv. file. The file contains one column of years (x value) and 3 columns of days of the year (y values). All columns are the same length. The code I currently have is:


read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")

mydata= read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")


attach(mydata)


install.packages("mblm")

library("mblm")


for (i in c(1:3)){

  x <- mblm(mydata[,i] ~ Year, mydata, repeated = FALSE)

  print(x)

}


Which gives me the following error:

Error in names(res$residuals) = as.character(1:length(res$residuals)) :

  'names' attribute [2] must be the same length as the vector [0]


Which I cannot seem to solve although as I understand it it is an error that I am causing in the mblm package. If anyone has any insight into how I could start fixing this that would be greatly appreciated!


Bailey


	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Sep  4 09:54:33 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Sep 2016 13:24:33 +0530
Subject: [R] Error in reading subset of data from CSV file
Message-ID: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>

Hi again,

I was trying to read a subset of Data from a CSV file using below code
as example :

library(sqldf)

Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
"bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
c("04-Jul-16",
"05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
"col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
-4L))
Dat

write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)

ReadName = '133261'
read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")

Loading required package: tcltk
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 1 did not have 7 elements

This code generates above Error. Could you please help me with a
pointer where something went wrong? My actual CSV file is quite huge
so I cant read it as whole. However basic structure of my original
file is similar as above "Dat"

Thanks for your time.


From ingfimo at gmail.com  Sun Sep  4 10:12:37 2016
From: ingfimo at gmail.com (Filippo Monari)
Date: Sun, 04 Sep 2016 09:12:37 +0100
Subject: [R] Splines
Message-ID: <57cbd777.4abf1c0a.491f2.f85b@mx.google.com>

Hi,
I would like to use the C spline functions if R for a FORTRAN subroutine. What header file should I refer to?

Regards
Filippo Monari

From drjimlemon at gmail.com  Sun Sep  4 10:55:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 4 Sep 2016 18:55:55 +1000
Subject: [R] Creating a loop with code from the mblm package
In-Reply-To: <YQBPR01MB01135F2D2F0B326ECF1E3ECDD9E40@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR01MB01135F2D2F0B326ECF1E3ECDD9E40@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fVENKu4q6-TY_JQjGwEmZcAYP+FPDPfvS0uRepCR5=F6A@mail.gmail.com>

Hi Bailey,
Treat it as a guess, but try this:

for (i in c(1:3)){
 y<-mydata[,i]
 x <- mblm(y ~ Year, mydata, repeated = FALSE)
 print(x)
}

I'm not sure that you can mix indexed columns with column names. Also,
Year is column 4, no?

Jim


On Sun, Sep 4, 2016 at 11:43 AM, Bailey Hewitt <bailster at hotmail.com> wrote:
> Hello,
>
>
> I am a novice in coding in R and have come across an error I am having a hard time fixing. I am trying to use the mblm package to run a Theil-Sen linear model. The code for this function is:
>
> mblm(Y ~ X, dataframe, repeated = FALSE)
>
> My goal is to put this into a loop so that I can calculate the Theil-Sen slope of each column in my csv. file. The file contains one column of years (x value) and 3 columns of days of the year (y values). All columns are the same length. The code I currently have is:
>
>
> read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>
> mydata= read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>
>
> attach(mydata)
>
>
> install.packages("mblm")
>
> library("mblm")
>
>
> for (i in c(1:3)){
>
>   x <- mblm(mydata[,i] ~ Year, mydata, repeated = FALSE)
>
>   print(x)
>
> }
>
>
> Which gives me the following error:
>
> Error in names(res$residuals) = as.character(1:length(res$residuals)) :
>
>   'names' attribute [2] must be the same length as the vector [0]
>
>
> Which I cannot seem to solve although as I understand it it is an error that I am causing in the mblm package. If anyone has any insight into how I could start fixing this that would be greatly appreciated!
>
>
> Bailey
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Sep  4 12:10:09 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 4 Sep 2016 20:10:09 +1000
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
Message-ID: <CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>

Hi Christofer,
You have embedded commas in your data structure. This is guaranteed to
mess up a CSV read.

Jim


On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I was trying to read a subset of Data from a CSV file using below code
> as example :
>
> library(sqldf)
>
> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
> c("04-Jul-16",
> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
> -4L))
> Dat
>
> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>
> ReadName = '133261'
> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>
> Loading required package: tcltk
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 1 did not have 7 elements
>
> This code generates above Error. Could you please help me with a
> pointer where something went wrong? My actual CSV file is quite huge
> so I cant read it as whole. However basic structure of my original
> file is similar as above "Dat"
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sun Sep  4 12:13:10 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Sep 2016 15:43:10 +0530
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
Message-ID: <CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>

Thanks Jim. But my data is like that and I have to live with that. Any
idea on workaround. Thanks,

On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Christofer,
> You have embedded commas in your data structure. This is guaranteed to
> mess up a CSV read.
>
> Jim
>
>
> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>> Hi again,
>>
>> I was trying to read a subset of Data from a CSV file using below code
>> as example :
>>
>> library(sqldf)
>>
>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>> c("04-Jul-16",
>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>> -4L))
>> Dat
>>
>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>
>> ReadName = '133261'
>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>
>> Loading required package: tcltk
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   line 1 did not have 7 elements
>>
>> This code generates above Error. Could you please help me with a
>> pointer where something went wrong? My actual CSV file is quite huge
>> so I cant read it as whole. However basic structure of my original
>> file is similar as above "Dat"
>>
>> Thanks for your time.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Sep  4 13:17:26 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 4 Sep 2016 21:17:26 +1000
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
	<CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
Message-ID: <CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>

I suppose you could try quote=TRUE

Jim


On Sun, Sep 4, 2016 at 8:13 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Thanks Jim. But my data is like that and I have to live with that. Any
> idea on workaround. Thanks,
>
> On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Christofer,
>> You have embedded commas in your data structure. This is guaranteed to
>> mess up a CSV read.
>>
>> Jim
>>
>>
>> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
>> <bogaso.christofer at gmail.com> wrote:
>>> Hi again,
>>>
>>> I was trying to read a subset of Data from a CSV file using below code
>>> as example :
>>>
>>> library(sqldf)
>>>
>>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>>> c("04-Jul-16",
>>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>>> -4L))
>>> Dat
>>>
>>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>>
>>> ReadName = '133261'
>>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>>
>>> Loading required package: tcltk
>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>   line 1 did not have 7 elements
>>>
>>> This code generates above Error. Could you please help me with a
>>> pointer where something went wrong? My actual CSV file is quite huge
>>> so I cant read it as whole. However basic structure of my original
>>> file is similar as above "Dat"
>>>
>>> Thanks for your time.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tmichaeli001 at gmail.com  Sun Sep  4 05:05:29 2016
From: tmichaeli001 at gmail.com (Tamar Michaeli)
Date: Sat, 3 Sep 2016 23:05:29 -0400
Subject: [R] impossible # of errors in a simple code
Message-ID: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>

Any help in resolving the following errors will be appreciated:

> pollutantmean <- function(directory, pollutant, id=1:332)
+ file_inc <- list.files("specdata", full.names=TRUE)
> dat <- data.frame()
> for(i in 1:10) {
+ dat <- rbind(dat, read.csv(file_inc[i]))
+ }
Error in read.table(file = file, header = header, sep = sep, quote = quote,
 :
  object 'file_inc' not found
> sulfate <- subset(dat( , 2))
Error in subset(dat(, 2)) : could not find function "dat"
> nitrate <- subset(dat( , 3))
Error in subset(dat(, 3)) : could not find function "dat"
> mean(pollutant)
Error in mean(pollutant) : object 'pollutant' not found
> save"pollutantmean.R"
Error: unexpected string constant in "        save"pollutantmean.R""

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Sep  4 13:29:16 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Sep 2016 16:59:16 +0530
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
	<CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
	<CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>
Message-ID: <CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>

Didnt work.... getting unused argument error.

On Sun, Sep 4, 2016 at 4:47 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> I suppose you could try quote=TRUE
>
> Jim
>
>
> On Sun, Sep 4, 2016 at 8:13 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>> Thanks Jim. But my data is like that and I have to live with that. Any
>> idea on workaround. Thanks,
>>
>> On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Christofer,
>>> You have embedded commas in your data structure. This is guaranteed to
>>> mess up a CSV read.
>>>
>>> Jim
>>>
>>>
>>> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
>>> <bogaso.christofer at gmail.com> wrote:
>>>> Hi again,
>>>>
>>>> I was trying to read a subset of Data from a CSV file using below code
>>>> as example :
>>>>
>>>> library(sqldf)
>>>>
>>>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>>>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>>>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>>>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>>>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>>>> c("04-Jul-16",
>>>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>>>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>>>> -4L))
>>>> Dat
>>>>
>>>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>>>
>>>> ReadName = '133261'
>>>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>>>
>>>> Loading required package: tcltk
>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>>   line 1 did not have 7 elements
>>>>
>>>> This code generates above Error. Could you please help me with a
>>>> pointer where something went wrong? My actual CSV file is quite huge
>>>> so I cant read it as whole. However basic structure of my original
>>>> file is similar as above "Dat"
>>>>
>>>> Thanks for your time.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Sep  4 13:38:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 4 Sep 2016 21:38:55 +1000
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
	<CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
	<CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>
	<CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>
Message-ID: <CA+8X3fWVAaKeWSF3JZvbBO1XqY+W6yWmdLFLZV_crKO+ZrdSQg@mail.gmail.com>

Shouldn't get that with write.csv.

Jim


On Sun, Sep 4, 2016 at 9:29 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Didnt work.... getting unused argument error.
>
> On Sun, Sep 4, 2016 at 4:47 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> I suppose you could try quote=TRUE
>>
>> Jim
>>
>>
>> On Sun, Sep 4, 2016 at 8:13 PM, Christofer Bogaso
>> <bogaso.christofer at gmail.com> wrote:
>>> Thanks Jim. But my data is like that and I have to live with that. Any
>>> idea on workaround. Thanks,
>>>
>>> On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> Hi Christofer,
>>>> You have embedded commas in your data structure. This is guaranteed to
>>>> mess up a CSV read.
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
>>>> <bogaso.christofer at gmail.com> wrote:
>>>>> Hi again,
>>>>>
>>>>> I was trying to read a subset of Data from a CSV file using below code
>>>>> as example :
>>>>>
>>>>> library(sqldf)
>>>>>
>>>>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>>>>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>>>>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>>>>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>>>>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>>>>> c("04-Jul-16",
>>>>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>>>>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>>>>> -4L))
>>>>> Dat
>>>>>
>>>>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>>>>
>>>>> ReadName = '133261'
>>>>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>>>>
>>>>> Loading required package: tcltk
>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>>>   line 1 did not have 7 elements
>>>>>
>>>>> This code generates above Error. Could you please help me with a
>>>>> pointer where something went wrong? My actual CSV file is quite huge
>>>>> so I cant read it as whole. However basic structure of my original
>>>>> file is similar as above "Dat"
>>>>>
>>>>> Thanks for your time.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sun Sep  4 13:38:54 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 4 Sep 2016 12:38:54 +0100
Subject: [R] impossible # of errors in a simple code
In-Reply-To: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>
References: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>
Message-ID: <e3359cf2-004e-3751-6261-891447175bf0@dewey.myzen.co.uk>

A useful rule is to fix the first error you understand and hope that the 
others go away.

On 04/09/2016 04:05, Tamar Michaeli wrote:
> Any help in resolving the following errors will be appreciated:
>
>> pollutantmean <- function(directory, pollutant, id=1:332)
> + file_inc <- list.files("specdata", full.names=TRUE)

So what did you hope your function was going to do, if you called it?

>> dat <- data.frame()
>> for(i in 1:10) {
> + dat <- rbind(dat, read.csv(file_inc[i]))
> + }
> Error in read.table(file = file, header = header, sep = sep, quote = quote,
>  :
>   object 'file_inc' not found

Why did you think at this point that you had an object called file_inc?

>> sulfate <- subset(dat( , 2))
> Error in subset(dat(, 2)) : could not find function "dat"

So you did not manage anywhere to define a function called dat.

>> nitrate <- subset(dat( , 3))
> Error in subset(dat(, 3)) : could not find function "dat"
>> mean(pollutant)
> Error in mean(pollutant) : object 'pollutant' not found

You have never defined it.

>> save"pollutantmean.R"
> Error: unexpected string constant in "        save"pollutantmean.R""

?save might help you here.


>
> 	[[alternative HTML version deleted]]
>


Please do not post in HTML as it makes your post unreadable.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From giorgio.garziano at ericsson.com  Sun Sep  4 13:51:45 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 4 Sep 2016 11:51:45 +0000
Subject: [R] Need advice on linear programming in R
Message-ID: <248E6FA047A8C746BA491485764190F53E9A394E@ESESSMB207.ericsson.se>

Hi Michael,

On top of all suggestions, I can mention the following packages for linear programming problems:


https://cran.r-project.org/web/packages/linprog/linprog.pdf


https://cran.r-project.org/web/packages/lpSolve/lpSolve.pdf


https://cran.r-project.org/web/packages/clue/clue.pdf

(see clue package solve_LSAP function)


https://cran.r-project.org/web/packages/adagio/adagio.pdf


As a reference book, "Using R for Numerical Analysis in Science and Engineering", CRC press:


https://www.crcpress.com/Using-R-for-Numerical-Analysis-in-Science-and-Engineering/Bloomfield/p/book/9781439884485



Further, I share with you the code implementing a greedy solution to your assignment problem:

set.seed(1023)
nbin <- 5
nrow <- 100
nvalue <- nbin*nrow

# generating random values
gMat2 <- matrix(as.integer(Mod(rnorm(nvalue, 5, 10))), nrow = nrow)
gMat2

# since you want to maximize the minimum bin sums value
# let us already find the maximum value per row and store its corresponding
# column id inside rowmax
rowmax <- apply(gMat2, 1, function(x) {which.max(x)})
rowmax

# maximum value per each row
max_per_row <- sapply(1:nrow, function(x) gMat2[x, rowmax[x]])
names(max_per_row) <- as.character(1:nrow)
max_per_row

# sorting max_per_row values in descreasing order
sorted <- base::sort(max_per_row, decreasing=TRUE)
sorted

# bin where to store sums
bin <- vector(mode="numeric", length = nbin)

# assignment output based on sorted vector
output <- c()

# looping on sorted and assign the bin with minimum current sum
for (i in seq_along(sorted)) {
  s <- sorted[i]
  min.bin <- which.min(bin)
  bin[min.bin] <- bin[min.bin] + s
  output <- c(output, min.bin)
}

df <- cbind(sorted, output)
ord <- order(as.integer(rownames(df)))

df2 <- df[ord,]
colnames(df2) <- c("value", "selected_bin")
df2 <- data.frame(selected_column = rowmax, df2)

# assignments table
df2

# resulting bins sum
bin

-----

Best,

GG



	[[alternative HTML version deleted]]


From katsiosf at gmail.com  Sun Sep  4 15:22:48 2016
From: katsiosf at gmail.com (Filippos Katsios)
Date: Sun, 4 Sep 2016 16:22:48 +0300
Subject: [R] Problem with adding a row in a data table
Message-ID: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>

Dear All,

I am relatively new to R and certainly new to the e-mailing list. I need
your help. I am working on a data frame, which looks like this:

Prod_name |  Date 1  |  Date 2 |  Date 3  |
------------------|-------------|------------|--------------|
Product 1    |     3      |      4     |     0       |
------------------|-------------|------------|--------------|
Product 2    |     5      |      3     |     3       |
------------------|-------------|------------|--------------|
Product 3    |     2      |      8     |     5       |

I am trying to add a new row with the following results:

Prod_name |  Date 1  |  Date 2 |  Date 3  |
------------------|-------------|------------|--------------|
Day_num    |     1      |      2     |      3      |
------------------|-------------|------------|--------------|
Product 1    |     3      |      4     |     0       |
------------------|-------------|------------|--------------|
Product 2    |     5      |      3     |     3       |
------------------|-------------|------------|--------------|
Product 3    |     2      |      8     |     5       |

Bellow you can find the things I tried and the results.
1)
r <- 1
newrow <- rep(1:7, 5, len=ncol(data_may)-1)
insertRow <- function(data_may, newrow, r) {
  data_may[seq(r+1,nrow(data_may)+1),] <- data_may[seq(r,nrow(data_may)),]
  data_may[r,] <- newrow
  data_may
}

It doesn't put the new row.
2)
data_may<-rbind(data_may,c("Day_num",newrow))

Error: cannot convert object to a data frame

3)
data_may[2093,]<-c("Day_num",rep(1:7, 5, len=ncol(data_may)-1))

It makes all the columns characters and when i try to change it it says
that you can change a list

How can I add the row while keeping the columns (apart from the first one)
as numeric or double or integer?

Thank you, in advance, for your help!

Kind regards
Filippos

	[[alternative HTML version deleted]]


From bailster at hotmail.com  Sun Sep  4 16:10:40 2016
From: bailster at hotmail.com (Bailey Hewitt)
Date: Sun, 4 Sep 2016 14:10:40 +0000
Subject: [R] Creating a loop with code from the mblm package
In-Reply-To: <CA+8X3fVENKu4q6-TY_JQjGwEmZcAYP+FPDPfvS0uRepCR5=F6A@mail.gmail.com>
References: <YQBPR01MB01135F2D2F0B326ECF1E3ECDD9E40@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>,
	<CA+8X3fVENKu4q6-TY_JQjGwEmZcAYP+FPDPfvS0uRepCR5=F6A@mail.gmail.com>
Message-ID: <YQBPR01MB011300CDA0D7C6303E42101DD9E70@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>

Hi Jim,


Thank you for the suggestion. Unfortunately, when I tried this it gave me the same error as I was getting before. I was wondering the same thing as you, because of the way my function is set up is it even possible to iterate through columns in that type of function? And my Year column is the first column in my csv file, which I thought made it column 0. Am I mistaken, is it supposed to be column 1?


Thanks!


Bailey


________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: September 4, 2016 4:55 AM
To: Bailey Hewitt
Cc: R-help
Subject: Re: [R] Creating a loop with code from the mblm package

Hi Bailey,
Treat it as a guess, but try this:

for (i in c(1:3)){
 y<-mydata[,i]
 x <- mblm(y ~ Year, mydata, repeated = FALSE)
 print(x)
}

I'm not sure that you can mix indexed columns with column names. Also,
Year is column 4, no?

Jim


On Sun, Sep 4, 2016 at 11:43 AM, Bailey Hewitt <bailster at hotmail.com> wrote:
> Hello,
>
>
> I am a novice in coding in R and have come across an error I am having a hard time fixing. I am trying to use the mblm package to run a Theil-Sen linear model. The code for this function is:
>
> mblm(Y ~ X, dataframe, repeated = FALSE)
>
> My goal is to put this into a loop so that I can calculate the Theil-Sen slope of each column in my csv. file. The file contains one column of years (x value) and 3 columns of days of the year (y values). All columns are the same length. The code I currently have is:
>
>
> read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>
> mydata= read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>
>
> attach(mydata)
>
>
> install.packages("mblm")
>
> library("mblm")
>
>
> for (i in c(1:3)){
>
>   x <- mblm(mydata[,i] ~ Year, mydata, repeated = FALSE)
>
>   print(x)
>
> }
>
>
> Which gives me the following error:
>
> Error in names(res$residuals) = as.character(1:length(res$residuals)) :
>
>   'names' attribute [2] must be the same length as the vector [0]
>
>
> Which I cannot seem to solve although as I understand it it is an error that I am causing in the mblm package. If anyone has any insight into how I [[elided Hotmail spam]]
>
>
> Bailey
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

z.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Sep  4 16:58:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Sep 2016 07:58:47 -0700
Subject: [R] Creating a loop with code from the mblm package
In-Reply-To: <YQBPR01MB011300CDA0D7C6303E42101DD9E70@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR01MB01135F2D2F0B326ECF1E3ECDD9E40@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
	<CA+8X3fVENKu4q6-TY_JQjGwEmZcAYP+FPDPfvS0uRepCR5=F6A@mail.gmail.com>
	<YQBPR01MB011300CDA0D7C6303E42101DD9E70@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQUePWjfH8TDXzJ_P5FEfJ4aMO3brXsAx9Tdw07iAJojw@mail.gmail.com>

Please go through an R tutorial or two before posting further here.
There are many good ones on the web. Some recommendations can be found
here:
https://www.rstudio.com/online-learning/

Your question:

"And my Year column is the first column in my csv file, which I
thought made it column 0. Am I mistaken, is it supposed to be column
1?"

is absolutely basic, and indicates that you have not yet made much
effort to learn R. The inevitable result, of course, is confusion and
errors of the sort you describe.

The answer is that R indices start at 1, but there is a great deal
more to them than that, which tutorials would tell you about.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 7:10 AM, Bailey Hewitt <bailster at hotmail.com> wrote:
> Hi Jim,
>
>
> Thank you for the suggestion. Unfortunately, when I tried this it gave me the same error as I was getting before. I was wondering the same thing as you, because of the way my function is set up is it even possible to iterate through columns in that type of function? And my Year column is the first column in my csv file, which I thought made it column 0. Am I mistaken, is it supposed to be column 1?
>
>
> Thanks!
>
>
> Bailey
>
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: September 4, 2016 4:55 AM
> To: Bailey Hewitt
> Cc: R-help
> Subject: Re: [R] Creating a loop with code from the mblm package
>
> Hi Bailey,
> Treat it as a guess, but try this:
>
> for (i in c(1:3)){
>  y<-mydata[,i]
>  x <- mblm(y ~ Year, mydata, repeated = FALSE)
>  print(x)
> }
>
> I'm not sure that you can mix indexed columns with column names. Also,
> Year is column 4, no?
>
> Jim
>
>
> On Sun, Sep 4, 2016 at 11:43 AM, Bailey Hewitt <bailster at hotmail.com> wrote:
>> Hello,
>>
>>
>> I am a novice in coding in R and have come across an error I am having a hard time fixing. I am trying to use the mblm package to run a Theil-Sen linear model. The code for this function is:
>>
>> mblm(Y ~ X, dataframe, repeated = FALSE)
>>
>> My goal is to put this into a loop so that I can calculate the Theil-Sen slope of each column in my csv. file. The file contains one column of years (x value) and 3 columns of days of the year (y values). All columns are the same length. The code I currently have is:
>>
>>
>> read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>>
>> mydata= read.csv("~/Documents/NH- Lake Mendota_SenSlope_Data2.csv", header = TRUE, sep = ",")
>>
>>
>> attach(mydata)
>>
>>
>> install.packages("mblm")
>>
>> library("mblm")
>>
>>
>> for (i in c(1:3)){
>>
>>   x <- mblm(mydata[,i] ~ Year, mydata, repeated = FALSE)
>>
>>   print(x)
>>
>> }
>>
>>
>> Which gives me the following error:
>>
>> Error in names(res$residuals) = as.character(1:length(res$residuals)) :
>>
>>   'names' attribute [2] must be the same length as the vector [0]
>>
>>
>> Which I cannot seem to solve although as I understand it it is an error that I am causing in the mblm package. If anyone has any insight into how I [[elided Hotmail spam]]
>>
>>
>> Bailey
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
> z.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...
>
>
>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep  4 17:20:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 04 Sep 2016 08:20:06 -0700
Subject: [R] Problem with adding a row in a data table
In-Reply-To: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>
References: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>
Message-ID: <F83F8B66-422C-4626-9549-877C654D0CD5@dcn.davis.ca.us>

The "c" function creates vectors. Rows of data frames are data frames, not vectors.

new_row  <- data.frame( Prod_name = "Day_name",  `Date 1`=1, `Date 2`=2,`Date 3`=3 )
data_may  <- rbind( new_row, data_may )

Furthermore, data frames are NOT spreadsheets. "Day_num" looks suspiciously UNlike a product name, which may mean the corresponding values in that row are not Dates, which would also lead you into trouble.

Please read the Posting Guide. In particular, you should read about making your examples reproducible. Part of that is posting in plain text and using the dput function to give us your sample data, because all too often the problem lies in the details of how you have imported and manipulated your data and the shortest way for us to see that the data are okay is to see it as it exists in your R script so far.
-- 
Sent from my phone. Please excuse my brevity.

On September 4, 2016 6:22:48 AM PDT, Filippos Katsios <katsiosf at gmail.com> wrote:
>Dear All,
>
>I am relatively new to R and certainly new to the e-mailing list. I
>need
>your help. I am working on a data frame, which looks like this:
>
>Prod_name |  Date 1  |  Date 2 |  Date 3  |
>------------------|-------------|------------|--------------|
>Product 1    |     3      |      4     |     0       |
>------------------|-------------|------------|--------------|
>Product 2    |     5      |      3     |     3       |
>------------------|-------------|------------|--------------|
>Product 3    |     2      |      8     |     5       |
>
>I am trying to add a new row with the following results:
>
>Prod_name |  Date 1  |  Date 2 |  Date 3  |
>------------------|-------------|------------|--------------|
>Day_num    |     1      |      2     |      3      |
>------------------|-------------|------------|--------------|
>Product 1    |     3      |      4     |     0       |
>------------------|-------------|------------|--------------|
>Product 2    |     5      |      3     |     3       |
>------------------|-------------|------------|--------------|
>Product 3    |     2      |      8     |     5       |
>
>Bellow you can find the things I tried and the results.
>1)
>r <- 1
>newrow <- rep(1:7, 5, len=ncol(data_may)-1)
>insertRow <- function(data_may, newrow, r) {
>data_may[seq(r+1,nrow(data_may)+1),] <-
>data_may[seq(r,nrow(data_may)),]
>  data_may[r,] <- newrow
>  data_may
>}
>
>It doesn't put the new row.
>2)
>data_may<-rbind(data_may,c("Day_num",newrow))
>
>Error: cannot convert object to a data frame
>
>3)
>data_may[2093,]<-c("Day_num",rep(1:7, 5, len=ncol(data_may)-1))
>
>It makes all the columns characters and when i try to change it it says
>that you can change a list
>
>How can I add the row while keeping the columns (apart from the first
>one)
>as numeric or double or integer?
>
>Thank you, in advance, for your help!
>
>Kind regards
>Filippos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep  4 18:30:37 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 04 Sep 2016 09:30:37 -0700
Subject: [R] Problem with adding a row in a data table
In-Reply-To: <CAETv-pKuQ4xot0hyB=Dc2O5YaLJgOtTFY5U4su-DViRpH8_uTQ@mail.gmail.com>
References: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>
	<F83F8B66-422C-4626-9549-877C654D0CD5@dcn.davis.ca.us>
	<CAETv-pKuQ4xot0hyB=Dc2O5YaLJgOtTFY5U4su-DViRpH8_uTQ@mail.gmail.com>
Message-ID: <231B84E8-FB5C-40A6-BA37-B81BA2073ACB@dcn.davis.ca.us>

Please use Reply-all to keep the mailing list in the loop. I cannot provide private assistance, and others may provide valuable input or respond faster than I can. 

It is very common that people cannot provide the original data. That means more work for YOU, though,  not for us.  It is up to you to create a small simulated data set and process it as if it were your original data. 

Your idea will indeed be a good algorithm, but you will fail in R if you don't set it up differently. Read [1] and provide us with a reproducible example data set and desired result and someone here will be able to show you how to do it correctly. 

[1] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On September 4, 2016 8:28:39 AM PDT, Filippos Katsios <katsiosf at gmail.com> wrote:
>Dear Jeff,
>I am sorry but I am not allowed to share the original data. You are
>right
>about the Prod_name row. However, my goal is to split the columns 
>"Date 1"
>etc into weekdays and weekends and manipulate them separately. I
>thought
>this would be the best way to do that (Assign to each day a number from
>1:7
>and then splitting them by a logical vector). Thank you for your help
>and
>your time!
>
>Filippos
>
>On 4 September 2016 at 18:20, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> The "c" function creates vectors. Rows of data frames are data
>frames, not
>> vectors.
>>
>> new_row  <- data.frame( Prod_name = "Day_name",  `Date 1`=1, `Date
>> 2`=2,`Date 3`=3 )
>> data_may  <- rbind( new_row, data_may )
>>
>> Furthermore, data frames are NOT spreadsheets. "Day_num" looks
>> suspiciously UNlike a product name, which may mean the corresponding
>values
>> in that row are not Dates, which would also lead you into trouble.
>>
>> Please read the Posting Guide. In particular, you should read about
>making
>> your examples reproducible. Part of that is posting in plain text and
>using
>> the dput function to give us your sample data, because all too often
>the
>> problem lies in the details of how you have imported and manipulated
>your
>> data and the shortest way for us to see that the data are okay is to
>see it
>> as it exists in your R script so far.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 4, 2016 6:22:48 AM PDT, Filippos Katsios
><katsiosf at gmail.com>
>> wrote:
>> >Dear All,
>> >
>> >I am relatively new to R and certainly new to the e-mailing list. I
>> >need
>> >your help. I am working on a data frame, which looks like this:
>> >
>> >Prod_name |  Date 1  |  Date 2 |  Date 3  |
>> >------------------|-------------|------------|--------------|
>> >Product 1    |     3      |      4     |     0       |
>> >------------------|-------------|------------|--------------|
>> >Product 2    |     5      |      3     |     3       |
>> >------------------|-------------|------------|--------------|
>> >Product 3    |     2      |      8     |     5       |
>> >
>> >I am trying to add a new row with the following results:
>> >
>> >Prod_name |  Date 1  |  Date 2 |  Date 3  |
>> >------------------|-------------|------------|--------------|
>> >Day_num    |     1      |      2     |      3      |
>> >------------------|-------------|------------|--------------|
>> >Product 1    |     3      |      4     |     0       |
>> >------------------|-------------|------------|--------------|
>> >Product 2    |     5      |      3     |     3       |
>> >------------------|-------------|------------|--------------|
>> >Product 3    |     2      |      8     |     5       |
>> >
>> >Bellow you can find the things I tried and the results.
>> >1)
>> >r <- 1
>> >newrow <- rep(1:7, 5, len=ncol(data_may)-1)
>> >insertRow <- function(data_may, newrow, r) {
>> >data_may[seq(r+1,nrow(data_may)+1),] <-
>> >data_may[seq(r,nrow(data_may)),]
>> >  data_may[r,] <- newrow
>> >  data_may
>> >}
>> >
>> >It doesn't put the new row.
>> >2)
>> >data_may<-rbind(data_may,c("Day_num",newrow))
>> >
>> >Error: cannot convert object to a data frame
>> >
>> >3)
>> >data_may[2093,]<-c("Day_num",rep(1:7, 5, len=ncol(data_may)-1))
>> >
>> >It makes all the columns characters and when i try to change it it
>says
>> >that you can change a list
>> >
>> >How can I add the row while keeping the columns (apart from the
>first
>> >one)
>> >as numeric or double or integer?
>> >
>> >Thank you, in advance, for your help!
>> >
>> >Kind regards
>> >Filippos
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From katsiosf at gmail.com  Sun Sep  4 19:40:04 2016
From: katsiosf at gmail.com (Filippos Katsios)
Date: Sun, 4 Sep 2016 20:40:04 +0300
Subject: [R] Problem with adding a row in a data table
In-Reply-To: <231B84E8-FB5C-40A6-BA37-B81BA2073ACB@dcn.davis.ca.us>
References: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>
	<F83F8B66-422C-4626-9549-877C654D0CD5@dcn.davis.ca.us>
	<CAETv-pKuQ4xot0hyB=Dc2O5YaLJgOtTFY5U4su-DViRpH8_uTQ@mail.gmail.com>
	<231B84E8-FB5C-40A6-BA37-B81BA2073ACB@dcn.davis.ca.us>
Message-ID: <CAETv-p+tw5W+Cf_f8QFBTz4GN+j=jT+HxTe6WrqYLNX=XagMfg@mail.gmail.com>

Dear all,

I believe that this will be a more helpful way to put the problem:
structure(list(Prod_name = c("Banana", "Apple", "Orange", "Yoghurt",
"Eggs", "Milk", "Day_num"), X1.1.2000 = c("1", "0", "4", "3",
"6", "2", "1"), X2.1.2000 = c("2", "4", "1", "5", "3", "0", "2"
), X3.1.2000 = c("1", "5", "2", "3", "0", "4", "3"), X4.1.2000 = c("2",
"4", "4", "1", "0", "0", "4"), X5.1.2000 = c("0", "0", "1", "0",
"2", "3", "5"), X6.1.2000 = c("1", "3", "2", "1", "4", "1", "6"
), X7.1.2000 = c("5", "4", "5", "2", "2", "1", "7")), .Names =
c("Prod_name",
"X1.1.2000", "X2.1.2000", "X3.1.2000", "X4.1.2000", "X5.1.2000",
"X6.1.2000", "X7.1.2000"), row.names = c(NA, 7L), class = "data.frame")

and the code:
https://gist.github.com/anonymous/750b02ad5db448d45c92a79059bf9844

Thank you for your help
Filippos

On 4 September 2016 at 19:30, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please use Reply-all to keep the mailing list in the loop. I cannot
> provide private assistance, and others may provide valuable input or
> respond faster than I can.
>
> It is very common that people cannot provide the original data. That means
> more work for YOU, though,  not for us.  It is up to you to create a small
> simulated data set and process it as if it were your original data.
>
> Your idea will indeed be a good algorithm, but you will fail in R if you
> don't set it up differently. Read [1] and provide us with a reproducible
> example data set and desired result and someone here will be able to show
> you how to do it correctly.
>
> [1] http://adv-r.had.co.nz/Reproducibility.html
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 4, 2016 8:28:39 AM PDT, Filippos Katsios <katsiosf at gmail.com>
> wrote:
> >Dear Jeff,
> >I am sorry but I am not allowed to share the original data. You are
> >right
> >about the Prod_name row. However, my goal is to split the columns
> >"Date 1"
> >etc into weekdays and weekends and manipulate them separately. I
> >thought
> >this would be the best way to do that (Assign to each day a number from
> >1:7
> >and then splitting them by a logical vector). Thank you for your help
> >and
> >your time!
> >
> >Filippos
> >
> >On 4 September 2016 at 18:20, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> The "c" function creates vectors. Rows of data frames are data
> >frames, not
> >> vectors.
> >>
> >> new_row  <- data.frame( Prod_name = "Day_name",  `Date 1`=1, `Date
> >> 2`=2,`Date 3`=3 )
> >> data_may  <- rbind( new_row, data_may )
> >>
> >> Furthermore, data frames are NOT spreadsheets. "Day_num" looks
> >> suspiciously UNlike a product name, which may mean the corresponding
> >values
> >> in that row are not Dates, which would also lead you into trouble.
> >>
> >> Please read the Posting Guide. In particular, you should read about
> >making
> >> your examples reproducible. Part of that is posting in plain text and
> >using
> >> the dput function to give us your sample data, because all too often
> >the
> >> problem lies in the details of how you have imported and manipulated
> >your
> >> data and the shortest way for us to see that the data are okay is to
> >see it
> >> as it exists in your R script so far.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On September 4, 2016 6:22:48 AM PDT, Filippos Katsios
> ><katsiosf at gmail.com>
> >> wrote:
> >> >Dear All,
> >> >
> >> >I am relatively new to R and certainly new to the e-mailing list. I
> >> >need
> >> >your help. I am working on a data frame, which looks like this:
> >> >
> >> >Prod_name |  Date 1  |  Date 2 |  Date 3  |
> >> >------------------|-------------|------------|--------------|
> >> >Product 1    |     3      |      4     |     0       |
> >> >------------------|-------------|------------|--------------|
> >> >Product 2    |     5      |      3     |     3       |
> >> >------------------|-------------|------------|--------------|
> >> >Product 3    |     2      |      8     |     5       |
> >> >
> >> >I am trying to add a new row with the following results:
> >> >
> >> >Prod_name |  Date 1  |  Date 2 |  Date 3  |
> >> >------------------|-------------|------------|--------------|
> >> >Day_num    |     1      |      2     |      3      |
> >> >------------------|-------------|------------|--------------|
> >> >Product 1    |     3      |      4     |     0       |
> >> >------------------|-------------|------------|--------------|
> >> >Product 2    |     5      |      3     |     3       |
> >> >------------------|-------------|------------|--------------|
> >> >Product 3    |     2      |      8     |     5       |
> >> >
> >> >Bellow you can find the things I tried and the results.
> >> >1)
> >> >r <- 1
> >> >newrow <- rep(1:7, 5, len=ncol(data_may)-1)
> >> >insertRow <- function(data_may, newrow, r) {
> >> >data_may[seq(r+1,nrow(data_may)+1),] <-
> >> >data_may[seq(r,nrow(data_may)),]
> >> >  data_may[r,] <- newrow
> >> >  data_may
> >> >}
> >> >
> >> >It doesn't put the new row.
> >> >2)
> >> >data_may<-rbind(data_may,c("Day_num",newrow))
> >> >
> >> >Error: cannot convert object to a data frame
> >> >
> >> >3)
> >> >data_may[2093,]<-c("Day_num",rep(1:7, 5, len=ncol(data_may)-1))
> >> >
> >> >It makes all the columns characters and when i try to change it it
> >says
> >> >that you can change a list
> >> >
> >> >How can I add the row while keeping the columns (apart from the
> >first
> >> >one)
> >> >as numeric or double or integer?
> >> >
> >> >Thank you, in advance, for your help!
> >> >
> >> >Kind regards
> >> >Filippos
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From bob at rud.is  Sun Sep  4 20:34:22 2016
From: bob at rud.is (Bob Rudis)
Date: Sun, 4 Sep 2016 14:34:22 -0400
Subject: [R] impossible # of errors in a simple code
In-Reply-To: <e3359cf2-004e-3751-6261-891447175bf0@dewey.myzen.co.uk>
References: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>
	<e3359cf2-004e-3751-6261-891447175bf0@dewey.myzen.co.uk>
Message-ID: <CAA-FpKX0+61qoLaabzXJbAWL88va41=fvSWW_qZkJ_CjsGnT2w@mail.gmail.com>

pretty sure you just missed the `{` at the beginning of the `function`
definition block.

On Sun, Sep 4, 2016 at 7:38 AM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> A useful rule is to fix the first error you understand and hope that the
> others go away.
>
> On 04/09/2016 04:05, Tamar Michaeli wrote:
>
>> Any help in resolving the following errors will be appreciated:
>>
>> pollutantmean <- function(directory, pollutant, id=1:332)
>>>
>> + file_inc <- list.files("specdata", full.names=TRUE)
>>
>
> So what did you hope your function was going to do, if you called it?
>
> dat <- data.frame()
>>> for(i in 1:10) {
>>>
>> + dat <- rbind(dat, read.csv(file_inc[i]))
>> + }
>> Error in read.table(file = file, header = header, sep = sep, quote =
>> quote,
>>  :
>>   object 'file_inc' not found
>>
>
> Why did you think at this point that you had an object called file_inc?
>
> sulfate <- subset(dat( , 2))
>>>
>> Error in subset(dat(, 2)) : could not find function "dat"
>>
>
> So you did not manage anywhere to define a function called dat.
>
> nitrate <- subset(dat( , 3))
>>>
>> Error in subset(dat(, 3)) : could not find function "dat"
>>
>>> mean(pollutant)
>>>
>> Error in mean(pollutant) : object 'pollutant' not found
>>
>
> You have never defined it.
>
> save"pollutantmean.R"
>>>
>> Error: unexpected string constant in "        save"pollutantmean.R""
>>
>
> ?save might help you here.
>
>
>
>>         [[alternative HTML version deleted]]
>>
>>
>
> Please do not post in HTML as it makes your post unreadable.
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Sep  4 21:21:59 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 4 Sep 2016 12:21:59 -0700
Subject: [R] impossible # of errors in a simple code
In-Reply-To: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>
References: <CACmghhB5DEtQvo1_sZDETANTsDYtSHciBS5GEPajt1Qrefhh+A@mail.gmail.com>
Message-ID: <42CFF6A8-C72D-45B1-8213-301D3E4DB874@comcast.net>


> On Sep 3, 2016, at 8:05 PM, Tamar Michaeli <tmichaeli001 at gmail.com> wrote:
> 
> Any help in resolving the following errors will be appreciated:
> 
>> pollutantmean <- function(directory, pollutant, id=1:332)
> + file_inc <- list.files("specdata", full.names=TRUE)
>> dat <- data.frame()
>> for(i in 1:10) {
> + dat <- rbind(dat, read.csv(file_inc[i]))
> + }
> Error in read.table(file = file, header = header, sep = sep, quote = quote,
> :
>  object 'file_inc' not found
>> sulfate <- subset(dat( , 2))
> Error in subset(dat(, 2)) : could not find function "dat"
>> nitrate <- subset(dat( , 3))
> Error in subset(dat(, 3)) : could not find function "dat"
>> mean(pollutant)
> Error in mean(pollutant) : object 'pollutant' not found
>> save"pollutantmean.R"
> Error: unexpected string constant in "        save"pollutantmean.R""

This is pretty clearly an effort at solving a homework problem for Peng's R Coursera course. Homework questions are off-topic on Rhelp (and are not really encouraged on StackOverflow but you can probably find a worked example there by searching on " [r] pollutant list.files specdata".)  When I tried out the course a few years ago the the participants were advised to post their questions at a website established for the course.

-- 
David.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep  4 22:56:05 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 4 Sep 2016 13:56:05 -0700 (PDT)
Subject: [R] Problem with adding a row in a data table
In-Reply-To: <CAETv-p+tw5W+Cf_f8QFBTz4GN+j=jT+HxTe6WrqYLNX=XagMfg@mail.gmail.com>
References: <CAETv-pKMh5prvVDof=e_mwFjCw0cbFX6ibeDunsWyjrKV3vNiA@mail.gmail.com>
	<F83F8B66-422C-4626-9549-877C654D0CD5@dcn.davis.ca.us>
	<CAETv-pKuQ4xot0hyB=Dc2O5YaLJgOtTFY5U4su-DViRpH8_uTQ@mail.gmail.com>
	<231B84E8-FB5C-40A6-BA37-B81BA2073ACB@dcn.davis.ca.us>
	<CAETv-p+tw5W+Cf_f8QFBTz4GN+j=jT+HxTe6WrqYLNX=XagMfg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609041341580.26242@pedal.dcn.davis.ca.us>

My suggested approach:

dta <- structure(list(Prod_name = c("Banana", "Apple", "Orange", 
"Yoghurt",
"Eggs", "Milk", "Day_num"), X1.1.2000 = c("1", "0", "4", "3",
"6", "2", "1"), X2.1.2000 = c("2", "4", "1", "5", "3", "0", "2"
), X3.1.2000 = c("1", "5", "2", "3", "0", "4", "3"), X4.1.2000 = c("2",
"4", "4", "1", "0", "0", "4"), X5.1.2000 = c("0", "0", "1", "0",
"2", "3", "5"), X6.1.2000 = c("1", "3", "2", "1", "4", "1", "6"
), X7.1.2000 = c("5", "4", "5", "2", "2", "1", "7")), .Names =
c("Prod_name",
"X1.1.2000", "X2.1.2000", "X3.1.2000", "X4.1.2000", "X5.1.2000",
"X6.1.2000", "X7.1.2000"), row.names = c(NA, 7L), class = "data.frame")

# The Day_num values ARE NOT data you will be aggregating and
# should not be in the data frame with meaningful values.
dta <- dta[ 1:6, ] # forget last garbage line
# assuming your data are intended to be numeric
for( i in 2:8 ) {
     dta[[ i ]] <- as.numeric( dta[[ i ]] )
}
# you didn't say what computation you want to accomplish on the data
# assuming you want to add values up by product and part of week

# base R functions
# generally useful to set timezone when using POSIXt types
Sys.setenv( TZ="Etc/GMT" )
# gather data values from multiple columns into long form
# I find this function very confusing, but it does work if you
# don't like depending on contributed packages that are easier to
# understand
dtaLong <- reshape( dta
                   , idvar = "Prod_name"
                   , varying = 1+seq.int( length( dta ) - 1 )
                   , v.names = "value"
                   , timevar = "XDates"
                   , times = names( dta )[ 1+seq.int( length( dta ) - 1 ) ]
                   , direction = "long"
                   )
# extract Date values from column names
dtaLong$Dates <- as.Date( dtaLong$XDates, format="X%d.%m.%Y" )
# read about POSIX types in the help page ?DateTimeClasses
dt_lt <- as.POSIXlt( dtaLong$Dates )
# extract the weekday information from the POSIXlt
dtaLong$wday <- dt_lt$wday # Sunday==0
# identify rows corresponding to time of week
dtaLong$WkPart <- ifelse( dtaLong$wday %in% c( 0, 6 )
                         , "Weekend"
                         , "Weekday" )
# aggregate by sum the value grouping by Prod_name and WkPart
dtaAgg <- aggregate( dtaLong$value
                    , dtaLong[ , c( "Prod_name", "WkPart" ), drop=FALSE ]
                    , FUN=sum
                    )

# or using dplyr/tidyr
library(dplyr)
library(tidyr)
library(lubridate)
# "pipe" data frames from one step to the next
dtaAgg2.a <- (   dta
              # tidyr way of making long form data
              %>% gather( XDates, value, -Prod_name )
              )
# dtaAgg2.a is purely for studying what is happening
dtaAgg2.b <- (   dta
            # tidyr way of making long form data
            %>% gather( XDates, value, -Prod_name )
            %>% mutate( Dates = as.Date( XDates, format="X%d.%m.%Y" )
                      , WkPart = ifelse( wday( Dates ) %in% c( 0, 6 )
                                       , "WeekEnd"
                                       , "WeekDay" )
                      )
            )
# dtaAgg2.b is also for studying what happens
# finally, run the whole pipeline of calculations
dtaAgg2 <- (   dta
            # tidyr way of making long form data
            %>% gather( XDates, value, -Prod_name )
            %>% mutate( Dates = as.Date( XDates, format="X%d.%m.%Y" )
                      , WkPart = ifelse( wday( Dates ) %in% c( 0, 6 )
                                       , "WeekEnd"
                                       , "WeekDay" )
                      )
            %>% group_by( Prod_name, WkPart )
            %>% summarise( SumOfValues = sum( value ) )
            )
# the group_by and summarise steps work together

On Sun, 4 Sep 2016, Filippos Katsios wrote:

> Dear all,
> I believe that this will be a more helpful way to put the problem:
> structure(list(Prod_name = c("Banana", "Apple", "Orange", "Yoghurt",?
> "Eggs", "Milk", "Day_num"), X1.1.2000 = c("1", "0", "4", "3",?
> "6", "2", "1"), X2.1.2000 = c("2", "4", "1", "5", "3", "0", "2"
> ), X3.1.2000 = c("1", "5", "2", "3", "0", "4", "3"), X4.1.2000 = c("2",?
> "4", "4", "1", "0", "0", "4"), X5.1.2000 = c("0", "0", "1", "0",?
> "2", "3", "5"), X6.1.2000 = c("1", "3", "2", "1", "4", "1", "6"
> ), X7.1.2000 = c("5", "4", "5", "2", "2", "1", "7")), .Names = c("Prod_name",?
> "X1.1.2000", "X2.1.2000", "X3.1.2000", "X4.1.2000", "X5.1.2000",?
> "X6.1.2000", "X7.1.2000"), row.names = c(NA, 7L), class = "data.frame")
> 
> and the code:
> https://gist.github.com/anonymous/750b02ad5db448d45c92a79059bf9844
> 
> Thank you for your help
> Filippos
> 
> On 4 September 2016 at 19:30, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>       Please use Reply-all to keep the mailing list in the loop. I cannot provide private assistance,
>       and others may provide valuable input or respond faster than I can.
>
>       It is very common that people cannot provide the original data. That means more work for YOU,
>       though,? not for us.? It is up to you to create a small simulated data set and process it as if
>       it were your original data.
>
>       Your idea will indeed be a good algorithm, but you will fail in R if you don't set it up
>       differently. Read [1] and provide us with a reproducible example data set and desired result and
>       someone here will be able to show you how to do it correctly.
>
>       [1] http://adv-r.had.co.nz/Reproducibility.html
>       --
>       Sent from my phone. Please excuse my brevity.
>
>       On September 4, 2016 8:28:39 AM PDT, Filippos Katsios <katsiosf at gmail.com> wrote:
>       >Dear Jeff,
>       >I am sorry but I am not allowed to share the original data. You are
>       >right
>       >about the Prod_name row. However, my goal is to split the columns
>       >"Date 1"
>       >etc into weekdays and weekends and manipulate them separately. I
>       >thought
>       >this would be the best way to do that (Assign to each day a number from
>       >1:7
>       >and then splitting them by a logical vector). Thank you for your help
>       >and
>       >your time!
>       >
>       >Filippos
>       >
>       >On 4 September 2016 at 18:20, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>       >wrote:
>       >
>       >> The "c" function creates vectors. Rows of data frames are data
>       >frames, not
>       >> vectors.
>       >>
>       >> new_row? <- data.frame( Prod_name = "Day_name",? `Date 1`=1, `Date
>       >> 2`=2,`Date 3`=3 )
>       >> data_may? <- rbind( new_row, data_may )
>       >>
>       >> Furthermore, data frames are NOT spreadsheets. "Day_num" looks
>       >> suspiciously UNlike a product name, which may mean the corresponding
>       >values
>       >> in that row are not Dates, which would also lead you into trouble.
>       >>
>       >> Please read the Posting Guide. In particular, you should read about
>       >making
>       >> your examples reproducible. Part of that is posting in plain text and
>       >using
>       >> the dput function to give us your sample data, because all too often
>       >the
>       >> problem lies in the details of how you have imported and manipulated
>       >your
>       >> data and the shortest way for us to see that the data are okay is to
>       >see it
>       >> as it exists in your R script so far.
>       >> --
>       >> Sent from my phone. Please excuse my brevity.
>       >>
>       >> On September 4, 2016 6:22:48 AM PDT, Filippos Katsios
>       ><katsiosf at gmail.com>
>       >> wrote:
>       >> >Dear All,
>       >> >
>       >> >I am relatively new to R and certainly new to the e-mailing list. I
>       >> >need
>       >> >your help. I am working on a data frame, which looks like this:
>       >> >
>       >> >Prod_name |? Date 1? |? Date 2 |? Date 3? |
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 1? ? |? ? ?3? ? ? |? ? ? 4? ? ?|? ? ?0? ? ? ?|
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 2? ? |? ? ?5? ? ? |? ? ? 3? ? ?|? ? ?3? ? ? ?|
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 3? ? |? ? ?2? ? ? |? ? ? 8? ? ?|? ? ?5? ? ? ?|
>       >> >
>       >> >I am trying to add a new row with the following results:
>       >> >
>       >> >Prod_name |? Date 1? |? Date 2 |? Date 3? |
>       >> >------------------|-------------|------------|--------------|
>       >> >Day_num? ? |? ? ?1? ? ? |? ? ? 2? ? ?|? ? ? 3? ? ? |
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 1? ? |? ? ?3? ? ? |? ? ? 4? ? ?|? ? ?0? ? ? ?|
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 2? ? |? ? ?5? ? ? |? ? ? 3? ? ?|? ? ?3? ? ? ?|
>       >> >------------------|-------------|------------|--------------|
>       >> >Product 3? ? |? ? ?2? ? ? |? ? ? 8? ? ?|? ? ?5? ? ? ?|
>       >> >
>       >> >Bellow you can find the things I tried and the results.
>       >> >1)
>       >> >r <- 1
>       >> >newrow <- rep(1:7, 5, len=ncol(data_may)-1)
>       >> >insertRow <- function(data_may, newrow, r) {
>       >> >data_may[seq(r+1,nrow(data_may)+1),] <-
>       >> >data_may[seq(r,nrow(data_may)),]
>       >> >? data_may[r,] <- newrow
>       >> >? data_may
>       >> >}
>       >> >
>       >> >It doesn't put the new row.
>       >> >2)
>       >> >data_may<-rbind(data_may,c("Day_num",newrow))
>       >> >
>       >> >Error: cannot convert object to a data frame
>       >> >
>       >> >3)
>       >> >data_may[2093,]<-c("Day_num",rep(1:7, 5, len=ncol(data_may)-1))
>       >> >
>       >> >It makes all the columns characters and when i try to change it it
>       >says
>       >> >that you can change a list
>       >> >
>       >> >How can I add the row while keeping the columns (apart from the
>       >first
>       >> >one)
>       >> >as numeric or double or integer?
>       >> >
>       >> >Thank you, in advance, for your help!
>       >> >
>       >> >Kind regards
>       >> >Filippos
>       >> >
>       >> >? ? ? ?[[alternative HTML version deleted]]
>       >> >
>       >> >______________________________________________
>       >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>       >> >https://stat.ethz.ch/mailman/listinfo/r-help
>       >> >PLEASE do read the posting guide
>       >> >http://www.R-project.org/posting-guide.html
>       >> >and provide commented, minimal, self-contained, reproducible code.
>       >>
>       >>
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From utz.ryan at gmail.com  Sun Sep  4 23:57:37 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Sun, 4 Sep 2016 17:57:37 -0400
Subject: [R] Treating a vector of characters as object names to create list
Message-ID: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>

Hello,

I have a vector of characters that I know will be object names and I'd like
to treat this vector as a series of names to create a list. But, for the
life of me, I cannot figure out how to treat a vector of characters as a
vector of object names when creating a list.

For example, this does exactly what I want to do (with 'merged.parameters'
as the end goal):

###
merging=c('alkalinity','iron')
alkalinity=c('39086','29801','90410','00410')
iron=c('01045','01046')
merged.parameters=list(alkalinity,iron)
###

But, say I have many, many parameters in 'merging' beyond alkalinity and
iron and I'd like to just cleanly turn the elements in 'merging' into a
list. This does not work:

###
merged.parameters=list(get(merging))
###

because it's only grabbing the first element of 'merging', for some reason.
Any advice? This feels like it really should be easy...

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep  5 00:07:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Sep 2016 15:07:42 -0700
Subject: [R] Treating a vector of characters as object names to create
	list
In-Reply-To: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
References: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
Message-ID: <CAGxFJbQrnxPbN+r3HDVOyDBrUaZz3hi1tf_XGwwGQAMwJ+2q4A@mail.gmail.com>

Time for an R tutorial or two to learn how to use the "apply" family
in R. I think what you want is:

merged_list <- lapply(merging, get)


-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 2:57 PM, Ryan Utz <utz.ryan at gmail.com> wrote:
> Hello,
>
> I have a vector of characters that I know will be object names and I'd like
> to treat this vector as a series of names to create a list. But, for the
> life of me, I cannot figure out how to treat a vector of characters as a
> vector of object names when creating a list.
>
> For example, this does exactly what I want to do (with 'merged.parameters'
> as the end goal):
>
> ###
> merging=c('alkalinity','iron')
> alkalinity=c('39086','29801','90410','00410')
> iron=c('01045','01046')
> merged.parameters=list(alkalinity,iron)
> ###
>
> But, say I have many, many parameters in 'merging' beyond alkalinity and
> iron and I'd like to just cleanly turn the elements in 'merging' into a
> list. This does not work:
>
> ###
> merged.parameters=list(get(merging))
> ###
>
> because it's only grabbing the first element of 'merging', for some reason.
> Any advice? This feels like it really should be easy...
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Sep  5 00:07:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 5 Sep 2016 08:07:47 +1000
Subject: [R] Treating a vector of characters as object names to create
	list
In-Reply-To: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
References: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
Message-ID: <CA+8X3fU0=-Z-SQUm5zSRyDCdFR2+H_YB3BMxMxiVGP+bVQ_uaw@mail.gmail.com>

Hi Ryan,
How about:

names(merged.parameters)<-merging

Jim


On Mon, Sep 5, 2016 at 7:57 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
> Hello,
>
> I have a vector of characters that I know will be object names and I'd like
> to treat this vector as a series of names to create a list. But, for the
> life of me, I cannot figure out how to treat a vector of characters as a
> vector of object names when creating a list.
>
> For example, this does exactly what I want to do (with 'merged.parameters'
> as the end goal):
>
> ###
> merging=c('alkalinity','iron')
> alkalinity=c('39086','29801','90410','00410')
> iron=c('01045','01046')
> merged.parameters=list(alkalinity,iron)
> ###
>
> But, say I have many, many parameters in 'merging' beyond alkalinity and
> iron and I'd like to just cleanly turn the elements in 'merging' into a
> list. This does not work:
>
> ###
> merged.parameters=list(get(merging))
> ###
>
> because it's only grabbing the first element of 'merging', for some reason.
> Any advice? This feels like it really should be easy...
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth.denes at ttk.mta.hu  Mon Sep  5 01:13:56 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Mon, 5 Sep 2016 01:13:56 +0200
Subject: [R] Treating a vector of characters as object names to create
 list
In-Reply-To: <CAGxFJbQrnxPbN+r3HDVOyDBrUaZz3hi1tf_XGwwGQAMwJ+2q4A@mail.gmail.com>
References: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
	<CAGxFJbQrnxPbN+r3HDVOyDBrUaZz3hi1tf_XGwwGQAMwJ+2q4A@mail.gmail.com>
Message-ID: <57CCAAB4.5020906@ttk.mta.hu>



On 09/05/2016 12:07 AM, Bert Gunter wrote:
> Time for an R tutorial or two to learn how to use the "apply" family
> in R. I think what you want is:
>
> merged_list <- lapply(merging, get)
>

Or even:
named_merged_list <- mget(merging)

Anyway, probably you could arrive to a list of parameters directly. 
(E.g., if you import the parameter values from an external source or if 
they are the return values of a function, etc.).

>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 4, 2016 at 2:57 PM, Ryan Utz <utz.ryan at gmail.com> wrote:
>> Hello,
>>
>> I have a vector of characters that I know will be object names and I'd like
>> to treat this vector as a series of names to create a list. But, for the
>> life of me, I cannot figure out how to treat a vector of characters as a
>> vector of object names when creating a list.
>>
>> For example, this does exactly what I want to do (with 'merged.parameters'
>> as the end goal):
>>
>> ###
>> merging=c('alkalinity','iron')
>> alkalinity=c('39086','29801','90410','00410')
>> iron=c('01045','01046')
>> merged.parameters=list(alkalinity,iron)
>> ###
>>
>> But, say I have many, many parameters in 'merging' beyond alkalinity and
>> iron and I'd like to just cleanly turn the elements in 'merging' into a
>> list. This does not work:
>>
>> ###
>> merged.parameters=list(get(merging))
>> ###
>>
>> because it's only grabbing the first element of 'merging', for some reason.
>> Any advice? This feels like it really should be easy...
>>
>> --
>>
>> Ryan Utz, Ph.D.
>> Assistant professor of water resources
>> *chatham**UNIVERSITY*
>> Home/Cell: (724) 272-7769
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Mon Sep  5 01:24:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Sep 2016 16:24:45 -0700
Subject: [R] Treating a vector of characters as object names to create
	list
In-Reply-To: <57CCAAB4.5020906@ttk.mta.hu>
References: <CAKJ8KVhr7D41iThsL6bYNDZKTASaKQMk=eanm4fw2K2-0k2ntA@mail.gmail.com>
	<CAGxFJbQrnxPbN+r3HDVOyDBrUaZz3hi1tf_XGwwGQAMwJ+2q4A@mail.gmail.com>
	<57CCAAB4.5020906@ttk.mta.hu>
Message-ID: <CAGxFJbT-R99GGXRExsRga4gAWF9bkWWLWf+w5gk9ez-z5XidTw@mail.gmail.com>

Thank you, D?nes. Better yet.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 4:13 PM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
>
>
> On 09/05/2016 12:07 AM, Bert Gunter wrote:
>>
>> Time for an R tutorial or two to learn how to use the "apply" family
>> in R. I think what you want is:
>>
>> merged_list <- lapply(merging, get)
>>
>
> Or even:
> named_merged_list <- mget(merging)
>
> Anyway, probably you could arrive to a list of parameters directly. (E.g.,
> if you import the parameter values from an external source or if they are
> the return values of a function, etc.).
>
>>
>> -- Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Sep 4, 2016 at 2:57 PM, Ryan Utz <utz.ryan at gmail.com> wrote:
>>>
>>> Hello,
>>>
>>> I have a vector of characters that I know will be object names and I'd
>>> like
>>> to treat this vector as a series of names to create a list. But, for the
>>> life of me, I cannot figure out how to treat a vector of characters as a
>>> vector of object names when creating a list.
>>>
>>> For example, this does exactly what I want to do (with
>>> 'merged.parameters'
>>> as the end goal):
>>>
>>> ###
>>> merging=c('alkalinity','iron')
>>> alkalinity=c('39086','29801','90410','00410')
>>> iron=c('01045','01046')
>>> merged.parameters=list(alkalinity,iron)
>>> ###
>>>
>>> But, say I have many, many parameters in 'merging' beyond alkalinity and
>>> iron and I'd like to just cleanly turn the elements in 'merging' into a
>>> list. This does not work:
>>>
>>> ###
>>> merged.parameters=list(get(merging))
>>> ###
>>>
>>> because it's only grabbing the first element of 'merging', for some
>>> reason.
>>> Any advice? This feels like it really should be easy...
>>>
>>> --
>>>
>>> Ryan Utz, Ph.D.
>>> Assistant professor of water resources
>>> *chatham**UNIVERSITY*
>>> Home/Cell: (724) 272-7769
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From dusa.adrian at unibuc.ro  Mon Sep  5 01:47:36 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 5 Sep 2016 02:47:36 +0300
Subject: [R] evaluating expressions as R console
Message-ID: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>

Dear R users,

I am trying to simulate a pseudo R console, evaluating commands. This is a
simple example of a series of command lines which get evaluated:

foo <- function(x) {
    print(x)
}
print)foo)
foo(2)


If I copied and pasted this example in an R console, this is the result to
replicate (and the benchmark to compare everything else):

> foo <- function(x) {
+     print(x)
+ }
> print)foo)
Error: unexpected ')' in "print)"
> foo(2)
[1] 2


The trouble I'm having is to reproduce this exact output, by evaluating the
chunk of code. I tried both Rscript and littler, but I am unable to
reproduce this.

I had some success via:

R CMD BATCH -q foo.R

(saving the chunk to a file called foo.R), which only works until the first
error appears. I can run it again on the subsequent command(s) after the
error, but the function foo(), which in a normal R console gets created
without any error, doesn't get preserved on the next run.

I also had some limited success with:

source("foo.R", echo = TRUE, keep.source = TRUE)

But the error message is different, and the first 4 lines are not echo-ed.

source() works pretty well if there are no errors, but otherwise I get the
same result as R CMD BATCH, namely only the error is displayed and the
function foo() doesn't get created in the current environment.

I would rather use source() than R CMD BATCH, due to specific environments
where the chunk should be evaluated in (not impossible, but inconvenient to
save environments and load them back in the R CMD BATCH).

Was also curious about knitr and pander, but again unable to replicate the
results in the real R console.

After many hours of searching, reading and testing, I would be grateful for
any hint.

Thank you in advance,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep  5 01:52:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Sep 2016 16:52:38 -0700
Subject: [R] evaluating expressions as R console
In-Reply-To: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>
References: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>
Message-ID: <CAGxFJbQAVm06acNaERzxjReU3YBWRKgTNn+wd2YeDyn0qxOAgw@mail.gmail.com>

You might want to look at the "evaluate" package.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 4:47 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> Dear R users,
>
> I am trying to simulate a pseudo R console, evaluating commands. This is a
> simple example of a series of command lines which get evaluated:
>
> foo <- function(x) {
>     print(x)
> }
> print)foo)
> foo(2)
>
>
> If I copied and pasted this example in an R console, this is the result to
> replicate (and the benchmark to compare everything else):
>
>> foo <- function(x) {
> +     print(x)
> + }
>> print)foo)
> Error: unexpected ')' in "print)"
>> foo(2)
> [1] 2
>
>
> The trouble I'm having is to reproduce this exact output, by evaluating the
> chunk of code. I tried both Rscript and littler, but I am unable to
> reproduce this.
>
> I had some success via:
>
> R CMD BATCH -q foo.R
>
> (saving the chunk to a file called foo.R), which only works until the first
> error appears. I can run it again on the subsequent command(s) after the
> error, but the function foo(), which in a normal R console gets created
> without any error, doesn't get preserved on the next run.
>
> I also had some limited success with:
>
> source("foo.R", echo = TRUE, keep.source = TRUE)
>
> But the error message is different, and the first 4 lines are not echo-ed.
>
> source() works pretty well if there are no errors, but otherwise I get the
> same result as R CMD BATCH, namely only the error is displayed and the
> function foo() doesn't get created in the current environment.
>
> I would rather use source() than R CMD BATCH, due to specific environments
> where the chunk should be evaluated in (not impossible, but inconvenient to
> save environments and load them back in the R CMD BATCH).
>
> Was also curious about knitr and pander, but again unable to replicate the
> results in the real R console.
>
> After many hours of searching, reading and testing, I would be grateful for
> any hint.
>
> Thank you in advance,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Mon Sep  5 06:06:59 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Mon, 5 Sep 2016 00:06:59 -0400
Subject: [R] element wise pattern recognition and string substitution
Message-ID: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>

Dear list,

I have a vector of strings that cannot be described by one pattern. So
let's say I construct a vector of patterns in the same length as the vector
of strings, can I do the element wise pattern recognition and string
substitution.

For example,

pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"

patterns <- c(pattern1,pattern2)
strings <- c('TX.WT.CUT.mean','mg.tx.cv')

Say I want to extract "WT.CUT" from the first string and "tx" from the
second string. If I do

sub(patterns, '\\2', strings), only the first pattern will be used.

looping the patterns doesn't work the way I want. Appreciate any comments.
Thanks.

Jun

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Sep  5 06:30:43 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 4 Sep 2016 21:30:43 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
Message-ID: <C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>

Your opening assertion is false. 

Provide a reproducible example and someone will demonstrate. 
-- 
Sent from my phone. Please excuse my brevity.

On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com> wrote:
>Dear list,
>
>I have a vector of strings that cannot be described by one pattern. So
>let's say I construct a vector of patterns in the same length as the
>vector
>of strings, can I do the element wise pattern recognition and string
>substitution.
>
>For example,
>
>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>
>patterns <- c(pattern1,pattern2)
>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>
>Say I want to extract "WT.CUT" from the first string and "tx" from the
>second string. If I do
>
>sub(patterns, '\\2', strings), only the first pattern will be used.
>
>looping the patterns doesn't work the way I want. Appreciate any
>comments.
>Thanks.
>
>Jun
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep  5 07:41:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Sep 2016 22:41:45 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
Message-ID: <CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>

Well, he did provide an example, and...


> z <- c('TX.WT.CUT.mean','mg.tx.cv')

> sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
[1] "WT.CUT" "tx"


## seems to do what was requested.

Jeff would have to amplify on his initial statement however: do you
mean that separate patterns can always be combined via "|" ?  Or
something deeper?

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Your opening assertion is false.
>
> Provide a reproducible example and someone will demonstrate.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com> wrote:
>>Dear list,
>>
>>I have a vector of strings that cannot be described by one pattern. So
>>let's say I construct a vector of patterns in the same length as the
>>vector
>>of strings, can I do the element wise pattern recognition and string
>>substitution.
>>
>>For example,
>>
>>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>
>>patterns <- c(pattern1,pattern2)
>>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>
>>Say I want to extract "WT.CUT" from the first string and "tx" from the
>>second string. If I do
>>
>>sub(patterns, '\\2', strings), only the first pattern will be used.
>>
>>looping the patterns doesn't work the way I want. Appreciate any
>>comments.
>>Thanks.
>>
>>Jun
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From elisabetta.petracci at gmail.com  Mon Sep  5 11:42:40 2016
From: elisabetta.petracci at gmail.com (Elisabetta Petracci)
Date: Mon, 5 Sep 2016 11:42:40 +0200
Subject: [R] conditional gap time frailty cox model for recurrent events
Message-ID: <CAOJF0JfnO-anu_xvogPK26dd+O5+sFVXyT9-EjfjDYK+HC27Fg@mail.gmail.com>

Dear users,

I am fitting a conditional gap time frailty cox model weighting
observations by means of inverse probability time dependent weigths.
Attached find the self-explaining dataset.

I have used the following sintax:

coxph(Surv(gaptstart,gaptstop,status)~treat+strata(nrecord01)+frailty(id,distribution="gamma",method="em"),
data=dataNOTDrr,weights=dataNOTDrr$weight)


And I get the following warning:

Warning message:
In coxpenal.fit(X, Y, strats, offset, init = init, control, weights =
weights,  :
  Inner loop failed to coverge for iterations 3 4


I have tried to:
- leave out the weights but I get the error anyway
- to randomly select a subset of patients and I don't get the error. This
seems to suggest that the problem is with some observations.

Any suggestion?

Many thanks,

Elisabetta

From goran.brostrom at umu.se  Mon Sep  5 12:06:15 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Mon, 5 Sep 2016 12:06:15 +0200
Subject: [R] conditional gap time frailty cox model for recurrent events
In-Reply-To: <CAOJF0JfnO-anu_xvogPK26dd+O5+sFVXyT9-EjfjDYK+HC27Fg@mail.gmail.com>
References: <CAOJF0JfnO-anu_xvogPK26dd+O5+sFVXyT9-EjfjDYK+HC27Fg@mail.gmail.com>
Message-ID: <b751d30e-04b4-75cb-f3b4-1aadf0f9116c@umu.se>

Dear Elisabetta,

I have no direct answer to your question, but a suggestion: Use the 
'coxme' function (in the package with the same name). In the help page 
for 'frailty' (survival) you will find: "The coxme package has 
superseded this method. It is faster, more stable, and more flexible."

Hth, G?ran

On 2016-09-05 11:42, Elisabetta Petracci wrote:
> Dear users,
>
> I am fitting a conditional gap time frailty cox model weighting
> observations by means of inverse probability time dependent weigths.
> Attached find the self-explaining dataset.
>
> I have used the following sintax:
>
> coxph(Surv(gaptstart,gaptstop,status)~treat+strata(nrecord01)+frailty(id,distribution="gamma",method="em"),
> data=dataNOTDrr,weights=dataNOTDrr$weight)
>
>
> And I get the following warning:
>
> Warning message:
> In coxpenal.fit(X, Y, strats, offset, init = init, control, weights =
> weights,  :
>   Inner loop failed to coverge for iterations 3 4
>
>
> I have tried to:
> - leave out the weights but I get the error anyway
> - to randomly select a subset of patients and I don't get the error. This
> seems to suggest that the problem is with some observations.
>
> Any suggestion?
>
> Many thanks,
>
> Elisabetta
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ingfimo at gmail.com  Mon Sep  5 12:11:53 2016
From: ingfimo at gmail.com (Filippo Monari)
Date: Mon, 5 Sep 2016 11:11:53 +0100
Subject: [R] Fwd: Splines
In-Reply-To: <57cbd777.4abf1c0a.491f2.f85b@mx.google.com>
References: <57cbd777.4abf1c0a.491f2.f85b@mx.google.com>
Message-ID: <57CD44E9.6040609@gmail.com>

Hi,
does anybody know what header file includes the bspline functions used in R?

Regards,
Filippo


-------- Forwarded Message --------
Subject: 	Splines
Date: 	Sun, 04 Sep 2016 09:12:37 +0100
From: 	Filippo Monari <ingfimo at gmail.com>
To: 	R-help at r-project.org



Hi,
I would like to use the C spline functions if R for a FORTRAN subroutine. What header file should I refer to?

Regards
Filippo Monari




	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Mon Sep  5 13:51:33 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Mon, 5 Sep 2016 12:51:33 +0100
Subject: [R] substring simultaneous conditions
Message-ID: <CAB630FFDeXLx=wt3o3jvXRg+HNysimVho_nTE-pT_NKSj6FH+A@mail.gmail.com>

Dear all,

I have searched all over and didn?t found an answer :( Sorry, I'm new.

I need urgently to "not analyse"the weight the ID's that have 07 in the
position 3 and 4 respectively, 01 or 11 in positions 11 and 12 of ID
variable. .

I used the following code:

base<--baseR[substr(baseR$'ID',3,4)!='03'
                      &substr(baseR$'ID',11,12)!='01'
                       &substr(baseR$'ID',11,12)!='11',]

But, instead of removing just the id's that respect the 3 conditions
simultaneously, base don't have all the id's that have 03 in the 3 and 4
positions os id variable, neither 01  in positions 11 and 12 of ID, neither 11
in positions 11 and 12 of ID variable.variable.

So, it seems, that the code exclude all the conditions, as it was a OR (|)
condition in spite of AND (&) condition.

Can anyone help me please?

I attach the data.

Best,
Rosa Oliveira

__________________________________

Antes de imprimir este e-mail pense bem se tem mesmo que o fazer.
H? cada vez menos ?rvores.
N?o imprima, pense na sua responsabilidade e compromisso com o MEIO
AMBIENTE!
<http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
<http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>

From J.Hillier at lboro.ac.uk  Mon Sep  5 14:19:23 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Mon, 5 Sep 2016 12:19:23 +0000
Subject: [R] sim() not working in example given in lava() documentation -
 please help.
Message-ID: <DB5PR04MB1496E0E1559693E4604FE25FA1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>

Dear All,

I am trying to simulate using a statistical model created in the lava() package.  My model gave the error message "Error in rep(0, ncol(fx)) : invalid 'times' argument". So, I used the example in the documentation for the lava() package - v1.4.4, on page 79; this is copied below with the output.  It did the same thing.

I can plot and view the model, so it appears to have been created correctly.

I am relative new to this, so don't have a good idea of where to start when a standard example fails like this. I have tried naive fiddling with the code, and Googling.  Any advice would be much appreciated.

Thank you

John

> ##################################################
> ## Logistic regression
> ##################################################
> m <- lvm(y~x+z)
> regression(m) <- x~z
> distribution(m,~y+z) <- binomial.lvm("logit")
> d <- sim(m,1e3)
Error in rep(0, ncol(fx)) : invalid 'times' argument




-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Mon Sep  5 14:41:57 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 05 Sep 2016 12:41:57 +0000
Subject: [R] substring simultaneous conditions
In-Reply-To: <CAB630FFDeXLx=wt3o3jvXRg+HNysimVho_nTE-pT_NKSj6FH+A@mail.gmail.com>
References: <CAB630FFDeXLx=wt3o3jvXRg+HNysimVho_nTE-pT_NKSj6FH+A@mail.gmail.com>
Message-ID: <CAKVAULNK4Gyp34-WW5=hg5kwjt+rrkxYDV_XAv2q7_nbOsiEXg@mail.gmail.com>

Dear Rosa,

you can use grep for pattern matching along the lines of:

x <- c("000711111101", "000711111111", "000711111112","123456789123")

grep("^[0-9]{2}07[0-9]{6}(01|11)", x)

Here I assume that your real IDs consist of integers only. The pattern
matches two integers followed by 07 followed by 6 integers and finally 01
or 11

Hope this helps,
Ulrik

On Mon, 5 Sep 2016 at 13:54 Rosa Oliveira <rosita21 at gmail.com> wrote:

> Dear all,
>
> I have searched all over and didn?t found an answer :( Sorry, I'm new.
>
> I need urgently to "not analyse"the weight the ID's that have 07 in the
> position 3 and 4 respectively, 01 or 11 in positions 11 and 12 of ID
> variable. .
>
> I used the following code:
>
> base<--baseR[substr(baseR$'ID',3,4)!='03'
>                       &substr(baseR$'ID',11,12)!='01'
>                        &substr(baseR$'ID',11,12)!='11',]
>
> But, instead of removing just the id's that respect the 3 conditions
> simultaneously, base don't have all the id's that have 03 in the 3 and 4
> positions os id variable, neither 01  in positions 11 and 12 of ID,
> neither 11
> in positions 11 and 12 of ID variable.variable.
>
> So, it seems, that the code exclude all the conditions, as it was a OR (|)
> condition in spite of AND (&) condition.
>
> Can anyone help me please?
>
> I attach the data.
>
> Best,
> Rosa Oliveira
>
> __________________________________
>
> Antes de imprimir este e-mail pense bem se tem mesmo que o fazer.
> H? cada vez menos ?rvores.
> N?o imprima, pense na sua responsabilidade e compromisso com o MEIO
> AMBIENTE!
> <
> http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg
> >
> <
> http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg
> >
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Sep  5 14:41:38 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 05 Sep 2016 13:41:38 +0100
Subject: [R] substring simultaneous conditions
In-Reply-To: <CAB630FFDeXLx=wt3o3jvXRg+HNysimVho_nTE-pT_NKSj6FH+A@mail.gmail.com>
Message-ID: <20160905134138.Horde.XEZkgqMdWDMQ25nPZAoTwJm@mail.sapo.pt>

Hello,

Try placing the & immediately after the substr() conditions, like this:


base <- baseR[substr(baseR[['ID']],3,4)!='03' &
                         substr(baseR[['ID']],11,12)!='01' &
                         substr(baseR[['ID']],11,12)!='11',]


Maybe I'm wrong but R might have decided that the instructions were  
complete before the next lines were reached.
And your attachment didn't make through. Use dput to post a data example.

dput(head(baseR, 30))  #paste the output of this in a mail


Hope this helps,

Rui Barradas




Citando Rosa Oliveira <rosita21 at gmail.com>:

> Dear all,
>
> I have searched all over and didn?t found an answer :( Sorry, I'm new.
>
> I need urgently to "not analyse"the weight the ID's that have 07 in the
> position 3 and 4 respectively, 01 or 11 in positions 11 and 12 of ID
> variable. .
>
> I used the following code:
>
> base<--baseR[substr(baseR$'ID',3,4)!='03'
>                       &substr(baseR$'ID',11,12)!='01'
>                        &substr(baseR$'ID',11,12)!='11',]
>
> But, instead of removing just the id's that respect the 3 conditions
> simultaneously, base don't have all the id's that have 03 in the 3 and 4
> positions os id variable, neither 01  in positions 11 and 12 of ID,  
> neither 11
> in positions 11 and 12 of ID variable.variable.
>
> So, it seems, that the code exclude all the conditions, as it was a OR (|)
> condition in spite of AND (&) condition.
>
> Can anyone help me please?
>
> I attach the data.
>
> Best,
> Rosa Oliveira
>
> __________________________________
>
> Antes de imprimir este e-mail pense bem se tem mesmo que o fazer.
> H? cada vez menos ?rvores.
> N?o imprima, pense na sua responsabilidade e compromisso com o MEIO
> AMBIENTE!
> <http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
> <http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Sep  5 15:01:52 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 5 Sep 2016 13:01:52 +0000
Subject: [R] sim() not working in example given in lava() documentation
 - please help.
In-Reply-To: <DB5PR04MB1496E0E1559693E4604FE25FA1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>
References: <DB5PR04MB1496E0E1559693E4604FE25FA1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B8D8@SRVEXCHMBX.precheza.cz>

Hi

I do not know anything about lava, however this

m <- lvm(y~x+z)
regression(m) <- x~z
distribution(m,~y+z) <- binomial.lvm("logit")
d <- sim(m,1e3)
head(d)
  y          x z
1 1  1.0033540 1
2 0  0.3834120 0
3 1 -0.3737790 1
4 1 -1.2927288 0
5 0 -0.4242461 1
6 0 -1.8349548 0
>

gives me some result without any error.

So obviosly something is broken in your side. Try to start clean R session and try this code again.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Hillier
> Sent: Monday, September 5, 2016 2:19 PM
> To: r-help mailing list <R-help at r-project.org>
> Subject: [R] sim() not working in example given in lava() documentation -
> please help.
>
> Dear All,
>
> I am trying to simulate using a statistical model created in the lava() package.
> My model gave the error message "Error in rep(0, ncol(fx)) : invalid 'times'
> argument". So, I used the example in the documentation for the lava()
> package - v1.4.4, on page 79; this is copied below with the output.  It did the
> same thing.
>
> I can plot and view the model, so it appears to have been created correctly.
>
> I am relative new to this, so don't have a good idea of where to start when a
> standard example fails like this. I have tried naive fiddling with the code, and
> Googling.  Any advice would be much appreciated.
>
> Thank you
>
> John
>
> > ##################################################
> > ## Logistic regression
> > ##################################################
> > m <- lvm(y~x+z)
> > regression(m) <- x~z
> > distribution(m,~y+z) <- binomial.lvm("logit")
> > d <- sim(m,1e3)
> Error in rep(0, ncol(fx)) : invalid 'times' argument
>
>
>
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From J.Hillier at lboro.ac.uk  Mon Sep  5 15:35:05 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Mon, 5 Sep 2016 13:35:05 +0000
Subject: [R] sim() not working in example given in lava() documentation
 - please help.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B8D8@SRVEXCHMBX.precheza.cz>
References: <DB5PR04MB1496E0E1559693E4604FE25FA1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B8D8@SRVEXCHMBX.precheza.cz>
Message-ID: <DB5PR04MB1496D1B8F1307E963FF42F75A1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>

Thank you very much Petr! An external check like you did really helps.


After shutting down, I've started new session and project in a different directory and it's working.


I will know next time that with R a full "turn it off and turn it on again" can make a difference even when I can't see why it should :-)


John


-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727
________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: 05 September 2016 14:01:52
To: John Hillier; r-help mailing list
Subject: RE: [R] sim() not working in example given in lava() documentation - please help.

Hi

I do not know anything about lava, however this

m <- lvm(y~x+z)
regression(m) <- x~z
distribution(m,~y+z) <- binomial.lvm("logit")
d <- sim(m,1e3)
head(d)
  y          x z
1 1  1.0033540 1
2 0  0.3834120 0
3 1 -0.3737790 1
4 1 -1.2927288 0
5 0 -0.4242461 1
6 0 -1.8349548 0
>

gives me some result without any error.

So obviosly something is broken in your side. Try to start clean R session and try this code again.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Hillier
> Sent: Monday, September 5, 2016 2:19 PM
> To: r-help mailing list <R-help at r-project.org>
> Subject: [R] sim() not working in example given in lava() documentation -
> please help.
>
> Dear All,
>
> I am trying to simulate using a statistical model created in the lava() package.
> My model gave the error message "Error in rep(0, ncol(fx)) : invalid 'times'
> argument". So, I used the example in the documentation for the lava()
> package - v1.4.4, on page 79; this is copied below with the output.  It did the
> same thing.
>
> I can plot and view the model, so it appears to have been created correctly.
>
> I am relative new to this, so don't have a good idea of where to start when a
> standard example fails like this. I have tried naive fiddling with the code, and
> Googling.  Any advice would be much appreciated.
>
> Thank you
>
> John
>
> > ##################################################
> > ## Logistic regression
> > ##################################################
> > m <- lvm(y~x+z)
> > regression(m) <- x~z
> > distribution(m,~y+z) <- binomial.lvm("logit")
> > d <- sim(m,1e3)
> Error in rep(0, ncol(fx)) : invalid 'times' argument
>
>
>
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Sep  5 15:57:04 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 5 Sep 2016 13:57:04 +0000
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+8X3fWVAaKeWSF3JZvbBO1XqY+W6yWmdLFLZV_crKO+ZrdSQg@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
	<CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
	<CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>
	<CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>
	<CA+8X3fWVAaKeWSF3JZvbBO1XqY+W6yWmdLFLZV_crKO+ZrdSQg@mail.gmail.com>
Message-ID: <b5220ee5850a4ef3ac9b87b568ef8f82@exch-2p-mbx-w2.ads.tamu.edu>

Try changing the separator to ;

# write.table() instead of write.csv()
> write.table(Dat, "Dat.csv", quote = FALSE, sep=";", row.names = FALSE)
> readLines("Dat.csv")
[1] "col 1;col 2;col 3;col 4;col 5;col 6"         
[2] "133261;aaa1;10.59;10.59;10.59;04-Jul-16"     
[3] "133261;aaa2;10.56;10.56;10.56;05-Jul-16"     
[4] "133262;bbb1, bbb;10.59;10.59;10.59;04-Jul-16"
[5] "133262;bbb3, bbb;10.56;10.56;10.56;05-Jul-16"
# Note read.csv2.sql() not read.csv.sql()
> read.csv2.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName", header=TRUE)
Error in sqliteSendQuery(con, statement, bind.data) : 
  error in statement: no such column: ReadName
In addition: Warning message:
closing unused connection 3 (Dat.csv)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Sunday, September 4, 2016 6:39 AM
To: Christofer Bogaso
Cc: r-help
Subject: Re: [R] Error in reading subset of data from CSV file

Shouldn't get that with write.csv.

Jim


On Sun, Sep 4, 2016 at 9:29 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Didnt work.... getting unused argument error.
>
> On Sun, Sep 4, 2016 at 4:47 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> I suppose you could try quote=TRUE
>>
>> Jim
>>
>>
>> On Sun, Sep 4, 2016 at 8:13 PM, Christofer Bogaso
>> <bogaso.christofer at gmail.com> wrote:
>>> Thanks Jim. But my data is like that and I have to live with that. Any
>>> idea on workaround. Thanks,
>>>
>>> On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> Hi Christofer,
>>>> You have embedded commas in your data structure. This is guaranteed to
>>>> mess up a CSV read.
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
>>>> <bogaso.christofer at gmail.com> wrote:
>>>>> Hi again,
>>>>>
>>>>> I was trying to read a subset of Data from a CSV file using below code
>>>>> as example :
>>>>>
>>>>> library(sqldf)
>>>>>
>>>>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>>>>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>>>>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>>>>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>>>>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>>>>> c("04-Jul-16",
>>>>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>>>>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>>>>> -4L))
>>>>> Dat
>>>>>
>>>>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>>>>
>>>>> ReadName = '133261'
>>>>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>>>>
>>>>> Loading required package: tcltk
>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>>>   line 1 did not have 7 elements
>>>>>
>>>>> This code generates above Error. Could you please help me with a
>>>>> pointer where something went wrong? My actual CSV file is quite huge
>>>>> so I cant read it as whole. However basic structure of my original
>>>>> file is similar as above "Dat"
>>>>>
>>>>> Thanks for your time.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Sep  5 16:05:41 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 5 Sep 2016 14:05:41 +0000
Subject: [R] sim() not working in example given in lava() documentation
 - please help.
In-Reply-To: <DB5PR04MB1496D1B8F1307E963FF42F75A1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>
References: <DB5PR04MB1496E0E1559693E4604FE25FA1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B8D8@SRVEXCHMBX.precheza.cz>
	<DB5PR04MB1496D1B8F1307E963FF42F75A1E60@DB5PR04MB1496.eurprd04.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B913@SRVEXCHMBX.precheza.cz>

Hi

First I thought that it could be due to variables which can be defined in your workspace however I had also x and y defined and did not experience error. I tried with the code with m, z, logit and lvm silly defined as variables but I did not experience any error too.

So I have no clue how you managed to get such error.

Cheers
Petr



From: John Hillier [mailto:J.Hillier at lboro.ac.uk]
Sent: Monday, September 5, 2016 3:35 PM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <R-help at r-project.org>
Subject: Re: [R] sim() not working in example given in lava() documentation - please help.


Thank you very much Petr! An external check like you did really helps.



After shutting down, I've started new session and project in a different directory and it's working.



I will know next time that with R a full "turn it off and turn it on again" can make a difference even when I can't see why it should :-)



John


-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727
________________________________
From: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Sent: 05 September 2016 14:01:52
To: John Hillier; r-help mailing list
Subject: RE: [R] sim() not working in example given in lava() documentation - please help.

Hi

I do not know anything about lava, however this

m <- lvm(y~x+z)
regression(m) <- x~z
distribution(m,~y+z) <- binomial.lvm("logit")
d <- sim(m,1e3)
head(d)
  y          x z
1 1  1.0033540 1
2 0  0.3834120 0
3 1 -0.3737790 1
4 1 -1.2927288 0
5 0 -0.4242461 1
6 0 -1.8349548 0
>

gives me some result without any error.

So obviosly something is broken in your side. Try to start clean R session and try this code again.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Hillier
> Sent: Monday, September 5, 2016 2:19 PM
> To: r-help mailing list <R-help at r-project.org<mailto:R-help at r-project.org>>
> Subject: [R] sim() not working in example given in lava() documentation -
> please help.
>
> Dear All,
>
> I am trying to simulate using a statistical model created in the lava() package.
> My model gave the error message "Error in rep(0, ncol(fx)) : invalid 'times'
> argument". So, I used the example in the documentation for the lava()
> package - v1.4.4, on page 79; this is copied below with the output.  It did the
> same thing.
>
> I can plot and view the model, so it appears to have been created correctly.
>
> I am relative new to this, so don't have a good idea of where to start when a
> standard example fails like this. I have tried naive fiddling with the code, and
> Googling.  Any advice would be much appreciated.
>
> Thank you
>
> John
>
> > ##################################################
> > ## Logistic regression
> > ##################################################
> > m <- lvm(y~x+z)
> > regression(m) <- x~z
> > distribution(m,~y+z) <- binomial.lvm("logit")
> > d <- sim(m,1e3)
> Error in rep(0, ncol(fx)) : invalid 'times' argument
>
>
>
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Sep  5 17:37:08 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 5 Sep 2016 08:37:08 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
Message-ID: <0AE632C9-BD2B-4662-90F2-F575B66E81D0@dcn.davis.ca.us>

Yes, sorry I did not look closer... regex can match any finite language, so there are no data sets you can feed to R that cannot be matched. [1] You may find it hard to see the pattern, or you may want to build the pattern programmatically to alleviate tedium for yourself, but regexes are not the constraint. 

http://www.cs.nuim.ie/~jpower/Courses/Previous/parsing/node18.html
-- 
Sent from my phone. Please excuse my brevity.

On September 4, 2016 10:41:45 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Well, he did provide an example, and...
>
>
>> z <- c('TX.WT.CUT.mean','mg.tx.cv')
>
>> sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>[1] "WT.CUT" "tx"
>
>
>## seems to do what was requested.
>
>Jeff would have to amplify on his initial statement however: do you
>mean that separate patterns can always be combined via "|" ?  Or
>something deeper?
>
>Cheers,
>Bert
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Your opening assertion is false.
>>
>> Provide a reproducible example and someone will demonstrate.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
>wrote:
>>>Dear list,
>>>
>>>I have a vector of strings that cannot be described by one pattern.
>So
>>>let's say I construct a vector of patterns in the same length as the
>>>vector
>>>of strings, can I do the element wise pattern recognition and string
>>>substitution.
>>>
>>>For example,
>>>
>>>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>
>>>patterns <- c(pattern1,pattern2)
>>>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>
>>>Say I want to extract "WT.CUT" from the first string and "tx" from
>the
>>>second string. If I do
>>>
>>>sub(patterns, '\\2', strings), only the first pattern will be used.
>>>
>>>looping the patterns doesn't work the way I want. Appreciate any
>>>comments.
>>>Thanks.
>>>
>>>Jun
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dusa.adrian at unibuc.ro  Mon Sep  5 17:39:06 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 5 Sep 2016 18:39:06 +0300
Subject: [R] evaluating expressions as R console
In-Reply-To: <CAGxFJbS4ZRKCn8iBptv7iDjx87=8hFUKAzuV9VtPx_mdMqhE4w@mail.gmail.com>
References: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>
	<CAGxFJbQAVm06acNaERzxjReU3YBWRKgTNn+wd2YeDyn0qxOAgw@mail.gmail.com>
	<CAJ=0CtAJnPJg6nJESS32_FYUGNqMzd6494g-eDjUHkaPKY0Y=w@mail.gmail.com>
	<CAGxFJbS4ZRKCn8iBptv7iDjx87=8hFUKAzuV9VtPx_mdMqhE4w@mail.gmail.com>
Message-ID: <CAJ=0CtA-r5WO7X=OoneQmejTfuQ=70RptxNdKZbMOBAOxB0Nqg@mail.gmail.com>

On Mon, Sep 5, 2016 at 5:33 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I'm sharing this with r-help, as your detailed response might help
> others help you.


Oh, my bad (thought I had replied to all).
I wanted to add anyways the intended result seems to be possible. If
pasting the code here...:
http://www.tutorialspoint.com/r_terminal_online.php

... the result is exactly as in the R console.

Maybe this is a different technology (direct websocket?), but if they are
evaluating the text they're doing a very good job.

Best,
Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From Kristina.Loderer at psy.lmu.de  Mon Sep  5 17:47:32 2016
From: Kristina.Loderer at psy.lmu.de (Kristina Loderer)
Date: Mon, 05 Sep 2016 17:47:32 +0200
Subject: [R] Antw: Re:  robumeta package - error
In-Reply-To: <e0c344bf-425f-ee71-892b-39305958d23e@dewey.myzen.co.uk>
References: <57C878E0020000D900041FBD@f11-gwia-1.fak11.uni-muenchen.de>
	<e0c344bf-425f-ee71-892b-39305958d23e@dewey.myzen.co.uk>
Message-ID: <57CDAFB4020000D900042100@f11-gwia-1.fak11.uni-muenchen.de>

Dear Michael,

thank you for your reply! I managed to solve the problem in the
meantime, there was an issue in the effect size conversion (correlations
to Fisher's z) that lead to zero values for some effect size variances. 

Regards,
Kristina


-----------------------------------------
Kristina Loderer
Ludwig-Maximilians-Universit?t M?nchen
Department Psychologie
Leopoldstr. 13
D-80802 M?nchen

Telefon: +49 (89) 2180-6047
Email: Kristina.Loderer at psy.lmu.de

-----------------------------------------
>>> Michael Dewey <lists at dewey.myzen.co.uk> 02.09.16 13.38 Uhr >>>
Dear Kristina

I do not use that package so cannot offer any direct help but

1 - can you fit the model with any other combination of parameters?
2 - what happens if you vary rho?
3 - if your data-set is small and not confidential can you share it, 
otherwise can you show us str(anxiety_control) or 
summary(anxiety_control) preferable without any variables you are not 
using in this model?
4 - there is a robust option in Wolfgang Viechtbauer's metafor package 
which might help although I am not sure how equivalent the analysis 
approaches are.

On 01/09/2016 17:52, Kristina Loderer wrote:
> Dear all,
>
> I am trying to fit a simple (intercept-only) meta-analytic model using
> the robumeta package using the following code:
>  anx_cont_mean<-robu(formula = es_fisher ~ 1, var.eff.size =
> variance_fisher, studynum = study_ID, modelweights = "CORR", rho =
0.8,
> small=TRUE, data = anxiety_control)
>
> When I try to run this model, the following error message pops up:
> Error in solve.default(sumXWX) :
>   system is computationally singular: reciprocal condition number = 0
>
> What exactly does this mean in the context of meta-analysis? I haven't
> been able to find any answers.
>
> Thank you,
> Kristina
>
>
> -----------------------------------------
> Kristina Loderer
> Ludwig-Maximilians-Universit?t M?nchen
> Department Psychologie
> Leopoldstr. 13
> D-80802 M?nchen
>
> Telefon: +49 (89) 2180-6047
> Email: Kristina.Loderer at psy.lmu.de
>
> -----------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From jdnewmil at dcn.davis.ca.us  Mon Sep  5 17:58:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Sep 2016 08:58:34 -0700
Subject: [R] Fwd: Splines
In-Reply-To: <57CD44E9.6040609@gmail.com>
References: <57cbd777.4abf1c0a.491f2.f85b@mx.google.com>
	<57CD44E9.6040609@gmail.com>
Message-ID: <E71A80E0-B477-44BC-AE4A-739B550943E9@dcn.davis.ca.us>

This is not the kind of thing people know off the top of their heads, and even if they do it is an ideal application of text search tools. Download the source and start looking. Don't neglect the licencing terms... your use of that code implies responsibilities on your part. 
-- 
Sent from my phone. Please excuse my brevity.

On September 5, 2016 3:11:53 AM PDT, Filippo Monari <ingfimo at gmail.com> wrote:
>Hi,
>does anybody know what header file includes the bspline functions used
>in R?
>
>Regards,
>Filippo
>
>
>-------- Forwarded Message --------
>Subject: 	Splines
>Date: 	Sun, 04 Sep 2016 09:12:37 +0100
>From: 	Filippo Monari <ingfimo at gmail.com>
>To: 	R-help at r-project.org
>
>
>
>Hi,
>I would like to use the C spline functions if R for a FORTRAN
>subroutine. What header file should I refer to?
>
>Regards
>Filippo Monari
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep  5 18:01:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Sep 2016 09:01:12 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <0AE632C9-BD2B-4662-90F2-F575B66E81D0@dcn.davis.ca.us>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<0AE632C9-BD2B-4662-90F2-F575B66E81D0@dcn.davis.ca.us>
Message-ID: <CAGxFJbQmdNNpwUr5HOT+xNAPqPH6sH+Vwdn5FZdL5ypagWbPuw@mail.gmail.com>

Jeff:

It is not obvious to me that the ability to *match* an arbitrary
pattern (including one of several different ones via "|" , per the
link you included) implies that sub() and friends can extract it, e.g.
via the /N construct or otherwise.  I would appreciate it if you or
someone else could show me how this can be done.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 5, 2016 at 8:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Yes, sorry I did not look closer... regex can match any finite language, so there are no data sets you can feed to R that cannot be matched. [1] You may find it hard to see the pattern, or you may want to build the pattern programmatically to alleviate tedium for yourself, but regexes are not the constraint.
>
> http://www.cs.nuim.ie/~jpower/Courses/Previous/parsing/node18.html
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 4, 2016 10:41:45 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>Well, he did provide an example, and...
>>
>>
>>> z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>
>>> sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>[1] "WT.CUT" "tx"
>>
>>
>>## seems to do what was requested.
>>
>>Jeff would have to amplify on his initial statement however: do you
>>mean that separate patterns can always be combined via "|" ?  Or
>>something deeper?
>>
>>Cheers,
>>Bert
>>Bert Gunter
>>
>>"The trouble with having an open mind is that people keep coming along
>>and sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Your opening assertion is false.
>>>
>>> Provide a reproducible example and someone will demonstrate.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
>>wrote:
>>>>Dear list,
>>>>
>>>>I have a vector of strings that cannot be described by one pattern.
>>So
>>>>let's say I construct a vector of patterns in the same length as the
>>>>vector
>>>>of strings, can I do the element wise pattern recognition and string
>>>>substitution.
>>>>
>>>>For example,
>>>>
>>>>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>>
>>>>patterns <- c(pattern1,pattern2)
>>>>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>
>>>>Say I want to extract "WT.CUT" from the first string and "tx" from
>>the
>>>>second string. If I do
>>>>
>>>>sub(patterns, '\\2', strings), only the first pattern will be used.
>>>>
>>>>looping the patterns doesn't work the way I want. Appreciate any
>>>>comments.
>>>>Thanks.
>>>>
>>>>Jun
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Mon Sep  5 18:44:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 5 Sep 2016 09:44:36 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbQmdNNpwUr5HOT+xNAPqPH6sH+Vwdn5FZdL5ypagWbPuw@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<0AE632C9-BD2B-4662-90F2-F575B66E81D0@dcn.davis.ca.us>
	<CAGxFJbQmdNNpwUr5HOT+xNAPqPH6sH+Vwdn5FZdL5ypagWbPuw@mail.gmail.com>
Message-ID: <24193BF2-B894-4D9E-8A59-A74FCF57969A@dcn.davis.ca.us>

I am not the one who proved this... I can only respond to your suggested counterexamples.
-- 
Sent from my phone. Please excuse my brevity.

On September 5, 2016 9:01:12 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Jeff:
>
>It is not obvious to me that the ability to *match* an arbitrary
>pattern (including one of several different ones via "|" , per the
>link you included) implies that sub() and friends can extract it, e.g.
>via the /N construct or otherwise.  I would appreciate it if you or
>someone else could show me how this can be done.
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Mon, Sep 5, 2016 at 8:37 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Yes, sorry I did not look closer... regex can match any finite
>language, so there are no data sets you can feed to R that cannot be
>matched. [1] You may find it hard to see the pattern, or you may want
>to build the pattern programmatically to alleviate tedium for yourself,
>but regexes are not the constraint.
>>
>> http://www.cs.nuim.ie/~jpower/Courses/Previous/parsing/node18.html
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 4, 2016 10:41:45 PM PDT, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>>>Well, he did provide an example, and...
>>>
>>>
>>>> z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>
>>>> sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>>[1] "WT.CUT" "tx"
>>>
>>>
>>>## seems to do what was requested.
>>>
>>>Jeff would have to amplify on his initial statement however: do you
>>>mean that separate patterns can always be combined via "|" ?  Or
>>>something deeper?
>>>
>>>Cheers,
>>>Bert
>>>Bert Gunter
>>>
>>>"The trouble with having an open mind is that people keep coming
>along
>>>and sticking things into it."
>>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>>On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>><jdnewmil at dcn.davis.ca.us> wrote:
>>>> Your opening assertion is false.
>>>>
>>>> Provide a reproducible example and someone will demonstrate.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On September 4, 2016 9:06:59 PM PDT, Jun Shen
><jun.shen.ut at gmail.com>
>>>wrote:
>>>>>Dear list,
>>>>>
>>>>>I have a vector of strings that cannot be described by one pattern.
>>>So
>>>>>let's say I construct a vector of patterns in the same length as
>the
>>>>>vector
>>>>>of strings, can I do the element wise pattern recognition and
>string
>>>>>substitution.
>>>>>
>>>>>For example,
>>>>>
>>>>>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>>>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>>>
>>>>>patterns <- c(pattern1,pattern2)
>>>>>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>>
>>>>>Say I want to extract "WT.CUT" from the first string and "tx" from
>>>the
>>>>>second string. If I do
>>>>>
>>>>>sub(patterns, '\\2', strings), only the first pattern will be used.
>>>>>
>>>>>looping the patterns doesn't work the way I want. Appreciate any
>>>>>comments.
>>>>>Thanks.
>>>>>
>>>>>Jun
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From jun.shen.ut at gmail.com  Mon Sep  5 18:56:32 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Mon, 5 Sep 2016 12:56:32 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
Message-ID: <CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>

Thanks for the reply, Bert.

Your solution solves the example. I actually have a more general situation
where I have this dot concatenated string from multiple variables. The
problem is those variables may have values with dots in there. The number
of dots are not consistent for all values of a variable. So I am thinking
to define a vector of patterns for the vector of the string and hopefully
to find a way to use a pattern from the pattern vector for each value of
the string vector. The only way I can think of is "for" loop, which can be
slow. Also these are happening in a function I am writing. Just wonder if
there is another more efficient way. Thanks a lot.

Jun

On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Well, he did provide an example, and...
>
>
> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>
> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> [1] "WT.CUT" "tx"
>
>
> ## seems to do what was requested.
>
> Jeff would have to amplify on his initial statement however: do you
> mean that separate patterns can always be combined via "|" ?  Or
> something deeper?
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> > Your opening assertion is false.
> >
> > Provide a reproducible example and someone will demonstrate.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
> wrote:
> >>Dear list,
> >>
> >>I have a vector of strings that cannot be described by one pattern. So
> >>let's say I construct a vector of patterns in the same length as the
> >>vector
> >>of strings, can I do the element wise pattern recognition and string
> >>substitution.
> >>
> >>For example,
> >>
> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >>
> >>patterns <- c(pattern1,pattern2)
> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>
> >>Say I want to extract "WT.CUT" from the first string and "tx" from the
> >>second string. If I do
> >>
> >>sub(patterns, '\\2', strings), only the first pattern will be used.
> >>
> >>looping the patterns doesn't work the way I want. Appreciate any
> >>comments.
> >>Thanks.
> >>
> >>Jun
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep  5 21:11:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Sep 2016 12:11:06 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
Message-ID: <CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>

Jun:

You need to provide a clear specification via regular expressions of
the patterns you wish to match -- at least for me to decipher it.
Others may be smarter than I, though...

Jeff: Thanks. I have now convinced myself that it can be done (a
"proof" of sorts): If pat1, pat2,..., patn are m different patterns
(in a vector of patterns)  to be matched in a vector of n strings,
where only one of the patterns will match in any string,  then use
paste() (probably via do.call()) or otherwise to paste them together
separated by "|" to form the concatenated pattern, pat. Then

sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)

should extract the matching pattern in each (perhaps with a little
fiddling due to precedence rules); e.g.

> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")

> pat1 <- "a+\\.*a+"
> pat2 <-"b+\\.*b+"
> pat <- c(pat1,pat2)

> pat <- do.call(paste,c(as.list(pat), sep="|"))
> pat
[1] "a+\\.*a+|b+\\.*b+"

> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
[1] "a.a"   "bb"    "b.bbb"

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Thanks for the reply, Bert.
>
> Your solution solves the example. I actually have a more general situation
> where I have this dot concatenated string from multiple variables. The
> problem is those variables may have values with dots in there. The number of
> dots are not consistent for all values of a variable. So I am thinking to
> define a vector of patterns for the vector of the string and hopefully to
> find a way to use a pattern from the pattern vector for each value of the
> string vector. The only way I can think of is "for" loop, which can be slow.
> Also these are happening in a function I am writing. Just wonder if there is
> another more efficient way. Thanks a lot.
>
> Jun
>
> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Well, he did provide an example, and...
>>
>>
>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>
>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> [1] "WT.CUT" "tx"
>>
>>
>> ## seems to do what was requested.
>>
>> Jeff would have to amplify on his initial statement however: do you
>> mean that separate patterns can always be combined via "|" ?  Or
>> something deeper?
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> > Your opening assertion is false.
>> >
>> > Provide a reproducible example and someone will demonstrate.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
>> > wrote:
>> >>Dear list,
>> >>
>> >>I have a vector of strings that cannot be described by one pattern. So
>> >>let's say I construct a vector of patterns in the same length as the
>> >>vector
>> >>of strings, can I do the element wise pattern recognition and string
>> >>substitution.
>> >>
>> >>For example,
>> >>
>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >>
>> >>patterns <- c(pattern1,pattern2)
>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>
>> >>Say I want to extract "WT.CUT" from the first string and "tx" from the
>> >>second string. If I do
>> >>
>> >>sub(patterns, '\\2', strings), only the first pattern will be used.
>> >>
>> >>looping the patterns doesn't work the way I want. Appreciate any
>> >>comments.
>> >>Thanks.
>> >>
>> >>Jun
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From dusa.adrian at unibuc.ro  Mon Sep  5 23:28:39 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 6 Sep 2016 00:28:39 +0300
Subject: [R] evaluating expressions as R console
In-Reply-To: <CAGxFJbS4ZRKCn8iBptv7iDjx87=8hFUKAzuV9VtPx_mdMqhE4w@mail.gmail.com>
References: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>
	<CAGxFJbQAVm06acNaERzxjReU3YBWRKgTNn+wd2YeDyn0qxOAgw@mail.gmail.com>
	<CAJ=0CtAJnPJg6nJESS32_FYUGNqMzd6494g-eDjUHkaPKY0Y=w@mail.gmail.com>
	<CAGxFJbS4ZRKCn8iBptv7iDjx87=8hFUKAzuV9VtPx_mdMqhE4w@mail.gmail.com>
Message-ID: <CAJ=0CtBuD6F5OXzHcPP8x=V3aOZQzxV8kym=NhzhSDYDHOb6+Q@mail.gmail.com>

I think I have found a working solution. Rather ugly, but working and will
keep looking for better alternatives, though.

The procedure involves:

- parsing one line at a time
- if incomplete, parse as many lines as necessary to form an expression
- determine all expressions in the original input
- evaluate each expression, one at a time
  (which shows individual errors and warnings)
- print each pair of:
    - expression
    - error, or result with possible warning(s)

It works reasonably quick for small chunks, but that is ok for my purposes.

I hope it helps anyone. Should there be better alternatives, I would be
more than grateful for a hint.

Best,
Adrian

On Mon, Sep 5, 2016 at 5:33 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I'm sharing this with r-help, as your detailed response might help
> others help you.
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 4, 2016 at 11:45 PM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
> > On Mon, Sep 5, 2016 at 2:52 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> You might want to look at the "evaluate" package.
> >
> >
> > Of course, forgot to mention. I did try it, but got:
> >
> >> bar <- readLines("foo.R", warn = FALSE)
> >> bar <- paste(bar, collapse = "\n")
> >> evaluate::evaluate(input = bar)
> > [[1]]
> > $src
> > [1] "foo <- function(x) {\n    print(x)\n}\nprint)foo)\nfoo(2)"
> >
> > attr(,"class")
> > [1] "source"
> >
> > [[2]]
> > <simpleError: <text>:4:6: unexpected ')'
> > 3: }
> > 4: print)
> >         ^>
> >
> > I ran into the same problem as source(): it works only if it doesn't have
> > any errors. In addition, the error message is also different because it
> > evaluates the entire chunk, whereas the R console evaluates one command
> > (line) at a time.
> >
> > Fixing the command:
> > bar2 <- "foo <- function(x) {\n    print(x)\n}\nprint(foo)\nfoo(2)"
> >
> > will fix the workflow in evaluate():
> >
> > evaluate::evaluate(input = bar2)
> >
> >
> > But it will also fix it with source():
> >
> >> source("foo2.R", echo = TRUE, keep.source = TRUE)
> >
> >> foo <- function(x) {
> > +     print(x)
> > + }
> >
> >> print(foo)
> > function(x) {
> >     print(x)
> > }
> >
> >> foo(2)
> > [1] 2
> >
> >
> > So evaluate() has more detail than source(), but essentially they do the
> > same thing in evaluating the whole chunk. From the help of source():
> > "Since the complete file is parsed before any of it is run, syntax errors
> > result in none of the code being run."
> >
> > So far, it seems that only R CMD BATCH is able to run one command at a
> time:
> >
> > $ R CMD BATCH -q foo.R
> > $ cat foo.Rout
> >> foo <- function(x) {
> > +     print(x)
> > + }
> >> print)foo)
> > Error: unexpected ')' in "print)"
> > Execution halted
> >
> > This error is exactly the same as in the R console, and the function
> foo()
> > is created before the error occurs. One possible solution is to get the
> > workspace saved, and run R CMD BATCH again on the rest of commands after
> the
> > error.
> >
> > But it still needs additional objects if the chunk is to be evaluated in
> a
> > specific environment. This is the point where I've got, and I don't know
> if
> > this is the best approach.
> >
> > Thank you,
> > Adrian
>


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From erikareb at gmail.com  Mon Sep  5 20:25:42 2016
From: erikareb at gmail.com (=?UTF-8?Q?Erika_Roc=C3=ADo_Espinosa_Balbuena?=)
Date: Mon, 5 Sep 2016 13:25:42 -0500
Subject: [R] Help with a code in R
Message-ID: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>

Hi,

I am working with this code:

forecast_nal<-data.frame()
out<-vector()
x<-foreach(i=1:nrow(comb)) %do%
{

s<-comb[i,'prod_id']

#Familia+Sumbarca+prod_id
#Serie

bcomb1<-b
bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
bcomb1<-arrange(bcomb1,year,week)
a<-bcomb1[1:1,'week']
d<-bcomb1[1:1,'year']
f<-nrow(bcomb1)
h<-bcomb1[f:f,'year']
j<-bcomb1[f:f,'week']
bcomb1<-bcomb1[,c(6)]

if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48))
{
out[i]<-s
}
else
{
       y <- ts(bcomb1, frequency=52, start=c(d, a))
##Casos

if (length(y)<=60)
{

v<-auto.arima(y)
v<-arimaorder(v)
fit <- arima(y, order = v ,method="ML")
      fca <- forecast(fit, h = 16)
dates <- attr(forecast_nal$mean, "tsp")
datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
fct<-cbind.data.frame(s,datecol,Point=fca$mean)
forecast_nal<- rbind.data.frame(forecast_nal,fct)
}
else
{

fit <- tbats(y)
fcb <- forecast(fit, h = 16)
dates <- attr(forecast_nal$mean, "tsp")
datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
            forecast_nal<- rbind.data.frame(forecast_nal,fct)
}
}
}
 But I am getting this error:

Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833, 26750.9374514082,
 :
  only replacement of elements is allowed

Can someone help me with this?

Thanks


-- 
Erika Roc?o Espinosa Balbuena

	[[alternative HTML version deleted]]


From abdoulayesar at gmail.com  Mon Sep  5 11:38:41 2016
From: abdoulayesar at gmail.com (Abdoulaye Sarr)
Date: Mon, 5 Sep 2016 09:38:41 +0000
Subject: [R] Fwd:  problem writing .bil files in netcdf
In-Reply-To: <15835E09-A95B-49F8-A574-F0307A3C25E0@gmail.com>
References: <9B68B493-7492-4CB6-A5C5-72C724E4483E@gmail.com>
	<CAAcGz9_v8UOic5Rc5yNCuCsQaRupr6WY=5cLQ4hEuUcM-jT=TQ@mail.gmail.com>
	<15835E09-A95B-49F8-A574-F0307A3C25E0@gmail.com>
Message-ID: <CAN=6O0LfVMaEdc58k-x7yV2aCtesxJDDusZHuPuMdM8LHk+yYw@mail.gmail.com>

---------- Forwarded message ----------
From: Abdoulaye SARR <abdoulayesar at gmail.com>
Date: Mon, Jan 1, 2001 at 4:02 AM
Subject: Re: [R] problem writing .bil files in netcdf
To: Michael Sumner <mdsumner at gmail.com>
Cc: r-help at r-project.org


Hi Michael,

I had a problem with my mac hopefully solve now.


For the  issue i submitted, I tried your suggestion with writeRaster which
creates a netcdf file. The problem when I look the results by displaying as
graph I seen the
values starting by -9000 and mainly are located in the continent
boundaries, so how to add in write taste the undef values and have precip
from 0 to x.


For the loop if successful is toe write each day in a separate netcdf file,
if done it will be easy to concatenate using nco or cdo.
To convert each day in netcdf I need to have an appropriate loop in a
script. I have to process many years.

Cheers,


Le 2 sept. 2016 ? 15:09, Michael Sumner <mdsumner at gmail.com> a ?crit :



On Fri, 2 Sep 2016 at 00:43 Abdoulaye SARR <abdoulayesar at gmail.com> wrote:

> Dear List,
>
> I have daily rainfall data in .bil format and can get info of the file
> using rgdal:
>
> > library(rgdal)
> > GDALinfo("/1981/v2p19810101.bil")
> rows        1600
> columns     1500
> bands       1
> lower left origin.x        -20
> lower left origin.y        -40
> res.x       0.05
> res.y       0.05
> ysign       -1
> oblique.x   0
> oblique.y   0
> driver      EHdr
> projection  NA
>
> How can I read all daily file and write them as netcdf files and
> concatenate as one yearly file and also avoid boundary pixels alter
> rainfall values.
>
>
Hi,

You can read the single .bil and write it to NetCDF with raster (and the
rgdal and ncdf4) package:

 library(raster)
r <- raster("/1981/v2p19810101.bil")
writeRaster(r, "v2p19810101.nc")

But, if you read in multi .bil files and build a multilayer raster, i.e.

st <- stack(list.files("/1981", pattern = "bil$", full.names = TRUE))

you *can* write it out to NetCDF, very similar to above with writeRaster,
but I think it will generate a variable (an netcdf array) for each layer.

To really write to .nc in a specific way you'll need to delve into the
standard tools in ncdf4, to create a file, create
variables/dimensions/attributes,
and then populate the variable, in this case probably one 3rd-level slice
for each .bil. That might be better done at the command line, say with nco
(the "nc operators"). There are copy-create idioms which is probably the
way to go if you have a template data file or CDF specification.

There may be some higher level tools in other packages on CRAN, check the
reverse depends/imports/suggests on CRAN for ncdf4. Also you should explore
RNetCDF which has an independent implementation.

 (raster really blitzes the field in terms of high-level tools here, but it
has limits, with writing NetCDF *in specific ways* being one of them. GDAL
has similar limitations, since it sees the world in this
"array-as-2d-bands" way).

HTH, at least a little.

Cheers, Mike.

Best regards,
>
> Eus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.
> org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Mon Sep  5 13:38:02 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Mon, 5 Sep 2016 12:38:02 +0100
Subject: [R] outliers in Box Plot
Message-ID: <CAB630FGxSdXQ+zPMNVYMdtKb7i9j8rOX2qf31OZ0mm25TvCFRA@mail.gmail.com>

Dear all,

I have searched all over and didn?t found an answer :(

I need urgently to "extract" de identification of the weight outliers of
the participants of a study.

So, I have a data base with several variables:
id
weight
are 2 off them.

So, I've done a boxplot and found the weight have outliers. Now I need to
identify the id's of those participants.
I can get the outliers values, nonetheless lots os them are not correct for
some vriables.

Can you please help me?

boxplot(WEIGHT~AGE,baseR,range=3)     #print WEIGHT boxplot
boxplot(WEIGHT~AGE==1,,baseR,range=3, plot=FALSE)$out      # find outliers
values to age 1 (example)


I attach the data.

Best,
Rosa Oliveira

__________________________________

Antes de imprimir este e-mail pense bem se tem mesmo que o fazer.
H? cada vez menos ?rvores.
N?o imprima, pense na sua responsabilidade e compromisso com o MEIO
AMBIENTE!
<http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
<http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>

From bgunter.4567 at gmail.com  Mon Sep  5 16:33:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Sep 2016 07:33:17 -0700
Subject: [R] evaluating expressions as R console
In-Reply-To: <CAJ=0CtAJnPJg6nJESS32_FYUGNqMzd6494g-eDjUHkaPKY0Y=w@mail.gmail.com>
References: <CAJ=0CtAPguqh6MEF2XQxq3KkPjAaKwsueg46G131yCF2=JEqFA@mail.gmail.com>
	<CAGxFJbQAVm06acNaERzxjReU3YBWRKgTNn+wd2YeDyn0qxOAgw@mail.gmail.com>
	<CAJ=0CtAJnPJg6nJESS32_FYUGNqMzd6494g-eDjUHkaPKY0Y=w@mail.gmail.com>
Message-ID: <CAGxFJbS4ZRKCn8iBptv7iDjx87=8hFUKAzuV9VtPx_mdMqhE4w@mail.gmail.com>

I'm sharing this with r-help, as your detailed response might help
others help you.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 4, 2016 at 11:45 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> On Mon, Sep 5, 2016 at 2:52 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> You might want to look at the "evaluate" package.
>
>
> Of course, forgot to mention. I did try it, but got:
>
>> bar <- readLines("foo.R", warn = FALSE)
>> bar <- paste(bar, collapse = "\n")
>> evaluate::evaluate(input = bar)
> [[1]]
> $src
> [1] "foo <- function(x) {\n    print(x)\n}\nprint)foo)\nfoo(2)"
>
> attr(,"class")
> [1] "source"
>
> [[2]]
> <simpleError: <text>:4:6: unexpected ')'
> 3: }
> 4: print)
>         ^>
>
> I ran into the same problem as source(): it works only if it doesn't have
> any errors. In addition, the error message is also different because it
> evaluates the entire chunk, whereas the R console evaluates one command
> (line) at a time.
>
> Fixing the command:
> bar2 <- "foo <- function(x) {\n    print(x)\n}\nprint(foo)\nfoo(2)"
>
> will fix the workflow in evaluate():
>
> evaluate::evaluate(input = bar2)
>
>
> But it will also fix it with source():
>
>> source("foo2.R", echo = TRUE, keep.source = TRUE)
>
>> foo <- function(x) {
> +     print(x)
> + }
>
>> print(foo)
> function(x) {
>     print(x)
> }
>
>> foo(2)
> [1] 2
>
>
> So evaluate() has more detail than source(), but essentially they do the
> same thing in evaluating the whole chunk. From the help of source():
> "Since the complete file is parsed before any of it is run, syntax errors
> result in none of the code being run."
>
> So far, it seems that only R CMD BATCH is able to run one command at a time:
>
> $ R CMD BATCH -q foo.R
> $ cat foo.Rout
>> foo <- function(x) {
> +     print(x)
> + }
>> print)foo)
> Error: unexpected ')' in "print)"
> Execution halted
>
> This error is exactly the same as in the R console, and the function foo()
> is created before the error occurs. One possible solution is to get the
> workspace saved, and run R CMD BATCH again on the rest of commands after the
> error.
>
> But it still needs additional objects if the chunk is to be evaluated in a
> specific environment. This is the point where I've got, and I don't know if
> this is the best approach.
>
> Thank you,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania


From jfca283 at gmail.com  Mon Sep  5 16:51:30 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Mon, 5 Sep 2016 11:51:30 -0300
Subject: [R] Seasonal package: "Error in x[[2]] : subscript out of bounds"
Message-ID: <CALBYkjKsRaZEVpLbs7s8oLS06egNBSuv8K1UyM3cjsASmw3gbQ@mail.gmail.com>

Hi
Im running X13 with the seasonal package. However, in some series i get
this error after specifying the x11 options:

o_1=ts(o1,frequency=12,start=c(2010,2))
so_1=seas(o_1, x11="",transform.function ="log",arima.model="([3] 1 1)(1 1
0)", x11.seasonalma="S3x5",x11.trendma=13)
Error in x[[2]] : subscript out of bounds

I have four series with almost the same code. Only in one of them the
process is applied correctly.  If i type so_1, i see this:

Error: object 'so_1' not found

The series that im working with are declared as time series. I mean, all of
them look exactly the same if i do a simple View(cbind(series1,
series2,...series4))
Can some one guide me ?
Thanks for your time and interest.

	[[alternative HTML version deleted]]


From Florian_Schwendinger at gmx.at  Mon Sep  5 19:58:50 2016
From: Florian_Schwendinger at gmx.at (Florian Schwendinger)
Date: Mon, 5 Sep 2016 19:58:50 +0200
Subject: [R] Error in reading subset of data from CSV file
In-Reply-To: <CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>
References: <CA+dpOJ=ks6H3Y3o9kriR1MRnR5D70YHUzUoQz49Yzjd9bs_DRA@mail.gmail.com>
	<CA+8X3fXE+F-irH3HMJ9RgJ=hX8Wnpdm1E-ts+Ko9rX_MA=VC4g@mail.gmail.com>
	<CA+dpOJnZ7Az1WNUZ4c6TBAiozfyE9c2PRhUb+VO5eZJjysPLdQ@mail.gmail.com>
	<CA+8X3fXfi-PJEenz+uosLwYeax+PmF9Onx-_AU+MJKHvm-AwiA@mail.gmail.com>
	<CA+dpOJmrdZYP2Swdo7=kOJ0zhyMVQaVvFgQ=cCubjTF6VFd7FQ@mail.gmail.com>
Message-ID: <57CDB25A.9020106@gmx.at>

There are several issues,

1. I think
ReadName = '133261'
read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")

should be replaced by something like this

ReadName = '133261'
sql_cmd <- sprintf("select * from file where col_1='%s'", ReadName)
sql_cmd
read.csv.sql("Dat.csv", sql = sql_cmd, sep="|")

2. I wouldn't use spaces in the column names.
3. Since you have in column 2 also your separator, you cloud switch the 
separator to "|" or ";" if possible.


colnames(Dat) <- gsub("\\s+", "_", colnames(Dat))
colnames(Dat)
write.table(Dat, "Dat.csv", quote = FALSE, row.names = FALSE, sep="|")

ReadName = '133261'
sql_cmd <- sprintf("select * from file where col_1='%s'", ReadName)
sql_cmd
read.csv.sql("Dat.csv", sql = sql_cmd, sep="|")


So the following works at my pc, but if you cant change the separator 
things will get more difficult.

colnames(Dat) <- gsub("\\s+", "_", colnames(Dat))
colnames(Dat)
write.table(Dat, "Dat.csv", quote = FALSE, row.names = FALSE, sep="|")

ReadName = '133261'
sql_cmd <- sprintf("select * from file where col_1='%s'", ReadName)
sql_cmd
read.csv.sql("Dat.csv", sql = sql_cmd, sep="|")

Best,
Florian


On 2016-09-04 13:29, Christofer Bogaso wrote:
> Didnt work.... getting unused argument error.
>
> On Sun, Sep 4, 2016 at 4:47 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> I suppose you could try quote=TRUE
>>
>> Jim
>>
>>
>> On Sun, Sep 4, 2016 at 8:13 PM, Christofer Bogaso
>> <bogaso.christofer at gmail.com> wrote:
>>> Thanks Jim. But my data is like that and I have to live with that. Any
>>> idea on workaround. Thanks,
>>>
>>> On Sun, Sep 4, 2016 at 3:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> Hi Christofer,
>>>> You have embedded commas in your data structure. This is guaranteed to
>>>> mess up a CSV read.
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Sun, Sep 4, 2016 at 5:54 PM, Christofer Bogaso
>>>> <bogaso.christofer at gmail.com> wrote:
>>>>> Hi again,
>>>>>
>>>>> I was trying to read a subset of Data from a CSV file using below code
>>>>> as example :
>>>>>
>>>>> library(sqldf)
>>>>>
>>>>> Dat = structure(list(`col 1` = c(133261L, 133261L, 133262L, 133262L
>>>>> ), `col 2` = structure(1:4, .Label = c("aaa1", "aaa2", "bbb1, bbb",
>>>>> "bbb3, bbb"), class = "factor"), `col 3` = c(10.59, 10.56, 10.59,
>>>>> 10.56), `col 4` = c(10.59, 10.56, 10.59, 10.56), `col 5` = c(10.59,
>>>>> 10.56, 10.59, 10.56), `col 6` = structure(c(1L, 2L, 1L, 2L), .Label =
>>>>> c("04-Jul-16",
>>>>> "05-Jul-16"), class = "factor")), .Names = c("col 1", "col 2",
>>>>> "col 3", "col 4", "col 5", "col 6"), class = "data.frame", row.names = c(NA,
>>>>> -4L))
>>>>> Dat
>>>>>
>>>>> write.csv(Dat, "Dat.csv", quote = FALSE, row.names = FALSE)
>>>>>
>>>>> ReadName = '133261'
>>>>> read.csv.sql("Dat.csv", sql = "select * from file where 'col 1' = ReadName")
>>>>>
>>>>> Loading required package: tcltk
>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>>>    line 1 did not have 7 elements
>>>>>
>>>>> This code generates above Error. Could you please help me with a
>>>>> pointer where something went wrong? My actual CSV file is quite huge
>>>>> so I cant read it as whole. However basic structure of my original
>>>>> file is similar as above "Dat"
>>>>>
>>>>> Thanks for your time.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stef.mientki at gmail.com  Mon Sep  5 22:28:50 2016
From: stef.mientki at gmail.com (Stef Mientki)
Date: Mon, 5 Sep 2016 22:28:50 +0200
Subject: [R] how to transform db query result into a set of timeseries ?
Message-ID: <931bc534-a894-5327-7e6e-b8e4ffe685b3@gmail.com>

hello,

I've a number of timeseries into a database and want to display these 
timeseries into graph.

Now the code below works well, but as the user can select which 
timeseries should be shown (up to 20 timeseries) the code below should 
be dynamic and can be quiet large and complex.

Is there an easier way to convert a database result into timeseries 
accepted by dygraph ?

     SQL <- "select Date, M, G, N from Compare_Model"
     df <- dbGetQuery ( con, statement = SQL )

     zon1 <- xts ( df$M,  as.POSIXct ( df$Date, format="%Y-%m-%d 
%H:%M:%S") )
     zon2 <- xts ( df$G,  as.POSIXct ( df$Date, format="%Y-%m-%d 
%H:%M:%S") )
     zon3 <- xts ( df$N,  as.POSIXct ( df$Date, format="%Y-%m-%d 
%H:%M:%S") )

     zonnen <- Reduce ( function(...) merge(..., all=TRUE ), list ( zon, 
zon2, zon3 ))

     dygraph ( zonnen )


thanks,

Stef


From drjimlemon at gmail.com  Tue Sep  6 02:31:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Sep 2016 10:31:01 +1000
Subject: [R] outliers in Box Plot
In-Reply-To: <CAB630FGxSdXQ+zPMNVYMdtKb7i9j8rOX2qf31OZ0mm25TvCFRA@mail.gmail.com>
References: <CAB630FGxSdXQ+zPMNVYMdtKb7i9j8rOX2qf31OZ0mm25TvCFRA@mail.gmail.com>
Message-ID: <CA+8X3fVDL4bOOX8Eb9GHXL5iVgt8-GCFDnkHyV9iRmmqnuw+sQ@mail.gmail.com>

Hi Rosa,
Your data never seem to get through. Nevertheless, here is a suggestion:

rodat<-data.frame(id=1:20,age=sample(c("10-20","21-30","31-40"),20,TRUE),
 weight=c(sample(40:70,18),110,120))
robp<-boxplot(weight~age,rodat)
rodat$id[which(rodat$weight %in% robp$out)]

Jim


On Mon, Sep 5, 2016 at 9:38 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> Dear all,
>
> I have searched all over and didn?t found an answer :(
>
> I need urgently to "extract" de identification of the weight outliers of
> the participants of a study.
>
> So, I have a data base with several variables:
> id
> weight
> are 2 off them.
>
> So, I've done a boxplot and found the weight have outliers. Now I need to
> identify the id's of those participants.
> I can get the outliers values, nonetheless lots os them are not correct for
> some vriables.
>
> Can you please help me?
>
> boxplot(WEIGHT~AGE,baseR,range=3)     #print WEIGHT boxplot
> boxplot(WEIGHT~AGE==1,,baseR,range=3, plot=FALSE)$out      # find outliers
> values to age 1 (example)
>
>
> I attach the data.
>
> Best,
> Rosa Oliveira
>
> __________________________________
>
> Antes de imprimir este e-mail pense bem se tem mesmo que o fazer.
> H? cada vez menos ?rvores.
> N?o imprima, pense na sua responsabilidade e compromisso com o MEIO
> AMBIENTE!
> <http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
> <http://pt.dreamstime.com/cora-ccedil-atildeo-criado-das-folhas-de-aacutervores-diferentes-thumb12275776.jpg>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Tue Sep  6 05:47:25 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 6 Sep 2016 03:47:25 +0000
Subject: [R] Help with a code in R
In-Reply-To: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
Message-ID: <E05C46B5-36C7-47CF-BBC7-B00E6E76C371@txbiomed.org>

Erika,

You have failed to supply reproducible code. I do not all that is missing, but a glance shows that you did not include the code to load the foreach package or a definition of the objects named comb and b.

It is very likely you will receive assistance if you can follow the posting guide http://www.R-project.org/posting-guide.html


Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Sep 5, 2016, at 1:25 PM, Erika Roc?o Espinosa Balbuena <erikareb at gmail.com> wrote:
>
> Hi,
>
> I am working with this code:
>
> forecast_nal<-data.frame()
> out<-vector()
> x<-foreach(i=1:nrow(comb)) %do%
> {
>
> s<-comb[i,'prod_id']
>
> #Familia+Sumbarca+prod_id
> #Serie
>
> bcomb1<-b
> bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> bcomb1<-arrange(bcomb1,year,week)
> a<-bcomb1[1:1,'week']
> d<-bcomb1[1:1,'year']
> f<-nrow(bcomb1)
> h<-bcomb1[f:f,'year']
> j<-bcomb1[f:f,'week']
> bcomb1<-bcomb1[,c(6)]
>
> if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48))
> {
> out[i]<-s
> }
> else
> {
>       y <- ts(bcomb1, frequency=52, start=c(d, a))
> ##Casos
>
> if (length(y)<=60)
> {
>
> v<-auto.arima(y)
> v<-arimaorder(v)
> fit <- arima(y, order = v ,method="ML")
>      fca <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> else
> {
>
> fit <- tbats(y)
> fcb <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>            forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> }
> }
> But I am getting this error:
>
> Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833, 26750.9374514082,
> :
>  only replacement of elements is allowed
>
> Can someone help me with this?
>
> Thanks
>
>
> --
> Erika Roc?o Espinosa Balbuena
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From petr.pikal at precheza.cz  Tue Sep  6 08:31:56 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 6 Sep 2016 06:31:56 +0000
Subject: [R] Help with a code in R
In-Reply-To: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>

Hi

Well, it seems to me that it is coded in different language like C++.
The code is not reproducible but the error seems to be from your call of ts

You can check it line by line with setting i to arbitrary value and inspect how your objects look like, however some of your constructions seems to me quite weird.

e.g.
forecast_nal<-data.frame()

leads to mempty data frame with no column named mean
> forecast_nal
data frame with 0 columns and 0 rows
> forecast_nal$mean
NULL

and I am rather surprised how this column come into existence.

BTW, are you sure that in each cycle your rbinded or cbinded objects have the same size?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erika Roc?o
> Espinosa Balbuena
> Sent: Monday, September 5, 2016 8:26 PM
> To: r-help at r-project.org
> Subject: [R] Help with a code in R
>
> Hi,
>
> I am working with this code:
>
> forecast_nal<-data.frame()
> out<-vector()
> x<-foreach(i=1:nrow(comb)) %do%
> {
>
> s<-comb[i,'prod_id']
>
> #Familia+Sumbarca+prod_id
> #Serie
>
> bcomb1<-b
> bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> bcomb1<-arrange(bcomb1,year,week)
> a<-bcomb1[1:1,'week']
> d<-bcomb1[1:1,'year']
> f<-nrow(bcomb1)
> h<-bcomb1[f:f,'year']
> j<-bcomb1[f:f,'week']
> bcomb1<-bcomb1[,c(6)]
>
> if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48)) { out[i]<-s }
> else {
>        y <- ts(bcomb1, frequency=52, start=c(d, a)) ##Casos
>
> if (length(y)<=60)
> {
>
> v<-auto.arima(y)
> v<-arimaorder(v)
> fit <- arima(y, order = v ,method="ML")
>       fca <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> else
> {
>
> fit <- tbats(y)
> fcb <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>             forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> }
> }
>  But I am getting this error:
>
> Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833, 26750.9374514082,
>  :
>   only replacement of elements is allowed
>
> Can someone help me with this?
>
> Thanks
>
>
> --
> Erika Roc?o Espinosa Balbuena
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tenan.simone at gmail.com  Tue Sep  6 09:52:34 2016
From: tenan.simone at gmail.com (Simone Tenan)
Date: Tue, 6 Sep 2016 09:52:34 +0200
Subject: [R] save R object into a remote directory
Message-ID: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>

Hi all,
I'm using R remotely via ssh connection in linux. I need to save a large R
object from the remote server to my laptop. How can I specify the path in
the save() function?

Thanks much for your help,
Simone

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Tue Sep  6 10:30:02 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 06 Sep 2016 10:30:02 +0200
Subject: [R] save R object into a remote directory
In-Reply-To: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>
	(Simone Tenan's message of "Tue, 6 Sep 2016 09:52:34 +0200")
References: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>
Message-ID: <m2a8flo2gl.fsf@krugs.de>

Simone Tenan <tenan.simone at gmail.com> writes:

> Hi all,
> I'm using R remotely via ssh connection in linux. I need to save a large R
> object from the remote server to my laptop. How can I specify the path in
> the save() function?

You are working on the remote machine and there is no way that you can
specify "out of the box" a save to client machine (I stand to be corrected). 

You could mount a directory on the client on the server, but I would
suggest to

1) save the object on the server (the where R is running on)
2) use scp from the client to copy the file from the server to the
client (the one you are typing on).

scp user at host1:file1 ./TheNameOfTheLocalFile

Cheers,

Rainer

>
> Thanks much for your help,
> Simone
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160906/0283a3db/attachment.bin>

From Rainer at krugs.de  Tue Sep  6 11:00:39 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 06 Sep 2016 11:00:39 +0200
Subject: [R] save R object into a remote directory
In-Reply-To: <CA+JR1Cd-jZL_Qd+WDrFcDJ9tazGFkk0Fauf2VTCd22gYzk5f4Q@mail.gmail.com>
	(Simone Tenan's message of "Tue, 6 Sep 2016 10:38:23 +0200")
References: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>
	<m2a8flo2gl.fsf@krugs.de>
	<CA+JR1Cd-jZL_Qd+WDrFcDJ9tazGFkk0Fauf2VTCd22gYzk5f4Q@mail.gmail.com>
Message-ID: <m260q9o11k.fsf@krugs.de>

Please reply to the mailing list to keep the conversation available for
everybody. I Send this mail to the mailing list as well.

Simone Tenan <tenan.simone at gmail.com> writes:

> Thanks Rainer,
> it's very kind of you. 
> Unfortunately, I cannot save the (large) R object where the current R session is running. There is not enough memory and when I tried I got the error "error
> writing to connection".

OK - essential piece of information.

In this case, your best bet is trying to mount an a flder from your
client on the server and than save there.

Contact you administrator to find out if this is possible or (s)he has
other suggestions.

> For that reason I was trying to save the object of of the remote server.
>
> Best,

Cheers,

Rainer

> Simone
>
> On 6 September 2016 at 10:30, Rainer M Krug <Rainer at krugs.de> wrote:
>
>  Simone Tenan <tenan.simone at gmail.com> writes:
>
>  > Hi all,
>  > I'm using R remotely via ssh connection in linux. I need to save a large R
>  > object from the remote server to my laptop. How can I specify the path in
>  > the save() function?
>
>  You are working on the remote machine and there is no way that you can
>  specify "out of the box" a save to client machine (I stand to be corrected).
>
>  You could mount a directory on the client on the server, but I would
>  suggest to
>
>  1) save the object on the server (the where R is running on)
>  2) use scp from the client to copy the file from the server to the
>  client (the one you are typing on).
>
>  scp user at host1:file1 ./TheNameOfTheLocalFile
>
>  Cheers,
>
>  Rainer
>
>  >
>  > Thanks much for your help,
>  > Simone
>  >
>  > [[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal, self-contained, reproducible code.
>
>  --
>  Rainer M. Krug
>  email: Rainer<at>krugs<dot>de
>  PGP: 0x0F52F982
>
>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160906/530a0360/attachment.bin>

From G.Maubach at weinwolf.de  Tue Sep  6 11:54:18 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 6 Sep 2016 11:54:18 +0200
Subject: [R] Iteration over variables
Message-ID: <OFF0CEE5C5.CFB851FB-ONC1258026.002D88FE-C1258026.003668B9@lotus.hawesko.de>

Hi All,

I would like to write a program that iterates over a set of dynamically 
generated variables and produces some stats or prints parts of the data.

# --- data
v_turnover_2011 <- c(10, 20, 30, 40 , 50)
v_customer_2011 <- c(0, 1, NA, 0, 1)
v_turnover_2012 <- c(10, 20, 30, 40 , 50)
v_customer_2012 <- c(0, 1, NA, 0, 1)
d_dataset <- data.frame(v_turnover_2011, v_turnover_2012,
                        v_customer_2011, v_customer_2012)

# -- Aim is to iterate over dynamically generated variables and compute
# -- statistics or print parts of the data

# -- Does not produce any output
for (year in 2011:2012) {
  head(d_dataset[, c(paste0("v_turnover_", year),
                     paste0("v_customer_", year))])
}

# -- Does not produce any output
aux_func <- function(year) {
  head(d_dataset[, c(paste0("v_turnover_", year),
                     paste0("v_customer_", year))])
}

for (year in 2011:2012) {
  aux_func(year = year)
}


d_results <- data.frame()
for (year in 2011:2012) {
  d_results <- rbind(d_results,
                     paste0("mean", year) = mean(d_dataset[, 
c(paste0("v_turnover_", year))]))
}

Is there a way to iterate over variables and compute statistics and print 
parts of the dataset?

Kind regards

Georg


From r.turner at auckland.ac.nz  Tue Sep  6 12:27:47 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 6 Sep 2016 12:27:47 +0200
Subject: [R] Iteration over variables
In-Reply-To: <OFF0CEE5C5.CFB851FB-ONC1258026.002D88FE-C1258026.003668B9@lotus.hawesko.de>
References: <OFF0CEE5C5.CFB851FB-ONC1258026.002D88FE-C1258026.003668B9@lotus.hawesko.de>
Message-ID: <57bde78a-e703-8ed0-ac0b-aaf325b2dacd@auckland.ac.nz>


You need to *print* results explicitly within a for-loop.

E.g.

   print(head(d_dataset[,
         c(paste0("v_turnover_",year),
           paste0("v_customer_", year))]))

See FAQ 7.16 for a related discussion.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 06/09/16 11:54, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I would like to write a program that iterates over a set of dynamically
> generated variables and produces some stats or prints parts of the data.
>
> # --- data
> v_turnover_2011 <- c(10, 20, 30, 40 , 50)
> v_customer_2011 <- c(0, 1, NA, 0, 1)
> v_turnover_2012 <- c(10, 20, 30, 40 , 50)
> v_customer_2012 <- c(0, 1, NA, 0, 1)
> d_dataset <- data.frame(v_turnover_2011, v_turnover_2012,
>                         v_customer_2011, v_customer_2012)
>
> # -- Aim is to iterate over dynamically generated variables and compute
> # -- statistics or print parts of the data
>
> # -- Does not produce any output
> for (year in 2011:2012) {
>   head(d_dataset[, c(paste0("v_turnover_", year),
>                      paste0("v_customer_", year))])
> }
>
> # -- Does not produce any output
> aux_func <- function(year) {
>   head(d_dataset[, c(paste0("v_turnover_", year),
>                      paste0("v_customer_", year))])
> }
>
> for (year in 2011:2012) {
>   aux_func(year = year)
> }
>
>
> d_results <- data.frame()
> for (year in 2011:2012) {
>   d_results <- rbind(d_results,
>                      paste0("mean", year) = mean(d_dataset[,
> c(paste0("v_turnover_", year))]))
> }
>
> Is there a way to iterate over variables and compute statistics and print
> parts of the dataset?


From ahalsiva at gmail.com  Tue Sep  6 02:17:36 2016
From: ahalsiva at gmail.com (Ahalya Sivathayalan)
Date: Mon, 5 Sep 2016 20:17:36 -0400
Subject: [R] finegray function in survival package
Message-ID: <CAL28AaejH8nMqP501Ja=nyT5xs9t+6ve+rACWJ-mAogvbRT35A@mail.gmail.com>

Dear R-Team,

I have been trying to use the finegray routine that creates a special data
so that Fine and Gray model can be fit. However, it does not seem to work.
Could you please help me with this issue?


Thanks,
Ahalya.

	[[alternative HTML version deleted]]


From aloboaleu at gmail.com  Tue Sep  6 08:52:15 2016
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Tue, 6 Sep 2016 08:52:15 +0200
Subject: [R] R-square prob is not calculated by randomization in lmPerm::lmp
Message-ID: <CALPC6DNi3Nbx55WRDGO1FZsAju6_TMjJPRm+Z2z2tDicdoHXRA@mail.gmail.com>

Any reason why the R-square prob is not calculated by randomization in
lmPerm::lmp? The help pages states "Either permutation test p-values
or the usual F-test p-values will be output", but I always get the F
test for R-square as with lm():

require(lmPerm)
x <- 1:1000
set.seed(1000)
y1 <- x*2+runif(1000,-100,100)
dat <- data.frame(x =x,y=y1)
summary(lmp(y~x, data=dat,center=FALSE,perm="Prob"))

[1] "Settings:  unique SS "

Call:
lmp(formula = y ~ x, data = dat, center = FALSE)

Residuals:
     Min       1Q   Median       3Q      Max
-100.431  -48.645    2.843   48.640  101.800

Coefficients:
  Estimate Iter Pr(Prob)
x    1.993 5000   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 57.3 on 998 degrees of freedom
Multiple R-Squared: 0.9902, Adjusted R-squared: 0.9902
F-statistic: 1.009e+05 on 1 and 998 DF,  p-value: < 2.2e-16


-- 
Agustin Lobo
aloboaleu at gmail.com


From audreykaspi at gmail.com  Tue Sep  6 08:56:04 2016
From: audreykaspi at gmail.com (Audrey Riddell)
Date: Tue, 6 Sep 2016 16:56:04 +1000
Subject: [R] (no subject)
Message-ID: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>

Hello,


I am trying to remove brackets and the text contained in brackets. I tried
to do a user defined formula... my attempt at this is pasted below.

cleanBetweenBrackets <- function(String)
  { return(gsub("\(.*?\)", "", String))}

 I keep getting errors (namely that there is an unrecognised escape
character in the string). I have looked at regex forums a bit, but cant
figure this out.

I want the above formula to be able to produce the following result

>Str<-"The cat is crazy (but not too crazy)"
>StrNoBrackets<-cleanBetweenBrackets(Str)
>StrNoBrackets
[1]  "The cat is crazy "

Assistance would be appreciated,

Audrey

	[[alternative HTML version deleted]]


From audreykaspi at gmail.com  Tue Sep  6 12:56:09 2016
From: audreykaspi at gmail.com (Audrey Riddell)
Date: Tue, 6 Sep 2016 20:56:09 +1000
Subject: [R] Fwd:
In-Reply-To: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>
References: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>
Message-ID: <CAJwbKktxFya2KE5rRGtgkX4x6ofZ=oBYkLXdEWf2wOSiGvvjLg@mail.gmail.com>

Hello,

I have been able to figure this out using \\ (two back slashes for escape)
Working R code for what I wanted is...

cleanBetweenBrackets <- function(String)
  { return(gsub("\\(.*?\\)", "", String))}

I thought I had tried that (the \\) before I emailed the list. Please
ignore my previous email.

Sorry for any inconvenience caused.

Audrey



---------- Forwarded message ----------
From: Audrey Riddell <audreykaspi at gmail.com>
Date: Tue, Sep 6, 2016 at 4:56 PM
Subject:
To: r-help at r-project.org


Hello,


I am trying to remove brackets and the text contained in brackets. I tried
to do a user defined formula... my attempt at this is pasted below.

cleanBetweenBrackets <- function(String)
  { return(gsub("\(.*?\)", "", String))}

 I keep getting errors (namely that there is an unrecognised escape
character in the string). I have looked at regex forums a bit, but cant
figure this out.

I want the above formula to be able to produce the following result

>Str<-"The cat is crazy (but not too crazy)"
>StrNoBrackets<-cleanBetweenBrackets(Str)
>StrNoBrackets
[1]  "The cat is crazy "

Assistance would be appreciated,

Audrey

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep  6 03:51:41 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Sep 2016 18:51:41 -0700
Subject: [R] Help with a code in R
In-Reply-To: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
Message-ID: <CAGxFJbRvAFS07BLnz5076DGpAti1Ytei7T=p26T8OaVpJ=vibg@mail.gmail.com>

?traceback
?debug
?trace

R has built-in debugging tools. Learn to use them.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 5, 2016 at 11:25 AM, Erika Roc?o Espinosa Balbuena
<erikareb at gmail.com> wrote:
> Hi,
>
> I am working with this code:
>
> forecast_nal<-data.frame()
> out<-vector()
> x<-foreach(i=1:nrow(comb)) %do%
> {
>
> s<-comb[i,'prod_id']
>
> #Familia+Sumbarca+prod_id
> #Serie
>
> bcomb1<-b
> bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> bcomb1<-arrange(bcomb1,year,week)
> a<-bcomb1[1:1,'week']
> d<-bcomb1[1:1,'year']
> f<-nrow(bcomb1)
> h<-bcomb1[f:f,'year']
> j<-bcomb1[f:f,'week']
> bcomb1<-bcomb1[,c(6)]
>
> if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48))
> {
> out[i]<-s
> }
> else
> {
>        y <- ts(bcomb1, frequency=52, start=c(d, a))
> ##Casos
>
> if (length(y)<=60)
> {
>
> v<-auto.arima(y)
> v<-arimaorder(v)
> fit <- arima(y, order = v ,method="ML")
>       fca <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> else
> {
>
> fit <- tbats(y)
> fcb <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>             forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> }
> }
>  But I am getting this error:
>
> Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833, 26750.9374514082,
>  :
>   only replacement of elements is allowed
>
> Can someone help me with this?
>
> Thanks
>
>
> --
> Erika Roc?o Espinosa Balbuena
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Sep  6 04:21:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Sep 2016 19:21:03 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
Message-ID: <CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>

Just noticed: My clumsy do.call() line in my previously posted code
below should be replaced with:
pat <- paste(pat,collapse = "|")


> pat <- c(pat1,pat2)
> paste(pat,collapse="|")
[1] "a+\\.*a+|b+\\.*b+"

************ replace this **************************
> pat <- do.call(paste,c(as.list(pat), sep="|"))
********************************************
> sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
[1] "a.a"   "bb"    "b.bbb"


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Jun:
>
> You need to provide a clear specification via regular expressions of
> the patterns you wish to match -- at least for me to decipher it.
> Others may be smarter than I, though...
>
> Jeff: Thanks. I have now convinced myself that it can be done (a
> "proof" of sorts): If pat1, pat2,..., patn are m different patterns
> (in a vector of patterns)  to be matched in a vector of n strings,
> where only one of the patterns will match in any string,  then use
> paste() (probably via do.call()) or otherwise to paste them together
> separated by "|" to form the concatenated pattern, pat. Then
>
> sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>
> should extract the matching pattern in each (perhaps with a little
> fiddling due to precedence rules); e.g.
>
>> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>
>> pat1 <- "a+\\.*a+"
>> pat2 <-"b+\\.*b+"
>> pat <- c(pat1,pat2)
>
>> pat <- do.call(paste,c(as.list(pat), sep="|"))
>> pat
> [1] "a+\\.*a+|b+\\.*b+"
>
>> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> [1] "a.a"   "bb"    "b.bbb"
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> Thanks for the reply, Bert.
>>
>> Your solution solves the example. I actually have a more general situation
>> where I have this dot concatenated string from multiple variables. The
>> problem is those variables may have values with dots in there. The number of
>> dots are not consistent for all values of a variable. So I am thinking to
>> define a vector of patterns for the vector of the string and hopefully to
>> find a way to use a pattern from the pattern vector for each value of the
>> string vector. The only way I can think of is "for" loop, which can be slow.
>> Also these are happening in a function I am writing. Just wonder if there is
>> another more efficient way. Thanks a lot.
>>
>> Jun
>>
>> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> Well, he did provide an example, and...
>>>
>>>
>>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>
>>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>> [1] "WT.CUT" "tx"
>>>
>>>
>>> ## seems to do what was requested.
>>>
>>> Jeff would have to amplify on his initial statement however: do you
>>> mean that separate patterns can always be combined via "|" ?  Or
>>> something deeper?
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>> > Your opening assertion is false.
>>> >
>>> > Provide a reproducible example and someone will demonstrate.
>>> > --
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
>>> > wrote:
>>> >>Dear list,
>>> >>
>>> >>I have a vector of strings that cannot be described by one pattern. So
>>> >>let's say I construct a vector of patterns in the same length as the
>>> >>vector
>>> >>of strings, can I do the element wise pattern recognition and string
>>> >>substitution.
>>> >>
>>> >>For example,
>>> >>
>>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>> >>
>>> >>patterns <- c(pattern1,pattern2)
>>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>> >>
>>> >>Say I want to extract "WT.CUT" from the first string and "tx" from the
>>> >>second string. If I do
>>> >>
>>> >>sub(patterns, '\\2', strings), only the first pattern will be used.
>>> >>
>>> >>looping the patterns doesn't work the way I want. Appreciate any
>>> >>comments.
>>> >>Thanks.
>>> >>
>>> >>Jun
>>> >>
>>> >>       [[alternative HTML version deleted]]
>>> >>
>>> >>______________________________________________
>>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>PLEASE do read the posting guide
>>> >>http://www.R-project.org/posting-guide.html
>>> >>and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>


From giorgio.garziano at ericsson.com  Tue Sep  6 15:09:36 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 6 Sep 2016 13:09:36 +0000
Subject: [R] outliers in Box Plot
Message-ID: <248E6FA047A8C746BA491485764190F53E9A4401@ESESSMB207.ericsson.se>

Hi Rosa,

you may take advantage of the extremevalues package.

https://cran.r-project.org/web/packages/extremevalues/extremevalues.pdf

An example:

set.seed(1023)
v3 <- c(rnorm(100, 0, 0.2), rnorm(5, 4, 0.1), rnorm(5, -4, 0.1))
v4 <- sample(v3, length(v3))
nam <- as.character(1:length(v4))
df <- data.frame(names = nam, values = v4)


library(extremevalues)

res <- getOutliersI(as.vector(df[,"values"]), FLim=c(0.001, 0.999), distribution="normal")

# indexes where outliers are located
res$iLeft
res$iRight

outliers_idx <- c(res$iLeft, res$iRight)

df_outliers <- data.frame(index= outliers_idx, values = df[outliers_idx,"values"])
df_outliers

outlierPlot(df[,"values"], L=res)


--

Best

GG



	[[alternative HTML version deleted]]


From tdehdari at gmail.com  Tue Sep  6 15:08:41 2016
From: tdehdari at gmail.com (Tahereh Dehdarirad)
Date: Tue, 6 Sep 2016 15:08:41 +0200
Subject: [R] Factor analysis and time as an offset variable
Message-ID: <CAJGnSAP_2-0nXhELtBCmbgLNC2pim+XxT4bbS69LhJ3eMZCMpw@mail.gmail.com>

Hi,

Is it possible to use time as an offset (exposure variable) in factor
analysis? If yes, would you please advise how?


Thanks,

Tahereh




Tahereh Dehdarirad
PhD Student of Library and Information Science
University of Barcelona, Spain

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Sep  6 15:33:15 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 6 Sep 2016 09:33:15 -0400
Subject: [R] (no subject)
In-Reply-To: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>
References: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>
Message-ID: <CAM_vjun-Rv3aPKUbr-=gOScPka=8jg=wK-9MozNVLSz4skowuQ@mail.gmail.com>

R's implementation of regex requires double backslashes. Reading
?regex will tell you more.


cleanBetweenBrackets <- function(String)
{
  return(gsub("\\(.*?\\)", "", String))
}

Str <- "The cat is crazy (but not too crazy)"

cleanBetweenBrackets(Str)

> cleanBetweenBrackets(Str)
[1] "The cat is crazy "


The trailing space is left as an exercise for the reader.

Sarah

On Tue, Sep 6, 2016 at 2:56 AM, Audrey Riddell <audreykaspi at gmail.com> wrote:
> Hello,
>
>
> I am trying to remove brackets and the text contained in brackets. I tried
> to do a user defined formula... my attempt at this is pasted below.
>
> cleanBetweenBrackets <- function(String)
>   { return(gsub("\(.*?\)", "", String))}
>
>  I keep getting errors (namely that there is an unrecognised escape
> character in the string). I have looked at regex forums a bit, but cant
> figure this out.
>
> I want the above formula to be able to produce the following result
>
>>Str<-"The cat is crazy (but not too crazy)"
>>StrNoBrackets<-cleanBetweenBrackets(Str)
>>StrNoBrackets
> [1]  "The cat is crazy "
>
> Assistance would be appreciated,
>
> Audrey
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From residuo.solow at gmail.com  Tue Sep  6 15:40:18 2016
From: residuo.solow at gmail.com (Sebastian Kruk)
Date: Tue, 6 Sep 2016 10:40:18 -0300
Subject: [R] graph together 4 series after HP filter
Message-ID: <CAMn86Ncqi9sxYtg_xLevLP950nb4yykSEssSSdvijhwt31U16Q@mail.gmail.com>

Dear R-users:

Let's see if you can help.

I have an matrix of class "ts" of 100 rows by 4 columns which called PP.

In each column I have the time series of quarterly GDP from 4 countries.

They applied the Hodrick -Prescott filter and now I want to plot
simultaneously cyclical component of the 4 countries and another window
graphed together the trend conponentes .

#If PP include the series of one country would do:
lambda <- 1600
DFIL <- hpfilter (PP, freq = lambda, type = "lambda" )
#First graph
plot(DFIL$x, plot.type = "single" col = 1:Countries , main = "Economy and
Trend" )
#Second graphic
plot(DFIL$cycle, plot.type = "single" col = 1:Countries, main = "Cycle" )
#A Deactivate the two graphics
pair(mfrow = c (1,1))

But I want to put on each graph window all the components'series.

Then I made first:
DFIL <- apply ( PP , 2, hpfilter , freq = lambda, type = "lambda" )
How can I graph all cyclical components together?

Regards,

Sebastian.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Sep  6 15:54:47 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 6 Sep 2016 15:54:47 +0200
Subject: [R] save R object into a remote directory
In-Reply-To: <m260q9o11k.fsf@krugs.de>
References: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>
	<m2a8flo2gl.fsf@krugs.de>
	<CA+JR1Cd-jZL_Qd+WDrFcDJ9tazGFkk0Fauf2VTCd22gYzk5f4Q@mail.gmail.com>
	<m260q9o11k.fsf@krugs.de>
Message-ID: <D76B6884-E59D-4594-B838-74B52F6F70B1@gmail.com>


On 06 Sep 2016, at 11:00 , Rainer M Krug <Rainer at krugs.de> wrote:

> Please reply to the mailing list to keep the conversation available for
> everybody. I Send this mail to the mailing list as well.
> 
> Simone Tenan <tenan.simone at gmail.com> writes:
> 
>> Thanks Rainer,
>> it's very kind of you. 
>> Unfortunately, I cannot save the (large) R object where the current R session is running. There is not enough memory and when I tried I got the error "error
>> writing to connection".
> 
> OK - essential piece of information.
> 
> In this case, your best bet is trying to mount an a flder from your
> client on the server and than save there.


I think you can in principle do something with a socketConnection and SSH port forwarding, but it is not trivial.

> Contact you administrator to find out if this is possible or (s)he has
> other suggestions.
> 

yep.

>> For that reason I was trying to save the object of of the remote server.
>> 
>> Best,
> 
> Cheers,
> 
> Rainer
> 
>> Simone
>> 
>> On 6 September 2016 at 10:30, Rainer M Krug <Rainer at krugs.de> wrote:
>> 
>> Simone Tenan <tenan.simone at gmail.com> writes:
>> 
>>> Hi all,
>>> I'm using R remotely via ssh connection in linux. I need to save a large R
>>> object from the remote server to my laptop. How can I specify the path in
>>> the save() function?
>> 
>> You are working on the remote machine and there is no way that you can
>> specify "out of the box" a save to client machine (I stand to be corrected).
>> 
>> You could mount a directory on the client on the server, but I would
>> suggest to
>> 
>> 1) save the object on the server (the where R is running on)
>> 2) use scp from the client to copy the file from the server to the
>> client (the one you are typing on).
>> 
>> scp user at host1:file1 ./TheNameOfTheLocalFile
>> 
>> Cheers,
>> 
>> Rainer
>> 
>>> 
>>> Thanks much for your help,
>>> Simone
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>> 
>> 
> 
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Tue Sep  6 15:56:15 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 06 Sep 2016 08:56:15 -0500
Subject: [R] Conditional gap time frailty cox model for recurrent events
In-Reply-To: <mailman.5.1473156001.15128.r-help@r-project.org>
References: <mailman.5.1473156001.15128.r-help@r-project.org>
Message-ID: <083a37$49ieoi@ironport10.mayo.edu>

You can ignore the message below.  The maximizing routine buried within the frailty() 
command buried with coxph() has a maximizer that is not the brightest.  It sometimes gets 
lost but then finds its way again.  The message is from one of those.  It likely took a 
not-so-good update step, and took a couple of iterations to recover.

In coxpenal.fit(X, Y, strats, offset, init = init, control, weights = weights,  :
    Inner loop failed to coverge for iterations 3 4

To be fair the maximizing problem for a mixed effects Cox model is not easy.  In the coxme 
code I have spent much more time on the details of this.

Terry Therneau

------------------------------

On 09/06/2016 05:00 AM, r-help-request at r-project.org wrote:
> Dear Elisabetta,
>
> I have no direct answer to your question, but a suggestion: Use the
> 'coxme' function (in the package with the same name). In the help page
> for 'frailty' (survival) you will find: "The coxme package has
> superseded this method. It is faster, more stable, and more flexible."
>
> Hth, G?ran
>
> On 2016-09-05 11:42, Elisabetta Petracci wrote:
>> >Dear users,
>> >
>> >I am fitting a conditional gap time frailty cox model weighting
>> >observations by means of inverse probability time dependent weigths.
>> >Attached find the self-explaining dataset.
>> >
>> >I have used the following sintax:
>> >
>> >coxph(Surv(gaptstart,gaptstop,status)~treat+strata(nrecord01)+frailty(id,distribution="gamma",method="em"),
>> >data=dataNOTDrr,weights=dataNOTDrr$weight)
>> >
>> >
>> >And I get the following warning:
>> >
>> >Warning message:
>> >In coxpenal.fit(X, Y, strats, offset, init = init, control, weights =
>> >weights,  :
>> >   Inner loop failed to coverge for iterations 3 4
>> >
>> >
>> >I have tried to:
>> >- leave out the weights but I get the error anyway
>> >- to randomly select a subset of patients and I don't get the error. This
>> >seems to suggest that the problem is with some observations.
>> >
>> >Any suggestion?
>> >
>> >Many thanks,
>> >
>> >Elisabetta
>> >


From jdnewmil at dcn.davis.ca.us  Tue Sep  6 16:20:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Sep 2016 07:20:22 -0700
Subject: [R] (no subject)
In-Reply-To: <CAM_vjun-Rv3aPKUbr-=gOScPka=8jg=wK-9MozNVLSz4skowuQ@mail.gmail.com>
References: <CAJwbKktVBeuVcxbPLWQx0hwQa8qDc+mD70-rinZuZtM87wZ+4A@mail.gmail.com>
	<CAM_vjun-Rv3aPKUbr-=gOScPka=8jg=wK-9MozNVLSz4skowuQ@mail.gmail.com>
Message-ID: <E374969C-25D7-492A-B5B0-3654C96E12B5@dcn.davis.ca.us>

It is not the implementation of regex that requires double backslashes, but the R string parser. You can use cat to see what the pattern looks like to the parser. Try

cat( "\\(.*?\\)" )
-- 
Sent from my phone. Please excuse my brevity.

On September 6, 2016 6:33:15 AM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>R's implementation of regex requires double backslashes. Reading
>?regex will tell you more.
>
>
>cleanBetweenBrackets <- function(String)
>{
>  return(gsub("\\(.*?\\)", "", String))
>}
>
>Str <- "The cat is crazy (but not too crazy)"
>
>cleanBetweenBrackets(Str)
>
>> cleanBetweenBrackets(Str)
>[1] "The cat is crazy "
>
>
>The trailing space is left as an exercise for the reader.
>
>Sarah
>
>On Tue, Sep 6, 2016 at 2:56 AM, Audrey Riddell <audreykaspi at gmail.com>
>wrote:
>> Hello,
>>
>>
>> I am trying to remove brackets and the text contained in brackets. I
>tried
>> to do a user defined formula... my attempt at this is pasted below.
>>
>> cleanBetweenBrackets <- function(String)
>>   { return(gsub("\(.*?\)", "", String))}
>>
>>  I keep getting errors (namely that there is an unrecognised escape
>> character in the string). I have looked at regex forums a bit, but
>cant
>> figure this out.
>>
>> I want the above formula to be able to produce the following result
>>
>>>Str<-"The cat is crazy (but not too crazy)"
>>>StrNoBrackets<-cleanBetweenBrackets(Str)
>>>StrNoBrackets
>> [1]  "The cat is crazy "
>>
>> Assistance would be appreciated,
>>
>> Audrey
>>


From jdnewmil at dcn.davis.ca.us  Tue Sep  6 16:31:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Sep 2016 07:31:18 -0700
Subject: [R] Factor analysis and time as an offset variable
In-Reply-To: <CAJGnSAP_2-0nXhELtBCmbgLNC2pim+XxT4bbS69LhJ3eMZCMpw@mail.gmail.com>
References: <CAJGnSAP_2-0nXhELtBCmbgLNC2pim+XxT4bbS69LhJ3eMZCMpw@mail.gmail.com>
Message-ID: <66230403-7F89-4284-A825-AAB1C62CFE89@dcn.davis.ca.us>

That step is easy, but context is hard. You really need to provide a reproducible example. There are many models, many analysis tools,  and many timescales to choose from. In fact, this could easily be mistaken for a question about statistics (not really on-topic here) since you have failed to indicate what any of your constraints or decisions in those areas are. 

It may be as simple as you not knowing about date or POSIXt arithmetic  (see ?DateTimeClasses).
-- 
Sent from my phone. Please excuse my brevity.

On September 6, 2016 6:08:41 AM PDT, Tahereh Dehdarirad <tdehdari at gmail.com> wrote:
>Hi,
>
>Is it possible to use time as an offset (exposure variable) in factor
>analysis? If yes, would you please advise how?
>
>
>Thanks,
>
>Tahereh
>
>
>
>
>Tahereh Dehdarirad
>PhD Student of Library and Information Science
>University of Barcelona, Spain
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Sep  6 16:35:32 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Sep 2016 07:35:32 -0700
Subject: [R] R-square prob is not calculated by randomization in
	lmPerm::lmp
In-Reply-To: <CALPC6DNi3Nbx55WRDGO1FZsAju6_TMjJPRm+Z2z2tDicdoHXRA@mail.gmail.com>
References: <CALPC6DNi3Nbx55WRDGO1FZsAju6_TMjJPRm+Z2z2tDicdoHXRA@mail.gmail.com>
Message-ID: <0605370B-DA49-47B0-9CD2-2610E39286D1@dcn.davis.ca.us>

That is contributed code. It could do anything the author felt like. I recommend reading the source code. 
-- 
Sent from my phone. Please excuse my brevity.

On September 5, 2016 11:52:15 PM PDT, Agustin Lobo <aloboaleu at gmail.com> wrote:
>Any reason why the R-square prob is not calculated by randomization in
>lmPerm::lmp? The help pages states "Either permutation test p-values
>or the usual F-test p-values will be output", but I always get the F
>test for R-square as with lm():
>
>require(lmPerm)
>x <- 1:1000
>set.seed(1000)
>y1 <- x*2+runif(1000,-100,100)
>dat <- data.frame(x =x,y=y1)
>summary(lmp(y~x, data=dat,center=FALSE,perm="Prob"))
>
>[1] "Settings:  unique SS "
>
>Call:
>lmp(formula = y ~ x, data = dat, center = FALSE)
>
>Residuals:
>     Min       1Q   Median       3Q      Max
>-100.431  -48.645    2.843   48.640  101.800
>
>Coefficients:
>  Estimate Iter Pr(Prob)
>x    1.993 5000   <2e-16 ***
>---
>Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>Residual standard error: 57.3 on 998 degrees of freedom
>Multiple R-Squared: 0.9902, Adjusted R-squared: 0.9902
>F-statistic: 1.009e+05 on 1 and 998 DF,  p-value: < 2.2e-16


From tdehdari at gmail.com  Tue Sep  6 16:38:26 2016
From: tdehdari at gmail.com (Tahereh Dehdarirad)
Date: Tue, 6 Sep 2016 16:38:26 +0200
Subject: [R] Factor analysis and time as an offset variable
In-Reply-To: <66230403-7F89-4284-A825-AAB1C62CFE89@dcn.davis.ca.us>
References: <CAJGnSAP_2-0nXhELtBCmbgLNC2pim+XxT4bbS69LhJ3eMZCMpw@mail.gmail.com>
	<66230403-7F89-4284-A825-AAB1C62CFE89@dcn.davis.ca.us>
Message-ID: <CAJGnSAMYzET2+afnKV6Y0aXtn_0HGiFJnFFN9O7n_byyMNNKNA@mail.gmail.com>

Thank you for your reply. I am grouping citation and some social media
indictors ( number of tweets, mendeley readers, etc). The number of
citaions a paper recievs or the number of social media indicators that a
papers receives depends on time. For example a paper published in 2009 has
more time to get citation than a paper pubished lets say in year 2016.

That is the reason I like to consider  time ( in my case the number of
years) a paper has been to the exposure of receiving citations in the
factor analysis.

Best,

Tahereh




Tahereh Dehdarirad
PhD Student of Library and Information Science
University of Barcelona, Spain

On Tue, Sep 6, 2016 at 4:31 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> That step is easy, but context is hard. You really need to provide a
> reproducible example. There are many models, many analysis tools,  and many
> timescales to choose from. In fact, this could easily be mistaken for a
> question about statistics (not really on-topic here) since you have failed
> to indicate what any of your constraints or decisions in those areas are.
>
> It may be as simple as you not knowing about date or POSIXt arithmetic
> (see ?DateTimeClasses).
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 6, 2016 6:08:41 AM PDT, Tahereh Dehdarirad <
> tdehdari at gmail.com> wrote:
> >Hi,
> >
> >Is it possible to use time as an offset (exposure variable) in factor
> >analysis? If yes, would you please advise how?
> >
> >
> >Thanks,
> >
> >Tahereh
> >
> >
> >
> >
> >Tahereh Dehdarirad
> >PhD Student of Library and Information Science
> >University of Barcelona, Spain
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep  6 16:45:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Sep 2016 07:45:13 -0700
Subject: [R] graph together 4 series after HP filter
In-Reply-To: <CAMn86Ncqi9sxYtg_xLevLP950nb4yykSEssSSdvijhwt31U16Q@mail.gmail.com>
References: <CAMn86Ncqi9sxYtg_xLevLP950nb4yykSEssSSdvijhwt31U16Q@mail.gmail.com>
Message-ID: <CAGxFJbQTVmQnc9J5rKsZi23E5a0ER9UOopMnKzq50zEETsUrbg@mail.gmail.com>

?lines
?points

to add to an existing base graphics graph. There are other ways to do
this in the other graph systems (ggplot, lattice,...) used in R.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 6, 2016 at 6:40 AM, Sebastian Kruk <residuo.solow at gmail.com> wrote:
> Dear R-users:
>
> Let's see if you can help.
>
> I have an matrix of class "ts" of 100 rows by 4 columns which called PP.
>
> In each column I have the time series of quarterly GDP from 4 countries.
>
> They applied the Hodrick -Prescott filter and now I want to plot
> simultaneously cyclical component of the 4 countries and another window
> graphed together the trend conponentes .
>
> #If PP include the series of one country would do:
> lambda <- 1600
> DFIL <- hpfilter (PP, freq = lambda, type = "lambda" )
> #First graph
> plot(DFIL$x, plot.type = "single" col = 1:Countries , main = "Economy and
> Trend" )
> #Second graphic
> plot(DFIL$cycle, plot.type = "single" col = 1:Countries, main = "Cycle" )
> #A Deactivate the two graphics
> pair(mfrow = c (1,1))
>
> But I want to put on each graph window all the components'series.
>
> Then I made first:
> DFIL <- apply ( PP , 2, hpfilter , freq = lambda, type = "lambda" )
> How can I graph all cyclical components together?
>
> Regards,
>
> Sebastian.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Tue Sep  6 17:00:19 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 6 Sep 2016 09:00:19 -0600
Subject: [R] R-square prob is not calculated by randomization in
	lmPerm::lmp
In-Reply-To: <0605370B-DA49-47B0-9CD2-2610E39286D1@dcn.davis.ca.us>
References: <CALPC6DNi3Nbx55WRDGO1FZsAju6_TMjJPRm+Z2z2tDicdoHXRA@mail.gmail.com>
	<0605370B-DA49-47B0-9CD2-2610E39286D1@dcn.davis.ca.us>
Message-ID: <CAM5M9BT3MN+rF0y1x+rKrqd-YfmqK2T6y_mgH9OZ66nsXQJUAg@mail.gmail.com>

For a linear model without an intercept term as in this example, neither
the usual permutation scheme for testing Ho: B1 = 0 nor usual definition of
R-squared apply.  So you need to check what the developer of this code
chose to do.  If I'm recalling correctly, in a linear model with an
intercept term the permutation test for Ho: B1 = B2 = ... Bp = 0 (i.e., all
coefficients other than the intercept = 0) is equivalent to a permutation
test for Ho: R-squared = 0.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Tue, Sep 6, 2016 at 8:35 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> That is contributed code. It could do anything the author felt like. I
> recommend reading the source code.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 5, 2016 11:52:15 PM PDT, Agustin Lobo <aloboaleu at gmail.com>
> wrote:
> >Any reason why the R-square prob is not calculated by randomization in
> >lmPerm::lmp? The help pages states "Either permutation test p-values
> >or the usual F-test p-values will be output", but I always get the F
> >test for R-square as with lm():
> >
> >require(lmPerm)
> >x <- 1:1000
> >set.seed(1000)
> >y1 <- x*2+runif(1000,-100,100)
> >dat <- data.frame(x =x,y=y1)
> >summary(lmp(y~x, data=dat,center=FALSE,perm="Prob"))
> >
> >[1] "Settings:  unique SS "
> >
> >Call:
> >lmp(formula = y ~ x, data = dat, center = FALSE)
> >
> >Residuals:
> >     Min       1Q   Median       3Q      Max
> >-100.431  -48.645    2.843   48.640  101.800
> >
> >Coefficients:
> >  Estimate Iter Pr(Prob)
> >x    1.993 5000   <2e-16 ***
> >---
> >Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >Residual standard error: 57.3 on 998 degrees of freedom
> >Multiple R-Squared: 0.9902, Adjusted R-squared: 0.9902
> >F-statistic: 1.009e+05 on 1 and 998 DF,  p-value: < 2.2e-16
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Tue Sep  6 17:11:49 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 6 Sep 2016 15:11:49 +0000
Subject: [R] graph together 4 series after HP filter
Message-ID: <248E6FA047A8C746BA491485764190F53E9A45A1@ESESSMB207.ericsson.se>

Hi Sebastian,

here are examples with ggplot2 and basic graphic.

http://stackoverflow.com/questions/3777174/plotting-two-variables-as-lines-using-ggplot2-on-the-same-graph

http://stackoverflow.com/questions/17150183/r-plot-multiple-lines-in-one-graph


You may also impress your audience by using iterative graphs as provided by dygraphs package.

https://blog.rstudio.org/2015/04/14/interactive-time-series-with-dygraphs/

You have to convert your xts objects starting from your ts ones.

An example:

getSymbols("AAPL", src = "yahoo", from = as.Date("2013-07-01"), to = as.Date("2016-06-30"))
getSymbols("YHOO", src = "yahoo", from = as.Date("2013-07-01"), to = as.Date("2016-06-30"))
getSymbols("CPHD", src = "yahoo", from = as.Date("2013-07-01"), to = as.Date("2016-06-30"))
getSymbols("EMC", src = "yahoo", from = as.Date("2013-07-01"), to = as.Date("2016-06-30"))
AAPL.xts <- Ad(AAPL)
YHOO.xts <- Ad(YHOO)
CPHD.xts <- Ad(CPHD)
EMC.xts <- Ad(EMC)

df <- data.frame(AAPL.xts, YHOO.xts, CPHD.xts, EMC.xts)
head(df)

library(dygraphs)
dygraph(df)

--

Best,

GG





	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Tue Sep  6 19:15:40 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 6 Sep 2016 10:15:40 -0700
Subject: [R] save R object into a remote directory
In-Reply-To: <m260q9o11k.fsf@krugs.de>
References: <CA+JR1CdnYSXgTqYT3t8M7fKzhhJzqi=zZoOO2hpX5JBS=-b7yA@mail.gmail.com>
	<m2a8flo2gl.fsf@krugs.de>
	<CA+JR1Cd-jZL_Qd+WDrFcDJ9tazGFkk0Fauf2VTCd22gYzk5f4Q@mail.gmail.com>
	<m260q9o11k.fsf@krugs.de>
Message-ID: <CAFDcVCSmUXdva6j6jAAL2+zZYXOWrU+shwO5Rc8kW77cL30KZQ@mail.gmail.com>

On Tue, Sep 6, 2016 at 2:00 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Please reply to the mailing list to keep the conversation available for
> everybody. I Send this mail to the mailing list as well.
>
> Simone Tenan <tenan.simone at gmail.com> writes:
>
>> Thanks Rainer,
>> it's very kind of you.
>> Unfortunately, I cannot save the (large) R object where the current R session is running. There is not enough memory and when I tried I got the error "error
>> writing to connection".
>
> OK - essential piece of information.

Assuming the remote machine you're logging into is running Linux:

Before anything else, did you try to save elsewhere than to your
/home/ folder/account? Try /tmp/.  That probably / hopefully doesn't
count to your account quota (and it gets wiped at every reboot).
There's also /var/tmp/ (a bit more persistent storage - survives
reboots).

/Henrik

PS. In R, the tempdir() function often points to a directory under
/tmp/, e.g.  tempdir() => "/tmp/RtmpWZPsip".  However, that will be
wiped by R itself when you quit the R session, so if you use tempdir()
you need to scp that file before you quit R.  It's probably better to
avoid tempdir() in your case.

>
> In this case, your best bet is trying to mount an a flder from your
> client on the server and than save there.
>
> Contact you administrator to find out if this is possible or (s)he has
> other suggestions.
>
>> For that reason I was trying to save the object of of the remote server.
>>
>> Best,
>
> Cheers,
>
> Rainer
>
>> Simone
>>
>> On 6 September 2016 at 10:30, Rainer M Krug <Rainer at krugs.de> wrote:
>>
>>  Simone Tenan <tenan.simone at gmail.com> writes:
>>
>>  > Hi all,
>>  > I'm using R remotely via ssh connection in linux. I need to save a large R
>>  > object from the remote server to my laptop. How can I specify the path in
>>  > the save() function?
>>
>>  You are working on the remote machine and there is no way that you can
>>  specify "out of the box" a save to client machine (I stand to be corrected).
>>
>>  You could mount a directory on the client on the server, but I would
>>  suggest to
>>
>>  1) save the object on the server (the where R is running on)
>>  2) use scp from the client to copy the file from the server to the
>>  client (the one you are typing on).
>>
>>  scp user at host1:file1 ./TheNameOfTheLocalFile
>>
>>  Cheers,
>>
>>  Rainer
>>
>>  >
>>  > Thanks much for your help,
>>  > Simone
>>  >
>>  > [[alternative HTML version deleted]]
>>  >
>>  > ______________________________________________
>>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>  > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>  > and provide commented, minimal, self-contained, reproducible code.
>>
>>  --
>>  Rainer M. Krug
>>  email: Rainer<at>krugs<dot>de
>>  PGP: 0x0F52F982
>>
>>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Wed Sep  7 00:59:18 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 6 Sep 2016 18:59:18 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
Message-ID: <CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>

Hi Bert,

I still couldn't make the multiple patterns to work. Here is an example. I
make the pattern as follows

final.pattern <-
"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"

test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
'240.m.g.>50-70.kg.geo.mean')

sub(final.pattern, '\\1', test.string)
sub(final.pattern, '\\2', test.string)
sub(final.pattern, '\\3', test.string)

Only the third string has been correctly parsed, which matches the
first pattern. It seems the rest of the patterns are not called.

Jun


On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Just noticed: My clumsy do.call() line in my previously posted code
> below should be replaced with:
> pat <- paste(pat,collapse = "|")
>
>
> > pat <- c(pat1,pat2)
> > paste(pat,collapse="|")
> [1] "a+\\.*a+|b+\\.*b+"
>
> ************ replace this **************************
> > pat <- do.call(paste,c(as.list(pat), sep="|"))
> ********************************************
> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
> [1] "a.a"   "bb"    "b.bbb"
>
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > Jun:
> >
> > You need to provide a clear specification via regular expressions of
> > the patterns you wish to match -- at least for me to decipher it.
> > Others may be smarter than I, though...
> >
> > Jeff: Thanks. I have now convinced myself that it can be done (a
> > "proof" of sorts): If pat1, pat2,..., patn are m different patterns
> > (in a vector of patterns)  to be matched in a vector of n strings,
> > where only one of the patterns will match in any string,  then use
> > paste() (probably via do.call()) or otherwise to paste them together
> > separated by "|" to form the concatenated pattern, pat. Then
> >
> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
> >
> > should extract the matching pattern in each (perhaps with a little
> > fiddling due to precedence rules); e.g.
> >
> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
> >
> >> pat1 <- "a+\\.*a+"
> >> pat2 <-"b+\\.*b+"
> >> pat <- c(pat1,pat2)
> >
> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> pat
> > [1] "a+\\.*a+|b+\\.*b+"
> >
> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> > [1] "a.a"   "bb"    "b.bbb"
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> >> Thanks for the reply, Bert.
> >>
> >> Your solution solves the example. I actually have a more general
> situation
> >> where I have this dot concatenated string from multiple variables. The
> >> problem is those variables may have values with dots in there. The
> number of
> >> dots are not consistent for all values of a variable. So I am thinking
> to
> >> define a vector of patterns for the vector of the string and hopefully
> to
> >> find a way to use a pattern from the pattern vector for each value of
> the
> >> string vector. The only way I can think of is "for" loop, which can be
> slow.
> >> Also these are happening in a function I am writing. Just wonder if
> there is
> >> another more efficient way. Thanks a lot.
> >>
> >> Jun
> >>
> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>>
> >>> Well, he did provide an example, and...
> >>>
> >>>
> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>>
> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> >>> [1] "WT.CUT" "tx"
> >>>
> >>>
> >>> ## seems to do what was requested.
> >>>
> >>> Jeff would have to amplify on his initial statement however: do you
> >>> mean that separate patterns can always be combined via "|" ?  Or
> >>> something deeper?
> >>>
> >>> Cheers,
> >>> Bert
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> >>> wrote:
> >>> > Your opening assertion is false.
> >>> >
> >>> > Provide a reproducible example and someone will demonstrate.
> >>> > --
> >>> > Sent from my phone. Please excuse my brevity.
> >>> >
> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com
> >
> >>> > wrote:
> >>> >>Dear list,
> >>> >>
> >>> >>I have a vector of strings that cannot be described by one pattern.
> So
> >>> >>let's say I construct a vector of patterns in the same length as the
> >>> >>vector
> >>> >>of strings, can I do the element wise pattern recognition and string
> >>> >>substitution.
> >>> >>
> >>> >>For example,
> >>> >>
> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >>> >>
> >>> >>patterns <- c(pattern1,pattern2)
> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>> >>
> >>> >>Say I want to extract "WT.CUT" from the first string and "tx" from
> the
> >>> >>second string. If I do
> >>> >>
> >>> >>sub(patterns, '\\2', strings), only the first pattern will be used.
> >>> >>
> >>> >>looping the patterns doesn't work the way I want. Appreciate any
> >>> >>comments.
> >>> >>Thanks.
> >>> >>
> >>> >>Jun
> >>> >>
> >>> >>       [[alternative HTML version deleted]]
> >>> >>
> >>> >>______________________________________________
> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>PLEASE do read the posting guide
> >>> >>http://www.R-project.org/posting-guide.html
> >>> >>and provide commented, minimal, self-contained, reproducible code.
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep  7 02:18:47 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 6 Sep 2016 17:18:47 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
Message-ID: <BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>

I am not near my computer today, but each parenthesis gets its own result number, so you should put the parenthesis around the whole pattern of alternatives instead of having many parentheses.

I recommend thinking in terms of what common information you expect to find in these various strings, and place your parentheses to capture that information. There is no other reason to put parentheses in the pattern... they are not grouping symbols. 
-- 
Sent from my phone. Please excuse my brevity.

On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Jun:
>
>1. Tell us your desired result from your test vector and maybe someone
>will help.
>
>2. As we played this game once already (you couldn't do it; I showed
>you how), this seems to be a function of your limitations with regular
>expressions. I'm probably not much better, but in any case, I don't
>intend to be your consultant. See if you can find someone locally to
>help you if you do not receive a satisfactory reply from the list.
>There are many people here who are pretty good at this sort of thing,
>but I don't know if they'll reply. Regex's are certainly complex. PERL
>people tend to be pretty good at them, I believe. There are numerous
>web sites and books on them if you need to acquire expertise for your
>work.
>
>Cheers,
>Bert
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> Hi Bert,
>>
>> I still couldn't make the multiple patterns to work. Here is an
>example. I
>> make the pattern as follows
>>
>> final.pattern <-
>>
>"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>>
>> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>> '240.m.g.>50-70.kg.geo.mean')
>>
>> sub(final.pattern, '\\1', test.string)
>> sub(final.pattern, '\\2', test.string)
>> sub(final.pattern, '\\3', test.string)
>>
>> Only the third string has been correctly parsed, which matches the
>first
>> pattern. It seems the rest of the patterns are not called.
>>
>> Jun
>>
>>
>> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>>
>>> Just noticed: My clumsy do.call() line in my previously posted code
>>> below should be replaced with:
>>> pat <- paste(pat,collapse = "|")
>>>
>>>
>>> > pat <- c(pat1,pat2)
>>> > paste(pat,collapse="|")
>>> [1] "a+\\.*a+|b+\\.*b+"
>>>
>>> ************ replace this **************************
>>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>>> ********************************************
>>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>>> [1] "a.a"   "bb"    "b.bbb"
>>>
>>>
>>> -- Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming
>along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
><bgunter.4567 at gmail.com>
>>> wrote:
>>> > Jun:
>>> >
>>> > You need to provide a clear specification via regular expressions
>of
>>> > the patterns you wish to match -- at least for me to decipher it.
>>> > Others may be smarter than I, though...
>>> >
>>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>patterns
>>> > (in a vector of patterns)  to be matched in a vector of n strings,
>>> > where only one of the patterns will match in any string,  then use
>>> > paste() (probably via do.call()) or otherwise to paste them
>together
>>> > separated by "|" to form the concatenated pattern, pat. Then
>>> >
>>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>>> >
>>> > should extract the matching pattern in each (perhaps with a little
>>> > fiddling due to precedence rules); e.g.
>>> >
>>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>>> >
>>> >> pat1 <- "a+\\.*a+"
>>> >> pat2 <-"b+\\.*b+"
>>> >> pat <- c(pat1,pat2)
>>> >
>>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>> >> pat
>>> > [1] "a+\\.*a+|b+\\.*b+"
>>> >
>>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>>> > [1] "a.a"   "bb"    "b.bbb"
>>> >
>>> > Cheers,
>>> > Bert
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming
>along
>>> > and sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>wrote:
>>> >> Thanks for the reply, Bert.
>>> >>
>>> >> Your solution solves the example. I actually have a more general
>>> >> situation
>>> >> where I have this dot concatenated string from multiple
>variables. The
>>> >> problem is those variables may have values with dots in there.
>The
>>> >> number of
>>> >> dots are not consistent for all values of a variable. So I am
>thinking
>>> >> to
>>> >> define a vector of patterns for the vector of the string and
>hopefully
>>> >> to
>>> >> find a way to use a pattern from the pattern vector for each
>value of
>>> >> the
>>> >> string vector. The only way I can think of is "for" loop, which
>can be
>>> >> slow.
>>> >> Also these are happening in a function I am writing. Just wonder
>if
>>> >> there is
>>> >> another more efficient way. Thanks a lot.
>>> >>
>>> >> Jun
>>> >>
>>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
><bgunter.4567 at gmail.com>
>>> >> wrote:
>>> >>>
>>> >>> Well, he did provide an example, and...
>>> >>>
>>> >>>
>>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>> >>>
>>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>> >>> [1] "WT.CUT" "tx"
>>> >>>
>>> >>>
>>> >>> ## seems to do what was requested.
>>> >>>
>>> >>> Jeff would have to amplify on his initial statement however: do
>you
>>> >>> mean that separate patterns can always be combined via "|" ?  Or
>>> >>> something deeper?
>>> >>>
>>> >>> Cheers,
>>> >>> Bert
>>> >>> Bert Gunter
>>> >>>
>>> >>> "The trouble with having an open mind is that people keep coming
>along
>>> >>> and sticking things into it."
>>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>)
>>> >>>
>>> >>>
>>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>> >>> <jdnewmil at dcn.davis.ca.us>
>>> >>> wrote:
>>> >>> > Your opening assertion is false.
>>> >>> >
>>> >>> > Provide a reproducible example and someone will demonstrate.
>>> >>> > --
>>> >>> > Sent from my phone. Please excuse my brevity.
>>> >>> >
>>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>>> >>> > <jun.shen.ut at gmail.com>
>>> >>> > wrote:
>>> >>> >>Dear list,
>>> >>> >>
>>> >>> >>I have a vector of strings that cannot be described by one
>pattern.
>>> >>> >> So
>>> >>> >>let's say I construct a vector of patterns in the same length
>as the
>>> >>> >>vector
>>> >>> >>of strings, can I do the element wise pattern recognition and
>string
>>> >>> >>substitution.
>>> >>> >>
>>> >>> >>For example,
>>> >>> >>
>>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>> >>> >>
>>> >>> >>patterns <- c(pattern1,pattern2)
>>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>> >>> >>
>>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>from
>>> >>> >> the
>>> >>> >>second string. If I do
>>> >>> >>
>>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>used.
>>> >>> >>
>>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>any
>>> >>> >>comments.
>>> >>> >>Thanks.
>>> >>> >>
>>> >>> >>Jun
>>> >>> >>
>>> >>> >>       [[alternative HTML version deleted]]
>>> >>> >>
>>> >>> >>______________________________________________
>>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> >>PLEASE do read the posting guide
>>> >>> >>http://www.R-project.org/posting-guide.html
>>> >>> >>and provide commented, minimal, self-contained, reproducible
>code.
>>> >>> >
>>> >>> > ______________________________________________
>>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> > PLEASE do read the posting guide
>>> >>> > http://www.R-project.org/posting-guide.html
>>> >>> > and provide commented, minimal, self-contained, reproducible
>code.
>>> >>
>>> >>
>>
>>


From jun.shen.ut at gmail.com  Wed Sep  7 02:57:16 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 6 Sep 2016 20:57:16 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
Message-ID: <CAMCXXmrAsVUX7io6pEwZV2qGUQ7AJALMMDo=Db9qMiwzrX05pg@mail.gmail.com>

Hi Bert,

In the final.pattern, there are ten patterns.

>sub(final.pattern, '\\1', test.string)
Expected results: "240.m.g" "3.mg.kg" "240.m.g"
Current results: "" "" "240.m.g"

>sub(final.pattern, '\\2', test.string)
Expected results: ">110.kg" ">110.kg" ">50-70.kg"
Current results: "" "" ">50-70.kg"

>sub(final.pattern, '\\3', test.string)
Expected results: "geo.mean" "P05" "geo.mean"
Current results: "" "" "geo.mean"

Right now, I only get the results from the third string.


On Tue, Sep 6, 2016 at 8:01 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Jun:
>
> 1. Tell us your desired result from your test vector and maybe someone
> will help.
>
> 2. As we played this game once already (you couldn't do it; I showed
> you how), this seems to be a function of your limitations with regular
> expressions. I'm probably not much better, but in any case, I don't
> intend to be your consultant. See if you can find someone locally to
> help you if you do not receive a satisfactory reply from the list.
> There are many people here who are pretty good at this sort of thing,
> but I don't know if they'll reply. Regex's are certainly complex. PERL
> people tend to be pretty good at them, I believe. There are numerous
> web sites and books on them if you need to acquire expertise for your
> work.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> > Hi Bert,
> >
> > I still couldn't make the multiple patterns to work. Here is an example.
> I
> > make the pattern as follows
> >
> > final.pattern <-
> > "(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-
> 70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.
> mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
> >
> > test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
> > '240.m.g.>50-70.kg.geo.mean')
> >
> > sub(final.pattern, '\\1', test.string)
> > sub(final.pattern, '\\2', test.string)
> > sub(final.pattern, '\\3', test.string)
> >
> > Only the third string has been correctly parsed, which matches the first
> > pattern. It seems the rest of the patterns are not called.
> >
> > Jun
> >
> >
> > On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> Just noticed: My clumsy do.call() line in my previously posted code
> >> below should be replaced with:
> >> pat <- paste(pat,collapse = "|")
> >>
> >>
> >> > pat <- c(pat1,pat2)
> >> > paste(pat,collapse="|")
> >> [1] "a+\\.*a+|b+\\.*b+"
> >>
> >> ************ replace this **************************
> >> > pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> ********************************************
> >> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
> >> [1] "a.a"   "bb"    "b.bbb"
> >>
> >>
> >> -- Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> > Jun:
> >> >
> >> > You need to provide a clear specification via regular expressions of
> >> > the patterns you wish to match -- at least for me to decipher it.
> >> > Others may be smarter than I, though...
> >> >
> >> > Jeff: Thanks. I have now convinced myself that it can be done (a
> >> > "proof" of sorts): If pat1, pat2,..., patn are m different patterns
> >> > (in a vector of patterns)  to be matched in a vector of n strings,
> >> > where only one of the patterns will match in any string,  then use
> >> > paste() (probably via do.call()) or otherwise to paste them together
> >> > separated by "|" to form the concatenated pattern, pat. Then
> >> >
> >> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
> >> >
> >> > should extract the matching pattern in each (perhaps with a little
> >> > fiddling due to precedence rules); e.g.
> >> >
> >> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
> >> >
> >> >> pat1 <- "a+\\.*a+"
> >> >> pat2 <-"b+\\.*b+"
> >> >> pat <- c(pat1,pat2)
> >> >
> >> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> >> pat
> >> > [1] "a+\\.*a+|b+\\.*b+"
> >> >
> >> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> >> > [1] "a.a"   "bb"    "b.bbb"
> >> >
> >> > Cheers,
> >> > Bert
> >> >
> >> >
> >> > Bert Gunter
> >> >
> >> > "The trouble with having an open mind is that people keep coming along
> >> > and sticking things into it."
> >> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
> wrote:
> >> >> Thanks for the reply, Bert.
> >> >>
> >> >> Your solution solves the example. I actually have a more general
> >> >> situation
> >> >> where I have this dot concatenated string from multiple variables.
> The
> >> >> problem is those variables may have values with dots in there. The
> >> >> number of
> >> >> dots are not consistent for all values of a variable. So I am
> thinking
> >> >> to
> >> >> define a vector of patterns for the vector of the string and
> hopefully
> >> >> to
> >> >> find a way to use a pattern from the pattern vector for each value of
> >> >> the
> >> >> string vector. The only way I can think of is "for" loop, which can
> be
> >> >> slow.
> >> >> Also these are happening in a function I am writing. Just wonder if
> >> >> there is
> >> >> another more efficient way. Thanks a lot.
> >> >>
> >> >> Jun
> >> >>
> >> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com>
> >> >> wrote:
> >> >>>
> >> >>> Well, he did provide an example, and...
> >> >>>
> >> >>>
> >> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >>>
> >> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> >> >>> [1] "WT.CUT" "tx"
> >> >>>
> >> >>>
> >> >>> ## seems to do what was requested.
> >> >>>
> >> >>> Jeff would have to amplify on his initial statement however: do you
> >> >>> mean that separate patterns can always be combined via "|" ?  Or
> >> >>> something deeper?
> >> >>>
> >> >>> Cheers,
> >> >>> Bert
> >> >>> Bert Gunter
> >> >>>
> >> >>> "The trouble with having an open mind is that people keep coming
> along
> >> >>> and sticking things into it."
> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>>
> >> >>>
> >> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
> >> >>> <jdnewmil at dcn.davis.ca.us>
> >> >>> wrote:
> >> >>> > Your opening assertion is false.
> >> >>> >
> >> >>> > Provide a reproducible example and someone will demonstrate.
> >> >>> > --
> >> >>> > Sent from my phone. Please excuse my brevity.
> >> >>> >
> >> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
> >> >>> > <jun.shen.ut at gmail.com>
> >> >>> > wrote:
> >> >>> >>Dear list,
> >> >>> >>
> >> >>> >>I have a vector of strings that cannot be described by one
> pattern.
> >> >>> >> So
> >> >>> >>let's say I construct a vector of patterns in the same length as
> the
> >> >>> >>vector
> >> >>> >>of strings, can I do the element wise pattern recognition and
> string
> >> >>> >>substitution.
> >> >>> >>
> >> >>> >>For example,
> >> >>> >>
> >> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >> >>> >>
> >> >>> >>patterns <- c(pattern1,pattern2)
> >> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >>> >>
> >> >>> >>Say I want to extract "WT.CUT" from the first string and "tx" from
> >> >>> >> the
> >> >>> >>second string. If I do
> >> >>> >>
> >> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
> used.
> >> >>> >>
> >> >>> >>looping the patterns doesn't work the way I want. Appreciate any
> >> >>> >>comments.
> >> >>> >>Thanks.
> >> >>> >>
> >> >>> >>Jun
> >> >>> >>
> >> >>> >>       [[alternative HTML version deleted]]
> >> >>> >>
> >> >>> >>______________________________________________
> >> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >>PLEASE do read the posting guide
> >> >>> >>http://www.R-project.org/posting-guide.html
> >> >>> >>and provide commented, minimal, self-contained, reproducible code.
> >> >>> >
> >> >>> > ______________________________________________
> >> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> > PLEASE do read the posting guide
> >> >>> > http://www.R-project.org/posting-guide.html
> >> >>> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >
> >
>

	[[alternative HTML version deleted]]


From davidmarino838 at gmail.com  Wed Sep  7 03:13:14 2016
From: davidmarino838 at gmail.com (Marino David)
Date: Wed, 7 Sep 2016 09:13:14 +0800
Subject: [R] Run an external software in R
Message-ID: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>

Hi all R users:

Does anybody have the experience of running an external software in R? I
try to use R to run ANSYS software, which is a engineering simulation
package. I ever have done this task in Matlab platform by executing
the following code line:

system('"C:\Program Files\Ansys Inc\v100\ANSYS\bin\intel\ansys100" -b -p
ane3fl -i D:\Ansys\MyAnsysCode.txt -o D:\Ansys\vm5.out');


Any idea regarding implementing this work is very welcome.

David

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Wed Sep  7 03:20:41 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 6 Sep 2016 21:20:41 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
Message-ID: <CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>

Hi Jeff,

Thanks for the reply. I tried your suggestion and it doesn't seem to work
and I tried a simple pattern as follows and it works as expected

sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1', "3.mg.kg.>50-70.kg.P05")
[1] "3.mg.kg"

sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2', "3.mg.kg.>50-70.kg.P05")
[1] ">50-70.kg"

sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3', "3.mg.kg.>50-70.kg.P05")
[1] "P05"

My problem is the pattern has to be dynamically constructed on the input
data of the function I am writing. It's actually not too difficult to
assemble the final.pattern with some code like the following

sort.var <- c('TX','WTCUT')
combn.sort.var <- do.call(expand.grid, lapply(sort.var,
function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))),
')', sep='')))
all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
final.pattern <- paste0(all.patterns, collapse='|')

You cannot run the code directly since the data object "all.exposure" is
not provided here.

Jun



On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I am not near my computer today, but each parenthesis gets its own result
> number, so you should put the parenthesis around the whole pattern of
> alternatives instead of having many parentheses.
>
> I recommend thinking in terms of what common information you expect to
> find in these various strings, and place your parentheses to capture that
> information. There is no other reason to put parentheses in the pattern...
> they are not grouping symbols.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >Jun:
> >
> >1. Tell us your desired result from your test vector and maybe someone
> >will help.
> >
> >2. As we played this game once already (you couldn't do it; I showed
> >you how), this seems to be a function of your limitations with regular
> >expressions. I'm probably not much better, but in any case, I don't
> >intend to be your consultant. See if you can find someone locally to
> >help you if you do not receive a satisfactory reply from the list.
> >There are many people here who are pretty good at this sort of thing,
> >but I don't know if they'll reply. Regex's are certainly complex. PERL
> >people tend to be pretty good at them, I believe. There are numerous
> >web sites and books on them if you need to acquire expertise for your
> >work.
> >
> >Cheers,
> >Bert
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> >> Hi Bert,
> >>
> >> I still couldn't make the multiple patterns to work. Here is an
> >example. I
> >> make the pattern as follows
> >>
> >> final.pattern <-
> >>
> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
> >>
> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
> >> '240.m.g.>50-70.kg.geo.mean')
> >>
> >> sub(final.pattern, '\\1', test.string)
> >> sub(final.pattern, '\\2', test.string)
> >> sub(final.pattern, '\\3', test.string)
> >>
> >> Only the third string has been correctly parsed, which matches the
> >first
> >> pattern. It seems the rest of the patterns are not called.
> >>
> >> Jun
> >>
> >>
> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >wrote:
> >>>
> >>> Just noticed: My clumsy do.call() line in my previously posted code
> >>> below should be replaced with:
> >>> pat <- paste(pat,collapse = "|")
> >>>
> >>>
> >>> > pat <- c(pat1,pat2)
> >>> > paste(pat,collapse="|")
> >>> [1] "a+\\.*a+|b+\\.*b+"
> >>>
> >>> ************ replace this **************************
> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
> >>> ********************************************
> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
> >>> [1] "a.a"   "bb"    "b.bbb"
> >>>
> >>>
> >>> -- Bert
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming
> >along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
> ><bgunter.4567 at gmail.com>
> >>> wrote:
> >>> > Jun:
> >>> >
> >>> > You need to provide a clear specification via regular expressions
> >of
> >>> > the patterns you wish to match -- at least for me to decipher it.
> >>> > Others may be smarter than I, though...
> >>> >
> >>> > Jeff: Thanks. I have now convinced myself that it can be done (a
> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
> >patterns
> >>> > (in a vector of patterns)  to be matched in a vector of n strings,
> >>> > where only one of the patterns will match in any string,  then use
> >>> > paste() (probably via do.call()) or otherwise to paste them
> >together
> >>> > separated by "|" to form the concatenated pattern, pat. Then
> >>> >
> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
> >>> >
> >>> > should extract the matching pattern in each (perhaps with a little
> >>> > fiddling due to precedence rules); e.g.
> >>> >
> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
> >>> >
> >>> >> pat1 <- "a+\\.*a+"
> >>> >> pat2 <-"b+\\.*b+"
> >>> >> pat <- c(pat1,pat2)
> >>> >
> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
> >>> >> pat
> >>> > [1] "a+\\.*a+|b+\\.*b+"
> >>> >
> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> >>> > [1] "a.a"   "bb"    "b.bbb"
> >>> >
> >>> > Cheers,
> >>> > Bert
> >>> >
> >>> >
> >>> > Bert Gunter
> >>> >
> >>> > "The trouble with having an open mind is that people keep coming
> >along
> >>> > and sticking things into it."
> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>> >
> >>> >
> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
> >wrote:
> >>> >> Thanks for the reply, Bert.
> >>> >>
> >>> >> Your solution solves the example. I actually have a more general
> >>> >> situation
> >>> >> where I have this dot concatenated string from multiple
> >variables. The
> >>> >> problem is those variables may have values with dots in there.
> >The
> >>> >> number of
> >>> >> dots are not consistent for all values of a variable. So I am
> >thinking
> >>> >> to
> >>> >> define a vector of patterns for the vector of the string and
> >hopefully
> >>> >> to
> >>> >> find a way to use a pattern from the pattern vector for each
> >value of
> >>> >> the
> >>> >> string vector. The only way I can think of is "for" loop, which
> >can be
> >>> >> slow.
> >>> >> Also these are happening in a function I am writing. Just wonder
> >if
> >>> >> there is
> >>> >> another more efficient way. Thanks a lot.
> >>> >>
> >>> >> Jun
> >>> >>
> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
> ><bgunter.4567 at gmail.com>
> >>> >> wrote:
> >>> >>>
> >>> >>> Well, he did provide an example, and...
> >>> >>>
> >>> >>>
> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>> >>>
> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> >>> >>> [1] "WT.CUT" "tx"
> >>> >>>
> >>> >>>
> >>> >>> ## seems to do what was requested.
> >>> >>>
> >>> >>> Jeff would have to amplify on his initial statement however: do
> >you
> >>> >>> mean that separate patterns can always be combined via "|" ?  Or
> >>> >>> something deeper?
> >>> >>>
> >>> >>> Cheers,
> >>> >>> Bert
> >>> >>> Bert Gunter
> >>> >>>
> >>> >>> "The trouble with having an open mind is that people keep coming
> >along
> >>> >>> and sticking things into it."
> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> >)
> >>> >>>
> >>> >>>
> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
> >>> >>> <jdnewmil at dcn.davis.ca.us>
> >>> >>> wrote:
> >>> >>> > Your opening assertion is false.
> >>> >>> >
> >>> >>> > Provide a reproducible example and someone will demonstrate.
> >>> >>> > --
> >>> >>> > Sent from my phone. Please excuse my brevity.
> >>> >>> >
> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
> >>> >>> > <jun.shen.ut at gmail.com>
> >>> >>> > wrote:
> >>> >>> >>Dear list,
> >>> >>> >>
> >>> >>> >>I have a vector of strings that cannot be described by one
> >pattern.
> >>> >>> >> So
> >>> >>> >>let's say I construct a vector of patterns in the same length
> >as the
> >>> >>> >>vector
> >>> >>> >>of strings, can I do the element wise pattern recognition and
> >string
> >>> >>> >>substitution.
> >>> >>> >>
> >>> >>> >>For example,
> >>> >>> >>
> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >>> >>> >>
> >>> >>> >>patterns <- c(pattern1,pattern2)
> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>> >>> >>
> >>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
> >from
> >>> >>> >> the
> >>> >>> >>second string. If I do
> >>> >>> >>
> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
> >used.
> >>> >>> >>
> >>> >>> >>looping the patterns doesn't work the way I want. Appreciate
> >any
> >>> >>> >>comments.
> >>> >>> >>Thanks.
> >>> >>> >>
> >>> >>> >>Jun
> >>> >>> >>
> >>> >>> >>       [[alternative HTML version deleted]]
> >>> >>> >>
> >>> >>> >>______________________________________________
> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> >>PLEASE do read the posting guide
> >>> >>> >>http://www.R-project.org/posting-guide.html
> >>> >>> >>and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>> >
> >>> >>> > ______________________________________________
> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> > PLEASE do read the posting guide
> >>> >>> > http://www.R-project.org/posting-guide.html
> >>> >>> > and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>
> >>> >>
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Wed Sep  7 05:59:12 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 6 Sep 2016 23:59:12 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
	<CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>
Message-ID: <CAMCXXmpcBcnHeWg=QATjt=uZLg+hUbbVBkP1U_Qh02DArGWwCw@mail.gmail.com>

Hi Ista,

Thanks for the suggestion. I didn't know mapply can be used this way! Let
me take one more step. Instead of defining a pattern for each string, I
would like to define a set of patterns from all the possible combination of
the unique values of those variables. Then I need each string to find a
pattern for itself. I know this is getting a little stretching. Thanks for
all the suggestion/comments from everyone.

Jun

On Tue, Sep 6, 2016 at 9:44 PM, Ista Zahn <istazahn at gmail.com> wrote:

> If you want to mach each element of 'strings' to a different regex, do
> it. Here are three ways, using your original example.
>
> pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>
> patterns <- c(pattern1,pattern2)
> strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>
> for(i in seq(strings)) print(sub(patterns[i], "\\2", strings[i]))
>
> mapply(sub, pattern = patterns, x = strings, MoreArgs=list(replacement =
> "\\2"))
>
> library(stringi)
> stri_replace_all_regex(strings, patterns, "$2")
>
> Best,
> Ista
> On Tue, Sep 6, 2016 at 9:20 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> > Hi Jeff,
> >
> > Thanks for the reply. I tried your suggestion and it doesn't seem to work
> > and I tried a simple pattern as follows and it works as expected
> >
> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1', "3.mg.kg
> .>50-70.kg.P05")
> > [1] "3.mg.kg"
> >
> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2', "3.mg.kg
> .>50-70.kg.P05")
> > [1] ">50-70.kg"
> >
> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3', "3.mg.kg
> .>50-70.kg.P05")
> > [1] "P05"
> >
> > My problem is the pattern has to be dynamically constructed on the input
> > data of the function I am writing. It's actually not too difficult to
> > assemble the final.pattern with some code like the following
> >
> > sort.var <- c('TX','WTCUT')
> > combn.sort.var <- do.call(expand.grid, lapply(sort.var,
> > function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.
> exposure[x]))),
> > ')', sep='')))
> > all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
> > final.pattern <- paste0(all.patterns, collapse='|')
> >
> > You cannot run the code directly since the data object "all.exposure" is
> > not provided here.
> >
> > Jun
> >
> >
> >
> > On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
> >
> > wrote:
> >
> >> I am not near my computer today, but each parenthesis gets its own
> result
> >> number, so you should put the parenthesis around the whole pattern of
> >> alternatives instead of having many parentheses.
> >>
> >> I recommend thinking in terms of what common information you expect to
> >> find in these various strings, and place your parentheses to capture
> that
> >> information. There is no other reason to put parentheses in the
> pattern...
> >> they are not grouping symbols.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <
> bgunter.4567 at gmail.com>
> >> wrote:
> >> >Jun:
> >> >
> >> >1. Tell us your desired result from your test vector and maybe someone
> >> >will help.
> >> >
> >> >2. As we played this game once already (you couldn't do it; I showed
> >> >you how), this seems to be a function of your limitations with regular
> >> >expressions. I'm probably not much better, but in any case, I don't
> >> >intend to be your consultant. See if you can find someone locally to
> >> >help you if you do not receive a satisfactory reply from the list.
> >> >There are many people here who are pretty good at this sort of thing,
> >> >but I don't know if they'll reply. Regex's are certainly complex. PERL
> >> >people tend to be pretty good at them, I believe. There are numerous
> >> >web sites and books on them if you need to acquire expertise for your
> >> >work.
> >> >
> >> >Cheers,
> >> >Bert
> >> >Bert Gunter
> >> >
> >> >"The trouble with having an open mind is that people keep coming along
> >> >and sticking things into it."
> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com>
> wrote:
> >> >> Hi Bert,
> >> >>
> >> >> I still couldn't make the multiple patterns to work. Here is an
> >> >example. I
> >> >> make the pattern as follows
> >> >>
> >> >> final.pattern <-
> >> >>
> >> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
> >> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
> >> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
> >> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
> >> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
> >> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
> >> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
> >> >>
> >> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
> >> >> '240.m.g.>50-70.kg.geo.mean')
> >> >>
> >> >> sub(final.pattern, '\\1', test.string)
> >> >> sub(final.pattern, '\\2', test.string)
> >> >> sub(final.pattern, '\\3', test.string)
> >> >>
> >> >> Only the third string has been correctly parsed, which matches the
> >> >first
> >> >> pattern. It seems the rest of the patterns are not called.
> >> >>
> >> >> Jun
> >> >>
> >> >>
> >> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com
> >
> >> >wrote:
> >> >>>
> >> >>> Just noticed: My clumsy do.call() line in my previously posted code
> >> >>> below should be replaced with:
> >> >>> pat <- paste(pat,collapse = "|")
> >> >>>
> >> >>>
> >> >>> > pat <- c(pat1,pat2)
> >> >>> > paste(pat,collapse="|")
> >> >>> [1] "a+\\.*a+|b+\\.*b+"
> >> >>>
> >> >>> ************ replace this **************************
> >> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> >>> ********************************************
> >> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
> >> >>> [1] "a.a"   "bb"    "b.bbb"
> >> >>>
> >> >>>
> >> >>> -- Bert
> >> >>> Bert Gunter
> >> >>>
> >> >>> "The trouble with having an open mind is that people keep coming
> >> >along
> >> >>> and sticking things into it."
> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>>
> >> >>>
> >> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
> >> ><bgunter.4567 at gmail.com>
> >> >>> wrote:
> >> >>> > Jun:
> >> >>> >
> >> >>> > You need to provide a clear specification via regular expressions
> >> >of
> >> >>> > the patterns you wish to match -- at least for me to decipher it.
> >> >>> > Others may be smarter than I, though...
> >> >>> >
> >> >>> > Jeff: Thanks. I have now convinced myself that it can be done (a
> >> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
> >> >patterns
> >> >>> > (in a vector of patterns)  to be matched in a vector of n strings,
> >> >>> > where only one of the patterns will match in any string,  then use
> >> >>> > paste() (probably via do.call()) or otherwise to paste them
> >> >together
> >> >>> > separated by "|" to form the concatenated pattern, pat. Then
> >> >>> >
> >> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
> >> >>> >
> >> >>> > should extract the matching pattern in each (perhaps with a little
> >> >>> > fiddling due to precedence rules); e.g.
> >> >>> >
> >> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
> >> >>> >
> >> >>> >> pat1 <- "a+\\.*a+"
> >> >>> >> pat2 <-"b+\\.*b+"
> >> >>> >> pat <- c(pat1,pat2)
> >> >>> >
> >> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> >>> >> pat
> >> >>> > [1] "a+\\.*a+|b+\\.*b+"
> >> >>> >
> >> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> >> >>> > [1] "a.a"   "bb"    "b.bbb"
> >> >>> >
> >> >>> > Cheers,
> >> >>> > Bert
> >> >>> >
> >> >>> >
> >> >>> > Bert Gunter
> >> >>> >
> >> >>> > "The trouble with having an open mind is that people keep coming
> >> >along
> >> >>> > and sticking things into it."
> >> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>> >
> >> >>> >
> >> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
> >> >wrote:
> >> >>> >> Thanks for the reply, Bert.
> >> >>> >>
> >> >>> >> Your solution solves the example. I actually have a more general
> >> >>> >> situation
> >> >>> >> where I have this dot concatenated string from multiple
> >> >variables. The
> >> >>> >> problem is those variables may have values with dots in there.
> >> >The
> >> >>> >> number of
> >> >>> >> dots are not consistent for all values of a variable. So I am
> >> >thinking
> >> >>> >> to
> >> >>> >> define a vector of patterns for the vector of the string and
> >> >hopefully
> >> >>> >> to
> >> >>> >> find a way to use a pattern from the pattern vector for each
> >> >value of
> >> >>> >> the
> >> >>> >> string vector. The only way I can think of is "for" loop, which
> >> >can be
> >> >>> >> slow.
> >> >>> >> Also these are happening in a function I am writing. Just wonder
> >> >if
> >> >>> >> there is
> >> >>> >> another more efficient way. Thanks a lot.
> >> >>> >>
> >> >>> >> Jun
> >> >>> >>
> >> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
> >> ><bgunter.4567 at gmail.com>
> >> >>> >> wrote:
> >> >>> >>>
> >> >>> >>> Well, he did provide an example, and...
> >> >>> >>>
> >> >>> >>>
> >> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >>> >>>
> >> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> >> >>> >>> [1] "WT.CUT" "tx"
> >> >>> >>>
> >> >>> >>>
> >> >>> >>> ## seems to do what was requested.
> >> >>> >>>
> >> >>> >>> Jeff would have to amplify on his initial statement however: do
> >> >you
> >> >>> >>> mean that separate patterns can always be combined via "|" ?  Or
> >> >>> >>> something deeper?
> >> >>> >>>
> >> >>> >>> Cheers,
> >> >>> >>> Bert
> >> >>> >>> Bert Gunter
> >> >>> >>>
> >> >>> >>> "The trouble with having an open mind is that people keep coming
> >> >along
> >> >>> >>> and sticking things into it."
> >> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> >> >)
> >> >>> >>>
> >> >>> >>>
> >> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
> >> >>> >>> <jdnewmil at dcn.davis.ca.us>
> >> >>> >>> wrote:
> >> >>> >>> > Your opening assertion is false.
> >> >>> >>> >
> >> >>> >>> > Provide a reproducible example and someone will demonstrate.
> >> >>> >>> > --
> >> >>> >>> > Sent from my phone. Please excuse my brevity.
> >> >>> >>> >
> >> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
> >> >>> >>> > <jun.shen.ut at gmail.com>
> >> >>> >>> > wrote:
> >> >>> >>> >>Dear list,
> >> >>> >>> >>
> >> >>> >>> >>I have a vector of strings that cannot be described by one
> >> >pattern.
> >> >>> >>> >> So
> >> >>> >>> >>let's say I construct a vector of patterns in the same length
> >> >as the
> >> >>> >>> >>vector
> >> >>> >>> >>of strings, can I do the element wise pattern recognition and
> >> >string
> >> >>> >>> >>substitution.
> >> >>> >>> >>
> >> >>> >>> >>For example,
> >> >>> >>> >>
> >> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >> >>> >>> >>
> >> >>> >>> >>patterns <- c(pattern1,pattern2)
> >> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >>> >>> >>
> >> >>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
> >> >from
> >> >>> >>> >> the
> >> >>> >>> >>second string. If I do
> >> >>> >>> >>
> >> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
> >> >used.
> >> >>> >>> >>
> >> >>> >>> >>looping the patterns doesn't work the way I want. Appreciate
> >> >any
> >> >>> >>> >>comments.
> >> >>> >>> >>Thanks.
> >> >>> >>> >>
> >> >>> >>> >>Jun
> >> >>> >>> >>
> >> >>> >>> >>       [[alternative HTML version deleted]]
> >> >>> >>> >>
> >> >>> >>> >>______________________________________________
> >> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >see
> >> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >>> >>PLEASE do read the posting guide
> >> >>> >>> >>http://www.R-project.org/posting-guide.html
> >> >>> >>> >>and provide commented, minimal, self-contained, reproducible
> >> >code.
> >> >>> >>> >
> >> >>> >>> > ______________________________________________
> >> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >see
> >> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >>> > PLEASE do read the posting guide
> >> >>> >>> > http://www.R-project.org/posting-guide.html
> >> >>> >>> > and provide commented, minimal, self-contained, reproducible
> >> >code.
> >> >>> >>
> >> >>> >>
> >> >>
> >> >>
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Sep  7 06:00:48 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Sep 2016 21:00:48 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbQzCsAvQyay405M-vHpyphUVpXTqTExOT6+KbssidHwog@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAGxFJbQzCsAvQyay405M-vHpyphUVpXTqTExOT6+KbssidHwog@mail.gmail.com>
Message-ID: <CAGxFJbSu3kRnUNf2rCO+pML9iVCBTCA4T-gJEhoXKpqfvBhFng@mail.gmail.com>

Jun:

"My problem is the pattern has to be dynamically constructed on the
input data of the function "

What does that mean? How can a pattern be "dynamically constructed"
when you have not made clear (at least to me, perhaps also to yourself
and/or others) *how* it is to be constructed?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 6, 2016 at 8:56 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Jeff:
>
> Not sure what you meant by this:
>
> "There is no other reason to put parentheses in the pattern... they
> are not grouping symbols."
>
> ... but in fact, from ?regexp
>
> "Repetition takes precedence over concatenation, which in turn takes
> precedence over alternation. A whole subexpression may be enclosed in
> parentheses to override these precedence rules. "
>
> So parentheses *are* in fact "grouping symbols."
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 6, 2016 at 5:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> I am not near my computer today, but each parenthesis gets its own result number, so you should put the parenthesis around the whole pattern of alternatives instead of having many parentheses.
>>
>> I recommend thinking in terms of what common information you expect to find in these various strings, and place your parentheses to capture that information. There is no other reason to put parentheses in the pattern... they are not grouping symbols.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>Jun:
>>>
>>>1. Tell us your desired result from your test vector and maybe someone
>>>will help.
>>>
>>>2. As we played this game once already (you couldn't do it; I showed
>>>you how), this seems to be a function of your limitations with regular
>>>expressions. I'm probably not much better, but in any case, I don't
>>>intend to be your consultant. See if you can find someone locally to
>>>help you if you do not receive a satisfactory reply from the list.
>>>There are many people here who are pretty good at this sort of thing,
>>>but I don't know if they'll reply. Regex's are certainly complex. PERL
>>>people tend to be pretty good at them, I believe. There are numerous
>>>web sites and books on them if you need to acquire expertise for your
>>>work.
>>>
>>>Cheers,
>>>Bert
>>>Bert Gunter
>>>
>>>"The trouble with having an open mind is that people keep coming along
>>>and sticking things into it."
>>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>>On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>>>> Hi Bert,
>>>>
>>>> I still couldn't make the multiple patterns to work. Here is an
>>>example. I
>>>> make the pattern as follows
>>>>
>>>> final.pattern <-
>>>>
>>>"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>>>>
>>>> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>>>> '240.m.g.>50-70.kg.geo.mean')
>>>>
>>>> sub(final.pattern, '\\1', test.string)
>>>> sub(final.pattern, '\\2', test.string)
>>>> sub(final.pattern, '\\3', test.string)
>>>>
>>>> Only the third string has been correctly parsed, which matches the
>>>first
>>>> pattern. It seems the rest of the patterns are not called.
>>>>
>>>> Jun
>>>>
>>>>
>>>> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>wrote:
>>>>>
>>>>> Just noticed: My clumsy do.call() line in my previously posted code
>>>>> below should be replaced with:
>>>>> pat <- paste(pat,collapse = "|")
>>>>>
>>>>>
>>>>> > pat <- c(pat1,pat2)
>>>>> > paste(pat,collapse="|")
>>>>> [1] "a+\\.*a+|b+\\.*b+"
>>>>>
>>>>> ************ replace this **************************
>>>>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>>> ********************************************
>>>>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>>>>> [1] "a.a"   "bb"    "b.bbb"
>>>>>
>>>>>
>>>>> -- Bert
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming
>>>along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>>><bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> > Jun:
>>>>> >
>>>>> > You need to provide a clear specification via regular expressions
>>>of
>>>>> > the patterns you wish to match -- at least for me to decipher it.
>>>>> > Others may be smarter than I, though...
>>>>> >
>>>>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>>>>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>>>patterns
>>>>> > (in a vector of patterns)  to be matched in a vector of n strings,
>>>>> > where only one of the patterns will match in any string,  then use
>>>>> > paste() (probably via do.call()) or otherwise to paste them
>>>together
>>>>> > separated by "|" to form the concatenated pattern, pat. Then
>>>>> >
>>>>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>>>>> >
>>>>> > should extract the matching pattern in each (perhaps with a little
>>>>> > fiddling due to precedence rules); e.g.
>>>>> >
>>>>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>>>>> >
>>>>> >> pat1 <- "a+\\.*a+"
>>>>> >> pat2 <-"b+\\.*b+"
>>>>> >> pat <- c(pat1,pat2)
>>>>> >
>>>>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>>> >> pat
>>>>> > [1] "a+\\.*a+|b+\\.*b+"
>>>>> >
>>>>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>>>>> > [1] "a.a"   "bb"    "b.bbb"
>>>>> >
>>>>> > Cheers,
>>>>> > Bert
>>>>> >
>>>>> >
>>>>> > Bert Gunter
>>>>> >
>>>>> > "The trouble with having an open mind is that people keep coming
>>>along
>>>>> > and sticking things into it."
>>>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> >
>>>>> >
>>>>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>>>wrote:
>>>>> >> Thanks for the reply, Bert.
>>>>> >>
>>>>> >> Your solution solves the example. I actually have a more general
>>>>> >> situation
>>>>> >> where I have this dot concatenated string from multiple
>>>variables. The
>>>>> >> problem is those variables may have values with dots in there.
>>>The
>>>>> >> number of
>>>>> >> dots are not consistent for all values of a variable. So I am
>>>thinking
>>>>> >> to
>>>>> >> define a vector of patterns for the vector of the string and
>>>hopefully
>>>>> >> to
>>>>> >> find a way to use a pattern from the pattern vector for each
>>>value of
>>>>> >> the
>>>>> >> string vector. The only way I can think of is "for" loop, which
>>>can be
>>>>> >> slow.
>>>>> >> Also these are happening in a function I am writing. Just wonder
>>>if
>>>>> >> there is
>>>>> >> another more efficient way. Thanks a lot.
>>>>> >>
>>>>> >> Jun
>>>>> >>
>>>>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>>><bgunter.4567 at gmail.com>
>>>>> >> wrote:
>>>>> >>>
>>>>> >>> Well, he did provide an example, and...
>>>>> >>>
>>>>> >>>
>>>>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>> >>>
>>>>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>>>> >>> [1] "WT.CUT" "tx"
>>>>> >>>
>>>>> >>>
>>>>> >>> ## seems to do what was requested.
>>>>> >>>
>>>>> >>> Jeff would have to amplify on his initial statement however: do
>>>you
>>>>> >>> mean that separate patterns can always be combined via "|" ?  Or
>>>>> >>> something deeper?
>>>>> >>>
>>>>> >>> Cheers,
>>>>> >>> Bert
>>>>> >>> Bert Gunter
>>>>> >>>
>>>>> >>> "The trouble with having an open mind is that people keep coming
>>>along
>>>>> >>> and sticking things into it."
>>>>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>>>)
>>>>> >>>
>>>>> >>>
>>>>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>>>> >>> <jdnewmil at dcn.davis.ca.us>
>>>>> >>> wrote:
>>>>> >>> > Your opening assertion is false.
>>>>> >>> >
>>>>> >>> > Provide a reproducible example and someone will demonstrate.
>>>>> >>> > --
>>>>> >>> > Sent from my phone. Please excuse my brevity.
>>>>> >>> >
>>>>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>>>>> >>> > <jun.shen.ut at gmail.com>
>>>>> >>> > wrote:
>>>>> >>> >>Dear list,
>>>>> >>> >>
>>>>> >>> >>I have a vector of strings that cannot be described by one
>>>pattern.
>>>>> >>> >> So
>>>>> >>> >>let's say I construct a vector of patterns in the same length
>>>as the
>>>>> >>> >>vector
>>>>> >>> >>of strings, can I do the element wise pattern recognition and
>>>string
>>>>> >>> >>substitution.
>>>>> >>> >>
>>>>> >>> >>For example,
>>>>> >>> >>
>>>>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>>> >>> >>
>>>>> >>> >>patterns <- c(pattern1,pattern2)
>>>>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>> >>> >>
>>>>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>>>from
>>>>> >>> >> the
>>>>> >>> >>second string. If I do
>>>>> >>> >>
>>>>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>>>used.
>>>>> >>> >>
>>>>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>>>any
>>>>> >>> >>comments.
>>>>> >>> >>Thanks.
>>>>> >>> >>
>>>>> >>> >>Jun
>>>>> >>> >>
>>>>> >>> >>       [[alternative HTML version deleted]]
>>>>> >>> >>
>>>>> >>> >>______________________________________________
>>>>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>> >>PLEASE do read the posting guide
>>>>> >>> >>http://www.R-project.org/posting-guide.html
>>>>> >>> >>and provide commented, minimal, self-contained, reproducible
>>>code.
>>>>> >>> >
>>>>> >>> > ______________________________________________
>>>>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>> > PLEASE do read the posting guide
>>>>> >>> > http://www.R-project.org/posting-guide.html
>>>>> >>> > and provide commented, minimal, self-contained, reproducible
>>>code.
>>>>> >>
>>>>> >>
>>>>
>>>>
>>


From bgunter.4567 at gmail.com  Wed Sep  7 06:06:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Sep 2016 21:06:21 -0700
Subject: [R] Run an external software in R
In-Reply-To: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
References: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
Message-ID: <CAGxFJbSpQc2b2Sr0snN0Hca7aCaJFKLQka+tbyz+_zu7KZoXJw@mail.gmail.com>

?system

But this begs the question: WHY would you want to do this? More
specifically, what should R communicate to your other software, and
what should the other software communicate to R?


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 6, 2016 at 6:13 PM, Marino David <davidmarino838 at gmail.com> wrote:
> Hi all R users:
>
> Does anybody have the experience of running an external software in R? I
> try to use R to run ANSYS software, which is a engineering simulation
> package. I ever have done this task in Matlab platform by executing
> the following code line:
>
> system('"C:\Program Files\Ansys Inc\v100\ANSYS\bin\intel\ansys100" -b -p
> ane3fl -i D:\Ansys\MyAnsysCode.txt -o D:\Ansys\vm5.out');
>
>
> Any idea regarding implementing this work is very welcome.
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Sep  7 06:25:51 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Sep 2016 21:25:51 -0700
Subject: [R] Run an external software in R
In-Reply-To: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
References: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
Message-ID: <CAF8bMcYxVnCSMko_OZKwh5qMs+CK5hninDLNhjdbGF4ah_NbBQ@mail.gmail.com>

You can use system() or shell(), which adds "cmd.exe /c " to the front of
your command
so you can use DOS syntax.  Remember to add double quotes when file names
have
spaces in them.  E.g., I can call an old version of R with the following
and later read its
text output into my current session.

> infile <- tempfile()
> cat("getRversion()\n", file=infile)
> outfile <- tempfile()
> shell(paste("\"C:\\Program Files\\R\\R-2.15.1\\bin\\R\" --quiet --vanilla
<", infile, ">", outfile))
> readLines(outfile)
[1] "> getRversion()" "[1] '2.15.1'"    "> "



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Sep 6, 2016 at 6:13 PM, Marino David <davidmarino838 at gmail.com>
wrote:

> Hi all R users:
>
> Does anybody have the experience of running an external software in R? I
> try to use R to run ANSYS software, which is a engineering simulation
> package. I ever have done this task in Matlab platform by executing
> the following code line:
>
> system('"C:\Program Files\Ansys Inc\v100\ANSYS\bin\intel\ansys100" -b -p
> ane3fl -i D:\Ansys\MyAnsysCode.txt -o D:\Ansys\vm5.out');
>
>
> Any idea regarding implementing this work is very welcome.
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep  7 09:04:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Sep 2016 00:04:09 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609062352360.64142@pedal.dcn.davis.ca.us>

Here are some suggestions:

test.string <- c( '240.m.g.>110.kg.geo.mean'
                 , '3.mg.kg.>110.kg.P05'
                 , '240.m.g.>50-70.kg.geo.mean'
                 )
# based on your literal idea
suggested.pattern1 <-
   "(240\\.m\\.g|3\\.mg\\.kg)\\.(>50-70\\.kg|>70-90\\.kg|>90-110\\.kg|50\\.kg\\.or\\.less|>110\\.kg)\\.(.*)"

resultL <- strsplit( sub( suggested.pattern1
                         , "\\1\t\\2\t\\3"
                         , test.string )
                    , split = "\t"
                    )

# equivalent based on apparent repetitive patterns in your sample data
suggested.pattern2 <- "(.*?m\\.g|kg)\\.(.*?kg|.*?less)\\.(.*)"

resultL2 <- strsplit( sub( suggested.pattern2
                          , "\\1\t\\2\t\\3"
                          , test.string
                          )
                     , split = "\t"
                     )

# put results into an organized table
DF <- setNames( data.frame( do.call( rbind, resultL ) )
               , c( "First", "Second", "Third" )
               )

By the way... please aim to make your examples reproducible. It would have 
been easy for you to define the necessary variables in example form
rather than sending a non-reproducible example.

On Tue, 6 Sep 2016, Jun Shen wrote:

> Hi Jeff,
> 
> Thanks for the reply. I tried your suggestion and it doesn't seem to work and I tried a simple pattern as follows and it works as expected
> 
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1', "3.mg.kg.>50-70.kg.P05")
> [1] "3.mg.kg"
> 
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2', "3.mg.kg.>50-70.kg.P05")
> [1] ">50-70.kg"
> 
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3', "3.mg.kg.>50-70.kg.P05")
> [1] "P05"
> 
> My problem is the pattern has to be dynamically constructed on the input data of the function I am writing. It's actually not too difficult
> to assemble the final.pattern with some code like the following
> 
> sort.var <- c('TX','WTCUT')
> combn.sort.var <- do.call(expand.grid, lapply(sort.var, function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))), ')',
> sep='')))
> all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
> final.pattern <- paste0(all.patterns, collapse='|')
> 
> You cannot run the code directly since the data object "all.exposure" is not provided here.
> 
> Jun
> 
> 
> 
> On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>       I am not near my computer today, but each parenthesis gets its own result number, so you should put the parenthesis around the
>       whole pattern of alternatives instead of having many parentheses.
>
>       I recommend thinking in terms of what common information you expect to find in these various strings, and place your parentheses
>       to capture that information. There is no other reason to put parentheses in the pattern... they are not grouping symbols.
>       --
>       Sent from my phone. Please excuse my brevity.
>
>       On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>       >Jun:
>       >
>       >1. Tell us your desired result from your test vector and maybe someone
>       >will help.
>       >
>       >2. As we played this game once already (you couldn't do it; I showed
>       >you how), this seems to be a function of your limitations with regular
>       >expressions. I'm probably not much better, but in any case, I don't
>       >intend to be your consultant. See if you can find someone locally to
>       >help you if you do not receive a satisfactory reply from the list.
>       >There are many people here who are pretty good at this sort of thing,
>       >but I don't know if they'll reply. Regex's are certainly complex. PERL
>       >people tend to be pretty good at them, I believe. There are numerous
>       >web sites and books on them if you need to acquire expertise for your
>       >work.
>       >
>       >Cheers,
>       >Bert
>       >Bert Gunter
>       >
>       >"The trouble with having an open mind is that people keep coming along
>       >and sticking things into it."
>       >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>       >
>       >
>       >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>       >> Hi Bert,
>       >>
>       >> I still couldn't make the multiple patterns to work. Here is an
>       >example. I
>       >> make the pattern as follows
>       >>
>       >> final.pattern <-
>       >>
> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.k
> g)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\
>       .kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>       >>
>       >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>       >> '240.m.g.>50-70.kg.geo.mean')
>       >>
>       >> sub(final.pattern, '\\1', test.string)
>       >> sub(final.pattern, '\\2', test.string)
>       >> sub(final.pattern, '\\3', test.string)
>       >>
>       >> Only the third string has been correctly parsed, which matches the
>       >first
>       >> pattern. It seems the rest of the patterns are not called.
>       >>
>       >> Jun
>       >>
>       >>
>       >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>       >wrote:
>       >>>
>       >>> Just noticed: My clumsy do.call() line in my previously posted code
>       >>> below should be replaced with:
>       >>> pat <- paste(pat,collapse = "|")
>       >>>
>       >>>
>       >>> > pat <- c(pat1,pat2)
>       >>> > paste(pat,collapse="|")
>       >>> [1] "a+\\.*a+|b+\\.*b+"
>       >>>
>       >>> ************ replace this **************************
>       >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>       >>> ********************************************
>       >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>       >>> [1] "a.a"? ?"bb"? ? "b.bbb"
>       >>>
>       >>>
>       >>> -- Bert
>       >>> Bert Gunter
>       >>>
>       >>> "The trouble with having an open mind is that people keep coming
>       >along
>       >>> and sticking things into it."
>       >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>       >>>
>       >>>
>       >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>       ><bgunter.4567 at gmail.com>
>       >>> wrote:
>       >>> > Jun:
>       >>> >
>       >>> > You need to provide a clear specification via regular expressions
>       >of
>       >>> > the patterns you wish to match -- at least for me to decipher it.
>       >>> > Others may be smarter than I, though...
>       >>> >
>       >>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>       >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>       >patterns
>       >>> > (in a vector of patterns)? to be matched in a vector of n strings,
>       >>> > where only one of the patterns will match in any string,? then use
>       >>> > paste() (probably via do.call()) or otherwise to paste them
>       >together
>       >>> > separated by "|" to form the concatenated pattern, pat. Then
>       >>> >
>       >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>       >>> >
>       >>> > should extract the matching pattern in each (perhaps with a little
>       >>> > fiddling due to precedence rules); e.g.
>       >>> >
>       >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>       >>> >
>       >>> >> pat1 <- "a+\\.*a+"
>       >>> >> pat2 <-"b+\\.*b+"
>       >>> >> pat <- c(pat1,pat2)
>       >>> >
>       >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>       >>> >> pat
>       >>> > [1] "a+\\.*a+|b+\\.*b+"
>       >>> >
>       >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>       >>> > [1] "a.a"? ?"bb"? ? "b.bbb"
>       >>> >
>       >>> > Cheers,
>       >>> > Bert
>       >>> >
>       >>> >
>       >>> > Bert Gunter
>       >>> >
>       >>> > "The trouble with having an open mind is that people keep coming
>       >along
>       >>> > and sticking things into it."
>       >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>       >>> >
>       >>> >
>       >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>       >wrote:
>       >>> >> Thanks for the reply, Bert.
>       >>> >>
>       >>> >> Your solution solves the example. I actually have a more general
>       >>> >> situation
>       >>> >> where I have this dot concatenated string from multiple
>       >variables. The
>       >>> >> problem is those variables may have values with dots in there.
>       >The
>       >>> >> number of
>       >>> >> dots are not consistent for all values of a variable. So I am
>       >thinking
>       >>> >> to
>       >>> >> define a vector of patterns for the vector of the string and
>       >hopefully
>       >>> >> to
>       >>> >> find a way to use a pattern from the pattern vector for each
>       >value of
>       >>> >> the
>       >>> >> string vector. The only way I can think of is "for" loop, which
>       >can be
>       >>> >> slow.
>       >>> >> Also these are happening in a function I am writing. Just wonder
>       >if
>       >>> >> there is
>       >>> >> another more efficient way. Thanks a lot.
>       >>> >>
>       >>> >> Jun
>       >>> >>
>       >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>       ><bgunter.4567 at gmail.com>
>       >>> >> wrote:
>       >>> >>>
>       >>> >>> Well, he did provide an example, and...
>       >>> >>>
>       >>> >>>
>       >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>       >>> >>>
>       >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>       >>> >>> [1] "WT.CUT" "tx"
>       >>> >>>
>       >>> >>>
>       >>> >>> ## seems to do what was requested.
>       >>> >>>
>       >>> >>> Jeff would have to amplify on his initial statement however: do
>       >you
>       >>> >>> mean that separate patterns can always be combined via "|" ?? Or
>       >>> >>> something deeper?
>       >>> >>>
>       >>> >>> Cheers,
>       >>> >>> Bert
>       >>> >>> Bert Gunter
>       >>> >>>
>       >>> >>> "The trouble with having an open mind is that people keep coming
>       >along
>       >>> >>> and sticking things into it."
>       >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>       >)
>       >>> >>>
>       >>> >>>
>       >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>       >>> >>> <jdnewmil at dcn.davis.ca.us>
>       >>> >>> wrote:
>       >>> >>> > Your opening assertion is false.
>       >>> >>> >
>       >>> >>> > Provide a reproducible example and someone will demonstrate.
>       >>> >>> > --
>       >>> >>> > Sent from my phone. Please excuse my brevity.
>       >>> >>> >
>       >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>       >>> >>> > <jun.shen.ut at gmail.com>
>       >>> >>> > wrote:
>       >>> >>> >>Dear list,
>       >>> >>> >>
>       >>> >>> >>I have a vector of strings that cannot be described by one
>       >pattern.
>       >>> >>> >> So
>       >>> >>> >>let's say I construct a vector of patterns in the same length
>       >as the
>       >>> >>> >>vector
>       >>> >>> >>of strings, can I do the element wise pattern recognition and
>       >string
>       >>> >>> >>substitution.
>       >>> >>> >>
>       >>> >>> >>For example,
>       >>> >>> >>
>       >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>       >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>       >>> >>> >>
>       >>> >>> >>patterns <- c(pattern1,pattern2)
>       >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>       >>> >>> >>
>       >>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>       >from
>       >>> >>> >> the
>       >>> >>> >>second string. If I do
>       >>> >>> >>
>       >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>       >used.
>       >>> >>> >>
>       >>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>       >any
>       >>> >>> >>comments.
>       >>> >>> >>Thanks.
>       >>> >>> >>
>       >>> >>> >>Jun
>       >>> >>> >>
>       >>> >>> >>? ? ? ?[[alternative HTML version deleted]]
>       >>> >>> >>
>       >>> >>> >>______________________________________________
>       >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>       >see
>       >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>       >>> >>> >>PLEASE do read the posting guide
>       >>> >>> >>http://www.R-project.org/posting-guide.html
>       >>> >>> >>and provide commented, minimal, self-contained, reproducible
>       >code.
>       >>> >>> >
>       >>> >>> > ______________________________________________
>       >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>       >see
>       >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>       >>> >>> > PLEASE do read the posting guide
>       >>> >>> > http://www.R-project.org/posting-guide.html
>       >>> >>> > and provide commented, minimal, self-contained, reproducible
>       >code.
>       >>> >>
>       >>> >>
>       >>
>       >>
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jdnewmil at dcn.davis.ca.us  Wed Sep  7 09:09:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 7 Sep 2016 00:09:38 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAGxFJbQzCsAvQyay405M-vHpyphUVpXTqTExOT6+KbssidHwog@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAGxFJbQzCsAvQyay405M-vHpyphUVpXTqTExOT6+KbssidHwog@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609070005470.64142@pedal.dcn.davis.ca.us>

My error. However, Jun has been severely abusing them... such use is 
unusual, and the "(?:" non-capturing group marker was invented because the
capture side effect is so central to the use of the regular parenthesis.

On Tue, 6 Sep 2016, Bert Gunter wrote:

> Jeff:
>
> Not sure what you meant by this:
>
> "There is no other reason to put parentheses in the pattern... they
> are not grouping symbols."
>
> ... but in fact, from ?regexp
>
> "Repetition takes precedence over concatenation, which in turn takes
> precedence over alternation. A whole subexpression may be enclosed in
> parentheses to override these precedence rules. "
>
> So parentheses *are* in fact "grouping symbols."
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 6, 2016 at 5:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> I am not near my computer today, but each parenthesis gets its own result number, so you should put the parenthesis around the whole pattern of alternatives instead of having many parentheses.
>>
>> I recommend thinking in terms of what common information you expect to find in these various strings, and place your parentheses to capture that information. There is no other reason to put parentheses in the pattern... they are not grouping symbols.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Jun:
>>>
>>> 1. Tell us your desired result from your test vector and maybe someone
>>> will help.
>>>
>>> 2. As we played this game once already (you couldn't do it; I showed
>>> you how), this seems to be a function of your limitations with regular
>>> expressions. I'm probably not much better, but in any case, I don't
>>> intend to be your consultant. See if you can find someone locally to
>>> help you if you do not receive a satisfactory reply from the list.
>>> There are many people here who are pretty good at this sort of thing,
>>> but I don't know if they'll reply. Regex's are certainly complex. PERL
>>> people tend to be pretty good at them, I believe. There are numerous
>>> web sites and books on them if you need to acquire expertise for your
>>> work.
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>>>> Hi Bert,
>>>>
>>>> I still couldn't make the multiple patterns to work. Here is an
>>> example. I
>>>> make the pattern as follows
>>>>
>>>> final.pattern <-
>>>>
>>> "(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>>>>
>>>> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>>>> '240.m.g.>50-70.kg.geo.mean')
>>>>
>>>> sub(final.pattern, '\\1', test.string)
>>>> sub(final.pattern, '\\2', test.string)
>>>> sub(final.pattern, '\\3', test.string)
>>>>
>>>> Only the third string has been correctly parsed, which matches the
>>> first
>>>> pattern. It seems the rest of the patterns are not called.
>>>>
>>>> Jun
>>>>
>>>>
>>>> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>>>
>>>>> Just noticed: My clumsy do.call() line in my previously posted code
>>>>> below should be replaced with:
>>>>> pat <- paste(pat,collapse = "|")
>>>>>
>>>>>
>>>>>> pat <- c(pat1,pat2)
>>>>>> paste(pat,collapse="|")
>>>>> [1] "a+\\.*a+|b+\\.*b+"
>>>>>
>>>>> ************ replace this **************************
>>>>>> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>>> ********************************************
>>>>>> sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>>>>> [1] "a.a"   "bb"    "b.bbb"
>>>>>
>>>>>
>>>>> -- Bert
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming
>>> along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>>> <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>> Jun:
>>>>>>
>>>>>> You need to provide a clear specification via regular expressions
>>> of
>>>>>> the patterns you wish to match -- at least for me to decipher it.
>>>>>> Others may be smarter than I, though...
>>>>>>
>>>>>> Jeff: Thanks. I have now convinced myself that it can be done (a
>>>>>> "proof" of sorts): If pat1, pat2,..., patn are m different
>>> patterns
>>>>>> (in a vector of patterns)  to be matched in a vector of n strings,
>>>>>> where only one of the patterns will match in any string,  then use
>>>>>> paste() (probably via do.call()) or otherwise to paste them
>>> together
>>>>>> separated by "|" to form the concatenated pattern, pat. Then
>>>>>>
>>>>>> sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>>>>>>
>>>>>> should extract the matching pattern in each (perhaps with a little
>>>>>> fiddling due to precedence rules); e.g.
>>>>>>
>>>>>>> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>>>>>>
>>>>>>> pat1 <- "a+\\.*a+"
>>>>>>> pat2 <-"b+\\.*b+"
>>>>>>> pat <- c(pat1,pat2)
>>>>>>
>>>>>>> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>>>>> pat
>>>>>> [1] "a+\\.*a+|b+\\.*b+"
>>>>>>
>>>>>>> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>>>>>> [1] "a.a"   "bb"    "b.bbb"
>>>>>>
>>>>>> Cheers,
>>>>>> Bert
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming
>>> along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>>> wrote:
>>>>>>> Thanks for the reply, Bert.
>>>>>>>
>>>>>>> Your solution solves the example. I actually have a more general
>>>>>>> situation
>>>>>>> where I have this dot concatenated string from multiple
>>> variables. The
>>>>>>> problem is those variables may have values with dots in there.
>>> The
>>>>>>> number of
>>>>>>> dots are not consistent for all values of a variable. So I am
>>> thinking
>>>>>>> to
>>>>>>> define a vector of patterns for the vector of the string and
>>> hopefully
>>>>>>> to
>>>>>>> find a way to use a pattern from the pattern vector for each
>>> value of
>>>>>>> the
>>>>>>> string vector. The only way I can think of is "for" loop, which
>>> can be
>>>>>>> slow.
>>>>>>> Also these are happening in a function I am writing. Just wonder
>>> if
>>>>>>> there is
>>>>>>> another more efficient way. Thanks a lot.
>>>>>>>
>>>>>>> Jun
>>>>>>>
>>>>>>> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>>> <bgunter.4567 at gmail.com>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>> Well, he did provide an example, and...
>>>>>>>>
>>>>>>>>
>>>>>>>>> z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>>>>>
>>>>>>>>> sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>>>>>>> [1] "WT.CUT" "tx"
>>>>>>>>
>>>>>>>>
>>>>>>>> ## seems to do what was requested.
>>>>>>>>
>>>>>>>> Jeff would have to amplify on his initial statement however: do
>>> you
>>>>>>>> mean that separate patterns can always be combined via "|" ?  Or
>>>>>>>> something deeper?
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>> Bert
>>>>>>>> Bert Gunter
>>>>>>>>
>>>>>>>> "The trouble with having an open mind is that people keep coming
>>> along
>>>>>>>> and sticking things into it."
>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>>> )
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>>>>>>> <jdnewmil at dcn.davis.ca.us>
>>>>>>>> wrote:
>>>>>>>>> Your opening assertion is false.
>>>>>>>>>
>>>>>>>>> Provide a reproducible example and someone will demonstrate.
>>>>>>>>> --
>>>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>>>>
>>>>>>>>> On September 4, 2016 9:06:59 PM PDT, Jun Shen
>>>>>>>>> <jun.shen.ut at gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>> Dear list,
>>>>>>>>>>
>>>>>>>>>> I have a vector of strings that cannot be described by one
>>> pattern.
>>>>>>>>>> So
>>>>>>>>>> let's say I construct a vector of patterns in the same length
>>> as the
>>>>>>>>>> vector
>>>>>>>>>> of strings, can I do the element wise pattern recognition and
>>> string
>>>>>>>>>> substitution.
>>>>>>>>>>
>>>>>>>>>> For example,
>>>>>>>>>>
>>>>>>>>>> pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>>>>>>>> pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>>>>>>>>
>>>>>>>>>> patterns <- c(pattern1,pattern2)
>>>>>>>>>> strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>>>>>>>>
>>>>>>>>>> Say I want to extract "WT.CUT" from the first string and "tx"
>>> from
>>>>>>>>>> the
>>>>>>>>>> second string. If I do
>>>>>>>>>>
>>>>>>>>>> sub(patterns, '\\2', strings), only the first pattern will be
>>> used.
>>>>>>>>>>
>>>>>>>>>> looping the patterns doesn't work the way I want. Appreciate
>>> any
>>>>>>>>>> comments.
>>>>>>>>>> Thanks.
>>>>>>>>>>
>>>>>>>>>> Jun
>>>>>>>>>>
>>>>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>
>>>>>>>
>>>>
>>>>
>>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From david at agros.it  Wed Sep  7 09:23:20 2016
From: david at agros.it (David Remotti)
Date: Wed, 7 Sep 2016 09:23:20 +0200
Subject: [R] Run an external software in R
In-Reply-To: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
References: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
Message-ID: <f6d27429-6863-7889-7e80-297391d22755@agros.it>

I use the opposite approach ... run R from another software (usually a 
GUI developed in VB), using Rscript from dos command line.

Maybe you can get the level of communication you need.

David Remotti


Il 07/09/2016 03:13, Marino David ha scritto:
> Hi all R users:
>
> Does anybody have the experience of running an external software in R? I
> try to use R to run ANSYS software, which is a engineering simulation
> package. I ever have done this task in Matlab platform by executing
> the following code line:
>
> system('"C:\Program Files\Ansys Inc\v100\ANSYS\bin\intel\ansys100" -b -p
> ane3fl -i D:\Ansys\MyAnsysCode.txt -o D:\Ansys\vm5.out');
>
>
> Any idea regarding implementing this work is very welcome.
>
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From c8linmch at googlemail.com  Tue Sep  6 20:40:28 2016
From: c8linmch at googlemail.com (caitlin mchugh)
Date: Tue, 6 Sep 2016 14:40:28 -0400
Subject: [R] Error while running Vegas function in cpvSNP package
In-Reply-To: <CACboDEr9FytgCX53A1x2dEp6o3oh3KXAy16VmdCVNZTytEr59A@mail.gmail.com>
References: <CACboDEr9FytgCX53A1x2dEp6o3oh3KXAy16VmdCVNZTytEr59A@mail.gmail.com>
Message-ID: <CAOqeDRUzb6CkaB_TE=Ox4tWOMH3fnidanMCirEW6SGe9CwfVng@mail.gmail.com>

Hello,

Please find attached a script where I tried to replicate the issue. I was
unable to reproduce the error. Perhaps you can send me more details?

Also, it appears the LD matrix you are using is not symmetric nor does it
have 1's on the diagonal. Both of these things should be satisfied for the
algorithm to work properly.

Feel free to let me know if you continue to run into errors.

Thanks,
Caitlin

On Thu, Sep 1, 2016 at 6:24 AM, MLSC <mlscmahe at gmail.com> wrote:

> Hello Sir,
>
> When I try to run vegas() function, I come across below errors, can
> somebody help me in fixing this issue?
>
> > test<-vegas(snpsGSC, gr,ldMat,1000,correction=TRUE,seed=NULL,
> verbose=FALSE)
> Warning: coercing ldMatrix from data.frame to matrix.
> Error in validObject(.Object) :
>   invalid class ?VEGASResultCollection? object: members must all be
> 'VEGASResult' classes
> > test<-vegas(gs2, gr,ldMat,1000,correction=TRUE,seed=NULL, verbose=FALSE)
> Warning: coercing ldMatrix from data.frame to matrix.
> Error in validObject(.Object) :
>   invalid class ?VEGASResultCollection? object: members must all be
> 'VEGASResult' classes
>
>
> Please find structure of objects used inside vegas(), below
>
>
> > class(gs2)
> [1] "GeneSetCollection"
> attr(,"package")
> [1] "GSEABase"
> > gs2
> GeneSetCollection
>   names: NA (1 total)
>   unique identifiers: 730005, 23755, ..., 23762 (8 total)
>   types in collection:
>     geneIdType: NullIdentifier (1 total)
>     collectionType: NullCollection (1 total)
> > snpsGSC
> GeneSetCollection
>   names: NA (1 total)
>   unique identifiers: rs9608956, rs6518694, ..., rs2240176 (117 total)
>   types in collection:
>     geneIdType: AnnotationIdentifier (1 total)
>     collectionType: NullCollection (1 total)
> > gr
> GRanges object with 10357 ranges and 6 metadata columns:
>           seqnames               ranges strand   |         P         SNP
>              <Rle>            <IRanges>  <Rle>   | <numeric> <character>
>       [1]    chr22 [16114244, 16114244]      *   |    0.9298  rs12157537
>       [2]    chr22 [16494187, 16494187]      *   |    0.2571   rs8142331
>       [3]    chr22 [16855618, 16855618]      *   |    0.3743   rs5747010
>       [4]    chr22 [17012935, 17012935]      *   |    0.1005   rs9604821
>       [5]    chr22 [17057138, 17057138]      *   |    0.5120   rs5746647
>       ...      ...                  ...    ... ...       ...         ...
>   [10353]    chr22 [51171693, 51171693]      *   |    0.6500    rs756638
>   [10354]    chr22 [51175626, 51175626]      *   |    0.5235   rs3810648
>   [10355]    chr22 [51178090, 51178090]      *   |    0.2008   rs2285395
>   [10356]    chr22 [51181759, 51181759]      *   |    0.4858  rs13056621
>   [10357]    chr22 [51211392, 51211392]      *   |    0.2952   rs3888396
>            Position Chromosome     Start       End
>           <integer>   <factor> <integer> <integer>
>       [1]  16114244      chr22  16114244  16114244
>       [2]  16494187      chr22  16494187  16494187
>       [3]  16855618      chr22  16855618  16855618
>       [4]  17012935      chr22  17012935  17012935
>       [5]  17057138      chr22  17057138  17057138
>       ...       ...        ...       ...       ...
>   [10353]  51171693      chr22  51171693  51171693
>   [10354]  51175626      chr22  51175626  51175626
>   [10355]  51178090      chr22  51178090  51178090
>   [10356]  51181759      chr22  51181759  51181759
>   [10357]  51211392      chr22  51211392  51211392
>   -------
>   seqinfo: 1 sequence from an unspecified genome; no seqlengths
>
> >ldMat
>                rs756638    rs3810648    rs2285395   rs13056621    rs3888396
> rs133433   2.302381e-04 1.593234e-03 1.745740e-03 3.279513e-03 1.135283e-03
> rs4645824  3.435556e-04 2.872766e-03 6.350416e-05 9.143595e-04 2.032939e-03
> rs12165592 1.164639e-04 6.331347e-03 1.911289e-03 2.124385e-03 7.972265e-04
> rs2413348  1.148297e-04 4.106582e-03 1.857187e-03 9.805785e-04 5.707284e-04
> rs5755729  6.863351e-04 7.718787e-04 1.794326e-04 9.102677e-05 1.835078e-05
> rs5755730  6.606449e-04 1.817608e-03 2.795217e-04 2.912946e-04 1.582141e-03
> rs738207   3.193647e-03 1.833686e-06 2.162108e-06 1.377696e-03 3.024123e-03
> rs28528068 5.097169e-04 9.289022e-05 8.253080e-05 9.775527e-06 4.618146e-04
> rs9610304  2.185120e-05 1.753900e-03 3.760546e-04 4.235130e-06 7.791331e-04
> rs5999844  1.511305e-04 5.263161e-05 1.594619e-04 3.668878e-04 9.886630e-05
> rs8136332  1.466643e-04 6.929900e-04 1.128017e-05 1.327246e-03 3.758860e-04
> rs909704   9.107431e-05 6.988505e-05 8.734125e-04 6.070963e-04 1.666259e-05
> rs10483191 1.563958e-04 6.843857e-04 1.050799e-05 1.289273e-03 3.944796e-04
> rs880211   7.008708e-05 3.167541e-03 6.418652e-04 2.483367e-04 1.344723e-03
> rs1107498  1.888331e-04 2.733062e-03 6.233536e-04 3.931746e-04 1.341147e-03
> rs5999855  3.143964e-05 5.473455e-03 1.166912e-03 4.374772e-03 2.152193e-03
> rs9610308  1.579521e-05 5.385714e-06 1.199517e-06 3.337275e-03 4.705493e-04
> rs713968   1.125728e-03 2.431651e-05 7.292905e-05 9.684127e-04 6.402607e-05
> rs139059   2.946244e-04 2.765441e-04 2.785183e-06 7.474786e-04 3.190005e-04
>  [ reached getOption("max.print") -- omitted 4981 rows ]
>
> Please find session info below,
> > sessionInfo()
> R version 3.2.4 Revised (2016-03-16 r70336)
> Platform: x86_64-pc-linux-gnu/64 (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats4    parallel  stats     graphics  grDevices utils     datasets
> [8] methods   base
>
> other attached packages:
>  [1] TxDb.Hsapiens.UCSC.hg18.knownGene_3.2.2
>  [2] VariantAnnotation_1.16.4
>  [3] Rsamtools_1.22.0
>  [4] Biostrings_2.38.4
>  [5] XVector_0.10.0
>  [6] SummarizedExperiment_1.0.2
>  [7] biomaRt_2.26.1
>  [8] snpStats_1.20.0
>  [9] Matrix_1.2-6
> [10] survival_2.39-5
> [11] genetics_1.3.8.1
> [12] mvtnorm_1.0-5
> [13] gtools_3.5.0
> [14] gdata_2.17.0
> [15] combinat_0.0-8
> [16] MultiPhen_2.0.1
> [17] meta_4.5-0
> [18] epitools_0.5-7
> [19] abind_1.4-5
> [20] MASS_7.3-45
> [21] BiocInstaller_1.20.3
> [22] TxDb.Hsapiens.UCSC.hg19.knownGene_3.2.2
> [23] cpvSNP_1.2.0
> [24] GSEABase_1.32.0
> [25] graph_1.48.0
> [26] annotate_1.48.0
> [27] XML_3.98-1.4
> [28] GenomicFeatures_1.22.13
> [29] AnnotationDbi_1.32.3
> [30] Biobase_2.30.0
> [31] GenomicRanges_1.22.4
> [32] GenomeInfoDb_1.6.3
> [33] IRanges_2.4.8
> [34] S4Vectors_0.8.11
> [35] BiocGenerics_0.16.1
>
> loaded via a namespace (and not attached):
>  [1] splines_3.2.4           lattice_0.20-33
> colorspace_1.2-6
>  [4] rtracklayer_1.30.4      HardyWeinberg_1.5.6
> DBI_0.5
>  [7] BiocParallel_1.4.3      RColorBrewer_1.1-2
> lambda.r_1.1.9
> [10] plyr_1.8.4              zlibbioc_1.16.0
> munsell_0.4.3
> [13] gtable_0.2.0            futile.logger_1.4.3
> caTools_1.17.1
> [16] Rcpp_0.12.6             KernSmooth_2.23-15
> xtable_1.8-2
> [19] corpcor_1.6.8           BSgenome_1.38.0
> scales_0.4.0
> [22] gplots_3.0.1            ggplot2_2.1.0
> grid_3.2.4
> [25] tools_3.2.4             bitops_1.0-6
> RCurl_1.95-4.8
> [28] RSQLite_1.0.0           mice_2.25
> futile.options_1.0.0
> [31] rpart_4.1-10            GenomicAlignments_1.6.3
> nnet_7.3-12
> >
>
> Thanking you in anticipation.
>
> Regards,
> Prashantha
>
>
>

From vwkv13 at mun.ca  Tue Sep  6 21:51:41 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Tue, 6 Sep 2016 13:51:41 -0600
Subject: [R] Pass an optional argument from Fortran subroutine to a R wrapper
Message-ID: <CALStW+otZ6vNJp+5mTtOYiX0zm5XHi_5KsbzFKyTUpt5=eW4Mw@mail.gmail.com>

Hello,

I have a Fortran subroutine which uses an optional argument in the call.

    subroutine data (n,ns,alpha,covmat,x,y)

    integer, intent(in):: n,ns
    double precision, intent(in)  :: alpha
    double precision, intent(in), optional ::covmat(n,ns)
    double precision, intent(out) :: x(n),y(n)
    ....
    end subroutine data

I tried the following R wrapper for this subroutine and got an error saying,

     Error in array(x, c(length(x), 1L), if (!is.null(names(x)))
list(names(x), :
    'data' must be of a vector type, was 'NULL'

I'm not sure if I passed the arguments correctly in the .Fortran() call. I
couldn't find anything helpful online. I would really appreciate any
help/comments.

    data1 <- function(n,ns,alpha,covmat=NULL){

    tmp <- .Fortran("data",
    n = as.integer(n),ns= as.integer(ns)
    alpha=as.numeric(alpha),covmat=as.matrix(covmat),
    x=as.double(rep(0,n)),y=as.double(rep(0,n)))
    )
     }
    result <- list(x=tmp$x, y=tmp$y)

    return(result)
    }

Thanks,
Vineetha

	[[alternative HTML version deleted]]


From pgilbert902 at gmail.com  Tue Sep  6 22:12:21 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 6 Sep 2016 16:12:21 -0400
Subject: [R] how to transform db query result into a set of timeseries
In-Reply-To: <mailman.5.1473156001.15128.r-help@r-project.org>
References: <mailman.5.1473156001.15128.r-help@r-project.org>
Message-ID: <8fa99f7a-be86-20fa-ee58-5e5c8fc1491d@gmail.com>

There is a utility function TSquery() in package TSsql that attempts to 
do this. Most of the functions in that package are for databases with a 
specific layout intended for storing time series, but TSquery() attempts 
to build a series from a somewhat arbitrary database. It is hard to be 
completely generic and handle every possible database structure, so you 
might just examine the function for hints. I think it does not handle 
%H:%M:%S but the general logic should help.

The main problem is that your query is not guaranteed to return data in 
time order. (You may be lucky if you loaded it that way, but it can 
change unexpectedly.) You can do the ordering with the xts() order.by 
argument but it is probably quicker to do it in the db so you need less 
manipulation of the data you get back. TSquery() uses   ORDER BY in the 
sql query to ensure the order:

    q <- paste(q, " GROUP BY ", dates, " ORDER BY ", dates, " ;")

If the query result is df then I think you can construct your series 
simply with

   zonnen <- xts( cbind(df$M. df$G, df$N),
                  order.by = as.POSIXct( df$Date,
                        format="%Y-%m-%d %H:%M:%S") )

There are several other details in the function that you may find useful.

Paul Gilbert

> Date: Mon, 5 Sep 2016 22:28:50 +0200
> From: Stef Mientki <stef.mientki at gmail.com>
> hello,
>
> I've a number of timeseries into a database and want to display these
> timeseries into graph.
>
> Now the code below works well, but as the user can select which
> timeseries should be shown (up to 20 timeseries) the code below should
> be dynamic and can be quiet large and complex.
>
> Is there an easier way to convert a database result into timeseries
> accepted by dygraph ?
>
>      SQL <- "select Date, M, G, N from Compare_Model"
>      df <- dbGetQuery ( con, statement = SQL )
>
>      zon1 <- xts ( df$M,  as.POSIXct ( df$Date, format="%Y-%m-%d
> %H:%M:%S") )
>      zon2 <- xts ( df$G,  as.POSIXct ( df$Date, format="%Y-%m-%d
> %H:%M:%S") )
>      zon3 <- xts ( df$N,  as.POSIXct ( df$Date, format="%Y-%m-%d
> %H:%M:%S") )
>
>      zonnen <- Reduce ( function(...) merge(..., all=TRUE ), list ( zon,
> zon2, zon3 ))
>
>      dygraph ( zonnen )
>
>
> thanks,
>
> Stef


From erikareb at gmail.com  Tue Sep  6 22:52:21 2016
From: erikareb at gmail.com (=?UTF-8?Q?Erika_Roc=C3=ADo_Espinosa_Balbuena?=)
Date: Tue, 6 Sep 2016 15:52:21 -0500
Subject: [R] Help with a code in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJMJkRJ810YLdivjief5Xrh1K=5VAfkkVdvhuzgAb_B7wHpGfA@mail.gmail.com>

Hi,

Yes the objetcs have the same structure, and forecast_nal is the variable
where I a trying to keep all the results of the forecast but I get the
error that it is only allowed the replacement.

2016-09-06 1:31 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> Well, it seems to me that it is coded in different language like C++.
> The code is not reproducible but the error seems to be from your call of ts
>
> You can check it line by line with setting i to arbitrary value and
> inspect how your objects look like, however some of your constructions
> seems to me quite weird.
>
> e.g.
> forecast_nal<-data.frame()
>
> leads to mempty data frame with no column named mean
> > forecast_nal
> data frame with 0 columns and 0 rows
> > forecast_nal$mean
> NULL
>
> and I am rather surprised how this column come into existence.
>
> BTW, are you sure that in each cycle your rbinded or cbinded objects have
> the same size?
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erika
> Roc?o
> > Espinosa Balbuena
> > Sent: Monday, September 5, 2016 8:26 PM
> > To: r-help at r-project.org
> > Subject: [R] Help with a code in R
> >
> > Hi,
> >
> > I am working with this code:
> >
> > forecast_nal<-data.frame()
> > out<-vector()
> > x<-foreach(i=1:nrow(comb)) %do%
> > {
> >
> > s<-comb[i,'prod_id']
> >
> > #Familia+Sumbarca+prod_id
> > #Serie
> >
> > bcomb1<-b
> > bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> > bcomb1<-arrange(bcomb1,year,week)
> > a<-bcomb1[1:1,'week']
> > d<-bcomb1[1:1,'year']
> > f<-nrow(bcomb1)
> > h<-bcomb1[f:f,'year']
> > j<-bcomb1[f:f,'week']
> > bcomb1<-bcomb1[,c(6)]
> >
> > if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48)) { out[i]<-s
> }
> > else {
> >        y <- ts(bcomb1, frequency=52, start=c(d, a)) ##Casos
> >
> > if (length(y)<=60)
> > {
> >
> > v<-auto.arima(y)
> > v<-arimaorder(v)
> > fit <- arima(y, order = v ,method="ML")
> >       fca <- forecast(fit, h = 16)
> > dates <- attr(forecast_nal$mean, "tsp")
> > datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> > fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> > forecast_nal<- rbind.data.frame(forecast_nal,fct)
> > }
> > else
> > {
> >
> > fit <- tbats(y)
> > fcb <- forecast(fit, h = 16)
> > dates <- attr(forecast_nal$mean, "tsp")
> > datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> > fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
> >             forecast_nal<- rbind.data.frame(forecast_nal,fct)
> > }
> > }
> > }
> >  But I am getting this error:
> >
> > Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833,
> 26750.9374514082,
> >  :
> >   only replacement of elements is allowed
> >
> > Can someone help me with this?
> >
> > Thanks
> >
> >
> > --
> > Erika Roc?o Espinosa Balbuena
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Erika Roc?o Espinosa Balbuena

	[[alternative HTML version deleted]]


From nickpardikes at gmail.com  Wed Sep  7 00:05:06 2016
From: nickpardikes at gmail.com (Nick Pardikes)
Date: Tue, 6 Sep 2016 15:05:06 -0700
Subject: [R] Resample with replacement to produce many rarefaction curves
 with same number of samples
Message-ID: <CABh5y=7bwOF9dP-M8YK0g2idKophnBqaLdoT=R0qFpNZhh13Og@mail.gmail.com>

I am currently having difficulty producing a graph using rarecurve in the
vegan package. I have produced rarefaction curves (seen below) using the
following code.


library(vegan)

myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
communities

netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
species (columns)

raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
rarecurve to plot a rarefaction for each individual community (n=50)


However I would like to produce a graph in which all rarefaction curves end
at the same sample size. For example, in this graph it would be great to
extend the x-axis (sample size) to 100 and have all curves end at this
point. Is there any way to use rarecurve to resample a community (row) with
replacement the same number of times for all 50 communities? With
replacement is important because the communities differ greatly in their
size (number of species).


I understand that rarefaction is useful to compare communities with
different sample efforts, but I would still like to generate the figure. My
actual data has 5000 simulated communities that differ greatly in matrix
size and number of samples.


Thank you in advance for your help and suggestions.


Cheers,

Nick

-- 
Nick Pardikes
PhD Candidate
Program in Ecology, Evolution, and Conservation Biology
University of Nevada
*https://nickpardikes.wordpress.com/ <https://nickpardikes.wordpress.com/>*
nickpardikes at gmail.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rarefaction.pdf
Type: application/pdf
Size: 19167 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160906/b3b6dabe/attachment.pdf>

From nickpardikes at gmail.com  Wed Sep  7 00:06:11 2016
From: nickpardikes at gmail.com (Nick Pardikes)
Date: Tue, 6 Sep 2016 15:06:11 -0700
Subject: [R] Resample with replacement to produce many rarefaction curves
 with same number of samples
Message-ID: <CABh5y=6Rs+qnoF3U8v3smYTufy+oBupT+hhyNSF0DbJMuLUyHg@mail.gmail.com>

Greetings,
I am currently having difficulty producing a graph using rarecurve in
the vegan package. I have produced rarefaction curves (seen below)
using the following code.


library(vegan)

myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of communities

netdata <- as.data.frame(myMat) #generates a matrix of communities
(rows), species (columns)

raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
rarecurve to plot a rarefaction for each individual community (n=50)


However I would like to produce a graph in which all rarefaction
curves end at the same sample size. For example, in this graph it
would be great to extend the x-axis (sample size) to 100 and have all
curves end at this point. Is there any way to use rarecurve to
resample a community (row) with replacement the same number of times
for all 50 communities? With replacement is important because the
communities differ greatly in their size (number of species).


I understand that rarefaction is useful to compare communities with
different sample efforts, but I would still like to generate the
figure. My actual data has 5000 simulated communities that differ
greatly in matrix size and number of samples.


Thank you in advance for your help and suggestions.


Cheers,

Nick


-- 
Nick Pardikes
PhD Candidate
Program in Ecology, Evolution, and Conservation Biology
University of Nevada
https://nickpardikes.wordpress.com/
nickpardikes at gmail.com


From nickpardikes at gmail.com  Wed Sep  7 00:07:46 2016
From: nickpardikes at gmail.com (Nick Pardikes)
Date: Tue, 6 Sep 2016 15:07:46 -0700
Subject: [R] Resample with replacement to produce many rarefaction curves
 with same number of samples
Message-ID: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>

I am currently having difficulty producing a graph using rarecurve in the
vegan package. I have produced rarefaction curves (seen below) using the
following code.


library(vegan)

myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
communities

netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
species (columns)

raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
rarecurve to plot a rarefaction for each individual community (n=50)


However I would like to produce a graph in which all rarefaction curves end
at the same sample size. For example, in this graph it would be great to
extend the x-axis (sample size) to 100 and have all curves end at this
point. Is there any way to use rarecurve to resample a community (row) with
replacement the same number of times for all 50 communities? With
replacement is important because the communities differ greatly in their
size (number of species).


I understand that rarefaction is useful to compare communities with
different sample efforts, but I would still like to generate the figure. My
actual data has 5000 simulated communities that differ greatly in matrix
size and number of samples.


Thank you in advance for your help and suggestions.


Cheers,

Nick

-- 
Nick Pardikes
PhD Candidate
Program in Ecology, Evolution, and Conservation Biology
University of Nevada
https://nickpardikes.wordpress.com/
nickpardikes at gmail.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rarefaction.pdf
Type: application/pdf
Size: 19167 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160906/4015a1ee/attachment.pdf>

From stef.mientki at gmail.com  Wed Sep  7 00:19:08 2016
From: stef.mientki at gmail.com (Stef Mientki)
Date: Wed, 7 Sep 2016 00:19:08 +0200
Subject: [R] how to transform db query result into a set of timeseries
In-Reply-To: <8fa99f7a-be86-20fa-ee58-5e5c8fc1491d@gmail.com>
References: <mailman.5.1473156001.15128.r-help@r-project.org>
	<8fa99f7a-be86-20fa-ee58-5e5c8fc1491d@gmail.com>
Message-ID: <37988510-f5c5-288d-dc4d-002653e0943e@gmail.com>

Thanks Paul,

I'm just a beginner with R, so I tried your simplest solution ( zonnen 
<- xts( cbind( ... ) and it seems to work fine.

cheers,
Stef

On 06-Sep-16 22:12, Paul Gilbert wrote:
> There is a utility function TSquery() in package TSsql that attempts 
> to do this. Most of the functions in that package are for databases 
> with a specific layout intended for storing time series, but TSquery() 
> attempts to build a series from a somewhat arbitrary database. It is 
> hard to be completely generic and handle every possible database 
> structure, so you might just examine the function for hints. I think 
> it does not handle %H:%M:%S but the general logic should help.
>
> The main problem is that your query is not guaranteed to return data 
> in time order. (You may be lucky if you loaded it that way, but it can 
> change unexpectedly.) You can do the ordering with the xts() order.by 
> argument but it is probably quicker to do it in the db so you need 
> less manipulation of the data you get back. TSquery() uses   ORDER BY 
> in the sql query to ensure the order:
>
>    q <- paste(q, " GROUP BY ", dates, " ORDER BY ", dates, " ;")
>
> If the query result is df then I think you can construct your series 
> simply with
>
>   zonnen <- xts( cbind(df$M. df$G, df$N),
>                  order.by = as.POSIXct( df$Date,
>                        format="%Y-%m-%d %H:%M:%S") )
>
> There are several other details in the function that you may find useful.
>
> Paul Gilbert
>
>> Date: Mon, 5 Sep 2016 22:28:50 +0200
>> From: Stef Mientki <stef.mientki at gmail.com>
>> hello,
>>
>> I've a number of timeseries into a database and want to display these
>> timeseries into graph.
>>
>> Now the code below works well, but as the user can select which
>> timeseries should be shown (up to 20 timeseries) the code below should
>> be dynamic and can be quiet large and complex.
>>
>> Is there an easier way to convert a database result into timeseries
>> accepted by dygraph ?
>>
>>      SQL <- "select Date, M, G, N from Compare_Model"
>>      df <- dbGetQuery ( con, statement = SQL )
>>
>>      zon1 <- xts ( df$M,  as.POSIXct ( df$Date, format="%Y-%m-%d
>> %H:%M:%S") )
>>      zon2 <- xts ( df$G,  as.POSIXct ( df$Date, format="%Y-%m-%d
>> %H:%M:%S") )
>>      zon3 <- xts ( df$N,  as.POSIXct ( df$Date, format="%Y-%m-%d
>> %H:%M:%S") )
>>
>>      zonnen <- Reduce ( function(...) merge(..., all=TRUE ), list ( zon,
>> zon2, zon3 ))
>>
>>      dygraph ( zonnen )
>>
>>
>> thanks,
>>
>> Stef


From bgunter.4567 at gmail.com  Wed Sep  7 02:01:04 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Sep 2016 17:01:04 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
Message-ID: <CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>

Jun:

1. Tell us your desired result from your test vector and maybe someone
will help.

2. As we played this game once already (you couldn't do it; I showed
you how), this seems to be a function of your limitations with regular
expressions. I'm probably not much better, but in any case, I don't
intend to be your consultant. See if you can find someone locally to
help you if you do not receive a satisfactory reply from the list.
There are many people here who are pretty good at this sort of thing,
but I don't know if they'll reply. Regex's are certainly complex. PERL
people tend to be pretty good at them, I believe. There are numerous
web sites and books on them if you need to acquire expertise for your
work.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi Bert,
>
> I still couldn't make the multiple patterns to work. Here is an example. I
> make the pattern as follows
>
> final.pattern <-
> "(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>
> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
> '240.m.g.>50-70.kg.geo.mean')
>
> sub(final.pattern, '\\1', test.string)
> sub(final.pattern, '\\2', test.string)
> sub(final.pattern, '\\3', test.string)
>
> Only the third string has been correctly parsed, which matches the first
> pattern. It seems the rest of the patterns are not called.
>
> Jun
>
>
> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Just noticed: My clumsy do.call() line in my previously posted code
>> below should be replaced with:
>> pat <- paste(pat,collapse = "|")
>>
>>
>> > pat <- c(pat1,pat2)
>> > paste(pat,collapse="|")
>> [1] "a+\\.*a+|b+\\.*b+"
>>
>> ************ replace this **************************
>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>> ********************************************
>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>> [1] "a.a"   "bb"    "b.bbb"
>>
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> > Jun:
>> >
>> > You need to provide a clear specification via regular expressions of
>> > the patterns you wish to match -- at least for me to decipher it.
>> > Others may be smarter than I, though...
>> >
>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>> > "proof" of sorts): If pat1, pat2,..., patn are m different patterns
>> > (in a vector of patterns)  to be matched in a vector of n strings,
>> > where only one of the patterns will match in any string,  then use
>> > paste() (probably via do.call()) or otherwise to paste them together
>> > separated by "|" to form the concatenated pattern, pat. Then
>> >
>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>> >
>> > should extract the matching pattern in each (perhaps with a little
>> > fiddling due to precedence rules); e.g.
>> >
>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>> >
>> >> pat1 <- "a+\\.*a+"
>> >> pat2 <-"b+\\.*b+"
>> >> pat <- c(pat1,pat2)
>> >
>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >> pat
>> > [1] "a+\\.*a+|b+\\.*b+"
>> >
>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>> > [1] "a.a"   "bb"    "b.bbb"
>> >
>> > Cheers,
>> > Bert
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> >> Thanks for the reply, Bert.
>> >>
>> >> Your solution solves the example. I actually have a more general
>> >> situation
>> >> where I have this dot concatenated string from multiple variables. The
>> >> problem is those variables may have values with dots in there. The
>> >> number of
>> >> dots are not consistent for all values of a variable. So I am thinking
>> >> to
>> >> define a vector of patterns for the vector of the string and hopefully
>> >> to
>> >> find a way to use a pattern from the pattern vector for each value of
>> >> the
>> >> string vector. The only way I can think of is "for" loop, which can be
>> >> slow.
>> >> Also these are happening in a function I am writing. Just wonder if
>> >> there is
>> >> another more efficient way. Thanks a lot.
>> >>
>> >> Jun
>> >>
>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> >> wrote:
>> >>>
>> >>> Well, he did provide an example, and...
>> >>>
>> >>>
>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>>
>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> >>> [1] "WT.CUT" "tx"
>> >>>
>> >>>
>> >>> ## seems to do what was requested.
>> >>>
>> >>> Jeff would have to amplify on his initial statement however: do you
>> >>> mean that separate patterns can always be combined via "|" ?  Or
>> >>> something deeper?
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>> >>> <jdnewmil at dcn.davis.ca.us>
>> >>> wrote:
>> >>> > Your opening assertion is false.
>> >>> >
>> >>> > Provide a reproducible example and someone will demonstrate.
>> >>> > --
>> >>> > Sent from my phone. Please excuse my brevity.
>> >>> >
>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>> >>> > <jun.shen.ut at gmail.com>
>> >>> > wrote:
>> >>> >>Dear list,
>> >>> >>
>> >>> >>I have a vector of strings that cannot be described by one pattern.
>> >>> >> So
>> >>> >>let's say I construct a vector of patterns in the same length as the
>> >>> >>vector
>> >>> >>of strings, can I do the element wise pattern recognition and string
>> >>> >>substitution.
>> >>> >>
>> >>> >>For example,
>> >>> >>
>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >>> >>
>> >>> >>patterns <- c(pattern1,pattern2)
>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>> >>
>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx" from
>> >>> >> the
>> >>> >>second string. If I do
>> >>> >>
>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be used.
>> >>> >>
>> >>> >>looping the patterns doesn't work the way I want. Appreciate any
>> >>> >>comments.
>> >>> >>Thanks.
>> >>> >>
>> >>> >>Jun
>> >>> >>
>> >>> >>       [[alternative HTML version deleted]]
>> >>> >>
>> >>> >>______________________________________________
>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >>PLEASE do read the posting guide
>> >>> >>http://www.R-project.org/posting-guide.html
>> >>> >>and provide commented, minimal, self-contained, reproducible code.
>> >>> >
>> >>> > ______________________________________________
>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> > PLEASE do read the posting guide
>> >>> > http://www.R-project.org/posting-guide.html
>> >>> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>
>


From istazahn at gmail.com  Wed Sep  7 03:44:36 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Sep 2016 21:44:36 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
Message-ID: <CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>

If you want to mach each element of 'strings' to a different regex, do
it. Here are three ways, using your original example.

pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"

patterns <- c(pattern1,pattern2)
strings <- c('TX.WT.CUT.mean','mg.tx.cv')

for(i in seq(strings)) print(sub(patterns[i], "\\2", strings[i]))

mapply(sub, pattern = patterns, x = strings, MoreArgs=list(replacement = "\\2"))

library(stringi)
stri_replace_all_regex(strings, patterns, "$2")

Best,
Ista
On Tue, Sep 6, 2016 at 9:20 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi Jeff,
>
> Thanks for the reply. I tried your suggestion and it doesn't seem to work
> and I tried a simple pattern as follows and it works as expected
>
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1', "3.mg.kg.>50-70.kg.P05")
> [1] "3.mg.kg"
>
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2', "3.mg.kg.>50-70.kg.P05")
> [1] ">50-70.kg"
>
> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3', "3.mg.kg.>50-70.kg.P05")
> [1] "P05"
>
> My problem is the pattern has to be dynamically constructed on the input
> data of the function I am writing. It's actually not too difficult to
> assemble the final.pattern with some code like the following
>
> sort.var <- c('TX','WTCUT')
> combn.sort.var <- do.call(expand.grid, lapply(sort.var,
> function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))),
> ')', sep='')))
> all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
> final.pattern <- paste0(all.patterns, collapse='|')
>
> You cannot run the code directly since the data object "all.exposure" is
> not provided here.
>
> Jun
>
>
>
> On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> I am not near my computer today, but each parenthesis gets its own result
>> number, so you should put the parenthesis around the whole pattern of
>> alternatives instead of having many parentheses.
>>
>> I recommend thinking in terms of what common information you expect to
>> find in these various strings, and place your parentheses to capture that
>> information. There is no other reason to put parentheses in the pattern...
>> they are not grouping symbols.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >Jun:
>> >
>> >1. Tell us your desired result from your test vector and maybe someone
>> >will help.
>> >
>> >2. As we played this game once already (you couldn't do it; I showed
>> >you how), this seems to be a function of your limitations with regular
>> >expressions. I'm probably not much better, but in any case, I don't
>> >intend to be your consultant. See if you can find someone locally to
>> >help you if you do not receive a satisfactory reply from the list.
>> >There are many people here who are pretty good at this sort of thing,
>> >but I don't know if they'll reply. Regex's are certainly complex. PERL
>> >people tend to be pretty good at them, I believe. There are numerous
>> >web sites and books on them if you need to acquire expertise for your
>> >work.
>> >
>> >Cheers,
>> >Bert
>> >Bert Gunter
>> >
>> >"The trouble with having an open mind is that people keep coming along
>> >and sticking things into it."
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> >> Hi Bert,
>> >>
>> >> I still couldn't make the multiple patterns to work. Here is an
>> >example. I
>> >> make the pattern as follows
>> >>
>> >> final.pattern <-
>> >>
>> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
>> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
>> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
>> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
>> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
>> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
>> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>> >>
>> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>> >> '240.m.g.>50-70.kg.geo.mean')
>> >>
>> >> sub(final.pattern, '\\1', test.string)
>> >> sub(final.pattern, '\\2', test.string)
>> >> sub(final.pattern, '\\3', test.string)
>> >>
>> >> Only the third string has been correctly parsed, which matches the
>> >first
>> >> pattern. It seems the rest of the patterns are not called.
>> >>
>> >> Jun
>> >>
>> >>
>> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> >wrote:
>> >>>
>> >>> Just noticed: My clumsy do.call() line in my previously posted code
>> >>> below should be replaced with:
>> >>> pat <- paste(pat,collapse = "|")
>> >>>
>> >>>
>> >>> > pat <- c(pat1,pat2)
>> >>> > paste(pat,collapse="|")
>> >>> [1] "a+\\.*a+|b+\\.*b+"
>> >>>
>> >>> ************ replace this **************************
>> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >>> ********************************************
>> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>> >>> [1] "a.a"   "bb"    "b.bbb"
>> >>>
>> >>>
>> >>> -- Bert
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming
>> >along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>> ><bgunter.4567 at gmail.com>
>> >>> wrote:
>> >>> > Jun:
>> >>> >
>> >>> > You need to provide a clear specification via regular expressions
>> >of
>> >>> > the patterns you wish to match -- at least for me to decipher it.
>> >>> > Others may be smarter than I, though...
>> >>> >
>> >>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>> >patterns
>> >>> > (in a vector of patterns)  to be matched in a vector of n strings,
>> >>> > where only one of the patterns will match in any string,  then use
>> >>> > paste() (probably via do.call()) or otherwise to paste them
>> >together
>> >>> > separated by "|" to form the concatenated pattern, pat. Then
>> >>> >
>> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>> >>> >
>> >>> > should extract the matching pattern in each (perhaps with a little
>> >>> > fiddling due to precedence rules); e.g.
>> >>> >
>> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>> >>> >
>> >>> >> pat1 <- "a+\\.*a+"
>> >>> >> pat2 <-"b+\\.*b+"
>> >>> >> pat <- c(pat1,pat2)
>> >>> >
>> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >>> >> pat
>> >>> > [1] "a+\\.*a+|b+\\.*b+"
>> >>> >
>> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>> >>> > [1] "a.a"   "bb"    "b.bbb"
>> >>> >
>> >>> > Cheers,
>> >>> > Bert
>> >>> >
>> >>> >
>> >>> > Bert Gunter
>> >>> >
>> >>> > "The trouble with having an open mind is that people keep coming
>> >along
>> >>> > and sticking things into it."
>> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>> >
>> >>> >
>> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>> >wrote:
>> >>> >> Thanks for the reply, Bert.
>> >>> >>
>> >>> >> Your solution solves the example. I actually have a more general
>> >>> >> situation
>> >>> >> where I have this dot concatenated string from multiple
>> >variables. The
>> >>> >> problem is those variables may have values with dots in there.
>> >The
>> >>> >> number of
>> >>> >> dots are not consistent for all values of a variable. So I am
>> >thinking
>> >>> >> to
>> >>> >> define a vector of patterns for the vector of the string and
>> >hopefully
>> >>> >> to
>> >>> >> find a way to use a pattern from the pattern vector for each
>> >value of
>> >>> >> the
>> >>> >> string vector. The only way I can think of is "for" loop, which
>> >can be
>> >>> >> slow.
>> >>> >> Also these are happening in a function I am writing. Just wonder
>> >if
>> >>> >> there is
>> >>> >> another more efficient way. Thanks a lot.
>> >>> >>
>> >>> >> Jun
>> >>> >>
>> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>> ><bgunter.4567 at gmail.com>
>> >>> >> wrote:
>> >>> >>>
>> >>> >>> Well, he did provide an example, and...
>> >>> >>>
>> >>> >>>
>> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>> >>>
>> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> >>> >>> [1] "WT.CUT" "tx"
>> >>> >>>
>> >>> >>>
>> >>> >>> ## seems to do what was requested.
>> >>> >>>
>> >>> >>> Jeff would have to amplify on his initial statement however: do
>> >you
>> >>> >>> mean that separate patterns can always be combined via "|" ?  Or
>> >>> >>> something deeper?
>> >>> >>>
>> >>> >>> Cheers,
>> >>> >>> Bert
>> >>> >>> Bert Gunter
>> >>> >>>
>> >>> >>> "The trouble with having an open mind is that people keep coming
>> >along
>> >>> >>> and sticking things into it."
>> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>> >)
>> >>> >>>
>> >>> >>>
>> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>> >>> >>> <jdnewmil at dcn.davis.ca.us>
>> >>> >>> wrote:
>> >>> >>> > Your opening assertion is false.
>> >>> >>> >
>> >>> >>> > Provide a reproducible example and someone will demonstrate.
>> >>> >>> > --
>> >>> >>> > Sent from my phone. Please excuse my brevity.
>> >>> >>> >
>> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>> >>> >>> > <jun.shen.ut at gmail.com>
>> >>> >>> > wrote:
>> >>> >>> >>Dear list,
>> >>> >>> >>
>> >>> >>> >>I have a vector of strings that cannot be described by one
>> >pattern.
>> >>> >>> >> So
>> >>> >>> >>let's say I construct a vector of patterns in the same length
>> >as the
>> >>> >>> >>vector
>> >>> >>> >>of strings, can I do the element wise pattern recognition and
>> >string
>> >>> >>> >>substitution.
>> >>> >>> >>
>> >>> >>> >>For example,
>> >>> >>> >>
>> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >>> >>> >>
>> >>> >>> >>patterns <- c(pattern1,pattern2)
>> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>> >>> >>
>> >>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>> >from
>> >>> >>> >> the
>> >>> >>> >>second string. If I do
>> >>> >>> >>
>> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>> >used.
>> >>> >>> >>
>> >>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>> >any
>> >>> >>> >>comments.
>> >>> >>> >>Thanks.
>> >>> >>> >>
>> >>> >>> >>Jun
>> >>> >>> >>
>> >>> >>> >>       [[alternative HTML version deleted]]
>> >>> >>> >>
>> >>> >>> >>______________________________________________
>> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >see
>> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >>> >>PLEASE do read the posting guide
>> >>> >>> >>http://www.R-project.org/posting-guide.html
>> >>> >>> >>and provide commented, minimal, self-contained, reproducible
>> >code.
>> >>> >>> >
>> >>> >>> > ______________________________________________
>> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >see
>> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >>> > PLEASE do read the posting guide
>> >>> >>> > http://www.R-project.org/posting-guide.html
>> >>> >>> > and provide commented, minimal, self-contained, reproducible
>> >code.
>> >>> >>
>> >>> >>
>> >>
>> >>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Sep  7 05:56:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Sep 2016 20:56:30 -0700
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
Message-ID: <CAGxFJbQzCsAvQyay405M-vHpyphUVpXTqTExOT6+KbssidHwog@mail.gmail.com>

Jeff:

Not sure what you meant by this:

"There is no other reason to put parentheses in the pattern... they
are not grouping symbols."

... but in fact, from ?regexp

"Repetition takes precedence over concatenation, which in turn takes
precedence over alternation. A whole subexpression may be enclosed in
parentheses to override these precedence rules. "

So parentheses *are* in fact "grouping symbols."

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 6, 2016 at 5:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> I am not near my computer today, but each parenthesis gets its own result number, so you should put the parenthesis around the whole pattern of alternatives instead of having many parentheses.
>
> I recommend thinking in terms of what common information you expect to find in these various strings, and place your parentheses to capture that information. There is no other reason to put parentheses in the pattern... they are not grouping symbols.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 6, 2016 5:01:04 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>Jun:
>>
>>1. Tell us your desired result from your test vector and maybe someone
>>will help.
>>
>>2. As we played this game once already (you couldn't do it; I showed
>>you how), this seems to be a function of your limitations with regular
>>expressions. I'm probably not much better, but in any case, I don't
>>intend to be your consultant. See if you can find someone locally to
>>help you if you do not receive a satisfactory reply from the list.
>>There are many people here who are pretty good at this sort of thing,
>>but I don't know if they'll reply. Regex's are certainly complex. PERL
>>people tend to be pretty good at them, I believe. There are numerous
>>web sites and books on them if you need to acquire expertise for your
>>work.
>>
>>Cheers,
>>Bert
>>Bert Gunter
>>
>>"The trouble with having an open mind is that people keep coming along
>>and sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>>> Hi Bert,
>>>
>>> I still couldn't make the multiple patterns to work. Here is an
>>example. I
>>> make the pattern as follows
>>>
>>> final.pattern <-
>>>
>>"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>>>
>>> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>>> '240.m.g.>50-70.kg.geo.mean')
>>>
>>> sub(final.pattern, '\\1', test.string)
>>> sub(final.pattern, '\\2', test.string)
>>> sub(final.pattern, '\\3', test.string)
>>>
>>> Only the third string has been correctly parsed, which matches the
>>first
>>> pattern. It seems the rest of the patterns are not called.
>>>
>>> Jun
>>>
>>>
>>> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>wrote:
>>>>
>>>> Just noticed: My clumsy do.call() line in my previously posted code
>>>> below should be replaced with:
>>>> pat <- paste(pat,collapse = "|")
>>>>
>>>>
>>>> > pat <- c(pat1,pat2)
>>>> > paste(pat,collapse="|")
>>>> [1] "a+\\.*a+|b+\\.*b+"
>>>>
>>>> ************ replace this **************************
>>>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>> ********************************************
>>>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>>>> [1] "a.a"   "bb"    "b.bbb"
>>>>
>>>>
>>>> -- Bert
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming
>>along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>><bgunter.4567 at gmail.com>
>>>> wrote:
>>>> > Jun:
>>>> >
>>>> > You need to provide a clear specification via regular expressions
>>of
>>>> > the patterns you wish to match -- at least for me to decipher it.
>>>> > Others may be smarter than I, though...
>>>> >
>>>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>>>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>>patterns
>>>> > (in a vector of patterns)  to be matched in a vector of n strings,
>>>> > where only one of the patterns will match in any string,  then use
>>>> > paste() (probably via do.call()) or otherwise to paste them
>>together
>>>> > separated by "|" to form the concatenated pattern, pat. Then
>>>> >
>>>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>>>> >
>>>> > should extract the matching pattern in each (perhaps with a little
>>>> > fiddling due to precedence rules); e.g.
>>>> >
>>>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>>>> >
>>>> >> pat1 <- "a+\\.*a+"
>>>> >> pat2 <-"b+\\.*b+"
>>>> >> pat <- c(pat1,pat2)
>>>> >
>>>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>>> >> pat
>>>> > [1] "a+\\.*a+|b+\\.*b+"
>>>> >
>>>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>>>> > [1] "a.a"   "bb"    "b.bbb"
>>>> >
>>>> > Cheers,
>>>> > Bert
>>>> >
>>>> >
>>>> > Bert Gunter
>>>> >
>>>> > "The trouble with having an open mind is that people keep coming
>>along
>>>> > and sticking things into it."
>>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> >
>>>> >
>>>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>>wrote:
>>>> >> Thanks for the reply, Bert.
>>>> >>
>>>> >> Your solution solves the example. I actually have a more general
>>>> >> situation
>>>> >> where I have this dot concatenated string from multiple
>>variables. The
>>>> >> problem is those variables may have values with dots in there.
>>The
>>>> >> number of
>>>> >> dots are not consistent for all values of a variable. So I am
>>thinking
>>>> >> to
>>>> >> define a vector of patterns for the vector of the string and
>>hopefully
>>>> >> to
>>>> >> find a way to use a pattern from the pattern vector for each
>>value of
>>>> >> the
>>>> >> string vector. The only way I can think of is "for" loop, which
>>can be
>>>> >> slow.
>>>> >> Also these are happening in a function I am writing. Just wonder
>>if
>>>> >> there is
>>>> >> another more efficient way. Thanks a lot.
>>>> >>
>>>> >> Jun
>>>> >>
>>>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>><bgunter.4567 at gmail.com>
>>>> >> wrote:
>>>> >>>
>>>> >>> Well, he did provide an example, and...
>>>> >>>
>>>> >>>
>>>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>> >>>
>>>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>>> >>> [1] "WT.CUT" "tx"
>>>> >>>
>>>> >>>
>>>> >>> ## seems to do what was requested.
>>>> >>>
>>>> >>> Jeff would have to amplify on his initial statement however: do
>>you
>>>> >>> mean that separate patterns can always be combined via "|" ?  Or
>>>> >>> something deeper?
>>>> >>>
>>>> >>> Cheers,
>>>> >>> Bert
>>>> >>> Bert Gunter
>>>> >>>
>>>> >>> "The trouble with having an open mind is that people keep coming
>>along
>>>> >>> and sticking things into it."
>>>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>>)
>>>> >>>
>>>> >>>
>>>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>>> >>> <jdnewmil at dcn.davis.ca.us>
>>>> >>> wrote:
>>>> >>> > Your opening assertion is false.
>>>> >>> >
>>>> >>> > Provide a reproducible example and someone will demonstrate.
>>>> >>> > --
>>>> >>> > Sent from my phone. Please excuse my brevity.
>>>> >>> >
>>>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>>>> >>> > <jun.shen.ut at gmail.com>
>>>> >>> > wrote:
>>>> >>> >>Dear list,
>>>> >>> >>
>>>> >>> >>I have a vector of strings that cannot be described by one
>>pattern.
>>>> >>> >> So
>>>> >>> >>let's say I construct a vector of patterns in the same length
>>as the
>>>> >>> >>vector
>>>> >>> >>of strings, can I do the element wise pattern recognition and
>>string
>>>> >>> >>substitution.
>>>> >>> >>
>>>> >>> >>For example,
>>>> >>> >>
>>>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>>> >>> >>
>>>> >>> >>patterns <- c(pattern1,pattern2)
>>>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>>> >>> >>
>>>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>>from
>>>> >>> >> the
>>>> >>> >>second string. If I do
>>>> >>> >>
>>>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>>used.
>>>> >>> >>
>>>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>>any
>>>> >>> >>comments.
>>>> >>> >>Thanks.
>>>> >>> >>
>>>> >>> >>Jun
>>>> >>> >>
>>>> >>> >>       [[alternative HTML version deleted]]
>>>> >>> >>
>>>> >>> >>______________________________________________
>>>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> >>PLEASE do read the posting guide
>>>> >>> >>http://www.R-project.org/posting-guide.html
>>>> >>> >>and provide commented, minimal, self-contained, reproducible
>>code.
>>>> >>> >
>>>> >>> > ______________________________________________
>>>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> > PLEASE do read the posting guide
>>>> >>> > http://www.R-project.org/posting-guide.html
>>>> >>> > and provide commented, minimal, self-contained, reproducible
>>code.
>>>> >>
>>>> >>
>>>
>>>
>


From Justin.Peter at usq.edu.au  Wed Sep  7 06:33:35 2016
From: Justin.Peter at usq.edu.au (Justin Peter)
Date: Wed, 7 Sep 2016 04:33:35 +0000
Subject: [R] Using apply on a three dimensional matrix and passing multiple
 arguments to user defined function
Message-ID: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>

Dear R-user,

I have a three-dimensional matrix of atmospheric data. The first two dimensions are spatial (lon and lat) and the third is time, such that

dim(data) <- c(nlon,nlat,ntime)

I wish to apply a land sea mask data which is a matrix of "0" and "1" if dim(nlon,nlat)

dim(lsmask) <- c(nlon,nlat)

I wish to set all of the elements in the two-dimensional array of data[,,ntime] for every 1:length(ntime).

I could do this in a loop:

for (i in 1:ntime){
    data[,,i][which(lsmask == 0)] <- NA
}

I would like to do this using apply, but I need to pass two variables to the function in apply (data and lsmask), where data is a two-dimensional array.

I tried:

mask <- function(x,y) {x[which(y==0)] <- NA}

masked_data <- apply(data,c(1,2),mask,y=lsmask)

but I get back a vector of dim(nlon,nlat) populated with NA.

Any clues as to what I am missing?

Thanks in advance for you help.

Kind regards,
Justin



--
Justin Peter
Research Fellow
International Centre for Applied Climate Sciences,
University of Southern Queensland
West St, Toowoomba, QLD, 4350
Australia

Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au>
Ph: +61 (0) 7 4631 1181
Fax: +61 (0) 7 4631 5581
Mob: +61 (0)474 774 107




_____________________________________________________________
This email (including any attached files) is confidential and is for the intended recipient(s) only. If you received this email by mistake, please, as a courtesy, tell the sender, then delete this email.

The views and opinions are the originator's and do not necessarily reflect those of the University of Southern Queensland. Although all reasonable precautions were taken to ensure that this email contained no viruses at the time it was sent we accept no liability for any losses arising from its receipt.

The University of Southern Queensland is a registered provider of education with the Australian Government.
(CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )


	[[alternative HTML version deleted]]


From andre.boliveira at hotmail.com  Wed Sep  7 07:44:01 2016
From: andre.boliveira at hotmail.com (Andre Barbosa Oliveira)
Date: Wed, 7 Sep 2016 05:44:01 +0000
Subject: [R] fPortfolio dont work in R 3.3.1
Message-ID: <BY2PR10MB0598B9454355A674D9F52066FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>

Hi,


I'm trying use the package fPortfolio in R version 3.3.1. But the package don't work. I recieve the messages below:


Package which is only available in source form, and may need
  compilation of C/C++/Fortran: 'Rsymphony'
  These will not be installed

Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'Rsymphony'
Erro: package or namespace load failed for 'fPortfolio'

How I can use fPortfolio in R 3.3.1?


Thanks in advance,


Andr? Barbosa Oliveira.



	[[alternative HTML version deleted]]


From Rainer at krugs.de  Wed Sep  7 09:07:42 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 07 Sep 2016 09:07:42 +0200
Subject: [R] Run an external software in R
In-Reply-To: <CAGxFJbSpQc2b2Sr0snN0Hca7aCaJFKLQka+tbyz+_zu7KZoXJw@mail.gmail.com>
	(Bert Gunter's message of "Tue, 6 Sep 2016 21:06:21 -0700")
References: <CABmD0bGS=jwfteBBcEo7SBuR-dtoXYpV5Jf1UX7F-Uu1UGWh5w@mail.gmail.com>
	<CAGxFJbSpQc2b2Sr0snN0Hca7aCaJFKLQka+tbyz+_zu7KZoXJw@mail.gmail.com>
Message-ID: <m2oa40qjb5.fsf@krugs.de>

Bert Gunter <bgunter.4567 at gmail.com> writes:

> ?system
>
> But this begs the question: WHY would you want to do this? More
> specifically, what should R communicate to your other software, and
> what should the other software communicate to R?

I am not the OP, buty I can give you an answer why I did this (OK - I
user rgrass7 - but under the hood the same in my case).

I don't have to say that R is extremely powerful and flexible - and when
you are used to R, it even becomes intuitive. So why not use R for
scripting, even if it is not statistical stuff? and with system() you
can call other languages (bash, grass, whatever you want) when things
are easier there - so in some cases, no data transfer between R and the
external program is even necessary.

But if you are asking about the specific case of the OP, I can't answer this.

Cheers,

Rainer

>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 6, 2016 at 6:13 PM, Marino David <davidmarino838 at gmail.com> wrote:
>> Hi all R users:
>>
>> Does anybody have the experience of running an external software in R? I
>> try to use R to run ANSYS software, which is a engineering simulation
>> package. I ever have done this task in Matlab platform by executing
>> the following code line:
>>
>> system('"C:\Program Files\Ansys Inc\v100\ANSYS\bin\intel\ansys100" -b -p
>> ane3fl -i D:\Ansys\MyAnsysCode.txt -o D:\Ansys\vm5.out');
>>
>>
>> Any idea regarding implementing this work is very welcome.
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160907/92494154/attachment.bin>

From bannert at kof.ethz.ch  Wed Sep  7 09:57:27 2016
From: bannert at kof.ethz.ch (Bannert  Matthias)
Date: Wed, 7 Sep 2016 07:57:27 +0000
Subject: [R] fPortfolio dont work in R 3.3.1
In-Reply-To: <BY2PR10MB0598B9454355A674D9F52066FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
References: <BY2PR10MB0598B9454355A674D9F52066FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
Message-ID: <8586FCA42D306C4DB0BD46EF9F1B58025B017148@MBX110.d.ethz.ch>

Andre, 

you need to make sure you got a C/C++ compiler as well as a Fortran compiler to compile a package from source that makes use of these language. Many R packages use one of those languages under the hood to speed things up. 

gcc / gfortran are common and free choices for such compilers. Depending on your OS, these ship with your OS' installation. What OS do you have? 

Also, i'd try to install RSymphony first and then install fPortfolio.

HTH, 

matt

Hi,


I'm trying use the package fPortfolio in R version 3.3.1. But the package don't work. I recieve the messages below:


Package which is only available in source form, and may need
  compilation of C/C++/Fortran: 'Rsymphony'
  These will not be installed

Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'Rsymphony'
Erro: package or namespace load failed for 'fPortfolio'

How I can use fPortfolio in R 3.3.1?


Thanks in advance,


Andr? Barbosa Oliveira.



        [[alternative HTML version deleted]]


From getchinmay at gmail.com  Wed Sep  7 10:17:10 2016
From: getchinmay at gmail.com (Chinmay Borwankar)
Date: Wed, 7 Sep 2016 11:17:10 +0300
Subject: [R] building R from source on gnu version >=5.4
Message-ID: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>

Hi,
    I want to integrate R with ROOTv6.06, which requires that,
    R be built with gcc compiler option "_GLIBCXX_USE_CXX11_ABI=0" .
    I am hoping that if I build R from source then there will be a way to
do this.
    Is there ?
    Regards.

-- 
Regards.

    Chinmay Borwankar

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Tue Sep  6 19:54:20 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 6 Sep 2016 13:54:20 -0400
Subject: [R] [R-pkgs] statquotes package released to CRAN
Message-ID: <5e149577-d9b8-7eb4-0fa8-f1bb7edcb6b7@yorku.ca>

## statquotes package released to CRAN

The statquotes package v. 0.2 has recently been released to CRAN.  In a spirit
similar to fortunes and gaussfacts, the function `statquote()`
displays a randomly chosen quotation from a data base consisting
of quotes about topics related to statistics, data visualization and science.

The data base is a collection of quotations assembled over the years from various
sources. The quotes are classified by general topics (and subtopics).

### Examples

> set.seed(761)
> statquote()
The best thing about being a statistician is that you get to play in everyone's backyard.
--- John W. Tukey
> statquote(topic="science")
Some people weave burlap into the fabric of our lives, and some weave gold thread. Both contribute
to make the whole picture beautiful and unique.
--- Anon.

### Development

The package is hosted on Github, at https://github.com/friendly/statquotes/.
Please report any problems or bugs at https://github.com/friendly/statquotes/issues.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From friendly at yorku.ca  Tue Sep  6 20:06:40 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 6 Sep 2016 14:06:40 -0400
Subject: [R] [R-pkgs] Lahman package v. 5.0.0 released to CRAN
Message-ID: <f691c99e-7d0b-cf73-2399-bfb2605aa572@yorku.ca>

## Lahman package v. 5.0.0 released to CRAN

Team Lahman is pleased to announce that v. 5.0.0 of the Lahamn package 
is now
on CRAN.  It contains the data from Sean Lahman's Baseball Database,
http://www.seanlahman.com/baseball-archive/statistics/
as a collection of data frames covering nearly all aspects of baseball
statistics from 1871--2015.

In this release,

* All data sets have been updated with data for the 2015 baseball 
season.  In
   addition, numerous corrections of data errors and inconsistencies 
discovered
   in previous year tables were applied.

* Documentation examples are now provided for all data tables.

*  Documentation examples were re-writtten to make extensive use of 
dplyr for data manipulation
   and ggplot2 for graphics.

### Development

All development of the package takes place on Github, 
https://github.com/cdalzell/Lahman.
Major versions of the R package are released only once a year, following 
the release of a
new 20XX archive on Sean Lahman's site.  This R release occurs after 
sufficient time has
elapsed to correct errors in the source data for a new season. Minor 
versions may be
released from time to time to correct errors in the R version or add 
functionality.

Please report any problems or issues with this new version as an issue 
on this site,
https://github.com/cdalzell/Lahman/issues.  Additional contributions are 
welcome.

There exists an old pseudo-wiki on R-Forge, 
http://lahman.r-forge.r-project.org/ that
collects some additional analyses and visualizations.

-- Team Lahman: Chris Dalzell (maintainer), Michael Friendly (author), 
Denis Murphy, Martin Monkman, Sean Lahman


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From erinm.hodgess at gmail.com  Wed Sep  7 11:56:03 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 7 Sep 2016 04:56:03 -0500
Subject: [R] Pass an optional argument from Fortran subroutine to a R
	wrapper
In-Reply-To: <CALStW+otZ6vNJp+5mTtOYiX0zm5XHi_5KsbzFKyTUpt5=eW4Mw@mail.gmail.com>
References: <CALStW+otZ6vNJp+5mTtOYiX0zm5XHi_5KsbzFKyTUpt5=eW4Mw@mail.gmail.com>
Message-ID: <CACxE24=Au5XzmYEOQU7nMQBrV5SUZx+DsvQTkLbBHEH46R_e2w@mail.gmail.com>

Hello!
You can't really pass the matrix as a matrix.  Send it as a vector,
re-construct it in the Fortran program.

Actually, if it's a covariance matrix and symmetric, you may be able to get
away with just sending part of the matrix.  For example, if you have the
following:

covmat<- matrix(c(1,0.9,0.81,0.9,1,0.9,0.81,0.9,1),nrow=3,ncol=3,byrow=TRUE)

cov1 <- covmat[1:3]



Then pass cov1 as a numeric.


It's easier and faster to manipulate your covariance matrix in the Fortran
program.


Hope this helps.


Sincerely,

Erin

On Tue, Sep 6, 2016 at 2:51 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca>
wrote:

> Hello,
>
> I have a Fortran subroutine which uses an optional argument in the call.
>
>     subroutine data (n,ns,alpha,covmat,x,y)
>
>     integer, intent(in):: n,ns
>     double precision, intent(in)  :: alpha
>     double precision, intent(in), optional ::covmat(n,ns)
>     double precision, intent(out) :: x(n),y(n)
>     ....
>     end subroutine data
>
> I tried the following R wrapper for this subroutine and got an error
> saying,
>
>      Error in array(x, c(length(x), 1L), if (!is.null(names(x)))
> list(names(x), :
>     'data' must be of a vector type, was 'NULL'
>
> I'm not sure if I passed the arguments correctly in the .Fortran() call. I
> couldn't find anything helpful online. I would really appreciate any
> help/comments.
>
>     data1 <- function(n,ns,alpha,covmat=NULL){
>
>     tmp <- .Fortran("data",
>     n = as.integer(n),ns= as.integer(ns)
>     alpha=as.numeric(alpha),covmat=as.matrix(covmat),
>     x=as.double(rep(0,n)),y=as.double(rep(0,n)))
>     )
>      }
>     result <- list(x=tmp$x, y=tmp$y)
>
>     return(result)
>     }
>
> Thanks,
> Vineetha
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From Haiko.Lietz at gesis.org  Wed Sep  7 12:05:34 2016
From: Haiko.Lietz at gesis.org (Lietz, Haiko)
Date: Wed, 7 Sep 2016 10:05:34 +0000
Subject: [R] Resolution parameter in Louvain community detection
Message-ID: <D57FB3A7BE5E14479A21F7832D5F1B34F569259E@svboexc02.gesis.intra>

Hi all,

igraph doesn't have a resolution parameter for Louvain community detection.

Does anybody know of another package that has it?

Best

Haiko


	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Wed Sep  7 13:09:21 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 7 Sep 2016 11:09:21 +0000
Subject: [R] how to manage missing values correctly when importing a data
	frame
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>

Dear R users,
I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:

Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes Test_20141231 Test_20151231
1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES

I load it with
Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)

print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
[1] "YES"

while
print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
[1] NA   "YES"


print(lapply(Storia_RM_RT, class)) gives

$Station_RM
[1] "integer"

$Sensor_RM
[1] "integer"

$Place_RM
[1] "character"

$Y_init_RM
[1] "integer"

$M_init_RM
[1] "integer"

$D_init_RM
[1] "integer"

$Long_cent_RM
[1] "numeric"

$Lat_cent_RM
[1] "numeric"

$Height_RM
[1] "integer"

$Continues
[1] "character"

$Station_RT
[1] "integer"

$Sensor_RT
[1] "integer"

$Place_RT
[1] "character"

$Name1_RT
[1] "character"

$Name2_RT
[1] "character"

$Long_cent_RT
[1] "numeric"

$Lat_cent_RT
[1] "numeric"
$Quota_RT
[1] "numeric"

$Actual_net
[1] "character"

$Notes
[1] "logical"

$Test_20141231
[1] "character"

$Test_20151231
[1] "character"

I am struggling to understand why the query through the field Station_RT does not work.
Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?

Thank you
Stefano Sofia


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Sep  7 14:29:37 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 07 Sep 2016 07:29:37 -0500
Subject: [R] finegray function in the survival package
In-Reply-To: <mailman.7.1473242402.7424.r-help@r-project.org>
References: <mailman.7.1473242402.7424.r-help@r-project.org>
Message-ID: <083a37$4a06rg@ironport10.mayo.edu>



On 09/07/2016 05:00 AM, r-help-request at r-project.org wrote:
> Dear R-Team,
>
> I have been trying to use the finegray routine that creates a special data
> so that Fine and Gray model can be fit. However, it does not seem to work.
> Could you please help me with this issue?
>
>
> Thanks,
> Ahalya.
>

You have given us no details of your example code that "doesn't work", and I can't read 
your mind.  So no, we can't help.  Give us a hint.

Terry T


From sarah.goslee at gmail.com  Wed Sep  7 15:11:06 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 7 Sep 2016 09:11:06 -0400
Subject: [R] how to manage missing values correctly when importing a
	data frame
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
Message-ID: <CAM_vjumgZeEttsmX5Cv7L5047PRy3KSv_O9BFFvR=LihB8RZ2w@mail.gmail.com>

R is refusing to make unwarranted assumptions about your data.

See inline.


# it's nicer to use dput() instead of pasting raw data

Storia_RM_RT <- structure(list(Station_RM = c(1400L, 1460L, 1500L,
1520L), Sensor_RM = 2701:2704,
    Place_RM = c("Novafeltria", "Carpegna", "Pesaro", "Fano"),
    Y_init_RM = c(1959L, 1963L, 1957L, 1957L), M_init_RM = c(1L,
    1L, 1L, 1L), D_init_RM = c(1L, 1L, 1L, 1L), Long_cent_RM = c(12.289552,
    12.332614, 12.909822, 13.017591), Lat_cent_RM = c(43.890057,
    43.778107, 43.910889, 43.840054), Height_RM = c(293L, 748L,
    11L, 4L), Continues = c("NO", "SI", "SI", "SI"), Station_RT = c(NA,
    702L, 112L, 152L), Sensor_RT = c(NA, 2954L, 1229L, 2671L),
    Place_RT = c(NA, "Carpegna", "Pesaro", "Fano"), Name1_RT = c(NA,
    "Carpegna", "Villa_Fastiggi", "Foce_Metauro"), Name2_RT = c(NA,
    "Carpegna", "Villa_Fastiggi", "Metaurilia"), Long_cent_RT = c(NA,
    12.340618, 12.86939, 13.053796), Lat_cent_RT = c(NA, 43.780575,
    43.89061, 43.826328), Height_RT = c(NA, 715, 22, 7.12), Actual_net
= c("CAE",
    "RT", "RT", "RT"), Notes = c(NA, NA, NA, NA), Test_20141231 = c("NO",
    "NO", "YES", "YES"), Test_20151231 = c("NO", "NO", "YES",
    "YES")), .Names = c("Station_RM", "Sensor_RM", "Place_RM",
"Y_init_RM", "M_init_RM", "D_init_RM", "Long_cent_RM", "Lat_cent_RM",
"Height_RM", "Continues", "Station_RT", "Sensor_RT", "Place_RT",
"Name1_RT", "Name2_RT", "Long_cent_RT", "Lat_cent_RT", "Height_RT",
"Actual_net", "Notes", "Test_20141231", "Test_20151231"), class =
"data.frame", row.names = c(NA,
-4L))


> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]
[1] "YES"

# Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]
# there's no such column; you probably mean Test_20151231

> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
[1] NA    "YES"

# What do you expect to have happen when Station_RT is NA? R has no idea
# whether it is 112 or not, so R returns an "I don't know" value that
# lets the user decide how to handle the missing data, rather than making
# assumptions.

# But you probably want one of these constructions:

Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112 &
!is.na(Storia_RM_RT$Station_RT)]

# subset automatically handles NAs, making the assumption I'm assuming you want.
subset(Storia_RM_RT, Station_RT == 112 )$Test_20151231

# This is the first form, somewhat more elegantly
with(Storia_RM_RT, Test_20151231[Station_RT == 112 & !is.na(Station_RT)])

On Wed, Sep 7, 2016 at 7:09 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R users,
> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:
>
> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes Test_20141231 Test_20151231
> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>
> I load it with
> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)
>
> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
> [1] "YES"
>
> while
> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
> [1] NA   "YES"
>
>
> print(lapply(Storia_RM_RT, class)) gives
>
> $Station_RM
> [1] "integer"
>
> $Sensor_RM
> [1] "integer"
>
> $Place_RM
> [1] "character"
>
> $Y_init_RM
> [1] "integer"
>
> $M_init_RM
> [1] "integer"
>
> $D_init_RM
> [1] "integer"
>
> $Long_cent_RM
> [1] "numeric"
>
> $Lat_cent_RM
> [1] "numeric"
>
> $Height_RM
> [1] "integer"
>
> $Continues
> [1] "character"
>
> $Station_RT
> [1] "integer"
>
> $Sensor_RT
> [1] "integer"
>
> $Place_RT
> [1] "character"
>
> $Name1_RT
> [1] "character"
>
> $Name2_RT
> [1] "character"
>
> $Long_cent_RT
> [1] "numeric"
>
> $Lat_cent_RT
> [1] "numeric"
> $Quota_RT
> [1] "numeric"
>
> $Actual_net
> [1] "character"
>
> $Notes
> [1] "logical"
>
> $Test_20141231
> [1] "character"
>
> $Test_20151231
> [1] "character"
>
> I am struggling to understand why the query through the field Station_RT does not work.
> Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?
>
> Thank you
> Stefano Sofia
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jvadams at usgs.gov  Wed Sep  7 15:17:50 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 7 Sep 2016 08:17:50 -0500
Subject: [R] Using apply on a three dimensional matrix and passing
 multiple arguments to user defined function
In-Reply-To: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
References: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
Message-ID: <CAN5YmCHC-GFNvO7bc_Lyk2p+UtRon=eDLnhHF4HiLP65RM4syw@mail.gmail.com>

Justin,

I don't think you can get the apply() function to return an array.  You
could use lapply() instead, and then use simplify2array() to convert the
list of matrices to an array.  Also, in your mask() function you don't need
the which() and you should return the x.  See my example with toy data
below.

# toy data
nlon <- 2
nlat <- 4
ntime <- 3
data <- array(1:(nlon*nlat*ntime), dim=c(nlon, nlat, ntime))
lsmask <- array(sample(0:1, size=nlon*nlat, replace=TRUE), dim=c(nlon,
nlat))

# newly defined function
mask <- function(x, y) {
  x[y==0] <- NA
  x
}

# doit
data2 <- simplify2array(lapply(1:ntime, function(i) mask(data[, , i],
lsmask)))


You may prefer to stick with the for() loop approach (for clarity or
simplicity or ...)  When I ramped up the toy data to much larger
dimensions, the lapply() approach was only slightly faster than the for()
loop approach on my PC.

data3 <- data
data3[ , , i] <- mask(data3[ , , i], lsmask)

Jean




On Tue, Sep 6, 2016 at 11:33 PM, Justin Peter <Justin.Peter at usq.edu.au>
wrote:

> Dear R-user,
>
> I have a three-dimensional matrix of atmospheric data. The first two
> dimensions are spatial (lon and lat) and the third is time, such that
>
> dim(data) <- c(nlon,nlat,ntime)
>
> I wish to apply a land sea mask data which is a matrix of "0" and "1" if
> dim(nlon,nlat)
>
> dim(lsmask) <- c(nlon,nlat)
>
> I wish to set all of the elements in the two-dimensional array of
> data[,,ntime] for every 1:length(ntime).
>
> I could do this in a loop:
>
> for (i in 1:ntime){
>     data[,,i][which(lsmask == 0)] <- NA
> }
>
> I would like to do this using apply, but I need to pass two variables to
> the function in apply (data and lsmask), where data is a two-dimensional
> array.
>
> I tried:
>
> mask <- function(x,y) {x[which(y==0)] <- NA}
>
> masked_data <- apply(data,c(1,2),mask,y=lsmask)
>
> but I get back a vector of dim(nlon,nlat) populated with NA.
>
> Any clues as to what I am missing?
>
> Thanks in advance for you help.
>
> Kind regards,
> Justin
>
>
>
> --
> Justin Peter
> Research Fellow
> International Centre for Applied Climate Sciences,
> University of Southern Queensland
> West St, Toowoomba, QLD, 4350
> Australia
>
> Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au>
> Ph: +61 (0) 7 4631 1181
> Fax: +61 (0) 7 4631 5581
> Mob: +61 (0)474 774 107
>
>
>
>
> _____________________________________________________________
> This email (including any attached files) is confidential and is for the
> intended recipient(s) only. If you received this email by mistake, please,
> as a courtesy, tell the sender, then delete this email.
>
> The views and opinions are the originator's and do not necessarily reflect
> those of the University of Southern Queensland. Although all reasonable
> precautions were taken to ensure that this email contained no viruses at
> the time it was sent we accept no liability for any losses arising from its
> receipt.
>
> The University of Southern Queensland is a registered provider of
> education with the Australian Government.
> (CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep  7 15:23:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Sep 2016 06:23:02 -0700
Subject: [R] building R from source on gnu version >=5.4
In-Reply-To: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>
References: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>
Message-ID: <D1EFE2AE-2E9F-4622-98D5-CE52A24581C7@dcn.davis.ca.us>

Many things are possible, especially if you read the Posting Guide which tells you you that questions involving compiling R belong on R-devel, not R-help.
-- 
Sent from my phone. Please excuse my brevity.

On September 7, 2016 1:17:10 AM PDT, Chinmay Borwankar <getchinmay at gmail.com> wrote:
>Hi,
>    I want to integrate R with ROOTv6.06, which requires that,
>    R be built with gcc compiler option "_GLIBCXX_USE_CXX11_ABI=0" .
>  I am hoping that if I build R from source then there will be a way to
>do this.
>    Is there ?
>    Regards.


From jdnewmil at dcn.davis.ca.us  Wed Sep  7 15:33:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Sep 2016 06:33:06 -0700
Subject: [R] Using apply on a three dimensional matrix and passing
	multiple arguments to user defined function
In-Reply-To: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
References: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
Message-ID: <FA1EBD51-E102-47D3-B8F9-178B1E461DC8@dcn.davis.ca.us>

Should be working, so the devil is in the details you are not showing. Please provide a reproducible (self-contained) example [1] and post in plain text rather than HTML formatted email to avoid code corruption. 

[1] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On September 6, 2016 9:33:35 PM PDT, Justin Peter <Justin.Peter at usq.edu.au> wrote:
>Dear R-user,
>
>I have a three-dimensional matrix of atmospheric data. The first two
>dimensions are spatial (lon and lat) and the third is time, such that
>
>dim(data) <- c(nlon,nlat,ntime)
>
>I wish to apply a land sea mask data which is a matrix of "0" and "1"
>if dim(nlon,nlat)
>
>dim(lsmask) <- c(nlon,nlat)
>
>I wish to set all of the elements in the two-dimensional array of
>data[,,ntime] for every 1:length(ntime).
>
>I could do this in a loop:
>
>for (i in 1:ntime){
>    data[,,i][which(lsmask == 0)] <- NA
>}
>
>I would like to do this using apply, but I need to pass two variables
>to the function in apply (data and lsmask), where data is a
>two-dimensional array.
>
>I tried:
>
>mask <- function(x,y) {x[which(y==0)] <- NA}
>
>masked_data <- apply(data,c(1,2),mask,y=lsmask)
>
>but I get back a vector of dim(nlon,nlat) populated with NA.
>
>Any clues as to what I am missing?
>
>Thanks in advance for you help.
>
>Kind regards,
>Justin
>
>
>
>--
>Justin Peter
>Research Fellow
>International Centre for Applied Climate Sciences,
>University of Southern Queensland
>West St, Toowoomba, QLD, 4350
>Australia
>
>Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au>
>Ph: +61 (0) 7 4631 1181
>Fax: +61 (0) 7 4631 5581
>Mob: +61 (0)474 774 107
>
>
>
>
>_____________________________________________________________
>This email (including any attached files) is confidential and is for
>the intended recipient(s) only. If you received this email by mistake,
>please, as a courtesy, tell the sender, then delete this email.
>
>The views and opinions are the originator's and do not necessarily
>reflect those of the University of Southern Queensland. Although all
>reasonable precautions were taken to ensure that this email contained
>no viruses at the time it was sent we accept no liability for any
>losses arising from its receipt.
>
>The University of Southern Queensland is a registered provider of
>education with the Australian Government.
>(CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Sep  7 15:34:44 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Sep 2016 09:34:44 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmpcBcnHeWg=QATjt=uZLg+hUbbVBkP1U_Qh02DArGWwCw@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
	<CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>
	<CAMCXXmpcBcnHeWg=QATjt=uZLg+hUbbVBkP1U_Qh02DArGWwCw@mail.gmail.com>
Message-ID: <CA+vqiLEnOp9hntOhKbkmjPbrkBU8pTJMySGNmkgzHCgj3bUUJQ@mail.gmail.com>

On Tue, Sep 6, 2016 at 11:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi Ista,
>
> Thanks for the suggestion. I didn't know mapply can be used this way! Let me
> take one more step. Instead of defining a pattern for each string, I would
> like to define a set of patterns from all the possible combination of the
> unique values of those variables. Then I need each string to find a pattern
> for itself.

Uh, humn, what?!? I have no idea what this means. Example?

--Ista

 I know this is getting a little stretching. Thanks for all the
> suggestion/comments from everyone.
>
> Jun
>
> On Tue, Sep 6, 2016 at 9:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> If you want to mach each element of 'strings' to a different regex, do
>> it. Here are three ways, using your original example.
>>
>> pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>
>> patterns <- c(pattern1,pattern2)
>> strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>
>> for(i in seq(strings)) print(sub(patterns[i], "\\2", strings[i]))
>>
>> mapply(sub, pattern = patterns, x = strings, MoreArgs=list(replacement =
>> "\\2"))
>>
>> library(stringi)
>> stri_replace_all_regex(strings, patterns, "$2")
>>
>> Best,
>> Ista
>> On Tue, Sep 6, 2016 at 9:20 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> > Hi Jeff,
>> >
>> > Thanks for the reply. I tried your suggestion and it doesn't seem to
>> > work
>> > and I tried a simple pattern as follows and it works as expected
>> >
>> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1',
>> > "3.mg.kg.>50-70.kg.P05")
>> > [1] "3.mg.kg"
>> >
>> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2',
>> > "3.mg.kg.>50-70.kg.P05")
>> > [1] ">50-70.kg"
>> >
>> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3',
>> > "3.mg.kg.>50-70.kg.P05")
>> > [1] "P05"
>> >
>> > My problem is the pattern has to be dynamically constructed on the input
>> > data of the function I am writing. It's actually not too difficult to
>> > assemble the final.pattern with some code like the following
>> >
>> > sort.var <- c('TX','WTCUT')
>> > combn.sort.var <- do.call(expand.grid, lapply(sort.var,
>> >
>> > function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))),
>> > ')', sep='')))
>> > all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
>> > final.pattern <- paste0(all.patterns, collapse='|')
>> >
>> > You cannot run the code directly since the data object "all.exposure" is
>> > not provided here.
>> >
>> > Jun
>> >
>> >
>> >
>> > On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller
>> > <jdnewmil at dcn.davis.ca.us>
>> > wrote:
>> >
>> >> I am not near my computer today, but each parenthesis gets its own
>> >> result
>> >> number, so you should put the parenthesis around the whole pattern of
>> >> alternatives instead of having many parentheses.
>> >>
>> >> I recommend thinking in terms of what common information you expect to
>> >> find in these various strings, and place your parentheses to capture
>> >> that
>> >> information. There is no other reason to put parentheses in the
>> >> pattern...
>> >> they are not grouping symbols.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On September 6, 2016 5:01:04 PM PDT, Bert Gunter
>> >> <bgunter.4567 at gmail.com>
>> >> wrote:
>> >> >Jun:
>> >> >
>> >> >1. Tell us your desired result from your test vector and maybe someone
>> >> >will help.
>> >> >
>> >> >2. As we played this game once already (you couldn't do it; I showed
>> >> >you how), this seems to be a function of your limitations with regular
>> >> >expressions. I'm probably not much better, but in any case, I don't
>> >> >intend to be your consultant. See if you can find someone locally to
>> >> >help you if you do not receive a satisfactory reply from the list.
>> >> >There are many people here who are pretty good at this sort of thing,
>> >> >but I don't know if they'll reply. Regex's are certainly complex. PERL
>> >> >people tend to be pretty good at them, I believe. There are numerous
>> >> >web sites and books on them if you need to acquire expertise for your
>> >> >work.
>> >> >
>> >> >Cheers,
>> >> >Bert
>> >> >Bert Gunter
>> >> >
>> >> >"The trouble with having an open mind is that people keep coming along
>> >> >and sticking things into it."
>> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >
>> >> >
>> >> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com>
>> >> > wrote:
>> >> >> Hi Bert,
>> >> >>
>> >> >> I still couldn't make the multiple patterns to work. Here is an
>> >> >example. I
>> >> >> make the pattern as follows
>> >> >>
>> >> >> final.pattern <-
>> >> >>
>> >> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
>> >> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
>> >> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
>> >> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
>> >> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
>> >> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
>> >> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>> >> >>
>> >> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg.>110.kg.P05',
>> >> >> '240.m.g.>50-70.kg.geo.mean')
>> >> >>
>> >> >> sub(final.pattern, '\\1', test.string)
>> >> >> sub(final.pattern, '\\2', test.string)
>> >> >> sub(final.pattern, '\\3', test.string)
>> >> >>
>> >> >> Only the third string has been correctly parsed, which matches the
>> >> >first
>> >> >> pattern. It seems the rest of the patterns are not called.
>> >> >>
>> >> >> Jun
>> >> >>
>> >> >>
>> >> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter
>> >> >> <bgunter.4567 at gmail.com>
>> >> >wrote:
>> >> >>>
>> >> >>> Just noticed: My clumsy do.call() line in my previously posted code
>> >> >>> below should be replaced with:
>> >> >>> pat <- paste(pat,collapse = "|")
>> >> >>>
>> >> >>>
>> >> >>> > pat <- c(pat1,pat2)
>> >> >>> > paste(pat,collapse="|")
>> >> >>> [1] "a+\\.*a+|b+\\.*b+"
>> >> >>>
>> >> >>> ************ replace this **************************
>> >> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >> >>> ********************************************
>> >> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>> >> >>> [1] "a.a"   "bb"    "b.bbb"
>> >> >>>
>> >> >>>
>> >> >>> -- Bert
>> >> >>> Bert Gunter
>> >> >>>
>> >> >>> "The trouble with having an open mind is that people keep coming
>> >> >along
>> >> >>> and sticking things into it."
>> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >>>
>> >> >>>
>> >> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>> >> ><bgunter.4567 at gmail.com>
>> >> >>> wrote:
>> >> >>> > Jun:
>> >> >>> >
>> >> >>> > You need to provide a clear specification via regular expressions
>> >> >of
>> >> >>> > the patterns you wish to match -- at least for me to decipher it.
>> >> >>> > Others may be smarter than I, though...
>> >> >>> >
>> >> >>> > Jeff: Thanks. I have now convinced myself that it can be done (a
>> >> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>> >> >patterns
>> >> >>> > (in a vector of patterns)  to be matched in a vector of n
>> >> >>> > strings,
>> >> >>> > where only one of the patterns will match in any string,  then
>> >> >>> > use
>> >> >>> > paste() (probably via do.call()) or otherwise to paste them
>> >> >together
>> >> >>> > separated by "|" to form the concatenated pattern, pat. Then
>> >> >>> >
>> >> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>> >> >>> >
>> >> >>> > should extract the matching pattern in each (perhaps with a
>> >> >>> > little
>> >> >>> > fiddling due to precedence rules); e.g.
>> >> >>> >
>> >> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>> >> >>> >
>> >> >>> >> pat1 <- "a+\\.*a+"
>> >> >>> >> pat2 <-"b+\\.*b+"
>> >> >>> >> pat <- c(pat1,pat2)
>> >> >>> >
>> >> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >> >>> >> pat
>> >> >>> > [1] "a+\\.*a+|b+\\.*b+"
>> >> >>> >
>> >> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>> >> >>> > [1] "a.a"   "bb"    "b.bbb"
>> >> >>> >
>> >> >>> > Cheers,
>> >> >>> > Bert
>> >> >>> >
>> >> >>> >
>> >> >>> > Bert Gunter
>> >> >>> >
>> >> >>> > "The trouble with having an open mind is that people keep coming
>> >> >along
>> >> >>> > and sticking things into it."
>> >> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>> >> >>> > )
>> >> >>> >
>> >> >>> >
>> >> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <jun.shen.ut at gmail.com>
>> >> >wrote:
>> >> >>> >> Thanks for the reply, Bert.
>> >> >>> >>
>> >> >>> >> Your solution solves the example. I actually have a more general
>> >> >>> >> situation
>> >> >>> >> where I have this dot concatenated string from multiple
>> >> >variables. The
>> >> >>> >> problem is those variables may have values with dots in there.
>> >> >The
>> >> >>> >> number of
>> >> >>> >> dots are not consistent for all values of a variable. So I am
>> >> >thinking
>> >> >>> >> to
>> >> >>> >> define a vector of patterns for the vector of the string and
>> >> >hopefully
>> >> >>> >> to
>> >> >>> >> find a way to use a pattern from the pattern vector for each
>> >> >value of
>> >> >>> >> the
>> >> >>> >> string vector. The only way I can think of is "for" loop, which
>> >> >can be
>> >> >>> >> slow.
>> >> >>> >> Also these are happening in a function I am writing. Just wonder
>> >> >if
>> >> >>> >> there is
>> >> >>> >> another more efficient way. Thanks a lot.
>> >> >>> >>
>> >> >>> >> Jun
>> >> >>> >>
>> >> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>> >> ><bgunter.4567 at gmail.com>
>> >> >>> >> wrote:
>> >> >>> >>>
>> >> >>> >>> Well, he did provide an example, and...
>> >> >>> >>>
>> >> >>> >>>
>> >> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >> >>> >>>
>> >> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> >> >>> >>> [1] "WT.CUT" "tx"
>> >> >>> >>>
>> >> >>> >>>
>> >> >>> >>> ## seems to do what was requested.
>> >> >>> >>>
>> >> >>> >>> Jeff would have to amplify on his initial statement however: do
>> >> >you
>> >> >>> >>> mean that separate patterns can always be combined via "|" ?
>> >> >>> >>> Or
>> >> >>> >>> something deeper?
>> >> >>> >>>
>> >> >>> >>> Cheers,
>> >> >>> >>> Bert
>> >> >>> >>> Bert Gunter
>> >> >>> >>>
>> >> >>> >>> "The trouble with having an open mind is that people keep
>> >> >>> >>> coming
>> >> >along
>> >> >>> >>> and sticking things into it."
>> >> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> >> >>> >>> strip
>> >> >)
>> >> >>> >>>
>> >> >>> >>>
>> >> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>> >> >>> >>> <jdnewmil at dcn.davis.ca.us>
>> >> >>> >>> wrote:
>> >> >>> >>> > Your opening assertion is false.
>> >> >>> >>> >
>> >> >>> >>> > Provide a reproducible example and someone will demonstrate.
>> >> >>> >>> > --
>> >> >>> >>> > Sent from my phone. Please excuse my brevity.
>> >> >>> >>> >
>> >> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>> >> >>> >>> > <jun.shen.ut at gmail.com>
>> >> >>> >>> > wrote:
>> >> >>> >>> >>Dear list,
>> >> >>> >>> >>
>> >> >>> >>> >>I have a vector of strings that cannot be described by one
>> >> >pattern.
>> >> >>> >>> >> So
>> >> >>> >>> >>let's say I construct a vector of patterns in the same length
>> >> >as the
>> >> >>> >>> >>vector
>> >> >>> >>> >>of strings, can I do the element wise pattern recognition and
>> >> >string
>> >> >>> >>> >>substitution.
>> >> >>> >>> >>
>> >> >>> >>> >>For example,
>> >> >>> >>> >>
>> >> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >> >>> >>> >>
>> >> >>> >>> >>patterns <- c(pattern1,pattern2)
>> >> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >> >>> >>> >>
>> >> >>> >>> >>Say I want to extract "WT.CUT" from the first string and "tx"
>> >> >from
>> >> >>> >>> >> the
>> >> >>> >>> >>second string. If I do
>> >> >>> >>> >>
>> >> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will be
>> >> >used.
>> >> >>> >>> >>
>> >> >>> >>> >>looping the patterns doesn't work the way I want. Appreciate
>> >> >any
>> >> >>> >>> >>comments.
>> >> >>> >>> >>Thanks.
>> >> >>> >>> >>
>> >> >>> >>> >>Jun
>> >> >>> >>> >>
>> >> >>> >>> >>       [[alternative HTML version deleted]]
>> >> >>> >>> >>
>> >> >>> >>> >>______________________________________________
>> >> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >see
>> >> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>> >>> >>PLEASE do read the posting guide
>> >> >>> >>> >>http://www.R-project.org/posting-guide.html
>> >> >>> >>> >>and provide commented, minimal, self-contained, reproducible
>> >> >code.
>> >> >>> >>> >
>> >> >>> >>> > ______________________________________________
>> >> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >see
>> >> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>> >>> > PLEASE do read the posting guide
>> >> >>> >>> > http://www.R-project.org/posting-guide.html
>> >> >>> >>> > and provide commented, minimal, self-contained, reproducible
>> >> >code.
>> >> >>> >>
>> >> >>> >>
>> >> >>
>> >> >>
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From petr.pikal at precheza.cz  Wed Sep  7 15:49:42 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 7 Sep 2016 13:49:42 +0000
Subject: [R] how to manage missing values correctly when importing a
	data	frame
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503BD0A@SRVEXCHMBX.precheza.cz>

Hi

Although you did not present your data in suitable format I do not see any problem.

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano
> Sofia
> Sent: Wednesday, September 7, 2016 1:09 PM
> To: r-help at r-project.org
> Subject: [R] how to manage missing values correctly when importing a data
> frame
>
> Dear R users,
> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4
> rows:
>
> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM
> Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT
> Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT
> Actual_net Notes Test_20141231 Test_20151231
> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA
> NA NA NA CAE NA NO NO
> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna
> Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro
> Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano
> Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>
> I load it with
> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep="
> ", dec = ".", stringsAsFactors = FALSE)
>
> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500])
> gives [1] "YES"

So you have unique value here

>
> while
> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT ==
> 112]) gives
> [1] NA   "YES"

and two values here, one is NA

see

dat<-data.frame(x1=c("a", "a", "b", NA), x2=c(1,2,3,3))
dat$x1<-as.character(dat$x1)

> dat$x1[dat$x2==1]
[1] "a"
> dat$x1[dat$x2==2]
[1] "a"
> dat$x1[dat$x2==3]
[1] "b" NA
>

You should consult R intro to understand basic object types, their distinctions and language basics.

Cheers
Petr


>
>
> print(lapply(Storia_RM_RT, class)) gives
>
> $Station_RM
> [1] "integer"
>
> $Sensor_RM
> [1] "integer"
>
> $Place_RM
> [1] "character"
>
> $Y_init_RM
> [1] "integer"
>
> $M_init_RM
> [1] "integer"
>
> $D_init_RM
> [1] "integer"
>
> $Long_cent_RM
> [1] "numeric"
>
> $Lat_cent_RM
> [1] "numeric"
>
> $Height_RM
> [1] "integer"
>
> $Continues
> [1] "character"
>
> $Station_RT
> [1] "integer"
>
> $Sensor_RT
> [1] "integer"
>
> $Place_RT
> [1] "character"
>
> $Name1_RT
> [1] "character"
>
> $Name2_RT
> [1] "character"
>
> $Long_cent_RT
> [1] "numeric"
>
> $Lat_cent_RT
> [1] "numeric"
> $Quota_RT
> [1] "numeric"
>
> $Actual_net
> [1] "character"
>
> $Notes
> [1] "logical"
>
> $Test_20141231
> [1] "character"
>
> $Test_20151231
> [1] "character"
>
> I am struggling to understand why the query through the field Station_RT
> does not work.
> Could please somebody help me to manage correctly the missing values? Is
> the mistake somewhere else?
>
> Thank you
> Stefano Sofia
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione Marche
> possono contenere informazioni confidenziali e con privilegi legali. Se non si ?
> il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo
> messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al
> mittente ed eliminarlo completamente dal sistema del proprio computer. Ai
> sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed
> urgenza, la risposta al presente messaggio di posta elettronica pu? essere
> visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain. E-mail
> messages to clients of Regione Marche may contain information that is
> confidential and legally privileged. Please do not read, copy, forward, or store
> this message unless you are an intended recipient of it. If you have received
> this message in error, please forward it to the sender and delete it
> completely from your computer system.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Sep  7 16:00:18 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 7 Sep 2016 14:00:18 +0000
Subject: [R] Help with a code in R
In-Reply-To: <CAJMJkRJ810YLdivjief5Xrh1K=5VAfkkVdvhuzgAb_B7wHpGfA@mail.gmail.com>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>
	<CAJMJkRJ810YLdivjief5Xrh1K=5VAfkkVdvhuzgAb_B7wHpGfA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503BD49@SRVEXCHMBX.precheza.cz>

Hi

see in line

From: Erika Roc?o Espinosa Balbuena [mailto:erikareb at gmail.com]
Sent: Tuesday, September 6, 2016 10:52 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Help with a code in R

Hi Erika

Yes the objetcs have the same structure, and forecast_nal is the variable where I a trying to keep all the results of the forecast but I get the error that it

How did you check? Can you prove it?

There is nobody who can check your code, only you. We get this error

Error in nrow(comb) : object 'comb' not found

Cheers
Petr

BTW, plain text posting is preferable.


is only allowed the replacement.

2016-09-06 1:31 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:
Hi

Well, it seems to me that it is coded in different language like C++.
The code is not reproducible but the error seems to be from your call of ts

You can check it line by line with setting i to arbitrary value and inspect how your objects look like, however some of your constructions seems to me quite weird.

e.g.
forecast_nal<-data.frame()

leads to mempty data frame with no column named mean
> forecast_nal
data frame with 0 columns and 0 rows
> forecast_nal$mean
NULL

and I am rather surprised how this column come into existence.

BTW, are you sure that in each cycle your rbinded or cbinded objects have the same size?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Erika Roc?o
> Espinosa Balbuena
> Sent: Monday, September 5, 2016 8:26 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Help with a code in R
>
> Hi,
>
> I am working with this code:
>
> forecast_nal<-data.frame()
> out<-vector()
> x<-foreach(i=1:nrow(comb)) %do%
> {
>
> s<-comb[i,'prod_id']
>
> #Familia+Sumbarca+prod_id
> #Serie
>
> bcomb1<-b
> bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> bcomb1<-arrange(bcomb1,year,week)
> a<-bcomb1[1:1,'week']
> d<-bcomb1[1:1,'year']
> f<-nrow(bcomb1)
> h<-bcomb1[f:f,'year']
> j<-bcomb1[f:f,'week']
> bcomb1<-bcomb1[,c(6)]
>
> if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48)) { out[i]<-s }
> else {
>        y <- ts(bcomb1, frequency=52, start=c(d, a)) ##Casos
>
> if (length(y)<=60)
> {
>
> v<-auto.arima(y)
> v<-arimaorder(v)
> fit <- arima(y, order = v ,method="ML")
>       fca <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> else
> {
>
> fit <- tbats(y)
> fcb <- forecast(fit, h = 16)
> dates <- attr(forecast_nal$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>             forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> }
> }
>  But I am getting this error:
>
> Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833, 26750.9374514082,
>  :
>   only replacement of elements is allowed
>
> Can someone help me with this?
>
> Thanks
>
>
> --
> Erika Roc?o Espinosa Balbuena
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



--
Erika Roc?o Espinosa Balbuena

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From luisfo89 at yahoo.es  Wed Sep  7 16:05:48 2016
From: luisfo89 at yahoo.es (Luisfo)
Date: Wed, 7 Sep 2016 16:05:48 +0200
Subject: [R] Using apply on a three dimensional matrix and passing
 multiple arguments to user defined function
In-Reply-To: <CAN5YmCHC-GFNvO7bc_Lyk2p+UtRon=eDLnhHF4HiLP65RM4syw@mail.gmail.com>
References: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
	<CAN5YmCHC-GFNvO7bc_Lyk2p+UtRon=eDLnhHF4HiLP65RM4syw@mail.gmail.com>
Message-ID: <852d264d-9ac2-b4e4-6b21-0a81608e89bb@yahoo.es>

Hi,

Jean's example with lapply works fine.

However, if you still want to use apply, I think this works.
One observation first. You were passing c(1,2) as second argument to 
apply, in your code. And that is what makes you have lots of NAs as a 
result, since your function is being applied twice, by rows and columns 
(first and second dimensions) respectively.
Use:
     masked_data <- apply(data,3,mask,y=lsmask)
     # but now masked_data has dim(nlon*nlat,ntime), so change it
     dim(masked_data) <- dim(data)

The apply goes over the third dimension (second parameter '3'), so it 
takes every nlot*nlat matrix as first argument for function mask.
I think it should work.

Regards,

*Luisfo Chiroque*
/PhD Student | PhD Candidate
IMDEA Networks Institute/
http://fourier.networks.imdea.org/people/~luis_nunez/ 
<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>

On 09/07/2016 03:17 PM, Adams, Jean wrote:
> Justin,
>
> I don't think you can get the apply() function to return an array.  You
> could use lapply() instead, and then use simplify2array() to convert the
> list of matrices to an array.  Also, in your mask() function you don't need
> the which() and you should return the x.  See my example with toy data
> below.
>
> # toy data
> nlon <- 2
> nlat <- 4
> ntime <- 3
> data <- array(1:(nlon*nlat*ntime), dim=c(nlon, nlat, ntime))
> lsmask <- array(sample(0:1, size=nlon*nlat, replace=TRUE), dim=c(nlon,
> nlat))
>
> # newly defined function
> mask <- function(x, y) {
>    x[y==0] <- NA
>    x
> }
>
> # doit
> data2 <- simplify2array(lapply(1:ntime, function(i) mask(data[, , i],
> lsmask)))
>
>
> You may prefer to stick with the for() loop approach (for clarity or
> simplicity or ...)  When I ramped up the toy data to much larger
> dimensions, the lapply() approach was only slightly faster than the for()
> loop approach on my PC.
>
> data3 <- data
> data3[ , , i] <- mask(data3[ , , i], lsmask)
>
> Jean
>
>
>
>
> On Tue, Sep 6, 2016 at 11:33 PM, Justin Peter <Justin.Peter at usq.edu.au>
> wrote:
>
>> Dear R-user,
>>
>> I have a three-dimensional matrix of atmospheric data. The first two
>> dimensions are spatial (lon and lat) and the third is time, such that
>>
>> dim(data) <- c(nlon,nlat,ntime)
>>
>> I wish to apply a land sea mask data which is a matrix of "0" and "1" if
>> dim(nlon,nlat)
>>
>> dim(lsmask) <- c(nlon,nlat)
>>
>> I wish to set all of the elements in the two-dimensional array of
>> data[,,ntime] for every 1:length(ntime).
>>
>> I could do this in a loop:
>>
>> for (i in 1:ntime){
>>      data[,,i][which(lsmask == 0)] <- NA
>> }
>>
>> I would like to do this using apply, but I need to pass two variables to
>> the function in apply (data and lsmask), where data is a two-dimensional
>> array.
>>
>> I tried:
>>
>> mask <- function(x,y) {x[which(y==0)] <- NA}
>>
>> masked_data <- apply(data,c(1,2),mask,y=lsmask)
>>
>> but I get back a vector of dim(nlon,nlat) populated with NA.
>>
>> Any clues as to what I am missing?
>>
>> Thanks in advance for you help.
>>
>> Kind regards,
>> Justin
>>
>>
>>
>> --
>> Justin Peter
>> Research Fellow
>> International Centre for Applied Climate Sciences,
>> University of Southern Queensland
>> West St, Toowoomba, QLD, 4350
>> Australia
>>
>> Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au>
>> Ph: +61 (0) 7 4631 1181
>> Fax: +61 (0) 7 4631 5581
>> Mob: +61 (0)474 774 107
>>
>>
>>
>>
>> _____________________________________________________________
>> This email (including any attached files) is confidential and is for the
>> intended recipient(s) only. If you received this email by mistake, please,
>> as a courtesy, tell the sender, then delete this email.
>>
>> The views and opinions are the originator's and do not necessarily reflect
>> those of the University of Southern Queensland. Although all reasonable
>> precautions were taken to ensure that this email contained no viruses at
>> the time it was sent we accept no liability for any losses arising from its
>> receipt.
>>
>> The University of Southern Queensland is a registered provider of
>> education with the Australian Government.
>> (CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Wed Sep  7 16:26:24 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 7 Sep 2016 14:26:24 +0000
Subject: [R] how to manage missing values correctly when importing a
 data frame
In-Reply-To: <CAM_vjumgZeEttsmX5Cv7L5047PRy3KSv_O9BFFvR=LihB8RZ2w@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>,
	<CAM_vjumgZeEttsmX5Cv7L5047PRy3KSv_O9BFFvR=LihB8RZ2w@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBDA9B9@ESINO.regionemarche.intra>

Thank you for your explanations, and your patience.
With all the humbleness that I can have, I am not a beginner in R. Said that I am really sorry if my question shows a big lack in understanding some basic object types and their distinctions.

I still find difficult to understand your comments (which are obviously correct), and I beg your pardon if I keep asking you the same question.
In my query to the data frame, Station_RT is exactly 112, and there is only one row where Station_RT is equal to 112. I would expect a unique value for Test_20151231.
Why R should expect to handle the possibility of having Station_RT = NA?

# > Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
# What do you expect to have happen when Station_RT is NA? R has no idea
# whether it is 112 or not, so R returns an "I don't know" value that
# lets the user decide how to handle the missing data, rather than making
# assumptions.

Again, sorry for my question
Stefano

________________________________________
Da: Sarah Goslee [sarah.goslee at gmail.com]
Inviato: mercoled? 7 settembre 2016 15.11
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] how to manage missing values correctly when importing a data frame

R is refusing to make unwarranted assumptions about your data.

See inline.


# it's nicer to use dput() instead of pasting raw data

Storia_RM_RT <- structure(list(Station_RM = c(1400L, 1460L, 1500L,
1520L), Sensor_RM = 2701:2704,
    Place_RM = c("Novafeltria", "Carpegna", "Pesaro", "Fano"),
    Y_init_RM = c(1959L, 1963L, 1957L, 1957L), M_init_RM = c(1L,
    1L, 1L, 1L), D_init_RM = c(1L, 1L, 1L, 1L), Long_cent_RM = c(12.289552,
    12.332614, 12.909822, 13.017591), Lat_cent_RM = c(43.890057,
    43.778107, 43.910889, 43.840054), Height_RM = c(293L, 748L,
    11L, 4L), Continues = c("NO", "SI", "SI", "SI"), Station_RT = c(NA,
    702L, 112L, 152L), Sensor_RT = c(NA, 2954L, 1229L, 2671L),
    Place_RT = c(NA, "Carpegna", "Pesaro", "Fano"), Name1_RT = c(NA,
    "Carpegna", "Villa_Fastiggi", "Foce_Metauro"), Name2_RT = c(NA,
    "Carpegna", "Villa_Fastiggi", "Metaurilia"), Long_cent_RT = c(NA,
    12.340618, 12.86939, 13.053796), Lat_cent_RT = c(NA, 43.780575,
    43.89061, 43.826328), Height_RT = c(NA, 715, 22, 7.12), Actual_net
= c("CAE",
    "RT", "RT", "RT"), Notes = c(NA, NA, NA, NA), Test_20141231 = c("NO",
    "NO", "YES", "YES"), Test_20151231 = c("NO", "NO", "YES",
    "YES")), .Names = c("Station_RM", "Sensor_RM", "Place_RM",
"Y_init_RM", "M_init_RM", "D_init_RM", "Long_cent_RM", "Lat_cent_RM",
"Height_RM", "Continues", "Station_RT", "Sensor_RT", "Place_RT",
"Name1_RT", "Name2_RT", "Long_cent_RT", "Lat_cent_RT", "Height_RT",
"Actual_net", "Notes", "Test_20141231", "Test_20151231"), class =
"data.frame", row.names = c(NA,
-4L))


> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]
[1] "YES"

# Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]
# there's no such column; you probably mean Test_20151231

> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
[1] NA    "YES"

# What do you expect to have happen when Station_RT is NA? R has no idea
# whether it is 112 or not, so R returns an "I don't know" value that
# lets the user decide how to handle the missing data, rather than making
# assumptions.

# But you probably want one of these constructions:

Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112 &
!is.na(Storia_RM_RT$Station_RT)]

# subset automatically handles NAs, making the assumption I'm assuming you want.
subset(Storia_RM_RT, Station_RT == 112 )$Test_20151231

# This is the first form, somewhat more elegantly
with(Storia_RM_RT, Test_20151231[Station_RT == 112 & !is.na(Station_RT)])

On Wed, Sep 7, 2016 at 7:09 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R users,
> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:
>
> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes Test_20141231 Test_20151231
> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>
> I load it with
> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)
>
> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
> [1] "YES"
>
> while
> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
> [1] NA   "YES"
>
>
> print(lapply(Storia_RM_RT, class)) gives
>
> $Station_RM
> [1] "integer"
>
> $Sensor_RM
> [1] "integer"
>
> $Place_RM
> [1] "character"
>
> $Y_init_RM
> [1] "integer"
>
> $M_init_RM
> [1] "integer"
>
> $D_init_RM
> [1] "integer"
>
> $Long_cent_RM
> [1] "numeric"
>
> $Lat_cent_RM
> [1] "numeric"
>
> $Height_RM
> [1] "integer"
>
> $Continues
> [1] "character"
>
> $Station_RT
> [1] "integer"
>
> $Sensor_RT
> [1] "integer"
>
> $Place_RT
> [1] "character"
>
> $Name1_RT
> [1] "character"
>
> $Name2_RT
> [1] "character"
>
> $Long_cent_RT
> [1] "numeric"
>
> $Lat_cent_RT
> [1] "numeric"
> $Quota_RT
> [1] "numeric"
>
> $Actual_net
> [1] "character"
>
> $Notes
> [1] "logical"
>
> $Test_20141231
> [1] "character"
>
> $Test_20151231
> [1] "character"
>
> I am struggling to understand why the query through the field Station_RT does not work.
> Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?
>
> Thank you
> Stefano Sofia
>
>

--
Sarah Goslee
http://www.functionaldiversity.org

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From sarah.goslee at gmail.com  Wed Sep  7 16:39:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 7 Sep 2016 10:39:30 -0400
Subject: [R] how to manage missing values correctly when importing a
	data frame
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBDA9B9@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
	<CAM_vjumgZeEttsmX5Cv7L5047PRy3KSv_O9BFFvR=LihB8RZ2w@mail.gmail.com>
	<8B435C9568170B469AE31E8891E8CC4F3DBDA9B9@ESINO.regionemarche.intra>
Message-ID: <CAM_vjum-K5THT0x5d4GYjez2CFsMhpDi3jVnK74tVv9eRXqwKg@mail.gmail.com>

On Wed, Sep 7, 2016 at 10:26 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Thank you for your explanations, and your patience.
> With all the humbleness that I can have, I am not a beginner in R. Said that I am really sorry if my question shows a big lack in understanding some basic object types and their distinctions.
>
> I still find difficult to understand your comments (which are obviously correct), and I beg your pardon if I keep asking you the same question.
> In my query to the data frame, Station_RT is exactly 112, and there is only one row where Station_RT is equal to 112. I would expect a unique value for Test_20151231.
> Why R should expect to handle the possibility of having Station_RT = NA?

If a value for Station_RT is missing, how does R know whether it is
112 or not? It could be. Instead of assuming that it is not, R tells
the user that there is a potential problem, and it's on the user to
decide explicitly whether NA values should be included or not.

If you read further down, I showed you two ways to handle that, one
that makes the same assumption you do, that NA values cannot ever be
112, and one that requires you to explicitly state that you want NA
values to be ignored.



>
> # > Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
> # What do you expect to have happen when Station_RT is NA? R has no idea
> # whether it is 112 or not, so R returns an "I don't know" value that
> # lets the user decide how to handle the missing data, rather than making
> # assumptions.
>
> Again, sorry for my question
> Stefano
>
> ________________________________________
> Da: Sarah Goslee [sarah.goslee at gmail.com]
> Inviato: mercoled? 7 settembre 2016 15.11
> A: Stefano Sofia
> Cc: r-help at r-project.org
> Oggetto: Re: [R] how to manage missing values correctly when importing a data frame
>
> R is refusing to make unwarranted assumptions about your data.
>
> See inline.
>
>
> # it's nicer to use dput() instead of pasting raw data
>
> Storia_RM_RT <- structure(list(Station_RM = c(1400L, 1460L, 1500L,
> 1520L), Sensor_RM = 2701:2704,
>     Place_RM = c("Novafeltria", "Carpegna", "Pesaro", "Fano"),
>     Y_init_RM = c(1959L, 1963L, 1957L, 1957L), M_init_RM = c(1L,
>     1L, 1L, 1L), D_init_RM = c(1L, 1L, 1L, 1L), Long_cent_RM = c(12.289552,
>     12.332614, 12.909822, 13.017591), Lat_cent_RM = c(43.890057,
>     43.778107, 43.910889, 43.840054), Height_RM = c(293L, 748L,
>     11L, 4L), Continues = c("NO", "SI", "SI", "SI"), Station_RT = c(NA,
>     702L, 112L, 152L), Sensor_RT = c(NA, 2954L, 1229L, 2671L),
>     Place_RT = c(NA, "Carpegna", "Pesaro", "Fano"), Name1_RT = c(NA,
>     "Carpegna", "Villa_Fastiggi", "Foce_Metauro"), Name2_RT = c(NA,
>     "Carpegna", "Villa_Fastiggi", "Metaurilia"), Long_cent_RT = c(NA,
>     12.340618, 12.86939, 13.053796), Lat_cent_RT = c(NA, 43.780575,
>     43.89061, 43.826328), Height_RT = c(NA, 715, 22, 7.12), Actual_net
> = c("CAE",
>     "RT", "RT", "RT"), Notes = c(NA, NA, NA, NA), Test_20141231 = c("NO",
>     "NO", "YES", "YES"), Test_20151231 = c("NO", "NO", "YES",
>     "YES")), .Names = c("Station_RM", "Sensor_RM", "Place_RM",
> "Y_init_RM", "M_init_RM", "D_init_RM", "Long_cent_RM", "Lat_cent_RM",
> "Height_RM", "Continues", "Station_RT", "Sensor_RT", "Place_RT",
> "Name1_RT", "Name2_RT", "Long_cent_RT", "Lat_cent_RT", "Height_RT",
> "Actual_net", "Notes", "Test_20141231", "Test_20151231"), class =
> "data.frame", row.names = c(NA,
> -4L))
>
>
>> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]
> [1] "YES"
>
> # Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]
> # there's no such column; you probably mean Test_20151231
>
>> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
> [1] NA    "YES"
>
> # What do you expect to have happen when Station_RT is NA? R has no idea
> # whether it is 112 or not, so R returns an "I don't know" value that
> # lets the user decide how to handle the missing data, rather than making
> # assumptions.
>
> # But you probably want one of these constructions:
>
> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112 &
> !is.na(Storia_RM_RT$Station_RT)]
>
> # subset automatically handles NAs, making the assumption I'm assuming you want.
> subset(Storia_RM_RT, Station_RT == 112 )$Test_20151231
>
> # This is the first form, somewhat more elegantly
> with(Storia_RM_RT, Test_20151231[Station_RT == 112 & !is.na(Station_RT)])
>
> On Wed, Sep 7, 2016 at 7:09 AM, Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
>> Dear R users,
>> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:
>>
>> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes Test_20141231 Test_20151231
>> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
>> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
>> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
>> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>>
>> I load it with
>> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)
>>
>> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
>> [1] "YES"
>>
>> while
>> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
>> [1] NA   "YES"
>>
>>
>> print(lapply(Storia_RM_RT, class)) gives
>>
>> $Station_RM
>> [1] "integer"
>>
>> $Sensor_RM
>> [1] "integer"
>>
>> $Place_RM
>> [1] "character"
>>
>> $Y_init_RM
>> [1] "integer"
>>
>> $M_init_RM
>> [1] "integer"
>>
>> $D_init_RM
>> [1] "integer"
>>
>> $Long_cent_RM
>> [1] "numeric"
>>
>> $Lat_cent_RM
>> [1] "numeric"
>>
>> $Height_RM
>> [1] "integer"
>>
>> $Continues
>> [1] "character"
>>
>> $Station_RT
>> [1] "integer"
>>
>> $Sensor_RT
>> [1] "integer"
>>
>> $Place_RT
>> [1] "character"
>>
>> $Name1_RT
>> [1] "character"
>>
>> $Name2_RT
>> [1] "character"
>>
>> $Long_cent_RT
>> [1] "numeric"
>>
>> $Lat_cent_RT
>> [1] "numeric"
>> $Quota_RT
>> [1] "numeric"
>>
>> $Actual_net
>> [1] "character"
>>
>> $Notes
>> [1] "logical"
>>
>> $Test_20141231
>> [1] "character"
>>
>> $Test_20151231
>> [1] "character"
>>
>> I am struggling to understand why the query through the field Station_RT does not work.
>> Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?
>>
>> Thank you
>> Stefano Sofia
>>
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>


From ivan.calandra at univ-reims.fr  Wed Sep  7 16:56:20 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 7 Sep 2016 16:56:20 +0200
Subject: [R] how to manage missing values correctly when importing a
 data frame
In-Reply-To: <CAM_vjum-K5THT0x5d4GYjez2CFsMhpDi3jVnK74tVv9eRXqwKg@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DBDA971@ESINO.regionemarche.intra>
	<CAM_vjumgZeEttsmX5Cv7L5047PRy3KSv_O9BFFvR=LihB8RZ2w@mail.gmail.com>
	<8B435C9568170B469AE31E8891E8CC4F3DBDA9B9@ESINO.regionemarche.intra>
	<CAM_vjum-K5THT0x5d4GYjez2CFsMhpDi3jVnK74tVv9eRXqwKg@mail.gmail.com>
Message-ID: <388bc333-497c-f806-e367-8aecb0a7df26@univ-reims.fr>

Hi Stefano,

I agree that this behavior of R can be somewhat counter-intuitive, but 
this can be seen as a safety procedure, so that no assumptions are made 
and problems can be easily identified.

I would think that in this case, the input data is in the wrong format. 
Half the columns are for RM and the other for RT, but the headers are 
exactly the same. The problem then happens because you actually have 
only 3 lines of data for station RT but 4 for station RM. So it is 
filled with NA.

IMHO, it would be better to add a column "station" with values being 
either RM or RT. In that case, you would not have whole NA lines. And 
you would have less columns to work with. See what I mean?

By the way, I like the matrix method for subsetting a data.frame, I find 
it easier and more flexible (maybe someone will tell if there are any 
drawbacks):
Storia_RM_RT[Storia_RM_RT$Station_RT==112, "Test_20151231"]

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 07/09/2016 ? 16:39, Sarah Goslee a ?crit :
> On Wed, Sep 7, 2016 at 10:26 AM, Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
>> Thank you for your explanations, and your patience.
>> With all the humbleness that I can have, I am not a beginner in R. Said that I am really sorry if my question shows a big lack in understanding some basic object types and their distinctions.
>>
>> I still find difficult to understand your comments (which are obviously correct), and I beg your pardon if I keep asking you the same question.
>> In my query to the data frame, Station_RT is exactly 112, and there is only one row where Station_RT is equal to 112. I would expect a unique value for Test_20151231.
>> Why R should expect to handle the possibility of having Station_RT = NA?
> If a value for Station_RT is missing, how does R know whether it is
> 112 or not? It could be. Instead of assuming that it is not, R tells
> the user that there is a potential problem, and it's on the user to
> decide explicitly whether NA values should be included or not.
>
> If you read further down, I showed you two ways to handle that, one
> that makes the same assumption you do, that NA values cannot ever be
> 112, and one that requires you to explicitly state that you want NA
> values to be ignored.
>
>
>
>> # > Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
>> # What do you expect to have happen when Station_RT is NA? R has no idea
>> # whether it is 112 or not, so R returns an "I don't know" value that
>> # lets the user decide how to handle the missing data, rather than making
>> # assumptions.
>>
>> Again, sorry for my question
>> Stefano
>>
>> ________________________________________
>> Da: Sarah Goslee [sarah.goslee at gmail.com]
>> Inviato: mercoled? 7 settembre 2016 15.11
>> A: Stefano Sofia
>> Cc: r-help at r-project.org
>> Oggetto: Re: [R] how to manage missing values correctly when importing a data frame
>>
>> R is refusing to make unwarranted assumptions about your data.
>>
>> See inline.
>>
>>
>> # it's nicer to use dput() instead of pasting raw data
>>
>> Storia_RM_RT <- structure(list(Station_RM = c(1400L, 1460L, 1500L,
>> 1520L), Sensor_RM = 2701:2704,
>>      Place_RM = c("Novafeltria", "Carpegna", "Pesaro", "Fano"),
>>      Y_init_RM = c(1959L, 1963L, 1957L, 1957L), M_init_RM = c(1L,
>>      1L, 1L, 1L), D_init_RM = c(1L, 1L, 1L, 1L), Long_cent_RM = c(12.289552,
>>      12.332614, 12.909822, 13.017591), Lat_cent_RM = c(43.890057,
>>      43.778107, 43.910889, 43.840054), Height_RM = c(293L, 748L,
>>      11L, 4L), Continues = c("NO", "SI", "SI", "SI"), Station_RT = c(NA,
>>      702L, 112L, 152L), Sensor_RT = c(NA, 2954L, 1229L, 2671L),
>>      Place_RT = c(NA, "Carpegna", "Pesaro", "Fano"), Name1_RT = c(NA,
>>      "Carpegna", "Villa_Fastiggi", "Foce_Metauro"), Name2_RT = c(NA,
>>      "Carpegna", "Villa_Fastiggi", "Metaurilia"), Long_cent_RT = c(NA,
>>      12.340618, 12.86939, 13.053796), Lat_cent_RT = c(NA, 43.780575,
>>      43.89061, 43.826328), Height_RT = c(NA, 715, 22, 7.12), Actual_net
>> = c("CAE",
>>      "RT", "RT", "RT"), Notes = c(NA, NA, NA, NA), Test_20141231 = c("NO",
>>      "NO", "YES", "YES"), Test_20151231 = c("NO", "NO", "YES",
>>      "YES")), .Names = c("Station_RM", "Sensor_RM", "Place_RM",
>> "Y_init_RM", "M_init_RM", "D_init_RM", "Long_cent_RM", "Lat_cent_RM",
>> "Height_RM", "Continues", "Station_RT", "Sensor_RT", "Place_RT",
>> "Name1_RT", "Name2_RT", "Long_cent_RT", "Lat_cent_RT", "Height_RT",
>> "Actual_net", "Notes", "Test_20141231", "Test_20151231"), class =
>> "data.frame", row.names = c(NA,
>> -4L))
>>
>>
>>> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]
>> [1] "YES"
>>
>> # Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]
>> # there's no such column; you probably mean Test_20151231
>>
>>> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112]
>> [1] NA    "YES"
>>
>> # What do you expect to have happen when Station_RT is NA? R has no idea
>> # whether it is 112 or not, so R returns an "I don't know" value that
>> # lets the user decide how to handle the missing data, rather than making
>> # assumptions.
>>
>> # But you probably want one of these constructions:
>>
>> Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RT == 112 &
>> !is.na(Storia_RM_RT$Station_RT)]
>>
>> # subset automatically handles NAs, making the assumption I'm assuming you want.
>> subset(Storia_RM_RT, Station_RT == 112 )$Test_20151231
>>
>> # This is the first form, somewhat more elegantly
>> with(Storia_RM_RT, Test_20151231[Station_RT == 112 & !is.na(Station_RT)])
>>
>> On Wed, Sep 7, 2016 at 7:09 AM, Stefano Sofia
>> <stefano.sofia at regione.marche.it> wrote:
>>> Dear R users,
>>> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:
>>>
>>> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes Test_20141231 Test_20151231
>>> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
>>> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
>>> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
>>> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>>>
>>> I load it with
>>> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)
>>>
>>> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
>>> [1] "YES"
>>>
>>> while
>>> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
>>> [1] NA   "YES"
>>>
>>>
>>> print(lapply(Storia_RM_RT, class)) gives
>>>
>>> $Station_RM
>>> [1] "integer"
>>>
>>> $Sensor_RM
>>> [1] "integer"
>>>
>>> $Place_RM
>>> [1] "character"
>>>
>>> $Y_init_RM
>>> [1] "integer"
>>>
>>> $M_init_RM
>>> [1] "integer"
>>>
>>> $D_init_RM
>>> [1] "integer"
>>>
>>> $Long_cent_RM
>>> [1] "numeric"
>>>
>>> $Lat_cent_RM
>>> [1] "numeric"
>>>
>>> $Height_RM
>>> [1] "integer"
>>>
>>> $Continues
>>> [1] "character"
>>>
>>> $Station_RT
>>> [1] "integer"
>>>
>>> $Sensor_RT
>>> [1] "integer"
>>>
>>> $Place_RT
>>> [1] "character"
>>>
>>> $Name1_RT
>>> [1] "character"
>>>
>>> $Name2_RT
>>> [1] "character"
>>>
>>> $Long_cent_RT
>>> [1] "numeric"
>>>
>>> $Lat_cent_RT
>>> [1] "numeric"
>>> $Quota_RT
>>> [1] "numeric"
>>>
>>> $Actual_net
>>> [1] "character"
>>>
>>> $Notes
>>> [1] "logical"
>>>
>>> $Test_20141231
>>> [1] "character"
>>>
>>> $Test_20151231
>>> [1] "character"
>>>
>>> I am struggling to understand why the query through the field Station_RT does not work.
>>> Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?
>>>
>>> Thank you
>>> Stefano Sofia
>>>
>>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Sep  7 12:21:17 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Sep 2016 20:21:17 +1000
Subject: [R] Resample with replacement to produce many rarefaction
 curves with same number of samples
In-Reply-To: <CABh5y=7bwOF9dP-M8YK0g2idKophnBqaLdoT=R0qFpNZhh13Og@mail.gmail.com>
References: <CABh5y=7bwOF9dP-M8YK0g2idKophnBqaLdoT=R0qFpNZhh13Og@mail.gmail.com>
Message-ID: <CA+8X3fVd=ErzQ57-pVLF2MXCW7mLr0gLaHana8O7H7-yNpZTxA@mail.gmail.com>

Hi Nick,
This is pretty rough, but it may help:

pdf("rd.pdf")
raredata<-rarecurve(cbind(netdata,netdata,netdata),label=FALSE,
 col=rgb(0,0,1,0.1),xlim=c(0,100),ylim=c(0,80))
rect(100,0,104,80,col="white",border=NA)
dev.off()

Jim

On Wed, Sep 7, 2016 at 8:05 AM, Nick Pardikes <nickpardikes at gmail.com> wrote:
> I am currently having difficulty producing a graph using rarecurve in the
> vegan package. I have produced rarefaction curves (seen below) using the
> following code.
>
>
> library(vegan)
>
> myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
> communities
>
> netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
> species (columns)
>
> raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
> rarecurve to plot a rarefaction for each individual community (n=50)
>
>
> However I would like to produce a graph in which all rarefaction curves end
> at the same sample size. For example, in this graph it would be great to
> extend the x-axis (sample size) to 100 and have all curves end at this
> point. Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).
>
>
> I understand that rarefaction is useful to compare communities with
> different sample efforts, but I would still like to generate the figure. My
> actual data has 5000 simulated communities that differ greatly in matrix
> size and number of samples.
>
>
> Thank you in advance for your help and suggestions.
>
>
> Cheers,
>
> Nick
>
> --
> Nick Pardikes
> PhD Candidate
> Program in Ecology, Evolution, and Conservation Biology
> University of Nevada
> *https://nickpardikes.wordpress.com/ <https://nickpardikes.wordpress.com/>*
> nickpardikes at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rd.pdf
Type: application/pdf
Size: 28579 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160907/13ed22e5/attachment.pdf>

From partners at packtpub.com  Wed Sep  7 13:01:39 2016
From: partners at packtpub.com (Partners)
Date: Wed, 7 Sep 2016 12:01:39 +0100 (BST)
Subject: [R] Books on R
In-Reply-To: <16753597.325.1472635917959.JavaMail.eeshah@PPMUM13CPU0149>
References: <5337879.2380.1444300538539.JavaMail.poonamg@PPMUM13CPU0470>
	<20230882.1364.1465464288292.JavaMail.eeshah@PPMUM13CPU0149>
	<32857435.1227.1466415329912.JavaMail.eeshah@PPMUM13CPU0149>
	<13681797.1921.1467374030187.JavaMail.eeshah@PPMUM13CPU0149>
	<15934776.514.1469780397385.JavaMail.eeshah@PPMUM13CPU0149>
	<13584284.3238.1470737483435.JavaMail.eeshah@PPMUM13CPU0149>
	<16627042.1857.1471592362917.JavaMail.eeshah@PPMUM13CPU0149>
	<16753597.325.1472635917959.JavaMail.eeshah@PPMUM13CPU0149>
Message-ID: <20582430.551.1473246105937.JavaMail.eeshah@PPMUM13CPU0149>

Hi Preetam, 

I was just wondering if you could get back to me regarding the book feature on r-project.org/doc/bib/R-books.html 

Awaiting your reply. 

Thanks & Regards 
Eesha 



Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Wednesday, August 31, 2016 3:02:54 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Just following up on my previous email. 

Awaiting your reply. 

Thanks & Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Friday, August 19, 2016 1:10:24 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Just checking in. 

Awaiting your reply. 

Thanks & Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Tuesday, August 9, 2016 3:42:13 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Just checking in to see if you got a chance to feature the books on the project website. 

And I also want to let you know that we have published a few more books on 'R' this year 
Learning R for Data Visualization 
Learning Probabilistic Graphical Models in R 
RStudio for R Statistical Computing Cookbook 
Mastering Parallel Programming with R 

Should I also add these books to your account for reviewing? 

Looking forward for your reply. 

Thanks & Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Friday, July 29, 2016 1:50:51 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Hope you are doing well. 

I just wanted an update about when would you be uploading the book link on the project website. 

Awaiting your reply. 

Thanks & Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Friday, July 1, 2016 5:22:42 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

I completely understand you must be caught up with many things at work. 
However, I was wondering if you have had a chance to review the books. 

Looking forward to hearing from you. 

Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Monday, June 20, 2016 3:05:23 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

How have you been? I hope you are having a good read. 

I just wanted an update about when would you be uploading the book link on the project website. 

Awaiting your reply. 


Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Thursday, June 9, 2016 2:54:48 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Just following up to see if you got a chance to review the books. 

Awaiting your reply. 

Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Tuesday, May 31, 2016 10:03:03 AM 
Subject: Re: [R] Books on R 


Hi Preetam, 

The following eBooks have been to your account on packtpub.com 

Web Application Development with R Using Shiny Second Edition 
R Machine Learning By Example 
R Deep Learning Essentials 

You can login to your account and select the format you desire to download. 
Please feel free to get in touch with me if you need any further assistance. 


Thanks & Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Monday, May 30, 2016 1:09:51 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Sure, no problem. 

In the meanwhile, we will add the following 3 eBooks to your account on packtpub.com 

Web Application Development with R Using Shiny Second Edition 
R Machine Learning By Example 
R Deep Learning Essentials 

Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Preetam Pal" <lordpreetam at gmail.com> 
To: "Partners" <partners at packtpub.com> 
Sent: Saturday, May 28, 2016 9:46:05 PM 
Subject: RE: [R] Books on R 



I haven't gone throgh many chapters in the e-book.... Ok if I take a couple of weeks for a meaningful review? 
Regards, 
Preetam 

From: Partners 
Sent: ?27-?05-?2016 04:15 PM 
To: Preetam Pal 
Subject: Re: [R] Books on R 


Hi Preetam, 

I was wondering if you got a chance to read my previous email. 

Awaiting your reply. 

Regards 
Eesha 




Eesha Harish 
Key Partner Executive 




----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Friday, May 20, 2016 8:51:05 AM 
Subject: Re: [R] Books on R 


Hi Preetam, 

Just following up to see if you've received my previous email regarding the book feature. 
Do write back to me as soon as you can. 

Looking forward to hearing from you. 


Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 





----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Tuesday, May 17, 2016 2:11:36 PM 
Subject: Re: [R] Books on R 


Hi Preetam, 

My name is Eesha Harish and I've recently joined Packt Publishing. My colleague Poonam was was in contact with you regarding featuring our books on r-project.org 

We have published 3 new titles on 'R'. We would appreciate if you could feature these book on the website as you have done for us in the past. 

Web Application Development with R Using Shiny Second Edition 
R Machine Learning By Example 
R Deep Learning Essentials 

I would be happy to provide you with eBook copies of the same for review. 
Do let me know if you need any further information. 


Thanks & Regards 
Eesha 





Eesha Harish 
Key Partner Executive 





----- Original Message -----

From: "Partners" <partners at packtpub.com> 
To: "Preetam Pal" <lordpreetam at gmail.com> 
Sent: Wednesday, November 4, 2015 11:38:45 AM 
Subject: Re: [R] Books on R 


Hi Preetam, 

How did you like the book? 
By when can I see the book up on the website? 

Awaiting your reply. 

Regards, 



Poonam Gupta 
Online Marketing Executive 



----- Original Message -----

From: "Preetam Pal" <lordpreetam at gmail.com> 
To: "Partners" <partners at packtpub.com> 
Sent: Friday, October 9, 2015 8:41:20 PM 
Subject: RE: [R] Books on R 



Can u plz send md the e book? 
Thanks, 
Preetam 


From: Partners 
Sent: ?09-?10-?2015 05:41 PM 
To: Preetam Pal 
Subject: Re: [R] Books on R 


Hi Preetam, 

These are the topics covered in Mastering R for Quantitative Finance (https://www.packtpub.com/big-data-and-business-intelligence/mastering-r-quantitative-finance): 
1: TIME SERIES ANALYSIS 
2: FACTOR MODELS 
3: FORECASTING VOLUME 
4: BIG DATA ? ADVANCED ANALYTICS 
5: FX DERIVATIVES 
6: INTEREST RATE DERIVATIVES AND MODELS 
7: EXOTIC OPTIONS 
8: OPTIMAL HEDGING 
9: FUNDAMENTAL ANALYSIS 
10: TECHNICAL ANALYSIS, NEURAL NETWORKS, AND LOGOPTIMAL PORTFOLIOS 
11: ASSET AND LIABILITY MANAGEMENT 
12: CAPITAL ADEQUACY 
13: SYSTEMIC RISKS 

I have provide you with the book link and you can read an overview of the book if you'd like. 
Or we can send e-books for you to see. 

Let me know if you need any information about the books. 

Regards, 



Poonam Gupta 
Online Marketing Executive 



----- Original Message -----

From: "Preetam Pal" <lordpreetam at gmail.com> 
To: "Partners" <partners at packtpub.com> 
Sent: Thursday, October 8, 2015 11:55:37 PM 
Subject: RE: [R] Books on R 



Hi, 
What are the topics covered in quantitative finance, the first book you mentioned? 
Regards, 
Preetam 

From: Partners 
Sent: ?08-?10-?2015 07:44 PM 
To: r-help at r-project.org 
Subject: [R] Books on R 

Hi, 

My name is Poonam and I work with Packt Publishing. 

I would like to inform you that we have published the following books on R recently: 
Mastering R for Quantitative Finance 
Machine learning with R Cookbook 
R Data Analysis Cookbook 
R High Performance Programming 
R Data Visualization Cookbook 
Learning Data mining with R 
Mastering Scientific Computing with R 
Data Manipulation with R - Second Edition 

It would be great if we could feature these books under the 'documentation' section of the website ( https://www.r-project.org/doc/bib/R-books.html ) 

Also, we will be glad to send you review copies of these books if you need. 
Please do let me know if you need any further information about these books. 

Best regards, 



Poonam Gupta 
Online Marketing Executive 



______________________________________________ 
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 



[image/png:Packt Logo.png] 













From istazahn at gmail.com  Wed Sep  7 15:30:22 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Sep 2016 09:30:22 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
Message-ID: <CA+vqiLFUivwj_GBO1SUnqgCb8V7n1Q1sunE0eu_iza-2tdyzXA@mail.gmail.com>

On Mon, Sep 5, 2016 at 12:56 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Thanks for the reply, Bert.
>
> Your solution solves the example. I actually have a more general situation
> where I have this dot concatenated string from multiple variables. The
> problem is those variables may have values with dots in there.

If you concatenated the variables yourself you could go back a step
and use another separator, i.e., one that doesn't appear in the
original variables. The separator does not need to be a single
character, e.g., "__.__" would be fine. This will make later parsing
with regular expressions much easier.

The number
> of dots are not consistent for all values of a variable. So I am thinking
> to define a vector of patterns for the vector of the string and hopefully
> to find a way to use a pattern from the pattern vector for each value of
> the string vector. The only way I can think of is "for" loop, which can be
> slow. Also these are happening in a function I am writing. Just wonder if
> there is another more efficient way. Thanks a lot.
>
> Jun
>
> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Well, he did provide an example, and...
>>
>>
>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>
>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> [1] "WT.CUT" "tx"
>>
>>
>> ## seems to do what was requested.
>>
>> Jeff would have to amplify on his initial statement however: do you
>> mean that separate patterns can always be combined via "|" ?  Or
>> something deeper?
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> > Your opening assertion is false.
>> >
>> > Provide a reproducible example and someone will demonstrate.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen <jun.shen.ut at gmail.com>
>> wrote:
>> >>Dear list,
>> >>
>> >>I have a vector of strings that cannot be described by one pattern. So
>> >>let's say I construct a vector of patterns in the same length as the
>> >>vector
>> >>of strings, can I do the element wise pattern recognition and string
>> >>substitution.
>> >>
>> >>For example,
>> >>
>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >>
>> >>patterns <- c(pattern1,pattern2)
>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>
>> >>Say I want to extract "WT.CUT" from the first string and "tx" from the
>> >>second string. If I do
>> >>
>> >>sub(patterns, '\\2', strings), only the first pattern will be used.
>> >>
>> >>looping the patterns doesn't work the way I want. Appreciate any
>> >>comments.
>> >>Thanks.
>> >>
>> >>Jun
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erikareb at gmail.com  Wed Sep  7 16:45:40 2016
From: erikareb at gmail.com (=?UTF-8?Q?Erika_Roc=C3=ADo_Espinosa_Balbuena?=)
Date: Wed, 7 Sep 2016 09:45:40 -0500
Subject: [R] Help with a code in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503BD49@SRVEXCHMBX.precheza.cz>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>
	<CAJMJkRJ810YLdivjief5Xrh1K=5VAfkkVdvhuzgAb_B7wHpGfA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503BD49@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJMJkRJ3wipkCK+RitTCTW+Z6jQsrE93uR9fXQpmr5TJUwkB1g@mail.gmail.com>

Hi,

Sorry, how can I review on line, but here is the complete code:


##Librerias
library(stats)
library(base)
library(dplyr)
library(timeDate)
library(zoo)
library(forecast)
#library(parallel)
library(foreach)
library(iterators)
#library(doParallel)
#library(snow)
#library(doSNOW)
library(reshape2)
library(pryr)
#library(rpivotTable)


#numCores <- detectCores()
#cl <- makeCluster(numCores)



###NACIONAL###
#setwd("C:/RealMetrics/02_Aplicaciones/RM_SCM_DRM/RTools/Erika_Test")

#write.csv(out, file="C:/Users/ErikaRoc?o/Documents/Curso R/nuevos.csv")
#rpivotTable(forecast_nal,rows="Familia","Submarca","prod_id",col="s",
aggregatorName="sum",vals="Point.Forecast")

##Lectura de datos
#datos<-read.csv("FCST_YEAR_WEEK_PROD_NAC.csv")
datos<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso
R/FCST_YEAR_WEEK_PROD_NAC.csv")
b<-data.frame(datos)

calendar<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_sem.csv")
forecast_date<-calendar[,c(8,9,14,10)]

espejo<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_prod.csv")

##Subbases
#Combinaciones
comb<-b[,c(3,4,5)]
comb<-comb %>% distinct
g<-seq(1,nrow(comb),by=1)
dates <- attr(fca$mean, "tsp")
datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
fct<-cbind.data.frame(s,datecol,Point=fca$mean)
forecast_nal<- rbind.data.frame(forecast_nal,fct)
}
else
{

fit <- tbats(y)
fcb <- forecast(fit, h = 16)
dates <- attr(fcb$mean, "tsp")
datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
            forecast_nal<- rbind.data.frame(forecast_nal,fct)
}
}
}


2016-09-07 9:00 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
>
>
> see in line
>
>
>
> *From:* Erika Roc?o Espinosa Balbuena [mailto:erikareb at gmail.com]
> *Sent:* Tuesday, September 6, 2016 10:52 PM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Help with a code in R
>
>
>
> Hi Erika
>
>
>
> Yes the objetcs have the same structure, and forecast_nal is the variable
> where I a trying to keep all the results of the forecast but I get the
> error that it
>
>
>
> How did you check? Can you prove it?
>
>
>
> There is nobody who can check your code, only you. We get this error
>
>
>
> Error in nrow(comb) : object 'comb' not found
>
>
>
> Cheers
>
> Petr
>
>
>
> BTW, plain text posting is preferable.
>
>
>
>
>
> is only allowed the replacement.
>
>
>
> 2016-09-06 1:31 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
> Hi
>
> Well, it seems to me that it is coded in different language like C++.
> The code is not reproducible but the error seems to be from your call of ts
>
> You can check it line by line with setting i to arbitrary value and
> inspect how your objects look like, however some of your constructions
> seems to me quite weird.
>
> e.g.
> forecast_nal<-data.frame()
>
> leads to mempty data frame with no column named mean
> > forecast_nal
> data frame with 0 columns and 0 rows
> > forecast_nal$mean
> NULL
>
> and I am rather surprised how this column come into existence.
>
> BTW, are you sure that in each cycle your rbinded or cbinded objects have
> the same size?
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erika
> Roc?o
> > Espinosa Balbuena
> > Sent: Monday, September 5, 2016 8:26 PM
> > To: r-help at r-project.org
> > Subject: [R] Help with a code in R
> >
> > Hi,
> >
> > I am working with this code:
> >
> > forecast_nal<-data.frame()
> > out<-vector()
> > x<-foreach(i=1:nrow(comb)) %do%
> > {
> >
> > s<-comb[i,'prod_id']
> >
> > #Familia+Sumbarca+prod_id
> > #Serie
> >
> > bcomb1<-b
> > bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
> > bcomb1<-arrange(bcomb1,year,week)
> > a<-bcomb1[1:1,'week']
> > d<-bcomb1[1:1,'year']
> > f<-nrow(bcomb1)
> > h<-bcomb1[f:f,'year']
> > j<-bcomb1[f:f,'week']
> > bcomb1<-bcomb1[,c(6)]
> >
> > if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48)) { out[i]<-s
> }
> > else {
> >        y <- ts(bcomb1, frequency=52, start=c(d, a)) ##Casos
> >
> > if (length(y)<=60)
> > {
> >
> > v<-auto.arima(y)
> > v<-arimaorder(v)
> > fit <- arima(y, order = v ,method="ML")
> >       fca <- forecast(fit, h = 16)
> > dates <- attr(forecast_nal$mean, "tsp")
> > datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> > fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> > forecast_nal<- rbind.data.frame(forecast_nal,fct)
> > }
> > else
> > {
> >
> > fit <- tbats(y)
> > fcb <- forecast(fit, h = 16)
> > dates <- attr(forecast_nal$mean, "tsp")
> > datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> > fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
> >             forecast_nal<- rbind.data.frame(forecast_nal,fct)
> > }
> > }
> > }
> >  But I am getting this error:
> >
> > Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833,
> 26750.9374514082,
> >  :
> >   only replacement of elements is allowed
> >
> > Can someone help me with this?
> >
> > Thanks
> >
> >
> > --
> > Erika Roc?o Espinosa Balbuena
> >
>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
>
>
> --
>
> Erika Roc?o Espinosa Balbuena
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Erika Roc?o Espinosa Balbuena

	[[alternative HTML version deleted]]


From luisfo89 at yahoo.es  Wed Sep  7 17:17:27 2016
From: luisfo89 at yahoo.es (Luisfo)
Date: Wed, 7 Sep 2016 17:17:27 +0200
Subject: [R] Resample with replacement to produce many rarefaction
 curves with same number of samples
In-Reply-To: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
Message-ID: <3438d607-86fc-75ca-ffc3-a8d12939e5a7@yahoo.es>

Hi Nick,

If you use the following
     raredata <- rarecurve(rrarefy(netdata, sample=100), label=F, 
col=rgb(0, 0, 1, 0.1))
should work for any sample size, e.g. sample=100.
However, you will have a 'warning' if you don't have samples enough, 
because it has not replacement.

If you type 'rrarefy' on the R console (without brackets), or any other 
function name, you will see the R code of the function.
rrarefy uses the function 'sample()' for sampling, but has no option for 
replacement.
I did the following. I created my custom rrarefy function from the original.
rrarefy.custom <- function (x, sample, rep.param=F)
{
   if (!identical(all.equal(x, round(x)), TRUE))
     stop("function is meaningful only for integers (counts)")
   x <- as.matrix(x)
   if (ncol(x) == 1)
     x <- t(x)
   if (length(sample) > 1 && length(sample) != nrow(x))
     stop(gettextf("length of 'sample' and number of rows of 'x' do not 
match"))
   sample <- rep(sample, length = nrow(x))
   colnames(x) <- colnames(x, do.NULL = FALSE)
   nm <- colnames(x)
   if (!rep.param && any(rowSums(x) < sample))
     warning("Some row sums < 'sample' and are not rarefied")
   for (i in 1:nrow(x)) {
     if (rep.param && sum(x[i, ]) <= sample[i])
       next
     row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
     row <- table(row)
     ind <- names(row)
     x[i, ] <- 0
     x[i, ind] <- row
   }
   x
}
You can check the differences with the original code if you type 
'rrarefy' on the R console.

So now, if you type the following
     raredata <- rarecurve(rrarefy.custom(netdata, 
sample=100,rep.param=T), label=F, col=rgb(0, 0, 1, 0.1))
you will have the desired behaviour.

WARNING: I do not understand about rarefunction curves or communities in 
your context. So, be careful when resampling. It might not be 
statistically correct.

Regards,
*Luisfo Chiroque*
/PhD Student | PhD Candidate
IMDEA Networks Institute/
http://fourier.networks.imdea.org/people/~luis_nunez/ 
<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>

On 09/07/2016 12:07 AM, Nick Pardikes wrote:
> I am currently having difficulty producing a graph using rarecurve in the
> vegan package. I have produced rarefaction curves (seen below) using the
> following code.
>
>
> library(vegan)
>
> myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
> communities
>
> netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
> species (columns)
>
> raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
> rarecurve to plot a rarefaction for each individual community (n=50)
>
>
> However I would like to produce a graph in which all rarefaction curves end
> at the same sample size. For example, in this graph it would be great to
> extend the x-axis (sample size) to 100 and have all curves end at this
> point. Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).
>
>
> I understand that rarefaction is useful to compare communities with
> different sample efforts, but I would still like to generate the figure. My
> actual data has 5000 simulated communities that differ greatly in matrix
> size and number of samples.
>
>
> Thank you in advance for your help and suggestions.
>
>
> Cheers,
>
> Nick
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From HDoran at air.org  Wed Sep  7 17:35:42 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 7 Sep 2016 15:35:42 +0000
Subject: [R] R-specific Software Requirement Specification
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>

I'm building a large program with many different people contributing to the coding in R and so it needs a well-articulated design spec. The program will have many different functions that must interact with each other, but the individual functions will be written by different people.

I'm curious if anyone has an R-specific SRS document to share that they have used for a similar purpose listing the objectives for each function, class definition, generics, what the function inherits from, and so on, or perhaps even a useful template for such work.

Thank you in advance.

Harold




	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Wed Sep  7 17:53:51 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 7 Sep 2016 15:53:51 +0000
Subject: [R] Help with a code in R
In-Reply-To: <CAJMJkRJ3wipkCK+RitTCTW+Z6jQsrE93uR9fXQpmr5TJUwkB1g@mail.gmail.com>
References: <CAJMJkRK_TRaEe8nXdrqNoTGKMvh0_1Pgf6UBDo78n6ER55RvMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503B9D8@SRVEXCHMBX.precheza.cz>
	<CAJMJkRJ810YLdivjief5Xrh1K=5VAfkkVdvhuzgAb_B7wHpGfA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503BD49@SRVEXCHMBX.precheza.cz>
	<CAJMJkRJ3wipkCK+RitTCTW+Z6jQsrE93uR9fXQpmr5TJUwkB1g@mail.gmail.com>
Message-ID: <20D9830F-2EB2-4BD2-91F8-53BDCB38A6BE@TxBiomed.org>

Erika,

The code you sent is missing some matching braces. For example, see this pair of lines:

forecast_nal <- rbind.data.frame(forecast_nal, fct)
}

I do not see a left brace anywhere before this right brace.



Without the content of the data structures datos, calendar and espejo from the three files, we will not be able to reproduce your code. Often you can use only a small subset of the data and reproduce a problem, but only you will be able to find out how much of the data are sufficient to reproduce the problem.

You could start by trying to produce the problem with a minimum amount of data. Try something along these lines:

datos <- read.csv("C:/Users/ErikaRoc?o/Documents/Curso
                  R/FCST_YEAR_WEEK_PROD_NAC.csv")
b <- data.frame(datos)[1:10, ]

calendar <-
  read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_sem.csv")
forecast_date <- calendar[1:10, c(8, 9, 14, 10)]

espejo <-
  read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_prod.csv")[1:10, ]

Then use these short versions of the dataframes in the rest of your code and see if you get the same error. You will likely have to play with the number of rows in each dataframe to fine the smallest number that will work. When you discover the smallest dataframes that recreate the error, you can send us the output from dput() as shown below:


datos <- read.csv("C:/Users/ErikaRoc?o/Documents/Curso
                  R/FCST_YEAR_WEEK_PROD_NAC.csv")
b <- data.frame(datos)
dput(b[1:10, ])

calendar <-
  read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_sem.csv")
forecast_date <- calendar[, c(8, 9, 14, 10)]
dput(forecast_date[1:10, ])

espejo <-
  read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_prod.csv")
dput(espejo[1:10, ])






R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Sep 7, 2016, at 9:45 AM, Erika Roc?o Espinosa Balbuena <erikareb at gmail.com> wrote:
>
> Hi,
>
> Sorry, how can I review on line, but here is the complete code:
>
>
> ##Librerias
> library(stats)
> library(base)
> library(dplyr)
> library(timeDate)
> library(zoo)
> library(forecast)
> #library(parallel)
> library(foreach)
> library(iterators)
> #library(doParallel)
> #library(snow)
> #library(doSNOW)
> library(reshape2)
> library(pryr)
> #library(rpivotTable)
>
>
> #numCores <- detectCores()
> #cl <- makeCluster(numCores)
>
>
>
> ###NACIONAL###
> #setwd("C:/RealMetrics/02_Aplicaciones/RM_SCM_DRM/RTools/Erika_Test")
>
> #write.csv(out, file="C:/Users/ErikaRoc?o/Documents/Curso R/nuevos.csv")
> #rpivotTable(forecast_nal,rows="Familia","Submarca","prod_id",col="s",
> aggregatorName="sum",vals="Point.Forecast")
>
> ##Lectura de datos
> #datos<-read.csv("FCST_YEAR_WEEK_PROD_NAC.csv")
> datos<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso
> R/FCST_YEAR_WEEK_PROD_NAC.csv")
> b<-data.frame(datos)
>
> calendar<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_sem.csv")
> forecast_date<-calendar[,c(8,9,14,10)]
>
> espejo<-read.csv("C:/Users/ErikaRoc?o/Documents/Curso R/cat_prod.csv")
>
> ##Subbases
> #Combinaciones
> comb<-b[,c(3,4,5)]
> comb<-comb %>% distinct
> g<-seq(1,nrow(comb),by=1)
> dates <- attr(fca$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
> forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> else
> {
>
> fit <- tbats(y)
> fcb <- forecast(fit, h = 16)
> dates <- attr(fcb$mean, "tsp")
> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>            forecast_nal<- rbind.data.frame(forecast_nal,fct)
> }
> }
> }
>
>
> 2016-09-07 9:00 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
>> Hi
>>
>>
>>
>> see in line
>>
>>
>>
>> *From:* Erika Roc?o Espinosa Balbuena [mailto:erikareb at gmail.com]
>> *Sent:* Tuesday, September 6, 2016 10:52 PM
>> *To:* PIKAL Petr <petr.pikal at precheza.cz>
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] Help with a code in R
>>
>>
>>
>> Hi Erika
>>
>>
>>
>> Yes the objetcs have the same structure, and forecast_nal is the variable
>> where I a trying to keep all the results of the forecast but I get the
>> error that it
>>
>>
>>
>> How did you check? Can you prove it?
>>
>>
>>
>> There is nobody who can check your code, only you. We get this error
>>
>>
>>
>> Error in nrow(comb) : object 'comb' not found
>>
>>
>>
>> Cheers
>>
>> Petr
>>
>>
>>
>> BTW, plain text posting is preferable.
>>
>>
>>
>>
>>
>> is only allowed the replacement.
>>
>>
>>
>> 2016-09-06 1:31 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>
>> Hi
>>
>> Well, it seems to me that it is coded in different language like C++.
>> The code is not reproducible but the error seems to be from your call of ts
>>
>> You can check it line by line with setting i to arbitrary value and
>> inspect how your objects look like, however some of your constructions
>> seems to me quite weird.
>>
>> e.g.
>> forecast_nal<-data.frame()
>>
>> leads to mempty data frame with no column named mean
>>> forecast_nal
>> data frame with 0 columns and 0 rows
>>> forecast_nal$mean
>> NULL
>>
>> and I am rather surprised how this column come into existence.
>>
>> BTW, are you sure that in each cycle your rbinded or cbinded objects have
>> the same size?
>>
>> Cheers
>> Petr
>>
>>
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erika
>> Roc?o
>>> Espinosa Balbuena
>>> Sent: Monday, September 5, 2016 8:26 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Help with a code in R
>>>
>>> Hi,
>>>
>>> I am working with this code:
>>>
>>> forecast_nal<-data.frame()
>>> out<-vector()
>>> x<-foreach(i=1:nrow(comb)) %do%
>>> {
>>>
>>> s<-comb[i,'prod_id']
>>>
>>> #Familia+Sumbarca+prod_id
>>> #Serie
>>>
>>> bcomb1<-b
>>> bcomb1<-subset(bcomb1,bcomb1$prod_id == s & bcomb1$year <= 2015)
>>> bcomb1<-arrange(bcomb1,year,week)
>>> a<-bcomb1[1:1,'week']
>>> d<-bcomb1[1:1,'year']
>>> f<-nrow(bcomb1)
>>> h<-bcomb1[f:f,'year']
>>> j<-bcomb1[f:f,'week']
>>> bcomb1<-bcomb1[,c(6)]
>>>
>>> if (length(bcomb1)<=10 || h=="2014" || (h=="2015" && j<=48)) { out[i]<-s
>> }
>>> else {
>>>       y <- ts(bcomb1, frequency=52, start=c(d, a)) ##Casos
>>>
>>> if (length(y)<=60)
>>> {
>>>
>>> v<-auto.arima(y)
>>> v<-arimaorder(v)
>>> fit <- arima(y, order = v ,method="ML")
>>>      fca <- forecast(fit, h = 16)
>>> dates <- attr(forecast_nal$mean, "tsp")
>>> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
>>> fct<-cbind.data.frame(s,datecol,Point=fca$mean)
>>> forecast_nal<- rbind.data.frame(forecast_nal,fct)
>>> }
>>> else
>>> {
>>>
>>> fit <- tbats(y)
>>> fcb <- forecast(fit, h = 16)
>>> dates <- attr(forecast_nal$mean, "tsp")
>>> datecol <- seq(from=dates[1], to=dates[2], by=1/dates[3])
>>> fct<-cbind.data.frame(s,datecol,Point=fcb$mean)
>>>            forecast_nal<- rbind.data.frame(forecast_nal,fct)
>>> }
>>> }
>>> }
>>> But I am getting this error:
>>>
>>> Error in `[<-.ts`(`*tmp*`, ri, value = c(26656.136365833,
>> 26750.9374514082,
>>> :
>>>  only replacement of elements is allowed
>>>
>>> Can someone help me with this?
>>>
>>> Thanks
>>>
>>>
>>> --
>>> Erika Roc?o Espinosa Balbuena
>>>
>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>>
>>
>>
>>
>> --
>>
>> Erika Roc?o Espinosa Balbuena
>>
>> ------------------------------
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
>
>
> --
> Erika Roc?o Espinosa Balbuena
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From rshepard at appl-ecosys.com  Wed Sep  7 17:56:15 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 7 Sep 2016 08:56:15 -0700 (PDT)
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
Message-ID: <alpine.LNX.2.11.1609070854050.18384@localhost>

On Wed, 7 Sep 2016, Doran, Harold wrote:

> I'm building a large program with many different people contributing to
> the coding in R and so it needs a well-articulated design spec. The
> program will have many different functions that must interact with each
> other, but the individual functions will be written by different people.

Harold,

   You need a version control system; I strongly recommend git
<https://git-scm.com/>.

Rich


From HDoran at air.org  Wed Sep  7 18:07:50 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 7 Sep 2016 16:07:50 +0000
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <alpine.LNX.2.11.1609070854050.18384@localhost>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<alpine.LNX.2.11.1609070854050.18384@localhost>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817D51@DC1VEX10MB01.air.org>

I use Mercurial for this. 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Wednesday, September 07, 2016 11:56 AM
To: r-help at r-project.org
Subject: Re: [R] R-specific Software Requirement Specification

On Wed, 7 Sep 2016, Doran, Harold wrote:

> I'm building a large program with many different people contributing 
> to the coding in R and so it needs a well-articulated design spec. The 
> program will have many different functions that must interact with 
> each other, but the individual functions will be written by different people.

Harold,

   You need a version control system; I strongly recommend git <https://git-scm.com/>.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Sep  7 18:12:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Sep 2016 09:12:53 -0700
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <alpine.LNX.2.11.1609070854050.18384@localhost>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<alpine.LNX.2.11.1609070854050.18384@localhost>
Message-ID: <CAGxFJbRdk8D=VeXD8iiGNYywD+z2qOqFnV=y5qQSsPB+P4A7-A@mail.gmail.com>

Yes! ...

and you might consider writing your specifications along with example
R code using rmarkdown. The Rstudio GUI has a nice interface and
support tools (e.g. for compiling and previewing the doc) for writing
rmarkdown, but you can also load and use the package through whatever
R interface you prefer.  Rstudio  also has good support for git:
https://jennybc.github.io/2014-05-12-ubc/ubc-r/session03_git.html


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 7, 2016 at 8:56 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Wed, 7 Sep 2016, Doran, Harold wrote:
>
>> I'm building a large program with many different people contributing to
>> the coding in R and so it needs a well-articulated design spec. The
>> program will have many different functions that must interact with each
>> other, but the individual functions will be written by different people.
>
>
> Harold,
>
>   You need a version control system; I strongly recommend git
> <https://git-scm.com/>.
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Sep  7 18:46:13 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 7 Sep 2016 12:46:13 -0400
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
Message-ID: <ed125138-40db-bf6f-f227-088b64d60568@gmail.com>

On 07/09/2016 11:35 AM, Doran, Harold wrote:
> I'm building a large program with many different people contributing to the coding in R and so it needs a well-articulated design spec. The program will have many different functions that must interact with each other, but the individual functions will be written by different people.
>
> I'm curious if anyone has an R-specific SRS document to share that they have used for a similar purpose listing the objectives for each function, class definition, generics, what the function inherits from, and so on, or perhaps even a useful template for such work.

The Rd help pages do some of this.  They aren't so good at describing 
the class hierarchy but are good at specifying individual functions.

Duncan Murdoch


From HDoran at air.org  Wed Sep  7 19:06:38 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 7 Sep 2016 17:06:38 +0000
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817E97@DC1VEX10MB01.air.org>

This is in fact a *very* good suggestion, Duncan. One could easily rewrite any existing R function by looking at the help page I believe. So, I could in fact begin by writing the help page which we know details the function inputs, details about each argument, what the function is expected to output etc. 

I suppose it is easy enough to add an "inherits from" or outputs an object of class "xyz" to this for my purpose.

 

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, September 07, 2016 12:46 PM
To: Doran, Harold <HDoran at air.org>; r-help at r-project.org
Subject: Re: [R] R-specific Software Requirement Specification

On 07/09/2016 11:35 AM, Doran, Harold wrote:
> I'm building a large program with many different people contributing to the coding in R and so it needs a well-articulated design spec. The program will have many different functions that must interact with each other, but the individual functions will be written by different people.
>
> I'm curious if anyone has an R-specific SRS document to share that they have used for a similar purpose listing the objectives for each function, class definition, generics, what the function inherits from, and so on, or perhaps even a useful template for such work.

The Rd help pages do some of this.  They aren't so good at describing the class hierarchy but are good at specifying individual functions.

Duncan Murdoch


From economatistica at yahoo.com.br  Wed Sep  7 20:41:58 2016
From: economatistica at yahoo.com.br (Edimeire Alexandra Pinto)
Date: Wed, 7 Sep 2016 18:41:58 +0000 (UTC)
Subject: [R] Dynamic forecast
References: <1494144236.501577.1473273718126.ref@mail.yahoo.com>
Message-ID: <1494144236.501577.1473273718126@mail.yahoo.com>


Good afternoon.
We have two typesof forecast using time series:?statistical forecast and dynamic forecast. I would like to make dynamic forecastsimilar to what uses Eviews software.


Does anyone know any package in R? Please.....

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep  7 22:53:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Sep 2016 13:53:12 -0700
Subject: [R] fPortfolio dont work in R 3.3.1
In-Reply-To: <8586FCA42D306C4DB0BD46EF9F1B58025B017148@MBX110.d.ethz.ch>
References: <BY2PR10MB0598B9454355A674D9F52066FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
	<8586FCA42D306C4DB0BD46EF9F1B58025B017148@MBX110.d.ethz.ch>
Message-ID: <C1DC3965-8F3C-46DE-8D81-7C80C9E04E80@comcast.net>


> On Sep 7, 2016, at 12:57 AM, Bannert Matthias <bannert at kof.ethz.ch> wrote:
> 
> Andre, 
> 
> you need to make sure you got a C/C++ compiler as well as a Fortran compiler to compile a package from source that makes use of these language. Many R packages use one of those languages under the hood to speed things up. 
> 
> gcc / gfortran are common and free choices for such compilers. Depending on your OS, these ship with your OS' installation. What OS do you have? 
> 
> Also, i'd try to install RSymphony first and then install fPortfolio.

Rsymphony is an interface to an external program named Symphony. Installation of SYMPHONY is required prior to installation of Rsymphony:

https://projects.coin-or.org/SYMPHONY


-- 
David

> 
> HTH, 
> 
> matt
> 
> Hi,
> 
> 
> I'm trying use the package fPortfolio in R version 3.3.1. But the package don't work. I recieve the messages below:
> 
> 
> Package which is only available in source form, and may need
>  compilation of C/C++/Fortran: 'Rsymphony'
>  These will not be installed
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>  there is no package called 'Rsymphony'
> Erro: package or namespace load failed for 'fPortfolio'
> 
> How I can use fPortfolio in R 3.3.1?
> 
> 
> Thanks in advance,
> 
> 
> Andr? Barbosa Oliveira.
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Sep  8 00:45:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Sep 2016 15:45:44 -0700
Subject: [R] fPortfolio dont work in R 3.3.1
In-Reply-To: <BY2PR10MB05989AF0F99C4216146A0CB1FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
References: <BY2PR10MB0598B9454355A674D9F52066FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
	<8586FCA42D306C4DB0BD46EF9F1B58025B017148@MBX110.d.ethz.ch>
	<C1DC3965-8F3C-46DE-8D81-7C80C9E04E80@comcast.net>
	<BY2PR10MB05989AF0F99C4216146A0CB1FCF80@BY2PR10MB0598.namprd10.prod.outlook.com>
Message-ID: <D4DEC8FF-AA41-4DBF-B739-5C5F1B340744@comcast.net>


> On Sep 7, 2016, at 2:35 PM, Andre Barbosa Oliveira <andre.boliveira at hotmail.com> wrote:
> 
> David,
> 
> I think the problem isn't the operacional system. I use the package fPortfolio without problems in R 3.2.3. But when I try use fPortfolio, in the same computer, but on R3.3.1 it don't work. 

I don't think you are reading my message carefully. You need a) SYMPHONY in order to b) install Rsymphony in order to c) install fPortfolio. Please do not correspond to only me. Rhelp has an expectation that copies will be sent to the list.
> 

> My OS is Windows 7.

Perhaps someone on the list with that OS (not mine) can tell you how to determine if SYMPHONY is installed on your machine. Sometimes there are environment variables needed to be set at the system level. I earlier gave you a link to the source, but sometimes that is not enough.

-- 
David.
> 
> Andre
> 
> De: David Winsemius <dwinsemius at comcast.net>
> Enviado: quarta-feira, 7 de setembro de 2016 17:53:12
> Para: Bannert Matthias
> Cc: Andre Barbosa Oliveira; mailman, r-help
> Assunto: Re: [R] fPortfolio dont work in R 3.3.1
>  
> 
> > On Sep 7, 2016, at 12:57 AM, Bannert Matthias <bannert at kof.ethz.ch> wrote:
> > 
> > Andre, 
> > 
> > you need to make sure you got a C/C++ compiler as well as a Fortran compiler to compile a package from source that makes use of these language. Many R packages use one of those languages under the hood to speed things up. 
> > 
> > gcc / gfortran are common and free choices for such compilers. Depending on your OS, these ship with your OS' installation. What OS do you have? 
> > 
> > Also, i'd try to install RSymphony first and then install fPortfolio.
> 
> Rsymphony is an interface to an external program named Symphony. Installation of SYMPHONY is required prior to installation of Rsymphony:
> 
> https://projects.coin-or.org/SYMPHONY
> 
> 
> -- 
> David
> 
> > 
> > HTH, 
> > 
> > matt
> > 
> > Hi,
> > 
> > 
> > I'm trying use the package fPortfolio in R version 3.3.1. But the package don't work. I recieve the messages below:
> > 
> > 
> > Package which is only available in source form, and may need
> >  compilation of C/C++/Fortran: 'Rsymphony'
> >  These will not be installed
> > 
> > Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
> >  there is no package called 'Rsymphony'
> > Erro: package or namespace load failed for 'fPortfolio'
> > 
> > How I can use fPortfolio in R 3.3.1?
> > 
> > 
> > Thanks in advance,
> > 
> > 
> > Andr? Barbosa Oliveira.
> > 
> > 
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From josh.m.ulrich at gmail.com  Thu Sep  8 01:56:54 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 7 Sep 2016 18:56:54 -0500
Subject: [R] how to transform db query result into a set of timeseries ?
In-Reply-To: <931bc534-a894-5327-7e6e-b8e4ffe685b3@gmail.com>
References: <931bc534-a894-5327-7e6e-b8e4ffe685b3@gmail.com>
Message-ID: <CAPPM_gSdMu6OnnXdG4Fcact9+JQzC+nDtWh9N3CfLdXjNr=SBg@mail.gmail.com>

There's no reason to create multiple xts objects if you intend to
merge them all into one object.  You say the user can select
timeseries, so I assume you have column names in a vector.  If so, you
can do something like this:

series <- c("M", "G", "N")
...
zonnen <- xts(df[,series], as.POSIXct(df$Date))
dygraph(zonnen)

On Mon, Sep 5, 2016 at 3:28 PM, Stef Mientki <stef.mientki at gmail.com> wrote:
> hello,
>
> I've a number of timeseries into a database and want to display these
> timeseries into graph.
>
> Now the code below works well, but as the user can select which timeseries
> should be shown (up to 20 timeseries) the code below should be dynamic and
> can be quiet large and complex.
>
> Is there an easier way to convert a database result into timeseries accepted
> by dygraph ?
>
>     SQL <- "select Date, M, G, N from Compare_Model"
>     df <- dbGetQuery ( con, statement = SQL )
>
>     zon1 <- xts ( df$M,  as.POSIXct ( df$Date, format="%Y-%m-%d %H:%M:%S") )
>     zon2 <- xts ( df$G,  as.POSIXct ( df$Date, format="%Y-%m-%d %H:%M:%S") )
>     zon3 <- xts ( df$N,  as.POSIXct ( df$Date, format="%Y-%m-%d %H:%M:%S") )
>
>     zonnen <- Reduce ( function(...) merge(..., all=TRUE ), list ( zon,
> zon2, zon3 ))
>
>     dygraph ( zonnen )
>
>
> thanks,
>
> Stef
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From getchinmay at gmail.com  Thu Sep  8 07:45:39 2016
From: getchinmay at gmail.com (Chinmay Borwankar)
Date: Thu, 8 Sep 2016 08:45:39 +0300
Subject: [R] building R from source on gnu version >=5.4
In-Reply-To: <D1EFE2AE-2E9F-4622-98D5-CE52A24581C7@dcn.davis.ca.us>
References: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>
	<D1EFE2AE-2E9F-4622-98D5-CE52A24581C7@dcn.davis.ca.us>
Message-ID: <CA+AH4+M8W=STkjFBhb=LKH+km9s+CbJBwKgYy_LvEij9h0LHkw@mail.gmail.com>

I believe building the source is not really "R-devel question" since I am
not really
developing anything for R. On the other hand, many people may want to build
the
R-code with their specific installation requirements.
Anyways, if it was wrong place I will post it at right place.


On 7 September 2016 at 16:23, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Many things are possible, especially if you read the Posting Guide which
> tells you you that questions involving compiling R belong on R-devel, not
> R-help.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 7, 2016 1:17:10 AM PDT, Chinmay Borwankar <
> getchinmay at gmail.com> wrote:
> >Hi,
> >    I want to integrate R with ROOTv6.06, which requires that,
> >    R be built with gcc compiler option "_GLIBCXX_USE_CXX11_ABI=0" .
> >  I am hoping that if I build R from source then there will be a way to
> >do this.
> >    Is there ?
> >    Regards.
>
>


-- 
Regards.

    Chinmay Borwankar

	[[alternative HTML version deleted]]


From darth.brando6 at gmail.com  Thu Sep  8 07:57:09 2016
From: darth.brando6 at gmail.com (darth brando)
Date: Thu, 8 Sep 2016 01:57:09 -0400
Subject: [R] hello i have a question on music analysis and mathematical
	synthesis related to r code
Message-ID: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>

Apologies for the long title but it is semi specific a topic and yes I am a noobs user to the system. I have read the guide and will attempt to adhere to the guide in this process and I do apologize in advance if I fail to do so, this is my first time here.

To the point; firstly version:

I have windows 7 64 bit OS, I'm going to be working with most current up to date version of R code for that OS with optional plug ins as needed, I am going to be using R code in conjunction with Fruity Loop Studio, dosbox/visual studio, and both synthesizer plug ins for Fruity Loop Studio and a physical soundblaster sound card in my alienware 15 2015 version as well as possibly a few emulator or OS instances for retro hardware to experiment with. Its a lot of software to take in yea, some I know by heart others like R Code I am a noob at. 

Now that the toolbox of software is out of the way; my Question:

Music is largely mathematically based, R Code is perfect for analyzing very large sets of data, naturally I saw some potential and wondered about the specifics of the type of application which follows.

I wish to use R Code to analyze portions of my personal library of music in order to discover the main sets of underlying patterns within that portion of my music library. I then wish to utilize patterns discovered to create a program which using proper algorithms set to those patterns to digitally synthesize music which conforms to those patterns but that would create said music automatically and potentially non stop; as in it does not stop writing the music and playing it until you turn it off. However; I do not wish this program to create a few tracks and play it on a loop, yes due to the patterns and the algorithms, certain bars and phrases will inevitably repeat but that doesn't mean just loop the same X amount of minutes.

Before I fall off tangent and go into semantics, I am asking help as;

The Music Genome Project
and Sony's musical mood auto playlist generator

are similar to this underlying theme but have gone down the road of separate applications and to the most important part:

I do not wish to infringe or plagiarize or violate copyright or IP on others said similar themed projects/products. 

my idea;

use themes and patterns present in a selection of music to then create a potentially infinite and unique mathematical auto play of algorithmically and digitally created music  

what I need help with;

inputting a large data set of audio files into an R Code application for pattern and algorithm analysis with out infringing on open, finished or ongoing projects.

I do not need help with porting the algorithm and pattern generator to an audio synthesis program--> that I  am familiar with how to do. 

I do not need help with making the end result potentially infinitely continued computation of algorithms within the found and set pattern parameters---> that I also know how to do.

I apologize for the long message and it's redundancies, it is simply my first time here and I wanted to be thorough.

Thank You for Reading!

Any advice on this will be supremely appreciated! 

---Darth Brando 

From aanchalsharma833 at gmail.com  Thu Sep  8 00:51:22 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Wed, 7 Sep 2016 15:51:22 -0700 (PDT)
Subject: [R] Fitting Mixture distributions
In-Reply-To: <E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
Message-ID: <c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>

Hi Simon

I am facing same problem as described above. i am trying to fit gaussian 
mixture model to my data using normalmixEM. I am running a Rscript which 
has this function running as part of it for about 17000 datasets (in loop). 
The script runs fine for some datasets, but it terminates when it 
encounters one dataset with the following error:

Error in normalmixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k = 2,  : 
  Too many tries!

(command used: expr_mix_gau <- normalmixEM(expr_glm_residuals, lambda = 
c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000, maxrestarts=200, verb 
= TRUE))
(expr_glm_residuals is my dataset which has residual values for different 
samples)

It is suggested that one should define the mu and sigma in the command by 
looking at your dataset. But in my case there are many datasets and it will 
keep on changing every time. please suggest what can I do to resolve this 
issue.

Regards
Anchal

On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
>
> Hi Tjun Kiat Teo, 
>
> you try to fit a Normal mixture to some data. The Normal mixture is very 
> delicate when it comes to parameter search: If the variance gets closer and 
> closer to zero, the log Likelihood becomes larger and larger for any values 
> of the remaining parameters. Furthermore for the EM algorithm it is known, 
> that it takes sometimes very long until convergence is reached. 
>
> Try the following: 
>
> Use as starting values for the component parameters: 
>
> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm = TRUE) * 
> runif(K) 
>
> For the weights just use either 1/K or the R cluster function with K 
> clusters 
>
> Here K is the number of components. Further enlarge the maximum number of 
> iterations. What you could also try is to randomize start parameters and 
> run an SEM (Stochastic EM). In my opinion the better method is in this case 
> a Bayesian method: MCMC. 
>
>
> Best 
>
> Simon 
>
>
> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com 
> <javascript:>> wrote: 
>
> > I was trying to use the normixEM in mixtools and I got this error 
> message. 
> > 
> > And I got this error message 
> > 
> > One of the variances is going to zero;  trying new starting values. 
> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too many 
> tries! 
> > 
> > Are there any other packages for fitting mixture distributions  ? 
> > 
> > 
> > Tjun Kiat Teo 
> > 
> >         [[alternative HTML version deleted]] 
> > 
> > ______________________________________________ 
> > R-h... at r-project.org <javascript:> mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> > and provide commented, minimal, self-contained, reproducible code. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From Justin.Peter at usq.edu.au  Thu Sep  8 02:48:13 2016
From: Justin.Peter at usq.edu.au (Justin Peter)
Date: Thu, 8 Sep 2016 00:48:13 +0000
Subject: [R] Using apply on a three dimensional matrix and passing
 multiple arguments to user defined function
In-Reply-To: <852d264d-9ac2-b4e4-6b21-0a81608e89bb@yahoo.es>
References: <1473222814.5386.13.camel@jpeter-laptop-usq.usq.edu.au>
	<CAN5YmCHC-GFNvO7bc_Lyk2p+UtRon=eDLnhHF4HiLP65RM4syw@mail.gmail.com>
	<852d264d-9ac2-b4e4-6b21-0a81608e89bb@yahoo.es>
Message-ID: <1473295692.5328.5.camel@jpeter-laptop-usq.usq.edu.au>

Dear Liusfo and Jean,

Thank you both for your help and suggestions, which both work.

As Jean mentioned, there is no real speed up using the apply family, which I thought there would be, so I will stick with the for loop for clarity.

Liusfo, the reason I used c(1,2) in the apply function (i.e. mask_data <- apply(data,c(1,2),mask,y=lsmask)) was because this is what you would do if you wanted to sum all the two-dimensional vectors over time (for instance to produce an average of a field over a year).

i.e. to get the sum you would do sum_data <- apply(data,c(1,2),sum)

I thought it would extend to using my mask function.

Anyway, thanks again for both of your help.

Cheers,
Justin
--
Justin Peter
Research Fellow
International Centre for Applied Climate Sciences,
University of Southern Queensland
West St, Toowoomba, QLD, 4350
Australia

Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au>
Ph: +61 (0) 7 4631 1181
Fax: +61 (0) 7 4631 5581
Mob: +61 (0)474 774 107


-----Original Message-----
From: Luisfo <luisfo89 at yahoo.es<mailto:Luisfo%20%3cluisfo89 at yahoo.es%3e>>
To: "Adams, Jean" <jvadams at usgs.gov<mailto:%22Adams,%20Jean%22%20%3cjvadams at usgs.gov%3e>>, Justin Peter <Justin.Peter at usq.edu.au<mailto:Justin%20Peter%20%3cJustin.Peter at usq.edu.au%3e>>
CC: r-help at r-project.org <r-help at r-project.org<mailto:%22r-help at r-project.org%22%20%3cr-help at r-project.org%3e>>
Subject: Re: [R] Using apply on a three dimensional matrix and passing multiple arguments to user defined function
Date: Wed, 7 Sep 2016 16:05:48 +0200

Hi,

Jean's example with lapply works fine.

However, if you still want to use apply, I think this works.
One observation first. You were passing c(1,2) as second argument to apply, in your code. And that is what makes you have lots of NAs as a result, since your function is being applied twice, by rows and columns (first and second dimensions) respectively.
Use:
    masked_data <- apply(data,3,mask,y=lsmask)
    # but now masked_data has dim(nlon*nlat,ntime), so change it
    dim(masked_data) <- dim(data)

The apply goes over the third dimension (second parameter '3'), so it takes every nlot*nlat matrix as first argument for function mask.
I think it should work.

Regards,

Luisfo Chiroque
PhD Student | PhD Candidate
IMDEA Networks Institute
http://fourier.networks.imdea.org/people/~luis_nunez/<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>


On 09/07/2016 03:17 PM, Adams, Jean wrote:



Justin,

I don't think you can get the apply() function to return an array.  You
could use lapply() instead, and then use simplify2array() to convert the
list of matrices to an array.  Also, in your mask() function you don't need
the which() and you should return the x.  See my example with toy data
below.

# toy data
nlon <- 2
nlat <- 4
ntime <- 3
data <- array(1:(nlon*nlat*ntime), dim=c(nlon, nlat, ntime))
lsmask <- array(sample(0:1, size=nlon*nlat, replace=TRUE), dim=c(nlon,
nlat))

# newly defined function
mask <- function(x, y) {
  x[y==0] <- NA
  x
}

# doit
data2 <- simplify2array(lapply(1:ntime, function(i) mask(data[, , i],
lsmask)))


You may prefer to stick with the for() loop approach (for clarity or
simplicity or ...)  When I ramped up the toy data to much larger
dimensions, the lapply() approach was only slightly faster than the for()
loop approach on my PC.

data3 <- data
data3[ , , i] <- mask(data3[ , , i], lsmask)

Jean




On Tue, Sep 6, 2016 at 11:33 PM, Justin Peter <Justin.Peter at usq.edu.au><mailto:Justin.Peter at usq.edu.au>
wrote:




Dear R-user,

I have a three-dimensional matrix of atmospheric data. The first two
dimensions are spatial (lon and lat) and the third is time, such that

dim(data) <- c(nlon,nlat,ntime)

I wish to apply a land sea mask data which is a matrix of "0" and "1" if
dim(nlon,nlat)

dim(lsmask) <- c(nlon,nlat)

I wish to set all of the elements in the two-dimensional array of
data[,,ntime] for every 1:length(ntime).

I could do this in a loop:

for (i in 1:ntime){
    data[,,i][which(lsmask == 0)] <- NA
}

I would like to do this using apply, but I need to pass two variables to
the function in apply (data and lsmask), where data is a two-dimensional
array.

I tried:

mask <- function(x,y) {x[which(y==0)] <- NA}

masked_data <- apply(data,c(1,2),mask,y=lsmask)

but I get back a vector of dim(nlon,nlat) populated with NA.

Any clues as to what I am missing?

Thanks in advance for you help.

Kind regards,
Justin



--
Justin Peter
Research Fellow
International Centre for Applied Climate Sciences,
University of Southern Queensland
West St, Toowoomba, QLD, 4350
Australia

Email: justin.peter at usq.edu.au<mailto:justin.peter at usq.edu.au><mailto:justin.peter at usq.edu.au><mailto:justin.peter at usq.edu.au>
Ph: +61 (0) 7 4631 1181
Fax: +61 (0) 7 4631 5581
Mob: +61 (0)474 774 107




_____________________________________________________________
This email (including any attached files) is confidential and is for the
intended recipient(s) only. If you received this email by mistake, please,
as a courtesy, tell the sender, then delete this email.

The views and opinions are the originator's and do not necessarily reflect
those of the University of Southern Queensland. Although all reasonable
precautions were taken to ensure that this email contained no viruses at
the time it was sent we accept no liability for any losses arising from its
receipt.

The University of Southern Queensland is a registered provider of
education with the Australian Government.
(CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




_____________________________________________________________
This email (including any attached files) is confidential and is for the intended recipient(s) only. If you received this email by mistake, please, as a courtesy, tell the sender, then delete this email.

The views and opinions are the originator's and do not necessarily reflect those of the University of Southern Queensland. Although all reasonable precautions were taken to ensure that this email contained no viruses at the time it was sent we accept no liability for any losses arising from its receipt.

The University of Southern Queensland is a registered provider of education with the Australian Government.
(CRICOS Institution Code QLD 00244B / NSW 02225M, TEQSA PRV12081 )


	[[alternative HTML version deleted]]


From nickpardikes at gmail.com  Wed Sep  7 22:27:46 2016
From: nickpardikes at gmail.com (Nick Pardikes)
Date: Wed, 7 Sep 2016 13:27:46 -0700
Subject: [R] Resample with replacement to produce many rarefaction
 curves with same number of samples
In-Reply-To: <3438d607-86fc-75ca-ffc3-a8d12939e5a7@yahoo.es>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
	<3438d607-86fc-75ca-ffc3-a8d12939e5a7@yahoo.es>
Message-ID: <CABh5y=7+HXfuh+T0A9smLR+iT+cPMgZh+x+7aLEQs6vJ0K4L2w@mail.gmail.com>

Hey Luisfo,

This looks great, however I still get the same plot as before (seen
below). The output looks the same. Here is the figure that was
generated from this code:

rrarefy.custom <- function (x, sample, rep.param=F)
{
  if (!identical(all.equal(x, round(x)), TRUE))
    stop("function is meaningful only for integers (counts)")
  x <- as.matrix(x)
  if (ncol(x) == 1)
    x <- t(x)
  if (length(sample) > 1 && length(sample) != nrow(x))
    stop(gettextf("length of 'sample' and number of rows of 'x' do not match"))
  sample <- rep(sample, length = nrow(x))
  colnames(x) <- colnames(x, do.NULL = FALSE)
  nm <- colnames(x)
  if (!rep.param && any(rowSums(x) < sample))
    warning("Some row sums < 'sample' and are not rarefied")
  for (i in 1:nrow(x)) {
    if (rep.param && sum(x[i, ]) <= sample[i])
      next
    row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
    row <- table(row)
    ind <- names(row)
    x[i, ] <- 0
    x[i, ind] <- row
  }
  x
}

raredata <- rarecurve(rrarefy.custom(netdata, sample=100,rep.param=T),
label=F, col=rgb(0, 0, 1, 0.1))

However, I like what you did to the rrarefy function to add the sample
with replacement option.

On Wed, Sep 7, 2016 at 8:17 AM, Luisfo <luisfo89 at yahoo.es> wrote:
> Hi Nick,
>
> If you use the following
>     raredata <- rarecurve(rrarefy(netdata, sample=100), label=F, col=rgb(0,
> 0, 1, 0.1))
> should work for any sample size, e.g. sample=100.
> However, you will have a 'warning' if you don't have samples enough, because
> it has not replacement.
>
> If you type 'rrarefy' on the R console (without brackets), or any other
> function name, you will see the R code of the function.
> rrarefy uses the function 'sample()' for sampling, but has no option for
> replacement.
> I did the following. I created my custom rrarefy function from the original.
> rrarefy.custom <- function (x, sample, rep.param=F)
> {
>   if (!identical(all.equal(x, round(x)), TRUE))
>     stop("function is meaningful only for integers (counts)")
>   x <- as.matrix(x)
>   if (ncol(x) == 1)
>     x <- t(x)
>   if (length(sample) > 1 && length(sample) != nrow(x))
>     stop(gettextf("length of 'sample' and number of rows of 'x' do not
> match"))
>   sample <- rep(sample, length = nrow(x))
>   colnames(x) <- colnames(x, do.NULL = FALSE)
>   nm <- colnames(x)
>   if (!rep.param && any(rowSums(x) < sample))
>     warning("Some row sums < 'sample' and are not rarefied")
>   for (i in 1:nrow(x)) {
>     if (rep.param && sum(x[i, ]) <= sample[i])
>       next
>     row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
>     row <- table(row)
>     ind <- names(row)
>     x[i, ] <- 0
>     x[i, ind] <- row
>   }
>   x
> }
> You can check the differences with the original code if you type 'rrarefy'
> on the R console.
>
> So now, if you type the following
>     raredata <- rarecurve(rrarefy.custom(netdata, sample=100,rep.param=T),
> label=F, col=rgb(0, 0, 1, 0.1))
> you will have the desired behaviour.
>
> WARNING: I do not understand about rarefunction curves or communities in
> your context. So, be careful when resampling. It might not be statistically
> correct.
>
> Regards,
> Luisfo Chiroque
> PhD Student | PhD Candidate
> IMDEA Networks Institute
> http://fourier.networks.imdea.org/people/~luis_nunez/
>
> On 09/07/2016 12:07 AM, Nick Pardikes wrote:
>
> I am currently having difficulty producing a graph using rarecurve in the
> vegan package. I have produced rarefaction curves (seen below) using the
> following code.
>
>
> library(vegan)
>
> myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
> communities
>
> netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
> species (columns)
>
> raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
> rarecurve to plot a rarefaction for each individual community (n=50)
>
>
> However I would like to produce a graph in which all rarefaction curves end
> at the same sample size. For example, in this graph it would be great to
> extend the x-axis (sample size) to 100 and have all curves end at this
> point. Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).
>
>
> I understand that rarefaction is useful to compare communities with
> different sample efforts, but I would still like to generate the figure. My
> actual data has 5000 simulated communities that differ greatly in matrix
> size and number of samples.
>
>
> Thank you in advance for your help and suggestions.
>
>
> Cheers,
>
> Nick
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Nick Pardikes
PhD Candidate
Program in Ecology, Evolution, and Conservation Biology
University of Nevada
https://nickpardikes.wordpress.com/
nickpardikes at gmail.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: luis_rarefaction.pdf
Type: application/pdf
Size: 19167 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160907/483b4faa/attachment.pdf>

From shaam249 at student.otago.ac.nz  Thu Sep  8 03:03:58 2016
From: shaam249 at student.otago.ac.nz (Amina Shahzadi Shahzadi)
Date: Thu, 8 Sep 2016 01:03:58 +0000
Subject: [R] Cannot convert from unsigned int to double
Message-ID: <SG2PR03MB0922273D7AE9088CAD7C0CEA90FB0@SG2PR03MB0922.apcprd03.prod.outlook.com>

Hi Dear

I am very new to use RcppArmadillo. I am trying to execute the following code. But I got the error

cannot convert 'arma::enable_if2<true, const arma::eOp<arma::eGlue<arma::Col<double>, arma::Col<double>, arma::eglue_plus>, arma::eop_exp> >::result {aka const arma::eOp<arma::eGlue<arma::Col<double>, arma::Col<double>, arma::eglue_plus>, arma::eop_exp>}' to 'double' in return
      return exp(alpha2+beta2);
                             ^
sample.cpp:36:1: warning: control reaches end of non-void function [-Wreturn-type]
 }



My code is  as follows: Any help in this regard.
Thank You



#include <RcppArmadillo.h>
using namespace Rcpp;
using namespace RcppArmadillo;
//[[Rcpp::depends(RcppArmadillo)]]
//[[Rcpp::export]]
arma::duble sample(arma::vec alpha, arma::vec beta)
{
        int m = alpha.size();
        arma::uvec index(m);
        for(int i=0; i<m; i++)
        {
                index(i) = i;
        }
        for(int i=0; i<m; i++)
        {
                for(int j=0; j<m; j++)
                {
                        {
                                if(i==j)
                                {
                                        arma::vec alpha1 = alpha.elem(find(index !=j));
                                        arma::vec beta1 = beta.elem(find(index!=j));
                                        return exp(alpha1(0)+beta1(1));
                                }
                                else
                                {
                                        arma::vec  alpha2 = alpha.elem(find(index !=i && index !=j));
                                        arma::vec beta2 = beta.elem(find(index !=i && index !=j));
                                         return exp(alpha2+beta2);
                                   }
                      }
           }
}
}




	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Sep  8 09:21:35 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 8 Sep 2016 17:21:35 +1000
Subject: [R] hello i have a question on music analysis and mathematical
 synthesis related to r code
In-Reply-To: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>
References: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>
Message-ID: <CA+8X3fULA5LQs=pQgqDJjTpR_nK+KUa66FDRCAL0QUkxRSCrWQ@mail.gmail.com>

Hi Darth,
Have a look at the tuneR package.

Jim


On Thu, Sep 8, 2016 at 3:57 PM, darth brando <darth.brando6 at gmail.com> wrote:
> Apologies for the long title but it is semi specific a topic and yes I am a noobs user to the system. I have read the guide and will attempt to adhere to the guide in this process and I do apologize in advance if I fail to do so, this is my first time here.
>
> To the point; firstly version:
>
> I have windows 7 64 bit OS, I'm going to be working with most current up to date version of R code for that OS with optional plug ins as needed, I am going to be using R code in conjunction with Fruity Loop Studio, dosbox/visual studio, and both synthesizer plug ins for Fruity Loop Studio and a physical soundblaster sound card in my alienware 15 2015 version as well as possibly a few emulator or OS instances for retro hardware to experiment with. Its a lot of software to take in yea, some I know by heart others like R Code I am a noob at.
>
> Now that the toolbox of software is out of the way; my Question:
>
> Music is largely mathematically based, R Code is perfect for analyzing very large sets of data, naturally I saw some potential and wondered about the specifics of the type of application which follows.
>
> I wish to use R Code to analyze portions of my personal library of music in order to discover the main sets of underlying patterns within that portion of my music library. I then wish to utilize patterns discovered to create a program which using proper algorithms set to those patterns to digitally synthesize music which conforms to those patterns but that would create said music automatically and potentially non stop; as in it does not stop writing the music and playing it until you turn it off. However; I do not wish this program to create a few tracks and play it on a loop, yes due to the patterns and the algorithms, certain bars and phrases will inevitably repeat but that doesn't mean just loop the same X amount of minutes.
>
> Before I fall off tangent and go into semantics, I am asking help as;
>
> The Music Genome Project
> and Sony's musical mood auto playlist generator
>
> are similar to this underlying theme but have gone down the road of separate applications and to the most important part:
>
> I do not wish to infringe or plagiarize or violate copyright or IP on others said similar themed projects/products.
>
> my idea;
>
> use themes and patterns present in a selection of music to then create a potentially infinite and unique mathematical auto play of algorithmically and digitally created music
>
> what I need help with;
>
> inputting a large data set of audio files into an R Code application for pattern and algorithm analysis with out infringing on open, finished or ongoing projects.
>
> I do not need help with porting the algorithm and pattern generator to an audio synthesis program--> that I  am familiar with how to do.
>
> I do not need help with making the end result potentially infinitely continued computation of algorithms within the found and set pattern parameters---> that I also know how to do.
>
> I apologize for the long message and it's redundancies, it is simply my first time here and I wanted to be thorough.
>
> Thank You for Reading!
>
> Any advice on this will be supremely appreciated!
>
> ---Darth Brando
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Sep  8 08:47:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Sep 2016 23:47:40 -0700
Subject: [R] Fitting Mixture distributions
In-Reply-To: <c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
	<c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
Message-ID: <CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>

"please suggest what can I do to resolve this
issue."

Fitting normal mixtures can be difficult, and sometime the
optimization algorithm (EM) will get stuck with very slow convergence.
Presumably there are options in the package to either increase the max
number of steps before giving up or make the convergence criteria less
sensitive. The former will increase the run time and the latter will
reduce the optimality (possibly leaving you farther from the true
optimum). So you should look into changing these as you think
appropriate.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 7, 2016 at 3:51 PM, Aanchal Sharma
<aanchalsharma833 at gmail.com> wrote:
> Hi Simon
>
> I am facing same problem as described above. i am trying to fit gaussian
> mixture model to my data using normalmixEM. I am running a Rscript which
> has this function running as part of it for about 17000 datasets (in loop).
> The script runs fine for some datasets, but it terminates when it
> encounters one dataset with the following error:
>
> Error in normalmixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k = 2,  :
>   Too many tries!
>
> (command used: expr_mix_gau <- normalmixEM(expr_glm_residuals, lambda =
> c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000, maxrestarts=200, verb
> = TRUE))
> (expr_glm_residuals is my dataset which has residual values for different
> samples)
>
> It is suggested that one should define the mu and sigma in the command by
> looking at your dataset. But in my case there are many datasets and it will
> keep on changing every time. please suggest what can I do to resolve this
> issue.
>
> Regards
> Anchal
>
> On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
>>
>> Hi Tjun Kiat Teo,
>>
>> you try to fit a Normal mixture to some data. The Normal mixture is very
>> delicate when it comes to parameter search: If the variance gets closer and
>> closer to zero, the log Likelihood becomes larger and larger for any values
>> of the remaining parameters. Furthermore for the EM algorithm it is known,
>> that it takes sometimes very long until convergence is reached.
>>
>> Try the following:
>>
>> Use as starting values for the component parameters:
>>
>> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm = TRUE) *
>> runif(K)
>>
>> For the weights just use either 1/K or the R cluster function with K
>> clusters
>>
>> Here K is the number of components. Further enlarge the maximum number of
>> iterations. What you could also try is to randomize start parameters and
>> run an SEM (Stochastic EM). In my opinion the better method is in this case
>> a Bayesian method: MCMC.
>>
>>
>> Best
>>
>> Simon
>>
>>
>> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com
>> <javascript:>> wrote:
>>
>> > I was trying to use the normixEM in mixtools and I got this error
>> message.
>> >
>> > And I got this error message
>> >
>> > One of the variances is going to zero;  trying new starting values.
>> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too many
>> tries!
>> >
>> > Are there any other packages for fitting mixture distributions  ?
>> >
>> >
>> > Tjun Kiat Teo
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-h... at r-project.org <javascript:> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-h... at r-project.org <javascript:> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Sep  8 08:51:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Sep 2016 23:51:09 -0700
Subject: [R] hello i have a question on music analysis and mathematical
 synthesis related to r code
In-Reply-To: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>
References: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>
Message-ID: <CAGxFJbT8F+oR24qoT=283ayBS5BQ6SX7DSg5_nsN2u7bPRg_rQ@mail.gmail.com>

Search on the Internet!

"Analyze music in R" had hits for several R packages that seemed like
they might be relevant.

Apologies if you've already done this and found mothing to meet your needs.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 7, 2016 at 10:57 PM, darth brando <darth.brando6 at gmail.com> wrote:
> Apologies for the long title but it is semi specific a topic and yes I am a noobs user to the system. I have read the guide and will attempt to adhere to the guide in this process and I do apologize in advance if I fail to do so, this is my first time here.
>
> To the point; firstly version:
>
> I have windows 7 64 bit OS, I'm going to be working with most current up to date version of R code for that OS with optional plug ins as needed, I am going to be using R code in conjunction with Fruity Loop Studio, dosbox/visual studio, and both synthesizer plug ins for Fruity Loop Studio and a physical soundblaster sound card in my alienware 15 2015 version as well as possibly a few emulator or OS instances for retro hardware to experiment with. Its a lot of software to take in yea, some I know by heart others like R Code I am a noob at.
>
> Now that the toolbox of software is out of the way; my Question:
>
> Music is largely mathematically based, R Code is perfect for analyzing very large sets of data, naturally I saw some potential and wondered about the specifics of the type of application which follows.
>
> I wish to use R Code to analyze portions of my personal library of music in order to discover the main sets of underlying patterns within that portion of my music library. I then wish to utilize patterns discovered to create a program which using proper algorithms set to those patterns to digitally synthesize music which conforms to those patterns but that would create said music automatically and potentially non stop; as in it does not stop writing the music and playing it until you turn it off. However; I do not wish this program to create a few tracks and play it on a loop, yes due to the patterns and the algorithms, certain bars and phrases will inevitably repeat but that doesn't mean just loop the same X amount of minutes.
>
> Before I fall off tangent and go into semantics, I am asking help as;
>
> The Music Genome Project
> and Sony's musical mood auto playlist generator
>
> are similar to this underlying theme but have gone down the road of separate applications and to the most important part:
>
> I do not wish to infringe or plagiarize or violate copyright or IP on others said similar themed projects/products.
>
> my idea;
>
> use themes and patterns present in a selection of music to then create a potentially infinite and unique mathematical auto play of algorithmically and digitally created music
>
> what I need help with;
>
> inputting a large data set of audio files into an R Code application for pattern and algorithm analysis with out infringing on open, finished or ongoing projects.
>
> I do not need help with porting the algorithm and pattern generator to an audio synthesis program--> that I  am familiar with how to do.
>
> I do not need help with making the end result potentially infinitely continued computation of algorithms within the found and set pattern parameters---> that I also know how to do.
>
> I apologize for the long message and it's redundancies, it is simply my first time here and I wanted to be thorough.
>
> Thank You for Reading!
>
> Any advice on this will be supremely appreciated!
>
> ---Darth Brando
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Sep  8 11:47:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 8 Sep 2016 02:47:28 -0700
Subject: [R] building R from source on gnu version >=5.4
In-Reply-To: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>
References: <CA+AH4+OA+-7b7W8oeCU05XsYA4SpLnwHYOy=LEhdJTF2KXaRVw@mail.gmail.com>
Message-ID: <FBEDA061-FCCD-4ACE-9324-455E9ED0097F@comcast.net>


> On Sep 7, 2016, at 1:17 AM, Chinmay Borwankar <getchinmay at gmail.com> wrote:
> 
> Hi,
>    I want to integrate R with ROOTv6.06, which requires that,
>    R be built with gcc compiler option "_GLIBCXX_USE_CXX11_ABI=0" .
>    I am hoping that if I build R from source then there will be a way to
> do this.
>    Is there ?

Like Jeff I believe this belongs on R-devel and any followups should go there. Appears you have not yet read the Posting Guide (since you continue to post in HTML and it does have a description of suitable topics for R-devel that to my reading appears to include this question.) 

https://www.r-project.org/posting-guide.html

The devel version of the Installation and Administration Manual has a section regarding CXX flags :

https://cran.r-project.org/doc/manuals/r-devel/R-admin.html#C_002b_002b-Support

-- 
David,

>    Regards.
> 
> -- 
> Regards.
> 
>    Chinmay Borwankar
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From veroandreo at gmail.com  Thu Sep  8 12:13:09 2016
From: veroandreo at gmail.com (Veronica Andreo)
Date: Thu, 8 Sep 2016 07:13:09 -0300
Subject: [R] get start and end date of ISO weeks giving a date as input
Message-ID: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>

Hello list,

Is there a quick way to get start and end date (%Y-%m-%d) from ISO
weeks if I only have dates?

For example, I have this date in which some event happened:
"2010-08-21". Not only I want the ISO week, which I can obtain either
with isoweek (lubridate) or ISOweek (ISOweek), but I want the start
and end date of that ISO week.

Do I need to print all ISO weeks from the period of interest and
sample there for start and end date? Or is there a better way to do
that?

Thanks a lot in advance!

Best,
Veronica


From es at enricoschumann.net  Thu Sep  8 12:53:12 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 08 Sep 2016 12:53:12 +0200
Subject: [R] get start and end date of ISO weeks giving a date as input
In-Reply-To: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
	(Veronica Andreo's message of "Thu, 8 Sep 2016 07:13:09 -0300")
References: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
Message-ID: <87h99qbr3b.fsf@enricoschumann.net>

On Thu, 08 Sep 2016, Veronica Andreo <veroandreo at gmail.com> writes:

> Hello list,
>
> Is there a quick way to get start and end date (%Y-%m-%d) from ISO
> weeks if I only have dates?
>
> For example, I have this date in which some event happened:
> "2010-08-21". Not only I want the ISO week, which I can obtain either
> with isoweek (lubridate) or ISOweek (ISOweek), but I want the start
> and end date of that ISO week.
>
> Do I need to print all ISO weeks from the period of interest and
> sample there for start and end date? Or is there a better way to do
> that?
>
> Thanks a lot in advance!
>
> Best,
> Veronica


You could use a function like the following one (which
assumes the start of the week is Monday and its end is
Sunday):

  d <- c("2010-08-21",
         "2016-08-01")

  iso_start_end <- function(d) {
      d <- as.Date(d)
      wday <- as.POSIXlt(d)$wday
      data.frame(date = d,
                 week = format(d, "%V"),
                 starts = d - wday + 1,
                 ends = d + 7 - wday)
  }
  
  iso_start_end(d)

The function should produce this output:

        date week     starts       ends
1 2010-08-21   33 2010-08-16 2010-08-22
2 2016-08-01   31 2016-08-01 2016-08-07



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From luisfo89 at yahoo.es  Thu Sep  8 12:55:32 2016
From: luisfo89 at yahoo.es (Luisfo)
Date: Thu, 8 Sep 2016 12:55:32 +0200
Subject: [R] Resample with replacement to produce many rarefaction
 curves with same number of samples
In-Reply-To: <CABh5y=7+HXfuh+T0A9smLR+iT+cPMgZh+x+7aLEQs6vJ0K4L2w@mail.gmail.com>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
	<3438d607-86fc-75ca-ffc3-a8d12939e5a7@yahoo.es>
	<CABh5y=7+HXfuh+T0A9smLR+iT+cPMgZh+x+7aLEQs6vJ0K4L2w@mail.gmail.com>
Message-ID: <4569d40c-b408-e02f-ee1e-48f0d1b2a575@yahoo.es>

Hi Nick,

Yes, you are right. There's one small bug on my code.
The 'if' within the for-loop is wrong. Try it now with the code below.

rrarefy.custom <- function (x, sample, rep.param=F)
{
   if (!identical(all.equal(x, round(x)), TRUE))
     stop("function is meaningful only for integers (counts)")
   x <- as.matrix(x)
   if (ncol(x) == 1)
     x <- t(x)
   if (length(sample) > 1 && length(sample) != nrow(x))
     stop(gettextf("length of 'sample' and number of rows of 'x' do not 
match"))
   sample <- rep(sample, length = nrow(x))
   colnames(x) <- colnames(x, do.NULL = FALSE)
   nm <- colnames(x)
   if (!rep.param && any(rowSums(x) < sample))
     warning("Some row sums < 'sample' and are not rarefied")
   for (i in 1:nrow(x)) {
     if (!rep.param && sum(x[i, ]) <= sample[i])
       next
     row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
     row <- table(row)
     ind <- names(row)
     x[i, ] <- 0
     x[i, ind] <- row
   }
   x
}

I have test it now before pasting it.

Best,

*Luisfo Chiroque*
/PhD Student | PhD Candidate
IMDEA Networks Institute/
http://fourier.networks.imdea.org/people/~luis_nunez/ 
<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>

On 09/07/2016 10:27 PM, Nick Pardikes wrote:
> Hey Luisfo,
>
> This looks great, however I still get the same plot as before (seen
> below). The output looks the same. Here is the figure that was
> generated from this code:
>
> rrarefy.custom <- function (x, sample, rep.param=F)
> {
>    if (!identical(all.equal(x, round(x)), TRUE))
>      stop("function is meaningful only for integers (counts)")
>    x <- as.matrix(x)
>    if (ncol(x) == 1)
>      x <- t(x)
>    if (length(sample) > 1 && length(sample) != nrow(x))
>      stop(gettextf("length of 'sample' and number of rows of 'x' do not match"))
>    sample <- rep(sample, length = nrow(x))
>    colnames(x) <- colnames(x, do.NULL = FALSE)
>    nm <- colnames(x)
>    if (!rep.param && any(rowSums(x) < sample))
>      warning("Some row sums < 'sample' and are not rarefied")
>    for (i in 1:nrow(x)) {
>      if (rep.param && sum(x[i, ]) <= sample[i])
>        next
>      row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
>      row <- table(row)
>      ind <- names(row)
>      x[i, ] <- 0
>      x[i, ind] <- row
>    }
>    x
> }
>
> raredata <- rarecurve(rrarefy.custom(netdata, sample=100,rep.param=T),
> label=F, col=rgb(0, 0, 1, 0.1))
>
> However, I like what you did to the rrarefy function to add the sample
> with replacement option.
>
> On Wed, Sep 7, 2016 at 8:17 AM, Luisfo <luisfo89 at yahoo.es> wrote:
>> Hi Nick,
>>
>> If you use the following
>>      raredata <- rarecurve(rrarefy(netdata, sample=100), label=F, col=rgb(0,
>> 0, 1, 0.1))
>> should work for any sample size, e.g. sample=100.
>> However, you will have a 'warning' if you don't have samples enough, because
>> it has not replacement.
>>
>> If you type 'rrarefy' on the R console (without brackets), or any other
>> function name, you will see the R code of the function.
>> rrarefy uses the function 'sample()' for sampling, but has no option for
>> replacement.
>> I did the following. I created my custom rrarefy function from the original.
>> rrarefy.custom <- function (x, sample, rep.param=F)
>> {
>>    if (!identical(all.equal(x, round(x)), TRUE))
>>      stop("function is meaningful only for integers (counts)")
>>    x <- as.matrix(x)
>>    if (ncol(x) == 1)
>>      x <- t(x)
>>    if (length(sample) > 1 && length(sample) != nrow(x))
>>      stop(gettextf("length of 'sample' and number of rows of 'x' do not
>> match"))
>>    sample <- rep(sample, length = nrow(x))
>>    colnames(x) <- colnames(x, do.NULL = FALSE)
>>    nm <- colnames(x)
>>    if (!rep.param && any(rowSums(x) < sample))
>>      warning("Some row sums < 'sample' and are not rarefied")
>>    for (i in 1:nrow(x)) {
>>      if (rep.param && sum(x[i, ]) <= sample[i])
>>        next
>>      row <- sample(rep(nm, times = x[i, ]), sample[i], replace = rep.param)
>>      row <- table(row)
>>      ind <- names(row)
>>      x[i, ] <- 0
>>      x[i, ind] <- row
>>    }
>>    x
>> }
>> You can check the differences with the original code if you type 'rrarefy'
>> on the R console.
>>
>> So now, if you type the following
>>      raredata <- rarecurve(rrarefy.custom(netdata, sample=100,rep.param=T),
>> label=F, col=rgb(0, 0, 1, 0.1))
>> you will have the desired behaviour.
>>
>> WARNING: I do not understand about rarefunction curves or communities in
>> your context. So, be careful when resampling. It might not be statistically
>> correct.
>>
>> Regards,
>> Luisfo Chiroque
>> PhD Student | PhD Candidate
>> IMDEA Networks Institute
>> http://fourier.networks.imdea.org/people/~luis_nunez/
>>
>> On 09/07/2016 12:07 AM, Nick Pardikes wrote:
>>
>> I am currently having difficulty producing a graph using rarecurve in the
>> vegan package. I have produced rarefaction curves (seen below) using the
>> following code.
>>
>>
>> library(vegan)
>>
>> myMat <- round(matrix(rlnorm(2000), 50)) #creates distribution of
>> communities
>>
>> netdata <- as.data.frame(myMat) #generates a matrix of communities (rows),
>> species (columns)
>>
>> raredata <- rarecurve(netdata, label=F, col=rgb(0, 0, 1, 0.1))  #uses
>> rarecurve to plot a rarefaction for each individual community (n=50)
>>
>>
>> However I would like to produce a graph in which all rarefaction curves end
>> at the same sample size. For example, in this graph it would be great to
>> extend the x-axis (sample size) to 100 and have all curves end at this
>> point. Is there any way to use rarecurve to resample a community (row) with
>> replacement the same number of times for all 50 communities? With
>> replacement is important because the communities differ greatly in their
>> size (number of species).
>>
>>
>> I understand that rarefaction is useful to compare communities with
>> different sample efforts, but I would still like to generate the figure. My
>> actual data has 5000 simulated communities that differ greatly in matrix
>> size and number of samples.
>>
>>
>> Thank you in advance for your help and suggestions.
>>
>>
>> Cheers,
>>
>> Nick
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>


	[[alternative HTML version deleted]]


From luisfo89 at yahoo.es  Thu Sep  8 13:20:14 2016
From: luisfo89 at yahoo.es (Luisfo)
Date: Thu, 8 Sep 2016 13:20:14 +0200
Subject: [R] get start and end date of ISO weeks giving a date as input
In-Reply-To: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
References: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
Message-ID: <e369a034-c5d7-e1ff-b561-06073c994bb2@yahoo.es>

Dear Veronica,

Here there's a way of doing what you requested.

library("lubridate")
# your date '2010-08-21' as Date object
dd <- as.Date(strptime("2010-08-21", format="%Y-%m-%d", tz="GMT"))
# take the first day of the year as Date object, i.e. 2010-01-01 in our 
example
ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"), 
format="%Y-%m-%d", tz="GMT"))
# the start and end dates
bound.dates <- ref.date + 7 * (week(dd)-1) + c(0,6)

I hope you find it useful.

Best,

*Luisfo Chiroque*
/PhD Student | PhD Candidate
IMDEA Networks Institute/
http://fourier.networks.imdea.org/people/~luis_nunez/ 
<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>

On 09/08/2016 12:13 PM, Veronica Andreo wrote:
> Hello list,
>
> Is there a quick way to get start and end date (%Y-%m-%d) from ISO
> weeks if I only have dates?
>
> For example, I have this date in which some event happened:
> "2010-08-21". Not only I want the ISO week, which I can obtain either
> with isoweek (lubridate) or ISOweek (ISOweek), but I want the start
> and end date of that ISO week.
>
> Do I need to print all ISO weeks from the period of interest and
> sample there for start and end date? Or is there a better way to do
> that?
>
> Thanks a lot in advance!
>
> Best,
> Veronica
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Thu Sep  8 14:06:34 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Thu, 8 Sep 2016 15:06:34 +0300
Subject: [R] Is there t.test with null hypothesis?
Message-ID: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>

I?m trying to do a t-test, where the null hypothesis for the two data sets has to be:

?the means are the same?/?difference in means is equal to one?

Using the t.test function in R I?m able to see that it uses the following ?alternative hypothesis?:

alternative hypothesis: true difference in means is not equal to 0

but does not seem to specify null hypothesis. I believe alternative and null hypotheses are different, although
I don?t exactly know how.

So what should I use for my t-test? Or is t.test ok?


From maechler at stat.math.ethz.ch  Thu Sep  8 14:38:10 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Sep 2016 14:38:10 +0200
Subject: [R] Fitting Mixture distributions
In-Reply-To: <CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
	<c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
	<CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>
Message-ID: <22481.23474.403070.875828@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Wed, 7 Sep 2016 23:47:40 -0700 writes:

    > "please suggest what can I do to resolve this
    > issue."

    > Fitting normal mixtures can be difficult, and sometime the
    > optimization algorithm (EM) will get stuck with very slow convergence.
    > Presumably there are options in the package to either increase the max
    > number of steps before giving up or make the convergence criteria less
    > sensitive. The former will increase the run time and the latter will
    > reduce the optimality (possibly leaving you farther from the true
    > optimum). So you should look into changing these as you think
    > appropriate.

I'm jumping in late, without having read everything preceding.

One of the last messages seemed to indicate that you are looking
at mixtures of *one*-dimensional gaussians.

If this is the case, I strongly recommend looking at (my) CRAN
package 'nor1mix' (the "1" is for "*one*-dimensional).

For a while now that small package is providing an alternative
to the EM, namely direct MLE, simply using optim(<likelihood>) where the
likelihood uses a somewhat smart parametrization.

Of course, *as the EM*, this also depends on the starting value,
but my (limited) experience has been that
  nor1mix::norMixMLE()
works considerably faster and more reliable than the EM (which I
also provide as    nor1mix::norMixEM() .

Apropos 'starting value': The help page shows how to use
kmeans() for "somewhat" reliable starts; alternatively, I'd
recommend using cluster::pam() to get a start there.

I'm glad to hear about experiences using these / comparing
these with other approaches.

Martin


--
Martin Maechler,
ETH Zurich


    > On Wed, Sep 7, 2016 at 3:51 PM, Aanchal Sharma
    > <aanchalsharma833 at gmail.com> wrote:
    >> Hi Simon
    >> 
    >> I am facing same problem as described above. i am trying to fit gaussian
    >> mixture model to my data using normalmixEM. I am running a Rscript which
    >> has this function running as part of it for about 17000 datasets (in loop).
    >> The script runs fine for some datasets, but it terminates when it
    >> encounters one dataset with the following error:
    >> 
    >> Error in normalmixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k = 2,  :
    >> Too many tries!
    >> 
    >> (command used: expr_mix_gau <- normalmixEM(expr_glm_residuals, lambda =
    >> c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000, maxrestarts=200, verb
    >> = TRUE))
    >> (expr_glm_residuals is my dataset which has residual values for different
    >> samples)
    >> 
    >> It is suggested that one should define the mu and sigma in the command by
    >> looking at your dataset. But in my case there are many datasets and it will
    >> keep on changing every time. please suggest what can I do to resolve this
    >> issue.
    >> 
    >> Regards
    >> Anchal
    >> 
    >> On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
    >>> 
    >>> Hi Tjun Kiat Teo,
    >>> 
    >>> you try to fit a Normal mixture to some data. The Normal mixture is very
    >>> delicate when it comes to parameter search: If the variance gets closer and
    >>> closer to zero, the log Likelihood becomes larger and larger for any values
    >>> of the remaining parameters. Furthermore for the EM algorithm it is known,
    >>> that it takes sometimes very long until convergence is reached.
    >>> 
    >>> Try the following:
    >>> 
    >>> Use as starting values for the component parameters:
    >>> 
    >>> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm = TRUE) *
    >>> runif(K)
    >>> 
    >>> For the weights just use either 1/K or the R cluster function with K
    >>> clusters
    >>> 
    >>> Here K is the number of components. Further enlarge the maximum number of
    >>> iterations. What you could also try is to randomize start parameters and
    >>> run an SEM (Stochastic EM). In my opinion the better method is in this case
    >>> a Bayesian method: MCMC.
    >>> 
    >>> 
    >>> Best
    >>> 
    >>> Simon
    >>> 
    >>> 
    >>> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com
    >>> <javascript:>> wrote:
    >>> 
    >>> > I was trying to use the normixEM in mixtools and I got this error
    >>> message.
    >>> >
    >>> > And I got this error message
    >>> >
    >>> > One of the variances is going to zero;  trying new starting values.
    >>> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too many
    >>> tries!
    >>> >
    >>> > Are there any other packages for fitting mixture distributions  ?
    >>> >
    >>> >
    >>> > Tjun Kiat Teo
    >>> >
    >>> >         [[alternative HTML version deleted]]
    >>> >
    >>> > ______________________________________________
    >>> > R-h... at r-project.org <javascript:> mailing list
    >>> > https://stat.ethz.ch/mailman/listinfo/r-help
    >>> > PLEASE do read the posting guide
    >>> http://www.R-project.org/posting-guide.html
    >>> > and provide commented, minimal, self-contained, reproducible code.
    >>> 
    >>> ______________________________________________
    >>> R-h... at r-project.org <javascript:> mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide
    >>> http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >>> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From rab45 at pitt.edu  Thu Sep  8 14:39:49 2016
From: rab45 at pitt.edu (Rick Bilonick)
Date: Thu, 8 Sep 2016 08:39:49 -0400
Subject: [R] Is there t.test with null hypothesis?
In-Reply-To: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>
References: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>
Message-ID: <c3268f8e-84e9-b2a6-27d5-ba995f0910c7@pitt.edu>

You need to include the argument "mu=1" (without parentheses). For example:

 > t.test(group1,group2, mu=1)

for a two-sample independent groups t-test. If you type:

 > ?t.test

you can see the help information for the t.test function.

RIck

On 09/08/2016 08:06 AM, Matti Viljamaa wrote:
> I?m trying to do a t-test, where the null hypothesis for the two data sets has to be:
>
> ?the means are the same?/?difference in means is equal to one?
>
> Using the t.test function in R I?m able to see that it uses the following ?alternative hypothesis?:
>
> alternative hypothesis: true difference in means is not equal to 0
>
> but does not seem to specify null hypothesis. I believe alternative and null hypotheses are different, although
> I don?t exactly know how.
>
> So what should I use for my t-test? Or is t.test ok?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://na01.safelinks.protection.outlook.com/?url=https%3a%2f%2fstat.ethz.ch%2fmailman%2flistinfo%2fr-help&data=01%7c01%7crab45%40pitt.edu%7c99a5b7c1533548c5ead708d3d7e0bb76%7c9ef9f489e0a04eeb87cc3a526112fd0d%7c1&sdata=Pf9Tku8lIeH9quNmY2dEmR4HNSLgShRP7p7Hx9HUCMY%3d
> PLEASE do read the posting guide https://na01.safelinks.protection.outlook.com/?url=http%3a%2f%2fwww.R-project.org%2fposting-guide.html&data=01%7c01%7crab45%40pitt.edu%7c99a5b7c1533548c5ead708d3d7e0bb76%7c9ef9f489e0a04eeb87cc3a526112fd0d%7c1&sdata=eGCmYy70ceyiJ%2bpgDXA8SaHHma%2f4DbxhIbSARUDYwxg%3d
> and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Thu Sep  8 14:43:55 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Thu, 8 Sep 2016 15:43:55 +0300
Subject: [R] How to interpret lm's coefficients?
Message-ID: <7B1F2208-B3B6-4D24-88F0-DF377F74127F@kapsi.fi>

I?m trying to understand how to interpret the return values, specifically ?Coefficients:?, of R?s lm function. I?m using it with a dichotomic predictor (mom_hs).

lm(data$kid_score ~ data$mom_hs) returns 

Coefficients:
#   (Intercept)  data$mom_hs  
# 77.55        11.77

I read that the (Intercept) value is the ?y-intercept? value b, i.e. the y value where the line intercept the y-axis.

The second value is the value of the term m (or ?slope?) in the equation of a line y=mx+b.

However,

These two numbers also have the following interpretations:

b or (Intercept) value is the same as:
The mean of those data$kid_score that have data$mom_hs == 0.
Why is this a valid interpretation?

m or data$mom_hs value is the same as:
The difference of means between those data$kid_score that have data$mom_hs == 1
and those data$kid_score that have data$mom_hs == 0.
Why is this a valid interpretation?

Can someone explain?

From stefanML at collocations.de  Thu Sep  8 14:46:03 2016
From: stefanML at collocations.de (Stefan Evert)
Date: Thu, 8 Sep 2016 14:46:03 +0200
Subject: [R] Resample with replacement to produce many rarefaction
	curves with same number of samples
In-Reply-To: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
Message-ID: <F3C6C39F-A477-4CE8-B381-FEC1000AAC47@collocations.de>


> On 7 Sep 2016, at 00:07, Nick Pardikes <nickpardikes at gmail.com> wrote:
> 
> Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).

Are you sure it makes sense to resample with replacement?  This will systematically underestimate the number of species at a given sample size (because of the artificial repetition) and will never find more species than there are in your original sample.

Best,
Stefan

From lists at dewey.myzen.co.uk  Thu Sep  8 14:48:08 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 8 Sep 2016 13:48:08 +0100
Subject: [R] Is there t.test with null hypothesis?
In-Reply-To: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>
References: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>
Message-ID: <e102333c-53a4-f73b-6d68-9457ec02ed07@dewey.myzen.co.uk>

Dear Matti

On 08/09/2016 13:06, Matti Viljamaa wrote:
> I?m trying to do a t-test, where the null hypothesis for the two data sets has to be:
>
> ?the means are the same?/?difference in means is equal to one?
>

That is two statements not one. Do you mean that your null is that the 
difference is 1? If so just subtract 1 from all the scores in the group 
which is predicted to be higher and run the t-test on the resulting scores.

> Using the t.test function in R I?m able to see that it uses the following ?alternative hypothesis?:
>
> alternative hypothesis: true difference in means is not equal to 0

It means that the null is that the difference is zero.

>
> but does not seem to specify null hypothesis. I believe alternative and null hypotheses are different, although
> I don?t exactly know how.
>
> So what should I use for my t-test? Or is t.test ok?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ceritaahmad at gmail.com  Thu Sep  8 14:50:43 2016
From: ceritaahmad at gmail.com (Ahmad Nursalim)
Date: Thu, 8 Sep 2016 19:50:43 +0700
Subject: [R]  CopyDetect Packgace
In-Reply-To: <CAGGEV7NLVpntNiWmfMPCZXa2OTutm_1vWXd8bnAfmATxbj1t6w@mail.gmail.com>
References: <CAGGEV7NLVpntNiWmfMPCZXa2OTutm_1vWXd8bnAfmATxbj1t6w@mail.gmail.com>
Message-ID: <CAGGEV7NOhAO-wHrka8buRdb=0RdVO=BpEQtHi_avqpn--cfQ8w@mail.gmail.com>

Dear All
x <- CopyDetect2 (data = data.abcd,
                          item.par = slopintrc,
                          pair = c (pairs [i, 1], pairs [i, 2]),
                          options = c ("A", "B", "C", "D", "E"))

What is the mean pair = c (pairs [i, 1], pairs [i, 2]),

Pleas Help Me

	[[alternative HTML version deleted]]


From veroandreo at gmail.com  Thu Sep  8 14:51:10 2016
From: veroandreo at gmail.com (Veronica Andreo)
Date: Thu, 8 Sep 2016 09:51:10 -0300
Subject: [R] get start and end date of ISO weeks giving a date as input
In-Reply-To: <e369a034-c5d7-e1ff-b561-06073c994bb2@yahoo.es>
References: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
	<e369a034-c5d7-e1ff-b561-06073c994bb2@yahoo.es>
Message-ID: <CAAMki4G92sbQXQ=zLJsbz9Nrqtof5-wus99azC4Tmjhqvf6+qw@mail.gmail.com>

Hello Luisfo and Enrico,

Thanks for your help! I've been testing both solutions... results differ
for the same date (I changed both functions to use ISO8601). And I added
contiguous dates, to see how they handle the start-end of the week.

So, here the results:

### one example
d <- c("2010-08-21","2010-08-22","2010-08-23","2010-08-24")
iso_start_end <- function(d) {
  d <- as.Date(d)
  wday <- as.POSIXlt(d)$wday
  data.frame(date = d,
             week = format(d, "%V"),
             starts = d - wday + 1,
             ends = d + 7 - wday)
}
iso_start_end(d)

        date week     starts       ends
1 2010-08-21   33 2010-08-16 2010-08-22
*2 2010-08-22   33 2010-08-23 2010-08-29*
3 2010-08-23   34 2010-08-23 2010-08-29
4 2010-08-24   34 2010-08-23 2010-08-29

### the other example:
dd <- as.Date(strptime('2010-08-21', format="%Y-%m-%d", tz="GMT"))
ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"), format="%Y-%m-%d"))
bound.dates <- ref.date + 7 * (isoweek(dd)) + c(0,6)
bound.dates
[1] "2010-08-20" "2010-08-26"

So, researching a bit more and inspired by those examples, I eventually
came up with this solution that seems to work fine... I share in case that
any other has a similar problem:

# get ISOweek for my vector of dates
week_iso<-ISOweek(d)

# vector with the format %Y-W%V-1 for start day of the ISO week
week_iso_day1 <- paste(week_iso,1, sep="-")

#  vector with the format %Y-W%V-7 for end day of the ISO week
week_iso_day7 <- paste(week_iso, 7, sep="-")

# use ISOweek2date
data.frame(date= d, week_iso = week_iso, start =
ISOweek2date(week_iso_day1), end = ISOweek2date(week_iso_day7)

        date week_iso      start        end
1 2010-08-21 2010-W33 2010-08-16 2010-08-22
2 2010-08-22 2010-W33 2010-08-16 2010-08-22
3 2010-08-23 2010-W34 2010-08-23 2010-08-29
4 2010-08-24 2010-W34 2010-08-23 2010-08-29


Thanks again for your time, ideas and help!

Best,
Vero


2016-09-08 8:20 GMT-03:00 Luisfo <luisfo89 at yahoo.es>:

> Dear Veronica,
>
> Here there's a way of doing what you requested.
>
> library("lubridate")
> # your date '2010-08-21' as Date object
> dd <- as.Date(strptime("2010-08-21", format="%Y-%m-%d", tz="GMT"))
> # take the first day of the year as Date object, i.e. 2010-01-01 in our
> example
> ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"),
> format="%Y-%m-%d", tz="GMT"))
> # the start and end dates
> bound.dates <- ref.date + 7 * (week(dd)-1) + c(0,6)
>
> I hope you find it useful.
>
> Best,
> *Luisfo Chiroque*
>
> *PhD Student | PhD Candidate IMDEA Networks Institute*
> http://fourier.networks.imdea.org/people/~luis_nunez/
>
> On 09/08/2016 12:13 PM, Veronica Andreo wrote:
>
> Hello list,
>
> Is there a quick way to get start and end date (%Y-%m-%d) from ISO
> weeks if I only have dates?
>
> For example, I have this date in which some event happened:
> "2010-08-21". Not only I want the ISO week, which I can obtain either
> with isoweek (lubridate) or ISOweek (ISOweek), but I want the start
> and end date of that ISO week.
>
> Do I need to print all ISO weeks from the period of interest and
> sample there for start and end date? Or is there a better way to do
> that?
>
> Thanks a lot in advance!
>
> Best,
> Veronica
>
> ______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Thu Sep  8 14:52:06 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Thu, 8 Sep 2016 15:52:06 +0300
Subject: [R] Is there t.test with null hypothesis?
In-Reply-To: <e102333c-53a4-f73b-6d68-9457ec02ed07@dewey.myzen.co.uk>
References: <E99CE9E0-9F5F-43AA-AEF4-EC748904C09E@kapsi.fi>
	<e102333c-53a4-f73b-6d68-9457ec02ed07@dewey.myzen.co.uk>
Message-ID: <278E586A-DC74-4B90-A465-1DABD3E6A5D8@kapsi.fi>


> On 08 Sep 2016, at 15:48, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Dear Matti
> 
> On 08/09/2016 13:06, Matti Viljamaa wrote:
>> I?m trying to do a t-test, where the null hypothesis for the two data sets has to be:
>> 
>> ?the means are the same?/?difference in means is equal to one?
>> 
> 
> That is two statements not one. Do you mean that your null is that the difference is 1? If so just subtract 1 from all the scores in the group which is predicted to be higher and run the t-test on the resulting scores.

Sorry typo, should of course be:

?the means are the same?/?difference in means is equal to zero?

so they are synonymous.

>> Using the t.test function in R I?m able to see that it uses the following ?alternative hypothesis?:
>> 
>> alternative hypothesis: true difference in means is not equal to 0
> 
> It means that the null is that the difference is zero.
> 
>> 
>> but does not seem to specify null hypothesis. I believe alternative and null hypotheses are different, although
>> I don?t exactly know how.
>> 
>> So what should I use for my t-test? Or is t.test ok?
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From friendly at yorku.ca  Thu Sep  8 15:19:07 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 8 Sep 2016 09:19:07 -0400
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
Message-ID: <94068da5-e33b-846d-6762-eae278971a04@yorku.ca>

You might also or instead look at the roxygen way of doing things, which 
maps to Rd files, but are much easier to write. In R Studio,
Code ->  Insert Roxygen skeleton does this for you from an existing 
function.  See: http://r-pkgs.had.co.nz/man.html

#' title goes here
#'
#' description goes here
#'
#' @param p1	desc of p1
#' @param p2
#' @param ...
#' @return
#' @export
#' @imports
#' @author
#' @seealso
#' @examples
#' example lines

foo <- function (p1, p2, ... ) {

}


On 9/7/2016 12:46 PM, Duncan Murdoch wrote:
> On 07/09/2016 11:35 AM, Doran, Harold wrote:
>> I'm building a large program with many different people contributing
>> to the coding in R and so it needs a well-articulated design spec. The
>> program will have many different functions that must interact with
>> each other, but the individual functions will be written by different
>> people.
>>
>> I'm curious if anyone has an R-specific SRS document to share that
>> they have used for a similar purpose listing the objectives for each
>> function, class definition, generics, what the function inherits from,
>> and so on, or perhaps even a useful template for such work.
>
> The Rd help pages do some of this.  They aren't so good at describing
> the class hierarchy but are good at specifying individual functions.
>
> Duncan Murdoch
>


From friendly at yorku.ca  Thu Sep  8 15:19:07 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 8 Sep 2016 09:19:07 -0400
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
Message-ID: <94068da5-e33b-846d-6762-eae278971a04@yorku.ca>

You might also or instead look at the roxygen way of doing things, which 
maps to Rd files, but are much easier to write. In R Studio,
Code ->  Insert Roxygen skeleton does this for you from an existing 
function.  See: http://r-pkgs.had.co.nz/man.html

#' title goes here
#'
#' description goes here
#'
#' @param p1	desc of p1
#' @param p2
#' @param ...
#' @return
#' @export
#' @imports
#' @author
#' @seealso
#' @examples
#' example lines

foo <- function (p1, p2, ... ) {

}


On 9/7/2016 12:46 PM, Duncan Murdoch wrote:
> On 07/09/2016 11:35 AM, Doran, Harold wrote:
>> I'm building a large program with many different people contributing
>> to the coding in R and so it needs a well-articulated design spec. The
>> program will have many different functions that must interact with
>> each other, but the individual functions will be written by different
>> people.
>>
>> I'm curious if anyone has an R-specific SRS document to share that
>> they have used for a similar purpose listing the objectives for each
>> function, class definition, generics, what the function inherits from,
>> and so on, or perhaps even a useful template for such work.
>
> The Rd help pages do some of this.  They aren't so good at describing
> the class hierarchy but are good at specifying individual functions.
>
> Duncan Murdoch
>


From es at enricoschumann.net  Thu Sep  8 15:41:44 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 08 Sep 2016 15:41:44 +0200
Subject: [R] get start and end date of ISO weeks giving a date as input
In-Reply-To: <CAAMki4G92sbQXQ=zLJsbz9Nrqtof5-wus99azC4Tmjhqvf6+qw@mail.gmail.com>
	(Veronica Andreo's message of "Thu, 8 Sep 2016 09:51:10 -0300")
References: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
	<e369a034-c5d7-e1ff-b561-06073c994bb2@yahoo.es>
	<CAAMki4G92sbQXQ=zLJsbz9Nrqtof5-wus99azC4Tmjhqvf6+qw@mail.gmail.com>
Message-ID: <87fupa4ig7.fsf@enricoschumann.net>

Hi Veronica,

please see inline.

On Thu, 08 Sep 2016, Veronica Andreo <veroandreo at gmail.com> writes:

> Hello Luisfo and Enrico,
>
> Thanks for your help! I've been testing both
> solutions... results differ for the same date (I
> changed both functions to use ISO8601). And I added
> contiguous dates, to see how they handle the
> start-end of the week.
>
> So, here the results:
>
> ### one example
> d <- c("2010-08-21","2010-08-22","2010-08-23","2010-08-24")
> iso_start_end <- function(d) {
> ? d <- as.Date(d)
> ? wday <- as.POSIXlt(d)$wday
> ? data.frame(date = d,
> ? ? ? ? ? ? ?week = format(d, "%V"),
> ? ? ? ? ? ? ?starts = d - wday + 1,
> ? ? ? ? ? ? ?ends = d + 7 - wday)
> }
> iso_start_end(d)
>
> ? ? ? ? date week ? ? starts ? ? ? ends
> 1 2010-08-21 ? 33 2010-08-16 2010-08-22
> 2 2010-08-22 ? 33 2010-08-23 2010-08-29
> 3 2010-08-23 ? 34 2010-08-23 2010-08-29
> 4 2010-08-24 ? 34 2010-08-23 2010-08-29

Yes, the second date makes no sense, and it happens
because Sunday is 0 (and not 7). My bad. Here is
a fixed version:

  iso_start_end <- function(d) {
      d <- as.Date(d)
      wday <- as.POSIXlt(d)$wday
      wday[wday == 0] <- 7
      data.frame(date = d,
                 week = format(d, "%V"),
                 starts = d - wday + 1,
                 ends = d + 7 - wday)
  }


> ### the other example:
> dd <- as.Date(strptime('2010-08-21', format="%Y-%m-%d", tz="GMT"))
> ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"), format="%Y-%m-%d"))
> bound.dates <- ref.date + 7 * (isoweek(dd)) + c(0,6)
> bound.dates
> [1] "2010-08-20" "2010-08-26"

You can use the function "weekdays" to see check the
results.

  > weekdays(bound.dates)
  [1] "Friday"   "Thursday"

> So, researching a bit more and inspired by those
> examples, I eventually came up with this solution
> that seems to work fine... I share in case that any
> other has a similar problem:
>
> # get ISOweek for my vector of dates?
> week_iso<-ISOweek(d)
>
> # vector with the format %Y-W%V-1 for start day of the ISO week
> week_iso_day1 <- paste(week_iso,1, sep="-")
>
> # ?vector with the format %Y-W%V-7 for end day of the ISO week
> week_iso_day7 <- paste(week_iso, 7, sep="-")
>
> # use ISOweek2date
> data.frame(date= d, week_iso = week_iso, start = ISOweek2date(week_iso_day1), end = ISOweek2date(week_iso_day7)
>
>         date week_iso      start        end
> 1 2010-08-21 2010-W33 2010-08-16 2010-08-22
> 2 2010-08-22 2010-W33 2010-08-16 2010-08-22
> 3 2010-08-23 2010-W34 2010-08-23 2010-08-29
> 4 2010-08-24 2010-W34 2010-08-23 2010-08-29

The updated 'iso_start_end' gives the same result.
  
          date week     starts       ends
  1 2010-08-21   33 2010-08-16 2010-08-22
  2 2010-08-22   33 2010-08-16 2010-08-22
  3 2010-08-23   34 2010-08-23 2010-08-29
  4 2010-08-24   34 2010-08-23 2010-08-29


Kind regards
     Enrico

> Thanks again for your time, ideas and help!
>
> Best,
> Vero
>
> 2016-09-08 8:20 GMT-03:00 Luisfo <luisfo89 at yahoo.es>:
>
>     Dear Veronica,
>    
>     Here there's a way of doing what you requested.
>    
>     library("lubridate")
>     # your date '2010-08-21' as Date object
>     dd <- as.Date(strptime("2010-08-21", format="%Y-%m-%d", tz="GMT"))
>     # take the first day of the year as Date object, i.e. 2010-01-01 in our example
>     ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"), format="%Y-%m-%d", tz="GMT"))
>     # the start and end dates
>     bound.dates <- ref.date + 7 * (week(dd)-1) + c(0,6)
>    
>     I hope you find it useful.
>    
>     Best,
>    
>     Luisfo Chiroque
>     PhD Student | PhD Candidate
>     IMDEA Networks Institute
>     http://fourier.networks.imdea.org/people/~luis_nunez/
>    
>     On 09/08/2016 12:13 PM, Veronica Andreo wrote:
>    
>         Hello list,
>         
>         Is there a quick way to get start and end date (%Y-%m-%d) from ISO
>         weeks if I only have dates?
>         
>         For example, I have this date in which some event happened:
>         "2010-08-21". Not only I want the ISO week, which I can obtain either
>         with isoweek (lubridate) or ISOweek (ISOweek), but I want the start
>         and end date of that ISO week.
>         
>         Do I need to print all ISO weeks from the period of interest and
>         sample there for start and end date? Or is there a better way to do
>         that?
>         
>         Thanks a lot in advance!
>         
>         Best,
>         Veronica
>

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From HDoran at air.org  Thu Sep  8 15:53:41 2016
From: HDoran at air.org (Doran, Harold)
Date: Thu, 8 Sep 2016 13:53:41 +0000
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <94068da5-e33b-846d-6762-eae278971a04@yorku.ca>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
	<94068da5-e33b-846d-6762-eae278971a04@yorku.ca>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860135819D37@DC1VEX10MB01.air.org>

I'm trying the example on Hadley's page. I save the following into a file called "test.R"

#' Add together two numbers.
#' 
#' @param x A number.
#' @param y A number.
#' @return The sum of \code{x} and \code{y}.
#' @examples
#' add(1, 1)
#' add(10, 1)
add <- function(x, y) {
  x + y
}

Then from the R workspace I try

> document()
Error: Could not find package root.

And also
> document('path\\to\\file\\test.R')

And gives same error


Below is my session information.


> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] devtools_1.12.0

loaded via a namespace (and not attached):
[1] magrittr_1.5   tools_3.3.1    withr_1.0.2    roxygen2_5.0.1 Rcpp_0.12.7   
[6] memoise_1.0.0  stringi_1.1.1  stringr_1.1.0  digest_0.6.10

-----Original Message-----
From: Michael Friendly [mailto:friendly at yorku.ca] 
Sent: Thursday, September 08, 2016 9:19 AM
To: Doran, Harold <HDoran at air.org>; r-help at r-project.org
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>
Subject: Re: R-specific Software Requirement Specification

You might also or instead look at the roxygen way of doing things, which maps to Rd files, but are much easier to write. In R Studio, Code ->  Insert Roxygen skeleton does this for you from an existing function.  See: http://r-pkgs.had.co.nz/man.html

#' title goes here
#'
#' description goes here
#'
#' @param p1	desc of p1
#' @param p2
#' @param ...
#' @return
#' @export
#' @imports
#' @author
#' @seealso
#' @examples
#' example lines

foo <- function (p1, p2, ... ) {

}


On 9/7/2016 12:46 PM, Duncan Murdoch wrote:
> On 07/09/2016 11:35 AM, Doran, Harold wrote:
>> I'm building a large program with many different people contributing 
>> to the coding in R and so it needs a well-articulated design spec. 
>> The program will have many different functions that must interact 
>> with each other, but the individual functions will be written by 
>> different people.
>>
>> I'm curious if anyone has an R-specific SRS document to share that 
>> they have used for a similar purpose listing the objectives for each 
>> function, class definition, generics, what the function inherits 
>> from, and so on, or perhaps even a useful template for such work.
>
> The Rd help pages do some of this.  They aren't so good at describing 
> the class hierarchy but are good at specifying individual functions.
>
> Duncan Murdoch
>


From jdnewmil at dcn.davis.ca.us  Thu Sep  8 16:05:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Sep 2016 07:05:29 -0700
Subject: [R] CopyDetect Packgace
In-Reply-To: <CAGGEV7NOhAO-wHrka8buRdb=0RdVO=BpEQtHi_avqpn--cfQ8w@mail.gmail.com>
References: <CAGGEV7NLVpntNiWmfMPCZXa2OTutm_1vWXd8bnAfmATxbj1t6w@mail.gmail.com>
	<CAGGEV7NOhAO-wHrka8buRdb=0RdVO=BpEQtHi_avqpn--cfQ8w@mail.gmail.com>
Message-ID: <91AA4CBE-282B-40D4-80D7-3E3DFF07CD6A@dcn.davis.ca.us>

Read the Posting Guide mentioned at the bottom of this message. 

Learn how to pose a question online. [1]

Post using plain text format so your code doesn't get damaged by the HTML formatting. 

[1] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On September 8, 2016 5:50:43 AM PDT, Ahmad Nursalim <ceritaahmad at gmail.com> wrote:
>Dear All
>x <- CopyDetect2 (data = data.abcd,
>                          item.par = slopintrc,
>                          pair = c (pairs [i, 1], pairs [i, 2]),
>                          options = c ("A", "B", "C", "D", "E"))
>
>What is the mean pair = c (pairs [i, 1], pairs [i, 2]),
>
>Pleas Help Me
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Thu Sep  8 16:15:13 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 8 Sep 2016 10:15:13 -0400
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135819D37@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
	<94068da5-e33b-846d-6762-eae278971a04@yorku.ca>
	<B08B6AF0CF8CA44F81B9983EEBDCD6860135819D37@DC1VEX10MB01.air.org>
Message-ID: <6127f6d2-2348-4175-2e68-e0f604cd77a6@yorku.ca>

devtools::document() is meant to be used within an R **package**, not 
for a standalone file.
Try devtools::create() first.

But at any rate, roxygen format seems to answer your question about how 
to describe the
specifications for a collection of functions written by different 
people.  Translation to .Rd
is not essential for this purpose.

Create a package, put it on github, and away you go.

On 9/8/2016 9:53 AM, Doran, Harold wrote:
> Then from the R workspace I try
>
>> >document()
> Error: Could not find package root.
>
> And also
>> >document('path\\to\\file\\test.R')
> And gives same error


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Sep  8 16:25:13 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 8 Sep 2016 14:25:13 +0000
Subject: [R] Resample with replacement to produce many
 rarefaction	curves with same number of samples
In-Reply-To: <F3C6C39F-A477-4CE8-B381-FEC1000AAC47@collocations.de>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
	<F3C6C39F-A477-4CE8-B381-FEC1000AAC47@collocations.de>
Message-ID: <676af1c0967d4a59acae8ea6ce853bb5@exch-2p-mbx-w2.ads.tamu.edu>

Sampling without replacement will never find more species than there are in your original sample either! 

Sampling without replacement treats the sample as the population for the purposes of estimating the outcomes at smaller sample sizes. Sampling with replacement (the same as bootstrapping) treats the sample as one possible outcome of a larger population at that sample size. 

There is another consideration. A zero value means different things at different sample sizes. At sample size 10, it means approximately less than 10%, but at sample size 100, it means approximately less than 1%, and so on. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefan Evert
Sent: Thursday, September 8, 2016 7:46 AM
To: Nick Pardikes
Cc: R-help Mailing List
Subject: Re: [R] Resample with replacement to produce many rarefaction curves with same number of samples


> On 7 Sep 2016, at 00:07, Nick Pardikes <nickpardikes at gmail.com> wrote:
> 
> Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).

Are you sure it makes sense to resample with replacement?  This will systematically underestimate the number of species at a given sample size (because of the artificial repetition) and will never find more species than there are in your original sample.

Best,
Stefan
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Sep  8 16:25:41 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 8 Sep 2016 14:25:41 +0000
Subject: [R] How to interpret lm's coefficients?
In-Reply-To: <7B1F2208-B3B6-4D24-88F0-DF377F74127F@kapsi.fi>
References: <7B1F2208-B3B6-4D24-88F0-DF377F74127F@kapsi.fi>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503C086@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matti
> Viljamaa
> Sent: Thursday, September 8, 2016 2:44 PM
> To: r-help at R-project.org
> Subject: [R] How to interpret lm's coefficients?
>
> I?m trying to understand how to interpret the return values, specifically
> ?Coefficients:?, of R?s lm function. I?m using it with a dichotomic predictor
> (mom_hs).
>
> lm(data$kid_score ~ data$mom_hs) returns
>
> Coefficients:
> #   (Intercept)  data$mom_hs
> # 77.55        11.77
>
> I read that the (Intercept) value is the ?y-intercept? value b, i.e. the y value
> where the line intercept the y-axis.
>
> The second value is the value of the term m (or ?slope?) in the equation of a
> line y=mx+b.
>
> However,
>
> These two numbers also have the following interpretations:
>
> b or (Intercept) value is the same as:
> The mean of those data$kid_score that have data$mom_hs == 0.
> Why is this a valid interpretation?

Well, you should rather to look into some statistical textbook. E.g.
Practical Regression and Anova using R,  Julian J. Faraway
or
SimpleR, J. Verzani

The explanation is not for few lines of plain text short mail.

But maybe others will disagree.

Cheers
Petr

PS.
Or you can try to find an interpretation from plots yourself.

plot(data$kid_score ~ data$mom_hs)
abline( lm(data$kid_score ~ data$mom_hs)



>
> m or data$mom_hs value is the same as:
> The difference of means between those data$kid_score that have
> data$mom_hs == 1 and those data$kid_score that have data$mom_hs == 0.
> Why is this a valid interpretation?
>
> Can someone explain?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Thu Sep  8 16:31:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 8 Sep 2016 10:31:56 -0400
Subject: [R] R-specific Software Requirement Specification
In-Reply-To: <6127f6d2-2348-4175-2e68-e0f604cd77a6@yorku.ca>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135817B33@DC1VEX10MB01.air.org>
	<ed125138-40db-bf6f-f227-088b64d60568@gmail.com>
	<94068da5-e33b-846d-6762-eae278971a04@yorku.ca>
	<B08B6AF0CF8CA44F81B9983EEBDCD6860135819D37@DC1VEX10MB01.air.org>
	<6127f6d2-2348-4175-2e68-e0f604cd77a6@yorku.ca>
Message-ID: <63c98200-f4a9-91c8-936b-9f6c1be43866@gmail.com>

On 08/09/2016 10:15 AM, Michael Friendly wrote:
> devtools::document() is meant to be used within an R **package**, not 
> for a standalone file.
> Try devtools::create() first.
>
> But at any rate, roxygen format seems to answer your question about 
> how to describe the
> specifications for a collection of functions written by different 
> people.  Translation to .Rd
> is not essential for this purpose.

I would say that separate Rd files would be preferable here.  If Harold 
writes the spec and puts it in Roxygen comments in a .R file, then 
Michael writes the function to match the comments, Michael may 
accidentally edit the Roxygen comments at the same time.  It's more work 
for Harold to notice that his spec has been changed than if it is in a 
separate file.

Duncan Murdoch
>
> Create a package, put it on github, and away you go.
>
> On 9/8/2016 9:53 AM, Doran, Harold wrote:
>> Then from the R workspace I try
>>
>>> >document()
>> Error: Could not find package root.
>>
>> And also
>>> >document('path\\to\\file\\test.R')
>> And gives same error
>
>
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>


From bgunter.4567 at gmail.com  Thu Sep  8 16:48:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Sep 2016 07:48:30 -0700
Subject: [R] Fwd: hello i have a question on music analysis and mathematical
 synthesis related to r code
In-Reply-To: <F0CFC4DE-A084-4B3F-B34E-B67D136F930A@gmail.com>
References: <0953313E-765F-446B-8755-EF06BEDD0D5E@gmail.com>
	<CAGxFJbT8F+oR24qoT=283ayBS5BQ6SX7DSg5_nsN2u7bPRg_rQ@mail.gmail.com>
	<F0CFC4DE-A084-4B3F-B34E-B67D136F930A@gmail.com>
Message-ID: <CAGxFJbRsCUPyCa15ONnYWQt5d1pQCY5p8Mbb+vQJysHk2dihoQ@mail.gmail.com>

Darth:

Please always cc the list if it is not a strictly personal
communication. The information you provide may be relevant and allow
others to help you.

Note also: Jim's suggestion of tuneR was a top hit from the google
search I suggested.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



---------- Forwarded message ----------
From: darth brando <darth.brando6 at gmail.com>
Date: Thu, Sep 8, 2016 at 12:16 AM
Subject: Re: [R] hello i have a question on music analysis and
mathematical synthesis related to r code
To: Bert Gunter <bgunter.4567 at gmail.com>


I've tried google to not much avail I'm afraid. Unless you can point
me in a more specific direction on how to browse the R category stuff
(like i mentioned I'm a very noobs user).

Unfortunately due to google's reliance on page rank; it gives you the
most popular most linked and most viewed pages and not the most
accurate or relevant.

Most of the tutorial/how to/help/ fix articles I've found are on how
to analyze individual tracks and correlate with other analyzed packets
but manually and one by one.

I wish to analyze an entire library to discover patterns and
algorithms within to then create an algorithm which applies those
patterns on permutation to near infinitely execute algorithmic
writing/reinterpretation of the found patterns and data sets.

In short;

I have a library of X amount of tracks,

I wish R code to find all:

1) tempo modulation patterns correlated to the pattern of used scales
and sequences to initiate those tempo modulations

2) the pitch an note pattern motifs for arpeggios used within that
data set and the algorithmic range they create when correlated

3) the min/max range on pitch, note, riffs and ad-lib/ step aka
extraneous added sfx (the range of the outliers and the pattern
algorithm of them within the library)

4) the pattern of min/max range of phrases/bars within the library

I will then essentially use this data and plug the parameters into a
synthesizer emulator application which will infinitely (until turned
off) attempt to emulate the "type" of music the library represents
using algorithms to continuously write sound data uniquely within the
4) pattern parameters above that I mentioned.

so far nothing I have found other than the data on R code logarithms
on chaos theory bifurcation model graphing comes close to the scope I
need help with.

> On Sep 8, 2016, at 02:51, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Search on the Internet!
>
> "Analyze music in R" had hits for several R packages that seemed like
> they might be relevant.
>
> Apologies if you've already done this and found mothing to meet your needs.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>> On Wed, Sep 7, 2016 at 10:57 PM, darth brando <darth.brando6 at gmail.com> wrote:
>> Apologies for the long title but it is semi specific a topic and yes I am a noobs user to the system. I have read the guide and will attempt to adhere to the guide in this process and I do apologize in advance if I fail to do so, this is my first time here.
>>
>> To the point; firstly version:
>>
>> I have windows 7 64 bit OS, I'm going to be working with most current up to date version of R code for that OS with optional plug ins as needed, I am going to be using R code in conjunction with Fruity Loop Studio, dosbox/visual studio, and both synthesizer plug ins for Fruity Loop Studio and a physical soundblaster sound card in my alienware 15 2015 version as well as possibly a few emulator or OS instances for retro hardware to experiment with. Its a lot of software to take in yea, some I know by heart others like R Code I am a noob at.
>>
>> Now that the toolbox of software is out of the way; my Question:
>>
>> Music is largely mathematically based, R Code is perfect for analyzing very large sets of data, naturally I saw some potential and wondered about the specifics of the type of application which follows.
>>
>> I wish to use R Code to analyze portions of my personal library of music in order to discover the main sets of underlying patterns within that portion of my music library. I then wish to utilize patterns discovered to create a program which using proper algorithms set to those patterns to digitally synthesize music which conforms to those patterns but that would create said music automatically and potentially non stop; as in it does not stop writing the music and playing it until you turn it off. However; I do not wish this program to create a few tracks and play it on a loop, yes due to the patterns and the algorithms, certain bars and phrases will inevitably repeat but that doesn't mean just loop the same X amount of minutes.
>>
>> Before I fall off tangent and go into semantics, I am asking help as;
>>
>> The Music Genome Project
>> and Sony's musical mood auto playlist generator
>>
>> are similar to this underlying theme but have gone down the road of separate applications and to the most important part:
>>
>> I do not wish to infringe or plagiarize or violate copyright or IP on others said similar themed projects/products.
>>
>> my idea;
>>
>> use themes and patterns present in a selection of music to then create a potentially infinite and unique mathematical auto play of algorithmically and digitally created music
>>
>> what I need help with;
>>
>> inputting a large data set of audio files into an R Code application for pattern and algorithm analysis with out infringing on open, finished or ongoing projects.
>>
>> I do not need help with porting the algorithm and pattern generator to an audio synthesis program--> that I  am familiar with how to do.
>>
>> I do not need help with making the end result potentially infinitely continued computation of algorithms within the found and set pattern parameters---> that I also know how to do.
>>
>> I apologize for the long message and it's redundancies, it is simply my first time here and I wanted to be thorough.
>>
>> Thank You for Reading!
>>
>> Any advice on this will be supremely appreciated!
>>
>> ---Darth Brando
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Sep  8 17:08:06 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 8 Sep 2016 15:08:06 +0000
Subject: [R] Resample with replacement to produce many
 rarefaction	curves with same number of samples
In-Reply-To: <676af1c0967d4a59acae8ea6ce853bb5@exch-2p-mbx-w2.ads.tamu.edu>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
	<F3C6C39F-A477-4CE8-B381-FEC1000AAC47@collocations.de>
	<676af1c0967d4a59acae8ea6ce853bb5@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <376d47279c6347e38e1ab487d973e41f@exch-2p-mbx-w2.ads.tamu.edu>

One way around this would be to use multinomial sampling, but as Stefan indicated, the maximum number of species at any size will, of course be 40 (in your example):

> set.seed(42)
> # Generate one sample
> census <- round(rlnorm(40))
> sum(census) # Sample size
[1] 76
> sum(as.logical(census)) # No of species present
[1] 31
> 
> # Create probabilities
> census.adj <- census
> # Add .5 to each 0 value
> census.adj[census.adj==0] <- .5
> census.adj <- census.adj/sum(census.adj)
> 
> pcensus <- rmultinom(50, 150, census.adj)
> 
> Species <- apply(pcensus, 2, function(x) sum(as.logical(x)))
> quantile(Species)
  0%  25%  50%  75% 100% 
  29   33   34   36   38

So projecting a sample of 76 to 150 gives an estimated median of 34 species.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Thursday, September 8, 2016 9:25 AM
To: Stefan Evert; Nick Pardikes
Cc: R-help Mailing List
Subject: Re: [R] Resample with replacement to produce many rarefaction curves with same number of samples

Sampling without replacement will never find more species than there are in your original sample either! 

Sampling without replacement treats the sample as the population for the purposes of estimating the outcomes at smaller sample sizes. Sampling with replacement (the same as bootstrapping) treats the sample as one possible outcome of a larger population at that sample size. 

There is another consideration. A zero value means different things at different sample sizes. At sample size 10, it means approximately less than 10%, but at sample size 100, it means approximately less than 1%, and so on. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefan Evert
Sent: Thursday, September 8, 2016 7:46 AM
To: Nick Pardikes
Cc: R-help Mailing List
Subject: Re: [R] Resample with replacement to produce many rarefaction curves with same number of samples


> On 7 Sep 2016, at 00:07, Nick Pardikes <nickpardikes at gmail.com> wrote:
> 
> Is there any way to use rarecurve to resample a community (row) with
> replacement the same number of times for all 50 communities? With
> replacement is important because the communities differ greatly in their
> size (number of species).

Are you sure it makes sense to resample with replacement?  This will systematically underestimate the number of species at a given sample size (because of the artificial repetition) and will never find more species than there are in your original sample.

Best,
Stefan
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Sep  8 16:59:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Sep 2016 07:59:27 -0700
Subject: [R] How to interpret lm's coefficients?
In-Reply-To: <7B1F2208-B3B6-4D24-88F0-DF377F74127F@kapsi.fi>
References: <7B1F2208-B3B6-4D24-88F0-DF377F74127F@kapsi.fi>
Message-ID: <CAGxFJbT+NMAN7Y6rfiGAu3Sjz4JbEghgNGpdOnQpbOznpp8w3Q@mail.gmail.com>

Petr Pikal said:

"The explanation is not for few lines of plain text short mail.

But maybe others will disagree."

Not I -- you should consult your teachers or texts (as Petr said) for
basic statistical questions.

I'll add a nugget to Petr's reply, however: it is very often the case
(for correlated regressors/covariates) that individual coefficients
cannot and should not be interpreted -- the "fit" is merely a
prediction engine.''

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 8, 2016 at 5:43 AM, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> I?m trying to understand how to interpret the return values, specifically ?Coefficients:?, of R?s lm function. I?m using it with a dichotomic predictor (mom_hs).
>
> lm(data$kid_score ~ data$mom_hs) returns
>
> Coefficients:
> #   (Intercept)  data$mom_hs
> # 77.55        11.77
>
> I read that the (Intercept) value is the ?y-intercept? value b, i.e. the y value where the line intercept the y-axis.
>
> The second value is the value of the term m (or ?slope?) in the equation of a line y=mx+b.
>
> However,
>
> These two numbers also have the following interpretations:
>
> b or (Intercept) value is the same as:
> The mean of those data$kid_score that have data$mom_hs == 0.
> Why is this a valid interpretation?
>
> m or data$mom_hs value is the same as:
> The difference of means between those data$kid_score that have data$mom_hs == 1
> and those data$kid_score that have data$mom_hs == 0.
> Why is this a valid interpretation?
>
> Can someone explain?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r-packages at r-project.org  Wed Sep  7 14:40:01 2016
From: r-packages at r-project.org (brodie gaslam via R-packages)
Date: Wed, 7 Sep 2016 12:40:01 +0000
Subject: [R] [R-pkgs] diffobj released to CRAN
References: <1718206551.1071563.1473252001303.ref@mail.yahoo.com>
Message-ID: <1718206551.1071563.1473252001303@mail.yahoo.com>

diffobj provides tools to compare the visual representation of R objects using the Myer's diff algorithm:

## Example:
> mx1 <- matrix(1:9, 3)
> mx2 <- mx1[-2,]
> diffPrint(mx1, mx2, format="raw")
< mx1                  > mx2
@@ 1,4 @@              @@ 1,3 @@
.       [,1] [,2] [,3]         [,1] [,2] [,3]
. [1,]    1    4    7    [1,]    1    4    7
< [2,]    2    5    8  ~
. [3,]    3    6    9    [2,]    3    6    9

This is similar to `tools::Rdiff`, but is easier to use directly with R objects, has colorized output if your terminal supports it, has semantic-aware handling of the text output of R objects, and does not require the GNU diff utility to be available on the system.

See the vignette for more details <https://cran.r-project.org/web/packages/diffobj/vignettes/diffobj.html>, and the Github page to submit issues <https://github.com/brodieG/diffobj>.

Many thanks to Uwe Ligges and Kurt Hornik for their patience with my first CRAN submission.

Brodie Gaslam.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From lawrence.michael at gene.com  Wed Sep  7 16:06:20 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 7 Sep 2016 07:06:20 -0700
Subject: [R] The R Journal, Volume 8, Issue 1
Message-ID: <CAOQ5NydXL7bbvFGMFOPR5wyVm5whZ7S8RNfYXO0MyxP5rBVYiA@mail.gmail.com>

Dear all,

The latest issue of The R Journal is now available at
http://journal.r-project.org/archive/2016-1/

Many thanks to all contributors.

Michael Lawrence

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From stefanML at collocations.de  Thu Sep  8 18:07:14 2016
From: stefanML at collocations.de (Stefan Evert)
Date: Thu, 8 Sep 2016 18:07:14 +0200
Subject: [R] Resample with replacement to produce many
	rarefaction	curves with same number of samples
In-Reply-To: <676af1c0967d4a59acae8ea6ce853bb5@exch-2p-mbx-w2.ads.tamu.edu>
References: <CABh5y=4w37kPdek8qvme27FKjx+4Kx6BpMFOQEFvp2SJGQi1Dg@mail.gmail.com>
	<F3C6C39F-A477-4CE8-B381-FEC1000AAC47@collocations.de>
	<676af1c0967d4a59acae8ea6ce853bb5@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <4C3A4406-4E8D-4658-BC17-58F3D0752F70@collocations.de>


> On 8 Sep 2016, at 16:25, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Sampling without replacement treats the sample as the population for the purposes of estimating the outcomes at smaller sample sizes. Sampling with replacement (the same as bootstrapping) treats the sample as one possible outcome of a larger population at that sample size. 

But the resamples aren't actually independent samples from the underlying population, and in contrast to the usual applications of bootstrapping they don't give a good approximation of independent samples if you look at type ("species") counts.

In my understanding ? which may be incomplete ? bootstrapping works for a test statistic computed from the measurements of a single numeric random variable (or perhaps several r.v.) in an i.i.d. sample.  The type count cannot be expressed as such a test statistic, hence we get the underestimation bias from sampling with replacement.

In NLP, we often use parametric power-law models of the population in order to extrapolate type counts (e.g. using this implementation http://zipfr.r-forge.r-project.org), but this implies strong (and often inappropriate) assumptions about the population.

Best,
Stefan


From davidsmi at microsoft.com  Thu Sep  8 22:27:59 2016
From: davidsmi at microsoft.com (David Smith)
Date: Thu, 8 Sep 2016 20:27:59 +0000
Subject: [R] Revolutions blog: August 2016 roundup
Message-ID: <CY1PR0301MB2105D6A04C2CE57D631329E2C8FB0@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of August:

An amusing short video extols the benefits of reproducible research with R:
http://blog.revolutionanalytics.com/2016/08/a-reproducibility-horror-story.html

A guide to implementing a churn model for mobile phone customers with Microsoft R Services:
http://blog.revolutionanalytics.com/2016/08/telco-customer-churn-with-r-in-sql-server-2016.html

Computerworld's Sharon Machlis presents 5 data visualizations each using 5 lines of R code:
http://blog.revolutionanalytics.com/2016/08/five-great-charts-in-5-lines-of-r-code-each.html

A five-part video series introducing Microsoft R Services:
http://blog.revolutionanalytics.com/2016/08/introduction-to-microsoft-r-server.html

David Robinson analyzes the sentiment of Donald Trump's (and staffers') tweets with R
http://blog.revolutionanalytics.com/2016/08/sentiment-analysis-of-trumps-tweets-with-r.html

Microsoft R Open 3.3.1 is now available for Windows, Mac and Linux:
http://blog.revolutionanalytics.com/2016/08/microsoft-r-open-331-now-available-for-windows-mac-and-linux.html

When to use (and when not to use) dual Y axes on time series charts:
http://blog.revolutionanalytics.com/2016/08/dual-axis-time-series.html

You can now use R from PowerBI to import, transform and visualize data:
http://blog.revolutionanalytics.com/2016/08/powerbi-and-r.html

An in-depth look at deep learning frameworks: Part 1
http://blog.revolutionanalytics.com/2016/08/deep-learning-part-1.html and Part 2
http://blog.revolutionanalytics.com/2016/08/deep-learning-part-2.html

The Data Science Summit (Sep 26-27 in Atlanta) features several R-related talks and a keynote presentation by Edward
Tufte http://blog.revolutionanalytics.com/2016/08/tufte-keynote.html

The jailbreakr package locates and extracts sub-tables from messy spreadsheets:
http://blog.revolutionanalytics.com/2016/08/jailbreakr.html

Using R to extract information from a PDF table to create a map of dispensary locations:
http://blog.revolutionanalytics.com/2016/08/dispensaries.html

Student debt is rising quickly in the US, as shown using the animation package:
http://blog.revolutionanalytics.com/2016/08/student-debt.html

A guide to tuning Apache Spark to optimize computations with Microsoft R Server:
http://blog.revolutionanalytics.com/2016/08/tuning-apache-spark.html

A review of several R packages providing access to online data sources:
http://blog.revolutionanalytics.com/2016/08/r-packages-data-access.html

A cheat-sheet for the dplyrXdf package:
http://blog.revolutionanalytics.com/2016/08/new-cheat-sheet-for-the-dplyrxdf-package.html

A beautiful example of creating publication-ready interactive graphics with R:
http://blog.revolutionanalytics.com/2016/08/interactive-illustrator-quality-graphics-with-r.html

A guide to simulating from the bivariate Normal distribution with R:
http://blog.revolutionanalytics.com/2016/08/simulating-form-the-bivariate-normal-distribution-in-r-1.html

Where to find resources previously available on the now-decommissioned inside-r.org:
http://blog.revolutionanalytics.com/2016/08/farewell-inside-rorg.html

An introduction to ROC curves in R: http://blog.revolutionanalytics.com/2016/08/roc-curves-in-two-lines-of-code.html

Azure ML Studio now supports Microsoft R Open and Python 2 and 3:
http://blog.revolutionanalytics.com/2016/08/ml-studio-mro-python3.html

General interest stories (not related to R) in the past month included: the font of the Stranger Things titles
(http://blog.revolutionanalytics.com/2016/08/because-its-friday-the-font-of-stranger-things.html), gravity waves
(http://blog.revolutionanalytics.com/2016/08/because-its-friday-lisa.html), a first-squirrel view
(http://blog.revolutionanalytics.com/2016/08/because-its-friday-the-squirrels-pov.html), and history set to 70's pop
(http://blog.revolutionanalytics.com/2016/08/because-its-friday-the-knack-to-learning-history.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From suttoncarl at ymail.com  Fri Sep  9 00:57:08 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Thu, 8 Sep 2016 22:57:08 +0000 (UTC)
Subject: [R] with and evaluation
References: <2110976318.1457480.1473375428410.ref@mail.yahoo.com>
Message-ID: <2110976318.1457480.1473375428410@mail.yahoo.com>

Hi
I have doing the R-exercises to improve my R programming capabilities. ?Data.frame exercise 4 showed me that I have ?a language problem. ?Here's the problem and my "solution".
# ?Exercise 4# ?Create a simple data frame from 3 vectors. Order the entire data frame by the# ?first column.df2 <- data.frame(a = 5:1,b = letters[1:5], c = runif(5))order(df2$a)?Naturally the order function did nothing. ?
Per "help"Description
order returns a permutation which rearranges its first argument into ascending or descending order, breaking ties by further arguments. sort.list is the same, using only one argument.See the examples for how to use these functions to sort data frames, etc.
Usage
order(..., na.last = TRUE, decreasing = FALSE,? ? ? method = c("shell", "radix"))
sort.list(x, partial = NULL, na.last = TRUE, decreasing = FALSE,? ? ? ? ? method = c("shell", "quick", "radix"))Arguments
... a sequence of numeric, complex, character or logical vectors, all of the same length, or a classed R object.
Well, doesn't ... mean any legal object? ?I gave it a legal object and got nada.And the answer absolutely has me screaming "Say What"df2[with(df2,order(a)),]

What's with "with? ?It is one function I do not use because I find it incomprehensible. ?To witEvaluate an R expression in an environment constructed from data, possibly modifying (a copy of) the original data.

First of all, if I'm not modifying data (or as a subset activity creating data), why an I doing whatever it is I'm doing? ("possibly modifying (a copy of) the original data.")
Evaluate. ?According to the thesarus A) assess(v), b) appraise, c) gage.
OK, am I in a safe area? ?I'll evaluate that. ?Do I desire future social contact with this person? ?I'll evaluate that.In no way do I ever evaluate an equation. ?I may attempt to solve it. ?I may do a computer program to do the calculations and return a result. ?I will probably evaluate the result as to whether or not it helps solve the problem. ?Think in terms of an income tax return. ?But evaluate an R expression? ?No clue what that might mean.
The remainder of the definition is also obtuse. ?an R expression in an environment constructed from data. ?Why would one make an environment without data? ?Obviously I am missing the point. ?My own created function makes a new environment, but I only created it to crunch numbers. ?If it doesn't crunch numbers it's useless.
The point is, I do not understand the definition of "with" and thus have no idea how to use it. ?I guess computerese is analogous to taxlawese. ?Familiar words have entirely different meanings.
Carl Sutton CPA

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep  9 01:07:54 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 8 Sep 2016 19:07:54 -0400
Subject: [R] with and evaluation
In-Reply-To: <2110976318.1457480.1473375428410@mail.yahoo.com>
References: <2110976318.1457480.1473375428410.ref@mail.yahoo.com>
	<2110976318.1457480.1473375428410@mail.yahoo.com>
Message-ID: <1b5f2204-15f4-723f-724d-d6fb94b40359@gmail.com>

On 08/09/2016 6:57 PM, Carl Sutton via R-help wrote:
> Hi
> I have doing the R-exercises to improve my R programming capabilities.  Data.frame exercise 4 showed me that I have  a language problem.  Here's the problem and my "solution".
> #  Exercise 4#  Create a simple data frame from 3 vectors. Order the entire data frame by the#  first column.df2 <- data.frame(a = 5:1,b = letters[1:5], c = runif(5))order(df2$a) Naturally the order function did nothing.
> Per "help"Description
> order returns a permutation which rearranges its first argument into ascending or descending order, breaking ties by further arguments. sort.list is the same, using only one argument.See the examples for how to use these functions to sort data frames, etc.
> Usage
> order(..., na.last = TRUE, decreasing = FALSE,      method = c("shell", "radix"))
> sort.list(x, partial = NULL, na.last = TRUE, decreasing = FALSE,          method = c("shell", "quick", "radix"))Arguments
> ... a sequence of numeric, complex, character or logical vectors, all of the same length, or a classed R object.
> Well, doesn't ... mean any legal object?  I gave it a legal object and got nada.And the answer absolutely has me screaming "Say What"df2[with(df2,order(a)),]
>
> What's with "with?  It is one function I do not use because I find it incomprehensible.  To witEvaluate an R expression in an environment constructed from data, possibly modifying (a copy of) the original data.
>
> First of all, if I'm not modifying data (or as a subset activity creating data), why an I doing whatever it is I'm doing? ("possibly modifying (a copy of) the original data.")
> Evaluate.  According to the thesarus A) assess(v), b) appraise, c) gage.
> OK, am I in a safe area?  I'll evaluate that.  Do I desire future social contact with this person?  I'll evaluate that.In no way do I ever evaluate an equation.  I may attempt to solve it.  I may do a computer program to do the calculations and return a result.  I will probably evaluate the result as to whether or not it helps solve the problem.  Think in terms of an income tax return.  But evaluate an R expression?  No clue what that might mean.
> The remainder of the definition is also obtuse.  an R expression in an environment constructed from data.  Why would one make an environment without data?  Obviously I am missing the point.  My own created function makes a new environment, but I only created it to crunch numbers.  If it doesn't crunch numbers it's useless.
> The point is, I do not understand the definition of "with" and thus have no idea how to use it.  I guess computerese is analogous to taxlawese.  Familiar words have entirely different meanings.
> Carl Sutton CPA
>
> 	[[alternative HTML version deleted]]

This is really hard to read, because you posted in HTML.  If you don't 
get a useful answer, please try again in plain text.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Fri Sep  9 04:17:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Sep 2016 19:17:39 -0700
Subject: [R] with and evaluation
In-Reply-To: <1b5f2204-15f4-723f-724d-d6fb94b40359@gmail.com>
References: <2110976318.1457480.1473375428410.ref@mail.yahoo.com>
	<2110976318.1457480.1473375428410@mail.yahoo.com>
	<1b5f2204-15f4-723f-724d-d6fb94b40359@gmail.com>
Message-ID: <E05D1565-67B5-4E19-994E-86B31DD22FCE@dcn.davis.ca.us>

You don't say where any of this code you are looking at came from, but I suspect [1]. If you feel the author of that site is failing to explain their answers sufficiently, please communicate that to them, not us. 

I agree that the documentation file for with() is rather opaque to a beginner and could be extended, but the jargon is referring to some valuable concepts that you should find a way to learn about (e.g. [2]). 

As Duncan pointed out,  most of your diatribe was destroyed by your use of HTML format email, so if you can fix that problem and pose your questions calmly and with complete context in the email then someone might be interested in discussing them further with you. 

[1] http://r-exercises.com/
[2] http://r-adv.had.co.nz
-- 
Sent from my phone. Please excuse my brevity.

On September 8, 2016 4:07:54 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 08/09/2016 6:57 PM, Carl Sutton via R-help wrote:
>> Hi
>> I have doing the R-exercises to improve my R programming
>capabilities.  Data.frame exercise 4 showed me that I have  a language
>problem.  Here's the problem and my "solution".
>> #  Exercise 4#  Create a simple data frame from 3 vectors. Order the
>entire data frame by the#  first column.df2 <- data.frame(a = 5:1,b =
>letters[1:5], c = runif(5))order(df2$a) Naturally the order function
>did nothing.
>> Per "help"Description
>> order returns a permutation which rearranges its first argument into
>ascending or descending order, breaking ties by further arguments.
>sort.list is the same, using only one argument.See the examples for how
>to use these functions to sort data frames, etc.
>> Usage
>> order(..., na.last = TRUE, decreasing = FALSE,      method =
>c("shell", "radix"))
>> sort.list(x, partial = NULL, na.last = TRUE, decreasing = FALSE,     
>    method = c("shell", "quick", "radix"))Arguments
>> ... a sequence of numeric, complex, character or logical vectors, all
>of the same length, or a classed R object.
>> Well, doesn't ... mean any legal object?  I gave it a legal object
>and got nada.And the answer absolutely has me screaming "Say
>What"df2[with(df2,order(a)),]
>>
>> What's with "with?  It is one function I do not use because I find it
>incomprehensible.  To witEvaluate an R expression in an environment
>constructed from data, possibly modifying (a copy of) the original
>data.
>>
>> First of all, if I'm not modifying data (or as a subset activity
>creating data), why an I doing whatever it is I'm doing? ("possibly
>modifying (a copy of) the original data.")
>> Evaluate.  According to the thesarus A) assess(v), b) appraise, c)
>gage.
>> OK, am I in a safe area?  I'll evaluate that.  Do I desire future
>social contact with this person?  I'll evaluate that.In no way do I
>ever evaluate an equation.  I may attempt to solve it.  I may do a
>computer program to do the calculations and return a result.  I will
>probably evaluate the result as to whether or not it helps solve the
>problem.  Think in terms of an income tax return.  But evaluate an R
>expression?  No clue what that might mean.
>> The remainder of the definition is also obtuse.  an R expression in
>an environment constructed from data.  Why would one make an
>environment without data?  Obviously I am missing the point.  My own
>created function makes a new environment, but I only created it to
>crunch numbers.  If it doesn't crunch numbers it's useless.
>> The point is, I do not understand the definition of "with" and thus
>have no idea how to use it.  I guess computerese is analogous to
>taxlawese.  Familiar words have entirely different meanings.
>> Carl Sutton CPA
>>
>> 	[[alternative HTML version deleted]]
>
>This is really hard to read, because you posted in HTML.  If you don't 
>get a useful answer, please try again in plain text.
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Sep  9 02:29:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Sep 2016 17:29:12 -0700
Subject: [R] with and evaluation
In-Reply-To: <2110976318.1457480.1473375428410@mail.yahoo.com>
References: <2110976318.1457480.1473375428410.ref@mail.yahoo.com>
	<2110976318.1457480.1473375428410@mail.yahoo.com>
Message-ID: <CAGxFJbToMevBTyQWUsCgEckDQM3wqJ8HTafyXqAPXvGUYnNshg@mail.gmail.com>

I echo Duncan's plea.

But I can easily resolve one question:

"What's with "with?  It is one function I do not use because I find it
incomprehensible. "

Consider:

## first, clear the workspace, also known as the Global environment
> rm(list=ls())

## now create a data frame (or list or environment or...) containing
objects named "x" and "w"
> d <- data.frame(x=1:3,w=5:7)
 ## now define a different "x" in the workspace
> x <- 4:6
>
> ## The following will produce an error, because there is no "w" in the workspace
> ##
> w
Error: object 'w' not found
>
> ## But this won't, since with() tells it's expression to first search in d.
>
> with(d,w)
[1] 5 6 7
>
> ## similarly
>
> ##error
> x+w
Error: object 'w' not found
>
> ## But
> with(d, x+w)
[1]  6  8 10
>
> ## In general, the second argument of d can be any expression that you could type at the console.
>
> ## If something can't be found in d, it will be looked for in d's "parent" environment, which is more involved than I want to get here. But:
>
> y <- 5
>
> with(d, x+y) ## used x in d, and y in the workspace.
[1] 6 7 8

HTH

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 8, 2016 at 3:57 PM, Carl Sutton via R-help
<r-help at r-project.org> wrote:
> Hi
> I have doing the R-exercises to improve my R programming capabilities.  Data.frame exercise 4 showed me that I have  a language problem.  Here's the problem and my "solution".
> #  Exercise 4#  Create a simple data frame from 3 vectors. Order the entire data frame by the#  first column.df2 <- data.frame(a = 5:1,b = letters[1:5], c = runif(5))order(df2$a) Naturally the order function did nothing.
> Per "help"Description
> order returns a permutation which rearranges its first argument into ascending or descending order, breaking ties by further arguments. sort.list is the same, using only one argument.See the examples for how to use these functions to sort data frames, etc.
> Usage
> order(..., na.last = TRUE, decreasing = FALSE,      method = c("shell", "radix"))
> sort.list(x, partial = NULL, na.last = TRUE, decreasing = FALSE,          method = c("shell", "quick", "radix"))Arguments
> ... a sequence of numeric, complex, character or logical vectors, all of the same length, or a classed R object.
> Well, doesn't ... mean any legal object?  I gave it a legal object and got nada.And the answer absolutely has me screaming "Say What"df2[with(df2,order(a)),]
>
> What's with "with?  It is one function I do not use because I find it incomprehensible.  To witEvaluate an R expression in an environment constructed from data, possibly modifying (a copy of) the original data.
>
> First of all, if I'm not modifying data (or as a subset activity creating data), why an I doing whatever it is I'm doing? ("possibly modifying (a copy of) the original data.")
> Evaluate.  According to the thesarus A) assess(v), b) appraise, c) gage.
> OK, am I in a safe area?  I'll evaluate that.  Do I desire future social contact with this person?  I'll evaluate that.In no way do I ever evaluate an equation.  I may attempt to solve it.  I may do a computer program to do the calculations and return a result.  I will probably evaluate the result as to whether or not it helps solve the problem.  Think in terms of an income tax return.  But evaluate an R expression?  No clue what that might mean.
> The remainder of the definition is also obtuse.  an R expression in an environment constructed from data.  Why would one make an environment without data?  Obviously I am missing the point.  My own created function makes a new environment, but I only created it to crunch numbers.  If it doesn't crunch numbers it's useless.
> The point is, I do not understand the definition of "with" and thus have no idea how to use it.  I guess computerese is analogous to taxlawese.  Familiar words have entirely different meanings.
> Carl Sutton CPA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Sep  9 02:35:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Sep 2016 17:35:18 -0700
Subject: [R] Have help list filters changed recently
Message-ID: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>

To all:

r-help has been holding up a lot of my recent messages: Have there
been any changes to help list filters that caused this? Is there
something I'm doing wrong? -- I have made no changes  that I am aware
of. Here's what I get:

Your mail to 'R-help' with the subject

    Re: [R] with and evaluation [for example]

Is being held until the list moderator can review it for approval.

The reason it is being held:

    The message headers matched a filter rule


Best,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From jax200 at gmail.com  Fri Sep  9 03:20:42 2016
From: jax200 at gmail.com (jax200)
Date: Thu, 8 Sep 2016 18:20:42 -0700
Subject: [R] New installation
In-Reply-To: <1465577653.1844383.633994305.58D1735D@webmail.messagingengine.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
	<CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
	<1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>
	<alpine.LRH.2.20.1606091724070.1083@aeolus.ecy.wa.gov>
	<m2shwlpm2h.fsf@krugs.de>
	<1465577653.1844383.633994305.58D1735D@webmail.messagingengine.com>
Message-ID: <CAN=BHS3573gOfoOOd6DBdsnTFxSFKZw=5voLzWuVm5w_cpfJJA@mail.gmail.com>

Following up on this thread, I went with ubuntu.  All is good....


Many thanks for your responses,

Jack

On Fri, Jun 10, 2016 at 9:54 AM, Leonardo Fontenelle <
leonardof at leonardof.med.br> wrote:

> Em Sex 10 jun. 2016, ?s 03:58, Rainer M Krug escreveu:
> > Clint Bowman <clint at ecy.wa.gov> writes:
> >
> > I am really wondering, why nobody mentioned Ubuntu so far?
> >
> > Ubuntu is a really nice distro, I never had problems with it, many
> > programs are available for Ubuntu, and it is build on Debian
> > (stable). Don't worry about Unity Window manager - there are many other
> > options available (Xubuntu being one of the better known ones - Ubuntu
> > just packed with a different Windows Manager).
> >
> > If you are new to Linux, I would really suggest Ubuntu.
>
> I believe any major Linux distribution will provide decent support for
> R, and I agree there are plenty of reasons for preferring Ubuntu or
> other Linux distributions over Arch Linux. The reason why I suggested
> Arch Linux was how up to date the package is, because that was the
> motivation of the original post.
>
> R 3.3.0 was released by the R Core Team on 2016-05-03, and on 2016-05-04
> it was available in Arch Linux's "testing" repository. On 2016-05-17,
> after at least one week with no (packaging) bug reports, the package was
> moved to the "extra". This is the usual rhythm. Don't be fooled by the
> repository name, it is the repository for popular software like Firefox,
> GNOME and LibreOffice, and it is maintained by official Arch Linux
> developers / package maintainers.
>
> Hope that helps,
>
> Leonardo Ferreira Fontenelle
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Sep  9 04:03:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 9 Sep 2016 12:03:52 +1000
Subject: [R] with and evaluation
In-Reply-To: <1b5f2204-15f4-723f-724d-d6fb94b40359@gmail.com>
References: <2110976318.1457480.1473375428410.ref@mail.yahoo.com>
	<2110976318.1457480.1473375428410@mail.yahoo.com>
	<1b5f2204-15f4-723f-724d-d6fb94b40359@gmail.com>
Message-ID: <CA+8X3fW6Rn90SrXpwXxxR2-aK00aK3Zu6sD8hiyZZP0Pg3XYRw@mail.gmail.com>

Hi Carl,
order vs sort
The order function just returns the indices necessary to put the
object into the sorted order, while the sort function returns the
sorted object. If you want to use the order function:

newdf2<-df2[(order(df2[,1]),]

Yes, "with" can be a bit challenging. Think of it as:

with(take_this_thing, and_do_this_with_it)

The usual problem is working out what you want to do and what you want
the function to return. It's probably best to just do things to data
objects in a stepwise manner until you get used to that.

Jim


On Fri, Sep 9, 2016 at 9:07 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/09/2016 6:57 PM, Carl Sutton via R-help wrote:
>>
>> Hi
>> I have doing the R-exercises to improve my R programming capabilities.
>> Data.frame exercise 4 showed me that I have  a language problem.  Here's the
>> problem and my "solution".
>> #  Exercise 4#  Create a simple data frame from 3 vectors. Order the
>> entire data frame by the#  first column.df2 <- data.frame(a = 5:1,b =
>> letters[1:5], c = runif(5))order(df2$a) Naturally the order function did
>> nothing.
>> Per "help"Description
>> order returns a permutation which rearranges its first argument into
>> ascending or descending order, breaking ties by further arguments. sort.list
>> is the same, using only one argument.See the examples for how to use these
>> functions to sort data frames, etc.
>> Usage
>> order(..., na.last = TRUE, decreasing = FALSE,      method = c("shell",
>> "radix"))
>> sort.list(x, partial = NULL, na.last = TRUE, decreasing = FALSE,
>> method = c("shell", "quick", "radix"))Arguments
>> ... a sequence of numeric, complex, character or logical vectors, all of
>> the same length, or a classed R object.
>> Well, doesn't ... mean any legal object?  I gave it a legal object and got
>> nada.And the answer absolutely has me screaming "Say
>> What"df2[with(df2,order(a)),]
>>
>> What's with "with?  It is one function I do not use because I find it
>> incomprehensible.  To witEvaluate an R expression in an environment
>> constructed from data, possibly modifying (a copy of) the original data.
>>
>> First of all, if I'm not modifying data (or as a subset activity creating
>> data), why an I doing whatever it is I'm doing? ("possibly modifying (a copy
>> of) the original data.")
>> Evaluate.  According to the thesarus A) assess(v), b) appraise, c) gage.
>> OK, am I in a safe area?  I'll evaluate that.  Do I desire future social
>> contact with this person?  I'll evaluate that.In no way do I ever evaluate
>> an equation.  I may attempt to solve it.  I may do a computer program to do
>> the calculations and return a result.  I will probably evaluate the result
>> as to whether or not it helps solve the problem.  Think in terms of an
>> income tax return.  But evaluate an R expression?  No clue what that might
>> mean.
>> The remainder of the definition is also obtuse.  an R expression in an
>> environment constructed from data.  Why would one make an environment
>> without data?  Obviously I am missing the point.  My own created function
>> makes a new environment, but I only created it to crunch numbers.  If it
>> doesn't crunch numbers it's useless.
>> The point is, I do not understand the definition of "with" and thus have
>> no idea how to use it.  I guess computerese is analogous to taxlawese.
>> Familiar words have entirely different meanings.
>> Carl Sutton CPA
>>
>>         [[alternative HTML version deleted]]
>
>
> This is really hard to read, because you posted in HTML.  If you don't get a
> useful answer, please try again in plain text.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Sep  9 05:29:38 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Sep 2016 22:29:38 -0500
Subject: [R] Have help list filters changed recently
In-Reply-To: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>
References: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>
Message-ID: <42106EA0-2F8C-4FAD-B41A-3D662705FEDA@me.com>

> On Sep 8, 2016, at 7:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> To all:
> 
> r-help has been holding up a lot of my recent messages: Have there
> been any changes to help list filters that caused this? Is there
> something I'm doing wrong? -- I have made no changes  that I am aware
> of. Here's what I get:
> 
> Your mail to 'R-help' with the subject
> 
>    Re: [R] with and evaluation [for example]
> 
> Is being held until the list moderator can review it for approval.
> 
> The reason it is being held:
> 
>    The message headers matched a filter rule
> 
> 
> Best,
> Bert


Bert,

Have there been a lot of cc's in your replies?

That is one thing that will tend to trigger the spam filters. I am not sure what the threshold is and I am not sure that Martin knows, but that has bitten me in the past on R-Help. As co-moderator with Martin on R-Devel, I have seen the other side of it there.

Might also be the e-mail domain of one of the respondents in the thread.

I think that it is the ETHZ SysAdmins that tend to control the formalized spam filters and heuristics.

Regards,

Marc


From jun.shen.ut at gmail.com  Fri Sep  9 06:14:14 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 9 Sep 2016 00:14:14 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CA+vqiLEnOp9hntOhKbkmjPbrkBU8pTJMySGNmkgzHCgj3bUUJQ@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
	<CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>
	<CAMCXXmpcBcnHeWg=QATjt=uZLg+hUbbVBkP1U_Qh02DArGWwCw@mail.gmail.com>
	<CA+vqiLEnOp9hntOhKbkmjPbrkBU8pTJMySGNmkgzHCgj3bUUJQ@mail.gmail.com>
Message-ID: <CAMCXXmpo_W1cOpy1Cda22A-fnOmFWsjOOXfGv6dcn17kwNcUFg@mail.gmail.com>

Hi Ista,

Imagine we have a data set called "all.exposure" with variables
"TX","WTCUT" for a function. The concatenated strings are generated by some
procedure within the function (the dot is used as separator, I can't change
that). Now I want to parse the strings back to the original values as in
"TX" and "WTCUT" (there could be more than two variables). Since the data
set is provided by users, I cannot pre-define the pattern. The patterns
have to be figured out from the values in "TX" and "WTCUT". It's easy if
the values in "TX" or "WTCUT" don't have any "." but much trickier if they
do. However, the number of the patterns are limited by the combination of
the unique values in "TX" and "WTCUT". All possible patterns can be
constructed by the code I posted in this thread. Now I need to figure out a
way to match the patterns to the strings so each string can be parsed
correctly. I have made some progress...

Jun

On Wed, Sep 7, 2016 at 9:34 AM, Ista Zahn <istazahn at gmail.com> wrote:

> On Tue, Sep 6, 2016 at 11:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> > Hi Ista,
> >
> > Thanks for the suggestion. I didn't know mapply can be used this way!
> Let me
> > take one more step. Instead of defining a pattern for each string, I
> would
> > like to define a set of patterns from all the possible combination of the
> > unique values of those variables. Then I need each string to find a
> pattern
> > for itself.
>
> Uh, humn, what?!? I have no idea what this means. Example?
>
> --Ista
>
>  I know this is getting a little stretching. Thanks for all the
> > suggestion/comments from everyone.
> >
> > Jun
> >
> > On Tue, Sep 6, 2016 at 9:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >>
> >> If you want to mach each element of 'strings' to a different regex, do
> >> it. Here are three ways, using your original example.
> >>
> >> pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >> pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >>
> >> patterns <- c(pattern1,pattern2)
> >> strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >>
> >> for(i in seq(strings)) print(sub(patterns[i], "\\2", strings[i]))
> >>
> >> mapply(sub, pattern = patterns, x = strings, MoreArgs=list(replacement =
> >> "\\2"))
> >>
> >> library(stringi)
> >> stri_replace_all_regex(strings, patterns, "$2")
> >>
> >> Best,
> >> Ista
> >> On Tue, Sep 6, 2016 at 9:20 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> >> > Hi Jeff,
> >> >
> >> > Thanks for the reply. I tried your suggestion and it doesn't seem to
> >> > work
> >> > and I tried a simple pattern as follows and it works as expected
> >> >
> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1',
> >> > "3.mg.kg.>50-70.kg.P05")
> >> > [1] "3.mg.kg"
> >> >
> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2',
> >> > "3.mg.kg.>50-70.kg.P05")
> >> > [1] ">50-70.kg"
> >> >
> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3',
> >> > "3.mg.kg.>50-70.kg.P05")
> >> > [1] "P05"
> >> >
> >> > My problem is the pattern has to be dynamically constructed on the
> input
> >> > data of the function I am writing. It's actually not too difficult to
> >> > assemble the final.pattern with some code like the following
> >> >
> >> > sort.var <- c('TX','WTCUT')
> >> > combn.sort.var <- do.call(expand.grid, lapply(sort.var,
> >> >
> >> > function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.
> exposure[x]))),
> >> > ')', sep='')))
> >> > all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
> >> > final.pattern <- paste0(all.patterns, collapse='|')
> >> >
> >> > You cannot run the code directly since the data object "all.exposure"
> is
> >> > not provided here.
> >> >
> >> > Jun
> >> >
> >> >
> >> >
> >> > On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller
> >> > <jdnewmil at dcn.davis.ca.us>
> >> > wrote:
> >> >
> >> >> I am not near my computer today, but each parenthesis gets its own
> >> >> result
> >> >> number, so you should put the parenthesis around the whole pattern of
> >> >> alternatives instead of having many parentheses.
> >> >>
> >> >> I recommend thinking in terms of what common information you expect
> to
> >> >> find in these various strings, and place your parentheses to capture
> >> >> that
> >> >> information. There is no other reason to put parentheses in the
> >> >> pattern...
> >> >> they are not grouping symbols.
> >> >> --
> >> >> Sent from my phone. Please excuse my brevity.
> >> >>
> >> >> On September 6, 2016 5:01:04 PM PDT, Bert Gunter
> >> >> <bgunter.4567 at gmail.com>
> >> >> wrote:
> >> >> >Jun:
> >> >> >
> >> >> >1. Tell us your desired result from your test vector and maybe
> someone
> >> >> >will help.
> >> >> >
> >> >> >2. As we played this game once already (you couldn't do it; I showed
> >> >> >you how), this seems to be a function of your limitations with
> regular
> >> >> >expressions. I'm probably not much better, but in any case, I don't
> >> >> >intend to be your consultant. See if you can find someone locally to
> >> >> >help you if you do not receive a satisfactory reply from the list.
> >> >> >There are many people here who are pretty good at this sort of
> thing,
> >> >> >but I don't know if they'll reply. Regex's are certainly complex.
> PERL
> >> >> >people tend to be pretty good at them, I believe. There are numerous
> >> >> >web sites and books on them if you need to acquire expertise for
> your
> >> >> >work.
> >> >> >
> >> >> >Cheers,
> >> >> >Bert
> >> >> >Bert Gunter
> >> >> >
> >> >> >"The trouble with having an open mind is that people keep coming
> along
> >> >> >and sticking things into it."
> >> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >> >
> >> >> >
> >> >> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com>
> >> >> > wrote:
> >> >> >> Hi Bert,
> >> >> >>
> >> >> >> I still couldn't make the multiple patterns to work. Here is an
> >> >> >example. I
> >> >> >> make the pattern as follows
> >> >> >>
> >> >> >> final.pattern <-
> >> >> >>
> >> >> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
> >> >> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
> >> >> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
> >> >> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
> >> >> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
> >> >> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
> >> >> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
> >> >> >>
> >> >> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg
> .>110.kg.P05',
> >> >> >> '240.m.g.>50-70.kg.geo.mean')
> >> >> >>
> >> >> >> sub(final.pattern, '\\1', test.string)
> >> >> >> sub(final.pattern, '\\2', test.string)
> >> >> >> sub(final.pattern, '\\3', test.string)
> >> >> >>
> >> >> >> Only the third string has been correctly parsed, which matches the
> >> >> >first
> >> >> >> pattern. It seems the rest of the patterns are not called.
> >> >> >>
> >> >> >> Jun
> >> >> >>
> >> >> >>
> >> >> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter
> >> >> >> <bgunter.4567 at gmail.com>
> >> >> >wrote:
> >> >> >>>
> >> >> >>> Just noticed: My clumsy do.call() line in my previously posted
> code
> >> >> >>> below should be replaced with:
> >> >> >>> pat <- paste(pat,collapse = "|")
> >> >> >>>
> >> >> >>>
> >> >> >>> > pat <- c(pat1,pat2)
> >> >> >>> > paste(pat,collapse="|")
> >> >> >>> [1] "a+\\.*a+|b+\\.*b+"
> >> >> >>>
> >> >> >>> ************ replace this **************************
> >> >> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> >> >>> ********************************************
> >> >> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
> >> >> >>> [1] "a.a"   "bb"    "b.bbb"
> >> >> >>>
> >> >> >>>
> >> >> >>> -- Bert
> >> >> >>> Bert Gunter
> >> >> >>>
> >> >> >>> "The trouble with having an open mind is that people keep coming
> >> >> >along
> >> >> >>> and sticking things into it."
> >> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> )
> >> >> >>>
> >> >> >>>
> >> >> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
> >> >> ><bgunter.4567 at gmail.com>
> >> >> >>> wrote:
> >> >> >>> > Jun:
> >> >> >>> >
> >> >> >>> > You need to provide a clear specification via regular
> expressions
> >> >> >of
> >> >> >>> > the patterns you wish to match -- at least for me to decipher
> it.
> >> >> >>> > Others may be smarter than I, though...
> >> >> >>> >
> >> >> >>> > Jeff: Thanks. I have now convinced myself that it can be done
> (a
> >> >> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
> >> >> >patterns
> >> >> >>> > (in a vector of patterns)  to be matched in a vector of n
> >> >> >>> > strings,
> >> >> >>> > where only one of the patterns will match in any string,  then
> >> >> >>> > use
> >> >> >>> > paste() (probably via do.call()) or otherwise to paste them
> >> >> >together
> >> >> >>> > separated by "|" to form the concatenated pattern, pat. Then
> >> >> >>> >
> >> >> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
> >> >> >>> >
> >> >> >>> > should extract the matching pattern in each (perhaps with a
> >> >> >>> > little
> >> >> >>> > fiddling due to precedence rules); e.g.
> >> >> >>> >
> >> >> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
> >> >> >>> >
> >> >> >>> >> pat1 <- "a+\\.*a+"
> >> >> >>> >> pat2 <-"b+\\.*b+"
> >> >> >>> >> pat <- c(pat1,pat2)
> >> >> >>> >
> >> >> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
> >> >> >>> >> pat
> >> >> >>> > [1] "a+\\.*a+|b+\\.*b+"
> >> >> >>> >
> >> >> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
> >> >> >>> > [1] "a.a"   "bb"    "b.bbb"
> >> >> >>> >
> >> >> >>> > Cheers,
> >> >> >>> > Bert
> >> >> >>> >
> >> >> >>> >
> >> >> >>> > Bert Gunter
> >> >> >>> >
> >> >> >>> > "The trouble with having an open mind is that people keep
> coming
> >> >> >along
> >> >> >>> > and sticking things into it."
> >> >> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic
> strip
> >> >> >>> > )
> >> >> >>> >
> >> >> >>> >
> >> >> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <
> jun.shen.ut at gmail.com>
> >> >> >wrote:
> >> >> >>> >> Thanks for the reply, Bert.
> >> >> >>> >>
> >> >> >>> >> Your solution solves the example. I actually have a more
> general
> >> >> >>> >> situation
> >> >> >>> >> where I have this dot concatenated string from multiple
> >> >> >variables. The
> >> >> >>> >> problem is those variables may have values with dots in there.
> >> >> >The
> >> >> >>> >> number of
> >> >> >>> >> dots are not consistent for all values of a variable. So I am
> >> >> >thinking
> >> >> >>> >> to
> >> >> >>> >> define a vector of patterns for the vector of the string and
> >> >> >hopefully
> >> >> >>> >> to
> >> >> >>> >> find a way to use a pattern from the pattern vector for each
> >> >> >value of
> >> >> >>> >> the
> >> >> >>> >> string vector. The only way I can think of is "for" loop,
> which
> >> >> >can be
> >> >> >>> >> slow.
> >> >> >>> >> Also these are happening in a function I am writing. Just
> wonder
> >> >> >if
> >> >> >>> >> there is
> >> >> >>> >> another more efficient way. Thanks a lot.
> >> >> >>> >>
> >> >> >>> >> Jun
> >> >> >>> >>
> >> >> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
> >> >> ><bgunter.4567 at gmail.com>
> >> >> >>> >> wrote:
> >> >> >>> >>>
> >> >> >>> >>> Well, he did provide an example, and...
> >> >> >>> >>>
> >> >> >>> >>>
> >> >> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >> >>> >>>
> >> >> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
> >> >> >>> >>> [1] "WT.CUT" "tx"
> >> >> >>> >>>
> >> >> >>> >>>
> >> >> >>> >>> ## seems to do what was requested.
> >> >> >>> >>>
> >> >> >>> >>> Jeff would have to amplify on his initial statement however:
> do
> >> >> >you
> >> >> >>> >>> mean that separate patterns can always be combined via "|" ?
> >> >> >>> >>> Or
> >> >> >>> >>> something deeper?
> >> >> >>> >>>
> >> >> >>> >>> Cheers,
> >> >> >>> >>> Bert
> >> >> >>> >>> Bert Gunter
> >> >> >>> >>>
> >> >> >>> >>> "The trouble with having an open mind is that people keep
> >> >> >>> >>> coming
> >> >> >along
> >> >> >>> >>> and sticking things into it."
> >> >> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
> >> >> >>> >>> strip
> >> >> >)
> >> >> >>> >>>
> >> >> >>> >>>
> >> >> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
> >> >> >>> >>> <jdnewmil at dcn.davis.ca.us>
> >> >> >>> >>> wrote:
> >> >> >>> >>> > Your opening assertion is false.
> >> >> >>> >>> >
> >> >> >>> >>> > Provide a reproducible example and someone will
> demonstrate.
> >> >> >>> >>> > --
> >> >> >>> >>> > Sent from my phone. Please excuse my brevity.
> >> >> >>> >>> >
> >> >> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
> >> >> >>> >>> > <jun.shen.ut at gmail.com>
> >> >> >>> >>> > wrote:
> >> >> >>> >>> >>Dear list,
> >> >> >>> >>> >>
> >> >> >>> >>> >>I have a vector of strings that cannot be described by one
> >> >> >pattern.
> >> >> >>> >>> >> So
> >> >> >>> >>> >>let's say I construct a vector of patterns in the same
> length
> >> >> >as the
> >> >> >>> >>> >>vector
> >> >> >>> >>> >>of strings, can I do the element wise pattern recognition
> and
> >> >> >string
> >> >> >>> >>> >>substitution.
> >> >> >>> >>> >>
> >> >> >>> >>> >>For example,
> >> >> >>> >>> >>
> >> >> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
> >> >> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
> >> >> >>> >>> >>
> >> >> >>> >>> >>patterns <- c(pattern1,pattern2)
> >> >> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
> >> >> >>> >>> >>
> >> >> >>> >>> >>Say I want to extract "WT.CUT" from the first string and
> "tx"
> >> >> >from
> >> >> >>> >>> >> the
> >> >> >>> >>> >>second string. If I do
> >> >> >>> >>> >>
> >> >> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern will
> be
> >> >> >used.
> >> >> >>> >>> >>
> >> >> >>> >>> >>looping the patterns doesn't work the way I want.
> Appreciate
> >> >> >any
> >> >> >>> >>> >>comments.
> >> >> >>> >>> >>Thanks.
> >> >> >>> >>> >>
> >> >> >>> >>> >>Jun
> >> >> >>> >>> >>
> >> >> >>> >>> >>       [[alternative HTML version deleted]]
> >> >> >>> >>> >>
> >> >> >>> >>> >>______________________________________________
> >> >> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >> >> >see
> >> >> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>> >>> >>PLEASE do read the posting guide
> >> >> >>> >>> >>http://www.R-project.org/posting-guide.html
> >> >> >>> >>> >>and provide commented, minimal, self-contained,
> reproducible
> >> >> >code.
> >> >> >>> >>> >
> >> >> >>> >>> > ______________________________________________
> >> >> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >> >> >see
> >> >> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>> >>> > PLEASE do read the posting guide
> >> >> >>> >>> > http://www.R-project.org/posting-guide.html
> >> >> >>> >>> > and provide commented, minimal, self-contained,
> reproducible
> >> >> >code.
> >> >> >>> >>
> >> >> >>> >>
> >> >> >>
> >> >> >>
> >> >>
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From suttoncarl at ymail.com  Fri Sep  9 06:46:43 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 9 Sep 2016 04:46:43 +0000 (UTC)
Subject: [R] understanding with
References: <1404010802.1670182.1473396403276.ref@mail.yahoo.com>
Message-ID: <1404010802.1670182.1473396403276@mail.yahoo.com>

?Hi?I have been doing theR-exercises to improve my R programming capabilities. ?Data.frame exercise4 showed me that I have a languageproblem. ?Yes, I am frustrated, but please don?t take this as acriticism of the R language.? Theroutines I have managed to write do marvelous things in a short period oftime.? I really want to do more, but thisis a steep rocky thick with underbrush hill that is not fun to climb.? But there are good resources.? Swirl is wonderful.? My thanks to the authors of thatpackage.? Jared Lander?s R for Everyoneis a really good beginners book.? DataCamp, Coursera, all informative courses.??Yes I?m frustrated.? After a couple of years on and off takingclasses, reading books, reading stack overflow and r-help just about daily, Iam learning to almost crawl.? At one timeI thought I had advanced to walking but days like today show me I?m a toddlerabout to fall on his backside.?Reading the manuals onCRAN is analogous to reading the tax code.?Without a specific objective for motivation, reading them is either painfulor a certain cure for insomnia.?Here's the problem Ireferred to at the beginning and my "solution".?# ?Exercise 4 fromR Exercises# ?Create a simpledata frame from 3 vectors. Order the entire data frame by the# ?first column.df2 <- data.frame(a =5:1,b = letters[1:5], c = runif(5))order(df2$a)?Naturally the orderfunction did nothing. ? But I did read the help page and thought I followedit.? And there is no obvious environmentissue.? It?s a simple data.frame and Iwant to order it by one column.? Such asdf2 <- data.table(df2)setkey(df2, a).? Done.?No fuss, no muss, no needing ?with?.?Per "help"Description?order returns apermutation which rearranges its first argument into ascending or descendingorder, breaking ties by further arguments. sort.list is the same, using onlyone argument.See the examples for howto use these functions to sort data frames, etc.?Usage?order(..., na.last =TRUE, decreasing = FALSE,? ? ?method = c("shell", "radix"))?sort.list(x, partial =NULL, na.last = TRUE, decreasing = FALSE,? ? ?? ? method = c("shell", "quick","radix"))Arguments?... a sequence of numeric,complex, character or logical vectors, all of the same length, or a classed Robject.?Well, doesn't ... meanany legal object? ?I gave it a legal object and got nada.??And the answerabsolutely has me screaming "Say What"df2[with(df2,order(a)),]??What's with "with??In Mr. Lander?s book, page 126, ?Here we used a new function, with.? This allows us to specify the columns of adata frame without having to specify the data.frame name each time.?? Great, I?m a horrible typist and will takeany and all typing shortcuts.? However, Idon?t use it because I don?t understand what it does.? Obviously it?s important, but I?m stuck on why or how I would use it.?It is one function I donot use because I find it incomprehensible. ?To witEvaluate an R expressionin an environment constructed from data, possibly modifying (a copy of) theoriginal data.?First of all, if I'm notmodifying data (or as a subset activity creating data), why am I doing whateverit is I'm doing? ("possibly modifying (a copy of) the originaldata.") Possibly???Evaluate.?According to the thesaurus a) assess(v), b) appraise, c) gage.?OK, am I in a safe area??I'll evaluate that. ?Do I desire future social contact with thisperson? ?I'll evaluate that.?In no way do I ever evaluatean equation. ?I may attempt to solve it. ?I may do a computer programto do the calculations and return a result. ?I will probably evaluate theresult as to whether or not it helps solve the problem. ?Think in terms ofan income tax return. ?But evaluate an R expression? ?No clue whatthat might mean.? And that is my problemin a nutshell.?The remainder of thedefinition is also obtuse. ?an R expression in an environmentconstructed from data. ?Why would one make an environment withoutdata? ?Obviously I am missing thepoint. ?My own created function makes a new environment, but I onlycreated it to crunch numbers. ?If it doesn't crunch numbers it's useless.?The point is, I do not understand the definitionof "with" and thus have no idea how to use it. ?I guesscomputerese is analogous to taxlawese. ?Familiar words have entirely different meanings.?Carl Sutton CPA?

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Sep  9 10:05:10 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Sep 2016 10:05:10 +0200
Subject: [R] Have help list filters changed recently
In-Reply-To: <42106EA0-2F8C-4FAD-B41A-3D662705FEDA@me.com>
References: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>
	<42106EA0-2F8C-4FAD-B41A-3D662705FEDA@me.com>
Message-ID: <22482.27958.985411.995195@stat.math.ethz.ch>

>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>     on Thu, 8 Sep 2016 22:29:38 -0500 writes:

    >> On Sep 8, 2016, at 7:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >> 
    >> To all:
    >> 
    >> r-help has been holding up a lot of my recent messages: Have there
    >> been any changes to help list filters that caused this? Is there
    >> something I'm doing wrong? -- I have made no changes  that I am aware
    >> of. Here's what I get:
    >> 
    >> Your mail to 'R-help' with the subject
    >> 
    >> Re: [R] with and evaluation [for example]
    >> 
    >> Is being held until the list moderator can review it for approval.
    >> 
    >> The reason it is being held:
    >> 
    >> The message headers matched a filter rule
    >> 
    >> 
    >> Best,
    >> Bert


    > Bert,

    > Have there been a lot of cc's in your replies?

    > That is one thing that will tend to trigger the spam filters. I am not sure what the threshold is and I am not sure that Martin knows, but that has bitten me in the past on R-Help. As co-moderator with Martin on R-Devel, I have seen the other side of it there.

    > Might also be the e-mail domain of one of the respondents in the thread.

    > I think that it is the ETHZ SysAdmins that tend to control the formalized spam filters and heuristics.

    > Regards,
    > Marc

Thank you, Marc.

Additionally, and with a bit more details, the reason

     " The message headers matched a filter rule "

is really from the very last filter bank, which is 'mailman' and
to answer Bert's question wrt that: No, nor the mailman setup,
nor the R-help specific extra filters have changed during the
last months, probably not even during the last years.

The mailman filters however *do* look at some of the upstream
spam filter results (most of which are ETH wide), and these do
change of course, continually being adapted.

Martin


From mviljamaa at kapsi.fi  Fri Sep  9 14:01:25 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Fri, 9 Sep 2016 15:01:25 +0300
Subject: [R] Matching/checking for occurence when values are double?
Message-ID: <3C5F908A-76CC-45D5-BFD9-5AB0D4C7A9EC@kapsi.fi>

I need to pick from a dataset those rows that have a double value set to 100.
However since the values in this column are like the following:

[1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
[7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
[13]  88.96280 114.11430 100.53410 120.41910 114.42690
?

Then can I match against 100 or 100.0? Or do I need to match against 100.00000 or something else?

E.g. does 

100.0 %in% kidmomiq$mom_iq 

produce a truthful match result with this kind of data (I?m getting 0 occurrences, which might be correct, but I?m not sure)?

From mviljamaa at kapsi.fi  Fri Sep  9 14:11:40 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Fri, 9 Sep 2016 15:11:40 +0300
Subject: [R] Comparison conditionals when extracting from data.frame not
	working reliably
Message-ID: <4D8C3AE0-F1C6-467B-9C4C-D98401AE0AE0@kapsi.fi>

I?m getting strange behaviour when trying to extract rows from a two-column data.frame with double values.

My data looks like:

       mom_iq kid_score
1   121.11750        65
2    89.36188        98
3   115.44320        85
4    99.44964        83
?

and I?m testing extracting rows that have mom_iq at some interval, so e.g.

kidmomiq[kidmomiq$mom_iq > 80.0 && kidmomiq$mom_iq < 130.0,]

correctly returns rows that have mom_iq \in ]80.0, 130.0[.

However, if I adjust this to:

kidmomiq[kidmomiq$mom_iq > 80.0 && kidmomiq$mom_iq < 120.0,]

(and there are clearly values that also fall \in ]80.0, 120.0[ !)

I get:

[1] mom_iq    kid_score
<0 rows> (or 0-length row.names)

Why does the extraction fail on some values, but not some others?

From istazahn at gmail.com  Fri Sep  9 14:27:42 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 9 Sep 2016 08:27:42 -0400
Subject: [R] Comparison conditionals when extracting from data.frame not
 working reliably
In-Reply-To: <4D8C3AE0-F1C6-467B-9C4C-D98401AE0AE0@kapsi.fi>
References: <4D8C3AE0-F1C6-467B-9C4C-D98401AE0AE0@kapsi.fi>
Message-ID: <CA+vqiLGFVyDa5tdr-4zNNmv+6vLhdrCYRUcP78tLe=jiHza3nA@mail.gmail.com>

Use & instead of &&

--Ista

On Sep 9, 2016 8:12 AM, "Matti Viljamaa" <mviljamaa at kapsi.fi> wrote:

> I?m getting strange behaviour when trying to extract rows from a
> two-column data.frame with double values.
>
> My data looks like:
>
>        mom_iq kid_score
> 1   121.11750        65
> 2    89.36188        98
> 3   115.44320        85
> 4    99.44964        83
> ?
>
> and I?m testing extracting rows that have mom_iq at some interval, so e.g.
>
> kidmomiq[kidmomiq$mom_iq > 80.0 && kidmomiq$mom_iq < 130.0,]
>
> correctly returns rows that have mom_iq \in ]80.0, 130.0[.
>
> However, if I adjust this to:
>
> kidmomiq[kidmomiq$mom_iq > 80.0 && kidmomiq$mom_iq < 120.0,]
>
> (and there are clearly values that also fall \in ]80.0, 120.0[ !)
>
> I get:
>
> [1] mom_iq    kid_score
> <0 rows> (or 0-length row.names)
>
> Why does the extraction fail on some values, but not some others?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From veroandreo at gmail.com  Fri Sep  9 14:29:50 2016
From: veroandreo at gmail.com (Veronica Andreo)
Date: Fri, 9 Sep 2016 09:29:50 -0300
Subject: [R] get start and end date of ISO weeks giving a date as input
In-Reply-To: <87fupa4ig7.fsf@enricoschumann.net>
References: <CAAMki4FYjUuGpginzKR6fFUc-YJspGSWFyWjFrjRtGOqUrxP-Q@mail.gmail.com>
	<e369a034-c5d7-e1ff-b561-06073c994bb2@yahoo.es>
	<CAAMki4G92sbQXQ=zLJsbz9Nrqtof5-wus99azC4Tmjhqvf6+qw@mail.gmail.com>
	<87fupa4ig7.fsf@enricoschumann.net>
Message-ID: <CAAMki4GnhghwOGnCcQL9qes++_jLfrWqLnA3B-up_v9H79xB2A@mail.gmail.com>

Hello Enrico,

2016-09-08 10:41 GMT-03:00 Enrico Schumann <es at enricoschumann.net>:

> Hi Veronica,
>
> please see inline.
>
> On Thu, 08 Sep 2016, Veronica Andreo <veroandreo at gmail.com> writes:
>
> > Hello Luisfo and Enrico,
> >
> > Thanks for your help! I've been testing both
> > solutions... results differ for the same date (I
> > changed both functions to use ISO8601). And I added
> > contiguous dates, to see how they handle the
> > start-end of the week.
> >
> > So, here the results:
> >
> > ### one example
> > d <- c("2010-08-21","2010-08-22","2010-08-23","2010-08-24")
> > iso_start_end <- function(d) {
> >   d <- as.Date(d)
> >   wday <- as.POSIXlt(d)$wday
> >   data.frame(date = d,
> >              week = format(d, "%V"),
> >              starts = d - wday + 1,
> >              ends = d + 7 - wday)
> > }
> > iso_start_end(d)
> >
> >         date week     starts       ends
> > 1 2010-08-21   33 2010-08-16 2010-08-22
> > 2 2010-08-22   33 2010-08-23 2010-08-29
> > 3 2010-08-23   34 2010-08-23 2010-08-29
> > 4 2010-08-24   34 2010-08-23 2010-08-29
>
> Yes, the second date makes no sense, and it happens
> because Sunday is 0 (and not 7). My bad. Here is
> a fixed version:
>
>   iso_start_end <- function(d) {
>       d <- as.Date(d)
>       wday <- as.POSIXlt(d)$wday
>       wday[wday == 0] <- 7
>       data.frame(date = d,
>                  week = format(d, "%V"),
>                  starts = d - wday + 1,
>                  ends = d + 7 - wday)
>   }
>
>
> > ### the other example:
> > dd <- as.Date(strptime('2010-08-21', format="%Y-%m-%d", tz="GMT"))
> > ref.date <- as.Date(strptime(paste0(year(dd),"-01-01"),
> format="%Y-%m-%d"))
> > bound.dates <- ref.date + 7 * (isoweek(dd)) + c(0,6)
> > bound.dates
> > [1] "2010-08-20" "2010-08-26"
>
> You can use the function "weekdays" to see check the
> results.
>
>   > weekdays(bound.dates)
>   [1] "Friday"   "Thursday"
>
> > So, researching a bit more and inspired by those
> > examples, I eventually came up with this solution
> > that seems to work fine... I share in case that any
> > other has a similar problem:
> >
> > # get ISOweek for my vector of dates
> > week_iso<-ISOweek(d)
> >
> > # vector with the format %Y-W%V-1 for start day of the ISO week
> > week_iso_day1 <- paste(week_iso,1, sep="-")
> >
> > #  vector with the format %Y-W%V-7 for end day of the ISO week
> > week_iso_day7 <- paste(week_iso, 7, sep="-")
> >
> > # use ISOweek2date
> > data.frame(date= d, week_iso = week_iso, start =
> ISOweek2date(week_iso_day1), end = ISOweek2date(week_iso_day7)
> >
> >         date week_iso      start        end
> > 1 2010-08-21 2010-W33 2010-08-16 2010-08-22
> > 2 2010-08-22 2010-W33 2010-08-16 2010-08-22
> > 3 2010-08-23 2010-W34 2010-08-23 2010-08-29
> > 4 2010-08-24 2010-W34 2010-08-23 2010-08-29
>
> The updated 'iso_start_end' gives the same result.
>
>           date week     starts       ends
>   1 2010-08-21   33 2010-08-16 2010-08-22
>   2 2010-08-22   33 2010-08-16 2010-08-22
>   3 2010-08-23   34 2010-08-23 2010-08-29
>   4 2010-08-24   34 2010-08-23 2010-08-29
>

Yes! Again, thanks for your time and help!

Best,
Vero

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Sep  9 14:29:56 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 9 Sep 2016 08:29:56 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <CAMCXXmpo_W1cOpy1Cda22A-fnOmFWsjOOXfGv6dcn17kwNcUFg@mail.gmail.com>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
	<CA+vqiLGss2dp-J8XaFYAUck7AHF-HDqQb2vy0MCNvUsqeq4_kQ@mail.gmail.com>
	<CAMCXXmpcBcnHeWg=QATjt=uZLg+hUbbVBkP1U_Qh02DArGWwCw@mail.gmail.com>
	<CA+vqiLEnOp9hntOhKbkmjPbrkBU8pTJMySGNmkgzHCgj3bUUJQ@mail.gmail.com>
	<CAMCXXmpo_W1cOpy1Cda22A-fnOmFWsjOOXfGv6dcn17kwNcUFg@mail.gmail.com>
Message-ID: <CA+vqiLEi4QVibdzzRPbnFRYywv0Je1GxLRq0FVRnmnhAv8aLZA@mail.gmail.com>

On Sep 9, 2016 12:14 AM, "Jun Shen" <jun.shen.ut at gmail.com> wrote:
>
> Hi Ista,
>
> Imagine we have a data set called "all.exposure" with variables
"TX","WTCUT" for a function.

I don't think imagining your situation is the best way. Make an example so
we can actually see what you are working with.

The concatenated strings are generated by some procedure within the
function (the dot is used as separator, I can't change that). Now I want to
parse the strings back to the original values as in "TX" and "WTCUT" (there
could be more than two variables). Since the data set is provided by users,
I cannot pre-define the pattern. The patterns have to be figured out from
the values in "TX" and "WTCUT". It's easy if the values in "TX" or "WTCUT"
don't have any "." but much trickier if they do. However, the number of the
patterns are limited by the combination of the unique values in "TX" and
"WTCUT". All possible patterns can be constructed by the code I posted in
this thread. Now I need to figure out a way to match the patterns to the
strings so each string can be parsed correctly. I have made some
progress...
>
> Jun
>
> On Wed, Sep 7, 2016 at 9:34 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> On Tue, Sep 6, 2016 at 11:59 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> > Hi Ista,
>> >
>> > Thanks for the suggestion. I didn't know mapply can be used this way!
Let me
>> > take one more step. Instead of defining a pattern for each string, I
would
>> > like to define a set of patterns from all the possible combination of
the
>> > unique values of those variables. Then I need each string to find a
pattern
>> > for itself.
>>
>> Uh, humn, what?!? I have no idea what this means. Example?
>>
>> --Ista
>>
>>  I know this is getting a little stretching. Thanks for all the
>> > suggestion/comments from everyone.
>> >
>> > Jun
>> >
>> > On Tue, Sep 6, 2016 at 9:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> >>
>> >> If you want to mach each element of 'strings' to a different regex, do
>> >> it. Here are three ways, using your original example.
>> >>
>> >> pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >> pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >>
>> >> patterns <- c(pattern1,pattern2)
>> >> strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >>
>> >> for(i in seq(strings)) print(sub(patterns[i], "\\2", strings[i]))
>> >>
>> >> mapply(sub, pattern = patterns, x = strings,
MoreArgs=list(replacement =
>> >> "\\2"))
>> >>
>> >> library(stringi)
>> >> stri_replace_all_regex(strings, patterns, "$2")
>> >>
>> >> Best,
>> >> Ista
>> >> On Tue, Sep 6, 2016 at 9:20 PM, Jun Shen <jun.shen.ut at gmail.com>
wrote:
>> >> > Hi Jeff,
>> >> >
>> >> > Thanks for the reply. I tried your suggestion and it doesn't seem to
>> >> > work
>> >> > and I tried a simple pattern as follows and it works as expected
>> >> >
>> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1',
>> >> > "3.mg.kg.>50-70.kg.P05")
>> >> > [1] "3.mg.kg"
>> >> >
>> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2',
>> >> > "3.mg.kg.>50-70.kg.P05")
>> >> > [1] ">50-70.kg"
>> >> >
>> >> > sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3',
>> >> > "3.mg.kg.>50-70.kg.P05")
>> >> > [1] "P05"
>> >> >
>> >> > My problem is the pattern has to be dynamically constructed on the
input
>> >> > data of the function I am writing. It's actually not too difficult
to
>> >> > assemble the final.pattern with some code like the following
>> >> >
>> >> > sort.var <- c('TX','WTCUT')
>> >> > combn.sort.var <- do.call(expand.grid, lapply(sort.var,
>> >> >
>> >> >
function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))),
>> >> > ')', sep='')))
>> >> > all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
>> >> > final.pattern <- paste0(all.patterns, collapse='|')
>> >> >
>> >> > You cannot run the code directly since the data object
"all.exposure" is
>> >> > not provided here.
>> >> >
>> >> > Jun
>> >> >
>> >> >
>> >> >
>> >> > On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller
>> >> > <jdnewmil at dcn.davis.ca.us>
>> >> > wrote:
>> >> >
>> >> >> I am not near my computer today, but each parenthesis gets its own
>> >> >> result
>> >> >> number, so you should put the parenthesis around the whole pattern
of
>> >> >> alternatives instead of having many parentheses.
>> >> >>
>> >> >> I recommend thinking in terms of what common information you
expect to
>> >> >> find in these various strings, and place your parentheses to
capture
>> >> >> that
>> >> >> information. There is no other reason to put parentheses in the
>> >> >> pattern...
>> >> >> they are not grouping symbols.
>> >> >> --
>> >> >> Sent from my phone. Please excuse my brevity.
>> >> >>
>> >> >> On September 6, 2016 5:01:04 PM PDT, Bert Gunter
>> >> >> <bgunter.4567 at gmail.com>
>> >> >> wrote:
>> >> >> >Jun:
>> >> >> >
>> >> >> >1. Tell us your desired result from your test vector and maybe
someone
>> >> >> >will help.
>> >> >> >
>> >> >> >2. As we played this game once already (you couldn't do it; I
showed
>> >> >> >you how), this seems to be a function of your limitations with
regular
>> >> >> >expressions. I'm probably not much better, but in any case, I
don't
>> >> >> >intend to be your consultant. See if you can find someone locally
to
>> >> >> >help you if you do not receive a satisfactory reply from the list.
>> >> >> >There are many people here who are pretty good at this sort of
thing,
>> >> >> >but I don't know if they'll reply. Regex's are certainly complex.
PERL
>> >> >> >people tend to be pretty good at them, I believe. There are
numerous
>> >> >> >web sites and books on them if you need to acquire expertise for
your
>> >> >> >work.
>> >> >> >
>> >> >> >Cheers,
>> >> >> >Bert
>> >> >> >Bert Gunter
>> >> >> >
>> >> >> >"The trouble with having an open mind is that people keep coming
along
>> >> >> >and sticking things into it."
>> >> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >> >
>> >> >> >
>> >> >> >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com>
>> >> >> > wrote:
>> >> >> >> Hi Bert,
>> >> >> >>
>> >> >> >> I still couldn't make the multiple patterns to work. Here is an
>> >> >> >example. I
>> >> >> >> make the pattern as follows
>> >> >> >>
>> >> >> >> final.pattern <-
>> >> >> >>
>> >> >> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>
>> >> >> 50-70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\
>> >> >> .mg\\.kg)\\.(>70-90\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.
>> >> >> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\
>> >> >> .g)\\.(50\\.kg\\.or\\.less)\\.(.*)|(3\\.mg\\.kg)\\.(50\\.kg\
>> >> >> \.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.kg)\\.(.*)|(3\\.
>> >> >> mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>> >> >> >>
>> >> >> >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg
.>110.kg.P05',
>> >> >> >> '240.m.g.>50-70.kg.geo.mean')
>> >> >> >>
>> >> >> >> sub(final.pattern, '\\1', test.string)
>> >> >> >> sub(final.pattern, '\\2', test.string)
>> >> >> >> sub(final.pattern, '\\3', test.string)
>> >> >> >>
>> >> >> >> Only the third string has been correctly parsed, which matches
the
>> >> >> >first
>> >> >> >> pattern. It seems the rest of the patterns are not called.
>> >> >> >>
>> >> >> >> Jun
>> >> >> >>
>> >> >> >>
>> >> >> >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter
>> >> >> >> <bgunter.4567 at gmail.com>
>> >> >> >wrote:
>> >> >> >>>
>> >> >> >>> Just noticed: My clumsy do.call() line in my previously posted
code
>> >> >> >>> below should be replaced with:
>> >> >> >>> pat <- paste(pat,collapse = "|")
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> > pat <- c(pat1,pat2)
>> >> >> >>> > paste(pat,collapse="|")
>> >> >> >>> [1] "a+\\.*a+|b+\\.*b+"
>> >> >> >>>
>> >> >> >>> ************ replace this **************************
>> >> >> >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >> >> >>> ********************************************
>> >> >> >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>> >> >> >>> [1] "a.a"   "bb"    "b.bbb"
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> -- Bert
>> >> >> >>> Bert Gunter
>> >> >> >>>
>> >> >> >>> "The trouble with having an open mind is that people keep
coming
>> >> >> >along
>> >> >> >>> and sticking things into it."
>> >> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
strip )
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>> >> >> ><bgunter.4567 at gmail.com>
>> >> >> >>> wrote:
>> >> >> >>> > Jun:
>> >> >> >>> >
>> >> >> >>> > You need to provide a clear specification via regular
expressions
>> >> >> >of
>> >> >> >>> > the patterns you wish to match -- at least for me to
decipher it.
>> >> >> >>> > Others may be smarter than I, though...
>> >> >> >>> >
>> >> >> >>> > Jeff: Thanks. I have now convinced myself that it can be
done (a
>> >> >> >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>> >> >> >patterns
>> >> >> >>> > (in a vector of patterns)  to be matched in a vector of n
>> >> >> >>> > strings,
>> >> >> >>> > where only one of the patterns will match in any string,
then
>> >> >> >>> > use
>> >> >> >>> > paste() (probably via do.call()) or otherwise to paste them
>> >> >> >together
>> >> >> >>> > separated by "|" to form the concatenated pattern, pat. Then
>> >> >> >>> >
>> >> >> >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>> >> >> >>> >
>> >> >> >>> > should extract the matching pattern in each (perhaps with a
>> >> >> >>> > little
>> >> >> >>> > fiddling due to precedence rules); e.g.
>> >> >> >>> >
>> >> >> >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>> >> >> >>> >
>> >> >> >>> >> pat1 <- "a+\\.*a+"
>> >> >> >>> >> pat2 <-"b+\\.*b+"
>> >> >> >>> >> pat <- c(pat1,pat2)
>> >> >> >>> >
>> >> >> >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>> >> >> >>> >> pat
>> >> >> >>> > [1] "a+\\.*a+|b+\\.*b+"
>> >> >> >>> >
>> >> >> >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>> >> >> >>> > [1] "a.a"   "bb"    "b.bbb"
>> >> >> >>> >
>> >> >> >>> > Cheers,
>> >> >> >>> > Bert
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> > Bert Gunter
>> >> >> >>> >
>> >> >> >>> > "The trouble with having an open mind is that people keep
coming
>> >> >> >along
>> >> >> >>> > and sticking things into it."
>> >> >> >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic
strip
>> >> >> >>> > )
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <
jun.shen.ut at gmail.com>
>> >> >> >wrote:
>> >> >> >>> >> Thanks for the reply, Bert.
>> >> >> >>> >>
>> >> >> >>> >> Your solution solves the example. I actually have a more
general
>> >> >> >>> >> situation
>> >> >> >>> >> where I have this dot concatenated string from multiple
>> >> >> >variables. The
>> >> >> >>> >> problem is those variables may have values with dots in
there.
>> >> >> >The
>> >> >> >>> >> number of
>> >> >> >>> >> dots are not consistent for all values of a variable. So I
am
>> >> >> >thinking
>> >> >> >>> >> to
>> >> >> >>> >> define a vector of patterns for the vector of the string and
>> >> >> >hopefully
>> >> >> >>> >> to
>> >> >> >>> >> find a way to use a pattern from the pattern vector for each
>> >> >> >value of
>> >> >> >>> >> the
>> >> >> >>> >> string vector. The only way I can think of is "for" loop,
which
>> >> >> >can be
>> >> >> >>> >> slow.
>> >> >> >>> >> Also these are happening in a function I am writing. Just
wonder
>> >> >> >if
>> >> >> >>> >> there is
>> >> >> >>> >> another more efficient way. Thanks a lot.
>> >> >> >>> >>
>> >> >> >>> >> Jun
>> >> >> >>> >>
>> >> >> >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>> >> >> ><bgunter.4567 at gmail.com>
>> >> >> >>> >> wrote:
>> >> >> >>> >>>
>> >> >> >>> >>> Well, he did provide an example, and...
>> >> >> >>> >>>
>> >> >> >>> >>>
>> >> >> >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >> >> >>> >>>
>> >> >> >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>> >> >> >>> >>> [1] "WT.CUT" "tx"
>> >> >> >>> >>>
>> >> >> >>> >>>
>> >> >> >>> >>> ## seems to do what was requested.
>> >> >> >>> >>>
>> >> >> >>> >>> Jeff would have to amplify on his initial statement
however: do
>> >> >> >you
>> >> >> >>> >>> mean that separate patterns can always be combined via "|"
?
>> >> >> >>> >>> Or
>> >> >> >>> >>> something deeper?
>> >> >> >>> >>>
>> >> >> >>> >>> Cheers,
>> >> >> >>> >>> Bert
>> >> >> >>> >>> Bert Gunter
>> >> >> >>> >>>
>> >> >> >>> >>> "The trouble with having an open mind is that people keep
>> >> >> >>> >>> coming
>> >> >> >along
>> >> >> >>> >>> and sticking things into it."
>> >> >> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> >> >> >>> >>> strip
>> >> >> >)
>> >> >> >>> >>>
>> >> >> >>> >>>
>> >> >> >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>> >> >> >>> >>> <jdnewmil at dcn.davis.ca.us>
>> >> >> >>> >>> wrote:
>> >> >> >>> >>> > Your opening assertion is false.
>> >> >> >>> >>> >
>> >> >> >>> >>> > Provide a reproducible example and someone will
demonstrate.
>> >> >> >>> >>> > --
>> >> >> >>> >>> > Sent from my phone. Please excuse my brevity.
>> >> >> >>> >>> >
>> >> >> >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>> >> >> >>> >>> > <jun.shen.ut at gmail.com>
>> >> >> >>> >>> > wrote:
>> >> >> >>> >>> >>Dear list,
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>I have a vector of strings that cannot be described by
one
>> >> >> >pattern.
>> >> >> >>> >>> >> So
>> >> >> >>> >>> >>let's say I construct a vector of patterns in the same
length
>> >> >> >as the
>> >> >> >>> >>> >>vector
>> >> >> >>> >>> >>of strings, can I do the element wise pattern
recognition and
>> >> >> >string
>> >> >> >>> >>> >>substitution.
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>For example,
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>> >> >> >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>patterns <- c(pattern1,pattern2)
>> >> >> >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>Say I want to extract "WT.CUT" from the first string and
"tx"
>> >> >> >from
>> >> >> >>> >>> >> the
>> >> >> >>> >>> >>second string. If I do
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>sub(patterns, '\\2', strings), only the first pattern
will be
>> >> >> >used.
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>looping the patterns doesn't work the way I want.
Appreciate
>> >> >> >any
>> >> >> >>> >>> >>comments.
>> >> >> >>> >>> >>Thanks.
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>Jun
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>       [[alternative HTML version deleted]]
>> >> >> >>> >>> >>
>> >> >> >>> >>> >>______________________________________________
>> >> >> >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and
more,
>> >> >> >see
>> >> >> >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >>> >>> >>PLEASE do read the posting guide
>> >> >> >>> >>> >>http://www.R-project.org/posting-guide.html
>> >> >> >>> >>> >>and provide commented, minimal, self-contained,
reproducible
>> >> >> >code.
>> >> >> >>> >>> >
>> >> >> >>> >>> > ______________________________________________
>> >> >> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
more,
>> >> >> >see
>> >> >> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >>> >>> > PLEASE do read the posting guide
>> >> >> >>> >>> > http://www.R-project.org/posting-guide.html
>> >> >> >>> >>> > and provide commented, minimal, self-contained,
reproducible
>> >> >> >code.
>> >> >> >>> >>
>> >> >> >>> >>
>> >> >> >>
>> >> >> >>
>> >> >>
>> >> >>
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Sep  9 14:47:39 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 09 Sep 2016 13:47:39 +0100
Subject: [R] Matching/checking for occurence when values are double?
In-Reply-To: <3C5F908A-76CC-45D5-BFD9-5AB0D4C7A9EC@kapsi.fi>
Message-ID: <20160909134739.Horde.NGNbUzdsVOSjpPeePOb5e8f@mail.sapo.pt>

Hello,

See FAQ 7.31.
It's irrelevant if you write 100 or 100.0, the values are the same.  
The difference would be between 100 (double) and 100L (integer).
To check for equality between floating-point numbers you can use, for  
instance, the following function.

equal <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps

equal(100, 100 + 2e-15)
[1] TRUE

Hope this helps,

Rui Barradas



Citando Matti Viljamaa <mviljamaa at kapsi.fi>:

> I need to pick from a dataset those rows that have a double value set to 100.
> However since the values in this column are like the following:
>
> [1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
> [7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
> [13]  88.96280 114.11430 100.53410 120.41910 114.42690
> ?
>
> Then can I match against 100 or 100.0? Or do I need to match against  
> 100.00000 or something else?
>
> E.g. does
>
> 100.0 %in% kidmomiq$mom_iq
>
> produce a truthful match result with this kind of data (I?m getting  
> 0 occurrences, which might be correct, but I?m not sure)?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cimentadaj at gmail.com  Fri Sep  9 14:49:53 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 9 Sep 2016 14:49:53 +0200
Subject: [R] Matching/checking for occurence when values are double?
In-Reply-To: <3C5F908A-76CC-45D5-BFD9-5AB0D4C7A9EC@kapsi.fi>
References: <3C5F908A-76CC-45D5-BFD9-5AB0D4C7A9EC@kapsi.fi>
Message-ID: <CALdB+JFhT89Lv6PeTRrPd4EWFVzXzQUEtjyn83EFo-yByMWd4A@mail.gmail.com>

Matching 100 to 100.0 or 100.00 or whatever N number of decimales will
always return a TRUE.

The expression your using is correct. A more complete expression would be
kidmomiq[100 == kidmomiq$mom_iq, ].



On Fri, Sep 9, 2016 at 2:01 PM, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:

I need to pick from a dataset those rows that have a double value set to
> 100.
> However since the values in this column are like the following:
>
> [1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
> [7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
> [13]  88.96280 114.11430 100.53410 120.41910 114.42690
> ?
>
> Then can I match against 100 or 100.0? Or do I need to match against
> 100.00000 or something else?
>
> E.g. does
>
> 100.0 %in% kidmomiq$mom_iq
>
> produce a truthful match result with this kind of data (I?m getting 0
> occurrences, which might be correct, but I?m not sure)?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Fri Sep  9 14:53:55 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 9 Sep 2016 14:53:55 +0200
Subject: [R] Matching/checking for occurence when values are double?
In-Reply-To: <20160909134739.Horde.NGNbUzdsVOSjpPeePOb5e8f@mail.sapo.pt>
References: <20160909134739.Horde.NGNbUzdsVOSjpPeePOb5e8f@mail.sapo.pt>
Message-ID: <7b34c3c3-97c1-4ced-cb8c-177c5a0d3bfa@univ-reims.fr>

Hi,

Not sure, but it seems that your function equal() is exactly what 
all.equal() does, isn't it?

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 09/09/2016 ? 14:47, ruipbarradas at sapo.pt a ?crit :
> Hello,
>
> See FAQ 7.31.
> It's irrelevant if you write 100 or 100.0, the values are the same. 
> The difference would be between 100 (double) and 100L (integer).
> To check for equality between floating-point numbers you can use, for 
> instance, the following function.
>
> equal <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps
>
> equal(100, 100 + 2e-15)
> [1] TRUE
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Matti Viljamaa <mviljamaa at kapsi.fi>:
>
>> I need to pick from a dataset those rows that have a double value set 
>> to 100.
>> However since the values in this column are like the following:
>>
>> [1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
>> [7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
>> [13]  88.96280 114.11430 100.53410 120.41910 114.42690
>> ?
>>
>> Then can I match against 100 or 100.0? Or do I need to match against 
>> 100.00000 or something else?
>>
>> E.g. does
>>
>> 100.0 %in% kidmomiq$mom_iq
>>
>> produce a truthful match result with this kind of data (I?m getting 0 
>> occurrences, which might be correct, but I?m not sure)?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From markleeds2 at gmail.com  Fri Sep  9 05:11:14 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 8 Sep 2016 23:11:14 -0400
Subject: [R] Have help list filters changed recently
In-Reply-To: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>
References: <CAGxFJbS4GpkECraXbRsujCkqH5quV=Kd8ncuYQN95VwQ6hxWFA@mail.gmail.com>
Message-ID: <CAHz+bWYk5djBogJXhPF5KdYg9yHs5ZFKbbWr=CK_zbgqJNVCpQ@mail.gmail.com>

Hi Bert: I saw that and let it through. I am not the one to ask but as far
as I know,
the filtering has not changed.


On Thu, Sep 8, 2016 at 8:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> To all:
>
> r-help has been holding up a lot of my recent messages: Have there
> been any changes to help list filters that caused this? Is there
> something I'm doing wrong? -- I have made no changes  that I am aware
> of. Here's what I get:
>
> Your mail to 'R-help' with the subject
>
>     Re: [R] with and evaluation [for example]
>
> Is being held until the list moderator can review it for approval.
>
> The reason it is being held:
>
>     The message headers matched a filter rule
>
>
> Best,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Fri Sep  9 15:30:33 2016
From: ssefick at gmail.com (stephen sefick)
Date: Fri, 9 Sep 2016 08:30:33 -0500
Subject: [R] digital online identifier (doi) CRAN manual?
Message-ID: <CADKEMqgzMesq3J3qW1nHr8HAvExJWtHCTRpahvFdCw_d8agDTQ@mail.gmail.com>

Hello all,

I apologize if this is the incorrect forum for this query. I am a package
maintainer, and would like to have a doi for the package manual. What might
be a good way to go about this?
kindest regards,

Stephen Sefick

-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Sep  9 15:31:08 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 09 Sep 2016 14:31:08 +0100
Subject: [R] Matching/checking for occurence when values are double?
In-Reply-To: <7b34c3c3-97c1-4ced-cb8c-177c5a0d3bfa@univ-reims.fr>
References: <20160909134739.Horde.NGNbUzdsVOSjpPeePOb5e8f@mail.sapo.pt>
	<7b34c3c3-97c1-4ced-cb8c-177c5a0d3bfa@univ-reims.fr>
Message-ID: <20160909143108.Horde.mZF5b8PlQ00pLQ9xOesVDr3@mail.sapo.pt>

Not exactly, all.equal is much more complete.
It accepts all kinds of objects, not just vectors.


Rui Barradas


Citando Ivan Calandra <ivan.calandra at univ-reims.fr>:

> Hi,
>
> Not sure, but it seems that your function equal() is exactly what  
> all.equal() does, isn't it?
>
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 09/09/2016 ? 14:47, ruipbarradas at sapo.pt a ?crit :
>> Hello,
>>
>> See FAQ 7.31.
>> It's irrelevant if you write 100 or 100.0, the values are the same.  
>> The difference would be between 100 (double) and 100L (integer).
>> To check for equality between floating-point numbers you can use,  
>> for instance, the following function.
>>
>> equal <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps
>>
>> equal(100, 100 + 2e-15)
>> [1] TRUE
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Citando Matti Viljamaa <mviljamaa at kapsi.fi>:
>>
>>> I need to pick from a dataset those rows that have a double value  
>>> set to 100.
>>> However since the values in this column are like the following:
>>>
>>> [1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
>>> [7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
>>> [13]  88.96280 114.11430 100.53410 120.41910 114.42690
>>> ?
>>>
>>> Then can I match against 100 or 100.0? Or do I need to match  
>>> against 100.00000 or something else?
>>>
>>> E.g. does
>>>
>>> 100.0 %in% kidmomiq$mom_iq
>>>
>>> produce a truthful match result with this kind of data (I?m  
>>> getting 0 occurrences, which might be correct, but I?m not sure)?
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Sep  9 15:39:14 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Sep 2016 09:39:14 -0400
Subject: [R] understanding with
In-Reply-To: <1404010802.1670182.1473396403276@mail.yahoo.com>
References: <1404010802.1670182.1473396403276.ref@mail.yahoo.com>
	<1404010802.1670182.1473396403276@mail.yahoo.com>
Message-ID: <CAM_vju=zfz=kxkQKEfVDhan9GA+yey4HKuAv6G2MhZD5MrP7jA@mail.gmail.com>

Like others on the list I have no interest in wading through your
block of HTML-mangled text.

But if your question is clearly stated by the subject line, then it's
quite straightforward.

with() saves you typing and often increases code clarity by telling R
where to look for named variables

# This example is best done in a clean R session

# Given some R objects

myLongDataframeName <- data.frame(x = runif(10), y = runif(10))

x <- 1:10
y <- 1:10

cor(myLongDataframeName$x, myLongDataframeName$y) # uses the data
frame columns named x and y
cor(x, y) # uses the R objects named x and y

# Here's the magic of with():

with(myLongDataframeName, cor(x, y)) # uses the data frame columns named x and y


On Fri, Sep 9, 2016 at 12:46 AM, Carl Sutton via R-help
<r-help at r-project.org> wrote:
>  Hi I have been doing theR-exercises to improve my R programming capabilities.  Data.frame exercise4 showed me that I have a languageproblem.  Yes, I am frustrated, but please don?t take this as acriticism of the R language.  Theroutines I have managed to write do marvelous things in a short period oftime.  I really want to do more, but thisis a steep rocky thick with underbrush hill that is not fun to climb.  But there are good resources.  Swirl is wonderful.  My thanks to the authors of thatpackage.  Jared Lander?s R for Everyoneis a really good beginners book.  DataCamp, Coursera, all informative courses.  Yes I?m frustrated.  After a couple of years on and off takingclasses, reading books, reading stack overflow and r-help just about daily, Iam learning to almost crawl.  At one timeI thought I had advanced to walking but days like today show me I?m a toddlerabout to fall on his backside. Reading the manuals onCRAN is analogous to reading the tax code. Without a specific objective for motivation, reading them is either painfulor a certain cure for insomnia. Here's the problem Ireferred to at the beginning and my "solution". #  Exercise 4 fromR Exercises#  Create a simpledata frame from 3 vectors. Order the entire data frame by the#  first column.df2 <- data.frame(a =5:1,b = letters[1:5], c = runif(5))order(df2$a) Naturally the orderfunction did nothing.   But I did read the help page and thought I followedit.  And there is no obvious environmentissue.  It?s a simple data.frame and Iwant to order it by one column.  Such asdf2 <- data.table(df2)setkey(df2, a).  Done. No fuss, no muss, no needing ?with?. Per "help"Description order returns apermutation which rearranges its first argument into ascending or descendingorder, breaking ties by further arguments. sort.list is the same, using onlyone argument.See the examples for howto use these functions to sort data frames, etc. Usage order(..., na.last =TRUE, decreasing = FALSE,     method = c("shell", "radix")) sort.list(x, partial =NULL, na.last = TRUE, decreasing = FALSE,         method = c("shell", "quick","radix"))Arguments ... a sequence of numeric,complex, character or logical vectors, all of the same length, or a classed Robject. Well, doesn't ... meanany legal object?  I gave it a legal object and got nada.  And the answerabsolutely has me screaming "Say What"df2[with(df2,order(a)),]  What's with "with? In Mr. Lander?s book, page 126, ?Here we used a new function, with.  This allows us to specify the columns of adata frame without having to specify the data.frame name each time.?  Great, I?m a horrible typist and will takeany and all typing shortcuts.  However, Idon?t use it because I don?t understand what it does.  Obviously it?s important, but I?m stuck on why or how I would use it. It is one function I donot use because I find it incomprehensible.  To witEvaluate an R expressionin an environment constructed from data, possibly modifying (a copy of) theoriginal data. First of all, if I'm notmodifying data (or as a subset activity creating data), why am I doing whateverit is I'm doing? ("possibly modifying (a copy of) the originaldata.") Possibly?? Evaluate. According to the thesaurus a) assess(v), b) appraise, c) gage. OK, am I in a safe area? I'll evaluate that.  Do I desire future social contact with thisperson?  I'll evaluate that. In no way do I ever evaluatean equation.  I may attempt to solve it.  I may do a computer programto do the calculations and return a result.  I will probably evaluate theresult as to whether or not it helps solve the problem.  Think in terms ofan income tax return.  But evaluate an R expression?  No clue whatthat might mean.  And that is my problemin a nutshell. The remainder of thedefinition is also obtuse.  an R expression in an environmentconstructed from data.  Why would one make an environment withoutdata?  Obviously I am missing thepoint.  My own created function makes a new environment, but I onlycreated it to crunch numbers.  If it doesn't crunch numbers it's useless. The point is, I do not understand the definitionof "with" and thus have no idea how to use it.  I guesscomputerese is analogous to taxlawese.  Familiar words have entirely different meanings. Carl Sutton CPA
>
>         [[alternative HTML version deleted]]



-- 
Sarah Goslee
http://www.functionaldiversity.org


From SKennedy at AnikaTherapeutics.com  Fri Sep  9 21:44:52 2016
From: SKennedy at AnikaTherapeutics.com (Steve Kennedy)
Date: Fri, 9 Sep 2016 19:44:52 +0000
Subject: [R] Apply a multi-variable function to a vector
Message-ID: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>

Hello,

I would like to define an arbitrary function of an arbitrary number of variables, for example, for 2 variables:

func2 <- function(time, temp) time + temp

I'd like to keep variable names that have a meaning in the problem (time and temperature above).

If I have a vector of values for these variables, for example in the 2-d case, c(10, 121), I'd like to apply my function (in this case func2) and obtain the result. Conceptually, something like,

func2(c(10,121))

becomes

func2(10,121)

Is there a simple way to accomplish this, for an arbitrary number of variables?  I'd like something that would simply work from the definition of the function.  If that is possible.

Thanks,

Steve Kennedy

CONFIDENTIALITY NOTICE: This e-mail message, including a...{{dropped:11}}


From stevek9123 at gmail.com  Fri Sep  9 21:50:59 2016
From: stevek9123 at gmail.com (Stephen Kennedy)
Date: Fri, 9 Sep 2016 15:50:59 -0400
Subject: [R] Apply a multi-variable function to a vector
Message-ID: <CAD__wHcHm60eQWTWKXA6yMLB0-sOubcRcDrNLuaW=RSf-LAKKw@mail.gmail.com>

Hello,



I would like to define an arbitrary function of an arbitrary number of
variables, for example, for 2 variables:



func2 <- function(time, temp) time + temp



I'd like to keep variable names that have a meaning in the problem (time
and temperature above).



If I have a vector of values for these variables, for example in the 2-d
case, c(10, 121), I'd like to apply my function (in this case func2) and
obtain the result. Conceptually, something like,



func2(c(10,121))



becomes



func2(10,121)



Is there a simple way to accomplish this, for an arbitrary number of
variables?  I?d like something that would simply work from the definition
of the function.  If that is possible.



Thanks,



Steve Kennedy

	[[alternative HTML version deleted]]


From pai1981 at gmail.com  Fri Sep  9 23:11:31 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Fri, 9 Sep 2016 15:11:31 -0600
Subject: [R] How to read a grib2 file
Message-ID: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>

Hi
I am trying to read a grib2 file in R.

Here is my script

library(rgdal)
library(sp)
library(rNOMADS)
gribfile<-"tmax.01.2011040100.daily.grb2"
grib <- readGDAL(gribfile)

I am getting following error :

dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
driver GRIB
and has 190 rows and 384 columns
dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
image within GRIB file.

Cheers
-Deb

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Sep  9 23:16:58 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 9 Sep 2016 14:16:58 -0700
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <CAD__wHcHm60eQWTWKXA6yMLB0-sOubcRcDrNLuaW=RSf-LAKKw@mail.gmail.com>
References: <CAD__wHcHm60eQWTWKXA6yMLB0-sOubcRcDrNLuaW=RSf-LAKKw@mail.gmail.com>
Message-ID: <CAF8bMcY3UwF-ybvQP=eg2RXWyj0EkkkK9k5hAWfGzjP--kOKOQ@mail.gmail.com>

Try do.call(), as in

> func2 <- function(time, temp) paste(time, temp)
> func2(121, 10)
[1] "121 10"
> do.call(func2, as.list(c(121,10)))
[1] "121 10"
> do.call(func2, list(121,10))
[1] "121 10"
>
> func2(121, time=10:12)
[1] "10 121" "11 121" "12 121"
> do.call(func2, list(121,time=10:12))
[1] "10 121" "11 121" "12 121"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 9, 2016 at 12:50 PM, Stephen Kennedy <stevek9123 at gmail.com>
wrote:

> Hello,
>
>
>
> I would like to define an arbitrary function of an arbitrary number of
> variables, for example, for 2 variables:
>
>
>
> func2 <- function(time, temp) time + temp
>
>
>
> I'd like to keep variable names that have a meaning in the problem (time
> and temperature above).
>
>
>
> If I have a vector of values for these variables, for example in the 2-d
> case, c(10, 121), I'd like to apply my function (in this case func2) and
> obtain the result. Conceptually, something like,
>
>
>
> func2(c(10,121))
>
>
>
> becomes
>
>
>
> func2(10,121)
>
>
>
> Is there a simple way to accomplish this, for an arbitrary number of
> variables?  I?d like something that would simply work from the definition
> of the function.  If that is possible.
>
>
>
> Thanks,
>
>
>
> Steve Kennedy
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Sep  9 23:38:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 09 Sep 2016 14:38:41 -0700
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
References: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
Message-ID: <3C75A0E4-EDDE-4963-AAB4-9EA4CA9C797B@dcn.davis.ca.us>

Your architecture has a bad smell to me. For one thing you are mixing different units in the same vector but should be putting multiple instances of the same variable into one vector. Lists of vectors (data frames) are typically used when multiple variables need to be grouped.

Another problem is that you are constraining the names of the variables you pass to the function to be named the same as they are inside the function. This really limits your use of those functions.

There really is too much abstraction going on here.
-- 
Sent from my phone. Please excuse my brevity.

On September 9, 2016 12:44:52 PM PDT, Steve Kennedy <SKennedy at AnikaTherapeutics.com> wrote:
>Hello,
>
>I would like to define an arbitrary function of an arbitrary number of
>variables, for example, for 2 variables:
>
>func2 <- function(time, temp) time + temp
>
>I'd like to keep variable names that have a meaning in the problem
>(time and temperature above).
>
>If I have a vector of values for these variables, for example in the
>2-d case, c(10, 121), I'd like to apply my function (in this case
>func2) and obtain the result. Conceptually, something like,
>
>func2(c(10,121))
>
>becomes
>
>func2(10,121)
>
>Is there a simple way to accomplish this, for an arbitrary number of
>variables?  I'd like something that would simply work from the
>definition of the function.  If that is possible.
>
>Thanks,
>
>Steve Kennedy
>
>CONFIDENTIALITY NOTICE: This e-mail message, including
>a...{{dropped:11}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Sep  9 23:49:13 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Sep 2016 17:49:13 -0400
Subject: [R] understanding with
In-Reply-To: <1427827072.2183819.1473456057227@mail.yahoo.com>
References: <1404010802.1670182.1473396403276.ref@mail.yahoo.com>
	<1404010802.1670182.1473396403276@mail.yahoo.com>
	<CAM_vju=zfz=kxkQKEfVDhan9GA+yey4HKuAv6G2MhZD5MrP7jA@mail.gmail.com>
	<1427827072.2183819.1473456057227@mail.yahoo.com>
Message-ID: <CAM_vjukXY2iY26D7LFU_tfbqXVTQ3H+swTVDTnjhykHAT051xQ@mail.gmail.com>

Hi Carl,

The duplicate names were to demonstrate the difference in search path
and environment, since you appeared to be confused.

If you dislike with, don't use it.



On Fri, Sep 9, 2016 at 5:20 PM, Carl Sutton <suttoncarl at ymail.com> wrote:
> Hi Sarah
>
> I see the difference, but pardon the big yawn, who writes code using the
> same variable names in separate vectors and lists/data.frames?  That smacks
> of bad planning in variable name selection and an invitation to disaster.
> If it can happen, it will.  Looks to me there is a possible lack of planning
> on the programmers part.  List variable names start with lst, data frames
> with df, data tables dt, and vectors as descriptive as possible.  If any of
> them are the same, I messed up.
>
> Carl Sutton CPA
>
>
> On Friday, September 9, 2016 6:39 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>
>
> Like others on the list I have no interest in wading through your
> block of HTML-mangled text.
>
> But if your question is clearly stated by the subject line, then it's
> quite straightforward.
>
> with() saves you typing and often increases code clarity by telling R
> where to look for named variables
>
> # This example is best done in a clean R session
>
> # Given some R objects
>
> myLongDataframeName <- data.frame(x = runif(10), y = runif(10))
>
> x <- 1:10
> y <- 1:10
>
> cor(myLongDataframeName$x, myLongDataframeName$y) # uses the data
> frame columns named x and y
> cor(x, y) # uses the R objects named x and y
>
> # Here's the magic of with():
>
> with(myLongDataframeName, cor(x, y)) # uses the data frame columns named x
> and y
>
>
> On Fri, Sep 9, 2016 at 12:46 AM, Carl Sutton via R-help
> <r-help at r-project.org> wrote:
>>  Hi I have been doing theR-exercises to improve my R programming
>> capabilities.  Data.frame exercise4 showed me that I have a languageproblem.
>> Yes, I am frustrated, but please don?t take this as acriticism of the R
>> language.  Theroutines I have managed to write do marvelous things in a
>> short period oftime.  I really want to do more, but thisis a steep rocky
>> thick with underbrush hill that is not fun to climb.  But there are good
>> resources.  Swirl is wonderful.  My thanks to the authors of thatpackage.
>> Jared Lander?s R for Everyoneis a really good beginners book.  DataCamp,
>> Coursera, all informative courses.  Yes I?m frustrated.  After a couple of
>> years on and off takingclasses, reading books, reading stack overflow and
>> r-help just about daily, Iam learning to almost crawl.  At one timeI thought
>> I had advanced to walking but days like today show me I?m a toddlerabout to
>> fall on his backside. Reading the manuals onCRAN is analogous to reading the
>> tax code. Without a specific objective for motivation, reading them is
>> either painfulor a certain cure for insomnia. Here's the problem Ireferred
>> to at the beginning and my "solution". #  Exercise 4 fromR Exercises#
>> Create a simpledata frame from 3 vectors. Order the entire data frame by
>> the#  first column.df2 <- data.frame(a =5:1,b = letters[1:5], c =
>> runif(5))order(df2$a) Naturally the orderfunction did nothing.  But I did
>> read the help page and thought I followedit.  And there is no obvious
>> environmentissue.  It?s a simple data.frame and Iwant to order it by one
>> column.  Such asdf2 <- data.table(df2)setkey(df2, a).  Done. No fuss, no
>> muss, no needing ?with?. Per "help"Description order returns apermutation
>> which rearranges its first argument into ascending or descendingorder,
>> breaking ties by further arguments. sort.list is the same, using onlyone
>> argument.See the examples for howto use these functions to sort data frames,
>> etc. Usage order(..., na.last =TRUE, decreasing = FALSE,    method =
>> c("shell", "radix")) sort.list(x, partial =NULL, na.last = TRUE, decreasing
>> = FALSE,        method = c("shell", "quick","radix"))Arguments ... a
>> sequence of numeric,complex, character or logical vectors, all of the same
>> length, or a classed Robject. Well, doesn't ... meanany legal object?  I
>> gave it a legal object and got nada.  And the answerabsolutely has me
>> screaming "Say What"df2[with(df2,order(a)),]  What's with "with? In Mr.
>> Lander?s book, page 126, ?Here we used a new function, with.  This allows us
>> to specify the columns of adata frame without having to specify the
>> data.frame name each time.?  Great, I?m a horrible typist and will takeany
>> and all typing shortcuts.  However, Idon?t use it because I don?t understand
>> what it does.  Obviously it?s important, but I?m stuck on why or how I would
>> use it. It is one function I donot use because I find it incomprehensible.
>> To witEvaluate an R expressionin an environment constructed from data,
>> possibly modifying (a copy of) theoriginal data. First of all, if I'm
>> notmodifying data (or as a subset activity creating data), why am I doing
>> whateverit is I'm doing? ("possibly modifying (a copy of) the
>> originaldata.") Possibly?? Evaluate. According to the thesaurus a)
>> assess(v), b) appraise, c) gage. OK, am I in a safe area? I'll evaluate
>> that.  Do I desire future social contact with thisperson?  I'll evaluate
>> that. In no way do I ever evaluatean equation.  I may attempt to solve it.
>> I may do a computer programto do the calculations and return a result.  I
>> will probably evaluate theresult as to whether or not it helps solve the
>> problem.  Think in terms ofan income tax return.  But evaluate an R
>> expression?  No clue whatthat might mean.  And that is my problemin a
>> nutshell. The remainder of thedefinition is also obtuse.  an R expression in
>> an environmentconstructed from data.  Why would one make an environment
>> withoutdata?  Obviously I am missing thepoint.  My own created function
>> makes a new environment, but I onlycreated it to crunch numbers.  If it
>> doesn't crunch numbers it's useless. The point is, I do not understand the
>> definitionof "with" and thus have no idea how to use it.  I guesscomputerese
>> is analogous to taxlawese.  Familiar words have entirely different meanings.
>> Carl Sutton CPA
>
>>
>>        [[alternative HTML version deleted]]
>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>


From smk5g5 at mail.missouri.edu  Sat Sep 10 03:55:18 2016
From: smk5g5 at mail.missouri.edu (Khan, Saad M. (MU-Student))
Date: Sat, 10 Sep 2016 01:55:18 +0000
Subject: [R] GGplot annotate by facet
Message-ID: <DM5PR01MB254050E8101F2D70CB33D67A90FD0@DM5PR01MB2540.prod.exchangelabs.com>

Hi,

I have a dataframe which I need to plot in ggplot2 it looks like this :-

head(nodelta_firstexon)
  Value Type  Histone
1  0.06 high  H3K27ac
2  0.12  low  H3K27ac
4  0.04 high H3K27me3
5  0.16  low H3K27me3
7  0.02 high H3K36me3
8  0.13  low H3K36me3

I have another data frame with p-v alues that looks like this :-


head(mypval_df)

  Histone count pvalues

1   H3K9ac     0   0.000

2 H3K27me3     0   0.000

3 H3K36me3  1000   1.000

4  H3K4me3   583   0.583

5  H3K4me1   882   0.882

6  H3K27ac   970   0.970

This is how I plot the first dataframe  using ggplot
p <- qplot(factor(Value),data=nodelta_firstexon,geom="bar",fill=factor(Type))+facet_wrap(~Histone)

Next I need to annotate p-values (p <= mypval_df$pvalues)  to each facet using the mypval_df.

I can't seem to find an example on how to do it. Would appreciate any help.

Regards
Saad

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Sat Sep 10 06:06:01 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Sat, 10 Sep 2016 00:06:01 -0400
Subject: [R] element wise pattern recognition and string substitution
In-Reply-To: <alpine.BSF.2.00.1609062352360.64142@pedal.dcn.davis.ca.us>
References: <CAMCXXmo_HShiEwsCPJjbttUyv-CaW5Ak+PsHG-weFW==Swgngg@mail.gmail.com>
	<C07F4678-B606-4951-B028-EAF7FCDCED6E@dcn.davis.ca.us>
	<CAGxFJbQLg4+RL06qX99DoCZ18uuaP9kO9H-Gf91wFD7SVPot0A@mail.gmail.com>
	<CAMCXXmrp5prCUMAsbug6j5hsLC6bmaNLY+NGYMreWvHde+R3Ew@mail.gmail.com>
	<CAGxFJbSPHRtY71z83YfsQBJsNkifFRkLxZckQr=L_B_aEAetHQ@mail.gmail.com>
	<CAGxFJbTEa+BswKTyKp_it2bC3AQg_5=4CfxDKXUsd_mTg9S0wQ@mail.gmail.com>
	<CAMCXXmo41HH3Pp=DWOq+Oyrx-Q=Hm6d=98PXsfJZ4LefLZ3kNw@mail.gmail.com>
	<CAGxFJbTVkkefKCiEBnwNYcP=Mbr1DUxG3kTHBuJc-NCMDU4U-Q@mail.gmail.com>
	<BA250B69-5740-4646-AA10-55C3FE0D53F2@dcn.davis.ca.us>
	<CAMCXXmr+mTqv1TQWYmnZHi6Tn4HUdT5_pwFgBiQcAvO6J5tXnQ@mail.gmail.com>
	<alpine.BSF.2.00.1609062352360.64142@pedal.dcn.davis.ca.us>
Message-ID: <CAMCXXmoLN1Q2qjOQnO1bkjpNMHi9-Xtv13VKJCEyiwM7Gat+gw@mail.gmail.com>

Hi Jeff,

I have been trying different methods and found your approach is the most
efficient. I am able to resolve the string-parsing problem. Let me report
back to the group.

This following example explains what I was trying to achieve.

melt.results is where the strings reside, testdata is a snippet of data
where the unique values are derived.  replace.metaChar is a function I
defined. Thanks for the help from everyone and appreciate any comment.

Jun
################################################################
melt.results <- structure(list(param = c("Cmin1", "Cminss", "Cmaxss",
"Cmin1",
"Cminss", "Cmin1", "Cminss", "Cmaxss", "Cmin1", "Cminss"), variable =
structure(c(1L,
5L, 9L, 14L, 18L, 21L, 25L, 29L, 34L, 38L), .Label =
c("240.mg.>110.kg.geo.mean",

"240.mg.>110.kg.cv", "240.mg.>110.kg.P05", "240.mg.>110.kg.P95",
"3.mg.kg.>110.kg.geo.mean", "3.mg.kg.>110.kg.cv", "3.mg.kg.>110.kg.P05",
"3.mg.kg.>110.kg.P95", "240.mg.>50-70.kg.geo.mean", "240.mg.>50-70.kg.cv",
"240.mg.>50-70.kg.P05", "240.mg.>50-70.kg.P95", "3.mg.kg.>50-70.kg.geo.mean",

"3.mg.kg.>50-70.kg.cv", "3.mg.kg.>50-70.kg.P05", "3.mg.kg.>50-70.kg.P95",
"240.mg.50.kg.or.less.geo.mean", "240.mg.50.kg.or.less.cv",
"240.mg.50.kg.or.less.P05",
"240.mg.50.kg.or.less.P95", "3.mg.kg.50.kg.or.less.geo.mean",
"3.mg.kg.50.kg.or.less.cv", "3.mg.kg.50.kg.or.less.P05",
"3.mg.kg.50.kg.or.less.P95",
"240.mg.>70-90.kg.geo.mean", "240.mg.>70-90.kg.cv", "240.mg.>70-90.kg.P05",
"240.mg.>70-90.kg.P95", "3.mg.kg.>70-90.kg.geo.mean", "3.mg.kg.>70-90.kg.cv",

"3.mg.kg.>70-90.kg.P05", "3.mg.kg.>70-90.kg.P95", "240.mg.>90-110.kg.geo.mean",

"240.mg.>90-110.kg.cv", "240.mg.>90-110.kg.P05", "240.mg.>90-110.kg.P95",
"3.mg.kg.>90-110.kg.geo.mean", "3.mg.kg.>90-110.kg.cv",
"3.mg.kg.>90-110.kg.P05",

"3.mg.kg.>90-110.kg.P95"), class = "factor"), value = c(97L,
144L, 76L, 137L, 18L, 104L, 92L, 87L, 111L, 41L)), .Names = c("param",
"variable", "value"), row.names = c(1L, 14L, 27L, 40L, 53L, 61L,
74L, 87L, 100L, 113L), class = "data.frame")

testdata <- structure(list(TX = c("240.mg", "3.mg.kg", "240.mg", "3.mg.kg",
"240.mg", "3.mg.kg", "240.mg", "3.mg.kg", "240.mg", "3.mg.kg"
), WTCUT = c(">50-70.kg", ">50-70.kg", ">70-90.kg", ">70-90.kg",
">90-110.kg", ">90-110.kg", "50.kg.or.less", "50.kg.or.less",
">110.kg", ">110.kg")), .Names = c("TX", "WTCUT"), row.names = c(1L,
2L, 7L, 8L, 19L, 20L, 21L, 22L, 129L, 130L), class = "data.frame")

replace.metaChar <- function(string) {
  metaChar <-
c("\\$","\\*","\\+","\\.","\\?","\\[","\\]","\\^","\\{","\\}","\\|","\\(","\\)","\\\\")
  metaReplace <-  paste('\\',metaChar, sep='')
  for(r in seq(metaChar)) gsub(metaChar[r], metaReplace[r], string) ->
string
  return(string)
}

sort.var <- c('TX','WTCUT')

one.pattern <- paste('\\b',paste(sapply(sapply(sort.var,
function(x)replace.metaChar(unique(testdata[[x]]))), function(y)
paste('(',paste(y,collapse='|'),')', sep='')), collapse='\\.'), '\\.(.*)',
sep='')

n.sort.var <- length(sort.var)
one.replacement <- paste('\\', seq(n.sort.var+1), collapse='\t', sep='')
one.results <- strsplit(sub(one.pattern, one.replacement,
melt.results$variable), split='\t')

melt.results[c(sort.var,'STATS')] <- as.data.frame(do.call(rbind,
one.results))

On Wed, Sep 7, 2016 at 3:04 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Here are some suggestions:
>
> test.string <- c( '240.m.g.>110.kg.geo.mean'
>                 , '3.mg.kg.>110.kg.P05'
>                 , '240.m.g.>50-70.kg.geo.mean'
>                 )
> # based on your literal idea
> suggested.pattern1 <-
>   "(240\\.m\\.g|3\\.mg\\.kg)\\.(>50-70\\.kg|>70-90\\.kg|>90-11
> 0\\.kg|50\\.kg\\.or\\.less|>110\\.kg)\\.(.*)"
>
> resultL <- strsplit( sub( suggested.pattern1
>                         , "\\1\t\\2\t\\3"
>                         , test.string )
>                    , split = "\t"
>                    )
>
> # equivalent based on apparent repetitive patterns in your sample data
> suggested.pattern2 <- "(.*?m\\.g|kg)\\.(.*?kg|.*?less)\\.(.*)"
>
> resultL2 <- strsplit( sub( suggested.pattern2
>                          , "\\1\t\\2\t\\3"
>                          , test.string
>                          )
>                     , split = "\t"
>                     )
>
> # put results into an organized table
> DF <- setNames( data.frame( do.call( rbind, resultL ) )
>               , c( "First", "Second", "Third" )
>               )
>
> By the way... please aim to make your examples reproducible. It would have
> been easy for you to define the necessary variables in example form
> rather than sending a non-reproducible example.
>
>
> On Tue, 6 Sep 2016, Jun Shen wrote:
>
> Hi Jeff,
>>
>> Thanks for the reply. I tried your suggestion and it doesn't seem to work
>> and I tried a simple pattern as follows and it works as expected
>>
>> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\1', "3.mg.kg
>> .>50-70.kg.P05")
>> [1] "3.mg.kg"
>>
>> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\2', "3.mg.kg
>> .>50-70.kg.P05")
>> [1] ">50-70.kg"
>>
>> sub("(3\\.mg\\.kg)\\.(>50-70\\.kg)\\.(.*)", '\\3', "3.mg.kg
>> .>50-70.kg.P05")
>> [1] "P05"
>>
>> My problem is the pattern has to be dynamically constructed on the input
>> data of the function I am writing. It's actually not too difficult
>> to assemble the final.pattern with some code like the following
>>
>> sort.var <- c('TX','WTCUT')
>> combn.sort.var <- do.call(expand.grid, lapply(sort.var,
>> function(x)paste('(',gsub('\\.','\\\\.',unlist(unique(all.exposure[x]))),
>> ')',
>> sep='')))
>> all.patterns <- do.call(paste, c(combn.sort.var, '(.*)', sep='\\.'))
>> final.pattern <- paste0(all.patterns, collapse='|')
>>
>> You cannot run the code directly since the data object "all.exposure" is
>> not provided here.
>>
>> Jun
>>
>>
>>
>> On Tue, Sep 6, 2016 at 8:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>       I am not near my computer today, but each parenthesis gets its own
>> result number, so you should put the parenthesis around the
>>       whole pattern of alternatives instead of having many parentheses.
>>
>>       I recommend thinking in terms of what common information you expect
>> to find in these various strings, and place your parentheses
>>       to capture that information. There is no other reason to put
>> parentheses in the pattern... they are not grouping symbols.
>>       --
>>       Sent from my phone. Please excuse my brevity.
>>
>>       On September 6, 2016 5:01:04 PM PDT, Bert Gunter <
>> bgunter.4567 at gmail.com> wrote:
>>       >Jun:
>>       >
>>       >1. Tell us your desired result from your test vector and maybe
>> someone
>>       >will help.
>>       >
>>       >2. As we played this game once already (you couldn't do it; I
>> showed
>>       >you how), this seems to be a function of your limitations with
>> regular
>>       >expressions. I'm probably not much better, but in any case, I don't
>>       >intend to be your consultant. See if you can find someone locally
>> to
>>       >help you if you do not receive a satisfactory reply from the list.
>>       >There are many people here who are pretty good at this sort of
>> thing,
>>       >but I don't know if they'll reply. Regex's are certainly complex.
>> PERL
>>       >people tend to be pretty good at them, I believe. There are
>> numerous
>>       >web sites and books on them if you need to acquire expertise for
>> your
>>       >work.
>>       >
>>       >Cheers,
>>       >Bert
>>       >Bert Gunter
>>       >
>>       >"The trouble with having an open mind is that people keep coming
>> along
>>       >and sticking things into it."
>>       >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>       >
>>       >
>>       >On Tue, Sep 6, 2016 at 3:59 PM, Jun Shen <jun.shen.ut at gmail.com>
>> wrote:
>>       >> Hi Bert,
>>       >>
>>       >> I still couldn't make the multiple patterns to work. Here is an
>>       >example. I
>>       >> make the pattern as follows
>>       >>
>>       >> final.pattern <-
>>       >>
>> >"(240\\.m\\.g)\\.(>50-70\\.kg)\\.(.*)|(3\\.mg\\.kg)\\.(>50-
>> 70\\.kg)\\.(.*)|(240\\.m\\.g)\\.(>70-90\\.kg)\\.(.*)|(3\\.
>> mg\\.kg)\\.(>70-90\\.k
>> g)\\.(.*)|(240\\.m\\.g)\\.(>90-110\\.kg)\\.(.*)|(3\\.mg\\.kg
>> )\\.(>90-110\\.kg)\\.(.*)|(240\\.m\\.g)\\.(50\\.kg\\.or\\.
>> less)\\.(.*)|(3\\.mg\\
>>       .kg)\\.(50\\.kg\\.or\\.less)\\.(.*)|(240\\.m\\.g)\\.(>110\\.
>> kg)\\.(.*)|(3\\.mg\\.kg)\\.(>110\\.kg)\\.(.*)"
>>       >>
>>       >> test.string <- c('240.m.g.>110.kg.geo.mean', '3.mg.kg
>> .>110.kg.P05',
>>       >> '240.m.g.>50-70.kg.geo.mean')
>>       >>
>>       >> sub(final.pattern, '\\1', test.string)
>>       >> sub(final.pattern, '\\2', test.string)
>>       >> sub(final.pattern, '\\3', test.string)
>>       >>
>>       >> Only the third string has been correctly parsed, which matches
>> the
>>       >first
>>       >> pattern. It seems the rest of the patterns are not called.
>>       >>
>>       >> Jun
>>       >>
>>       >>
>>       >> On Mon, Sep 5, 2016 at 10:21 PM, Bert Gunter <
>> bgunter.4567 at gmail.com>
>>       >wrote:
>>       >>>
>>       >>> Just noticed: My clumsy do.call() line in my previously posted
>> code
>>       >>> below should be replaced with:
>>       >>> pat <- paste(pat,collapse = "|")
>>       >>>
>>       >>>
>>       >>> > pat <- c(pat1,pat2)
>>       >>> > paste(pat,collapse="|")
>>       >>> [1] "a+\\.*a+|b+\\.*b+"
>>       >>>
>>       >>> ************ replace this **************************
>>       >>> > pat <- do.call(paste,c(as.list(pat), sep="|"))
>>       >>> ********************************************
>>       >>> > sub(paste0("^[^b]*(",pat,").*$"),"\\1",z)
>>       >>> [1] "a.a"   "bb"    "b.bbb"
>>       >>>
>>       >>>
>>       >>> -- Bert
>>       >>> Bert Gunter
>>       >>>
>>       >>> "The trouble with having an open mind is that people keep coming
>>       >along
>>       >>> and sticking things into it."
>>       >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> strip )
>>       >>>
>>       >>>
>>       >>> On Mon, Sep 5, 2016 at 12:11 PM, Bert Gunter
>>       ><bgunter.4567 at gmail.com>
>>       >>> wrote:
>>       >>> > Jun:
>>       >>> >
>>       >>> > You need to provide a clear specification via regular
>> expressions
>>       >of
>>       >>> > the patterns you wish to match -- at least for me to decipher
>> it.
>>       >>> > Others may be smarter than I, though...
>>       >>> >
>>       >>> > Jeff: Thanks. I have now convinced myself that it can be done
>> (a
>>       >>> > "proof" of sorts): If pat1, pat2,..., patn are m different
>>       >patterns
>>       >>> > (in a vector of patterns)  to be matched in a vector of n
>> strings,
>>       >>> > where only one of the patterns will match in any string,
>> then use
>>       >>> > paste() (probably via do.call()) or otherwise to paste them
>>       >together
>>       >>> > separated by "|" to form the concatenated pattern, pat. Then
>>       >>> >
>>       >>> > sub(paste0("^.*(",pat, ").*$"),"\\1",thevector)
>>       >>> >
>>       >>> > should extract the matching pattern in each (perhaps with a
>> little
>>       >>> > fiddling due to precedence rules); e.g.
>>       >>> >
>>       >>> >> z <-c(".fg.h.g.a.a", "bb..dd.ef.tgf.", "foo...b.bbb.tgy")
>>       >>> >
>>       >>> >> pat1 <- "a+\\.*a+"
>>       >>> >> pat2 <-"b+\\.*b+"
>>       >>> >> pat <- c(pat1,pat2)
>>       >>> >
>>       >>> >> pat <- do.call(paste,c(as.list(pat), sep="|"))
>>       >>> >> pat
>>       >>> > [1] "a+\\.*a+|b+\\.*b+"
>>       >>> >
>>       >>> >> sub(paste0("^[^b]*(",pat,").*$"), "\\1", z)
>>       >>> > [1] "a.a"   "bb"    "b.bbb"
>>       >>> >
>>       >>> > Cheers,
>>       >>> > Bert
>>       >>> >
>>       >>> >
>>       >>> > Bert Gunter
>>       >>> >
>>       >>> > "The trouble with having an open mind is that people keep
>> coming
>>       >along
>>       >>> > and sticking things into it."
>>       >>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> strip )
>>       >>> >
>>       >>> >
>>       >>> > On Mon, Sep 5, 2016 at 9:56 AM, Jun Shen <
>> jun.shen.ut at gmail.com>
>>       >wrote:
>>       >>> >> Thanks for the reply, Bert.
>>       >>> >>
>>       >>> >> Your solution solves the example. I actually have a more
>> general
>>       >>> >> situation
>>       >>> >> where I have this dot concatenated string from multiple
>>       >variables. The
>>       >>> >> problem is those variables may have values with dots in
>> there.
>>       >The
>>       >>> >> number of
>>       >>> >> dots are not consistent for all values of a variable. So I am
>>       >thinking
>>       >>> >> to
>>       >>> >> define a vector of patterns for the vector of the string and
>>       >hopefully
>>       >>> >> to
>>       >>> >> find a way to use a pattern from the pattern vector for each
>>       >value of
>>       >>> >> the
>>       >>> >> string vector. The only way I can think of is "for" loop,
>> which
>>       >can be
>>       >>> >> slow.
>>       >>> >> Also these are happening in a function I am writing. Just
>> wonder
>>       >if
>>       >>> >> there is
>>       >>> >> another more efficient way. Thanks a lot.
>>       >>> >>
>>       >>> >> Jun
>>       >>> >>
>>       >>> >> On Mon, Sep 5, 2016 at 1:41 AM, Bert Gunter
>>       ><bgunter.4567 at gmail.com>
>>       >>> >> wrote:
>>       >>> >>>
>>       >>> >>> Well, he did provide an example, and...
>>       >>> >>>
>>       >>> >>>
>>       >>> >>> > z <- c('TX.WT.CUT.mean','mg.tx.cv')
>>       >>> >>>
>>       >>> >>> > sub("^.+?\\.(.+)\\.[^.]+$","\\1",z)
>>       >>> >>> [1] "WT.CUT" "tx"
>>       >>> >>>
>>       >>> >>>
>>       >>> >>> ## seems to do what was requested.
>>       >>> >>>
>>       >>> >>> Jeff would have to amplify on his initial statement
>> however: do
>>       >you
>>       >>> >>> mean that separate patterns can always be combined via "|"
>> ?  Or
>>       >>> >>> something deeper?
>>       >>> >>>
>>       >>> >>> Cheers,
>>       >>> >>> Bert
>>       >>> >>> Bert Gunter
>>       >>> >>>
>>       >>> >>> "The trouble with having an open mind is that people keep
>> coming
>>       >along
>>       >>> >>> and sticking things into it."
>>       >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> strip
>>       >)
>>       >>> >>>
>>       >>> >>>
>>       >>> >>> On Sun, Sep 4, 2016 at 9:30 PM, Jeff Newmiller
>>       >>> >>> <jdnewmil at dcn.davis.ca.us>
>>       >>> >>> wrote:
>>       >>> >>> > Your opening assertion is false.
>>       >>> >>> >
>>       >>> >>> > Provide a reproducible example and someone will
>> demonstrate.
>>       >>> >>> > --
>>       >>> >>> > Sent from my phone. Please excuse my brevity.
>>       >>> >>> >
>>       >>> >>> > On September 4, 2016 9:06:59 PM PDT, Jun Shen
>>       >>> >>> > <jun.shen.ut at gmail.com>
>>       >>> >>> > wrote:
>>       >>> >>> >>Dear list,
>>       >>> >>> >>
>>       >>> >>> >>I have a vector of strings that cannot be described by one
>>       >pattern.
>>       >>> >>> >> So
>>       >>> >>> >>let's say I construct a vector of patterns in the same
>> length
>>       >as the
>>       >>> >>> >>vector
>>       >>> >>> >>of strings, can I do the element wise pattern recognition
>> and
>>       >string
>>       >>> >>> >>substitution.
>>       >>> >>> >>
>>       >>> >>> >>For example,
>>       >>> >>> >>
>>       >>> >>> >>pattern1 <- "([^.]*)\\.([^.]*\\.[^.]*)\\.(.*)"
>>       >>> >>> >>pattern2 <- "([^.]*)\\.([^.]*)\\.(.*)"
>>       >>> >>> >>
>>       >>> >>> >>patterns <- c(pattern1,pattern2)
>>       >>> >>> >>strings <- c('TX.WT.CUT.mean','mg.tx.cv')
>>       >>> >>> >>
>>       >>> >>> >>Say I want to extract "WT.CUT" from the first string and
>> "tx"
>>       >from
>>       >>> >>> >> the
>>       >>> >>> >>second string. If I do
>>       >>> >>> >>
>>       >>> >>> >>sub(patterns, '\\2', strings), only the first pattern
>> will be
>>       >used.
>>       >>> >>> >>
>>       >>> >>> >>looping the patterns doesn't work the way I want.
>> Appreciate
>>       >any
>>       >>> >>> >>comments.
>>       >>> >>> >>Thanks.
>>       >>> >>> >>
>>       >>> >>> >>Jun
>>       >>> >>> >>
>>       >>> >>> >>       [[alternative HTML version deleted]]
>>       >>> >>> >>
>>       >>> >>> >>______________________________________________
>>       >>> >>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>>       >see
>>       >>> >>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>       >>> >>> >>PLEASE do read the posting guide
>>       >>> >>> >>http://www.R-project.org/posting-guide.html
>>       >>> >>> >>and provide commented, minimal, self-contained,
>> reproducible
>>       >code.
>>       >>> >>> >
>>       >>> >>> > ______________________________________________
>>       >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>>       >see
>>       >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>       >>> >>> > PLEASE do read the posting guide
>>       >>> >>> > http://www.R-project.org/posting-guide.html
>>       >>> >>> > and provide commented, minimal, self-contained,
>> reproducible
>>       >code.
>>       >>> >>
>>       >>> >>
>>       >>
>>       >>
>>
>>
>>
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Sep 10 07:29:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 9 Sep 2016 22:29:22 -0700 (PDT)
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <AEAC5C2D55889A488576EDAA792CC287D6D6AA@anikaexch01.anikatherapeutics.com>
References: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
	<3C75A0E4-EDDE-4963-AAB4-9EA4CA9C797B@dcn.davis.ca.us>
	<AEAC5C2D55889A488576EDAA792CC287D6D6AA@anikaexch01.anikatherapeutics.com>
Message-ID: <alpine.BSF.2.00.1609092215100.48224@pedal.dcn.davis.ca.us>

Not sure I understand what you really want, if you have found ways to 
accomplish what you want but are not satisfied with them. That is one 
reason why keeping the mailing list involved (by reply-all) is good for 
you. From my end, I don't do one-on-one support online, and may not be 
able to carry on a thread to the end if I get busy.

Your concept of a generalized outer function sounds to me like:

myfunc <- function( A, B, C ) {
  A * B + C
}

gouter <- function( FUN, ... ) {
  args <- list( ... )
  DF <- do.call( expand.grid, args )
  array( data = do.call( FUN, DF )
       , dim = sapply( args, FUN=length )
       , dimnames = args
       )
}

gouter( myfunc, A = 1:3, B=2:6, C=3:4 )
# , , C = 3
#
#    B
# A   2  3  4  5  6
#   1 5  6  7  8  9
#   2 7  9 11 13 15
#   3 9 12 15 18 21
#
# , , C = 4
#
#    B
# A    2  3  4  5  6
#   1  6  7  8  9 10
#   2  8 10 12 14 16
#   3 10 13 16 19 22

I generally just tack on columns to the expand.grid result... I almost 
never have a need for multidimensional arrays.

On Fri, 9 Sep 2016, Steve Kennedy wrote:

> Hello,
>
> Abstraction is what I want.  I'm actually looking to do something more 
> complicated.  The functions do.call, and as.list get me most of the way 
> there, but there is something I'm missing ...
>
> My eventual goal is to produce a multi-dimensional version of 'outer'. 
> Like my.outer(func, a_vec, b_vec, c_vec, ..), where the function of the 
> variables 'a', 'b', 'c', etc. would be applied to the vectors from the 
> outer product of the vectors of values for each variable.
>
> I wanted to use expand.grid (does require reshaping the output).  Using 
> temps = c(40,50,60) and times = c(1:5), this doesn't quite seem to work:
>
>   apply(expand.grid(temps,times), 1, function(a) do.call(func2, as.list(a)))
>
> although this does work:
>
>   do.call(func2, as.list(c(10, 121)))
>
> And, this also works:
>
>  apply(expand.grid(temps,times), 1, function(a) do.call("+", as.list(a)))
>
> There is some subtlety here I don't understand.
>
> Thanks,
>
> Steve
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Friday, September 09, 2016 5:39 PM
> To: Steve Kennedy; r-help at r-project.org
> Subject: Re: [R] Apply a multi-variable function to a vector
>
> Your architecture has a bad smell to me. For one thing you are mixing 
> different units in the same vector but should be putting multiple 
> instances of the same variable into one vector. Lists of vectors (data 
> frames) are typically used when multiple variables need to be grouped.
>
> Another problem is that you are constraining the names of the variables 
> you pass to the function to be named the same as they are inside the 
> function. This really limits your use of those functions.
>
> There really is too much abstraction going on here.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 9, 2016 12:44:52 PM PDT, Steve Kennedy <SKennedy at AnikaTherapeutics.com> wrote:
>> Hello,
>>
>> I would like to define an arbitrary function of an arbitrary number of
>> variables, for example, for 2 variables:
>>
>> func2 <- function(time, temp) time + temp
>>
>> I'd like to keep variable names that have a meaning in the problem
>> (time and temperature above).
>>
>> If I have a vector of values for these variables, for example in the
>> 2-d case, c(10, 121), I'd like to apply my function (in this case
>> func2) and obtain the result. Conceptually, something like,
>>
>> func2(c(10,121))
>>
>> becomes
>>
>> func2(10,121)
>>
>> Is there a simple way to accomplish this, for an arbitrary number of
>> variables?  I'd like something that would simply work from the
>> definition of the function.  If that is possible.
>>
>> Thanks,
>>
>> Steve Kennedy
>>
>> CONFIDENTIALITY NOTICE: This e-mail message, including
>> a...{{dropped:11}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> http://cp.mcafee.com/d/k-Kr6x0g6hASyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPq
>> tTT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOw
>> evW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jq9JcTvANOoVcsCej76XCOsVH
>> kiPajSvvcCatoDwCHIcfBisEeRO9sDVWNIhgxVxmhUagJ3AdcOFRJVKxJBxdcS2_id41Fr1
>> pFtd40wIIumd46Cy1lI-syVDoOQwvVEwtrxqsGMd44WCy3jh0p-QWNdLECZzL1
>> PLEASE do read the posting guide
>> http://cp.mcafee.com/d/5fHCMUp418SyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPqt
>> TT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOwe
>> vW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jqpJcTvANOoVcsCej76XCM0gbb
>> HhG8_qv00smHisE4iV5Ki7Y3zoyx3P2IzMkxq78qpBjHrPt3rb2qpI5-Aq83iS2PiWq811p
>> oYIq8dd42HpYV5PeNBF0_Ph0WT2QVlwq89Rd46Cy0PZFRyrvhd_2KV
>> and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail message, including any attachments, contains information belonging to Anika Therapeutics, Inc. and is for the sole use of the intended recipient(s) and may contain confidential, proprietary, copyrighted and privileged information. Any unauthorized review, use, disclosure, distribution or copying is strictly prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message immediately.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sat Sep 10 08:27:16 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 9 Sep 2016 23:27:16 -0700 (PDT)
Subject: [R] understanding with
In-Reply-To: <CAM_vjukXY2iY26D7LFU_tfbqXVTQ3H+swTVDTnjhykHAT051xQ@mail.gmail.com>
References: <1404010802.1670182.1473396403276.ref@mail.yahoo.com>
	<1404010802.1670182.1473396403276@mail.yahoo.com>
	<CAM_vju=zfz=kxkQKEfVDhan9GA+yey4HKuAv6G2MhZD5MrP7jA@mail.gmail.com>
	<1427827072.2183819.1473456057227@mail.yahoo.com>
	<CAM_vjukXY2iY26D7LFU_tfbqXVTQ3H+swTVDTnjhykHAT051xQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609092244490.48224@pedal.dcn.davis.ca.us>

Indeed, you don't have to write code with constructs you don't like, but 
you should be able to read it. Considerable effort under the label "scope" 
[1] is expended in programming language design specifically to allow 
re-use of variable names in different contexts. Because I do understand 
scope, I don't need to worry about whether variables with the same names 
might exist in different places in the program, much the same way I don't 
worry about multiple files called README that can be found in different 
directories on my hard disk... they are in different contexts, so there is 
no need to be confused between them or be disturbed that they exist. This 
does mean that if you want to read my code, you will also need to be 
comfortable with scope.

The with function is just helpful syntactic sugar for reducing repetitious 
typing of the name of the list/data frame that contains several objects 
you want to refer to in a single expression.

[1] https://en.wikipedia.org/wiki/Scope_(computer_science)

On Fri, 9 Sep 2016, Sarah Goslee wrote:

> Hi Carl,
>
> The duplicate names were to demonstrate the difference in search path
> and environment, since you appeared to be confused.
>
> If you dislike with, don't use it.
>
>
>
> On Fri, Sep 9, 2016 at 5:20 PM, Carl Sutton <suttoncarl at ymail.com> wrote:
>> Hi Sarah
>>
>> I see the difference, but pardon the big yawn, who writes code using the
>> same variable names in separate vectors and lists/data.frames?  That smacks
>> of bad planning in variable name selection and an invitation to disaster.
>> If it can happen, it will.  Looks to me there is a possible lack of planning
>> on the programmers part.  List variable names start with lst, data frames
>> with df, data tables dt, and vectors as descriptive as possible.  If any of
>> them are the same, I messed up.
>>
>> Carl Sutton CPA
>>
>>
>> On Friday, September 9, 2016 6:39 AM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>>
>>
>> Like others on the list I have no interest in wading through your
>> block of HTML-mangled text.
>>
>> But if your question is clearly stated by the subject line, then it's
>> quite straightforward.
>>
>> with() saves you typing and often increases code clarity by telling R
>> where to look for named variables
>>
>> # This example is best done in a clean R session
>>
>> # Given some R objects
>>
>> myLongDataframeName <- data.frame(x = runif(10), y = runif(10))
>>
>> x <- 1:10
>> y <- 1:10
>>
>> cor(myLongDataframeName$x, myLongDataframeName$y) # uses the data
>> frame columns named x and y
>> cor(x, y) # uses the R objects named x and y
>>
>> # Here's the magic of with():
>>
>> with(myLongDataframeName, cor(x, y)) # uses the data frame columns named x
>> and y
>>
>>
>> On Fri, Sep 9, 2016 at 12:46 AM, Carl Sutton via R-help
>> <r-help at r-project.org> wrote:
>>>  Hi I have been doing theR-exercises to improve my R programming
>>> capabilities.  Data.frame exercise4 showed me that I have a languageproblem.
>>> Yes, I am frustrated, but please don?t take this as acriticism of the R
>>> language.  Theroutines I have managed to write do marvelous things in a
>>> short period oftime.  I really want to do more, but thisis a steep rocky
>>> thick with underbrush hill that is not fun to climb.  But there are good
>>> resources.  Swirl is wonderful.  My thanks to the authors of thatpackage.
>>> Jared Lander?s R for Everyoneis a really good beginners book.  DataCamp,
>>> Coursera, all informative courses.  Yes I?m frustrated.  After a couple of
>>> years on and off takingclasses, reading books, reading stack overflow and
>>> r-help just about daily, Iam learning to almost crawl.  At one timeI thought
>>> I had advanced to walking but days like today show me I?m a toddlerabout to
>>> fall on his backside. Reading the manuals onCRAN is analogous to reading the
>>> tax code. Without a specific objective for motivation, reading them is
>>> either painfulor a certain cure for insomnia. Here's the problem Ireferred
>>> to at the beginning and my "solution". #  Exercise 4 fromR Exercises#
>>> Create a simpledata frame from 3 vectors. Order the entire data frame by
>>> the#  first column.df2 <- data.frame(a =5:1,b = letters[1:5], c =
>>> runif(5))order(df2$a) Naturally the orderfunction did nothing.  But I did
>>> read the help page and thought I followedit.  And there is no obvious
>>> environmentissue.  It?s a simple data.frame and Iwant to order it by one
>>> column.  Such asdf2 <- data.table(df2)setkey(df2, a).  Done. No fuss, no
>>> muss, no needing ?with?. Per "help"Description order returns apermutation
>>> which rearranges its first argument into ascending or descendingorder,
>>> breaking ties by further arguments. sort.list is the same, using onlyone
>>> argument.See the examples for howto use these functions to sort data frames,
>>> etc. Usage order(..., na.last =TRUE, decreasing = FALSE,    method =
>>> c("shell", "radix")) sort.list(x, partial =NULL, na.last = TRUE, decreasing
>>> = FALSE,        method = c("shell", "quick","radix"))Arguments ... a
>>> sequence of numeric,complex, character or logical vectors, all of the same
>>> length, or a classed Robject. Well, doesn't ... meanany legal object?  I
>>> gave it a legal object and got nada.  And the answerabsolutely has me
>>> screaming "Say What"df2[with(df2,order(a)),]  What's with "with? In Mr.
>>> Lander?s book, page 126, ?Here we used a new function, with.  This allows us
>>> to specify the columns of adata frame without having to specify the
>>> data.frame name each time.?  Great, I?m a horrible typist and will takeany
>>> and all typing shortcuts.  However, Idon?t use it because I don?t understand
>>> what it does.  Obviously it?s important, but I?m stuck on why or how I would
>>> use it. It is one function I donot use because I find it incomprehensible.
>>> To witEvaluate an R expressionin an environment constructed from data,
>>> possibly modifying (a copy of) theoriginal data. First of all, if I'm
>>> notmodifying data (or as a subset activity creating data), why am I doing
>>> whateverit is I'm doing? ("possibly modifying (a copy of) the
>>> originaldata.") Possibly?? Evaluate. According to the thesaurus a)
>>> assess(v), b) appraise, c) gage. OK, am I in a safe area? I'll evaluate
>>> that.  Do I desire future social contact with thisperson?  I'll evaluate
>>> that. In no way do I ever evaluatean equation.  I may attempt to solve it.
>>> I may do a computer programto do the calculations and return a result.  I
>>> will probably evaluate theresult as to whether or not it helps solve the
>>> problem.  Think in terms ofan income tax return.  But evaluate an R
>>> expression?  No clue whatthat might mean.  And that is my problemin a
>>> nutshell. The remainder of thedefinition is also obtuse.  an R expression in
>>> an environmentconstructed from data.  Why would one make an environment
>>> withoutdata?  Obviously I am missing thepoint.  My own created function
>>> makes a new environment, but I onlycreated it to crunch numbers.  If it
>>> doesn't crunch numbers it's useless. The point is, I do not understand the
>>> definitionof "with" and thus have no idea how to use it.  I guesscomputerese
>>> is analogous to taxlawese.  Familiar words have entirely different meanings.
>>> Carl Sutton CPA
>>
>>>
>>>        [[alternative HTML version deleted]]
>>
>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From pdalgd at gmail.com  Sat Sep 10 11:45:39 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 10 Sep 2016 11:45:39 +0200
Subject: [R] understanding with
In-Reply-To: <alpine.BSF.2.00.1609092244490.48224@pedal.dcn.davis.ca.us>
References: <1404010802.1670182.1473396403276.ref@mail.yahoo.com>
	<1404010802.1670182.1473396403276@mail.yahoo.com>
	<CAM_vju=zfz=kxkQKEfVDhan9GA+yey4HKuAv6G2MhZD5MrP7jA@mail.gmail.com>
	<1427827072.2183819.1473456057227@mail.yahoo.com>
	<CAM_vjukXY2iY26D7LFU_tfbqXVTQ3H+swTVDTnjhykHAT051xQ@mail.gmail.com>
	<alpine.BSF.2.00.1609092244490.48224@pedal.dcn.davis.ca.us>
Message-ID: <AAAB00A9-3FB0-43C2-B9C3-31CB0B50297E@gmail.com>


> On 10 Sep 2016, at 08:27 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> 
> The with function is just helpful syntactic sugar for reducing repetitious typing of the name of the list/data frame that contains several objects you want to refer to in a single expression.

A little more than that, witness the difference between these two:

> plot(airquality$Ozone)
> with(airquality, plot(Ozone))


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From stevek9123 at gmail.com  Sat Sep 10 14:15:20 2016
From: stevek9123 at gmail.com (Stephen Kennedy)
Date: Sat, 10 Sep 2016 08:15:20 -0400
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <alpine.BSF.2.00.1609092215100.48224@pedal.dcn.davis.ca.us>
References: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
	<3C75A0E4-EDDE-4963-AAB4-9EA4CA9C797B@dcn.davis.ca.us>
	<AEAC5C2D55889A488576EDAA792CC287D6D6AA@anikaexch01.anikatherapeutics.com>
	<alpine.BSF.2.00.1609092215100.48224@pedal.dcn.davis.ca.us>
Message-ID: <CAD__wHezEo_Ce-b_9334Q1z5Rz=wHvJHS=yD_6AE=oiPtpFOLA@mail.gmail.com>

Thanks.  I have gotten some replies.  One problem was that I was not
passing the names of the vectors to expand.grid.  I didn't think I had to
do that and that caused problems with do.call.

I wanted to just define the vectors of variables values, the function,
func, and then pass that to my.outer.

I was using A <- c( ... )

Then, expand.grid(A, etc.) with do.call and as.list and without the names
use in 'fund', there was an error.  I didn't think it would matter what
names I used in defining the function.

Thanks very much.  I think I have some good alternatives that all work.

Steve


On Sat, Sep 10, 2016 at 1:29 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Not sure I understand what you really want, if you have found ways to
> accomplish what you want but are not satisfied with them. That is one
> reason why keeping the mailing list involved (by reply-all) is good for
> you. From my end, I don't do one-on-one support online, and may not be able
> to carry on a thread to the end if I get busy.
>
> Your concept of a generalized outer function sounds to me like:
>
> myfunc <- function( A, B, C ) {
>  A * B + C
> }
>
> gouter <- function( FUN, ... ) {
>  args <- list( ... )
>  DF <- do.call( expand.grid, args )
>  array( data = do.call( FUN, DF )
>       , dim = sapply( args, FUN=length )
>       , dimnames = args
>       )
> }
>
> gouter( myfunc, A = 1:3, B=2:6, C=3:4 )
> # , , C = 3
> #
> #    B
> # A   2  3  4  5  6
> #   1 5  6  7  8  9
> #   2 7  9 11 13 15
> #   3 9 12 15 18 21
> #
> # , , C = 4
> #
> #    B
> # A    2  3  4  5  6
> #   1  6  7  8  9 10
> #   2  8 10 12 14 16
> #   3 10 13 16 19 22
>
> I generally just tack on columns to the expand.grid result... I almost
> never have a need for multidimensional arrays.
>
> On Fri, 9 Sep 2016, Steve Kennedy wrote:
>
> Hello,
>>
>> Abstraction is what I want.  I'm actually looking to do something more
>> complicated.  The functions do.call, and as.list get me most of the way
>> there, but there is something I'm missing ...
>>
>> My eventual goal is to produce a multi-dimensional version of 'outer'.
>> Like my.outer(func, a_vec, b_vec, c_vec, ..), where the function of the
>> variables 'a', 'b', 'c', etc. would be applied to the vectors from the
>> outer product of the vectors of values for each variable.
>>
>> I wanted to use expand.grid (does require reshaping the output).  Using
>> temps = c(40,50,60) and times = c(1:5), this doesn't quite seem to work:
>>
>>   apply(expand.grid(temps,times), 1, function(a) do.call(func2,
>> as.list(a)))
>>
>> although this does work:
>>
>>   do.call(func2, as.list(c(10, 121)))
>>
>> And, this also works:
>>
>>  apply(expand.grid(temps,times), 1, function(a) do.call("+", as.list(a)))
>>
>> There is some subtlety here I don't understand.
>>
>> Thanks,
>>
>> Steve
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Friday, September 09, 2016 5:39 PM
>> To: Steve Kennedy; r-help at r-project.org
>> Subject: Re: [R] Apply a multi-variable function to a vector
>>
>> Your architecture has a bad smell to me. For one thing you are mixing
>> different units in the same vector but should be putting multiple instances
>> of the same variable into one vector. Lists of vectors (data frames) are
>> typically used when multiple variables need to be grouped.
>>
>> Another problem is that you are constraining the names of the variables
>> you pass to the function to be named the same as they are inside the
>> function. This really limits your use of those functions.
>>
>> There really is too much abstraction going on here.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 9, 2016 12:44:52 PM PDT, Steve Kennedy
>> <SKennedy at AnikaTherapeutics.com> wrote:
>>
>>> Hello,
>>>
>>> I would like to define an arbitrary function of an arbitrary number of
>>> variables, for example, for 2 variables:
>>>
>>> func2 <- function(time, temp) time + temp
>>>
>>> I'd like to keep variable names that have a meaning in the problem
>>> (time and temperature above).
>>>
>>> If I have a vector of values for these variables, for example in the
>>> 2-d case, c(10, 121), I'd like to apply my function (in this case
>>> func2) and obtain the result. Conceptually, something like,
>>>
>>> func2(c(10,121))
>>>
>>> becomes
>>>
>>> func2(10,121)
>>>
>>> Is there a simple way to accomplish this, for an arbitrary number of
>>> variables?  I'd like something that would simply work from the
>>> definition of the function.  If that is possible.
>>>
>>> Thanks,
>>>
>>> Steve Kennedy
>>>
>>> CONFIDENTIALITY NOTICE: This e-mail message, including
>>> a...{{dropped:11}}
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> http://cp.mcafee.com/d/k-Kr6x0g6hASyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPq
>>> tTT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOw
>>> evW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jq9JcTvANOoVcsCej76XCOsVH
>>> kiPajSvvcCatoDwCHIcfBisEeRO9sDVWNIhgxVxmhUagJ3AdcOFRJVKxJBxdcS2_id41Fr1
>>> pFtd40wIIumd46Cy1lI-syVDoOQwvVEwtrxqsGMd44WCy3jh0p-QWNdLECZzL1
>>> PLEASE do read the posting guide
>>> http://cp.mcafee.com/d/5fHCMUp418SyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPqt
>>> TT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOwe
>>> vW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jqpJcTvANOoVcsCej76XCM0gbb
>>> HhG8_qv00smHisE4iV5Ki7Y3zoyx3P2IzMkxq78qpBjHrPt3rb2qpI5-Aq83iS2PiWq811p
>>> oYIq8dd42HpYV5PeNBF0_Ph0WT2QVlwq89Rd46Cy0PZFRyrvhd_2KV
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> CONFIDENTIALITY NOTICE: This e-mail message, including any attachments,
>> contains information belonging to Anika Therapeutics, Inc. and is for the
>> sole use of the intended recipient(s) and may contain confidential,
>> proprietary, copyrighted and privileged information. Any unauthorized
>> review, use, disclosure, distribution or copying is strictly prohibited. If
>> you are not the intended recipient, please contact the sender by reply
>> e-mail and destroy all copies of the original message immediately.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Sep 10 14:42:21 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 10 Sep 2016 04:42:21 -0800
Subject: [R] GGplot annotate by facet
In-Reply-To: <DM5PR01MB254050E8101F2D70CB33D67A90FD0@DM5PR01MB2540.prod.exchangelabs.com>
Message-ID: <934DA2EAEDB.000001CDjrkrideau@inbox.com>

Hi Saad,

Please have a look at 

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
and/or
http://adv-r.had.co.nz/Reproducibility.html

for some suggestions on how to ask a question on R-help

In particular it would be handy to have some sample data in dput() format.

I always mess up geom_bar() calls and at the moment don't understand exactly what you are doing here qplot(factor(Value),data=dat1,
      geom="bar",fill=factor(Type))


John Kane
Kingston ON Canada


> -----Original Message-----
> From: smk5g5 at mail.missouri.edu
> Sent: Sat, 10 Sep 2016 01:55:18 +0000
> To: r-help at r-project.org
> Subject: [R] GGplot annotate by facet
> 
> Hi,
> 
> I have a dataframe which I need to plot in ggplot2 it looks like this :-
> 
> head(nodelta_firstexon)
>   Value Type  Histone
> 1  0.06 high  H3K27ac
> 2  0.12  low  H3K27ac
> 4  0.04 high H3K27me3
> 5  0.16  low H3K27me3
> 7  0.02 high H3K36me3
> 8  0.13  low H3K36me3
> 
> I have another data frame with p-v alues that looks like this :-
> 
> 
> head(mypval_df)
> 
>   Histone count pvalues
> 
> 1   H3K9ac     0   0.000
> 
> 2 H3K27me3     0   0.000
> 
> 3 H3K36me3  1000   1.000
> 
> 4  H3K4me3   583   0.583
> 
> 5  H3K4me1   882   0.882
> 
> 6  H3K27ac   970   0.970
> 
> This is how I plot the first dataframe  using ggplot
> p <-
> qplot(factor(Value),data=nodelta_firstexon,geom="bar",fill=factor(Type))+facet_wrap(~Histone)
> 
> Next I need to annotate p-values (p <= mypval_df$pvalues)  to each facet
> using the mypval_df.
> 
> I can't seem to find an example on how to do it. Would appreciate any
> help.
> 
> Regards
> Saad
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mdsumner at gmail.com  Sat Sep 10 10:33:53 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 10 Sep 2016 08:33:53 +0000
Subject: [R] How to read a grib2 file
In-Reply-To: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
References: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
Message-ID: <CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>

On Sat, 10 Sep 2016 at 07:12 Debasish Pai Mazumder <pai1981 at gmail.com>
wrote:

> Hi
> I am trying to read a grib2 file in R.
>
> Here is my script
>
> library(rgdal)
> library(sp)
> library(rNOMADS)
> gribfile<-"tmax.01.2011040100.daily.grb2"
> grib <- readGDAL(gribfile)
>
> I am getting following error :
>
> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
> Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
> driver GRIB
> and has 190 rows and 384 columns
> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
> Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
> image within GRIB file.
>
>
Hi there, please check if JPEG2000 is in the gdalDrivers() list, i.e.  in

rgdal::gdalDrivers()$name

You are looking for one starting with "JP2" as per the list next to the
"JPEG2000" rows here:

http://gdal.org/formats_list.html

I have  JP2OpenJPEG on one system, but not (for example) on the Windows
CRAN binary for rgdal, which is the only readily available Windows build
for this package.

I you don't have it, you might try on a system that has the JP2OpenJPEG driver,
or ask someone to try on your behalf. You'd want to find out if that will
enable this read for you before investing time in the Linux configuration.

It's not too hard to set up a Linux system for this, but does assume a bit
of experience on your part. Some of the docker images in the rockerverse
have this all sorted I believe, but it's been a while since I used them.

https://hub.docker.com/u/rocker/

Cheers, Mike.




> Cheers
> -Deb
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From joysn71 at gmail.com  Sat Sep 10 15:51:16 2016
From: joysn71 at gmail.com (Joysn71)
Date: Sat, 10 Sep 2016 15:51:16 +0200
Subject: [R] Architect from Open Analytics
Message-ID: <1473515476.27497.9.camel@gmail.com>

Hello,

i am new to R and try to use Architect from Open Analytics (0.9.8 on
Debian 64bit).?

Is anybody on this list using this tool?
I am asking because it seems to have lots of problems, like:

* not possible to open the package manager
* not possible to open details from the "About Architect" dialog
* some commands not supported

> a <- c(1:10)
> a
?[1]??1??2??3??4??5??6??7??8??9 10
> data.entry(a)
Error in dataentry(odata, as.list(Modes)) :?
? X11 dataentry cannot be loaded
In addition: Warning message:
In dataentry(odata, as.list(Modes)) :
? unable to load shared object
'/opt/architect/stable/20160518101101/plugins/eu.openanalytics.architec
t.r.server.gtk.linux.x86_64_0.9.8.201511181238/R/modules//R_de.so':
? libpng12.so.0: cannot open shared object file: No such file or
directory

Problems with Eclipse UI:

eclipse.buildId=unknown
java.version=1.8.0_102
java.vendor=Oracle Corporation
BootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_GB
Command-line arguments:??-data file:/home/chris/.architect/workspace/
-os linux -ws gtk -arch x86_64

org.eclipse.ui
Error
Sat Sep 10 15:09:55 CEST 2016
Unhandled event loop exception

java.lang.NullPointerException
	at
org.eclipse.swt.widgets.TabFolder.gtk_switch_page(TabFolder.java:490)
	at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:2009)
	at
org.eclipse.swt.widgets.Display.windowProc(Display.java:4723)
	at org.eclipse.swt.internal.gtk.OS._gtk_widget_show(Native
Method)
	at
org.eclipse.swt.internal.gtk.OS.gtk_widget_show(OS.java:14727)
	at
org.eclipse.swt.widgets.TabFolder.createItem(TabFolder.java:274)
	at
org.eclipse.swt.widgets.TabItem.createWidget(TabItem.java:123)
	at org.eclipse.swt.widgets.TabItem.<init>(TabItem.java:75)
	at
de.walware.statet.r.internal.ui.pkgmanager.RPkgManagerDialog.createDial
ogContent(RPkgManagerDialog.java:151)
	at
de.walware.statet.nico.ui.util.ToolDialog.createDialogArea(ToolDialog.j
ava:99)
	at
org.eclipse.jface.dialogs.TitleAreaDialog.createContents(TitleAreaDialo
g.java:161)
	at
de.walware.statet.r.internal.ui.pkgmanager.RPkgManagerDialog.createCont
ents(RPkgManagerDialog.java:113)
	at org.eclipse.jface.window.Window.create(Window.java:430)
	at org.eclipse.jface.dialogs.Dialog.create(Dialog.java:1096)
	at org.eclipse.jface.window.Window.open(Window.java:792)

Maybe somebody has some experience with Architect, any hint is
appreciated :)

BR
Joysn


From ruipbarradas at sapo.pt  Sat Sep 10 21:02:43 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 10 Sep 2016 20:02:43 +0100
Subject: [R] Matching/checking for occurence when values are double?
In-Reply-To: <20160909143108.Horde.mZF5b8PlQ00pLQ9xOesVDr3@mail.sapo.pt>
References: <20160909134739.Horde.NGNbUzdsVOSjpPeePOb5e8f@mail.sapo.pt>
	<7b34c3c3-97c1-4ced-cb8c-177c5a0d3bfa@univ-reims.fr>
	<20160909143108.Horde.mZF5b8PlQ00pLQ9xOesVDr3@mail.sapo.pt>
Message-ID: <20160910200243.Horde.o0szDHennVV3fObd1TMFXe-@mail.sapo.pt>

Actually, there was another reason for the function equal() but I  
wasn't remembering what.
all.equal doesn't recycle its arguments, just see this example.

equal <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps

x <- seq(0, 1, by = 0.2)
x == 0.6
all.equal(x, 0.6)
equal(x, 0.6)

Rui Barradas



Citando ruipbarradas at sapo.pt:

> Not exactly, all.equal is much more complete.
> It accepts all kinds of objects, not just vectors.
>
>
> Rui Barradas
>
>
> Citando Ivan Calandra <ivan.calandra at univ-reims.fr>:
>
>> Hi,
>>
>> Not sure, but it seems that your function equal() is exactly what  
>> all.equal() does, isn't it?
>>
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 09/09/2016 ? 14:47, ruipbarradas at sapo.pt a ?crit :
>>> Hello,
>>>
>>> See FAQ 7.31.
>>> It's irrelevant if you write 100 or 100.0, the values are the  
>>> same. The difference would be between 100 (double) and 100L  
>>> (integer).
>>> To check for equality between floating-point numbers you can use,  
>>> for instance, the following function.
>>>
>>> equal <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps
>>>
>>> equal(100, 100 + 2e-15)
>>> [1] TRUE
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> Citando Matti Viljamaa <mviljamaa at kapsi.fi>:
>>>
>>>> I need to pick from a dataset those rows that have a double value  
>>>> set to 100.
>>>> However since the values in this column are like the following:
>>>>
>>>> [1] 121.11750  89.36188 115.44320  99.44964  92.74571 107.90180
>>>> [7] 138.89310 125.14510  81.61953  95.07307  88.57700  94.85971
>>>> [13]  88.96280 114.11430 100.53410 120.41910 114.42690
>>>> ?
>>>>
>>>> Then can I match against 100 or 100.0? Or do I need to match  
>>>> against 100.00000 or something else?
>>>>
>>>> E.g. does
>>>>
>>>> 100.0 %in% kidmomiq$mom_iq
>>>>
>>>> produce a truthful match result with this kind of data (I?m  
>>>> getting 0 occurrences, which might be correct, but I?m not sure)?
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide  
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Sat Sep 10 21:23:37 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 10 Sep 2016 19:23:37 +0000 (GMT)
Subject: [R] using a regular expression
Message-ID: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>

I have a file that for basically carries three datasets of differing lengths. ?To make this a single downloadable file the creator of the file as used both NUL hex00 and space hex20 to normalize the lengths.

Below is the function that I am writing. ?I am using sed to replace the hex characters. ?First, to get past NUL I use sed to replace hex 00 with hex 20. ?This has worked. ?Once the Nul is removed and can successfully parse the file with ReadLine sub_str. ?This final step before delimiting the file and making it nice and tidy is to remove the hex 20 characters. ? I am using the same strategy to eliminate the spaces and sed command works in a shell but does not work in the R function. ?What am I doing wrong? ?I have dput - some of the nastier lines with hex 20 characters below my code.

Any advice is appreciated.

Glenn

arm <- function(filepath){
callpath <- paste(filepath, "arm.txt", sep ="")
ARMReturn <- paste(filepath, "arm.csv", sep = "")
ARMPoolReturnPath <- paste(filepath,"armatpool.csv", sep = "")
ARMNextChgReturnPath <- paste(filepath,"nexratechangedate.csv", sep = "")
ARMFirstPmtReturnPath <- paste(filepath,"firstpaymentdate.csv", sep = "")

# This file contains NUL hex characters before parsing the file replace
# the hex NUL x00 with space x20 and save as a csv file. Use system command
sedcommand <- paste("sed -e 's/\\x00/\\x20/g' <", 
filepath, "arm.txt", 
">", "arm.csv", sep = " ")
system(sedcommand)

# read the arm quartile data to a file once skipNuls then length of each
# record set changes and the data map provided by FNMA is no longer valid
# with respect to the length of each embedded data set
data <- readLines(ARMReturn, encoding = "ascii")

quartile <- NULL
numchar <- nchar(x = data, type = "chars")
start <- c(seq(1, numchar, 399))
end <- c(seq(399, numchar, 399))
quartile <- str_sub(data, start[1:length(start)], end[1:length(end)])
write(quartile, ARMReturn)

# The file has been parsed accroding to length 400 for each data element.
# The next step is to remove all the trailing white space hex character
# x20

sedcommand2 <- paste("sed -e '/\\x20/d' <", 
filepath, "arm.csv", 
">", "arm2.csv", sep = "")
system(sedcommand2)
} # end of function


c("                                                 555556 WS320021201006125{000378{000348{                                                                                                                                                                                                                                                                                                                       ", 
"                                                  555556 WS320021201006250{000954{000880{                                                                                                                                                                                                                                                                                                                      ", 
"                                                   555556 WS320021201005625{001062{000983{                                                                                                                                                                                                                                                                                                                     ", 
"                                                    555556 WS320030101005250{000027{000025{                                                                                                                                                                                                                                                                                                                    ", 
"                                                     555556 WS320030101006500{000033{000030{                                                                                                                                                                                                                                                                                                                   ", 
"                                                      555556 WS320030101005125{000061{000056{                                                                                                                                                                                                                                                                                                                  ", 
"                                                       555556 WS320030101005375{000095{000088{                                                                                                                                                                                                                                                                                                                 ", 
"                                                        555556 WS320030101005350{000217{000200{                                                                                                                                                                                                                                                                                                                ", 
"                                                         555556 WS320030101006125{000400{000369{                                                                                                                                                                                                                                                                                                               ", 
"                                                          555556 WS320030101005310{000439{000406{                                                                                                                                                                                                                                                                                                              ", 
"                                                           555556 WS320030101006000{000573{000529{                                                                                                                                                                                                                                                                                                             "





From r at catwhisker.org  Sun Sep 11 15:50:14 2016
From: r at catwhisker.org (David Wolfskill)
Date: Sun, 11 Sep 2016 06:50:14 -0700
Subject: [R] using a regular expression
In-Reply-To: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
References: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
Message-ID: <20160911135014.GI1100@albert.catwhisker.org>

On Sat, Sep 10, 2016 at 07:23:37PM +0000, Glenn Schultz wrote:
> ...
> Below is the function that I am writing. ?I am using sed to replace the hex characters. ?First, to get past NUL I use sed to replace hex 00 with hex 20. ?This has worked. ?Once the Nul is removed and can successfully parse the file with ReadLine sub_str. ?This final step before delimiting the file and making it nice and tidy is to remove the hex 20 characters. ? I am using the same strategy to eliminate the spaces and sed command works in a shell but does not work in the R function. ?What am I doing wrong? ?I have dput - some of the nastier lines with hex 20 characters below my code.

I believe that you will find that the sed "d" command deletes the
"pattern space" (in a simple text file, it would delete the line) in
which the specified regular expression is found.

I suspect that you actually want to eliminate the "space" characters
themselves, so rather than:

> ...
> # The file has been parsed accroding to length 400 for each data element.
> # The next step is to remove all the trailing white space hex character
> # x20
> 
> sedcommand2 <- paste("sed -e '/\\x20/d' <", 

what is wanted is:

sedcommand2 <- paste("sed -e 's/\\x20//g' <", 

> ... 

Note that you might consider using R's gsub() function to perform that
"space elimination"both natively and a bit earlier.

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who would murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160911/9bf52a5e/attachment.bin>

From marco.prado.bs at gmail.com  Sun Sep 11 17:54:11 2016
From: marco.prado.bs at gmail.com (Marco Silva)
Date: Sun, 11 Sep 2016 12:54:11 -0300
Subject: [R] using a regular expression
In-Reply-To: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
References: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
Message-ID: <1473608568-sup-78@ubatuba>

Excerpts from Glenn Schultz's message of 2016-09-10 19:23:37 +0000:
> I have a file that for basically carries three datasets of differing
> lengths. ?To make this a single downloadable file the creator of the
> file as used both NUL hex00 and space hex20 to normalize the lengths.
> 
> Below is the function that I am writing. ?I am using sed to replace
> the hex characters. ?First, to get past NUL I use sed to replace hex
> 00 with hex 20. ?This has worked. ?Once the Nul is removed and can
> successfully parse the file with ReadLine sub_str. ?This final step
> before delimiting the file and making it nice and tidy is to remove
> the hex 20 characters. ? I am using the same strategy to eliminate the
> spaces and sed command works in a shell but does not work in the R
> function. ?What am I doing wrong? ?I have dput - some of the nastier
> lines with hex 20 characters below my code.
> 
> Any advice is appreciated.

You can use readLines(pipe(sedcommand)) to get the filtered dataset.

I didn't understand what kind of filtering you are doing, it seems
confused to me. But, someone pointed out that use of command 'd' is for
deletion of the role pattern space, so if you are trying to substitute
use:

s/pattern//g # effectively removing pattern from the text


Best Luck,

Marco

-- 
Marco Arthur @ (M)arco Creatives


From thierry.onkelinx at inbo.be  Sun Sep 11 22:12:20 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 11 Sep 2016 22:12:20 +0200
Subject: [R] digital online identifier (doi) CRAN manual?
In-Reply-To: <CADKEMqgzMesq3J3qW1nHr8HAvExJWtHCTRpahvFdCw_d8agDTQ@mail.gmail.com>
References: <CADKEMqgzMesq3J3qW1nHr8HAvExJWtHCTRpahvFdCw_d8agDTQ@mail.gmail.com>
Message-ID: <CAJuCY5y9PkYfMEafmhJRnJCwvAi-=mCsc=c1SBgY8SL3yLAxyQ@mail.gmail.com>

Dear Stephen,

I use https://zenodo.org/ to get a DOI for a package. E.g.
http://dx.doi.org/10.5281/zenodo.48423

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-09 15:30 GMT+02:00 stephen sefick <ssefick at gmail.com>:

> Hello all,
>
> I apologize if this is the incorrect forum for this query. I am a package
> maintainer, and would like to have a doi for the package manual. What might
> be a good way to go about this?
> kindest regards,
>
> Stephen Sefick
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chrishold at psyctc.org  Mon Sep 12 07:57:39 2016
From: chrishold at psyctc.org (Chris Evans)
Date: Mon, 12 Sep 2016 06:57:39 +0100 (BST)
Subject: [R] Help with strftime error "character string is not in a standard
 unambiguous format"
Message-ID: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>

I am trying to read activity data created by Garmin. It outputs dates like this:

"Thu, 25 Aug 2016 6:34 PM"

The problem that has stumped me is this:

> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
Error in as.POSIXlt.character(x, tz = tz) : 
  character string is not in a standard unambiguous format

I _thought_ I had this running OK but that error is catching me now.  I think I've read ?strftime and written that format string correctly to match the input but I'm stumped now.

Can someone advise me?  Many thanks in advance,

Chris


> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=English_United Kingdom.1252 
[2] LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.3.1 tools_3.3.1   
>


From chrishold at psyctc.org  Mon Sep 12 12:33:23 2016
From: chrishold at psyctc.org (Chris Evans)
Date: Mon, 12 Sep 2016 11:33:23 +0100 (BST)
Subject: [R] Help with strftime error "character string is not in a
 standard unambiguous format"
In-Reply-To: <247D5644-7908-4186-A0F0-AD6221CE81BE@gmail.com>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
	<247D5644-7908-4186-A0F0-AD6221CE81BE@gmail.com>
Message-ID: <2008343551.62062455.1473676403125.JavaMail.zimbra@psyctc.org>

OK. I'm an idiot (not for the first time and, sadly, no doubt not for the last). strptime() was all that was needed: just that one pesky character and I can't remember now why I went astray there, but thanks to all who supplied the answer and all who supplied additional useful information. 

As ever, deeply indebted to the R and R-help communities, 

Chris 

> From: "Ismail SEZEN" <sezenismail at gmail.com>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "r-help" <r-help at r-project.org>
> Sent: Monday, 12 September, 2016 10:36:51
> Subject: Re: [R] Help with strftime error "character string is not in a standard
> unambiguous format"

> It should be strptime for character vectors.

> strptime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p?)

>> On 12 Sep 2016, at 08:57, Chris Evans < chrishold at psyctc.org > wrote:

>>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
	[[alternative HTML version deleted]]


From es at enricoschumann.net  Mon Sep 12 11:05:44 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 12 Sep 2016 11:05:44 +0200
Subject: [R] Help with strftime error "character string is not in a
	standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
	(Chris Evans's message of "Mon, 12 Sep 2016 06:57:39 +0100 (BST)")
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <87d1k9jxnb.fsf@enricoschumann.net>

On Mon, 12 Sep 2016, Chris Evans <chrishold at psyctc.org> writes:

> I am trying to read activity data created by Garmin. It outputs dates like this:
>
> "Thu, 25 Aug 2016 6:34 PM"
>
> The problem that has stumped me is this:
>
>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
> Error in as.POSIXlt.character(x, tz = tz) : 
>   character string is not in a standard unambiguous format


Didn't you mean strptime?
                   ^
  > strptime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")

  ## [1] "2016-08-25 18:34:00 CEST"


> I _thought_ I had this running OK but that error is catching me now.
> I think I've read ?strftime and written that format string correctly
> to match the input but I'm stumped now.
>
> Can someone advise me?  Many thanks in advance,
>
> Chris
>
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252 
> [2] LC_CTYPE=English_United Kingdom.1252   
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                           
> [5] LC_TIME=English_United Kingdom.1252    
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
>
> loaded via a namespace (and not attached):
> [1] compiler_3.3.1 tools_3.3.1   
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From pdalgd at gmail.com  Mon Sep 12 09:12:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 12 Sep 2016 09:12:06 +0200
Subject: [R] Help with strftime error "character string is not in a
	standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <D713FEBE-56B7-43E6-8DA6-AE2EB61D99A5@gmail.com>


> On 12 Sep 2016, at 07:57 , Chris Evans <chrishold at psyctc.org> wrote:
> 
>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")

strptime, not strftime...

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sezenismail at gmail.com  Mon Sep 12 11:36:51 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 12 Sep 2016 12:36:51 +0300
Subject: [R] Help with strftime error "character string is not in a
	standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <247D5644-7908-4186-A0F0-AD6221CE81BE@gmail.com>

It should be strptime for character vectors.

strptime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p?)

> On 12 Sep 2016, at 08:57, Chris Evans <chrishold at psyctc.org> wrote:
> 
>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")


	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Mon Sep 12 10:23:57 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Mon, 12 Sep 2016 01:23:57 -0700
Subject: [R] Help with strftime error "character string is not in a
 standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <531ea40f-e771-9b53-cfb0-2afaf6e0137f@gmail.com>

On 9/11/2016 10:57 PM, Chris Evans wrote:
> I am trying to read activity data created by Garmin. It outputs dates like this:
>
> "Thu, 25 Aug 2016 6:34 PM"
>
> The problem that has stumped me is this:
>
>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
> Error in as.POSIXlt.character(x, tz = tz) :
>   character string is not in a standard unambiguous format
>
> I _thought_ I had this running OK but that error is catching me now.  I think I've read ?strftime and written that format string correctly to match the input but I'm stumped now.
>
> Can someone advise me?  Many thanks in advance,
>
> Chris
>
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.3.1 tools_3.3.1
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

I have always used strptime() for this task, and

 > strptime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
[1] "2016-08-25 18:34:00 PDT"

works for me.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From pdalgd at gmail.com  Mon Sep 12 13:25:24 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 12 Sep 2016 13:25:24 +0200
Subject: [R] Help with strftime error "character string is not in a
	standard unambiguous format"
In-Reply-To: <2008343551.62062455.1473676403125.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
	<247D5644-7908-4186-A0F0-AD6221CE81BE@gmail.com>
	<2008343551.62062455.1473676403125.JavaMail.zimbra@psyctc.org>
Message-ID: <CC39AEFE-E77F-4D47-9849-C60A70B3F58E@gmail.com>


On 12 Sep 2016, at 12:33 , Chris Evans <chrishold at psyctc.org> wrote:

> OK. I'm an idiot (not for the first time and, sadly, no doubt not for the last). strptime() was all that was needed: just that one pesky character and I can't remember now why I went astray there, but thanks to all who supplied the answer and all who supplied additional useful information. 

Usually happens because you think it is p for print, so the other one must be f. (It's really _p_arse and _f_ormat.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From roundsjeremiah at gmail.com  Mon Sep 12 09:37:56 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Mon, 12 Sep 2016 00:37:56 -0700
Subject: [R] Help with strftime error "character string is not in a
 standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <CAOjnRsattSU46upF64g-anMqbYfw+5inVAZ8-XUdDmO_v+Fr5A@mail.gmail.com>

Not sure what the issue is with the provided code  but note:
library(lubridate)
 lubridate::dmy_hm("Thu, 25 Aug 2016 6:34 PM")
[1] "2016-08-25 18:34:00 UTC"


Though if you go that route: set the TZ because on the timestamp it is
ambiguous.

On Sun, Sep 11, 2016 at 10:57 PM, Chris Evans <chrishold at psyctc.org> wrote:

> I am trying to read activity data created by Garmin. It outputs dates like
> this:
>
> "Thu, 25 Aug 2016 6:34 PM"
>
> The problem that has stumped me is this:
>
> > strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
> Error in as.POSIXlt.character(x, tz = tz) :
>   character string is not in a standard unambiguous format
>
> I _thought_ I had this running OK but that error is catching me now.  I
> think I've read ?strftime and written that format string correctly to match
> the input but I'm stumped now.
>
> Can someone advise me?  Many thanks in advance,
>
> Chris
>
>
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.3.1 tools_3.3.1
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Sep 12 10:00:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Sep 2016 01:00:48 -0700
Subject: [R] Help with strftime error "character string is not in a
	standard unambiguous format"
In-Reply-To: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
References: <1235908215.61957888.1473659859937.JavaMail.zimbra@psyctc.org>
Message-ID: <92AEC9AB-FCF9-4C29-A56D-2EDD6E3DB4E6@dcn.davis.ca.us>

Perhaps use the correct function.  (Just one little letter off...)
-- 
Sent from my phone. Please excuse my brevity.

On September 11, 2016 10:57:39 PM PDT, Chris Evans <chrishold at psyctc.org> wrote:
>I am trying to read activity data created by Garmin. It outputs dates
>like this:
>
>"Thu, 25 Aug 2016 6:34 PM"
>
>The problem that has stumped me is this:
>
>> strftime("Thu, 25 Aug 2016 6:34 PM",format="%a, %d %b %Y %I:%M %p")
>Error in as.POSIXlt.character(x, tz = tz) : 
>  character string is not in a standard unambiguous format
>
>I _thought_ I had this running OK but that error is catching me now.  I
>think I've read ?strftime and written that format string correctly to
>match the input but I'm stumped now.
>
>Can someone advise me?  Many thanks in advance,
>
>Chris
>
>
>> sessionInfo()
>R version 3.3.1 (2016-06-21)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 10 x64 (build 10586)
>
>locale:
>[1] LC_COLLATE=English_United Kingdom.1252 
>[2] LC_CTYPE=English_United Kingdom.1252   
>[3] LC_MONETARY=English_United Kingdom.1252
>[4] LC_NUMERIC=C                           
>[5] LC_TIME=English_United Kingdom.1252    
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] compiler_3.3.1 tools_3.3.1   
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From nicholas.wray at ntlworld.com  Mon Sep 12 14:56:46 2016
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 12 Sep 2016 13:56:46 +0100 (BST)
Subject: [R] Where are the PCA outputs?
Message-ID: <2087264668.246098.1473685006630.JavaMail.open-xchange@oxbe17.tb.ukmail.iss.as9143.net>

Hi R Folk  I have been kicking some data around and one thing has been to try a
PC analysis  on it, but whereas in the online examples I've looked at the prcomp
function gives a set of five outputs when I use the prcomp function it only
gives me a set of standard deviations and the rotation matrix

My data (pcl) is this:

resmat.3...2. resmat.3...3. resmat.3...4.
1     0.08749276   0.015706470         0.259
2     0.08749276   0.039266176         0.198
3     0.10630841   0.047119411         0.235
4     0.25307047   0.062825881         0.374
5     0.14393971   0.117798527         0.534
6     0.23049169   0.023559705         0.355
7     0.15052518   0.007853235         0.179
8     0.09784137   0.031412940         0.219
9     0.09878215   0.039266176         0.301
10    0.14111736   0.157064702         0.285
11    0.03951286   0.015706470         0.036
12    0.16181457   0.125651762         0.324
13    0.13359110   0.031412940         0.304
14    0.08278885   0.031412940         0.221
15    0.08561120   0.023559705         0.207
16    0.12042015   0.039266176         0.194
17    0.13359110   0.047119411         0.164
18    0.08937433   0.047119411         0.216
19    0.12700562   0.023559705         0.230

the output is then
> prcomp(pcl,scale.=T)
Standard deviations:
[1] 1.4049397 0.8447366 0.5590747

Rotation:
PC1         PC2        PC3
resmat.3...2. 0.5599782 -0.64434772 -0.5208075
resmat.3...3. 0.5229417  0.76245515 -0.3810434
resmat.3...4. 0.6426168 -0.05897597  0.7639146

Does anyone know why the other things are not appearing?

Thanks, Nick
	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Mon Sep 12 15:00:50 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 12 Sep 2016 08:00:50 -0500
Subject: [R] Where are the PCA outputs?
In-Reply-To: <2087264668.246098.1473685006630.JavaMail.open-xchange@oxbe17.tb.ukmail.iss.as9143.net>
References: <2087264668.246098.1473685006630.JavaMail.open-xchange@oxbe17.tb.ukmail.iss.as9143.net>
Message-ID: <CAKxd1KONFf1Gnym_VSy_6HbPYbWRV42NcX0vhKyu3-=3dJ7Lpg@mail.gmail.com>

Hi Nick,

"prcomp" returns an object of class "prcomp" so when you simply 'print' the
object it gets passed to the "print.prcomp" function.  If you want to see
all the objects you should assign the results to an object.

Regards,
Charles

On Mon, Sep 12, 2016 at 7:56 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

> Hi R Folk  I have been kicking some data around and one thing has been to
> try a
> PC analysis  on it, but whereas in the online examples I've looked at the
> prcomp
> function gives a set of five outputs when I use the prcomp function it only
> gives me a set of standard deviations and the rotation matrix
>
> My data (pcl) is this:
>
> resmat.3...2. resmat.3...3. resmat.3...4.
> 1     0.08749276   0.015706470         0.259
> 2     0.08749276   0.039266176         0.198
> 3     0.10630841   0.047119411         0.235
> 4     0.25307047   0.062825881         0.374
> 5     0.14393971   0.117798527         0.534
> 6     0.23049169   0.023559705         0.355
> 7     0.15052518   0.007853235         0.179
> 8     0.09784137   0.031412940         0.219
> 9     0.09878215   0.039266176         0.301
> 10    0.14111736   0.157064702         0.285
> 11    0.03951286   0.015706470         0.036
> 12    0.16181457   0.125651762         0.324
> 13    0.13359110   0.031412940         0.304
> 14    0.08278885   0.031412940         0.221
> 15    0.08561120   0.023559705         0.207
> 16    0.12042015   0.039266176         0.194
> 17    0.13359110   0.047119411         0.164
> 18    0.08937433   0.047119411         0.216
> 19    0.12700562   0.023559705         0.230
>
> the output is then
> > prcomp(pcl,scale.=T)
> Standard deviations:
> [1] 1.4049397 0.8447366 0.5590747
>
> Rotation:
> PC1         PC2        PC3
> resmat.3...2. 0.5599782 -0.64434772 -0.5208075
> resmat.3...3. 0.5229417  0.76245515 -0.3810434
> resmat.3...4. 0.6426168 -0.05897597  0.7639146
>
> Does anyone know why the other things are not appearing?
>
> Thanks, Nick
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From benjamin.stocker at daimler.com  Mon Sep 12 09:39:34 2016
From: benjamin.stocker at daimler.com (benjamin.stocker at daimler.com)
Date: Mon, 12 Sep 2016 07:39:34 +0000
Subject: [R] commercial license
Message-ID: <aa457e0c168e423f96adef0fddb0d426@DE36S004EXC87.wp.corpintra.net>

Dear r-project Team

How does It cost a commercial license for the R Console and the R-comander GUI without the Rstudio enviroment.
Thanks for helping me.


Freundliche Gr?sse/Kind regards

Benjamin Stocker
Reporting/Controlling MBC
Mercedes-Benz Schweiz AG
Bernstrasse 55
8952 Schlieren/Switzerland

Phone +41 44 755 84 24
Fax +41 44 755 82 17
mailto:benjamin.stocker at daimler.com

www.mercedes-benz.ch<http://www.mercedes-benz.ch/>


If you are not the addressee, please inform us immediately that you have received this e-mail by mistake, and delete it. We thank you for your support.


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Sep 12 16:10:41 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 12 Sep 2016 16:10:41 +0200
Subject: [R] commercial license
In-Reply-To: <aa457e0c168e423f96adef0fddb0d426@DE36S004EXC87.wp.corpintra.net>
References: <aa457e0c168e423f96adef0fddb0d426@DE36S004EXC87.wp.corpintra.net>
Message-ID: <CAJuCY5zugPCF9PFEzEQu86uT0GZS62189BpBdv9b6y7RGCGT5Q@mail.gmail.com>

Dear Benjamin,

Have a look at FAQ 2.11:
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-12 9:39 GMT+02:00 <benjamin.stocker at daimler.com>:

> Dear r-project Team
>
> How does It cost a commercial license for the R Console and the R-comander
> GUI without the Rstudio enviroment.
> Thanks for helping me.
>
>
> Freundliche Gr?sse/Kind regards
>
> Benjamin Stocker
> Reporting/Controlling MBC
> Mercedes-Benz Schweiz AG
> Bernstrasse 55
> 8952 Schlieren/Switzerland
>
> Phone +41 44 755 84 24
> Fax +41 44 755 82 17
> mailto:benjamin.stocker at daimler.com
>
> www.mercedes-benz.ch<http://www.mercedes-benz.ch/>
>
>
> If you are not the addressee, please inform us immediately that you have
> received this e-mail by mistake, and delete it. We thank you for your
> support.
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Sep 12 16:14:15 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 12 Sep 2016 15:14:15 +0100
Subject: [R] commercial license
In-Reply-To: <432e5ad48de04927aca47c05fa938a4a@EX-0-HT0.lancs.local>
References: <432e5ad48de04927aca47c05fa938a4a@EX-0-HT0.lancs.local>
Message-ID: <CANVKczP4orRJBbF6S5gLsjyqb-fPxitLQPbE8UbJhAeh2KNuKw@mail.gmail.com>

Why do you want a commercial license? The software is free of charge
and free to use anywhere.

If you want support of some kind, then you need to spell this out -
there are companies and consultants who will support your R work for a
price.


On Mon, Sep 12, 2016 at 8:39 AM, benjamin.stocker at daimler.com
<benjamin.stocker at daimler.com> wrote:
> Dear r-project Team
>
> How does It cost a commercial license for the R Console and the R-comander GUI without the Rstudio enviroment.
> Thanks for helping me.
>
>
> Freundliche Gr?sse/Kind regards
>
> Benjamin Stocker
> Reporting/Controlling MBC
> Mercedes-Benz Schweiz AG
> Bernstrasse 55
> 8952 Schlieren/Switzerland
>
> Phone +41 44 755 84 24
> Fax +41 44 755 82 17
> mailto:benjamin.stocker at daimler.com
>
> www.mercedes-benz.ch<http://www.mercedes-benz.ch/>
>
>
> If you are not the addressee, please inform us immediately that you have received this e-mail by mistake, and delete it. We thank you for your support.
>
>
>         [[alternative HTML version deleted]]
>


From stefano.sofia at regione.marche.it  Mon Sep 12 16:19:40 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 12 Sep 2016 14:19:40 +0000
Subject: [R] (no subject)
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBDB118@ESINO.regionemarche.intra>

Thank you to Sarah Goslee and Ivan Calandra for their exhaustive explanations.

About Ivan Calandra's suggestion to put data in the right format adding a column "station" with values being
either RM or RT, I would ask Ivan if he means to divide the initial data frame into two data frames, one for RM and one for RT.
If this is the case, then I would find a way to link the two data frames, and this might not be the most efficient solution. But likely I miss the true meaning of the comment.

Thank you
Stefano

----------------------------------------------------------------------------------------
>
> Message: 14
> Date: Wed, 7 Sep 2016 16:56:20 +0200
> From: Ivan Calandra <ivan.calandra at univ-reims.fr>
> To: r-help at r-project.org
> Subject: Re: [R] how to manage missing values correctly when importing
>         a data frame
> Message-ID: <388bc333-497c-f806-e367-8aecb0a7df26 at univ-reims.fr>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
> Hi Stefano,
>
> I agree that this behavior of R can be somewhat counter-intuitive, but
> this can be seen as a safety procedure, so that no assumptions are made
> and problems can be easily identified.
>
> I would think that in this case, the input data is in the wrong format.
> Half the columns are for RM and the other for RT, but the headers are
> exactly the same. The problem then happens because you actually have
> only 3 lines of data for station RT but 4 for station RM. So it is
> filled with NA.
>
> IMHO, it would be better to add a column "station" with values being
> either RM or RT. In that case, you would not have whole NA lines. And
> you would have less columns to work with. See what I mean?
>
> By the way, I like the matrix method for subsetting a data.frame, I find
> it easier and more flexible (maybe someone will tell if there are any
> drawbacks):
> Storia_RM_RT[Storia_RM_RT$Station_RT==112, "Test_20151231"]
>
> HTH,
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
>
> ----------------------------------------------------------------------------------------

> Original Message:
>
> Dear R users,
> I have a data frame with 22 columns, called Storia_RM_RT. Here the first 4 rows:
>
> Station_RM Sensor_RM Place_RM Y_init_RM M_init_RM D_init_RM Long_cent_RM Lat_cent_RM Height_RM Continues Station_RT Sensor_RT Place_RT Name1_RT Name2_RT Long_cent_RT Lat_cent_RT Height_RT Actual_net Notes
> Test_20141231 Test_20151231
> 1400 2701 Novafeltria 1959 1 1 12.289552 43.890057 293 NO NA NA NA NA NA NA NA NA CAE NA NO NO
> 1460 2702 Carpegna 1963 1 1 12.332614 43.778107 748 SI 702 2954 Carpegna Carpegna Carpegna 12.340618 43.780575 715 RT NA NO NO
> 1500 2703 Pesaro 1957 1 1 12.909822 43.910889 11 SI 112 1229 Pesaro Villa_Fastiggi Villa_Fastiggi 12.86939 43.890610 22 RT NA YES YES
> 1520 2704 Fano 1957 1 1 13.017591 43.840054 4 SI 152 2671 Fano Foce_Metauro Metaurilia 13.053796 43.826328 7.12 RT NA YES YES
>
> I load it with
> Storia_RM_RT <- read.table(file="Storia_RM_RT.txt", header = TRUE, sep=" ", dec = ".", stringsAsFactors = FALSE)
>
> print(Storia_RM_RT$Test_20151231[Storia_RM_RT$Station_RM == 1500]) gives
> [1] "YES"
>
> while
> print(Storia_RM_RT$Omogenea_20151231[Storia_RM_RT$Station_RT == 112]) gives
> [1] NA   "YES"
>
>
> I am struggling to understand why the query through the field Station_RT does not work.
> Could please somebody help me to manage correctly the missing values? Is the mistake somewhere else?
>
> Thank you
> Stefano Sofia


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Sep 12 16:28:48 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 12 Sep 2016 14:28:48 +0000
Subject: [R] Where are the PCA outputs?
In-Reply-To: <CAKxd1KONFf1Gnym_VSy_6HbPYbWRV42NcX0vhKyu3-=3dJ7Lpg@mail.gmail.com>
References: <2087264668.246098.1473685006630.JavaMail.open-xchange@oxbe17.tb.ukmail.iss.as9143.net>
	<CAKxd1KONFf1Gnym_VSy_6HbPYbWRV42NcX0vhKyu3-=3dJ7Lpg@mail.gmail.com>
Message-ID: <c9f6671408b9464b8e427aa440917338@exch-2p-mbx-w2.ads.tamu.edu>

At the risk of being redundant, the command prcomp(pcl, scale.=T) is the same as the command print(prcomp(pcl, scale.=T)). This passes the results of prcomp() to print() which prints some of them (whatever the function print.prcomp() is programmed to display) and then throws them away. To save the results, you need to assign them to an object, e.g.

> pcl.pca <- prcomp(pcl, scale.=T)

Or any other name you choose. Now pcl.pca is a list of 5 elements:

> str(pcl.pca)
List of 5
 $ sdev    : num [1:3] 1.405 0.845 0.559
 $ rotation: num [1:3, 1:3] 0.56 0.523 0.643 -0.644 0.762 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "resmat.3...2." "resmat.3...3." "resmat.3...4."
  .. ..$ : chr [1:3] "PC1" "PC2" "PC3"
 $ center  : Named num [1:3] 0.1248 0.0488 0.2545
  ..- attr(*, "names")= chr [1:3] "resmat.3...2." "resmat.3...3." "resmat.3...4."
 $ scale   : Named num [1:3] 0.051 0.0405 0.1023
  ..- attr(*, "names")= chr [1:3] "resmat.3...2." "resmat.3...3." "resmat.3...4."
 $ x       : num [1:19, 1:3] -0.808 -0.887 -0.346 2.341 2.857 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:19] "1" "2" "3" "4" ...
  .. ..$ : chr [1:3] "PC1" "PC2" "PC3"
 - attr(*, "class")= chr "prcomp"

To plot the principal component scores, try

> plot(pcl.pca$x[, 1:2])

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Determan
Sent: Monday, September 12, 2016 8:01 AM
To: WRAY NICHOLAS
Cc: r-help
Subject: Re: [R] Where are the PCA outputs?

Hi Nick,

"prcomp" returns an object of class "prcomp" so when you simply 'print' the
object it gets passed to the "print.prcomp" function.  If you want to see
all the objects you should assign the results to an object.

Regards,
Charles

On Mon, Sep 12, 2016 at 7:56 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

> Hi R Folk  I have been kicking some data around and one thing has been to
> try a
> PC analysis  on it, but whereas in the online examples I've looked at the
> prcomp
> function gives a set of five outputs when I use the prcomp function it only
> gives me a set of standard deviations and the rotation matrix
>
> My data (pcl) is this:
>
> resmat.3...2. resmat.3...3. resmat.3...4.
> 1     0.08749276   0.015706470         0.259
> 2     0.08749276   0.039266176         0.198
> 3     0.10630841   0.047119411         0.235
> 4     0.25307047   0.062825881         0.374
> 5     0.14393971   0.117798527         0.534
> 6     0.23049169   0.023559705         0.355
> 7     0.15052518   0.007853235         0.179
> 8     0.09784137   0.031412940         0.219
> 9     0.09878215   0.039266176         0.301
> 10    0.14111736   0.157064702         0.285
> 11    0.03951286   0.015706470         0.036
> 12    0.16181457   0.125651762         0.324
> 13    0.13359110   0.031412940         0.304
> 14    0.08278885   0.031412940         0.221
> 15    0.08561120   0.023559705         0.207
> 16    0.12042015   0.039266176         0.194
> 17    0.13359110   0.047119411         0.164
> 18    0.08937433   0.047119411         0.216
> 19    0.12700562   0.023559705         0.230
>
> the output is then
> > prcomp(pcl,scale.=T)
> Standard deviations:
> [1] 1.4049397 0.8447366 0.5590747
>
> Rotation:
> PC1         PC2        PC3
> resmat.3...2. 0.5599782 -0.64434772 -0.5208075
> resmat.3...3. 0.5229417  0.76245515 -0.3810434
> resmat.3...4. 0.6426168 -0.05897597  0.7639146
>
> Does anyone know why the other things are not appearing?
>
> Thanks, Nick
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From albmont at centroin.com.br  Mon Sep 12 16:32:47 2016
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Mon, 12 Sep 2016 10:32:47 -0400
Subject: [R] (d,p,r,q) for all distributions, but no m?
Message-ID: <480604097.395567426.1473690767952.JavaMail.zimbra@centroin.com.br>

Today I need to compute the means for some distributions... and there's no easy way to do it!

I mean (no pun intended), there is (d,p,r,q) for all distributions (like: dgamma, pgamma, rgamma, qgamma; dchisq, pchisq, rchisq, dchisp; etc), but there is no "m"-functions, like a mgamma to get the mean (or any momentum) of gamma, a mchisq, a mnorm, etc.

May I suggest adding these functions?

Alberto Monteiro


From bgunter.4567 at gmail.com  Mon Sep 12 16:51:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Sep 2016 07:51:28 -0700
Subject: [R] (d,p,r,q) for all distributions, but no m?
In-Reply-To: <480604097.395567426.1473690767952.JavaMail.zimbra@centroin.com.br>
References: <480604097.395567426.1473690767952.JavaMail.zimbra@centroin.com.br>
Message-ID: <CAGxFJbT94Z_1D5vnZ9Li2TOUxp9vFoK8hHsjAYWNwH_rc=qZdg@mail.gmail.com>

No you may not.

I suggest that you *first search before posting* -- e.g. on "R package
moments of distributions" -- where you would find the package
"moments" that apparently already does exactly what you suggest (there
are some other packages as well). You could also first search the CRAN
task views site to find this:

https://cran.r-project.org/web/views/Distributions.html

R is a mature software environment with something like 8000 packages.
It is highly unlikely that you (or I !) would think of some simple
statistical functionality that is not already available.



Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 12, 2016 at 7:32 AM, ALBERTO VIEIRA FERREIRA MONTEIRO
<albmont at centroin.com.br> wrote:
> Today I need to compute the means for some distributions... and there's no easy way to do it!
>
> I mean (no pun intended), there is (d,p,r,q) for all distributions (like: dgamma, pgamma, rgamma, qgamma; dchisq, pchisq, rchisq, dchisp; etc), but there is no "m"-functions, like a mgamma to get the mean (or any momentum) of gamma, a mchisq, a mnorm, etc.
>
> May I suggest adding these functions?
>
> Alberto Monteiro
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Mon Sep 12 17:01:03 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 12 Sep 2016 15:01:03 +0000
Subject: [R] commercial license
In-Reply-To: <aa457e0c168e423f96adef0fddb0d426@DE36S004EXC87.wp.corpintra.net>
References: <aa457e0c168e423f96adef0fddb0d426@DE36S004EXC87.wp.corpintra.net>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83657680F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Benjamin,

Like R, the Rcmdr package is free software distributed under the GNU General Public License. For more information, type ?license at the R > command prompt.

I hope this helps,
 John

--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> benjamin.stocker at daimler.com
> Sent: Monday, September 12, 2016 3:40 AM
> To: r-help at r-project.org
> Subject: [R] commercial license
> 
> Dear r-project Team
> 
> How does It cost a commercial license for the R Console and the R-
> comander GUI without the Rstudio enviroment.
> Thanks for helping me.
> 
> 
> Freundliche Gr?sse/Kind regards
> 
> Benjamin Stocker
> Reporting/Controlling MBC
> Mercedes-Benz Schweiz AG
> Bernstrasse 55
> 8952 Schlieren/Switzerland
> 
> Phone +41 44 755 84 24
> Fax +41 44 755 82 17
> mailto:benjamin.stocker at daimler.com
> 
> www.mercedes-benz.ch<http://www.mercedes-benz.ch/>
> 
> 
> If you are not the addressee, please inform us immediately that you have
> received this e-mail by mistake, and delete it. We thank you for your
> support.
> 
> 
> 	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Sep 12 18:32:30 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Sep 2016 09:32:30 -0700
Subject: [R] using a regular expression
In-Reply-To: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
References: <73d3b297-e335-4244-89c8-22c922b4a7cd@me.com>
Message-ID: <34EA2123-D5F4-44FC-9554-CEFE722A257F@dcn.davis.ca.us>

If you think you might want to put this function into a package, it would be much better to use gsub instead of passing the job off to an external program, because non-POSIX operating systems (Windows) will be a headache to support.
-- 
Sent from my phone. Please excuse my brevity.

On September 10, 2016 12:23:37 PM PDT, Glenn Schultz <glennmschultz at me.com> wrote:
>I have a file that for basically carries three datasets of differing
>lengths. ?To make this a single downloadable file the creator of the
>file as used both NUL hex00 and space hex20 to normalize the lengths.
>
>Below is the function that I am writing. ?I am using sed to replace the
>hex characters. ?First, to get past NUL I use sed to replace hex 00
>with hex 20. ?This has worked. ?Once the Nul is removed and can
>successfully parse the file with ReadLine sub_str. ?This final step
>before delimiting the file and making it nice and tidy is to remove the
>hex 20 characters. ? I am using the same strategy to eliminate the
>spaces and sed command works in a shell but does not work in the R
>function. ?What am I doing wrong? ?I have dput - some of the nastier
>lines with hex 20 characters below my code.
>
>Any advice is appreciated.
>
>Glenn
>
>arm <- function(filepath){
>callpath <- paste(filepath, "arm.txt", sep ="")
>ARMReturn <- paste(filepath, "arm.csv", sep = "")
>ARMPoolReturnPath <- paste(filepath,"armatpool.csv", sep = "")
>ARMNextChgReturnPath <- paste(filepath,"nexratechangedate.csv", sep =
>"")
>ARMFirstPmtReturnPath <- paste(filepath,"firstpaymentdate.csv", sep =
>"")
>
># This file contains NUL hex characters before parsing the file replace
># the hex NUL x00 with space x20 and save as a csv file. Use system
>command
>sedcommand <- paste("sed -e 's/\\x00/\\x20/g' <", 
>filepath, "arm.txt", 
>">", "arm.csv", sep = " ")
>system(sedcommand)
>
># read the arm quartile data to a file once skipNuls then length of
>each
># record set changes and the data map provided by FNMA is no longer
>valid
># with respect to the length of each embedded data set
>data <- readLines(ARMReturn, encoding = "ascii")
>
>quartile <- NULL
>numchar <- nchar(x = data, type = "chars")
>start <- c(seq(1, numchar, 399))
>end <- c(seq(399, numchar, 399))
>quartile <- str_sub(data, start[1:length(start)], end[1:length(end)])
>write(quartile, ARMReturn)
>
># The file has been parsed accroding to length 400 for each data
>element.
># The next step is to remove all the trailing white space hex character
># x20
>
>sedcommand2 <- paste("sed -e '/\\x20/d' <", 
>filepath, "arm.csv", 
>">", "arm2.csv", sep = "")
>system(sedcommand2)
>} # end of function
>
>
>c("                                                 555556
>WS320021201006125{000378{000348{                                       
>                                                                    ", 
>"                                                  555556
>WS320021201006250{000954{000880{                                       
>                                                                    ", 
>"                                                   555556
>WS320021201005625{001062{000983{                                       
>                                                                    ", 
>"                                                    555556
>WS320030101005250{000027{000025{                                       
>                                                                    ", 
>"                                                     555556
>WS320030101006500{000033{000030{                                       
>                                                                    ", 
>"                                                      555556
>WS320030101005125{000061{000056{                                       
>                                                                    ", 
>"                                                       555556
>WS320030101005375{000095{000088{                                       
>                                                                    ", 
>"                                                        555556
>WS320030101005350{000217{000200{                                       
>                                                                    ", 
>"                                                         555556
>WS320030101006125{000400{000369{                                       
>                                                                    ", 
>"                                                          555556
>WS320030101005310{000439{000406{                                       
>                                                                    ", 
>"                                                           555556
>WS320030101006000{000573{000529{                                       
>                                                                      "
>
>
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter at comcast.net  Thu Sep  8 18:56:15 2016
From: bgunter at comcast.net (Bert Gunter)
Date: Thu, 8 Sep 2016 09:56:15 -0700
Subject: [R] [R-pkgs] stripless package version 1.0-2 now on CRAN
Message-ID: <63626547-A7D3-4D0A-B24A-18AE3400C1AB@comcast.net>

A vignette has been added to the package. I hope that even those who don?t use the package will find its discussion of trellis graphics useful. Otherwise, this is a minor update that fixes some bugs and adds a few small features. See the NEWS file for details. As always, comments and suggestions welcome. 

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From tomdharray at gmail.com  Mon Sep 12 16:39:06 2016
From: tomdharray at gmail.com (Tom D. Harray)
Date: Mon, 12 Sep 2016 10:39:06 -0400
Subject: [R] Arules Package: Rules subset with 'empty' left hand side (lhs)
Message-ID: <CAM9RCO9MJa=Hay_aX58B-SC5kqeyApqJ9KPXqeyCzzD=mEnMGA@mail.gmail.com>

Hello,

subsets of association rules (with respect to support, confidence, lift, or
items) can be obtained with the arules::subset() function; e.g.

  rm(list = ls(all.names = TRUE))
  library(arules)
  set.seed(42)

  x <- lapply(X = 1:500, FUN = function(i)
    sample(x = 1:10, size = sample(1:5, 1), replace = FALSE)
  )
  x <- as(x, 'transactions')

  rules <- apriori(
    data = x,
    parameter = list(target = 'rules', minlen = 1, maxlen = 2,
      support = 0.10, confidence = 0.32)
  )
  rules <- arules::sort(x = rules, decreasing = TRUE, by ='support')

gives the rules
3  {}  => {1} 0.330   0.3300000  1.0000000
2  {}  => {3} 0.326   0.3260000  1.0000000
1  {}  => {2} 0.320   0.3200000  1.0000000
20 {3} => {1} 0.120   0.3680982  1.1154490
21 {1} => {3} 0.120   0.3636364  1.1154490
16 {4} => {3} 0.114   0.3677419  1.1280427
(...)

However, I cannot figure out (help/web) how to get the subset for the rules
with empty left hand side (lhs) like subset(rules, lhs == ''). I  could run the
apriori() function twice and adjust the min/maxlen parameters as a band
aid fix.


So my question is: How do I subset() association rules with empty lhs?


Thanks and regards,

Dirk


From stevek9123 at gmail.com  Mon Sep 12 21:58:47 2016
From: stevek9123 at gmail.com (Stephen Kennedy)
Date: Mon, 12 Sep 2016 15:58:47 -0400
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <alpine.BSF.2.00.1609092215100.48224@pedal.dcn.davis.ca.us>
References: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
	<3C75A0E4-EDDE-4963-AAB4-9EA4CA9C797B@dcn.davis.ca.us>
	<AEAC5C2D55889A488576EDAA792CC287D6D6AA@anikaexch01.anikatherapeutics.com>
	<alpine.BSF.2.00.1609092215100.48224@pedal.dcn.davis.ca.us>
Message-ID: <CAD__wHfZNLrkESWDtFL1Rx6=LOQtPA6-zGKaQNL6d7LfP8dpig@mail.gmail.com>

Hello Jeff,

I kept fooling with this, and also looking around the web and I actually
found something on stackoverflow, which does what I had in mind.  You
mentioned that you would rarely use someting like this, but the link is:

http://stackoverflow.com/questions/6192848/how-to-generalize-outer-to-n-dimensions

This may not be efficient, but what I like is that you can name the vectors
of variable values anything, as well as the names of the variables in the
arbitrary function.  It is not sensitive to the 'names' of anything.

Here is the code.  I used the function you defined for me, but for example
you can just pass in a vector of values (1:3, etc. below) and this produces
the output array.  I would name the vector something that means something
to me (temperature_vals = c(), etc.), and then pass that to multi.outer,
and the function will be applied (independent of what you name the
variables in the function).

Thanks again for your help.  The responses are like a tutorial for me ...

Best,

Steve



list_args <- Vectorize( function(a,b) c( as.list(a), as.list(b) ),
+                         SIMPLIFY = FALSE)

 make_args_mtx <- function( alist ) {
+     Reduce(function(x, y) outer(x, y, list_args), alist)
+ }

 multi.outer <- function(f, ... ) {
+     args <- make_args_mtx(list(...))
+     apply(args, 1:length(dim(args)), function(a) do.call(f, a[[1]] ) )
+ }


multi.outer(myfunc, 1:3, 2:6, 3:4)
, , 1

     [,1] [,2] [,3] [,4] [,5]
[1,]    5    6    7    8    9
[2,]    7    9   11   13   15
[3,]    9   12   15   18   21

, , 2

     [,1] [,2] [,3] [,4] [,5]
[1,]    6    7    8    9   10
[2,]    8   10   12   14   16
[3,]   10   13   16   19   22

On Sat, Sep 10, 2016 at 1:29 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Not sure I understand what you really want, if you have found ways to
> accomplish what you want but are not satisfied with them. That is one
> reason why keeping the mailing list involved (by reply-all) is good for
> you. From my end, I don't do one-on-one support online, and may not be able
> to carry on a thread to the end if I get busy.
>
> Your concept of a generalized outer function sounds to me like:
>
> myfunc <- function( A, B, C ) {
>  A * B + C
> }
>
> gouter <- function( FUN, ... ) {
>  args <- list( ... )
>  DF <- do.call( expand.grid, args )
>  array( data = do.call( FUN, DF )
>       , dim = sapply( args, FUN=length )
>       , dimnames = args
>       )
> }
>
> gouter( myfunc, A = 1:3, B=2:6, C=3:4 )
> # , , C = 3
> #
> #    B
> # A   2  3  4  5  6
> #   1 5  6  7  8  9
> #   2 7  9 11 13 15
> #   3 9 12 15 18 21
> #
> # , , C = 4
> #
> #    B
> # A    2  3  4  5  6
> #   1  6  7  8  9 10
> #   2  8 10 12 14 16
> #   3 10 13 16 19 22
>
> I generally just tack on columns to the expand.grid result... I almost
> never have a need for multidimensional arrays.
>
> On Fri, 9 Sep 2016, Steve Kennedy wrote:
>
> Hello,
>>
>> Abstraction is what I want.  I'm actually looking to do something more
>> complicated.  The functions do.call, and as.list get me most of the way
>> there, but there is something I'm missing ...
>>
>> My eventual goal is to produce a multi-dimensional version of 'outer'.
>> Like my.outer(func, a_vec, b_vec, c_vec, ..), where the function of the
>> variables 'a', 'b', 'c', etc. would be applied to the vectors from the
>> outer product of the vectors of values for each variable.
>>
>> I wanted to use expand.grid (does require reshaping the output).  Using
>> temps = c(40,50,60) and times = c(1:5), this doesn't quite seem to work:
>>
>>   apply(expand.grid(temps,times), 1, function(a) do.call(func2,
>> as.list(a)))
>>
>> although this does work:
>>
>>   do.call(func2, as.list(c(10, 121)))
>>
>> And, this also works:
>>
>>  apply(expand.grid(temps,times), 1, function(a) do.call("+", as.list(a)))
>>
>> There is some subtlety here I don't understand.
>>
>> Thanks,
>>
>> Steve
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Friday, September 09, 2016 5:39 PM
>> To: Steve Kennedy; r-help at r-project.org
>> Subject: Re: [R] Apply a multi-variable function to a vector
>>
>> Your architecture has a bad smell to me. For one thing you are mixing
>> different units in the same vector but should be putting multiple instances
>> of the same variable into one vector. Lists of vectors (data frames) are
>> typically used when multiple variables need to be grouped.
>>
>> Another problem is that you are constraining the names of the variables
>> you pass to the function to be named the same as they are inside the
>> function. This really limits your use of those functions.
>>
>> There really is too much abstraction going on here.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 9, 2016 12:44:52 PM PDT, Steve Kennedy
>> <SKennedy at AnikaTherapeutics.com> wrote:
>>
>>> Hello,
>>>
>>> I would like to define an arbitrary function of an arbitrary number of
>>> variables, for example, for 2 variables:
>>>
>>> func2 <- function(time, temp) time + temp
>>>
>>> I'd like to keep variable names that have a meaning in the problem
>>> (time and temperature above).
>>>
>>> If I have a vector of values for these variables, for example in the
>>> 2-d case, c(10, 121), I'd like to apply my function (in this case
>>> func2) and obtain the result. Conceptually, something like,
>>>
>>> func2(c(10,121))
>>>
>>> becomes
>>>
>>> func2(10,121)
>>>
>>> Is there a simple way to accomplish this, for an arbitrary number of
>>> variables?  I'd like something that would simply work from the
>>> definition of the function.  If that is possible.
>>>
>>> Thanks,
>>>
>>> Steve Kennedy
>>>
>>> CONFIDENTIALITY NOTICE: This e-mail message, including
>>> a...{{dropped:11}}
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> http://cp.mcafee.com/d/k-Kr6x0g6hASyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPq
>>> tTT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOw
>>> evW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jq9JcTvANOoVcsCej76XCOsVH
>>> kiPajSvvcCatoDwCHIcfBisEeRO9sDVWNIhgxVxmhUagJ3AdcOFRJVKxJBxdcS2_id41Fr1
>>> pFtd40wIIumd46Cy1lI-syVDoOQwvVEwtrxqsGMd44WCy3jh0p-QWNdLECZzL1
>>> PLEASE do read the posting guide
>>> http://cp.mcafee.com/d/5fHCMUp418SyMepov78FI6XCQXLK3AnCrFCQXLK3AnCnAPqt
>>> TT1ObPdSjqaby8VMsUyYrEl-4fgb0HoiaXcDYtmZKsHkVsTI95tCj-eHuTelGsKrpYwCOwe
>>> vW_ccnpuKNRXBQQT1TfcFzCnTeEyCJtdmXP_axVZicHs3jqpJcTvANOoVcsCej76XCM0gbb
>>> HhG8_qv00smHisE4iV5Ki7Y3zoyx3P2IzMkxq78qpBjHrPt3rb2qpI5-Aq83iS2PiWq811p
>>> oYIq8dd42HpYV5PeNBF0_Ph0WT2QVlwq89Rd46Cy0PZFRyrvhd_2KV
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> CONFIDENTIALITY NOTICE: This e-mail message, including any attachments,
>> contains information belonging to Anika Therapeutics, Inc. and is for the
>> sole use of the intended recipient(s) and may contain confidential,
>> proprietary, copyrighted and privileged information. Any unauthorized
>> review, use, disclosure, distribution or copying is strictly prohibited. If
>> you are not the intended recipient, please contact the sender by reply
>> e-mail and destroy all copies of the original message immediately.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From jieding.ding at nih.gov  Mon Sep 12 23:14:39 2016
From: jieding.ding at nih.gov (Ding, Jie Ding (NIH/NIA/ERP) [F])
Date: Mon, 12 Sep 2016 21:14:39 +0000
Subject: [R] Hausman Test
Message-ID: <09ED3FEB6FED184B85A5A5640FF33C1E636C989E@msgb06.nih.gov>

Dear Achim,

Sorry to have disturbed you. I have encountered a problem  when computing Hausman test statistics (i.e. p values)  in R to compare OLS and 2SLS models.

The problem is a discrepancy between the two p-value outputs from the "manual approach (by hand)" and the " diagnostics argument" in the "AER" library, respectively.

With respect to manual approach, I used the following codes:

cf_diff<-coef(ivreg)-coef(olsreg)
vc_diff<-vcov(ivreg)-vcov(olsreg)
x2_diff<-as.vector(t(cf_diff)%*% solve(vc_diff)%*%cf_diff)
pchisq(x2_diff,df=2,lower.tail=FALSE)


For diagnostic approach, I applied the following:

summary(ivreg, vcov = sandwich, df = Inf, diagnostics = TRUE)


However, p-value from the manual approach is always much larger than the diagnostic approach, e.g.  0.329 vs. 0.138

I would expect the values should be the same. Your advice would be highly appreciated.

With very best wishes,
Jennifer



	[[alternative HTML version deleted]]


From pai1981 at gmail.com  Tue Sep 13 00:56:18 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Mon, 12 Sep 2016 16:56:18 -0600
Subject: [R] How to read a grib2 file
In-Reply-To: <CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>
References: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
	<CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>
Message-ID: <CAM9mbiAMF3Hneca2jdv5A=jyPphh1NCri9Ooq2bwQ7Pd9A+TTQ@mail.gmail.com>

Thanks for your suggestion. I have checked and I don't have JPEG2000 in
ggdalDrivers()). I am pretty new in R. I don't understand how to do I
implement JPEG2000 (JP2OpenJPEG driver) in gdalDrivers() so that I can read
grib2 files

with regards
-Deb

On Sat, Sep 10, 2016 at 2:33 AM, Michael Sumner <mdsumner at gmail.com> wrote:

>
>
> On Sat, 10 Sep 2016 at 07:12 Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
>
>> Hi
>> I am trying to read a grib2 file in R.
>>
>> Here is my script
>>
>> library(rgdal)
>> library(sp)
>> library(rNOMADS)
>> gribfile<-"tmax.01.2011040100.daily.grb2"
>> grib <- readGDAL(gribfile)
>>
>> I am getting following error :
>>
>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>> Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
>> driver GRIB
>> and has 190 rows and 384 columns
>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>> Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
>> image within GRIB file.
>>
>>
> Hi there, please check if JPEG2000 is in the gdalDrivers() list, i.e.  in
>
> rgdal::gdalDrivers()$name
>
> You are looking for one starting with "JP2" as per the list next to the
> "JPEG2000" rows here:
>
> http://gdal.org/formats_list.html
>
> I have  JP2OpenJPEG on one system, but not (for example) on the Windows
> CRAN binary for rgdal, which is the only readily available Windows build
> for this package.
>
> I you don't have it, you might try on a system that has the JP2OpenJPEG driver,
> or ask someone to try on your behalf. You'd want to find out if that will
> enable this read for you before investing time in the Linux configuration.
>
> It's not too hard to set up a Linux system for this, but does assume a bit
> of experience on your part. Some of the docker images in the rockerverse
> have this all sorted I believe, but it's been a while since I used them.
>
> https://hub.docker.com/u/rocker/
>
> Cheers, Mike.
>
>
>
>
>> Cheers
>> -Deb
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From aanchalsharma833 at gmail.com  Tue Sep 13 01:40:15 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Mon, 12 Sep 2016 19:40:15 -0400
Subject: [R] Fitting Mixture distributions
In-Reply-To: <22481.23474.403070.875828@stat.math.ethz.ch>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
	<c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
	<CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>
	<22481.23474.403070.875828@stat.math.ethz.ch>
Message-ID: <CAFp0Li3MudaE1=QU6y5FrEZKqCC3hYg+PMN4x+80qpvQPqY=vA@mail.gmail.com>

Thanks for the reply.

I have another related issue with Gamma mixture model. here is the
description:

I am trying to fit a 2 component gamma mixture model to my data (residual
values obtained after running Generalized Linear Model), using following
command (part of the code):

 expr_mix_gamma <- gammamixEM(expr_glm_residuals, lambda = c(0.75,0.25), k
= 2, epsilon = 1e-08, maxit = 1000, maxrestarts=20, verb = TRUE)

The code runs for multiple gene files (in loop). it runs fine for some
files whereas for others it throws following error:

    Error in gammamixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k = 2,
 : Try different number of components?

I tried increasing iterations and decreasing the convergence value, but
that doesn't seem to work. Is there anything else that I can try?
Thanks


On Thu, Sep 8, 2016 at 8:38 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>     on Wed, 7 Sep 2016 23:47:40 -0700 writes:
>
>     > "please suggest what can I do to resolve this
>     > issue."
>
>     > Fitting normal mixtures can be difficult, and sometime the
>     > optimization algorithm (EM) will get stuck with very slow
> convergence.
>     > Presumably there are options in the package to either increase the
> max
>     > number of steps before giving up or make the convergence criteria
> less
>     > sensitive. The former will increase the run time and the latter will
>     > reduce the optimality (possibly leaving you farther from the true
>     > optimum). So you should look into changing these as you think
>     > appropriate.
>
> I'm jumping in late, without having read everything preceding.
>
> One of the last messages seemed to indicate that you are looking
> at mixtures of *one*-dimensional gaussians.
>
> If this is the case, I strongly recommend looking at (my) CRAN
> package 'nor1mix' (the "1" is for "*one*-dimensional).
>
> For a while now that small package is providing an alternative
> to the EM, namely direct MLE, simply using optim(<likelihood>) where the
> likelihood uses a somewhat smart parametrization.
>
> Of course, *as the EM*, this also depends on the starting value,
> but my (limited) experience has been that
>   nor1mix::norMixMLE()
> works considerably faster and more reliable than the EM (which I
> also provide as    nor1mix::norMixEM() .
>
> Apropos 'starting value': The help page shows how to use
> kmeans() for "somewhat" reliable starts; alternatively, I'd
> recommend using cluster::pam() to get a start there.
>
> I'm glad to hear about experiences using these / comparing
> these with other approaches.
>
> Martin
>
>
> --
> Martin Maechler,
> ETH Zurich
>
>
>     > On Wed, Sep 7, 2016 at 3:51 PM, Aanchal Sharma
>     > <aanchalsharma833 at gmail.com> wrote:
>     >> Hi Simon
>     >>
>     >> I am facing same problem as described above. i am trying to fit
> gaussian
>     >> mixture model to my data using normalmixEM. I am running a Rscript
> which
>     >> has this function running as part of it for about 17000 datasets
> (in loop).
>     >> The script runs fine for some datasets, but it terminates when it
>     >> encounters one dataset with the following error:
>     >>
>     >> Error in normalmixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k
> = 2,  :
>     >> Too many tries!
>     >>
>     >> (command used: expr_mix_gau <- normalmixEM(expr_glm_residuals,
> lambda =
>     >> c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000,
> maxrestarts=200, verb
>     >> = TRUE))
>     >> (expr_glm_residuals is my dataset which has residual values for
> different
>     >> samples)
>     >>
>     >> It is suggested that one should define the mu and sigma in the
> command by
>     >> looking at your dataset. But in my case there are many datasets and
> it will
>     >> keep on changing every time. please suggest what can I do to
> resolve this
>     >> issue.
>     >>
>     >> Regards
>     >> Anchal
>     >>
>     >> On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
>     >>>
>     >>> Hi Tjun Kiat Teo,
>     >>>
>     >>> you try to fit a Normal mixture to some data. The Normal mixture
> is very
>     >>> delicate when it comes to parameter search: If the variance gets
> closer and
>     >>> closer to zero, the log Likelihood becomes larger and larger for
> any values
>     >>> of the remaining parameters. Furthermore for the EM algorithm it
> is known,
>     >>> that it takes sometimes very long until convergence is reached.
>     >>>
>     >>> Try the following:
>     >>>
>     >>> Use as starting values for the component parameters:
>     >>>
>     >>> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm =
> TRUE) *
>     >>> runif(K)
>     >>>
>     >>> For the weights just use either 1/K or the R cluster function with
> K
>     >>> clusters
>     >>>
>     >>> Here K is the number of components. Further enlarge the maximum
> number of
>     >>> iterations. What you could also try is to randomize start
> parameters and
>     >>> run an SEM (Stochastic EM). In my opinion the better method is in
> this case
>     >>> a Bayesian method: MCMC.
>     >>>
>     >>>
>     >>> Best
>     >>>
>     >>> Simon
>     >>>
>     >>>
>     >>> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com
>     >>> <javascript:>> wrote:
>     >>>
>     >>> > I was trying to use the normixEM in mixtools and I got this error
>     >>> message.
>     >>> >
>     >>> > And I got this error message
>     >>> >
>     >>> > One of the variances is going to zero;  trying new starting
> values.
>     >>> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too
> many
>     >>> tries!
>     >>> >
>     >>> > Are there any other packages for fitting mixture distributions  ?
>     >>> >
>     >>> >
>     >>> > Tjun Kiat Teo
>     >>> >
>     >>> >         [[alternative HTML version deleted]]
>     >>> >
>     >>> > ______________________________________________
>     >>> > R-h... at r-project.org <javascript:> mailing list
>     >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> > PLEASE do read the posting guide
>     >>> http://www.R-project.org/posting-guide.html
>     >>> > and provide commented, minimal, self-contained, reproducible
> code.
>     >>>
>     >>> ______________________________________________
>     >>> R-h... at r-project.org <javascript:> mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> PLEASE do read the posting guide
>     >>> http://www.R-project.org/posting-guide.html
>     >>> and provide commented, minimal, self-contained, reproducible code.
>     >>>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 13 02:18:56 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Sep 2016 17:18:56 -0700
Subject: [R] Fitting Mixture distributions
In-Reply-To: <CAFp0Li3MudaE1=QU6y5FrEZKqCC3hYg+PMN4x+80qpvQPqY=vA@mail.gmail.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
	<c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
	<CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>
	<22481.23474.403070.875828@stat.math.ethz.ch>
	<CAFp0Li3MudaE1=QU6y5FrEZKqCC3hYg+PMN4x+80qpvQPqY=vA@mail.gmail.com>
Message-ID: <CAGxFJbS7FF6ZfnnePEBn=T57PKjgPf1=QCXUyqwESwmXpH5H5g@mail.gmail.com>

Do you mean "increase the convergence value." Decreasing it should
make it harder to converge (I believe, depending on exactly how
"convergence vaue" is defined,  so doublecheck.)

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 12, 2016 at 4:40 PM, Aanchal Sharma
<aanchalsharma833 at gmail.com> wrote:
> Thanks for the reply.
>
> I have another related issue with Gamma mixture model. here is the
> description:
>
> I am trying to fit a 2 component gamma mixture model to my data (residual
> values obtained after running Generalized Linear Model), using following
> command (part of the code):
>
>  expr_mix_gamma <- gammamixEM(expr_glm_residuals, lambda = c(0.75,0.25), k =
> 2, epsilon = 1e-08, maxit = 1000, maxrestarts=20, verb = TRUE)
>
> The code runs for multiple gene files (in loop). it runs fine for some files
> whereas for others it throws following error:
>
>     Error in gammamixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k = 2,
> : Try different number of components?
>
> I tried increasing iterations and decreasing the convergence value, but that
> doesn't seem to work. Is there anything else that I can try?
> Thanks
>
>
> On Thu, Sep 8, 2016 at 8:38 AM, Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>>
>> >>>>> Bert Gunter <bgunter.4567 at gmail.com>
>> >>>>>     on Wed, 7 Sep 2016 23:47:40 -0700 writes:
>>
>>     > "please suggest what can I do to resolve this
>>     > issue."
>>
>>     > Fitting normal mixtures can be difficult, and sometime the
>>     > optimization algorithm (EM) will get stuck with very slow
>> convergence.
>>     > Presumably there are options in the package to either increase the
>> max
>>     > number of steps before giving up or make the convergence criteria
>> less
>>     > sensitive. The former will increase the run time and the latter will
>>     > reduce the optimality (possibly leaving you farther from the true
>>     > optimum). So you should look into changing these as you think
>>     > appropriate.
>>
>> I'm jumping in late, without having read everything preceding.
>>
>> One of the last messages seemed to indicate that you are looking
>> at mixtures of *one*-dimensional gaussians.
>>
>> If this is the case, I strongly recommend looking at (my) CRAN
>> package 'nor1mix' (the "1" is for "*one*-dimensional).
>>
>> For a while now that small package is providing an alternative
>> to the EM, namely direct MLE, simply using optim(<likelihood>) where the
>> likelihood uses a somewhat smart parametrization.
>>
>> Of course, *as the EM*, this also depends on the starting value,
>> but my (limited) experience has been that
>>   nor1mix::norMixMLE()
>> works considerably faster and more reliable than the EM (which I
>> also provide as    nor1mix::norMixEM() .
>>
>> Apropos 'starting value': The help page shows how to use
>> kmeans() for "somewhat" reliable starts; alternatively, I'd
>> recommend using cluster::pam() to get a start there.
>>
>> I'm glad to hear about experiences using these / comparing
>> these with other approaches.
>>
>> Martin
>>
>>
>> --
>> Martin Maechler,
>> ETH Zurich
>>
>>
>>     > On Wed, Sep 7, 2016 at 3:51 PM, Aanchal Sharma
>>     > <aanchalsharma833 at gmail.com> wrote:
>>     >> Hi Simon
>>     >>
>>     >> I am facing same problem as described above. i am trying to fit
>> gaussian
>>     >> mixture model to my data using normalmixEM. I am running a Rscript
>> which
>>     >> has this function running as part of it for about 17000 datasets
>> (in loop).
>>     >> The script runs fine for some datasets, but it terminates when it
>>     >> encounters one dataset with the following error:
>>     >>
>>     >> Error in normalmixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k
>> = 2,  :
>>     >> Too many tries!
>>     >>
>>     >> (command used: expr_mix_gau <- normalmixEM(expr_glm_residuals,
>> lambda =
>>     >> c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000,
>> maxrestarts=200, verb
>>     >> = TRUE))
>>     >> (expr_glm_residuals is my dataset which has residual values for
>> different
>>     >> samples)
>>     >>
>>     >> It is suggested that one should define the mu and sigma in the
>> command by
>>     >> looking at your dataset. But in my case there are many datasets and
>> it will
>>     >> keep on changing every time. please suggest what can I do to
>> resolve this
>>     >> issue.
>>     >>
>>     >> Regards
>>     >> Anchal
>>     >>
>>     >> On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
>>     >>>
>>     >>> Hi Tjun Kiat Teo,
>>     >>>
>>     >>> you try to fit a Normal mixture to some data. The Normal mixture
>> is very
>>     >>> delicate when it comes to parameter search: If the variance gets
>> closer and
>>     >>> closer to zero, the log Likelihood becomes larger and larger for
>> any values
>>     >>> of the remaining parameters. Furthermore for the EM algorithm it
>> is known,
>>     >>> that it takes sometimes very long until convergence is reached.
>>     >>>
>>     >>> Try the following:
>>     >>>
>>     >>> Use as starting values for the component parameters:
>>     >>>
>>     >>> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm =
>> TRUE) *
>>     >>> runif(K)
>>     >>>
>>     >>> For the weights just use either 1/K or the R cluster function with
>> K
>>     >>> clusters
>>     >>>
>>     >>> Here K is the number of components. Further enlarge the maximum
>> number of
>>     >>> iterations. What you could also try is to randomize start
>> parameters and
>>     >>> run an SEM (Stochastic EM). In my opinion the better method is in
>> this case
>>     >>> a Bayesian method: MCMC.
>>     >>>
>>     >>>
>>     >>> Best
>>     >>>
>>     >>> Simon
>>     >>>
>>     >>>
>>     >>> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com
>>     >>> <javascript:>> wrote:
>>     >>>
>>     >>> > I was trying to use the normixEM in mixtools and I got this
>> error
>>     >>> message.
>>     >>> >
>>     >>> > And I got this error message
>>     >>> >
>>     >>> > One of the variances is going to zero;  trying new starting
>> values.
>>     >>> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too
>> many
>>     >>> tries!
>>     >>> >
>>     >>> > Are there any other packages for fitting mixture distributions
>> ?
>>     >>> >
>>     >>> >
>>     >>> > Tjun Kiat Teo
>>     >>> >
>>     >>> >         [[alternative HTML version deleted]]
>>     >>> >
>>     >>> > ______________________________________________
>>     >>> > R-h... at r-project.org <javascript:> mailing list
>>     >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>     >>> > PLEASE do read the posting guide
>>     >>> http://www.R-project.org/posting-guide.html
>>     >>> > and provide commented, minimal, self-contained, reproducible
>> code.
>>     >>>
>>     >>> ______________________________________________
>>     >>> R-h... at r-project.org <javascript:> mailing list
>>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >>> PLEASE do read the posting guide
>>     >>> http://www.R-project.org/posting-guide.html
>>     >>> and provide commented, minimal, self-contained, reproducible code.
>>     >>>
>>     >> ______________________________________________
>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>     >> and provide commented, minimal, self-contained, reproducible code.
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Anchal Sharma, PhD
> Postdoctoral Fellow
> 195, Little Albany street,
> Cancer Institute of New Jersey
> Rutgers University
> NJ-08901


From Achim.Zeileis at uibk.ac.at  Tue Sep 13 08:20:14 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 13 Sep 2016 08:20:14 +0200 (CEST)
Subject: [R] Hausman Test
In-Reply-To: <09ED3FEB6FED184B85A5A5640FF33C1E636C989E@msgb06.nih.gov>
References: <09ED3FEB6FED184B85A5A5640FF33C1E636C989E@msgb06.nih.gov>
Message-ID: <alpine.DEB.2.20.1609130817550.17291@paninaro>

On Mon, 12 Sep 2016, Ding, Jie Ding (NIH/NIA/ERP) [F] wrote:

> Dear Achim,
>
> Sorry to have disturbed you. I have encountered a problem  when computing Hausman test statistics (i.e. p values)  in R to compare OLS and 2SLS models.
>
> The problem is a discrepancy between the two p-value outputs from the "manual approach (by hand)" and the " diagnostics argument" in the "AER" library, respectively.
>
> With respect to manual approach, I used the following codes:
>
> cf_diff<-coef(ivreg)-coef(olsreg)
> vc_diff<-vcov(ivreg)-vcov(olsreg)
> x2_diff<-as.vector(t(cf_diff)%*% solve(vc_diff)%*%cf_diff)
> pchisq(x2_diff,df=2,lower.tail=FALSE)
>
>
> For diagnostic approach, I applied the following:
>
> summary(ivreg, vcov = sandwich, df = Inf, diagnostics = TRUE)
>
>
> However, p-value from the manual approach is always much larger than the 
> diagnostic approach, e.g.  0.329 vs. 0.138
>
> I would expect the values should be the same. Your advice would be 
> highly appreciated.

The Wu-Hausman test in ivreg() follows the auugmented regression approach 
that is also used by Stata. This regresses the endogenous variable on the 
instruments and includes the fitted values in an OLS regression. The test 
is then a simple Wald test, see:
http://www.stata.com/support/faqs/statistics/durbin-wu-hausman-test/

> With very best wishes,
> Jennifer
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mviljamaa at kapsi.fi  Tue Sep 13 09:37:18 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Tue, 13 Sep 2016 10:37:18 +0300
Subject: [R] Is this kind of removing of elements from data.frame
	(in)efficient?
Message-ID: <5aeb5e3a9f3fa40302792135e8dcc65b@kapsi.fi>

So I'm a beginner in R and I was testing the removal of elements from a 
data.frame.

The way I remove the element(s) with the minimum value in kid_score 
variable is to do:

kidmomhs <- data[kidmomhs$kid_score != min(kidmomhs$kid_score),]

So now kidmomhs is the same data, but without the row(s) with the 
minimum value of kid_score.

Judging by the syntax this looks as if R might be creating a copy of the 
data array, just without the rows that were removed.

The question however is, is this the most efficient way to remove 
elements from data structures in R? And is the above inefficient? Does 
the above create copies of almost the entire data structure?

In other programming languages I've become accustomed to doing removal 
of elements by changing them to NULL and then e.g. reordering the data 
structure. Rather than having to take copies of almost the entire data 
structure.


From luisfo89 at yahoo.es  Tue Sep 13 11:10:42 2016
From: luisfo89 at yahoo.es (Luisfo)
Date: Tue, 13 Sep 2016 11:10:42 +0200
Subject: [R] Arules Package: Rules subset with 'empty' left hand side
 (lhs)
In-Reply-To: <CAM9RCO9MJa=Hay_aX58B-SC5kqeyApqJ9KPXqeyCzzD=mEnMGA@mail.gmail.com>
References: <CAM9RCO9MJa=Hay_aX58B-SC5kqeyApqJ9KPXqeyCzzD=mEnMGA@mail.gmail.com>
Message-ID: <7e56d7ed-4e14-5376-dad1-52088a1db109@yahoo.es>

Dear Tom,

I think this is the line you need
   arules::subset(rules, subset=lhs %pin% "")
I found the solution here: 
http://stackoverflow.com/questions/27926131/how-to-get-items-for-both-lhs-and-rhs-for-only-specific-columns-in-arules

One more thing. For printing the rules, I needed the inspect() command 
you didn't provide.

I hope this helps.

Best,

*Luisfo Chiroque*
/PhD Student | PhD Candidate
IMDEA Networks Institute/
http://fourier.networks.imdea.org/people/~luis_nunez/ 
<http://fourier.networks.imdea.org/people/%7Eluis_nunez/>

On 09/12/2016 04:39 PM, Tom D. Harray wrote:
> Hello,
>
> subsets of association rules (with respect to support, confidence, lift, or
> items) can be obtained with the arules::subset() function; e.g.
>
>    rm(list = ls(all.names = TRUE))
>    library(arules)
>    set.seed(42)
>
>    x <- lapply(X = 1:500, FUN = function(i)
>      sample(x = 1:10, size = sample(1:5, 1), replace = FALSE)
>    )
>    x <- as(x, 'transactions')
>
>    rules <- apriori(
>      data = x,
>      parameter = list(target = 'rules', minlen = 1, maxlen = 2,
>        support = 0.10, confidence = 0.32)
>    )
>    rules <- arules::sort(x = rules, decreasing = TRUE, by ='support')
>
> gives the rules
> 3  {}  => {1} 0.330   0.3300000  1.0000000
> 2  {}  => {3} 0.326   0.3260000  1.0000000
> 1  {}  => {2} 0.320   0.3200000  1.0000000
> 20 {3} => {1} 0.120   0.3680982  1.1154490
> 21 {1} => {3} 0.120   0.3636364  1.1154490
> 16 {4} => {3} 0.114   0.3677419  1.1280427
> (...)
>
> However, I cannot figure out (help/web) how to get the subset for the rules
> with empty left hand side (lhs) like subset(rules, lhs == ''). I  could run the
> apriori() function twice and adjust the min/maxlen parameters as a band
> aid fix.
>
>
> So my question is: How do I subset() association rules with empty lhs?
>
>
> Thanks and regards,
>
> Dirk
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From manu.reddy52 at gmail.com  Tue Sep 13 12:46:05 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Tue, 13 Sep 2016 16:16:05 +0530
Subject: [R] Drill down reports in R
Message-ID: <CADG9u0B_Tiw-6URXpKs-F8TH_X117uNWPspVmZciPOt7aZqmnw@mail.gmail.com>

Hi,



  How to generate ?Drill down reports ?  (like please refer below url) in R
using any package ? I did lot of research in google but I didn?t found
suitable link .

 Can anyone help how to do that in R ?



url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/



Thanks in Advance !

Manu.

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Sep 13 13:26:10 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 13 Sep 2016 11:26:10 +0000
Subject: [R] How to read a grib2 file
In-Reply-To: <CAM9mbiAMF3Hneca2jdv5A=jyPphh1NCri9Ooq2bwQ7Pd9A+TTQ@mail.gmail.com>
References: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
	<CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>
	<CAM9mbiAMF3Hneca2jdv5A=jyPphh1NCri9Ooq2bwQ7Pd9A+TTQ@mail.gmail.com>
Message-ID: <CAAcGz9-jKLJOM_dTg8Xdc=1+nab+KaAtu_NwgHBfNMNSbUzvBA@mail.gmail.com>

What is your computer system? What is the output of this?

sessionInfo()

If you point to a file I'll try it so I can tell you the minimum system
requirements.

Cheers, Mike

On Tue, 13 Sep 2016, 08:56 Debasish Pai Mazumder <pai1981 at gmail.com> wrote:

> Thanks for your suggestion. I have checked and I don't have JPEG2000 in
> ggdalDrivers()). I am pretty new in R. I don't understand how to do I
> implement JPEG2000 (JP2OpenJPEG driver) in gdalDrivers() so that I can
> read grib2 files
>
> with regards
> -Deb
>
> On Sat, Sep 10, 2016 at 2:33 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
>>
>>
>> On Sat, 10 Sep 2016 at 07:12 Debasish Pai Mazumder <pai1981 at gmail.com>
>> wrote:
>>
>>> Hi
>>> I am trying to read a grib2 file in R.
>>>
>>> Here is my script
>>>
>>> library(rgdal)
>>> library(sp)
>>> library(rNOMADS)
>>> gribfile<-"tmax.01.2011040100.daily.grb2"
>>> grib <- readGDAL(gribfile)
>>>
>>> I am getting following error :
>>>
>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>> Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
>>> driver GRIB
>>> and has 190 rows and 384 columns
>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>> Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
>>> image within GRIB file.
>>>
>>>
>> Hi there, please check if JPEG2000 is in the gdalDrivers() list, i.e.  in
>>
>> rgdal::gdalDrivers()$name
>>
>> You are looking for one starting with "JP2" as per the list next to the
>> "JPEG2000" rows here:
>>
>> http://gdal.org/formats_list.html
>>
>> I have  JP2OpenJPEG on one system, but not (for example) on the Windows
>> CRAN binary for rgdal, which is the only readily available Windows build
>> for this package.
>>
>> I you don't have it, you might try on a system that has the JP2OpenJPEG driver,
>> or ask someone to try on your behalf. You'd want to find out if that will
>> enable this read for you before investing time in the Linux configuration.
>>
>> It's not too hard to set up a Linux system for this, but does assume a
>> bit of experience on your part. Some of the docker images in the
>> rockerverse have this all sorted I believe, but it's been a while since I
>> used them.
>>
>> https://hub.docker.com/u/rocker/
>>
>> Cheers, Mike.
>>
>>
>>
>>
>>> Cheers
>>> -Deb
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Sep 13 13:43:33 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 13 Sep 2016 12:43:33 +0100
Subject: [R] Apply a multi-variable function to a vector
In-Reply-To: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
References: <AEAC5C2D55889A488576EDAA792CC287D6D657@anikaexch01.anikatherapeutics.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403F11E3730@GBTEDVPEXCMB04.corp.lgc-group.com>

> I would like to define an arbitrary function of an arbitrary number of variables,
> for example, for 2 variables:
> 
> func2 <- function(time, temp) time + temp
> 
> I'd like to keep variable names that have a meaning in the problem (time and
> temperature above).

Not quite enough information here.

If we called 
func2(30, 298, 23)

which has an arbitrary third argument, what would you like to happen to the third argument? And a fourth, fifth and so on? Something consistent for all arguments, or something different for each depending on its (arbitrary) name?


S Ellison





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From attenka at utu.fi  Tue Sep 13 11:58:23 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 13 Sep 2016 12:58:23 +0300
Subject: [R] More tube-like lines3D?
Message-ID: <57D7CDBF.5050209@utu.fi>

Hi,

Is it possible to give 3d-like form for rgl lines3d-lines? Although I 
increase lwd, lines still look like lines, not like tubes.

-- 
Atte Tenkanen, FT MuM
Turun Martinseurakunnan kanttori
p. 040-3417125


From murdoch.duncan at gmail.com  Tue Sep 13 14:12:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 13 Sep 2016 08:12:56 -0400
Subject: [R] More tube-like lines3D?
In-Reply-To: <57D7CDBF.5050209@utu.fi>
References: <57D7CDBF.5050209@utu.fi>
Message-ID: <93b64cca-c99d-4f21-5d5b-126ba8f5d921@gmail.com>

On 13/09/2016 5:58 AM, Atte Tenkanen wrote:
> Hi,
>
> Is it possible to give 3d-like form for rgl lines3d-lines? Although I
> increase lwd, lines still look like lines, not like tubes.
>
cylinder3d() should do that.  It puts a substantially larger burden on 
the graphics system, so if you draw too many of them, things will slow 
down noticeably.

Duncan Murdoch


From marongiu.luigi at gmail.com  Tue Sep 13 15:00:46 2016
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 13 Sep 2016 14:00:46 +0100
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
Message-ID: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>

Dear all,
I am working on Linux Ubuntu 16.04 and I have installed R 3.2. I need
to upgrade to R 3.3 and I tried several options available online with
no success. I downloaded the tar.gz file for R 3.3 and I would like to
ask how can I use this file in order to accomplish the upgrade.
Many thanks,
Luigi


From ashenkin at ufl.edu  Tue Sep 13 15:05:43 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Tue, 13 Sep 2016 14:05:43 +0100
Subject: [R] Maximum # of DLLs reached, or, how to clean up after yourself?
Message-ID: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>

Hello all,

I have a number of analyses that call bunches of sub-scripts, and in the 
end, I get the "maximal number of DLLs reached" error.  This has been 
asked before (e.g. 
http://stackoverflow.com/questions/36974206/r-maximal-number-of-dlls-reached), 
and the general answer is, "just clean up after yourself".

Assuming there are no plans to raise this 100-DLL limit in the near 
future, my question becomes, what is best practice for cleaning up 
(detaching) loaded packages in scripts, when those scripts are sometimes 
called from other scripts?  One can detach all packages at the end of a 
script that were loaded at the beginning of the script.  However, if a 
package is required in a calling script, one should really make sure it 
hadn't been loaded prior to sub-script invocation before detaching it.

I could write a custom function that pushes and pops package names from 
a global list, in order to keep track, but maybe there's a better way 
out there...

Thanks for any thoughts.

Allie


From loris.bennett at fu-berlin.de  Tue Sep 13 15:44:29 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 13 Sep 2016 15:44:29 +0200
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
Message-ID: <87y42vykw2.fsf@hornfels.zedat.fu-berlin.de>

Luigi Marongiu <marongiu.luigi at gmail.com> writes:

> Dear all,
> I am working on Linux Ubuntu 16.04 and I have installed R 3.2. I need
> to upgrade to R 3.3 and I tried several options available online with
> no success. I downloaded the tar.gz file for R 3.3 and I would like to
> ask how can I use this file in order to accomplish the upgrade.
> Many thanks,
> Luigi
>

Have you looked here:

https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-R-under-Unix_002dalikes

?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From marc_schwartz at me.com  Tue Sep 13 15:52:41 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 13 Sep 2016 08:52:41 -0500
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
In-Reply-To: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
Message-ID: <366B9D52-B1DD-4E6F-BBF9-5273F87290F2@me.com>


> On Sep 13, 2016, at 8:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Dear all,
> I am working on Linux Ubuntu 16.04 and I have installed R 3.2. I need
> to upgrade to R 3.3 and I tried several options available online with
> no success. I downloaded the tar.gz file for R 3.3 and I would like to
> ask how can I use this file in order to accomplish the upgrade.
> Many thanks,
> Luigi


There is a dedicated e-mail list for R on Debian and derivatives like Ubuntu:

  https://stat.ethz.ch/mailman/listinfo/r-sig-debian

You should subscribe to that list and then post your query there.

The answer to your question will depend, to a large extent, on how you installed R in the first place.

There are pre-compiled binaries available for R on Debian and derivatives, thanks to extensive efforts on the part of Dirk and others to maintain those repositories.

The R-SIG-Debian subscribers can help you, but be sure to indicate how you installed the version of R that you are currently using when you post there.

Regards,

Marc Schwartz


From sinha.varuna85 at gmail.com  Tue Sep 13 16:02:20 2016
From: sinha.varuna85 at gmail.com (Varun Sinha)
Date: Tue, 13 Sep 2016 17:02:20 +0300
Subject: [R] syntax to connect to linked SQL server using RODBC
Message-ID: <CAF-rFrJnbVeAZ4ua7wWmRMdMOsPJ_XoQ2zhatNf9UE_SRjv+kw@mail.gmail.com>

Hi All,

I would like to know how to connect to a "linked server" from R. I find the
linked server under Server Objects > Linked Servers on SQL management
studio.

Here is the current way I am using to connect to the server:

dbhandle <- odbcDriverConnect('driver={SQL
Server};server=servername;database=databasename;trusted_connection=true')

table1 <- as.data.table(sqlQuery(dbhandle, 'select a, b from table1'))

Could you please let me know the syntax to do the same but with the linked
server instead? I would like to connect to a database on the linked server
and run the query to pull data.

Thank you for your help.

Best regards,
Varun

	[[alternative HTML version deleted]]


From attenka at utu.fi  Tue Sep 13 14:35:39 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 13 Sep 2016 15:35:39 +0300
Subject: [R] More tube-like lines3D?
In-Reply-To: <93b64cca-c99d-4f21-5d5b-126ba8f5d921@gmail.com>
References: <57D7CDBF.5050209@utu.fi>
	<93b64cca-c99d-4f21-5d5b-126ba8f5d921@gmail.com>
Message-ID: <57D7F29B.5000902@utu.fi>

Thanks, time is no problem!

Atte

13.9.2016, 15.12, Duncan Murdoch kirjoitti:
> On 13/09/2016 5:58 AM, Atte Tenkanen wrote:
>> Hi,
>>
>> Is it possible to give 3d-like form for rgl lines3d-lines? Although I
>> increase lwd, lines still look like lines, not like tubes.
>>
> cylinder3d() should do that.  It puts a substantially larger burden on 
> the graphics system, so if you draw too many of them, things will slow 
> down noticeably.
>
> Duncan Murdoch
>

-- 
Atte Tenkanen, FT MuM
Turun Martinseurakunnan kanttori
p. 040-3417125


From tomdharray at gmail.com  Tue Sep 13 15:30:54 2016
From: tomdharray at gmail.com (Tom D. Harray)
Date: Tue, 13 Sep 2016 09:30:54 -0400
Subject: [R] Arules Package: Rules subset with 'empty' left hand side
	(lhs)
In-Reply-To: <7e56d7ed-4e14-5376-dad1-52088a1db109@yahoo.es>
References: <CAM9RCO9MJa=Hay_aX58B-SC5kqeyApqJ9KPXqeyCzzD=mEnMGA@mail.gmail.com>
	<7e56d7ed-4e14-5376-dad1-52088a1db109@yahoo.es>
Message-ID: <CAM9RCO-v_tES8qtKt-EK0eMDsvAunbk5FKos7Sp+ojCkyh+yQA@mail.gmail.com>

Hello Luisfo,

thank you for the hint: Your suggestion

   arules::subset(rules, subset=lhs %pin% "")

gave 18 rules (out of 21) in my example, and not 3, what I have expected.

Surprisingly the negation of the subset condition

   arules::subset(x = rules, subset = !(lhs %pin% ""))

returns the 3 rules with empty lhs.


Hello Martin,

I add you to this thread, because the arules::subset() behaviour
appears to me to be a bug in arules. And I'd like to suggest to add an
explanation/example to arules::subset() help.


Cheers,

Dirk

On 13 September 2016 at 05:10, Luisfo <luisfo89 at yahoo.es> wrote:
> Dear Tom,
>
> I think this is the line you need
>   arules::subset(rules, subset=lhs %pin% "")
> I found the solution here:
> http://stackoverflow.com/questions/27926131/how-to-get-items-for-both-lhs-and-rhs-for-only-specific-columns-in-arules
>
> One more thing. For printing the rules, I needed the inspect() command you
> didn't provide.
>
> I hope this helps.
>
> Best,
>
> Luisfo Chiroque
> PhD Student | PhD Candidate
> IMDEA Networks Institute
> http://fourier.networks.imdea.org/people/~luis_nunez/
>
> On 09/12/2016 04:39 PM, Tom D. Harray wrote:
>
> Hello,
>
> subsets of association rules (with respect to support, confidence, lift, or
> items) can be obtained with the arules::subset() function; e.g.
>
>   rm(list = ls(all.names = TRUE))
>   library(arules)
>   set.seed(42)
>
>   x <- lapply(X = 1:500, FUN = function(i)
>     sample(x = 1:10, size = sample(1:5, 1), replace = FALSE)
>   )
>   x <- as(x, 'transactions')
>
>   rules <- apriori(
>     data = x,
>     parameter = list(target = 'rules', minlen = 1, maxlen = 2,
>       support = 0.10, confidence = 0.32)
>   )
>   rules <- arules::sort(x = rules, decreasing = TRUE, by ='support')
>
> gives the rules
> 3  {}  => {1} 0.330   0.3300000  1.0000000
> 2  {}  => {3} 0.326   0.3260000  1.0000000
> 1  {}  => {2} 0.320   0.3200000  1.0000000
> 20 {3} => {1} 0.120   0.3680982  1.1154490
> 21 {1} => {3} 0.120   0.3636364  1.1154490
> 16 {4} => {3} 0.114   0.3677419  1.1280427
> (...)
>
> However, I cannot figure out (help/web) how to get the subset for the rules
> with empty left hand side (lhs) like subset(rules, lhs == ''). I  could run
> the
> apriori() function twice and adjust the min/maxlen parameters as a band
> aid fix.
>
>
> So my question is: How do I subset() association rules with empty lhs?
>
>
> Thanks and regards,
>
> Dirk
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Tue Sep 13 16:43:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Sep 2016 07:43:42 -0700
Subject: [R] Is this kind of removing of elements from
	data.frame	(in)efficient?
In-Reply-To: <5aeb5e3a9f3fa40302792135e8dcc65b@kapsi.fi>
References: <5aeb5e3a9f3fa40302792135e8dcc65b@kapsi.fi>
Message-ID: <F1E2CC92-87C9-4B9D-BABF-79B34ACE69C4@dcn.davis.ca.us>

Your example is not reproducible [1], so the apparent error in it is distracting... perhaps you meant

kidmomhs <- kidmomhs[kidmomhs$kid_score != min(kidmomhs$kid_score),]

yes, this creates a copy, and because the object name is re-used on the left side the original memory gets returned to the memory pool the next time garbage collection occurs. 

While this may seem inefficient, this (functional) programming model is much less likely to lead to programming errors than in-place approaches. My advice is to refrain from premature optimization and get the algorithm right, then later you could rewrite using something like the data.table package if the standard functional model is too slow for a particular application.

In addition, I tend to find that not re-using the object name (not releasing the memory) aids debugging and traceability, which if you are looking to make reproducible research is often an advantage.

[1] see e.g. http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On September 13, 2016 12:37:18 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>So I'm a beginner in R and I was testing the removal of elements from a
>
>data.frame.
>
>The way I remove the element(s) with the minimum value in kid_score 
>variable is to do:
>
>kidmomhs <- data[kidmomhs$kid_score != min(kidmomhs$kid_score),]
>
>So now kidmomhs is the same data, but without the row(s) with the 
>minimum value of kid_score.
>
>Judging by the syntax this looks as if R might be creating a copy of
>the 
>data array, just without the rows that were removed.
>
>The question however is, is this the most efficient way to remove 
>elements from data structures in R? And is the above inefficient? Does 
>the above create copies of almost the entire data structure?
>
>In other programming languages I've become accustomed to doing removal 
>of elements by changing them to NULL and then e.g. reordering the data 
>structure. Rather than having to take copies of almost the entire data 
>structure.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Tue Sep 13 16:48:53 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 13 Sep 2016 06:48:53 -0800
Subject: [R] Drill down reports in R
In-Reply-To: <CADG9u0B_Tiw-6URXpKs-F8TH_X117uNWPspVmZciPOt7aZqmnw@mail.gmail.com>
Message-ID: <BA206927C2E.000000F4jrkrideau@inbox.com>

It is not really clear what you want but have a look at ?subset perhaps.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: manu.reddy52 at gmail.com
> Sent: Tue, 13 Sep 2016 16:16:05 +0530
> To: r-help at r-project.org
> Subject: [R] Drill down reports in R
> 
> Hi,
> 
> 
> 
>   How to generate ?Drill down reports ?  (like please refer below url) in
> R
> using any package ? I did lot of research in google but I didn?t found
> suitable link .
> 
>  Can anyone help how to do that in R ?
> 
> 
> 
> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
> 
> 
> 
> Thanks in Advance !
> 
> Manu.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From pai1981 at gmail.com  Tue Sep 13 16:49:50 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Tue, 13 Sep 2016 08:49:50 -0600
Subject: [R] How to read a grib2 file
In-Reply-To: <CAAcGz9-jKLJOM_dTg8Xdc=1+nab+KaAtu_NwgHBfNMNSbUzvBA@mail.gmail.com>
References: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
	<CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>
	<CAM9mbiAMF3Hneca2jdv5A=jyPphh1NCri9Ooq2bwQ7Pd9A+TTQ@mail.gmail.com>
	<CAAcGz9-jKLJOM_dTg8Xdc=1+nab+KaAtu_NwgHBfNMNSbUzvBA@mail.gmail.com>
Message-ID: <CAM9mbiDL-Kj5EqTKfx+hnwbJrHE8NZ4J6XKzgmA=b8YFAgHTzw@mail.gmail.com>

Hi Mike,
Thanks again. I am using Mac OS

Here is the required info

> sessionInfo()
R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.6 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rNOMADS_2.3.0 rvest_0.3.2   xml2_1.0.0    rgdal_1.1-10  raster_2.5-8
sp_1.2-3

loaded via a namespace (and not attached):
[1] httr_1.1.0      magrittr_1.5    R6_2.1.2        rsconnect_0.4.3
tools_3.2.4
[6] Rcpp_0.12.4     grid_3.2.4      lattice_0.20-33

I am trying to read " tmax.01.2011040100.daily.grb2" from
http://nomads.ncdc.noaa.gov/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/

with regards
-Deb


On Tue, Sep 13, 2016 at 5:26 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> What is your computer system? What is the output of this?
>
> sessionInfo()
>
> If you point to a file I'll try it so I can tell you the minimum system
> requirements.
>
> Cheers, Mike
>
> On Tue, 13 Sep 2016, 08:56 Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
>
>> Thanks for your suggestion. I have checked and I don't have JPEG2000 in
>> ggdalDrivers()). I am pretty new in R. I don't understand how to do I
>> implement JPEG2000 (JP2OpenJPEG driver) in gdalDrivers() so that I can
>> read grib2 files
>>
>> with regards
>> -Deb
>>
>> On Sat, Sep 10, 2016 at 2:33 AM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>
>>>
>>>
>>> On Sat, 10 Sep 2016 at 07:12 Debasish Pai Mazumder <pai1981 at gmail.com>
>>> wrote:
>>>
>>>> Hi
>>>> I am trying to read a grib2 file in R.
>>>>
>>>> Here is my script
>>>>
>>>> library(rgdal)
>>>> library(sp)
>>>> library(rNOMADS)
>>>> gribfile<-"tmax.01.2011040100.daily.grb2"
>>>> grib <- readGDAL(gribfile)
>>>>
>>>> I am getting following error :
>>>>
>>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>>> Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
>>>> driver GRIB
>>>> and has 190 rows and 384 columns
>>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>>> Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
>>>> image within GRIB file.
>>>>
>>>>
>>> Hi there, please check if JPEG2000 is in the gdalDrivers() list, i.e.
>>>  in
>>>
>>> rgdal::gdalDrivers()$name
>>>
>>> You are looking for one starting with "JP2" as per the list next to the
>>> "JPEG2000" rows here:
>>>
>>> http://gdal.org/formats_list.html
>>>
>>> I have  JP2OpenJPEG on one system, but not (for example) on the Windows
>>> CRAN binary for rgdal, which is the only readily available Windows build
>>> for this package.
>>>
>>> I you don't have it, you might try on a system that has the JP2OpenJPEG driver,
>>> or ask someone to try on your behalf. You'd want to find out if that will
>>> enable this read for you before investing time in the Linux configuration.
>>>
>>> It's not too hard to set up a Linux system for this, but does assume a
>>> bit of experience on your part. Some of the docker images in the
>>> rockerverse have this all sorted I believe, but it's been a while since I
>>> used them.
>>>
>>> https://hub.docker.com/u/rocker/
>>>
>>> Cheers, Mike.
>>>
>>>
>>>
>>>
>>>> Cheers
>>>> -Deb
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> --
>>> Dr. Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> 203 Channel Highway
>>> Kingston Tasmania 7050 Australia
>>>
>>>
>> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 13 16:59:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Sep 2016 07:59:06 -0700
Subject: [R] syntax to connect to linked SQL server using RODBC
In-Reply-To: <CAF-rFrJnbVeAZ4ua7wWmRMdMOsPJ_XoQ2zhatNf9UE_SRjv+kw@mail.gmail.com>
References: <CAF-rFrJnbVeAZ4ua7wWmRMdMOsPJ_XoQ2zhatNf9UE_SRjv+kw@mail.gmail.com>
Message-ID: <BEC5449F-EE19-4327-ABAF-D766E1A86BDD@dcn.davis.ca.us>

This is not an R concept, and it may be highly specific to the SQL Server API rather than the ODBC API. You might try doing as the Posting Guide recommends and posting in the R-sig-db mailing list. I would also recommend that you figure out from Microsoft documentation what programming API your GUI software example is using to accomplish this rather than referring to that GUI program in your question.
-- 
Sent from my phone. Please excuse my brevity.

On September 13, 2016 7:02:20 AM PDT, Varun Sinha <sinha.varuna85 at gmail.com> wrote:
>Hi All,
>
>I would like to know how to connect to a "linked server" from R. I find
>the
>linked server under Server Objects > Linked Servers on SQL management
>studio.
>
>Here is the current way I am using to connect to the server:
>
>dbhandle <- odbcDriverConnect('driver={SQL
>Server};server=servername;database=databasename;trusted_connection=true')
>
>table1 <- as.data.table(sqlQuery(dbhandle, 'select a, b from table1'))
>
>Could you please let me know the syntax to do the same but with the
>linked
>server instead? I would like to connect to a database on the linked
>server
>and run the query to pull data.
>
>Thank you for your help.
>
>Best regards,
>Varun
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Sep 13 17:03:47 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 13 Sep 2016 10:03:47 -0500
Subject: [R] Drill down reports in R
In-Reply-To: <BA206927C2E.000000F4jrkrideau@inbox.com>
References: <BA206927C2E.000000F4jrkrideau@inbox.com>
Message-ID: <F599BCDB-6794-4FC0-ABAE-AAD468F49288@me.com>

Hi,

Generally "drilldown" reports require a dynamic GUI that supports widgets that generate the data queries behind the scenes in response to user input/clicks and then updated the display dynamically with the additional data/content.

This would be more typical of business oriented reporting/OLAP tools like Cognos, Business Objects, Crystal Reports, etc.

The first thing that came to mind is RStudio's Shiny, which I do not use, but their gallery seems to have some possibilities:

  http://shiny.rstudio.com/gallery/

Regards,

Marc Schwartz


> On Sep 13, 2016, at 9:48 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
> It is not really clear what you want but have a look at ?subset perhaps.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: manu.reddy52 at gmail.com
>> Sent: Tue, 13 Sep 2016 16:16:05 +0530
>> To: r-help at r-project.org
>> Subject: [R] Drill down reports in R
>> 
>> Hi,
>> 
>> 
>> 
>>  How to generate ?Drill down reports ?  (like please refer below url) in
>> R
>> using any package ? I did lot of research in google but I didn?t found
>> suitable link .
>> 
>> Can anyone help how to do that in R ?
>> 
>> 
>> 
>> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
>> 
>> 
>> 
>> Thanks in Advance !
>> 
>> Manu.


From manu.reddy52 at gmail.com  Tue Sep 13 17:30:59 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Tue, 13 Sep 2016 21:00:59 +0530
Subject: [R] syntax to connect to linked SQL server using RODBC
In-Reply-To: <BEC5449F-EE19-4327-ABAF-D766E1A86BDD@dcn.davis.ca.us>
References: <CAF-rFrJnbVeAZ4ua7wWmRMdMOsPJ_XoQ2zhatNf9UE_SRjv+kw@mail.gmail.com>
	<BEC5449F-EE19-4327-ABAF-D766E1A86BDD@dcn.davis.ca.us>
Message-ID: <CADG9u0BDCNk0XhmU4spZ=paNRfwm62Ht14QRpgAKJvQG9jSp=w@mail.gmail.com>

Hi Varun,

  Basically when we are pulling data from linked server through SSMS/some
other client tools we may need to use query like this format
* linkedservername.databasename.schemaname.tablename* and in this case your
query like this,

table1 <- as.data.table(sqlQuery(dbhandle, 'select * from
linkedservername.databasename.schemaname.tablename'))

Manu.

On Tue, Sep 13, 2016 at 8:29 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is not an R concept, and it may be highly specific to the SQL Server
> API rather than the ODBC API. You might try doing as the Posting Guide
> recommends and posting in the R-sig-db mailing list. I would also recommend
> that you figure out from Microsoft documentation what programming API your
> GUI software example is using to accomplish this rather than referring to
> that GUI program in your question.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 13, 2016 7:02:20 AM PDT, Varun Sinha <
> sinha.varuna85 at gmail.com> wrote:
> >Hi All,
> >
> >I would like to know how to connect to a "linked server" from R. I find
> >the
> >linked server under Server Objects > Linked Servers on SQL management
> >studio.
> >
> >Here is the current way I am using to connect to the server:
> >
> >dbhandle <- odbcDriverConnect('driver={SQL
> >Server};server=servername;database=databasename;trusted_connection=true')
> >
> >table1 <- as.data.table(sqlQuery(dbhandle, 'select a, b from table1'))
> >
> >Could you please let me know the syntax to do the same but with the
> >linked
> >server instead? I would like to connect to a database on the linked
> >server
> >and run the query to pull data.
> >
> >Thank you for your help.
> >
> >Best regards,
> >Varun
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 


Thanks,
Manohar Reddy P
+91-9705302062.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 13 17:43:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Sep 2016 08:43:39 -0700
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
In-Reply-To: <87y42vykw2.fsf@hornfels.zedat.fu-berlin.de>
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
	<87y42vykw2.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <75AF30E7-B3E0-433F-A46F-7A811F5E431C@dcn.davis.ca.us>

For this query I would rather recommend [1] as reference, though Marc's suggestion to switch mailing lists is best.

[1] https://cran.r-project.org/bin/linux/ubuntu/
-- 
Sent from my phone. Please excuse my brevity.

On September 13, 2016 6:44:29 AM PDT, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>Luigi Marongiu <marongiu.luigi at gmail.com> writes:
>
>> Dear all,
>> I am working on Linux Ubuntu 16.04 and I have installed R 3.2. I need
>> to upgrade to R 3.3 and I tried several options available online with
>> no success. I downloaded the tar.gz file for R 3.3 and I would like
>to
>> ask how can I use this file in order to accomplish the upgrade.
>> Many thanks,
>> Luigi
>>
>
>Have you looked here:
>
>https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-R-under-Unix_002dalikes
>
>?
>
>Cheers,
>
>Loris
>
>-- 
>Dr. Loris Bennett (Mr.)
>ZEDAT, Freie Universit?t Berlin         Email
>loris.bennett at fu-berlin.de
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Tue Sep 13 16:20:58 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 13 Sep 2016 16:20:58 +0200
Subject: [R] Minimum Binding Box in 3D
Message-ID: <20160913142058.GB1215@chicca2>

Dear All,
I would like to know if anybody is aware of an R implementation of a
minimal bounding box ( http://bit.ly/2cKaSgT ) algorithm in R for
points in 3 dimensions.
It looks like there is no shortage of implementations in 2 dimensions,
e.g.

http://bit.ly/2cKaSh0
http://bit.ly/2cKboLS

but I cannot find any implementation for the 3D case.
Many thanks

Lorenzo


From cleotebby at gmail.com  Tue Sep 13 16:55:51 2016
From: cleotebby at gmail.com (Cleo Tebby)
Date: Tue, 13 Sep 2016 16:55:51 +0200
Subject: [R] Error with permutest on dbrda object in vegan
Message-ID: <CAHzJ1R6pPy2vh59i7WkfGB_5iofBu-Y0jYqWHUCpnQuGKd2BeA@mail.gmail.com>

Dear all,

I am using distance-based RDA in vegan 2.4-1 with direct decomposition
(no constant added, imaginary axes included) and trying to test axis
significance. Permutations seem to work with first=FALSE, but not
first=TRUE. The error message is "invalid comparison with complex
values".

Here is my code:

library(vegan)
data(pyrifos)
ditch <- gl(12, 1, length=132)
week <- gl(11, 12, labels=c(-4, -1, 0.1, 1, 2, 4, 8, 12, 15, 19, 24))
dose <- factor(rep(c(0.1, 0, 0, 0.9, 0, 44, 6, 0.1, 44, 0.9, 0, 6), 11))
res_rda_pyrifos_inv_BC<-dbrda(pyrifos~interaction(week,dose) +
Condition(week), distance = "bray")
ctrl_pyrifos <- how(plots = Plots(strata = ditch,type = "free"),
within = Within(type = "series"), nperm = 99)
permutest(res_rda_pyrifos_inv_BC,  permutations=ctrl_pyrifos, first=TRUE)

I get this message:

"Permutation test for dbrda

Plots: ditch, plot permutation: free
Permutation: series
Number of permutations: 9999

Call: dbrda(formula = pyrifos_inv_raw ~ interaction(week, dose) +
Condition(week), distance = "bray")
Error in x$F.perm >= x$F.0 - EPS : invalid comparison with complex values"

Any help would be appreciated!
Thanks,
Cleo Tebby


From manu.reddy52 at gmail.com  Tue Sep 13 18:11:02 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Tue, 13 Sep 2016 21:41:02 +0530
Subject: [R] Drill down reports in R
In-Reply-To: <F599BCDB-6794-4FC0-ABAE-AAD468F49288@me.com>
References: <BA206927C2E.000000F4jrkrideau@inbox.com>
	<F599BCDB-6794-4FC0-ABAE-AAD468F49288@me.com>
Message-ID: <CADG9u0ANLC_A=6-Xzqi0_SxKJnD_--JY6KzRJdvd51aQy7PZoQ@mail.gmail.com>

Hi Jhon,



 Thanks for responding my email ,actually my requirement is I have Orders
and related tables and now I need to generate a report something looks like
below whenever user click on ?+? that report will be expanded .I know it is
possible in SSRS (SQl Server Reporting Services) but now my requirement is
I need to generate that kind of report in R.



 If we look at screen shot (or PFA) almost 100244 order exists  8 times
,now I want to generate the report whenever user clicks on order 100244 and
it needs to be expand and need to display the cost of all the products and
what are the products they were purchased on this orderID .



Note: in backend I did using Group by (sql) but I don?t know how to present
in this report.





Hi Marc,



   Thanks,Currently I?m creating reports  using shinyapps only ,I have
checked out throghly with shinyapps but I didn?t find any solution,is there
any alternative way that I can use to genarate the drill down report.



 Manu.

On Tue, Sep 13, 2016 at 8:33 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> Generally "drilldown" reports require a dynamic GUI that supports widgets
> that generate the data queries behind the scenes in response to user
> input/clicks and then updated the display dynamically with the additional
> data/content.
>
> This would be more typical of business oriented reporting/OLAP tools like
> Cognos, Business Objects, Crystal Reports, etc.
>
> The first thing that came to mind is RStudio's Shiny, which I do not use,
> but their gallery seems to have some possibilities:
>
>   http://shiny.rstudio.com/gallery/
>
> Regards,
>
> Marc Schwartz
>
>
> > On Sep 13, 2016, at 9:48 AM, John Kane <jrkrideau at inbox.com> wrote:
> >
> > It is not really clear what you want but have a look at ?subset perhaps.
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: manu.reddy52 at gmail.com
> >> Sent: Tue, 13 Sep 2016 16:16:05 +0530
> >> To: r-help at r-project.org
> >> Subject: [R] Drill down reports in R
> >>
> >> Hi,
> >>
> >>
> >>
> >>  How to generate ?Drill down reports ?  (like please refer below url) in
> >> R
> >> using any package ? I did lot of research in google but I didn?t found
> >> suitable link .
> >>
> >> Can anyone help how to do that in R ?
> >>
> >>
> >>
> >> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
> >>
> >>
> >>
> >> Thanks in Advance !
> >>
> >> Manu.
>
>


-- 


Thanks,
Manohar Reddy P
+91-9705302062.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Orders_details.PNG
Type: image/png
Size: 16182 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160913/d816e9a9/attachment.png>

From msharp at txbiomed.org  Tue Sep 13 18:26:35 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 13 Sep 2016 16:26:35 +0000
Subject: [R] Drill down reports in R
In-Reply-To: <CADG9u0ANLC_A=6-Xzqi0_SxKJnD_--JY6KzRJdvd51aQy7PZoQ@mail.gmail.com>
References: <BA206927C2E.000000F4jrkrideau@inbox.com>
	<F599BCDB-6794-4FC0-ABAE-AAD468F49288@me.com>
	<CADG9u0ANLC_A=6-Xzqi0_SxKJnD_--JY6KzRJdvd51aQy7PZoQ@mail.gmail.com>
Message-ID: <46C90CA2-F425-4B19-9C9B-DD3D18E9178F@TxBiomed.org>

Manu,

With pure R, you can simply write a link in the parent document to a child document you have created. Alternative, and likely better, solutions could be based on AJAX, but I do not think you are going to do that all within R.

Mark
> On Sep 13, 2016, at 11:11 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>
> Hi Jhon,
>
>
>
> Thanks for responding my email ,actually my requirement is I have Orders
> and related tables and now I need to generate a report something looks like
> below whenever user click on ?+? that report will be expanded .I know it is
> possible in SSRS (SQl Server Reporting Services) but now my requirement is
> I need to generate that kind of report in R.
>
>
>
> If we look at screen shot (or PFA) almost 100244 order exists  8 times
> ,now I want to generate the report whenever user clicks on order 100244 and
> it needs to be expand and need to display the cost of all the products and
> what are the products they were purchased on this orderID .
>
>
>
> Note: in backend I did using Group by (sql) but I don?t know how to present
> in this report.
>
>
>
>
>
> Hi Marc,
>
>
>
>   Thanks,Currently I?m creating reports  using shinyapps only ,I have
> checked out throghly with shinyapps but I didn?t find any solution,is there
> any alternative way that I can use to genarate the drill down report.
>
>
>
> Manu.
>
> On Tue, Sep 13, 2016 at 8:33 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> Hi,
>>
>> Generally "drilldown" reports require a dynamic GUI that supports widgets
>> that generate the data queries behind the scenes in response to user
>> input/clicks and then updated the display dynamically with the additional
>> data/content.
>>
>> This would be more typical of business oriented reporting/OLAP tools like
>> Cognos, Business Objects, Crystal Reports, etc.
>>
>> The first thing that came to mind is RStudio's Shiny, which I do not use,
>> but their gallery seems to have some possibilities:
>>
>>  http://shiny.rstudio.com/gallery/
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> On Sep 13, 2016, at 9:48 AM, John Kane <jrkrideau at inbox.com> wrote:
>>>
>>> It is not really clear what you want but have a look at ?subset perhaps.
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: manu.reddy52 at gmail.com
>>>> Sent: Tue, 13 Sep 2016 16:16:05 +0530
>>>> To: r-help at r-project.org
>>>> Subject: [R] Drill down reports in R
>>>>
>>>> Hi,
>>>>
>>>>
>>>>
>>>> How to generate ?Drill down reports ?  (like please refer below url) in
>>>> R
>>>> using any package ? I did lot of research in google but I didn?t found
>>>> suitable link .
>>>>
>>>> Can anyone help how to do that in R ?
>>>>
>>>>
>>>>
>>>> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
>>>>
>>>>
>>>>
>>>> Thanks in Advance !
>>>>
>>>> Manu.
>>
>>
>
>
> --
>
>
> Thanks,
> Manohar Reddy P
> +91-9705302062.
> <Orders_details.PNG>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From marc_schwartz at me.com  Tue Sep 13 18:36:13 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 13 Sep 2016 11:36:13 -0500
Subject: [R] Drill down reports in R
In-Reply-To: <CADG9u0ANLC_A=6-Xzqi0_SxKJnD_--JY6KzRJdvd51aQy7PZoQ@mail.gmail.com>
References: <BA206927C2E.000000F4jrkrideau@inbox.com>
	<F599BCDB-6794-4FC0-ABAE-AAD468F49288@me.com>
	<CADG9u0ANLC_A=6-Xzqi0_SxKJnD_--JY6KzRJdvd51aQy7PZoQ@mail.gmail.com>
Message-ID: <CE705DE5-9A23-49EB-B3AC-5966C2572D85@me.com>


> On Sep 13, 2016, at 11:11 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> 
> Hi Jhon,
> 
>  
>  Thanks for responding my email ,actually my requirement is I have Orders and related tables and now I need to generate a report something looks like below whenever user click on ?+? that report will be expanded .I know it is possible in SSRS (SQl Server Reporting Services) but now my requirement is I need to generate that kind of report in R.
> 
>  
>  If we look at screen shot (or PFA) almost 100244 order exists  8 times ,now I want to generate the report whenever user clicks on order 100244 and it needs to be expand and need to display the cost of all the products and what are the products they were purchased on this orderID .
> 
>  
> Note: in backend I did using Group by (sql) but I don?t know how to present in this report.
> 
>  
> 
> 
>  
> Hi Marc,
> 
>  
>    Thanks,Currently I?m creating reports  using shinyapps only ,I have checked out throghly with shinyapps but I didn?t find any solution,is there any alternative way that I can use to genarate the drill down report.
> 
>  
>  Manu.
> 

Hi Manu,

As noted, the type of functionality that you are looking for would typically require a GUI that supports dynamic interactions and updating. That is why there are dedicated reporting tools, as I noted, that have evolved over the years, to serve that need in the typical business domains where it is used. 

Most of those tools typically interface with a live server database backend (e.g. Oracle, MySQL, etc.), a local database or spreadsheet file (e.g. MS Access or Excel via ODBC) or an intermediate "OLAP cube" construct, as the primary data repository to which dynamic queries are sent based upon user inputs from the GUI.

If Shiny does not have that in place already and you wanted to use Shiny, you would need to develop it on your own or have likely have to pay someone do it for you.

I am not aware of other possible R related GUIs that support that type of interaction, albeit, it is possible that somebody has done something that is not yet well publicized or may be for internal use only. 

There are a variety of supporting technologies (e.g. AJAX, Java, etc.) that could provide for that type of functionality, either stand alone or within a browser based environment, but it would not be "pure R" per se.

It may also be possible that one of the other commercial R vendors (e.g. Microsoft) have built something on top of a server version of R and you would need to contact them to see if that is the case.

Regards,

Marc

> 
> On Tue, Sep 13, 2016 at 8:33 PM, Marc Schwartz <marc_schwartz at me.com <mailto:marc_schwartz at me.com>> wrote:
> Hi,
> 
> Generally "drilldown" reports require a dynamic GUI that supports widgets that generate the data queries behind the scenes in response to user input/clicks and then updated the display dynamically with the additional data/content.
> 
> This would be more typical of business oriented reporting/OLAP tools like Cognos, Business Objects, Crystal Reports, etc.
> 
> The first thing that came to mind is RStudio's Shiny, which I do not use, but their gallery seems to have some possibilities:
> 
>   http://shiny.rstudio.com/gallery/ <http://shiny.rstudio.com/gallery/>
> 
> Regards,
> 
> Marc Schwartz
> 
> 
> > On Sep 13, 2016, at 9:48 AM, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
> >
> > It is not really clear what you want but have a look at ?subset perhaps.
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: manu.reddy52 at gmail.com <mailto:manu.reddy52 at gmail.com>
> >> Sent: Tue, 13 Sep 2016 16:16:05 +0530
> >> To: r-help at r-project.org <mailto:r-help at r-project.org>
> >> Subject: [R] Drill down reports in R
> >>
> >> Hi,
> >>
> >>
> >>
> >>  How to generate ?Drill down reports ?  (like please refer below url) in
> >> R
> >> using any package ? I did lot of research in google but I didn?t found
> >> suitable link .
> >>
> >> Can anyone help how to do that in R ?
> >>
> >>
> >>
> >> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/ <http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/>
> >>
> >>
> >>
> >> Thanks in Advance !
> >>
> >> Manu.
> 
> 
> 
> 
> -- 
> 
> 
> Thanks,
> Manohar Reddy P
> +91-9705302062.
> 


	[[alternative HTML version deleted]]


From 538280 at gmail.com  Tue Sep 13 19:32:28 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 13 Sep 2016 11:32:28 -0600
Subject: [R] Drill down reports in R
In-Reply-To: <CADG9u0B_Tiw-6URXpKs-F8TH_X117uNWPspVmZciPOt7aZqmnw@mail.gmail.com>
References: <CADG9u0B_Tiw-6URXpKs-F8TH_X117uNWPspVmZciPOt7aZqmnw@mail.gmail.com>
Message-ID: <CAFEqCdz3O5j=1=BQXO=nrdbtAUCcxu7x6B51Sha=HiR1YiGdrg@mail.gmail.com>

As has been mentioned, this really requires a GUI tool beyond just R.
Luckily there are many GUI tools that have been linked to R and if
Shiny (the shiniest of them) does not have something like this easily
available so far then you may want to look elsewhere in the meantime.

One option is the tcltk package which interfaces with the Tk GUI tools
(and the tcl language) which does have the pieces to build in the
expandable/drill down interface.  One implementation of this is the
TkListView function in the TeachingDemos package which can be used to
view list objects in this manner (it starts with the top level list
objects, then when you click on a + symbol it will open that piece and
show one level down).

One possibility would be to create all of your results in a list, then
view it with TkListView  (this will require all computations up front,
whether anyone looks at them or not).

Another option would be to start with TkListView and rewrite it to do
things more dynamically and with the output that you want to show.

There is also the shinyTree package on CRAN that allows a tree type
object in shiny that may do what you want (I don't know what all
options it allows and what it can display beyond what is in the
Readme).



On Tue, Sep 13, 2016 at 4:46 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> Hi,
>
>
>
>   How to generate ?Drill down reports ?  (like please refer below url) in R
> using any package ? I did lot of research in google but I didn?t found
> suitable link .
>
>  Can anyone help how to do that in R ?
>
>
>
> url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
>
>
>
> Thanks in Advance !
>
> Manu.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From henrik.bengtsson at gmail.com  Tue Sep 13 20:23:13 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 13 Sep 2016 11:23:13 -0700
Subject: [R] Maximum # of DLLs reached, or,
	how to clean up after yourself?
In-Reply-To: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>
References: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>
Message-ID: <CAFDcVCT_vb_v0zeYpYOY1KRCK62N78=-36OGbupUFVsCbneg6Q@mail.gmail.com>

In R.utils (>= 2.4.0), which I hope to submitted to CRAN today or
tomorrow, you can simply call:

   R.utils::gcDLLs()

It will look at base::getLoadedDLLs() and its content and compare to
loadedNamespaces() and unregister any "stray" DLLs that remain after
corresponding packages have been unloaded.

Until the new version is on CRAN, you can install it via

    source("http://callr.org/install#HenrikBengtsson/R.utils at develop")

or alternatively just source() the source file:

    source("https://raw.githubusercontent.com/HenrikBengtsson/R.utils/develop/R/gcDLLs.R")


DISCUSSION:
(this might be better suited for R-devel; feel free to move it there)

As far as I understand the problem, running into this error / limit is
_not_ the fault of the user.  Instead, I'd argue that it is the
responsibility of package developers to make sure to unregister any
registered DLLs of theirs when the package is unloaded.  A developer
can do this by adding the following to their package:

.onUnload <- function(libpath) {
    library.dynam.unload(utils::packageName(), libpath)
 }

That should be all - then the DLL will be unloaded as soon as the
package is unloaded.

I would like to suggest that 'R CMD check' would include a check that
asserts when a package is unloaded it does not leave any registered
DLLs behind, e.g.

* checking whether the namespace can be unloaded cleanly ... WARNING
  Unloading the namespace does not unload DLL
* checking loading without being on the library search path ... OK

For further details on my thoughts on this, see
https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29.

Hope this helps

Henrik

On Tue, Sep 13, 2016 at 6:05 AM, Alexander Shenkin <ashenkin at ufl.edu> wrote:
> Hello all,
>
> I have a number of analyses that call bunches of sub-scripts, and in the
> end, I get the "maximal number of DLLs reached" error.  This has been asked
> before (e.g.
> http://stackoverflow.com/questions/36974206/r-maximal-number-of-dlls-reached),
> and the general answer is, "just clean up after yourself".
>
> Assuming there are no plans to raise this 100-DLL limit in the near future,
> my question becomes, what is best practice for cleaning up (detaching)
> loaded packages in scripts, when those scripts are sometimes called from
> other scripts?  One can detach all packages at the end of a script that were
> loaded at the beginning of the script.  However, if a package is required in
> a calling script, one should really make sure it hadn't been loaded prior to
> sub-script invocation before detaching it.
>
> I could write a custom function that pushes and pops package names from a
> global list, in order to keep track, but maybe there's a better way out
> there...
>
> Thanks for any thoughts.
>
> Allie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Sep 14 00:04:24 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Sep 2016 15:04:24 -0700
Subject: [R] Minimum Binding Box in 3D
In-Reply-To: <20160913142058.GB1215@chicca2>
References: <20160913142058.GB1215@chicca2>
Message-ID: <1C2DBA7F-5560-44A4-939A-B059F06420FA@comcast.net>


> On Sep 13, 2016, at 7:20 AM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Dear All,
> I would like to know if anybody is aware of an R implementation of a
> minimal bounding box ( http://bit.ly/2cKaSgT ) algorithm in R for
> points in 3 dimensions.
> It looks like there is no shortage of implementations in 2 dimensions,
> e.g.
> 
> http://bit.ly/2cKaSh0
> http://bit.ly/2cKboLS
> 
> but I cannot find any implementation for the 3D case.

There should be no difficulty finding functions that derive a convex hull in three dimensions and the first answer to the first link above (on StackOverflow) describes an algorithm that lets you go from a polyhedron to a bounding box. 


> Many thanks
> 
> Lorenzo
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From aanchalsharma833 at gmail.com  Wed Sep 14 00:46:58 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Tue, 13 Sep 2016 18:46:58 -0400
Subject: [R] Fitting Mixture distributions
In-Reply-To: <CAGxFJbS7FF6ZfnnePEBn=T57PKjgPf1=QCXUyqwESwmXpH5H5g@mail.gmail.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
	<E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>
	<c742bf40-b995-463a-b652-87909969cc09@googlegroups.com>
	<CAGxFJbT41DE6E32fToSLOXQwv_zFEMYA29+_Q=hsOF_ugNgdNg@mail.gmail.com>
	<22481.23474.403070.875828@stat.math.ethz.ch>
	<CAFp0Li3MudaE1=QU6y5FrEZKqCC3hYg+PMN4x+80qpvQPqY=vA@mail.gmail.com>
	<CAGxFJbS7FF6ZfnnePEBn=T57PKjgPf1=QCXUyqwESwmXpH5H5g@mail.gmail.com>
Message-ID: <CAFp0Li0+w3jB4EbgvOhcBjzRbGWvshecK9SZ77CYaePOVpcqDA@mail.gmail.com>

Yes, I mentioned it wrong , I increased the value. This did not help
either. what helped is removing some samples which had zero (close to zero)
values. So its working fine for this error.

But there is another problem.
For one of the genes it says throws following error:

iteration = 1  log-lik diff = NaN  log-lik = NaN
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed

Seems like EM is not able to calculate log-lik value (NaN) at the first
iteration itself. any idea why that can happen?
It works fine for the other genes in the loop. Tried looking for difference
in the inputs, but could not come up with anything striking.
Thanks for consistent inputs.

On Mon, Sep 12, 2016 at 8:18 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Do you mean "increase the convergence value." Decreasing it should
> make it harder to converge (I believe, depending on exactly how
> "convergence vaue" is defined,  so doublecheck.)
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 12, 2016 at 4:40 PM, Aanchal Sharma
> <aanchalsharma833 at gmail.com> wrote:
> > Thanks for the reply.
> >
> > I have another related issue with Gamma mixture model. here is the
> > description:
> >
> > I am trying to fit a 2 component gamma mixture model to my data (residual
> > values obtained after running Generalized Linear Model), using following
> > command (part of the code):
> >
> >  expr_mix_gamma <- gammamixEM(expr_glm_residuals, lambda = c(0.75,0.25),
> k =
> > 2, epsilon = 1e-08, maxit = 1000, maxrestarts=20, verb = TRUE)
> >
> > The code runs for multiple gene files (in loop). it runs fine for some
> files
> > whereas for others it throws following error:
> >
> >     Error in gammamixEM(expr_glm_residuals, lambda = c(0.75, 0.25), k =
> 2,
> > : Try different number of components?
> >
> > I tried increasing iterations and decreasing the convergence value, but
> that
> > doesn't seem to work. Is there anything else that I can try?
> > Thanks
> >
> >
> > On Thu, Sep 8, 2016 at 8:38 AM, Martin Maechler <
> maechler at stat.math.ethz.ch>
> > wrote:
> >>
> >> >>>>> Bert Gunter <bgunter.4567 at gmail.com>
> >> >>>>>     on Wed, 7 Sep 2016 23:47:40 -0700 writes:
> >>
> >>     > "please suggest what can I do to resolve this
> >>     > issue."
> >>
> >>     > Fitting normal mixtures can be difficult, and sometime the
> >>     > optimization algorithm (EM) will get stuck with very slow
> >> convergence.
> >>     > Presumably there are options in the package to either increase the
> >> max
> >>     > number of steps before giving up or make the convergence criteria
> >> less
> >>     > sensitive. The former will increase the run time and the latter
> will
> >>     > reduce the optimality (possibly leaving you farther from the true
> >>     > optimum). So you should look into changing these as you think
> >>     > appropriate.
> >>
> >> I'm jumping in late, without having read everything preceding.
> >>
> >> One of the last messages seemed to indicate that you are looking
> >> at mixtures of *one*-dimensional gaussians.
> >>
> >> If this is the case, I strongly recommend looking at (my) CRAN
> >> package 'nor1mix' (the "1" is for "*one*-dimensional).
> >>
> >> For a while now that small package is providing an alternative
> >> to the EM, namely direct MLE, simply using optim(<likelihood>) where the
> >> likelihood uses a somewhat smart parametrization.
> >>
> >> Of course, *as the EM*, this also depends on the starting value,
> >> but my (limited) experience has been that
> >>   nor1mix::norMixMLE()
> >> works considerably faster and more reliable than the EM (which I
> >> also provide as    nor1mix::norMixEM() .
> >>
> >> Apropos 'starting value': The help page shows how to use
> >> kmeans() for "somewhat" reliable starts; alternatively, I'd
> >> recommend using cluster::pam() to get a start there.
> >>
> >> I'm glad to hear about experiences using these / comparing
> >> these with other approaches.
> >>
> >> Martin
> >>
> >>
> >> --
> >> Martin Maechler,
> >> ETH Zurich
> >>
> >>
> >>     > On Wed, Sep 7, 2016 at 3:51 PM, Aanchal Sharma
> >>     > <aanchalsharma833 at gmail.com> wrote:
> >>     >> Hi Simon
> >>     >>
> >>     >> I am facing same problem as described above. i am trying to fit
> >> gaussian
> >>     >> mixture model to my data using normalmixEM. I am running a
> Rscript
> >> which
> >>     >> has this function running as part of it for about 17000 datasets
> >> (in loop).
> >>     >> The script runs fine for some datasets, but it terminates when it
> >>     >> encounters one dataset with the following error:
> >>     >>
> >>     >> Error in normalmixEM(expr_glm_residuals, lambda = c(0.75,
> 0.25), k
> >> = 2,  :
> >>     >> Too many tries!
> >>     >>
> >>     >> (command used: expr_mix_gau <- normalmixEM(expr_glm_residuals,
> >> lambda =
> >>     >> c(0.75,0.25), k = 2, epsilon = 1e-08, maxit = 10000,
> >> maxrestarts=200, verb
> >>     >> = TRUE))
> >>     >> (expr_glm_residuals is my dataset which has residual values for
> >> different
> >>     >> samples)
> >>     >>
> >>     >> It is suggested that one should define the mu and sigma in the
> >> command by
> >>     >> looking at your dataset. But in my case there are many datasets
> and
> >> it will
> >>     >> keep on changing every time. please suggest what can I do to
> >> resolve this
> >>     >> issue.
> >>     >>
> >>     >> Regards
> >>     >> Anchal
> >>     >>
> >>     >> On Tuesday, 16 July 2013 17:53:09 UTC-4, Simon Zehnder wrote:
> >>     >>>
> >>     >>> Hi Tjun Kiat Teo,
> >>     >>>
> >>     >>> you try to fit a Normal mixture to some data. The Normal mixture
> >> is very
> >>     >>> delicate when it comes to parameter search: If the variance gets
> >> closer and
> >>     >>> closer to zero, the log Likelihood becomes larger and larger for
> >> any values
> >>     >>> of the remaining parameters. Furthermore for the EM algorithm it
> >> is known,
> >>     >>> that it takes sometimes very long until convergence is reached.
> >>     >>>
> >>     >>> Try the following:
> >>     >>>
> >>     >>> Use as starting values for the component parameters:
> >>     >>>
> >>     >>> start.par <- mean(your.data, na.rm = TRUE) + sd(your.data,
> na.rm =
> >> TRUE) *
> >>     >>> runif(K)
> >>     >>>
> >>     >>> For the weights just use either 1/K or the R cluster function
> with
> >> K
> >>     >>> clusters
> >>     >>>
> >>     >>> Here K is the number of components. Further enlarge the maximum
> >> number of
> >>     >>> iterations. What you could also try is to randomize start
> >> parameters and
> >>     >>> run an SEM (Stochastic EM). In my opinion the better method is
> in
> >> this case
> >>     >>> a Bayesian method: MCMC.
> >>     >>>
> >>     >>>
> >>     >>> Best
> >>     >>>
> >>     >>> Simon
> >>     >>>
> >>     >>>
> >>     >>> On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teot... at gmail.com
> >>     >>> <javascript:>> wrote:
> >>     >>>
> >>     >>> > I was trying to use the normixEM in mixtools and I got this
> >> error
> >>     >>> message.
> >>     >>> >
> >>     >>> > And I got this error message
> >>     >>> >
> >>     >>> > One of the variances is going to zero;  trying new starting
> >> values.
> >>     >>> > Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too
> >> many
> >>     >>> tries!
> >>     >>> >
> >>     >>> > Are there any other packages for fitting mixture distributions
> >> ?
> >>     >>> >
> >>     >>> >
> >>     >>> > Tjun Kiat Teo
> >>     >>> >
> >>     >>> >         [[alternative HTML version deleted]]
> >>     >>> >
> >>     >>> > ______________________________________________
> >>     >>> > R-h... at r-project.org <javascript:> mailing list
> >>     >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>     >>> > PLEASE do read the posting guide
> >>     >>> http://www.R-project.org/posting-guide.html
> >>     >>> > and provide commented, minimal, self-contained, reproducible
> >> code.
> >>     >>>
> >>     >>> ______________________________________________
> >>     >>> R-h... at r-project.org <javascript:> mailing list
> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>     >>> PLEASE do read the posting guide
> >>     >>> http://www.R-project.org/posting-guide.html
> >>     >>> and provide commented, minimal, self-contained, reproducible
> code.
> >>     >>>
> >>     >> ______________________________________________
> >>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>     >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>     >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>     >> and provide commented, minimal, self-contained, reproducible
> code.
> >>
> >>     > ______________________________________________
> >>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>     > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>     > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Anchal Sharma, PhD
> > Postdoctoral Fellow
> > 195, Little Albany street,
> > Cancer Institute of New Jersey
> > Rutgers University
> > NJ-08901
>



-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From erich.neuwirth at univie.ac.at  Wed Sep 14 07:54:44 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 14 Sep 2016 07:54:44 +0200
Subject: [R] gene name problem in Excel, and an R analogue
Message-ID: <333F0819-169F-4312-9A02-ED3A94006D7D@univie.ac.at>

Since many people commenting on the gene name problem in Excel essentially tell us
This could never have happened with R
I want to show you a somewhat related issue:


ff1 <- tempfile()
cat(file = ff1, "12345", "1E002", sep = "\n")
xdf1 <- read.fwf(ff1, widths = 5, stringsAsFactors=FALSE)

ff2 <- tempfile()
cat(file = ff2, "12345", "1E002","1A010", sep = "\n")
xdf2 <- read.fwf(ff2, widths = 5, stringsAsFactors=FALSE)

in xdf1, the variable is numeric, in xdf2, it is a character variable.
Of course, in hindsight this makes sense. But the problem is similar to the
Excel problem where something which could be a date is interpreted as a date.

A possible solution with my read.fwf problem would be to have a parameter
forcing variables to be read as strings.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160914/2dd78d01/attachment.bin>

From loris.bennett at fu-berlin.de  Wed Sep 14 07:57:52 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 14 Sep 2016 07:57:52 +0200
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
	<87y42vykw2.fsf@hornfels.zedat.fu-berlin.de>
	<75AF30E7-B3E0-433F-A46F-7A811F5E431C@dcn.davis.ca.us>
Message-ID: <87lgyvuiov.fsf@hornfels.zedat.fu-berlin.de>

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> For this query I would rather recommend [1] as reference, though
> Marc's suggestion to switch mailing lists is best.
>
> [1] https://cran.r-project.org/bin/linux/ubuntu/

But doesn't this merely describe how to install the version of R
packaged for his version of Ubuntu?  As I understood the OP, he has
already installed this version, which is 3.2.3, but would like to
install 3.3.1, which he will have to install from the sources.

If this is the case, then there is no point reposting to r-sig-debian,
since he just has to do a generic unix-like install.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jdnewmil at dcn.davis.ca.us  Wed Sep 14 09:21:27 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Sep 2016 00:21:27 -0700
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
In-Reply-To: <87lgyvuiov.fsf@hornfels.zedat.fu-berlin.de>
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
	<87y42vykw2.fsf@hornfels.zedat.fu-berlin.de>
	<75AF30E7-B3E0-433F-A46F-7A811F5E431C@dcn.davis.ca.us>
	<87lgyvuiov.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <12608A27-ECC8-418B-9714-A0E90B668AF2@dcn.davis.ca.us>

No, the default Ubuntu version is behind but that link tells how to properly install the current version using the packaging system, which makes it more easily maintained than a custom compile would be.  (Thanks, Dirk, Michael and Vincent!) Anyway, still OT here.
-- 
Sent from my phone. Please excuse my brevity.

On September 13, 2016 10:57:52 PM PDT, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>> For this query I would rather recommend [1] as reference, though
>> Marc's suggestion to switch mailing lists is best.
>>
>> [1] https://cran.r-project.org/bin/linux/ubuntu/
>
>But doesn't this merely describe how to install the version of R
>packaged for his version of Ubuntu?  As I understood the OP, he has
>already installed this version, which is 3.2.3, but would like to
>install 3.3.1, which he will have to install from the sources.
>
>If this is the case, then there is no point reposting to r-sig-debian,
>since he just has to do a generic unix-like install.
>
>Cheers,
>
>Loris
>
>-- 
>Dr. Loris Bennett (Mr.)
>ZEDAT, Freie Universit?t Berlin         Email
>loris.bennett at fu-berlin.de
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Sep 14 09:28:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Sep 2016 00:28:50 -0700
Subject: [R] gene name problem in Excel, and an R analogue
In-Reply-To: <333F0819-169F-4312-9A02-ED3A94006D7D@univie.ac.at>
References: <333F0819-169F-4312-9A02-ED3A94006D7D@univie.ac.at>
Message-ID: <47F0DA9E-3E1A-40B1-BDC5-38D62FB05B4D@dcn.davis.ca.us>

What, like the colClasses argument? Darn that ellipsis and its consequent deferred documentation... but it _is_ mentioned in passing in ?read.fwf.
-- 
Sent from my phone. Please excuse my brevity.

On September 13, 2016 10:54:44 PM PDT, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
>Since many people commenting on the gene name problem in Excel
>essentially tell us
>This could never have happened with R
>I want to show you a somewhat related issue:
>
>
>ff1 <- tempfile()
>cat(file = ff1, "12345", "1E002", sep = "\n")
>xdf1 <- read.fwf(ff1, widths = 5, stringsAsFactors=FALSE)
>
>ff2 <- tempfile()
>cat(file = ff2, "12345", "1E002","1A010", sep = "\n")
>xdf2 <- read.fwf(ff2, widths = 5, stringsAsFactors=FALSE)
>
>in xdf1, the variable is numeric, in xdf2, it is a character variable.
>Of course, in hindsight this makes sense. But the problem is similar to
>the
>Excel problem where something which could be a date is interpreted as a
>date.
>
>A possible solution with my read.fwf problem would be to have a
>parameter
>forcing variables to be read as strings.
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ashenkin at ufl.edu  Wed Sep 14 10:49:55 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Wed, 14 Sep 2016 09:49:55 +0100
Subject: [R] Maximum # of DLLs reached, or,
 how to clean up after yourself?
In-Reply-To: <CAFDcVCT_vb_v0zeYpYOY1KRCK62N78=-36OGbupUFVsCbneg6Q@mail.gmail.com>
References: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>
	<CAFDcVCT_vb_v0zeYpYOY1KRCK62N78=-36OGbupUFVsCbneg6Q@mail.gmail.com>
Message-ID: <06990b84-2e9e-a4c9-6b0c-982bd5a22fb6@ufl.edu>

Hi Henrik,

Thanks for your reply.  I didn't realize that floating DLLs were an 
issue (good to know).  My query is actually a bit more basic.  I'm 
actually wondering how folks manage their loading and unloading of 
packages when calling scripts within scripts.

Quick example:
Script1:
	library(package1)
	source("script2.r")
	# do stuff reliant on package1
	detach("package:package1", unload=TRUE)

Script2:
	library(package1)
	library(package2)
	# do stuff reliant on package1 and package2
	detach("package:package1", unload=TRUE)
	detach("package:package2", unload=TRUE)

Script2 breaks Script1 by unloading package1 (though unloading package2 
is ok).  I will have to test whether each package is loaded in Script2 
before loading it, and use that list when unloading at the end of the 
Script2.  *Unless there's a better way to do it* (which is my question - 
is there?).  I'm possibly just pushing the whole procedural scripting 
thing too far, but I also think that this likely isn't uncommon in R.

Any thoughts greatly appreciated!

Thanks,
Allie

On 9/13/2016 7:23 PM, Henrik Bengtsson wrote:
> In R.utils (>= 2.4.0), which I hope to submitted to CRAN today or
> tomorrow, you can simply call:
>
>    R.utils::gcDLLs()
>
> It will look at base::getLoadedDLLs() and its content and compare to
> loadedNamespaces() and unregister any "stray" DLLs that remain after
> corresponding packages have been unloaded.
>
> Until the new version is on CRAN, you can install it via
>
>     source("http://callr.org/install#HenrikBengtsson/R.utils at develop")
>
> or alternatively just source() the source file:
>
>     source("https://raw.githubusercontent.com/HenrikBengtsson/R.utils/develop/R/gcDLLs.R")
>
>
> DISCUSSION:
> (this might be better suited for R-devel; feel free to move it there)
>
> As far as I understand the problem, running into this error / limit is
> _not_ the fault of the user.  Instead, I'd argue that it is the
> responsibility of package developers to make sure to unregister any
> registered DLLs of theirs when the package is unloaded.  A developer
> can do this by adding the following to their package:
>
> .onUnload <- function(libpath) {
>     library.dynam.unload(utils::packageName(), libpath)
>  }
>
> That should be all - then the DLL will be unloaded as soon as the
> package is unloaded.
>
> I would like to suggest that 'R CMD check' would include a check that
> asserts when a package is unloaded it does not leave any registered
> DLLs behind, e.g.
>
> * checking whether the namespace can be unloaded cleanly ... WARNING
>   Unloading the namespace does not unload DLL
> * checking loading without being on the library search path ... OK
>
> For further details on my thoughts on this, see
> https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29.
>
> Hope this helps
>
> Henrik
>
> On Tue, Sep 13, 2016 at 6:05 AM, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>> Hello all,
>>
>> I have a number of analyses that call bunches of sub-scripts, and in the
>> end, I get the "maximal number of DLLs reached" error.  This has been asked
>> before (e.g.
>> http://stackoverflow.com/questions/36974206/r-maximal-number-of-dlls-reached),
>> and the general answer is, "just clean up after yourself".
>>
>> Assuming there are no plans to raise this 100-DLL limit in the near future,
>> my question becomes, what is best practice for cleaning up (detaching)
>> loaded packages in scripts, when those scripts are sometimes called from
>> other scripts?  One can detach all packages at the end of a script that were
>> loaded at the beginning of the script.  However, if a package is required in
>> a calling script, one should really make sure it hadn't been loaded prior to
>> sub-script invocation before detaching it.
>>
>> I could write a custom function that pushes and pops package names from a
>> global list, in order to keep track, but maybe there's a better way out
>> there...
>>
>> Thanks for any thoughts.
>>
>> Allie
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Aljosa.Aleksandrovic at man.com  Wed Sep 14 10:50:57 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Wed, 14 Sep 2016 08:50:57 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <080a62ee4649488da8da859e39b93d91@PLONINEXMS136.maninvestments.ad.man.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
	<680bb398817a4f7ca6498f6bbf07ff8e@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=ezuVBAA53AubZnGDp=gge6q3ak4dcVihJSifk0nyNDw@mail.gmail.com>
	<080a62ee4649488da8da859e39b93d91@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <958a8e44323b4c7487d3c6aeb272b949@PLONINEXMS136.maninvestments.ad.man.com>

Hi all,

I'm using nnls() to run multi-factor regressions with a non-negativity constraint on all the coefficients. It works well, but unfortunately the nnls() function only returns the parameter estimates, the residual sum-of-squares, the residuals (that is response minus fitted values) and the fitted values.

Furthermore, does somebody know how I can get the below outputs using nnls()?

	- Coefficient Std. Errors
	- t values
	- p values

Thanks a lot for your help!

Kind regards,
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Senior Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aleksandrovic, Aljosa (Pfaeffikon)
Sent: Donnerstag, 28. April 2016 15:06
To: Gabor Grothendieck
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

Thx a lot Gabor!

Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
Sent: Donnerstag, 28. April 2016 14:48
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

The nls2 package can be used to get starting values.

On Thu, Apr 28, 2016 at 8:42 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi Gabor,
>
> Thanks a lot for your help!
>
> I tried to implement your nonlinear least squares solver on my data set. I was just wondering about the argument start. If I would like to force all my coefficients to be inside an interval, let?s say, between 0 and 1, what kind of starting values are normally recommended for the start argument (e.g. Using a 4 factor model with b1, b2, b3 and b4, I tried start = list(b1 = 0.5, b2 = 0.5, b3 = 0.5, b4 = 0.5))? I also tried other starting values ... Hence, the outputs are very sensitive to that start argument?
>
> Thanks a lot for your answer in advance!
>
> Kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 76 03
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Dienstag, 26. April 2016 17:59
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> This is a quadratic programming problem that you can solve using 
> either a quadratic programming solver with constraints or a general 
> nonlinear solver with constraints.  See 
> https://cran.r-project.org/web/views/Optimization.html
> for more info on what is available.
>
> Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:
>
> # test data
> set.seed(123)
> n <- 1000
> X1 <- rnorm(n)
> X2 <- rnorm(n)
> X3 <- rnorm(n)
> Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)
>
> # fit
> library(nlmrt)
> fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
>      data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
>      lower = numeric(3),
>      start = list(b1 = 1, b2 = 2, b3 = 3))
>
> giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:
>
>> fm$coefficients / sum(fm$coefficients)
>      b1      b2      b3
> 0.18463 0.27887 0.53650
>
>
> On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards, Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles aljosa.aleksandrovic at man.com 
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka 
>> Shing Knowledge Institute of St. Michael's Hospital Assistant 
>> Professor, Dalla Lana School of Public Health University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It 
>> contains information which may be confidential and privileged. If you 
>> are not the intended recipient, please notify the sender immediately, 
>> destroy this email and any attachments and do not otherwise disclose 
>> or use them. Email transmission is not a secure method of 
>> communication and Man cannot accept responsibility for the 
>> completeness or accuracy of this email or any attachments. Whilst Man 
>> makes every effort to keep its network free from viruses, it does not 
>> accept responsibility for any computer virus which might be 
>> transferred by way of this email or any attachments. This email does 
>> not constitute a request, offer, recommendation or solicitation of 
>> any kind to buy, subscribe, sell or redeem any investment instruments 
>> or to perform other such transactions of any kind. Man reserves the 
>> right to monitor, record and retain all electronic and telephone 
>> communications through its network in accordance with applicable laws 
>> and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From highstat at highstat.com  Wed Sep 14 10:56:22 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 14 Sep 2016 09:56:22 +0100
Subject: [R] Course: Data exploration, regression,
 GLM & GAM with introduction to R
Message-ID: <d65503c9-2479-f5d4-c361-e5f8b00dc861@highstat.com>


We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with introduction to R

Where:  Lisbon, Portugal

When:   13-17 February 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_02Lisbon_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

9-13 January 2017: Data exploration, regression, GLM & GAM

20-24 February 2017: Introduction to Regression Models with Spatial and 
Temporal Correlatio

9-13 October 2017: Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From mdsumner at gmail.com  Wed Sep 14 12:03:54 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 14 Sep 2016 10:03:54 +0000
Subject: [R] How to read a grib2 file
In-Reply-To: <CAM9mbiDL-Kj5EqTKfx+hnwbJrHE8NZ4J6XKzgmA=b8YFAgHTzw@mail.gmail.com>
References: <CAM9mbiC799tYWOt4P0RWS5DjZgkau5f93Y3neV=SqDBE_ZEtNw@mail.gmail.com>
	<CAAcGz98aBT+P6bF-gVvVO0gSjv3ZcLPsrfbgr-VgDj2yjA=Smw@mail.gmail.com>
	<CAM9mbiAMF3Hneca2jdv5A=jyPphh1NCri9Ooq2bwQ7Pd9A+TTQ@mail.gmail.com>
	<CAAcGz9-jKLJOM_dTg8Xdc=1+nab+KaAtu_NwgHBfNMNSbUzvBA@mail.gmail.com>
	<CAM9mbiDL-Kj5EqTKfx+hnwbJrHE8NZ4J6XKzgmA=b8YFAgHTzw@mail.gmail.com>
Message-ID: <CAAcGz98RTZbQJF4X4tkM5M-iLL=mLi6jeWTUMO7kueW0Axj-9g@mail.gmail.com>

On Wed, 14 Sep 2016 at 00:49 Debasish Pai Mazumder <pai1981 at gmail.com>
wrote:

> Hi Mike,
> Thanks again. I am using Mac OS
>
> Here is the required info
>
> > sessionInfo()
> R version 3.2.4 (2016-03-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.6 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rNOMADS_2.3.0 rvest_0.3.2   xml2_1.0.0    rgdal_1.1-10  raster_2.5-8
> sp_1.2-3
>
> loaded via a namespace (and not attached):
> [1] httr_1.1.0      magrittr_1.5    R6_2.1.2        rsconnect_0.4.3
> tools_3.2.4
> [6] Rcpp_0.12.4     grid_3.2.4      lattice_0.20-33
>
> I am trying to read " tmax.01.2011040100.daily.grb2" from
> http://nomads.ncdc.noaa.gov/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/
>
>

I was a bit surprised, but this does work on Windows - so at the very least
you can run it there with the standard CRAN R and rgdal+raster. Here's the
R code I used, and the resulting session info. (It also works on Debian,
but I'll assume you don't want those details).

f <- "
http://nomads.ncdc.noaa.gov/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
"
download.file(f, basename(f), mode = "wb")
library(raster)
raster(basename(f))
# class       : RasterLayer
# band        : 1  (of  1224  bands)
# dimensions  : 190, 384, 72960  (nrow, ncol, ncell)
# resolution  : 0.9374987, 0.9473684  (x, y)
# extent      : -0.4687493, 359.5307, -90.24932, 89.75068  (xmin, xmax,
ymin, ymax)
# coord. ref. : +proj=longlat +a=6371229 +b=6371229 +no_defs
# data source : tmax.01.2011040100.daily.grb2
# names       : tmax.01.2011040100.daily

This at least gives you an easy pathway if you can get a Windows machine. I
have nearly no experience with Mac, so you'll have to pursue use of rgdal
in that OS if you really need it.

HTH

R version 3.3.1 Patched (2016-09-09 r71227)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
[5] LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] raster_2.5-8 sp_1.2-4

loaded via a namespace (and not attached):
[1] rgdal_1.1-10    Rcpp_0.12.6     grid_3.3.1      lattice_0.20-33






> with regards
> -Deb
>
>
> On Tue, Sep 13, 2016 at 5:26 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
>> What is your computer system? What is the output of this?
>>
>> sessionInfo()
>>
>> If you point to a file I'll try it so I can tell you the minimum system
>> requirements.
>>
>> Cheers, Mike
>>
>> On Tue, 13 Sep 2016, 08:56 Debasish Pai Mazumder <pai1981 at gmail.com>
>> wrote:
>>
>>> Thanks for your suggestion. I have checked and I don't have JPEG2000 in
>>> ggdalDrivers()). I am pretty new in R. I don't understand how to do I
>>> implement JPEG2000 (JP2OpenJPEG driver) in gdalDrivers() so that I can
>>> read grib2 files
>>>
>>> with regards
>>> -Deb
>>>
>>> On Sat, Sep 10, 2016 at 2:33 AM, Michael Sumner <mdsumner at gmail.com>
>>> wrote:
>>>
>>>>
>>>>
>>>> On Sat, 10 Sep 2016 at 07:12 Debasish Pai Mazumder <pai1981 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi
>>>>> I am trying to read a grib2 file in R.
>>>>>
>>>>> Here is my script
>>>>>
>>>>> library(rgdal)
>>>>> library(sp)
>>>>> library(rNOMADS)
>>>>> gribfile<-"tmax.01.2011040100.daily.grb2"
>>>>> grib <- readGDAL(gribfile)
>>>>>
>>>>> I am getting following error :
>>>>>
>>>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>>>> Is the JPEG2000 driver available?tmax.01.2011040100.daily.grb2 has GDAL
>>>>> driver GRIB
>>>>> and has 190 rows and 384 columns
>>>>> dec_jpeg2000: Unable to open JPEG2000 image within GRIB file.
>>>>> Is the JPEG2000 driver available?dec_jpeg2000: Unable to open JPEG2000
>>>>> image within GRIB file.
>>>>>
>>>>>
>>>> Hi there, please check if JPEG2000 is in the gdalDrivers() list, i.e.
>>>>  in
>>>>
>>>> rgdal::gdalDrivers()$name
>>>>
>>>> You are looking for one starting with "JP2" as per the list next to the
>>>> "JPEG2000" rows here:
>>>>
>>>> http://gdal.org/formats_list.html
>>>>
>>>> I have  JP2OpenJPEG on one system, but not (for example) on the
>>>> Windows CRAN binary for rgdal, which is the only readily available Windows
>>>> build for this package.
>>>>
>>>> I you don't have it, you might try on a system that has the JP2OpenJPEG driver,
>>>> or ask someone to try on your behalf. You'd want to find out if that will
>>>> enable this read for you before investing time in the Linux configuration.
>>>>
>>>> It's not too hard to set up a Linux system for this, but does assume a
>>>> bit of experience on your part. Some of the docker images in the
>>>> rockerverse have this all sorted I believe, but it's been a while since I
>>>> used them.
>>>>
>>>> https://hub.docker.com/u/rocker/
>>>>
>>>> Cheers, Mike.
>>>>
>>>>
>>>>
>>>>
>>>>> Cheers
>>>>> -Deb
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> --
>>>> Dr. Michael Sumner
>>>> Software and Database Engineer
>>>> Australian Antarctic Division
>>>> 203 Channel Highway
>>>> Kingston Tasmania 7050 Australia
>>>>
>>>>
>>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Sep 14 12:48:41 2016
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 14 Sep 2016 02:48:41 -0800
Subject: [R] gene name problem in Excel, and an R analogue
In-Reply-To: <333F0819-169F-4312-9A02-ED3A94006D7D@univie.ac.at>
Message-ID: <C49A31D1BB8.0000090Cjrkrideau@inbox.com>

 I see it (after a lot of peering at the code).  It is a nasty problem but I suspect one that would get flagged later in an analysis (well in most cases).

The Excel problem is serious in another way. Many people use Excel or other spreadsheets as data entry tool ---which I think was the cause of the issue in the gene study---and can lose the data completely if there is no paper backup. In your example, one can run str() and diagnose the problem and  recover (i.e. convert)the data.  

If I have 30,000 rows of data in a spreadsheet is there anyway I can tell if some of my character data has converted to numerical dates and convert back? 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: erich.neuwirth at univie.ac.at
> Sent: Wed, 14 Sep 2016 07:54:44 +0200
> To: r-help at r-project.org
> Subject: [R] gene name problem in Excel, and an R analogue
> 
> Since many people commenting on the gene name problem in Excel
> essentially tell us
> This could never have happened with R
> I want to show you a somewhat related issue:
> 
> 
> ff1 <- tempfile()
> cat(file = ff1, "12345", "1E002", sep = "\n")
> xdf1 <- read.fwf(ff1, widths = 5, stringsAsFactors=FALSE)
> 
> ff2 <- tempfile()
> cat(file = ff2, "12345", "1E002","1A010", sep = "\n")
> xdf2 <- read.fwf(ff2, widths = 5, stringsAsFactors=FALSE)
> 
> in xdf1, the variable is numeric, in xdf2, it is a character variable.
> Of course, in hindsight this makes sense. But the problem is similar to
> the
> Excel problem where something which could be a date is interpreted as a
> date.
> 
> A possible solution with my read.fwf problem would be to have a parameter
> forcing variables to be read as strings.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jdnewmil at dcn.davis.ca.us  Wed Sep 14 15:41:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Sep 2016 06:41:06 -0700
Subject: [R] Maximum # of DLLs reached, or,
	how to clean up after yourself?
In-Reply-To: <06990b84-2e9e-a4c9-6b0c-982bd5a22fb6@ufl.edu>
References: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>
	<CAFDcVCT_vb_v0zeYpYOY1KRCK62N78=-36OGbupUFVsCbneg6Q@mail.gmail.com>
	<06990b84-2e9e-a4c9-6b0c-982bd5a22fb6@ufl.edu>
Message-ID: <54D53BAC-0FB0-41AD-A3CD-DF6ED88BE209@dcn.davis.ca.us>

I never detach packages. I rarely load more than 6 or 7 packages directly before restarting R. I frequently re-run my scripts in new R sessions to confirm reproducibility. 
-- 
Sent from my phone. Please excuse my brevity.

On September 14, 2016 1:49:55 AM PDT, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>Hi Henrik,
>
>Thanks for your reply.  I didn't realize that floating DLLs were an 
>issue (good to know).  My query is actually a bit more basic.  I'm 
>actually wondering how folks manage their loading and unloading of 
>packages when calling scripts within scripts.
>
>Quick example:
>Script1:
>	library(package1)
>	source("script2.r")
>	# do stuff reliant on package1
>	detach("package:package1", unload=TRUE)
>
>Script2:
>	library(package1)
>	library(package2)
>	# do stuff reliant on package1 and package2
>	detach("package:package1", unload=TRUE)
>	detach("package:package2", unload=TRUE)
>
>Script2 breaks Script1 by unloading package1 (though unloading package2
>
>is ok).  I will have to test whether each package is loaded in Script2 
>before loading it, and use that list when unloading at the end of the 
>Script2.  *Unless there's a better way to do it* (which is my question
>- 
>is there?).  I'm possibly just pushing the whole procedural scripting 
>thing too far, but I also think that this likely isn't uncommon in R.
>
>Any thoughts greatly appreciated!
>
>Thanks,
>Allie
>
>On 9/13/2016 7:23 PM, Henrik Bengtsson wrote:
>> In R.utils (>= 2.4.0), which I hope to submitted to CRAN today or
>> tomorrow, you can simply call:
>>
>>    R.utils::gcDLLs()
>>
>> It will look at base::getLoadedDLLs() and its content and compare to
>> loadedNamespaces() and unregister any "stray" DLLs that remain after
>> corresponding packages have been unloaded.
>>
>> Until the new version is on CRAN, you can install it via
>>
>>    
>source("http://callr.org/install#HenrikBengtsson/R.utils at develop")
>>
>> or alternatively just source() the source file:
>>
>>    
>source("https://raw.githubusercontent.com/HenrikBengtsson/R.utils/develop/R/gcDLLs.R")
>>
>>
>> DISCUSSION:
>> (this might be better suited for R-devel; feel free to move it there)
>>
>> As far as I understand the problem, running into this error / limit
>is
>> _not_ the fault of the user.  Instead, I'd argue that it is the
>> responsibility of package developers to make sure to unregister any
>> registered DLLs of theirs when the package is unloaded.  A developer
>> can do this by adding the following to their package:
>>
>> .onUnload <- function(libpath) {
>>     library.dynam.unload(utils::packageName(), libpath)
>>  }
>>
>> That should be all - then the DLL will be unloaded as soon as the
>> package is unloaded.
>>
>> I would like to suggest that 'R CMD check' would include a check that
>> asserts when a package is unloaded it does not leave any registered
>> DLLs behind, e.g.
>>
>> * checking whether the namespace can be unloaded cleanly ... WARNING
>>   Unloading the namespace does not unload DLL
>> * checking loading without being on the library search path ... OK
>>
>> For further details on my thoughts on this, see
>> https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29.
>>
>> Hope this helps
>>
>> Henrik
>>
>> On Tue, Sep 13, 2016 at 6:05 AM, Alexander Shenkin <ashenkin at ufl.edu>
>wrote:
>>> Hello all,
>>>
>>> I have a number of analyses that call bunches of sub-scripts, and in
>the
>>> end, I get the "maximal number of DLLs reached" error.  This has
>been asked
>>> before (e.g.
>>>
>http://stackoverflow.com/questions/36974206/r-maximal-number-of-dlls-reached),
>>> and the general answer is, "just clean up after yourself".
>>>
>>> Assuming there are no plans to raise this 100-DLL limit in the near
>future,
>>> my question becomes, what is best practice for cleaning up
>(detaching)
>>> loaded packages in scripts, when those scripts are sometimes called
>from
>>> other scripts?  One can detach all packages at the end of a script
>that were
>>> loaded at the beginning of the script.  However, if a package is
>required in
>>> a calling script, one should really make sure it hadn't been loaded
>prior to
>>> sub-script invocation before detaching it.
>>>
>>> I could write a custom function that pushes and pops package names
>from a
>>> global list, in order to keep track, but maybe there's a better way
>out
>>> there...
>>>
>>> Thanks for any thoughts.
>>>
>>> Allie
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mhahsler at lyle.smu.edu  Wed Sep 14 02:18:10 2016
From: mhahsler at lyle.smu.edu (Michael Hahsler)
Date: Tue, 13 Sep 2016 19:18:10 -0500
Subject: [R] Arules Package: Rules subset with 'empty' left hand side
 (lhs)
In-Reply-To: <CAM9RCO-v_tES8qtKt-EK0eMDsvAunbk5FKos7Sp+ojCkyh+yQA@mail.gmail.com>
References: <CAM9RCO9MJa=Hay_aX58B-SC5kqeyApqJ9KPXqeyCzzD=mEnMGA@mail.gmail.com>
	<7e56d7ed-4e14-5376-dad1-52088a1db109@yahoo.es>
	<CAM9RCO-v_tES8qtKt-EK0eMDsvAunbk5FKos7Sp+ojCkyh+yQA@mail.gmail.com>
Message-ID: <b321f962-b043-1226-611a-55d4c2251ebd@lyle.smu.edu>

Hi all,

There is no item with the label "".

 > itemLabels(rules)
[1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10"

arules::subset(rules, subset=lhs %pin% "") should return an empty set or 
throw an error---I will fix that in the next release of arules.

To get the rules with 0 elements in the lhs do this:

 > r0 <- rules [size(lhs(rules))==0]
 > inspect(r0)

   lhs    rhs support confidence lift
3 {}  => {1} 0.330   0.330      1
2 {}  => {3} 0.326   0.326      1
1 {}  => {2} 0.320   0.320      1

Hope this helps,
Michael

On 09/13/2016 08:30 AM, Tom D. Harray wrote:
> Hello Luisfo,
>
> thank you for the hint: Your suggestion
>
>    arules::subset(rules, subset=lhs %pin% "")
>
> gave 18 rules (out of 21) in my example, and not 3, what I have expected.
>
> Surprisingly the negation of the subset condition
>
>    arules::subset(x = rules, subset = !(lhs %pin% ""))
>
> returns the 3 rules with empty lhs.
>
>
> Hello Martin,
>
> I add you to this thread, because the arules::subset() behaviour
> appears to me to be a bug in arules. And I'd like to suggest to add an
> explanation/example to arules::subset() help.
>
>
> Cheers,
>
> Dirk
>
> On 13 September 2016 at 05:10, Luisfo <luisfo89 at yahoo.es> wrote:
>> Dear Tom,
>>
>> I think this is the line you need
>>   arules::subset(rules, subset=lhs %pin% "")
>> I found the solution here:
>> http://stackoverflow.com/questions/27926131/how-to-get-items-for-both-lhs-and-rhs-for-only-specific-columns-in-arules
>>
>> One more thing. For printing the rules, I needed the inspect() command you
>> didn't provide.
>>
>> I hope this helps.
>>
>> Best,
>>
>> Luisfo Chiroque
>> PhD Student | PhD Candidate
>> IMDEA Networks Institute
>> http://fourier.networks.imdea.org/people/~luis_nunez/
>>
>> On 09/12/2016 04:39 PM, Tom D. Harray wrote:
>>
>> Hello,
>>
>> subsets of association rules (with respect to support, confidence, lift, or
>> items) can be obtained with the arules::subset() function; e.g.
>>
>>   rm(list = ls(all.names = TRUE))
>>   library(arules)
>>   set.seed(42)
>>
>>   x <- lapply(X = 1:500, FUN = function(i)
>>     sample(x = 1:10, size = sample(1:5, 1), replace = FALSE)
>>   )
>>   x <- as(x, 'transactions')
>>
>>   rules <- apriori(
>>     data = x,
>>     parameter = list(target = 'rules', minlen = 1, maxlen = 2,
>>       support = 0.10, confidence = 0.32)
>>   )
>>   rules <- arules::sort(x = rules, decreasing = TRUE, by ='support')
>>
>> gives the rules
>> 3  {}  => {1} 0.330   0.3300000  1.0000000
>> 2  {}  => {3} 0.326   0.3260000  1.0000000
>> 1  {}  => {2} 0.320   0.3200000  1.0000000
>> 20 {3} => {1} 0.120   0.3680982  1.1154490
>> 21 {1} => {3} 0.120   0.3636364  1.1154490
>> 16 {4} => {3} 0.114   0.3677419  1.1280427
>> (...)
>>
>> However, I cannot figure out (help/web) how to get the subset for the rules
>> with empty left hand side (lhs) like subset(rules, lhs == ''). I  could run
>> the
>> apriori() function twice and adjust the min/maxlen parameters as a band
>> aid fix.
>>
>>
>> So my question is: How do I subset() association rules with empty lhs?
>>
>>
>> Thanks and regards,
>>
>> Dirk
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

-- 
   Michael Hahsler, Assistant Professor
   Department of Engineering Management, Information, and Systems
   Department of Computer Science and Engineering (by courtesy)
   Bobby B. Lyle School of Engineering
   Southern Methodist University, Dallas, Texas

   office: Caruth Hall, suite 337, room 311
   email:  mhahsler at lyle.smu.edu
   web:    http://lyle.smu.edu/~mhahsler


From alain.guillet at uclouvain.be  Wed Sep 14 08:53:25 2016
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Wed, 14 Sep 2016 08:53:25 +0200
Subject: [R] Upgrade R 3.2 to 3.3 using tar.gz file on Ubuntu 16.04
In-Reply-To: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
References: <CAMk+s2TakZwo4k8OMsCX3s2mp+u1NbQmw+EPtxh1MR8_CwVXjQ@mail.gmail.com>
Message-ID: <c95b449e-024f-68b7-b169-8dfc37f3151e@uclouvain.be>

Dear Luigi,

You have to modify the /etc/apt/source.list file in order to add a new 
depot to get a new R version. Everything is explained on the page 
https://cran.r-project.org/bin/linux/ubuntu/ .

Alain


On 13/09/16 15:00, Luigi Marongiu wrote:
> Dear all,
> I am working on Linux Ubuntu 16.04 and I have installed R 3.2. I need
> to upgrade to R 3.3 and I tried several options available online with
> no success. I downloaded the tar.gz file for R 3.3 and I would like to
> ask how can I use this file in order to accomplish the upgrade.
> Many thanks,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> .
>

-- 
Alain Guillet
Statistician and Computer Scientist

SMCS - IMMAQ - Universit? catholique de Louvain
http://www.uclouvain.be/smcs

Bureau c.316
Voie du Roman Pays, 20 (bte L1.04.01)
B-1348 Louvain-la-Neuve
Belgium

Tel: +32 10 47 30 50

Acc?s: http://www.uclouvain.be/323631.html


From Margaret.MacDougall at ed.ac.uk  Wed Sep 14 15:05:34 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Wed, 14 Sep 2016 13:05:34 +0000
Subject: [R] Cross-classified multilevel binary logistic regression model
 with random effects at level 2
Message-ID: <VI1PR0502MB302186D6335821EF435E237FC5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Hello

I am not a seasoned R user and am therefore keen to identify a book chapter that can provide structured advice on setting up the type of model I am interested in using R. I would like to run a cross-classified multilevel binary logistic regression model. The model contains two level 2 random effects variables. These variables are crossed to form a cross-classified design. The model has subjects at level one and these subjects are nested within each of the two level two variables. I understand that the R package lme4 may be suitable for running my model and that there are several published books on running mixed models in R. If a list member is able to kindly recommend whether one of these books is particularly helpful in helping less experienced R users fully understand how to use this (or an alternative) program specifically for the model I have outlined above, I would be most grateful for recommendations.

Thank you so much

Best wishes

Margaret

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160914/a492d896/attachment.pl>

From alaios at yahoo.com  Wed Sep 14 15:01:46 2016
From: alaios at yahoo.com (Alaios)
Date: Wed, 14 Sep 2016 13:01:46 +0000 (UTC)
Subject: [R] why data.frame, mutate package and not lists
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
Message-ID: <1997079468.894657.1473858106099@mail.yahoo.com>

Hi all,I have seen data.frames and operations from the mutate package getting really popular. In the last years I have been using extensively lists, is there any reason to not use lists and use other data types for data manipulation and storage?
Any article that describe their differences??I would like to thank you for your replyRegardsAlex
	[[alternative HTML version deleted]]


From manu.reddy52 at gmail.com  Wed Sep 14 17:12:49 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Wed, 14 Sep 2016 20:42:49 +0530
Subject: [R] Drill down reports in R
In-Reply-To: <CAFEqCdz3O5j=1=BQXO=nrdbtAUCcxu7x6B51Sha=HiR1YiGdrg@mail.gmail.com>
References: <CADG9u0B_Tiw-6URXpKs-F8TH_X117uNWPspVmZciPOt7aZqmnw@mail.gmail.com>
	<CAFEqCdz3O5j=1=BQXO=nrdbtAUCcxu7x6B51Sha=HiR1YiGdrg@mail.gmail.com>
Message-ID: <CADG9u0BY04=_PcsDB0PKgEAPGiMSuKoiwxz8yUgO059gghORUA@mail.gmail.com>

Hi ,



  It would be great if someone can share the links how to generate the
drill down reports/tables using combination of  ?R & Javascript/Ajax/some
other packages?.



Note : I tried with *shinytree* package but it?s not met my requirement.



Manu.

On Tue, Sep 13, 2016 at 11:02 PM, Greg Snow <538280 at gmail.com> wrote:

> As has been mentioned, this really requires a GUI tool beyond just R.
> Luckily there are many GUI tools that have been linked to R and if
> Shiny (the shiniest of them) does not have something like this easily
> available so far then you may want to look elsewhere in the meantime.
>
> One option is the tcltk package which interfaces with the Tk GUI tools
> (and the tcl language) which does have the pieces to build in the
> expandable/drill down interface.  One implementation of this is the
> TkListView function in the TeachingDemos package which can be used to
> view list objects in this manner (it starts with the top level list
> objects, then when you click on a + symbol it will open that piece and
> show one level down).
>
> One possibility would be to create all of your results in a list, then
> view it with TkListView  (this will require all computations up front,
> whether anyone looks at them or not).
>
> Another option would be to start with TkListView and rewrite it to do
> things more dynamically and with the output that you want to show.
>
> There is also the shinyTree package on CRAN that allows a tree type
> object in shiny that may do what you want (I don't know what all
> options it allows and what it can display beyond what is in the
> Readme).
>
>
>
> On Tue, Sep 13, 2016 at 4:46 AM, Manohar Reddy <manu.reddy52 at gmail.com>
> wrote:
> > Hi,
> >
> >
> >
> >   How to generate ?Drill down reports ?  (like please refer below url)
> in R
> > using any package ? I did lot of research in google but I didn?t found
> > suitable link .
> >
> >  Can anyone help how to do that in R ?
> >
> >
> >
> > url :  http://bhushan.extreme-advice.com/drilldown-report-in-ssrs/
> >
> >
> >
> > Thanks in Advance !
> >
> > Manu.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>



-- 


Thanks,
Manohar Reddy P
+91-9705302062.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep 14 17:17:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Sep 2016 08:17:09 -0700
Subject: [R] Cross-classified multilevel binary logistic regression
	model with random effects at level 2
In-Reply-To: <VI1PR0502MB302186D6335821EF435E237FC5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB302186D6335821EF435E237FC5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <87E886AD-BE5D-4610-8236-CF5461EB77D2@comcast.net>


> On Sep 14, 2016, at 6:05 AM, MACDOUGALL Margaret <Margaret.MacDougall at ed.ac.uk> wrote:
> 
> Hello
> 
> I am not a seasoned R user and am therefore keen to identify a book chapter that can provide structured advice on setting up the type of model I am interested in using R. I would like to run a cross-classified multilevel binary logistic regression model. The model contains two level 2 random effects variables. These variables are crossed to form a cross-classified design. The model has subjects at level one and these subjects are nested within each of the two level two variables. I understand that the R package lme4 may be suitable for running my model and that there are several published books on running mixed models in R. If a list member is able to kindly recommend whether one of these books is particularly helpful in helping less experienced R users fully understand how to use this (or an alternative) program specifically for the model I have outlined above, I would be most grateful for recommendations.

You would get the widest and most knowledgeable audience for this question at the MixedModels mailing list.

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 


David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Wed Sep 14 17:30:42 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 14 Sep 2016 10:30:42 -0500
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <1997079468.894657.1473858106099@mail.yahoo.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
Message-ID: <0CFCF7D0-49FE-4808-9835-D9DB94592313@me.com>


> On Sep 14, 2016, at 8:01 AM, Alaios via R-help <r-help at r-project.org> wrote:
> 
> Hi all,I have seen data.frames and operations from the mutate package getting really popular. In the last years I have been using extensively lists, is there any reason to not use lists and use other data types for data manipulation and storage?
> Any article that describe their differences? I would like to thank you for your replyRegardsAlex

Hi,

Presuming that you are referring to the mutate() **function**, which is in the dplyr package on CRAN, that package provides a variety of functions to manipulate data in R.

Data frames **are** lists with a data.frame class attribute, but with the proviso that each column in the data frame, which is a list element, has the same length, but like a list, may have different data types (e.g. character, numeric, etc.). 

Thus, a data frame is effectively a rectangular data structure, conceptually in the same manner as an Excel worksheet.

A list, which is a more generic data structure, can contain list elements of variable lengths and data types. 

You might want to begin by reviewing:

  https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists-and-data-frames

which is a section on lists and data frames in the Introduction To R Manual.

It would be surprising, to me at least, that you have been using R for several years and have not come across data frames, since they are used in many typical operations, including regression models and the like.

Regards,

Marc Schwartz
 

From bgunter.4567 at gmail.com  Wed Sep 14 17:34:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 14 Sep 2016 08:34:47 -0700
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <1997079468.894657.1473858106099@mail.yahoo.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
Message-ID: <CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>

This is partially a matter of subjectve opinion, and so pointless; but
I would point out that data frames are the canonical structure for a
great many of R's modeling and graphics functions, e.g. lm, xyplot,
etc.

As for mutate() etc., that's about UI's and user friendliness, and
imho my ho is meaningless.

Best,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 14, 2016 at 6:01 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Hi all,I have seen data.frames and operations from the mutate package getting really popular. In the last years I have been using extensively lists, is there any reason to not use lists and use other data types for data manipulation and storage?
> Any article that describe their differences? I would like to thank you for your replyRegardsAlex
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joeceradini at gmail.com  Wed Sep 14 18:25:07 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 14 Sep 2016 10:25:07 -0600
Subject: [R] gsub: replacing slashes in a string
Message-ID: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>

Hi all,

There are many R help posts out there dealing with slashes in gsub. I
understand slashes are "escape characters" and thus need to be treated
differently, and display differently in R. However, I'm still stuck on
find-replace problem, and would appreciate any tips. Thanks!

GOAL: replace all "\\" with "/", so when export file to csv all slashes are
the same.

(test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))

Lengths are all the same, I think (?) because of how R displays/deals with
slashes. However, when I export this to a csv, e.g., there are still double
slashes, which is a problem for me.
nchar(test)

Change direction of slashes - works.
(test2 <- gsub("\\", "//", test, fixed = TRUE))

Now lengths are now not the same....
nchar(test2)

Change from double to single - does not work. Is this because it actually
is a single slash but R is just displaying it as double? Regardless, when I
export from R the double slashes do appear.
gsub("////", "//", test2, fixed = TRUE)
gsub("////", "//", test2)
gsub("////////", "////", test2, fixed = TRUE)
gsub("////////", "////", test2)

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Sep 14 18:57:25 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 14 Sep 2016 17:57:25 +0100
Subject: [R] gsub: replacing slashes in a string
In-Reply-To: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
Message-ID: <20160914175725.Horde.g-ApfS_pBjnrT7N3qrK5BZW@mail.sapo.pt>

Hello,

I failing to understand the problem, isn't the following what you want?

(test2 <- gsub("\\", "/", test, fixed = TRUE))
[1] "8/24/2016" "8/24/2016" "6/16/2016" "6/16/2016"

Hope this helps,

Rui Barradas


Citando Joe Ceradini <joeceradini at gmail.com>:

> Hi all,
>
> There are many R help posts out there dealing with slashes in gsub. I
> understand slashes are "escape characters" and thus need to be treated
> differently, and display differently in R. However, I'm still stuck on
> find-replace problem, and would appreciate any tips. Thanks!
>
> GOAL: replace all "\\" with "/", so when export file to csv all slashes are
> the same.
>
> (test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))
>
> Lengths are all the same, I think (?) because of how R displays/deals with
> slashes. However, when I export this to a csv, e.g., there are still double
> slashes, which is a problem for me.
> nchar(test)
>
> Change direction of slashes - works.
> (test2 <- gsub("\\", "//", test, fixed = TRUE))
>
> Now lengths are now not the same....
> nchar(test2)
>
> Change from double to single - does not work. Is this because it actually
> is a single slash but R is just displaying it as double? Regardless, when I
> export from R the double slashes do appear.
> gsub("////", "//", test2, fixed = TRUE)
> gsub("////", "//", test2)
> gsub("////////", "////", test2, fixed = TRUE)
> gsub("////////", "////", test2)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Sep 14 18:59:41 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 14 Sep 2016 16:59:41 +0000
Subject: [R] gsub: replacing slashes in a string
In-Reply-To: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
References: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
Message-ID: <b9782d7316a9463e82dd7d7629902276@exch-2p-mbx-w2.ads.tamu.edu>

Is this what you want?

> (test2 <- gsub("\\", "/", test, fixed = TRUE))
[1] "8/24/2016" "8/24/2016" "6/16/2016" "6/16/2016"
> nchar(test2)
[1] 9 9 9 9
> write.csv(test2)
"","x"
"1","8/24/2016"
"2","8/24/2016"
"3","6/16/2016"
"4","6/16/2016"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joe Ceradini
Sent: Wednesday, September 14, 2016 11:25 AM
To: Zilefac
Subject: [R] gsub: replacing slashes in a string

Hi all,

There are many R help posts out there dealing with slashes in gsub. I
understand slashes are "escape characters" and thus need to be treated
differently, and display differently in R. However, I'm still stuck on
find-replace problem, and would appreciate any tips. Thanks!

GOAL: replace all "\\" with "/", so when export file to csv all slashes are
the same.

(test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))

Lengths are all the same, I think (?) because of how R displays/deals with
slashes. However, when I export this to a csv, e.g., there are still double
slashes, which is a problem for me.
nchar(test)

Change direction of slashes - works.
(test2 <- gsub("\\", "//", test, fixed = TRUE))

Now lengths are now not the same....
nchar(test2)

Change from double to single - does not work. Is this because it actually
is a single slash but R is just displaying it as double? Regardless, when I
export from R the double slashes do appear.
gsub("////", "//", test2, fixed = TRUE)
gsub("////", "//", test2)
gsub("////////", "////", test2, fixed = TRUE)
gsub("////////", "////", test2)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From joeceradini at gmail.com  Wed Sep 14 19:03:31 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 14 Sep 2016 11:03:31 -0600
Subject: [R] gsub: replacing slashes in a string
In-Reply-To: <b9782d7316a9463e82dd7d7629902276@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
	<b9782d7316a9463e82dd7d7629902276@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAKq2vL4xhEt+GSrS0FVGpGOx4AjyMC5CzxtoyuRjmDDRFqMJ0A@mail.gmail.com>

Wow. Thanks David and Rui. I thought I needed to "escape" the replacement
slash as well, which is why I had "//" rather than "/". I swear I had tried
all the slash combos, but missed the obvious one. Much easier than I made
it out to be.

Thanks!
Joe

On Wed, Sep 14, 2016 at 10:59 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Is this what you want?
>
> > (test2 <- gsub("\\", "/", test, fixed = TRUE))
> [1] "8/24/2016" "8/24/2016" "6/16/2016" "6/16/2016"
> > nchar(test2)
> [1] 9 9 9 9
> > write.csv(test2)
> "","x"
> "1","8/24/2016"
> "2","8/24/2016"
> "3","6/16/2016"
> "4","6/16/2016"
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joe
> Ceradini
> Sent: Wednesday, September 14, 2016 11:25 AM
> To: Zilefac
> Subject: [R] gsub: replacing slashes in a string
>
> Hi all,
>
> There are many R help posts out there dealing with slashes in gsub. I
> understand slashes are "escape characters" and thus need to be treated
> differently, and display differently in R. However, I'm still stuck on
> find-replace problem, and would appreciate any tips. Thanks!
>
> GOAL: replace all "\\" with "/", so when export file to csv all slashes are
> the same.
>
> (test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))
>
> Lengths are all the same, I think (?) because of how R displays/deals with
> slashes. However, when I export this to a csv, e.g., there are still double
> slashes, which is a problem for me.
> nchar(test)
>
> Change direction of slashes - works.
> (test2 <- gsub("\\", "//", test, fixed = TRUE))
>
> Now lengths are now not the same....
> nchar(test2)
>
> Change from double to single - does not work. Is this because it actually
> is a single slash but R is just displaying it as double? Regardless, when I
> export from R the double slashes do appear.
> gsub("////", "//", test2, fixed = TRUE)
> gsub("////", "//", test2)
> gsub("////////", "////", test2, fixed = TRUE)
> gsub("////////", "////", test2)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Sep 14 19:06:10 2016
From: jholtman at gmail.com (jim holtman)
Date: Wed, 14 Sep 2016 13:06:10 -0400
Subject: [R] gsub: replacing slashes in a string
In-Reply-To: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
References: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
Message-ID: <CAAxdm-7eKUTHLUokOfA7Skwa3GmEcQ5GWeK98Vj606fLe1PPQw@mail.gmail.com>

try this:

> gsub("\\\\", "/", test)
[1] "8/24/2016" "8/24/2016" "6/16/2016" "6/16/2016"




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Sep 14, 2016 at 12:25 PM, Joe Ceradini <joeceradini at gmail.com>
wrote:

> Hi all,
>
> There are many R help posts out there dealing with slashes in gsub. I
> understand slashes are "escape characters" and thus need to be treated
> differently, and display differently in R. However, I'm still stuck on
> find-replace problem, and would appreciate any tips. Thanks!
>
> GOAL: replace all "\\" with "/", so when export file to csv all slashes are
> the same.
>
> (test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))
>
> Lengths are all the same, I think (?) because of how R displays/deals with
> slashes. However, when I export this to a csv, e.g., there are still double
> slashes, which is a problem for me.
> nchar(test)
>
> Change direction of slashes - works.
> (test2 <- gsub("\\", "//", test, fixed = TRUE))
>
> Now lengths are now not the same....
> nchar(test2)
>
> Change from double to single - does not work. Is this because it actually
> is a single slash but R is just displaying it as double? Regardless, when I
> export from R the double slashes do appear.
> gsub("////", "//", test2, fixed = TRUE)
> gsub("////", "//", test2)
> gsub("////////", "////", test2, fixed = TRUE)
> gsub("////////", "////", test2)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From joeceradini at gmail.com  Wed Sep 14 19:15:24 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 14 Sep 2016 11:15:24 -0600
Subject: [R] gsub: replacing slashes in a string
In-Reply-To: <CAAxdm-7eKUTHLUokOfA7Skwa3GmEcQ5GWeK98Vj606fLe1PPQw@mail.gmail.com>
References: <CAKq2vL5jZDGm-ejpxYt+EyEiyMP+j6aDGksih-grFpue3-4nOA@mail.gmail.com>
	<CAAxdm-7eKUTHLUokOfA7Skwa3GmEcQ5GWeK98Vj606fLe1PPQw@mail.gmail.com>
Message-ID: <CAKq2vL7djiLVtY3qEusymEAa0+M9Py1SjGrSz3e5TQdbifkPQA@mail.gmail.com>

Thanks Jim!

Joe

On Wed, Sep 14, 2016 at 11:06 AM, jim holtman <jholtman at gmail.com> wrote:

> try this:
>
> > gsub("\\\\", "/", test)
> [1] "8/24/2016" "8/24/2016" "6/16/2016" "6/16/2016"
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Sep 14, 2016 at 12:25 PM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
>
>> Hi all,
>>
>> There are many R help posts out there dealing with slashes in gsub. I
>> understand slashes are "escape characters" and thus need to be treated
>> differently, and display differently in R. However, I'm still stuck on
>> find-replace problem, and would appreciate any tips. Thanks!
>>
>> GOAL: replace all "\\" with "/", so when export file to csv all slashes
>> are
>> the same.
>>
>> (test <- c("8/24/2016", "8/24/2016", "6/16/2016", "6\\16\\2016"))
>>
>> Lengths are all the same, I think (?) because of how R displays/deals with
>> slashes. However, when I export this to a csv, e.g., there are still
>> double
>> slashes, which is a problem for me.
>> nchar(test)
>>
>> Change direction of slashes - works.
>> (test2 <- gsub("\\", "//", test, fixed = TRUE))
>>
>> Now lengths are now not the same....
>> nchar(test2)
>>
>> Change from double to single - does not work. Is this because it actually
>> is a single slash but R is just displaying it as double? Regardless, when
>> I
>> export from R the double slashes do appear.
>> gsub("////", "//", test2, fixed = TRUE)
>> gsub("////", "//", test2)
>> gsub("////////", "////", test2, fixed = TRUE)
>> gsub("////////", "////", test2)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Wed Sep 14 20:15:36 2016
From: alaios at yahoo.com (Alaios)
Date: Wed, 14 Sep 2016 18:15:36 +0000 (UTC)
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
Message-ID: <1682947458.1177650.1473876936388@mail.yahoo.com>

thanks for all the answers. I think also ggplot2 requires data.frames.If you want to add variable to data.frame you have to use attach, detach. Right?Any more links that discuss thoe two different approaches?Alex 

    On Wednesday, September 14, 2016 5:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 This is partially a matter of subjectve opinion, and so pointless; but
I would point out that data frames are the canonical structure for a
great many of R's modeling and graphics functions, e.g. lm, xyplot,
etc.

As for mutate() etc., that's about UI's and user friendliness, and
imho my ho is meaningless.

Best,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 14, 2016 at 6:01 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Hi all,I have seen data.frames and operations from the mutate package getting really popular. In the last years I have been using extensively lists, is there any reason to not use lists and use other data types for data manipulation and storage?
> Any article that describe their differences? I would like to thank you for your replyRegardsAlex
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From roundsjeremiah at gmail.com  Wed Sep 14 20:40:08 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Wed, 14 Sep 2016 11:40:08 -0700
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <1682947458.1177650.1473876936388@mail.yahoo.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
	<1682947458.1177650.1473876936388@mail.yahoo.com>
Message-ID: <CAOjnRsY0zPTZDevpuE7Ya1EBa=qyh-X9fCgT+EyWbN5VWw1h7g@mail.gmail.com>

"If you want to add variable to data.frame you have to use attach, detach.
Right?"

Not quite.  Use it like a list to add a variable to a data.frame

e.g.
df = list()
df$var1 = 1:10
df = as.data.frame(df)
df$var2 = 1:10
df[["var3"]] = 1:10
df
df = as.list(df)
df$var4 = 1:10
as.data.frame(df)

Ironically the primary reason to use a data.frame in my head is to signal
that you are thinking of your data as a row-oriented tabular storage.
 "Ironic" because in technical detail that is not a requirement to be a
data.frame, but when I reflect on the typical way a seasoned R programmer
approaches list and data.frames that is basically what they are
communicating.

I was going to post that a reason to use data.frames is to take advantages
of optimizations and syntax sugar for data.frames, but in reality if code
does not assume a row-oriented data structure in a data.frame there is not
much I can think of that exists in the way of optimization.  For example,
we could point to "subset" and say that is a reason to use data.frames and
not list, but that only works if you use data.frame in a conventional way.

In the end, my advice to you is if it is a table make it a data.frame and
if it is not easily thought of as a table or row-oriented data structure
keep it as a list.

Thanks,
Jeremiah





On Wed, Sep 14, 2016 at 11:15 AM, Alaios via R-help <r-help at r-project.org>
wrote:

> thanks for all the answers. I think also ggplot2 requires data.frames.If
> you want to add variable to data.frame you have to use attach, detach.
> Right?Any more links that discuss thoe two different approaches?Alex
>
>     On Wednesday, September 14, 2016 5:34 PM, Bert Gunter <
> bgunter.4567 at gmail.com> wrote:
>
>
>  This is partially a matter of subjectve opinion, and so pointless; but
> I would point out that data frames are the canonical structure for a
> great many of R's modeling and graphics functions, e.g. lm, xyplot,
> etc.
>
> As for mutate() etc., that's about UI's and user friendliness, and
> imho my ho is meaningless.
>
> Best,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Sep 14, 2016 at 6:01 AM, Alaios via R-help <r-help at r-project.org>
> wrote:
> > Hi all,I have seen data.frames and operations from the mutate package
> getting really popular. In the last years I have been using extensively
> lists, is there any reason to not use lists and use other data types for
> data manipulation and storage?
> > Any article that describe their differences? I would like to thank you
> for your replyRegardsAlex
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roundsjeremiah at gmail.com  Wed Sep 14 20:41:29 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Wed, 14 Sep 2016 11:41:29 -0700
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <CAOjnRsY0zPTZDevpuE7Ya1EBa=qyh-X9fCgT+EyWbN5VWw1h7g@mail.gmail.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
	<1682947458.1177650.1473876936388@mail.yahoo.com>
	<CAOjnRsY0zPTZDevpuE7Ya1EBa=qyh-X9fCgT+EyWbN5VWw1h7g@mail.gmail.com>
Message-ID: <CAOjnRsZpL4ZG-1rLrM8CsFwUOu6O18H3Kn84-C4UzSgXt=oMdQ@mail.gmail.com>

There is also this syntax for adding variables
df[, "var5"] = 1:10

and the syntax sugar for row-oriented storage:
df[1:5,]

On Wed, Sep 14, 2016 at 11:40 AM, jeremiah rounds <roundsjeremiah at gmail.com>
wrote:

> "If you want to add variable to data.frame you have to use attach, detach.
> Right?"
>
> Not quite.  Use it like a list to add a variable to a data.frame
>
> e.g.
> df = list()
> df$var1 = 1:10
> df = as.data.frame(df)
> df$var2 = 1:10
> df[["var3"]] = 1:10
> df
> df = as.list(df)
> df$var4 = 1:10
> as.data.frame(df)
>
> Ironically the primary reason to use a data.frame in my head is to signal
> that you are thinking of your data as a row-oriented tabular storage.
>  "Ironic" because in technical detail that is not a requirement to be a
> data.frame, but when I reflect on the typical way a seasoned R programmer
> approaches list and data.frames that is basically what they are
> communicating.
>
> I was going to post that a reason to use data.frames is to take advantages
> of optimizations and syntax sugar for data.frames, but in reality if code
> does not assume a row-oriented data structure in a data.frame there is not
> much I can think of that exists in the way of optimization.  For example,
> we could point to "subset" and say that is a reason to use data.frames and
> not list, but that only works if you use data.frame in a conventional way.
>
> In the end, my advice to you is if it is a table make it a data.frame and
> if it is not easily thought of as a table or row-oriented data structure
> keep it as a list.
>
> Thanks,
> Jeremiah
>
>
>
>
>
> On Wed, Sep 14, 2016 at 11:15 AM, Alaios via R-help <r-help at r-project.org>
> wrote:
>
>> thanks for all the answers. I think also ggplot2 requires data.frames.If
>> you want to add variable to data.frame you have to use attach, detach.
>> Right?Any more links that discuss thoe two different approaches?Alex
>>
>>     On Wednesday, September 14, 2016 5:34 PM, Bert Gunter <
>> bgunter.4567 at gmail.com> wrote:
>>
>>
>>  This is partially a matter of subjectve opinion, and so pointless; but
>> I would point out that data frames are the canonical structure for a
>> great many of R's modeling and graphics functions, e.g. lm, xyplot,
>> etc.
>>
>> As for mutate() etc., that's about UI's and user friendliness, and
>> imho my ho is meaningless.
>>
>> Best,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Sep 14, 2016 at 6:01 AM, Alaios via R-help <r-help at r-project.org>
>> wrote:
>> > Hi all,I have seen data.frames and operations from the mutate package
>> getting really popular. In the last years I have been using extensively
>> lists, is there any reason to not use lists and use other data types for
>> data manipulation and storage?
>> > Any article that describe their differences? I would like to thank you
>> for your replyRegardsAlex
>> >        [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Sep 14 20:42:15 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 14 Sep 2016 11:42:15 -0700
Subject: [R] Maximum # of DLLs reached, or,
	how to clean up after yourself?
In-Reply-To: <54D53BAC-0FB0-41AD-A3CD-DF6ED88BE209@dcn.davis.ca.us>
References: <f0d0b6e5-ce53-74ea-d4c2-54345224425f@ufl.edu>
	<CAFDcVCT_vb_v0zeYpYOY1KRCK62N78=-36OGbupUFVsCbneg6Q@mail.gmail.com>
	<06990b84-2e9e-a4c9-6b0c-982bd5a22fb6@ufl.edu>
	<54D53BAC-0FB0-41AD-A3CD-DF6ED88BE209@dcn.davis.ca.us>
Message-ID: <CAFDcVCQVMdYDAQYUdfuWrvcWmgJhbKpXaxWACkZLNSF810=wpw@mail.gmail.com>

As Jeff says, I think the common use case is to run/rerun in fresh R sessions.

But, yes, if you'd like to have each script clean up after itself,
then you need to check with pkgs0 <- loadedNamespaces() to see what
packages are loaded when the script starts (not just attached) and
then unload the ones added at the end by pkgsDiff <-
setdiff(loadedNamespaces(), pkgs0).   However, it's not as simple as
calling unloadNamespace(pkgsDiff), because they need to be unloaded in
an order that is compatible with the package dependencies.   One way
is to too use while(length(pkgDiffs) > 0) loop over with a
try(unloadNamespace(pkg)) until all are unloaded.   At the end, run
R.utils::gcDLLs() too (now on CRAN).

unloadNamespace("foo") should result in the same as
detach("package::foo", unload=TRUE) [anyone correct me if I'm wrong].

Hope this helps

Henrik

On Wed, Sep 14, 2016 at 6:41 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I never detach packages. I rarely load more than 6 or 7 packages directly before restarting R. I frequently re-run my scripts in new R sessions to confirm reproducibility.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 14, 2016 1:49:55 AM PDT, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>>Hi Henrik,
>>
>>Thanks for your reply.  I didn't realize that floating DLLs were an
>>issue (good to know).  My query is actually a bit more basic.  I'm
>>actually wondering how folks manage their loading and unloading of
>>packages when calling scripts within scripts.
>>
>>Quick example:
>>Script1:
>>       library(package1)
>>       source("script2.r")
>>       # do stuff reliant on package1
>>       detach("package:package1", unload=TRUE)
>>
>>Script2:
>>       library(package1)
>>       library(package2)
>>       # do stuff reliant on package1 and package2
>>       detach("package:package1", unload=TRUE)
>>       detach("package:package2", unload=TRUE)
>>
>>Script2 breaks Script1 by unloading package1 (though unloading package2
>>
>>is ok).  I will have to test whether each package is loaded in Script2
>>before loading it, and use that list when unloading at the end of the
>>Script2.  *Unless there's a better way to do it* (which is my question
>>-
>>is there?).  I'm possibly just pushing the whole procedural scripting
>>thing too far, but I also think that this likely isn't uncommon in R.
>>
>>Any thoughts greatly appreciated!
>>
>>Thanks,
>>Allie
>>
>>On 9/13/2016 7:23 PM, Henrik Bengtsson wrote:
>>> In R.utils (>= 2.4.0), which I hope to submitted to CRAN today or
>>> tomorrow, you can simply call:
>>>
>>>    R.utils::gcDLLs()
>>>
>>> It will look at base::getLoadedDLLs() and its content and compare to
>>> loadedNamespaces() and unregister any "stray" DLLs that remain after
>>> corresponding packages have been unloaded.
>>>
>>> Until the new version is on CRAN, you can install it via
>>>
>>>
>>source("http://callr.org/install#HenrikBengtsson/R.utils at develop")
>>>
>>> or alternatively just source() the source file:
>>>
>>>
>>source("https://raw.githubusercontent.com/HenrikBengtsson/R.utils/develop/R/gcDLLs.R")
>>>
>>>
>>> DISCUSSION:
>>> (this might be better suited for R-devel; feel free to move it there)
>>>
>>> As far as I understand the problem, running into this error / limit
>>is
>>> _not_ the fault of the user.  Instead, I'd argue that it is the
>>> responsibility of package developers to make sure to unregister any
>>> registered DLLs of theirs when the package is unloaded.  A developer
>>> can do this by adding the following to their package:
>>>
>>> .onUnload <- function(libpath) {
>>>     library.dynam.unload(utils::packageName(), libpath)
>>>  }
>>>
>>> That should be all - then the DLL will be unloaded as soon as the
>>> package is unloaded.
>>>
>>> I would like to suggest that 'R CMD check' would include a check that
>>> asserts when a package is unloaded it does not leave any registered
>>> DLLs behind, e.g.
>>>
>>> * checking whether the namespace can be unloaded cleanly ... WARNING
>>>   Unloading the namespace does not unload DLL
>>> * checking loading without being on the library search path ... OK
>>>
>>> For further details on my thoughts on this, see
>>> https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29.
>>>
>>> Hope this helps
>>>
>>> Henrik
>>>
>>> On Tue, Sep 13, 2016 at 6:05 AM, Alexander Shenkin <ashenkin at ufl.edu>
>>wrote:
>>>> Hello all,
>>>>
>>>> I have a number of analyses that call bunches of sub-scripts, and in
>>the
>>>> end, I get the "maximal number of DLLs reached" error.  This has
>>been asked
>>>> before (e.g.
>>>>
>>http://stackoverflow.com/questions/36974206/r-maximal-number-of-dlls-reached),
>>>> and the general answer is, "just clean up after yourself".
>>>>
>>>> Assuming there are no plans to raise this 100-DLL limit in the near
>>future,
>>>> my question becomes, what is best practice for cleaning up
>>(detaching)
>>>> loaded packages in scripts, when those scripts are sometimes called
>>from
>>>> other scripts?  One can detach all packages at the end of a script
>>that were
>>>> loaded at the beginning of the script.  However, if a package is
>>required in
>>>> a calling script, one should really make sure it hadn't been loaded
>>prior to
>>>> sub-script invocation before detaching it.
>>>>
>>>> I could write a custom function that pushes and pops package names
>>from a
>>>> global list, in order to keep track, but maybe there's a better way
>>out
>>>> there...
>>>>
>>>> Thanks for any thoughts.
>>>>
>>>> Allie
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Wed Sep 14 20:54:25 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Sep 2016 14:54:25 -0400
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <CAOjnRsY0zPTZDevpuE7Ya1EBa=qyh-X9fCgT+EyWbN5VWw1h7g@mail.gmail.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
	<1682947458.1177650.1473876936388@mail.yahoo.com>
	<CAOjnRsY0zPTZDevpuE7Ya1EBa=qyh-X9fCgT+EyWbN5VWw1h7g@mail.gmail.com>
Message-ID: <3f1cfb9f-feaf-4f35-e978-762701b3b0be@gmail.com>

On 14/09/2016 2:40 PM, jeremiah rounds wrote:
> "If you want to add variable to data.frame you have to use attach, detach.
> Right?"
>
> Not quite.  Use it like a list to add a variable to a data.frame
>
> e.g.
> df = list()
> df$var1 = 1:10
> df = as.data.frame(df)
> df$var2 = 1:10
> df[["var3"]] = 1:10
> df
> df = as.list(df)
> df$var4 = 1:10
> as.data.frame(df)
>
> Ironically the primary reason to use a data.frame in my head is to signal
> that you are thinking of your data as a row-oriented tabular storage.
>   "Ironic" because in technical detail that is not a requirement to be a
> data.frame, but when I reflect on the typical way a seasoned R programmer
> approaches list and data.frames that is basically what they are
> communicating.

I believe it is intended to be a requirement.  You can construct things 
with class "data.frame" that don't have that structure, but lots of 
stuff will go wrong if you do.

Duncan Murdoch
>
> I was going to post that a reason to use data.frames is to take advantages
> of optimizations and syntax sugar for data.frames, but in reality if code
> does not assume a row-oriented data structure in a data.frame there is not
> much I can think of that exists in the way of optimization.  For example,
> we could point to "subset" and say that is a reason to use data.frames and
> not list, but that only works if you use data.frame in a conventional way.
>
> In the end, my advice to you is if it is a table make it a data.frame and
> if it is not easily thought of as a table or row-oriented data structure
> keep it as a list.
>
> Thanks,
> Jeremiah
>
>
>
>
>
> On Wed, Sep 14, 2016 at 11:15 AM, Alaios via R-help <r-help at r-project.org>
> wrote:
>
> > thanks for all the answers. I think also ggplot2 requires data.frames.If
> > you want to add variable to data.frame you have to use attach, detach.
> > Right?Any more links that discuss thoe two different approaches?Alex
> >
> >     On Wednesday, September 14, 2016 5:34 PM, Bert Gunter <
> > bgunter.4567 at gmail.com> wrote:
> >
> >
> >  This is partially a matter of subjectve opinion, and so pointless; but
> > I would point out that data frames are the canonical structure for a
> > great many of R's modeling and graphics functions, e.g. lm, xyplot,
> > etc.
> >
> > As for mutate() etc., that's about UI's and user friendliness, and
> > imho my ho is meaningless.
> >
> > Best,
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Wed, Sep 14, 2016 at 6:01 AM, Alaios via R-help <r-help at r-project.org>
> > wrote:
> > > Hi all,I have seen data.frames and operations from the mutate package
> > getting really popular. In the last years I have been using extensively
> > lists, is there any reason to not use lists and use other data types for
> > data manipulation and storage?
> > > Any article that describe their differences? I would like to thank you
> > for your replyRegardsAlex
> > >        [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.br.lomas at gmail.com  Wed Sep 14 21:33:34 2016
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Wed, 14 Sep 2016 13:33:34 -0600
Subject: [R] Creating dataframe with subtotals by all fields and totals of
	subtotals
Message-ID: <CAOHXzyVezhm1ZmZzaRC1TaDPz0wge--XiL4W+KJ_XCwae0e0rw@mail.gmail.com>

Hello R-Helpers,

I'm trying to to create a subtotal category for each column in a
dataset, and totals of subtotals, resulting in one data frame.  I
figure I could do this by a whack of aggregate() and rbind(), but I'm
hoping there is a simpler way.

Below is a sample dataset. Underneath I create an "All" salesmen
subtotal and rbind it with the original dataset.  I could do that for
"Drink" and "Region", then also do combinations of salesmen, drink,
and region subtotals.  However, I'm hoping somebody out there is more
clever than I am.

Thanks!
Peter


dat <- structure(list(Date = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L,
                                         2L, 3L, 1L, 2L, 3L, 1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
                                         3L, 1L, 2L, 3L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 3L), .Label = c("2012-01",

                                  "2012-02", "2012-03"), class =
"factor"), Region = structure(c(1L,


                          1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 1L, 1L,
2L, 2L, 2L, 3L, 3L,


                          3L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 1L,
1L, 1L, 2L, 2L, 2L,


                          3L, 3L, 3L), .Label = c("Zone1", "Zone2",
"Zone3"), class = "factor"),
                      Drink = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 1L,
                                          1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
                                          2L, 2L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L), .Label = c("Cola",

                           "Orange Juice"), class = "factor"),
Salesman = structure(c(1L,


               1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L,


               1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L,


               2L, 2L, 2L, 2L, 2L), .Label = c("Joe", "Marty"), class
= "factor"),
                      Sales = c(10L, 36L, 9L, 39L, 12L, 61L, 62L, 28L, 82L, 1L,
                                38L, 14L, 55L, 50L, 62L, 64L, 69L,
65L, 28L, 85L, 66L, 66L,
                                75L, 59L, 31L, 14L, 93L, 35L, 24L,
11L, 4L, 30L, 2L, 17L,
                                36L, 47L)), .Names = c("Date",
"Region", "Drink", "Salesman",
                                                       "Sales"), class
= "data.frame", row.names = c(NA, -36L))



all.salesman <- aggregate(Sales~Date+Region+Drink, data=dat, FUN=sum)
all.salesman$Salesman <- "All"
dat <- rbind(dat, all.salesman)


From Margaret.MacDougall at ed.ac.uk  Wed Sep 14 18:17:41 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Wed, 14 Sep 2016 16:17:41 +0000
Subject: [R] Cross-classified multilevel binary logistic regression
 model with random effects at level 2
In-Reply-To: <87E886AD-BE5D-4610-8236-CF5461EB77D2@comcast.net>
References: <VI1PR0502MB302186D6335821EF435E237FC5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<87E886AD-BE5D-4610-8236-CF5461EB77D2@comcast.net>
Message-ID: <VI1PR0502MB3021561816B248ACBBD591AFC5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Thank you for this valued advice, David, in response to which I have sent a very similar message to the list you recommend.  I would also welcome suggestions from members of the r-help at r-project list, where appropriate.

Best wishes

Margaret






-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 14 September 2016 16:17
To: MACDOUGALL Margaret <Margaret.MacDougall at ed.ac.uk>
Cc: r-help at r-project.org
Subject: Re: [R] Cross-classified multilevel binary logistic regression model with random effects at level 2


> On Sep 14, 2016, at 6:05 AM, MACDOUGALL Margaret <Margaret.MacDougall at ed.ac.uk> wrote:
> 
> Hello
> 
> I am not a seasoned R user and am therefore keen to identify a book chapter that can provide structured advice on setting up the type of model I am interested in using R. I would like to run a cross-classified multilevel binary logistic regression model. The model contains two level 2 random effects variables. These variables are crossed to form a cross-classified design. The model has subjects at level one and these subjects are nested within each of the two level two variables. I understand that the R package lme4 may be suitable for running my model and that there are several published books on running mixed models in R. If a list member is able to kindly recommend whether one of these books is particularly helpful in helping less experienced R users fully understand how to use this (or an alternative) program specifically for the model I have outlined above, I would be most grateful for recommendations.

You would get the widest and most knowledgeable audience for this question at the MixedModels mailing list.

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 


David Winsemius
Alameda, CA, USA


From aanchalsharma833 at gmail.com  Wed Sep 14 22:46:20 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Wed, 14 Sep 2016 16:46:20 -0400
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture model)
Message-ID: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>

Hi,

I am trying to fit Gamma mixture model to my data (residual values obtained
after fitting Generalized linear Model) using gammamixEM. It is part of the
script which does it for multiple datasets in loop. The code is running
fine for some datasets but it terminates for some giving following error:

" iteration = 1  log-lik diff = NaN  log-lik = NaN
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed"

Seems like EM is not able to calculate log-lik value (NaN) at the first
iteration itself. any idea why that can happen?
It works fine for the other genes in the loop. Tried looking for difference
in the inputs, but could not come up with anything striking.

Regards
Anchal



-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep 15 02:04:05 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Sep 2016 20:04:05 -0400
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture
 model)
In-Reply-To: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
References: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
Message-ID: <956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>

On 14/09/2016 4:46 PM, Aanchal Sharma wrote:
> Hi,
>
> I am trying to fit Gamma mixture model to my data (residual values obtained
> after fitting Generalized linear Model) using gammamixEM. It is part of the
> script which does it for multiple datasets in loop. The code is running
> fine for some datasets but it terminates for some giving following error:
>
> " iteration = 1  log-lik diff = NaN  log-lik = NaN
> Error in while (diff > epsilon && iter < maxit) { :
>   missing value where TRUE/FALSE needed"
>
> Seems like EM is not able to calculate log-lik value (NaN) at the first
> iteration itself. any idea why that can happen?
> It works fine for the other genes in the loop. Tried looking for difference
> in the inputs, but could not come up with anything striking.
>

THere are lots of ways to get NaN in numerical calculations.   A common 
one if you are using log() to calculate log likelihoods is that rounding 
error gives you a negative likelihood, and then log(lik) comes out to NaN.

You just need to look really closely at each step of your calculations. 
Avoid using log(); use the functions that build it in (e.g. instead of 
log(dnorm(x)), use dnorm(x, log = TRUE)).

Duncan Murdoch


From dwinsemius at comcast.net  Thu Sep 15 02:09:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Sep 2016 17:09:30 -0700
Subject: [R] Creating dataframe with subtotals by all fields and totals
	of subtotals
In-Reply-To: <CAOHXzyVezhm1ZmZzaRC1TaDPz0wge--XiL4W+KJ_XCwae0e0rw@mail.gmail.com>
References: <CAOHXzyVezhm1ZmZzaRC1TaDPz0wge--XiL4W+KJ_XCwae0e0rw@mail.gmail.com>
Message-ID: <12A0A371-9C1C-4691-B90D-169C2A3938BE@comcast.net>


> On Sep 14, 2016, at 12:33 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
> 
> Hello R-Helpers,
> 
> I'm trying to to create a subtotal category for each column in a
> dataset, and totals of subtotals, resulting in one data frame.  I
> figure I could do this by a whack of aggregate() and rbind(), but I'm
> hoping there is a simpler way.
> 
> Below is a sample dataset. Underneath I create an "All" salesmen
> subtotal and rbind it with the original dataset.  I could do that for
> "Drink" and "Region", then also do combinations of salesmen, drink,
> and region subtotals.  However, I'm hoping somebody out there is more
> clever than I am.

I'm pretty sure that Hadley (who is rather smart) already built that into the plyr package where he lets people specify marginal subtotals. I'd be slightly surprised if that feature wasn't carried over to dplyr, although I have not see it illustrated yet. But my memory may be failing in htis area. I'm not able to put any substance to that notion after searching.

I've answered a couple of questions over the years on StackOverflow that deal with marginal calculations and you might find the addmargin function less of a "whack" that the route you were imagining:

http://stackoverflow.com/questions/5863456/r-calculating-margins-or-row-col-sums-for-a-data-frame
http://stackoverflow.com/questions/5982546/r-calculating-column-sums-row-sums-as-an-aggregation-from-a-dataframe/5982943#5982943


> 
> Thanks!
> Peter
> 
> 
> dat <- structure(list(Date = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L,
>                                         2L, 3L, 1L, 2L, 3L, 1L, 2L,
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>                                         3L, 1L, 2L, 3L, 1L, 2L, 3L,
> 1L, 2L, 3L, 1L, 2L, 3L), .Label = c("2012-01",
> 
>                                  "2012-02", "2012-03"), class =
> "factor"), Region = structure(c(1L,
> 
> 
>                          1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 1L, 1L,
> 2L, 2L, 2L, 3L, 3L,
> 
> 
>                          3L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 1L,
> 1L, 1L, 2L, 2L, 2L,
> 
> 
>                          3L, 3L, 3L), .Label = c("Zone1", "Zone2",
> "Zone3"), class = "factor"),
>                      Drink = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 1L,
>                                          1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>                                          2L, 2L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L), .Label = c("Cola",
> 
>                           "Orange Juice"), class = "factor"),
> Salesman = structure(c(1L,
> 
> 
>               1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L,
> 
> 
>               1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L,
> 
> 
>               2L, 2L, 2L, 2L, 2L), .Label = c("Joe", "Marty"), class
> = "factor"),
>                      Sales = c(10L, 36L, 9L, 39L, 12L, 61L, 62L, 28L, 82L, 1L,
>                                38L, 14L, 55L, 50L, 62L, 64L, 69L,
> 65L, 28L, 85L, 66L, 66L,
>                                75L, 59L, 31L, 14L, 93L, 35L, 24L,
> 11L, 4L, 30L, 2L, 17L,
>                                36L, 47L)), .Names = c("Date",
> "Region", "Drink", "Salesman",
>                                                       "Sales"), class
> = "data.frame", row.names = c(NA, -36L))
> 
> 
> 
> all.salesman <- aggregate(Sales~Date+Region+Drink, data=dat, FUN=sum)
> all.salesman$Salesman <- "All"
> dat <- rbind(dat, all.salesman)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kris.angelovski at solutionmetrics.com.au  Thu Sep 15 03:25:58 2016
From: kris.angelovski at solutionmetrics.com.au (Kris Angelovski)
Date: Thu, 15 Sep 2016 01:25:58 +0000
Subject: [R] Data Visualisation,
 Predictive Modelling Courses: Syd/Melb/Canb/Adel in September
Message-ID: <KL1PR0601MB14306B54231A7A1B1C2B38B7C5F00@KL1PR0601MB1430.apcprd06.prod.outlook.com>

Hi,

SolutionMetrics is presenting Data Visualisation and Data Science/Predictive Modelling courses in Sydney, Melbourne, Canberra and Adelaide.

Data Visualisation (1 Day)

Introduction to Data Analysis and Graphics - Histograms, Box Plots, Bar Charts, Scatter Plots; Changing symbols, colours, style of points, axes, range; 3D plots; Time-Series plots; Lattice; ggplot2; Map plots; Shiny; Producing publication quality reports. More Info<http://bit.ly/2bSAUDc>

Data Science/Predictive Modelling (1 Day)

Introduction to Data Science/Predictive Modelling, Regression modelling, Linear, Non-linear, Multiple, Stepwise and Regression Trees, Classification: Logistic Regression and Tree based methods; Clustering. More Info<http://bit.ly/2c1nQGe>

Location


     Date


Course


Sydney

19 Sep 2016

Data Visualisation

20 Sep 2016

Data Science/Predictive modelling


Melbourne

22 Sep 2016

Data Visualisation

23 Sep 2016

Data Science/Predictive modelling


Canberra

26 Sep 2016

Data Visualisation

27 Sep 2016

Data Science/Predictive modelling


Adelaide

29 Sep 2016

Data Visualisation

30 Sep 2016

Data Science/Predictive modelling


To book, please email enquiries at solutionmetrics.com.au<mailto:enquiries at solutionmetrics.com.au> or call +61 2 9233 6888
Full Schedule<http://bit.ly/13lJ4ag>
Regards,
Kris Angelovski | Chief Data Scientist | SolutionMetrics
T +61 2 9233 6888 | M +61 488 388 338
E kris.angelovski at solutionmetrics.com.au<mailto:kris.angelovski at solutionmetrics.com.au>
solutionmetrics.com.au<http://www.solutionmetrics.com.au/> | Suite 44, Level 9, 88 Pitt Street Sydney NSW 2000




	[[alternative HTML version deleted]]


From madsenpw at gmail.com  Wed Sep 14 22:41:39 2016
From: madsenpw at gmail.com (P Mads)
Date: Wed, 14 Sep 2016 14:41:39 -0600
Subject: [R] Need help with renaming sub-directories and its files after
 attribute vales from a shapefile
Message-ID: <CAOXxoAhhNZ=mtFx0SsjeWua+oZg_DkKBh9T9Q_62oO7155VpQA@mail.gmail.com>

Hello,
Keep in mind I am VERY new to using R... What I am trying to do is package
hundreds of files into a new sub-directory. I was able to accomplish this
with the code below. HOWEVER, I have come to find that instead of merely
having to name the new sub-directory after the 7-digit numeric prefix in
the file names, the sub-directories AND the corresponding files all have to
be named after a certain attribute value in a shapefile ("DOQ_Index").
Basically, what I need to do is 1) match the filenames' 7-digit prefix to
the "ID" attribute field in the shapefile (eg. 4310950 = '4310950' - "ID"
field); then, 2) for those matches, I need to create a sub-directory based
on a DIFFERENT attribute field value ("CODE" field) and then 3) rename the
matching files based on the "CODE" attribute field and move those files to
the new sub-directory. Whew. Does that make sense?? Anyway, can someone
help me with this while keeping the basic code structure below?
Thank you! - Pmads

#read in the QuadIndex *-- I recently added this step thinking this is how
to read the shapefile*
q<- readOGR(dsn="C:/GeoHub/Test", layer="DOQ_Index")

#set the working directory
setwd("C:/GeoHub/Test/TestZip")

#get a list of directories
dlist<- list.dirs()
#remove the first vector
dlist<- dlist[-1]

#If the files are all in the working directory
  vec1 <-  list.files()
  vec1

  lst1 <- split(vec1,substr(vec1,3,9))

  #Create the sub-directory based on the first 7 numeric prefix
  sapply(file.path(getwd(),names(lst1)),dir.create)

  #Move the files to the sub-directory
  lapply(seq_along(lst1), function(i)
file.rename(lst1[[i]],paste(file.path(names(lst1[i])), lst1[[i]],sep="/")))
  list.files(recursive=TRUE)

	[[alternative HTML version deleted]]


From bhaskar.kolkata at gmail.com  Thu Sep 15 01:36:36 2016
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Wed, 14 Sep 2016 19:36:36 -0400
Subject: [R] Time format lagging issue
In-Reply-To: <CAF8bMcY-s9com=ON+COWihd7PaW245bwgR-4eXDRtEZ5MTi5mg@mail.gmail.com>
References: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>
	<D3EC9D33.184DAB%macqueen1@llnl.gov>
	<CAF8bMcY-s9com=ON+COWihd7PaW245bwgR-4eXDRtEZ5MTi5mg@mail.gmail.com>
Message-ID: <CAEGXkYUxamxJ8wkPN827XYhDPqBGh1+8T0D_=X5mRqUh-cVMDw@mail.gmail.com>

Thanks for all your feedbacks. This is helpful.

My apologies for any inconvenience due to asterisks.

Thanks,
Bhaskar

On Wed, Aug 31, 2016 at 6:09 PM, William Dunlap <wdunlap at tibco.com> wrote:

> That
>   tmp1 - 30*60
> can also be done as
>   tmp1 - as.difftime(30, units="mins")
> so you don't have to remember that the internal representation of POSIXct
> is seconds since the start of 1970.  You can choose from the following
> equivalent expressions.
>   tmp1 - as.difftime(0.5, units="hours")
>   tmp1 - as.difftime(1/2 * 1/24, units="days")
>   tmp1 - as.difftime(30*60, units="secs")
>   tmp1 - as.difftime(1/2 * 1/24 * 1/7, units="weeks")
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Aug 31, 2016 at 2:44 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
>> Try following this example:
>>
>> mydf <- data.frame(t1=c('201112312230', '201112312330'))
>> tmp1 <- as.POSIXct(mydf$t1, format='%Y%m%d%H%M')
>> tmp2 <- tmp1 - 30*60
>> mydf$t2 <- format(tmp2, '%Y%m%d%H%M')
>>
>> It can be made into a single line, but I used intermediate variables tmp1
>> and tmp2 so that it would be easier to follow.
>>
>> Base R is more than adequate for this task.
>>
>> Please get rid of the asterisks in your next email. The just get in the
>> way. Learn how to send plain text email, not HTML email. Please.
>>
>>
>>
>>
>> --
>> Don MacQueen
>>
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>>
>>
>>
>>
>>
>> On 8/31/16, 9:07 AM, "R-help on behalf of Bhaskar Mitra"
>> <r-help-bounces at r-project.org on behalf of bhaskar.kolkata at gmail.com>
>> wrote:
>>
>> >Hello Everyone,
>> >
>> >I am trying a shift the time series in a dataframe (df) by 30 minutes .
>> My
>> >current format looks something like this :
>> >
>> >
>> >
>> >*df$$Time 1*
>> >
>> >
>> >*201112312230*
>> >
>> >*201112312300*
>> >
>> >*201112312330*
>> >
>> >
>> >
>> >*I am trying to add an additional column of time (df$Time 2) next to
>> Time
>> >1 by lagging it by ? 30minutes. Something like this :*
>> >
>> >
>> >*df$Time1                   **df$$Time2*
>> >
>> >
>> >*201112312230          **201112312200*
>> >
>> >*201112312300          **201112312230*
>> >
>> >*201112312330          **201112312300*
>> >
>> >*201112312330          *
>> >
>> >
>> >
>> >
>> >
>> >*Based on some of the suggestions available, I have tried this option *
>> >
>> >
>> >
>> >*require(zoo)*
>> >
>> >*df1$Time2  <- lag(df1$Time1, -1, na.pad = TRUE)*
>> >
>> >*View(df1)*
>> >
>> >
>> >
>> >*This does not however give me the desired result. I would appreciate any
>> >suggestions/advice in this regard.*
>> >
>> >
>> >*Thanks,*
>> >
>> >*Bhaskar*
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Sep 15 14:04:51 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 15 Sep 2016 13:04:51 +0100
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <1682947458.1177650.1473876936388@mail.yahoo.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
	<1682947458.1177650.1473876936388@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403F11E3C11@GBTEDVPEXCMB04.corp.lgc-group.com>



>If you want
> to add variable to data.frame you have to use attach, detach. Right?

I'd have said "not at all", not "not quite". attach and detach have almost exactly nothing to do with adding to a data frame. 
You can add to a data frame using  
dfrm$newvar <- <something>
dfrm['newvar'] <- <something> 
cbind(dfrm, newvar=<something>) #adds a new variable called 'newvar'
rbind #to add rows
merge #to add columns and/or rows from another data frame
... and a few other things.

The only relevance of attach/detach is to do with the behaviour of attached objects, not to do with adding to data frames. If you have attach()ed something, changing the original object does not automatically update the copy of its variables in the current environment, or vice versa, because attach(), as documented, creates a _copy_. So _if_ you have attach()ed a data frame - or a list - you can't change the copy by changing the original object and you can't change the original object by changing the copy.  Only if you need to change both do you need to detach and reattach.

As a rule, I generally avoid attach() for that and other reasons (most of which are listed in ?attach). attach()is only sensible if you have already completed all the manipulation needed on the attached object first. Even then, using with() is safer.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From r.turner at auckland.ac.nz  Thu Sep 15 14:24:48 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 15 Sep 2016 14:24:48 +0200
Subject: [R] why data.frame, mutate package and not lists
In-Reply-To: <1A8C1289955EF649A09086A153E2672403F11E3C11@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <1997079468.894657.1473858106099.ref@mail.yahoo.com>
	<1997079468.894657.1473858106099@mail.yahoo.com>
	<CAGxFJbQ8vdEs73JJadBTubLBvp641z9BTVTXYaJMC+DXuWxn3w@mail.gmail.com>
	<1682947458.1177650.1473876936388@mail.yahoo.com>
	<1A8C1289955EF649A09086A153E2672403F11E3C11@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <06c9ae23-f69e-beca-43f5-98640cf30d56@auckland.ac.nz>

On 15/09/16 14:04, S Ellison wrote:
>
>
>> If you want
>> to add variable to data.frame you have to use attach, detach. Right?
>
> I'd have said "not at all", not "not quite". attach and detach have
> almost exactly nothing to do with adding to a data frame. You can add
> to a data frame using dfrm$newvar <- <something> dfrm['newvar'] <-
> <something> cbind(dfrm, newvar=<something>) #adds a new variable
> called 'newvar' rbind #to add rows merge #to add columns and/or rows
> from another data frame ... and a few other things.
>
> The only relevance of attach/detach is to do with the behaviour of
> attached objects, not to do with adding to data frames. If you have
> attach()ed something, changing the original object does not
> automatically update the copy of its variables in the current
> environment, or vice versa, because attach(), as documented, creates
> a _copy_. So _if_ you have attach()ed a data frame - or a list - you
> can't change the copy by changing the original object and you can't
> change the original object by changing the copy.  Only if you need to
> change both do you need to detach and reattach.
>
> As a rule, I generally avoid attach() for that and other reasons
> (most of which are listed in ?attach). attach()is only sensible if
> you have already completed all the manipulation needed on the
> attached object first. Even then, using with() is safer.

Extremely well and clearly put.  This is one of those "I wish *I* had 
said that!" posts.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From cryan at binghamton.edu  Thu Sep 15 16:09:48 2016
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Thu, 15 Sep 2016 10:09:48 -0400
Subject: [R] dplyr or plyr or both?
Message-ID: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>

I've set myself the task of learning about these packages, and about
tidy data concepts.

What is the relationship between plyr and dplyr?  Does the latter
replace the former (meaning I can concentrate on learning the latter)?
Or is there ever a need to use functions from both (meaning I should
learn both)?

Thanks.

--Chris Ryan


From ruipbarradas at sapo.pt  Thu Sep 15 16:20:46 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 15 Sep 2016 15:20:46 +0100
Subject: [R] dplyr or plyr or both?
In-Reply-To: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
Message-ID: <20160915152046.Horde.yezpYAht8BElCL2B0PaW-Tp@mail.sapo.pt>

Hello,

Maybe you should ask the maintainer of both packages.

> maintainer("plyr")
[1] "Hadley Wickham <hadley at rstudio.com>"
> maintainer("dplyr")
[1] "Hadley Wickham <hadley at rstudio.com>"

Hope this helps,

Rui Barradas



Citando Christopher W Ryan <cryan at binghamton.edu>:

> I've set myself the task of learning about these packages, and about
> tidy data concepts.
>
> What is the relationship between plyr and dplyr?  Does the latter
> replace the former (meaning I can concentrate on learning the latter)?
> Or is there ever a need to use functions from both (meaning I should
> learn both)?
>
> Thanks.
>
> --Chris Ryan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Sep 15 17:06:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Sep 2016 08:06:45 -0700
Subject: [R] dplyr or plyr or both?
In-Reply-To: <20160915152046.Horde.yezpYAht8BElCL2B0PaW-Tp@mail.sapo.pt>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
	<20160915152046.Horde.yezpYAht8BElCL2B0PaW-Tp@mail.sapo.pt>
Message-ID: <CAGxFJbSWsJ=BVsCbcq1TZGPAD1HyZjB1vvjuPypDMQA_nOEa1A@mail.gmail.com>

I see no reason to bother Hadley in the age of google.

Search on "dplyr versus plyr" and read what you get! (on the first hit, even)

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 15, 2016 at 7:20 AM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Maybe you should ask the maintainer of both packages.
>
>> maintainer("plyr")
>
> [1] "Hadley Wickham <hadley at rstudio.com>"
>>
>> maintainer("dplyr")
>
> [1] "Hadley Wickham <hadley at rstudio.com>"
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Christopher W Ryan <cryan at binghamton.edu>:
>
>
>> I've set myself the task of learning about these packages, and about
>> tidy data concepts.
>>
>> What is the relationship between plyr and dplyr?  Does the latter
>> replace the former (meaning I can concentrate on learning the latter)?
>> Or is there ever a need to use functions from both (meaning I should
>> learn both)?
>>
>> Thanks.
>>
>> --Chris Ryan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Thu Sep 15 18:17:25 2016
From: HDoran at air.org (Doran, Harold)
Date: Thu, 15 Sep 2016 16:17:25 +0000
Subject: [R] Better use of regex
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>

I have produced a terribly inefficient piece of codes. In the end, it gives exactly what I need, but clumsily steps through multiple steps which I'm sure could be more efficiently reduced.

Below is a reproducible example. What I have to begin with is character vector, dimInfo. What I want to do is parse this vector 1) find the elements containing 'HS' and 2) grab *only* the first character after the "HS_". The final line of code in the example gives what I need.

Any suggestions on a better approach?

Harold


dimInfo <- c("RecordID", "oppID", "position", "key", "operational", "IsSelected", 
"score", "item_1_HS_conv_ovrl_scr", "item_1_HS_elab_ovrl_scr", 
"item_1_HS_org_ovrl_scr")

ff <- dimInfo[grep('HS', dimInfo)]
gg <- strsplit(ff, 'HS_')
hh <- sapply(1:3, function(i) gg[[i]][2])
substr(hh, 1, 1)


From ruipbarradas at sapo.pt  Thu Sep 15 18:35:44 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 15 Sep 2016 17:35:44 +0100
Subject: [R] Better use of regex
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>
Message-ID: <20160915173544.Horde.smjaeHpGmcsoZWIGpI5M_oG@mail.sapo.pt>

Hello,

What about the following?

ff <- dimInfo[grep('HS', dimInfo)]
sub("^.*HS_([[:alnum:]]).*$", "\\1", ff)


Hope this helps,

Rui Barradas


Citando Doran, Harold <HDoran at air.org>:

> I have produced a terribly inefficient piece of codes. In the end,  
> it gives exactly what I need, but clumsily steps through multiple  
> steps which I'm sure could be more efficiently reduced.
>
> Below is a reproducible example. What I have to begin with is  
> character vector, dimInfo. What I want to do is parse this vector 1)  
> find the elements containing 'HS' and 2) grab *only* the first  
> character after the "HS_". The final line of code in the example  
> gives what I need.
>
> Any suggestions on a better approach?
>
> Harold
>
>
> dimInfo <- c("RecordID", "oppID", "position", "key", "operational",  
> "IsSelected",
> "score", "item_1_HS_conv_ovrl_scr", "item_1_HS_elab_ovrl_scr",
> "item_1_HS_org_ovrl_scr")
>
> ff <- dimInfo[grep('HS', dimInfo)]
> gg <- strsplit(ff, 'HS_')
> hh <- sapply(1:3, function(i) gg[[i]][2])
> substr(hh, 1, 1)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bob at rud.is  Thu Sep 15 18:38:31 2016
From: bob at rud.is (Bob Rudis)
Date: Thu, 15 Sep 2016 12:38:31 -0400
Subject: [R] Better use of regex
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>
Message-ID: <CAA-FpKVZZPG7btn21D6-Tikz-n0_cwGL3LM7FpL9Gm1VoEeMdg@mail.gmail.com>

Base:

    Filter(Negate(is.na), sapply(regmatches(dimInfo, regexec("HS_(.{1})",
dimInfo)), "[", 2))

Modernverse:

    library(stringi)
    library(purrr)

    stri_match_first_regex(dimInfo, "HS_(.{1})")[,2] %>%
      discard(is.na)


They both use capture groups to find the matches and return just the
matches. The "{1}" isn't really necessary but I include to show that you
can match whatever lengths you want, in this case just 1 char.

On Thu, Sep 15, 2016 at 12:17 PM, Doran, Harold <HDoran at air.org> wrote:

> I have produced a terribly inefficient piece of codes. In the end, it
> gives exactly what I need, but clumsily steps through multiple steps which
> I'm sure could be more efficiently reduced.
>
> Below is a reproducible example. What I have to begin with is character
> vector, dimInfo. What I want to do is parse this vector 1) find the
> elements containing 'HS' and 2) grab *only* the first character after the
> "HS_". The final line of code in the example gives what I need.
>
> Any suggestions on a better approach?
>
> Harold
>
>
> dimInfo <- c("RecordID", "oppID", "position", "key", "operational",
> "IsSelected",
> "score", "item_1_HS_conv_ovrl_scr", "item_1_HS_elab_ovrl_scr",
> "item_1_HS_org_ovrl_scr")
>
> ff <- dimInfo[grep('HS', dimInfo)]
> gg <- strsplit(ff, 'HS_')
> hh <- sapply(1:3, function(i) gg[[i]][2])
> substr(hh, 1, 1)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Sep 15 18:47:56 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Sep 2016 09:47:56 -0700
Subject: [R] Better use of regex
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6860135821D18@DC1VEX10MB01.air.org>
Message-ID: <CAGxFJbSWRSd33eUKi=qJ0X3XbVxj63FQTbxrpZg=aR0WPPFQ7A@mail.gmail.com>

Thanks for the reproducible example.

Using regular expressions:

sub(".*HS_(.).*", "\\1", dimInfo[grep("HS_",dimInfo)])

The grep() gets just the indices that contain "HS_" and the sub()
picks up the character you want from the subvector indexed by them and
replaces everything with it.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 15, 2016 at 9:17 AM, Doran, Harold <HDoran at air.org> wrote:
> I have produced a terribly inefficient piece of codes. In the end, it gives exactly what I need, but clumsily steps through multiple steps which I'm sure could be more efficiently reduced.
>
> Below is a reproducible example. What I have to begin with is character vector, dimInfo. What I want to do is parse this vector 1) find the elements containing 'HS' and 2) grab *only* the first character after the "HS_". The final line of code in the example gives what I need.
>
> Any suggestions on a better approach?
>
> Harold
>
>
> dimInfo <- c("RecordID", "oppID", "position", "key", "operational", "IsSelected",
> "score", "item_1_HS_conv_ovrl_scr", "item_1_HS_elab_ovrl_scr",
> "item_1_HS_org_ovrl_scr")
>
> ff <- dimInfo[grep('HS', dimInfo)]
> gg <- strsplit(ff, 'HS_')
> hh <- sapply(1:3, function(i) gg[[i]][2])
> substr(hh, 1, 1)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fransiepansiekevertje at gmail.com  Thu Sep 15 19:08:05 2016
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Thu, 15 Sep 2016 19:08:05 +0200
Subject: [R] dplyr or plyr or both?
In-Reply-To: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
Message-ID: <CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>

Hello Christopher and others
:
What cannot be stressed enough is: do not combine both packages, it gives
errors and incorrect results! I will show that below
--------------------------------------------------------
a<-data.frame(groep=1:4,v=1:40)
library(dplyr)
a %>% group_by(groep) %>% summarise(m=mean(v),n=n())
# groep     m     n
# <int> <dbl> <int>
# 1     1    19    10
# 2     2    20    10
# 3     3    21    10
# 4     4    22    10
# correct

library(plyr)
a %>% group_by(groep) %>% summarise(m=mean(v),n=n())

Error in n() : This function should not be called directly
# ???
a %>% group_by(groep) %>% summarise(m=mean(v))
# m
# 1 20.5
#incorrect!
--------------------------------------------------

So both n() and group_by from dplyr don't work after library(plyr)!

My advice is: do not use plyr. Unfortunately plyr has some functions that
are very important, and that are not in dplyr. For instance: rbind.fill()
(for combining the rows of two dataframes with unequal columns). If you
need this: do'nt library plyr, use plyr::rbind.fil

Until now I have the impression that it is also possible to library dplyr
after plyr, but it is better to remove plyr!

This is a serious problem that has been reported before, but not solved (in
dplyr 0.5.0 and plyr 1.8.4)

Frams

2016-09-15 16:09 GMT+02:00 Christopher W Ryan <cryan at binghamton.edu>:

> I've set myself the task of learning about these packages, and about
> tidy data concepts.
>
> What is the relationship between plyr and dplyr?  Does the latter
> replace the former (meaning I can concentrate on learning the latter)?
> Or is there ever a need to use functions from both (meaning I should
> learn both)?
>
> Thanks.
>
> --Chris Ryan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Thu Sep 15 20:32:57 2016
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Thu, 15 Sep 2016 14:32:57 -0400
Subject: [R] dplyr or plyr or both?
In-Reply-To: <CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
	<CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
Message-ID: <57DAE959.8040102@binghamton.edu>

Thank you Frans. This is exactly the sort of nuance that I want to learn 
about.

--Chris

Frans Marcelissen wrote:
> Hello Christopher and others
> :
> What cannot be stressed enough is: do not combine both packages, it
> gives errors and incorrect results! I will show that below
> --------------------------------------------------------
> a<-data.frame(groep=1:4,v=1:40)
> library(dplyr)
> a %>% group_by(groep) %>% summarise(m=mean(v),n=n())
> # groep     m     n
> # <int> <dbl> <int>
> # 1     1    19    10
> # 2     2    20    10
> # 3     3    21    10
> # 4     4    22    10
> # correct
>
> library(plyr)
> a %>% group_by(groep) %>% summarise(m=mean(v),n=n())
>
> Error in n() : This function should not be called directly
> # ???
> a %>% group_by(groep) %>% summarise(m=mean(v))
> # m
> # 1 20.5
> #incorrect!
> --------------------------------------------------
>
> So both n() and group_by from dplyr don't work after library(plyr)!
>
> My advice is: do not use plyr. Unfortunately plyr has some functions
> that are very important, and that are not in dplyr. For
> instance: rbind.fill() (for combining the rows of two dataframes with
> unequal columns). If you need this: do'nt library plyr, use plyr::rbind.fil
>
> Until now I have the impression that it is also possible to library
> dplyr after plyr, but it is better to remove plyr!
>
> This is a serious problem that has been reported before, but not solved
> (in dplyr 0.5.0 and plyr 1.8.4)
>
> Frams
>
> 2016-09-15 16:09 GMT+02:00 Christopher W Ryan <cryan at binghamton.edu
> <mailto:cryan at binghamton.edu>>:
>
>     I've set myself the task of learning about these packages, and about
>     tidy data concepts.
>
>     What is the relationship between plyr and dplyr?  Does the latter
>     replace the former (meaning I can concentrate on learning the latter)?
>     Or is there ever a need to use functions from both (meaning I should
>     learn both)?
>
>     Thanks.
>
>     --Chris Ryan
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From dusa.adrian at unibuc.ro  Thu Sep 15 21:08:41 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 15 Sep 2016 22:08:41 +0300
Subject: [R] separate commands by semicolon
Message-ID: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>

Dear R-helpers,

When parsing a text, I would like to separate commands written on the same
line, by a semicolon.
Something like:

x <- "foo <- '3;4'; bar <- \"don't ; use semicolons\""

Ideally, that would translate to these two commands in a character vector
of length 2:
foo <- '3;4'
bar <- "don't ; use semicolons"

It's probably a regexp magic, but I just can't find it.

Any hint is highly appreciated,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From roncaglia.laura at gmail.com  Thu Sep 15 18:40:03 2016
From: roncaglia.laura at gmail.com (laura roncaglia)
Date: Thu, 15 Sep 2016 18:40:03 +0200
Subject: [R] apply weight to a data frame
Message-ID: <CAApwzotkM5YmkYzRjsurYeW1N1s7tYxY23i_R-T-3r7hjBdNgw@mail.gmail.com>

I am a beginner user of R.

I am writing the master thesis using a data frame from a national survey.
The data frame contains several variables, one of which contains the survey
weights.

I need to apply the survey weights to the data frame, in order to use the
data frame with the plm package (I need to run a fixed effect analysis).

I know that I could use packages different from plm, but I am more
interested in weighting the data frame.

Thank you in advance.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Sep 15 21:28:05 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Sep 2016 12:28:05 -0700
Subject: [R] separate commands by semicolon
In-Reply-To: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
Message-ID: <CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>

The most reliable way to split such lines is with parse(text=x).
Regular expressions don't do well with context-free grammars.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 15, 2016 at 12:08 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:

> Dear R-helpers,
>
> When parsing a text, I would like to separate commands written on the same
> line, by a semicolon.
> Something like:
>
> x <- "foo <- '3;4'; bar <- \"don't ; use semicolons\""
>
> Ideally, that would translate to these two commands in a character vector
> of length 2:
> foo <- '3;4'
> bar <- "don't ; use semicolons"
>
> It's probably a regexp magic, but I just can't find it.
>
> Any hint is highly appreciated,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Sep 15 21:17:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Sep 2016 12:17:31 -0700
Subject: [R] dplyr or plyr or both?
In-Reply-To: <CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
	<CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
Message-ID: <B441F7D1-4EA9-4522-ACCB-E23FB36090CE@dcn.davis.ca.us>

The incorrect results are unfortunate and can trip up the inexperienced user, but this problem is straightforward to resolve if you explicitly specify which versions of the conflicting functions to use. The more interesting question I saw was whether the intent is to deprecate plyr, but so far that  does not appear to be the case.

While I agree that mixing them can be trouble-prone, I think in many cases both will continue to be used. 
-- 
Sent from my phone. Please excuse my brevity.

On September 15, 2016 10:08:05 AM PDT, Frans Marcelissen <fransiepansiekevertje at gmail.com> wrote:
>Hello Christopher and others
>:
>What cannot be stressed enough is: do not combine both packages, it
>gives
>errors and incorrect results! I will show that below
>--------------------------------------------------------
>a<-data.frame(groep=1:4,v=1:40)
>library(dplyr)
>a %>% group_by(groep) %>% summarise(m=mean(v),n=n())
># groep     m     n
># <int> <dbl> <int>
># 1     1    19    10
># 2     2    20    10
># 3     3    21    10
># 4     4    22    10
># correct
>
>library(plyr)
>a %>% group_by(groep) %>% summarise(m=mean(v),n=n())
>
>Error in n() : This function should not be called directly
># ???
>a %>% group_by(groep) %>% summarise(m=mean(v))
># m
># 1 20.5
>#incorrect!
>--------------------------------------------------
>
>So both n() and group_by from dplyr don't work after library(plyr)!
>
>My advice is: do not use plyr. Unfortunately plyr has some functions
>that
>are very important, and that are not in dplyr. For instance:
>rbind.fill()
>(for combining the rows of two dataframes with unequal columns). If you
>need this: do'nt library plyr, use plyr::rbind.fil
>
>Until now I have the impression that it is also possible to library
>dplyr
>after plyr, but it is better to remove plyr!
>
>This is a serious problem that has been reported before, but not solved
>(in
>dplyr 0.5.0 and plyr 1.8.4)
>
>Frams
>
>2016-09-15 16:09 GMT+02:00 Christopher W Ryan <cryan at binghamton.edu>:
>
>> I've set myself the task of learning about these packages, and about
>> tidy data concepts.
>>
>> What is the relationship between plyr and dplyr?  Does the latter
>> replace the former (meaning I can concentrate on learning the
>latter)?
>> Or is there ever a need to use functions from both (meaning I should
>> learn both)?
>>
>> Thanks.
>>
>> --Chris Ryan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Thu Sep 15 21:59:02 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Thu, 15 Sep 2016 13:59:02 -0600
Subject: [R] box type in Hmisc xYplot
Message-ID: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>

Does anyone know how to change the box type in Hmisc package function
xYplot.  I want only the left and bottom axes drawn, similar to what I
would accomplish with bty="l" argument in plot() function.  bty= argument
did not do anything for me in xYplot().

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Thu Sep 15 22:02:26 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 15 Sep 2016 23:02:26 +0300
Subject: [R] separate commands by semicolon
In-Reply-To: <CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
Message-ID: <CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>

On Thu, Sep 15, 2016 at 10:28 PM, William Dunlap <wdunlap at tibco.com> wrote:

> The most reliable way to split such lines is with parse(text=x).
> Regular expressions don't do well with context-free grammars.
>

Oh, that's right of course.
> as.character(parse(text = x))
[1] "foo <- \"3;4\""                    "bar <- \"don't ; use semicolons\""

That was simple enough, thanks very much,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From fransiepansiekevertje at gmail.com  Thu Sep 15 22:28:51 2016
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Thu, 15 Sep 2016 22:28:51 +0200
Subject: [R] dplyr or plyr or both?
In-Reply-To: <B441F7D1-4EA9-4522-ACCB-E23FB36090CE@dcn.davis.ca.us>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
	<CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
	<B441F7D1-4EA9-4522-ACCB-E23FB36090CE@dcn.davis.ca.us>
Message-ID: <57db047d.81091c0a.48fb5.7fef@mx.google.com>

I never realised that nonsense results don?n bother experienced users?.. Probably I am not experienced wiith my 6years of R professional work.
I think your advise is incomplete: a %>% dplyr::group_by(groep) %>% dplyr::summarise(m=mean(v),n=dplyr::n())
Gives the same problems and makes the line ugly. Or how would you do this?
I stick with my advise: use dplyr. if you do not need plyr: stay away from it. If you need it: do not attach it, but use the plyr:: notation.
I agree that plyr is something else as dplyr, and unfortunately plyr will be used for some time.

Verzonden vanuit Mail voor Windows 10

Van: Jeff Newmiller
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Sep 15 22:32:18 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Sep 2016 13:32:18 -0700
Subject: [R] box type in Hmisc xYplot
In-Reply-To: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>
References: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>
Message-ID: <7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>


> On Sep 15, 2016, at 12:59 PM, Cade, Brian <cadeb at usgs.gov> wrote:
> 
> Does anyone know how to change the box type in Hmisc package function
> xYplot.  I want only the left and bottom axes drawn, similar to what I
> would accomplish with bty="l" argument in plot() function.  bty= argument
> did not do anything for me in xYplot().

Frank switched over to lattice so base-graphics arguments are not necessarily honored (unless they're shared with lattice::xyplot). So you need to think how you would specify the options in lattice::xyplot and then try to pass those arguments, since there is a "dots" mechanism. I tried finding a solution in Sarkar's Lattice book but didn't come up with anything. The "box" settings I found applied to bwplot "boxes".

(Not attempting example since no data offered. You might consider searching the archives.)

-- 

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Thu Sep 15 22:44:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Sep 2016 13:44:20 -0700
Subject: [R] box type in Hmisc xYplot
In-Reply-To: <7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>
References: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>
	<7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>
Message-ID: <CAGxFJbSaCWV7pw19GXaw8PbZ4XXTDT1As4N48-ug7jT=JEh4sA@mail.gmail.com>

I do not know about xYplot, but the "scales" argument controls axes in
xyplot. For example:

scales = list(alternating = 1)

would draw axes on left/bottom ...  see ?xyplot for details and subtleties.

Again, might not work for xYplot.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 15, 2016 at 1:32 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Sep 15, 2016, at 12:59 PM, Cade, Brian <cadeb at usgs.gov> wrote:
>>
>> Does anyone know how to change the box type in Hmisc package function
>> xYplot.  I want only the left and bottom axes drawn, similar to what I
>> would accomplish with bty="l" argument in plot() function.  bty= argument
>> did not do anything for me in xYplot().
>
> Frank switched over to lattice so base-graphics arguments are not necessarily honored (unless they're shared with lattice::xyplot). So you need to think how you would specify the options in lattice::xyplot and then try to pass those arguments, since there is a "dots" mechanism. I tried finding a solution in Sarkar's Lattice book but didn't come up with anything. The "box" settings I found applied to bwplot "boxes".
>
> (Not attempting example since no data offered. You might consider searching the archives.)
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Thu Sep 15 23:01:23 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Thu, 15 Sep 2016 15:01:23 -0600
Subject: [R] box type in Hmisc xYplot
In-Reply-To: <CAGxFJbSaCWV7pw19GXaw8PbZ4XXTDT1As4N48-ug7jT=JEh4sA@mail.gmail.com>
References: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>
	<7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>
	<CAGxFJbSaCWV7pw19GXaw8PbZ4XXTDT1As4N48-ug7jT=JEh4sA@mail.gmail.com>
Message-ID: <CAM5M9BRT1r14L0RTAnc=HZ=2rF6Neqiu+yoOa7oiQkb5EnrtTg@mail.gmail.com>

No even in xyplot() the scales argument is not eliminating plotting of the
top and right graph axes.  It is not the scale of the axes I want
eliminated but the actual lines.  But thank you for trying.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Thu, Sep 15, 2016 at 2:44 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I do not know about xYplot, but the "scales" argument controls axes in
> xyplot. For example:
>
> scales = list(alternating = 1)
>
> would draw axes on left/bottom ...  see ?xyplot for details and subtleties.
>
> Again, might not work for xYplot.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Sep 15, 2016 at 1:32 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >> On Sep 15, 2016, at 12:59 PM, Cade, Brian <cadeb at usgs.gov> wrote:
> >>
> >> Does anyone know how to change the box type in Hmisc package function
> >> xYplot.  I want only the left and bottom axes drawn, similar to what I
> >> would accomplish with bty="l" argument in plot() function.  bty=
> argument
> >> did not do anything for me in xYplot().
> >
> > Frank switched over to lattice so base-graphics arguments are not
> necessarily honored (unless they're shared with lattice::xyplot). So you
> need to think how you would specify the options in lattice::xyplot and then
> try to pass those arguments, since there is a "dots" mechanism. I tried
> finding a solution in Sarkar's Lattice book but didn't come up with
> anything. The "box" settings I found applied to bwplot "boxes".
> >
> > (Not attempting example since no data offered. You might consider
> searching the archives.)
> >
> > --
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Sep 15 23:29:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Sep 2016 14:29:29 -0700
Subject: [R] dplyr or plyr or both?
In-Reply-To: <57db047d.81091c0a.48fb5.7fef@mx.google.com>
References: <CAM+rpYkDSXyFR374c-2JuAL2UQ2OgEvwdxLwsAuFmoELVBnAQQ@mail.gmail.com>
	<CAFFQM6ZT2pPcyB04ygqJ9Ok-moFXNap3eaK+kqQVuVYhTNME1w@mail.gmail.com>
	<B441F7D1-4EA9-4522-ACCB-E23FB36090CE@dcn.davis.ca.us>
	<57db047d.81091c0a.48fb5.7fef@mx.google.com>
Message-ID: <C54070A2-4676-48BB-A7B1-0F380CEA9BD0@dcn.davis.ca.us>

You are ignoring the warning issued when you load plyr after dplyr and then complaining. Simply reversing the sequence of library statements is sufficient to fix your example.

I agree that it is not ideal and that using just one at a time is easier, but you can use both, and for now a lot of packages use plyr and are not going to be rewritten for dplyr because dplyr doesn't do everything plyr does.

The more subtle problem with using both is that you may need to be explicit about which package's function to use with dplyr:: or plyr:: notation, so WHERE POSSIBLE I also recommend using dplyr.
-- 
Sent from my phone. Please excuse my brevity.

On September 15, 2016 1:28:51 PM PDT, Frans Marcelissen <fransiepansiekevertje at gmail.com> wrote:
>I never realised that nonsense results don?n bother experienced
>users?.. Probably I am not experienced wiith my 6years of R
>professional work.
>I think your advise is incomplete: a %>% dplyr::group_by(groep) %>%
>dplyr::summarise(m=mean(v),n=dplyr::n())
>Gives the same problems and makes the line ugly. Or how would you do
>this?
>I stick with my advise: use dplyr. if you do not need plyr: stay away
>from it. If you need it: do not attach it, but use the plyr:: notation.
>I agree that plyr is something else as dplyr, and unfortunately plyr
>will be used for some time.
>
>Verzonden vanuit Mail voor Windows 10
>
>Van: Jeff Newmiller


From dwinsemius at comcast.net  Thu Sep 15 23:44:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Sep 2016 14:44:16 -0700
Subject: [R] box type in Hmisc xYplot
In-Reply-To: <7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>
References: <CAM5M9BQtPCax6cMwZDvhahnP-bpemRJWYMEqGkwi_Vp8JQX6xQ@mail.gmail.com>
	<7AEF437E-42DC-4A6E-B12A-82F0B54C6769@comcast.net>
Message-ID: <E481BF14-477E-4F89-BE8E-41EE22428CD4@comcast.net>


> On Sep 15, 2016, at 1:32 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Sep 15, 2016, at 12:59 PM, Cade, Brian <cadeb at usgs.gov> wrote:
>> 
>> Does anyone know how to change the box type in Hmisc package function
>> xYplot.  I want only the left and bottom axes drawn, similar to what I
>> would accomplish with bty="l" argument in plot() function.  bty= argument
>> did not do anything for me in xYplot().
> 
> Frank switched over to lattice so base-graphics arguments are not necessarily honored (unless they're shared with lattice::xyplot). So you need to think how you would specify the options in lattice::xyplot and then try to pass those arguments, since there is a "dots" mechanism. I tried finding a solution in Sarkar's Lattice book but didn't come up with anything. The "box" settings I found applied to bwplot "boxes".
> 
> (Not attempting example since no data offered. You might consider searching the archives.)
> 

Searching the archives "scores" again:

https://stat.ethz.ch/pipermail/r-help/2007-September/140098.html

-- 

David Winsemius
Alameda, CA, USA


From aanchalsharma833 at gmail.com  Fri Sep 16 00:04:18 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Thu, 15 Sep 2016 18:04:18 -0400
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture
	model)
In-Reply-To: <956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>
References: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
	<956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>
Message-ID: <CAFp0Li0nmnDt9hHi6KPFDpFWeG3_ddbAgHQmKM8jz7v6L7OwOA@mail.gmail.com>

I am using a function gammamixEM where it does it by default. I do not have
the option to change it.
Conceptually, what can make the algorithm not able to calculate likelihood
value at all (and hence log-lik=Nan)? Is there sth wrong with the data?
Under what conditions does it happen?

On Wed, Sep 14, 2016 at 8:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 14/09/2016 4:46 PM, Aanchal Sharma wrote:
>
>> Hi,
>>
>> I am trying to fit Gamma mixture model to my data (residual values
>> obtained
>> after fitting Generalized linear Model) using gammamixEM. It is part of
>> the
>> script which does it for multiple datasets in loop. The code is running
>> fine for some datasets but it terminates for some giving following error:
>>
>> " iteration = 1  log-lik diff = NaN  log-lik = NaN
>> Error in while (diff > epsilon && iter < maxit) { :
>>   missing value where TRUE/FALSE needed"
>>
>> Seems like EM is not able to calculate log-lik value (NaN) at the first
>> iteration itself. any idea why that can happen?
>> It works fine for the other genes in the loop. Tried looking for
>> difference
>> in the inputs, but could not come up with anything striking.
>>
>>
> THere are lots of ways to get NaN in numerical calculations.   A common
> one if you are using log() to calculate log likelihoods is that rounding
> error gives you a negative likelihood, and then log(lik) comes out to NaN.
>
> You just need to look really closely at each step of your calculations.
> Avoid using log(); use the functions that build it in (e.g. instead of
> log(dnorm(x)), use dnorm(x, log = TRUE)).
>
> Duncan Murdoch
>
>


-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Sep 16 04:32:24 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Sep 2016 19:32:24 -0700
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture
	model)
In-Reply-To: <CAFp0Li0nmnDt9hHi6KPFDpFWeG3_ddbAgHQmKM8jz7v6L7OwOA@mail.gmail.com>
References: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
	<956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>
	<CAFp0Li0nmnDt9hHi6KPFDpFWeG3_ddbAgHQmKM8jz7v6L7OwOA@mail.gmail.com>
Message-ID: <CAF8bMcbAN-p3-2++udaRtx0_iK-4MmxSYH12sSdLJCD6VaF3_Q@mail.gmail.com>

Does the data contain non-positive values?

> out <- mixtools::gammamixEM(as.numeric(0:100), lambda = c(1, 1, 1)/3,
verb = TRUE)
iteration = 1  log-lik diff = NaN  log-lik = NaN
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 15, 2016 at 3:04 PM, Aanchal Sharma <aanchalsharma833 at gmail.com>
wrote:

> I am using a function gammamixEM where it does it by default. I do not have
> the option to change it.
> Conceptually, what can make the algorithm not able to calculate likelihood
> value at all (and hence log-lik=Nan)? Is there sth wrong with the data?
> Under what conditions does it happen?
>
> On Wed, Sep 14, 2016 at 8:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 14/09/2016 4:46 PM, Aanchal Sharma wrote:
> >
> >> Hi,
> >>
> >> I am trying to fit Gamma mixture model to my data (residual values
> >> obtained
> >> after fitting Generalized linear Model) using gammamixEM. It is part of
> >> the
> >> script which does it for multiple datasets in loop. The code is running
> >> fine for some datasets but it terminates for some giving following
> error:
> >>
> >> " iteration = 1  log-lik diff = NaN  log-lik = NaN
> >> Error in while (diff > epsilon && iter < maxit) { :
> >>   missing value where TRUE/FALSE needed"
> >>
> >> Seems like EM is not able to calculate log-lik value (NaN) at the first
> >> iteration itself. any idea why that can happen?
> >> It works fine for the other genes in the loop. Tried looking for
> >> difference
> >> in the inputs, but could not come up with anything striking.
> >>
> >>
> > THere are lots of ways to get NaN in numerical calculations.   A common
> > one if you are using log() to calculate log likelihoods is that rounding
> > error gives you a negative likelihood, and then log(lik) comes out to
> NaN.
> >
> > You just need to look really closely at each step of your calculations.
> > Avoid using log(); use the functions that build it in (e.g. instead of
> > log(dnorm(x)), use dnorm(x, log = TRUE)).
> >
> > Duncan Murdoch
> >
> >
>
>
> --
> Anchal Sharma, PhD
> Postdoctoral Fellow
> 195, Little Albany street,
> Cancer Institute of New Jersey
> Rutgers University
> NJ-08901
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From smk5g5 at mail.missouri.edu  Fri Sep 16 04:38:12 2016
From: smk5g5 at mail.missouri.edu (Khan, Saad M. (MU-Student))
Date: Fri, 16 Sep 2016 02:38:12 +0000
Subject: [R] Visualizing and clustering one half of a symmetric matrix
Message-ID: <DM5PR01MB254071DD125AED6B28F4712790F30@DM5PR01MB2540.prod.exchangelabs.com>

Hi all,

I have a distance matrix (symmetric) which looks somewhat like this (only a small portion shown)

                ENSG00000101413 ENSG00000176884 ENSG00000185532 ENSG00000106829
ENSG00000101413           1.000           1.000           1.000           1.000
ENSG00000176884           0.328           0.258           0.260           0.390
ENSG00000185532           1.000           1.000           1.000           1.000
ENSG00000106829           0.684           0.443           0.531           0.701

These distances are custom measures that I need to cluster. Since it's a symmetric matrix I only need to consider one half triangle of the matrix. So I do something like this :-

newmat <- ensembl_copygosimmat
newmat[upper.tri(ensembl_copygosimmat)] <- NA

Then I wanted to visualize how the lower triangle looked using pheatmap which does hierarchical clustering itself.

library(pheatmap)
pheatmap(newmat)

But since there are NA values in the matrix (in the upper half) it always throws an error. I was wondering what would be the ideal way to visualize as well as cluster such a matrix.

Regards
Saad

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Fri Sep 16 06:33:13 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 15 Sep 2016 21:33:13 -0700
Subject: [R] Visualizing and clustering one half of a symmetric matrix
In-Reply-To: <DM5PR01MB254071DD125AED6B28F4712790F30@DM5PR01MB2540.prod.exchangelabs.com>
References: <DM5PR01MB254071DD125AED6B28F4712790F30@DM5PR01MB2540.prod.exchangelabs.com>
Message-ID: <CA+hbrhU0KfbxKVeaEY0OLWS2=iA_cET6KkxCy5Eui-uJXoPe4w@mail.gmail.com>

Do not set the upper (or lower) triangle to NA. Simply supply the full
matrix to pheatmap. I am not an expert on pheatmap but looking at the
manual you should supply clustering_distance_rows = "none",
clustering_distance_cols = "none" or something like that to make
pheatmap interpret the matrix as a distance matrix. Read carefully
through the help on pheatmap to make sure the function plots what you
want it to plot.

HTH,

Peter

On Thu, Sep 15, 2016 at 7:38 PM, Khan, Saad M. (MU-Student)
<smk5g5 at mail.missouri.edu> wrote:
> Hi all,
>
> I have a distance matrix (symmetric) which looks somewhat like this (only a small portion shown)
>
>                 ENSG00000101413 ENSG00000176884 ENSG00000185532 ENSG00000106829
> ENSG00000101413           1.000           1.000           1.000           1.000
> ENSG00000176884           0.328           0.258           0.260           0.390
> ENSG00000185532           1.000           1.000           1.000           1.000
> ENSG00000106829           0.684           0.443           0.531           0.701
>
> These distances are custom measures that I need to cluster. Since it's a symmetric matrix I only need to consider one half triangle of the matrix. So I do something like this :-
>
> newmat <- ensembl_copygosimmat
> newmat[upper.tri(ensembl_copygosimmat)] <- NA
>
> Then I wanted to visualize how the lower triangle looked using pheatmap which does hierarchical clustering itself.
>
> library(pheatmap)
> pheatmap(newmat)
>
> But since there are NA values in the matrix (in the upper half) it always throws an error. I was wondering what would be the ideal way to visualize as well as cluster such a matrix.
>
> Regards
> Saad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From manu.reddy52 at gmail.com  Fri Sep 16 06:35:45 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 16 Sep 2016 10:05:45 +0530
Subject: [R] stfrtime function not returning proper results through sqldf
 package in R
Message-ID: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>

Hi ,



  I have data something looks like below (or PFA), but when I?m extracting
month  using *strftime*  function through *sqldf* library ,it?s returning
below results but it?s not returning exact results ,it supposed to return
 05,05,05,06,06,06.Can anyone please guide me how to do that with *strftime*
function.



Thanks in advance.



Quiries :


library(scales)

# load data:
log <- data.frame(Date =
c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013/06/05","2013/06/07"),
  Quantity = c(9,1,15,4,5,17,18))


# convert date variable from factor to date format:
log$Date <- as.Date(log$Date,
  "%Y/%m/%d") # tabulate all the options here
str(log)







Manu.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: strftime_sqldf_screenshot.PNG
Type: image/png
Size: 28620 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160916/099a3c19/attachment.png>

From jdnewmil at dcn.davis.ca.us  Fri Sep 16 08:02:01 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Sep 2016 23:02:01 -0700
Subject: [R] stfrtime function not returning proper results through
	sqldf package in R
In-Reply-To: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
Message-ID: <FCD8F247-A911-4900-9ECC-10D32CE6B0EC@dcn.davis.ca.us>

This question is missing pieces... the example is incomplete. 
-- 
Sent from my phone. Please excuse my brevity.

On September 15, 2016 9:35:45 PM PDT, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>Hi ,
>
>
>
>I have data something looks like below (or PFA), but when I?m
>extracting
>month  using *strftime*  function through *sqldf* library ,it?s
>returning
>below results but it?s not returning exact results ,it supposed to
>return
>05,05,05,06,06,06.Can anyone please guide me how to do that with
>*strftime*
>function.
>
>
>
>Thanks in advance.
>
>
>
>Quiries :
>
>
>library(scales)
>
># load data:
>log <- data.frame(Date =
>c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013/06/05","2013/06/07"),
>  Quantity = c(9,1,15,4,5,17,18))
>
>
># convert date variable from factor to date format:
>log$Date <- as.Date(log$Date,
>  "%Y/%m/%d") # tabulate all the options here
>str(log)
>
>
>
>
>
>
>
>Manu.
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Sep 16 09:21:33 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 07:21:33 +0000
Subject: [R] apply weight to a data frame
In-Reply-To: <CAApwzotkM5YmkYzRjsurYeW1N1s7tYxY23i_R-T-3r7hjBdNgw@mail.gmail.com>
References: <CAApwzotkM5YmkYzRjsurYeW1N1s7tYxY23i_R-T-3r7hjBdNgw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D29E@SRVEXCHMBX.precheza.cz>

Hi

I do not know much about plm but your request seems to me pretty cryptic, probably even for knowledgeable person.

There is no weight argument in plm call so I wonder how do you want to "weight data frame".

The only weighting scheme for data frame I can imagine is to repeat rows somehow according to weight value, but I do not consider it proper way.

You should probably explain what do you mean by data frame weighing to get relevant answer.
But I may be completely out of understanding your problem.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of laura
> roncaglia
> Sent: Thursday, September 15, 2016 6:40 PM
> To: r-help at r-project.org
> Subject: [R] apply weight to a data frame
>
> I am a beginner user of R.
>
> I am writing the master thesis using a data frame from a national survey.
> The data frame contains several variables, one of which contains the survey
> weights.
>
> I need to apply the survey weights to the data frame, in order to use the data
> frame with the plm package (I need to run a fixed effect analysis).
>
> I know that I could use packages different from plm, but I am more
> interested in weighting the data frame.
>
> Thank you in advance.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From manu.reddy52 at gmail.com  Fri Sep 16 09:24:29 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 16 Sep 2016 12:54:29 +0530
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <FCD8F247-A911-4900-9ECC-10D32CE6B0EC@dcn.davis.ca.us>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<FCD8F247-A911-4900-9ECC-10D32CE6B0EC@dcn.davis.ca.us>
Message-ID: <CADG9u0BiXAPGXAwaqcbxpjDqQxujsXm9H6k5DognOy22MRXOWw@mail.gmail.com>

Jeff,



  Thanks,my question is when I?m using strftime function in sqldf package
it?s not returning the results which has supposed to return ,now how can I
get the excat month from my sample data with strftime function through
sqldf package ?



Manu.

On Fri, Sep 16, 2016 at 11:32 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This question is missing pieces... the example is incomplete.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 15, 2016 9:35:45 PM PDT, Manohar Reddy <
> manu.reddy52 at gmail.com> wrote:
> >Hi ,
> >
> >
> >
> >I have data something looks like below (or PFA), but when I?m
> >extracting
> >month  using *strftime*  function through *sqldf* library ,it?s
> >returning
> >below results but it?s not returning exact results ,it supposed to
> >return
> >05,05,05,06,06,06.Can anyone please guide me how to do that with
> >*strftime*
> >function.
> >
> >
> >
> >Thanks in advance.
> >
> >
> >
> >Quiries :
> >
> >
> >library(scales)
> >
> ># load data:
> >log <- data.frame(Date =
> >c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","
> 2013/06/02","2013/06/05","2013/06/07"),
> >  Quantity = c(9,1,15,4,5,17,18))
> >
> >
> ># convert date variable from factor to date format:
> >log$Date <- as.Date(log$Date,
> >  "%Y/%m/%d") # tabulate all the options here
> >str(log)
> >
> >
> >
> >
> >
> >
> >
> >Manu.
> >
> >
> >------------------------------------------------------------------------
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 


Thanks,
Manohar Reddy P
+91-9705302062.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep 16 09:26:21 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 07:26:21 +0000
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>

Hi

Hm
> format(log$Date, "%m")
[1] "05" "05" "05" "06" "06" "06" "06"
> strftime(log$Date, "%m")
[1] "05" "05" "05" "06" "06" "06" "06"
>

works for me.

Just a blind guess, is an object date somwhere in your environment?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Manohar
> Reddy
> Sent: Friday, September 16, 2016 6:36 AM
> To: R-help <r-help at r-project.org>
> Subject: [R] stfrtime function not returning proper results through sqldf
> package in R
>
> Hi ,
>
>
>
>   I have data something looks like below (or PFA), but when I?m extracting
> month  using *strftime*  function through *sqldf* library ,it?s returning
> below results but it?s not returning exact results ,it supposed to return
> 05,05,05,06,06,06.Can anyone please guide me how to do that with
> *strftime* function.
>
>
>
> Thanks in advance.
>
>
>
> Quiries :
>
>
> library(scales)
>
> # load data:
> log <- data.frame(Date =
> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013
> /06/05","2013/06/07"),
>   Quantity = c(9,1,15,4,5,17,18))
>
>
> # convert date variable from factor to date format:
> log$Date <- as.Date(log$Date,
>   "%Y/%m/%d") # tabulate all the options here
> str(log)
>
>
>
>
>
>
>
> Manu.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Sep 16 10:44:31 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 08:44:31 +0000
Subject: [R] apply weight to a data frame
In-Reply-To: <CAApwzot3boXTU27M568zkj_K0YV8_zNVyW-sQwJkn0CXg2Nv5g@mail.gmail.com>
References: <CAApwzotkM5YmkYzRjsurYeW1N1s7tYxY23i_R-T-3r7hjBdNgw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D29E@SRVEXCHMBX.precheza.cz>
	<CAApwzot3boXTU27M568zkj_K0YV8_zNVyW-sQwJkn0CXg2Nv5g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2EE@SRVEXCHMBX.precheza.cz>

Hi

Pls, keep conversation on list, you can get answer from others, more capable than myself in survey analysis. As I said I am not an expert in this task but you seem to seek some statistical help. For this maybe stackexchange can be more appropriate.

If you want some help here, you should present some data (not necessarily real), some R code and what did you expect and did not get.

I went through help for survey and plm but did not find any mention that those two packages are somehow related. In some survey functions you can use weight argument but I did not find any note that these functions could result in object suitable for plm

Cheers
Petr

From: laura roncaglia [mailto:roncaglia.laura at gmail.com]
Sent: Friday, September 16, 2016 9:36 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] apply weight to a data frame

Thank you for your answer.

The data frame contains social and economic variables (like sex, education level, age, income, wealth and so on); since the survey is conduct on a number of family smaller than the national one, I should use survey weights to make the survey's data more representative (the survey data could be influenced by the family choosen, using the survey weights the data should be adjusted).

Now I am trying  to get a weighted data frame using the survey package (to replicate weights) ; in this way I hope I will be able to use the plm package without problems.

Do you think it could be right?

2016-09-16 9:21 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:
Hi

I do not know much about plm but your request seems to me pretty cryptic, probably even for knowledgeable person.

There is no weight argument in plm call so I wonder how do you want to "weight data frame".

The only weighting scheme for data frame I can imagine is to repeat rows somehow according to weight value, but I do not consider it proper way.

You should probably explain what do you mean by data frame weighing to get relevant answer.
But I may be completely out of understanding your problem.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of laura
> roncaglia
> Sent: Thursday, September 15, 2016 6:40 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] apply weight to a data frame
>
> I am a beginner user of R.
>
> I am writing the master thesis using a data frame from a national survey.
> The data frame contains several variables, one of which contains the survey
> weights.
>
> I need to apply the survey weights to the data frame, in order to use the data
> frame with the plm package (I need to run a fixed effect analysis).
>
> I know that I could use packages different from plm, but I am more
> interested in weighting the data frame.
>
> Thank you in advance.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.




________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From manu.reddy52 at gmail.com  Fri Sep 16 11:54:31 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 16 Sep 2016 15:24:31 +0530
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
Message-ID: <CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>

Hi Petr,



 Thanks, For me also it?s working fine when I directly used that function
 but when I call strftime function through sqldf package it?s returning NA
values (PFA) ,but my requirement is I need to do that only sqldf as I?m
writing some ?T sql ? queries against on the dataset.



Manu.

On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Hm
> > format(log$Date, "%m")
> [1] "05" "05" "05" "06" "06" "06" "06"
> > strftime(log$Date, "%m")
> [1] "05" "05" "05" "06" "06" "06" "06"
> >
>
> works for me.
>
> Just a blind guess, is an object date somwhere in your environment?
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Manohar
> > Reddy
> > Sent: Friday, September 16, 2016 6:36 AM
> > To: R-help <r-help at r-project.org>
> > Subject: [R] stfrtime function not returning proper results through sqldf
> > package in R
> >
> > Hi ,
> >
> >
> >
> >   I have data something looks like below (or PFA), but when I?m
> extracting
> > month  using *strftime*  function through *sqldf* library ,it?s returning
> > below results but it?s not returning exact results ,it supposed to return
> > 05,05,05,06,06,06.Can anyone please guide me how to do that with
> > *strftime* function.
> >
> >
> >
> > Thanks in advance.
> >
> >
> >
> > Quiries :
> >
> >
> > library(scales)
> >
> > # load data:
> > log <- data.frame(Date =
> > c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013
> > /06/05","2013/06/07"),
> >   Quantity = c(9,1,15,4,5,17,18))
> >
> >
> > # convert date variable from factor to date format:
> > log$Date <- as.Date(log$Date,
> >   "%Y/%m/%d") # tabulate all the options here
> > str(log)
> >
> >
> >
> >
> >
> >
> >
> > Manu.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 


Thanks,
Manohar Reddy P
+91-9705302062.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: strftime_error.PNG
Type: image/png
Size: 20848 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160916/a1cf3153/attachment.png>

From smk5g5 at mail.missouri.edu  Fri Sep 16 06:40:18 2016
From: smk5g5 at mail.missouri.edu (Khan, Saad M. (MU-Student))
Date: Fri, 16 Sep 2016 04:40:18 +0000
Subject: [R] Visualizing and clustering one half of a symmetric matrix
In-Reply-To: <CA+hbrhU0KfbxKVeaEY0OLWS2=iA_cET6KkxCy5Eui-uJXoPe4w@mail.gmail.com>
References: <DM5PR01MB254071DD125AED6B28F4712790F30@DM5PR01MB2540.prod.exchangelabs.com>,
	<CA+hbrhU0KfbxKVeaEY0OLWS2=iA_cET6KkxCy5Eui-uJXoPe4w@mail.gmail.com>
Message-ID: <DM5PR01MB25406936A6C1854DFC69E4B790F30@DM5PR01MB2540.prod.exchangelabs.com>

I do want to cluster it and only plot the lower half of the matrix.



________________________________
From: Peter Langfelder <peter.langfelder at gmail.com>
Sent: Thursday, September 15, 2016 11:33:13 PM
To: Khan, Saad M. (MU-Student)
Cc: r-help at R-project.org
Subject: Re: [R] Visualizing and clustering one half of a symmetric matrix

Do not set the upper (or lower) triangle to NA. Simply supply the full
matrix to pheatmap. I am not an expert on pheatmap but looking at the
manual you should supply clustering_distance_rows = "none",
clustering_distance_cols = "none" or something like that to make
pheatmap interpret the matrix as a distance matrix. Read carefully
through the help on pheatmap to make sure the function plots what you
want it to plot.

HTH,

Peter

On Thu, Sep 15, 2016 at 7:38 PM, Khan, Saad M. (MU-Student)
<smk5g5 at mail.missouri.edu> wrote:
> Hi all,
>
> I have a distance matrix (symmetric) which looks somewhat like this (only a small portion shown)
>
>                 ENSG00000101413 ENSG00000176884 ENSG00000185532 ENSG00000106829
> ENSG00000101413           1.000           1.000           1.000           1.000
> ENSG00000176884           0.328           0.258           0.260           0.390
> ENSG00000185532           1.000           1.000           1.000           1.000
> ENSG00000106829           0.684           0.443           0.531           0.701
>
> These distances are custom measures that I need to cluster. Since it's a symmetric matrix I only need to consider one half triangle of the matrix. So I do something like this :-
>
> newmat <- ensembl_copygosimmat
> newmat[upper.tri(ensembl_copygosimmat)] <- NA
>
> Then I wanted to visualize how the lower triangle looked using pheatmap which does hierarchical clustering itself.
>
> library(pheatmap)
> pheatmap(newmat)
>
> But since there are NA values in the matrix (in the upper half) it always throws an error. I was wondering what would be the ideal way to visualize as well as cluster such a matrix.
>
> Regards
> Saad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep 16 13:48:15 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 11:48:15 +0000
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>

Hi

Most probably there is some syntactic suger how to correctly formulate sql query.

> sqldf('select Date, strftime("Date", "%m") from log')
        Date strftime("Date", "%m")
1 2013-05-25                   <NA>
2 2013-05-28                   <NA>
3 2013-05-31                   <NA>
4 2013-06-01                   <NA>
5 2013-06-02                   <NA>
6 2013-06-05                   <NA>
7 2013-06-07                   <NA>
> sqldf('select Date, format("Date", "%m") from log')
Error in sqliteSendQuery(con, statement, bind.data) :
  error in statement: no such function: format
>

format(sqldf("select Date from log"), "%m")

This one however works.

Cheers
Petr

From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
Sent: Friday, September 16, 2016 11:55 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] stfrtime function not returning proper results through sqldf package in R


Hi Petr,

 Thanks, For me also it?s working fine when I directly used that function  but when I call strftime function through sqldf package it?s returning NA values (PFA) ,but my requirement is I need to do that only sqldf as I?m writing some ?T sql ? queries against on the dataset.

Manu.

On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Hm
> format(log$Date, "%m")
[1] "05" "05" "05" "06" "06" "06" "06"
> strftime(log$Date, "%m")
[1] "05" "05" "05" "06" "06" "06" "06"
>

works for me.

Just a blind guess, is an object date somwhere in your environment?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Manohar
> Reddy
> Sent: Friday, September 16, 2016 6:36 AM
> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] stfrtime function not returning proper results through sqldf
> package in R
>
> Hi ,
>
>
>
>   I have data something looks like below (or PFA), but when I?m extracting
> month  using *strftime*  function through *sqldf* library ,it?s returning
> below results but it?s not returning exact results ,it supposed to return
> 05,05,05,06,06,06.Can anyone please guide me how to do that with
> *strftime* function.
>
>
>
> Thanks in advance.
>
>
>
> Quiries :
>
>
> library(scales)
>
> # load data:
> log <- data.frame(Date =
> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013
> /06/05","2013/06/07"),
>   Quantity = c(9,1,15,4,5,17,18))
>
>
> # convert date variable from factor to date format:
> log$Date <- as.Date(log$Date,
>   "%Y/%m/%d") # tabulate all the options here
> str(log)
>
>
>
>
>
>
>
> Manu.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



--


Thanks,
Manohar Reddy P
+91-9705302062.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Sep 16 14:44:39 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 16 Sep 2016 14:44:39 +0200
Subject: [R] stfrtime function not returning proper results through
	sqldf package in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
Message-ID: <D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>

Presumably, sqldf does not know about Date object so passes an integer that gets interpreted as who knows what...

This seems to work:

> df <- data.frame(date=as.character(Sys.Date()+seq(0,180,,10)))
> cbind(df, sqldf("select strftime( '%m', date) from df"))
         date strftime( '%m', date)
1  2016-09-16                    09
2  2016-10-06                    10
3  2016-10-26                    10
4  2016-11-15                    11
5  2016-12-05                    12
6  2016-12-25                    12
7  2017-01-14                    01
8  2017-02-03                    02
9  2017-02-23                    02
10 2017-03-15                    03

-pd



On 16 Sep 2016, at 13:48 , PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> Most probably there is some syntactic suger how to correctly formulate sql query.
> 
>> sqldf('select Date, strftime("Date", "%m") from log')
>        Date strftime("Date", "%m")
> 1 2013-05-25                   <NA>
> 2 2013-05-28                   <NA>
> 3 2013-05-31                   <NA>
> 4 2013-06-01                   <NA>
> 5 2013-06-02                   <NA>
> 6 2013-06-05                   <NA>
> 7 2013-06-07                   <NA>
>> sqldf('select Date, format("Date", "%m") from log')
> Error in sqliteSendQuery(con, statement, bind.data) :
>  error in statement: no such function: format
>> 
> 
> format(sqldf("select Date from log"), "%m")
> 
> This one however works.
> 
> Cheers
> Petr
> 
> From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
> Sent: Friday, September 16, 2016 11:55 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] stfrtime function not returning proper results through sqldf package in R
> 
> 
> Hi Petr,
> 
> Thanks, For me also it?s working fine when I directly used that function  but when I call strftime function through sqldf package it?s returning NA values (PFA) ,but my requirement is I need to do that only sqldf as I?m writing some ?T sql ? queries against on the dataset.
> 
> Manu.
> 
> On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
> 
> Hm
>> format(log$Date, "%m")
> [1] "05" "05" "05" "06" "06" "06" "06"
>> strftime(log$Date, "%m")
> [1] "05" "05" "05" "06" "06" "06" "06"
>> 
> 
> works for me.
> 
> Just a blind guess, is an object date somwhere in your environment?
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Manohar
>> Reddy
>> Sent: Friday, September 16, 2016 6:36 AM
>> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
>> Subject: [R] stfrtime function not returning proper results through sqldf
>> package in R
>> 
>> Hi ,
>> 
>> 
>> 
>>  I have data something looks like below (or PFA), but when I?m extracting
>> month  using *strftime*  function through *sqldf* library ,it?s returning
>> below results but it?s not returning exact results ,it supposed to return
>> 05,05,05,06,06,06.Can anyone please guide me how to do that with
>> *strftime* function.
>> 
>> 
>> 
>> Thanks in advance.
>> 
>> 
>> 
>> Quiries :
>> 
>> 
>> library(scales)
>> 
>> # load data:
>> log <- data.frame(Date =
>> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013
>> /06/05","2013/06/07"),
>>  Quantity = c(9,1,15,4,5,17,18))
>> 
>> 
>> # convert date variable from factor to date format:
>> log$Date <- as.Date(log$Date,
>>  "%Y/%m/%d") # tabulate all the options here
>> str(log)
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Manu.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> 
> 
> 
> --
> 
> 
> Thanks,
> Manohar Reddy P
> +91-9705302062.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Fri Sep 16 15:23:48 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 13:23:48 +0000
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>

Hi Peter

The devil is in detail

Data from OP had different format and was transferred to Date object by as.Date, which results in incorrect values (and NA if not transferred)
df <- data.frame(Date = c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02",
"2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
df$Date<-as.Date(df$Date)
cbind(df, sqldf("select strftime( '%m', Date) from df"))

Data formatted according to your example transferred to Date object by as data, again incorrect result
df2 <- data.frame(Date = c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
df2$Date<-as.Date(df2$Date)
cbind(df2, sqldf("select strftime( '%m', Date) from df2"))

Data formatted according to your example but **not** changed to Dates, correct result
df3 <- data.frame(Date = c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
cbind(df3, sqldf("select strftime( '%m', Date) from df3"))

so sqldf is a bit peculiar about required input values and does not know how to handle Date objects.

Cheers
Petr


> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: Friday, September 16, 2016 2:45 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Manohar Reddy <manu.reddy52 at gmail.com>; R-help <r-help at r-
> project.org>
> Subject: Re: [R] stfrtime function not returning proper results through sqldf
> package in R
>
> Presumably, sqldf does not know about Date object so passes an integer that
> gets interpreted as who knows what...
>
> This seems to work:
>
> > df <- data.frame(date=as.character(Sys.Date()+seq(0,180,,10)))
> > cbind(df, sqldf("select strftime( '%m', date) from df"))
>          date strftime( '%m', date)
> 1  2016-09-16                    09
> 2  2016-10-06                    10
> 3  2016-10-26                    10
> 4  2016-11-15                    11
> 5  2016-12-05                    12
> 6  2016-12-25                    12
> 7  2017-01-14                    01
> 8  2017-02-03                    02
> 9  2017-02-23                    02
> 10 2017-03-15                    03
>
> -pd
>
>
>
> On 16 Sep 2016, at 13:48 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > Most probably there is some syntactic suger how to correctly formulate sql
> query.
> >
> >> sqldf('select Date, strftime("Date", "%m") from log')
> >        Date strftime("Date", "%m")
> > 1 2013-05-25                   <NA>
> > 2 2013-05-28                   <NA>
> > 3 2013-05-31                   <NA>
> > 4 2013-06-01                   <NA>
> > 5 2013-06-02                   <NA>
> > 6 2013-06-05                   <NA>
> > 7 2013-06-07                   <NA>
> >> sqldf('select Date, format("Date", "%m") from log')
> > Error in sqliteSendQuery(con, statement, bind.data) :
> >  error in statement: no such function: format
> >>
> >
> > format(sqldf("select Date from log"), "%m")
> >
> > This one however works.
> >
> > Cheers
> > Petr
> >
> > From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
> > Sent: Friday, September 16, 2016 11:55 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: R-help <r-help at r-project.org>
> > Subject: Re: [R] stfrtime function not returning proper results
> > through sqldf package in R
> >
> >
> > Hi Petr,
> >
> > Thanks, For me also it?s working fine when I directly used that function  but
> when I call strftime function through sqldf package it?s returning NA values
> (PFA) ,but my requirement is I need to do that only sqldf as I?m writing some
> ?T sql ? queries against on the dataset.
> >
> > Manu.
> >
> > On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr
> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Hm
> >> format(log$Date, "%m")
> > [1] "05" "05" "05" "06" "06" "06" "06"
> >> strftime(log$Date, "%m")
> > [1] "05" "05" "05" "06" "06" "06" "06"
> >>
> >
> > works for me.
> >
> > Just a blind guess, is an object date somwhere in your environment?
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help
> >> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.
> >> org>] On Behalf Of Manohar Reddy
> >> Sent: Friday, September 16, 2016 6:36 AM
> >> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
> >> Subject: [R] stfrtime function not returning proper results through
> >> sqldf package in R
> >>
> >> Hi ,
> >>
> >>
> >>
> >>  I have data something looks like below (or PFA), but when I?m
> >> extracting month  using *strftime*  function through *sqldf* library
> >> ,it?s returning below results but it?s not returning exact results
> >> ,it supposed to return 05,05,05,06,06,06.Can anyone please guide me
> >> how to do that with
> >> *strftime* function.
> >>
> >>
> >>
> >> Thanks in advance.
> >>
> >>
> >>
> >> Quiries :
> >>
> >>
> >> library(scales)
> >>
> >> # load data:
> >> log <- data.frame(Date =
> >> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2
> >> 013
> >> /06/05","2013/06/07"),
> >>  Quantity = c(9,1,15,4,5,17,18))
> >>
> >>
> >> # convert date variable from factor to date format:
> >> log$Date <- as.Date(log$Date,
> >>  "%Y/%m/%d") # tabulate all the options here
> >> str(log)
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> Manu.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy,
> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its copies
> from your system.
> > If you are not the intended recipient of this e-mail, you are not authorized
> to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> > - the sender insists on that the respective contract is concluded only upon
> an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which he/she
> is expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
> >
> >
> >
> > --
> >
> >
> > Thanks,
> > Manohar Reddy P
> > +91-9705302062.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy,
> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its copies
> from your system.
> > If you are not the intended recipient of this e-mail, you are not authorized
> to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> > - the sender insists on that the respective contract is concluded only upon
> an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which he/she
> is expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From susmitha117 at gmail.com  Fri Sep 16 14:08:30 2016
From: susmitha117 at gmail.com (susmita T)
Date: Fri, 16 Sep 2016 08:08:30 -0400
Subject: [R] Query to find minimum value in a matrix in R
Message-ID: <00612011-683F-458C-BAD9-5BB46BD42044@gmail.com>

Hi,
Good Morning! I am new to R and finding difficulty in understanding the code. Since few days I am stuck at single line of code which I am unable to understand.
Though there may be number of logics to find min value. As a new beginner I am following a book and as it has the following code

mind<-function(d)
{
	n<-nrow(d)
	dd<-cbind(d,1:n)
	wmins<-apply(dd[-n,],1,imin)
	i<-which.min(wmins[2,])
	j<-wmins[1,i]
	return(c(d[i,j],i,j))
}
imin<-function(x)
{
	lx<-length(x)
	i<-x[lx]
	j<-which.min(x[(i+1):(lx-1)])
	k<-i+j
	return(c(k,x[k]))
}

So when executed this with mind(below matrix) I get
0	12	13	8	20
12	0	15	28	88
13	15	0	6	9
8	28	6	0	33
20	88	9	33	0
the answer as 6 , row 3 column 4

Due to the symmetry of the matrix , the skipping of the early part of row is done by using expression (x[(i+1):(lx-1)])..(which is in red color in the code shown above). I am unable to understand
the line in red code and how it is implemented in the line 5(i.e wins)?(shown in pink color in the code above
I have done necessary homework to understand but still finding it hard to get it. Please someone help.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Sep 16 16:15:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 16 Sep 2016 07:15:31 -0700
Subject: [R] stfrtime function not returning proper results through
	sqldf package in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
Message-ID: <5A89F065-5E1B-4360-8767-8E7E7C8EC633@dcn.davis.ca.us>

SQLite only understands certain fundamental data types, and neither Date nor POSIXct types are among them. They get stored as their internal numeric representations. 

The internal numeric representations of Date and POSIXct are incompatible. You are sending Dates to SQLite and trying to then interpret it as POSIXct by handing that numeric to strftime.

Note that within R the Date and POSIXct types are made sort-of compatible by internal checking of class attributes that are not stored in SQLite. They are still only sort-of compatible because Date has no concept of time zone and always assumes GMT rather than local time when being converted.

I recommend retrieving the stored Date value as a Date value into R so that strftime can recognize how to interpret it. If you need to handle time as well as date you may find that converting to character first before converting to POSIXct with an appropriate time zone behaves with least surprises. 
-- 
Sent from my phone. Please excuse my brevity.

On September 16, 2016 6:23:48 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi Peter
>
>The devil is in detail
>
>Data from OP had different format and was transferred to Date object by
>as.Date, which results in incorrect values (and NA if not transferred)
>df <- data.frame(Date =
>c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02",
>"2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
>df$Date<-as.Date(df$Date)
>cbind(df, sqldf("select strftime( '%m', Date) from df"))
>
>Data formatted according to your example transferred to Date object by
>as data, again incorrect result
>df2 <- data.frame(Date =
>c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>df2$Date<-as.Date(df2$Date)
>cbind(df2, sqldf("select strftime( '%m', Date) from df2"))
>
>Data formatted according to your example but **not** changed to Dates,
>correct result
>df3 <- data.frame(Date =
>c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>cbind(df3, sqldf("select strftime( '%m', Date) from df3"))
>
>so sqldf is a bit peculiar about required input values and does not
>know how to handle Date objects.
>
>Cheers
>Petr
>
>
>> -----Original Message-----
>> From: peter dalgaard [mailto:pdalgd at gmail.com]
>> Sent: Friday, September 16, 2016 2:45 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>
>> Cc: Manohar Reddy <manu.reddy52 at gmail.com>; R-help <r-help at r-
>> project.org>
>> Subject: Re: [R] stfrtime function not returning proper results
>through sqldf
>> package in R
>>
>> Presumably, sqldf does not know about Date object so passes an
>integer that
>> gets interpreted as who knows what...
>>
>> This seems to work:
>>
>> > df <- data.frame(date=as.character(Sys.Date()+seq(0,180,,10)))
>> > cbind(df, sqldf("select strftime( '%m', date) from df"))
>>          date strftime( '%m', date)
>> 1  2016-09-16                    09
>> 2  2016-10-06                    10
>> 3  2016-10-26                    10
>> 4  2016-11-15                    11
>> 5  2016-12-05                    12
>> 6  2016-12-25                    12
>> 7  2017-01-14                    01
>> 8  2017-02-03                    02
>> 9  2017-02-23                    02
>> 10 2017-03-15                    03
>>
>> -pd
>>
>>
>>
>> On 16 Sep 2016, at 13:48 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>
>> > Hi
>> >
>> > Most probably there is some syntactic suger how to correctly
>formulate sql
>> query.
>> >
>> >> sqldf('select Date, strftime("Date", "%m") from log')
>> >        Date strftime("Date", "%m")
>> > 1 2013-05-25                   <NA>
>> > 2 2013-05-28                   <NA>
>> > 3 2013-05-31                   <NA>
>> > 4 2013-06-01                   <NA>
>> > 5 2013-06-02                   <NA>
>> > 6 2013-06-05                   <NA>
>> > 7 2013-06-07                   <NA>
>> >> sqldf('select Date, format("Date", "%m") from log')
>> > Error in sqliteSendQuery(con, statement, bind.data) :
>> >  error in statement: no such function: format
>> >>
>> >
>> > format(sqldf("select Date from log"), "%m")
>> >
>> > This one however works.
>> >
>> > Cheers
>> > Petr
>> >
>> > From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
>> > Sent: Friday, September 16, 2016 11:55 AM
>> > To: PIKAL Petr <petr.pikal at precheza.cz>
>> > Cc: R-help <r-help at r-project.org>
>> > Subject: Re: [R] stfrtime function not returning proper results
>> > through sqldf package in R
>> >
>> >
>> > Hi Petr,
>> >
>> > Thanks, For me also it?s working fine when I directly used that
>function  but
>> when I call strftime function through sqldf package it?s returning NA
>values
>> (PFA) ,but my requirement is I need to do that only sqldf as I?m
>writing some
>> ?T sql ? queries against on the dataset.
>> >
>> > Manu.
>> >
>> > On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr
>> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
>> > Hi
>> >
>> > Hm
>> >> format(log$Date, "%m")
>> > [1] "05" "05" "05" "06" "06" "06" "06"
>> >> strftime(log$Date, "%m")
>> > [1] "05" "05" "05" "06" "06" "06" "06"
>> >>
>> >
>> > works for me.
>> >
>> > Just a blind guess, is an object date somwhere in your environment?
>> >
>> > Cheers
>> > Petr
>> >
>> >
>> >> -----Original Message-----
>> >> From: R-help
>> >>
>[mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.
>> >> org>] On Behalf Of Manohar Reddy
>> >> Sent: Friday, September 16, 2016 6:36 AM
>> >> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
>> >> Subject: [R] stfrtime function not returning proper results
>through
>> >> sqldf package in R
>> >>
>> >> Hi ,
>> >>
>> >>
>> >>
>> >>  I have data something looks like below (or PFA), but when I?m
>> >> extracting month  using *strftime*  function through *sqldf*
>library
>> >> ,it?s returning below results but it?s not returning exact results
>> >> ,it supposed to return 05,05,05,06,06,06.Can anyone please guide
>me
>> >> how to do that with
>> >> *strftime* function.
>> >>
>> >>
>> >>
>> >> Thanks in advance.
>> >>
>> >>
>> >>
>> >> Quiries :
>> >>
>> >>
>> >> library(scales)
>> >>
>> >> # load data:
>> >> log <- data.frame(Date =
>> >>
>c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2
>> >> 013
>> >> /06/05","2013/06/07"),
>> >>  Quantity = c(9,1,15,4,5,17,18))
>> >>
>> >>
>> >> # convert date variable from factor to date format:
>> >> log$Date <- as.Date(log$Date,
>> >>  "%Y/%m/%d") # tabulate all the options here
>> >> str(log)
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> Manu.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie
>> vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy,
>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m
>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>zastoupen?
>> zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential
>and are
>> intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform
>its
>> sender. Delete the contents of this e-mail with all attachments and
>its copies
>> from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>authorized
>> to use, disseminate, copy or disclose this e-mail in any manner.
>> > The sender of this e-mail shall not be liable for any possible
>damage caused
>> by modifications of the e-mail or by delay with transfer of the
>email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering
>into a
>> contract in any time, for any reason, and without stating any
>reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>immediately
>> accept such offer; The sender of this e-mail (offer) excludes any
>acceptance
>> of the offer on the part of the recipient containing any amendment or
>> variation.
>> > - the sender insists on that the respective contract is concluded
>only upon
>> an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized
>to enter
>> into any contracts on behalf of the company except for cases in which
>he/she
>> is expressly authorized to do so in writing, and such authorization
>or power of
>> attorney is submitted to the recipient or the person represented by
>the
>> recipient, or the existence of such authorization is known to the
>recipient of
>> the person represented by the recipient.
>> >
>> >
>> >
>> > --
>> >
>> >
>> > Thanks,
>> > Manohar Reddy P
>> > +91-9705302062.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie
>> vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy,
>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m
>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>zastoupen?
>> zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential
>and are
>> intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform
>its
>> sender. Delete the contents of this e-mail with all attachments and
>its copies
>> from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>authorized
>> to use, disseminate, copy or disclose this e-mail in any manner.
>> > The sender of this e-mail shall not be liable for any possible
>damage caused
>> by modifications of the e-mail or by delay with transfer of the
>email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering
>into a
>> contract in any time, for any reason, and without stating any
>reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>immediately
>> accept such offer; The sender of this e-mail (offer) excludes any
>acceptance
>> of the offer on the part of the recipient containing any amendment or
>> variation.
>> > - the sender insists on that the respective contract is concluded
>only upon
>> an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized
>to enter
>> into any contracts on behalf of the company except for cases in which
>he/she
>> is expressly authorized to do so in writing, and such authorization
>or power of
>> attorney is submitted to the recipient or the person represented by
>the
>> recipient, or the existence of such authorization is known to the
>recipient of
>> the person represented by the recipient.
>> >
>> >     [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
>2000
>> Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Fri Sep 16 16:20:17 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 16 Sep 2016 15:20:17 +0100
Subject: [R] Query to find minimum value in a matrix in R
In-Reply-To: <00612011-683F-458C-BAD9-5BB46BD42044@gmail.com>
References: <00612011-683F-458C-BAD9-5BB46BD42044@gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403F11E3EFE@GBTEDVPEXCMB04.corp.lgc-group.com>

> I am unable to understand the line in red code 
Colour does not survive plain text transmission; try adding comments (# ...) instead, or state which line of code you do not understand.

In the mean time you could take a look, first, as 
?cbind
?apply
?'[' 

with particular attention to the meaning of negative indices (like '-n' in dd[-n,])

S Ellison



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of susmita T
> Sent: 16 September 2016 13:09
> To: r-help at r-project.org
> Subject: [R] Query to find minimum value in a matrix in R
> 
> Hi,
> Good Morning! I am new to R and finding difficulty in understanding the code.
> Since few days I am stuck at single line of code which I am unable to
> understand.
> Though there may be number of logics to find min value. As a new beginner I
> am following a book and as it has the following code
> 
> mind<-function(d)
> {
> 	n<-nrow(d)
> 	dd<-cbind(d,1:n)
> 	wmins<-apply(dd[-n,],1,imin)
> 	i<-which.min(wmins[2,])
> 	j<-wmins[1,i]
> 	return(c(d[i,j],i,j))
> }
> imin<-function(x)
> {
> 	lx<-length(x)
> 	i<-x[lx]
> 	j<-which.min(x[(i+1):(lx-1)])
> 	k<-i+j
> 	return(c(k,x[k]))
> }
> 
> So when executed this with mind(below matrix) I get
> 0	12	13	8	20
> 12	0	15	28	88
> 13	15	0	6	9
> 8	28	6	0	33
> 20	88	9	33	0
> the answer as 6 , row 3 column 4
> 
> Due to the symmetry of the matrix , the skipping of the early part of row is
> done by using expression (x[(i+1):(lx-1)])..(which is in red color in the code
> shown above). I am unable to understand the line in red code and how it is
> implemented in the line 5(i.e wins)?(shown in pink color in the code above I
> have done necessary homework to understand but still finding it hard to get it.
> Please someone help.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From ggrothendieck at gmail.com  Fri Sep 16 16:48:25 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Sep 2016 10:48:25 -0400
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <5A89F065-5E1B-4360-8767-8E7E7C8EC633@dcn.davis.ca.us>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
	<5A89F065-5E1B-4360-8767-8E7E7C8EC633@dcn.davis.ca.us>
Message-ID: <CAP01uRkcz8L6swwjgpK87cvXf7=OGdjzE1w3vX9p-fqCx-uYVA@mail.gmail.com>

To be precise it's SQLite that does not have date and time data types.
If you use an sqldf backend such as H2 that does have such types then
sqldf will pass them as such.  In the case of R's "Date" class such
objects are passed to SQLite as numbers since that is what SQLite can
understand but they are passed as dates to H2 (and other backends if
they have a date type).

Also note that after sqldf passes a date to SQLite as a number then
when SQLite passes it back to sqldf then sqldf  knows that it was
originally a date (due to the column name being the same) and coerces
it to Date class again.  In the example below sqldf passed the number
of days to 2000-01-01 since the UNIX epoch to SQLite.  SQLite then
processed it and passed it back as a number again. Then sqldf realized
that it was originally a Date because the column name is still d and
the original column d was of "Date" class and so coerces the number
from SQLite to Date.  There are a limited number of circumstances
where this heuristic works but they are sufficient that it's often
transparent even though SQLite has no date and time types.

> library(sqldf)
> DF <- data.frame(d = as.Date("2000-01-01"))
> sqldf("select d+1 as d from DF") # return next day
           d
1 2000-01-02

At the same time iif you really need to do serious date processing on
the SQL side it's much easier with an sqldf backend such as H2 that
actually supports date and time types and no heuristic is needed by
sqldf and no user workarounds on the R side are needed.


On Fri, Sep 16, 2016 at 10:15 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> SQLite only understands certain fundamental data types, and neither Date nor POSIXct types are among them. They get stored as their internal numeric representations.
>
> The internal numeric representations of Date and POSIXct are incompatible. You are sending Dates to SQLite and trying to then interpret it as POSIXct by handing that numeric to strftime.
>
> Note that within R the Date and POSIXct types are made sort-of compatible by internal checking of class attributes that are not stored in SQLite. They are still only sort-of compatible because Date has no concept of time zone and always assumes GMT rather than local time when being converted.
>
> I recommend retrieving the stored Date value as a Date value into R so that strftime can recognize how to interpret it. If you need to handle time as well as date you may find that converting to character first before converting to POSIXct with an appropriate time zone behaves with least surprises.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 16, 2016 6:23:48 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>Hi Peter
>>
>>The devil is in detail
>>
>>Data from OP had different format and was transferred to Date object by
>>as.Date, which results in incorrect values (and NA if not transferred)
>>df <- data.frame(Date =
>>c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02",
>>"2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
>>df$Date<-as.Date(df$Date)
>>cbind(df, sqldf("select strftime( '%m', Date) from df"))
>>
>>Data formatted according to your example transferred to Date object by
>>as data, again incorrect result
>>df2 <- data.frame(Date =
>>c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>>"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>>df2$Date<-as.Date(df2$Date)
>>cbind(df2, sqldf("select strftime( '%m', Date) from df2"))
>>
>>Data formatted according to your example but **not** changed to Dates,
>>correct result
>>df3 <- data.frame(Date =
>>c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>>"2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>>cbind(df3, sqldf("select strftime( '%m', Date) from df3"))
>>
>>so sqldf is a bit peculiar about required input values and does not
>>know how to handle Date objects.
>>
>>Cheers
>>Petr
>>
>>
>>> -----Original Message-----
>>> From: peter dalgaard [mailto:pdalgd at gmail.com]
>>> Sent: Friday, September 16, 2016 2:45 PM
>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>> Cc: Manohar Reddy <manu.reddy52 at gmail.com>; R-help <r-help at r-
>>> project.org>
>>> Subject: Re: [R] stfrtime function not returning proper results
>>through sqldf
>>> package in R
>>>
>>> Presumably, sqldf does not know about Date object so passes an
>>integer that
>>> gets interpreted as who knows what...
>>>
>>> This seems to work:
>>>
>>> > df <- data.frame(date=as.character(Sys.Date()+seq(0,180,,10)))
>>> > cbind(df, sqldf("select strftime( '%m', date) from df"))
>>>          date strftime( '%m', date)
>>> 1  2016-09-16                    09
>>> 2  2016-10-06                    10
>>> 3  2016-10-26                    10
>>> 4  2016-11-15                    11
>>> 5  2016-12-05                    12
>>> 6  2016-12-25                    12
>>> 7  2017-01-14                    01
>>> 8  2017-02-03                    02
>>> 9  2017-02-23                    02
>>> 10 2017-03-15                    03
>>>
>>> -pd
>>>
>>>
>>>
>>> On 16 Sep 2016, at 13:48 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>
>>> > Hi
>>> >
>>> > Most probably there is some syntactic suger how to correctly
>>formulate sql
>>> query.
>>> >
>>> >> sqldf('select Date, strftime("Date", "%m") from log')
>>> >        Date strftime("Date", "%m")
>>> > 1 2013-05-25                   <NA>
>>> > 2 2013-05-28                   <NA>
>>> > 3 2013-05-31                   <NA>
>>> > 4 2013-06-01                   <NA>
>>> > 5 2013-06-02                   <NA>
>>> > 6 2013-06-05                   <NA>
>>> > 7 2013-06-07                   <NA>
>>> >> sqldf('select Date, format("Date", "%m") from log')
>>> > Error in sqliteSendQuery(con, statement, bind.data) :
>>> >  error in statement: no such function: format
>>> >>
>>> >
>>> > format(sqldf("select Date from log"), "%m")
>>> >
>>> > This one however works.
>>> >
>>> > Cheers
>>> > Petr
>>> >
>>> > From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
>>> > Sent: Friday, September 16, 2016 11:55 AM
>>> > To: PIKAL Petr <petr.pikal at precheza.cz>
>>> > Cc: R-help <r-help at r-project.org>
>>> > Subject: Re: [R] stfrtime function not returning proper results
>>> > through sqldf package in R
>>> >
>>> >
>>> > Hi Petr,
>>> >
>>> > Thanks, For me also it?s working fine when I directly used that
>>function  but
>>> when I call strftime function through sqldf package it?s returning NA
>>values
>>> (PFA) ,but my requirement is I need to do that only sqldf as I?m
>>writing some
>>> ?T sql ? queries against on the dataset.
>>> >
>>> > Manu.
>>> >
>>> > On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr
>>> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
>>> > Hi
>>> >
>>> > Hm
>>> >> format(log$Date, "%m")
>>> > [1] "05" "05" "05" "06" "06" "06" "06"
>>> >> strftime(log$Date, "%m")
>>> > [1] "05" "05" "05" "06" "06" "06" "06"
>>> >>
>>> >
>>> > works for me.
>>> >
>>> > Just a blind guess, is an object date somwhere in your environment?
>>> >
>>> > Cheers
>>> > Petr
>>> >
>>> >
>>> >> -----Original Message-----
>>> >> From: R-help
>>> >>
>>[mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.
>>> >> org>] On Behalf Of Manohar Reddy
>>> >> Sent: Friday, September 16, 2016 6:36 AM
>>> >> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
>>> >> Subject: [R] stfrtime function not returning proper results
>>through
>>> >> sqldf package in R
>>> >>
>>> >> Hi ,
>>> >>
>>> >>
>>> >>
>>> >>  I have data something looks like below (or PFA), but when I?m
>>> >> extracting month  using *strftime*  function through *sqldf*
>>library
>>> >> ,it?s returning below results but it?s not returning exact results
>>> >> ,it supposed to return 05,05,05,06,06,06.Can anyone please guide
>>me
>>> >> how to do that with
>>> >> *strftime* function.
>>> >>
>>> >>
>>> >>
>>> >> Thanks in advance.
>>> >>
>>> >>
>>> >>
>>> >> Quiries :
>>> >>
>>> >>
>>> >> library(scales)
>>> >>
>>> >> # load data:
>>> >> log <- data.frame(Date =
>>> >>
>>c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2
>>> >> 013
>>> >> /06/05","2013/06/07"),
>>> >>  Quantity = c(9,1,15,4,5,17,18))
>>> >>
>>> >>
>>> >> # convert date variable from factor to date format:
>>> >> log$Date <- as.Date(log$Date,
>>> >>  "%Y/%m/%d") # tabulate all the options here
>>> >> str(log)
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> Manu.
>>> >
>>> > ________________________________
>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>jsou
>>> ur?eny pouze jeho adres?t?m.
>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>kopie
>>> vyma?te ze sv?ho syst?mu.
>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>tento
>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>> >
>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>smlouvy,
>>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>>nab?dky ze
>>> strany p??jemce s dodatkem ?i odchylkou.
>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>v?slovn?m
>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>>zastoupen?
>>> zn?m?.
>>> >
>>> > This e-mail and any documents attached to it may be confidential
>>and are
>>> intended only for its intended recipients.
>>> > If you received this e-mail by mistake, please immediately inform
>>its
>>> sender. Delete the contents of this e-mail with all attachments and
>>its copies
>>> from your system.
>>> > If you are not the intended recipient of this e-mail, you are not
>>authorized
>>> to use, disseminate, copy or disclose this e-mail in any manner.
>>> > The sender of this e-mail shall not be liable for any possible
>>damage caused
>>> by modifications of the e-mail or by delay with transfer of the
>>email.
>>> >
>>> > In case that this e-mail forms part of business dealings:
>>> > - the sender reserves the right to end negotiations about entering
>>into a
>>> contract in any time, for any reason, and without stating any
>>reasoning.
>>> > - if the e-mail contains an offer, the recipient is entitled to
>>immediately
>>> accept such offer; The sender of this e-mail (offer) excludes any
>>acceptance
>>> of the offer on the part of the recipient containing any amendment or
>>> variation.
>>> > - the sender insists on that the respective contract is concluded
>>only upon
>>> an express mutual agreement on all its aspects.
>>> > - the sender of this e-mail informs that he/she is not authorized
>>to enter
>>> into any contracts on behalf of the company except for cases in which
>>he/she
>>> is expressly authorized to do so in writing, and such authorization
>>or power of
>>> attorney is submitted to the recipient or the person represented by
>>the
>>> recipient, or the existence of such authorization is known to the
>>recipient of
>>> the person represented by the recipient.
>>> >
>>> >
>>> >
>>> > --
>>> >
>>> >
>>> > Thanks,
>>> > Manohar Reddy P
>>> > +91-9705302062.
>>> >
>>> > ________________________________
>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>jsou
>>> ur?eny pouze jeho adres?t?m.
>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>kopie
>>> vyma?te ze sv?ho syst?mu.
>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>tento
>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>> >
>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>smlouvy,
>>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>>nab?dky ze
>>> strany p??jemce s dodatkem ?i odchylkou.
>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>v?slovn?m
>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>>zastoupen?
>>> zn?m?.
>>> >
>>> > This e-mail and any documents attached to it may be confidential
>>and are
>>> intended only for its intended recipients.
>>> > If you received this e-mail by mistake, please immediately inform
>>its
>>> sender. Delete the contents of this e-mail with all attachments and
>>its copies
>>> from your system.
>>> > If you are not the intended recipient of this e-mail, you are not
>>authorized
>>> to use, disseminate, copy or disclose this e-mail in any manner.
>>> > The sender of this e-mail shall not be liable for any possible
>>damage caused
>>> by modifications of the e-mail or by delay with transfer of the
>>email.
>>> >
>>> > In case that this e-mail forms part of business dealings:
>>> > - the sender reserves the right to end negotiations about entering
>>into a
>>> contract in any time, for any reason, and without stating any
>>reasoning.
>>> > - if the e-mail contains an offer, the recipient is entitled to
>>immediately
>>> accept such offer; The sender of this e-mail (offer) excludes any
>>acceptance
>>> of the offer on the part of the recipient containing any amendment or
>>> variation.
>>> > - the sender insists on that the respective contract is concluded
>>only upon
>>> an express mutual agreement on all its aspects.
>>> > - the sender of this e-mail informs that he/she is not authorized
>>to enter
>>> into any contracts on behalf of the company except for cases in which
>>he/she
>>> is expressly authorized to do so in writing, and such authorization
>>or power of
>>> attorney is submitted to the recipient or the person represented by
>>the
>>> recipient, or the existence of such authorization is known to the
>>recipient of
>>> the person represented by the recipient.
>>> >
>>> >     [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
>>2000
>>> Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>________________________________
>>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>ur?eny pouze jeho adres?t?m.
>>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>kopie vyma?te ze sv?ho syst?mu.
>>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>
>>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>>ze strany p??jemce s dodatkem ?i odchylkou.
>>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>>zn?m?.
>>
>>This e-mail and any documents attached to it may be confidential and
>>are intended only for its intended recipients.
>>If you received this e-mail by mistake, please immediately inform its
>>sender. Delete the contents of this e-mail with all attachments and its
>>copies from your system.
>>If you are not the intended recipient of this e-mail, you are not
>>authorized to use, disseminate, copy or disclose this e-mail in any
>>manner.
>>The sender of this e-mail shall not be liable for any possible damage
>>caused by modifications of the e-mail or by delay with transfer of the
>>email.
>>
>>In case that this e-mail forms part of business dealings:
>>- the sender reserves the right to end negotiations about entering into
>>a contract in any time, for any reason, and without stating any
>>reasoning.
>>- if the e-mail contains an offer, the recipient is entitled to
>>immediately accept such offer; The sender of this e-mail (offer)
>>excludes any acceptance of the offer on the part of the recipient
>>containing any amendment or variation.
>>- the sender insists on that the respective contract is concluded only
>>upon an express mutual agreement on all its aspects.
>>- the sender of this e-mail informs that he/she is not authorized to
>>enter into any contracts on behalf of the company except for cases in
>>which he/she is expressly authorized to do so in writing, and such
>>authorization or power of attorney is submitted to the recipient or the
>>person represented by the recipient, or the existence of such
>>authorization is known to the recipient of the person represented by
>>the recipient.
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From petr.pikal at precheza.cz  Fri Sep 16 17:15:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Sep 2016 15:15:29 +0000
Subject: [R] Query to find minimum value in a matrix in R
In-Reply-To: <00612011-683F-458C-BAD9-5BB46BD42044@gmail.com>
References: <00612011-683F-458C-BAD9-5BB46BD42044@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D3E9@SRVEXCHMBX.precheza.cz>

Hi

you can follow logic of functions by using debug and see how they operate by inspecting objects evaluated within functions.

See
?debug

However it seems to me that your functions are quite complicated. If I understand correctly, they compute minimum value of upper part of matrix. If I am correct, this function does the same, is shorter, more understandable and extensible.

min.upper <- function(x) {
mm <- min(x[upper.tri(x)])
x[lower.tri(x)] <- NA
ind <- which(x==mm, arr.ind=TRUE)
c(mm, ind)
}

mat <- structure(c(0, 5, 9, 13, 5, 0, 10, 14, 9, 10, 0, 15, 13, 14,
15, 0), .Dim = c(4L, 4L), .Dimnames = list(NULL, c("col1", "col2",
"col3", "col4")))
min.upper(mat)
[1] 5 1 2

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of susmita T
> Sent: Friday, September 16, 2016 2:09 PM
> To: r-help at r-project.org
> Subject: [R] Query to find minimum value in a matrix in R
>
> Hi,
> Good Morning! I am new to R and finding difficulty in understanding the
> code. Since few days I am stuck at single line of code which I am unable to
> understand.
> Though there may be number of logics to find min value. As a new beginner I
> am following a book and as it has the following code
>
> mind<-function(d)
> {
>       n<-nrow(d)
>       dd<-cbind(d,1:n)
>       wmins<-apply(dd[-n,],1,imin)
>       i<-which.min(wmins[2,])
>       j<-wmins[1,i]
>       return(c(d[i,j],i,j))
> }
> imin<-function(x)
> {
>       lx<-length(x)
>       i<-x[lx]
>       j<-which.min(x[(i+1):(lx-1)])
>       k<-i+j
>       return(c(k,x[k]))
> }
>
> So when executed this with mind(below matrix) I get
> 0     12      13      8       20
> 12    0       15      28      88
> 13    15      0       6       9
> 8     28      6       0       33
> 20    88      9       33      0
> the answer as 6 , row 3 column 4
>
> Due to the symmetry of the matrix , the skipping of the early part of row is
> done by using expression (x[(i+1):(lx-1)])..(which is in red color in the code
> shown above). I am unable to understand the line in red code and how it is
> implemented in the line 5(i.e wins)?(shown in pink color in the code above I
> have done necessary homework to understand but still finding it hard to get
> it. Please someone help.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Fri Sep 16 17:38:07 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 16 Sep 2016 17:38:07 +0200
Subject: [R] stfrtime function not returning proper results through
	sqldf package in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
Message-ID: <D691506D-2CF9-4B5E-8406-8F9B9B847E3B@gmail.com>


On 16 Sep 2016, at 15:23 , PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi Peter
> 
> The devil is in detail
> 
> Data from OP had different format and was transferred to Date object by as.Date, which results in incorrect values (and NA if not transferred)
> df <- data.frame(Date = c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02",
> "2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
> df$Date<-as.Date(df$Date)
> cbind(df, sqldf("select strftime( '%m', Date) from df"))
> 

To be fair, he actually used as.Date(...., "%Y/%m/%d"), so the values were in fact correct. The issue lay in the conversion to integer.

I can't figure out how those integers are interpreted, though:

> df <- data.frame(date=c(0,1000,2000))
> cbind(df, sqldf("select strftime( '%Y-%m-%d', date) from df"))
  date strftime( '%Y-%m-%d', date)
1    0                  -471-11-24
2 1000                  -471-08-20
3 2000                  -470-05-16

so the Epoch is nothing sensible and negative years are more than a thousand days??


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From manu.reddy52 at gmail.com  Fri Sep 16 18:14:50 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 16 Sep 2016 21:44:50 +0530
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <D691506D-2CF9-4B5E-8406-8F9B9B847E3B@gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
	<D691506D-2CF9-4B5E-8406-8F9B9B847E3B@gmail.com>
Message-ID: <CADG9u0DjQ8WuxnXFEB-TUNQjzYq+244cZuDny2eXPY6Uo0qHvQ@mail.gmail.com>

First of all I would like to say thanks to everyone for sharing valuable
information, now I can able to do that if date column datatype is ?Factor?
but by default the date column datatype is ?POSIXct? in R ,so whenever I
want apply stfrtime function with sqldf package ,do I need to convert the
date datatype to factor ??? or is there any alternative  way?



Manu.

On Fri, Sep 16, 2016 at 9:08 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 16 Sep 2016, at 15:23 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi Peter
> >
> > The devil is in detail
> >
> > Data from OP had different format and was transferred to Date object by
> as.Date, which results in incorrect values (and NA if not transferred)
> > df <- data.frame(Date = c("2013/05/25","2013/05/28","
> 2013/05/31","2013/06/01","2013/06/02",
> > "2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
> > df$Date<-as.Date(df$Date)
> > cbind(df, sqldf("select strftime( '%m', Date) from df"))
> >
>
> To be fair, he actually used as.Date(...., "%Y/%m/%d"), so the values were
> in fact correct. The issue lay in the conversion to integer.
>
> I can't figure out how those integers are interpreted, though:
>
> > df <- data.frame(date=c(0,1000,2000))
> > cbind(df, sqldf("select strftime( '%Y-%m-%d', date) from df"))
>   date strftime( '%Y-%m-%d', date)
> 1    0                  -471-11-24
> 2 1000                  -471-08-20
> 3 2000                  -470-05-16
>
> so the Epoch is nothing sensible and negative years are more than a
> thousand days??
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>


-- 


Thanks,
Manohar Reddy P
+91-9705302062.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Sep 16 18:17:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 16 Sep 2016 09:17:09 -0700 (PDT)
Subject: [R] stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <CAP01uRkcz8L6swwjgpK87cvXf7=OGdjzE1w3vX9p-fqCx-uYVA@mail.gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D2C2@SRVEXCHMBX.precheza.cz>
	<CADG9u0AvBYQirNbb6Y5qJzZHn7O5pMXjf_MYqhdaDw+mhPxe6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D355@SRVEXCHMBX.precheza.cz>
	<D00F36C7-5AB3-4E21-BC8B-DA924F16F5E8@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D39A@SRVEXCHMBX.precheza.cz>
	<5A89F065-5E1B-4360-8767-8E7E7C8EC633@dcn.davis.ca.us>
	<CAP01uRkcz8L6swwjgpK87cvXf7=OGdjzE1w3vX9p-fqCx-uYVA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609160843360.21894@pedal.dcn.davis.ca.us>

Yes, some of my info was outdated and misleading. :)

However, after I RTFM [1] it becomes clear that the strftime function 
being invoked in the SQL statement has completely different parameters 
(both ordering and interpretation) and behavior than the strftime function 
in R, and that is the primary issue affecting the original question.

> library(sqldf)
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
Loading required package: DBI
> Sys.setenv( TZ="GMT" )
> log <- data.frame( DateC = c( "2013/05/25", "2013/05/28", "2013/05/31","2013/06/01"
+                             , "2013/06/02", "2013/06/05", "2013/06/07" )
+                  , Quantity = c( 9, 1, 15, 4, 5, 17, 18 )
+                  , stringsAsFactors = FALSE
+                  )
> log$Date <- as.Date( log$DateC, format="%Y/%m/%d" )
> log$DateS <- as.character( log$Date, format="%Y-%m-%d" )
> str( log )
'data.frame':   7 obs. of  4 variables:
  $ DateC   : chr  "2013/05/25" "2013/05/28" "2013/05/31" "2013/06/01" ...
  $ Quantity: num  9 1 15 4 5 17 18
  $ Date    : Date, format: "2013-05-25" "2013-05-28" ...
  $ DateS   : chr  "2013-05-25" "2013-05-28" "2013-05-31" "2013-06-01" ...
> # SQLite treatment of standard date string format converts to 
> # astronomical Julian Day
> sqldf( "select strftime( '%J', '1970-01-01' )" )
Loading required package: tcltk
   strftime( '%J', '1970-01-01' )
1                      2440587.5
> # SQLite strftime function can understand strings or julian day
> # SQLite does not know 'Date' column is being stored by sqldf as days 
> # since 1970-01-01
> sqldf( "select Date, Date AS DateN, strftime( '%Y-%m-%d', Date+2440587.5 ) AS DateJC, Date+2440587.5 AS DateJN from log", method=c( "Date", "numeric", "character", "numeric" ) )
         Date DateN     DateJC  DateJN
1 2013-05-25 15850 2013-05-25 2456438
2 2013-05-28 15853 2013-05-28 2456441
3 2013-05-31 15856 2013-05-31 2456444
4 2013-06-01 15857 2013-06-01 2456445
5 2013-06-02 15858 2013-06-02 2456446
6 2013-06-05 15861 2013-06-05 2456449
7 2013-06-07 15863 2013-06-07 2456451
> # So, to group by month using month computed in SQLite, have to convert 
> # to JD
> sqldf( "select strftime( '%m', Date+2440587.5 ) AS Month, sum(Quantity) AS SumOfQuantity from log group by Month" )
   Month SumOfQuantity
1    05            25
2    06            44
>
> # alternatively, figure out the month in R first
> log$Month <- strftime( log$Date, format="%m" )
> sqldf( "select Month, sum(Quantity) AS SumOfQuantity from log group by Month" )
   Month SumOfQuantity
1    05            25
2    06            44

---
[1] https://www.sqlite.org/lang_datefunc.html

On Fri, 16 Sep 2016, Gabor Grothendieck wrote:

> To be precise it's SQLite that does not have date and time data types.
> If you use an sqldf backend such as H2 that does have such types then
> sqldf will pass them as such.  In the case of R's "Date" class such
> objects are passed to SQLite as numbers since that is what SQLite can
> understand but they are passed as dates to H2 (and other backends if
> they have a date type).
>
> Also note that after sqldf passes a date to SQLite as a number then
> when SQLite passes it back to sqldf then sqldf  knows that it was
> originally a date (due to the column name being the same) and coerces
> it to Date class again.  In the example below sqldf passed the number
> of days to 2000-01-01 since the UNIX epoch to SQLite.  SQLite then
> processed it and passed it back as a number again. Then sqldf realized
> that it was originally a Date because the column name is still d and
> the original column d was of "Date" class and so coerces the number
> from SQLite to Date.  There are a limited number of circumstances
> where this heuristic works but they are sufficient that it's often
> transparent even though SQLite has no date and time types.
>
>> library(sqldf)
>> DF <- data.frame(d = as.Date("2000-01-01"))
>> sqldf("select d+1 as d from DF") # return next day
>           d
> 1 2000-01-02
>
> At the same time iif you really need to do serious date processing on
> the SQL side it's much easier with an sqldf backend such as H2 that
> actually supports date and time types and no heuristic is needed by
> sqldf and no user workarounds on the R side are needed.
>
>
> On Fri, Sep 16, 2016 at 10:15 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> SQLite only understands certain fundamental data types, and neither Date nor POSIXct types are among them. They get stored as their internal numeric representations.
>>
>> The internal numeric representations of Date and POSIXct are incompatible. You are sending Dates to SQLite and trying to then interpret it as POSIXct by handing that numeric to strftime.
>>
>> Note that within R the Date and POSIXct types are made sort-of compatible by internal checking of class attributes that are not stored in SQLite. They are still only sort-of compatible because Date has no concept of time zone and always assumes GMT rather than local time when being converted.
>>
>> I recommend retrieving the stored Date value as a Date value into R so that strftime can recognize how to interpret it. If you need to handle time as well as date you may find that converting to character first before converting to POSIXct with an appropriate time zone behaves with least surprises.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 16, 2016 6:23:48 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>> Hi Peter
>>>
>>> The devil is in detail
>>>
>>> Data from OP had different format and was transferred to Date object by
>>> as.Date, which results in incorrect values (and NA if not transferred)
>>> df <- data.frame(Date =
>>> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02",
>>> "2013/06/05","2013/06/07"), Quantity = c(9,1,15,4,5,17,18))
>>> df$Date<-as.Date(df$Date)
>>> cbind(df, sqldf("select strftime( '%m', Date) from df"))
>>>
>>> Data formatted according to your example transferred to Date object by
>>> as data, again incorrect result
>>> df2 <- data.frame(Date =
>>> c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>>> "2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>>> df2$Date<-as.Date(df2$Date)
>>> cbind(df2, sqldf("select strftime( '%m', Date) from df2"))
>>>
>>> Data formatted according to your example but **not** changed to Dates,
>>> correct result
>>> df3 <- data.frame(Date =
>>> c("2013-05-25","2013-05-28","2013-05-31","2013-06-01","2013-06-02",
>>> "2013-06-05","2013-06-07"), Quantity = c(9,1,15,4,5,17,18))
>>> cbind(df3, sqldf("select strftime( '%m', Date) from df3"))
>>>
>>> so sqldf is a bit peculiar about required input values and does not
>>> know how to handle Date objects.
>>>
>>> Cheers
>>> Petr
>>>
>>>
>>>> -----Original Message-----
>>>> From: peter dalgaard [mailto:pdalgd at gmail.com]
>>>> Sent: Friday, September 16, 2016 2:45 PM
>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>>> Cc: Manohar Reddy <manu.reddy52 at gmail.com>; R-help <r-help at r-
>>>> project.org>
>>>> Subject: Re: [R] stfrtime function not returning proper results
>>> through sqldf
>>>> package in R
>>>>
>>>> Presumably, sqldf does not know about Date object so passes an
>>> integer that
>>>> gets interpreted as who knows what...
>>>>
>>>> This seems to work:
>>>>
>>>>> df <- data.frame(date=as.character(Sys.Date()+seq(0,180,,10)))
>>>>> cbind(df, sqldf("select strftime( '%m', date) from df"))
>>>>          date strftime( '%m', date)
>>>> 1  2016-09-16                    09
>>>> 2  2016-10-06                    10
>>>> 3  2016-10-26                    10
>>>> 4  2016-11-15                    11
>>>> 5  2016-12-05                    12
>>>> 6  2016-12-25                    12
>>>> 7  2017-01-14                    01
>>>> 8  2017-02-03                    02
>>>> 9  2017-02-23                    02
>>>> 10 2017-03-15                    03
>>>>
>>>> -pd
>>>>
>>>>
>>>>
>>>> On 16 Sep 2016, at 13:48 , PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> Most probably there is some syntactic suger how to correctly
>>> formulate sql
>>>> query.
>>>>>
>>>>>> sqldf('select Date, strftime("Date", "%m") from log')
>>>>>        Date strftime("Date", "%m")
>>>>> 1 2013-05-25                   <NA>
>>>>> 2 2013-05-28                   <NA>
>>>>> 3 2013-05-31                   <NA>
>>>>> 4 2013-06-01                   <NA>
>>>>> 5 2013-06-02                   <NA>
>>>>> 6 2013-06-05                   <NA>
>>>>> 7 2013-06-07                   <NA>
>>>>>> sqldf('select Date, format("Date", "%m") from log')
>>>>> Error in sqliteSendQuery(con, statement, bind.data) :
>>>>>  error in statement: no such function: format
>>>>>>
>>>>>
>>>>> format(sqldf("select Date from log"), "%m")
>>>>>
>>>>> This one however works.
>>>>>
>>>>> Cheers
>>>>> Petr
>>>>>
>>>>> From: Manohar Reddy [mailto:manu.reddy52 at gmail.com]
>>>>> Sent: Friday, September 16, 2016 11:55 AM
>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>>>> Cc: R-help <r-help at r-project.org>
>>>>> Subject: Re: [R] stfrtime function not returning proper results
>>>>> through sqldf package in R
>>>>>
>>>>>
>>>>> Hi Petr,
>>>>>
>>>>> Thanks, For me also it?s working fine when I directly used that
>>> function  but
>>>> when I call strftime function through sqldf package it?s returning NA
>>> values
>>>> (PFA) ,but my requirement is I need to do that only sqldf as I?m
>>> writing some
>>>> ?T sql ? queries against on the dataset.
>>>>>
>>>>> Manu.
>>>>>
>>>>> On Fri, Sep 16, 2016 at 12:56 PM, PIKAL Petr
>>>> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
>>>>> Hi
>>>>>
>>>>> Hm
>>>>>> format(log$Date, "%m")
>>>>> [1] "05" "05" "05" "06" "06" "06" "06"
>>>>>> strftime(log$Date, "%m")
>>>>> [1] "05" "05" "05" "06" "06" "06" "06"
>>>>>>
>>>>>
>>>>> works for me.
>>>>>
>>>>> Just a blind guess, is an object date somwhere in your environment?
>>>>>
>>>>> Cheers
>>>>> Petr
>>>>>
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: R-help
>>>>>>
>>> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.
>>>>>> org>] On Behalf Of Manohar Reddy
>>>>>> Sent: Friday, September 16, 2016 6:36 AM
>>>>>> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
>>>>>> Subject: [R] stfrtime function not returning proper results
>>> through
>>>>>> sqldf package in R
>>>>>>
>>>>>> Hi ,
>>>>>>
>>>>>>
>>>>>>
>>>>>>  I have data something looks like below (or PFA), but when I?m
>>>>>> extracting month  using *strftime*  function through *sqldf*
>>> library
>>>>>> ,it?s returning below results but it?s not returning exact results
>>>>>> ,it supposed to return 05,05,05,06,06,06.Can anyone please guide
>>> me
>>>>>> how to do that with
>>>>>> *strftime* function.
>>>>>>
>>>>>>
>>>>>>
>>>>>> Thanks in advance.
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quiries :
>>>>>>
>>>>>>
>>>>>> library(scales)
>>>>>>
>>>>>> # load data:
>>>>>> log <- data.frame(Date =
>>>>>>
>>> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2
>>>>>> 013
>>>>>> /06/05","2013/06/07"),
>>>>>>  Quantity = c(9,1,15,4,5,17,18))
>>>>>>
>>>>>>
>>>>>> # convert date variable from factor to date format:
>>>>>> log$Date <- as.Date(log$Date,
>>>>>>  "%Y/%m/%d") # tabulate all the options here
>>>>>> str(log)
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Manu.
>>>>>
>>>>> ________________________________
>>>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>> jsou
>>>> ur?eny pouze jeho adres?t?m.
>>>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie
>>>> vyma?te ze sv?ho syst?mu.
>>>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>> tento
>>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>>>>
>>>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> smlouvy,
>>>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>>> nab?dky ze
>>>> strany p??jemce s dodatkem ?i odchylkou.
>>>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> v?slovn?m
>>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>>> zastoupen?
>>>> zn?m?.
>>>>>
>>>>> This e-mail and any documents attached to it may be confidential
>>> and are
>>>> intended only for its intended recipients.
>>>>> If you received this e-mail by mistake, please immediately inform
>>> its
>>>> sender. Delete the contents of this e-mail with all attachments and
>>> its copies
>>>> from your system.
>>>>> If you are not the intended recipient of this e-mail, you are not
>>> authorized
>>>> to use, disseminate, copy or disclose this e-mail in any manner.
>>>>> The sender of this e-mail shall not be liable for any possible
>>> damage caused
>>>> by modifications of the e-mail or by delay with transfer of the
>>> email.
>>>>>
>>>>> In case that this e-mail forms part of business dealings:
>>>>> - the sender reserves the right to end negotiations about entering
>>> into a
>>>> contract in any time, for any reason, and without stating any
>>> reasoning.
>>>>> - if the e-mail contains an offer, the recipient is entitled to
>>> immediately
>>>> accept such offer; The sender of this e-mail (offer) excludes any
>>> acceptance
>>>> of the offer on the part of the recipient containing any amendment or
>>>> variation.
>>>>> - the sender insists on that the respective contract is concluded
>>> only upon
>>>> an express mutual agreement on all its aspects.
>>>>> - the sender of this e-mail informs that he/she is not authorized
>>> to enter
>>>> into any contracts on behalf of the company except for cases in which
>>> he/she
>>>> is expressly authorized to do so in writing, and such authorization
>>> or power of
>>>> attorney is submitted to the recipient or the person represented by
>>> the
>>>> recipient, or the existence of such authorization is known to the
>>> recipient of
>>>> the person represented by the recipient.
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>>
>>>>>
>>>>> Thanks,
>>>>> Manohar Reddy P
>>>>> +91-9705302062.
>>>>>
>>>>> ________________________________
>>>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>> jsou
>>>> ur?eny pouze jeho adres?t?m.
>>>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie
>>>> vyma?te ze sv?ho syst?mu.
>>>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>> tento
>>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>>>>
>>>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> smlouvy,
>>>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>>> nab?dky ze
>>>> strany p??jemce s dodatkem ?i odchylkou.
>>>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> v?slovn?m
>>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>>> zastoupen?
>>>> zn?m?.
>>>>>
>>>>> This e-mail and any documents attached to it may be confidential
>>> and are
>>>> intended only for its intended recipients.
>>>>> If you received this e-mail by mistake, please immediately inform
>>> its
>>>> sender. Delete the contents of this e-mail with all attachments and
>>> its copies
>>>> from your system.
>>>>> If you are not the intended recipient of this e-mail, you are not
>>> authorized
>>>> to use, disseminate, copy or disclose this e-mail in any manner.
>>>>> The sender of this e-mail shall not be liable for any possible
>>> damage caused
>>>> by modifications of the e-mail or by delay with transfer of the
>>> email.
>>>>>
>>>>> In case that this e-mail forms part of business dealings:
>>>>> - the sender reserves the right to end negotiations about entering
>>> into a
>>>> contract in any time, for any reason, and without stating any
>>> reasoning.
>>>>> - if the e-mail contains an offer, the recipient is entitled to
>>> immediately
>>>> accept such offer; The sender of this e-mail (offer) excludes any
>>> acceptance
>>>> of the offer on the part of the recipient containing any amendment or
>>>> variation.
>>>>> - the sender insists on that the respective contract is concluded
>>> only upon
>>>> an express mutual agreement on all its aspects.
>>>>> - the sender of this e-mail informs that he/she is not authorized
>>> to enter
>>>> into any contracts on behalf of the company except for cases in which
>>> he/she
>>>> is expressly authorized to do so in writing, and such authorization
>>> or power of
>>>> attorney is submitted to the recipient or the person represented by
>>> the
>>>> recipient, or the existence of such authorization is known to the
>>> recipient of
>>>> the person represented by the recipient.
>>>>>
>>>>>     [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
>>> 2000
>>>> Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Office: A 4.23
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>> ________________________________
>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>> ur?eny pouze jeho adres?t?m.
>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie vyma?te ze sv?ho syst?mu.
>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>>
>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>>> ze strany p??jemce s dodatkem ?i odchylkou.
>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>>> zn?m?.
>>>
>>> This e-mail and any documents attached to it may be confidential and
>>> are intended only for its intended recipients.
>>> If you received this e-mail by mistake, please immediately inform its
>>> sender. Delete the contents of this e-mail with all attachments and its
>>> copies from your system.
>>> If you are not the intended recipient of this e-mail, you are not
>>> authorized to use, disseminate, copy or disclose this e-mail in any
>>> manner.
>>> The sender of this e-mail shall not be liable for any possible damage
>>> caused by modifications of the e-mail or by delay with transfer of the
>>> email.
>>>
>>> In case that this e-mail forms part of business dealings:
>>> - the sender reserves the right to end negotiations about entering into
>>> a contract in any time, for any reason, and without stating any
>>> reasoning.
>>> - if the e-mail contains an offer, the recipient is entitled to
>>> immediately accept such offer; The sender of this e-mail (offer)
>>> excludes any acceptance of the offer on the part of the recipient
>>> containing any amendment or variation.
>>> - the sender insists on that the respective contract is concluded only
>>> upon an express mutual agreement on all its aspects.
>>> - the sender of this e-mail informs that he/she is not authorized to
>>> enter into any contracts on behalf of the company except for cases in
>>> which he/she is expressly authorized to do so in writing, and such
>>> authorization or power of attorney is submitted to the recipient or the
>>> person represented by the recipient, or the existence of such
>>> authorization is known to the recipient of the person represented by
>>> the recipient.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ggrothendieck at gmail.com  Fri Sep 16 18:21:35 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Sep 2016 12:21:35 -0400
Subject: [R] Fwd: stfrtime function not returning proper results through
 sqldf package in R
In-Reply-To: <CAP01uR=o_Q2pE8XJ2E+5S4WrDtHWnqnCa0Uxgk9p8Wtxr6Tkxw@mail.gmail.com>
References: <CADG9u0BFRPB1ufYSFqpQ_gfW4-qS3f2=GBWJ883dv7nB_384GA@mail.gmail.com>
	<CAP01uR=o_Q2pE8XJ2E+5S4WrDtHWnqnCa0Uxgk9p8Wtxr6Tkxw@mail.gmail.com>
Message-ID: <CAP01uR=Ej0uThO9nsYt1FgHRH7Wa3URNUx7uy-K-+S05f+NzWQ@mail.gmail.com>

1. Convert the date from R's origin to the origin used by SQLite's
strftime function and then be sure you are using the correct SQLite
strftime syntax:

    library(sqldf)
    sqldf("select strftime('%m', Date + 2440588.5) month from log")

2. Alternately use the H2 backend which actually supports dates unlike
SQLite which only supports functions that interpret certain numbers
and character strings as dates.

    library(RH2) # if RH2 is loaded sqldf will default to the H2 database
    library(sqldf)
    sqldf("select month(Date) from log")

Note that the first time you use sqldf with RH2 in a session it will
load java which is time consuming but after that it should run ok.

Note: See

1. the sqldf home page which has more info on dates and times:
https://github.com/ggrothendieck/sqldf

2. the sqldf help page:
?sqldf

3. the SQLite date and time function page which explains SQLite's
strftime function
https://www.sqlite.org/lang_datefunc.html

4. the H2 documentation:
http://www.h2database.com

On Fri, Sep 16, 2016 at 12:35 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> Hi ,
>
>
>
>   I have data something looks like below (or PFA), but when I?m extracting
> month  using *strftime*  function through *sqldf* library ,it?s returning
> below results but it?s not returning exact results ,it supposed to return
>  05,05,05,06,06,06.Can anyone please guide me how to do that with *strftime*
> function.
>
>
>
> Thanks in advance.
>
>
>
> Quiries :
>
>
> library(scales)
>
> # load data:
> log <- data.frame(Date =
> c("2013/05/25","2013/05/28","2013/05/31","2013/06/01","2013/06/02","2013/06/05","2013/06/07"),
>   Quantity = c(9,1,15,4,5,17,18))
>
>
> # convert date variable from factor to date format:
> log$Date <- as.Date(log$Date,
>   "%Y/%m/%d") # tabulate all the options here
> str(log)
>
>
>
>
>
>
>
> Manu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From aanchalsharma833 at gmail.com  Fri Sep 16 19:28:35 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Fri, 16 Sep 2016 13:28:35 -0400
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture
	model)
In-Reply-To: <CAF8bMcbAN-p3-2++udaRtx0_iK-4MmxSYH12sSdLJCD6VaF3_Q@mail.gmail.com>
References: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
	<956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>
	<CAFp0Li0nmnDt9hHi6KPFDpFWeG3_ddbAgHQmKM8jz7v6L7OwOA@mail.gmail.com>
	<CAF8bMcbAN-p3-2++udaRtx0_iK-4MmxSYH12sSdLJCD6VaF3_Q@mail.gmail.com>
Message-ID: <CAFp0Li0LWFv4o1Ah1gxyvSjUBnqGGUgE-=2qmQMUBTHpW=01tg@mail.gmail.com>

Data has no negative values. Values range from 0.001 to 1.01.
Following is the summary, in case that helps:

 Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 0.0010  0.8126  0.8536  0.8464  0.8888  1.0180

SD: 0.07489977

Any clue?



On Thu, Sep 15, 2016 at 10:32 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Does the data contain non-positive values?
>
> > out <- mixtools::gammamixEM(as.numeric(0:100), lambda = c(1, 1, 1)/3,
> verb = TRUE)
> iteration = 1  log-lik diff = NaN  log-lik = NaN
> Error in while (diff > epsilon && iter < maxit) { :
>   missing value where TRUE/FALSE needed
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Sep 15, 2016 at 3:04 PM, Aanchal Sharma <
> aanchalsharma833 at gmail.com> wrote:
>
>> I am using a function gammamixEM where it does it by default. I do not
>> have
>> the option to change it.
>> Conceptually, what can make the algorithm not able to calculate likelihood
>> value at all (and hence log-lik=Nan)? Is there sth wrong with the data?
>> Under what conditions does it happen?
>>
>> On Wed, Sep 14, 2016 at 8:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> >
>> wrote:
>>
>> > On 14/09/2016 4:46 PM, Aanchal Sharma wrote:
>> >
>> >> Hi,
>> >>
>> >> I am trying to fit Gamma mixture model to my data (residual values
>> >> obtained
>> >> after fitting Generalized linear Model) using gammamixEM. It is part of
>> >> the
>> >> script which does it for multiple datasets in loop. The code is running
>> >> fine for some datasets but it terminates for some giving following
>> error:
>> >>
>> >> " iteration = 1  log-lik diff = NaN  log-lik = NaN
>> >> Error in while (diff > epsilon && iter < maxit) { :
>> >>   missing value where TRUE/FALSE needed"
>> >>
>> >> Seems like EM is not able to calculate log-lik value (NaN) at the first
>> >> iteration itself. any idea why that can happen?
>> >> It works fine for the other genes in the loop. Tried looking for
>> >> difference
>> >> in the inputs, but could not come up with anything striking.
>> >>
>> >>
>> > THere are lots of ways to get NaN in numerical calculations.   A common
>> > one if you are using log() to calculate log likelihoods is that rounding
>> > error gives you a negative likelihood, and then log(lik) comes out to
>> NaN.
>> >
>> > You just need to look really closely at each step of your calculations.
>> > Avoid using log(); use the functions that build it in (e.g. instead of
>> > log(dnorm(x)), use dnorm(x, log = TRUE)).
>> >
>> > Duncan Murdoch
>> >
>> >
>>
>>
>> --
>> Anchal Sharma, PhD
>> Postdoctoral Fellow
>> 195, Little Albany street,
>> Cancer Institute of New Jersey
>> Rutgers University
>> NJ-08901
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Sep 16 20:23:08 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 16 Sep 2016 11:23:08 -0700
Subject: [R] NaN Log-lik value in EM algorithm (fitting Gamma mixture
	model)
In-Reply-To: <CAFp0Li0LWFv4o1Ah1gxyvSjUBnqGGUgE-=2qmQMUBTHpW=01tg@mail.gmail.com>
References: <CAFp0Li11VFEM+gi_gXTGLB6ebO_XXiHrWQGaR_pxETSZjL2P_Q@mail.gmail.com>
	<956496c5-82f9-7ee2-75e8-56c5b47bd512@gmail.com>
	<CAFp0Li0nmnDt9hHi6KPFDpFWeG3_ddbAgHQmKM8jz7v6L7OwOA@mail.gmail.com>
	<CAF8bMcbAN-p3-2++udaRtx0_iK-4MmxSYH12sSdLJCD6VaF3_Q@mail.gmail.com>
	<CAFp0Li0LWFv4o1Ah1gxyvSjUBnqGGUgE-=2qmQMUBTHpW=01tg@mail.gmail.com>
Message-ID: <CAF8bMcY5jqzjkaWq0t3SpW0Kz1Vjujc=rtk5EQaa93rhzXK-8g@mail.gmail.com>

You should report the issue to the author/maintainer of the mixtools
package.  gammamixEM can get into this situation when the data is not an
obvious mixture so it has a hard time coming up with a good starting point
for the coefficient estimates.  E.g.,

> out <- mixtools::gammamixEM(rep(c(0.0001, 0.8126, .8536, .8888,
1.0180),c(1,45,150,45,1)), lambda = c(1, 1, 1)/3)
Note: Choosing new starting values.
Note: Choosing new starting values.
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
2: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
3: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
4: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
> out <- mixtools::gammamixEM(rep(c(0.0001, 0.8126, .8536, .8888,
1.0180),c(1,45,150,45,1)), lambda = c(1, 1, 1)/3)
Note: Choosing new starting values.
Note: Choosing new starting values.
Note: Choosing new starting values.
Note: Choosing new starting values.
Note: Choosing new starting values.
Note: Choosing new starting values.
Note: Choosing new starting values.
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed
In addition: There were 14 warnings (use warnings() to see them)
> out <- mixtools::gammamixEM(rep(c(0.0001, 0.8126, .8536, .8888,
1.0180),c(1,45,150,45,1)), lambda = c(1, 1, 1)/3, alpha=c(.4, .9))
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
2: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
3: In dgamma(x, shape = alpha[j], scale = beta[j]) : NaNs produced
> out <- mixtools::gammamixEM(rep(c(0.0001, 0.8126, .8536, .8888,
1.0180),c(1,45,150,45,1)), lambda = c(1, 1, 1)/3, alpha=c(.4, .9),
beta=c(1,1))
Error in while (diff > epsilon && iter < maxit) { :
  missing value where TRUE/FALSE needed

In the meantime, use tryCatch() or try() so your loop over all genes can do
all the other genes and return some sort of special value where the
estimation procedure fails.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 16, 2016 at 10:28 AM, Aanchal Sharma <aanchalsharma833 at gmail.com
> wrote:

> Data has no negative values. Values range from 0.001 to 1.01.
> Following is the summary, in case that helps:
>
>  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  0.0010  0.8126  0.8536  0.8464  0.8888  1.0180
>
> SD: 0.07489977
>
> Any clue?
>
>
>
> On Thu, Sep 15, 2016 at 10:32 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> Does the data contain non-positive values?
>>
>> > out <- mixtools::gammamixEM(as.numeric(0:100), lambda = c(1, 1, 1)/3,
>> verb = TRUE)
>> iteration = 1  log-lik diff = NaN  log-lik = NaN
>> Error in while (diff > epsilon && iter < maxit) { :
>>   missing value where TRUE/FALSE needed
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Sep 15, 2016 at 3:04 PM, Aanchal Sharma <
>> aanchalsharma833 at gmail.com> wrote:
>>
>>> I am using a function gammamixEM where it does it by default. I do not
>>> have
>>> the option to change it.
>>> Conceptually, what can make the algorithm not able to calculate
>>> likelihood
>>> value at all (and hence log-lik=Nan)? Is there sth wrong with the data?
>>> Under what conditions does it happen?
>>>
>>> On Wed, Sep 14, 2016 at 8:04 PM, Duncan Murdoch <
>>> murdoch.duncan at gmail.com>
>>> wrote:
>>>
>>> > On 14/09/2016 4:46 PM, Aanchal Sharma wrote:
>>> >
>>> >> Hi,
>>> >>
>>> >> I am trying to fit Gamma mixture model to my data (residual values
>>> >> obtained
>>> >> after fitting Generalized linear Model) using gammamixEM. It is part
>>> of
>>> >> the
>>> >> script which does it for multiple datasets in loop. The code is
>>> running
>>> >> fine for some datasets but it terminates for some giving following
>>> error:
>>> >>
>>> >> " iteration = 1  log-lik diff = NaN  log-lik = NaN
>>> >> Error in while (diff > epsilon && iter < maxit) { :
>>> >>   missing value where TRUE/FALSE needed"
>>> >>
>>> >> Seems like EM is not able to calculate log-lik value (NaN) at the
>>> first
>>> >> iteration itself. any idea why that can happen?
>>> >> It works fine for the other genes in the loop. Tried looking for
>>> >> difference
>>> >> in the inputs, but could not come up with anything striking.
>>> >>
>>> >>
>>> > THere are lots of ways to get NaN in numerical calculations.   A common
>>> > one if you are using log() to calculate log likelihoods is that
>>> rounding
>>> > error gives you a negative likelihood, and then log(lik) comes out to
>>> NaN.
>>> >
>>> > You just need to look really closely at each step of your calculations.
>>> > Avoid using log(); use the functions that build it in (e.g. instead of
>>> > log(dnorm(x)), use dnorm(x, log = TRUE)).
>>> >
>>> > Duncan Murdoch
>>> >
>>> >
>>>
>>>
>>> --
>>> Anchal Sharma, PhD
>>> Postdoctoral Fellow
>>> 195, Little Albany street,
>>> Cancer Institute of New Jersey
>>> Rutgers University
>>> NJ-08901
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> Anchal Sharma, PhD
> Postdoctoral Fellow
> 195, Little Albany street,
> Cancer Institute of New Jersey
> Rutgers University
> NJ-08901
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Sat Sep 17 00:43:03 2016
From: miaojpm at gmail.com (John)
Date: Fri, 16 Sep 2016 15:43:03 -0700
Subject: [R] ggplot2: geom_segment does not produce the color I desire?
Message-ID: <CABcx46AJsBAHQSqdT41SLQ5ft6MYVzB2t=2WFxLD7ZO2fYmDvg@mail.gmail.com>

Hi,

   I have a dataset "test". I try to produce a "green" arrow but it gives a
"red" arrow (as attached). Could someone tell me how I can fix it? Thanks,

> test
        date    co       y1       y2
5 2011-11-28 green 196.6559 1.600267
> dput(test)
structure(list(date = structure(15306, class = "Date"), co = "green",
    y1 = 196.655872, y2 = 1.600267), .Names = c("date", "co",
"y1", "y2"), class = "data.frame", row.names = 5L)
> ggplot()+    geom_segment(mapping = aes(x = as.Date(test[,"date"]), y =
y1, xend = as.Date(test[,"date"]), yend = y2, color=co), data=test,
arrow=arrow())
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test_plot1609.pdf
Type: application/pdf
Size: 4609 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160916/1ac3dd1e/attachment.pdf>

From erich.neuwirth at univie.ac.at  Sat Sep 17 08:06:07 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sat, 17 Sep 2016 08:06:07 +0200
Subject: [R] ggplot2: geom_segment does not produce the color I desire?
In-Reply-To: <CABcx46AJsBAHQSqdT41SLQ5ft6MYVzB2t=2WFxLD7ZO2fYmDvg@mail.gmail.com>
References: <CABcx46AJsBAHQSqdT41SLQ5ft6MYVzB2t=2WFxLD7ZO2fYmDvg@mail.gmail.com>
Message-ID: <1FFC3217-549C-4EBC-95FF-2FDA24754D87@univie.ac.at>

Here are 2 solutions to you problem:

If you only want to use one color (for possibly many arrows),
this will work:

ggplot()+geom_segment(mapping = aes(x = as.Date(test[,"date"]),
                                    y =y1,
                                    xend = as.Date(test[,"date"]),
                                    yend = y2), color="green", data=testdf,
                      arrow=arrow())


if you use a variable to colors different items differently,
you are using a mapping.
If you want to override ggplot?s default mapping, you set the palette explicitly:

ggplot()+geom_segment(mapping = aes(x = as.Date(test[,"date"]),
                                    y =y1,
                                    xend = as.Date(test[,"date"]),
                                    yend = y2, color=co), data=testdf,
                                    arrow=arrow()) +
      scale_color_manual(values=list(green="green"))


> On Sep 17, 2016, at 00:43, John <miaojpm at gmail.com> wrote:
> 
>> 
>> test
>        date    co       y1       y2
> 5 2011-11-28 green 196.6559 1.600267
>> dput(test)
> structure(list(date = structure(15306, class = "Date"), co = "green",
>    y1 = 196.655872, y2 = 1.600267), .Names = c("date", "co",
> "y1", "y2"), class = "data.frame", row.names = 5L)
>> ggplot()+    geom_segment(mapping = aes(x = as.Date(test[,"date"]), y =
> y1, xend = as.Date(test[,"date"]), yend = y2, color=co), data=test,
> arrow=arrow())
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160917/1174e7cd/attachment.bin>

From farzana.akbari at stu-mail.um.ac.ir  Fri Sep 16 15:45:03 2016
From: farzana.akbari at stu-mail.um.ac.ir (farzana.akbari)
Date: Fri, 16 Sep 2016 18:15:03 +0430
Subject: [R] brms error
Message-ID: <96191c7249b7aa571267a2a58b77abc5@stu.um.ac.ir>

 

?IN THE NAME OF GOD?   

  HI DEAR 

 I AM A M.SC. STUDENT OF ACCOUNTING IN FERDOWSI UNIVERSITY OF MASHHAD
AND I WANT TO USE BRMS PACKAGE FOR BAYSIAN MULTILEVEL ANALYSIS FOR MY
RESEARCH 

 I INSTALL RSTAN AND RTOOLS AND BRMS BUT I CANNOT SOLVE THIS PROBLEM OF
(ERROR). 

 I AM SOMEWHAT NEW IN R AND I DO NOT KNOW WHAT SHOULD I DO?! 

data("kidney") 

fit1 <- brm(formula = time | cens(censored) ~ age * sex + disease + (1 +
age|patient), data = kidney, family = lognormal(), prior =
c(set_prior("normal(0,5)", class = "b"), set_prior("cauchy(0,2)", class
= "sd"), set_prior("lkj(2)", class = "cor")), warmup = 1000, iter =
2000, chains = 4, control = list(adapt_delta = 0.95)) 

 Error in compileCode(f, code, language = language, verbose = verbose) :
Compilation ERROR, function(s)/method(s) not created!
C:/Rtools/mingw_64/lib/gcc/x86_64-w64-mingw32/4.9.3/include/tmmintrin.h:
In function
'run':C:/Rtools/mingw_64/lib/gcc/x86_64-w64-mingw32/4.9.3/include/tmmintrin.h:188:32:
error: '__builtin_ia32_palignr128' needs isa option -m32 -mssse3
(__v2di)__Y, __N * 8);
^C:/Rtools/mingw_64/lib/gcc/x86_64-w64-mingw32/4.9.3/include/tmmintrin.h:188:32:
error: '__builtin_ia32_palignr128' needs isa option -m32 -mssse3
(__v2di)__Y, __N * 8); ^lto-wrapper: C:\Rtools\mingw_64\bin\g++.exe
returned 1 exit
statusC:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
lto-wrapper failedcollect2.exe: error: ld returned 1 exit status 

I HAVE SENT YOU DETAILS IN ATTACH FILE. IF YOU HELP ME, I WILL BE VERY
TANKFUL  

 BEST REGARDS 

FARZANA AKBARI 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: BRMS.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160916/b87d6424/attachment.txt>

From dominik.schneider at colorado.edu  Fri Sep 16 18:10:49 2016
From: dominik.schneider at colorado.edu (Dominik Schneider)
Date: Fri, 16 Sep 2016 10:10:49 -0600
Subject: [R] glmnet vignette question
Message-ID: <CAF1jk_nQTZAr-2GJA6rM=KtBL=khdnjO=xMS_Hj6cJb3-+oM+Q@mail.gmail.com>

I'm doing some linear modeling and am new to the ridge/lasso/elasticnet
procedures. In my case I have N>>p (p=15 based on variables used in past
literature and some physical reasoning) so my understanding is that I
should be interested in ridge regression to avoid the issue of
multicollinearity of predictors.  Lasso is useful when p>>N.

In the past I have performed step-wise regression with stepAIC in both
directions to choose my variables and then used VIF to determine if any of
these variables are correlated. My understanding is that ridge regression
is a more robust approach for this workflow.

Reading the glmnet_beta vignette, it describes the alpha parameter where
alpha=1 is a lasso regression and alpha=0 is a ridge regression. Farther
down the authors suggest a 10 fold validation to determine an alpha value
and based on the plots shown, say that alpha=1 does the best here. However,
all the models look like they approach the same MSE and alpha=0 is the
lowest curve for all lambda (but maybe this second point doesn't matter?).
With my data I get a very similar looking set of curves so I'm trying to
decide if I should stick with alpha=1 instead of alpha=0. Is there a way to
extract MSE for a lambda, e.g. lambda.1se?

Any advice or clarification is appreciated. Thanks.
Dominik

	[[alternative HTML version deleted]]


From dominik.schneider at colorado.edu  Fri Sep 16 18:33:53 2016
From: dominik.schneider at colorado.edu (Dominik Schneider)
Date: Fri, 16 Sep 2016 10:33:53 -0600
Subject: [R] glmnet vignette question
In-Reply-To: <CAF1jk_nQTZAr-2GJA6rM=KtBL=khdnjO=xMS_Hj6cJb3-+oM+Q@mail.gmail.com>
References: <CAF1jk_nQTZAr-2GJA6rM=KtBL=khdnjO=xMS_Hj6cJb3-+oM+Q@mail.gmail.com>
Message-ID: <CAF1jk_m1rRQzdmSvi5aY0C+asOFYcs2poGm3UhygJwE6vRmC9w@mail.gmail.com>

> Is there a way to extract MSE for a lambda, e.g. lambda.1se?
nevermind this specific question. it's now obvious. However my overall
question stands.

On Fri, Sep 16, 2016 at 10:10 AM, Dominik Schneider <
dominik.schneider at colorado.edu> wrote:

> I'm doing some linear modeling and am new to the ridge/lasso/elasticnet
> procedures. In my case I have N>>p (p=15 based on variables used in past
> literature and some physical reasoning) so my understanding is that I
> should be interested in ridge regression to avoid the issue of
> multicollinearity of predictors.  Lasso is useful when p>>N.
>
> In the past I have performed step-wise regression with stepAIC in both
> directions to choose my variables and then used VIF to determine if any of
> these variables are correlated. My understanding is that ridge regression
> is a more robust approach for this workflow.
>
> Reading the glmnet_beta vignette, it describes the alpha parameter where
> alpha=1 is a lasso regression and alpha=0 is a ridge regression. Farther
> down the authors suggest a 10 fold validation to determine an alpha value
> and based on the plots shown, say that alpha=1 does the best here. However,
> all the models look like they approach the same MSE and alpha=0 is the
> lowest curve for all lambda (but maybe this second point doesn't matter?).
> With my data I get a very similar looking set of curves so I'm trying to
> decide if I should stick with alpha=1 instead of alpha=0. Is there a way to
> extract MSE for a lambda, e.g. lambda.1se?
>
> Any advice or clarification is appreciated. Thanks.
> Dominik
>
>

	[[alternative HTML version deleted]]


From anuragsharma532 at gmail.com  Fri Sep 16 19:24:55 2016
From: anuragsharma532 at gmail.com (ANURAG SHARMA)
Date: Fri, 16 Sep 2016 10:24:55 -0700
Subject: [R] Request for R code
Message-ID: <CAF76zB8djNY_-8zpt+LtTwZHMVqo0NZrQ=ynmciri4Shei99+Q@mail.gmail.com>

Heyy I want to apply LASSO method in AFT model. So can you guys please help
me by sending R code for that.

Regards
Anurag Sharma
Mphil Statistics
Faculty of Mathematical Science
Ph no-+91-8285468733

	[[alternative HTML version deleted]]


From mikeyoung83 at gmail.com  Fri Sep 16 19:59:23 2016
From: mikeyoung83 at gmail.com (Michael Young)
Date: Fri, 16 Sep 2016 10:59:23 -0700
Subject: [R] Help modifying "aheatmap" or find a new heatmap package
Message-ID: <CAED8d0yWJqM1w7Bh0tCi4VYDy0Vp_xKxRMyOgt+Rss4kr_vv1g@mail.gmail.com>

I am currently using "aheatmap" which is generating heatmaps based on
Pearson correlation.  My data consists of RPKM values for genes from 2
groups.  Each group has about 70 samples.

Is there anyway that I can modify "aheatmap" so that it generates heat maps
based on the actual input values (RPKM) and not Pearson correlation?  I
want the heatmap to show high heat for higher RPKM and cold heat for lower
RPKM.

If not, is there a package out there that can do this?

Michael

	[[alternative HTML version deleted]]


From mikeyoung83 at gmail.com  Fri Sep 16 20:10:34 2016
From: mikeyoung83 at gmail.com (Michael Young)
Date: Fri, 16 Sep 2016 11:10:34 -0700
Subject: [R] Help modifying "aheatmap" or find a new heatmap package
Message-ID: <CAED8d0zB47Lgapo5HbN4N_mFqhOjAAhGj8KdBS3Oi5W=dr_Uxw@mail.gmail.com>

I am currently using "aheatmap" which is generating heatmaps based on
Pearson correlation.  My data consists of RPKM values for genes from 2
groups.  Each group has about 70 samples.

Is there anyway that I can modify "aheatmap" so that it generates heat maps
based on the actual input values (RPKM) and not Pearson correlation?  I
want the heatmap to show high heat for higher RPKM and cold heat for lower
RPKM.
If not, is there a package out there that can do this?

Michael

	[[alternative HTML version deleted]]


From dosc3612 at colorado.edu  Sat Sep 17 05:52:05 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Fri, 16 Sep 2016 21:52:05 -0600
Subject: [R] ggplot2: geom_segment does not produce the color I desire?
In-Reply-To: <CABcx46AJsBAHQSqdT41SLQ5ft6MYVzB2t=2WFxLD7ZO2fYmDvg@mail.gmail.com>
References: <CABcx46AJsBAHQSqdT41SLQ5ft6MYVzB2t=2WFxLD7ZO2fYmDvg@mail.gmail.com>
Message-ID: <CAF1jk_=fu1J70E0uL7PGDUzenNaWKY711iEC3GYRTGJmO00B=w@mail.gmail.com>

ggplot will assign, or map if you will, the color based on the default
color scale when color is specified with the mapping argument such as
mapping = aes(color=...). You have two options:

1. if you want the color of your arrow to be based on a column in your
data, then manually scale the color with
scale_colour_manual(values=c('green')):
ggplot()+
geom_segment(mapping = aes(x = as.Date(test[,"date"]), y = y1, xend =
as.Date(test[,"date"]), yend = y2, color=co), data=test, arrow=arrow())+
scale_colour_manual(values=c('green'))

2. If the color doesn't need to be "mapped" based on your data, then you
can simply specify colour *outside* the aes() like this:
ggplot()+
geom_segment(mapping = aes(x = as.Date(test[,"date"]), y = y1, xend =
as.Date(test[,"date"]), yend = y2), color='green', data=test, arrow=arrow())

keep in mind that only the first option will produce a legend, if you need
that.



On Friday, September 16, 2016, John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I have a dataset "test". I try to produce a "green" arrow but it gives a
> "red" arrow (as attached). Could someone tell me how I can fix it? Thanks,
>
> > test
>         date    co       y1       y2
> 5 2011-11-28 green 196.6559 1.600267
> > dput(test)
> structure(list(date = structure(15306, class = "Date"), co = "green",
>     y1 = 196.655872, y2 = 1.600267), .Names = c("date", "co",
> "y1", "y2"), class = "data.frame", row.names = 5L)
> > ggplot()+    geom_segment(mapping = aes(x = as.Date(test[,"date"]), y =
> y1, xend = as.Date(test[,"date"]), yend = y2, color=co), data=test,
> arrow=arrow())
> >
>

	[[alternative HTML version deleted]]


From phiroc at free.fr  Sat Sep 17 14:05:58 2016
From: phiroc at free.fr (Philippe de Rochambeau)
Date: Sat, 17 Sep 2016 14:05:58 +0200
Subject: [R] Accelerating binRead
Message-ID: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>

Hello,
the following function, which stores numeric values extracted from a binary file, into an R matrix, is very slow, especially when the said file is several MB in size.
Should I rewrite the function in inline C or in C/C++ using Rcpp? If the latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp newbie)?
Many thanks.
Best regards,
phiroc


-------------

# inputPath is something like http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin>

PLTreader <- function(inputPath){
	URL <- file(inputPath, "rb")
	PLT <- matrix(nrow=0, ncol=6)
	compteurDePrints = 0
	compteurDeLignes <- 0
	maxiPrints = 5
	displayData <- FALSE
	while (TRUE) {
		periodIndex <- readBin(URL, integer(), size=4, n=1, endian="little") # int (4 bytes)
		eventId <- readBin(URL, integer(), size=4, n=1, endian="little") # int (4 bytes)
		dword1 <- readBin(URL, integer(), size=4, signed=FALSE, n=1, endian="little") # int
		dword2 <- readBin(URL, integer(), size=4, signed=FALSE, n=1, endian="little") # int
		if (dword1 < 0) {
			dword1 = dword1 + 2^32-1;
		}
		eventDate = (dword2*2^32 + dword1)/1000
		repNum <- readBin(URL, integer(), size=2, n=1, endian="little") # short (2 bytes)
		exp <- readBin(URL, numeric(), size=4, n=1, endian="little") # float (4 bytes, strangely enough, would expect 8)
		loss <- readBin(URL, numeric(), size=4, n=1, endian="little") # float (4 bytes)
		PLT <- rbind(PLT, c(periodIndex, eventId, eventDate, repNum, exp, loss))
	} # end while
	return(PLT)
	close(URL)
}

----------------
	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Sat Sep 17 16:10:05 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Sat, 17 Sep 2016 17:10:05 +0300
Subject: [R] Accelerating binRead
In-Reply-To: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
Message-ID: <E75E6FFC-6DE9-4F3F-8DE4-B44E09CF3369@gmail.com>

I suspect that rbind is responsible. Use list and append instead of rbind. At the end, combine elements of list by do.call(?rbind?, list).

> On 17 Sep 2016, at 15:05, Philippe de Rochambeau <phiroc at free.fr> wrote:
> 
> Hello,
> the following function, which stores numeric values extracted from a binary file, into an R matrix, is very slow, especially when the said file is several MB in size.
> Should I rewrite the function in inline C or in C/C++ using Rcpp? If the latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp newbie)?
> Many thanks.
> Best regards,
> phiroc
> 
> 
> -------------
> 
> # inputPath is something like http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin>
> 
> PLTreader <- function(inputPath){
> 	URL <- file(inputPath, "rb")
> 	PLT <- matrix(nrow=0, ncol=6)
> 	compteurDePrints = 0
> 	compteurDeLignes <- 0
> 	maxiPrints = 5
> 	displayData <- FALSE
> 	while (TRUE) {
> 		periodIndex <- readBin(URL, integer(), size=4, n=1, endian="little") # int (4 bytes)
> 		eventId <- readBin(URL, integer(), size=4, n=1, endian="little") # int (4 bytes)
> 		dword1 <- readBin(URL, integer(), size=4, signed=FALSE, n=1, endian="little") # int
> 		dword2 <- readBin(URL, integer(), size=4, signed=FALSE, n=1, endian="little") # int
> 		if (dword1 < 0) {
> 			dword1 = dword1 + 2^32-1;
> 		}
> 		eventDate = (dword2*2^32 + dword1)/1000
> 		repNum <- readBin(URL, integer(), size=2, n=1, endian="little") # short (2 bytes)
> 		exp <- readBin(URL, numeric(), size=4, n=1, endian="little") # float (4 bytes, strangely enough, would expect 8)
> 		loss <- readBin(URL, numeric(), size=4, n=1, endian="little") # float (4 bytes)
> 		PLT <- rbind(PLT, c(periodIndex, eventId, eventDate, repNum, exp, loss))
> 	} # end while
> 	return(PLT)
> 	close(URL)
> }
> 
> ----------------
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abhinabaroy09 at gmail.com  Sat Sep 17 16:28:50 2016
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Sat, 17 Sep 2016 19:58:50 +0530
Subject: [R] Portfolio Optimization
Message-ID: <CANtKHPU3c2mdqmLE32Gpz1FARfN_w4s=2+FqE+8J9cGCSc0U9g@mail.gmail.com>

Hi,

Has anybody worked on portfolio optimization using Genetic Algorithm in R?

Could you please share the code and some references on this topic?

Really appreciate your help.

Thanks,
Abhinaba

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Sep 17 16:32:05 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 17 Sep 2016 07:32:05 -0700
Subject: [R] glmnet vignette question
In-Reply-To: <CAF1jk_m1rRQzdmSvi5aY0C+asOFYcs2poGm3UhygJwE6vRmC9w@mail.gmail.com>
References: <CAF1jk_nQTZAr-2GJA6rM=KtBL=khdnjO=xMS_Hj6cJb3-+oM+Q@mail.gmail.com>
	<CAF1jk_m1rRQzdmSvi5aY0C+asOFYcs2poGm3UhygJwE6vRmC9w@mail.gmail.com>
Message-ID: <CAGxFJbTuGK=Df1_RVworL8B5TWfVQt3npEbUBNV6O2=frKaa2g@mail.gmail.com>

You seem to be mainly asking for help with statistical methodology,
which is generally off topic for this list, which is about help with R
programming. I suggest you study the references given in the
vignette/package and/or post to a statistical list like
stats.stackexchange.com instead.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 16, 2016 at 9:33 AM, Dominik Schneider
<dominik.schneider at colorado.edu> wrote:
>> Is there a way to extract MSE for a lambda, e.g. lambda.1se?
> nevermind this specific question. it's now obvious. However my overall
> question stands.
>
> On Fri, Sep 16, 2016 at 10:10 AM, Dominik Schneider <
> dominik.schneider at colorado.edu> wrote:
>
>> I'm doing some linear modeling and am new to the ridge/lasso/elasticnet
>> procedures. In my case I have N>>p (p=15 based on variables used in past
>> literature and some physical reasoning) so my understanding is that I
>> should be interested in ridge regression to avoid the issue of
>> multicollinearity of predictors.  Lasso is useful when p>>N.
>>
>> In the past I have performed step-wise regression with stepAIC in both
>> directions to choose my variables and then used VIF to determine if any of
>> these variables are correlated. My understanding is that ridge regression
>> is a more robust approach for this workflow.
>>
>> Reading the glmnet_beta vignette, it describes the alpha parameter where
>> alpha=1 is a lasso regression and alpha=0 is a ridge regression. Farther
>> down the authors suggest a 10 fold validation to determine an alpha value
>> and based on the plots shown, say that alpha=1 does the best here. However,
>> all the models look like they approach the same MSE and alpha=0 is the
>> lowest curve for all lambda (but maybe this second point doesn't matter?).
>> With my data I get a very similar looking set of curves so I'm trying to
>> decide if I should stick with alpha=1 instead of alpha=0. Is there a way to
>> extract MSE for a lambda, e.g. lambda.1se?
>>
>> Any advice or clarification is appreciated. Thanks.
>> Dominik
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Sep 17 16:51:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Sep 2016 07:51:31 -0700
Subject: [R] Accelerating binRead
In-Reply-To: <E75E6FFC-6DE9-4F3F-8DE4-B44E09CF3369@gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<E75E6FFC-6DE9-4F3F-8DE4-B44E09CF3369@gmail.com>
Message-ID: <97EB174F-5991-4C46-A2B8-68E70254171C@dcn.davis.ca.us>

Appending to lists is only very slightly more efficient than incremental rbinding. Ideally you can figure out an upper bound for number of records, preallocate a data frame of that size, modify each element as you go in-place, and shrink the data frame once at the end as needed. If you cannot do that, you can append fixed size data frames and follow the same strategy in chunks with a single do.call/rbind at the end. 

Note that reproducible examples including example data often yield working code, while incomplete examples tend to yield handwaving descriptions like the above. 

I will note that any code placed after a return function is useless. I highly recommend avoiding the return function like the plague... use the expression-at-the-end-of-the-function method of returning.
-- 
Sent from my phone. Please excuse my brevity.

On September 17, 2016 7:10:05 AM PDT, Ismail SEZEN <sezenismail at gmail.com> wrote:
>I suspect that rbind is responsible. Use list and append instead of
>rbind. At the end, combine elements of list by do.call(?rbind?, list).
>
>> On 17 Sep 2016, at 15:05, Philippe de Rochambeau <phiroc at free.fr>
>wrote:
>> 
>> Hello,
>> the following function, which stores numeric values extracted from a
>binary file, into an R matrix, is very slow, especially when the said
>file is several MB in size.
>> Should I rewrite the function in inline C or in C/C++ using Rcpp? If
>the latter case is true, how do you ? readBin ?  in Rcpp (I?m a total
>Rcpp newbie)?
>> Many thanks.
>> Best regards,
>> phiroc
>> 
>> 
>> -------------
>> 
>> # inputPath is something like
>http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin
><http://myintranet/getData?pathToFile=/usr/lib/xxx/yyy/data.bin>
>> 
>> PLTreader <- function(inputPath){
>> 	URL <- file(inputPath, "rb")
>> 	PLT <- matrix(nrow=0, ncol=6)
>> 	compteurDePrints = 0
>> 	compteurDeLignes <- 0
>> 	maxiPrints = 5
>> 	displayData <- FALSE
>> 	while (TRUE) {
>> 		periodIndex <- readBin(URL, integer(), size=4, n=1,
>endian="little") # int (4 bytes)
>> 		eventId <- readBin(URL, integer(), size=4, n=1, endian="little") #
>int (4 bytes)
>> 		dword1 <- readBin(URL, integer(), size=4, signed=FALSE, n=1,
>endian="little") # int
>> 		dword2 <- readBin(URL, integer(), size=4, signed=FALSE, n=1,
>endian="little") # int
>> 		if (dword1 < 0) {
>> 			dword1 = dword1 + 2^32-1;
>> 		}
>> 		eventDate = (dword2*2^32 + dword1)/1000
>> 		repNum <- readBin(URL, integer(), size=2, n=1, endian="little") #
>short (2 bytes)
>> 		exp <- readBin(URL, numeric(), size=4, n=1, endian="little") #
>float (4 bytes, strangely enough, would expect 8)
>> 		loss <- readBin(URL, numeric(), size=4, n=1, endian="little") #
>float (4 bytes)
>> 		PLT <- rbind(PLT, c(periodIndex, eventId, eventDate, repNum, exp,
>loss))
>> 	} # end while
>> 	return(PLT)
>> 	close(URL)
>> }
>> 
>> ----------------
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Sep 17 17:00:07 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 17 Sep 2016 11:00:07 -0400
Subject: [R] Accelerating binRead
In-Reply-To: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
Message-ID: <CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>

Your example was not reproducible.  Also how do you "break" out of the
"while" loop?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr>
wrote:

> Hello,
> the following function, which stores numeric values extracted from a
> binary file, into an R matrix, is very slow, especially when the said file
> is several MB in size.
> Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
> newbie)?
> Many thanks.
> Best regards,
> phiroc
>
>
> -------------
>
> # inputPath is something like http://myintranet/getData?
> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?
> pathToFile=/usr/lib/xxx/yyy/data.bin>
>
> PLTreader <- function(inputPath){
>         URL <- file(inputPath, "rb")
>         PLT <- matrix(nrow=0, ncol=6)
>         compteurDePrints = 0
>         compteurDeLignes <- 0
>         maxiPrints = 5
>         displayData <- FALSE
>         while (TRUE) {
>                 periodIndex <- readBin(URL, integer(), size=4, n=1,
> endian="little") # int (4 bytes)
>                 eventId <- readBin(URL, integer(), size=4, n=1,
> endian="little") # int (4 bytes)
>                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
> n=1, endian="little") # int
>                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
> n=1, endian="little") # int
>                 if (dword1 < 0) {
>                         dword1 = dword1 + 2^32-1;
>                 }
>                 eventDate = (dword2*2^32 + dword1)/1000
>                 repNum <- readBin(URL, integer(), size=2, n=1,
> endian="little") # short (2 bytes)
>                 exp <- readBin(URL, numeric(), size=4, n=1,
> endian="little") # float (4 bytes, strangely enough, would expect 8)
>                 loss <- readBin(URL, numeric(), size=4, n=1,
> endian="little") # float (4 bytes)
>                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> repNum, exp, loss))
>         } # end while
>         return(PLT)
>         close(URL)
> }
>
> ----------------
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Sat Sep 17 17:04:20 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Sat, 17 Sep 2016 15:04:20 +0000
Subject: [R] Accelerating binRead
In-Reply-To: <CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
Message-ID: <CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>

I noticed same issue but didnt care much :)

On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com> wrote:

> Your example was not reproducible.  Also how do you "break" out of the
> "while" loop?
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr>
> wrote:
>
> > Hello,
> > the following function, which stores numeric values extracted from a
> > binary file, into an R matrix, is very slow, especially when the said
> file
> > is several MB in size.
> > Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
> > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
> > newbie)?
> > Many thanks.
> > Best regards,
> > phiroc
> >
> >
> > -------------
> >
> > # inputPath is something like http://myintranet/getData?
> > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?
> > pathToFile=/usr/lib/xxx/yyy/data.bin>
> >
> > PLTreader <- function(inputPath){
> >         URL <- file(inputPath, "rb")
> >         PLT <- matrix(nrow=0, ncol=6)
> >         compteurDePrints = 0
> >         compteurDeLignes <- 0
> >         maxiPrints = 5
> >         displayData <- FALSE
> >         while (TRUE) {
> >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
> > endian="little") # int (4 bytes)
> >                 eventId <- readBin(URL, integer(), size=4, n=1,
> > endian="little") # int (4 bytes)
> >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
> > n=1, endian="little") # int
> >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
> > n=1, endian="little") # int
> >                 if (dword1 < 0) {
> >                         dword1 = dword1 + 2^32-1;
> >                 }
> >                 eventDate = (dword2*2^32 + dword1)/1000
> >                 repNum <- readBin(URL, integer(), size=2, n=1,
> > endian="little") # short (2 bytes)
> >                 exp <- readBin(URL, numeric(), size=4, n=1,
> > endian="little") # float (4 bytes, strangely enough, would expect 8)
> >                 loss <- readBin(URL, numeric(), size=4, n=1,
> > endian="little") # float (4 bytes)
> >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> > repNum, exp, loss))
> >         } # end while
> >         return(PLT)
> >         close(URL)
> > }
> >
> > ----------------
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bob at rud.is  Sat Sep 17 17:09:23 2016
From: bob at rud.is (Bob Rudis)
Date: Sat, 17 Sep 2016 11:09:23 -0400
Subject: [R] Accelerating binRead
In-Reply-To: <CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
Message-ID: <CAA-FpKU3D+11jsRmOdffuKxZe2MjjsxNHd-Q6XP0qZ5KkEHecg@mail.gmail.com>

You should probably pick a forum ? here or SO :
http://stackoverflow.com/questions/39547398/faster-reading-of-binary-files-in-r
: - vs cross-post to all of them.

On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com>
wrote:

> I noticed same issue but didnt care much :)
>
> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com> wrote:
>
> > Your example was not reproducible.  Also how do you "break" out of the
> > "while" loop?
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> > On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr>
> > wrote:
> >
> > > Hello,
> > > the following function, which stores numeric values extracted from a
> > > binary file, into an R matrix, is very slow, especially when the said
> > file
> > > is several MB in size.
> > > Should I rewrite the function in inline C or in C/C++ using Rcpp? If
> the
> > > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
> > > newbie)?
> > > Many thanks.
> > > Best regards,
> > > phiroc
> > >
> > >
> > > -------------
> > >
> > > # inputPath is something like http://myintranet/getData?
> > > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?
> > > pathToFile=/usr/lib/xxx/yyy/data.bin>
> > >
> > > PLTreader <- function(inputPath){
> > >         URL <- file(inputPath, "rb")
> > >         PLT <- matrix(nrow=0, ncol=6)
> > >         compteurDePrints = 0
> > >         compteurDeLignes <- 0
> > >         maxiPrints = 5
> > >         displayData <- FALSE
> > >         while (TRUE) {
> > >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
> > > endian="little") # int (4 bytes)
> > >                 eventId <- readBin(URL, integer(), size=4, n=1,
> > > endian="little") # int (4 bytes)
> > >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
> > > n=1, endian="little") # int
> > >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
> > > n=1, endian="little") # int
> > >                 if (dword1 < 0) {
> > >                         dword1 = dword1 + 2^32-1;
> > >                 }
> > >                 eventDate = (dword2*2^32 + dword1)/1000
> > >                 repNum <- readBin(URL, integer(), size=2, n=1,
> > > endian="little") # short (2 bytes)
> > >                 exp <- readBin(URL, numeric(), size=4, n=1,
> > > endian="little") # float (4 bytes, strangely enough, would expect 8)
> > >                 loss <- readBin(URL, numeric(), size=4, n=1,
> > > endian="little") # float (4 bytes)
> > >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> > > repNum, exp, loss))
> > >         } # end while
> > >         return(PLT)
> > >         close(URL)
> > > }
> > >
> > > ----------------
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Sat Sep 17 17:28:06 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 17 Sep 2016 18:28:06 +0300
Subject: [R] separate commands by semicolon
In-Reply-To: <CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
Message-ID: <CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>

There is one minor problem with parse(): if any of the individual commands
has an error, the entire text will be parsed in a single error.

For example, in a normal R console:

> print(2); ls(
[1] 2
+

So first print(2) is executed, and only after the console expects the user
to continue the command from ls(
Parsing the same text:

> parse(text = "print(2); ls(")
Error in parse(text = "print(2); ls(") :
  <text>:2:0: unexpected end of input
1: print(2); ls(
   ^

What I would need is something to separate the two commands, irrespective
of their syntactical correctness:

[1] "print(2)" "ls("

I hope this explains the situation,
Adrian

On Thu, Sep 15, 2016 at 11:02 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:

> On Thu, Sep 15, 2016 at 10:28 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> The most reliable way to split such lines is with parse(text=x).
>> Regular expressions don't do well with context-free grammars.
>>
>
> Oh, that's right of course.
> > as.character(parse(text = x))
> [1] "foo <- \"3;4\""                    "bar <- \"don't ; use semicolons\""
>
> That was simple enough, thanks very much,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sat Sep 17 20:24:47 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 17 Sep 2016 14:24:47 -0400
Subject: [R] Accelerating binRead
In-Reply-To: <CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
Message-ID: <CAAxdm-48+5DyCVtU7nwWxZvQEUT3r-0mSSuaYsi_OaEG82vLRw@mail.gmail.com>

I would also suggest that you take a look at the 'pack' package which can
convert the binary input to the value you want.  Part of your performance
problems might be all the short reads that you are doing.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com>
wrote:

> I noticed same issue but didnt care much :)
>
> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com> wrote:
>
>> Your example was not reproducible.  Also how do you "break" out of the
>> "while" loop?
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr>
>> wrote:
>>
>> > Hello,
>> > the following function, which stores numeric values extracted from a
>> > binary file, into an R matrix, is very slow, especially when the said
>> file
>> > is several MB in size.
>> > Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>> > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>> > newbie)?
>> > Many thanks.
>> > Best regards,
>> > phiroc
>> >
>> >
>> > -------------
>> >
>> > # inputPath is something like http://myintranet/getData?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin>
>> >
>> > PLTreader <- function(inputPath){
>> >         URL <- file(inputPath, "rb")
>> >         PLT <- matrix(nrow=0, ncol=6)
>> >         compteurDePrints = 0
>> >         compteurDeLignes <- 0
>> >         maxiPrints = 5
>> >         displayData <- FALSE
>> >         while (TRUE) {
>> >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 eventId <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 if (dword1 < 0) {
>> >                         dword1 = dword1 + 2^32-1;
>> >                 }
>> >                 eventDate = (dword2*2^32 + dword1)/1000
>> >                 repNum <- readBin(URL, integer(), size=2, n=1,
>> > endian="little") # short (2 bytes)
>> >                 exp <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes, strangely enough, would expect 8)
>> >                 loss <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes)
>> >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>> > repNum, exp, loss))
>> >         } # end while
>> >         return(PLT)
>> >         close(URL)
>> > }
>> >
>> > ----------------
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sat Sep 17 20:38:23 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 17 Sep 2016 14:38:23 -0400
Subject: [R] Accelerating binRead
In-Reply-To: <CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
Message-ID: <CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>

Here is an example of how to do it:

x <- 1:10  # integer values
xf <- seq(1.0, 2, by = 0.1)  # floating point

setwd("d:/temp")

# create file to write to
output <- file('integer.bin', 'wb')
writeBin(x, output)  # write integer
writeBin(xf, output)  # write reals
close(output)


library(pack)
library(readr)

# read all the data at once
allbin <- read_file_raw('integer.bin')

# decode the data into a list
(result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com>
wrote:

> I noticed same issue but didnt care much :)
>
> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com> wrote:
>
>> Your example was not reproducible.  Also how do you "break" out of the
>> "while" loop?
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr>
>> wrote:
>>
>> > Hello,
>> > the following function, which stores numeric values extracted from a
>> > binary file, into an R matrix, is very slow, especially when the said
>> file
>> > is several MB in size.
>> > Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>> > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>> > newbie)?
>> > Many thanks.
>> > Best regards,
>> > phiroc
>> >
>> >
>> > -------------
>> >
>> > # inputPath is something like http://myintranet/getData?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin>
>> >
>> > PLTreader <- function(inputPath){
>> >         URL <- file(inputPath, "rb")
>> >         PLT <- matrix(nrow=0, ncol=6)
>> >         compteurDePrints = 0
>> >         compteurDeLignes <- 0
>> >         maxiPrints = 5
>> >         displayData <- FALSE
>> >         while (TRUE) {
>> >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 eventId <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 if (dword1 < 0) {
>> >                         dword1 = dword1 + 2^32-1;
>> >                 }
>> >                 eventDate = (dword2*2^32 + dword1)/1000
>> >                 repNum <- readBin(URL, integer(), size=2, n=1,
>> > endian="little") # short (2 bytes)
>> >                 exp <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes, strangely enough, would expect 8)
>> >                 loss <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes)
>> >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>> > repNum, exp, loss))
>> >         } # end while
>> >         return(PLT)
>> >         close(URL)
>> > }
>> >
>> > ----------------
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Sep 17 23:12:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Sep 2016 14:12:44 -0700
Subject: [R] separate commands by semicolon
In-Reply-To: <CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
	<CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
Message-ID: <10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>


> On Sep 17, 2016, at 8:28 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> 
> There is one minor problem with parse(): if any of the individual commands
> has an error, the entire text will be parsed in a single error.
> 
> For example, in a normal R console:
> 
>> print(2); ls(
> [1] 2
> +
> 
> So first print(2) is executed, and only after the console expects the user
> to continue the command from ls(
> Parsing the same text:
> 
>> parse(text = "print(2); ls(")
> Error in parse(text = "print(2); ls(") :
>  <text>:2:0: unexpected end of input
> 1: print(2); ls(
>   ^
> 
> What I would need is something to separate the two commands, irrespective
> of their syntactical correctness:
> 
> [1] "print(2)" "ls("
> 
> I hope this explains the situation,

Not entirely clear. If you were intending to just get character output then you could just use:

strsplit(txt, ";")

If you wanted parsing to an R expression to occur you could pass through sapply and get a full accounting of the syntactic deficit using `try`:

sapply(strsplit( "print(2); ls(" , ";")[[1]] , function(t) {try(parse(text=t))})
Error in parse(text = t) : <text>:2:0: unexpected end of input
1:  ls(
   ^
expression(`print(2)` = print(2), ` ls(` = "Error in parse(text = t) : <text>:2:0: unexpected end of input\n1:  ls(\n   ^\n")


> Adrian
> 
> On Thu, Sep 15, 2016 at 11:02 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> 
>> On Thu, Sep 15, 2016 at 10:28 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>> 
>>> The most reliable way to split such lines is with parse(text=x).
>>> Regular expressions don't do well with context-free grammars.
>>> 
>> 
>> Oh, that's right of course.
>>> as.character(parse(text = x))
>> [1] "foo <- \"3;4\""                    "bar <- \"don't ; use semicolons\""
>> 
>> That was simple enough, thanks very much,
>> Adrian
>> 
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>> 
> 
> 
> 
> -- 
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From peter.langfelder at gmail.com  Sat Sep 17 23:34:00 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sat, 17 Sep 2016 14:34:00 -0700
Subject: [R] separate commands by semicolon
In-Reply-To: <10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
	<CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
	<10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>
Message-ID: <CA+hbrhXWDPmL6=_xY_jADmR2kK03Y9EnFAW597-B0AsFi8or3A@mail.gmail.com>

On Sat, Sep 17, 2016 at 2:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> Not entirely clear. If you were intending to just get character output then you could just use:
>
> strsplit(txt, ";")
>
> If you wanted parsing to an R expression to occur you could pass through sapply and get a full accounting of the syntactic deficit using `try`:
>
> sapply(strsplit( "print(2); ls(" , ";")[[1]] , function(t) {try(parse(text=t))})
> Error in parse(text = t) : <text>:2:0: unexpected end of input
> 1:  ls(
>    ^
> expression(`print(2)` = print(2), ` ls(` = "Error in parse(text = t) : <text>:2:0: unexpected end of input\n1:  ls(\n   ^\n")
>

You would want to avoid splitting within character strings
(print(";")) and in comments (print(2); ls() # This prints 2; then
lists...) The comment char could also appear in a character string,
where it does not mean the start of a comment...

Not sure how to accomplish that using strsplit (or in general using
just regular expressions).

Peter


From drjimlemon at gmail.com  Sun Sep 18 01:33:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 18 Sep 2016 09:33:56 +1000
Subject: [R] Help modifying "aheatmap" or find a new heatmap package
In-Reply-To: <CAED8d0zB47Lgapo5HbN4N_mFqhOjAAhGj8KdBS3Oi5W=dr_Uxw@mail.gmail.com>
References: <CAED8d0zB47Lgapo5HbN4N_mFqhOjAAhGj8KdBS3Oi5W=dr_Uxw@mail.gmail.com>
Message-ID: <CA+8X3fVPwyNi2sNVJ_59HeaOdrJ0A1=XtRTYzmOHgLODoYKNQQ@mail.gmail.com>

Hi Michael,
Maybe color2D.matplot (plotrix). Have a look at the examples.

Jim


On Sat, Sep 17, 2016 at 4:10 AM, Michael Young <mikeyoung83 at gmail.com> wrote:
> I am currently using "aheatmap" which is generating heatmaps based on
> Pearson correlation.  My data consists of RPKM values for genes from 2
> groups.  Each group has about 70 samples.
>
> Is there anyway that I can modify "aheatmap" so that it generates heat maps
> based on the actual input values (RPKM) and not Pearson correlation?  I
> want the heatmap to show high heat for higher RPKM and cold heat for lower
> RPKM.
> If not, is there a package out there that can do this?
>
> Michael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Sun Sep 18 07:22:52 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 18 Sep 2016 05:22:52 +0000
Subject: [R] Help modifying "aheatmap" or find a new heatmap package
In-Reply-To: <CA+8X3fVPwyNi2sNVJ_59HeaOdrJ0A1=XtRTYzmOHgLODoYKNQQ@mail.gmail.com>
References: <CAED8d0zB47Lgapo5HbN4N_mFqhOjAAhGj8KdBS3Oi5W=dr_Uxw@mail.gmail.com>
	<CA+8X3fVPwyNi2sNVJ_59HeaOdrJ0A1=XtRTYzmOHgLODoYKNQQ@mail.gmail.com>
Message-ID: <CAKVAULP92-xJTbzODJCcOJ-TO=3JnxYZBAB6kyVmkLNKJ5UbzA@mail.gmail.com>

I am a huge fan of pheatmap and use it for all my heatmaps.

Alternatively you can use ggplot2 and geom_tile

Hth
Ulrik

Jim Lemon <drjimlemon at gmail.com> schrieb am So., 18. Sep. 2016 01:35:

> Hi Michael,
> Maybe color2D.matplot (plotrix). Have a look at the examples.
>
> Jim
>
>
> On Sat, Sep 17, 2016 at 4:10 AM, Michael Young <mikeyoung83 at gmail.com>
> wrote:
> > I am currently using "aheatmap" which is generating heatmaps based on
> > Pearson correlation.  My data consists of RPKM values for genes from 2
> > groups.  Each group has about 70 samples.
> >
> > Is there anyway that I can modify "aheatmap" so that it generates heat
> maps
> > based on the actual input values (RPKM) and not Pearson correlation?  I
> > want the heatmap to show high heat for higher RPKM and cold heat for
> lower
> > RPKM.
> > If not, is there a package out there that can do this?
> >
> > Michael
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phiroc at free.fr  Sat Sep 17 20:45:52 2016
From: phiroc at free.fr (Philippe de Rochambeau)
Date: Sat, 17 Sep 2016 20:45:52 +0200
Subject: [R] Accelerating binRead
In-Reply-To: <CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
Message-ID: <B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>

Hi Jim,
this is exactly the answer I was look for. Many thanks. I didn?t R had a pack function, as in PERL.
To answer your earlier question, I am trying to update legacy code to read a binary file with unknown size, over a network, slice up it into rows each containing an integer, an integer, a long, a short, a float and a float, and stuff the rows into a matrix.
Best regards,
Philippe

> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com> a ?crit :
> 
> Here is an example of how to do it:
> 
> x <- 1:10  # integer values
> xf <- seq(1.0, 2, by = 0.1)  # floating point
> 
> setwd("d:/temp")
> 
> # create file to write to
> output <- file('integer.bin', 'wb')
> writeBin(x, output)  # write integer
> writeBin(xf, output)  # write reals
> close(output)
> 
> 
> library(pack)
> library(readr)
> 
> # read all the data at once
> allbin <- read_file_raw('integer.bin')
> 
> # decode the data into a list
> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
> 
> 
> 
> 
> Jim Holtman
> Data Munger Guru
>  
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com <mailto:sezenismail at gmail.com>> wrote:
> I noticed same issue but didnt care much :)
> 
> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> wrote:
> Your example was not reproducible.  Also how do you "break" out of the
> "while" loop?
> 
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr <mailto:phiroc at free.fr>>
> wrote:
> 
> > Hello,
> > the following function, which stores numeric values extracted from a
> > binary file, into an R matrix, is very slow, especially when the said file
> > is several MB in size.
> > Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
> > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
> > newbie)?
> > Many thanks.
> > Best regards,
> > phiroc
> >
> >
> > -------------
> >
> > # inputPath is something like http://myintranet/getData <http://myintranet/getData>?
> > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <http://myintranet/getData>?
> > pathToFile=/usr/lib/xxx/yyy/data.bin>
> >
> > PLTreader <- function(inputPath){
> >         URL <- file(inputPath, "rb")
> >         PLT <- matrix(nrow=0, ncol=6)
> >         compteurDePrints = 0
> >         compteurDeLignes <- 0
> >         maxiPrints = 5
> >         displayData <- FALSE
> >         while (TRUE) {
> >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
> > endian="little") # int (4 bytes)
> >                 eventId <- readBin(URL, integer(), size=4, n=1,
> > endian="little") # int (4 bytes)
> >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
> > n=1, endian="little") # int
> >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
> > n=1, endian="little") # int
> >                 if (dword1 < 0) {
> >                         dword1 = dword1 + 2^32-1;
> >                 }
> >                 eventDate = (dword2*2^32 + dword1)/1000
> >                 repNum <- readBin(URL, integer(), size=2, n=1,
> > endian="little") # short (2 bytes)
> >                 exp <- readBin(URL, numeric(), size=4, n=1,
> > endian="little") # float (4 bytes, strangely enough, would expect 8)
> >                 loss <- readBin(URL, numeric(), size=4, n=1,
> > endian="little") # float (4 bytes)
> >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> > repNum, exp, loss))
> >         } # end while
> >         return(PLT)
> >         close(URL)
> > }
> >
> > ----------------
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/>
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From phiroc at free.fr  Sun Sep 18 09:35:55 2016
From: phiroc at free.fr (Philippe de Rochambeau)
Date: Sun, 18 Sep 2016 09:35:55 +0200
Subject: [R] Accelerating binRead
In-Reply-To: <B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
Message-ID: <EB8A1894-958D-4DD9-83A1-5E3ABE4E090F@free.fr>

The only difference between the below code and my program is that the former assumes that the file only contains one row of 10 ints + 10 floats , whereas my program doesn?t know in advance how many rows the file contains, unless it downloads it first and computes the potential number of rows based on its size.

> Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a ?crit :
> 
> Hi Jim,
> this is exactly the answer I was look for. Many thanks. I didn?t R had a pack function, as in PERL.
> To answer your earlier question, I am trying to update legacy code to read a binary file with unknown size, over a network, slice up it into rows each containing an integer, an integer, a long, a short, a float and a float, and stuff the rows into a matrix.
> Best regards,
> Philippe
> 
>> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> a ?crit :
>> 
>> Here is an example of how to do it:
>> 
>> x <- 1:10  # integer values
>> xf <- seq(1.0, 2, by = 0.1)  # floating point
>> 
>> setwd("d:/temp")
>> 
>> # create file to write to
>> output <- file('integer.bin', 'wb')
>> writeBin(x, output)  # write integer
>> writeBin(xf, output)  # write reals
>> close(output)
>> 
>> 
>> library(pack)
>> library(readr)
>> 
>> # read all the data at once
>> allbin <- read_file_raw('integer.bin')
>> 
>> # decode the data into a list
>> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
>> 
>> 
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>>  
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com <mailto:sezenismail at gmail.com>> wrote:
>> I noticed same issue but didnt care much :)
>> 
>> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> wrote:
>> Your example was not reproducible.  Also how do you "break" out of the
>> "while" loop?
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr <mailto:phiroc at free.fr>>
>> wrote:
>> 
>> > Hello,
>> > the following function, which stores numeric values extracted from a
>> > binary file, into an R matrix, is very slow, especially when the said file
>> > is several MB in size.
>> > Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>> > latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>> > newbie)?
>> > Many thanks.
>> > Best regards,
>> > phiroc
>> >
>> >
>> > -------------
>> >
>> > # inputPath is something like http://myintranet/getData <http://myintranet/getData>?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <http://myintranet/getData>?
>> > pathToFile=/usr/lib/xxx/yyy/data.bin>
>> >
>> > PLTreader <- function(inputPath){
>> >         URL <- file(inputPath, "rb")
>> >         PLT <- matrix(nrow=0, ncol=6)
>> >         compteurDePrints = 0
>> >         compteurDeLignes <- 0
>> >         maxiPrints = 5
>> >         displayData <- FALSE
>> >         while (TRUE) {
>> >                 periodIndex <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 eventId <- readBin(URL, integer(), size=4, n=1,
>> > endian="little") # int (4 bytes)
>> >                 dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>> > n=1, endian="little") # int
>> >                 if (dword1 < 0) {
>> >                         dword1 = dword1 + 2^32-1;
>> >                 }
>> >                 eventDate = (dword2*2^32 + dword1)/1000
>> >                 repNum <- readBin(URL, integer(), size=2, n=1,
>> > endian="little") # short (2 bytes)
>> >                 exp <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes, strangely enough, would expect 8)
>> >                 loss <- readBin(URL, numeric(), size=4, n=1,
>> > endian="little") # float (4 bytes)
>> >                 PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>> > repNum, exp, loss))
>> >         } # end while
>> >         return(PLT)
>> >         close(URL)
>> > }
>> >
>> > ----------------
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/>
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From phiroc at free.fr  Sun Sep 18 11:02:59 2016
From: phiroc at free.fr (Philippe de Rochambeau)
Date: Sun, 18 Sep 2016 11:02:59 +0200
Subject: [R] Accelerating binRead
In-Reply-To: <B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
Message-ID: <D563E423-2167-41DB-BC82-1502751BA507@free.fr>

Please find below code that attempts to read ints, longs and floats from a binary file (which is a simplification of my original program).
Please disregard the R inefficiencies, such as using rbind, for now.
I?ve also included Java code to generate the binary file.
The output shows that, at one point, anInt becomes undefined. Unfortunately, I couldn?t find the correct R function to determine whether inInt is undefined or not, as is.null, is.nan, and is.infinite don?t work.
Any help would be much appreciated.
Many thanks in advance.
Philippe

???????
[1] "anInt = 1"
[1] "is.null  FALSE"
[1] "is.nan  FALSE"
[1] "is.infinite  FALSE"
[1] "aLong = 2"
[1] "aFloat = 3.44440007209778"
[1] "--------------------------"
[1] "anInt = 2"
[1] "is.null  FALSE"
[1] "is.nan  FALSE"
[1] "is.infinite  FALSE"
[1] "aLong = 22"
[1] "aFloat = 13.4644002914429"
[1] "--------------------------"
[1] "anInt = 3"
[1] "is.null  FALSE"
[1] "is.nan  FALSE"
[1] "is.infinite  FALSE"
[1] "aLong = 55"
[1] "aFloat = 45.4444007873535"
[1] "--------------------------"
[1] "anInt = "
[1] "is.null  FALSE"
[1] "is.nan  "
[1] "is.infinite  "
[1] "aLong = "
[1] "aFloat = "
[1] "--------------------------"
     [,1]      [,2]      [,3]     
[1,] 1         2         3.4444   
[2,] 2         22        13.4644  
[3,] 3         55        45.4444  
[4,] Integer,0 Integer,0 Numeric,0
> 

-----------


?????????????????????

readFile <- function(inputPath) {
  URL <- file(inputPath, "rb")
  PLT <- matrix(nrow=0, ncol=3)
  counte <- 0
  max <- 4
  while (counte < max) {
    anInt <- readBin(con=URL, what=integer(), size=4, n=1, endian="big")
    print(paste("anInt =", anInt))
    #if (! (anInt == 0)) { print(paste("empty int")); break }
    print(paste("is.null ", is.null(anInt)))
    print(paste("is.nan ", is.nan(anInt)))
    print(paste("is.infinite ", is.infinite(anInt)))
    aLong <- readBin(URL, integer(), size=8, n=1, endian="big") 
    print(paste("aLong =", aLong))
    aFloat <- readBin(URL, numeric(), size=4, n=1, endian="big")
    print(paste("aFloat =", aFloat))
    print("--------------------------")
    PLT <- rbind(PLT, list(anInt, aLong, aFloat))
    counte <- counte + 1
  } # end while
  close(URL)
  PLT
}
fichier <- "/Users/philippe/Desktop/datatests/data0.bin"
PLT2 <- readFile(fichier)
print(PLT2)
?????????????????????

import java.io.*;

public class Main {
	
	Main() {
		writeData();
	}
	
	public static void main(String[] args) {
		new Main();
	}
	
	public void writeData() {
		
		final String path = "/Users/philippe/Desktop/datatests/data0.bin";
		
		DataOutputStream dos;
		try {
			dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(path)));
			// big endian write! ("high byte first") , see https://docs.oracle.com/javase/7/docs/api/java/io/DataOutputStream.html
			dos.writeInt(1);
			dos.writeLong(2L);
			dos.writeFloat(3.4444F);
			
			dos.writeInt(2);
			dos.writeLong(22L);
			dos.writeFloat(13.4644F);
			
			dos.writeInt(3);
			dos.writeLong(55L);
			dos.writeFloat(45.4444F);
			
			dos.close();
		} catch (FileNotFoundException e) {
			e.printStackTrace();
		} catch (IOException ioe) {
			ioe.printStackTrace();
		}
		
	}

}


?????????????????????






> Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a ?crit :
> 
> Hi Jim,
> this is exactly the answer I was look for. Many thanks. I didn?t R had a pack function, as in PERL.
> To answer your earlier question, I am trying to update legacy code to read a binary file with unknown size, over a network, slice up it into rows each containing an integer, an integer, a long, a short, a float and a float, and stuff the rows into a matrix.
> Best regards,
> Philippe
> 
>> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> a ?crit :
>> 
>> Here is an example of how to do it:
>> 
>> x <- 1:10  # integer values
>> xf <- seq(1.0, 2, by = 0.1)  # floating point
>> 
>> setwd("d:/temp")
>> 
>> # create file to write to
>> output <- file('integer.bin', 'wb')
>> writeBin(x, output)  # write integer
>> writeBin(xf, output)  # write reals
>> close(output)
>> 
>> 
>> library(pack)
>> library(readr)
>> 
>> # read all the data at once
>> allbin <- read_file_raw('integer.bin')
>> 
>> # decode the data into a list
>> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
>> 
>> 
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com <mailto:sezenismail at gmail.com><mailto:sezenismail at gmail.com <mailto:sezenismail at gmail.com>>> wrote:
>> I noticed same issue but didnt care much :)
>> 
>> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com> <mailto:jholtman at gmail.com <mailto:jholtman at gmail.com>>> wrote:
>> Your example was not reproducible.  Also how do you "break" out of the
>> "while" loop?
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr <mailto:phiroc at free.fr> <mailto:phiroc at free.fr <mailto:phiroc at free.fr>>>
>> wrote:
>> 
>>> Hello,
>>> the following function, which stores numeric values extracted from a
>>> binary file, into an R matrix, is very slow, especially when the said file
>>> is several MB in size.
>>> Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>>> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>>> newbie)?
>>> Many thanks.
>>> Best regards,
>>> phiroc
>>> 
>>> 
>>> -------------
>>> 
>>> # inputPath is something like http://myintranet/getData <http://myintranet/getData><http://myintranet/getData <http://myintranet/getData>>?
>>> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <http://myintranet/getData> <http://myintranet/getData <http://myintranet/getData>>?
>>> pathToFile=/usr/lib/xxx/yyy/data.bin>
>>> 
>>> PLTreader <- function(inputPath){
>>>        URL <- file(inputPath, "rb")
>>>        PLT <- matrix(nrow=0, ncol=6)
>>>        compteurDePrints = 0
>>>        compteurDeLignes <- 0
>>>        maxiPrints = 5
>>>        displayData <- FALSE
>>>        while (TRUE) {
>>>                periodIndex <- readBin(URL, integer(), size=4, n=1,
>>> endian="little") # int (4 bytes)
>>>                eventId <- readBin(URL, integer(), size=4, n=1,
>>> endian="little") # int (4 bytes)
>>>                dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>>> n=1, endian="little") # int
>>>                dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>>> n=1, endian="little") # int
>>>                if (dword1 < 0) {
>>>                        dword1 = dword1 + 2^32-1;
>>>                }
>>>                eventDate = (dword2*2^32 + dword1)/1000
>>>                repNum <- readBin(URL, integer(), size=2, n=1,
>>> endian="little") # short (2 bytes)
>>>                exp <- readBin(URL, numeric(), size=4, n=1,
>>> endian="little") # float (4 bytes, strangely enough, would expect 8)
>>>                loss <- readBin(URL, numeric(), size=4, n=1,
>>> endian="little") # float (4 bytes)
>>>                PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>>> repNum, exp, loss))
>>>        } # end while
>>>        return(PLT)
>>>        close(URL)
>>> }
>>> 
>>> ----------------
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>> PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/> <http://www.r-project.org/ <http://www.r-project.org/>>
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sun Sep 18 16:05:59 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 18 Sep 2016 14:05:59 +0000
Subject: [R] Accelerating binRead
In-Reply-To: <D563E423-2167-41DB-BC82-1502751BA507@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
	<D563E423-2167-41DB-BC82-1502751BA507@free.fr>
Message-ID: <CAAcGz9_BZmgHeHp5GnBNOd3N5eTDiJTLeS6r6WKgc-RjpEQDjA@mail.gmail.com>

On Sun, 18 Sep 2016, 19:04 Philippe de Rochambeau <phiroc at free.fr> wrote:

> Please find below code that attempts to read ints, longs and floats from a
> binary file (which is a simplification of my original program).
> Please disregard the R inefficiencies, such as using rbind, for now.
> I?ve also included Java code to generate the binary file.
> The output shows that, at one point, anInt becomes undefined.
> Unfortunately, I couldn?t find the correct R function to determine whether
> inInt is undefined or not, as is.null, is.nan, and is.infinite don?t work.
> Any help would be much appreciated.
> Many thanks in advance.
> Philippe
>
> ???????
> [1] "anInt = 1"
> [1] "is.null  FALSE"
> [1] "is.nan  FALSE"
> [1] "is.infinite  FALSE"
> [1] "aLong = 2"
> [1] "aFloat = 3.44440007209778"
> [1] "--------------------------"
> [1] "anInt = 2"
> [1] "is.null  FALSE"
> [1] "is.nan  FALSE"
> [1] "is.infinite  FALSE"
> [1] "aLong = 22"
> [1] "aFloat = 13.4644002914429"
> [1] "--------------------------"
> [1] "anInt = 3"
> [1] "is.null  FALSE"
> [1] "is.nan  FALSE"
> [1] "is.infinite  FALSE"
> [1] "aLong = 55"
> [1] "aFloat = 45.4444007873535"
> [1] "--------------------------"
> [1] "anInt = "
> [1] "is.null  FALSE"
> [1] "is.nan  "
> [1] "is.infinite  "
> [1] "aLong = "
> [1] "aFloat = "
> [1] "--------------------------"
>      [,1]      [,2]      [,3]
> [1,] 1         2         3.4444
> [2,] 2         22        13.4644
> [3,] 3         55        45.4444
> [4,] Integer,0 Integer,0 Numeric,0
> >
>
> -----------
>
>
> ?????????????????????
>
> readFile <- function(inputPath) {
>   URL <- file(inputPath, "rb")
>   PLT <- matrix(nrow=0, ncol=3)
>   counte <- 0
>   max <- 4
>   while (counte < max) {
>     anInt <- readBin(con=URL, what=integer(), size=4, n=1, endian="big")
>     print(paste("anInt =", anInt))
>     #if (! (anInt == 0)) { print(paste("empty int")); break }
>     print(paste("is.null ", is.null(anInt)))
>     print(paste("is.nan ", is.nan(anInt)))
>     print(paste("is.infinite ", is.infinite(anInt)))
>     aLong <- readBin(URL, integer(), size=8, n=1, endian="big")
>     print(paste("aLong =", aLong))
>     aFloat <- readBin(URL, numeric(), size=4, n=1, endian="big")
>     print(paste("aFloat =", aFloat))
>     print("--------------------------")
>     PLT <- rbind(PLT, list(anInt, aLong, aFloat))
>     counte <- counte + 1
>   } # end while
>   close(URL)
>   PLT
> }
> fichier <- "/Users/philippe/Desktop/datatests/data0.bin"
> PLT2 <- readFile(fichier)
> print(PLT2)
> ?????????????????????
>
> import java.io.*;
>
> public class Main {
>
>         Main() {
>                 writeData();
>         }
>
>         public static void main(String[] args) {
>                 new Main();
>         }
>
>         public void writeData() {
>
>                 final String path =
> "/Users/philippe/Desktop/datatests/data0.bin";
>
>                 DataOutputStream dos;
>                 try {
>                         dos = new DataOutputStream(new
> BufferedOutputStream(new FileOutputStream(path)));
>                         // big endian write! ("high byte first") , see
> https://docs.oracle.com/javase/7/docs/api/java/io/DataOutputStream.html
>                         dos.writeInt(1);
>                         dos.writeLong(2L);
>                         dos.writeFloat(3.4444F);
>
>                         dos.writeInt(2);
>                         dos.writeLong(22L);
>                         dos.writeFloat(13.4644F);
>
>                         dos.writeInt(3);
>                         dos.writeLong(55L);
>                         dos.writeFloat(45.4444F);
>
>                         dos.close();
>                 } catch (FileNotFoundException e) {
>                         e.printStackTrace();
>                 } catch (IOException ioe) {
>                         ioe.printStackTrace();
>                 }
>
>         }
>
> }
>
>
> ?????????????????????
>
>
>
>
>
>
> > Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a
> ?crit :
> >
> > Hi Jim,
> > this is exactly the answer I was look for. Many thanks. I didn?t R had a
> pack function, as in PERL.
> > To answer your earlier question, I am trying to update legacy code to
> read a binary file with unknown size, over a network, slice up it into rows
> each containing an integer, an integer, a long, a short, a float and a
> float, and stuff the rows into a matrix.
>


It's possible to read all rows fast as raw(), then parse in a vectorised
way with matrix indexing to group the bytes appropriately. There is an
example on the mailing list somewhere, but otherwise I can show an example
if that's of interest.


Cheers, Mike


> Best regards,
> > Philippe
> >
> >> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:
> jholtman at gmail.com>> a ?crit :
> >>
> >> Here is an example of how to do it:
> >>
> >> x <- 1:10  # integer values
> >> xf <- seq(1.0, 2, by = 0.1)  # floating point
> >>
> >> setwd("d:/temp")
> >>
> >> # create file to write to
> >> output <- file('integer.bin', 'wb')
> >> writeBin(x, output)  # write integer
> >> writeBin(xf, output)  # write reals
> >> close(output)
> >>
> >>
> >> library(pack)
> >> library(readr)
> >>
> >> # read all the data at once
> >> allbin <- read_file_raw('integer.bin')
> >>
> >> # decode the data into a list
> >> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
> >>
> >>
> >>
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com
> <mailto:sezenismail at gmail.com><mailto:sezenismail at gmail.com <mailto:
> sezenismail at gmail.com>>> wrote:
> >> I noticed same issue but didnt care much :)
> >>
> >> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:
> jholtman at gmail.com> <mailto:jholtman at gmail.com <mailto:jholtman at gmail.com>>>
> wrote:
> >> Your example was not reproducible.  Also how do you "break" out of the
> >> "while" loop?
> >>
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr
> <mailto:phiroc at free.fr> <mailto:phiroc at free.fr <mailto:phiroc at free.fr>>>
> >> wrote:
> >>
> >>> Hello,
> >>> the following function, which stores numeric values extracted from a
> >>> binary file, into an R matrix, is very slow, especially when the said
> file
> >>> is several MB in size.
> >>> Should I rewrite the function in inline C or in C/C++ using Rcpp? If
> the
> >>> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
> >>> newbie)?
> >>> Many thanks.
> >>> Best regards,
> >>> phiroc
> >>>
> >>>
> >>> -------------
> >>>
> >>> # inputPath is something like http://myintranet/getData <
> http://myintranet/getData><http://myintranet/getData <
> http://myintranet/getData>>?
> >>> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <
> http://myintranet/getData> <http://myintranet/getData <
> http://myintranet/getData>>?
> >>> pathToFile=/usr/lib/xxx/yyy/data.bin>
> >>>
> >>> PLTreader <- function(inputPath){
> >>>        URL <- file(inputPath, "rb")
> >>>        PLT <- matrix(nrow=0, ncol=6)
> >>>        compteurDePrints = 0
> >>>        compteurDeLignes <- 0
> >>>        maxiPrints = 5
> >>>        displayData <- FALSE
> >>>        while (TRUE) {
> >>>                periodIndex <- readBin(URL, integer(), size=4, n=1,
> >>> endian="little") # int (4 bytes)
> >>>                eventId <- readBin(URL, integer(), size=4, n=1,
> >>> endian="little") # int (4 bytes)
> >>>                dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
> >>> n=1, endian="little") # int
> >>>                dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
> >>> n=1, endian="little") # int
> >>>                if (dword1 < 0) {
> >>>                        dword1 = dword1 + 2^32-1;
> >>>                }
> >>>                eventDate = (dword2*2^32 + dword1)/1000
> >>>                repNum <- readBin(URL, integer(), size=2, n=1,
> >>> endian="little") # short (2 bytes)
> >>>                exp <- readBin(URL, numeric(), size=4, n=1,
> >>> endian="little") # float (4 bytes, strangely enough, would expect 8)
> >>>                loss <- readBin(URL, numeric(), size=4, n=1,
> >>> endian="little") # float (4 bytes)
> >>>                PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> >>> repNum, exp, loss))
> >>>        } # end while
> >>>        return(PLT)
> >>>        close(URL)
> >>> }
> >>>
> >>> ----------------
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:
> R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help><
> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>>
> >>> PLEASE do read the posting guide http://www.R-project.org/ <
> http://www.r-project.org/> <http://www.r-project.org/ <
> http://www.r-project.org/>>
> >>> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:
> R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help><
> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>>
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html> <
> http://www.r-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html>>
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Sun Sep 18 16:25:47 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 18 Sep 2016 17:25:47 +0300
Subject: [R] What are the red line and cut line in lm's Residuals vs Fitted
	plot?
Message-ID: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>

What are the red line and cut line in lm's Residuals vs Fitted plot?

As seen in e.g.:

http://i.imgur.com/QvZ6oeT.png


From phiroc at free.fr  Sun Sep 18 17:02:00 2016
From: phiroc at free.fr (Philippe de Rochambeau)
Date: Sun, 18 Sep 2016 17:02:00 +0200
Subject: [R] Accelerating binRead
In-Reply-To: <CAAcGz9_BZmgHeHp5GnBNOd3N5eTDiJTLeS6r6WKgc-RjpEQDjA@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
	<D563E423-2167-41DB-BC82-1502751BA507@free.fr>
	<CAAcGz9_BZmgHeHp5GnBNOd3N5eTDiJTLeS6r6WKgc-RjpEQDjA@mail.gmail.com>
Message-ID: <A22CB35D-76A5-4BB3-B882-2AE2CFBBB4FD@free.fr>

I would gladly examine your example, Mike.
Cheers,
Philippe

> Le 18 sept. 2016 ? 16:05, Michael Sumner <mdsumner at gmail.com> a ?crit :
> 
> 
> 
>> On Sun, 18 Sep 2016, 19:04 Philippe de Rochambeau <phiroc at free.fr> wrote:
>> Please find below code that attempts to read ints, longs and floats from a binary file (which is a simplification of my original program).
>> Please disregard the R inefficiencies, such as using rbind, for now.
>> I?ve also included Java code to generate the binary file.
>> The output shows that, at one point, anInt becomes undefined. Unfortunately, I couldn?t find the correct R function to determine whether inInt is undefined or not, as is.null, is.nan, and is.infinite don?t work.
>> Any help would be much appreciated.
>> Many thanks in advance.
>> Philippe
>> 
>> ???????
>> [1] "anInt = 1"
>> [1] "is.null  FALSE"
>> [1] "is.nan  FALSE"
>> [1] "is.infinite  FALSE"
>> [1] "aLong = 2"
>> [1] "aFloat = 3.44440007209778"
>> [1] "--------------------------"
>> [1] "anInt = 2"
>> [1] "is.null  FALSE"
>> [1] "is.nan  FALSE"
>> [1] "is.infinite  FALSE"
>> [1] "aLong = 22"
>> [1] "aFloat = 13.4644002914429"
>> [1] "--------------------------"
>> [1] "anInt = 3"
>> [1] "is.null  FALSE"
>> [1] "is.nan  FALSE"
>> [1] "is.infinite  FALSE"
>> [1] "aLong = 55"
>> [1] "aFloat = 45.4444007873535"
>> [1] "--------------------------"
>> [1] "anInt = "
>> [1] "is.null  FALSE"
>> [1] "is.nan  "
>> [1] "is.infinite  "
>> [1] "aLong = "
>> [1] "aFloat = "
>> [1] "--------------------------"
>>      [,1]      [,2]      [,3]
>> [1,] 1         2         3.4444
>> [2,] 2         22        13.4644
>> [3,] 3         55        45.4444
>> [4,] Integer,0 Integer,0 Numeric,0
>> >
>> 
>> -----------
>> 
>> 
>> ?????????????????????
>> 
>> readFile <- function(inputPath) {
>>   URL <- file(inputPath, "rb")
>>   PLT <- matrix(nrow=0, ncol=3)
>>   counte <- 0
>>   max <- 4
>>   while (counte < max) {
>>     anInt <- readBin(con=URL, what=integer(), size=4, n=1, endian="big")
>>     print(paste("anInt =", anInt))
>>     #if (! (anInt == 0)) { print(paste("empty int")); break }
>>     print(paste("is.null ", is.null(anInt)))
>>     print(paste("is.nan ", is.nan(anInt)))
>>     print(paste("is.infinite ", is.infinite(anInt)))
>>     aLong <- readBin(URL, integer(), size=8, n=1, endian="big")
>>     print(paste("aLong =", aLong))
>>     aFloat <- readBin(URL, numeric(), size=4, n=1, endian="big")
>>     print(paste("aFloat =", aFloat))
>>     print("--------------------------")
>>     PLT <- rbind(PLT, list(anInt, aLong, aFloat))
>>     counte <- counte + 1
>>   } # end while
>>   close(URL)
>>   PLT
>> }
>> fichier <- "/Users/philippe/Desktop/datatests/data0.bin"
>> PLT2 <- readFile(fichier)
>> print(PLT2)
>> ?????????????????????
>> 
>> import java.io.*;
>> 
>> public class Main {
>> 
>>         Main() {
>>                 writeData();
>>         }
>> 
>>         public static void main(String[] args) {
>>                 new Main();
>>         }
>> 
>>         public void writeData() {
>> 
>>                 final String path = "/Users/philippe/Desktop/datatests/data0.bin";
>> 
>>                 DataOutputStream dos;
>>                 try {
>>                         dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(path)));
>>                         // big endian write! ("high byte first") , see https://docs.oracle.com/javase/7/docs/api/java/io/DataOutputStream.html
>>                         dos.writeInt(1);
>>                         dos.writeLong(2L);
>>                         dos.writeFloat(3.4444F);
>> 
>>                         dos.writeInt(2);
>>                         dos.writeLong(22L);
>>                         dos.writeFloat(13.4644F);
>> 
>>                         dos.writeInt(3);
>>                         dos.writeLong(55L);
>>                         dos.writeFloat(45.4444F);
>> 
>>                         dos.close();
>>                 } catch (FileNotFoundException e) {
>>                         e.printStackTrace();
>>                 } catch (IOException ioe) {
>>                         ioe.printStackTrace();
>>                 }
>> 
>>         }
>> 
>> }
>> 
>> 
>> ?????????????????????
>> 
>> 
>> 
>> 
>> 
>> 
>> > Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a ?crit :
>> >
>> > Hi Jim,
>> > this is exactly the answer I was look for. Many thanks. I didn?t R had a pack function, as in PERL.
>> > To answer your earlier question, I am trying to update legacy code to read a binary file with unknown size, over a network, slice up it into rows each containing an integer, an integer, a long, a short, a float and a float, and stuff the rows into a matrix.
> 
> 
> 
> It's possible to read all rows fast as raw(), then parse in a vectorised way with matrix indexing to group the bytes appropriately. There is an example on the mailing list somewhere, but otherwise I can show an example if that's of interest.  
> 
> 
> Cheers, Mike
> 
> 
>> > Best regards,
>> > Philippe
>> >
>> >> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> a ?crit :
>> >>
>> >> Here is an example of how to do it:
>> >>
>> >> x <- 1:10  # integer values
>> >> xf <- seq(1.0, 2, by = 0.1)  # floating point
>> >>
>> >> setwd("d:/temp")
>> >>
>> >> # create file to write to
>> >> output <- file('integer.bin', 'wb')
>> >> writeBin(x, output)  # write integer
>> >> writeBin(xf, output)  # write reals
>> >> close(output)
>> >>
>> >>
>> >> library(pack)
>> >> library(readr)
>> >>
>> >> # read all the data at once
>> >> allbin <- read_file_raw('integer.bin')
>> >>
>> >> # decode the data into a list
>> >> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
>> >>
>> >>
>> >>
>> >>
>> >> Jim Holtman
>> >> Data Munger Guru
>> >>
>> >> What is the problem that you are trying to solve?
>> >> Tell me what you want to do, not how you want to do it.
>> >>
>> >> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com <mailto:sezenismail at gmail.com><mailto:sezenismail at gmail.com <mailto:sezenismail at gmail.com>>> wrote:
>> >> I noticed same issue but didnt care much :)
>> >>
>> >> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com> <mailto:jholtman at gmail.com <mailto:jholtman at gmail.com>>> wrote:
>> >> Your example was not reproducible.  Also how do you "break" out of the
>> >> "while" loop?
>> >>
>> >>
>> >> Jim Holtman
>> >> Data Munger Guru
>> >>
>> >> What is the problem that you are trying to solve?
>> >> Tell me what you want to do, not how you want to do it.
>> >>
>> >> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr <mailto:phiroc at free.fr> <mailto:phiroc at free.fr <mailto:phiroc at free.fr>>>
>> >> wrote:
>> >>
>> >>> Hello,
>> >>> the following function, which stores numeric values extracted from a
>> >>> binary file, into an R matrix, is very slow, especially when the said file
>> >>> is several MB in size.
>> >>> Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>> >>> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>> >>> newbie)?
>> >>> Many thanks.
>> >>> Best regards,
>> >>> phiroc
>> >>>
>> >>>
>> >>> -------------
>> >>>
>> >>> # inputPath is something like http://myintranet/getData <http://myintranet/getData><http://myintranet/getData <http://myintranet/getData>>?
>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <http://myintranet/getData> <http://myintranet/getData <http://myintranet/getData>>?
>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin>
>> >>>
>> >>> PLTreader <- function(inputPath){
>> >>>        URL <- file(inputPath, "rb")
>> >>>        PLT <- matrix(nrow=0, ncol=6)
>> >>>        compteurDePrints = 0
>> >>>        compteurDeLignes <- 0
>> >>>        maxiPrints = 5
>> >>>        displayData <- FALSE
>> >>>        while (TRUE) {
>> >>>                periodIndex <- readBin(URL, integer(), size=4, n=1,
>> >>> endian="little") # int (4 bytes)
>> >>>                eventId <- readBin(URL, integer(), size=4, n=1,
>> >>> endian="little") # int (4 bytes)
>> >>>                dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>> >>> n=1, endian="little") # int
>> >>>                dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>> >>> n=1, endian="little") # int
>> >>>                if (dword1 < 0) {
>> >>>                        dword1 = dword1 + 2^32-1;
>> >>>                }
>> >>>                eventDate = (dword2*2^32 + dword1)/1000
>> >>>                repNum <- readBin(URL, integer(), size=2, n=1,
>> >>> endian="little") # short (2 bytes)
>> >>>                exp <- readBin(URL, numeric(), size=4, n=1,
>> >>> endian="little") # float (4 bytes, strangely enough, would expect 8)
>> >>>                loss <- readBin(URL, numeric(), size=4, n=1,
>> >>> endian="little") # float (4 bytes)
>> >>>                PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>> >>> repNum, exp, loss))
>> >>>        } # end while
>> >>>        return(PLT)
>> >>>        close(URL)
>> >>> }
>> >>>
>> >>> ----------------
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>> >>> PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/> <http://www.r-project.org/ <http://www.r-project.org/>>
>> >>> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>        [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
> 

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Sun Sep 18 17:26:52 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 18 Sep 2016 18:26:52 +0300
Subject: [R] How to plot the regression line of multivariable linear model?
Message-ID: <37a6040699aa8f8eeb546d80af95039f@kapsi.fi>

I'm having a bit of trouble plotting the regression line of 
multivariable linear model.

Specifically my model has one response and two predictors, i.e. it's of 
the form

Y = b_0+b_1*X_1+b_2*X_2

Plotting the regression line for a single predictor model

Y = b_0+b_1*X_1

is simple enough, just call abline() with the coefficients returned by 
lm().

However, I don't know if this can be adapted to multivariable linear 
models.

I also know about curve(), but I don't know how am I supposed to input 
the multivariable model's coefficients into it.


From sezenismail at gmail.com  Sun Sep 18 17:47:29 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Sun, 18 Sep 2016 18:47:29 +0300
Subject: [R] How to plot the regression line of multivariable linear
	model?
In-Reply-To: <37a6040699aa8f8eeb546d80af95039f@kapsi.fi>
References: <37a6040699aa8f8eeb546d80af95039f@kapsi.fi>
Message-ID: <49261942-ADA7-48A7-92EB-48C42CE511E7@gmail.com>


> Specifically my model has one response and two predictors, i.e. it's of the form
> 
> Y = b_0+b_1*X_1+b_2*X_2
> 
> Plotting the regression line for a single predictor model
> 
> Y = b_0+b_1*X_1
> 
> is simple enough, just call abline() with the coefficients returned by lm().

Single variable linear model has only 1 regression line.
For two predictors, your regression line! is a surface. (it is not a line anymore)
For 3 predictors, your regression line! is a volume etc?

> 
> However, I don't know if this can be adapted to multivariable linear models.

Yes, but in a limited manner. Assume your model is Y ~ x1 + x2 + x3

set x2 and x3 constant  (for instance, to median of the series) predict (predict.lm) Y.predicted values against x1. Order x1 and  Y.predicted values and plot them by lines command on Y ~ x1 scatter plot.

Do same thing for other variables.


From henrik.bengtsson at gmail.com  Sun Sep 18 18:20:01 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 18 Sep 2016 09:20:01 -0700
Subject: [R] Accelerating binRead
In-Reply-To: <A22CB35D-76A5-4BB3-B882-2AE2CFBBB4FD@free.fr>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
	<D563E423-2167-41DB-BC82-1502751BA507@free.fr>
	<CAAcGz9_BZmgHeHp5GnBNOd3N5eTDiJTLeS6r6WKgc-RjpEQDjA@mail.gmail.com>
	<A22CB35D-76A5-4BB3-B882-2AE2CFBBB4FD@free.fr>
Message-ID: <CAFDcVCTnYn1aHR4xZduinCRnSJQZPVKa8+N6mmSN+7ysBrscHA@mail.gmail.com>

I second Mike's proposal - it works, e.g.
https://github.com/HenrikBengtsson/affxparser/blob/5bf1a9162904c56d59c4735a8d7eb427e4f085e4/R/readCcg.R#L535-L583

Here's an outline. Say each row consists of tuple (iiii=4-byte
integer, ffff=4-byte float, ss=2 byte integer) so that the
byte-by-byte content of your file look like this:

  iiiiffffss
  iiiiffffss
  iiiiffffss
  ...
  iiiiffffss

Then read this is as raw bytes (file_size can also be a very large
number in case it's unknown):

  raw <- readBin(con, what="raw", n=file_size)

Turn into a (4+4+2)-by-K raw matrix:

  raw <- matrix(raw, nrow=4+4+2)

so that your raw bytes has the following layout:

  iii ... i
  iii ... i
  iii ... i
  iii ... i
  fff ... f
  fff ... f
  fff ... f
  fff ... f
  sss ... s
  sss ... s

Then extract the three submatrices of interest:

  iiii <- raw[1:4,]
  ffff <- raw[5:8,]
  ss <- raw[9:10,]

Here you can discard raw, i.e. rm(list="raw").

Since R stores matrices in a column-by-column order internally, your
bytes are already in the proper order.  Finally, re-read these with
appropriate readBin() settings, e.g.

  i <- readBin(iiii, what="integer", size=4L)
  f <- readBin(ffff, what="double", size=4L)
  s <- readBin(ss, what="integer", size=2L)

Put into a 3-by-K data.frame:

  data <- data.frame(i=i, f=f, s=s)

/Henrik

On Sun, Sep 18, 2016 at 8:02 AM, Philippe de Rochambeau <phiroc at free.fr> wrote:
> I would gladly examine your example, Mike.
> Cheers,
> Philippe
>
>> Le 18 sept. 2016 ? 16:05, Michael Sumner <mdsumner at gmail.com> a ?crit :
>>
>>
>>
>>> On Sun, 18 Sep 2016, 19:04 Philippe de Rochambeau <phiroc at free.fr> wrote:
>>> Please find below code that attempts to read ints, longs and floats from a binary file (which is a simplification of my original program).
>>> Please disregard the R inefficiencies, such as using rbind, for now.
>>> I?ve also included Java code to generate the binary file.
>>> The output shows that, at one point, anInt becomes undefined. Unfortunately, I couldn?t find the correct R function to determine whether inInt is undefined or not, as is.null, is.nan, and is.infinite don?t work.
>>> Any help would be much appreciated.
>>> Many thanks in advance.
>>> Philippe
>>>
>>> ???????
>>> [1] "anInt = 1"
>>> [1] "is.null  FALSE"
>>> [1] "is.nan  FALSE"
>>> [1] "is.infinite  FALSE"
>>> [1] "aLong = 2"
>>> [1] "aFloat = 3.44440007209778"
>>> [1] "--------------------------"
>>> [1] "anInt = 2"
>>> [1] "is.null  FALSE"
>>> [1] "is.nan  FALSE"
>>> [1] "is.infinite  FALSE"
>>> [1] "aLong = 22"
>>> [1] "aFloat = 13.4644002914429"
>>> [1] "--------------------------"
>>> [1] "anInt = 3"
>>> [1] "is.null  FALSE"
>>> [1] "is.nan  FALSE"
>>> [1] "is.infinite  FALSE"
>>> [1] "aLong = 55"
>>> [1] "aFloat = 45.4444007873535"
>>> [1] "--------------------------"
>>> [1] "anInt = "
>>> [1] "is.null  FALSE"
>>> [1] "is.nan  "
>>> [1] "is.infinite  "
>>> [1] "aLong = "
>>> [1] "aFloat = "
>>> [1] "--------------------------"
>>>      [,1]      [,2]      [,3]
>>> [1,] 1         2         3.4444
>>> [2,] 2         22        13.4644
>>> [3,] 3         55        45.4444
>>> [4,] Integer,0 Integer,0 Numeric,0
>>> >
>>>
>>> -----------
>>>
>>>
>>> ?????????????????????
>>>
>>> readFile <- function(inputPath) {
>>>   URL <- file(inputPath, "rb")
>>>   PLT <- matrix(nrow=0, ncol=3)
>>>   counte <- 0
>>>   max <- 4
>>>   while (counte < max) {
>>>     anInt <- readBin(con=URL, what=integer(), size=4, n=1, endian="big")
>>>     print(paste("anInt =", anInt))
>>>     #if (! (anInt == 0)) { print(paste("empty int")); break }
>>>     print(paste("is.null ", is.null(anInt)))
>>>     print(paste("is.nan ", is.nan(anInt)))
>>>     print(paste("is.infinite ", is.infinite(anInt)))
>>>     aLong <- readBin(URL, integer(), size=8, n=1, endian="big")
>>>     print(paste("aLong =", aLong))
>>>     aFloat <- readBin(URL, numeric(), size=4, n=1, endian="big")
>>>     print(paste("aFloat =", aFloat))
>>>     print("--------------------------")
>>>     PLT <- rbind(PLT, list(anInt, aLong, aFloat))
>>>     counte <- counte + 1
>>>   } # end while
>>>   close(URL)
>>>   PLT
>>> }
>>> fichier <- "/Users/philippe/Desktop/datatests/data0.bin"
>>> PLT2 <- readFile(fichier)
>>> print(PLT2)
>>> ?????????????????????
>>>
>>> import java.io.*;
>>>
>>> public class Main {
>>>
>>>         Main() {
>>>                 writeData();
>>>         }
>>>
>>>         public static void main(String[] args) {
>>>                 new Main();
>>>         }
>>>
>>>         public void writeData() {
>>>
>>>                 final String path = "/Users/philippe/Desktop/datatests/data0.bin";
>>>
>>>                 DataOutputStream dos;
>>>                 try {
>>>                         dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(path)));
>>>                         // big endian write! ("high byte first") , see https://docs.oracle.com/javase/7/docs/api/java/io/DataOutputStream.html
>>>                         dos.writeInt(1);
>>>                         dos.writeLong(2L);
>>>                         dos.writeFloat(3.4444F);
>>>
>>>                         dos.writeInt(2);
>>>                         dos.writeLong(22L);
>>>                         dos.writeFloat(13.4644F);
>>>
>>>                         dos.writeInt(3);
>>>                         dos.writeLong(55L);
>>>                         dos.writeFloat(45.4444F);
>>>
>>>                         dos.close();
>>>                 } catch (FileNotFoundException e) {
>>>                         e.printStackTrace();
>>>                 } catch (IOException ioe) {
>>>                         ioe.printStackTrace();
>>>                 }
>>>
>>>         }
>>>
>>> }
>>>
>>>
>>> ?????????????????????
>>>
>>>
>>>
>>>
>>>
>>>
>>> > Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a ?crit :
>>> >
>>> > Hi Jim,
>>> > this is exactly the answer I was look for. Many thanks. I didn?t R had a pack function, as in PERL.
>>> > To answer your earlier question, I am trying to update legacy code to read a binary file with unknown size, over a network, slice up it into rows each containing an integer, an integer, a long, a short, a float and a float, and stuff the rows into a matrix.
>>
>>
>>
>> It's possible to read all rows fast as raw(), then parse in a vectorised way with matrix indexing to group the bytes appropriately. There is an example on the mailing list somewhere, but otherwise I can show an example if that's of interest.
>>
>>
>> Cheers, Mike
>>
>>
>>> > Best regards,
>>> > Philippe
>>> >
>>> >> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com>> a ?crit :
>>> >>
>>> >> Here is an example of how to do it:
>>> >>
>>> >> x <- 1:10  # integer values
>>> >> xf <- seq(1.0, 2, by = 0.1)  # floating point
>>> >>
>>> >> setwd("d:/temp")
>>> >>
>>> >> # create file to write to
>>> >> output <- file('integer.bin', 'wb')
>>> >> writeBin(x, output)  # write integer
>>> >> writeBin(xf, output)  # write reals
>>> >> close(output)
>>> >>
>>> >>
>>> >> library(pack)
>>> >> library(readr)
>>> >>
>>> >> # read all the data at once
>>> >> allbin <- read_file_raw('integer.bin')
>>> >>
>>> >> # decode the data into a list
>>> >> (result <- unpack("V V V V V V V V V V d d d d d d d d d d", allbin))
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> Jim Holtman
>>> >> Data Munger Guru
>>> >>
>>> >> What is the problem that you are trying to solve?
>>> >> Tell me what you want to do, not how you want to do it.
>>> >>
>>> >> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <sezenismail at gmail.com <mailto:sezenismail at gmail.com><mailto:sezenismail at gmail.com <mailto:sezenismail at gmail.com>>> wrote:
>>> >> I noticed same issue but didnt care much :)
>>> >>
>>> >> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com <mailto:jholtman at gmail.com> <mailto:jholtman at gmail.com <mailto:jholtman at gmail.com>>> wrote:
>>> >> Your example was not reproducible.  Also how do you "break" out of the
>>> >> "while" loop?
>>> >>
>>> >>
>>> >> Jim Holtman
>>> >> Data Munger Guru
>>> >>
>>> >> What is the problem that you are trying to solve?
>>> >> Tell me what you want to do, not how you want to do it.
>>> >>
>>> >> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <phiroc at free.fr <mailto:phiroc at free.fr> <mailto:phiroc at free.fr <mailto:phiroc at free.fr>>>
>>> >> wrote:
>>> >>
>>> >>> Hello,
>>> >>> the following function, which stores numeric values extracted from a
>>> >>> binary file, into an R matrix, is very slow, especially when the said file
>>> >>> is several MB in size.
>>> >>> Should I rewrite the function in inline C or in C/C++ using Rcpp? If the
>>> >>> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total Rcpp
>>> >>> newbie)?
>>> >>> Many thanks.
>>> >>> Best regards,
>>> >>> phiroc
>>> >>>
>>> >>>
>>> >>> -------------
>>> >>>
>>> >>> # inputPath is something like http://myintranet/getData <http://myintranet/getData><http://myintranet/getData <http://myintranet/getData>>?
>>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <http://myintranet/getData> <http://myintranet/getData <http://myintranet/getData>>?
>>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin>
>>> >>>
>>> >>> PLTreader <- function(inputPath){
>>> >>>        URL <- file(inputPath, "rb")
>>> >>>        PLT <- matrix(nrow=0, ncol=6)
>>> >>>        compteurDePrints = 0
>>> >>>        compteurDeLignes <- 0
>>> >>>        maxiPrints = 5
>>> >>>        displayData <- FALSE
>>> >>>        while (TRUE) {
>>> >>>                periodIndex <- readBin(URL, integer(), size=4, n=1,
>>> >>> endian="little") # int (4 bytes)
>>> >>>                eventId <- readBin(URL, integer(), size=4, n=1,
>>> >>> endian="little") # int (4 bytes)
>>> >>>                dword1 <- readBin(URL, integer(), size=4, signed=FALSE,
>>> >>> n=1, endian="little") # int
>>> >>>                dword2 <- readBin(URL, integer(), size=4, signed=FALSE,
>>> >>> n=1, endian="little") # int
>>> >>>                if (dword1 < 0) {
>>> >>>                        dword1 = dword1 + 2^32-1;
>>> >>>                }
>>> >>>                eventDate = (dword2*2^32 + dword1)/1000
>>> >>>                repNum <- readBin(URL, integer(), size=2, n=1,
>>> >>> endian="little") # short (2 bytes)
>>> >>>                exp <- readBin(URL, numeric(), size=4, n=1,
>>> >>> endian="little") # float (4 bytes, strangely enough, would expect 8)
>>> >>>                loss <- readBin(URL, numeric(), size=4, n=1,
>>> >>> endian="little") # float (4 bytes)
>>> >>>                PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
>>> >>> repNum, exp, loss))
>>> >>>        } # end while
>>> >>>        return(PLT)
>>> >>>        close(URL)
>>> >>> }
>>> >>>
>>> >>> ----------------
>>> >>>        [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>> >>> PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/> <http://www.r-project.org/ <http://www.r-project.org/>>
>>> >>> posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>        [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help><https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Sep 18 18:36:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Sep 2016 09:36:16 -0700
Subject: [R] What are the red line and cut line in lm's Residuals vs
	Fitted plot?
In-Reply-To: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
References: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
Message-ID: <6B8CFD75-5F59-46FD-865F-328385FDD7CA@comcast.net>


> On Sep 18, 2016, at 7:25 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> What are the red line and cut line in lm's Residuals vs Fitted plot?
> 
> As seen in e.g.:
> 
> http://i.imgur.com/QvZ6oeT.png

R has a `plot.lm` function that is invoked by `plot(lm_object)` when `lm_object` has a class of "lm". It produces multiple diagnostic plots. The default is for display of 4 of the possible 6 plots.

The help page can be specifically accessed by:

?plot.lm

And run the first example:

lm.SR <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)
plot(lm.SR)


If you have further question about that particular plot, which would be the first one, you should first review the help page and then review the code seen with:

plot.lm
#Error: object 'plot.lm' not found
getAnywhere(plot.lm)  # the way to see code that is not exported:

See:

function (x, which = c(1L:3L, 5L), caption = list("Residuals vs Fitted", 
    "Normal Q-Q", "Scale-Location", "Cook's distance", "Residuals vs Leverage", 
    expression("Cook's dist vs Leverage  " * h[ii]/(1 - h[ii]))), 
    panel = if (add.smooth) panel.smooth else points, sub.caption = NULL, 
    main = "", ask = prod(par("mfcol")) < length(which) && dev.interactive(), 
    ..., id.n = 3, labels.id = names(residuals(x)), cex.id = 0.75, 
    qqline = TRUE, cook.levels = c(0.5, 1), add.smooth = getOption("add.smooth"), 
    label.pos = c(4, 2), cex.caption = 1, cex.oma.main = 1.25) 


Note: I checked the option setting with:

> getOption("add.smooth")
[1] TRUE

---snipped plotting set up logic -----

if (show[1L]) {
        ylim <- range(r, na.rm = TRUE)
        if (id.n > 0) 
            ylim <- extendrange(r = ylim, f = 0.08)
        dev.hold()
        plot(yh, r, xlab = l.fit, ylab = "Residuals", main = main, 
            ylim = ylim, type = "n", ...)
        panel(yh, r, ...)   # this is what is drawing the "red line"
        if (one.fig) 
            title(sub = sub.caption, ...)
        mtext(getCaption(1), 3, 0.25, cex = cex.caption)
        if (id.n > 0) {
            y.id <- r[show.r]
            y.id[y.id < 0] <- y.id[y.id < 0] - strheight(" ")/3
            text.id(yh[show.r], y.id, show.r)
        }
        abline(h = 0, lty = 3, col = "gray")  # this is drawing the dotted line
        dev.flush()


So the `panel` function is creating the "red line" and its help page is at:

?panel.smooth   #...

... since the `panel funciton was given that value.

-- 
David.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mviljamaa at kapsi.fi  Sun Sep 18 19:41:37 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 18 Sep 2016 20:41:37 +0300
Subject: [R] How are interaction terms computed in lm's result / problems
 with interaction terms in lm?
Message-ID: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>

I'm trying to use interaction terms in lm and for the following types of 
models:

fit3_hs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs + kidmomhsage$mom_age * 1)
fit3_nohs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs + kidmomhsage$mom_age * 0)

where you see the last term being the interaction term (it's 
mom_age*mom_hs where mom_hs takes values 0 or 1), the results are 
causing a bit of confusion.

fit3_hs returns:

Call:
lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs +
     kidmomhsage$mom_age * 1)

Coefficients:
         (Intercept)  kidmomhsage$mom_age
             70.4787               0.3261
  kidmomhsage$mom_hs
             11.3112


fit3_nohs returns:

Call:
lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs +
     kidmomhsage$mom_age * 0)

Coefficients:
kidmomhsage$mom_age   kidmomhsage$mom_hs
               3.368               11.568

Now why is (Intercept) term missing from the second one?
Also since in the first one the interaction term's coefficient should be 
added to the coefficient of mom_age, then is the return value of 
kidmomhsage$mom_age 0.3261 the sum of the coefficient of mom_age and the 
coefficient of the interaction term? Or would I need to produce the sum 
myself somehow?


From mviljamaa at kapsi.fi  Sun Sep 18 20:01:43 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 18 Sep 2016 21:01:43 +0300
Subject: [R] How are interaction terms computed in lm's result /
 problems with interaction terms in lm?
In-Reply-To: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>
References: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>
Message-ID: <2589aff5996006053582d41245d7f2dc@kapsi.fi>

Also if you, rather than doing what's done below, do:

fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs)

Then this gives the result:

Call:
lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs +
     kidmomhsage$mom_age * kidmomhsage$mom_hs)

Coefficients:
                            (Intercept)
                                110.542
                    kidmomhsage$mom_age
                                 -1.522
                     kidmomhsage$mom_hs
                                -41.287
kidmomhsage$mom_age:kidmomhsage$mom_hs
                                  2.391

Where the interaction term now seems properly interpretable. So perhaps 
this is the way to use interaction terms with lm.

However, in the above, is the coefficient 2.391 of 
kidmomhsage$mom_age:kidmomhsage$mom_hs actually only that for mom_hs == 
1 in which case for mom_hs == 0 one would simply ignore the last 
coefficient?

And would one still need to perform summations of kidmomhsage$mom_age 
and kidmomhsage$mom_age:kidmomhsage$mom_hs coefficients, i.e. the 
coefficient for kidmomhsage$mom_age = -1.522 + 2.391?


On 2016-09-18 20:41, mviljamaa wrote:
> I'm trying to use interaction terms in lm and for the following types 
> of models:
> 
> fit3_hs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age * 1)
> fit3_nohs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age * 0)
> 
> where you see the last term being the interaction term (it's
> mom_age*mom_hs where mom_hs takes values 0 or 1), the results are
> causing a bit of confusion.
> 
> fit3_hs returns:
> 
> Call:
> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
> kidmomhsage$mom_hs +
>     kidmomhsage$mom_age * 1)
> 
> Coefficients:
>         (Intercept)  kidmomhsage$mom_age
>             70.4787               0.3261
>  kidmomhsage$mom_hs
>             11.3112
> 
> 
> fit3_nohs returns:
> 
> Call:
> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
> kidmomhsage$mom_hs +
>     kidmomhsage$mom_age * 0)
> 
> Coefficients:
> kidmomhsage$mom_age   kidmomhsage$mom_hs
>               3.368               11.568
> 
> Now why is (Intercept) term missing from the second one?
> Also since in the first one the interaction term's coefficient should
> be added to the coefficient of mom_age, then is the return value of
> kidmomhsage$mom_age 0.3261 the sum of the coefficient of mom_age and
> the coefficient of the interaction term? Or would I need to produce
> the sum myself somehow?


From tring at gvdnet.dk  Sun Sep 18 20:05:27 2016
From: tring at gvdnet.dk (Troels Ring)
Date: Sun, 18 Sep 2016 20:05:27 +0200
Subject: [R] ggplot2 lost label
Message-ID: <17c2a552-819f-3cc1-281d-c81209ce48c3@gvdnet.dk>

dear friends - I have a problem in ggplot2 which I hope you can help me 
understand and solve.

Running windows 7, R 3.2.1

grp <- gl(3,4,12)
trt <- gl(4,1,12)
num <- c(11,1,0,0,6,2,0,0,1,9,10,10)
MM <- data.frame(grp=grp,num=num,trt=trt)
levels(MM$grp)<- c("anest1","anest2","anest3")
levels(MM$trt)<- c("drug1","drug2","drug3","drug4")
MM

ggplot(data=MM)+ 
geom_bar(mapping=aes(x=grp,y=num),fill=trt,stat="identity") +
theme(legend.position="top") + ylab("Number")+xlab("")

How do Imake ggplot make a label? - I tried to 
annotate("text",1,5,"drug1") returning

mapping: x = x, xmin = xmin, y = y
geom_text: na.rm = FALSE
stat_identity: na.rm = FALSE
position_identity

so that was not as I thought. How do I get the label directly - or 
annotate if that is the only possibility?

Best wishes

Troels Ring


From dwinsemius at comcast.net  Sun Sep 18 21:18:21 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Sep 2016 12:18:21 -0700
Subject: [R] How are interaction terms computed in lm's result /
	problems with interaction terms in lm?
In-Reply-To: <2589aff5996006053582d41245d7f2dc@kapsi.fi>
References: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>
	<2589aff5996006053582d41245d7f2dc@kapsi.fi>
Message-ID: <5B0203F2-C1F1-416D-8A94-F601A8FDF9AE@comcast.net>


> On Sep 18, 2016, at 11:01 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> Also if you, rather than doing what's done below, do:
> 
> fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> Then this gives the result:
> 
> Call:
> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs +
>    kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> Coefficients:
>                           (Intercept)
>                               110.542
>                   kidmomhsage$mom_age
>                                -1.522
>                    kidmomhsage$mom_hs
>                               -41.287
> kidmomhsage$mom_age:kidmomhsage$mom_hs
>                                 2.391
> 
> Where the interaction term now seems properly interpretable. So perhaps this is the way to use interaction terms with lm.
> 
> However, in the above, is the coefficient 2.391 of kidmomhsage$mom_age:kidmomhsage$mom_hs actually only that for mom_hs == 1 in which case for mom_hs == 0 one would simply ignore the last coefficient?

Yes.

In all of this it would much clearer and safer if you supplied a dataframe to the data parameter of lm:

lm(formula =kid_score ~ mom_age +mom_hs + mom_age*mom_hs, data= kidmomhsage)

> 
> And would one still need to perform summations of kidmomhsage$mom_age and kidmomhsage$mom_age:kidmomhsage$mom_hs coefficients, i.e. the coefficient for kidmomhsage$mom_age = -1.522 + 2.391?

Yes, at least if I'm understanding your terminology. That is the net mom_age coefficient for those subjects with mom_hs values not at the base level.

> 
> 
> On 2016-09-18 20:41, mviljamaa wrote:
>> I'm trying to use interaction terms in lm and for the following types of models:
>> fit3_hs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
>> kidmomhsage$mom_hs + kidmomhsage$mom_age * 1)
>> fit3_nohs <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
>> kidmomhsage$mom_hs + kidmomhsage$mom_age * 0)
>> where you see the last term being the interaction term (it's
>> mom_age*mom_hs where mom_hs takes values 0 or 1), the results are
>> causing a bit of confusion.
>> fit3_hs returns:
>> Call:
>> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs +
>>    kidmomhsage$mom_age * 1)
>> Coefficients:
>>        (Intercept)  kidmomhsage$mom_age
>>            70.4787               0.3261
>> kidmomhsage$mom_hs
>>            11.3112
>> fit3_nohs returns:
>> Call:
>> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs +
>>    kidmomhsage$mom_age * 0)
>> Coefficients:
>> kidmomhsage$mom_age   kidmomhsage$mom_hs
>>              3.368               11.568
>> Now why is (Intercept) term missing from the second one?

In R, formula terms `1` and `0` have special meaning. In the first model you "formula-added" mom_age to mom_age and got, not 2*mom_age, but rather just mom_age. In the second model you got the formula equivalent of `mom_age + mom_hs + 0` which is an intercept-free specification. Read:

?formula

I misremembered a pithy summary of this topic that I thought was by Greg Snow in the fortunes package about why one should almost never use intercept free models, but it's not showing up for me, but perhaps some of these Rhelp threads will be useful:

http://markmail.org/message/o7kbarfvpdobmdir?q=list:org%2Er-project%2Er-help+snow+intercept+0

You could easily substitute 'ripley', 'lumley' or several other names in that search strategy in Rhelp's archives and get equally credible material.


>> Also since in the first one the interaction term's coefficient should
>> be added to the coefficient of mom_age, then is the return value of
>> kidmomhsage$mom_age 0.3261 the sum of the coefficient of mom_age and
>> the coefficient of the interaction term? Or would I need to produce
>> the sum myself somehow?

In the first one the intercept is the mean predicted score for a mom_age of zero and an mon_hs at the base value, so it is essentially setting a reference value to be added to any of the _age and _hs increments or decrements for cases of particular values of those covariates. The mom_age coefficient is averaged over the cases with both values of mom_hs. 

These sound like questions whose answers are typically learned in a first course on regression. So the answer _should_ all be in whatever standard regression textbook you _should_ be reading. They are only borderline on-topic for rhelp. We don't advertise as a statistics tutoring service, so I think any followup questions on this matter of interpreting model output should be directed to CrossValidated.com

As the standard sig says: Please read the Posting Guide and the second line as well.
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 18 21:27:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Sep 2016 12:27:09 -0700
Subject: [R] ggplot2 lost label
In-Reply-To: <17c2a552-819f-3cc1-281d-c81209ce48c3@gvdnet.dk>
References: <17c2a552-819f-3cc1-281d-c81209ce48c3@gvdnet.dk>
Message-ID: <EE8100C6-5FF1-45A7-B3F6-39C5FE80FAED@comcast.net>


> On Sep 18, 2016, at 11:05 AM, Troels Ring <tring at gvdnet.dk> wrote:
> 
> dear friends - I have a problem in ggplot2 which I hope you can help me understand and solve.
> 
> Running windows 7, R 3.2.1
> 
> grp <- gl(3,4,12)
> trt <- gl(4,1,12)
> num <- c(11,1,0,0,6,2,0,0,1,9,10,10)
> MM <- data.frame(grp=grp,num=num,trt=trt)
> levels(MM$grp)<- c("anest1","anest2","anest3")
> levels(MM$trt)<- c("drug1","drug2","drug3","drug4")
> MM
> 
> ggplot(data=MM)+ geom_bar(mapping=aes(x=grp,y=num),fill=trt,stat="identity") +
> theme(legend.position="top") + ylab("Number")+xlab("")
> 
> How do Imake ggplot make a label? - I tried to annotate("text",1,5,"drug1") returning
> 
> mapping: x = x, xmin = xmin, y = y
> geom_text: na.rm = FALSE
> stat_identity: na.rm = FALSE
> position_identity

I wasn't sure what that "return" was signifying. Trying to add that annotate call to a ggplot object threw an error:

Error: geom_text requires the following missing aesthetics: label

Fixing that produced n apparently unlabelled plot except I thin realized you were trying to annotate in the same color ( "black") as that section of bar. So this succeeds:

 ggplot(data=MM)+ geom_bar(mapping=aes(x=grp,y=num),fill=trt,stat="identity") +
         theme(legend.position="top") + ylab("Number")+ xlab("")+  
         annotate("text",1,5,label="drug1", col="orange")

> 
> so that was not as I thought. How do I get the label directly

I'm not a very accomplished ggplotter so there may be "direct" methods. I remember a "directlabels" package that does some cool stuff but I'm not well-versed in it eiehter..


> - or annotate if that is the only possibility?
> 
> Best wishes
> 
> Troels Ring
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mviljamaa at kapsi.fi  Sun Sep 18 21:39:51 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 18 Sep 2016 22:39:51 +0300
Subject: [R] How are interaction terms computed in lm's result /
 problems with interaction terms in lm?
In-Reply-To: <5B0203F2-C1F1-416D-8A94-F601A8FDF9AE@comcast.net>
References: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>
	<2589aff5996006053582d41245d7f2dc@kapsi.fi>
	<5B0203F2-C1F1-416D-8A94-F601A8FDF9AE@comcast.net>
Message-ID: <dda901fad26f2b4b7ea73517cad95000@kapsi.fi>

> On Sep 18, 2016, at 11:01 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> Also if you, rather than doing what's done below, do:
> 
> fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
> kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> Then this gives the result:
> 
> Call:
> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
> kidmomhsage$mom_hs +
>    kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> Coefficients:
>                           (Intercept)
>                               110.542
>                   kidmomhsage$mom_age
>                                -1.522
>                    kidmomhsage$mom_hs
>                               -41.287
> kidmomhsage$mom_age:kidmomhsage$mom_hs
>                                 2.391
> 
> Where the interaction term now seems properly interpretable. So perhaps 
> this is the way to use interaction terms with lm.

But why does

fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age * 
kidmomhsage$mom_hs)

also give exactly the same result:

Call:
lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age * 
kidmomhsage$mom_hs)

Coefficients:
                            (Intercept)
                                110.542
                    kidmomhsage$mom_age
                                 -1.522
                     kidmomhsage$mom_hs
                                -41.287
kidmomhsage$mom_age:kidmomhsage$mom_hs
                                  2.391

It's as if lm is interpreting there having to also be "independent" 
mom_age and mom_hs variables, if there's just the interaction term. Why 
does it work this way?


From dwinsemius at comcast.net  Sun Sep 18 21:50:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Sep 2016 12:50:44 -0700
Subject: [R] How are interaction terms computed in lm's result /
	problems with interaction terms in lm?
In-Reply-To: <dda901fad26f2b4b7ea73517cad95000@kapsi.fi>
References: <26f87b00b4ba6238a58196149ab6a090@kapsi.fi>
	<2589aff5996006053582d41245d7f2dc@kapsi.fi>
	<5B0203F2-C1F1-416D-8A94-F601A8FDF9AE@comcast.net>
	<dda901fad26f2b4b7ea73517cad95000@kapsi.fi>
Message-ID: <F8CA77F8-6AED-4452-8F22-1E3D5D5E40F0@comcast.net>


> On Sep 18, 2016, at 12:39 PM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
>> On Sep 18, 2016, at 11:01 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
>> Also if you, rather than doing what's done below, do:
>> fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs)
>> Then this gives the result:
>> Call:
>> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age + kidmomhsage$mom_hs +
>>   kidmomhsage$mom_age * kidmomhsage$mom_hs)
>> Coefficients:
>>                          (Intercept)
>>                              110.542
>>                  kidmomhsage$mom_age
>>                               -1.522
>>                   kidmomhsage$mom_hs
>>                              -41.287
>> kidmomhsage$mom_age:kidmomhsage$mom_hs
>>                                2.391
>> Where the interaction term now seems properly interpretable. So perhaps this is the way to use interaction terms with lm.
> 
> But why does
> 
> fit3 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> also give exactly the same result:
> 
> Call:
> lm(formula = kidmomhsage$kid_score ~ kidmomhsage$mom_age * kidmomhsage$mom_hs)
> 
> Coefficients:
>                           (Intercept)
>                               110.542
>                   kidmomhsage$mom_age
>                                -1.522
>                    kidmomhsage$mom_hs
>                               -41.287
> kidmomhsage$mom_age:kidmomhsage$mom_hs
>                                 2.391
> 
> It's as if lm is interpreting there having to also be "independent" mom_age and mom_hs variables, if there's just the interaction term. Why does it work this way?

kidmomhsage$mom_age * kidmomhsage$mom_hs 

... is expanded by the formula-engine so that it is exactly:

 kidmomhsage$mom_age + kidmomhsage$mom_hs + kidmomhsage$mom_age:kidmomhsage$mom_hs

(That's essentially the definiton of the `*`-operator in the formula-world.)



David Winsemius
Alameda, CA, USA


From mdsumner at gmail.com  Mon Sep 19 00:41:53 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 18 Sep 2016 22:41:53 +0000
Subject: [R] Accelerating binRead
In-Reply-To: <CAFDcVCTnYn1aHR4xZduinCRnSJQZPVKa8+N6mmSN+7ysBrscHA@mail.gmail.com>
References: <3E1FB75A-732D-4B37-8BD5-15D3C832F2C7@free.fr>
	<CAAxdm-5Xu7bShtpN53DoH3u-G4dD8VajjmtC9UmNSzSq86yNWA@mail.gmail.com>
	<CABOzBw1061MNASx7iThBSQ0EFh730fOErqePVc9EwxM7Six2HQ@mail.gmail.com>
	<CAAxdm-6BnxuBckzGbAepaACpx03mu_XE8jOvE0+EB=Fu-h67oA@mail.gmail.com>
	<B813AE2A-BF10-4812-826B-0D434B064EDE@free.fr>
	<D563E423-2167-41DB-BC82-1502751BA507@free.fr>
	<CAAcGz9_BZmgHeHp5GnBNOd3N5eTDiJTLeS6r6WKgc-RjpEQDjA@mail.gmail.com>
	<A22CB35D-76A5-4BB3-B882-2AE2CFBBB4FD@free.fr>
	<CAFDcVCTnYn1aHR4xZduinCRnSJQZPVKa8+N6mmSN+7ysBrscHA@mail.gmail.com>
Message-ID: <CAAcGz99r+KMCXyb7e+NyH228OmntFucQM7oqAMkayxNZ=m4AtA@mail.gmail.com>

Thanks Henrik, that's it. Fwiw I found this old post too, I am still
surprised this doesn't seem to get used a lot(?). It's a "neat trick" for
row-wise binary, without compiled code.

http://cyclemumner.blogspot.com.au/2010/06/read-las-data-with-r.html?m=1

Also you should look at Paul Murrell's hexView package, and associated R
Journal paper.

Cheers, Mike

On Mon, 19 Sep 2016, 02:20 Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> I second Mike's proposal - it works, e.g.
>
> https://github.com/HenrikBengtsson/affxparser/blob/5bf1a9162904c56d59c4735a8d7eb427e4f085e4/R/readCcg.R#L535-L583
>
> Here's an outline. Say each row consists of tuple (iiii=4-byte
> integer, ffff=4-byte float, ss=2 byte integer) so that the
> byte-by-byte content of your file look like this:
>
>   iiiiffffss
>   iiiiffffss
>   iiiiffffss
>   ...
>   iiiiffffss
>
> Then read this is as raw bytes (file_size can also be a very large
> number in case it's unknown):
>
>   raw <- readBin(con, what="raw", n=file_size)
>
> Turn into a (4+4+2)-by-K raw matrix:
>
>   raw <- matrix(raw, nrow=4+4+2)
>
> so that your raw bytes has the following layout:
>
>   iii ... i
>   iii ... i
>   iii ... i
>   iii ... i
>   fff ... f
>   fff ... f
>   fff ... f
>   fff ... f
>   sss ... s
>   sss ... s
>
> Then extract the three submatrices of interest:
>
>   iiii <- raw[1:4,]
>   ffff <- raw[5:8,]
>   ss <- raw[9:10,]
>
> Here you can discard raw, i.e. rm(list="raw").
>
> Since R stores matrices in a column-by-column order internally, your
> bytes are already in the proper order.  Finally, re-read these with
> appropriate readBin() settings, e.g.
>
>   i <- readBin(iiii, what="integer", size=4L)
>   f <- readBin(ffff, what="double", size=4L)
>   s <- readBin(ss, what="integer", size=2L)
>
> Put into a 3-by-K data.frame:
>
>   data <- data.frame(i=i, f=f, s=s)
>
> /Henrik
>
> On Sun, Sep 18, 2016 at 8:02 AM, Philippe de Rochambeau <phiroc at free.fr>
> wrote:
> > I would gladly examine your example, Mike.
> > Cheers,
> > Philippe
> >
> >> Le 18 sept. 2016 ? 16:05, Michael Sumner <mdsumner at gmail.com> a ?crit :
> >>
> >>
> >>
> >>> On Sun, 18 Sep 2016, 19:04 Philippe de Rochambeau <phiroc at free.fr>
> wrote:
> >>> Please find below code that attempts to read ints, longs and floats
> from a binary file (which is a simplification of my original program).
> >>> Please disregard the R inefficiencies, such as using rbind, for now.
> >>> I?ve also included Java code to generate the binary file.
> >>> The output shows that, at one point, anInt becomes undefined.
> Unfortunately, I couldn?t find the correct R function to determine whether
> inInt is undefined or not, as is.null, is.nan, and is.infinite don?t work.
> >>> Any help would be much appreciated.
> >>> Many thanks in advance.
> >>> Philippe
> >>>
> >>> ???????
> >>> [1] "anInt = 1"
> >>> [1] "is.null  FALSE"
> >>> [1] "is.nan  FALSE"
> >>> [1] "is.infinite  FALSE"
> >>> [1] "aLong = 2"
> >>> [1] "aFloat = 3.44440007209778"
> >>> [1] "--------------------------"
> >>> [1] "anInt = 2"
> >>> [1] "is.null  FALSE"
> >>> [1] "is.nan  FALSE"
> >>> [1] "is.infinite  FALSE"
> >>> [1] "aLong = 22"
> >>> [1] "aFloat = 13.4644002914429"
> >>> [1] "--------------------------"
> >>> [1] "anInt = 3"
> >>> [1] "is.null  FALSE"
> >>> [1] "is.nan  FALSE"
> >>> [1] "is.infinite  FALSE"
> >>> [1] "aLong = 55"
> >>> [1] "aFloat = 45.4444007873535"
> >>> [1] "--------------------------"
> >>> [1] "anInt = "
> >>> [1] "is.null  FALSE"
> >>> [1] "is.nan  "
> >>> [1] "is.infinite  "
> >>> [1] "aLong = "
> >>> [1] "aFloat = "
> >>> [1] "--------------------------"
> >>>      [,1]      [,2]      [,3]
> >>> [1,] 1         2         3.4444
> >>> [2,] 2         22        13.4644
> >>> [3,] 3         55        45.4444
> >>> [4,] Integer,0 Integer,0 Numeric,0
> >>> >
> >>>
> >>> -----------
> >>>
> >>>
> >>> ?????????????????????
> >>>
> >>> readFile <- function(inputPath) {
> >>>   URL <- file(inputPath, "rb")
> >>>   PLT <- matrix(nrow=0, ncol=3)
> >>>   counte <- 0
> >>>   max <- 4
> >>>   while (counte < max) {
> >>>     anInt <- readBin(con=URL, what=integer(), size=4, n=1,
> endian="big")
> >>>     print(paste("anInt =", anInt))
> >>>     #if (! (anInt == 0)) { print(paste("empty int")); break }
> >>>     print(paste("is.null ", is.null(anInt)))
> >>>     print(paste("is.nan ", is.nan(anInt)))
> >>>     print(paste("is.infinite ", is.infinite(anInt)))
> >>>     aLong <- readBin(URL, integer(), size=8, n=1, endian="big")
> >>>     print(paste("aLong =", aLong))
> >>>     aFloat <- readBin(URL, numeric(), size=4, n=1, endian="big")
> >>>     print(paste("aFloat =", aFloat))
> >>>     print("--------------------------")
> >>>     PLT <- rbind(PLT, list(anInt, aLong, aFloat))
> >>>     counte <- counte + 1
> >>>   } # end while
> >>>   close(URL)
> >>>   PLT
> >>> }
> >>> fichier <- "/Users/philippe/Desktop/datatests/data0.bin"
> >>> PLT2 <- readFile(fichier)
> >>> print(PLT2)
> >>> ?????????????????????
> >>>
> >>> import java.io.*;
> >>>
> >>> public class Main {
> >>>
> >>>         Main() {
> >>>                 writeData();
> >>>         }
> >>>
> >>>         public static void main(String[] args) {
> >>>                 new Main();
> >>>         }
> >>>
> >>>         public void writeData() {
> >>>
> >>>                 final String path =
> "/Users/philippe/Desktop/datatests/data0.bin";
> >>>
> >>>                 DataOutputStream dos;
> >>>                 try {
> >>>                         dos = new DataOutputStream(new
> BufferedOutputStream(new FileOutputStream(path)));
> >>>                         // big endian write! ("high byte first") , see
> https://docs.oracle.com/javase/7/docs/api/java/io/DataOutputStream.html
> >>>                         dos.writeInt(1);
> >>>                         dos.writeLong(2L);
> >>>                         dos.writeFloat(3.4444F);
> >>>
> >>>                         dos.writeInt(2);
> >>>                         dos.writeLong(22L);
> >>>                         dos.writeFloat(13.4644F);
> >>>
> >>>                         dos.writeInt(3);
> >>>                         dos.writeLong(55L);
> >>>                         dos.writeFloat(45.4444F);
> >>>
> >>>                         dos.close();
> >>>                 } catch (FileNotFoundException e) {
> >>>                         e.printStackTrace();
> >>>                 } catch (IOException ioe) {
> >>>                         ioe.printStackTrace();
> >>>                 }
> >>>
> >>>         }
> >>>
> >>> }
> >>>
> >>>
> >>> ?????????????????????
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> > Le 17 sept. 2016 ? 20:45, Philippe de Rochambeau <phiroc at free.fr> a
> ?crit :
> >>> >
> >>> > Hi Jim,
> >>> > this is exactly the answer I was look for. Many thanks. I didn?t R
> had a pack function, as in PERL.
> >>> > To answer your earlier question, I am trying to update legacy code
> to read a binary file with unknown size, over a network, slice up it into
> rows each containing an integer, an integer, a long, a short, a float and a
> float, and stuff the rows into a matrix.
> >>
> >>
> >>
> >> It's possible to read all rows fast as raw(), then parse in a
> vectorised way with matrix indexing to group the bytes appropriately. There
> is an example on the mailing list somewhere, but otherwise I can show an
> example if that's of interest.
> >>
> >>
> >> Cheers, Mike
> >>
> >>
> >>> > Best regards,
> >>> > Philippe
> >>> >
> >>> >> Le 17 sept. 2016 ? 20:38, jim holtman <jholtman at gmail.com <mailto:
> jholtman at gmail.com>> a ?crit :
> >>> >>
> >>> >> Here is an example of how to do it:
> >>> >>
> >>> >> x <- 1:10  # integer values
> >>> >> xf <- seq(1.0, 2, by = 0.1)  # floating point
> >>> >>
> >>> >> setwd("d:/temp")
> >>> >>
> >>> >> # create file to write to
> >>> >> output <- file('integer.bin', 'wb')
> >>> >> writeBin(x, output)  # write integer
> >>> >> writeBin(xf, output)  # write reals
> >>> >> close(output)
> >>> >>
> >>> >>
> >>> >> library(pack)
> >>> >> library(readr)
> >>> >>
> >>> >> # read all the data at once
> >>> >> allbin <- read_file_raw('integer.bin')
> >>> >>
> >>> >> # decode the data into a list
> >>> >> (result <- unpack("V V V V V V V V V V d d d d d d d d d d",
> allbin))
> >>> >>
> >>> >>
> >>> >>
> >>> >>
> >>> >> Jim Holtman
> >>> >> Data Munger Guru
> >>> >>
> >>> >> What is the problem that you are trying to solve?
> >>> >> Tell me what you want to do, not how you want to do it.
> >>> >>
> >>> >> On Sat, Sep 17, 2016 at 11:04 AM, Ismail SEZEN <
> sezenismail at gmail.com <mailto:sezenismail at gmail.com><mailto:
> sezenismail at gmail.com <mailto:sezenismail at gmail.com>>> wrote:
> >>> >> I noticed same issue but didnt care much :)
> >>> >>
> >>> >> On Sat, Sep 17, 2016, 18:01 jim holtman <jholtman at gmail.com
> <mailto:jholtman at gmail.com> <mailto:jholtman at gmail.com <mailto:
> jholtman at gmail.com>>> wrote:
> >>> >> Your example was not reproducible.  Also how do you "break" out of
> the
> >>> >> "while" loop?
> >>> >>
> >>> >>
> >>> >> Jim Holtman
> >>> >> Data Munger Guru
> >>> >>
> >>> >> What is the problem that you are trying to solve?
> >>> >> Tell me what you want to do, not how you want to do it.
> >>> >>
> >>> >> On Sat, Sep 17, 2016 at 8:05 AM, Philippe de Rochambeau <
> phiroc at free.fr <mailto:phiroc at free.fr> <mailto:phiroc at free.fr <mailto:
> phiroc at free.fr>>>
> >>> >> wrote:
> >>> >>
> >>> >>> Hello,
> >>> >>> the following function, which stores numeric values extracted from
> a
> >>> >>> binary file, into an R matrix, is very slow, especially when the
> said file
> >>> >>> is several MB in size.
> >>> >>> Should I rewrite the function in inline C or in C/C++ using Rcpp?
> If the
> >>> >>> latter case is true, how do you ? readBin ?  in Rcpp (I?m a total
> Rcpp
> >>> >>> newbie)?
> >>> >>> Many thanks.
> >>> >>> Best regards,
> >>> >>> phiroc
> >>> >>>
> >>> >>>
> >>> >>> -------------
> >>> >>>
> >>> >>> # inputPath is something like http://myintranet/getData <
> http://myintranet/getData><http://myintranet/getData <
> http://myintranet/getData>>?
> >>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin <http://myintranet/getData <
> http://myintranet/getData> <http://myintranet/getData <
> http://myintranet/getData>>?
> >>> >>> pathToFile=/usr/lib/xxx/yyy/data.bin>
> >>> >>>
> >>> >>> PLTreader <- function(inputPath){
> >>> >>>        URL <- file(inputPath, "rb")
> >>> >>>        PLT <- matrix(nrow=0, ncol=6)
> >>> >>>        compteurDePrints = 0
> >>> >>>        compteurDeLignes <- 0
> >>> >>>        maxiPrints = 5
> >>> >>>        displayData <- FALSE
> >>> >>>        while (TRUE) {
> >>> >>>                periodIndex <- readBin(URL, integer(), size=4, n=1,
> >>> >>> endian="little") # int (4 bytes)
> >>> >>>                eventId <- readBin(URL, integer(), size=4, n=1,
> >>> >>> endian="little") # int (4 bytes)
> >>> >>>                dword1 <- readBin(URL, integer(), size=4,
> signed=FALSE,
> >>> >>> n=1, endian="little") # int
> >>> >>>                dword2 <- readBin(URL, integer(), size=4,
> signed=FALSE,
> >>> >>> n=1, endian="little") # int
> >>> >>>                if (dword1 < 0) {
> >>> >>>                        dword1 = dword1 + 2^32-1;
> >>> >>>                }
> >>> >>>                eventDate = (dword2*2^32 + dword1)/1000
> >>> >>>                repNum <- readBin(URL, integer(), size=2, n=1,
> >>> >>> endian="little") # short (2 bytes)
> >>> >>>                exp <- readBin(URL, numeric(), size=4, n=1,
> >>> >>> endian="little") # float (4 bytes, strangely enough, would expect
> 8)
> >>> >>>                loss <- readBin(URL, numeric(), size=4, n=1,
> >>> >>> endian="little") # float (4 bytes)
> >>> >>>                PLT <- rbind(PLT, c(periodIndex, eventId, eventDate,
> >>> >>> repNum, exp, loss))
> >>> >>>        } # end while
> >>> >>>        return(PLT)
> >>> >>>        close(URL)
> >>> >>> }
> >>> >>>
> >>> >>> ----------------
> >>> >>>        [[alternative HTML version deleted]]
> >>> >>>
> >>> >>> ______________________________________________
> >>> >>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:
> R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> >>> >>> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help><
> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>>
> >>> >>> PLEASE do read the posting guide http://www.R-project.org/ <
> http://www.r-project.org/> <http://www.r-project.org/ <
> http://www.r-project.org/>>
> >>> >>> posting-guide.html
> >>> >>> and provide commented, minimal, self-contained, reproducible code.
> >>> >>
> >>> >>        [[alternative HTML version deleted]]
> >>> >>
> >>> >> ______________________________________________
> >>> >> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:
> R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> >>> >> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help><
> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>>
> >>> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html> <
> http://www.r-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html>>
> >>> >> and provide commented, minimal, self-contained, reproducible code.
> >>> >
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> >>> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html>
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Dr. Michael Sumner
> >> Software and Database Engineer
> >> Australian Antarctic Division
> >> 203 Channel Highway
> >> Kingston Tasmania 7050 Australia
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Sep 19 13:41:53 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 12:41:53 +0100
Subject: [R] What are the red line and cut line in lm's Residuals vs
 Fitted	plot?
In-Reply-To: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
References: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE67701B@GBTEDVPEXCMB04.corp.lgc-group.com>

> What are the red line and cut line in lm's Residuals vs Fitted plot?
The dotted line is at 0 and the red line is a locally weighted regression calculated using lowess and plotted using panel.smooth. 

See ?panel.smooth and ?lowess for details

The main clue to this is in the arguments to ?plot.lm, which uses panel.smooth as a panel function. 

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From manu.reddy52 at gmail.com  Mon Sep 19 13:56:06 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Mon, 19 Sep 2016 17:26:06 +0530
Subject: [R] Reg : :How to plot and present the multiple values whenever
 user placed mouse on point it using plotly and ggplot2
Message-ID: <CADG9u0DQijDpu2LJ43RpDToU1uNNUOvhHH_pxvOonwp6nQnmzg@mail.gmail.com>

Hi,

  for my question please browse below url,thanks in advance .

   url :
http://community.plot.ly/t/how-to-plot-and-present-the-multiple-values-whenever-user-placed-mouse-on-point-it-using-plotly-and-ggplot2/2139?u=manohar

Manu.

	[[alternative HTML version deleted]]


From t.fioravanti at pm.univpm.it  Mon Sep 19 10:53:37 2016
From: t.fioravanti at pm.univpm.it (FIORAVANTI TATIANA)
Date: Mon, 19 Sep 2016 08:53:37 +0000
Subject: [R] Problem Mixstock in R
Message-ID: <DB5PR04MB206943D53AACC21A4152F0EEAEF40@DB5PR04MB2069.eurprd04.prod.outlook.com>

Dear members of the R-project

I am doing a mixed stock analysis with the Mixstock Package in R, at the end of the analysis I would summarize all my results (mean, standard deviation, median, percentile, etc...) using the mysum(x, name=NULL) function, but I don't understand which is the correct manner to set up it, what "x" and "name"are? ..Can you help me? Thank you very much,

Tatiana



	[[alternative HTML version deleted]]


From silke.zachariae at imise.uni-leipzig.de  Mon Sep 19 13:53:41 2016
From: silke.zachariae at imise.uni-leipzig.de (Silke Zachariae)
Date: Mon, 19 Sep 2016 13:53:41 +0200
Subject: [R] Problem pyears and left truncated data
Message-ID: <f791da85-12ee-47db-b5cb-ebcd5e18c529@imise.uni-leipzig.de>

Dear all,

for a project I want to calculate cancer incidence rates by decades (0-20,20-30,30-40,..,70-80).
I have left truncated data, my Surv object has the form Surv(time=age,time2=age2, event, type="counting").

I tried different ways to get results for n, events, and person-years, but the results are not as expected.

The best results are for 
pyears(Surv(age,age2,event)~cut(age,c(0, 20,30,40,50,60,70,80))
             +group, data,scale=1)
However, the person-years is too high, since observation time of patients that start before 20 years of age are added completely to the observation decade of 0-20.

Person 1: 18 -31 years of age observation time
Person 2: 18 - 19 years of age observation time

Result gained: n = 2, pyears = 14  for 0-20 years
Result expected: n=2, pyears=3 for 0-20 years

Furthermore, the documentation says, that the cut function is not advised to use, but tcut does not work with my data.

What do I have to do to use the pyears-function for left truncated data? Are there any working examples for that case?

Many thanks and best wishes, Silke Zachariae


From dusa.adrian at unibuc.ro  Mon Sep 19 13:59:42 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 19 Sep 2016 14:59:42 +0300
Subject: [R] separate commands by semicolon
In-Reply-To: <CA+hbrhXWDPmL6=_xY_jADmR2kK03Y9EnFAW597-B0AsFi8or3A@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
	<CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
	<10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>
	<CA+hbrhXWDPmL6=_xY_jADmR2kK03Y9EnFAW597-B0AsFi8or3A@mail.gmail.com>
Message-ID: <CAJ=0CtDWvrSAqMFNLdZ+wUPk6-NQEdmKKWRgbcMkWuNXQ_4xYQ@mail.gmail.com>

On Sun, Sep 18, 2016 at 12:34 AM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> On Sat, Sep 17, 2016 at 2:12 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> > Not entirely clear. If you were intending to just get character output
> then you could just use:
> >
> > strsplit(txt, ";")
>
> You would want to avoid splitting within character strings
> (print(";")) and in comments (print(2); ls() # This prints 2; then
> lists...) The comment char could also appear in a character string,
> where it does not mean the start of a comment...


Yes, that would be the problem.
Returning to my original post, modifying the example:

x <- "print(2); bar <- \"don't ; use semicolons\"; foo <- '3;4'; ls("

This should result in a character vector of length 4:
[1] "print(2)"                          "bar <- \"don't ; use semicolons\""
[3] "foo <- '3;4'"                      "ls("

even though the last command would cause an error using parse(text = x)

Perhaps this is not that important (I am trying to simulate a normal R
console), and parse only if it syntactically correct.
I was merely curious if this could be done, likely using regular
expressions (surely strsplit doesn't solve it).

Best,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From mkashif at uaf.edu.pk  Mon Sep 19 14:09:31 2016
From: mkashif at uaf.edu.pk (Muhammad  Kashif)
Date: Mon, 19 Sep 2016 12:09:31 +0000
Subject: [R] add outlier in data set
Message-ID: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>

dear r users

I have one question that how we add one or more outliers in the data set.


For example if we generate data set from Weibull distribution using function

n=10
k<-rweibull(n, shape=2.5, scale = 1.3)
k

the output is

> k
 [1] 0.6507619 0.6229385 1.6838931 1.1661324 0.4907947 1.3416666 0.9536739 0.9368029 1.1992996
[10] 0.8401084


now i want to add outlier in the output of the values.

In simple words i want to generate a data set and then i add one or two outlier in that data set.

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Sep 19 14:15:20 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 13:15:20 +0100
Subject: [R] add outlier in data set
In-Reply-To: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
References: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>

> I have one question that how we add one or more outliers in the data set.
See ?c to add values to a vector.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From murdoch.duncan at gmail.com  Mon Sep 19 14:19:48 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Sep 2016 08:19:48 -0400
Subject: [R] separate commands by semicolon
In-Reply-To: <CAJ=0CtDWvrSAqMFNLdZ+wUPk6-NQEdmKKWRgbcMkWuNXQ_4xYQ@mail.gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
	<CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
	<10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>
	<CA+hbrhXWDPmL6=_xY_jADmR2kK03Y9EnFAW597-B0AsFi8or3A@mail.gmail.com>
	<CAJ=0CtDWvrSAqMFNLdZ+wUPk6-NQEdmKKWRgbcMkWuNXQ_4xYQ@mail.gmail.com>
Message-ID: <830aee6b-7211-3b82-2ec1-6457421f30df@gmail.com>

On 19/09/2016 7:59 AM, Adrian Du?a wrote:
> On Sun, Sep 18, 2016 at 12:34 AM, Peter Langfelder <
> peter.langfelder at gmail.com> wrote:
>
> > On Sat, Sep 17, 2016 at 2:12 PM, David Winsemius <dwinsemius at comcast.net>
> > wrote:
> > > Not entirely clear. If you were intending to just get character output
> > then you could just use:
> > >
> > > strsplit(txt, ";")
> >
> > You would want to avoid splitting within character strings
> > (print(";")) and in comments (print(2); ls() # This prints 2; then
> > lists...) The comment char could also appear in a character string,
> > where it does not mean the start of a comment...
>
>
> Yes, that would be the problem.
> Returning to my original post, modifying the example:
>
> x <- "print(2); bar <- \"don't ; use semicolons\"; foo <- '3;4'; ls("
>
> This should result in a character vector of length 4:
> [1] "print(2)"                          "bar <- \"don't ; use semicolons\""
> [3] "foo <- '3;4'"                      "ls("
>
> even though the last command would cause an error using parse(text = x)
>
> Perhaps this is not that important (I am trying to simulate a normal R
> console), and parse only if it syntactically correct.
> I was merely curious if this could be done, likely using regular
> expressions (surely strsplit doesn't solve it).
>
> Best,
> Adrian
>
See the section on "partial parsing" in the ?parse help page.

Duncan Murdoch


From S.Ellison at LGCGroup.com  Mon Sep 19 14:22:52 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 13:22:52 +0100
Subject: [R] Request for R code
In-Reply-To: <CAF76zB8djNY_-8zpt+LtTwZHMVqo0NZrQ=ynmciri4Shei99+Q@mail.gmail.com>
References: <CAF76zB8djNY_-8zpt+LtTwZHMVqo0NZrQ=ynmciri4Shei99+Q@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE677038@GBTEDVPEXCMB04.corp.lgc-group.com>

> Heyy I want to apply LASSO method in AFT model. So can you guys please help
> me by sending R code for that.

Try
help.search("LASSO")
or 
RSiteSearch("LASSO")
or Google "LASSO method in AFT using R"

There are leads in both.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mkashif at uaf.edu.pk  Mon Sep 19 14:25:08 2016
From: mkashif at uaf.edu.pk (Muhammad  Kashif)
Date: Mon, 19 Sep 2016 12:25:08 +0000
Subject: [R] add outlier in data set
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>,
	<1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>

Dear Ellison

yes its working but if i want to replaced the any value in the the output . e.g i want to replace 0.65 with 10. then what i do

________________________________
From: S Ellison <S.Ellison at LGCGroup.com>
Sent: Monday, September 19, 2016 5:15:20 PM
To: Muhammad Kashif; r-help at r-project.org
Subject: RE: add outlier in data set

> I have one question that how we add one or more outliers in the data set.
See ?c to add values to a vector.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:11}}


From mviljamaa at kapsi.fi  Mon Sep 19 14:31:56 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Mon, 19 Sep 2016 15:31:56 +0300
Subject: [R] What are the red line and cut line in lm's Residuals vs
 Fitted	plot?
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FE67701B@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
	<1A8C1289955EF649A09086A153E2672403FE67701B@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <2ec8b7ad282e3fb43ee60c3dc2698359@kapsi.fi>

Do you mean that the red line is a regression line?
Why is the regression (line) weighted?

On 2016-09-19 14:41, S Ellison wrote:
>> What are the red line and cut line in lm's Residuals vs Fitted plot?
> The dotted line is at 0 and the red line is a locally weighted
> regression calculated using lowess and plotted using panel.smooth.
> 
> See ?panel.smooth and ?lowess for details
> 
> The main clue to this is in the arguments to ?plot.lm, which uses
> panel.smooth as a panel function.
> 
> S Ellison
> 
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From petr.pikal at precheza.cz  Mon Sep 19 14:49:01 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 19 Sep 2016 12:49:01 +0000
Subject: [R] add outlier in data set
In-Reply-To: <VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
References: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>,
	<1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>
	<VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503D93E@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Muhammad Kashif
> Sent: Monday, September 19, 2016 2:25 PM
> To: S Ellison <S.Ellison at LGCGroup.com>; r-help at r-project.org
> Subject: Re: [R] add outlier in data set
>
> Dear Ellison
>
> yes its working but if i want to replaced the any value in the the output . e.g i
> want to replace 0.65 with 10. then what i do

If you hav vector x and want to replace value 0.65 by 10 you can do

x[x == .65] <- 10

However it is not as easy as it seems. It is possible that value 0.65 cannot be matched exactly.

see
vec <- c(650, 65, 6.5, 0.65, .065)
x <- vec/c(1000, 100, 10, 1, 0.1)
x<-c(x, sqrt(.65)^2)
x==.65
[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
x
[1] 0.65 0.65 0.65 0.65 0.65 0.65

The last value is slightly different from 0.65. See FEQ 7.31 for explanation of floating point behaviour.

It is prefarable to use rounding with floating point comparison.

round(x,2)==.65
 [1] TRUE TRUE TRUE TRUE TRUE TRUE

Cheers
Petr



>
> ________________________________
> From: S Ellison <S.Ellison at LGCGroup.com>
> Sent: Monday, September 19, 2016 5:15:20 PM
> To: Muhammad Kashif; r-help at r-project.org
> Subject: RE: add outlier in data set
>
> > I have one question that how we add one or more outliers in the data set.
> See ?c to add values to a vector.
>
> S Ellison
>
>
> **********************************************************
> *********
> This email and any attachments are confidential. Any use...{{dropped:11}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From nznajad28 at yahoo.com  Mon Sep 19 14:15:38 2016
From: nznajad28 at yahoo.com (najad zamirah zaki)
Date: Mon, 19 Sep 2016 12:15:38 +0000 (UTC)
Subject: [R] Density plot error
References: <120656726.819703.1474287339007.ref@mail.yahoo.com>
Message-ID: <120656726.819703.1474287339007@mail.yahoo.com>

Hi,
I'm Najad, a student at the University of Glasgow. I really need help with a script of mine to plot density plot for my data. I kept on having an error saying?need at least 2 points to select a bandwidth automaticallyI've tried to replace the NaN in my data to zero but still the same. I'm not good with R and don't understand the coding language so I need help on this. I've attached here the data and the script that I use. I use R version 3.1.1
Thank you?Warm regards,Najad Zaki

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: peptides.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160919/10d536e9/attachment.txt>

From S.Ellison at LGCGroup.com  Mon Sep 19 15:43:47 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 14:43:47 +0100
Subject: [R] What are the red line and cut line in lm's Residuals vs
 Fitted	plot?
In-Reply-To: <2ec8b7ad282e3fb43ee60c3dc2698359@kapsi.fi>
References: <f1d8ee562d9ce3ac9836e87fb9269e6a@kapsi.fi>
	<1A8C1289955EF649A09086A153E2672403FE67701B@GBTEDVPEXCMB04.corp.lgc-group.com>
	<2ec8b7ad282e3fb43ee60c3dc2698359@kapsi.fi>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE677092@GBTEDVPEXCMB04.corp.lgc-group.com>

> Do you mean that the red line is a regression line?
> Why is the regression (line) weighted?
I suggest you look up 'locally weighted regression' to find out why that is useful and what it is for.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From dusa.adrian at unibuc.ro  Mon Sep 19 15:54:48 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 19 Sep 2016 16:54:48 +0300
Subject: [R] separate commands by semicolon
In-Reply-To: <830aee6b-7211-3b82-2ec1-6457421f30df@gmail.com>
References: <CAJ=0CtBJiwt9h9VuCt5-t=4k6Z6L2_4KiLR-i6MOwk+hdanwVw@mail.gmail.com>
	<CAF8bMcaFdNx0zbw2kyetg_Ac80Qndz8eDy3VKkVF6+mav75DyA@mail.gmail.com>
	<CAJ=0CtB8TY4S3xa0+AsZ-5u08gwKH=XOtH4h9P14cTkaZ9Q1JA@mail.gmail.com>
	<CAJ=0CtBKYGt4Jo_+ECf_J6oxmr6=QDi5cFdSrNvCyre56k-Ynw@mail.gmail.com>
	<10E32FE0-F5E4-4F2A-ADC1-A177F1178C97@comcast.net>
	<CA+hbrhXWDPmL6=_xY_jADmR2kK03Y9EnFAW597-B0AsFi8or3A@mail.gmail.com>
	<CAJ=0CtDWvrSAqMFNLdZ+wUPk6-NQEdmKKWRgbcMkWuNXQ_4xYQ@mail.gmail.com>
	<830aee6b-7211-3b82-2ec1-6457421f30df@gmail.com>
Message-ID: <CAJ=0CtAuev_Hw14Fdk8aEWqaKR0Xwd-JxHZjY05so2Fm8qAL8g@mail.gmail.com>

Oh yes, completely forgot about partial parsing. One possible (quick)
solution:

txt <- "print(2); bar <- \"don't ; use semicolons\"; foo <- '3;4'; ls("
sf <- srcfile("txt")
tryit <- tryCatch(parse(text = txt, srcfile = sf), error = identity)
gpd <- getParseData(sf)
pos <- c(0, gpd$col1[gpd$token == "';'"], nchar(txt) + 1)
final <- c()
for (i in seq(length(pos) - 1)) {
    final <- c(final, substr(txt, pos[i] + 1, pos[i + 1] - 1))
}

Which outputs:
[1] "print(2)"                           " bar <- \"don't ; use
semicolons\""
[3] " foo <- '3;4'"                      " ls("

Excellent, thanks very much,
Adrian



On Mon, Sep 19, 2016 at 3:19 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/09/2016 7:59 AM, Adrian Du?a wrote:
>
>> On Sun, Sep 18, 2016 at 12:34 AM, Peter Langfelder <
>> peter.langfelder at gmail.com> wrote:
>>
>> > On Sat, Sep 17, 2016 at 2:12 PM, David Winsemius <
>> dwinsemius at comcast.net>
>> > wrote:
>> > > Not entirely clear. If you were intending to just get character output
>> > then you could just use:
>> > >
>> > > strsplit(txt, ";")
>> >
>> > You would want to avoid splitting within character strings
>> > (print(";")) and in comments (print(2); ls() # This prints 2; then
>> > lists...) The comment char could also appear in a character string,
>> > where it does not mean the start of a comment...
>>
>>
>> Yes, that would be the problem.
>> Returning to my original post, modifying the example:
>>
>> x <- "print(2); bar <- \"don't ; use semicolons\"; foo <- '3;4'; ls("
>>
>> This should result in a character vector of length 4:
>> [1] "print(2)"                          "bar <- \"don't ; use
>> semicolons\""
>> [3] "foo <- '3;4'"                      "ls("
>>
>> even though the last command would cause an error using parse(text = x)
>>
>> Perhaps this is not that important (I am trying to simulate a normal R
>> console), and parse only if it syntactically correct.
>> I was merely curious if this could be done, likely using regular
>> expressions (surely strsplit doesn't solve it).
>>
>> Best,
>> Adrian
>>
>> See the section on "partial parsing" in the ?parse help page.
>
> Duncan Murdoch
>
>


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Sep 19 15:57:43 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 14:57:43 +0100
Subject: [R] add outlier in data set
In-Reply-To: <VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
References: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>,
	<1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>
	<VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE6770AE@GBTEDVPEXCMB04.corp.lgc-group.com>

> yes its working but if i want to replaced the any value in the the output . e.g i
> want to replace 0.65 with 10. then what i do

Read "An introduction to R" in your R help system (help.start() if you cannot find the menu item). Section 2 and particularly 2.7 is essential reading for what you are trying to do.

See also the Note and examples in ?"==" which are also essential reading for comparisons involving floating point numbers; also FAQ 7.31.

S Ellison





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mviljamaa at kapsi.fi  Mon Sep 19 17:50:03 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Mon, 19 Sep 2016 18:50:03 +0300
Subject: [R] Overlapping axis numbering and labels when using par(new=TRUE)?
Message-ID: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>

I'm trying to plot two data sets on the same plot by using 
par(new=TRUE).

However this results in the axis numbering and labels being plotted 
twice as seen in the following picture:

http://i.imgur.com/4b1sNIc.png

How can I get the axis numbering and labels to not overlap? I could also 
manage with plotting only the axis numbering and labels of the other 
plot, but not of the other.


From jdnewmil at dcn.davis.ca.us  Mon Sep 19 17:56:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 19 Sep 2016 08:56:20 -0700
Subject: [R] Density plot error
In-Reply-To: <120656726.819703.1474287339007@mail.yahoo.com>
References: <120656726.819703.1474287339007.ref@mail.yahoo.com>
	<120656726.819703.1474287339007@mail.yahoo.com>
Message-ID: <5BF5E80A-FC41-4F79-8B6F-DFEE43A6DD43@dcn.davis.ca.us>

You desperately need to read the Posting Guide mentioned at the bottom of every posting on this list. Avoid attachments (your code did not come through), keep sample data size minimal, don't reply to other topic messages (start a fresh email thread so your message doesn't get buried in other people's mailboxes.). Ideally you will provide sample data as part of your sample code using dput, but you may be having difficulty reading the data into memory in the first place so you might not be ready for that. Also [1] would probably be helpful to you. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
-- 
Sent from my phone. Please excuse my brevity.

On September 19, 2016 5:15:38 AM PDT, najad zamirah zaki via R-help <r-help at r-project.org> wrote:
>Hi,
>I'm Najad, a student at the University of Glasgow. I really need help
>with a script of mine to plot density plot for my data. I kept on
>having an error saying?need at least 2 points to select a bandwidth
>automaticallyI've tried to replace the NaN in my data to zero but still
>the same. I'm not good with R and don't understand the coding language
>so I need help on this. I've attached here the data and the script that
>I use. I use R version 3.1.1
>Thank you?Warm regards,Najad Zaki
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Sep 19 18:03:03 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 19 Sep 2016 16:03:03 +0000
Subject: [R] Overlapping axis numbering and labels when using
 par(new=TRUE)?
In-Reply-To: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
References: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
Message-ID: <D4055A07.1866F2%macqueen1@llnl.gov>

Take a look at what

 plot(1:10, yaxt='n', xaxt='n')

does. Then study the help page for the par function, i.e.,

?par

See also

?axis

-Don
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/19/16, 8:50 AM, "R-help on behalf of mviljamaa"
<r-help-bounces at r-project.org on behalf of mviljamaa at kapsi.fi> wrote:

>I'm trying to plot two data sets on the same plot by using
>par(new=TRUE).
>
>However this results in the axis numbering and labels being plotted
>twice as seen in the following picture:
>
>http://i.imgur.com/4b1sNIc.png
>
>How can I get the axis numbering and labels to not overlap? I could also
>manage with plotting only the axis numbering and labels of the other
>plot, but not of the other.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kanikasahni.90 at gmail.com  Mon Sep 19 12:39:46 2016
From: kanikasahni.90 at gmail.com (Kanika Sahni)
Date: Mon, 19 Sep 2016 16:09:46 +0530
Subject: [R] help
Message-ID: <CAMfVGyS0D3Av49mg+2MnWEtrMk2a468Yb2r0sxozayGAUsZ5_A@mail.gmail.com>

Input1: A list of distinct numbers,L1
Input2: A single number, T

Output all combinations of L1 that can yield T using +,-,*,/.

eq:
L1=[4,5,2,3] and T=6. Output: [2*3],[2+4],[5+3-2],[3*4/2] ..... all other
combinations.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep 19 22:09:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Sep 2016 13:09:19 -0700
Subject: [R] help
In-Reply-To: <CAMfVGyS0D3Av49mg+2MnWEtrMk2a468Yb2r0sxozayGAUsZ5_A@mail.gmail.com>
References: <CAMfVGyS0D3Av49mg+2MnWEtrMk2a468Yb2r0sxozayGAUsZ5_A@mail.gmail.com>
Message-ID: <CAGxFJbR6DEMTeJbJHrNv1A+-Scm7FhM1QENquEf9MewWGumQnw@mail.gmail.com>

This looks like homework. We don't do homework here (if we can avoid
it). Ask your prof/TA for help.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 19, 2016 at 3:39 AM, Kanika Sahni <kanikasahni.90 at gmail.com> wrote:
> Input1: A list of distinct numbers,L1
> Input2: A single number, T
>
> Output all combinations of L1 that can yield T using +,-,*,/.
>
> eq:
> L1=[4,5,2,3] and T=6. Output: [2*3],[2+4],[5+3-2],[3*4/2] ..... all other
> combinations.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Sep 19 23:06:03 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Sep 2016 14:06:03 -0700
Subject: [R] Overlapping axis numbering and labels when using
	par(new=TRUE)?
In-Reply-To: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
References: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
Message-ID: <D6B7E78C-9071-4CFB-BB41-223386B6D9A0@comcast.net>


> On Sep 19, 2016, at 8:50 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I'm trying to plot two data sets on the same plot by using par(new=TRUE).
> 
> However this results in the axis numbering and labels being plotted twice as seen in the following picture:
> 
> http://i.imgur.com/4b1sNIc.png
> 
> How can I get the axis numbering and labels to not overlap? I could also manage with plotting only the axis numbering and labels of the other plot, but not of the other.

You need to set the ylim values of both plots to the same range, and suppress plotting of the ylab in one of hte plot calls.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon Sep 19 23:08:04 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 20 Sep 2016 07:08:04 +1000
Subject: [R] Overlapping axis numbering and labels when using
	par(new=TRUE)?
In-Reply-To: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
References: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
Message-ID: <CA+8X3fV7M=KwL4aqZyGtQMpArDEnfG7uKMb65BLeULCj14fUEA@mail.gmail.com>

Hi mviljamaa,
Have a look a the twoord.plot function in the plotrix package.

Jim


On Tue, Sep 20, 2016 at 1:50 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> I'm trying to plot two data sets on the same plot by using par(new=TRUE).
>
> However this results in the axis numbering and labels being plotted twice as
> seen in the following picture:
>
> http://i.imgur.com/4b1sNIc.png
>
> How can I get the axis numbering and labels to not overlap? I could also
> manage with plotting only the axis numbering and labels of the other plot,
> but not of the other.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Sep 19 23:39:56 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Sep 2016 22:39:56 +0100
Subject: [R] Overlapping axis numbering and labels when using
 par(new=TRUE)?
In-Reply-To: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
References: <ced7211290ad8b08281dd756f1f2481c@kapsi.fi>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE7A2E72@GBTEDVPEXCMB04.corp.lgc-group.com>

> How can I get the axis numbering and labels to not overlap? I could also

Try specifying las=2 in your plot command?
See ?plot.default and ?par

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jwd at surewest.net  Tue Sep 20 02:41:04 2016
From: jwd at surewest.net (John Dougherty)
Date: Mon, 19 Sep 2016 17:41:04 -0700
Subject: [R] add outlier in data set
In-Reply-To: <VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
References: <VI1PR07MB13258ACB4D4B6231AAFD819B94F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FE677030@GBTEDVPEXCMB04.corp.lgc-group.com>
	<VI1PR07MB1325E596E27ACF8D6F9180B394F40@VI1PR07MB1325.eurprd07.prod.outlook.com>
Message-ID: <20160919174104.50e13b9a@draco>

On Mon, 19 Sep 2016 12:25:08 +0000
"Muhammad  Kashif" <mkashif at uaf.edu.pk> wrote:

> Dear Ellison
> 
> yes its working but if i want to replaced the any value in the the
> output . e.g i want to replace 0.65 with 10. then what i do
> 
Save the data as a CSV file.  Edit the file with a basic ascii text
editor (these days unicode perhaps).  Read the new data back into R.
There also ways to do this within R:

https://therostrumblog.wordpress.com/2014/01/29/basic-data-frame-manipulations-in-r/ 

see "Altering a value".

There is a great deal of "help" in R using either the "?" or
apropos().  It is worth using these.  Also some useful free books are
available from the R Project site.  

-- 

John


From miaojpm at gmail.com  Tue Sep 20 05:37:30 2016
From: miaojpm at gmail.com (John)
Date: Mon, 19 Sep 2016 20:37:30 -0700
Subject: [R] Return the indices of rows of a data frame
Message-ID: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>

Hi,

   I have the following dataframe:

> temp<-data.frame(a=c(1,1,2), b=2:4, c=1:3)
> row.names(temp)<-c("D", "E", "F")
> temp
  a b c
D 1 2 1
E 1 3 2
F 2 4 3

   I would like R to tell me which rows has value "a" equal to 1. The
answer is the first row and the second row, or row D and row E. Which
function should i use? function subset? function which?

   Thanks!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 20 06:06:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 19 Sep 2016 21:06:38 -0700
Subject: [R] Return the indices of rows of a data frame
In-Reply-To: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
References: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
Message-ID: <AD10EE55-8C5B-4F5D-9343-C6DF43F4CABB@dcn.davis.ca.us>

What do you think?
This is covered in the Introduction to R document that comes with R.
-- 
Sent from my phone. Please excuse my brevity.

On September 19, 2016 8:37:30 PM PDT, John <miaojpm at gmail.com> wrote:
>Hi,
>
>   I have the following dataframe:
>
>> temp<-data.frame(a=c(1,1,2), b=2:4, c=1:3)
>> row.names(temp)<-c("D", "E", "F")
>> temp
>  a b c
>D 1 2 1
>E 1 3 2
>F 2 4 3
>
>   I would like R to tell me which rows has value "a" equal to 1. The
>answer is the first row and the second row, or row D and row E. Which
>function should i use? function subset? function which?
>
>   Thanks!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tatekorea at gmail.com  Mon Sep 19 22:34:35 2016
From: tatekorea at gmail.com (GwanSeon Kim)
Date: Mon, 19 Sep 2016 16:34:35 -0400
Subject: [R] Errors in Raster to Point
Message-ID: <CAAVy6R+5bzWOy1xVf=ZA_nvXrGDPnkQs-pej=YR1w7gdMwZtfg@mail.gmail.com>

Hi, all
I am just beginner to use R.
I am working with TIF image file, and the information about the raster is
following:

class       : RasterLayer
dimensions  : 11150, 21808, 243159200  (nrow, ncol, ncell)
resolution  : 30, 30  (x, y)
extent      : 569685, 1223925, 1513995, 1848495  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
+y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0
data source :
C:\Users\Gwan\AppData\Local\Temp\Rtmpg506Ee\raster\r_tmp_2016-09-14_122409_6260_09589.grd
names       : test_map
values      : 1, 225  (min, max)
attributes  :
       ID OBJECTID Value Red Green Blue   Count               Class_Name
Opacity
 from:  0        2     1   1     0    0 5982503                     Corn
    1
 to  : 48      255   254   0     0    0   10336 Dbl Crop Barley/Soybeans
    1



>From this Rasterlayer, I want to convert raster to point for each pixel
based on "Value (one of column name)" and create a raster with
georeferenced information.
I used code as following: RP <- rasterToPoints(KY_raster)
However, I could not get the points and have an error message "cannot
allocate vector of size 5.4 Gb" and "Your computer is low on memory. Save
your files and close these programs".
Could someone please help me how I can convert to raster to points??
Best,

	[[alternative HTML version deleted]]


From mwojnowicz at cylance.com  Tue Sep 20 01:38:32 2016
From: mwojnowicz at cylance.com (Mike Wojnowicz)
Date: Mon, 19 Sep 2016 23:38:32 +0000
Subject: [R] Where is R installed on my Linux?
Message-ID: <D405C506.266F%mwojnowicz@cylance.com>

I have successfully installed R on my AWS EC2 r3.8 box running Linux with
>sudo yum install -y R

However, I cannot find R anywhere (which I want for the sake of tar'ing it up and decompressing to make future installations easier.)  For example,

> rpm -ql R

Says there is nothing to show.

Does anyone have any ideas?

-Mike





	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Sep 20 08:32:54 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 20 Sep 2016 16:32:54 +1000
Subject: [R] Where is R installed on my Linux?
In-Reply-To: <D405C506.266F%mwojnowicz@cylance.com>
References: <D405C506.266F%mwojnowicz@cylance.com>
Message-ID: <CA+8X3fVgOd=E=_et4A7N=37DTX_Xx1uLPU7z_Jiz9v9yi+_5YQ@mail.gmail.com>

Hi Mike,
Depending upon the flavor of Linux (looks like it's in the RedHat
family) it will usually start by running the command "R" in a
terminal. What does:

which R

say? Then look in the startup file (often in /usr/local/bin) for the
R_HOME directory.

Jim


On Tue, Sep 20, 2016 at 9:38 AM, Mike Wojnowicz <mwojnowicz at cylance.com> wrote:
> I have successfully installed R on my AWS EC2 r3.8 box running Linux with
>>sudo yum install -y R
>
> However, I cannot find R anywhere (which I want for the sake of tar'ing it up and decompressing to make future installations easier.)  For example,
>
>> rpm -ql R
>
> Says there is nothing to show.
>
> Does anyone have any ideas?
>
> -Mike
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Tue Sep 20 09:10:42 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 20 Sep 2016 09:10:42 +0200
Subject: [R] Where is R installed on my Linux?
References: <D405C506.266F%mwojnowicz@cylance.com>
Message-ID: <87wpi7nj0t.fsf@hornfels.zedat.fu-berlin.de>

Mike Wojnowicz <mwojnowicz at cylance.com> writes:

> I have successfully installed R on my AWS EC2 r3.8 box running Linux with
>>sudo yum install -y R
>
> However, I cannot find R anywhere (which I want for the sake of
> tar'ing it up and decompressing to make future installations easier.)
> For example,
>
>> rpm -ql R
>
> Says there is nothing to show.
>
> Does anyone have any ideas?
>
> -Mike

If you run

  yum info R

you'll find this description:

  This is a metapackage that provides both core R userspace and
  all R development components.

The metapackage consists of 'r-core' plus various other packages.  These
are the packages that 'rpm' sees.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From mviljamaa at kapsi.fi  Tue Sep 20 10:00:51 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Tue, 20 Sep 2016 11:00:51 +0300
Subject: [R] Using lm's subset parameter results in Error in xj[i] : invalid
 subscript type 'list'
Message-ID: <09254fcb83553e3295bbf3370ceeb97f@kapsi.fi>

I'm trying to take lm on a subset of my dataset and to do this I believe 
I need to pass my subset of the data as the subset parameter of lm.

So I do my subsetting:

firstkids <- kidmomhsage[0:234,], i.e. the first 234 rows of the data 
frame.

Then construct the model:

fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs, 
subset=firstkids)

which results in:

Error in xj[i] : invalid subscript type 'list'

I read somewhere a recommendation to use "unlist":

fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age + 
kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs, 
subset=unlist(firstkids))

which seems to not produce the error and results in some sort of model, 
but is this model the correct one (i.e. for the data set firstkids, just 
as it originally appears)? How does unlist change the data?


From mdsumner at gmail.com  Tue Sep 20 10:01:38 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 20 Sep 2016 08:01:38 +0000
Subject: [R] Errors in Raster to Point
In-Reply-To: <CAAVy6R+5bzWOy1xVf=ZA_nvXrGDPnkQs-pej=YR1w7gdMwZtfg@mail.gmail.com>
References: <CAAVy6R+5bzWOy1xVf=ZA_nvXrGDPnkQs-pej=YR1w7gdMwZtfg@mail.gmail.com>
Message-ID: <CAAcGz99V=baTPDwHX+YrCDBaKS4HX5DS-XC3qGAPMGYKqDtOCw@mail.gmail.com>

On Tue, 20 Sep 2016, 15:55 GwanSeon Kim <tatekorea at gmail.com> wrote:

> Hi, all
> I am just beginner to use R.
> I am working with TIF image file, and the information about the raster is
> following:
>
> class       : RasterLayer
> dimensions  : 11150, 21808, 243159200  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 569685, 1223925, 1513995, 1848495  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0
> data source :
>
> C:\Users\Gwan\AppData\Local\Temp\Rtmpg506Ee\raster\r_tmp_2016-09-14_122409_6260_09589.grd
> names       : test_map
> values      : 1, 225  (min, max)
> attributes  :
>        ID OBJECTID Value Red Green Blue   Count               Class_Name
> Opacity
>  from:  0        2     1   1     0    0 5982503                     Corn
>     1
>  to  : 48      255   254   0     0    0   10336 Dbl Crop Barley/Soybeans
>     1
>
>
>
> >From this Rasterlayer, I want to convert raster to point for each pixel
> based on "Value (one of column name)" and create a raster with
> georeferenced information.
> I used code as following: RP <- rasterToPoints(KY_raster)
> However, I could not get the points and have an error message "cannot
> allocate vector of size 5.4 Gb" and "Your computer is low on memory. Save
> your files and close these programs".
> Could someone please help me how I can convert to raster to points??
> Best,
>


The First question is why? The point (centre)coordinates of every pixel are
massively redundant since they are a simple function of cell index and the
raster's extent.

You might try as.data.frame with xy =TRUE to avoid any overhead in casting
to Spatial, but still it's very likely that this is just a step towards
your actual goal. Tell us what you want to do and I am sure there is a
better way.

Cheers, Mike

>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From cimentadaj at gmail.com  Tue Sep 20 10:14:24 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Tue, 20 Sep 2016 10:14:24 +0200
Subject: [R] Using lm's subset parameter results in Error in xj[i] :
 invalid subscript type 'list'
In-Reply-To: <09254fcb83553e3295bbf3370ceeb97f@kapsi.fi>
References: <09254fcb83553e3295bbf3370ceeb97f@kapsi.fi>
Message-ID: <CALdB+JEhKLAuHm35ckdqkMnGgLGSuP0JhdeGpJCd5n7qpOpkjw@mail.gmail.com>

By subsetting the rows in the firstkids data frame, you've already
subsetted your data.

Try specifying firstkids as your data instead of a subset in the lm call.
Also, eliminate the kidmomhsage prefix from all of your variables since
you're running the linear model on a different data frame(firstkids)

Something along this line:

lm(kid_score ~ mom_age ...., data = firstkids)

*Jorge Cimentada*
*Ph.D. Candidate*
Dpt. Ci?ncies Pol?tiques i Socials
Ramon Trias Fargas, 25-27 | 08005 Barcelona

Office 24.331
[Tel.] 697 382 009
jorge.cimentada at upf.edu
http://www.upf.edu/dcpis/



On Tue, Sep 20, 2016 at 10:00 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:

> I'm trying to take lm on a subset of my dataset and to do this I believe I
> need to pass my subset of the data as the subset parameter of lm.
>
> So I do my subsetting:
>
> firstkids <- kidmomhsage[0:234,], i.e. the first 234 rows of the data
> frame.
>
> Then construct the model:
>
> fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs,
> subset=firstkids)
>
> which results in:
>
> Error in xj[i] : invalid subscript type 'list'
>
> I read somewhere a recommendation to use "unlist":
>
> fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age * kidmomhsage$mom_hs,
> subset=unlist(firstkids))
>
> which seems to not produce the error and results in some sort of model,
> but is this model the correct one (i.e. for the data set firstkids, just as
> it originally appears)? How does unlist change the data?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signatura-correu.png
Type: image/png
Size: 3020 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160920/282edeae/attachment.png>

From haenlein at escpeurope.eu  Tue Sep 20 10:34:30 2016
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 20 Sep 2016 10:34:30 +0200
Subject: [R] lm model with many categorical variables
Message-ID: <CAOyz9G5KJtf7U5DLj6-OrqNzi485D+Ujv2WRd3388TtYoJbHVg@mail.gmail.com>

Dear all,

I am trying to estimate a lm model with one continuous dependent variable
and 11 independent variables that are all categorical, some of which have
many categories (several dozens in some cases).

I am not interested in statistical inference to a larger population. The
objective of my model is to find a way to best predict my continuous
variable within the sample.

When I run the lm model I evidently get many regression coefficients that
are not significant. Is there some way to automatically combine levels of a
categorical variable together if the regression coefficients for the
individual levels are not significant?

My idea is to find some form of grouping of the different categories that
allows me to work with less levels while keeping or even improving the
quality of predictions.

Thanks,

Michael

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Sep 20 10:41:40 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Sep 2016 08:41:40 +0000
Subject: [R] Using lm's subset parameter results in Error in xj[i] :
 invalid subscript type 'list'
In-Reply-To: <09254fcb83553e3295bbf3370ceeb97f@kapsi.fi>
References: <09254fcb83553e3295bbf3370ceeb97f@kapsi.fi>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DBF5@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of mviljamaa
> Sent: Tuesday, September 20, 2016 10:01 AM
> To: r-help at r-project.org
> Subject: [R] Using lm's subset parameter results in Error in xj[i] : invalid
> subscript type 'list'
>
> I'm trying to take lm on a subset of my dataset and to do this I believe I need
> to pass my subset of the data as the subset parameter of lm.
>
> So I do my subsetting:
>
> firstkids <- kidmomhsage[0:234,], i.e. the first 234 rows of the data frame.

It works, however line numbering in R starts with 1 not 0. R is clever enough to subset with 0:xx vector however you will not get line 1 by subsetting with 0

dd<-data.frame(a=1:10, b=rnorm(10))
dd[0,]
[1] a b
<0 rows> (or 0-length row.names)

>
> Then construct the model:
>
> fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age *
> kidmomhsage$mom_hs,
> subset=firstkids)

You definitelly should spend some time with introductory documentation. The above construction shall be e.g.

fit4 <- lm(kid_score ~ mom_age +mom_hs + mom_age *mom_hs, data = kidmomhsage,  subset=1:234)

>
> which results in:
>
> Error in xj[i] : invalid subscript type 'list'
>
> I read somewhere a recommendation to use "unlist":

I wonder where did you read such recommendation for lm function, you should better avoid that source.

Cheers
Petr

>
> fit4 <- lm(kidmomhsage$kid_score ~ kidmomhsage$mom_age +
> kidmomhsage$mom_hs + kidmomhsage$mom_age *
> kidmomhsage$mom_hs,
> subset=unlist(firstkids))
>
> which seems to not produce the error and results in some sort of model, but
> is this model the correct one (i.e. for the data set firstkids, just as it originally
> appears)? How does unlist change the data?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From deb at debasis.in  Tue Sep 20 08:12:16 2016
From: deb at debasis.in (Dr. Debasis Ghosh)
Date: Tue, 20 Sep 2016 01:12:16 -0500
Subject: [R] Issue on LGP solving
Message-ID: <003101d21305$eff48770$cfdd9650$@in>

I was solving a LGP problem which is very basic. 

 

Find x0 = [x1; x2], n0 = [n1; n2; n3] and p0 = [p1; p2; p3] that minimize a
= [(2p1); (n2); (n3)]

The objectives are as follows

10x1 + 15x2 + n1 - p1 = 40

100x1 + 100x2 + n2 - p2 = 1000

x2 + n3 - p3 = 7

x; n; p >= 0

The solution is x' = [4; 0] and a = [0; 600; 7]

 

 

> local({pkg <- select.list(sort(.packages(all.available =
TRUE)),graphics=TRUE)

+ if(nchar(pkg)) library(pkg, character.only=TRUE)})

> local({pkg <- select.list(sort(.packages(all.available =
TRUE)),graphics=TRUE)

+ if(nchar(pkg)) library(pkg, character.only=TRUE)})

 

 

> coeff<-matrix (c(10,15,100,100,0,1), nrow=3, ncol=2, byrow=TRUE)

> target<-c(40,1000,7)

> p1<-c(2,0,0,0,0,0)

> p2 <- c(0,0,0,0,1,0)

> p3<- c(0,0,0,0,0,1)

> achievement <- data.frame(p1,p2,p3)

> achievement

  p1 p2 p3

1  2  0  0

2  0  0  0

3  0  0  0

4  0  0  0

5  0  1  0

6  0  0  1

> llgp(coeff,target,achievement)

 

Do you have any idea why I am seeing below error ?

 

 

Error in matrix(0, nrow = levels, ncol = nonbasics) : 

  invalid 'nrow' value (too large or NA)

In addition: Warning messages:

1: In max(achievements$priority) :

  no non-missing arguments to max; returning -Inf

2: In matrix(0, nrow = levels, ncol = nonbasics) :

  NAs introduced by coercion to integer range

 

Regards,

Debasis Ghosh, Ph.D

 


	[[alternative HTML version deleted]]


From roncaglia.laura at gmail.com  Tue Sep 20 12:04:24 2016
From: roncaglia.laura at gmail.com (laura roncaglia)
Date: Tue, 20 Sep 2016 12:04:24 +0200
Subject: [R] Run a fixed effect regression and a logit regression on a
 national survey that need to be "weighted"
Message-ID: <CAApwzosiBO0AWdK0f4p8y3wS1bcTDbPkgCORDz7cSYOsraVfmg@mail.gmail.com>

I am a beginner user of R. I am using a national survey to test what
variables influence the partecipation in complementary pensions (the
partecipation in complementary pension is voluntary in my country).

Since the dependent variable is a dummy (1 if the person partecipate and 0
otherwise) I want to run a logit or probit regression; moreover I want to
run a fixed effect regression since I subset the survey in order to have
only the individuals interviewed more than one time.

The data frame is composed by several social and economical variables and
it also contain a variable "weight" which is the survey weight (they are
weighting coefficients to adjust the results of the sample to the national
data).

 family pers sex income pension1     10    1   F  10000       12
20    1   F  20000       13     20    2   M  40000       04     30
1   M  25000       05     30    2   F  50000       06     40    1   M
60000       1

pers is the component of the family and pension takes 1 if the person
partecipate to complementary pension (it is a semplification of the
original survey, which contains more variables and observation (aroun 22k
observations)).

I know how to use the plm and glm functions for a fixed effect or logit
regressoin; in this case I don't know what to do since I need to take
account of the survey weights.

I used the svydesing function to "weight" the data frame:

df1 <- svydesign(ids=~1, data=df, weights=~dfweight)

I used ids=~1 because there isn't a "cluster" variable in the survey (I
know that the towns are ramdomly selected and then individuals are ramdomly
selected, but there isn't a variable that indicate the stratification).

At this point I am lost: I don't know if it is right to use the survey
package and then what function use to run the regression, or there is a way
to use the plm or glm functions taking account of the weights.

I tried so hard to search a solution on the website but if you could give
me an answer I'd be glad.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Sep 20 13:54:58 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Sep 2016 11:54:58 +0000
Subject: [R] Issue on LGP solving
In-Reply-To: <003101d21305$eff48770$cfdd9650$@in>
References: <003101d21305$eff48770$cfdd9650$@in>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DCA6@SRVEXCHMBX.precheza.cz>

Hi

Just a wild guess. Achievement in the goalprog package is data frame with four named columns (objective, priority, p and n).

Your achievement is 3 column data.frame with names p1, p2 and p3.

Maybe data frame with defined structure is required.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dr.
> Debasis Ghosh
> Sent: Tuesday, September 20, 2016 8:12 AM
> To: R-help at r-project.org
> Subject: [R] Issue on LGP solving
>
> I was solving a LGP problem which is very basic.
>
>
>
> Find x0 = [x1; x2], n0 = [n1; n2; n3] and p0 = [p1; p2; p3] that minimize a =
> [(2p1); (n2); (n3)]
>
> The objectives are as follows
>
> 10x1 + 15x2 + n1 - p1 = 40
>
> 100x1 + 100x2 + n2 - p2 = 1000
>
> x2 + n3 - p3 = 7
>
> x; n; p >= 0
>
> The solution is x' = [4; 0] and a = [0; 600; 7]
>
>
>
>
>
> > local({pkg <- select.list(sort(.packages(all.available =
> TRUE)),graphics=TRUE)
>
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>
> > local({pkg <- select.list(sort(.packages(all.available =
> TRUE)),graphics=TRUE)
>
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>
>
>
>
>
> > coeff<-matrix (c(10,15,100,100,0,1), nrow=3, ncol=2, byrow=TRUE)
>
> > target<-c(40,1000,7)
>
> > p1<-c(2,0,0,0,0,0)
>
> > p2 <- c(0,0,0,0,1,0)
>
> > p3<- c(0,0,0,0,0,1)
>
> > achievement <- data.frame(p1,p2,p3)
>
> > achievement
>
>   p1 p2 p3
>
> 1  2  0  0
>
> 2  0  0  0
>
> 3  0  0  0
>
> 4  0  0  0
>
> 5  0  1  0
>
> 6  0  0  1
>
> > llgp(coeff,target,achievement)
>
>
>
> Do you have any idea why I am seeing below error ?
>
>
>
>
>
> Error in matrix(0, nrow = levels, ncol = nonbasics) :
>
>   invalid 'nrow' value (too large or NA)
>
> In addition: Warning messages:
>
> 1: In max(achievements$priority) :
>
>   no non-missing arguments to max; returning -Inf
>
> 2: In matrix(0, nrow = levels, ncol = nonbasics) :
>
>   NAs introduced by coercion to integer range
>
>
>
> Regards,
>
> Debasis Ghosh, Ph.D
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sezenismail at gmail.com  Tue Sep 20 14:24:31 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 20 Sep 2016 15:24:31 +0300
Subject: [R] lm model with many categorical variables
In-Reply-To: <CAOyz9G5KJtf7U5DLj6-OrqNzi485D+Ujv2WRd3388TtYoJbHVg@mail.gmail.com>
References: <CAOyz9G5KJtf7U5DLj6-OrqNzi485D+Ujv2WRd3388TtYoJbHVg@mail.gmail.com>
Message-ID: <B1E7BEA8-5B58-4D7D-8770-32BE24F9BECB@gmail.com>


> On 20 Sep 2016, at 11:34, Michael Haenlein <haenlein at escpeurope.eu> wrote:
> 
> Dear all,
> 
> I am trying to estimate a lm model with one continuous dependent variable
> and 11 independent variables that are all categorical, some of which have
> many categories (several dozens in some cases).

If I?m not wrong, ( I assume that categorical variables are in factor form) lm will pick the most crowded categories and will try to fit a linear model over them. (This might be wrong, please correct me somebody)

> 
> I am not interested in statistical inference to a larger population. The
> objective of my model is to find a way to best predict my continuous
> variable within the sample.

The best pick would be a CART ( Classification and Reg. Tree, rpart) or CIT (Conditional Inference Tree, ctree) model to predict continous response variable by categorical variables. Please, see new partykit (old party) package for CIT.

> 
> When I run the lm model I evidently get many regression coefficients that
> are not significant. Is there some way to automatically combine levels of a
> categorical variable together if the regression coefficients for the
> individual levels are not significant?


> 
> My idea is to find some form of grouping of the different categories that
> allows me to work with less levels while keeping or even improving the
> quality of predictions.

I also want to mention cforest here, you can measure the importance of your predictor variables. I would recommend partykit package for categorical predictors, but also you can give it a try to rpart.

> 
> Thanks,
> 
> Michael
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david at agros.it  Tue Sep 20 14:45:50 2016
From: david at agros.it (David Remotti)
Date: Tue, 20 Sep 2016 14:45:50 +0200
Subject: [R] Errors in Raster to Point
In-Reply-To: <CAAVy6R+5bzWOy1xVf=ZA_nvXrGDPnkQs-pej=YR1w7gdMwZtfg@mail.gmail.com>
References: <CAAVy6R+5bzWOy1xVf=ZA_nvXrGDPnkQs-pej=YR1w7gdMwZtfg@mail.gmail.com>
Message-ID: <52d8044b-ad9d-18d4-6c49-2bf45bd2bc70@agros.it>

First answer is that R is not the proper environment for such a 
question. There a re many free package for image analysis or even GIS. 
Try for example Q-GIS

David


Il 19/09/2016 22:34, GwanSeon Kim ha scritto:
> Hi, all
> I am just beginner to use R.
> I am working with TIF image file, and the information about the raster is
> following:
>
> class       : RasterLayer
> dimensions  : 11150, 21808, 243159200  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 569685, 1223925, 1513995, 1848495  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0
> data source :
> C:\Users\Gwan\AppData\Local\Temp\Rtmpg506Ee\raster\r_tmp_2016-09-14_122409_6260_09589.grd
> names       : test_map
> values      : 1, 225  (min, max)
> attributes  :
>         ID OBJECTID Value Red Green Blue   Count               Class_Name
> Opacity
>   from:  0        2     1   1     0    0 5982503                     Corn
>      1
>   to  : 48      255   254   0     0    0   10336 Dbl Crop Barley/Soybeans
>      1
>
>
>
> >From this Rasterlayer, I want to convert raster to point for each pixel
> based on "Value (one of column name)" and create a raster with
> georeferenced information.
> I used code as following: RP <- rasterToPoints(KY_raster)
> However, I could not get the points and have an error message "cannot
> allocate vector of size 5.4 Gb" and "Your computer is low on memory. Save
> your files and close these programs".
> Could someone please help me how I can convert to raster to points??
> Best,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deb at debasis.in  Tue Sep 20 15:58:55 2016
From: deb at debasis.in (Dr. Debasis Ghosh)
Date: Tue, 20 Sep 2016 08:58:55 -0500
Subject: [R] Issue on LGP solving
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DCA6@SRVEXCHMBX.precheza.cz>
References: <003101d21305$eff48770$cfdd9650$@in>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DCA6@SRVEXCHMBX.precheza.cz>
Message-ID: <001d01d21347$20ec5290$62c4f7b0$@in>

Thanks Petr!! However, I found in the goalprog package I found "achievements" as "a  data frame with the deviation variables for each objective together with the
priority level". I defined

> p1<-c(2,0,0,0,0,0)
> p2 <- c(0,0,0,0,1,0)
> p3<- c(0,0,0,0,0,1)
> achievement <- data.frame(p1,p2,p3)

Here p1, p2 and p3 are the 3 priority levels. 

I understand the problem is at "achievement" data frame. To your point, data frame with four named columns (objective, priority, p and n), how these four columns are defined ? 

Appreciate your time Petr. Thanks again!! 

Regards,
Debasis Ghosh, Ph.D

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: Tuesday, September 20, 2016 6:55 AM
To: Dr. Debasis Ghosh; R-help at r-project.org
Subject: RE: [R] Issue on LGP solving

Hi

Just a wild guess. Achievement in the goalprog package is data frame with four named columns (objective, priority, p and n).

Your achievement is 3 column data.frame with names p1, p2 and p3.

Maybe data frame with defined structure is required.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dr.
> Debasis Ghosh
> Sent: Tuesday, September 20, 2016 8:12 AM
> To: R-help at r-project.org
> Subject: [R] Issue on LGP solving
>
> I was solving a LGP problem which is very basic.
>
>
>
> Find x0 = [x1; x2], n0 = [n1; n2; n3] and p0 = [p1; p2; p3] that minimize a =
> [(2p1); (n2); (n3)]
>
> The objectives are as follows
>
> 10x1 + 15x2 + n1 - p1 = 40
>
> 100x1 + 100x2 + n2 - p2 = 1000
>
> x2 + n3 - p3 = 7
>
> x; n; p >= 0
>
> The solution is x' = [4; 0] and a = [0; 600; 7]
>
>
>
>
>
> > local({pkg <- select.list(sort(.packages(all.available =
> TRUE)),graphics=TRUE)
>
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>
> > local({pkg <- select.list(sort(.packages(all.available =
> TRUE)),graphics=TRUE)
>
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>
>
>
>
>
> > coeff<-matrix (c(10,15,100,100,0,1), nrow=3, ncol=2, byrow=TRUE)
>
> > target<-c(40,1000,7)
>
> > p1<-c(2,0,0,0,0,0)
>
> > p2 <- c(0,0,0,0,1,0)
>
> > p3<- c(0,0,0,0,0,1)
>
> > achievement <- data.frame(p1,p2,p3)
>
> > achievement
>
>   p1 p2 p3
>
> 1  2  0  0
>
> 2  0  0  0
>
> 3  0  0  0
>
> 4  0  0  0
>
> 5  0  1  0
>
> 6  0  0  1
>
> > llgp(coeff,target,achievement)
>
>
>
> Do you have any idea why I am seeing below error ?
>
>
>
>
>
> Error in matrix(0, nrow = levels, ncol = nonbasics) :
>
>   invalid 'nrow' value (too large or NA)
>
> In addition: Warning messages:
>
> 1: In max(achievements$priority) :
>
>   no non-missing arguments to max; returning -Inf
>
> 2: In matrix(0, nrow = levels, ncol = nonbasics) :
>
>   NAs introduced by coercion to integer range
>
>
>
> Regards,
>
> Debasis Ghosh, Ph.D
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From rbaer at atsu.edu  Tue Sep 20 16:12:03 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Tue, 20 Sep 2016 09:12:03 -0500
Subject: [R] Return the indices of rows of a data frame
In-Reply-To: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
References: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
Message-ID: <248d3a80-2633-9ecd-a676-c1263fb5238c@atsu.edu>



On 9/19/2016 10:37 PM, John wrote:
> Hi,
>
>     I have the following dataframe:
>
>> temp<-data.frame(a=c(1,1,2), b=2:4, c=1:3)
>> row.names(temp)<-c("D", "E", "F")
>> temp
>    a b c
> D 1 2 1
> E 1 3 2
> F 2 4 3
>
>     I would like R to tell me which rows has value "a" equal to 1. The
> answer is the first row and the second row, or row D and row E. Which
> function should i use? function subset? function which?

row.names(temp[temp$a==1,])

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From bgunter.4567 at gmail.com  Tue Sep 20 16:41:37 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Sep 2016 07:41:37 -0700
Subject: [R] Return the indices of rows of a data frame
In-Reply-To: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
References: <CABcx46AXy0t3Aj1=hHnn_+fCrJbc+RnEgVsfpV9XbJrZudYwgw@mail.gmail.com>
Message-ID: <CAGxFJbR_mbkc09G8Ryf7th2Psg+wh=TggbqhDGuiPa0YXFNBKQ@mail.gmail.com>

There are many good R tutorials on the web. Some recommendations can
be found here:

https://www.rstudio.com/online-learning/#R

Please spend some time learning fundamental R constructs and
functionality before posting what appear to be very basic questions
here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 19, 2016 at 8:37 PM, John <miaojpm at gmail.com> wrote:
> Hi,
>
>    I have the following dataframe:
>
>> temp<-data.frame(a=c(1,1,2), b=2:4, c=1:3)
>> row.names(temp)<-c("D", "E", "F")
>> temp
>   a b c
> D 1 2 1
> E 1 3 2
> F 2 4 3
>
>    I would like R to tell me which rows has value "a" equal to 1. The
> answer is the first row and the second row, or row D and row E. Which
> function should i use? function subset? function which?
>
>    Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Sep 20 16:49:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Sep 2016 07:49:02 -0700
Subject: [R] lm model with many categorical variables
In-Reply-To: <CAOyz9G5KJtf7U5DLj6-OrqNzi485D+Ujv2WRd3388TtYoJbHVg@mail.gmail.com>
References: <CAOyz9G5KJtf7U5DLj6-OrqNzi485D+Ujv2WRd3388TtYoJbHVg@mail.gmail.com>
Message-ID: <CAGxFJbTWdiu164Y6q=A1mvjbaASacz_oCpSz2mr6o4PqNESq5w@mail.gmail.com>

You need statistical help, which is generally off topic here. I
suggest you post to a statistcal site like stats.stackexchange.com
instead. Better yet, find a local statistical expert with whom you can
consult.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 20, 2016 at 1:34 AM, Michael Haenlein
<haenlein at escpeurope.eu> wrote:
> Dear all,
>
> I am trying to estimate a lm model with one continuous dependent variable
> and 11 independent variables that are all categorical, some of which have
> many categories (several dozens in some cases).
>
> I am not interested in statistical inference to a larger population. The
> objective of my model is to find a way to best predict my continuous
> variable within the sample.
>
> When I run the lm model I evidently get many regression coefficients that
> are not significant. Is there some way to automatically combine levels of a
> categorical variable together if the regression coefficients for the
> individual levels are not significant?
>
> My idea is to find some form of grouping of the different categories that
> allows me to work with less levels while keeping or even improving the
> quality of predictions.
>
> Thanks,
>
> Michael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Tue Sep 20 18:23:45 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 20 Sep 2016 11:23:45 -0500
Subject: [R] Run a fixed effect regression and a logit regression on a
 national survey that need to be "weighted"
In-Reply-To: <CAApwzosiBO0AWdK0f4p8y3wS1bcTDbPkgCORDz7cSYOsraVfmg@mail.gmail.com>
References: <CAApwzosiBO0AWdK0f4p8y3wS1bcTDbPkgCORDz7cSYOsraVfmg@mail.gmail.com>
Message-ID: <CAN5YmCGNJKAdHypQ3gH8Re3x76LXgP0x9Si82KEpu2+EG-2KOQ@mail.gmail.com>

If you want your records to be weighted by the survey weights during the
analysis, then use the weights= argument of the glm() function.

Jean

On Tue, Sep 20, 2016 at 5:04 AM, laura roncaglia <roncaglia.laura at gmail.com>
wrote:

> I am a beginner user of R. I am using a national survey to test what
> variables influence the partecipation in complementary pensions (the
> partecipation in complementary pension is voluntary in my country).
>
> Since the dependent variable is a dummy (1 if the person partecipate and 0
> otherwise) I want to run a logit or probit regression; moreover I want to
> run a fixed effect regression since I subset the survey in order to have
> only the individuals interviewed more than one time.
>
> The data frame is composed by several social and economical variables and
> it also contain a variable "weight" which is the survey weight (they are
> weighting coefficients to adjust the results of the sample to the national
> data).
>
>  family pers sex income pension1     10    1   F  10000       12
> 20    1   F  20000       13     20    2   M  40000       04     30
> 1   M  25000       05     30    2   F  50000       06     40    1   M
> 60000       1
>
> pers is the component of the family and pension takes 1 if the person
> partecipate to complementary pension (it is a semplification of the
> original survey, which contains more variables and observation (aroun 22k
> observations)).
>
> I know how to use the plm and glm functions for a fixed effect or logit
> regressoin; in this case I don't know what to do since I need to take
> account of the survey weights.
>
> I used the svydesing function to "weight" the data frame:
>
> df1 <- svydesign(ids=~1, data=df, weights=~dfweight)
>
> I used ids=~1 because there isn't a "cluster" variable in the survey (I
> know that the towns are ramdomly selected and then individuals are ramdomly
> selected, but there isn't a variable that indicate the stratification).
>
> At this point I am lost: I don't know if it is right to use the survey
> package and then what function use to run the regression, or there is a way
> to use the plm or glm functions taking account of the weights.
>
> I tried so hard to search a solution on the website but if you could give
> me an answer I'd be glad.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Tue Sep 20 18:22:48 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Tue, 20 Sep 2016 19:22:48 +0300
Subject: [R] mgcv: bam(),
	error in models with random intercepts and random slopes
Message-ID: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>

Hi all

I am using the bam function of the mgcv package to model behavioral data of
a learning experiment. To model individual variation in learning rate, I am
testing models with (a) by-participant random intercepts of trial, (b)
by-participant random slopes and random intercepts of trial, and (c)
by-participant random smooth terms.

While all (a) and (c) models converge, I am getting an error for every
possible variation of a model with random intercepts and random slopes. For
example:

m1.rs<-bam(acc~ 1 + igc + s(ctrial) + s(sbj, bs="re") + s(ctrial, sbj,
bs="re") , data=data_a, family=binomial)
Error in G$smooth[[i]]$first.para:G$smooth[[i]]$last.para :
  argument of length 0

Any idea on what that error might be?

Thank you in advance for your time.
Fotis

P.S.: R version: 3.3.1, mgcv version: 1.8.15

-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

	[[alternative HTML version deleted]]


From pauline.laille at gmail.com  Tue Sep 20 14:42:56 2016
From: pauline.laille at gmail.com (=?UTF-8?Q?Pauline_La=C3=AFlle?=)
Date: Tue, 20 Sep 2016 14:42:56 +0200
Subject: [R] "invalid argument to unary operator" while selecting rows by
	name
Message-ID: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>

Dear all,

I built a dataframe with read.csv2(). Initially, row names are integers
(order of answers to a survey). They are listed in the csv's first column.
The import works well and my dataframe looks like I wanted it to look.

Row names go as follows :
 [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"  "89"
 "91"  "93"  "105" "110" "111" "117" "119" "120"
 [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
"178" "179" "184" "186" "192" "193" "200" "201" "228"
etc.

I would like to drop rows "601" & "604" to clean the dataframe.

While data["601",] shows me the first row i'd like to drop, data[-"601",]
returns the following :
Error in -"601" : invalid argument to unary operator

idem with data[c("601","604"),] and data[-c("601","604"),]

It is the first time that I run into this specific error. After reading a
bit about it I still don't understand what it means and how to fix it.

Thanks for reading!
Best,
Pauline.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 20 19:08:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Sep 2016 10:08:43 -0700
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>
References: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>
Message-ID: <CAGxFJbQCrsF-6N84S+v6-uSroYb7rC00MM9t4rrfsH8+t914=Q@mail.gmail.com>

Hint: "601"  is not 601.

Have you gone through any R tutorials?

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 20, 2016 at 5:42 AM, Pauline La?lle
<pauline.laille at gmail.com> wrote:
> Dear all,
>
> I built a dataframe with read.csv2(). Initially, row names are integers
> (order of answers to a survey). They are listed in the csv's first column.
> The import works well and my dataframe looks like I wanted it to look.
>
> Row names go as follows :
>  [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"  "89"
>  "91"  "93"  "105" "110" "111" "117" "119" "120"
>  [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
> "178" "179" "184" "186" "192" "193" "200" "201" "228"
> etc.
>
> I would like to drop rows "601" & "604" to clean the dataframe.
>
> While data["601",] shows me the first row i'd like to drop, data[-"601",]
> returns the following :
> Error in -"601" : invalid argument to unary operator
>
> idem with data[c("601","604"),] and data[-c("601","604"),]
>
> It is the first time that I run into this specific error. After reading a
> bit about it I still don't understand what it means and how to fix it.
>
> Thanks for reading!
> Best,
> Pauline.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Tue Sep 20 19:52:08 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 20 Sep 2016 18:52:08 +0100
Subject: [R] "invalid argument to unary operator" while selecting rows
 by name
In-Reply-To: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>
Message-ID: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>

Hello,

Try something like the following.

ix <- which(c("601", "604") %in% rownames(data))
clean <- data[-ix, ]


Hope this helps,

Rui Barradas




Citando Pauline La?lle <pauline.laille at gmail.com>:

> Dear all,
>
> I built a dataframe with read.csv2(). Initially, row names are integers
> (order of answers to a survey). They are listed in the csv's first column.
> The import works well and my dataframe looks like I wanted it to look.
>
> Row names go as follows :
>  [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"  "89"
>  "91"  "93"  "105" "110" "111" "117" "119" "120"
>  [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
> "178" "179" "184" "186" "192" "193" "200" "201" "228"
> etc.
>
> I would like to drop rows "601" & "604" to clean the dataframe.
>
> While data["601",] shows me the first row i'd like to drop, data[-"601",]
> returns the following :
> Error in -"601" : invalid argument to unary operator
>
> idem with data[c("601","604"),] and data[-c("601","604"),]
>
> It is the first time that I run into this specific error. After reading a
> bit about it I still don't understand what it means and how to fix it.
>
> Thanks for reading!
> Best,
> Pauline.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Sep 20 19:58:10 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 20 Sep 2016 11:58:10 -0600
Subject: [R] How to plot the regression line of multivariable linear
	model?
In-Reply-To: <37a6040699aa8f8eeb546d80af95039f@kapsi.fi>
References: <37a6040699aa8f8eeb546d80af95039f@kapsi.fi>
Message-ID: <CAFEqCdyw3=WYG9oRErBQA-EuX8y3ksTAzi_op_DqMAa11y=MOw@mail.gmail.com>

You might consider the Predict.Plot and TkPredict functions in the
TeachingDemos package.  These help you explore multiple linear
regression models by plotting the "line" relating the response to one
of the predictors at given values of the other predictors.  These
lines can be combined in a single plot (Predict.Plot) or changed
interactively (TkPredict).  See the examples in the help page.

On Sun, Sep 18, 2016 at 9:26 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> I'm having a bit of trouble plotting the regression line of multivariable
> linear model.
>
> Specifically my model has one response and two predictors, i.e. it's of the
> form
>
> Y = b_0+b_1*X_1+b_2*X_2
>
> Plotting the regression line for a single predictor model
>
> Y = b_0+b_1*X_1
>
> is simple enough, just call abline() with the coefficients returned by lm().
>
> However, I don't know if this can be adapted to multivariable linear models.
>
> I also know about curve(), but I don't know how am I supposed to input the
> multivariable model's coefficients into it.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ruipbarradas at sapo.pt  Tue Sep 20 20:13:54 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 20 Sep 2016 19:13:54 +0100
Subject: [R] "invalid argument to unary operator" while selecting rows
 by name
In-Reply-To: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
Message-ID: <20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>

Sorry, I've made a stupid mistake.
It's obviously the other way around.

ix <- which(rownames(data) %in% c("601", "604"))
clean <- data[-ix, ]


Rui Barradas


Citando ruipbarradas at sapo.pt:

> Hello,
>
> Try something like the following.
>
> ix <- which(c("601", "604") %in% rownames(data))
> clean <- data[-ix, ]
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
>
> Citando Pauline La?lle <pauline.laille at gmail.com>:
>
>> Dear all,
>>
>> I built a dataframe with read.csv2(). Initially, row names are integers
>> (order of answers to a survey). They are listed in the csv's first column.
>> The import works well and my dataframe looks like I wanted it to look.
>>
>> Row names go as follows :
>> [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"  "89"
>> "91"  "93"  "105" "110" "111" "117" "119" "120"
>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
>> etc.
>>
>> I would like to drop rows "601" & "604" to clean the dataframe.
>>
>> While data["601",] shows me the first row i'd like to drop, data[-"601",]
>> returns the following :
>> Error in -"601" : invalid argument to unary operator
>>
>> idem with data[c("601","604"),] and data[-c("601","604"),]
>>
>> It is the first time that I run into this specific error. After reading a
>> bit about it I still don't understand what it means and how to fix it.
>>
>> Thanks for reading!
>> Best,
>> Pauline.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue Sep 20 23:46:16 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 15:46:16 -0600
Subject: [R] about data problem
Message-ID: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>

Hi R users,

I have a problem in reading data.
For example, part of my dataframe is like this:

df
month day year          Discharge
   3        1   2010                6.4
   3        2   2010               7.58
   3        3   2010               6.82
   3        4   2010               8.63
   3        5   2010               8.16
   3        6   2010               7.58

Then if I type summary(df), why it converts the discharge data to levels? I
also met the same problem when reading some other csv files. How to solve
this problem? Thanks.

Discharge
7.58     :2
6.4       :1
6.82     :1
8.63     :1
8.16     :1

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Tue Sep 20 23:55:38 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 20 Sep 2016 15:55:38 -0600
Subject: [R] about data problem
In-Reply-To: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
Message-ID: <CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>

This indicates that your Discharge column has been stored/converted as
a factor (run str(df) to verify and check other columns).  This
usually happens when functions like read.table are left to try to
figure out what each column is and it finds something in that column
that cannot be converted to a number (possibly an oh instead of a
zero, an el instead of a one, or just a letter or punctuation mark
accidentally in the file).  You can either find the error in your
original data, fix it, and reread the data, or specify that the column
should be numeric using the colClasses argument to read.table or other
function.



On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a problem in reading data.
> For example, part of my dataframe is like this:
>
> df
> month day year          Discharge
>    3        1   2010                6.4
>    3        2   2010               7.58
>    3        3   2010               6.82
>    3        4   2010               8.63
>    3        5   2010               8.16
>    3        6   2010               7.58
>
> Then if I type summary(df), why it converts the discharge data to levels? I
> also met the same problem when reading some other csv files. How to solve
> this problem? Thanks.
>
> Discharge
> 7.58     :2
> 6.4       :1
> 6.82     :1
> 8.63     :1
> 8.16     :1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From chocold12 at gmail.com  Wed Sep 21 00:00:11 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 16:00:11 -0600
Subject: [R] about data problem
In-Reply-To: <CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
Message-ID: <CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>

Yes, it is stored as factor. I can't check out any problem in the original
data. Reread data doesn't help either. I use read.csv to read in the data,
do you think it is better to use read.table? Thanks again.

On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com> wrote:

> This indicates that your Discharge column has been stored/converted as
> a factor (run str(df) to verify and check other columns).  This
> usually happens when functions like read.table are left to try to
> figure out what each column is and it finds something in that column
> that cannot be converted to a number (possibly an oh instead of a
> zero, an el instead of a one, or just a letter or punctuation mark
> accidentally in the file).  You can either find the error in your
> original data, fix it, and reread the data, or specify that the column
> should be numeric using the colClasses argument to read.table or other
> function.
>
>
>
> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> >
> > I have a problem in reading data.
> > For example, part of my dataframe is like this:
> >
> > df
> > month day year          Discharge
> >    3        1   2010                6.4
> >    3        2   2010               7.58
> >    3        3   2010               6.82
> >    3        4   2010               8.63
> >    3        5   2010               8.16
> >    3        6   2010               7.58
> >
> > Then if I type summary(df), why it converts the discharge data to
> levels? I
> > also met the same problem when reading some other csv files. How to solve
> > this problem? Thanks.
> >
> > Discharge
> > 7.58     :2
> > 6.4       :1
> > 6.82     :1
> > 8.63     :1
> > 8.16     :1
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From fanjianling at gmail.com  Wed Sep 21 00:09:03 2016
From: fanjianling at gmail.com (Jianling Fan)
Date: Tue, 20 Sep 2016 16:09:03 -0600
Subject: [R] about data problem
In-Reply-To: <CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
Message-ID: <CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>

Add the "stringsAsFactors = F"  when you read the data, and then
convert them to numeric.

On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
> Yes, it is stored as factor. I can't check out any problem in the original
> data. Reread data doesn't help either. I use read.csv to read in the data,
> do you think it is better to use read.table? Thanks again.
>
> On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com> wrote:
>
>> This indicates that your Discharge column has been stored/converted as
>> a factor (run str(df) to verify and check other columns).  This
>> usually happens when functions like read.table are left to try to
>> figure out what each column is and it finds something in that column
>> that cannot be converted to a number (possibly an oh instead of a
>> zero, an el instead of a one, or just a letter or punctuation mark
>> accidentally in the file).  You can either find the error in your
>> original data, fix it, and reread the data, or specify that the column
>> should be numeric using the colClasses argument to read.table or other
>> function.
>>
>>
>>
>> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com> wrote:
>> > Hi R users,
>> >
>> > I have a problem in reading data.
>> > For example, part of my dataframe is like this:
>> >
>> > df
>> > month day year          Discharge
>> >    3        1   2010                6.4
>> >    3        2   2010               7.58
>> >    3        3   2010               6.82
>> >    3        4   2010               8.63
>> >    3        5   2010               8.16
>> >    3        6   2010               7.58
>> >
>> > Then if I type summary(df), why it converts the discharge data to
>> levels? I
>> > also met the same problem when reading some other csv files. How to solve
>> > this problem? Thanks.
>> >
>> > Discharge
>> > 7.58     :2
>> > 6.4       :1
>> > 6.82     :1
>> > 8.63     :1
>> > 8.16     :1
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Jianling Fan
???


From chocold12 at gmail.com  Wed Sep 21 00:11:42 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 16:11:42 -0600
Subject: [R] about data problem
In-Reply-To: <CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
Message-ID: <CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>

I reread the data, and use 'na.rm = T' when reading the data. This time it
has no such problem. It seems that the existence of NAs convert the integer
to factor. Thanks for your help.


On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com> wrote:

> Add the "stringsAsFactors = F"  when you read the data, and then
> convert them to numeric.
>
> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
> > Yes, it is stored as factor. I can't check out any problem in the
> original
> > data. Reread data doesn't help either. I use read.csv to read in the
> data,
> > do you think it is better to use read.table? Thanks again.
> >
> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com> wrote:
> >
> >> This indicates that your Discharge column has been stored/converted as
> >> a factor (run str(df) to verify and check other columns).  This
> >> usually happens when functions like read.table are left to try to
> >> figure out what each column is and it finds something in that column
> >> that cannot be converted to a number (possibly an oh instead of a
> >> zero, an el instead of a one, or just a letter or punctuation mark
> >> accidentally in the file).  You can either find the error in your
> >> original data, fix it, and reread the data, or specify that the column
> >> should be numeric using the colClasses argument to read.table or other
> >> function.
> >>
> >>
> >>
> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com> wrote:
> >> > Hi R users,
> >> >
> >> > I have a problem in reading data.
> >> > For example, part of my dataframe is like this:
> >> >
> >> > df
> >> > month day year          Discharge
> >> >    3        1   2010                6.4
> >> >    3        2   2010               7.58
> >> >    3        3   2010               6.82
> >> >    3        4   2010               8.63
> >> >    3        5   2010               8.16
> >> >    3        6   2010               7.58
> >> >
> >> > Then if I type summary(df), why it converts the discharge data to
> >> levels? I
> >> > also met the same problem when reading some other csv files. How to
> solve
> >> > this problem? Thanks.
> >> >
> >> > Discharge
> >> > 7.58     :2
> >> > 6.4       :1
> >> > 6.82     :1
> >> > 8.63     :1
> >> > 8.16     :1
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Gregory (Greg) L. Snow Ph.D.
> >> 538280 at gmail.com
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Jianling Fan
> ???
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep 21 00:30:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Sep 2016 15:30:26 -0700
Subject: [R] about data problem
In-Reply-To: <CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
Message-ID: <45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>

I suppose you can do what works for your data, but I wouldn't recommend na.rm=TRUE because it hides problems rather than clarifying them. 

If in fact your data includes true NA values (the letters NA or simply nothing between the commas are typical ways this information may be indicated), then read.csv will NOT change from integer to factor (particularly if you have specified which markers represent NA using the na.strings argument documented under read.table)... so you probably DO have unexpected garbage still in your data which could be obscuring valuable information that could affect your conclusions. 
-- 
Sent from my phone. Please excuse my brevity.

On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com> wrote:
>I reread the data, and use 'na.rm = T' when reading the data. This time
>it
>has no such problem. It seems that the existence of NAs convert the
>integer
>to factor. Thanks for your help.
>
>
>On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
>wrote:
>
>> Add the "stringsAsFactors = F"  when you read the data, and then
>> convert them to numeric.
>>
>> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
>> > Yes, it is stored as factor. I can't check out any problem in the
>> original
>> > data. Reread data doesn't help either. I use read.csv to read in
>the
>> data,
>> > do you think it is better to use read.table? Thanks again.
>> >
>> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
>wrote:
>> >
>> >> This indicates that your Discharge column has been
>stored/converted as
>> >> a factor (run str(df) to verify and check other columns).  This
>> >> usually happens when functions like read.table are left to try to
>> >> figure out what each column is and it finds something in that
>column
>> >> that cannot be converted to a number (possibly an oh instead of a
>> >> zero, an el instead of a one, or just a letter or punctuation mark
>> >> accidentally in the file).  You can either find the error in your
>> >> original data, fix it, and reread the data, or specify that the
>column
>> >> should be numeric using the colClasses argument to read.table or
>other
>> >> function.
>> >>
>> >>
>> >>
>> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
>wrote:
>> >> > Hi R users,
>> >> >
>> >> > I have a problem in reading data.
>> >> > For example, part of my dataframe is like this:
>> >> >
>> >> > df
>> >> > month day year          Discharge
>> >> >    3        1   2010                6.4
>> >> >    3        2   2010               7.58
>> >> >    3        3   2010               6.82
>> >> >    3        4   2010               8.63
>> >> >    3        5   2010               8.16
>> >> >    3        6   2010               7.58
>> >> >
>> >> > Then if I type summary(df), why it converts the discharge data
>to
>> >> levels? I
>> >> > also met the same problem when reading some other csv files. How
>to
>> solve
>> >> > this problem? Thanks.
>> >> >
>> >> > Discharge
>> >> > 7.58     :2
>> >> > 6.4       :1
>> >> > 6.82     :1
>> >> > 8.63     :1
>> >> > 8.16     :1
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>> >>
>> >> --
>> >> Gregory (Greg) L. Snow Ph.D.
>> >> 538280 at gmail.com
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Jianling Fan
>> ???
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Wed Sep 21 00:42:39 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 16:42:39 -0600
Subject: [R] about data problem
In-Reply-To: <45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
Message-ID: <CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>

Thanks. Then what should I do to solve the problem?

On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I suppose you can do what works for your data, but I wouldn't recommend
> na.rm=TRUE because it hides problems rather than clarifying them.
>
> If in fact your data includes true NA values (the letters NA or simply
> nothing between the commas are typical ways this information may be
> indicated), then read.csv will NOT change from integer to factor
> (particularly if you have specified which markers represent NA using the
> na.strings argument documented under read.table)... so you probably DO have
> unexpected garbage still in your data which could be obscuring valuable
> information that could affect your conclusions.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com> wrote:
> >I reread the data, and use 'na.rm = T' when reading the data. This time
> >it
> >has no such problem. It seems that the existence of NAs convert the
> >integer
> >to factor. Thanks for your help.
> >
> >
> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
> >wrote:
> >
> >> Add the "stringsAsFactors = F"  when you read the data, and then
> >> convert them to numeric.
> >>
> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
> >> > Yes, it is stored as factor. I can't check out any problem in the
> >> original
> >> > data. Reread data doesn't help either. I use read.csv to read in
> >the
> >> data,
> >> > do you think it is better to use read.table? Thanks again.
> >> >
> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
> >wrote:
> >> >
> >> >> This indicates that your Discharge column has been
> >stored/converted as
> >> >> a factor (run str(df) to verify and check other columns).  This
> >> >> usually happens when functions like read.table are left to try to
> >> >> figure out what each column is and it finds something in that
> >column
> >> >> that cannot be converted to a number (possibly an oh instead of a
> >> >> zero, an el instead of a one, or just a letter or punctuation mark
> >> >> accidentally in the file).  You can either find the error in your
> >> >> original data, fix it, and reread the data, or specify that the
> >column
> >> >> should be numeric using the colClasses argument to read.table or
> >other
> >> >> function.
> >> >>
> >> >>
> >> >>
> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
> >wrote:
> >> >> > Hi R users,
> >> >> >
> >> >> > I have a problem in reading data.
> >> >> > For example, part of my dataframe is like this:
> >> >> >
> >> >> > df
> >> >> > month day year          Discharge
> >> >> >    3        1   2010                6.4
> >> >> >    3        2   2010               7.58
> >> >> >    3        3   2010               6.82
> >> >> >    3        4   2010               8.63
> >> >> >    3        5   2010               8.16
> >> >> >    3        6   2010               7.58
> >> >> >
> >> >> > Then if I type summary(df), why it converts the discharge data
> >to
> >> >> levels? I
> >> >> > also met the same problem when reading some other csv files. How
> >to
> >> solve
> >> >> > this problem? Thanks.
> >> >> >
> >> >> > Discharge
> >> >> > 7.58     :2
> >> >> > 6.4       :1
> >> >> > 6.82     :1
> >> >> > 8.63     :1
> >> >> > 8.16     :1
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> >> posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible
> >code.
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Gregory (Greg) L. Snow Ph.D.
> >> >> 538280 at gmail.com
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Jianling Fan
> >> ???
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Sep 21 00:56:57 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 16:56:57 -0600
Subject: [R] about data problem
In-Reply-To: <CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
Message-ID: <CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>

Is there a function in read.csv that I can use to avoid converting numeric
to factor? Thanks a lot.



On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com> wrote:

> Thanks. Then what should I do to solve the problem?
>
> On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> I suppose you can do what works for your data, but I wouldn't recommend
>> na.rm=TRUE because it hides problems rather than clarifying them.
>>
>> If in fact your data includes true NA values (the letters NA or simply
>> nothing between the commas are typical ways this information may be
>> indicated), then read.csv will NOT change from integer to factor
>> (particularly if you have specified which markers represent NA using the
>> na.strings argument documented under read.table)... so you probably DO have
>> unexpected garbage still in your data which could be obscuring valuable
>> information that could affect your conclusions.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com>
>> wrote:
>> >I reread the data, and use 'na.rm = T' when reading the data. This time
>> >it
>> >has no such problem. It seems that the existence of NAs convert the
>> >integer
>> >to factor. Thanks for your help.
>> >
>> >
>> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
>> >wrote:
>> >
>> >> Add the "stringsAsFactors = F"  when you read the data, and then
>> >> convert them to numeric.
>> >>
>> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
>> >> > Yes, it is stored as factor. I can't check out any problem in the
>> >> original
>> >> > data. Reread data doesn't help either. I use read.csv to read in
>> >the
>> >> data,
>> >> > do you think it is better to use read.table? Thanks again.
>> >> >
>> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
>> >wrote:
>> >> >
>> >> >> This indicates that your Discharge column has been
>> >stored/converted as
>> >> >> a factor (run str(df) to verify and check other columns).  This
>> >> >> usually happens when functions like read.table are left to try to
>> >> >> figure out what each column is and it finds something in that
>> >column
>> >> >> that cannot be converted to a number (possibly an oh instead of a
>> >> >> zero, an el instead of a one, or just a letter or punctuation mark
>> >> >> accidentally in the file).  You can either find the error in your
>> >> >> original data, fix it, and reread the data, or specify that the
>> >column
>> >> >> should be numeric using the colClasses argument to read.table or
>> >other
>> >> >> function.
>> >> >>
>> >> >>
>> >> >>
>> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
>> >wrote:
>> >> >> > Hi R users,
>> >> >> >
>> >> >> > I have a problem in reading data.
>> >> >> > For example, part of my dataframe is like this:
>> >> >> >
>> >> >> > df
>> >> >> > month day year          Discharge
>> >> >> >    3        1   2010                6.4
>> >> >> >    3        2   2010               7.58
>> >> >> >    3        3   2010               6.82
>> >> >> >    3        4   2010               8.63
>> >> >> >    3        5   2010               8.16
>> >> >> >    3        6   2010               7.58
>> >> >> >
>> >> >> > Then if I type summary(df), why it converts the discharge data
>> >to
>> >> >> levels? I
>> >> >> > also met the same problem when reading some other csv files. How
>> >to
>> >> solve
>> >> >> > this problem? Thanks.
>> >> >> >
>> >> >> > Discharge
>> >> >> > 7.58     :2
>> >> >> > 6.4       :1
>> >> >> > 6.82     :1
>> >> >> > 8.63     :1
>> >> >> > 8.16     :1
>> >> >> >
>> >> >> >         [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >see
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> >> posting-guide.html
>> >> >> > and provide commented, minimal, self-contained, reproducible
>> >code.
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Gregory (Greg) L. Snow Ph.D.
>> >> >> 538280 at gmail.com
>> >> >>
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >>
>> >> --
>> >> Jianling Fan
>> >> ???
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From joeceradini at gmail.com  Wed Sep 21 01:06:17 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Tue, 20 Sep 2016 17:06:17 -0600
Subject: [R] about data problem
In-Reply-To: <CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
Message-ID: <CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>

read.csv("your_data.csv", stringsAsFactors=FALSE)
(I'm just reiterating Jianling said...)

Joe

On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:

> Is there a function in read.csv that I can use to avoid converting numeric
> to factor? Thanks a lot.
>
>
>
> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com> wrote:
>
> > Thanks. Then what should I do to solve the problem?
> >
> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> I suppose you can do what works for your data, but I wouldn't recommend
> >> na.rm=TRUE because it hides problems rather than clarifying them.
> >>
> >> If in fact your data includes true NA values (the letters NA or simply
> >> nothing between the commas are typical ways this information may be
> >> indicated), then read.csv will NOT change from integer to factor
> >> (particularly if you have specified which markers represent NA using the
> >> na.strings argument documented under read.table)... so you probably DO
> have
> >> unexpected garbage still in your data which could be obscuring valuable
> >> information that could affect your conclusions.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com>
> >> wrote:
> >> >I reread the data, and use 'na.rm = T' when reading the data. This time
> >> >it
> >> >has no such problem. It seems that the existence of NAs convert the
> >> >integer
> >> >to factor. Thanks for your help.
> >> >
> >> >
> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
> >> >wrote:
> >> >
> >> >> Add the "stringsAsFactors = F"  when you read the data, and then
> >> >> convert them to numeric.
> >> >>
> >> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
> >> >> > Yes, it is stored as factor. I can't check out any problem in the
> >> >> original
> >> >> > data. Reread data doesn't help either. I use read.csv to read in
> >> >the
> >> >> data,
> >> >> > do you think it is better to use read.table? Thanks again.
> >> >> >
> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
> >> >wrote:
> >> >> >
> >> >> >> This indicates that your Discharge column has been
> >> >stored/converted as
> >> >> >> a factor (run str(df) to verify and check other columns).  This
> >> >> >> usually happens when functions like read.table are left to try to
> >> >> >> figure out what each column is and it finds something in that
> >> >column
> >> >> >> that cannot be converted to a number (possibly an oh instead of a
> >> >> >> zero, an el instead of a one, or just a letter or punctuation mark
> >> >> >> accidentally in the file).  You can either find the error in your
> >> >> >> original data, fix it, and reread the data, or specify that the
> >> >column
> >> >> >> should be numeric using the colClasses argument to read.table or
> >> >other
> >> >> >> function.
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
> >> >wrote:
> >> >> >> > Hi R users,
> >> >> >> >
> >> >> >> > I have a problem in reading data.
> >> >> >> > For example, part of my dataframe is like this:
> >> >> >> >
> >> >> >> > df
> >> >> >> > month day year          Discharge
> >> >> >> >    3        1   2010                6.4
> >> >> >> >    3        2   2010               7.58
> >> >> >> >    3        3   2010               6.82
> >> >> >> >    3        4   2010               8.63
> >> >> >> >    3        5   2010               8.16
> >> >> >> >    3        6   2010               7.58
> >> >> >> >
> >> >> >> > Then if I type summary(df), why it converts the discharge data
> >> >to
> >> >> >> levels? I
> >> >> >> > also met the same problem when reading some other csv files. How
> >> >to
> >> >> solve
> >> >> >> > this problem? Thanks.
> >> >> >> >
> >> >> >> > Discharge
> >> >> >> > 7.58     :2
> >> >> >> > 6.4       :1
> >> >> >> > 6.82     :1
> >> >> >> > 8.63     :1
> >> >> >> > 8.16     :1
> >> >> >> >
> >> >> >> >         [[alternative HTML version deleted]]
> >> >> >> >
> >> >> >> > ______________________________________________
> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >see
> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> >> >> posting-guide.html
> >> >> >> > and provide commented, minimal, self-contained, reproducible
> >> >code.
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >> --
> >> >> >> Gregory (Greg) L. Snow Ph.D.
> >> >> >> 538280 at gmail.com
> >> >> >>
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> >> posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Jianling Fan
> >> >> ???
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep 21 01:08:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Sep 2016 16:08:11 -0700
Subject: [R] about data problem
In-Reply-To: <CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
Message-ID: <AC107F84-2B4D-49FB-8901-CA4D1ADD39E5@dcn.davis.ca.us>

Find the offending data. One approach is to look at the input data with your image sensors and neural pattern processor (eyes and brain). One way to reduce the load on those told is to read in the data with the stringsAsFactors=TRUE argument and try manually converting the resulting character strings into numeric values. You can then use the is.na function to find which rows failed to convert and use indexing to review the strings that had trouble. 

# I recommend against using df as a variable name, since it is the name of a function in base R
dta$DischargeNum <- as.numeric( dta$Discharge )
dta[ is.na( dta$DischargeNum ), "Discharge" ]
-- 
Sent from my phone. Please excuse my brevity.

On September 20, 2016 3:42:39 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Thanks. Then what should I do to solve the problem?
>
>On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> I suppose you can do what works for your data, but I wouldn't
>recommend
>> na.rm=TRUE because it hides problems rather than clarifying them.
>>
>> If in fact your data includes true NA values (the letters NA or
>simply
>> nothing between the commas are typical ways this information may be
>> indicated), then read.csv will NOT change from integer to factor
>> (particularly if you have specified which markers represent NA using
>the
>> na.strings argument documented under read.table)... so you probably
>DO have
>> unexpected garbage still in your data which could be obscuring
>valuable
>> information that could affect your conclusions.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com>
>wrote:
>> >I reread the data, and use 'na.rm = T' when reading the data. This
>time
>> >it
>> >has no such problem. It seems that the existence of NAs convert the
>> >integer
>> >to factor. Thanks for your help.
>> >
>> >
>> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan
><fanjianling at gmail.com>
>> >wrote:
>> >
>> >> Add the "stringsAsFactors = F"  when you read the data, and then
>> >> convert them to numeric.
>> >>
>> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com>
>wrote:
>> >> > Yes, it is stored as factor. I can't check out any problem in
>the
>> >> original
>> >> > data. Reread data doesn't help either. I use read.csv to read in
>> >the
>> >> data,
>> >> > do you think it is better to use read.table? Thanks again.
>> >> >
>> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
>> >wrote:
>> >> >
>> >> >> This indicates that your Discharge column has been
>> >stored/converted as
>> >> >> a factor (run str(df) to verify and check other columns).  This
>> >> >> usually happens when functions like read.table are left to try
>to
>> >> >> figure out what each column is and it finds something in that
>> >column
>> >> >> that cannot be converted to a number (possibly an oh instead of
>a
>> >> >> zero, an el instead of a one, or just a letter or punctuation
>mark
>> >> >> accidentally in the file).  You can either find the error in
>your
>> >> >> original data, fix it, and reread the data, or specify that the
>> >column
>> >> >> should be numeric using the colClasses argument to read.table
>or
>> >other
>> >> >> function.
>> >> >>
>> >> >>
>> >> >>
>> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
>> >wrote:
>> >> >> > Hi R users,
>> >> >> >
>> >> >> > I have a problem in reading data.
>> >> >> > For example, part of my dataframe is like this:
>> >> >> >
>> >> >> > df
>> >> >> > month day year          Discharge
>> >> >> >    3        1   2010                6.4
>> >> >> >    3        2   2010               7.58
>> >> >> >    3        3   2010               6.82
>> >> >> >    3        4   2010               8.63
>> >> >> >    3        5   2010               8.16
>> >> >> >    3        6   2010               7.58
>> >> >> >
>> >> >> > Then if I type summary(df), why it converts the discharge
>data
>> >to
>> >> >> levels? I
>> >> >> > also met the same problem when reading some other csv files.
>How
>> >to
>> >> solve
>> >> >> > this problem? Thanks.
>> >> >> >
>> >> >> > Discharge
>> >> >> > 7.58     :2
>> >> >> > 6.4       :1
>> >> >> > 6.82     :1
>> >> >> > 8.63     :1
>> >> >> > 8.16     :1
>> >> >> >
>> >> >> >         [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >see
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> >> posting-guide.html
>> >> >> > and provide commented, minimal, self-contained, reproducible
>> >code.
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Gregory (Greg) L. Snow Ph.D.
>> >> >> 538280 at gmail.com
>> >> >>
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>> >>
>> >> --
>> >> Jianling Fan
>> >> ???
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From chocold12 at gmail.com  Wed Sep 21 01:09:02 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 17:09:02 -0600
Subject: [R] about data problem
In-Reply-To: <CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
	<CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
Message-ID: <CAN5afy88cegPF2iFoSXQfGzZY2edAUgYrZyst0WrCezdJx1hQg@mail.gmail.com>

Yes, I tried to add this statement when reading the dataset.
But when I use summary(df), it shows:
Discharge
Length:
Class  :character
Mode  :character


On Tue, Sep 20, 2016 at 5:06 PM, Joe Ceradini <joeceradini at gmail.com> wrote:

> read.csv("your_data.csv", stringsAsFactors=FALSE)
> (I'm just reiterating Jianling said...)
>
> Joe
>
> On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Is there a function in read.csv that I can use to avoid converting numeric
>> to factor? Thanks a lot.
>>
>>
>>
>> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com> wrote:
>>
>> > Thanks. Then what should I do to solve the problem?
>> >
>> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us>
>> > wrote:
>> >
>> >> I suppose you can do what works for your data, but I wouldn't recommend
>> >> na.rm=TRUE because it hides problems rather than clarifying them.
>> >>
>> >> If in fact your data includes true NA values (the letters NA or simply
>> >> nothing between the commas are typical ways this information may be
>> >> indicated), then read.csv will NOT change from integer to factor
>> >> (particularly if you have specified which markers represent NA using
>> the
>> >> na.strings argument documented under read.table)... so you probably DO
>> have
>> >> unexpected garbage still in your data which could be obscuring valuable
>> >> information that could affect your conclusions.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com>
>> >> wrote:
>> >> >I reread the data, and use 'na.rm = T' when reading the data. This
>> time
>> >> >it
>> >> >has no such problem. It seems that the existence of NAs convert the
>> >> >integer
>> >> >to factor. Thanks for your help.
>> >> >
>> >> >
>> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
>> >> >wrote:
>> >> >
>> >> >> Add the "stringsAsFactors = F"  when you read the data, and then
>> >> >> convert them to numeric.
>> >> >>
>> >> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
>> >> >> > Yes, it is stored as factor. I can't check out any problem in the
>> >> >> original
>> >> >> > data. Reread data doesn't help either. I use read.csv to read in
>> >> >the
>> >> >> data,
>> >> >> > do you think it is better to use read.table? Thanks again.
>> >> >> >
>> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
>> >> >wrote:
>> >> >> >
>> >> >> >> This indicates that your Discharge column has been
>> >> >stored/converted as
>> >> >> >> a factor (run str(df) to verify and check other columns).  This
>> >> >> >> usually happens when functions like read.table are left to try to
>> >> >> >> figure out what each column is and it finds something in that
>> >> >column
>> >> >> >> that cannot be converted to a number (possibly an oh instead of a
>> >> >> >> zero, an el instead of a one, or just a letter or punctuation
>> mark
>> >> >> >> accidentally in the file).  You can either find the error in your
>> >> >> >> original data, fix it, and reread the data, or specify that the
>> >> >column
>> >> >> >> should be numeric using the colClasses argument to read.table or
>> >> >other
>> >> >> >> function.
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
>> >> >wrote:
>> >> >> >> > Hi R users,
>> >> >> >> >
>> >> >> >> > I have a problem in reading data.
>> >> >> >> > For example, part of my dataframe is like this:
>> >> >> >> >
>> >> >> >> > df
>> >> >> >> > month day year          Discharge
>> >> >> >> >    3        1   2010                6.4
>> >> >> >> >    3        2   2010               7.58
>> >> >> >> >    3        3   2010               6.82
>> >> >> >> >    3        4   2010               8.63
>> >> >> >> >    3        5   2010               8.16
>> >> >> >> >    3        6   2010               7.58
>> >> >> >> >
>> >> >> >> > Then if I type summary(df), why it converts the discharge data
>> >> >to
>> >> >> >> levels? I
>> >> >> >> > also met the same problem when reading some other csv files.
>> How
>> >> >to
>> >> >> solve
>> >> >> >> > this problem? Thanks.
>> >> >> >> >
>> >> >> >> > Discharge
>> >> >> >> > 7.58     :2
>> >> >> >> > 6.4       :1
>> >> >> >> > 6.82     :1
>> >> >> >> > 8.63     :1
>> >> >> >> > 8.16     :1
>> >> >> >> >
>> >> >> >> >         [[alternative HTML version deleted]]
>> >> >> >> >
>> >> >> >> > ______________________________________________
>> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >see
>> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> >> >> posting-guide.html
>> >> >> >> > and provide commented, minimal, self-contained, reproducible
>> >> >code.
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >> --
>> >> >> >> Gregory (Greg) L. Snow Ph.D.
>> >> >> >> 538280 at gmail.com
>> >> >> >>
>> >> >> >
>> >> >> >         [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> > PLEASE do read the posting guide http://www.R-project.org/
>> >> >> posting-guide.html
>> >> >> > and provide commented, minimal, self-contained, reproducible code.
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Jianling Fan
>> >> >> ???
>> >> >>
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep 21 01:18:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Sep 2016 16:18:57 -0700
Subject: [R] about data problem
In-Reply-To: <CAN5afy88cegPF2iFoSXQfGzZY2edAUgYrZyst0WrCezdJx1hQg@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
	<CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
	<CAN5afy88cegPF2iFoSXQfGzZY2edAUgYrZyst0WrCezdJx1hQg@mail.gmail.com>
Message-ID: <3F1043F3-524F-410D-BAE0-50EFFE6DEB30@dcn.davis.ca.us>

Which means it avoided converting to factor... Success!

Note that the column apparently has garbage characters in one or more of the rows, which should be evident when you LOOK AT THE CHARACTERS in the column. They should all be numeric symbols, plus or minus, and perhaps decimal points. If they are not, then the conversion to numeric will be incomplete. See my other message. You have the choice of editing the file (may have concerns with traceability), or you can write R code that removes the garbage characters using gsub.
-- 
Sent from my phone. Please excuse my brevity.

On September 20, 2016 4:09:02 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Yes, I tried to add this statement when reading the dataset.
>But when I use summary(df), it shows:
>Discharge
>Length:
>Class  :character
>Mode  :character
>
>
>On Tue, Sep 20, 2016 at 5:06 PM, Joe Ceradini <joeceradini at gmail.com>
>wrote:
>
>> read.csv("your_data.csv", stringsAsFactors=FALSE)
>> (I'm just reiterating Jianling said...)
>>
>> Joe
>>
>> On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:
>>
>>> Is there a function in read.csv that I can use to avoid converting
>numeric
>>> to factor? Thanks a lot.
>>>
>>>
>>>
>>> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com>
>wrote:
>>>
>>> > Thanks. Then what should I do to solve the problem?
>>> >
>>> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us>
>>> > wrote:
>>> >
>>> >> I suppose you can do what works for your data, but I wouldn't
>recommend
>>> >> na.rm=TRUE because it hides problems rather than clarifying them.
>>> >>
>>> >> If in fact your data includes true NA values (the letters NA or
>simply
>>> >> nothing between the commas are typical ways this information may
>be
>>> >> indicated), then read.csv will NOT change from integer to factor
>>> >> (particularly if you have specified which markers represent NA
>using
>>> the
>>> >> na.strings argument documented under read.table)... so you
>probably DO
>>> have
>>> >> unexpected garbage still in your data which could be obscuring
>valuable
>>> >> information that could affect your conclusions.
>>> >> --
>>> >> Sent from my phone. Please excuse my brevity.
>>> >>
>>> >> On September 20, 2016 3:11:42 PM PDT, lily li
><chocold12 at gmail.com>
>>> >> wrote:
>>> >> >I reread the data, and use 'na.rm = T' when reading the data.
>This
>>> time
>>> >> >it
>>> >> >has no such problem. It seems that the existence of NAs convert
>the
>>> >> >integer
>>> >> >to factor. Thanks for your help.
>>> >> >
>>> >> >
>>> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan
><fanjianling at gmail.com>
>>> >> >wrote:
>>> >> >
>>> >> >> Add the "stringsAsFactors = F"  when you read the data, and
>then
>>> >> >> convert them to numeric.
>>> >> >>
>>> >> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com>
>wrote:
>>> >> >> > Yes, it is stored as factor. I can't check out any problem
>in the
>>> >> >> original
>>> >> >> > data. Reread data doesn't help either. I use read.csv to
>read in
>>> >> >the
>>> >> >> data,
>>> >> >> > do you think it is better to use read.table? Thanks again.
>>> >> >> >
>>> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow
><538280 at gmail.com>
>>> >> >wrote:
>>> >> >> >
>>> >> >> >> This indicates that your Discharge column has been
>>> >> >stored/converted as
>>> >> >> >> a factor (run str(df) to verify and check other columns). 
>This
>>> >> >> >> usually happens when functions like read.table are left to
>try to
>>> >> >> >> figure out what each column is and it finds something in
>that
>>> >> >column
>>> >> >> >> that cannot be converted to a number (possibly an oh
>instead of a
>>> >> >> >> zero, an el instead of a one, or just a letter or
>punctuation
>>> mark
>>> >> >> >> accidentally in the file).  You can either find the error
>in your
>>> >> >> >> original data, fix it, and reread the data, or specify that
>the
>>> >> >column
>>> >> >> >> should be numeric using the colClasses argument to
>read.table or
>>> >> >other
>>> >> >> >> function.
>>> >> >> >>
>>> >> >> >>
>>> >> >> >>
>>> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li
><chocold12 at gmail.com>
>>> >> >wrote:
>>> >> >> >> > Hi R users,
>>> >> >> >> >
>>> >> >> >> > I have a problem in reading data.
>>> >> >> >> > For example, part of my dataframe is like this:
>>> >> >> >> >
>>> >> >> >> > df
>>> >> >> >> > month day year          Discharge
>>> >> >> >> >    3        1   2010                6.4
>>> >> >> >> >    3        2   2010               7.58
>>> >> >> >> >    3        3   2010               6.82
>>> >> >> >> >    3        4   2010               8.63
>>> >> >> >> >    3        5   2010               8.16
>>> >> >> >> >    3        6   2010               7.58
>>> >> >> >> >
>>> >> >> >> > Then if I type summary(df), why it converts the discharge
>data
>>> >> >to
>>> >> >> >> levels? I
>>> >> >> >> > also met the same problem when reading some other csv
>files.
>>> How
>>> >> >to
>>> >> >> solve
>>> >> >> >> > this problem? Thanks.
>>> >> >> >> >
>>> >> >> >> > Discharge
>>> >> >> >> > 7.58     :2
>>> >> >> >> > 6.4       :1
>>> >> >> >> > 6.82     :1
>>> >> >> >> > 8.63     :1
>>> >> >> >> > 8.16     :1
>>> >> >> >> >
>>> >> >> >> >         [[alternative HTML version deleted]]
>>> >> >> >> >
>>> >> >> >> > ______________________________________________
>>> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more,
>>> >> >see
>>> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >> >> > PLEASE do read the posting guide
>http://www.R-project.org/
>>> >> >> >> posting-guide.html
>>> >> >> >> > and provide commented, minimal, self-contained,
>reproducible
>>> >> >code.
>>> >> >> >>
>>> >> >> >>
>>> >> >> >>
>>> >> >> >> --
>>> >> >> >> Gregory (Greg) L. Snow Ph.D.
>>> >> >> >> 538280 at gmail.com
>>> >> >> >>
>>> >> >> >
>>> >> >> >         [[alternative HTML version deleted]]
>>> >> >> >
>>> >> >> > ______________________________________________
>>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >> > PLEASE do read the posting guide http://www.R-project.org/
>>> >> >> posting-guide.html
>>> >> >> > and provide commented, minimal, self-contained, reproducible
>code.
>>> >> >>
>>> >> >>
>>> >> >>
>>> >> >> --
>>> >> >> Jianling Fan
>>> >> >> ???
>>> >> >>
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> >
>>> >> >______________________________________________
>>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >PLEASE do read the posting guide
>>> >> >http://www.R-project.org/posting-guide.html
>>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>>> >>
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>> --
>> Cooperative Fish and Wildlife Research Unit
>> Zoology and Physiology Dept.
>> University of Wyoming
>> JoeCeradini at gmail.com / 914.707.8506
>> wyocoopunit.org
>>
>>


From chocold12 at gmail.com  Wed Sep 21 01:22:41 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 20 Sep 2016 17:22:41 -0600
Subject: [R] about data problem
In-Reply-To: <3F1043F3-524F-410D-BAE0-50EFFE6DEB30@dcn.davis.ca.us>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
	<CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
	<CAN5afy88cegPF2iFoSXQfGzZY2edAUgYrZyst0WrCezdJx1hQg@mail.gmail.com>
	<3F1043F3-524F-410D-BAE0-50EFFE6DEB30@dcn.davis.ca.us>
Message-ID: <CAN5afy_DpneeEx1kkHYF=tVZ9bX2A-px=6gBjRRTk04EVkEGNg@mail.gmail.com>

Thanks. The former method works. I confused character with factor.

Besides, I should use: dta$DischargeNum <- as.numeric( dta$Discharge )
instead of: dta$Discharge <- as.numeric( dta$Discharge )


On Tue, Sep 20, 2016 at 5:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Which means it avoided converting to factor... Success!
>
> Note that the column apparently has garbage characters in one or more of
> the rows, which should be evident when you LOOK AT THE CHARACTERS in the
> column. They should all be numeric symbols, plus or minus, and perhaps
> decimal points. If they are not, then the conversion to numeric will be
> incomplete. See my other message. You have the choice of editing the file
> (may have concerns with traceability), or you can write R code that removes
> the garbage characters using gsub.
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 20, 2016 4:09:02 PM PDT, lily li <chocold12 at gmail.com> wrote:
> >Yes, I tried to add this statement when reading the dataset.
> >But when I use summary(df), it shows:
> >Discharge
> >Length:
> >Class  :character
> >Mode  :character
> >
> >
> >On Tue, Sep 20, 2016 at 5:06 PM, Joe Ceradini <joeceradini at gmail.com>
> >wrote:
> >
> >> read.csv("your_data.csv", stringsAsFactors=FALSE)
> >> (I'm just reiterating Jianling said...)
> >>
> >> Joe
> >>
> >> On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:
> >>
> >>> Is there a function in read.csv that I can use to avoid converting
> >numeric
> >>> to factor? Thanks a lot.
> >>>
> >>>
> >>>
> >>> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com>
> >wrote:
> >>>
> >>> > Thanks. Then what should I do to solve the problem?
> >>> >
> >>> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
> >>> jdnewmil at dcn.davis.ca.us>
> >>> > wrote:
> >>> >
> >>> >> I suppose you can do what works for your data, but I wouldn't
> >recommend
> >>> >> na.rm=TRUE because it hides problems rather than clarifying them.
> >>> >>
> >>> >> If in fact your data includes true NA values (the letters NA or
> >simply
> >>> >> nothing between the commas are typical ways this information may
> >be
> >>> >> indicated), then read.csv will NOT change from integer to factor
> >>> >> (particularly if you have specified which markers represent NA
> >using
> >>> the
> >>> >> na.strings argument documented under read.table)... so you
> >probably DO
> >>> have
> >>> >> unexpected garbage still in your data which could be obscuring
> >valuable
> >>> >> information that could affect your conclusions.
> >>> >> --
> >>> >> Sent from my phone. Please excuse my brevity.
> >>> >>
> >>> >> On September 20, 2016 3:11:42 PM PDT, lily li
> ><chocold12 at gmail.com>
> >>> >> wrote:
> >>> >> >I reread the data, and use 'na.rm = T' when reading the data.
> >This
> >>> time
> >>> >> >it
> >>> >> >has no such problem. It seems that the existence of NAs convert
> >the
> >>> >> >integer
> >>> >> >to factor. Thanks for your help.
> >>> >> >
> >>> >> >
> >>> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan
> ><fanjianling at gmail.com>
> >>> >> >wrote:
> >>> >> >
> >>> >> >> Add the "stringsAsFactors = F"  when you read the data, and
> >then
> >>> >> >> convert them to numeric.
> >>> >> >>
> >>> >> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com>
> >wrote:
> >>> >> >> > Yes, it is stored as factor. I can't check out any problem
> >in the
> >>> >> >> original
> >>> >> >> > data. Reread data doesn't help either. I use read.csv to
> >read in
> >>> >> >the
> >>> >> >> data,
> >>> >> >> > do you think it is better to use read.table? Thanks again.
> >>> >> >> >
> >>> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow
> ><538280 at gmail.com>
> >>> >> >wrote:
> >>> >> >> >
> >>> >> >> >> This indicates that your Discharge column has been
> >>> >> >stored/converted as
> >>> >> >> >> a factor (run str(df) to verify and check other columns).
> >This
> >>> >> >> >> usually happens when functions like read.table are left to
> >try to
> >>> >> >> >> figure out what each column is and it finds something in
> >that
> >>> >> >column
> >>> >> >> >> that cannot be converted to a number (possibly an oh
> >instead of a
> >>> >> >> >> zero, an el instead of a one, or just a letter or
> >punctuation
> >>> mark
> >>> >> >> >> accidentally in the file).  You can either find the error
> >in your
> >>> >> >> >> original data, fix it, and reread the data, or specify that
> >the
> >>> >> >column
> >>> >> >> >> should be numeric using the colClasses argument to
> >read.table or
> >>> >> >other
> >>> >> >> >> function.
> >>> >> >> >>
> >>> >> >> >>
> >>> >> >> >>
> >>> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li
> ><chocold12 at gmail.com>
> >>> >> >wrote:
> >>> >> >> >> > Hi R users,
> >>> >> >> >> >
> >>> >> >> >> > I have a problem in reading data.
> >>> >> >> >> > For example, part of my dataframe is like this:
> >>> >> >> >> >
> >>> >> >> >> > df
> >>> >> >> >> > month day year          Discharge
> >>> >> >> >> >    3        1   2010                6.4
> >>> >> >> >> >    3        2   2010               7.58
> >>> >> >> >> >    3        3   2010               6.82
> >>> >> >> >> >    3        4   2010               8.63
> >>> >> >> >> >    3        5   2010               8.16
> >>> >> >> >> >    3        6   2010               7.58
> >>> >> >> >> >
> >>> >> >> >> > Then if I type summary(df), why it converts the discharge
> >data
> >>> >> >to
> >>> >> >> >> levels? I
> >>> >> >> >> > also met the same problem when reading some other csv
> >files.
> >>> How
> >>> >> >to
> >>> >> >> solve
> >>> >> >> >> > this problem? Thanks.
> >>> >> >> >> >
> >>> >> >> >> > Discharge
> >>> >> >> >> > 7.58     :2
> >>> >> >> >> > 6.4       :1
> >>> >> >> >> > 6.82     :1
> >>> >> >> >> > 8.63     :1
> >>> >> >> >> > 8.16     :1
> >>> >> >> >> >
> >>> >> >> >> >         [[alternative HTML version deleted]]
> >>> >> >> >> >
> >>> >> >> >> > ______________________________________________
> >>> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >>> >> >see
> >>> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> >> >> > PLEASE do read the posting guide
> >http://www.R-project.org/
> >>> >> >> >> posting-guide.html
> >>> >> >> >> > and provide commented, minimal, self-contained,
> >reproducible
> >>> >> >code.
> >>> >> >> >>
> >>> >> >> >>
> >>> >> >> >>
> >>> >> >> >> --
> >>> >> >> >> Gregory (Greg) L. Snow Ph.D.
> >>> >> >> >> 538280 at gmail.com
> >>> >> >> >>
> >>> >> >> >
> >>> >> >> >         [[alternative HTML version deleted]]
> >>> >> >> >
> >>> >> >> > ______________________________________________
> >>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more, see
> >>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> >> > PLEASE do read the posting guide http://www.R-project.org/
> >>> >> >> posting-guide.html
> >>> >> >> > and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >> >>
> >>> >> >>
> >>> >> >>
> >>> >> >> --
> >>> >> >> Jianling Fan
> >>> >> >> ???
> >>> >> >>
> >>> >> >
> >>> >> >       [[alternative HTML version deleted]]
> >>> >> >
> >>> >> >______________________________________________
> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> >PLEASE do read the posting guide
> >>> >> >http://www.R-project.org/posting-guide.html
> >>> >> >and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>
> >>> >>
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >> --
> >> Cooperative Fish and Wildlife Research Unit
> >> Zoology and Physiology Dept.
> >> University of Wyoming
> >> JoeCeradini at gmail.com / 914.707.8506
> >> wyocoopunit.org
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Sep 21 02:06:04 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Sep 2016 17:06:04 -0700
Subject: [R] about data problem
In-Reply-To: <CAN5afy_DpneeEx1kkHYF=tVZ9bX2A-px=6gBjRRTk04EVkEGNg@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
	<CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
	<CAN5afy88cegPF2iFoSXQfGzZY2edAUgYrZyst0WrCezdJx1hQg@mail.gmail.com>
	<3F1043F3-524F-410D-BAE0-50EFFE6DEB30@dcn.davis.ca.us>
	<CAN5afy_DpneeEx1kkHYF=tVZ9bX2A-px=6gBjRRTk04EVkEGNg@mail.gmail.com>
Message-ID: <C5E22230-7A81-4158-92F1-ECFE0F3CA804@dcn.davis.ca.us>

You can use the latter IF you know there are no problems with the input data. If you need to troubleshoot then you need separate columns so you can compare them. 
-- 
Sent from my phone. Please excuse my brevity.

On September 20, 2016 4:22:41 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Thanks. The former method works. I confused character with factor.
>
>Besides, I should use: dta$DischargeNum <- as.numeric( dta$Discharge )
>instead of: dta$Discharge <- as.numeric( dta$Discharge )
>
>
>On Tue, Sep 20, 2016 at 5:18 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Which means it avoided converting to factor... Success!
>>
>> Note that the column apparently has garbage characters in one or more
>of
>> the rows, which should be evident when you LOOK AT THE CHARACTERS in
>the
>> column. They should all be numeric symbols, plus or minus, and
>perhaps
>> decimal points. If they are not, then the conversion to numeric will
>be
>> incomplete. See my other message. You have the choice of editing the
>file
>> (may have concerns with traceability), or you can write R code that
>removes
>> the garbage characters using gsub.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 20, 2016 4:09:02 PM PDT, lily li <chocold12 at gmail.com>
>wrote:
>> >Yes, I tried to add this statement when reading the dataset.
>> >But when I use summary(df), it shows:
>> >Discharge
>> >Length:
>> >Class  :character
>> >Mode  :character
>> >
>> >
>> >On Tue, Sep 20, 2016 at 5:06 PM, Joe Ceradini
><joeceradini at gmail.com>
>> >wrote:
>> >
>> >> read.csv("your_data.csv", stringsAsFactors=FALSE)
>> >> (I'm just reiterating Jianling said...)
>> >>
>> >> Joe
>> >>
>> >> On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com>
>wrote:
>> >>
>> >>> Is there a function in read.csv that I can use to avoid
>converting
>> >numeric
>> >>> to factor? Thanks a lot.
>> >>>
>> >>>
>> >>>
>> >>> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com>
>> >wrote:
>> >>>
>> >>> > Thanks. Then what should I do to solve the problem?
>> >>> >
>> >>> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
>> >>> jdnewmil at dcn.davis.ca.us>
>> >>> > wrote:
>> >>> >
>> >>> >> I suppose you can do what works for your data, but I wouldn't
>> >recommend
>> >>> >> na.rm=TRUE because it hides problems rather than clarifying
>them.
>> >>> >>
>> >>> >> If in fact your data includes true NA values (the letters NA
>or
>> >simply
>> >>> >> nothing between the commas are typical ways this information
>may
>> >be
>> >>> >> indicated), then read.csv will NOT change from integer to
>factor
>> >>> >> (particularly if you have specified which markers represent NA
>> >using
>> >>> the
>> >>> >> na.strings argument documented under read.table)... so you
>> >probably DO
>> >>> have
>> >>> >> unexpected garbage still in your data which could be obscuring
>> >valuable
>> >>> >> information that could affect your conclusions.
>> >>> >> --
>> >>> >> Sent from my phone. Please excuse my brevity.
>> >>> >>
>> >>> >> On September 20, 2016 3:11:42 PM PDT, lily li
>> ><chocold12 at gmail.com>
>> >>> >> wrote:
>> >>> >> >I reread the data, and use 'na.rm = T' when reading the data.
>> >This
>> >>> time
>> >>> >> >it
>> >>> >> >has no such problem. It seems that the existence of NAs
>convert
>> >the
>> >>> >> >integer
>> >>> >> >to factor. Thanks for your help.
>> >>> >> >
>> >>> >> >
>> >>> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan
>> ><fanjianling at gmail.com>
>> >>> >> >wrote:
>> >>> >> >
>> >>> >> >> Add the "stringsAsFactors = F"  when you read the data, and
>> >then
>> >>> >> >> convert them to numeric.
>> >>> >> >>
>> >>> >> >> On 20 September 2016 at 16:00, lily li
><chocold12 at gmail.com>
>> >wrote:
>> >>> >> >> > Yes, it is stored as factor. I can't check out any
>problem
>> >in the
>> >>> >> >> original
>> >>> >> >> > data. Reread data doesn't help either. I use read.csv to
>> >read in
>> >>> >> >the
>> >>> >> >> data,
>> >>> >> >> > do you think it is better to use read.table? Thanks
>again.
>> >>> >> >> >
>> >>> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow
>> ><538280 at gmail.com>
>> >>> >> >wrote:
>> >>> >> >> >
>> >>> >> >> >> This indicates that your Discharge column has been
>> >>> >> >stored/converted as
>> >>> >> >> >> a factor (run str(df) to verify and check other
>columns).
>> >This
>> >>> >> >> >> usually happens when functions like read.table are left
>to
>> >try to
>> >>> >> >> >> figure out what each column is and it finds something in
>> >that
>> >>> >> >column
>> >>> >> >> >> that cannot be converted to a number (possibly an oh
>> >instead of a
>> >>> >> >> >> zero, an el instead of a one, or just a letter or
>> >punctuation
>> >>> mark
>> >>> >> >> >> accidentally in the file).  You can either find the
>error
>> >in your
>> >>> >> >> >> original data, fix it, and reread the data, or specify
>that
>> >the
>> >>> >> >column
>> >>> >> >> >> should be numeric using the colClasses argument to
>> >read.table or
>> >>> >> >other
>> >>> >> >> >> function.
>> >>> >> >> >>
>> >>> >> >> >>
>> >>> >> >> >>
>> >>> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li
>> ><chocold12 at gmail.com>
>> >>> >> >wrote:
>> >>> >> >> >> > Hi R users,
>> >>> >> >> >> >
>> >>> >> >> >> > I have a problem in reading data.
>> >>> >> >> >> > For example, part of my dataframe is like this:
>> >>> >> >> >> >
>> >>> >> >> >> > df
>> >>> >> >> >> > month day year          Discharge
>> >>> >> >> >> >    3        1   2010                6.4
>> >>> >> >> >> >    3        2   2010               7.58
>> >>> >> >> >> >    3        3   2010               6.82
>> >>> >> >> >> >    3        4   2010               8.63
>> >>> >> >> >> >    3        5   2010               8.16
>> >>> >> >> >> >    3        6   2010               7.58
>> >>> >> >> >> >
>> >>> >> >> >> > Then if I type summary(df), why it converts the
>discharge
>> >data
>> >>> >> >to
>> >>> >> >> >> levels? I
>> >>> >> >> >> > also met the same problem when reading some other csv
>> >files.
>> >>> How
>> >>> >> >to
>> >>> >> >> solve
>> >>> >> >> >> > this problem? Thanks.
>> >>> >> >> >> >
>> >>> >> >> >> > Discharge
>> >>> >> >> >> > 7.58     :2
>> >>> >> >> >> > 6.4       :1
>> >>> >> >> >> > 6.82     :1
>> >>> >> >> >> > 8.63     :1
>> >>> >> >> >> > 8.16     :1
>> >>> >> >> >> >
>> >>> >> >> >> >         [[alternative HTML version deleted]]
>> >>> >> >> >> >
>> >>> >> >> >> > ______________________________________________
>> >>> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE
>and
>> >more,
>> >>> >> >see
>> >>> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >> >> >> > PLEASE do read the posting guide
>> >http://www.R-project.org/
>> >>> >> >> >> posting-guide.html
>> >>> >> >> >> > and provide commented, minimal, self-contained,
>> >reproducible
>> >>> >> >code.
>> >>> >> >> >>
>> >>> >> >> >>
>> >>> >> >> >>
>> >>> >> >> >> --
>> >>> >> >> >> Gregory (Greg) L. Snow Ph.D.
>> >>> >> >> >> 538280 at gmail.com
>> >>> >> >> >>
>> >>> >> >> >
>> >>> >> >> >         [[alternative HTML version deleted]]
>> >>> >> >> >
>> >>> >> >> > ______________________________________________
>> >>> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> >more, see
>> >>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >> >> > PLEASE do read the posting guide
>http://www.R-project.org/
>> >>> >> >> posting-guide.html
>> >>> >> >> > and provide commented, minimal, self-contained,
>reproducible
>> >code.
>> >>> >> >>
>> >>> >> >>
>> >>> >> >>
>> >>> >> >> --
>> >>> >> >> Jianling Fan
>> >>> >> >> ???
>> >>> >> >>
>> >>> >> >
>> >>> >> >       [[alternative HTML version deleted]]
>> >>> >> >
>> >>> >> >______________________________________________
>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >see
>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >> >PLEASE do read the posting guide
>> >>> >> >http://www.R-project.org/posting-guide.html
>> >>> >> >and provide commented, minimal, self-contained, reproducible
>> >code.
>> >>> >>
>> >>> >>
>> >>> >
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/posti
>> >>> ng-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >> Cooperative Fish and Wildlife Research Unit
>> >> Zoology and Physiology Dept.
>> >> University of Wyoming
>> >> JoeCeradini at gmail.com / 914.707.8506
>> >> wyocoopunit.org
>> >>
>> >>
>>
>>


From bcrombie at utk.edu  Tue Sep 20 21:31:47 2016
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Tue, 20 Sep 2016 19:31:47 +0000
Subject: [R] if/else help
Message-ID: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>

If a data.frame (r4) does not exist in my R environment, I would like to create it before I move on to the next step in my script. How do I make that happen?  Here is what I want to do from a code perspective:

if (exists(r4))
{
is.data.frame(get(r4))
}
else
{
a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
}

Thanks for your help,
B

	[[alternative HTML version deleted]]


From kkam-int at echigo.ne.jp  Wed Sep 21 02:30:15 2016
From: kkam-int at echigo.ne.jp (Kamin Kyuji)
Date: Wed, 21 Sep 2016 09:30:15 +0900
Subject: [R] Query on the R of free soft version 3
Message-ID: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>

Dear

 

Although I can install the new version of the R, I can not open the soft.

 

How do I do it?

 

Kyuzi Kamoi, MD.


	[[alternative HTML version deleted]]


From sastinson at ucdavis.edu  Wed Sep 21 07:28:02 2016
From: sastinson at ucdavis.edu (Sarah Stinson)
Date: Tue, 20 Sep 2016 22:28:02 -0700
Subject: [R] Help with PCA data file prep and R code
Message-ID: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>

Hello DRUGs,
I'm new to R and would appreciate some expert advice on prepping files for,
and running, PCA...

My data set consists of aquatic invertebrate and zooplankton count data and
physicochemical measurements from an ecotoxicology study. Four chemical
treatments were applied to mesocosm tanks, 4 replicates per treatment (16
tanks total), then data were collected weekly over a 3 month period.

I cleaned the data in excel by removing columns with all zero values, and
all rows with NA values.
All zooplankton values were volume normalized, then log normalized. All
other data was log normalized in excel prior to analysis in R. All vectorss
are numeric. I've attached the .csv file to this email rather that using
dput(dataframe). I hope that's acceptable.

My questions are:

1. Did I do the cleaning step appropriately? I know that there are ways to
run PCA's using data that contain NA values (pcaMethods), but wasn't able
to get the code to work...
(I understand that this isn't strictly an R question, but any help would be
appreciated.)
2. Does my code look correct for the PCA and visualization (see below)?

Thanks in advance,
Sarah

#read data
mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")

#run PCA
meso.pca <- prcomp(mesocleaned,
                   center = TRUE,
                   scale. = TRUE)

# print method
print(meso.pca)

#compute standard deviation of each principal component
std_dev <- meso.pca$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:10]

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:20]

#The first principal component explains 12.7% of the variance
#The second explains 8.1%

#visualize
biplot(meso.pca)

#for visualization, make Treatment vector a factor instead of numeric
meso.treatment <- as.factor(mesocleaned[, 3])

#ggbiplot to visualize by Treatment group
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

library(devtools)
install_github("ggbiplot", "vqv")
library(ggbiplot)

print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
meso.treatment, ellipse = TRUE, circle = TRUE))
g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
              groups = meso.treatment, ellipse = TRUE,
              circle = TRUE)
g <- g + scale_color_brewer(name = deparse(substitute(Treatments)), palette
= 'Dark2') #must change meso.treatment to a factor for this to work
g <- g + theme(legend.direction = 'horizontal',
               legend.position = 'top')
print(g)

#Circle plot
#plot each variables coefficients inside a unit circle to get insight on a
possible interpretation for PCs.
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

theta <- seq(0,2*pi,length.out = 100)
circle <- data.frame(x = cos(theta), y = sin(theta))
p <- ggplot(circle,aes(x,y)) + geom_path()

loadings <- data.frame(meso.pca$rotation,
                       .names = row.names(meso.pca$rotation))
p + geom_text(data=loadings,
              mapping=aes(x = PC1, y = PC2, label = .names, colour =
.names)) +
  coord_fixed(ratio=1) +
  labs(x = "PC1", y = "PC2")

From roncaglia.laura at gmail.com  Wed Sep 21 08:42:37 2016
From: roncaglia.laura at gmail.com (laura roncaglia)
Date: Wed, 21 Sep 2016 08:42:37 +0200
Subject: [R] Run a fixed effect regression and a logit regression on a
 national survey that need to be "weighted"
In-Reply-To: <CAN5YmCGNJKAdHypQ3gH8Re3x76LXgP0x9Si82KEpu2+EG-2KOQ@mail.gmail.com>
References: <CAApwzosiBO0AWdK0f4p8y3wS1bcTDbPkgCORDz7cSYOsraVfmg@mail.gmail.com>
	<CAN5YmCGNJKAdHypQ3gH8Re3x76LXgP0x9Si82KEpu2+EG-2KOQ@mail.gmail.com>
Message-ID: <CAApwzovB-5cEFMjY2AQ-T_pRyshKcZRHGfHHRfB9vYE1hrVSow@mail.gmail.com>

Thank you for the answer but I had already tried that way; when I introduce
weights in the glm appears the error:

Warning: non-integer #successes in a binomial glm!

I tried to run the glm regression using the family quasibinomial:

eq <- glm(pip ~ men + age_pr + age_c + I(age_pr^2) + I(age_c^2),
weights = dfweights, data = df, family = quasibinomial(link =
"logit"))

Do you think it could be a right solution?

2016-09-20 18:23 GMT+02:00 Adams, Jean <jvadams at usgs.gov>:

> If you want your records to be weighted by the survey weights during the
> analysis, then use the weights= argument of the glm() function.
>
> Jean
>
> On Tue, Sep 20, 2016 at 5:04 AM, laura roncaglia <
> roncaglia.laura at gmail.com> wrote:
>
>> I am a beginner user of R. I am using a national survey to test what
>> variables influence the partecipation in complementary pensions (the
>> partecipation in complementary pension is voluntary in my country).
>>
>> Since the dependent variable is a dummy (1 if the person partecipate and 0
>> otherwise) I want to run a logit or probit regression; moreover I want to
>> run a fixed effect regression since I subset the survey in order to have
>> only the individuals interviewed more than one time.
>>
>> The data frame is composed by several social and economical variables and
>> it also contain a variable "weight" which is the survey weight (they are
>> weighting coefficients to adjust the results of the sample to the national
>> data).
>>
>>  family pers sex income pension1     10    1   F  10000       12
>> 20    1   F  20000       13     20    2   M  40000       04     30
>> 1   M  25000       05     30    2   F  50000       06     40    1   M
>> 60000       1
>>
>> pers is the component of the family and pension takes 1 if the person
>> partecipate to complementary pension (it is a semplification of the
>> original survey, which contains more variables and observation (aroun 22k
>> observations)).
>>
>> I know how to use the plm and glm functions for a fixed effect or logit
>> regressoin; in this case I don't know what to do since I need to take
>> account of the survey weights.
>>
>> I used the svydesing function to "weight" the data frame:
>>
>> df1 <- svydesign(ids=~1, data=df, weights=~dfweight)
>>
>> I used ids=~1 because there isn't a "cluster" variable in the survey (I
>> know that the towns are ramdomly selected and then individuals are
>> ramdomly
>> selected, but there isn't a variable that indicate the stratification).
>>
>> At this point I am lost: I don't know if it is right to use the survey
>> package and then what function use to run the regression, or there is a
>> way
>> to use the plm or glm functions taking account of the weights.
>>
>> I tried so hard to search a solution on the website but if you could give
>> me an answer I'd be glad.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Sep 21 08:52:05 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 21 Sep 2016 06:52:05 +0000
Subject: [R] Issue on LGP solving
In-Reply-To: <001d01d21347$20ec5290$62c4f7b0$@in>
References: <003101d21305$eff48770$cfdd9650$@in>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DCA6@SRVEXCHMBX.precheza.cz>
	<001d01d21347$20ec5290$62c4f7b0$@in>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DDC9@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: Dr. Debasis Ghosh [mailto:deb at debasis.in]
> Sent: Tuesday, September 20, 2016 3:59 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; R-help at r-project.org
> Subject: RE: [R] Issue on LGP solving
>
> Thanks Petr!! However, I found in the goalprog package I found
> "achievements" as "a  data frame with the deviation variables for each
> objective together with the priority level". I defined
>
> > p1<-c(2,0,0,0,0,0)
> > p2 <- c(0,0,0,0,1,0)
> > p3<- c(0,0,0,0,0,1)
> > achievement <- data.frame(p1,p2,p3)
>
> Here p1, p2 and p3 are the 3 priority levels.
>
> I understand the problem is at "achievement" data frame. To your point,
> data frame with four named columns (objective, priority, p and n), how
> these four columns are defined ?

I have no idea as I never used this package. It was just my guess from difference between your call and manual pages I found on internet.
If I were you I would go through help pages for the package and tried to understand what is going on.
If I did not understand it I would try to find some extended tutorial about this method.
If I did not find anything I would either gave up or seek some help from local statistical expert or contacted maintainer of this package.

Cheers
Petr

>
> Appreciate your time Petr. Thanks again!!
>
> Regards,
> Debasis Ghosh, Ph.D
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Tuesday, September 20, 2016 6:55 AM
> To: Dr. Debasis Ghosh; R-help at r-project.org
> Subject: RE: [R] Issue on LGP solving
>
> Hi
>
> Just a wild guess. Achievement in the goalprog package is data frame with
> four named columns (objective, priority, p and n).
>
> Your achievement is 3 column data.frame with names p1, p2 and p3.
>
> Maybe data frame with defined structure is required.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dr.
> > Debasis Ghosh
> > Sent: Tuesday, September 20, 2016 8:12 AM
> > To: R-help at r-project.org
> > Subject: [R] Issue on LGP solving
> >
> > I was solving a LGP problem which is very basic.
> >
> >
> >
> > Find x0 = [x1; x2], n0 = [n1; n2; n3] and p0 = [p1; p2; p3] that
> > minimize a = [(2p1); (n2); (n3)]
> >
> > The objectives are as follows
> >
> > 10x1 + 15x2 + n1 - p1 = 40
> >
> > 100x1 + 100x2 + n2 - p2 = 1000
> >
> > x2 + n3 - p3 = 7
> >
> > x; n; p >= 0
> >
> > The solution is x' = [4; 0] and a = [0; 600; 7]
> >
> >
> >
> >
> >
> > > local({pkg <- select.list(sort(.packages(all.available =
> > TRUE)),graphics=TRUE)
> >
> > + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> >
> > > local({pkg <- select.list(sort(.packages(all.available =
> > TRUE)),graphics=TRUE)
> >
> > + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> >
> >
> >
> >
> >
> > > coeff<-matrix (c(10,15,100,100,0,1), nrow=3, ncol=2, byrow=TRUE)
> >
> > > target<-c(40,1000,7)
> >
> > > p1<-c(2,0,0,0,0,0)
> >
> > > p2 <- c(0,0,0,0,1,0)
> >
> > > p3<- c(0,0,0,0,0,1)
> >
> > > achievement <- data.frame(p1,p2,p3)
> >
> > > achievement
> >
> >   p1 p2 p3
> >
> > 1  2  0  0
> >
> > 2  0  0  0
> >
> > 3  0  0  0
> >
> > 4  0  0  0
> >
> > 5  0  1  0
> >
> > 6  0  0  1
> >
> > > llgp(coeff,target,achievement)
> >
> >
> >
> > Do you have any idea why I am seeing below error ?
> >
> >
> >
> >
> >
> > Error in matrix(0, nrow = levels, ncol = nonbasics) :
> >
> >   invalid 'nrow' value (too large or NA)
> >
> > In addition: Warning messages:
> >
> > 1: In max(achievements$priority) :
> >
> >   no non-missing arguments to max; returning -Inf
> >
> > 2: In matrix(0, nrow = levels, ncol = nonbasics) :
> >
> >   NAs introduced by coercion to integer range
> >
> >
> >
> > Regards,
> >
> > Debasis Ghosh, Ph.D
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a
> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from
> your system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Wed Sep 21 08:57:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Sep 2016 23:57:54 -0700
Subject: [R] if/else help
In-Reply-To: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
References: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
Message-ID: <9E29902A-F00E-4312-AD07-44CD47BD347F@dcn.davis.ca.us>

Get rid of the commas? Get rid of the get() function call? Get rid of the cbind() function call?  Post using plain text format so the HTML doesn't screw up code? Read the Posting Guide? All of these ideas have merit IMHO...
-- 
Sent from my phone. Please excuse my brevity.

On September 20, 2016 12:31:47 PM PDT, "Crombie, Burnette N" <bcrombie at utk.edu> wrote:
>If a data.frame (r4) does not exist in my R environment, I would like
>to create it before I move on to the next step in my script. How do I
>make that happen?  Here is what I want to do from a code perspective:
>
>if (exists(r4))
>{
>is.data.frame(get(r4))
>}
>else
>{
>a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
>}
>
>Thanks for your help,
>B
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Sep 21 08:58:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 20 Sep 2016 23:58:23 -0700
Subject: [R] if/else help
In-Reply-To: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
References: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
Message-ID: <DDB8BFAE-439E-4003-849B-52371B84FEA7@comcast.net>


> On Sep 20, 2016, at 12:31 PM, Crombie, Burnette N <bcrombie at utk.edu> wrote:
> 
> If a data.frame (r4) does not exist in my R environment, I would like to create it before I move on to the next step in my script. How do I make that happen?  Here is what I want to do from a code perspective:
> 
> if (exists(r4))
> {
> is.data.frame(get(r4))
> }
> else
> {
> a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
> }
> 
> Thanks for your help,
> B
> 
> 	[[alternative HTML version deleted]]

Please, please, please, do not encourage people to use the construction:

data.frame(cbind(....

...and learn to distrust whatever misguided example you learned it from. (Yes, I know there is one in the help pages but that is an exception to the rule.)

There is no reason to use it. It would be much clearer to do this:

r4 <- data.frame(a = 0, b = 0, c = 0, d = "x")    # only one column is factor-class.

If you did it your way you would have gotten four columns of factors, (first cbind() creates a character matrix, and then data.frame() creates factors)  ... which does not appear to be what you expected.

And ... as always has been the case on Rhelp, ... learn to post in plain text.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Sep 21 09:00:10 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Sep 2016 00:00:10 -0700
Subject: [R] Query on the R of free soft version 3
In-Reply-To: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>
References: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>
Message-ID: <8FE01D1E-D9F5-44A6-B550-884D4537D9F0@comcast.net>


> On Sep 20, 2016, at 5:30 PM, Kamin Kyuji <kkam-int at echigo.ne.jp> wrote:
> 
> Dear
> 
> 
> 
> Although I can install the new version of the R, I can not open the soft.
> 
> 
> 
> How do I do it?

Surely you will need to tell us more than that. This just tells us you are having problems but nothing else.


> 
> 
> 
> Kyuzi Kamoi, MD.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Wed Sep 21 09:05:36 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 21 Sep 2016 07:05:36 +0000
Subject: [R] Query on the R of free soft version 3
In-Reply-To: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>
References: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503DE38@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kamin
> Kyuji
> Sent: Wednesday, September 21, 2016 2:30 AM
> To: R-help at r-project.org
> Subject: [R] Query on the R of free soft version 3
>
> Dear
>
>
>
> Although I can install the new version of the R, I can not open the soft.
>
>
>
> How do I do it?

Did you try to doubleclick on R icon?

Your short question imply either our mind reading capability or our presence in your office. The later is not the case however some clever helpers are better in first option than other, so you maybe get better hints.

Cheers
Petr

>
>
>
> Kyuzi Kamoi, MD.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From simon.wood at bath.edu  Wed Sep 21 09:45:03 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Wed, 21 Sep 2016 08:45:03 +0100
Subject: [R] mgcv: bam(),
 error in models with random intercepts and random slopes
In-Reply-To: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>
References: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>
Message-ID: <28c36396-782b-81d1-17a9-327a59ca6c61@bath.edu>

Any chance you could send me the data and exact code that produces this 
(I'll only use the data for investigating this issue of course - often 
data with the predictor replaced by noise will produce the same error, 
if sending the raw data is a problem)?
best, Simon (mgcv maintainer)

On 20/09/16 17:22, Fotis Fotiadis wrote:
> Hi all
>
> I am using the bam function of the mgcv package to model behavioral data of
> a learning experiment. To model individual variation in learning rate, I am
> testing models with (a) by-participant random intercepts of trial, (b)
> by-participant random slopes and random intercepts of trial, and (c)
> by-participant random smooth terms.
>
> While all (a) and (c) models converge, I am getting an error for every
> possible variation of a model with random intercepts and random slopes. For
> example:
>
> m1.rs<-bam(acc~ 1 + igc + s(ctrial) + s(sbj, bs="re") + s(ctrial, sbj,
> bs="re") , data=data_a, family=binomial)
> Error in G$smooth[[i]]$first.para:G$smooth[[i]]$last.para :
>    argument of length 0
>
> Any idea on what that error might be?
>
> Thank you in advance for your time.
> Fotis
>
> P.S.: R version: 3.3.1, mgcv version: 1.8.15
>


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From ruipbarradas at sapo.pt  Wed Sep 21 10:26:07 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 21 Sep 2016 09:26:07 +0100
Subject: [R] "invalid argument to unary operator" while selecting rows
 by name
In-Reply-To: <CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
	<CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
Message-ID: <20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>

Hello,

The error message means exactly what it says. The operator '-' is  
unary and cannot be followed by a non-numeric atomic object (a vector).
Try for instance

x <- list(a=1:10, b=rnorm(5))
-x

Rui Barradas
?

Citando Pauline La?lle <pauline.laille at gmail.com>:

> Works like a charm, thanks! Still don't know what that error message  
> means though. Any idea?
>
> ? 2016-09-20 20:13 GMT+02:00 <ruipbarradas at sapo.pt>:
>> Sorry, I've made a stupid mistake.
>> It's obviously the other way around.
>>
>> ix <- which(rownames(data) %in% c("601", "604"))
>> clean <- data[-ix, ]
>>
>> Rui Barradas
>>
>> Citando ruipbarradas at sapo.pt:  ?
>>> Hello,
>>>
>>> Try something like the following.
>>>
>>> ix <- which(c("601", "604") %in% rownames(data))
>>> clean <- data[-ix, ]
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Citando Pauline La?lle <pauline.laille at gmail.com>:
>>> ?
>>>> Dear all,
>>>>
>>>> I built a dataframe with read.csv2(). Initially, row names are integers
>>>> (order of answers to a survey). They are listed in the csv's first column.
>>>> The import works well and my dataframe looks like I wanted it to look.
>>>>
>>>> Row names go as follows :
>>>> [1] "6"? ?"29"? "31"? "32"? "52"? "55"? "63"? "71"? "72"? "80"? "88"? "89"
>>>> "91"? "93"? "105" "110" "111" "117" "119" "120"
>>>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
>>>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
>>>> etc.
>>>>
>>>> I would like to drop rows "601" & "604" to clean the dataframe.
>>>>
>>>> While data["601",] shows me the first row i'd like to drop, data[-"601",]
>>>> returns the following :
>>>> Error in -"601" : invalid argument to unary operator
>>>>
>>>> idem with data[c("601","604"),] and data[-c("601","604"),]
>>>>
>>>> It is the first time that I run into this specific error. After reading a
>>>> bit about it I still don't understand what it means and how to fix it.
>>>>
>>>> Thanks for reading!
>>>> Best,
>>>> Pauline.
>>>>
>>>> ? ? ? ? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide  
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ?

?

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Sep 21 12:54:37 2016
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 21 Sep 2016 02:54:37 -0800
Subject: [R] Query on the R of free soft version 3
In-Reply-To: <007001d2139f$533cff80$f9b6fe80$@echigo.ne.jp>
Message-ID: <1CA9FFA852D.00000C0Cjrkrideau@inbox.com>

What is your operating system?

Please do not post in HTML.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kkam-int at echigo.ne.jp
> Sent: Wed, 21 Sep 2016 09:30:15 +0900
> To: r-help at r-project.org
> Subject: [R] Query on the R of free soft version 3
> 
> Dear
> 
> 
> 
> Although I can install the new version of the R, I can not open the soft.
> 
> 
> 
> How do I do it?
> 
> 
> 
> Kyuzi Kamoi, MD.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From maechler at stat.math.ethz.ch  Wed Sep 21 13:01:20 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Sep 2016 13:01:20 +0200
Subject: [R] about data problem
In-Reply-To: <CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
References: <CAN5afy9Tve6Jh42dRhcR7dOOEYxBZTKtq4DJz26+UUetbO=qsw@mail.gmail.com>
	<CAFEqCdyHFFYVQ5c1m0enNyA_h9DqgmU0q963NKfyCnPyJi2Rzw@mail.gmail.com>
	<CAN5afy8oZ+L-OMXUEk=cpf2ju882Oabv+jNqjF0KdU+LmkN6Og@mail.gmail.com>
	<CAJ7mryKxZZHPH3uA0FLxtvGJ5Z_MC9ucCFht-LbnpAde4yBWEA@mail.gmail.com>
	<CAN5afy8yTDcjWccGMvzB81O=ZVYjrOHQV662b-KK4eG7iO9bRw@mail.gmail.com>
	<45171C13-989D-408C-8761-CFCB14A4BC6E@dcn.davis.ca.us>
	<CAN5afy9PVPmQCzsfJJ_k-3R_8VH=AN5g+OSSDEpM-hrRbXnKSg@mail.gmail.com>
	<CAN5afy-Ou6k3ncN1-0XAx1rgoftUsdbidcwNPRbjChh7Z=hQTA@mail.gmail.com>
	<CAKq2vL5AU41v+nHRe9gy_CfMP4=K0vr0mJ7oP+h6xEtvot_YRQ@mail.gmail.com>
Message-ID: <22498.26752.140560.47070@stat.math.ethz.ch>

>>>>> Joe Ceradini <joeceradini at gmail.com>
>>>>>     on Tue, 20 Sep 2016 17:06:17 -0600 writes:

    > read.csv("your_data.csv", stringsAsFactors=FALSE)
    > (I'm just reiterating Jianling said...)

If you do not have very many columns, and want to become more
efficient and knowledgeable,
I strongly recommend alternatively to use the 'colClasses' argument
to read.csv or read.table (they are the same apart from defaults
for arguments!) and set "numeric" for numeric columns.

This has a similar effect to the *combination* of
 1)  stringsAsFactors = FALSE
 2)  foo <- as.numeric(foo) # for respective columns

Martin


    > Joe

    > On Tue, Sep 20, 2016 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:

    >> Is there a function in read.csv that I can use to avoid converting numeric
    >> to factor? Thanks a lot.
    >> 
    >> 
    >> 
    >> On Tue, Sep 20, 2016 at 4:42 PM, lily li <chocold12 at gmail.com> wrote:
    >> 
    >> > Thanks. Then what should I do to solve the problem?
    >> >
    >> > On Tue, Sep 20, 2016 at 4:30 PM, Jeff Newmiller <
    >> jdnewmil at dcn.davis.ca.us>
    >> > wrote:
    >> >
    >> >> I suppose you can do what works for your data, but I wouldn't recommend
    >> >> na.rm=TRUE because it hides problems rather than clarifying them.
    >> >>
    >> >> If in fact your data includes true NA values (the letters NA or simply
    >> >> nothing between the commas are typical ways this information may be
    >> >> indicated), then read.csv will NOT change from integer to factor
    >> >> (particularly if you have specified which markers represent NA using the
    >> >> na.strings argument documented under read.table)... so you probably DO
    >> have
    >> >> unexpected garbage still in your data which could be obscuring valuable
    >> >> information that could affect your conclusions.
    >> >> --
    >> >> Sent from my phone. Please excuse my brevity.
    >> >>
    >> >> On September 20, 2016 3:11:42 PM PDT, lily li <chocold12 at gmail.com>
    >> >> wrote:
    >> >> >I reread the data, and use 'na.rm = T' when reading the data. This time
    >> >> >it
    >> >> >has no such problem. It seems that the existence of NAs convert the
    >> >> >integer
    >> >> >to factor. Thanks for your help.
    >> >> >
    >> >> >
    >> >> >On Tue, Sep 20, 2016 at 4:09 PM, Jianling Fan <fanjianling at gmail.com>
    >> >> >wrote:
    >> >> >
    >> >> >> Add the "stringsAsFactors = F"  when you read the data, and then
    >> >> >> convert them to numeric.
    >> >> >>
    >> >> >> On 20 September 2016 at 16:00, lily li <chocold12 at gmail.com> wrote:
    >> >> >> > Yes, it is stored as factor. I can't check out any problem in the
    >> >> >> original
    >> >> >> > data. Reread data doesn't help either. I use read.csv to read in
    >> >> >the
    >> >> >> data,
    >> >> >> > do you think it is better to use read.table? Thanks again.
    >> >> >> >
    >> >> >> > On Tue, Sep 20, 2016 at 3:55 PM, Greg Snow <538280 at gmail.com>
    >> >> >wrote:
    >> >> >> >
    >> >> >> >> This indicates that your Discharge column has been
    >> >> >stored/converted as
    >> >> >> >> a factor (run str(df) to verify and check other columns).  This
    >> >> >> >> usually happens when functions like read.table are left to try to
    >> >> >> >> figure out what each column is and it finds something in that
    >> >> >column
    >> >> >> >> that cannot be converted to a number (possibly an oh instead of a
    >> >> >> >> zero, an el instead of a one, or just a letter or punctuation mark
    >> >> >> >> accidentally in the file).  You can either find the error in your
    >> >> >> >> original data, fix it, and reread the data, or specify that the
    >> >> >column
    >> >> >> >> should be numeric using the colClasses argument to read.table or
    >> >> >other
    >> >> >> >> function.
    >> >> >> >>
    >> >> >> >>
    >> >> >> >>
    >> >> >> >> On Tue, Sep 20, 2016 at 3:46 PM, lily li <chocold12 at gmail.com>
    >> >> >wrote:
    >> >> >> >> > Hi R users,
    >> >> >> >> >
    >> >> >> >> > I have a problem in reading data.
    >> >> >> >> > For example, part of my dataframe is like this:
    >> >> >> >> >
    >> >> >> >> > df
    >> >> >> >> > month day year          Discharge
    >> >> >> >> >    3        1   2010                6.4
    >> >> >> >> >    3        2   2010               7.58
    >> >> >> >> >    3        3   2010               6.82
    >> >> >> >> >    3        4   2010               8.63
    >> >> >> >> >    3        5   2010               8.16
    >> >> >> >> >    3        6   2010               7.58
    >> >> >> >> >
    >> >> >> >> > Then if I type summary(df), why it converts the discharge data
    >> >> >to
    >> >> >> >> levels? I
    >> >> >> >> > also met the same problem when reading some other csv files. How
    >> >> >to
    >> >> >> solve
    >> >> >> >> > this problem? Thanks.
    >> >> >> >> >
    >> >> >> >> > Discharge
    >> >> >> >> > 7.58     :2
    >> >> >> >> > 6.4       :1
    >> >> >> >> > 6.82     :1
    >> >> >> >> > 8.63     :1
    >> >> >> >> > 8.16     :1
    >> >> >> >> >
    >> >> >> >> >         [[alternative HTML version deleted]]
    >> >> >> >> >
    >> >> >> >> > ______________________________________________
    >> >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
    >> >> >see
    >> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> >> >> > PLEASE do read the posting guide http://www.R-project.org/
    >> >> >> >> posting-guide.html
    >> >> >> >> > and provide commented, minimal, self-contained, reproducible
    >> >> >code.
    >> >> >> >>
    >> >> >> >>
    >> >> >> >>
    >> >> >> >> --
    >> >> >> >> Gregory (Greg) L. Snow Ph.D.
    >> >> >> >> 538280 at gmail.com
    >> >> >> >>
    >> >> >> >
    >> >> >> >         [[alternative HTML version deleted]]
    >> >> >> >
    >> >> >> > ______________________________________________
    >> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> >> > PLEASE do read the posting guide http://www.R-project.org/
    >> >> >> posting-guide.html
    >> >> >> > and provide commented, minimal, self-contained, reproducible code.
    >> >> >>
    >> >> >>
    >> >> >>
    >> >> >> --
    >> >> >> Jianling Fan
    >> >> >> ???
    >> >> >>
    >> >> >
    >> >> >       [[alternative HTML version deleted]]
    >> >> >
    >> >> >______________________________________________
    >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> >PLEASE do read the posting guide
    >> >> >http://www.R-project.org/posting-guide.html
    >> >> >and provide commented, minimal, self-contained, reproducible code.
    >> >>
    >> >>
    >> >
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/
    >> posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.




    > -- 
    > Cooperative Fish and Wildlife Research Unit
    > Zoology and Physiology Dept.
    > University of Wyoming
    > JoeCeradini at gmail.com / 914.707.8506
    > wyocoopunit.org

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Wed Sep 21 13:33:27 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 21 Sep 2016 12:33:27 +0100
Subject: [R] "invalid argument to unary operator" while selecting rows
 by name
In-Reply-To: <20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
	<CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
	<20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE6774B1@GBTEDVPEXCMB04.corp.lgc-group.com>

> > Works like a charm, thanks! Still don't know what that error message
> > means though. Any idea?

You tried to negate a character string.
-"601"

'-' can't do that.

[-x] relies on negative _numbers_ to remove elements, not on separate interpretation of '-' and 'x'.



S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From dcarlson at tamu.edu  Wed Sep 21 16:11:24 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 21 Sep 2016 14:11:24 +0000
Subject: [R] Help with PCA data file prep and R code
In-Reply-To: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
References: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
Message-ID: <ba8a4fc087264203aef0317c6e86897c@exch-2p-mbx-w2.ads.tamu.edu>

It was not acceptable. Files with a .csv extension are stripped by the list. If you rename it as .txt it should survive. It appears that you have a controlled experimental design with explanatory and response variables, so why are you using pca which lumps them together? Alternatives might be canonical correlations or canonical correspondence analysis that would let you analyze the count data in terms of the treatments.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Stinson
Sent: Wednesday, September 21, 2016 12:28 AM
To: r-help at r-project.org
Subject: [R] Help with PCA data file prep and R code

Hello DRUGs,
I'm new to R and would appreciate some expert advice on prepping files for,
and running, PCA...

My data set consists of aquatic invertebrate and zooplankton count data and
physicochemical measurements from an ecotoxicology study. Four chemical
treatments were applied to mesocosm tanks, 4 replicates per treatment (16
tanks total), then data were collected weekly over a 3 month period.

I cleaned the data in excel by removing columns with all zero values, and
all rows with NA values.
All zooplankton values were volume normalized, then log normalized. All
other data was log normalized in excel prior to analysis in R. All vectorss
are numeric. I've attached the .csv file to this email rather that using
dput(dataframe). I hope that's acceptable.

My questions are:

1. Did I do the cleaning step appropriately? I know that there are ways to
run PCA's using data that contain NA values (pcaMethods), but wasn't able
to get the code to work...
(I understand that this isn't strictly an R question, but any help would be
appreciated.)
2. Does my code look correct for the PCA and visualization (see below)?

Thanks in advance,
Sarah

#read data
mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")

#run PCA
meso.pca <- prcomp(mesocleaned,
                   center = TRUE,
                   scale. = TRUE)

# print method
print(meso.pca)

#compute standard deviation of each principal component
std_dev <- meso.pca$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:10]

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:20]

#The first principal component explains 12.7% of the variance
#The second explains 8.1%

#visualize
biplot(meso.pca)

#for visualization, make Treatment vector a factor instead of numeric
meso.treatment <- as.factor(mesocleaned[, 3])

#ggbiplot to visualize by Treatment group
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

library(devtools)
install_github("ggbiplot", "vqv")
library(ggbiplot)

print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
meso.treatment, ellipse = TRUE, circle = TRUE))
g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
              groups = meso.treatment, ellipse = TRUE,
              circle = TRUE)
g <- g + scale_color_brewer(name = deparse(substitute(Treatments)), palette
= 'Dark2') #must change meso.treatment to a factor for this to work
g <- g + theme(legend.direction = 'horizontal',
               legend.position = 'top')
print(g)

#Circle plot
#plot each variables coefficients inside a unit circle to get insight on a
possible interpretation for PCs.
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

theta <- seq(0,2*pi,length.out = 100)
circle <- data.frame(x = cos(theta), y = sin(theta))
p <- ggplot(circle,aes(x,y)) + geom_path()

loadings <- data.frame(meso.pca$rotation,
                       .names = row.names(meso.pca$rotation))
p + geom_text(data=loadings,
              mapping=aes(x = PC1, y = PC2, label = .names, colour =
.names)) +
  coord_fixed(ratio=1) +
  labs(x = "PC1", y = "PC2")
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Wed Sep 21 16:19:42 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Wed, 21 Sep 2016 17:19:42 +0300
Subject: [R] Why removing the (Intercept) from lm is done by adding -1?
Message-ID: <c1a7527d35c7ada5f98cd2e3d9e2983a@kapsi.fi>

So I found out that to remove the (Intercept) term from lm's model one 
can add -1 to the predictors. I.e. do lm(resp ~ x1 + x2 - 1)

Another way is to add 0, e.g. lm(resp ~ 0 + x1 + x2).

Adding (or setting the (Intercept) term) zero seems more logical than 
subtracting one, but why is there the method of subtracting one? Why 
does subtracting one mean that the (Intercept) term disappears?


From sarah.goslee at gmail.com  Wed Sep 21 16:34:00 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 21 Sep 2016 10:34:00 -0400
Subject: [R] Why removing the (Intercept) from lm is done by adding -1?
In-Reply-To: <c1a7527d35c7ada5f98cd2e3d9e2983a@kapsi.fi>
References: <c1a7527d35c7ada5f98cd2e3d9e2983a@kapsi.fi>
Message-ID: <CAM_vjunM82FtTnVgv5uK-88VYDntztA4rPZuw-pYi2tdU5=jiw@mail.gmail.com>

Linear regression is of the form

y = mx + b

right?

And in R, - means omit, as in

mydataframe[, -1]

right?

But when you specify a formula within lm(), the intercept is implicit.
That is, you write:

y ~ x

and m and b are fitted.

So if you want to omit the intercept, you use 1 as a placeholder
rather than leaving the - dangling somewhere.

y ~ x - 1

But as you say, there are other ways, so use the one you like.

Note that if you really wanted to subtract 1 from x before fitting the
model, you'd need to make that clear to R:

y ~ I(x - 1)

This is all in the help for formula, where it says "The - operator
removes the specified terms".


Sarah

On Wed, Sep 21, 2016 at 10:19 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> So I found out that to remove the (Intercept) term from lm's model one can
> add -1 to the predictors. I.e. do lm(resp ~ x1 + x2 - 1)
>
> Another way is to add 0, e.g. lm(resp ~ 0 + x1 + x2).
>
> Adding (or setting the (Intercept) term) zero seems more logical than
> subtracting one, but why is there the method of subtracting one? Why does
> subtracting one mean that the (Intercept) term disappears?
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From bgunter.4567 at gmail.com  Wed Sep 21 16:45:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Sep 2016 07:45:09 -0700
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
	<CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
	<20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
Message-ID: <CAGxFJbRyyH4NmpHGdv6Ngesb2hBmKhTmbdwGBC=ihS9qPTxnwQ@mail.gmail.com>

No, Rui, your example misses the point. Your initial sentence hits it.

The OP needs to carefully read
?"["
and/or spend some time with a suitable R tutorial to learn proper
syntax for subscripting. Asking foolish questions in lieu of doing her
homework seems wrongheaded to me. Others may disagree, of course.

Cheers,
Bert




Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 21, 2016 at 1:26 AM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> The error message means exactly what it says. The operator '-' is
> unary and cannot be followed by a non-numeric atomic object (a vector).
> Try for instance
>
> x <- list(a=1:10, b=rnorm(5))
> -x
>
> Rui Barradas
>
>
> Citando Pauline La?lle <pauline.laille at gmail.com>:
>
>> Works like a charm, thanks! Still don't know what that error message
>> means though. Any idea?
>>
>>   2016-09-20 20:13 GMT+02:00 <ruipbarradas at sapo.pt>:
>>> Sorry, I've made a stupid mistake.
>>> It's obviously the other way around.
>>>
>>> ix <- which(rownames(data) %in% c("601", "604"))
>>> clean <- data[-ix, ]
>>>
>>> Rui Barradas
>>>
>>> Citando ruipbarradas at sapo.pt:
>>>> Hello,
>>>>
>>>> Try something like the following.
>>>>
>>>> ix <- which(c("601", "604") %in% rownames(data))
>>>> clean <- data[-ix, ]
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Citando Pauline La?lle <pauline.laille at gmail.com>:
>>>>
>>>>> Dear all,
>>>>>
>>>>> I built a dataframe with read.csv2(). Initially, row names are integers
>>>>> (order of answers to a survey). They are listed in the csv's first column.
>>>>> The import works well and my dataframe looks like I wanted it to look.
>>>>>
>>>>> Row names go as follows :
>>>>> [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"  "89"
>>>>> "91"  "93"  "105" "110" "111" "117" "119" "120"
>>>>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
>>>>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
>>>>> etc.
>>>>>
>>>>> I would like to drop rows "601" & "604" to clean the dataframe.
>>>>>
>>>>> While data["601",] shows me the first row i'd like to drop, data[-"601",]
>>>>> returns the following :
>>>>> Error in -"601" : invalid argument to unary operator
>>>>>
>>>>> idem with data[c("601","604"),] and data[-c("601","604"),]
>>>>>
>>>>> It is the first time that I run into this specific error. After reading a
>>>>> bit about it I still don't understand what it means and how to fix it.
>>>>>
>>>>> Thanks for reading!
>>>>> Best,
>>>>> Pauline.
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Sep 21 16:47:44 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 21 Sep 2016 07:47:44 -0700
Subject: [R] if/else help
In-Reply-To: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
References: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
Message-ID: <CAF8bMcYf327S_DZCXJ5KsrvnXNxqxR_FLKJKOb9ynep5L_SkHw@mail.gmail.com>

If you write your code as functions you can avoid the nasty
'if(exists("x"))x<-...' business this by writing default values for
arguments to your function.   They will be computed only when
they are used.  E.g.,

analyzeData <- function(a=0, b=0, c=0, d="x", r4 = data.frame(a, b, c, d)) {
    summary(r4)
}

> analyzeData(c=101:102)
       a           b           c         d
 Min.   :0   Min.   :0   Min.   :101.0   x:2
 1st Qu.:0   1st Qu.:0   1st Qu.:101.2
 Median :0   Median :0   Median :101.5
 Mean   :0   Mean   :0   Mean   :101.5
 3rd Qu.:0   3rd Qu.:0   3rd Qu.:101.8
 Max.   :0   Max.   :0   Max.   :102.0
> analyzeData(r4=data.frame(a=10:11,b=20:21,c=30:31,d=c("x","y")))
       a               b               c         d
 Min.   :10.00   Min.   :20.00   Min.   :30.00   x:1
 1st Qu.:10.25   1st Qu.:20.25   1st Qu.:30.25   y:1
 Median :10.50   Median :20.50   Median :30.50
 Mean   :10.50   Mean   :20.50   Mean   :30.50
 3rd Qu.:10.75   3rd Qu.:20.75   3rd Qu.:30.75
 Max.   :11.00   Max.   :21.00   Max.   :31.00



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Sep 20, 2016 at 12:31 PM, Crombie, Burnette N <bcrombie at utk.edu>
wrote:

> If a data.frame (r4) does not exist in my R environment, I would like to
> create it before I move on to the next step in my script. How do I make
> that happen?  Here is what I want to do from a code perspective:
>
> if (exists(r4))
> {
> is.data.frame(get(r4))
> }
> else
> {
> a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
> }
>
> Thanks for your help,
> B
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sastinson at ucdavis.edu  Wed Sep 21 17:25:02 2016
From: sastinson at ucdavis.edu (Sarah Stinson)
Date: Wed, 21 Sep 2016 08:25:02 -0700
Subject: [R] Help with PCA data file prep and R code
In-Reply-To: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
References: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
Message-ID: <CABYg=7aPXTJnC1pGCmVdWmVT-ZKvjnaCNy0AzHmpNHg-RE9ZxQ@mail.gmail.com>

Hello DRUGs,
I'm new to R and would appreciate some expert advice on prepping files for,
and running, PCA...

My data set consists of aquatic invertebrate and zooplankton count data and
physicochemical measurements from an ecotoxicology study. Four chemical
treatments were applied to mesocosm tanks, 4 replicates per treatment (16
tanks total), then data were collected weekly over a 3 month period.

I cleaned the data in excel by removing columns with all zero values, and
all rows with NA values.
All zooplankton values were volume normalized, then log normalized. All
other data was log normalized in excel prior to analysis in R. All vectorss
are numeric. I've attached the .txt file to this email rather that using
dput(dataframe).

My questions are:

1. Did I do the cleaning step appropriately? I know that there are ways to
run PCA's using data that contain NA values (pcaMethods), but wasn't able
to get the code to work...
(I understand that this isn't strictly an R question, but any help would be
appreciated.)
2. Does my code look correct for the PCA and visualization (see below)?

Thanks in advance,
Sarah

#read data
mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")

#run PCA
meso.pca <- prcomp(mesocleaned,
                   center = TRUE,
                   scale. = TRUE)

# print method
print(meso.pca)

#compute standard deviation of each principal component
std_dev <- meso.pca$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:10]

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:20]

#The first principal component explains 12.7% of the variance
#The second explains 8.1%

#visualize
biplot(meso.pca)

#for visualization, make Treatment vector a factor instead of numeric
meso.treatment <- as.factor(mesocleaned[, 3])

#ggbiplot to visualize by Treatment group
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

library(devtools)
install_github("ggbiplot", "vqv")
library(ggbiplot)

print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
meso.treatment, ellipse = TRUE, circle = TRUE))
g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
              groups = meso.treatment, ellipse = TRUE,
              circle = TRUE)
g <- g + scale_color_brewer(name = deparse(substitute(Treatments)), palette
= 'Dark2') #must change meso.treatment to a factor for this to work
g <- g + theme(legend.direction = 'horizontal',
               legend.position = 'top')
print(g)

#Circle plot
#plot each variables coefficients inside a unit circle to get insight on a
possible interpretation for PCs.
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

theta <- seq(0,2*pi,length.out = 100)
circle <- data.frame(x = cos(theta), y = sin(theta))
p <- ggplot(circle,aes(x,y)) + geom_path()

loadings <- data.frame(meso.pca$rotation,
                       .names = row.names(meso.pca$rotation))
p + geom_text(data=loadings,
              mapping=aes(x = PC1, y = PC2, label = .names, colour =
.names)) +
  coord_fixed(ratio=1) +
  labs(x = "PC1", y = "PC2")

On Tue, Sep 20, 2016 at 10:28 PM, Sarah Stinson <sastinson at ucdavis.edu>
wrote:

> Hello DRUGs,
> I'm new to R and would appreciate some expert advice on prepping files
> for, and running, PCA...
>
> My data set consists of aquatic invertebrate and zooplankton count data
> and physicochemical measurements from an ecotoxicology study. Four chemical
> treatments were applied to mesocosm tanks, 4 replicates per treatment (16
> tanks total), then data were collected weekly over a 3 month period.
>
> I cleaned the data in excel by removing columns with all zero values, and
> all rows with NA values.
> All zooplankton values were volume normalized, then log normalized. All
> other data was log normalized in excel prior to analysis in R. All vectorss
> are numeric. I've attached the .csv file to this email rather that using
> dput(dataframe). I hope that's acceptable.
>
> My questions are:
>
> 1. Did I do the cleaning step appropriately? I know that there are ways to
> run PCA's using data that contain NA values (pcaMethods), but wasn't able
> to get the code to work...
> (I understand that this isn't strictly an R question, but any help would
> be appreciated.)
> 2. Does my code look correct for the PCA and visualization (see below)?
>
> Thanks in advance,
> Sarah
>
> #read data
> mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")
>
> #run PCA
> meso.pca <- prcomp(mesocleaned,
>                    center = TRUE,
>                    scale. = TRUE)
>
> # print method
> print(meso.pca)
>
> #compute standard deviation of each principal component
> std_dev <- meso.pca$sdev
>
> #compute variance
> pr_var <- std_dev^2
>
> #check variance of first 10 components
> pr_var[1:10]
>
> #proportion of variance explained
> prop_varex <- pr_var/sum(pr_var)
> prop_varex[1:20]
>
> #The first principal component explains 12.7% of the variance
> #The second explains 8.1%
>
> #visualize
> biplot(meso.pca)
>
> #for visualization, make Treatment vector a factor instead of numeric
> meso.treatment <- as.factor(mesocleaned[, 3])
>
> #ggbiplot to visualize by Treatment group
> #reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>
> library(devtools)
> install_github("ggbiplot", "vqv")
> library(ggbiplot)
>
> print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
> meso.treatment, ellipse = TRUE, circle = TRUE))
> g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
>               groups = meso.treatment, ellipse = TRUE,
>               circle = TRUE)
> g <- g + scale_color_brewer(name = deparse(substitute(Treatments)),
> palette = 'Dark2') #must change meso.treatment to a factor for this to work
> g <- g + theme(legend.direction = 'horizontal',
>                legend.position = 'top')
> print(g)
>
> #Circle plot
> #plot each variables coefficients inside a unit circle to get insight on a
> possible interpretation for PCs.
> #reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>
> theta <- seq(0,2*pi,length.out = 100)
> circle <- data.frame(x = cos(theta), y = sin(theta))
> p <- ggplot(circle,aes(x,y)) + geom_path()
>
> loadings <- data.frame(meso.pca$rotation,
>                        .names = row.names(meso.pca$rotation))
> p + geom_text(data=loadings,
>               mapping=aes(x = PC1, y = PC2, label = .names, colour =
> .names)) +
>   coord_fixed(ratio=1) +
>   labs(x = "PC1", y = "PC2")
>
>
-------------- next part --------------
Tank #	Date	Treatment	Temperature meter (C )	pH	DO mg	DO percent	EC	SC	Ephemeroptera	Dysticidae	Tipulidae	Chironomidae	Chaoboridae	Anopholes	Culex	Diptera	Zygoptera	Anisoptera	Odonata	Gastropoda	Corixidae	Hyalella	Nematoda	Hydrachnidae	Cyclopoida	Calanoida	Nauplia	Bosminidae	Chydoridae	Ceriodaphnia	Ostracoda	Keratellahiemalis	Keratellacochlearis	Anuraeopsisspec.	Notholcaspec.	Brachionusangularis	Brachionusquadridentatus	Mytilinaventralis	Platyiaspatulus	Trichocercassp.	Polyarthrasp.	Rotifera
1	08.26.15	control	19.4	8.72	8.15	85.9	719	799	0	0	0	1.361727836	1.230448921	0.698970004	1.968482949	2.155336037	0	0.954242509	0.954242509	0.954242509	0	0	0	0.477121255	2.653490783	0	2.178294218	2.874953569	2.778188332	2.778188332	3.719554865	0	0	0	0	0	3.254826811	0	0	0	0	3.254826811
2	08.26.15	control	18.9	9.3	9.23	96.9	634	718	1.462397998	0	0	1.113943352	0.84509804	0	0	1.278753601	0.698970004	1.397940009	1.462397998	0	0	0.954242509	0.698970004	0.477121255	3.254826811	0	2.178294218	0	3.537257874	3.430837555	3.874431973	0	0	0	0	0	3.988361943	2.178294218	0	0	0	6.166656161
3	08.26.15	control	18.7	9.23	8.05	84.7	642	731	2.012837225	0	0	1.491361694	0.954242509	0.698970004	2.103803721	2.23299611	0	1.278753601	1.278753601	0.477121255	0	0.954242509	0	0.698970004	0	0	2.134399087	0	3.034691437	2.976756765	3.034691437	0	0	0	0	0	0	0	0	0	0	0
4	08.26.15	control	18.5	9.46	9.07	95.7	633	724	2.021189299	0	0	1.176091259	0.84509804	0.477121255	0	1.431363764	0.698970004	1.230448921	1.322219295	0.698970004	0	0	0.698970004	0.477121255	0	0	2.148536707	0	2.623596445	4.245835955	2.448021484	2.148536707	0	0	0	0	2.148536707	2.148536707	0	0	0	6.445610121
5	08.26.15	high diuron	18.4	9.34	8.56	90.4	622	711	1.875061263	0	0	1.544068044	1.875061263	0	1.230448921	2.11058971	1.431363764	0.954242509	1.544068044	1.72427587	0	1.653212514	0	0.954242509	2.734062209	0	2.134399087	0	0	4.188133326	3.245390563	0	0	0	0	0	2.134399087	0	0	2.134399087	0	4.268798174
6	08.26.15	high diuron	18.7	9.27	8.47	89.69	614	699	1.959041392	0	0	1.431363764	1.113943352	0	1.113943352	1.770852012	0	1.176091259	1.176091259	0.698970004	0	0.698970004	0.84509804	0.84509804	2.734062209	0	0	3.131521252	2.609390445	3.307505558	3.511545308	0	0	0	0	0	3.687591987	0	0	0	0	3.687591987
7	08.26.15	high diuron	18.6	9.17	8.26	87.3	680	773	1.591064607	0	0	1.113943352	1.113943352	0	0.698970004	1.462397998	0	1.176091259	1.176091259	0	0	0.477121255	0.698970004	0.698970004	2.107452407	0	0	0	0	3.672342151	2.406783568	0	0	0	0	0	4.450416436	0	0	2.582307069	0	7.032723505
8	08.26.15	high diuron	18.4	9.26	8.86	93.6	640	732	2.012837225	0	0	1.113943352	1.230448921	0.698970004	1.230448921	1.69019608	0.477121255	1.230448921	1.278753601	0	0	0	0	0.84509804	0	0	2.43383264	0	3.210649025	3.493067717	2.909886331	0	0	0	0	0	3.963756437	2.134399087	0	0	0	6.098155524
9	08.26.15	low diuron bifenthrin	18.1	9.16	7.84	82.7	695	800	1.230448921	0	0	1.397940009	1.770852012	0	1.851258349	2.184691431	0	0.954242509	0.954242509	0.698970004	0	0.698970004	0	0	2.859734288	0	2.462693138	0	2.638285261	3.201829649	3.063629264	0	0	0	2.16315712	0	2.16315712	0	0	2.16315712	0	6.48947136
10	08.26.15	low diuron bifenthrin	18.2	9.11	6.81	72.5	653	751	1.886490725	0	0	1.959041392	0.84509804	0	1.462397998	2.096910013	0	1.041392685	1.041392685	0.477121255	0	0	0.84509804	0	2.148536707	0	2.623596445	2.148536707	3.187115801	3.29179066	2.845031715	0	0	0	0	0	4.467674841	0	0	0	0	4.467674841
11	08.26.15	low diuron bifenthrin	18.2	9.26	8.52	91	609	700	1.740362689	0	0.698970004	1.568201724	1.278753601	0.698970004	1.113943352	1.875061263	0.477121255	1.230448921	1.278753601	0.954242509	0	0	0.477121255	0.477121255	3.020916086	0	2.778188332	0	3.537257874	4.321552724	3.883031008	0	0	0	0	0	0	2.178294218	0	0	0	2.178294218
12	08.26.15	low diuron bifenthrin	18.2	9.38	7.71	82.6	629	725	1.633468456	0	0	1.230448921	0.698970004	0.477121255	2.247973266	2.298853076	0	1.176091259	1.176091259	0.698970004	0	0	0.698970004	1.113943352	0	0	0	0	0	2.685606569	2.986188468	0	0	0	0	0	3.438195948	0	0	0	0	3.438195948
13	08.26.15	high diuron bifenthrin	17.5	9.37	9.29	98.2	609	710	1.51851394	0	0	1.612783857	1.591064607	0	1.041392685	1.949390007	0	0.954242509	0.954242509	0	0	0.477121255	1.113943352	0	2.193985593	0	2.193985593	0	2.493624149	3.653692654	2.89072715	0	0	0	0	0	0	0	0	0	0	0
14	08.26.15	high diuron bifenthrin	18	9.35	9.01	97.2	618	714	0.954242509	0	0	1.397940009	1.176091259	0	2.117271296	2.227886705	1.176091259	1.041392685	1.397940009	0.477121255	0	1.491361694	0	0	3.036695572	0	3.036695572	0	3.63845613	4.55669828	4.010784544	0	0	0	0	0	2.193985593	0	2.193985593	0	0	4.387971186
15	08.26.15	high diuron bifenthrin	18.3	9.38	8.66	94.5	657	753	1.949390007	0	0	1.431363764	0	0	0	1.431363764	0.477121255	1.230448921	1.278753601	0.698970004	0	0	0	0.698970004	2.448021484	0	0	0	0	2.845031715	2.623596445	0	0	0	0	0	3.400885834	0	0	0	0	3.400885834
16	08.26.15	high diuron bifenthrin	17.9	9.29	8.95	95.2	693	801	1.653212514	0	0	1.838849091	1.113943352	0	0.698970004	1.929418926	0.698970004	1.230448921	1.322219295	0.954242509	0	0	0	0.477121255	3.020916086	0	2.95403827	0	0	3.891463082	3.755263878	0	0	0	0	0	0	2.178294218	0	0	0	2.178294218
1	09.02.15	control	20	9.05	9.92	108.9	700	773	1.041392685	0	0	1.397940009	1.322219295	1.361727836	2.495544338	2.57863921	0	1.041392685	1.041392685	0	0	0	0	0.477121255	3.479283934	0	3.980780285	0	3.07202262	3.4186077	3.807675738	0	0	0	0	0	2.817044357	2.120713597	0	0	2.120713597	7.058471551
2	09.02.15	control	19.6	9.3	10.1	109.8	635	708	1.812913357	0	0	1.361727836	0.477121255	0	0.84509804	1.491361694	0	1.041392685	1.041392685	0.84509804	0	1.113943352	0	0	3.07202262	0	2.120713597	0	3.020916086	3.348055856	3.81644831	0	0	0	0	0	4.482914298	2.420095946	0	0	2.720299768	9.623310012
3	09.02.15	control	19.3	9.2	9.01	97.5	656	737	1.672097858	0	0	1.919078092	1.770852012	1.230448921	1.838849091	2.352182518	0.477121255	1.568201724	1.591064607	0.698970004	0	0.698970004	0.954242509	0.954242509	2.120713597	0	2.817044357	0	2.420095946	3.685703314	3.196869365	0	0	0	0	0	4.844145455	2.120713597	0	0	3.117743317	10.08260237
4	09.02.15	control	19.1	9.44	9.78	105.3	645	727	1.72427587	0	0	1.230448921	1.041392685	0	1.591064607	1.826074803	1.176091259	1.278753601	1.51851394	0.84509804	0	0	1.113943352	0.698970004	0	0	0	0	2.734062209	4.479519572	3.493067717	0	0	0	0	0	3.649811532	2.609390445	0	0	0	6.259201977
5	09.02.15	high diuron	19.1	9.26	9.17	98.4	625	704	1.826074803	0.477121255	0	0	0	0	2.828015064	2.828015064	1.176091259	1.113943352	1.431363764	1.491361694	0	1.462397998	0	1.041392685	3.020916086	0	2.120713597	2.595636597	2.420095946	4.056969373	2.720299768	0	0	0	0	0	2.120713597	0	0	0	0	2.120713597
6	09.02.15	high diuron	19.2	9.3	9.97	107.8	624	701	1.875061263	0	0.698970004	2.029383778	1.812913357	0.477121255	1.612783857	2.348304863	1.113943352	0.698970004	1.230448921	0.84509804	0	0	0.698970004	0	0	0	0	0	0	3.307505558	2.43383264	0	0	0	0	0	2.976756765	0	0	0	0	2.976756765
7	09.02.15	high diuron	19.3	9.19	8.89	96	703	787	1.176091259	0	0	1.653212514	1.875061263	0.698970004	1.113943352	2.130333768	0	0.84509804	0.84509804	0	0	0.84509804	0	0	2.706961648	0	2.582307069	0	2.107452407	4.548105156	4.116918472	0	0	0	0	0	4.669905172	2.803701077	0	2.107452407	2.882768563	12.46382722
8	09.02.15	high diuron	19	9.33	10.19	109.9	643	726	1.908485019	0	0	1.041392685	1.397940009	0	1.462397998	1.799340549	0.84509804	1.361727836	1.462397998	0	0	0	0	1.041392685	0	0	0	0	0	3.263776724	2.96298326	0	0	0	0	0	3.159105895	0	0	0	0	3.159105895
9	09.02.15	low diuron bifenthrin	19	9.13	9.52	102.2	714	805	1.707570176	0.698970004	0	1.176091259	0	0.698970004	2.392696953	2.423245874	0	1.230448921	1.230448921	0	0	0	0.698970004	0.477121255	2.830811959	0	2.43383264	0	3.034691437	4.396035584	3.277557615	0	0	0	0	0	3.131521252	0	0	0	2.134399087	5.265920339
10	09.02.15	low diuron bifenthrin	19	9.04	8.42	90.5	672	759	1.707570176	0	0	1.908485019	1.755874856	0	1.361727836	2.201397124	0.477121255	0	0.477121255	0	0	0	0.698970004	0.84509804	2.120713597	0	2.120713597	0	3.479283934	3.760940019	3.020916086	0	0	0	0	0	4.532398122	2.120713597	0	2.420095946	0	9.073207665
11	09.02.15	low diuron bifenthrin	19.1	9.22	9.95	102.5	616	694	1.113943352	0	0	1.544068044	0.954242509	0.698970004	1.462397998	1.875061263	0.84509804	0.954242509	1.176091259	0	0	1.113943352	0	0	0	0	0	0	2.477881497	4.038766558	3.217060206	0	0	0	0	0	2.477881497	0	0	0	0	2.477881497
12	09.02.15	low diuron bifenthrin	19.2	9.3	9.69	104.4	656	738	1.51851394	0	0	1.491361694	0.84509804	0.477121255	1.612783857	1.908485019	0	1.113943352	1.113943352	0.477121255	0	0	0	0.477121255	3.963756437	0	3.63645061	0	3.493067717	3.172884771	3.172884771	0	0	0	0	0	3.930591821	2.134399087	0	2.734062209	0	8.799053117
13	09.02.15	high diuron bifenthrin	19.2	9.25	9.86	106.9	627	705	1.51851394	0	0	1.397940009	1.322219295	0.698970004	1.785329835	2.045322979	0.477121255	0.698970004	0.84509804	0	0	1.113943352	1.041392685	0	2.448021484	0	0	0	3.29179066	3.808266122	2.448021484	0	0	0	0	0	0	0	0	0	2.92410953	2.92410953
14	09.02.15	high diuron bifenthrin	19.5	9.33	10.39	112.6	622	696	0.698970004	0	0	1.633468456	0.698970004	0.84509804	2.527629901	2.589949601	1.278753601	1.041392685	1.462397998	0.698970004	0	1.69019608	0	0	2.720299768	0	0	0	3.159105895	3.91680518	3.321739096	0	0	0	0	0	3.321739096	0	0	0	0	3.321739096
15	09.02.15	high diuron bifenthrin	19.6	9.32	9.7	105.4	682	760	1.875061263	0	0	1.491361694	0.954242509	0	1.462397998	1.826074803	0.477121255	1.113943352	1.176091259	0	0	0	0	1.041392685	2.734062209	0	0	0	0	2.830811959	3.034691437	0	0	0	0	0	0	0	0	0	0	0
16	09.02.15	high diuron bifenthrin	19	9.28	10.26	110	703	795	1.653212514	0	0	1.86332286	1.544068044	0	1.176091259	2.08278537	0.477121255	1.041392685	1.113943352	1.041392685	0	0	0.477121255	1.113943352	3.277557615	0	2.134399087	0	2.609390445	4.065736094	4.184307167	0	0	0	0	0	2.134399087	2.134399087	0	0	0	4.268798174
1	09.09.15	control	18.2	9.19	9.94	105.9	759	871	1.462397998	0	0	1.397940009	1.113943352	0	1.672097858	1.939519253	0	0	0	0.698970004	0	0	0.698970004	0.84509804	3.755263878	0	4.425840268	0	2.178294218	4.324643654	3.590488842	0	0	0	0	0	0	3.175693866	0	2.778188332	2.178294218	8.132176416
2	09.09.15	control	17	9.42	10.93	113.6	643	759	1.176091259	0	0	1.230448921	1.113943352	0.477121255	1.278753601	1.707570176	0.84509804	1.041392685	1.230448921	0.698970004	0	0.954242509	0.698970004	0.84509804	2.653490783	0	0	0	3.217060206	3.652621882	4.104857016	0	0	0	0	0	3.321739096	2.178294218	0	2.477881497	0	7.977914811
3	09.09.15	control	16.6	9.18	9.47	97	662	789	1.397940009	0	0	0.477121255	0.698970004	0.84509804	2.484299839	2.501059262	0.698970004	0.84509804	1.041392685	0	0	0.954242509	0	0.954242509	3.048918942	0	2.148536707	0	2.748276803	4.285342352	3.607945875	0	0	0	0	0	5.053929606	0	0	0	0	5.053929606
4	09.09.15	control	16.3	9.38	9.92	101.2	658	789	1.041392685	0.477121255	0	1.361727836	0.954242509	0.477121255	1.113943352	1.653212514	1.278753601	0.84509804	1.397940009	0.698970004	0	0	0.84509804	0.477121255	0	0	0	0	2.638285261	4.490591816	3.41560334	0	0	2.16315712	0	0	4.490591816	2.16315712	0	0	0	8.816906056
5	09.09.15	high diuron	16.4	9.28	8.77	89.9	647	772	1.612783857	0	0	1.041392685	0.698970004	0	2.037426498	2.089905111	1.799340549	1.176091259	1.886490725	1.672097858	0	2.257678575	0	0	4.050503902	0	3.891463082	0	2.178294218	3.573459963	3.078856296	0	0	0	0	0	2.95403827	2.178294218	0	2.477881497	3.454310174	11.06452416
6	09.09.15	high diuron	16.7	9.28	8.86	91.1	645	768	1.462397998	0	0	1.230448921	0.84509804	0.84509804	2.1430148	2.227886705	1.322219295	0.954242509	1.462397998	0.477121255	0	0	0	1.041392685	2.178294218	0	0	0	2.477881497	3.755263878	3.931329703	0	0	0	0	0	3.254826811	0	0	2.178294218	2.178294218	7.611415247
7	09.09.15	high diuron	16.7	9.17	8.46	87.1	708	841	1.591064607	0.477121255	0	1.653212514	0	0.477121255	1.908485019	2.103803721	0.698970004	0.954242509	1.113943352	0.698970004	0	0.477121255	0	0.698970004	2.95403827	0	3.020916086	0	2.477881497	4.392905494	3.694005781	0	0	0	0	0	4.491388329	2.477881497	0	2.178294218	3.020916086	12.16848013
8	09.09.15	high diuron	16.1	9.3	9.23	93.9	661	796	1.568201724	0.477121255	0	1.176091259	0.477121255	0.84509804	1.838849091	1.968482949	1.51851394	1.041392685	1.633468456	0	0	0	0.698970004	0.84509804	3.020916086	0	3.078856296	0	0	4.463220652	2.178294218	0	0	0	0	0	4.073067772	0	0	0	0	4.073067772
9	09.09.15	low diuron bifenthrin	16.3	9.25	9.22	94.1	713	852	1.568201724	0	0	1.230448921	1.113943352	0.954242509	2.423245874	2.478566496	0	0.954242509	0.954242509	0.477121255	0	0	0.477121255	1.113943352	2.778188332	0	2.778188332	0	3.217060206	4.460976309	3.175693866	0	0	0	0	0	2.653490783	0	0	0	2.178294218	4.831785001
10	09.09.15	low diuron bifenthrin	16.1	9.18	9.14	93.2	675	813	1.361727836	0	0	0.84509804	1.041392685	0.84509804	1.653212514	1.826074803	1.431363764	1.278753601	1.653212514	0.954242509	0	0	0	1.041392685	0	0	0	0	3.41560334	4.164515118	2.938815545	0	0	0	0	0	4.417859177	0	0	2.16315712	0	6.581016297
11	09.09.15	low diuron bifenthrin	16	9.36	9.92	100.8	620	748	1.322219295	0	0	1.041392685	1.113943352	0.84509804	2.068185862	2.161368002	1.322219295	0.954242509	1.462397998	0	0	0.84509804	0	0.954242509	3.321739096	0	3.111015108	0	3.463010735	4.110712303	3.684799662	0	0	0	0	0	2.210273092	2.210273092	0	2.810321315	4.000023777	11.23089128
12	09.09.15	low diuron bifenthrin	16.2	9.46	10.83	110.1	642	771	1.322219295	0	0	1.113943352	0.698970004	0	1.672097858	1.799340549	1.322219295	1.113943352	1.51851394	0	0.477121255	0	0.477121255	0.698970004	2.653490783	0	0	0	2.874953569	2.477881497	3.217060206	0	0	0	0	0	2.178294218	0	0	2.178294218	0	4.356588436
13	09.09.15	high diuron bifenthrin	15.3	9.35	10.1	100.6	618	758	1.322219295	0	0	0.698970004	0.84509804	1.230448921	2.206825876	2.271841607	0.954242509	0.477121255	1.041392685	0.477121255	0	1.322219295	0.698970004	1.113943352	3.145751342	0	3.094637628	0	2.79395675	3.863355592	3.622665561	0	0	0	0	0	0	2.89072715	0	2.193985593	3.606279127	8.69099187
14	09.09.15	high diuron bifenthrin	15.9	9.46	10.58	106.9	616	747	1.230448921	0	0	1.812913357	1.041392685	0.698970004	2.053078443	2.281033367	1.491361694	1.113943352	1.633468456	0.698970004	0	1.431363764	1.041392685	0.477121255	3.020916086	2.178294218	2.874953569	0	3.497761337	4.418458594	3.497761337	0	0	0	0	0	3.666859203	0	0	2.477881497	0	6.1447407
15	09.09.15	high diuron bifenthrin	16.2	9.36	8.67	88.3	695	834	1.397940009	0.477121255	0	1.041392685	0.84509804	0	1.431363764	1.633468456	0.954242509	0.954242509	1.230448921	0	0	0	0	1.176091259	3.694005781	0	2.178294218	0	2.653490783	3.590488842	3.430837555	2.477881497	0	0	0	0	2.178294218	0	0	0	0	4.656175715
16	09.09.15	high diuron bifenthrin	15.6	9.34	9.32	93.5	707	862	1.176091259	0.477121255	0	0.477121255	1.278753601	0.698970004	1.633468456	1.826074803	0	1.041392685	1.041392685	0	0	0	0	1.230448921	0	0	0	0	2.778188332	0	3.175693866	0	0	0	0	0	2.178294218	0	0	0	0	2.178294218
1	09.16.15	control	17.1	9.28	10.76	109.8	746	880	0	0.698970004	0	2.029383778	0.84509804	0	1.544068044	2.167317335	0.477121255	1.176091259	1.230448921	0	0	0	0	0.954242509	3.517958449	0	3.321739096	0	2.477881497	4.032776746	2.95403827	0	0	0	0	0	2.477881497	0	0	2.178294218	2.178294218	6.834469933
2	09.16.15	control	17.4	9.43	11.47	119	638	749	1.322219295	0	0.477121255	1.113943352	1.361727836	0	0.84509804	1.653212514	0.477121255	1.041392685	1.113943352	0.84509804	0	0.954242509	0	0.477121255	0	0	2.178294218	0	2.778188332	4.109936144	3.47657894	0	0	0	0	0	2.178294218	0	0	0	2.95403827	5.132332488
3	09.16.15	control	17.1	9.3	10.85	112.6	656	771	1.544068044	0.477121255	0	1.278753601	1.361727836	0.698970004	1.568201724	1.919078092	0.698970004	0.954242509	1.113943352	0.84509804	0	1.397940009	1.041392685	0.698970004	2.43383264	0	2.134399087	0	2.734062209	4.070756467	3.453572465	0	0	0	0	0	4.430069522	2.134399087	0	0	2.609390445	9.173859054
4	09.16.15	control	16.8	9.47	11.33	116.5	652	773	1.612783857	0	0	1.113943352	0.698970004	1.176091259	1.230448921	1.672097858	1.041392685	0.698970004	1.176091259	0.477121255	0	0	0.698970004	0	2.595636597	0	0	0	2.420095946	4.701751883	3.923643782	0	0	0	0	0	5.023212025	0	0	0	0	5.023212025
5	09.16.15	high diuron	16.9	9.26	9.72	100.6	632	747	1.431363764	0	0	1.672097858	0.698970004	0	1.113943352	1.799340549	1.826074803	0.954242509	1.875061263	1.612783857	0	2.285557309	0	0	3.522022409	0	2.762974214	0	2.16315712	2.462693138	2.859734288	0	0	0	0	0	2.462693138	2.16315712	0	2.16315712	3.274338334	10.06334571
6	09.16.15	high diuron	16.5	9.14	9.82	100.3	658	786	1.785329835	0.477121255	0	1.113943352	0.954242509	0.477121255	1.322219295	1.653212514	0.954242509	1.041392685	1.278753601	0	0	0	0.477121255	1.176091259	2.845031715	0	3.100028348	0	2.448021484	4.252674994	3.321739096	0	0	0	0	0	4.186861681	0	0	0	0	4.186861681
7	09.16.15	high diuron	16.5	9.1	8.84	90.3	739	881	1.278753601	0.477121255	0	1.51851394	0.84509804	0.477121255	1.113943352	1.72427587	0	0.84509804	0.84509804	0	0	0.954242509	0.477121255	0.698970004	0	0	0	0	0	4.562093163	0	0	0	0	0	0	4.455086149	0	0	0	2.623596445	7.078682594
8	09.16.15	high diuron	16.4	9.23	10.47	106.6	803	671	1.672097858	0	0	1.361727836	1.041392685	0.698970004	0.954242509	1.653212514	1.041392685	1.041392685	1.322219295	0	0	0	0.477121255	0.954242509	3.100028348	0	3.349754879	0	2.448021484	4.294681899	2.748276803	0	0	0	0	0	3.224880838	0	0	0	0	3.224880838
9	09.16.15	low diuron bifenthrin	16.6	9.18	9.59	99.9	710	844	1.361727836	0	0	1.919078092	1.113943352	0	1.431363764	2.08278537	0	1.041392685	1.041392685	0	0	0	0	0.84509804	2.909886331	0	2.609390445	0	2.734062209	4.467674841	3.33552091	0	0	0	0	0	0	0	0	0	2.830811959	2.830811959
10	09.16.15	low diuron bifenthrin	16.6	9.21	10.35	106.4	689	821	1.462397998	0	0	1.770852012	1.041392685	0.477121255	2.1430148	2.324282455	0.954242509	0.698970004	1.113943352	0.698970004	0	0	0	1.230448921	0	0	2.623596445	0	2.845031715	4.089958729	0	0	0	0	0	0	4.609344417	0	0	0	0	4.609344417
11	09.16.15	low diuron bifenthrin	16.5	9.41	11.42	116.7	625	746	1.322219295	0	0	1.278753601	0.477121255	0	0.954242509	1.491361694	1.041392685	1.041392685	1.322219295	0	0	0.954242509	0	0.84509804	2.193985593	0	2.193985593	0	0	4.023748275	3.094637628	0	0	0	0	0	2.669250603	0	0	0	2.79395675	5.463207353
12	09.16.15	low diuron bifenthrin	16.4	9.83	13.4	132.8	662	793	1.113943352	0.477121255	0	1.361727836	0.698970004	0.477121255	1.397940009	1.72427587	0.84509804	1.113943352	1.278753601	0	0	0	0	0.84509804	3.931329703	0	4.239886962	0	3.351688516	3.652621882	3.217060206	0	0	0	0	0	2.178294218	0	0	3.020916086	0	5.199210304
13	09.16.15	high diuron bifenthrin	16.8	9.2	10.82	111	625	740	1.633468456	0	0	0.698970004	1.397940009	0.477121255	1.397940009	1.740362689	0.84509804	1.113943352	1.278753601	0	0	0.84509804	0.84509804	0.954242509	0	0	3.379705162	0	0	3.946305134	2.778188332	0	0	0	0	0	0	0	0	0	0	0
14	09.16.15	high diuron bifenthrin	17	9.45	12.32	127.1	645	762	0	0	0	1.176091259	0.698970004	0	1.278753601	1.568201724	0.954242509	0.954242509	1.230448921	0.698970004	0	1.431363764	0.477121255	0.84509804	2.859734288	0	3.005690901	0	3.986283636	4.568415706	0	3.005690901	0	0	0	0	3.522022409	0	0	2.16315712	0	8.69087043
15	09.16.15	high diuron bifenthrin	16.9	9.35	10.66	109.9	715	844	1.361727836	0	0	1.51851394	0.698970004	0	0.477121255	1.591064607	0.84509804	1.278753601	1.397940009	0	0	0	0	0.698970004	3.306506523	0	2.16315712	0	2.16315712	3.461344151	3.522022409	0	0	0	0	0	0	0	0	0	0	0
16	09.16.15	high diuron bifenthrin	16.5	9.3	9.92	101.5	744	888	1.322219295	0	0	1.113943352	1.230448921	0.698970004	1.176091259	1.672097858	0.477121255	0.84509804	0.954242509	0	0	0.477121255	0	0.698970004	2.95403827	0	2.178294218	0	0	4.621018572	3.946305134	0	0	0	0	0	0	0	0	0	0	0
1	09.23.15	control	16	9.04	9.15	92.5	766	920	1.230448921	0.954242509	0	2.328379603	1.361727836	0	2.426511261	2.701567985	0	1.361727836	1.361727836	0.477121255	0	0	0.477121255	1.176091259	3.351688516	0	4.014295091	3.555736028	2.178294218	3.899734556	3.020916086	0	0	0	0	0	3.454310174	0	0	2.778188332	0	6.232498506
2	09.23.15	control	15.4	9.24	9.87	99.1	642	783	0.84509804	0	0	1.812913357	1.462397998	1.041392685	1.361727836	2.096910013	1.113943352	1.113943352	1.397940009	0	0	0.698970004	0	0	2.778188332	0	0	0	0	4.765361031	3.622665561	0	2.477881497	0	0	0	3.573459963	0	0	2.178294218	0	8.229635678
3	09.23.15	control	15	9.18	9.22	89.7	658	812	1.431363764	0.477121255	0	2.136720567	1.707570176	0	1.397940009	2.324282455	1.041392685	1.653212514	1.740362689	0.84509804	0	0	0	0.698970004	3.048918942	0	3.100028348	3.758300383	2.92410953	4.008806171	3.677011042	0	0	0	0	0	4.678204242	0	0	2.148536707	0	6.826740949
4	09.23.15	control	14.9	9.29	8.69	85.6	665	824	1.51851394	0.477121255	0	1.755874856	1.51851394	1.230448921	1.568201724	2.149219113	0.954242509	0.954242509	1.230448921	0.477121255	0	0	0	0.698970004	2.477881497	0	0	3.590488842	0	4.327712741	3.856705622	0	0	0	0	0	4.962160135	0	0	0	0	4.962160135
5	09.23.15	high diuron	15.2	9.13	8.6	85.8	655	807	1.278753601	0	0	1.176091259	1.544068044	1.041392685	0	1.770852012	2.012837225	1.431363764	2.11058971	1.838849091	0	1.875061263	0	1.113943352	3.488004637	0	3.937882551	2.845031715	0	3.3760724	3.187115801	0	0	0	0	0	2.448021484	0	0	2.845031715	0	5.293053199
6	09.23.15	high diuron	15	9.02	8.26	81.9	666	823	1.278753601	0	0	1.886490725	1.176091259	0.698970004	1.812913357	2.247973266	1.278753601	0.84509804	1.397940009	0	0	0	0	0.477121255	2.762974214	0	2.462693138	3.622665561	2.859734288	3.916091553	3.201829649	0	0	0	0	0	4.358840104	0	0	2.16315712	0	6.521997224
7	09.23.15	high diuron	15.2	8.9	7.09	70.8	763	938	1.278753601	0	0	1.755874856	0.698970004	1.176091259	2.021189299	2.252853031	0.477121255	1.431363764	1.462397998	1.278753601	0	0.84509804	0	0.477121255	2.762974214	0	2.638285261	4.185498207	0	4.377666155	3.783484804	0	0	0	0	0	4.413033818	0	0	0	0	4.413033818
8	09.23.15	high diuron	14.8	9.03	8.52	84.5	689	856	1.230448921	0	0	1.633468456	0	1.041392685	0.84509804	1.770852012	1.278753601	0.698970004	1.361727836	0	0	0	0	0.477121255	3.522022409	0	0	0	0	3.71654993	3.892613384	0	0	0	0	0	2.16315712	0	0	0	0	2.16315712
9	09.23.15	low diuron bifenthrin	15.1	8.98	7.96	78.8	718	886	1.431363764	0	0	1.633468456	1.361727836	1.230448921	1.707570176	2.123851641	0	1.322219295	1.322219295	0.698970004	0	0	0.698970004	0.698970004	2.653490783	2.178294218	0	2.778188332	0	4.376819337	3.537257874	0	0	0	0	0	0	0	0	0	0	0
10	09.23.15	low diuron bifenthrin	14.8	9.08	8.73	84.9	674	838	1.230448921	0	0	1.919078092	0.477121255	1.278753601	1.707570176	2.184691431	0.477121255	1.113943352	1.176091259	0.477121255	0	0	0	1.041392685	3.114740106	0	2.859734288	4.079278285	3.274338334	3.704317857	3.558224138	0	0	0	0	0	4.463375008	0	0	0	0	4.463375008
11	09.23.15	low diuron bifenthrin	14.6	9.21	9.4	91.9	622	777	1.591064607	0.477121255	0	1.230448921	0.698970004	0.698970004	1.113943352	1.568201724	1.230448921	1.113943352	1.462397998	0.954242509	0	0.477121255	0.477121255	0	3.129968574	0	2.874953569	3.175693866	3.020916086	4.02054344	2.874953569	0	0	0	0	0	2.178294218	0	0	2.653490783	0	4.831785001
12	09.23.15	low diuron bifenthrin	14.7	9.41	11.46	112.5	648	807	1.431363764	0	0	1.361727836	0.477121255	0.84509804	1.397940009	1.740362689	1.361727836	1.041392685	1.51851394	0	0	0	0	0.698970004	3.762299079	0	3.063629264	3.005690901	3.23959547	3.502723188	2.762974214	0	0	0	0	0	0	0	0	3.23959547	0	3.23959547
13	09.23.15	high diuron bifenthrin	14.6	9.19	9.18	90.3	627	782	1.113943352	0	0	1.230448921	1.041392685	0	1.230448921	1.633468456	0.477121255	1.113943352	1.176091259	0.954242509	0	0.698970004	0	0.477121255	3.406023444	0	3.637901957	3.47657894	2.874953569	3.743684067	3.289570338	0	0	0	0	0	2.178294218	0	0	3.847563528	3.175693866	9.201551612
14	09.23.15	high diuron bifenthrin	14.6	9.28	10.06	98.4	635	791	0	0	0	1.770852012	1.041392685	0	0.698970004	1.86332286	1.785329835	1.113943352	1.86332286	1.431363764	0	1.176091259	0	0.954242509	3.289570338	2.653490783	2.778188332	3.454310174	3.808939864	3.788258555	3.129968574	0	0	0	0	0	3.254826811	0	0	0	0	3.254826811
15	09.23.15	high diuron bifenthrin	14.9	9.17	9.29	92.2	717	887	1.113943352	0	0	1.986771734	1.113943352	0.698970004	1.361727836	2.130333768	0.954242509	0.84509804	1.176091259	0	0	0	0	1.113943352	3.719554865	0	3.537257874	2.874953569	2.178294218	3.666859203	2.778188332	0	0	0	0	0	0	0	0	2.874953569	0	2.874953569
16	09.23.15	high diuron bifenthrin	14.7	9.04	8.2	81.1	753	938	1.278753601	0.477121255	0	1.51851394	0.84509804	0	0.477121255	1.612783857	0	0.954242509	0.954242509	0	0	0	0	0.698970004	2.193985593	0	0	4.212414172	2.669250603	3.696435596	3.696435596	0	0	0	0	0	0	0	0	0	0	0
1	09.30.15	control	16.9	9.16	9.52	97	826	976	0.477121255	0	0	1.612783857	1.361727836	0	1.740362689	2.068185862	0	0.698970004	0.698970004	0	0	0	0.477121255	0	2.509962945	0	2.810321315	3.52993616	0	4.386583438	3.654842849	0	0	0	0	0	4.681813958	0	0	0	2.685606569	7.367420527
2	09.30.15	control	16.4	9.43	10.53	106.7	697	833	0.84509804	0	0	1.397940009	1.176091259	0.698970004	0.698970004	1.672097858	0.477121255	0.84509804	0.954242509	0	0	0.477121255	0	0	2.193985593	0	2.193985593	0	0	4.389873027	4.228650394	0	0	0	0	0	0	0	0	2.193985593	0	2.193985593
3	09.30.15	control	15.9	9.32	9.56	95.9	697	844	1.113943352	0	0	1.51851394	1.278753601	0.477121255	1.278753601	1.851258349	0.477121255	1.278753601	1.322219295	0	0	0	0	0.698970004	3.23959547	0	3.063629264	3.850421379	3.522022409	4.253609914	3.23959547	0	0	0	0	2.938815545	3.575252858	0	0	0	0	6.514068403
4	09.30.15	control	15.8	9.3	10.27	103.1	711	863	0.84509804	0	0	1.462397998	0.954242509	0.477121255	0	1.591064607	0.698970004	0.698970004	0.954242509	0	0	0	0.477121255	0	3.036695572	0	3.395492959	0	0	3.63845613	4.036336228	0	0	0	0	0	0	0	0	0	0	0
5	09.30.15	high diuron	15.7	9.32	8.89	89.7	697	847	0.477121255	0	0	0	0.477121255	0	1.278753601	1.322219295	1.431363764	0.698970004	1.491361694	0.477121255	0	1.361727836	0	0.954242509	3.915819386	0	3.652621882	3.537257874	0	3.606875129	2.178294218	0	0	0	0	2.874953569	2.178294218	0	0	3.175693866	0	8.228941653
6	09.30.15	high diuron	15.6	9.13	8.55	86.4	720	878	1.176091259	0	0	1.397940009	0.477121255	0.84509804	1.322219295	1.72427587	0.954242509	1.041392685	1.278753601	0	0	0	0	0	3.217060206	0	2.477881497	0	0	4.751753017	4.08925319	0	0	0	0	0	3.743684067	0	0	2.477881497	0	6.221565564
7	09.30.15	high diuron	15.9	9.06	8.26	85.4	813	984	1.322219295	0.477121255	0	1.653212514	0	0	1.113943352	1.755874856	0	0.84509804	0.84509804	0	0	0.477121255	0	0	2.79395675	0	0	3.036695572	3.232845063	3.77105542	4.173498602	0	0	0	0	0	4.048569574	0	0	0	0	4.048569574
8	09.30.15	high diuron	15.4	9.24	9.26	94.3	730	894	0.698970004	0.477121255	0	1.041392685	0	1.322219295	1.278753601	1.69019608	1.230448921	1.230448921	1.51851394	0	0	0	0	0	3.814514106	0	3.191477784	0	0	3.9394362	3.513550674	0	0	0	0	0	0	0	0	0	0	0
9	09.30.15	low diuron bifenthrin	15.5	9.18	8.48	85.1	771	942	1.397940009	0	0	1.176091259	0.698970004	0.84509804	1.322219295	1.653212514	0	0.698970004	0.698970004	0	0	0	0.698970004	0.477121255	3.289570338	0	3.020916086	2.95403827	3.175693866	4.200737197	3.838224843	0	0	0	0	0	0	0	0	0	2.178294218	2.178294218
10	09.30.15	low diuron bifenthrin	15.2	9.22	9.53	95.4	712	876	0.698970004	0	0	0.84509804	0	0	2.103803721	2.123851641	0.477121255	0.477121255	0.698970004	0	0	0	0	0.477121255	3.145751342	0	2.193985593	0	0	5.089378261	3.55304764	0	0	0	0	0	0	0	0	0	0	0
11	09.30.15	low diuron bifenthrin	15.2	9.39	9.73	97.1	657	810	1.230448921	0.477121255	0	0.698970004	0	1.176091259	1.322219295	1.591064607	0.954242509	1.176091259	1.361727836	0	0	0	0	0	3.383859397	0	2.986188468	4.070948404	3.321739096	3.438195948	2.986188468	0	0	0	0	0	0	0	0	3.053071206	2.509962945	5.563034151
12	09.30.15	low diuron bifenthrin	15.1	9.66	11.27	112.7	688	849	0.84509804	0	0	1.041392685	1.041392685	0	0.698970004	1.397940009	0	0.698970004	0.698970004	0	0	0	0	0.698970004	3.890224169	0	3.44662607	3.77105542	3.668412697	4.042495974	3.44662607	0	0	0	0	0	2.193985593	0	0	3.589250089	3.036695572	8.819931254
13	09.30.15	high diuron bifenthrin	15	9.4	9.61	95.7	680	841	1.113943352	0	0	1.041392685	0	0.477121255	1.361727836	1.544068044	0.477121255	0.698970004	0.84509804	0	0	0.477121255	0	0	3.77105542	0	3.191477784	3.759475536	2.89072715	3.814514106	3.270612452	0	0	0	0	0	0	0	0	3.305356642	3.305356642	6.610713284
14	09.30.15	high diuron bifenthrin	14.9	9.48	10.91	108.6	676	837	0.477121255	0	0	0.954242509	0	0.477121255	0.954242509	1.278753601	1.278753601	0.84509804	1.397940009	0	0	0.84509804	0	0.477121255	2.810321315	0	2.986188468	3.684799662	3.888885991	4.260690931	3.053071206	0	0	0	0	0	3.24922607	0	0	2.509962945	0	5.759189015
15	09.30.15	high diuron bifenthrin	15.1	9.37	8.95	89.4	771	950	0.477121255	0	0	1.397940009	0	0.698970004	0.477121255	1.491361694	0	0.698970004	0.698970004	0	0	0	0	0	3.622665561	0	4.082685823	3.463010735	2.509962945	3.550133719	2.907096879	0	3.20785785	0	0	0	3.52993616	0	0	2.685606569	0	9.423400579
16	09.30.15	high diuron bifenthrin	14.7	9.27	9.23	92	795	989	0.84509804	0	0	1.544068044	1.176091259	1.041392685	1.397940009	1.919078092	0	0.954242509	0.954242509	0	0	0	0	0.84509804	3.162130259	0	2.907096879	3.897839689	0	4.058884931	3.940032281	0	0	0	0	0	0	0	0	0	2.986188468	2.986188468
1	10.07.15	control	16	9.26	8.84	89.9	844	1015	1.361727836	0.477121255	0	1.770852012	1.431363764	0	1.230448921	2.012837225	0.84509804	1.278753601	1.397940009	0	0	0	0.477121255	1.113943352	3.283969356	0	3.321739096	0	0	3.958401906	4.081235877	0	0	0	0	0	2.845031715	2.720299768	0	0	0	5.565331483
2	10.07.15	control	15.7	9.36	9.12	92.6	701	852	0.698970004	0	0	1.785329835	1.491361694	0.477121255	0.698970004	1.986771734	1.278753601	1.113943352	1.491361694	0	0	0.477121255	0.477121255	0.477121255	3.053071206	0	2.210273092	2.509962945	3.906612514	4.510798112	4.24503986	0	2.210273092	2.210273092	0	0	2.210273092	2.210273092	0	0	0	8.841092368
3	10.07.15	control	15.2	9.18	8.7	86.6	679	835	1.230448921	0	0	1.755874856	1.51851394	0	0.954242509	1.995635195	1.230448921	1.491361694	1.672097858	0.84509804	0	0	0	0.698970004	0	0	2.178294218	0	0	4.628732526	4.067535754	0	0	0	0	0	2.477881497	0	0	0	0	2.477881497
4	10.07.15	control	15.2	9.28	8.68	86.4	721	887	1.041392685	0	0	1.929418926	0.954242509	1.176091259	1.322219295	2.103803721	1.176091259	1.176091259	1.462397998	0.698970004	0	0	0	0	2.827328802	0	3.480038322	3.804473725	2.22720349	4.436825486	3.826746714	0	0	0	0	0	4.249952288	0	0	2.22720349	0	6.477155778
5	10.07.15	high diuron	15	9.12	7.82	77.8	694	857	0.84509804	0	0	1.230448921	0.84509804	0	1.230448921	1.591064607	2.1430148	1.041392685	2.173186268	1.462397998	0	2.460897843	0	0	3.053071206	0	0	0	0	4.517232025	2.810321315	0	0	0	0	0	0	0	0	0	0	0
6	10.07.15	high diuron	14.8	9.04	8.25	83.3	710	882	1.041392685	0	0	1.431363764	1.176091259	0.954242509	0.954242509	1.755874856	1.397940009	1.397940009	1.69019608	1.041392685	0	0	0	0.84509804	2.509962945	0	3.383859397	0	2.210273092	4.448153382	3.963510753	0	0	0	0	0	0	0	0	2.685606569	0	2.685606569
7	10.07.15	high diuron	15.5	8.97	7.5	81.8	844	1030	1.322219295	0	0	1.397940009	0.477121255	0.477121255	1.361727836	1.707570176	0	0.698970004	0.698970004	0	0	0.477121255	0	0	2.509962945	0	0	3.321739096	2.685606569	3.438195948	0	0	0	0	0	0	4.064958552	0	0	0	0	4.064958552
8	10.07.15	high diuron	15.2	9.13	8.42	83.7	758	932	0.698970004	0	0	1.86332286	0	1.041392685	1.361727836	2.021189299	1.278753601	0.84509804	1.397940009	0	0	0	0.477121255	0	3.841119731	0	2.509962945	0	2.907096879	4.16665964	3.870405024	0	0	0	0	0	0	0	0	0	0	0
9	10.07.15	low diuron bifenthrin	15.4	9.06	7.54	76.4	795	974	0.84509804	0	0	1.672097858	1.041392685	2.012837225	0.477121255	2.212187604	0.477121255	1.113943352	1.176091259	0.698970004	0	0	0	0.954242509	3.525781433	0	2.702605456	0	0	4.289102307	3.224880838	0	0	0	0	0	0	0	0	0	0	0
10	10.07.15	low diuron bifenthrin	14.9	9.11	8.42	83.1	716	887	1.278753601	0	0	1.707570176	0.477121255	1.86332286	0.698970004	2.11058971	0.954242509	1.176091259	1.361727836	0	0	0	0	0	2.493624149	0	2.89072715	3.589250089	2.969815295	4.51549395	3.55304764	0	0	0	0	0	2.493624149	0	0	2.493624149	0	4.987248298
11	10.07.15	low diuron bifenthrin	14.8	9.23	8.18	81.2	664	825	1.113943352	0.477121255	0	1.431363764	0	0.84509804	0	1.591064607	1.397940009	1.041392685	1.544068044	0.698970004	0	0	0	0.698970004	4.207615585	0	3.286994242	2.210273092	2.907096879	3.931915331	3.963510753	0	0	0	0	0	2.210273092	0	0	2.509962945	0	4.720236037
12	10.07.15	low diuron bifenthrin	14.8	9.48	10.18	100.5	698	867	0.698970004	0	0	1.462397998	0	1.230448921	0.477121255	1.672097858	0.84509804	1.278753601	1.397940009	0	0	0	0	0	2.810321315	0	3.053071206	0	2.907096879	0	4.207615585	0	0	0	0	0	2.509962945	0	0	2.810321315	0	5.32028426
13	10.07.15	high diuron bifenthrin	14.8	9.27	9	88.5	685	851	0.954242509	0	0	1.397940009	0	0.477121255	1.230448921	1.672097858	0.84509804	1.113943352	1.278753601	0.477121255	0	1.176091259	0	0	3.55304764	0	2.79395675	0	0	4.072048626	2.89072715	0	0	0	0	0	0	0	0	0	0	0
14	10.07.15	high diuron bifenthrin	14.7	9.3	9.36	92.2	681	848	0.698970004	0	0	1.799340549	1.041392685	0.698970004	0	1.886490725	1.591064607	1.278753601	1.755874856	1.176091259	0	1.176091259	0.698970004	0.477121255	2.493624149	0	2.193985593	0	3.367475882	3.696435596	3.305356642	0	0	0	0	0	0	0	0	0	0	0
15	10.07.15	high diuron bifenthrin	14.7	9.18	8.36	82.5	786	978	0.84509804	0	0	0.954242509	0.84509804	1.041392685	0	1.397940009	1.113943352	1.176091259	1.431363764	0	0	0	0	0.954242509	3.77105542	0	3.983635031	4.392612953	2.79395675	3.395492959	3.232845063	0	2.89072715	0	0	0	0	0	0	2.79395675	0	5.6846839
16	10.07.15	high diuron bifenthrin	14.5	9.13	7.9	76.8	819	1024	0.477121255	0	0	1.591064607	0	0.477121255	1.278753601	1.770852012	0.698970004	0.954242509	1.113943352	0	0	0	0	0.954242509	3.087803747	0	0	0	0	3.356485276	4.074896229	0	0	0	0	0	0	0	0	0	0	0
1	10.14.15	control	17.3	8.7	10.8	112.3	795	926	1.176091259	0.698970004	0	1.919078092	1.322219295	0	1.113943352	2.06069784	0.84509804	1.041392685	1.230448921	0	0	0	0	1.113943352	3.424357849	0	3.349754879	0	0	4.279002505	4.132244516	0	0	0	0	0	0	0	0	3.424357849	2.623596445	6.047954294
2	10.14.15	control	16.8	9	9.83	101.4	712	842	1.176091259	0	0	1.397940009	1.113943352	0	0	1.568201724	1.361727836	1.230448921	1.591064607	0	0	0.477121255	0	0.698970004	2.874953569	0	2.874953569	0	3.652621882	4.286016164	3.454310174	0	0	0	0	0	0	0	0	2.477881497	0	2.477881497
3	10.14.15	control	16.7	9.11	10.04	103.4	832	833	1.230448921	0.698970004	0	1.653212514	0.84509804	0	0.698970004	1.740362689	1.113943352	1.491361694	1.633468456	0.84509804	0	0	0	1.113943352	3.308381604	0	3.145751342	0	3.76688019	4.297194573	4.012575277	0	0	0	0	0	2.107452407	0	0	2.406783568	2.107452407	6.621688382
4	10.14.15	control	16.6	9.22	9.3	95.5	732	872	0.698970004	0.698970004	0	1.397940009	0.698970004	0.477121255	0.477121255	1.51851394	0.954242509	1.113943352	1.322219295	0.477121255	0	0	0.477121255	0	3.020916086	0	2.874953569	0	2.874953569	4.124826563	4.258213311	0	0	0	0	0	0	0	0	0	0	0
5	10.14.15	high diuron	16.6	9.13	8.73	89.5	711	848	1.113943352	0	0	1.176091259	0.477121255	0	1.041392685	1.462397998	1.612783857	0	1.612783857	1.322219295	0	2.247973266	0	0	3.673806579	0	3.196869365	0	2.720299768	3.865659232	4.17434595	0	0	0	0	0	0	0	0	0	0	0
6	10.14.15	high diuron	16.4	9.02	9.33	95.5	704	842	1.462397998	0	0	1.113943352	1.041392685	0	0	1.361727836	1.612783857	1.397940009	1.812913357	0	0	0.477121255	0	1.113943352	3.070089763	0	3.546964569	0	2.827328802	4.591989031	3.877892045	0	0	0	0	0	2.22720349	0	0	0	2.22720349	4.45440698
7	10.14.15	high diuron	17.5	8.99	8.73	91.3	833	971	1.278753601	0	0	1.740362689	0	0	1.278753601	1.875061263	0	0.84509804	0.84509804	0	0	1.041392685	0	0	2.638285261	0	0	0	0	5.003401096	3.502723188	0	0	0	0	0	4.324537435	0	0	2.16315712	0	6.487694555
8	10.14.15	high diuron	17.1	9.1	9.83	101.8	739	870	0.477121255	0	0	1.707570176	0	0	0.954242509	1.770852012	1.544068044	0.698970004	1.591064607	0.477121255	0	0	0	0.698970004	4.118005144	0	3.529268725	0	0	4.295575158	3.386651147	0	0	0	0	0	0	0	0	0	2.134399087	2.134399087
9	10.14.15	low diuron bifenthrin	17.3	9.1	9.16	95.5	790	925	1.278753601	0	0	1.812913357	1.176091259	0.477121255	0.954242509	1.949390007	0	1.278753601	1.278753601	0.954242509	0	0	0.477121255	1.113943352	3.114740106	0	2.16315712	0	3.439075657	3.439075657	3.908405665	0	0	0	0	0	0	0	0	0	0	0
10	10.14.15	low diuron bifenthrin	16.3	9.07	9.33	95	722	864	1.113943352	0.477121255	0	1.230448921	0.477121255	0.477121255	0.477121255	1.361727836	1.361727836	1.230448921	1.591064607	0.84509804	0	0	0	1.230448921	2.845031715	0	2.148536707	0	2.92410953	2.748276803	4.469737932	0	0	0	0	0	0	0	0	0	0	0
11	10.14.15	low diuron bifenthrin	16.5	9.12	9.03	92.6	667	796	1.230448921	0.477121255	0	1.041392685	0.698970004	0.477121255	0.477121255	1.278753601	1.397940009	0.954242509	1.51851394	0	0	0.477121255	0	1.113943352	3.424357849	0	2.148536707	0	0	3.3760724	4.194686515	0	0	0	0	0	2.148536707	0	0	2.92410953	0	5.072646237
12	10.14.15	low diuron bifenthrin	16.3	9.36	11.02	112.3	674	809	1.176091259	0.477121255	0	1.72427587	1.230448921	0.477121255	0.477121255	1.875061263	1.041392685	0.954242509	1.278753601	0	0	0	0.477121255	0.84509804	2.609390445	0	0	0	2.609390445	3.245390563	4.085478494	0	0	0	0	0	0	0	0	0	0	0
13	10.14.15	high diuron bifenthrin	16	9.27	10.22	103.8	683	826	1.113943352	0.477121255	0	1.113943352	0	0.954242509	1.176091259	1.568201724	1.612783857	1.278753601	1.770852012	0	0	1.397940009	0.477121255	0.698970004	3.650687813	0	2.148536707	2.623596445	0	4.30382482	3.467807974	0	0	0	0	0	0	0	0	0	0	0
14	10.14.15	high diuron bifenthrin	16	9.26	9.99	101.2	686	829	0.84509804	0.698970004	0	1.278753601	0	0.477121255	0.477121255	1.431363764	1.612783857	0.954242509	1.69019608	0.698970004	0	1.278753601	0	0.698970004	2.462693138	0	0	2.16315712	3.336455451	4.494631664	3.80368494	0	0	0	0	0	0	0	0	2.16315712	0	2.16315712
15	10.14.15	high diuron bifenthrin	16.3	9.12	8.68	88.7	784	940	1.113943352	0	0	2.004321374	1.397940009	0	0.477121255	2.103803721	1.278753601	1.51851394	1.707570176	0	0	0	0	1.278753601	3.931066923	0	3.336455451	0	2.462693138	3.575252858	4.364302762	0	0	0	0	0	0	0	0	3.841467813	0	3.841467813
16	10.14.15	high diuron bifenthrin	16	9.09	9.49	96.2	798	963	0.698970004	0.477121255	0	1.462397998	0.698970004	0	0	1.51851394	0	1.041392685	1.041392685	0.698970004	0	0	0	1.113943352	3.773021114	0	2.859734288	0	0	3.439075657	3.306506523	0	0	0	0	0	0	0	0	0	0	0
1	10.21.15	control	14.3	9.07	11.06	107.4	755	950	1.397940009	0	0	1.755874856	1.176091259	0	1.361727836	1.968482949	0.477121255	0.954242509	1.041392685	0	0	0	0.477121255	0.954242509	3.573459963	0	3.666859203	2.178294218	2.653490783	4.224647889	3.555736028	0	0	0	0	0	0	0	0	0	0	0
2	10.21.15	control	13.7	9.25	10.44	100.2	678	865	0.477121255	0.698970004	0	1.707570176	1.041392685	0	0	1.785329835	1.322219295	0.84509804	1.431363764	0	0	0.84509804	0	0	3.47657894	2.178294218	3.020916086	0	3.915819386	4.415969889	4.282636599	0	0	0	0	0	0	0	0	0	0	0
3	10.21.15	control	13.7	9.22	10.95	105.6	664	846	0.698970004	0	0	1.612783857	0.954242509	0	0.698970004	1.740362689	0.954242509	1.176091259	1.361727836	0	0	0	0	0.477121255	3.511545308	0	2.43383264	0	3.71106839	4.905722674	4.03433043	0	0	0	0	0	0	0	0	0	0	0
4	10.21.15	control	13.4	9.31	9.84	94.5	701	901	1.176091259	0.477121255	0	1.72427587	1.041392685	0.954242509	0.477121255	1.86332286	0.84509804	0.84509804	1.113943352	0.477121255	0	0	1.041392685	0	3.454310174	0	2.95403827	0	2.477881497	4.895568802	3.874431973	0	0	0	0	0	2.778188332	0	0	2.477881497	0	5.256069829
5	10.21.15	high diuron	13.4	9.15	8.98	87.8	648	833	0.954242509	0	0	1.361727836	0	0	0.477121255	1.431363764	1.397940009	0	1.397940009	1.322219295	0	2.396199347	0	0.477121255	4.191226204	0	3.722759396	0	2.669250603	3.094637628	3.305356642	0	0	0	0	0	0	0	0	2.193985593	0	2.193985593
6	10.21.15	high diuron	13.2	9.12	10.75	103	658	849	1.278753601	0	0	1.230448921	0.698970004	0	0.477121255	1.361727836	1.431363764	1.322219295	1.672097858	0.477121255	0	0.477121255	0	0.477121255	3.321739096	0	0	0	3.224880838	5.026258432	4.154071383	0	0	0	0	0	0	0	0	3.525781433	0	3.525781433
7	10.21.15	high diuron	13.7	9.12	9.89	95.8	766	978	1.278753601	0	0	1.707570176	0	0	0.477121255	1.72427587	0.954242509	0.954242509	1.230448921	0.84509804	0	0.477121255	0.477121255	0.698970004	3.005690901	0	2.462693138	0	2.762974214	5.217832742	4.142466526	0	0	0	0	0	3.952604138	0	0	2.16315712	0	6.115761258
8	10.21.15	high diuron	13.6	9.27	11.15	107.7	690	882	0.84509804	0.477121255	0	1.041392685	0.84509804	0	0.477121255	1.278753601	1.491361694	0	1.491361694	0	0	0	0	0.84509804	4.129678704	0	2.653490783	2.874953569	0	3.652621882	3.379705162	0	0	0	0	0	0	0	0	0	0	0
9	10.21.15	low diuron bifenthrin	13.8	9.19	9.51	92.3	751	955	0.954242509	0.698970004	0	1.397940009	0.84509804	0.954242509	0.954242509	1.672097858	0	0.84509804	0.84509804	0.698970004	0	0	0	1.278753601	3.892613384	0	3.114740106	2.16315712	3.637385367	3.336455451	3.979753448	0	0	0	0	0	0	0	0	0	0	0
10	10.21.15	low diuron bifenthrin	13.2	9.16	10.37	99	681	878	0.954242509	0	0	1.041392685	0.698970004	0	0.477121255	1.230448921	1.361727836	1.361727836	1.653212514	0.954242509	0	0.477121255	0	0.954242509	3.172884771	0	3.277557615	2.134399087	3.649811532	4.403059088	3.562682971	0	0	0	0	0	0	0	0	0	2.43383264	2.43383264
11	10.21.15	low diuron bifenthrin	13.3	9.25	10.3	98.7	637	820	0.954242509	0.698970004	0	1.113943352	0.698970004	0	1.041392685	1.431363764	1.230448921	0.84509804	1.361727836	1.041392685	0	0	0.477121255	0	3.454310174	0	2.178294218	0	3.555736028	3.351688516	4.119919599	0	0	0	0	0	3.537257874	0	0	0	0	3.537257874
12	10.21.15	low diuron bifenthrin	13.1	9.44	11.85	112.8	625	811	1.591064607	0.698970004	0	1.755874856	0.477121255	0.477121255	0	1.785329835	1.591064607	1.113943352	1.707570176	0	0	0	1.041392685	1.113943352	3.992717087	0	2.462693138	0	3.773021114	4.601083972	3.900581303	0	0	0	0	0	0	0	0	0	0	0
13	10.21.15	high diuron bifenthrin	13	9.33	11.08	105.4	645	837	0	0	0	0.954242509	0.698970004	0.698970004	0.477121255	1.278753601	1.51851394	1.176091259	1.672097858	0	0	1.176091259	0	0.698970004	3.517958449	0	2.178294218	0	3.379705162	4.877840265	4.056255722	0	0	0	0	0	0	0	0	0	0	0
14	10.21.15	high diuron bifenthrin	13	9.31	10.82	102.9	652	846	0.477121255	0	0	1.612783857	0.477121255	0.477121255	1.113943352	1.755874856	1.633468456	0.84509804	1.69019608	0.954242509	0	1.041392685	0.477121255	0.477121255	2.16315712	0	0	0	2.462693138	3.502723188	3.704317857	0	0	0	0	0	2.762974214	0	0	0	0	2.762974214
15	10.21.15	high diuron bifenthrin	13	9.13	8.88	84.4	756	980	1.113943352	0	0	1.176091259	0.477121255	0.477121255	0	1.278753601	1.113943352	0.84509804	1.278753601	0	0	0	0	0.698970004	3.175693866	0	0	0	0	0	3.430837555	0	0	0	0	0	4.038766558	0	0	0	0	4.038766558
16	10.21.15	high diuron bifenthrin	13.1	9.17	10.09	96.5	757	979	0.698970004	0.477121255	0	1.544068044	0	0.698970004	0	1.591064607	0.477121255	0	0.477121255	1.041392685	0	0	0	1.361727836	3.916091553	0	2.762974214	0	2.462693138	3.691731253	3.916091553	0	0	0	0	0	0	0	0	0	0	0
1	10.28.15	control	14.3	9.07	10.58	103.1	773	973	1.462397998	0	0	1.51851394	1.176091259	0	1.230448921	1.826074803	0.84509804	0	0.84509804	0.698970004	0	0	0.477121255	0.954242509	3.351688516	0	2.874953569	0	2.778188332	3.694005781	4.162205604	0	0	0	0	0	2.477881497	0	0	0	0	2.477881497
2	10.28.15	control	13.8	9.2	10.74	103.3	706	899	1.322219295	0	0	1.397940009	0.954242509	0.477121255	0.698970004	1.591064607	1.278753601	1.113943352	1.491361694	0.477121255	0	1.041392685	0.477121255	1.041392685	3.411876905	0	2.509962945	0	3.841119731	4.099717782	4.515097961	0	0	0	0	0	2.210273092	0	0	0	0	2.210273092
3	10.28.15	control	13.7	9.21	11.19	106.6	648	823	1.361727836	0.477121255	0	0.84509804	0.477121255	0.477121255	0.954242509	1.278753601	0.84509804	1.041392685	1.230448921	0	0	0.954242509	0	0.954242509	2.830811959	0	3.277557615	0	3.838833437	5.030477548	4.381638351	0	0	0	0	0	0	0	0	0	3.94416306	3.94416306
4	10.28.15	control	13.7	9.27	9.82	94.5	730	931	0.698970004	0.84509804	0	1.633468456	0.954242509	0.698970004	0.698970004	1.770852012	1.322219295	0.477121255	1.361727836	0.698970004	0	0	0.84509804	0.477121255	3.406023444	0	2.95403827	0	3.078856296	5.130131984	3.974790552	0	0	0	0	0	3.078856296	0	0	0	2.874953569	5.953809865
5	10.28.15	high diuron	13.6	9.14	9.12	88.2	705	901	0	0	0	0.477121255	0	0	0	0.477121255	2.149219113	0.477121255	2.155336037	0.84509804	0	2.674861141	0	0	4.246548457	0	3.575252858	0	2.938815545	4.160194042	3.979753448	0	0	0	0	0	2.938815545	0	0	0	0	2.938815545
6	10.28.15	high diuron	13.5	9.1	1074	103.3	683	875	1.397940009	0	0	1.176091259	0.477121255	0	0.698970004	1.322219295	1.591064607	1.278753601	1.755874856	0.477121255	0	0	0	1.041392685	2.748276803	0	2.748276803	0	3.349754879	4.132244516	4.300798516	0	0	0	0	0	3.048918942	0	0	0	0	3.048918942
7	10.28.15	high diuron	13.8	9.11	9.6	92.8	816	1039	1.612783857	0.477121255	0	1.672097858	0	0	0.698970004	1.707570176	0.698970004	0.954242509	1.113943352	0.698970004	0	0.477121255	0	1.041392685	2.874953569	0	2.778188332	0	3.020916086	4.810894434	3.891463082	0	0	0	0	0	3.020916086	0	0	0	0	3.020916086
8	10.28.15	high diuron	13.9	9.27	10.78	104.6	723	918	1.431363764	0.477121255	0	1.113943352	0	0.84509804	1.041392685	1.491361694	1.544068044	0.477121255	1.568201724	0	0	0	0	1.041392685	4.026703165	0	0	0	3.321739096	3.818922553	4.196620891	0	0	0	0	0	0	0	0	0	0	0
9	10.28.15	low diuron bifenthrin	13.9	9.17	8.84	86	786	997	1.491361694	0	0	1.278753601	1.041392685	1.113943352	1.568201724	1.886490725	0	0.84509804	0.84509804	0.477121255	0	0	0.477121255	1.230448921	3.020916086	0	0	0	2.178294218	2.477881497	3.289570338	0	0	0	0	0	0	0	0	0	0	0
10	10.28.15	low diuron bifenthrin	13.5	9.13	10.71	102.7	704	902	0.84509804	0	0	1.230448921	0	0	1.322219295	1.568201724	1.397940009	1.322219295	1.653212514	0.954242509	0	0	0	1.113943352	3.351688516	0	2.178294218	0	2.95403827	4.405869954	3.988361943	0	0	0	0	0	0	0	0	0	0	0
11	10.28.15	low diuron bifenthrin	13.5	9.25	10.61	102	656	840	1.322219295	0	0	0.954242509	1.041392685	0.698970004	0.84509804	1.462397998	1.591064607	0.84509804	1.653212514	0	0	0.84509804	0	0.954242509	3.463010735	0	0	0	3.20785785	3.712822777	3.787443111	0	0	0	0	0	3.162130259	0	0	0	0	3.162130259
12	10.28.15	low diuron bifenthrin	13.3	9.44	11.98	114.5	653	841	1.278753601	0	0	1.397940009	0.477121255	0	0	1.431363764	1.361727836	1.278753601	1.612783857	0	0	0	0.84509804	0.698970004	3.783484804	0	4.029436313	0	3.201829649	4.029436313	3.336455451	0	0	0	0	0	2.16315712	0	0	0	0	2.16315712
13	10.28.15	high diuron bifenthrin	13.3	9.37	11.42	109.2	663	853	1.113943352	0.477121255	0	0.698970004	0	0	0	0.698970004	1.361727836	0.954242509	1.491361694	0.477121255	0	1.51851394	0.477121255	1.230448921	3.575252858	0	0	0	3.005690901	4.510425435	4.099717782	0	0	0	0	0	0	0	0	0	0	0
14	10.28.15	high diuron bifenthrin	13.4	9.3	11.12	105.6	682	878	1.230448921	0	0	1.851258349	1.041392685	0	1.322219295	2.004321374	1.431363764	0.698970004	1.491361694	0.698970004	0	1.51851394	1.041392685	0.84509804	2.669250603	0	0	0	2.969815295	3.947122153	3.270612452	0	0	0	0	0	2.193985593	0	0	0	0	2.193985593
15	10.28.15	high diuron bifenthrin	13.4	9.05	8.75	84.6	785	1008	1.230448921	0.477121255	0	1.278753601	0	0	0.698970004	1.361727836	1.176091259	0.84509804	1.322219295	0	0	0	0	1.361727836	3.497761337	0	2.95403827	0	2.178294218	2.178294218	4.050503902	0	0	0	0	0	4.951383163	0	0	0	0	4.951383163
16	10.28.15	high diuron bifenthrin	13.5	9.13	9.85	94.8	793	1017	1.041392685	0.477121255	0	1.113943352	1.041392685	0	1.041392685	1.51851394	0	0.84509804	0.84509804	0.477121255	0	0	0	1.230448921	2.874953569	0	0	0	2.178294218	3.020916086	4.001522057	0	0	0	0	0	0	0	0	0	0	0

From macqueen1 at llnl.gov  Wed Sep 21 17:26:11 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 21 Sep 2016 15:26:11 +0000
Subject: [R] if/else help
Message-ID: <D407F18D.186A8A%macqueen1@llnl.gov>

Hopefully this is not a homework question.

The other responses are fine, but I would suggest the simplest way to do
exactly what you ask is


if (!exists('r4')) r4 <- data.frame(a=0, b=0, c=0, d='x')


The exists() function requires a character string for its first argument,
i.e., the name of the object, not the object itself (check the help page
for exists).

Using "get" to get it doesn't make sense if it already exists.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/20/16, 12:31 PM, "R-help on behalf of Crombie, Burnette N"
<r-help-bounces at r-project.org on behalf of bcrombie at utk.edu> wrote:

>If a data.frame (r4) does not exist in my R environment, I would like to
>create it before I move on to the next step in my script. How do I make
>that happen?  Here is what I want to do from a code perspective:
>
>if (exists(r4))
>{
>is.data.frame(get(r4))
>}
>else
>{
>a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
>}
>
>Thanks for your help,
>B
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Wed Sep 21 17:34:35 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 21 Sep 2016 16:34:35 +0100
Subject: [R] FW: Why removing the (Intercept) from lm is done by adding -1?
In-Reply-To: <CAM_vjunM82FtTnVgv5uK-88VYDntztA4rPZuw-pYi2tdU5=jiw@mail.gmail.com>
References: <c1a7527d35c7ada5f98cd2e3d9e2983a@kapsi.fi>
	<CAM_vjunM82FtTnVgv5uK-88VYDntztA4rPZuw-pYi2tdU5=jiw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE67756B@GBTEDVPEXCMB04.corp.lgc-group.com>

> Subject: Re: [R] Why removing the (Intercept) from lm is done by adding -1?
> 
> And in R, - means omit, as in
> mydataframe[, -1]
> right?

Not really, no. 
In the specific interpretation of an R model formula, '-' means 'remove the _term_ following '-'  ...'.  As below:
> This is all in the help for formula, where it says "The - operator removes the
> specified terms".

Almost everywhere else, '-'  it means negate as a unary operator and subtract as a binary operator. 
In '[', '-' still means negate, not remove. It's just that '[' uses negative _numbers_ as a special case to denote omission. As a recent post noted, [-"601",] does not work.

> > Adding (or setting the (Intercept) term) zero seems more logical than
> > subtracting one, but why is there the method of subtracting one? Why
> > does subtracting one mean that the (Intercept) term disappears?
See above; '-' _in a formula_ means 'remove the following term'

Following that consistently, if there's a weirdness there, it's that ~0+x works to omit the intercept, not that ~x-1 does. 

But that arises from a slightly different, but still fairly reasonable, perspective on describing the model.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From dwinsemius at comcast.net  Wed Sep 21 18:06:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Sep 2016 09:06:41 -0700
Subject: [R] if/else help
In-Reply-To: <D407F18D.186A8A%macqueen1@llnl.gov>
References: <D407F18D.186A8A%macqueen1@llnl.gov>
Message-ID: <128514D9-BCBD-4F6B-A2E6-DFA1413E0D3A@comcast.net>


> On Sep 21, 2016, at 8:26 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> Hopefully this is not a homework question.
> 
> The other responses are fine, but I would suggest the simplest way to do
> exactly what you ask is
> 
> 
> if (!exists('r4')) r4 <- data.frame(a=0, b=0, c=0, d='x')
> 
> 
> The exists() function requires a character string for its first argument,
> i.e., the name of the object, not the object itself (check the help page
> for exists).

Since the implicit goal is to determine whether a data.frame by that name is in the search path one could add the requirement that the 'list'-mode be added as a requirement in the search:

 if ( !exists('r4', mode='list') ){ r4 <- data.frame(a=0, b=0, c=0, d='x')}

That would avoid a 'false'-detection (or at least an unintended detection) for a function by that name if one `exist`-ed. It would also mask any `r4` that might have been a matrix or other atomic vector outside the local evaluation frame.

-- 
David.


> 
> Using "get" to get it doesn't make sense if it already exists.
> 
> -Don
> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 9/20/16, 12:31 PM, "R-help on behalf of Crombie, Burnette N"
> <r-help-bounces at r-project.org on behalf of bcrombie at utk.edu> wrote:
> 
>> If a data.frame (r4) does not exist in my R environment, I would like to
>> create it before I move on to the next step in my script. How do I make
>> that happen?  Here is what I want to do from a code perspective:
>> 
>> if (exists(r4))
>> {
>> is.data.frame(get(r4))
>> }
>> else
>> {
>> a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
>> }
>> 
>> Thanks for your help,
>> B
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Wed Sep 21 18:07:01 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 21 Sep 2016 09:07:01 -0700
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <CAGxFJbRyyH4NmpHGdv6Ngesb2hBmKhTmbdwGBC=ihS9qPTxnwQ@mail.gmail.com>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
	<CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
	<20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
	<CAGxFJbRyyH4NmpHGdv6Ngesb2hBmKhTmbdwGBC=ihS9qPTxnwQ@mail.gmail.com>
Message-ID: <CAF8bMcb53kDOSMu5K7ZK7o4e3QVAF+p9OjOD7CMRjiMYxrrkNw@mail.gmail.com>

The OP cannot be entirely blamed for thinking that x[,-"ColName"]
would omit x's "ColName" from the result.  Base R and many packages
have commonly used functions that do context-sensitive (aka 'nonstandard')
evaluation.

E.g. subset() evaluates each argument in a different way:
  > subset(data.frame(ColA=1:3,ColB=-(11:13)), -ColB>11, -ColA)
    ColB
  2  -12
  3  -13



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Sep 21, 2016 at 7:45 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> No, Rui, your example misses the point. Your initial sentence hits it.
>
> The OP needs to carefully read
> ?"["
> and/or spend some time with a suitable R tutorial to learn proper
> syntax for subscripting. Asking foolish questions in lieu of doing her
> homework seems wrongheaded to me. Others may disagree, of course.
>
> Cheers,
> Bert
>
>
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Sep 21, 2016 at 1:26 AM,  <ruipbarradas at sapo.pt> wrote:
> > Hello,
> >
> > The error message means exactly what it says. The operator '-' is
> > unary and cannot be followed by a non-numeric atomic object (a vector).
> > Try for instance
> >
> > x <- list(a=1:10, b=rnorm(5))
> > -x
> >
> > Rui Barradas
> >
> >
> > Citando Pauline La?lle <pauline.laille at gmail.com>:
> >
> >> Works like a charm, thanks! Still don't know what that error message
> >> means though. Any idea?
> >>
> >>   2016-09-20 20:13 GMT+02:00 <ruipbarradas at sapo.pt>:
> >>> Sorry, I've made a stupid mistake.
> >>> It's obviously the other way around.
> >>>
> >>> ix <- which(rownames(data) %in% c("601", "604"))
> >>> clean <- data[-ix, ]
> >>>
> >>> Rui Barradas
> >>>
> >>> Citando ruipbarradas at sapo.pt:
> >>>> Hello,
> >>>>
> >>>> Try something like the following.
> >>>>
> >>>> ix <- which(c("601", "604") %in% rownames(data))
> >>>> clean <- data[-ix, ]
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> Citando Pauline La?lle <pauline.laille at gmail.com>:
> >>>>
> >>>>> Dear all,
> >>>>>
> >>>>> I built a dataframe with read.csv2(). Initially, row names are
> integers
> >>>>> (order of answers to a survey). They are listed in the csv's first
> column.
> >>>>> The import works well and my dataframe looks like I wanted it to
> look.
> >>>>>
> >>>>> Row names go as follows :
> >>>>> [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"
> "88"  "89"
> >>>>> "91"  "93"  "105" "110" "111" "117" "119" "120"
> >>>>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169"
> "177"
> >>>>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
> >>>>> etc.
> >>>>>
> >>>>> I would like to drop rows "601" & "604" to clean the dataframe.
> >>>>>
> >>>>> While data["601",] shows me the first row i'd like to drop,
> data[-"601",]
> >>>>> returns the following :
> >>>>> Error in -"601" : invalid argument to unary operator
> >>>>>
> >>>>> idem with data[c("601","604"),] and data[-c("601","604"),]
> >>>>>
> >>>>> It is the first time that I run into this specific error. After
> reading a
> >>>>> bit about it I still don't understand what it means and how to fix
> it.
> >>>>>
> >>>>> Thanks for reading!
> >>>>> Best,
> >>>>> Pauline.
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Sep 21 21:18:15 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 21 Sep 2016 21:18:15 +0200
Subject: [R] Problem Mixstock in R
In-Reply-To: <DB5PR04MB206943D53AACC21A4152F0EEAEF40@DB5PR04MB2069.eurprd04.prod.outlook.com>
References: <DB5PR04MB206943D53AACC21A4152F0EEAEF40@DB5PR04MB2069.eurprd04.prod.outlook.com>
Message-ID: <521cd70c-58bc-6751-9d43-ad0b27ec6e1b@yahoo.fr>

Le 19/09/2016 ? 10:53, FIORAVANTI TATIANA a ?crit :
> Dear members of the R-project
>
> I am doing a mixed stock analysis with the Mixstock Package in R, at the end of the analysis I would summarize all my results (mean, standard deviation, median, percentile, etc...) using the mysum(x, name=NULL) function, but I don't understand which is the correct manner to set up it, what "x" and "name"are? ..Can you help me? Thank you very much,
>
> Tatiana
>
Dear Tatiana,

First: I don't find the Mixstock package in CRAN. You should indicate 
how to install it.
Second: I don't find anywhere a function mysum(). Is it part of the 
Mixstock package?
Third: Send a reproducible exemple to show what you tried to use the 
function.

Finaly you should read the posting guide in this list to have more 
chance to have answers.

Sincerely,

Marc


From NordlDJ at dshs.wa.gov  Wed Sep 21 22:33:05 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 21 Sep 2016 20:33:05 +0000
Subject: [R] Problem Mixstock in R
In-Reply-To: <521cd70c-58bc-6751-9d43-ad0b27ec6e1b@yahoo.fr>
References: <DB5PR04MB206943D53AACC21A4152F0EEAEF40@DB5PR04MB2069.eurprd04.prod.outlook.com>
	<521cd70c-58bc-6751-9d43-ad0b27ec6e1b@yahoo.fr>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766309B0818@WAXMXOLYMB025.WAX.wa.lcl>

Googling "mixstock CRAN" I found the following:

Package 'mixstock' was removed from the CRAN repository.
Formerly available versions can be obtained from the archive.
Archived on 2014-08-30 as long-term memory-access errors were not corrected.


You might want to contact the maintainer of the package directly with your questions.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Girondot via R-help
> Sent: Wednesday, September 21, 2016 12:18 PM
> To: r-help at r-project.org; t.fioravanti at pm.univpm.it
> Subject: Re: [R] Problem Mixstock in R
> 
> Le 19/09/2016 ? 10:53, FIORAVANTI TATIANA a ?crit :
> > Dear members of the R-project
> >
> > I am doing a mixed stock analysis with the Mixstock Package in R, at
> > the end of the analysis I would summarize all my results (mean,
> > standard deviation, median, percentile, etc...) using the mysum(x,
> > name=NULL) function, but I don't understand which is the correct
> > manner to set up it, what "x" and "name"are? ..Can you help me? Thank
> > you very much,
> >
> > Tatiana
> >
> Dear Tatiana,
> 
> First: I don't find the Mixstock package in CRAN. You should indicate how to
> install it.
> Second: I don't find anywhere a function mysum(). Is it part of the Mixstock
> package?
> Third: Send a reproducible exemple to show what you tried to use the
> function.
> 
> Finaly you should read the posting guide in this list to have more chance to
> have answers.
> 
> Sincerely,
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reichmanj at sbcglobal.net  Thu Sep 22 04:20:35 2016
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Wed, 21 Sep 2016 21:20:35 -0500
Subject: [R] Establishing dates in Time Series Data
Message-ID: <000001d21477$e805e590$b811b0b0$@sbcglobal.net>

R-Help Forum

 

I'm working with a time series data set whose times periods are days of the
year.  While it's pretty straight forward of how, for example, to start my
series on (say) January 2015,but  how do I write the code such that my time
series starts on (say) the 3rd of Jan 2015?

 

> Mytsdata <-  ts(variable, frequency=12, start=c(2015,1))  

 

Jeff


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Sep 22 05:31:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Sep 2016 20:31:12 -0700
Subject: [R] Establishing dates in Time Series Data
In-Reply-To: <000001d21477$e805e590$b811b0b0$@sbcglobal.net>
References: <000001d21477$e805e590$b811b0b0$@sbcglobal.net>
Message-ID: <8B4BEFB2-C770-4528-82EF-D1D1788C2CBF@comcast.net>


> On Sep 21, 2016, at 7:20 PM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
> R-Help Forum
> 
> 
> 
> I'm working with a time series data set whose times periods are days of the
> year.  While it's pretty straight forward of how, for example, to start my
> series on (say) January 2015,but  how do I write the code such that my time
> series starts on (say) the 3rd of Jan 2015?
> 
> 
> 
>> Mytsdata <-  ts(variable, frequency=12, start=c(2015,1))  
> 

Wouldn't this require a frequency that matched the number of days in a year?

-- 
David
> 
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From simon.wood at bath.edu  Thu Sep 22 15:25:48 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 22 Sep 2016 14:25:48 +0100
Subject: [R] mgcv: bam(),
 error in models with random intercepts and random slopes
In-Reply-To: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>
References: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>
Message-ID: <890463f0-aafe-e420-550c-52f0fdec44ea@bath.edu>

Hi Fotis,

Thanks for the report, and sending me the data and code (off list). The 
problem is triggered by 'ctrial' being a (one column) matrix. An 
immediate fix is

data_a$ctrial <- as.numeric(data_a$ctrial)

- mgcv 1.8-16 will catch the problem automatically internally.

best,
Simon

On 20/09/16 17:22, Fotis Fotiadis wrote:
> Hi all
>
> I am using the bam function of the mgcv package to model behavioral data of
> a learning experiment. To model individual variation in learning rate, I am
> testing models with (a) by-participant random intercepts of trial, (b)
> by-participant random slopes and random intercepts of trial, and (c)
> by-participant random smooth terms.
>
> While all (a) and (c) models converge, I am getting an error for every
> possible variation of a model with random intercepts and random slopes. For
> example:
>
> m1.rs<-bam(acc~ 1 + igc + s(ctrial) + s(sbj, bs="re") + s(ctrial, sbj,
> bs="re") , data=data_a, family=binomial)
> Error in G$smooth[[i]]$first.para:G$smooth[[i]]$last.para :
>    argument of length 0
>
> Any idea on what that error might be?
>
> Thank you in advance for your time.
> Fotis
>
> P.S.: R version: 3.3.1, mgcv version: 1.8.15
>


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From bcrombie at utk.edu  Wed Sep 21 16:59:56 2016
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Wed, 21 Sep 2016 14:59:56 +0000
Subject: [R] if/else help
In-Reply-To: <CAF8bMcYf327S_DZCXJ5KsrvnXNxqxR_FLKJKOb9ynep5L_SkHw@mail.gmail.com>
References: <MWHPR02MB226990C1CD7AB2854F7A1858D5F70@MWHPR02MB2269.namprd02.prod.outlook.com>
	<CAF8bMcYf327S_DZCXJ5KsrvnXNxqxR_FLKJKOb9ynep5L_SkHw@mail.gmail.com>
Message-ID: <MWHPR02MB22692546CA9D60C458F083D1D5F60@MWHPR02MB2269.namprd02.prod.outlook.com>

Thanks very much for your detailed reply to my post.  Very helpful/useful tool(s) you?ve provide me.  Best wishes, B.

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Wednesday, September 21, 2016 10:48 AM
To: Crombie, Burnette N <bcrombie at utk.edu>
Cc: r-help at r-project.org
Subject: Re: [R] if/else help

If you write your code as functions you can avoid the nasty 'if(exists("x"))x<-...' business this by writing default values for
arguments to your function.   They will be computed only when
they are used.  E.g.,
analyzeData <- function(a=0, b=0, c=0, d="x", r4 = data.frame(a, b, c, d)) {
    summary(r4)
}
> analyzeData(c=101:102)
       a           b           c         d
 Min.   :0   Min.   :0   Min.   :101.0   x:2
 1st Qu.:0   1st Qu.:0   1st Qu.:101.2
 Median :0   Median :0   Median :101.5
 Mean   :0   Mean   :0   Mean   :101.5
 3rd Qu.:0   3rd Qu.:0   3rd Qu.:101.8
 Max.   :0   Max.   :0   Max.   :102.0
> analyzeData(r4=data.frame(a=10:11,b=20:21,c=30:31,d=c("x","y")))
       a               b               c         d
 Min.   :10.00   Min.   :20.00   Min.   :30.00   x:1
 1st Qu.:10.25   1st Qu.:20.25   1st Qu.:30.25   y:1
 Median :10.50   Median :20.50   Median :30.50
 Mean   :10.50   Mean   :20.50   Mean   :30.50
 3rd Qu.:10.75   3rd Qu.:20.75   3rd Qu.:30.75
 Max.   :11.00   Max.   :21.00   Max.   :31.00


Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Sep 20, 2016 at 12:31 PM, Crombie, Burnette N <bcrombie at utk.edu<mailto:bcrombie at utk.edu>> wrote:
If a data.frame (r4) does not exist in my R environment, I would like to create it before I move on to the next step in my script. How do I make that happen?  Here is what I want to do from a code perspective:

if (exists(r4))
{
is.data.frame(get(r4))
}
else
{
a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d))
}

Thanks for your help,
B

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bcrombie at utk.edu  Wed Sep 21 17:38:15 2016
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Wed, 21 Sep 2016 15:38:15 +0000
Subject: [R] if/else help
In-Reply-To: <D407F18D.186A8A%macqueen1@llnl.gov>
References: <D407F18D.186A8A%macqueen1@llnl.gov>
Message-ID: <MWHPR02MB2269F8C019CB906523AA6133D5F60@MWHPR02MB2269.namprd02.prod.outlook.com>

Thank you for your time, Don.  Exactly what I was looking for - a one-liner.  Feedback from others on this post has been good to expand my knowledge, though.  I'm too old for homework but have just started using R if/else, loops, and functions and trying to get the hang of them.  Best wishes - B

-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Wednesday, September 21, 2016 11:26 AM
To: Crombie, Burnette N <bcrombie at utk.edu>; r-help at r-project.org
Subject: Re: [R] if/else help

Hopefully this is not a homework question.

The other responses are fine, but I would suggest the simplest way to do exactly what you ask is


if (!exists('r4')) r4 <- data.frame(a=0, b=0, c=0, d='x')


The exists() function requires a character string for its first argument, i.e., the name of the object, not the object itself (check the help page for exists).

Using "get" to get it doesn't make sense if it already exists.

-Don

--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/20/16, 12:31 PM, "R-help on behalf of Crombie, Burnette N"
<r-help-bounces at r-project.org on behalf of bcrombie at utk.edu> wrote:

>If a data.frame (r4) does not exist in my R environment, I would like 
>to create it before I move on to the next step in my script. How do I 
>make that happen?  Here is what I want to do from a code perspective:
>
>if (exists(r4))
>{
>is.data.frame(get(r4))
>}
>else
>{
>a <- 0, b <- 0, c <- 0, d <- "x", r4 <- data.frame(cbind(a,b,c,d)) }
>
>Thanks for your help,
>B
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Colin.Phillips at opsi.co.za  Thu Sep 22 10:45:25 2016
From: Colin.Phillips at opsi.co.za (Colin Phillips)
Date: Thu, 22 Sep 2016 08:45:25 +0000
Subject: [R] `head` doesn't show all columns for an empty data.frame
Message-ID: <3324B7325269484EA3138CA78BAC628366702DA3@mbx03>

I'm sure I'm doing something wrong, but I'm seeing strange behaviour using the `head` and `tail` functions on an empty data.frame.

To reproduce:
# create an empty data frame.  I actually read an empty table from Excel using `readWorkbook` from package `openxlsx`
test <- structure(list(Code = NULL, Name = NULL, Address = NULL, Sun.Hrs = NULL, 
    Mon.Hrs = NULL), .Names = c("Code", "Name", "Address", "Sun.Hrs", 
"Mon.Hrs"), class = "data.frame", row.names = integer(0))

# show the data frame
test

# output in console:
#     [1] Code    Name    Address Sun.Hrs Mon.Hrs
#     <0 rows> (or 0-length row.names)

# note that the data frame has 0 rows and 5 columns
# show the structure
str(test)

# output in console:
#'data.frame':	0 obs. of  5 variables:
# $ Code   : NULL
# $ Name   : NULL
# $ Address: NULL
# $ Sun.Hrs: NULL
# $ Mon.Hrs: NULL

#again, the structure shows 5 columns.  However...
head(test); tail(test)

# output in console:
#[1] Name    Sun.Hrs
#<0 rows> (or 0-length row.names)
#[1] Name    Sun.Hrs
#<0 rows> (or 0-length row.names)

# now we have only two columns
 
Weird, right?

So, here's my session info:
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats4    grid      stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] tidyr_0.6.0       lpSolve_5.6.13    flexclust_1.3-4   modeltools_0.2-21 lattice_0.20-34   gtools_3.5.0      reshape2_1.4.1    ash_1.0-15        RODBC_1.3-13     
[10] ggmap_2.6.1       ggplot2_2.1.0     dplyr_0.5.0       assertthat_0.1    openxlsx_3.0.0   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.7       plyr_1.8.4        tools_3.3.1       digest_0.6.10     tibble_1.2        gtable_0.2.0      png_0.1-7         DBI_0.5-1         mapproj_1.2-4    
[10] parallel_3.3.1    proto_0.3-10      stringr_1.1.0     RgoogleMaps_1.4.1 maps_3.1.1        R6_2.1.3          jpeg_0.1-8        sp_1.2-3          magrittr_1.5     
[19] scales_0.4.0      geosphere_1.5-5   colorspace_1.2-6  labeling_0.3      stringi_1.1.1     lazyeval_0.2.0    munsell_0.4.3     rjson_0.2.15     

This is not an urgent issue, I just think it's curious, so it would be nice to understand why it happens.

Thanks,

Colin


From pauline.laille at gmail.com  Wed Sep 21 09:49:51 2016
From: pauline.laille at gmail.com (=?UTF-8?Q?Pauline_La=C3=AFlle?=)
Date: Wed, 21 Sep 2016 09:49:51 +0200
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <CAGxFJbQCrsF-6N84S+v6-uSroYb7rC00MM9t4rrfsH8+t914=Q@mail.gmail.com>
References: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>
	<CAGxFJbQCrsF-6N84S+v6-uSroYb7rC00MM9t4rrfsH8+t914=Q@mail.gmail.com>
Message-ID: <CAJuz8G_oX0BsL8+5-N34Xa_kKsx=XYd_yaNMr+Pavr+wMtvj+w@mail.gmail.com>

Hi, thanks for the answer.
In this case, the row named "601" is not the 601st row of the table, but
the 117th. data[601,] actually refers to a non existing row.
I was wondering why data[-"601,] generates an error message whereas
data["601",] does not?

2016-09-20 19:08 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Hint: "601"  is not 601.
>
> Have you gone through any R tutorials?
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 20, 2016 at 5:42 AM, Pauline La?lle
> <pauline.laille at gmail.com> wrote:
> > Dear all,
> >
> > I built a dataframe with read.csv2(). Initially, row names are integers
> > (order of answers to a survey). They are listed in the csv's first
> column.
> > The import works well and my dataframe looks like I wanted it to look.
> >
> > Row names go as follows :
> >  [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"
> "89"
> >  "91"  "93"  "105" "110" "111" "117" "119" "120"
> >  [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
> > "178" "179" "184" "186" "192" "193" "200" "201" "228"
> > etc.
> >
> > I would like to drop rows "601" & "604" to clean the dataframe.
> >
> > While data["601",] shows me the first row i'd like to drop, data[-"601",]
> > returns the following :
> > Error in -"601" : invalid argument to unary operator
> >
> > idem with data[c("601","604"),] and data[-c("601","604"),]
> >
> > It is the first time that I run into this specific error. After reading a
> > bit about it I still don't understand what it means and how to fix it.
> >
> > Thanks for reading!
> > Best,
> > Pauline.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pauline.laille at gmail.com  Wed Sep 21 09:51:13 2016
From: pauline.laille at gmail.com (=?UTF-8?Q?Pauline_La=C3=AFlle?=)
Date: Wed, 21 Sep 2016 09:51:13 +0200
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
Message-ID: <CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>

Works like a charm, thanks!
Still don't know what that error message means though. Any idea?

2016-09-20 20:13 GMT+02:00 <ruipbarradas at sapo.pt>:

> Sorry, I've made a stupid mistake.
> It's obviously the other way around.
>
> ix <- which(rownames(data) %in% c("601", "604"))
> clean <- data[-ix, ]
>
>
> Rui Barradas
>
>
> Citando ruipbarradas at sapo.pt:
>
>
> Hello,
>>
>> Try something like the following.
>>
>> ix <- which(c("601", "604") %in% rownames(data))
>> clean <- data[-ix, ]
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>>
>> Citando Pauline La?lle <pauline.laille at gmail.com>:
>>
>> Dear all,
>>>
>>> I built a dataframe with read.csv2(). Initially, row names are integers
>>> (order of answers to a survey). They are listed in the csv's first
>>> column.
>>> The import works well and my dataframe looks like I wanted it to look.
>>>
>>> Row names go as follows :
>>> [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"
>>> "89"
>>> "91"  "93"  "105" "110" "111" "117" "119" "120"
>>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
>>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
>>> etc.
>>>
>>> I would like to drop rows "601" & "604" to clean the dataframe.
>>>
>>> While data["601",] shows me the first row i'd like to drop, data[-"601",]
>>> returns the following :
>>> Error in -"601" : invalid argument to unary operator
>>>
>>> idem with data[c("601","604"),] and data[-c("601","604"),]
>>>
>>> It is the first time that I run into this specific error. After reading a
>>> bit about it I still don't understand what it means and how to fix it.
>>>
>>> Thanks for reading!
>>> Best,
>>> Pauline.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>

	[[alternative HTML version deleted]]


From pauline.laille at gmail.com  Wed Sep 21 20:24:44 2016
From: pauline.laille at gmail.com (=?UTF-8?Q?Pauline_La=C3=AFlle?=)
Date: Wed, 21 Sep 2016 20:24:44 +0200
Subject: [R] "invalid argument to unary operator" while selecting rows
	by name
In-Reply-To: <CAF8bMcb53kDOSMu5K7ZK7o4e3QVAF+p9OjOD7CMRjiMYxrrkNw@mail.gmail.com>
References: <20160920185208.Horde.Mw_jwySKQ6UkoZAHWFB2X9h@mail.sapo.pt>
	<20160920191354.Horde.30aFrouY3FDTSaCBfy5iDNm@mail.sapo.pt>
	<CAJuz8G9k-qhtKO6Z9K5VBQJk-a8XeJQnm8vidXfrAUNWksNs9g@mail.gmail.com>
	<20160921092607.Horde.soqqwQpGDLd0JER0DuIgOKO@mail.sapo.pt>
	<CAGxFJbRyyH4NmpHGdv6Ngesb2hBmKhTmbdwGBC=ihS9qPTxnwQ@mail.gmail.com>
	<CAF8bMcb53kDOSMu5K7ZK7o4e3QVAF+p9OjOD7CMRjiMYxrrkNw@mail.gmail.com>
Message-ID: <CAJuz8G8qgapO0e3RU32HBsj6G2NZ=ADHFWG49+n71J8oBbuivw@mail.gmail.com>

Tanks for all your answers and for taking the time to help me better
understand my mistake.
I will take your advice and do some reading!
Best,
P.

Le mercredi 21 septembre 2016, William Dunlap <wdunlap at tibco.com> a ?crit :

> The OP cannot be entirely blamed for thinking that x[,-"ColName"]
> would omit x's "ColName" from the result.  Base R and many packages
> have commonly used functions that do context-sensitive (aka 'nonstandard')
> evaluation.
>
> E.g. subset() evaluates each argument in a different way:
>   > subset(data.frame(ColA=1:3,ColB=-(11:13)), -ColB>11, -ColA)
>     ColB
>   2  -12
>   3  -13
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Sep 21, 2016 at 7:45 AM, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:_e(%7B%7D,'cvml','bgunter.4567 at gmail.com');>> wrote:
>
>> No, Rui, your example misses the point. Your initial sentence hits it.
>>
>> The OP needs to carefully read
>> ?"["
>> and/or spend some time with a suitable R tutorial to learn proper
>> syntax for subscripting. Asking foolish questions in lieu of doing her
>> homework seems wrongheaded to me. Others may disagree, of course.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Sep 21, 2016 at 1:26 AM,  <ruipbarradas at sapo.pt
>> <javascript:_e(%7B%7D,'cvml','ruipbarradas at sapo.pt');>> wrote:
>> > Hello,
>> >
>> > The error message means exactly what it says. The operator '-' is
>> > unary and cannot be followed by a non-numeric atomic object (a vector).
>> > Try for instance
>> >
>> > x <- list(a=1:10, b=rnorm(5))
>> > -x
>> >
>> > Rui Barradas
>> >
>> >
>> > Citando Pauline La?lle <pauline.laille at gmail.com
>> <javascript:_e(%7B%7D,'cvml','pauline.laille at gmail.com');>>:
>> >
>> >> Works like a charm, thanks! Still don't know what that error message
>> >> means though. Any idea?
>> >>
>> >>   2016-09-20 20:13 GMT+02:00 <ruipbarradas at sapo.pt
>> <javascript:_e(%7B%7D,'cvml','ruipbarradas at sapo.pt');>>:
>> >>> Sorry, I've made a stupid mistake.
>> >>> It's obviously the other way around.
>> >>>
>> >>> ix <- which(rownames(data) %in% c("601", "604"))
>> >>> clean <- data[-ix, ]
>> >>>
>> >>> Rui Barradas
>> >>>
>> >>> Citando ruipbarradas at sapo.pt
>> <javascript:_e(%7B%7D,'cvml','ruipbarradas at sapo.pt');>:
>> >>>> Hello,
>> >>>>
>> >>>> Try something like the following.
>> >>>>
>> >>>> ix <- which(c("601", "604") %in% rownames(data))
>> >>>> clean <- data[-ix, ]
>> >>>>
>> >>>> Hope this helps,
>> >>>>
>> >>>> Rui Barradas
>> >>>>
>> >>>> Citando Pauline La?lle <pauline.laille at gmail.com
>> <javascript:_e(%7B%7D,'cvml','pauline.laille at gmail.com');>>:
>> >>>>
>> >>>>> Dear all,
>> >>>>>
>> >>>>> I built a dataframe with read.csv2(). Initially, row names are
>> integers
>> >>>>> (order of answers to a survey). They are listed in the csv's first
>> column.
>> >>>>> The import works well and my dataframe looks like I wanted it to
>> look.
>> >>>>>
>> >>>>> Row names go as follows :
>> >>>>> [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"
>> "88"  "89"
>> >>>>> "91"  "93"  "105" "110" "111" "117" "119" "120"
>> >>>>> [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169"
>> "177"
>> >>>>> "178" "179" "184" "186" "192" "193" "200" "201" "228"
>> >>>>> etc.
>> >>>>>
>> >>>>> I would like to drop rows "601" & "604" to clean the dataframe.
>> >>>>>
>> >>>>> While data["601",] shows me the first row i'd like to drop,
>> data[-"601",]
>> >>>>> returns the following :
>> >>>>> Error in -"601" : invalid argument to unary operator
>> >>>>>
>> >>>>> idem with data[c("601","604"),] and data[-c("601","604"),]
>> >>>>>
>> >>>>> It is the first time that I run into this specific error. After
>> reading a
>> >>>>> bit about it I still don't understand what it means and how to fix
>> it.
>> >>>>>
>> >>>>> Thanks for reading!
>> >>>>> Best,
>> >>>>> Pauline.
>> >>>>>
>> >>>>>         [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');> mailing list --
>> To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');> mailing list --
>> To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');> mailing list --
>> To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');> mailing list --
>> To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Thu Sep 22 16:04:10 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 22 Sep 2016 10:04:10 -0400
Subject: [R] Add annotation text outside of an xyplot (lattice package)
Message-ID: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>

Dear list,

Just wonder if there is a way to add annotation text outside an xyplot,
(e.g. the bottom of the plot). the panel.text seems only add text within
the plot. Thanks.

Jun

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep 22 16:24:45 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Sep 2016 10:24:45 -0400
Subject: [R] `head` doesn't show all columns for an empty data.frame
In-Reply-To: <3324B7325269484EA3138CA78BAC628366702DA3@mbx03>
References: <3324B7325269484EA3138CA78BAC628366702DA3@mbx03>
Message-ID: <80fce1f6-7309-73e4-a206-fb55f1f218d0@gmail.com>

On 22/09/2016 4:45 AM, Colin Phillips wrote:
> I'm sure I'm doing something wrong, but I'm seeing strange behaviour using the `head` and `tail` functions on an empty data.frame.
>
> To reproduce:
> # create an empty data frame.  I actually read an empty table from Excel using `readWorkbook` from package `openxlsx`
> test <- structure(list(Code = NULL, Name = NULL, Address = NULL, Sun.Hrs = NULL,
>     Mon.Hrs = NULL), .Names = c("Code", "Name", "Address", "Sun.Hrs",
> "Mon.Hrs"), class = "data.frame", row.names = integer(0))

That's not a valid dataframe, it's just labelled as one.  If you tried 
to create it with data.frame(), you'd get something different.

 > test <- data.frame(Code = NULL, Name = NULL, Address = NULL, Sun.Hrs 
= NULL,
+     Mon.Hrs = NULL)
 > test
data frame with 0 columns and 0 rows

You can create a zero-row dataframe as long as you put 0-length vectors 
in as columns.  NULL is not a vector.

 > test <- data.frame(Code = numeric(0), Name = numeric(0), Address = 
numeric(0), Sun.Hrs = numeric(0),
+     Mon.Hrs = numeric(0))
 > test
[1] Code    Name    Address Sun.Hrs Mon.Hrs
<0 rows> (or 0-length row.names)

If you do that, head() works:

 > head(test)
[1] Code    Name    Address Sun.Hrs Mon.Hrs
<0 rows> (or 0-length row.names)

So this is a bug in openxlsx.  It's also a well-known limitation of the 
S3 object system:  you can easily create things that are labelled with a 
certain class, but aren't valid objects of that class.

Duncan Murdoch


From cof at qualityexcellence.es  Thu Sep 22 16:39:09 2016
From: cof at qualityexcellence.es (Carlos Ortega)
Date: Thu, 22 Sep 2016 16:39:09 +0200
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
Message-ID: <CAOKbq8idTzuwRtmtdHzVkU4LwNpcLP3symKu3YUcE+ediQf4bg@mail.gmail.com>

Hi,

Yes, you can use "latticeExtra" package and use a text layer on top of your
current chart.

Thanks,
Carlos Ortega

2016-09-22 16:04 GMT+02:00 Jun Shen <jun.shen.ut at gmail.com>:

> Dear list,
>
> Just wonder if there is a way to add annotation text outside an xyplot,
> (e.g. the bottom of the plot). the panel.text seems only add text within
> the plot. Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Saludos,
Carlos Ortega
www.qualityexcellence.es

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Sep 22 16:43:50 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 22 Sep 2016 15:43:50 +0100
Subject: [R] "invalid argument to unary operator" while selecting rows
 by name
In-Reply-To: <CAJuz8G_oX0BsL8+5-N34Xa_kKsx=XYd_yaNMr+Pavr+wMtvj+w@mail.gmail.com>
References: <CAJuz8G89Q6-f2OBA0UC=iS+SAopOpkbHR6zUMB=zOY+v1PLFnA@mail.gmail.com>
	<CAGxFJbQCrsF-6N84S+v6-uSroYb7rC00MM9t4rrfsH8+t914=Q@mail.gmail.com>
	<CAJuz8G_oX0BsL8+5-N34Xa_kKsx=XYd_yaNMr+Pavr+wMtvj+w@mail.gmail.com>
Message-ID: <20160922154350.Horde.c1bQ13bJzmyuar6HZbKgUOm@mail.sapo.pt>

Hello,

data["601",] doesn't generate an error because you can also refer to a  
row by its name, as an alternative to refering to it by row number.  
It's the same with vectors, just consider the following case.

(x <- c("601"=1, b=2))
x[1]
x["601"]  # the same

But when you want to remove it you must negate an index number so  
x[-"601"] is wrong for reasons already explained.

Rui Barradas


Citando Pauline La?lle <pauline.laille at gmail.com>:

> Hi, thanks for the answer.
> In this case, the row named "601" is not the 601st row of the table, but
> the 117th. data[601,] actually refers to a non existing row.
> I was wondering why data[-"601,] generates an error message whereas
> data["601",] does not?
>
> 2016-09-20 19:08 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
>> Hint: "601"  is not 601.
>>
>> Have you gone through any R tutorials?
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Sep 20, 2016 at 5:42 AM, Pauline La?lle
>> <pauline.laille at gmail.com> wrote:
>> > Dear all,
>> >
>> > I built a dataframe with read.csv2(). Initially, row names are integers
>> > (order of answers to a survey). They are listed in the csv's first
>> column.
>> > The import works well and my dataframe looks like I wanted it to look.
>> >
>> > Row names go as follows :
>> >  [1] "6"   "29"  "31"  "32"  "52"  "55"  "63"  "71"  "72"  "80"  "88"
>> "89"
>> >  "91"  "93"  "105" "110" "111" "117" "119" "120"
>> >  [21] "122" "127" "128" "133" "137" "140" "163" "165" "167" "169" "177"
>> > "178" "179" "184" "186" "192" "193" "200" "201" "228"
>> > etc.
>> >
>> > I would like to drop rows "601" & "604" to clean the dataframe.
>> >
>> > While data["601",] shows me the first row i'd like to drop, data[-"601",]
>> > returns the following :
>> > Error in -"601" : invalid argument to unary operator
>> >
>> > idem with data[c("601","604"),] and data[-c("601","604"),]
>> >
>> > It is the first time that I run into this specific error. After reading a
>> > bit about it I still don't understand what it means and how to fix it.
>> >
>> > Thanks for reading!
>> > Best,
>> > Pauline.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Thu Sep 22 17:01:49 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 22 Sep 2016 08:01:49 -0700
Subject: [R] Variable String formation
Message-ID: <F7B5F37C-8A74-45E8-A9B9-C0C3DAC45CAB@noaa.gov>

Hi All:

I am trying to write code to create a string to be executed as a command.  The string will be of the form:

"param <- param[,rev(seq_len(dataYLen)),,drop = FALSE]"

Now just creating that string is simple enough.  Where the problem arises is the array param could be 2, 3, or 4 dimensions, and the dimension where  "rev(seq_len(dataYLen))" occurs can vary.  At present I have the following solution:

      paramLen <-  3
      latLoc <- 2
      myComma1 <- paste(rep(',', times = (latLoc-1)), 'rev(seq_len(dataYLen))', sep="", collapse="")
      myComma2 <- paste(rep(',', times = (paramLen-latLoc+1)),sep="", collapse="")
      paramCommand <- paste0('param <- param[', myComma1, myComma2, 'drop = FALSE]')

(paramLen can be 2,3,4 and latLoc can be 1,2,3,4)  but this strikes me as pretty kludgy.  I am hoping there is a more elegant way of doing this.

Thanks,

-Roy

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From oliviermerle35 at gmail.com  Thu Sep 22 17:41:20 2016
From: oliviermerle35 at gmail.com (Olivier Merle)
Date: Thu, 22 Sep 2016 17:41:20 +0200
Subject: [R] Memory not release when an environment is created
Message-ID: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>

Dear,

When I use big data for a temporary use it seems that the memory is not
released when a function/environement is created nearby.
Here the reproducible exemple:

test<-function(){
x=matrix(0,50000,10000)
y=function(nb) nb^2
return(y)
}
xx=test() # 3 Go of Ram is used
gc() # Memory is not released !! even if x has been destroyed [look into
software mem used]
format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size of
the object
rm(xx)
gc() # Memory is released

## Classic
test2<-function(){
x=matrix(0,50000,10000)
y=1
return(y)
}
xx=test2() # Memory is used
gc() # => Memory is released

How can I release the data in test without destroying the xx object ? As x
which is big object is destroyed, I though I could get my memory back but
it seems that the function y is keeping the x object.

Best

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Thu Sep 22 18:45:37 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 22 Sep 2016 19:45:37 +0300
Subject: [R] Memory not release when an environment is created
In-Reply-To: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
Message-ID: <F6BA3685-66D1-407E-A781-684EBB4F490A@gmail.com>


> On 22 Sep 2016, at 18:41, Olivier Merle <oliviermerle35 at gmail.com> wrote:
> 
> Dear,
> 
> When I use big data for a temporary use it seems that the memory is not
> released when a function/environement is created nearby.
> Here the reproducible exemple:
> 
> test<-function(){
> x=matrix(0,50000,10000)
> y=function(nb) nb^2
> return(y)
> }
> xx=test() # 3 Go of Ram is used
> gc() # Memory is not released !! even if x has been destroyed [look into
> software mem used]

Because y is a function and returns with its own environment.

ls(environment(xx)) # x and y objects are still there

> How can I release the data in test without destroying the xx object ? As x
> which is big object is destroyed, I though I could get my memory back but
> it seems that the function y is keeping the x object.

if you do not need the x object in y function then remove it in it?s own environment as follows;

> test<-function(){
> x=matrix(0,50000,10000)
   rm(x)
> y=function(nb) nb^2
> return(y)
> }

or if you need to remove it out of the function;

rm("x", envir = environment(xx))
ls(environment(xx)) # x has gone

 If y function uses x somehow, then you will need to live with a big object.

From dwinsemius at comcast.net  Thu Sep 22 19:41:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Sep 2016 10:41:30 -0700
Subject: [R] Memory not release when an environment is created
In-Reply-To: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
Message-ID: <8F507974-74EA-4EDD-8C1D-3BEFEC1E4CA3@comcast.net>


> On Sep 22, 2016, at 8:41 AM, Olivier Merle <oliviermerle35 at gmail.com> wrote:
> 
> Dear,
> 
> When I use big data for a temporary use it seems that the memory is not
> released when a function/environement is created nearby.
> Here the reproducible exemple:
> 
> test<-function(){
> x=matrix(0,50000,10000)
> y=function(nb) nb^2
> return(y)
> }
> xx=test() # 3 Go of Ram is used
> gc() # Memory is not released !! even if x has been destroyed [look into
> software mem used]

Looking at this I would imagine that the unreleased memory is allocated within the `xx` objects environment (since functions in R are actually closures that carry along their environments of creation.


> format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size of
> the object
> rm(xx)
> gc() # Memory is released
> 
> ## Classic
> test2<-function(){
> x=matrix(0,50000,10000)
> y=1
> return(y)
> }
> xx=test2() # Memory is used
> gc() # => Memory is released
> 
> How can I release the data in test without destroying the xx object ? As x
> which is big object is destroyed, I though I could get my memory back but
> it seems that the function y is keeping the x object.

That's how I understand the semantics of R. You would need to replace the environment that is attached to `xx`. I madesomwaht smaller object:

test<-function(
x=matrix(0,500,
y=function(nb) 
return(y)
}
xx=test() 

> environment(xx)
<environment: 0x7fda21ba35f0>

> object.size(xx)
1384 bytes
> ls(x, envir=environment(xx) )
[1] "x" "y"
> ?get
> object.size( get("x", envir=environment(xx) ) )
400200 bytes

Even with that perspective in mind it still took me two tries to get rid of the xx object, since my abilities to "program on the language" are still fairly modest.:

> eval( x <- NULL, envir=environment(xx) )
NULL
> object.size( get("x", envir=environment(xx) ) )
400200 bytes
> eval( quote(x <- NULL), envir=environment(xx) )
> object.size( get("x", envir=environment(xx) ) )
0 bytes

So now I have learned that object.size does not include measurements of the size of function environments, a fact about which I was not aware.

Best;
David.

> 
> Best
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Sep 22 19:57:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Sep 2016 10:57:46 -0700
Subject: [R] Memory not release when an environment is created
In-Reply-To: <F6BA3685-66D1-407E-A781-684EBB4F490A@gmail.com>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
	<F6BA3685-66D1-407E-A781-684EBB4F490A@gmail.com>
Message-ID: <76F92022-B5B2-4E71-8647-AB3D132C4A64@comcast.net>


> On Sep 22, 2016, at 9:45 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
> 
> 
>> On 22 Sep 2016, at 18:41, Olivier Merle <oliviermerle35 at gmail.com> wrote:
>> 
>> Dear,
>> 
>> When I use big data for a temporary use it seems that the memory is not
>> released when a function/environement is created nearby.
>> Here the reproducible exemple:
>> 
>> test<-function(){
>> x=matrix(0,50000,10000)
>> y=function(nb) nb^2
>> return(y)
>> }
>> xx=test() # 3 Go of Ram is used
>> gc() # Memory is not released !! even if x has been destroyed [look into
>> software mem used]
> 
> Because y is a function and returns with its own environment.
> 
> ls(environment(xx)) # x and y objects are still there
> 
>> How can I release the data in test without destroying the xx object ? As x
>> which is big object is destroyed, I though I could get my memory back but
>> it seems that the function y is keeping the x object.
> 
> if you do not need the x object in y function then remove it in it?s own environment as follows;
> 
>> test<-function(){
>> x=matrix(0,50000,10000)
>   rm(x)
>> y=function(nb) nb^2
>> return(y)
>> }
> 
> or if you need to remove it out of the function;
> 
> rm("x", envir = environment(xx))
> ls(environment(xx)) # x has gone

That's much clearer than my `eval(quote(...` approach. I had forgotten that `rm` had an 'environment' parameter. I had considered trying:

environment(xx)$x <- NULL   # but after looking at `environment`'s help page I was pretty sure it would have failed 

# But there again I was wrong:

test<-function(){
x=matrix(0,500,100)
y=function(nb) nb^2
return(y)
}
xx=test()

environment(xx)$x <- NULL


> object.size( get("x", envir=environment(xx) ) )
0 bytes

I still think rm() is the way to go but this offers another illustration of available methods of environment mangling, er, manipulation.

Best;
David.


> 
> If y function uses x somehow, then you will need to live with a big object.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Sep 22 20:21:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Sep 2016 11:21:15 -0700
Subject: [R] Variable String formation
In-Reply-To: <F7B5F37C-8A74-45E8-A9B9-C0C3DAC45CAB@noaa.gov>
References: <F7B5F37C-8A74-45E8-A9B9-C0C3DAC45CAB@noaa.gov>
Message-ID: <BF7F8479-ACAD-4D0D-94C1-74737D312262@comcast.net>


> On Sep 22, 2016, at 8:01 AM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi All:
> 
> I am trying to write code to create a string to be executed as a command.  The string will be of the form:
> 
> "param <- param[,rev(seq_len(dataYLen)),,drop = FALSE]"
> 
> Now just creating that string is simple enough.  Where the problem arises is the array param could be 2, 3, or 4 dimensions, and the dimension where  "rev(seq_len(dataYLen))" occurs can vary.  At present I have the following solution:
> 
>      paramLen <-  3
>      latLoc <- 2
>      myComma1 <- paste(rep(',', times = (latLoc-1)), 'rev(seq_len(dataYLen))', sep="", collapse="")
>      myComma2 <- paste(rep(',', times = (paramLen-latLoc+1)),sep="", collapse="")
>      paramCommand <- paste0('param <- param[', myComma1, myComma2, 'drop = FALSE]')
> 
> (paramLen can be 2,3,4 and latLoc can be 1,2,3,4)  but this strikes me as pretty kludgy.  I am hoping there is a more elegant way of doing this.
> 

 Take a look at this function to see if it allows you to make this cleaner:

?R.utils::extract.array 

(Author = Henrik Bengtsson; so you have can have confidence in its quality.)

Found with the ever-useful `findFn` function:

findFn("extract slice array")
found 28 matches;  retrieving 2 pages
2 
Downloaded 28 links in 24 packages.

To whose author/maintainer I give almost daily silent thank yous:

 maintainer('sos')
[1] "Spencer Graves <spencer.graves at prodsyse.com>"


> Thanks,
> 
> -Roy
> 
> 


David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Thu Sep 22 20:29:38 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Sep 2016 11:29:38 -0700
Subject: [R] Memory not release when an environment is created
In-Reply-To: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
Message-ID: <CAF8bMcZcoH47ais37jy3QiTD3aWmYEsx91arO3B8GJYxJfCqqg@mail.gmail.com>

I like to have my function-returning functions use new.env(parent=XXX)
to make an environment for the returned function and put into it only
the objects needed by the function.  The 'XXX' should be a an environment
which will hang around anyway.  It could be globalenv(), but if your
function
is in a package, as.environment(paste0("package:", .packageName))
would work well.  The later ensures the your returned function has access
to all the other functions in that package.

E.g.,
> makeFunc1 <- function(x) {
    envir <- new.env(parent = environment(sys.function()))
    envir$xmax <- max(x)
    envir$xmin <- min(x)
    with(envir, function(y) (y - xmin) / (xmax - xmin))
}
> f <- makeFunc1(1:1e8)
> ls.str(all=TRUE, environment(f))
xmax :  int 100000000
xmin :  int 1
> parent.env(environment(f))
<environment: R_GlobalEnv>
> f(c(1234567, 2345678))
[1] 0.01234566 0.02345677



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 22, 2016 at 8:41 AM, Olivier Merle <oliviermerle35 at gmail.com>
wrote:

> Dear,
>
> When I use big data for a temporary use it seems that the memory is not
> released when a function/environement is created nearby.
> Here the reproducible exemple:
>
> test<-function(){
> x=matrix(0,50000,10000)
> y=function(nb) nb^2
> return(y)
> }
> xx=test() # 3 Go of Ram is used
> gc() # Memory is not released !! even if x has been destroyed [look into
> software mem used]
> format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size
> of
> the object
> rm(xx)
> gc() # Memory is released
>
> ## Classic
> test2<-function(){
> x=matrix(0,50000,10000)
> y=1
> return(y)
> }
> xx=test2() # Memory is used
> gc() # => Memory is released
>
> How can I release the data in test without destroying the xx object ? As x
> which is big object is destroyed, I though I could get my memory back but
> it seems that the function y is keeping the x object.
>
> Best
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Thu Sep 22 21:01:38 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 22 Sep 2016 14:01:38 -0500
Subject: [R] Memory not release when an environment is created
In-Reply-To: <CAF8bMcZcoH47ais37jy3QiTD3aWmYEsx91arO3B8GJYxJfCqqg@mail.gmail.com>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
	<CAF8bMcZcoH47ais37jy3QiTD3aWmYEsx91arO3B8GJYxJfCqqg@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1609221358300.11459@lukes-macbook-air.local>

My preference is to use a top level function in the package or global
env that takes as arguments just the variables I want in the parent
frame. That avoids the explicit environment manipulations. Here that
would be

> makeFunc0 <- function(xmin, xmax)
       function(y) (y - xmin) / (xmax - xmin)

> makeFunc1 <- function(x)
       makeFunc0(min(x), max(x))

> f <- makeFunc1(1:1e8)
> ls.str(all=TRUE, environment(f))
xmax :  int 100000000
xmin :  int 1
> parent.env(environment(f))
<environment: R_GlobalEnv>
> f(c(1234567, 2345678))
[1] 0.01234566 0.02345677

Best,

luke


On Thu, 22 Sep 2016, William Dunlap via R-help wrote:

> I like to have my function-returning functions use new.env(parent=XXX)
> to make an environment for the returned function and put into it only
> the objects needed by the function.  The 'XXX' should be a an environment
> which will hang around anyway.  It could be globalenv(), but if your
> function
> is in a package, as.environment(paste0("package:", .packageName))
> would work well.  The later ensures the your returned function has access
> to all the other functions in that package.
>
> E.g.,
>> makeFunc1 <- function(x) {
>    envir <- new.env(parent = environment(sys.function()))
>    envir$xmax <- max(x)
>    envir$xmin <- min(x)
>    with(envir, function(y) (y - xmin) / (xmax - xmin))
> }
>> f <- makeFunc1(1:1e8)
>> ls.str(all=TRUE, environment(f))
> xmax :  int 100000000
> xmin :  int 1
>> parent.env(environment(f))
> <environment: R_GlobalEnv>
>> f(c(1234567, 2345678))
> [1] 0.01234566 0.02345677
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Sep 22, 2016 at 8:41 AM, Olivier Merle <oliviermerle35 at gmail.com>
> wrote:
>
>> Dear,
>>
>> When I use big data for a temporary use it seems that the memory is not
>> released when a function/environement is created nearby.
>> Here the reproducible exemple:
>>
>> test<-function(){
>> x=matrix(0,50000,10000)
>> y=function(nb) nb^2
>> return(y)
>> }
>> xx=test() # 3 Go of Ram is used
>> gc() # Memory is not released !! even if x has been destroyed [look into
>> software mem used]
>> format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size
>> of
>> the object
>> rm(xx)
>> gc() # Memory is released
>>
>> ## Classic
>> test2<-function(){
>> x=matrix(0,50000,10000)
>> y=1
>> return(y)
>> }
>> xx=test2() # Memory is used
>> gc() # => Memory is released
>>
>> How can I release the data in test without destroying the xx object ? As x
>> which is big object is destroyed, I though I could get my memory back but
>> it seems that the function y is keeping the x object.
>>
>> Best
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke-tierney at uiowa.edu  Thu Sep 22 21:24:21 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 22 Sep 2016 14:24:21 -0500
Subject: [R] Memory not release when an environment is created
In-Reply-To: <alpine.OSX.2.20.1609221358300.11459@lukes-macbook-air.local>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
	<CAF8bMcZcoH47ais37jy3QiTD3aWmYEsx91arO3B8GJYxJfCqqg@mail.gmail.com>
	<alpine.OSX.2.20.1609221358300.11459@lukes-macbook-air.local>
Message-ID: <alpine.OSX.2.20.1609221420080.11459@lukes-macbook-air.local>

On Thu, 22 Sep 2016, luke-tierney at uiowa.edu wrote:

> My preference is to use a top level function in the package or global
> env that takes as arguments just the variables I want in the parent
> frame. That avoids the explicit environment manipulations. Here that
> would be
>
>> makeFunc0 <- function(xmin, xmax)
>      function(y) (y - xmin) / (xmax - xmin)
>

But I do keep forgetting the need to force the parameters if you don't
want a big value to stick around until the returned function is used
the first time, so a better definition of makeFUnc0 is

makeFunc0 <- function(xmin, xmax) {
     force(xmin)
     force(xmax)
     function(y) (y - xmin) / (xmax - xmin)
}

Best,

luke

>> makeFunc1 <- function(x)
>      makeFunc0(min(x), max(x))
>
>> f <- makeFunc1(1:1e8)
>> ls.str(all=TRUE, environment(f))
> xmax :  int 100000000
> xmin :  int 1
>> parent.env(environment(f))
> <environment: R_GlobalEnv>
>> f(c(1234567, 2345678))
> [1] 0.01234566 0.02345677
>
> Best,
>
> luke
>
>
> On Thu, 22 Sep 2016, William Dunlap via R-help wrote:
>
>> I like to have my function-returning functions use new.env(parent=XXX)
>> to make an environment for the returned function and put into it only
>> the objects needed by the function.  The 'XXX' should be a an environment
>> which will hang around anyway.  It could be globalenv(), but if your
>> function
>> is in a package, as.environment(paste0("package:", .packageName))
>> would work well.  The later ensures the your returned function has access
>> to all the other functions in that package.
>> 
>> E.g.,
>>> makeFunc1 <- function(x) {
>>    envir <- new.env(parent = environment(sys.function()))
>>    envir$xmax <- max(x)
>>    envir$xmin <- min(x)
>>    with(envir, function(y) (y - xmin) / (xmax - xmin))
>> }
>>> f <- makeFunc1(1:1e8)
>>> ls.str(all=TRUE, environment(f))
>> xmax :  int 100000000
>> xmin :  int 1
>>> parent.env(environment(f))
>> <environment: R_GlobalEnv>
>>> f(c(1234567, 2345678))
>> [1] 0.01234566 0.02345677
>> 
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Thu, Sep 22, 2016 at 8:41 AM, Olivier Merle <oliviermerle35 at gmail.com>
>> wrote:
>> 
>>> Dear,
>>> 
>>> When I use big data for a temporary use it seems that the memory is not
>>> released when a function/environement is created nearby.
>>> Here the reproducible exemple:
>>> 
>>> test<-function(){
>>> x=matrix(0,50000,10000)
>>> y=function(nb) nb^2
>>> return(y)
>>> }
>>> xx=test() # 3 Go of Ram is used
>>> gc() # Memory is not released !! even if x has been destroyed [look into
>>> software mem used]
>>> format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size
>>> of
>>> the object
>>> rm(xx)
>>> gc() # Memory is released
>>> 
>>> ## Classic
>>> test2<-function(){
>>> x=matrix(0,50000,10000)
>>> y=1
>>> return(y)
>>> }
>>> xx=test2() # Memory is used
>>> gc() # => Memory is released
>>> 
>>> How can I release the data in test without destroying the xx object ? As x
>>> which is big object is destroyed, I though I could get my memory back but
>>> it seems that the function y is keeping the x object.
>>> 
>>> Best
>>>
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From fotisfotiadis at gmail.com  Thu Sep 22 19:32:55 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Thu, 22 Sep 2016 20:32:55 +0300
Subject: [R] mgcv: bam(),
 error in models with random intercepts and random slopes
In-Reply-To: <890463f0-aafe-e420-550c-52f0fdec44ea@bath.edu>
References: <CAAO1Nnd8i1fBtvHfJ9oirp_twGtTPgo29z75_QyW=aj9WjjyOw@mail.gmail.com>
	<890463f0-aafe-e420-550c-52f0fdec44ea@bath.edu>
Message-ID: <CAAO1NneGn+yNEnvpsNy-t5GXoOzMErjM7DAW5ocRZpXVbgEx4Q@mail.gmail.com>

Dear Professor Wood,

Thank you for taking the time to fix the problem.

Best,
Fotis



On Thu, Sep 22, 2016 at 4:25 PM, Simon Wood <simon.wood at bath.edu> wrote:

> Hi Fotis,
>
> Thanks for the report, and sending me the data and code (off list). The
> problem is triggered by 'ctrial' being a (one column) matrix. An immediate
> fix is
>
> data_a$ctrial <- as.numeric(data_a$ctrial)
>
> - mgcv 1.8-16 will catch the problem automatically internally.
>
> best,
> Simon
>
> On 20/09/16 17:22, Fotis Fotiadis wrote:
>
>> Hi all
>>
>> I am using the bam function of the mgcv package to model behavioral data
>> of
>> a learning experiment. To model individual variation in learning rate, I
>> am
>> testing models with (a) by-participant random intercepts of trial, (b)
>> by-participant random slopes and random intercepts of trial, and (c)
>> by-participant random smooth terms.
>>
>> While all (a) and (c) models converge, I am getting an error for every
>> possible variation of a model with random intercepts and random slopes.
>> For
>> example:
>>
>> m1.rs<-bam(acc~ 1 + igc + s(ctrial) + s(sbj, bs="re") + s(ctrial, sbj,
>> bs="re") , data=data_a, family=binomial)
>> Error in G$smooth[[i]]$first.para:G$smooth[[i]]$last.para :
>>    argument of length 0
>>
>> Any idea on what that error might be?
>>
>> Thank you in advance for your time.
>> Fotis
>>
>> P.S.: R version: 3.3.1, mgcv version: 1.8.15
>>
>>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>


-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Sep 22 22:23:18 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 22 Sep 2016 20:23:18 +0000
Subject: [R] Help with PCA data file prep and R code
In-Reply-To: <CABYg=7aPXTJnC1pGCmVdWmVT-ZKvjnaCNy0AzHmpNHg-RE9ZxQ@mail.gmail.com>
References: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
	<CABYg=7aPXTJnC1pGCmVdWmVT-ZKvjnaCNy0AzHmpNHg-RE9ZxQ@mail.gmail.com>
Message-ID: <f5c0b6ece41d4422b21d95252681aa3b@exch-2p-mbx-w2.ads.tamu.edu>

Looking at your data there are several issues.

1. Tank is an integer, but it sounds like you intend to use it as a categorical measure. If so that it should be a factor, but factors cannot be used in pca. Is Tank 10 10 times more of something than Tank 1?

2. Date is a factor. That means you are not measuring time, just the fact that 2 rows are the same time or different time. Factors cannot be used in pca.

3. Treatment is a factor, but factors cannot be used in pca.

4. Your log transformed data has many 0's and no negative values. Did you add 1 to each value before taking logarithms?

First line of your code after reading the data:

> meso.pca <- prcomp(mesocleaned, center=TRUE, scale.=TRUE)
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
>                    scale. = TRUE)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Stinson
Sent: Wednesday, September 21, 2016 10:25 AM
To: r-help at r-project.org
Subject: Re: [R] Help with PCA data file prep and R code

Hello DRUGs,
I'm new to R and would appreciate some expert advice on prepping files for,
and running, PCA...

My data set consists of aquatic invertebrate and zooplankton count data and
physicochemical measurements from an ecotoxicology study. Four chemical
treatments were applied to mesocosm tanks, 4 replicates per treatment (16
tanks total), then data were collected weekly over a 3 month period.

I cleaned the data in excel by removing columns with all zero values, and
all rows with NA values.
All zooplankton values were volume normalized, then log normalized. All
other data was log normalized in excel prior to analysis in R. All vectorss
are numeric. I've attached the .txt file to this email rather that using
dput(dataframe).

My questions are:

1. Did I do the cleaning step appropriately? I know that there are ways to
run PCA's using data that contain NA values (pcaMethods), but wasn't able
to get the code to work...
(I understand that this isn't strictly an R question, but any help would be
appreciated.)
2. Does my code look correct for the PCA and visualization (see below)?

Thanks in advance,
Sarah

#read data
mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")

#run PCA
meso.pca <- prcomp(mesocleaned,
                   center = TRUE,
                   scale. = TRUE)

# print method
print(meso.pca)

#compute standard deviation of each principal component
std_dev <- meso.pca$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:10]

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:20]

#The first principal component explains 12.7% of the variance
#The second explains 8.1%

#visualize
biplot(meso.pca)

#for visualization, make Treatment vector a factor instead of numeric
meso.treatment <- as.factor(mesocleaned[, 3])

#ggbiplot to visualize by Treatment group
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

library(devtools)
install_github("ggbiplot", "vqv")
library(ggbiplot)

print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
meso.treatment, ellipse = TRUE, circle = TRUE))
g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
              groups = meso.treatment, ellipse = TRUE,
              circle = TRUE)
g <- g + scale_color_brewer(name = deparse(substitute(Treatments)), palette
= 'Dark2') #must change meso.treatment to a factor for this to work
g <- g + theme(legend.direction = 'horizontal',
               legend.position = 'top')
print(g)

#Circle plot
#plot each variables coefficients inside a unit circle to get insight on a
possible interpretation for PCs.
#reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/

theta <- seq(0,2*pi,length.out = 100)
circle <- data.frame(x = cos(theta), y = sin(theta))
p <- ggplot(circle,aes(x,y)) + geom_path()

loadings <- data.frame(meso.pca$rotation,
                       .names = row.names(meso.pca$rotation))
p + geom_text(data=loadings,
              mapping=aes(x = PC1, y = PC2, label = .names, colour =
.names)) +
  coord_fixed(ratio=1) +
  labs(x = "PC1", y = "PC2")

On Tue, Sep 20, 2016 at 10:28 PM, Sarah Stinson <sastinson at ucdavis.edu>
wrote:

> Hello DRUGs,
> I'm new to R and would appreciate some expert advice on prepping files
> for, and running, PCA...
>
> My data set consists of aquatic invertebrate and zooplankton count data
> and physicochemical measurements from an ecotoxicology study. Four chemical
> treatments were applied to mesocosm tanks, 4 replicates per treatment (16
> tanks total), then data were collected weekly over a 3 month period.
>
> I cleaned the data in excel by removing columns with all zero values, and
> all rows with NA values.
> All zooplankton values were volume normalized, then log normalized. All
> other data was log normalized in excel prior to analysis in R. All vectorss
> are numeric. I've attached the .csv file to this email rather that using
> dput(dataframe). I hope that's acceptable.
>
> My questions are:
>
> 1. Did I do the cleaning step appropriately? I know that there are ways to
> run PCA's using data that contain NA values (pcaMethods), but wasn't able
> to get the code to work...
> (I understand that this isn't strictly an R question, but any help would
> be appreciated.)
> 2. Does my code look correct for the PCA and visualization (see below)?
>
> Thanks in advance,
> Sarah
>
> #read data
> mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")
>
> #run PCA
> meso.pca <- prcomp(mesocleaned,
>                    center = TRUE,
>                    scale. = TRUE)
>
> # print method
> print(meso.pca)
>
> #compute standard deviation of each principal component
> std_dev <- meso.pca$sdev
>
> #compute variance
> pr_var <- std_dev^2
>
> #check variance of first 10 components
> pr_var[1:10]
>
> #proportion of variance explained
> prop_varex <- pr_var/sum(pr_var)
> prop_varex[1:20]
>
> #The first principal component explains 12.7% of the variance
> #The second explains 8.1%
>
> #visualize
> biplot(meso.pca)
>
> #for visualization, make Treatment vector a factor instead of numeric
> meso.treatment <- as.factor(mesocleaned[, 3])
>
> #ggbiplot to visualize by Treatment group
> #reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>
> library(devtools)
> install_github("ggbiplot", "vqv")
> library(ggbiplot)
>
> print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
> meso.treatment, ellipse = TRUE, circle = TRUE))
> g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
>               groups = meso.treatment, ellipse = TRUE,
>               circle = TRUE)
> g <- g + scale_color_brewer(name = deparse(substitute(Treatments)),
> palette = 'Dark2') #must change meso.treatment to a factor for this to work
> g <- g + theme(legend.direction = 'horizontal',
>                legend.position = 'top')
> print(g)
>
> #Circle plot
> #plot each variables coefficients inside a unit circle to get insight on a
> possible interpretation for PCs.
> #reference: https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>
> theta <- seq(0,2*pi,length.out = 100)
> circle <- data.frame(x = cos(theta), y = sin(theta))
> p <- ggplot(circle,aes(x,y)) + geom_path()
>
> loadings <- data.frame(meso.pca$rotation,
>                        .names = row.names(meso.pca$rotation))
> p + geom_text(data=loadings,
>               mapping=aes(x = PC1, y = PC2, label = .names, colour =
> .names)) +
>   coord_fixed(ratio=1) +
>   labs(x = "PC1", y = "PC2")
>
>

From S.Ellison at LGCGroup.com  Fri Sep 23 00:35:23 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 22 Sep 2016 23:35:23 +0100
Subject: [R] [R-pkg-devel] doc url to vignette
In-Reply-To: <c74b78f5-9c43-d00e-f6fe-de9a7b6b1b82@gmail.com>
References: <DB5PR0401MB19905F1EED03C60CB43D107AD5F70@DB5PR0401MB1990.eurprd04.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FE6774B7@GBTEDVPEXCMB04.corp.lgc-group.com>
	<c74b78f5-9c43-d00e-f6fe-de9a7b6b1b82@gmail.com>
Message-ID: <B863C2A1FDD75D49AB58DDFD865FA1AE5EF484131D@GBTEDVPEXCMB04.corp.lgc-group.com>

> In other words, try to mislead CRAN.  

Well, no. The thought was that if CRAN has agreed an exception, as Uwe had indicated, you might want a simpler way of maintaining it than discussing it on every update.

I can see that that would sidestep an enforced regular review, though.

Keep up the good work; it is much appreciated.

Steve E

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From pdalgd at gmail.com  Fri Sep 23 01:52:52 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 23 Sep 2016 01:52:52 +0200
Subject: [R] Memory not release when an environment is created
In-Reply-To: <alpine.OSX.2.20.1609221420080.11459@lukes-macbook-air.local>
References: <CAOO9HP02Uc1auuMoJVUSw0Gib1Yed3vq85Gjitgf54Sd66Qo5w@mail.gmail.com>
	<CAF8bMcZcoH47ais37jy3QiTD3aWmYEsx91arO3B8GJYxJfCqqg@mail.gmail.com>
	<alpine.OSX.2.20.1609221358300.11459@lukes-macbook-air.local>
	<alpine.OSX.2.20.1609221420080.11459@lukes-macbook-air.local>
Message-ID: <A1B87F09-B040-4490-A9EC-BBFAAFDE6220@gmail.com>


> On 22 Sep 2016, at 21:24 , luke-tierney at uiowa.edu wrote:
> 
> On Thu, 22 Sep 2016, luke-tierney at uiowa.edu wrote:
> 
>> My preference is to use a top level function in the package or global
>> env that takes as arguments just the variables I want in the parent
>> frame. That avoids the explicit environment manipulations. Here that
>> would be
>> 
>>> makeFunc0 <- function(xmin, xmax)
>>     function(y) (y - xmin) / (xmax - xmin)
>> 
> 
> But I do keep forgetting the need to force the parameters if you don't
> want a big value to stick around until the returned function is used
> the first time,

...not to mention the pains that arise if the makeFunc0 gets called with argument expressions that involve items that may change before the first call of the returned function.

> so a better definition of makeFUnc0 is
> 
> makeFunc0 <- function(xmin, xmax) {
>    force(xmin)
>    force(xmax)
>    function(y) (y - xmin) / (xmax - xmin)
> }
> 
> Best,
> 
> luke
> 
>>> makeFunc1 <- function(x)
>>     makeFunc0(min(x), max(x))
>> 
>>> f <- makeFunc1(1:1e8)
>>> ls.str(all=TRUE, environment(f))
>> xmax :  int 100000000
>> xmin :  int 1
>>> parent.env(environment(f))
>> <environment: R_GlobalEnv>
>>> f(c(1234567, 2345678))
>> [1] 0.01234566 0.02345677
>> 
>> Best,
>> 
>> luke
>> 
>> 
>> On Thu, 22 Sep 2016, William Dunlap via R-help wrote:
>> 
>>> I like to have my function-returning functions use new.env(parent=XXX)
>>> to make an environment for the returned function and put into it only
>>> the objects needed by the function.  The 'XXX' should be a an environment
>>> which will hang around anyway.  It could be globalenv(), but if your
>>> function
>>> is in a package, as.environment(paste0("package:", .packageName))
>>> would work well.  The later ensures the your returned function has access
>>> to all the other functions in that package.
>>> E.g.,
>>>> makeFunc1 <- function(x) {
>>>   envir <- new.env(parent = environment(sys.function()))
>>>   envir$xmax <- max(x)
>>>   envir$xmin <- min(x)
>>>   with(envir, function(y) (y - xmin) / (xmax - xmin))
>>> }
>>>> f <- makeFunc1(1:1e8)
>>>> ls.str(all=TRUE, environment(f))
>>> xmax :  int 100000000
>>> xmin :  int 1
>>>> parent.env(environment(f))
>>> <environment: R_GlobalEnv>
>>>> f(c(1234567, 2345678))
>>> [1] 0.01234566 0.02345677
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> On Thu, Sep 22, 2016 at 8:41 AM, Olivier Merle <oliviermerle35 at gmail.com>
>>> wrote:
>>>> Dear,
>>>> When I use big data for a temporary use it seems that the memory is not
>>>> released when a function/environement is created nearby.
>>>> Here the reproducible exemple:
>>>> test<-function(){
>>>> x=matrix(0,50000,10000)
>>>> y=function(nb) nb^2
>>>> return(y)
>>>> }
>>>> xx=test() # 3 Go of Ram is used
>>>> gc() # Memory is not released !! even if x has been destroyed [look into
>>>> software mem used]
>>>> format(object.size(xx),units="auto") # 1.4 KiB => R is worng on the size
>>>> of
>>>> the object
>>>> rm(xx)
>>>> gc() # Memory is released
>>>> ## Classic
>>>> test2<-function(){
>>>> x=matrix(0,50000,10000)
>>>> y=1
>>>> return(y)
>>>> }
>>>> xx=test2() # Memory is used
>>>> gc() # => Memory is released
>>>> How can I release the data in test without destroying the xx object ? As x
>>>> which is big object is destroyed, I though I could get my memory back but
>>>> it seems that the function y is keeping the x object.
>>>> Best
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 	[[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> -- 
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>   Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sabasehrish at yahoo.com  Fri Sep 23 04:27:57 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Fri, 23 Sep 2016 02:27:57 +0000 (UTC)
Subject: [R] Replacing value with "1"
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
Message-ID: <593128637.115496.1474597677212@mail.yahoo.com>

Hi

I have a matrix that contains 1565 rows and 132 columns. All the observations are either "0" or "1". Now I want to keep all the observations same but just one change, i.e. whenever there is "1", the very next value in the same row should become "1". Please see below as a sample:

>df

     0    0    1    0    0
    NA    0    1    1    0
     0    1    0    0    NA

What I want is:


    0    0    1    1    0
   NA    0    1    1    1
    0    1    1    0    NA



I shall be thankful for the reply.


Saba


From rmh at temple.edu  Fri Sep 23 04:55:40 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 22 Sep 2016 22:55:40 -0400
Subject: [R] Replacing value with "1"
In-Reply-To: <593128637.115496.1474597677212@mail.yahoo.com>
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
	<593128637.115496.1474597677212@mail.yahoo.com>
Message-ID: <CAGx1TMBvQNbB-qijzrqM_45FhFOckTv7pPTvP=rJifz5UT_rSQ@mail.gmail.com>

tmpf <- function(x) {
  n <- length(x)
  indices <- which(match(x,1) == 1)
  x[indices+1] <- 1
  x[1:n]  ## needed for the case when the last item in a row has value 1
}

tmp <- matrix(c(0,0,1,0,0,
                NA,0,1,1,0,
                0,1,0,0,NA,
                1,0,1,0,1), ## last item in row has value 1
              byrow=TRUE, 4, 5)

tmp

t(apply(tmp, 1, tmpf))

On Thu, Sep 22, 2016 at 10:27 PM, Saba Sehrish via R-help
<r-help at r-project.org> wrote:
> Hi
>
> I have a matrix that contains 1565 rows and 132 columns. All the observations are either "0" or "1". Now I want to keep all the observations same but just one change, i.e. whenever there is "1", the very next value in the same row should become "1". Please see below as a sample:
>
>>df
>
>      0    0    1    0    0
>     NA    0    1    1    0
>      0    1    0    0    NA
>
> What I want is:
>
>
>     0    0    1    1    0
>    NA    0    1    1    1
>     0    1    1    0    NA
>
>
>
> I shall be thankful for the reply.
>
>
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Sep 23 05:13:35 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 23 Sep 2016 13:13:35 +1000
Subject: [R] Replacing value with "1"
In-Reply-To: <593128637.115496.1474597677212@mail.yahoo.com>
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
	<593128637.115496.1474597677212@mail.yahoo.com>
Message-ID: <CA+8X3fVH_AgGqbj8AK6YrbApzGsr9+RgYkWHpXfQFKmLHSy=zA@mail.gmail.com>

Hi Saba,
Try this:

df<-matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA),nrow=3)
dimdf<-dim(df)
df1<-df==1
df[cbind(rep(FALSE,dimdf[1]),df1[,-dimdf[2]])]<-1

Jim



On Fri, Sep 23, 2016 at 12:27 PM, Saba Sehrish via R-help
<r-help at r-project.org> wrote:
> Hi
>
> I have a matrix that contains 1565 rows and 132 columns. All the observations are either "0" or "1". Now I want to keep all the observations same but just one change, i.e. whenever there is "1", the very next value in the same row should become "1". Please see below as a sample:
>
>>df
>
>      0    0    1    0    0
>     NA    0    1    1    0
>      0    1    0    0    NA
>
> What I want is:
>
>
>     0    0    1    1    0
>    NA    0    1    1    1
>     0    1    1    0    NA
>
>
>
> I shall be thankful for the reply.
>
>
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Fri Sep 23 08:19:46 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 22 Sep 2016 23:19:46 -0700
Subject: [R] Replacing value with "1"
In-Reply-To: <CA+8X3fVH_AgGqbj8AK6YrbApzGsr9+RgYkWHpXfQFKmLHSy=zA@mail.gmail.com>
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
	<593128637.115496.1474597677212@mail.yahoo.com>
	<CA+8X3fVH_AgGqbj8AK6YrbApzGsr9+RgYkWHpXfQFKmLHSy=zA@mail.gmail.com>
Message-ID: <CAFDcVCTXub_mXLYrAb_tMZs97HFRv0m591X7=VWpHOH3c-Qs5Q@mail.gmail.com>

which(df == 1, arr.ind=TRUE) is useful here:

> df <- matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA), nrow=3)
> df
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    1    0    0
[2,]   NA    0    1    1    0
[3,]    0    1    0    0   NA

> ## Identify (row,col) indices for 1:s
> idxs <- which(df == 1, arr.ind=TRUE)
> idxs
     row col
[1,]   3   2
[2,]   1   3
[3,]   2   3
[4,]   2   4

> ## Drop any in the last column
> idxs <- idxs[idxs[,"col"] < ncol(df), , drop=FALSE]
> idxs
     row col
[1,]   3   2
[2,]   1   3
[3,]   2   3
[4,]   2   4

> idxs[,"col"] <- idxs[,"col"] + 1L
> idxs
     row col
[1,]   3   3
[2,]   1   4
[3,]   2   4
[4,]   2   5

> df[idxs] <- 1
> df
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    1    1    0
[2,]   NA    0    1    1    1
[3,]    0    1    1    0   NA

/Henrik

On Thu, Sep 22, 2016 at 8:13 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Saba,
> Try this:
>
> df<-matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA),nrow=3)
> dimdf<-dim(df)
> df1<-df==1
> df[cbind(rep(FALSE,dimdf[1]),df1[,-dimdf[2]])]<-1
>
> Jim
>
>
>
> On Fri, Sep 23, 2016 at 12:27 PM, Saba Sehrish via R-help
> <r-help at r-project.org> wrote:
>> Hi
>>
>> I have a matrix that contains 1565 rows and 132 columns. All the observations are either "0" or "1". Now I want to keep all the observations same but just one change, i.e. whenever there is "1", the very next value in the same row should become "1". Please see below as a sample:
>>
>>>df
>>
>>      0    0    1    0    0
>>     NA    0    1    1    0
>>      0    1    0    0    NA
>>
>> What I want is:
>>
>>
>>     0    0    1    1    0
>>    NA    0    1    1    1
>>     0    1    1    0    NA
>>
>>
>>
>> I shall be thankful for the reply.
>>
>>
>> Saba
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From schubert.seb at gmail.com  Fri Sep 23 11:25:07 2016
From: schubert.seb at gmail.com (Sebastian Schubert)
Date: Fri, 23 Sep 2016 11:25:07 +0200
Subject: [R] R_LIBS_SITE in Renviron ignored (?)
Message-ID: <CAMVMZDCYF-0=M_U6R-NS0U0_Aq9XYG4vcWrPevys0kzQAzxB=Q@mail.gmail.com>

Hi all,

I am on CentOS 7.2 (Linux x86_64) with R from EPEL.

Maybe I get the documentation wrong but it seems, the variable
R_LIBS_SITE in Renviron is ignored while, for example, R_LIBS_USER is
not.

What R tells me:

R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
...
Platform: x86_64-redhat-linux-gnu (64-bit)
...
> .libPaths()
[1] "/usr/lib64/R/library" "/usr/share/R/library"
> .Library
[1] "/usr/lib64/R/library"
> .Library.site
[1] "/usr/lib64/R/library" "/usr/share/R/library"
> R.home(component = "home")
[1] "/usr/lib64/R"

However, the respective Renviron includes the following:
# grep R_LIBS_SITE /usr/lib64/R/etc/Renviron
R_LIBS_SITE=${R_LIBS_SITE-'/usr/local/lib/R/site-library:/usr/local/lib/R/library:/usr/lib64/R/library:/usr/share/R/library'}

Apparently, this setting is not applied when I start R. However,
changes for example in R_LIBS_USER in the same file are applied, thus
the file must be read...

I don't see where R_LIBS_SITE could be overwritten elsewhere. I get
the same behaviour in R when I start it with

R --no-environ --no-site-file --no-init-file

Any idea?

Thanks a lot,
Sebastian


From acefix at rocketmail.com  Thu Sep 22 23:02:20 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 22 Sep 2016 21:02:20 +0000 (UTC)
Subject: [R] how to pass multiple pattern varibles to grep()
References: <1596082082.3041347.1474578140499.ref@mail.yahoo.com>
Message-ID: <1596082082.3041347.1474578140499@mail.yahoo.com>

Hello, there,
My patterns are defined by variables, for example:z="h"v="x"
I have a vector: 
a=c("th","mx","t")
I would like to find elements in vector a that contain either "h", or "x"
grep("h|x", a) apparently works. However, when I tried: grep(z|v,a), it did not work. Can anyone help how to handle such situation?
Thanks.
Ace 

    On Wednesday, March 18, 2015 5:52 PM, Fix Ace <acefix at rocketmail.com> wrote:
 

 Thank you very much!
I do need to learn more about R!! 


     On Tuesday, March 17, 2015 9:26 PM, William Dunlap <wdunlap at tibco.com> wrote:
   

 Fix Ace wrote?? ?What is the default "n"?
512:? ?> length(density(rnorm(10^6))$x)? ?[1] 512? ?> args(density.default)? ?function (x, bw = "nrd0", adjust = 1, kernel = c("gaussian",?? ? ? ?"epanechnikov", "rectangular", "triangular", "biweight",?? ? ? ?"cosine", "optcosine"), weights = NULL, window = kernel,?? ? ? ?width, give.Rkern = FALSE, n = 512, from, to, cut = 3, na.rm = FALSE,?? ? ? ?...)? ?NULL? ?> ?density # or ?density.default, should also tell you about its meaning

Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Tue, Mar 17, 2015 at 7:02 PM, Fix Ace <acefix at rocketmail.com> wrote:

Thank you for the email.
What is the default "n"?
Thanks! 


     On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
   

 Increasing the value of 'n' given to density will give an estimate at more points so it will look smoother.? Try n=2^18.
Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:



?I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to examine only small range of data, I found that the plot was not smooth (as shown below):
plot(density(test$V2), xlim=c(0,1000))


?Is there away to make it smoother?
Thanks a lot!!

?


?



? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   



   

   
	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Fri Sep 23 00:40:33 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 23 Sep 2016 04:10:33 +0530
Subject: [R] MLE Estimation in Extreme Value Approach to VaR (using Frechet
	distribution)
Message-ID: <CAHVFrXGAsVAuMftCyuxj1iCS_Uv6-2w9qUePMszEC6SpP-sxKg@mail.gmail.com>

Hi R-Users,

I am trying to estimate 95%-le VaR (Value-at-Risk) of a portfolio using
Extreme Value Theory. In particular, I'll use the Frechet distribution
(heavy left tail),

I have data on percentage returns ( R_t) for T = 5000 past dates. This data
has been divided into g = 50 non-overlapping periods of size n = 100 each
and we compute the minimum return r_i over each period (i = 1,2,3,....,50)

Firstly, I need to estimate, by maximum likelihood approach, the 3 unknown
parameters:  a (scale), b (shift) and alpha = -1/k (tail index)
 Interpretation: *(r_i - b)/a*  converges to the *Frechet distribution*,
which is given by: *F*(x) = 1 - exp[ -( 1+kx )^(1/k) ]*


 The likelihood (to be maximized wrt a,b and k ) is given by: L = f(r_1) *
f(r_2) *......*f(r_g),
 where *f(r_i)  =  (1/a) * [ 1 + k*m_i ]^(-1+ 1/k) * exp[- ( 1 +
k*m_i)^(1/k) ]*  i = 1,2,3,.....g
 Here, as a short-hand, I have used m_i = (r_i - b)/a

My question is: this ML-estimation by differentiating L is going to be
extremely messy and the data may be poorly-conditioned (eg, the returns
data may be positive, negative and of very small magnitude [~ 10^(-5) to
10^(-3) ].)
Wanted your help in performing this estimation process efficiently.

As a wrap, the 95%-le VaR would finally come to *VaR = b - (a/k) * [ 1 -
{-n*log(0.95)}^k ]*, but of course, I need to plug in the estimated a,b and
k values here.

Any help will be sincerely appreciated.
(For details, you can use Section 7.5.2 & 7.6 of '*Analysis of Financial
Time Series*' by Ruey S.Tsay -2nd edition)


- -
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From noguchi.japan at gmail.com  Fri Sep 23 11:15:31 2016
From: noguchi.japan at gmail.com (Yoshikazu Noguchi)
Date: Fri, 23 Sep 2016 18:15:31 +0900
Subject: [R] R Help: System Identification for First order delay and dead
	time with TF model
Message-ID: <000201d2157b$0a3175e0$1e9461a0$@gmail.com>

Hello,

 

May I ask your help?

 

I would like to do System Identification using time series data which has
transport delay. 

First of all, I would like to identify the following parameters (K, Tau, TD)
for SISO case in the following Laplace domain equation: 

K, Tau, TD:   ymodel = (K/(Tau*s +1)) * exp(-TD*s) 

I have time series data, y (Process output) and U (process input). 

 

Object function: Min ( (y-ymodel)^2) 

 

I failed to find the right package in R for this issue? Could you please
tell me which package I should use to solve this issue?

 

Thanks. 

 

Y. Noguchi


	[[alternative HTML version deleted]]


From anmhuerfanoba at unal.edu.co  Fri Sep 23 16:07:18 2016
From: anmhuerfanoba at unal.edu.co (Andrea Marcela Huerfano Barbosa)
Date: Fri, 23 Sep 2016 09:07:18 -0500
Subject: [R] How to construct a double-entry with variables from a dataset
Message-ID: <CAGTB1-zjWKfEs-2ZsOFnos9GT_JNTsKKfVX55Edu4YO+YhtxaA@mail.gmail.com>

Hi everyone,
My name is Marcela, I am bachelor student of statistics.
I have a data frame with 59 variables and two of them are categorical  and
 have three levels each one,  I would like to construct a double -entry
table with this variables, I mean the categorical ones.

Any help will be really thankful

Thanks for reading
Andrea Marcela
--

	[[alternative HTML version deleted]]


From t.fioravanti at pm.univpm.it  Fri Sep 23 16:54:31 2016
From: t.fioravanti at pm.univpm.it (FIORAVANTI TATIANA)
Date: Fri, 23 Sep 2016 14:54:31 +0000
Subject: [R] Problem Mixstock in R
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA2766309B0818@WAXMXOLYMB025.WAX.wa.lcl>
References: <DB5PR04MB206943D53AACC21A4152F0EEAEF40@DB5PR04MB2069.eurprd04.prod.outlook.com>
	<521cd70c-58bc-6751-9d43-ad0b27ec6e1b@yahoo.fr>,
	<F7E6D18CC2877149AB5296CE54EA2766309B0818@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <DB5PR04MB20696594796C22A95F7C1773AEC80@DB5PR04MB2069.eurprd04.prod.outlook.com>

I know that currently the Mixstock package is not available on CRAN, I have downloaded the Mixstock v.0.9.5.1 from CRAN's archive, but this version is not supported by R v.3.3.1, for this reason I have used an older version of R (v. 2.14). I have followed, without any problems, all the passages described in "Mixed stock analysis in R: getting started with the mixstock package" (2012), and I performed my mixed stock analysis used the MCMC. At the end of the analysis I would get all the statistical results (mean, standard deviation, median, 2.5 and 97.5 percentile, etc). I have read on the manual of the package mixstock v.0.9.5.1 that the mysum() function could be useful to calculate summary statistics of one or more columns of MCMC output, but I am not able to set it correctly because I do not understand which are the arguments of the functions ("x" and "names"). I tried with: mysum(mydata.mcmc, myvec = NULL) where "mydata.mcmc" is the result of the mixed stock analysis with MCMC and "myvec" is a vector that contain all the column names but I obtained only an error message. Following your instructions I wrote to the maintener of the package and I hope for an answer, but if someone could help me it would be great.


Thank you so much

Tatiana


________________________________
Da: R-help <r-help-bounces at r-project.org> per conto di Nordlund, Dan (DSHS/RDA) <NordlDJ at dshs.wa.gov>
Inviato: mercoled? 21 settembre 2016 22.33
A: r-help at r-project.org
Oggetto: Re: [R] Problem Mixstock in R

Googling "mixstock CRAN" I found the following:

Package 'mixstock' was removed from the CRAN repository.
Formerly available versions can be obtained from the archive.
Archived on 2014-08-30 as long-term memory-access errors were not corrected.


You might want to contact the maintainer of the package directly with your questions.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Girondot via R-help
> Sent: Wednesday, September 21, 2016 12:18 PM
> To: r-help at r-project.org; t.fioravanti at pm.univpm.it
> Subject: Re: [R] Problem Mixstock in R
>
> Le 19/09/2016 ? 10:53, FIORAVANTI TATIANA a ?crit :
> > Dear members of the R-project
> >
> > I am doing a mixed stock analysis with the Mixstock Package in R, at
> > the end of the analysis I would summarize all my results (mean,
> > standard deviation, median, percentile, etc...) using the mysum(x,
> > name=NULL) function, but I don't understand which is the correct
> > manner to set up it, what "x" and "name"are? ..Can you help me? Thank
> > you very much,
> >
> > Tatiana
> >
> Dear Tatiana,
>
> First: I don't find the Mixstock package in CRAN. You should indicate how to
> install it.
> Second: I don't find anywhere a function mysum(). Is it part of the Mixstock
> package?
> Third: Send a reproducible exemple to show what you tried to use the
> function.
>
> Finaly you should read the posting guide in this list to have more chance to
> have answers.
>
> Sincerely,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Sep 23 17:22:20 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 23 Sep 2016 16:22:20 +0100
Subject: [R] How to construct a double-entry with variables from a
	dataset
In-Reply-To: <CAGTB1-zjWKfEs-2ZsOFnos9GT_JNTsKKfVX55Edu4YO+YhtxaA@mail.gmail.com>
References: <CAGTB1-zjWKfEs-2ZsOFnos9GT_JNTsKKfVX55Edu4YO+YhtxaA@mail.gmail.com>
Message-ID: <c7a003f3-0d6f-728d-440f-57720c329aaa@dewey.myzen.co.uk>

Dear Marcela

Can you clarify what you mean by a double entry table?

On 23/09/2016 15:07, Andrea Marcela Huerfano Barbosa wrote:
> Hi everyone,
> My name is Marcela, I am bachelor student of statistics.
> I have a data frame with 59 variables and two of them are categorical  and
>  have three levels each one,  I would like to construct a double -entry
> table with this variables, I mean the categorical ones.
>
> Any help will be really thankful
>
> Thanks for reading
> Andrea Marcela
> --
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ruipbarradas at sapo.pt  Fri Sep 23 17:26:31 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 23 Sep 2016 16:26:31 +0100
Subject: [R] How to construct a double-entry with variables from a
 dataset
In-Reply-To: <CAGTB1-zjWKfEs-2ZsOFnos9GT_JNTsKKfVX55Edu4YO+YhtxaA@mail.gmail.com>
Message-ID: <20160923162631.Horde.45odu2ZumiH6FS17NYErGXY@mail.sapo.pt>

Hello,

Is this what you mean?

dat <- data.frame(x = rnorm(100), A = factor(sample(3, 100, TRUE)), B  
= factor(sample(3, 100, TRUE)))
xtabs(~ A + B, dat)


Hope this helps,

Rui Barradas


Citando Andrea Marcela Huerfano Barbosa <anmhuerfanoba at unal.edu.co>:

> Hi everyone,
> My name is Marcela, I am bachelor student of statistics.
> I have a data frame with 59 variables and two of them are categorical  and
>  have three levels each one,  I would like to construct a double -entry
> table with this variables, I mean the categorical ones.
>
> Any help will be really thankful
>
> Thanks for reading
> Andrea Marcela
> --
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From emammendes at gmail.com  Fri Sep 23 17:44:22 2016
From: emammendes at gmail.com (Eduardo M. A. M. Mendes)
Date: Fri, 23 Sep 2016 12:44:22 -0300
Subject: [R] R Help: System Identification for First order delay and
	dead time with TF model
In-Reply-To: <000201d2157b$0a3175e0$1e9461a0$@gmail.com>
References: <000201d2157b$0a3175e0$1e9461a0$@gmail.com>
Message-ID: <572F900B-6649-4044-ACB9-2915192C33D6@gmail.com>

Hi 

This is a continuous time system.  Are you willing to discretize the model?  

Regards 

Ed

Enviado do meu iPhone

> Em 23 de set de 2016, ?s 06:15, Yoshikazu Noguchi <noguchi.japan at gmail.com> escreveu:
> 
> Hello,
> 
> 
> 
> May I ask your help?
> 
> 
> 
> I would like to do System Identification using time series data which has
> transport delay. 
> 
> First of all, I would like to identify the following parameters (K, Tau, TD)
> for SISO case in the following Laplace domain equation: 
> 
> K, Tau, TD:   ymodel = (K/(Tau*s +1)) * exp(-TD*s) 
> 
> I have time series data, y (Process output) and U (process input). 
> 
> 
> 
> Object function: Min ( (y-ymodel)^2) 
> 
> 
> 
> I failed to find the right package in R for this issue? Could you please
> tell me which package I should use to solve this issue?
> 
> 
> 
> Thanks. 
> 
> 
> 
> Y. Noguchi
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Sep 23 18:25:25 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 23 Sep 2016 09:25:25 -0700 (PDT)
Subject: [R] Replacing value with "1"
In-Reply-To: <CAFDcVCTXub_mXLYrAb_tMZs97HFRv0m591X7=VWpHOH3c-Qs5Q@mail.gmail.com>
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
	<593128637.115496.1474597677212@mail.yahoo.com>
	<CA+8X3fVH_AgGqbj8AK6YrbApzGsr9+RgYkWHpXfQFKmLHSy=zA@mail.gmail.com>
	<CAFDcVCTXub_mXLYrAb_tMZs97HFRv0m591X7=VWpHOH3c-Qs5Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1609230923140.12422@pedal.dcn.davis.ca.us>

Another approach using in-place replacement and thinking with matrix 
operations instead of vector operations:

DF <- matrix( c( 0,  0, 1, 0, 0
                , NA, 0, 1, 1, 0
                , 0,  1, 0, 0, NA )
             , byrow=TRUE
             , nrow=3 )
DF2 <- DF
DF2[ , -1 ] <- ifelse(   !is.na( DF[ , -ncol( DF ) ] )
                        & 1 == DF[ , -ncol( DF ) ]
                      , 1
                      , DF[ , -1 ]
                      )

On Thu, 22 Sep 2016, Henrik Bengtsson wrote:

> which(df == 1, arr.ind=TRUE) is useful here:
>
>> df <- matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA), nrow=3)
>> df
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    0    0    1    0    0
> [2,]   NA    0    1    1    0
> [3,]    0    1    0    0   NA
>
>> ## Identify (row,col) indices for 1:s
>> idxs <- which(df == 1, arr.ind=TRUE)
>> idxs
>     row col
> [1,]   3   2
> [2,]   1   3
> [3,]   2   3
> [4,]   2   4
>
>> ## Drop any in the last column
>> idxs <- idxs[idxs[,"col"] < ncol(df), , drop=FALSE]
>> idxs
>     row col
> [1,]   3   2
> [2,]   1   3
> [3,]   2   3
> [4,]   2   4
>
>> idxs[,"col"] <- idxs[,"col"] + 1L
>> idxs
>     row col
> [1,]   3   3
> [2,]   1   4
> [3,]   2   4
> [4,]   2   5
>
>> df[idxs] <- 1
>> df
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    0    0    1    1    0
> [2,]   NA    0    1    1    1
> [3,]    0    1    1    0   NA
>
> /Henrik
>
> On Thu, Sep 22, 2016 at 8:13 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Saba,
>> Try this:
>>
>> df<-matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA),nrow=3)
>> dimdf<-dim(df)
>> df1<-df==1
>> df[cbind(rep(FALSE,dimdf[1]),df1[,-dimdf[2]])]<-1
>>
>> Jim
>>
>>
>>
>> On Fri, Sep 23, 2016 at 12:27 PM, Saba Sehrish via R-help
>> <r-help at r-project.org> wrote:
>>> Hi
>>>
>>> I have a matrix that contains 1565 rows and 132 columns. All the observations are either "0" or "1". Now I want to keep all the observations same but just one change, i.e. whenever there is "1", the very next value in the same row should become "1". Please see below as a sample:
>>>
>>>> df
>>>
>>>      0    0    1    0    0
>>>     NA    0    1    1    0
>>>      0    1    0    0    NA
>>>
>>> What I want is:
>>>
>>>
>>>     0    0    1    1    0
>>>    NA    0    1    1    1
>>>     0    1    1    0    NA
>>>
>>>
>>>
>>> I shall be thankful for the reply.
>>>
>>>
>>> Saba
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Fri Sep 23 18:34:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 23 Sep 2016 09:34:38 -0700 (PDT)
Subject: [R] how to pass multiple pattern varibles to grep()
In-Reply-To: <1596082082.3041347.1474578140499@mail.yahoo.com>
References: <1596082082.3041347.1474578140499.ref@mail.yahoo.com>
	<1596082082.3041347.1474578140499@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1609230927420.12422@pedal.dcn.davis.ca.us>

The | symbol has a completely different meaning in R syntax than it has in 
regular expression syntax. R hands of pattern strings to the regex library 
without looking inside the strings any more than it has to. Likewise, the 
regex library has no clue about R syntax. Your attempt failed to create a 
character string for grep to give to the regex library. To do that read 
?paste.

grep( paste( z, v, sep = "|" ), a )

On Thu, 22 Sep 2016, Fix Ace via R-help wrote:

> Hello, there,
> My patterns are defined by variables, for example:z="h"v="x"
> I have a vector: 
> a=c("th","mx","t")
> I would like to find elements in vector a that contain either "h", or "x"
> grep("h|x", a) apparently works. However, when I tried: grep(z|v,a), it did not work. Can anyone help how to handle such situation?
> Thanks.
> Ace 
>
>    On Wednesday, March 18, 2015 5:52 PM, Fix Ace <acefix at rocketmail.com> wrote:
> 
>
> Thank you very much!
> I do need to learn more about R!! 
>
>
>     On Tuesday, March 17, 2015 9:26 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
>
> Fix Ace wrote?? ?What is the default "n"?
> 512:? ?> length(density(rnorm(10^6))$x)? ?[1] 512? ?> args(density.default)? ?function (x, bw = "nrd0", adjust = 1, kernel = c("gaussian",?? ? ? ?"epanechnikov", "rectangular", "triangular", "biweight",?? ? ? ?"cosine", "optcosine"), weights = NULL, window = kernel,?? ? ? ?width, give.Rkern = FALSE, n = 512, from, to, cut = 3, na.rm = FALSE,?? ? ? ?...)? ?NULL? ?> ?density # or ?density.default, should also tell you about its meaning
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> On Tue, Mar 17, 2015 at 7:02 PM, Fix Ace <acefix at rocketmail.com> wrote:
>
> Thank you for the email.
> What is the default "n"?
> Thanks! 
>
>
>     On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
>
> Increasing the value of 'n' given to density will give an estimate at more points so it will look smoother.? Try n=2^18.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:
>
>
>
> ?I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to examine only small range of data, I found that the plot was not smooth (as shown below):
> plot(density(test$V2), xlim=c(0,1000))
>
>
> ?Is there away to make it smoother?
> Thanks a lot!!
>
> ?
>
>
> ?
>
>
>
> ? 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> 
>
>
>
> 
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From bgunter.4567 at gmail.com  Fri Sep 23 18:59:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Sep 2016 09:59:31 -0700
Subject: [R] how to pass multiple pattern varibles to grep()
In-Reply-To: <alpine.BSF.2.00.1609230927420.12422@pedal.dcn.davis.ca.us>
References: <1596082082.3041347.1474578140499.ref@mail.yahoo.com>
	<1596082082.3041347.1474578140499@mail.yahoo.com>
	<alpine.BSF.2.00.1609230927420.12422@pedal.dcn.davis.ca.us>
Message-ID: <CAGxFJbSTYnLa5UcTMkfGpAMy22jz3XiUZWF4RR8wBukxSNXnXg@mail.gmail.com>

"The | symbol has a completely different meaning in R syntax than it
has in regular expression syntax."

Well, actually it doesn't -- loosely speaking, they both mean "or" (ok
-- interpreting concatenation as "or" is a bit of a stretch). Perhaps
to clarify your statement (stop here if none is needed!):

1) z|v  is an R expression that evaluates to the disjunction of the
values of objects z and v, which should be logical (and will be
coerced to logicals if needed and possible). That is, the result is
logical,

2) paste(z,v, sep = "|") evaluates to a character string which is the
concatenation of character string values of z and v with "|" in the
middle. regex needs character strings to define its patterns.

Clear?

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 23, 2016 at 9:34 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The | symbol has a completely different meaning in R syntax than it has in
> regular expression syntax. R hands of pattern strings to the regex library
> without looking inside the strings any more than it has to. Likewise, the
> regex library has no clue about R syntax. Your attempt failed to create a
> character string for grep to give to the regex library. To do that read
> ?paste.
>
> grep( paste( z, v, sep = "|" ), a )
>
>
> On Thu, 22 Sep 2016, Fix Ace via R-help wrote:
>
>> Hello, there,
>> My patterns are defined by variables, for example:z="h"v="x"
>> I have a vector: a=c("th","mx","t")
>> I would like to find elements in vector a that contain either "h", or "x"
>> grep("h|x", a) apparently works. However, when I tried: grep(z|v,a), it
>> did not work. Can anyone help how to handle such situation?
>> Thanks.
>> Ace
>>    On Wednesday, March 18, 2015 5:52 PM, Fix Ace <acefix at rocketmail.com>
>> wrote:
>>
>>
>> Thank you very much!
>> I do need to learn more about R!!
>>
>>     On Tuesday, March 17, 2015 9:26 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>
>> Fix Ace wrote    What is the default "n"?
>> 512:   > length(density(rnorm(10^6))$x)   [1] 512   >
>> args(density.default)   function (x, bw = "nrd0", adjust = 1, kernel =
>> c("gaussian",        "epanechnikov", "rectangular", "triangular",
>> "biweight",        "cosine", "optcosine"), weights = NULL, window = kernel,
>> width, give.Rkern = FALSE, n = 512, from, to, cut = 3, na.rm = FALSE,
>> ...)   NULL   > ?density # or ?density.default, should also tell you about
>> its meaning
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> On Tue, Mar 17, 2015 at 7:02 PM, Fix Ace <acefix at rocketmail.com> wrote:
>>
>> Thank you for the email.
>> What is the default "n"?
>> Thanks!
>>
>>     On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>
>> Increasing the value of 'n' given to density will give an estimate at more
>> points so it will look smoother.  Try n=2^18.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:
>>
>>
>>
>>  I have a dataset with 6187 elements, ranged from 3 to 104028. When I
>> tried to examine only small range of data, I found that the plot was not
>> smooth (as shown below):
>> plot(density(test$V2), xlim=c(0,1000))
>>
>>
>>  Is there away to make it smoother?
>> Thanks a lot!!
>>
>>
>>
>>
>>
>>
>>
>>
>>   ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jstewart at provplan.org  Fri Sep 23 20:42:40 2016
From: jstewart at provplan.org (Joel Stewart)
Date: Fri, 23 Sep 2016 18:42:40 +0000
Subject: [R] R freezing issue when checking to see if variable belongs to
 two different vectors
Message-ID: <3C5C4EB2DF3179418F241E4C2147F2AB25667744@TPPExch2K10.tpp.local>

I often find myself trying to get a quick assessment of how much of one vector is inside of another vector. I almost always try this with variables that are some sort of identifier, like a client id number or an SSN. I typically do this:

table( DF1$Identifier %in% DF2$Identifier)

This will return a count of True and False logical responses. However, sometimes when I try to do this my computer will freeze and I am unable to stop or escape the process, requiring me to shutdown R via the task manager. I was wondering if anybody else experiences this and, if so, why this might be happening.

Thanks in advance,

Joel


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Sep 23 23:40:51 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Sep 2016 14:40:51 -0700
Subject: [R] R freezing issue when checking to see if variable belongs
 to two different vectors
In-Reply-To: <3C5C4EB2DF3179418F241E4C2147F2AB25667744@TPPExch2K10.tpp.local>
References: <3C5C4EB2DF3179418F241E4C2147F2AB25667744@TPPExch2K10.tpp.local>
Message-ID: <CAGxFJbRuqK=uAODmLPN7PQmq5JxZc-1P-=4gnKCOUDntekk6HA@mail.gmail.com>

It might help if you specify your hardware, OS (presumably Windows?)
and version, and your R version. Also possibly how large your vectors
are and what other processes you have running.

Other than that, I have no clue, of course.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 23, 2016 at 11:42 AM, Joel Stewart <jstewart at provplan.org> wrote:
> I often find myself trying to get a quick assessment of how much of one vector is inside of another vector. I almost always try this with variables that are some sort of identifier, like a client id number or an SSN. I typically do this:
>
> table( DF1$Identifier %in% DF2$Identifier)
>
> This will return a count of True and False logical responses. However, sometimes when I try to do this my computer will freeze and I am unable to stop or escape the process, requiring me to shutdown R via the task manager. I was wondering if anybody else experiences this and, if so, why this might be happening.
>
> Thanks in advance,
>
> Joel
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Sep 24 00:30:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Sep 2016 18:30:03 -0400
Subject: [R] R freezing issue when checking to see if variable belongs
 to two different vectors
In-Reply-To: <3C5C4EB2DF3179418F241E4C2147F2AB25667744@TPPExch2K10.tpp.local>
References: <3C5C4EB2DF3179418F241E4C2147F2AB25667744@TPPExch2K10.tpp.local>
Message-ID: <a5df87f8-1c18-2f5e-76c3-549c262aff93@gmail.com>

On 23/09/2016 2:42 PM, Joel Stewart wrote:
> I often find myself trying to get a quick assessment of how much of one vector is inside of another vector. I almost always try this with variables that are some sort of identifier, like a client id number or an SSN. I typically do this:
>
> table( DF1$Identifier %in% DF2$Identifier)
>
> This will return a count of True and False logical responses. However, sometimes when I try to do this my computer will freeze and I am unable to stop or escape the process, requiring me to shutdown R via the task manager. I was wondering if anybody else experiences this and, if so, why this might be happening.

No, I've never seen that.

If you ever find a reproducible example to trigger that, please post it 
to the bug list.  (This might be a little hard if you've never posted 
there before; due to abuse by spammers, we need to authorize each user 
manually.  But at least we only need to do that once per user.)

If you can't make this happen reproducibly, it probably won't get 
investigated.

Duncan Murdoch


From cbenjami at BTBOCES.ORG  Sat Sep 24 05:01:03 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Sat, 24 Sep 2016 03:01:03 +0000
Subject: [R] Svyglm Error in Survey Package
Message-ID: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>

In attempting to use the svyglm call in the R Survey Package, I am receiving the error: Error in pwt[i] : invalid subscript type 'list'

I have not been able to find a lot of information on how to resolve the error; one source advised it was related to how the subsetting command was executed.

This was my initial attempt:

mc1 <- svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1),na.action)
summary(mc1)
This was my second approach trying to change up how I had subsetted the data:
summary(mc1)
samp1 <- subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1)
dim(samp1)
mc1 <- svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset=samp1,na.action)
summary(mc1)?

Both attempts resulted in the same error stated above.  Any advisement in how to resolve this error would be greatly appreciated.
Sincerely,
Courtney Benjamin

?



Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sat Sep 24 05:11:09 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 23 Sep 2016 23:11:09 -0400
Subject: [R] Svyglm Error in Survey Package
In-Reply-To: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>
References: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>
Message-ID: <CAOwvMDz_gtSVWL7NRw9rxmXzqxuQge9ntOSGSWBxOyqE_g7h1g@mail.gmail.com>

hi could you make this a minimal reproducible example?

On Sep 24, 2016 12:03 PM, "Courtney Benjamin" <cbenjami at btboces.org> wrote:

> In attempting to use the svyglm call in the R Survey Package, I am
> receiving the error: Error in pwt[i] : invalid subscript type 'list'
>
> I have not been able to find a lot of information on how to resolve the
> error; one source advised it was related to how the subsetting command was
> executed.
>
> This was my initial attempt:
>
> mc1 <- svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset(elsq1ch_brr,BYSCTRL==1
> & G10COHRT==1),na.action)
> summary(mc1)
> This was my second approach trying to change up how I had subsetted the
> data:
> summary(mc1)
> samp1 <- subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1)
> dim(samp1)
> mc1 <- svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset=
> samp1,na.action)
> summary(mc1)?
>
> Both attempts resulted in the same error stated above.  Any advisement in
> how to resolve this error would be greatly appreciated.
> Sincerely,
> Courtney Benjamin
>
> ?
>
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org<mailto:cbenjami at btboces.org>
>
> 607-763-8633
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dgcatanzaro at gmail.com  Sat Sep 24 05:58:15 2016
From: dgcatanzaro at gmail.com (Donald Catanzaro)
Date: Fri, 23 Sep 2016 22:58:15 -0500
Subject: [R] Cumulative Incident Function does not go to end of dataset
Message-ID: <CAJ_nJtNOVL=TH4W+yZs45PuXugz0rtB2y5hREvdO1KizSDpCmg@mail.gmail.com>

Hi All,

I have been working on a Competing Risks analysis using the mstate package
and when I run my analysis I was surprised to see the cumulative incident
function ending substantially before my data set did.

You can reproduce the behavior (kind of) using the data that was provided
with mstate:

library(mstate)
data(aidssi)
ci <- Cuminc(time=aidssi$time, status=aidssi$status)


and you can see that ci goes to 10.448

However, when you use the cmprsk package, the CIF goes pretty much to the
end of the data


library(cmprsk)
CI.overall <- cuminc(ftime =aidssi$time, fstatus=aidssi$status)

and you can see that CI.overall ends at 12

Using the data provided in the package, a difference of < 2 years is not
terrible but with my dataset mstate ends at 1.02 while cmprsk ends at 4 (my
max for event time is 4.9) and that is a substantial difference.

 I believe I must be missing something here.  Is there a way to get mstate to
report the entire CIF ?

-- 
- Don

Donald Catanzaro PhD
dgcatanzaro at gmail.com
16144 Sigmond Lane
Lowell, AR 72745
479-721-2533

	[[alternative HTML version deleted]]


From rhurlin at gwdg.de  Sat Sep 24 08:49:00 2016
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 24 Sep 2016 08:49:00 +0200
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
Message-ID: <1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>

Hi,

one possible solution is to use ltext().

ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))

You have to know or to find out best fitting coordinates.

Via adj you can control, if the text should adjust left, center or right
to the coords, and above, center or bottom of them.

HTH,
Rainer Hurling


Am 22.09.2016 um 16:04 schrieb Jun Shen:
> Dear list,
> 
> Just wonder if there is a way to add annotation text outside an xyplot,
> (e.g. the bottom of the plot). the panel.text seems only add text within
> the plot. Thanks.
> 
> Jun


From jfox at mcmaster.ca  Sat Sep 24 15:38:12 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 24 Sep 2016 13:38:12 +0000
Subject: [R] Svyglm Error in Survey Package
In-Reply-To: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>
References: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83657E8A7@FHSDB2D11-2.csu.mcmaster.ca>

Dear Courtney,

I think that you're confused about how to use the subset argument to svyglm() and about what the subset() function returns. The subset argument should be a logical expression, evaluating to TRUE or FALSE for each case; subset() returns a data set (e.g., a "survey.design" object).

Here's an example adapted from ?svyglm:

------------------- snip-------------------
data(api)
dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
summary(svyglm(api00~ell+meals+mobility, design=dstrat))
summary(svyglm(api00~ell+meals+mobility, design=dstrat, subset = pcttest > 90))
summary(svyglm(api00~ell+meals+mobility, design=subset(dstrat, subset = pcttest > 90)))
------------------- snip-------------------

The last two commands produce the same results.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox

        

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Courtney
> Benjamin
> Sent: September 23, 2016 11:01 PM
> To: r-help at r-project.org
> Subject: [R] Svyglm Error in Survey Package
> 
> In attempting to use the svyglm call in the R Survey Package, I am receiving the
> error: Error in pwt[i] : invalid subscript type 'list'
> 
> I have not been able to find a lot of information on how to resolve the error;
> one source advised it was related to how the subsetting command was
> executed.
> 
> This was my initial attempt:
> 
> mc1 <-
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset(elsq1ch_brr,
> BYSCTRL==1 & G10COHRT==1),na.action)
> summary(mc1)
> This was my second approach trying to change up how I had subsetted the
> data:
> summary(mc1)
> samp1 <- subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1)
> dim(samp1)
> mc1 <-
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset=samp1,na.ac
> tion)
> summary(mc1)?
> 
> Both attempts resulted in the same error stated above.  Any advisement in how
> to resolve this error would be greatly appreciated.
> Sincerely,
> Courtney Benjamin
> 
> ?
> 
> 
> 
> Courtney Benjamin
> 
> Broome-Tioga BOCES
> 
> Automotive Technology II Teacher
> 
> Located at Gault Toyota
> 
> Doctoral Candidate-Educational Theory & Practice
> 
> State University of New York at Binghamton
> 
> cbenjami at btboces.org<mailto:cbenjami at btboces.org>
> 
> 607-763-8633
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Sep 24 16:17:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 24 Sep 2016 07:17:29 -0700
Subject: [R] Cumulative Incident Function does not go to end of dataset
In-Reply-To: <CAJ_nJtNOVL=TH4W+yZs45PuXugz0rtB2y5hREvdO1KizSDpCmg@mail.gmail.com>
References: <CAJ_nJtNOVL=TH4W+yZs45PuXugz0rtB2y5hREvdO1KizSDpCmg@mail.gmail.com>
Message-ID: <F8D62111-85A2-4D89-ABFA-7644D77DA062@comcast.net>


> On Sep 23, 2016, at 8:58 PM, Donald Catanzaro <dgcatanzaro at gmail.com> wrote:
> 
> Hi All,
> 
> I have been working on a Competing Risks analysis using the mstate package
> and when I run my analysis I was surprised to see the cumulative incident
> function ending substantially before my data set did.
> 
> You can reproduce the behavior (kind of) using the data that was provided
> with mstate:
> 
> library(mstate)
> data(aidssi)
> ci <- Cuminc(time=aidssi$time, status=aidssi$status)
> 
> 
> and you can see that ci goes to 10.448
> 
> However, when you use the cmprsk package, the CIF goes pretty much to the
> end of the data
> 
> 
> library(cmprsk)
> CI.overall <- cuminc(ftime =aidssi$time, fstatus=aidssi$status)
> 
> and you can see that CI.overall ends at 12
> 
> Using the data provided in the package, a difference of < 2 years is not
> terrible but with my dataset mstate ends at 1.02 while cmprsk ends at 4 (my
> max for event time is 4.9) and that is a substantial difference.
> 
> I believe I must be missing something here.  Is there a way to get mstate to
> report the entire CIF ?


If you compare the output of plot(ci) and plot(CI.overall) they appear identical, modulo a difference in the range of the plot.

The help page for Cuminc says that: "Cuminc is now simply a wrapper around survfit of the survival package with type="mstate", only maintained for backward compatibility. The survfit object is kept as attribute (attr("survfit")), and the print, plot and summary functions are simply print, plot and summary applied to the survfit object."  So it would seem that you should be extracting your desired estimates from that  attribute.

> 
> -- 
> - Don
> 
> Donald Catanzaro PhD
> dgcatanzaro at gmail.com
> 16144 Sigmond Lane
> Lowell, AR 72745
> 479-721-2533
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat Sep 24 17:04:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Sep 2016 08:04:30 -0700
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
Message-ID: <CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>

No.

ltext/panel.text plots text *within* panels; IIUC, the  OP requested
text outside the plots. For that see the details for "main" and/or
"sub" in ?xyplot. I think it could also be done more flexibly via a
legend or a key with a title but no content -- again, see the Help
page -- but haven't tried it.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de> wrote:
> Hi,
>
> one possible solution is to use ltext().
>
> ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
>
> You have to know or to find out best fitting coordinates.
>
> Via adj you can control, if the text should adjust left, center or right
> to the coords, and above, center or bottom of them.
>
> HTH,
> Rainer Hurling
>
>
> Am 22.09.2016 um 16:04 schrieb Jun Shen:
>> Dear list,
>>
>> Just wonder if there is a way to add annotation text outside an xyplot,
>> (e.g. the bottom of the plot). the panel.text seems only add text within
>> the plot. Thanks.
>>
>> Jun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kaushalaarushi at gmail.com  Sat Sep 24 20:49:57 2016
From: kaushalaarushi at gmail.com (Aarushi Kaushal)
Date: Sun, 25 Sep 2016 00:19:57 +0530
Subject: [R] Query regarding Approximate/Fuzzy matching & String
 Extraction(numeric) in R
Message-ID: <CAPjbwKKH1a2iWx+haOZrsLOtM2EU5x_Z+RHobZ=60tfYS0ogQQ@mail.gmail.com>

Hey there,

I work for an organisation named Bullero Capital Pvt. Ltd. in New Delhi,
which is involved in financial services, Portfolio management to be
precise. Recently we've started creating ourselves a database using R for
all the stocks etc. to be automated and hence analyzed accordingly for
future investment purposes (data related to which is already available, and
in our possession).

I and a colleague of mine, we are currently at the data cleaning stage -
where we need to organize and format the data according to how we want it
in the database. The problem lies in notation & symbols used in the
original csv data files acquired from the government website - where we
have to do approximate matching (for efficiency) and thereby extract the
numerics only from that string of characters from the respective columns of
the dataframe.

1.) As of now we are looking at using the agrep function, to detect &
locate the pattern matches namely - DIVIDEND , SPLIT, BONUS

2.) From there on carry out the extraction of the respective numeric values
associated with these actions in to the corresponding columns -
BONUS_NUM(Numerator for the ratio), BONUS_DEN( Denominator for the ratio),
SPLIT_NUM(Numerator for the ratio), SPLIT_DEN (Denominator for the Ratio),
FInal Dividend, Interim Dividend & Special Dividend.


COLUMN PURPOSE

   1. DIVIDEND-RE.1/- PER SHARE
   2. AGM/DIV-RS.3.50 PER SHARE
   3. SPL DIV-RS.2.70 PER SHARE
   4. DIV - FIN 3.50RE PER SHARE + SPL-Rs.1.4
   5. FV SPLIT Rs.10 to RE.1
   6. BON 3:2 + SPLT Rs. 5 to Rs.2.5
   7. BONUS 4:1
   8. DIV:10%

Ex.
DIVIDEND-RE.1/- PER SHARE
FINAL_DIV-1

AGM/DIV-RS.3.50 PER SHARE
FINAL_DIV-3.50

SPL DIV-RS.2.70 PER SHARE
SPECIAL DIV-2.70

Ex.
FV SPLIT Rs.10 to RE.1
SPLIT_NUM - 1
SPLIT_DEN - 10

Ex. BONUS 4:1
BONUS_NUM - 4
BONUS_DEN - 1

However, the problem with that is that agrep returns the vector indices
 instead of the string indices which makes it cumbersome to extract the
numeric values following the respective matches.
So I want a Fuzzy logic approach to

   - check for the presence of SPLIT, DIVIDEND, BONUS
   - index of which ever cell the pattern match occurs in the column
   PURPOSE of the data frame
   - index position of that particular pattern in the string to extract the
   numerical value following the matched pattern

*Basically Is there any way in R to determine if the patterns can be
checked and matched approximately while returning for value - the indices
for the same in the respective strings?**(such that if in case the symbols
change furthermore in the future according to the government website's
notation in the data storage, or the format/positioning/spacing changes -
it could account for all those changes automatically.)*
I am attaching below the .csv file consisting of just the column we need to
carry out the cleaning in for your convenience.

It would be very helpful, if we could get some guidance as to how to
proceed further at the earliest.

regards,
aarushi kaushal

From dwinsemius at comcast.net  Sun Sep 25 04:18:18 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 24 Sep 2016 19:18:18 -0700
Subject: [R] Query regarding Approximate/Fuzzy matching & String
	Extraction(numeric) in R
In-Reply-To: <CAPjbwKKH1a2iWx+haOZrsLOtM2EU5x_Z+RHobZ=60tfYS0ogQQ@mail.gmail.com>
References: <CAPjbwKKH1a2iWx+haOZrsLOtM2EU5x_Z+RHobZ=60tfYS0ogQQ@mail.gmail.com>
Message-ID: <3212397A-F25C-4367-A14C-A1294B4EC522@comcast.net>


> On Sep 24, 2016, at 11:49 AM, Aarushi Kaushal <kaushalaarushi at gmail.com> wrote:
> 
> Hey there,
> 
> I work for an organisation named Bullero Capital Pvt. Ltd. in New Delhi,
> which is involved in financial services, Portfolio management to be
> precise. Recently we've started creating ourselves a database using R for
> all the stocks etc. to be automated and hence analyzed accordingly for
> future investment purposes (data related to which is already available, and
> in our possession).
> 
> I and a colleague of mine, we are currently at the data cleaning stage -
> where we need to organize and format the data according to how we want it
> in the database. The problem lies in notation & symbols used in the
> original csv data files acquired from the government website - where we
> have to do approximate matching (for efficiency) and thereby extract the
> numerics only from that string of characters from the respective columns of
> the dataframe.
> 
> 1.) As of now we are looking at using the agrep function, to detect &
> locate the pattern matches namely - DIVIDEND , SPLIT, BONUS
> 
> 2.) From there on carry out the extraction of the respective numeric values
> associated with these actions in to the corresponding columns -
> BONUS_NUM(Numerator for the ratio), BONUS_DEN( Denominator for the ratio),
> SPLIT_NUM(Numerator for the ratio), SPLIT_DEN (Denominator for the Ratio),
> FInal Dividend, Interim Dividend & Special Dividend.
> 
> 
> COLUMN PURPOSE
> 
>   1. DIVIDEND-RE.1/- PER SHARE
>   2. AGM/DIV-RS.3.50 PER SHARE
>   3. SPL DIV-RS.2.70 PER SHARE
>   4. DIV - FIN 3.50RE PER SHARE + SPL-Rs.1.4
>   5. FV SPLIT Rs.10 to RE.1
>   6. BON 3:2 + SPLT Rs. 5 to Rs.2.5
>   7. BONUS 4:1
>   8. DIV:10%
> 
> Ex.
> DIVIDEND-RE.1/- PER SHARE
> FINAL_DIV-1
> 
> AGM/DIV-RS.3.50 PER SHARE
> FINAL_DIV-3.50
> 
> SPL DIV-RS.2.70 PER SHARE
> SPECIAL DIV-2.70
> 
> Ex.
> FV SPLIT Rs.10 to RE.1
> SPLIT_NUM - 1
> SPLIT_DEN - 10
> 
> Ex. BONUS 4:1
> BONUS_NUM - 4
> BONUS_DEN - 1
> 
> However, the problem with that is that agrep returns the vector indices
> instead of the string indices which makes it cumbersome to extract the
> numeric values following the respective matches.

Please read ?agrep which was my starting point. (I needed to see if `agrep` was like grep in being capable of returning character values of matches.)

Can you explain what that actually means? What would be a "string index" if it is not the value returned when the parameter to `agrep` is setas:  value=TRUE?


> So I want a Fuzzy logic approach to
> 
>   - check for the presence of SPLIT, DIVIDEND, BONUS
>   - index of which ever cell the pattern match occurs in the column
>   PURPOSE of the data frame
>   - index position of that particular pattern in the string to extract the
>   numerical value following the matched pattern
> 
> *Basically Is there any way in R to determine if the patterns can be
> checked and matched approximately while returning for value - the indices
> for the same in the respective strings?**(such that if in case the symbols
> change furthermore in the future according to the government website's
> notation in the data storage, or the format/positioning/spacing changes -
> it could account for all those changes automatically.)*
> I am attaching below the .csv file consisting of just the column we need to
> carry out the cleaning in for your convenience.
> 
> It would be very helpful, if we could get some guidance as to how to
> proceed further at the earliest.

It would be helpful for us for _you_ to construct a simple example and explain what was desired from it (as is described in the Posting Guide).

-- 

David Winsemius
Alameda, CA, USA


From dgcatanzaro at gmail.com  Sun Sep 25 06:02:49 2016
From: dgcatanzaro at gmail.com (Donald Catanzaro)
Date: Sat, 24 Sep 2016 23:02:49 -0500
Subject: [R] Cumulative Incident Function does not go to end of dataset
In-Reply-To: <F8D62111-85A2-4D89-ABFA-7644D77DA062@comcast.net>
References: <CAJ_nJtNOVL=TH4W+yZs45PuXugz0rtB2y5hREvdO1KizSDpCmg@mail.gmail.com>
	<F8D62111-85A2-4D89-ABFA-7644D77DA062@comcast.net>
Message-ID: <CAJ_nJtOASU0+8-pCxoLmDv8up=pX+isGuY_CQ1T=snAwageVhA@mail.gmail.com>

Hi All,

Thank you David, I see now that what I need to do is something like

plot(attr(ci,"survfit"), col=c("red","green"))


and I will get the plot with the two CIFs in different colors.

On Sat, Sep 24, 2016 at 9:17 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 23, 2016, at 8:58 PM, Donald Catanzaro <dgcatanzaro at gmail.com>
> wrote:
> >
> > Hi All,
> >
> > I have been working on a Competing Risks analysis using the mstate
> package
> > and when I run my analysis I was surprised to see the cumulative incident
> > function ending substantially before my data set did.
> >
> > You can reproduce the behavior (kind of) using the data that was provided
> > with mstate:
> >
> > library(mstate)
> > data(aidssi)
> > ci <- Cuminc(time=aidssi$time, status=aidssi$status)
> >
> >
> > and you can see that ci goes to 10.448
> >
> > However, when you use the cmprsk package, the CIF goes pretty much to the
> > end of the data
> >
> >
> > library(cmprsk)
> > CI.overall <- cuminc(ftime =aidssi$time, fstatus=aidssi$status)
> >
> > and you can see that CI.overall ends at 12
> >
> > Using the data provided in the package, a difference of < 2 years is not
> > terrible but with my dataset mstate ends at 1.02 while cmprsk ends at 4
> (my
> > max for event time is 4.9) and that is a substantial difference.
> >
> > I believe I must be missing something here.  Is there a way to get
> mstate to
> > report the entire CIF ?
>
>
> If you compare the output of plot(ci) and plot(CI.overall) they appear
> identical, modulo a difference in the range of the plot.
>
> The help page for Cuminc says that: "Cuminc is now simply a wrapper around
> survfit of the survival package with type="mstate", only maintained for
> backward compatibility. The survfit object is kept as attribute
> (attr("survfit")), and the print, plot and summary functions are simply
> print, plot and summary applied to the survfit object."  So it would seem
> that you should be extracting your desired estimates from that  attribute.
>
> >
> > --
> > - Don
> >
> > Donald Catanzaro PhD
> > dgcatanzaro at gmail.com
> > 16144 Sigmond Lane
> > Lowell, AR 72745
> > 479-721-2533
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
- Don

Donald Catanzaro PhD
dgcatanzaro at gmail.com
16144 Sigmond Lane
Lowell, AR 72745
479-721-2533

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Sep 25 06:03:57 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Sep 2016 21:03:57 -0700
Subject: [R] Query regarding Approximate/Fuzzy matching & String
 Extraction(numeric) in R
In-Reply-To: <CAPjbwKKH1a2iWx+haOZrsLOtM2EU5x_Z+RHobZ=60tfYS0ogQQ@mail.gmail.com>
References: <CAPjbwKKH1a2iWx+haOZrsLOtM2EU5x_Z+RHobZ=60tfYS0ogQQ@mail.gmail.com>
Message-ID: <CAGxFJbQHZg4qQ6Nokt7JkdNLpoQwxjcv1JpfQuycLeH=DwK=qA@mail.gmail.com>

"So I want a **Fuzzy logic approach** to..."

That is a near meaningless buzzword.

I suggest you search on "fuzzy logic" on the rseek.org website and see
if any of the hits there does whatever it is that you have in mind.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 24, 2016 at 11:49 AM, Aarushi Kaushal
<kaushalaarushi at gmail.com> wrote:
> Hey there,
>
> I work for an organisation named Bullero Capital Pvt. Ltd. in New Delhi,
> which is involved in financial services, Portfolio management to be
> precise. Recently we've started creating ourselves a database using R for
> all the stocks etc. to be automated and hence analyzed accordingly for
> future investment purposes (data related to which is already available, and
> in our possession).
>
> I and a colleague of mine, we are currently at the data cleaning stage -
> where we need to organize and format the data according to how we want it
> in the database. The problem lies in notation & symbols used in the
> original csv data files acquired from the government website - where we
> have to do approximate matching (for efficiency) and thereby extract the
> numerics only from that string of characters from the respective columns of
> the dataframe.
>
> 1.) As of now we are looking at using the agrep function, to detect &
> locate the pattern matches namely - DIVIDEND , SPLIT, BONUS
>
> 2.) From there on carry out the extraction of the respective numeric values
> associated with these actions in to the corresponding columns -
> BONUS_NUM(Numerator for the ratio), BONUS_DEN( Denominator for the ratio),
> SPLIT_NUM(Numerator for the ratio), SPLIT_DEN (Denominator for the Ratio),
> FInal Dividend, Interim Dividend & Special Dividend.
>
>
> COLUMN PURPOSE
>
>    1. DIVIDEND-RE.1/- PER SHARE
>    2. AGM/DIV-RS.3.50 PER SHARE
>    3. SPL DIV-RS.2.70 PER SHARE
>    4. DIV - FIN 3.50RE PER SHARE + SPL-Rs.1.4
>    5. FV SPLIT Rs.10 to RE.1
>    6. BON 3:2 + SPLT Rs. 5 to Rs.2.5
>    7. BONUS 4:1
>    8. DIV:10%
>
> Ex.
> DIVIDEND-RE.1/- PER SHARE
> FINAL_DIV-1
>
> AGM/DIV-RS.3.50 PER SHARE
> FINAL_DIV-3.50
>
> SPL DIV-RS.2.70 PER SHARE
> SPECIAL DIV-2.70
>
> Ex.
> FV SPLIT Rs.10 to RE.1
> SPLIT_NUM - 1
> SPLIT_DEN - 10
>
> Ex. BONUS 4:1
> BONUS_NUM - 4
> BONUS_DEN - 1
>
> However, the problem with that is that agrep returns the vector indices
>  instead of the string indices which makes it cumbersome to extract the
> numeric values following the respective matches.
> So I want a Fuzzy logic approach to
>
>    - check for the presence of SPLIT, DIVIDEND, BONUS
>    - index of which ever cell the pattern match occurs in the column
>    PURPOSE of the data frame
>    - index position of that particular pattern in the string to extract the
>    numerical value following the matched pattern
>
> *Basically Is there any way in R to determine if the patterns can be
> checked and matched approximately while returning for value - the indices
> for the same in the respective strings?**(such that if in case the symbols
> change furthermore in the future according to the government website's
> notation in the data storage, or the format/positioning/spacing changes -
> it could account for all those changes automatically.)*
> I am attaching below the .csv file consisting of just the column we need to
> carry out the cleaning in for your convenience.
>
> It would be very helpful, if we could get some guidance as to how to
> proceed further at the earliest.
>
> regards,
> aarushi kaushal
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Sun Sep 25 13:51:01 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Sun, 25 Sep 2016 14:51:01 +0300
Subject: [R] How to add overall xlabel and ylabel?
Message-ID: <11FFA667-19CB-4779-8ED3-DF6A542908EE@kapsi.fi>

I have created a 2x2 plot using par(mfrow = c(2, 2)).

I can add x- and ylabels to individual plots, but what I want is to add overall xlabel and ylabel for the entire 2x2 plot.

How to do this?

From mviljamaa at kapsi.fi  Sun Sep 25 15:01:29 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Sun, 25 Sep 2016 16:01:29 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And Error:
	longer object length is not a multiple of shorter object length
Message-ID: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>

I?m trying to plot regression lines using curve()

The way I do it is:

bs <- coef(fit2)

and then for example:

curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')

This above code runs into error:

Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  : 
  'expr' did not evaluate to an object of length 'n'
In addition: Warning message:
In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
  longer object length is not a multiple of shorter object length

Which I?ve investigated might be related to the lengths of the different objects being multiplied or summed.
Taking length(g$x) or length(g$y) of

g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x, from=min(lka), to=max(lka), add=TRUE, col='red')

returns 101.

However length(lka) is 375. But perhaps these being different is not the problem?

I however do see that the whole range of lka is not plotted, for some reason. So how can I be sure
that it passes through all x-values in lka? And i.e. that the lengths of objects inside curve() are correct?

What can I do?

From btupper at bigelow.org  Sun Sep 25 15:02:34 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 25 Sep 2016 09:02:34 -0400
Subject: [R] How to add overall xlabel and ylabel?
In-Reply-To: <11FFA667-19CB-4779-8ED3-DF6A542908EE@kapsi.fi>
References: <11FFA667-19CB-4779-8ED3-DF6A542908EE@kapsi.fi>
Message-ID: <CFFD1D43-7BF2-46CE-876D-E8ADA4EFE02E@bigelow.org>

Hi,

Here's a place to start...

https://www.r-bloggers.com/two-tips-adding-title-for-graph-with-multiple-plots-add-significance-asterix-onto-a-boxplot/

You might also want to checkout the text() function and the xpd argument to par.

Ben

> On Sep 25, 2016, at 7:51 AM, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I have created a 2x2 plot using par(mfrow = c(2, 2)).
> 
> I can add x- and ylabels to individual plots, but what I want is to add overall xlabel and ylabel for the entire 2x2 plot.
> 
> How to do this?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From mviljamaa at kapsi.fi  Sun Sep 25 15:10:16 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Sun, 25 Sep 2016 16:10:16 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
Message-ID: <C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>

Writing:

bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka

i.e. without that being inside curve produces a vector of length 375.

So now it seems that curve() is really skipping some lka-/x-values.

> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I?m trying to plot regression lines using curve()
> 
> The way I do it is:
> 
> bs <- coef(fit2)
> 
> and then for example:
> 
> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
> 
> This above code runs into error:
> 
> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  : 
>  'expr' did not evaluate to an object of length 'n'
> In addition: Warning message:
> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>  longer object length is not a multiple of shorter object length
> 
> Which I?ve investigated might be related to the lengths of the different objects being multiplied or summed.
> Taking length(g$x) or length(g$y) of
> 
> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x, from=min(lka), to=max(lka), add=TRUE, col='red')
> 
> returns 101.
> 
> However length(lka) is 375. But perhaps these being different is not the problem?
> 
> I however do see that the whole range of lka is not plotted, for some reason. So how can I be sure
> that it passes through all x-values in lka? And i.e. that the lengths of objects inside curve() are correct?
> 
> What can I do?


From jfox at mcmaster.ca  Sun Sep 25 15:21:15 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 25 Sep 2016 13:21:15 +0000
Subject: [R] Svyglm Error in Survey Package
In-Reply-To: <1474772057025.52119@BTBOCES.ORG>
References: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>,
	<ACD1644AA6C67E4FBD0C350625508EC83657E8A7@FHSDB2D11-2.csu.mcmaster.ca>
	<1474772057025.52119@BTBOCES.ORG>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83657EA6C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Courtney,

You're confusing a function call, na.action(na.omit), with an argument specification, na.action=na.omit  (and, in any event, there is no na.action() function). But you don't have to specify na.action=na.omit, because na.omit (which produces a complete-case analysis) is the default na.action. See ?glm for more information. 

If you haven't already done so, you might want to read something about how statistical modeling functions in R -- and possibly R more generally -- work. In the long run, that likely will save you some time.

I'm cc'ing this to the r-help email list, where you posed your original question. It's generally a good idea to keep responses on the list.

I hope this helps,
 John

> -----Original Message-----
> From: Courtney Benjamin [mailto:cbenjami at BTBOCES.ORG]
> Sent: September 24, 2016 10:55 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: Svyglm Error in Survey Package
> 
> Hello Dr. Fox,
> Thank you very much for your explanation; I am in better shape now with the
> subset argument and I am no longer getting the error.  Now I am not having
> success with specifying the na.action argument.  I would like to exclude NAs
> like I have done in other commands with na.rm=TRUE.
> The following are my attempts:
> >
> summary(svyglm(F3ATTAINMENT~F1PARED+F1SES2QU,design=elsq1ch_brr,su
> bset
> > =BYSCTRL==1 & G10COHRT==1,na.action))
> Error in glm(formula = F3ATTAINMENT ~ F1PARED + F1SES2QU, subset =
> BYSCTRL ==  :
>   argument "na.action" is missing, with no default
> 
> >
> summary(svyglm(F3ATTAINMENT~F1PARED+F1SES2QU,design=elsq1ch_brr,su
> bset
> > =BYSCTRL==1 & G10COHRT==1,na.action(na.omit))
> +
> Any guidance you would be willing to provide is greatly appreciated; I have
> only been using R for about 6 months.
> Sincerely
> Courtney
> 
> Courtney Benjamin
> Broome-Tioga BOCES
> Automotive Technology II Teacher
> Located at Gault Toyota
> Doctoral Candidate-Educational Theory & Practice State University of New York
> at Binghamton cbenjami at btboces.org
> 607-763-8633
> 
> ________________________________________
> From: Fox, John <jfox at mcmaster.ca>
> Sent: Saturday, September 24, 2016 9:38 AM
> To: Courtney Benjamin
> Cc: r-help at r-project.org
> Subject: RE: Svyglm Error in Survey Package
> 
> Dear Courtney,
> 
> I think that you're confused about how to use the subset argument to svyglm()
> and about what the subset() function returns. The subset argument should be a
> logical expression, evaluating to TRUE or FALSE for each case; subset() returns
> a data set (e.g., a "survey.design" object).
> 
> Here's an example adapted from ?svyglm:
> 
> ------------------- snip-------------------
> data(api)
> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
> summary(svyglm(api00~ell+meals+mobility, design=dstrat))
> summary(svyglm(api00~ell+meals+mobility, design=dstrat, subset = pcttest >
> 90)) summary(svyglm(api00~ell+meals+mobility, design=subset(dstrat, subset
> = pcttest > 90)))
> ------------------- snip-------------------
> 
> The last two commands produce the same results.
> 
> I hope this helps,
>  John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Courtney Benjamin
> > Sent: September 23, 2016 11:01 PM
> > To: r-help at r-project.org
> > Subject: [R] Svyglm Error in Survey Package
> >
> > In attempting to use the svyglm call in the R Survey Package, I am
> > receiving the
> > error: Error in pwt[i] : invalid subscript type 'list'
> >
> > I have not been able to find a lot of information on how to resolve
> > the error; one source advised it was related to how the subsetting
> > command was executed.
> >
> > This was my initial attempt:
> >
> > mc1 <-
> >
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset(elsq1ch_brr,
> > BYSCTRL==1 & G10COHRT==1),na.action)
> > summary(mc1)
> > This was my second approach trying to change up how I had subsetted
> > the
> > data:
> > summary(mc1)
> > samp1 <- subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1)
> > dim(samp1)
> > mc1 <-
> >
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset=samp1,na.ac
> > tion)
> > summary(mc1)?
> >
> > Both attempts resulted in the same error stated above.  Any advisement
> > in how to resolve this error would be greatly appreciated.
> > Sincerely,
> > Courtney Benjamin
> >
> > ?
> >
> >
> >
> > Courtney Benjamin
> >
> > Broome-Tioga BOCES
> >
> > Automotive Technology II Teacher
> >
> > Located at Gault Toyota
> >
> > Doctoral Candidate-Educational Theory & Practice
> >
> > State University of New York at Binghamton
> >
> > cbenjami at btboces.org<mailto:cbenjami at btboces.org>
> >
> > 607-763-8633
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.


From murdoch.duncan at gmail.com  Sun Sep 25 17:30:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 25 Sep 2016 11:30:03 -0400
Subject: [R] curve() doesn't seem to use the whole range of x? And
 Error: longer object length is not a multiple of shorter object length
In-Reply-To: <C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
Message-ID: <3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>

On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
> Writing:
>
> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>
> i.e. without that being inside curve produces a vector of length 375.
>
> So now it seems that curve() is really skipping some lka-/x-values.

How could curve() know what the length of lka is?  You're telling it to 
set x to a sequence of values of length 101 (the default) from min(lka) 
to max(lka).  You never tell it to set x to lka.

curve() is designed to plot expressions or functions, not vectors.  If 
you actually want to plot line segments using your original data, use
lines().  (You'll likely need to sort your x values into increasing 
order if you do that, or you'll get a pretty ugly plot.)

Duncan Murdoch

>
>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>>
>> I?m trying to plot regression lines using curve()
>>
>> The way I do it is:
>>
>> bs <- coef(fit2)
>>
>> and then for example:
>>
>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
>>
>> This above code runs into error:
>>
>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>>  'expr' did not evaluate to an object of length 'n'
>> In addition: Warning message:
>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>>  longer object length is not a multiple of shorter object length
>>
>> Which I?ve investigated might be related to the lengths of the different objects being multiplied or summed.
>> Taking length(g$x) or length(g$y) of
>>
>> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x, from=min(lka), to=max(lka), add=TRUE, col='red')
>>
>> returns 101.
>>
>> However length(lka) is 375. But perhaps these being different is not the problem?
>>
>> I however do see that the whole range of lka is not plotted, for some reason. So how can I be sure
>> that it passes through all x-values in lka? And i.e. that the lengths of objects inside curve() are correct?
>>
>> What can I do?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sun Sep 25 17:31:26 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 25 Sep 2016 11:31:26 -0400
Subject: [R] How to add overall xlabel and ylabel?
In-Reply-To: <11FFA667-19CB-4779-8ED3-DF6A542908EE@kapsi.fi>
References: <11FFA667-19CB-4779-8ED3-DF6A542908EE@kapsi.fi>
Message-ID: <bb093366-2fb3-1897-1bdd-5b1865dfb171@gmail.com>

On 25/09/2016 7:51 AM, Matti Viljamaa wrote:
> I have created a 2x2 plot using par(mfrow = c(2, 2)).
>
> I can add x- and ylabels to individual plots, but what I want is to add overall xlabel and ylabel for the entire 2x2 plot.
>
> How to do this?

First you need to make space using par(oma=...), then use mtext(..., 
outer = TRUE).

Duncan Murdoch


From mviljamaa at kapsi.fi  Sun Sep 25 17:36:49 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 25 Sep 2016 18:36:49 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
 Error: longer object length is not a multiple of shorter object length
In-Reply-To: <3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
Message-ID: <3b45221f544cf692a599f06726fca469@kapsi.fi>

On 2016-09-25 18:30, Duncan Murdoch wrote:
> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>> Writing:
>> 
>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>> 
>> i.e. without that being inside curve produces a vector of length 375.
>> 
>> So now it seems that curve() is really skipping some lka-/x-values.
> 
> How could curve() know what the length of lka is?  You're telling it
> to set x to a sequence of values of length 101 (the default) from
> min(lka) to max(lka).  You never tell it to set x to lka.
> 
> curve() is designed to plot expressions or functions, not vectors.  If
> you actually want to plot line segments using your original data, use
> lines().  (You'll likely need to sort your x values into increasing
> order if you do that, or you'll get a pretty ugly plot.)
> 
> Duncan Murdoch

I know that about curve(), but since this function uses lka as a 
parameter, then how should I formulate it for curve so that I don't get 
the error about wrong lengths?

>> 
>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>>> 
>>> I?m trying to plot regression lines using curve()
>>> 
>>> The way I do it is:
>>> 
>>> bs <- coef(fit2)
>>> 
>>> and then for example:
>>> 
>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, 
>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>> 
>>> This above code runs into error:
>>> 
>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + 
>>> bs["lka"] *  :
>>>  'expr' did not evaluate to an object of length 'n'
>>> In addition: Warning message:
>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>>>  longer object length is not a multiple of shorter object length
>>> 
>>> Which I?ve investigated might be related to the lengths of the 
>>> different objects being multiplied or summed.
>>> Taking length(g$x) or length(g$y) of
>>> 
>>> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x, 
>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>> 
>>> returns 101.
>>> 
>>> However length(lka) is 375. But perhaps these being different is not 
>>> the problem?
>>> 
>>> I however do see that the whole range of lka is not plotted, for some 
>>> reason. So how can I be sure
>>> that it passes through all x-values in lka? And i.e. that the lengths 
>>> of objects inside curve() are correct?
>>> 
>>> What can I do?
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From jdnewmil at dcn.davis.ca.us  Sun Sep 25 17:52:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Sep 2016 08:52:50 -0700
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <3b45221f544cf692a599f06726fca469@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
Message-ID: <E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>

You seem to be confused about what curve is doing vs. what you are doing. 

A) Compute the points you want to plot and put them into 2 vectors. Then figure out how to plot those vectors. Then (perhaps) consider putting that all into one line of code again. 

B) The predict function is the preferred way to compute points. It may be educational for you to do the computations by hand at first, but in the long run using predict will help you avoid problems getting the equations right in multiple places in your script. 

C) Learn what makes an example reproducible (e.g. [1] or [2]), and ask your questions with reproducible code and data so we can give you concrete responses. 

[1] http://adv-r.had.co.nz/Reproducibility.html
[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
-- 
Sent from my phone. Please excuse my brevity.

On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>On 2016-09-25 18:30, Duncan Murdoch wrote:
>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>> Writing:
>>> 
>>>
>bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>> 
>>> i.e. without that being inside curve produces a vector of length
>375.
>>> 
>>> So now it seems that curve() is really skipping some lka-/x-values.
>> 
>> How could curve() know what the length of lka is?  You're telling it
>> to set x to a sequence of values of length 101 (the default) from
>> min(lka) to max(lka).  You never tell it to set x to lka.
>> 
>> curve() is designed to plot expressions or functions, not vectors. 
>If
>> you actually want to plot line segments using your original data, use
>> lines().  (You'll likely need to sort your x values into increasing
>> order if you do that, or you'll get a pretty ugly plot.)
>> 
>> Duncan Murdoch
>
>I know that about curve(), but since this function uses lka as a 
>parameter, then how should I formulate it for curve so that I don't get
>
>the error about wrong lengths?
>
>>> 
>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>wrote:
>>>> 
>>>> I?m trying to plot regression lines using curve()
>>>> 
>>>> The way I do it is:
>>>> 
>>>> bs <- coef(fit2)
>>>> 
>>>> and then for example:
>>>> 
>>>>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>
>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>> 
>>>> This above code runs into error:
>>>> 
>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + 
>>>> bs["lka"] *  :
>>>>  'expr' did not evaluate to an object of length 'n'
>>>> In addition: Warning message:
>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] * 
>:
>>>>  longer object length is not a multiple of shorter object length
>>>> 
>>>> Which I?ve investigated might be related to the lengths of the 
>>>> different objects being multiplied or summed.
>>>> Taking length(g$x) or length(g$y) of
>>>> 
>>>> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>
>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>> 
>>>> returns 101.
>>>> 
>>>> However length(lka) is 375. But perhaps these being different is
>not 
>>>> the problem?
>>>> 
>>>> I however do see that the whole range of lka is not plotted, for
>some 
>>>> reason. So how can I be sure
>>>> that it passes through all x-values in lka? And i.e. that the
>lengths 
>>>> of objects inside curve() are correct?
>>>> 
>>>> What can I do?
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Sun Sep 25 18:04:09 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 25 Sep 2016 19:04:09 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
 Error: longer object length is not a multiple of shorter object length
In-Reply-To: <E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
Message-ID: <247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>

On 2016-09-25 18:52, Jeff Newmiller wrote:
> You seem to be confused about what curve is doing vs. what you are 
> doing.

But my x-range in curve()'s parameters from and to should be the entire 
lka vector, since they are from=min(lka) and to=max(lka). Then why does 
this not span the entire of lka? Because of duplicate entries or what?

It seems like I cannot use curve(), since my x-axis must be exactly lka 
for the function to plot the y value for every lka value.

> A) Compute the points you want to plot and put them into 2 vectors.
> Then figure out how to plot those vectors. Then (perhaps) consider
> putting that all into one line of code again.
> 
> B) The predict function is the preferred way to compute points. It may
> be educational for you to do the computations by hand at first, but in
> the long run using predict will help you avoid problems getting the
> equations right in multiple places in your script.
> 
> C) Learn what makes an example reproducible (e.g. [1] or [2]), and ask
> your questions with reproducible code and data so we can give you
> concrete responses.
> 
> [1] http://adv-r.had.co.nz/Reproducibility.html
> [2]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> --
> Sent from my phone. Please excuse my brevity.
> 
> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi> 
> wrote:
>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>> Writing:
>>>> 
>>>> 
>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>> 
>>>> i.e. without that being inside curve produces a vector of length
>> 375.
>>>> 
>>>> So now it seems that curve() is really skipping some lka-/x-values.
>>> 
>>> How could curve() know what the length of lka is?  You're telling it
>>> to set x to a sequence of values of length 101 (the default) from
>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>> 
>>> curve() is designed to plot expressions or functions, not vectors.
>> If
>>> you actually want to plot line segments using your original data, use
>>> lines().  (You'll likely need to sort your x values into increasing
>>> order if you do that, or you'll get a pretty ugly plot.)
>>> 
>>> Duncan Murdoch
>> 
>> I know that about curve(), but since this function uses lka as a
>> parameter, then how should I formulate it for curve so that I don't 
>> get
>> 
>> the error about wrong lengths?
>> 
>>>> 
>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>> wrote:
>>>>> 
>>>>> I?m trying to plot regression lines using curve()
>>>>> 
>>>>> The way I do it is:
>>>>> 
>>>>> bs <- coef(fit2)
>>>>> 
>>>>> and then for example:
>>>>> 
>>>>> 
>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>> 
>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>> 
>>>>> This above code runs into error:
>>>>> 
>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] +
>>>>> bs["lka"] *  :
>>>>>  'expr' did not evaluate to an object of length 'n'
>>>>> In addition: Warning message:
>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *
>> :
>>>>>  longer object length is not a multiple of shorter object length
>>>>> 
>>>>> Which I?ve investigated might be related to the lengths of the
>>>>> different objects being multiplied or summed.
>>>>> Taking length(g$x) or length(g$y) of
>>>>> 
>>>>> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>> 
>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>> 
>>>>> returns 101.
>>>>> 
>>>>> However length(lka) is 375. But perhaps these being different is
>> not
>>>>> the problem?
>>>>> 
>>>>> I however do see that the whole range of lka is not plotted, for
>> some
>>>>> reason. So how can I be sure
>>>>> that it passes through all x-values in lka? And i.e. that the
>> lengths
>>>>> of objects inside curve() are correct?
>>>>> 
>>>>> What can I do?
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep 25 18:24:14 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Sep 2016 09:24:14 -0700
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
Message-ID: <28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>

Go directly to C. Do not pass go, do not collect $200.

You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from. 
-- 
Sent from my phone. Please excuse my brevity.

On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>On 2016-09-25 18:52, Jeff Newmiller wrote:
>> You seem to be confused about what curve is doing vs. what you are 
>> doing.
>
>But my x-range in curve()'s parameters from and to should be the entire
>
>lka vector, since they are from=min(lka) and to=max(lka). Then why does
>
>this not span the entire of lka? Because of duplicate entries or what?
>
>It seems like I cannot use curve(), since my x-axis must be exactly lka
>
>for the function to plot the y value for every lka value.
>
>> A) Compute the points you want to plot and put them into 2 vectors.
>> Then figure out how to plot those vectors. Then (perhaps) consider
>> putting that all into one line of code again.
>> 
>> B) The predict function is the preferred way to compute points. It
>may
>> be educational for you to do the computations by hand at first, but
>in
>> the long run using predict will help you avoid problems getting the
>> equations right in multiple places in your script.
>> 
>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>ask
>> your questions with reproducible code and data so we can give you
>> concrete responses.
>> 
>> [1] http://adv-r.had.co.nz/Reproducibility.html
>> [2]
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi> 
>> wrote:
>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>> Writing:
>>>>> 
>>>>> 
>>>
>bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>> 
>>>>> i.e. without that being inside curve produces a vector of length
>>> 375.
>>>>> 
>>>>> So now it seems that curve() is really skipping some
>lka-/x-values.
>>>> 
>>>> How could curve() know what the length of lka is?  You're telling
>it
>>>> to set x to a sequence of values of length 101 (the default) from
>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>> 
>>>> curve() is designed to plot expressions or functions, not vectors.
>>> If
>>>> you actually want to plot line segments using your original data,
>use
>>>> lines().  (You'll likely need to sort your x values into increasing
>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>> 
>>>> Duncan Murdoch
>>> 
>>> I know that about curve(), but since this function uses lka as a
>>> parameter, then how should I formulate it for curve so that I don't 
>>> get
>>> 
>>> the error about wrong lengths?
>>> 
>>>>> 
>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>> wrote:
>>>>>> 
>>>>>> I?m trying to plot regression lines using curve()
>>>>>> 
>>>>>> The way I do it is:
>>>>>> 
>>>>>> bs <- coef(fit2)
>>>>>> 
>>>>>> and then for example:
>>>>>> 
>>>>>> 
>>>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>> 
>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>> 
>>>>>> This above code runs into error:
>>>>>> 
>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>+
>>>>>> bs["lka"] *  :
>>>>>>  'expr' did not evaluate to an object of length 'n'
>>>>>> In addition: Warning message:
>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>*
>>> :
>>>>>>  longer object length is not a multiple of shorter object length
>>>>>> 
>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>> different objects being multiplied or summed.
>>>>>> Taking length(g$x) or length(g$y) of
>>>>>> 
>>>>>> g <-
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>> 
>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>> 
>>>>>> returns 101.
>>>>>> 
>>>>>> However length(lka) is 375. But perhaps these being different is
>>> not
>>>>>> the problem?
>>>>>> 
>>>>>> I however do see that the whole range of lka is not plotted, for
>>> some
>>>>>> reason. So how can I be sure
>>>>>> that it passes through all x-values in lka? And i.e. that the
>>> lengths
>>>>>> of objects inside curve() are correct?
>>>>>> 
>>>>>> What can I do?
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Sun Sep 25 18:32:37 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Sun, 25 Sep 2016 12:32:37 -0400
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
	<CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
Message-ID: <CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>

Thanks Bert, sub works pretty well.

Carlos, thanks for the suggestion. As I am not familiar with latticeExatra,
not sure how hard it is to make it work with my plot. I'll try.

On Sat, Sep 24, 2016 at 11:04 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> No.
>
> ltext/panel.text plots text *within* panels; IIUC, the  OP requested
> text outside the plots. For that see the details for "main" and/or
> "sub" in ?xyplot. I think it could also be done more flexibly via a
> legend or a key with a title but no content -- again, see the Help
> page -- but haven't tried it.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de> wrote:
> > Hi,
> >
> > one possible solution is to use ltext().
> >
> > ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
> >
> > You have to know or to find out best fitting coordinates.
> >
> > Via adj you can control, if the text should adjust left, center or right
> > to the coords, and above, center or bottom of them.
> >
> > HTH,
> > Rainer Hurling
> >
> >
> > Am 22.09.2016 um 16:04 schrieb Jun Shen:
> >> Dear list,
> >>
> >> Just wonder if there is a way to add annotation text outside an xyplot,
> >> (e.g. the bottom of the plot). the panel.text seems only add text within
> >> the plot. Thanks.
> >>
> >> Jun
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Sun Sep 25 18:37:56 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Sun, 25 Sep 2016 19:37:56 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
Message-ID: <94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>

Okay here?s a pretty short code to reproduce it:

data <- read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE)
attach(data)

fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)

bs <- coef(fit2)

varitB <- c(data[koulu == 'B',]$mies)
varitB[varitB == 0] = 2
plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)

curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')


> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Go directly to C. Do not pass go, do not collect $200.
> 
> You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>> You seem to be confused about what curve is doing vs. what you are 
>>> doing.
>> 
>> But my x-range in curve()'s parameters from and to should be the entire
>> 
>> lka vector, since they are from=min(lka) and to=max(lka). Then why does
>> 
>> this not span the entire of lka? Because of duplicate entries or what?
>> 
>> It seems like I cannot use curve(), since my x-axis must be exactly lka
>> 
>> for the function to plot the y value for every lka value.
>> 
>>> A) Compute the points you want to plot and put them into 2 vectors.
>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>> putting that all into one line of code again.
>>> 
>>> B) The predict function is the preferred way to compute points. It
>> may
>>> be educational for you to do the computations by hand at first, but
>> in
>>> the long run using predict will help you avoid problems getting the
>>> equations right in multiple places in your script.
>>> 
>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>> ask
>>> your questions with reproducible code and data so we can give you
>>> concrete responses.
>>> 
>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>> [2]
>>> 
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi> 
>>> wrote:
>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>> Writing:
>>>>>> 
>>>>>> 
>>>> 
>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>> 
>>>>>> i.e. without that being inside curve produces a vector of length
>>>> 375.
>>>>>> 
>>>>>> So now it seems that curve() is really skipping some
>> lka-/x-values.
>>>>> 
>>>>> How could curve() know what the length of lka is?  You're telling
>> it
>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>> 
>>>>> curve() is designed to plot expressions or functions, not vectors.
>>>> If
>>>>> you actually want to plot line segments using your original data,
>> use
>>>>> lines().  (You'll likely need to sort your x values into increasing
>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>> 
>>>>> Duncan Murdoch
>>>> 
>>>> I know that about curve(), but since this function uses lka as a
>>>> parameter, then how should I formulate it for curve so that I don't 
>>>> get
>>>> 
>>>> the error about wrong lengths?
>>>> 
>>>>>> 
>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>> wrote:
>>>>>>> 
>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>> 
>>>>>>> The way I do it is:
>>>>>>> 
>>>>>>> bs <- coef(fit2)
>>>>>>> 
>>>>>>> and then for example:
>>>>>>> 
>>>>>>> 
>>>> 
>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>> 
>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>> 
>>>>>>> This above code runs into error:
>>>>>>> 
>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>> +
>>>>>>> bs["lka"] *  :
>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>> In addition: Warning message:
>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>> *
>>>> :
>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>> 
>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>> different objects being multiplied or summed.
>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>> 
>>>>>>> g <-
>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>> 
>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>> 
>>>>>>> returns 101.
>>>>>>> 
>>>>>>> However length(lka) is 375. But perhaps these being different is
>>>> not
>>>>>>> the problem?
>>>>>>> 
>>>>>>> I however do see that the whole range of lka is not plotted, for
>>>> some
>>>>>>> reason. So how can I be sure
>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>> lengths
>>>>>>> of objects inside curve() are correct?
>>>>>>> 
>>>>>>> What can I do?
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 


From cbenjami at BTBOCES.ORG  Sun Sep 25 18:57:03 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Sun, 25 Sep 2016 16:57:03 +0000
Subject: [R] Svyglm Error in Survey Package
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83657EA6C@FHSDB2D11-2.csu.mcmaster.ca>
References: <9edb4382035c49b891b71b896b8359ca@SCRICMAIL1.AD.SouthCentralRIC.org>,
	<ACD1644AA6C67E4FBD0C350625508EC83657E8A7@FHSDB2D11-2.csu.mcmaster.ca>
	<1474772057025.52119@BTBOCES.ORG>,
	<ACD1644AA6C67E4FBD0C350625508EC83657EA6C@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <1474822601932.66163@BTBOCES.ORG>

Hello Dr. Fox,
Thank you very much for your recommendations and I will take action on following them.  I appreciate your willingness to provide guidance on my novice questions.
Sincerely,
Courtney

________________________________________
From: Fox, John <jfox at mcmaster.ca>
Sent: Sunday, September 25, 2016 9:21 AM
To: Courtney Benjamin
Cc: r-help at r-project.org
Subject: RE: Svyglm Error in Survey Package

Dear Courtney,

You're confusing a function call, na.action(na.omit), with an argument specification, na.action=na.omit  (and, in any event, there is no na.action() function). But you don't have to specify na.action=na.omit, because na.omit (which produces a complete-case analysis) is the default na.action. See ?glm for more information.

If you haven't already done so, you might want to read something about how statistical modeling functions in R -- and possibly R more generally -- work. In the long run, that likely will save you some time.

I'm cc'ing this to the r-help email list, where you posed your original question. It's generally a good idea to keep responses on the list.

I hope this helps,
 John

> -----Original Message-----
> From: Courtney Benjamin [mailto:cbenjami at BTBOCES.ORG]
> Sent: September 24, 2016 10:55 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: Svyglm Error in Survey Package
>
> Hello Dr. Fox,
> Thank you very much for your explanation; I am in better shape now with the
> subset argument and I am no longer getting the error.  Now I am not having
> success with specifying the na.action argument.  I would like to exclude NAs
> like I have done in other commands with na.rm=TRUE.
> The following are my attempts:
> >
> summary(svyglm(F3ATTAINMENT~F1PARED+F1SES2QU,design=elsq1ch_brr,su
> bset
> > =BYSCTRL==1 & G10COHRT==1,na.action))
> Error in glm(formula = F3ATTAINMENT ~ F1PARED + F1SES2QU, subset =
> BYSCTRL ==  :
>   argument "na.action" is missing, with no default
>
> >
> summary(svyglm(F3ATTAINMENT~F1PARED+F1SES2QU,design=elsq1ch_brr,su
> bset
> > =BYSCTRL==1 & G10COHRT==1,na.action(na.omit))
> +
> Any guidance you would be willing to provide is greatly appreciated; I have
> only been using R for about 6 months.
> Sincerely
> Courtney
>
> Courtney Benjamin
> Broome-Tioga BOCES
> Automotive Technology II Teacher
> Located at Gault Toyota
> Doctoral Candidate-Educational Theory & Practice State University of New York
> at Binghamton cbenjami at btboces.org
> 607-763-8633
>
> ________________________________________
> From: Fox, John <jfox at mcmaster.ca>
> Sent: Saturday, September 24, 2016 9:38 AM
> To: Courtney Benjamin
> Cc: r-help at r-project.org
> Subject: RE: Svyglm Error in Survey Package
>
> Dear Courtney,
>
> I think that you're confused about how to use the subset argument to svyglm()
> and about what the subset() function returns. The subset argument should be a
> logical expression, evaluating to TRUE or FALSE for each case; subset() returns
> a data set (e.g., a "survey.design" object).
>
> Here's an example adapted from ?svyglm:
>
> ------------------- snip-------------------
> data(api)
> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
> summary(svyglm(api00~ell+meals+mobility, design=dstrat))
> summary(svyglm(api00~ell+meals+mobility, design=dstrat, subset = pcttest >
> 90)) summary(svyglm(api00~ell+meals+mobility, design=subset(dstrat, subset
> = pcttest > 90)))
> ------------------- snip-------------------
>
> The last two commands produce the same results.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Courtney Benjamin
> > Sent: September 23, 2016 11:01 PM
> > To: r-help at r-project.org
> > Subject: [R] Svyglm Error in Survey Package
> >
> > In attempting to use the svyglm call in the R Survey Package, I am
> > receiving the
> > error: Error in pwt[i] : invalid subscript type 'list'
> >
> > I have not been able to find a lot of information on how to resolve
> > the error; one source advised it was related to how the subsetting
> > command was executed.
> >
> > This was my initial attempt:
> >
> > mc1 <-
> >
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset(elsq1ch_brr,
> > BYSCTRL==1 & G10COHRT==1),na.action)
> > summary(mc1)
> > This was my second approach trying to change up how I had subsetted
> > the
> > data:
> > summary(mc1)
> > samp1 <- subset(elsq1ch_brr,BYSCTRL==1 & G10COHRT==1)
> > dim(samp1)
> > mc1 <-
> >
> svyglm(F3ATTAINMENT~F1SES2QU+F1RGPP2,elsq1ch_brr,subset=samp1,na.ac
> > tion)
> > summary(mc1)?
> >
> > Both attempts resulted in the same error stated above.  Any advisement
> > in how to resolve this error would be greatly appreciated.
> > Sincerely,
> > Courtney Benjamin
> >
> > ?
> >
> >
> >
> > Courtney Benjamin
> >
> > Broome-Tioga BOCES
> >
> > Automotive Technology II Teacher
> >
> > Located at Gault Toyota
> >
> > Doctoral Candidate-Educational Theory & Practice
> >
> > State University of New York at Binghamton
> >
> > cbenjami at btboces.org<mailto:cbenjami at btboces.org>
> >
> > 607-763-8633
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep 25 19:20:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Sep 2016 10:20:18 -0700
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
Message-ID: <FC38E366-C7A0-48E1-89AB-62C88902B0E3@dcn.davis.ca.us>

Object clka not found.

Did you test run it in a fresh R environment? 
-- 
Sent from my phone. Please excuse my brevity.

On September 25, 2016 9:37:56 AM PDT, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>Okay here?s a pretty short code to reproduce it:
>
>data <-
>read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt",
>header=TRUE)
>attach(data)
>
>fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
>
>bs <- coef(fit2)
>
>varitB <- c(data[koulu == 'B',]$mies)
>varitB[varitB == 0] = 2
>plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist,
>col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)
>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>from=min(lka), to=max(lka), add=TRUE, col='red')
>
>
>> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> Go directly to C. Do not pass go, do not collect $200.
>> 
>> You think curve does something, but you are missing what it actually
>does. Since you don't seem to be learning from reading ?curve or from
>our responses, you need to give us an example you can learn from. 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi>
>wrote:
>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>> You seem to be confused about what curve is doing vs. what you are 
>>>> doing.
>>> 
>>> But my x-range in curve()'s parameters from and to should be the
>entire
>>> 
>>> lka vector, since they are from=min(lka) and to=max(lka). Then why
>does
>>> 
>>> this not span the entire of lka? Because of duplicate entries or
>what?
>>> 
>>> It seems like I cannot use curve(), since my x-axis must be exactly
>lka
>>> 
>>> for the function to plot the y value for every lka value.
>>> 
>>>> A) Compute the points you want to plot and put them into 2 vectors.
>>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>>> putting that all into one line of code again.
>>>> 
>>>> B) The predict function is the preferred way to compute points. It
>>> may
>>>> be educational for you to do the computations by hand at first, but
>>> in
>>>> the long run using predict will help you avoid problems getting the
>>>> equations right in multiple places in your script.
>>>> 
>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>>> ask
>>>> your questions with reproducible code and data so we can give you
>>>> concrete responses.
>>>> 
>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>> [2]
>>>> 
>>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa
><mviljamaa at kapsi.fi> 
>>>> wrote:
>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>> Writing:
>>>>>>> 
>>>>>>> 
>>>>> 
>>>
>bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>> 
>>>>>>> i.e. without that being inside curve produces a vector of length
>>>>> 375.
>>>>>>> 
>>>>>>> So now it seems that curve() is really skipping some
>>> lka-/x-values.
>>>>>> 
>>>>>> How could curve() know what the length of lka is?  You're telling
>>> it
>>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>> 
>>>>>> curve() is designed to plot expressions or functions, not
>vectors.
>>>>> If
>>>>>> you actually want to plot line segments using your original data,
>>> use
>>>>>> lines().  (You'll likely need to sort your x values into
>increasing
>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>> 
>>>>>> Duncan Murdoch
>>>>> 
>>>>> I know that about curve(), but since this function uses lka as a
>>>>> parameter, then how should I formulate it for curve so that I
>don't 
>>>>> get
>>>>> 
>>>>> the error about wrong lengths?
>>>>> 
>>>>>>> 
>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>>> wrote:
>>>>>>>> 
>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>> 
>>>>>>>> The way I do it is:
>>>>>>>> 
>>>>>>>> bs <- coef(fit2)
>>>>>>>> 
>>>>>>>> and then for example:
>>>>>>>> 
>>>>>>>> 
>>>>> 
>>>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>> 
>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>> 
>>>>>>>> This above code runs into error:
>>>>>>>> 
>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 +
>bs["kouluB"]
>>> +
>>>>>>>> bs["lka"] *  :
>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>> In addition: Warning message:
>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] +
>bs["lka"]
>>> *
>>>>> :
>>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>>> 
>>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>>> different objects being multiplied or summed.
>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>> 
>>>>>>>> g <-
>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>> 
>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>> 
>>>>>>>> returns 101.
>>>>>>>> 
>>>>>>>> However length(lka) is 375. But perhaps these being different
>is
>>>>> not
>>>>>>>> the problem?
>>>>>>>> 
>>>>>>>> I however do see that the whole range of lka is not plotted,
>for
>>>>> some
>>>>>>>> reason. So how can I be sure
>>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>>> lengths
>>>>>>>> of objects inside curve() are correct?
>>>>>>>> 
>>>>>>>> What can I do?
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From mviljamaa at kapsi.fi  Sun Sep 25 19:21:37 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Sun, 25 Sep 2016 20:21:37 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
Message-ID: <69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>


> On 25 Sep 2016, at 19:37, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> 
> Okay here?s a pretty short code to reproduce it:
> 
> data <- read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE)

data$clka <- I(data$lka - mean(data$lka))

> attach(data)
> 
> fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
> 
> bs <- coef(fit2)
> 
> varitB <- c(data[koulu == 'B',]$mies)
> varitB[varitB == 0] = 2
> plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)
> 
> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
> 
> 
>> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> Go directly to C. Do not pass go, do not collect $200.
>> 
>> You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from. 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>> You seem to be confused about what curve is doing vs. what you are 
>>>> doing.
>>> 
>>> But my x-range in curve()'s parameters from and to should be the entire
>>> 
>>> lka vector, since they are from=min(lka) and to=max(lka). Then why does
>>> 
>>> this not span the entire of lka? Because of duplicate entries or what?
>>> 
>>> It seems like I cannot use curve(), since my x-axis must be exactly lka
>>> 
>>> for the function to plot the y value for every lka value.
>>> 
>>>> A) Compute the points you want to plot and put them into 2 vectors.
>>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>>> putting that all into one line of code again.
>>>> 
>>>> B) The predict function is the preferred way to compute points. It
>>> may
>>>> be educational for you to do the computations by hand at first, but
>>> in
>>>> the long run using predict will help you avoid problems getting the
>>>> equations right in multiple places in your script.
>>>> 
>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>>> ask
>>>> your questions with reproducible code and data so we can give you
>>>> concrete responses.
>>>> 
>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>> [2]
>>>> 
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi> 
>>>> wrote:
>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>> Writing:
>>>>>>> 
>>>>>>> 
>>>>> 
>>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>> 
>>>>>>> i.e. without that being inside curve produces a vector of length
>>>>> 375.
>>>>>>> 
>>>>>>> So now it seems that curve() is really skipping some
>>> lka-/x-values.
>>>>>> 
>>>>>> How could curve() know what the length of lka is?  You're telling
>>> it
>>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>> 
>>>>>> curve() is designed to plot expressions or functions, not vectors.
>>>>> If
>>>>>> you actually want to plot line segments using your original data,
>>> use
>>>>>> lines().  (You'll likely need to sort your x values into increasing
>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>> 
>>>>>> Duncan Murdoch
>>>>> 
>>>>> I know that about curve(), but since this function uses lka as a
>>>>> parameter, then how should I formulate it for curve so that I don't 
>>>>> get
>>>>> 
>>>>> the error about wrong lengths?
>>>>> 
>>>>>>> 
>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>>> wrote:
>>>>>>>> 
>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>> 
>>>>>>>> The way I do it is:
>>>>>>>> 
>>>>>>>> bs <- coef(fit2)
>>>>>>>> 
>>>>>>>> and then for example:
>>>>>>>> 
>>>>>>>> 
>>>>> 
>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>> 
>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>> 
>>>>>>>> This above code runs into error:
>>>>>>>> 
>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>>> +
>>>>>>>> bs["lka"] *  :
>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>> In addition: Warning message:
>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>>> *
>>>>> :
>>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>>> 
>>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>>> different objects being multiplied or summed.
>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>> 
>>>>>>>> g <-
>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>> 
>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>> 
>>>>>>>> returns 101.
>>>>>>>> 
>>>>>>>> However length(lka) is 375. But perhaps these being different is
>>>>> not
>>>>>>>> the problem?
>>>>>>>> 
>>>>>>>> I however do see that the whole range of lka is not plotted, for
>>>>> some
>>>>>>>> reason. So how can I be sure
>>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>>> lengths
>>>>>>>> of objects inside curve() are correct?
>>>>>>>> 
>>>>>>>> What can I do?
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From jdnewmil at dcn.davis.ca.us  Sun Sep 25 20:23:45 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Sep 2016 11:23:45 -0700 (PDT)
Subject: [R] curve() doesn't seem to use the whole range of x? And
 Error: longer object length is not a multiple of shorter object length
In-Reply-To: <69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
	<69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>
Message-ID: <alpine.BSF.2.00.1609251108250.25794@pedal.dcn.davis.ca.us>

This illustrates why you need to post a reproducible example. You have a 
number of confounding factors in your code.

First, "data" is a commonly-used function... avoid using it for variable 
names.

Second, using the attach function this way leads to confusion... best to 
forget this function until you start building packages.

Third, clka is linearly dependent on lka, so having them both in the 
regression is not possible. In this case lm has chosen to ignore clka so 
that bs("clka") is NA.

Fourth, curve expects you to give it a function, and instead you have 
given it a vector.

Fifth, you are plotting versus lka, but attempting to vary clka in the 
curve call.

There are a number of directions you could go with this to get a working 
output... below is my version.

dta <- read.table( "http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE )
fit2 <- lm( ruotsi.pist ~ mies + koulu*lka, data=dta )
bs <- coef( fit2 )
rpBylka <- function( lka ) {
   kouluB <- factor( "B", levels = levels( dta$koulu ) )
   newdta <- expand.grid( mies=0, koulu=kouluB, lka=lka )
   predict( fit2, newdata = newdta )
}
dtaKouluB <- subset( dta, koulu == "B" )
varitB <- dtaKouluB$mies
varitB[ varitB == 0 ] <- 2
plot( dtaKouluB$lka
     , dtaKouluB$ruotsi.pist
     , col=varitB
     , pch=16
     , xlab='lka'
     , ylab='ruotsi.pist'
     , main='Lukio B'
     )
curve( rpBylka, from = min( dta$lka ), max( dta$lka ), add=TRUE, col="red" )

On Sun, 25 Sep 2016, Matti Viljamaa wrote:

>
>> On 25 Sep 2016, at 19:37, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>>
>> Okay here?s a pretty short code to reproduce it:
>>
>> data <- read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE)
>
> data$clka <- I(data$lka - mean(data$lka))
>
>> attach(data)
>>
>> fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
>>
>> bs <- coef(fit2)
>>
>> varitB <- c(data[koulu == 'B',]$mies)
>> varitB[varitB == 0] = 2
>> plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)
>>
>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
>>
>>
>>> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> Go directly to C. Do not pass go, do not collect $200.
>>>
>>> You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>>> You seem to be confused about what curve is doing vs. what you are
>>>>> doing.
>>>>
>>>> But my x-range in curve()'s parameters from and to should be the entire
>>>>
>>>> lka vector, since they are from=min(lka) and to=max(lka). Then why does
>>>>
>>>> this not span the entire of lka? Because of duplicate entries or what?
>>>>
>>>> It seems like I cannot use curve(), since my x-axis must be exactly lka
>>>>
>>>> for the function to plot the y value for every lka value.
>>>>
>>>>> A) Compute the points you want to plot and put them into 2 vectors.
>>>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>>>> putting that all into one line of code again.
>>>>>
>>>>> B) The predict function is the preferred way to compute points. It
>>>> may
>>>>> be educational for you to do the computations by hand at first, but
>>>> in
>>>>> the long run using predict will help you avoid problems getting the
>>>>> equations right in multiple places in your script.
>>>>>
>>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>>>> ask
>>>>> your questions with reproducible code and data so we can give you
>>>>> concrete responses.
>>>>>
>>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>>> [2]
>>>>>
>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi>
>>>>> wrote:
>>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>>> Writing:
>>>>>>>>
>>>>>>>>
>>>>>>
>>>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>>>
>>>>>>>> i.e. without that being inside curve produces a vector of length
>>>>>> 375.
>>>>>>>>
>>>>>>>> So now it seems that curve() is really skipping some
>>>> lka-/x-values.
>>>>>>>
>>>>>>> How could curve() know what the length of lka is?  You're telling
>>>> it
>>>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>>>
>>>>>>> curve() is designed to plot expressions or functions, not vectors.
>>>>>> If
>>>>>>> you actually want to plot line segments using your original data,
>>>> use
>>>>>>> lines().  (You'll likely need to sort your x values into increasing
>>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>>>
>>>>>>> Duncan Murdoch
>>>>>>
>>>>>> I know that about curve(), but since this function uses lka as a
>>>>>> parameter, then how should I formulate it for curve so that I don't
>>>>>> get
>>>>>>
>>>>>> the error about wrong lengths?
>>>>>>
>>>>>>>>
>>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>>>
>>>>>>>>> The way I do it is:
>>>>>>>>>
>>>>>>>>> bs <- coef(fit2)
>>>>>>>>>
>>>>>>>>> and then for example:
>>>>>>>>>
>>>>>>>>>
>>>>>>
>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>>>
>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>
>>>>>>>>> This above code runs into error:
>>>>>>>>>
>>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>>>> +
>>>>>>>>> bs["lka"] *  :
>>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>>> In addition: Warning message:
>>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>>>> *
>>>>>> :
>>>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>>>>
>>>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>>>> different objects being multiplied or summed.
>>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>>>
>>>>>>>>> g <-
>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>>>
>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>
>>>>>>>>> returns 101.
>>>>>>>>>
>>>>>>>>> However length(lka) is 375. But perhaps these being different is
>>>>>> not
>>>>>>>>> the problem?
>>>>>>>>>
>>>>>>>>> I however do see that the whole range of lka is not plotted, for
>>>>>> some
>>>>>>>>> reason. So how can I be sure
>>>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>>>> lengths
>>>>>>>>> of objects inside curve() are correct?
>>>>>>>>>
>>>>>>>>> What can I do?
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From rmh at temple.edu  Sun Sep 25 20:44:25 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 25 Sep 2016 14:44:25 -0400
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
	<CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
	<CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>
Message-ID: <CAGx1TMA0B1m=CpbYso3LXQ0wRFte4=d0=Zr2zkq0DNGFgqTU-g@mail.gmail.com>

library(lattice)
library(latticeExtra)
tmp <- data.frame(x=1:10, y=1:10)

xyplot(y ~ x, data=tmp)

xyplot(y ~ x, data=tmp, main="text outside panel clipped") +
  ## "+" must be on same line as first statement.
  ## This use of "+" is from latticeExtra.
  latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))

xyplot(y ~ x, data=tmp, main="outside text displayed",
       par.settings=list(clip=list(panel=FALSE)) ## permit text
outside the panel
                         ) +
  ## "+" must be on same line as first statement.
  ## This use of "+" is from latticeExtra.
  latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))

## I use the phrasing "latticeExtra::layer", not the simpler "layer".
## latticeExtra and ggplot2 both use layer and they use it incompatibly.
## It is possible for both packages to be loaded at the same time, therefore
## I specify latticeExtra explicitly.

## ltext and panel.text are the same.


On Sun, Sep 25, 2016 at 12:32 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Thanks Bert, sub works pretty well.
>
> Carlos, thanks for the suggestion. As I am not familiar with latticeExatra,
> not sure how hard it is to make it work with my plot. I'll try.
>
> On Sat, Sep 24, 2016 at 11:04 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> No.
>>
>> ltext/panel.text plots text *within* panels; IIUC, the  OP requested
>> text outside the plots. For that see the details for "main" and/or
>> "sub" in ?xyplot. I think it could also be done more flexibly via a
>> legend or a key with a title but no content -- again, see the Help
>> page -- but haven't tried it.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de> wrote:
>> > Hi,
>> >
>> > one possible solution is to use ltext().
>> >
>> > ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
>> >
>> > You have to know or to find out best fitting coordinates.
>> >
>> > Via adj you can control, if the text should adjust left, center or right
>> > to the coords, and above, center or bottom of them.
>> >
>> > HTH,
>> > Rainer Hurling
>> >
>> >
>> > Am 22.09.2016 um 16:04 schrieb Jun Shen:
>> >> Dear list,
>> >>
>> >> Just wonder if there is a way to add annotation text outside an xyplot,
>> >> (e.g. the bottom of the plot). the panel.text seems only add text within
>> >> the plot. Thanks.
>> >>
>> >> Jun
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Sun Sep 25 21:19:59 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Sun, 25 Sep 2016 19:19:59 +0000 (UTC)
Subject: [R] BCa confidence bands around fitted curves MARS regression
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
Message-ID: <2091422228.8503672.1474831199161@mail.yahoo.com>

Dear R-experts,

I have fitted a MARS regression and am trying now to plot/draw the BCa confidence bands around the 3 fitted curves (QUALITESANSREDONDANC, competitivite and innovation).


Here is the reproducible example.


############################

Dataset = data.frame(PIBparHab=c(43931,67524,48348,44827,52409,15245,24453,57636,28992,17102,51495,47243,40908,22494,12784,48391,44221,32514,35132,46679,106022,9817,99635,38678,49128,12876,20732,17151,19670,41053,22488,57134,83295,10660),

QUALITESANSREDONDANCE=c(1082.5,1066.6,1079.3,1079.9,1074.9,1008.6,1007.5,1111.3,1108.2,1109.7,1059.6,1165.1,1026.7,1035.1,997.8,1044.8,1073.6,1085.7,1083.8,1021.6,1036.2,1075.3,1069.3,1101.4,1086.9,1072.1,1166.7,983.9,1004.5,1082.5,1123.5,1094.9,1105.1,1010.8),

competitivite=c(89,83,78,73,90,71,77,85,61,67,98,82,70,43,57,78,72,79,61,71,86,63,90,75,87,64,60,56,66,80,53,91,97,62),

innovation=c(56,52,53,54,57,43,54,60,47,55,58,62,52,35,47,59,56,56,45,52,58,33,57,57,61,40,45,41,50,61,50,65,68,34))

install.packages("earth")

library(earth)

newdata=na.omit(Dataset)

model=earth(PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation,data=newdata, penalty=-1)

summary(model)

plot(model)

plotmo(model)


############################

Best Regards,
S


From fabien.tarrade at gmail.com  Sun Sep 25 21:22:37 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 25 Sep 2016 21:22:37 +0200
Subject: [R] how to remove all messages when loading a library ?
Message-ID: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>

Hi there,

I would like to remove all messages when I load library (I fact I am 
using "require" and "install.packages"). I tried many options and look 
at the documentation for the 2 functions.
For example I am using the following piece of code: init.R

print("step 1")
# Install library if not installed
if (!require("plyr",quietly=TRUE,warn.conflicts=FALSE)) 
suppressMessages(install.packages("plyr",quietly=TRUE))
if (!require("dplyr",quietly=TRUE)) 
suppressMessages(install.packages("dplyr",quietly=TRUE))
if (!require("stringr",quietly=TRUE)) 
suppressMessages(install.packages("stringr",quietly=TRUE))
if (!require("readr",quietly=TRUE)) 
suppressMessages(install.packages("readr",quietly=TRUE))
if (!require("tidyr",quietly=TRUE)) 
suppressMessages(install.packages("tidyr",quietly=TRUE))
if (!require("XML",quietly=TRUE)) 
suppressMessages(install.packages("XML",quietly=TRUE))
if (!require("Rcpp",quietly=TRUE)) 
suppressMessages(install.packages("Rcpp",quietly=TRUE))
if (!require("rbenchmark",quietly=TRUE)) 
suppressMessages(install.packages("rbenchmark",quietly=TRUE))
if (!require("tiff",quietly=TRUE)) 
suppressMessages(install.packages("tiff",quietly=TRUE))
if (!require("xlsx",quietly=TRUE)) 
suppressMessages(install.packages("xlsx",quietly=TRUE))
if (!require("ROracle",quietly=TRUE)) 
suppressMessages(install.packages("T:/CH/R/ROracle_1.2-2.zip", repos = 
NULL, type = "source",quietly=TRUE))
print("step 2")

and I run the code in this way:
 > source("./init.R",encoding = 
"UTF-8",verbose=FALSE,echo=FALSE,print.eval=FALSE)

and I get the following output that I don't manage to remove:

[1] "step 1"

Attache Paket: ?dplyr?

Die folgenden Objekte sind maskiert von ?package:plyr?:

     arrange, count, desc, failwith, id, mutate, rename, summarise, 
summarize

Die folgenden Objekte sind maskiert von ?package:stats?:

     filter, lag

Die folgenden Objekte sind maskiert von ?package:base?:

     intersect, setdiff, setequal, union
[1] "step 2"

What is the way to get no messages at all when loading library ? ( or 
using other R function in general).
I am trying to keep only the important messages and so far I am getting 
way too much messages.

Thanks
Cheers
Fabien


-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Zurich, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>

From bgunter.4567 at gmail.com  Sun Sep 25 22:34:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Sep 2016 13:34:53 -0700
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAGx1TMA0B1m=CpbYso3LXQ0wRFte4=d0=Zr2zkq0DNGFgqTU-g@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
	<CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
	<CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>
	<CAGx1TMA0B1m=CpbYso3LXQ0wRFte4=d0=Zr2zkq0DNGFgqTU-g@mail.gmail.com>
Message-ID: <CAGxFJbTJ62UZRZQ4MnBAmo7kigLvJVvQvc-OQ+j1yfgY9ZW0oA@mail.gmail.com>

... but what if there are multiple panels?

"The layer mechanism is a method for augmenting a panel function. It
allows expressions to be added to the panel function without knowing
what the original panel function was. "

As I understand it, the OP requested annotation for the entire lattice
display, not single panels thereof. This seems more like a "sub" or
"legend"  addition.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 25, 2016 at 11:44 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> library(lattice)
> library(latticeExtra)
> tmp <- data.frame(x=1:10, y=1:10)
>
> xyplot(y ~ x, data=tmp)
>
> xyplot(y ~ x, data=tmp, main="text outside panel clipped") +
>   ## "+" must be on same line as first statement.
>   ## This use of "+" is from latticeExtra.
>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))
>
> xyplot(y ~ x, data=tmp, main="outside text displayed",
>        par.settings=list(clip=list(panel=FALSE)) ## permit text
> outside the panel
>                          ) +
>   ## "+" must be on same line as first statement.
>   ## This use of "+" is from latticeExtra.
>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))
>
> ## I use the phrasing "latticeExtra::layer", not the simpler "layer".
> ## latticeExtra and ggplot2 both use layer and they use it incompatibly.
> ## It is possible for both packages to be loaded at the same time, therefore
> ## I specify latticeExtra explicitly.
>
> ## ltext and panel.text are the same.
>
>
> On Sun, Sep 25, 2016 at 12:32 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>> Thanks Bert, sub works pretty well.
>>
>> Carlos, thanks for the suggestion. As I am not familiar with latticeExatra,
>> not sure how hard it is to make it work with my plot. I'll try.
>>
>> On Sat, Sep 24, 2016 at 11:04 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> No.
>>>
>>> ltext/panel.text plots text *within* panels; IIUC, the  OP requested
>>> text outside the plots. For that see the details for "main" and/or
>>> "sub" in ?xyplot. I think it could also be done more flexibly via a
>>> legend or a key with a title but no content -- again, see the Help
>>> page -- but haven't tried it.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de> wrote:
>>> > Hi,
>>> >
>>> > one possible solution is to use ltext().
>>> >
>>> > ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
>>> >
>>> > You have to know or to find out best fitting coordinates.
>>> >
>>> > Via adj you can control, if the text should adjust left, center or right
>>> > to the coords, and above, center or bottom of them.
>>> >
>>> > HTH,
>>> > Rainer Hurling
>>> >
>>> >
>>> > Am 22.09.2016 um 16:04 schrieb Jun Shen:
>>> >> Dear list,
>>> >>
>>> >> Just wonder if there is a way to add annotation text outside an xyplot,
>>> >> (e.g. the bottom of the plot). the panel.text seems only add text within
>>> >> the plot. Thanks.
>>> >>
>>> >> Jun
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Sep 25 22:39:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Sep 2016 13:39:50 -0700
Subject: [R] BCa confidence bands around fitted curves MARS regression
In-Reply-To: <2091422228.8503672.1474831199161@mail.yahoo.com>
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
	<2091422228.8503672.1474831199161@mail.yahoo.com>
Message-ID: <CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>

Presumably the "earth" package lacks this functionality ...?

So, obvious query: did you try using the boot package? If not, why
not? If so, show us the code that failed.

Or am I missing the point?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 25, 2016 at 12:19 PM, varin sacha via R-help
<r-help at r-project.org> wrote:
> Dear R-experts,
>
> I have fitted a MARS regression and am trying now to plot/draw the BCa confidence bands around the 3 fitted curves (QUALITESANSREDONDANC, competitivite and innovation).
>
>
> Here is the reproducible example.
>
>
> ############################
>
> Dataset = data.frame(PIBparHab=c(43931,67524,48348,44827,52409,15245,24453,57636,28992,17102,51495,47243,40908,22494,12784,48391,44221,32514,35132,46679,106022,9817,99635,38678,49128,12876,20732,17151,19670,41053,22488,57134,83295,10660),
>
> QUALITESANSREDONDANCE=c(1082.5,1066.6,1079.3,1079.9,1074.9,1008.6,1007.5,1111.3,1108.2,1109.7,1059.6,1165.1,1026.7,1035.1,997.8,1044.8,1073.6,1085.7,1083.8,1021.6,1036.2,1075.3,1069.3,1101.4,1086.9,1072.1,1166.7,983.9,1004.5,1082.5,1123.5,1094.9,1105.1,1010.8),
>
> competitivite=c(89,83,78,73,90,71,77,85,61,67,98,82,70,43,57,78,72,79,61,71,86,63,90,75,87,64,60,56,66,80,53,91,97,62),
>
> innovation=c(56,52,53,54,57,43,54,60,47,55,58,62,52,35,47,59,56,56,45,52,58,33,57,57,61,40,45,41,50,61,50,65,68,34))
>
> install.packages("earth")
>
> library(earth)
>
> newdata=na.omit(Dataset)
>
> model=earth(PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation,data=newdata, penalty=-1)
>
> summary(model)
>
> plot(model)
>
> plotmo(model)
>
>
> ############################
>
> Best Regards,
> S
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Sep 25 22:42:57 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 25 Sep 2016 16:42:57 -0400
Subject: [R] how to remove all messages when loading a library ?
In-Reply-To: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>
References: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>
Message-ID: <CAAxdm-7j7_KGuX9+dKuJu9yGJuWDYZb2259xECUM635V2Qe6Xw@mail.gmail.com>

Try enclosing the whole thing in "suppressMessages";

suppressMessages({
    if (!require("plyr",quietly=TRUE,warn.conflicts=FALSE))
suppressMessages(install.packages("plyr",quietly=TRUE))
    if (!require("dplyr",quietly=TRUE))
suppressMessages(install.packages("dplyr",quietly=TRUE))
    if (!require("stringr",quietly=TRUE))
suppressMessages(install.packages("stringr",quietly=TRUE))
    if (!require("readr",quietly=TRUE))
suppressMessages(install.packages("readr",quietly=TRUE))
    if (!require("tidyr",quietly=TRUE))
suppressMessages(install.packages("tidyr",quietly=TRUE))
    if (!require("XML",quietly=TRUE))
suppressMessages(install.packages("XML",quietly=TRUE))
    if (!require("Rcpp",quietly=TRUE))
suppressMessages(install.packages("Rcpp",quietly=TRUE))
    if (!require("rbenchmark",quietly=TRUE))
suppressMessages(install.packages("rbenchmark",quietly=TRUE))
    if (!require("tiff",quietly=TRUE))
suppressMessages(install.packages("tiff",quietly=TRUE))
    if (!require("xlsx",quietly=TRUE))
suppressMessages(install.packages("xlsx",quietly=TRUE))
    if (!require("ROracle",quietly=TRUE))
suppressMessages(install.packages("T:/CH/R/ROracle_1.2-2.zip", repos =
NULL, type = "source",quietly=TRUE))
})




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Sep 25, 2016 at 3:22 PM, Fabien Tarrade <fabien.tarrade at gmail.com>
wrote:

> Hi there,
>
> I would like to remove all messages when I load library (I fact I am using
> "require" and "install.packages"). I tried many options and look at the
> documentation for the 2 functions.
> For example I am using the following piece of code: init.R
>
> print("step 1")
> # Install library if not installed
> if (!require("plyr",quietly=TRUE,warn.conflicts=FALSE))
> suppressMessages(install.packages("plyr",quietly=TRUE))
> if (!require("dplyr",quietly=TRUE)) suppressMessages(install.packa
> ges("dplyr",quietly=TRUE))
> if (!require("stringr",quietly=TRUE)) suppressMessages(install.packa
> ges("stringr",quietly=TRUE))
> if (!require("readr",quietly=TRUE)) suppressMessages(install.packa
> ges("readr",quietly=TRUE))
> if (!require("tidyr",quietly=TRUE)) suppressMessages(install.packa
> ges("tidyr",quietly=TRUE))
> if (!require("XML",quietly=TRUE)) suppressMessages(install.packa
> ges("XML",quietly=TRUE))
> if (!require("Rcpp",quietly=TRUE)) suppressMessages(install.packa
> ges("Rcpp",quietly=TRUE))
> if (!require("rbenchmark",quietly=TRUE)) suppressMessages(install.packa
> ges("rbenchmark",quietly=TRUE))
> if (!require("tiff",quietly=TRUE)) suppressMessages(install.packa
> ges("tiff",quietly=TRUE))
> if (!require("xlsx",quietly=TRUE)) suppressMessages(install.packa
> ges("xlsx",quietly=TRUE))
> if (!require("ROracle",quietly=TRUE)) suppressMessages(install.packa
> ges("T:/CH/R/ROracle_1.2-2.zip", repos = NULL, type =
> "source",quietly=TRUE))
> print("step 2")
>
> and I run the code in this way:
> > source("./init.R",encoding = "UTF-8",verbose=FALSE,echo=FAL
> SE,print.eval=FALSE)
>
> and I get the following output that I don't manage to remove:
>
> [1] "step 1"
>
> Attache Paket: ?dplyr?
>
> Die folgenden Objekte sind maskiert von ?package:plyr?:
>
>     arrange, count, desc, failwith, id, mutate, rename, summarise,
> summarize
>
> Die folgenden Objekte sind maskiert von ?package:stats?:
>
>     filter, lag
>
> Die folgenden Objekte sind maskiert von ?package:base?:
>
>     intersect, setdiff, setequal, union
> [1] "step 2"
>
> What is the way to get no messages at all when loading library ? ( or
> using other R function in general).
> I am trying to keep only the important messages and so far I am getting
> way too much messages.
>
> Thanks
> Cheers
> Fabien
>
>
> --
> Dr Fabien Tarrade
>
> Quantitative Analyst/Developer - Data Scientist
>
> Senior data analyst specialised in the modelling, processing and
> statistical treatment of data.
> PhD in Physics, 10 years of experience as researcher at the forefront of
> international scientific research.
> Fascinated by finance and data modelling.
>
> Zurich, Switzerland
>
> Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
> Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
>
> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter <
> https://twitter.com/fabtar> Google <https://plus.google.com/+Fabi
> enTarradeProfile/posts> Facebook <https://www.facebook.com/fabi
> en.tarrade.eu> Google <skype:fabtarhiggs?call> Xing <
> https://www.xing.com/profile/Fabien_Tarrade>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Sep 25 22:47:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Sep 2016 13:47:22 -0700
Subject: [R] how to remove all messages when loading a library ?
In-Reply-To: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>
References: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>
Message-ID: <CAGxFJbRoCrxVbqeGBTKv2hc0BdXuW7D4AxORY86fBMMF0Z+5GA@mail.gmail.com>

?? Dont you already have the answer: you must set warn.conflicts =
FALSE in all your library calls.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 25, 2016 at 12:22 PM, Fabien Tarrade
<fabien.tarrade at gmail.com> wrote:
> Hi there,
>
> I would like to remove all messages when I load library (I fact I am using
> "require" and "install.packages"). I tried many options and look at the
> documentation for the 2 functions.
> For example I am using the following piece of code: init.R
>
> print("step 1")
> # Install library if not installed
> if (!require("plyr",quietly=TRUE,warn.conflicts=FALSE))
> suppressMessages(install.packages("plyr",quietly=TRUE))
> if (!require("dplyr",quietly=TRUE))
> suppressMessages(install.packages("dplyr",quietly=TRUE))
> if (!require("stringr",quietly=TRUE))
> suppressMessages(install.packages("stringr",quietly=TRUE))
> if (!require("readr",quietly=TRUE))
> suppressMessages(install.packages("readr",quietly=TRUE))
> if (!require("tidyr",quietly=TRUE))
> suppressMessages(install.packages("tidyr",quietly=TRUE))
> if (!require("XML",quietly=TRUE))
> suppressMessages(install.packages("XML",quietly=TRUE))
> if (!require("Rcpp",quietly=TRUE))
> suppressMessages(install.packages("Rcpp",quietly=TRUE))
> if (!require("rbenchmark",quietly=TRUE))
> suppressMessages(install.packages("rbenchmark",quietly=TRUE))
> if (!require("tiff",quietly=TRUE))
> suppressMessages(install.packages("tiff",quietly=TRUE))
> if (!require("xlsx",quietly=TRUE))
> suppressMessages(install.packages("xlsx",quietly=TRUE))
> if (!require("ROracle",quietly=TRUE))
> suppressMessages(install.packages("T:/CH/R/ROracle_1.2-2.zip", repos = NULL,
> type = "source",quietly=TRUE))
> print("step 2")
>
> and I run the code in this way:
>> source("./init.R",encoding =
>> "UTF-8",verbose=FALSE,echo=FALSE,print.eval=FALSE)
>
> and I get the following output that I don't manage to remove:
>
> [1] "step 1"
>
> Attache Paket: ?dplyr?
>
> Die folgenden Objekte sind maskiert von ?package:plyr?:
>
>     arrange, count, desc, failwith, id, mutate, rename, summarise, summarize
>
> Die folgenden Objekte sind maskiert von ?package:stats?:
>
>     filter, lag
>
> Die folgenden Objekte sind maskiert von ?package:base?:
>
>     intersect, setdiff, setequal, union
> [1] "step 2"
>
> What is the way to get no messages at all when loading library ? ( or using
> other R function in general).
> I am trying to keep only the important messages and so far I am getting way
> too much messages.
>
> Thanks
> Cheers
> Fabien
>
>
> --
> Dr Fabien Tarrade
>
> Quantitative Analyst/Developer - Data Scientist
>
> Senior data analyst specialised in the modelling, processing and statistical
> treatment of data.
> PhD in Physics, 10 years of experience as researcher at the forefront of
> international scientific research.
> Fascinated by finance and data modelling.
>
> Zurich, Switzerland
>
> Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
> Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
>
> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
> <https://twitter.com/fabtar> Google
> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
> Xing <https://www.xing.com/profile/Fabien_Tarrade>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sun Sep 25 23:18:36 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 25 Sep 2016 17:18:36 -0400
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAGxFJbTJ62UZRZQ4MnBAmo7kigLvJVvQvc-OQ+j1yfgY9ZW0oA@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
	<CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
	<CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>
	<CAGx1TMA0B1m=CpbYso3LXQ0wRFte4=d0=Zr2zkq0DNGFgqTU-g@mail.gmail.com>
	<CAGxFJbTJ62UZRZQ4MnBAmo7kigLvJVvQvc-OQ+j1yfgY9ZW0oA@mail.gmail.com>
Message-ID: <CAGx1TMCKnKaGcfgR6LJnm=VOx2Zgtt1jiHO24OeE6VayaKrQKw@mail.gmail.com>

Bert,

I interpreted the OP's request as a single panel xyplot.
The latticeExtra::layer mechanism does work for multiple plots.


library(lattice)
library(latticeExtra)
tmp <- data.frame(x=1:10, y=1:10, g=rep(c("A","B"), each=5))

xyplot(y ~ x | g, data=tmp)

xyplot(y ~ x | g, data=tmp, main="outside text displayed",
       par.settings=list(clip=list(panel=FALSE))) +
  latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))

xyplot(y ~ x | g, data=tmp, main="outside text displayed",
       par.settings=list(clip=list(panel=FALSE))) +
  latticeExtra::layer(panel.text(x=2, y=-0.5,
       label=c("very interesting", "also interesting")[panel.number()]))


For the overall lattice display I agree that the mechanisms you
suggested are approriate.

Rich


On Sun, Sep 25, 2016 at 4:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ... but what if there are multiple panels?
>
> "The layer mechanism is a method for augmenting a panel function. It
> allows expressions to be added to the panel function without knowing
> what the original panel function was. "
>
> As I understand it, the OP requested annotation for the entire lattice
> display, not single panels thereof. This seems more like a "sub" or
> "legend"  addition.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 25, 2016 at 11:44 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> library(lattice)
>> library(latticeExtra)
>> tmp <- data.frame(x=1:10, y=1:10)
>>
>> xyplot(y ~ x, data=tmp)
>>
>> xyplot(y ~ x, data=tmp, main="text outside panel clipped") +
>>   ## "+" must be on same line as first statement.
>>   ## This use of "+" is from latticeExtra.
>>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))
>>
>> xyplot(y ~ x, data=tmp, main="outside text displayed",
>>        par.settings=list(clip=list(panel=FALSE)) ## permit text
>> outside the panel
>>                          ) +
>>   ## "+" must be on same line as first statement.
>>   ## This use of "+" is from latticeExtra.
>>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))
>>
>> ## I use the phrasing "latticeExtra::layer", not the simpler "layer".
>> ## latticeExtra and ggplot2 both use layer and they use it incompatibly.
>> ## It is possible for both packages to be loaded at the same time, therefore
>> ## I specify latticeExtra explicitly.
>>
>> ## ltext and panel.text are the same.
>>
>>
>> On Sun, Sep 25, 2016 at 12:32 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
>>> Thanks Bert, sub works pretty well.
>>>
>>> Carlos, thanks for the suggestion. As I am not familiar with latticeExatra,
>>> not sure how hard it is to make it work with my plot. I'll try.
>>>
>>> On Sat, Sep 24, 2016 at 11:04 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>>> No.
>>>>
>>>> ltext/panel.text plots text *within* panels; IIUC, the  OP requested
>>>> text outside the plots. For that see the details for "main" and/or
>>>> "sub" in ?xyplot. I think it could also be done more flexibly via a
>>>> legend or a key with a title but no content -- again, see the Help
>>>> page -- but haven't tried it.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de> wrote:
>>>> > Hi,
>>>> >
>>>> > one possible solution is to use ltext().
>>>> >
>>>> > ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
>>>> >
>>>> > You have to know or to find out best fitting coordinates.
>>>> >
>>>> > Via adj you can control, if the text should adjust left, center or right
>>>> > to the coords, and above, center or bottom of them.
>>>> >
>>>> > HTH,
>>>> > Rainer Hurling
>>>> >
>>>> >
>>>> > Am 22.09.2016 um 16:04 schrieb Jun Shen:
>>>> >> Dear list,
>>>> >>
>>>> >> Just wonder if there is a way to add annotation text outside an xyplot,
>>>> >> (e.g. the bottom of the plot). the panel.text seems only add text within
>>>> >> the plot. Thanks.
>>>> >>
>>>> >> Jun
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From fabien.tarrade at gmail.com  Sun Sep 25 23:09:20 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 25 Sep 2016 23:09:20 +0200
Subject: [R] how to remove all messages when loading a library ?
In-Reply-To: <CAGxFJbRoCrxVbqeGBTKv2hc0BdXuW7D4AxORY86fBMMF0Z+5GA@mail.gmail.com>
References: <873a4652-40c9-2793-a328-beb4a824ab2a@gmail.com>
	<CAGxFJbRoCrxVbqeGBTKv2hc0BdXuW7D4AxORY86fBMMF0Z+5GA@mail.gmail.com>
Message-ID: <16353088-b6b3-fd7c-05bb-ff7b68173bd6@gmail.com>

Hi Bert,

> ?? Dont you already have the answer: you must set warn.conflicts =
> FALSE in all your library calls.
Thanks. This works. Now understand the logic but first I was thinking 
that removing WARNING messages should remove conflit warning as well.

Anyway it works.

Thanks
Cheers
Fabien
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 25, 2016 at 12:22 PM, Fabien Tarrade
> <fabien.tarrade at gmail.com> wrote:
>> Hi there,
>>
>> I would like to remove all messages when I load library (I fact I am using
>> "require" and "install.packages"). I tried many options and look at the
>> documentation for the 2 functions.
>> For example I am using the following piece of code: init.R
>>
>> print("step 1")
>> # Install library if not installed
>> if (!require("plyr",quietly=TRUE,warn.conflicts=FALSE))
>> suppressMessages(install.packages("plyr",quietly=TRUE))
>> if (!require("dplyr",quietly=TRUE))
>> suppressMessages(install.packages("dplyr",quietly=TRUE))
>> if (!require("stringr",quietly=TRUE))
>> suppressMessages(install.packages("stringr",quietly=TRUE))
>> if (!require("readr",quietly=TRUE))
>> suppressMessages(install.packages("readr",quietly=TRUE))
>> if (!require("tidyr",quietly=TRUE))
>> suppressMessages(install.packages("tidyr",quietly=TRUE))
>> if (!require("XML",quietly=TRUE))
>> suppressMessages(install.packages("XML",quietly=TRUE))
>> if (!require("Rcpp",quietly=TRUE))
>> suppressMessages(install.packages("Rcpp",quietly=TRUE))
>> if (!require("rbenchmark",quietly=TRUE))
>> suppressMessages(install.packages("rbenchmark",quietly=TRUE))
>> if (!require("tiff",quietly=TRUE))
>> suppressMessages(install.packages("tiff",quietly=TRUE))
>> if (!require("xlsx",quietly=TRUE))
>> suppressMessages(install.packages("xlsx",quietly=TRUE))
>> if (!require("ROracle",quietly=TRUE))
>> suppressMessages(install.packages("T:/CH/R/ROracle_1.2-2.zip", repos = NULL,
>> type = "source",quietly=TRUE))
>> print("step 2")
>>
>> and I run the code in this way:
>>> source("./init.R",encoding =
>>> "UTF-8",verbose=FALSE,echo=FALSE,print.eval=FALSE)
>> and I get the following output that I don't manage to remove:
>>
>> [1] "step 1"
>>
>> Attache Paket: ?dplyr?
>>
>> Die folgenden Objekte sind maskiert von ?package:plyr?:
>>
>>      arrange, count, desc, failwith, id, mutate, rename, summarise, summarize
>>
>> Die folgenden Objekte sind maskiert von ?package:stats?:
>>
>>      filter, lag
>>
>> Die folgenden Objekte sind maskiert von ?package:base?:
>>
>>      intersect, setdiff, setequal, union
>> [1] "step 2"
>>
>> What is the way to get no messages at all when loading library ? ( or using
>> other R function in general).
>> I am trying to keep only the important messages and so far I am getting way
>> too much messages.
>>
>> Thanks
>> Cheers
>> Fabien
>>
>>
>> --
>> Dr Fabien Tarrade
>>
>> Quantitative Analyst/Developer - Data Scientist
>>
>> Senior data analyst specialised in the modelling, processing and statistical
>> treatment of data.
>> PhD in Physics, 10 years of experience as researcher at the forefront of
>> international scientific research.
>> Fascinated by finance and data modelling.
>>
>> Zurich, Switzerland
>>
>> Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
>> Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
>>
>> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
>> <https://twitter.com/fabtar> Google
>> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
>> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
>> Xing <https://www.xing.com/profile/Fabien_Tarrade>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>

From JSorkin at grecc.umaryland.edu  Mon Sep 26 03:43:16 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 25 Sep 2016 21:43:16 -0400
Subject: [R] Produce multiple line graphs
In-Reply-To: <CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
	<2091422228.8503672.1474831199161@mail.yahoo.com>
	<CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
Message-ID: <57E844F4020000CB00161C11@smtp.medicine.umaryland.edu>

I have a data frame that contains data for multiple (seven) subjects. Each subject is represented by a new value of PID.
I would like to plot the data for all seven subjects. For each subject I want to plot a line showing CT as a function of Nit, with the dots for each subject joined. I have tried to accomplish this using the by function. I get an error message, 
Error in match.fun(panel) : 
  'xx[, "CT"]' is not a function, character or symbol
I have no idea what is causing the error, nor how to correct the error, nor how to get the dots for each point be connected by a line.


Any help would be appreciated!


PID <- c( 1 ,  1   ,  1   , 1   , 2, 2, 2, 2, 3   ,   3  ,  3   ,  3   ,  4   ,  4,  4, 4    , 5, 5, 5, 5, 6, 6, 6, 6, 7   ,  7   ,    7  , 7)
Nit <- c(NA , -9.23,-11.61,-7.88,NA,NA,NA,NA,-5.59,  0.73,-10.55, -9.13,  3.67, NA, NA,-13.26,NA,NA,NA,NA,NA,NA,NA,NA,-9.36,  5.08,  -5.73, 2.02)
CT  <- c(544,459   ,432   ,NA   ,NA,NA,NA,NA,1398 ,1287  ,1049  , NA   ,543   ,474,507,NA    ,NA,NA,NA,NA,NA,NA,NA,NA,992  ,992   ,1078   ,NA)
xx  <- data.frame(PID=PID,Nit=Nit,CT=CT)
xx
by(xx,as.factor(xx[,"PID"]),plot,xx[,"Nit"],xx[,"CT"])




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jun.shen.ut at gmail.com  Mon Sep 26 03:47:32 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Sun, 25 Sep 2016 21:47:32 -0400
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAGx1TMCKnKaGcfgR6LJnm=VOx2Zgtt1jiHO24OeE6VayaKrQKw@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
	<1f371cd9-0ac1-b2a4-2327-44e500cfe327@gwdg.de>
	<CAGxFJbTM_MDkFj7ia7iLepN=cjxRa2zfaFrojp9bwbWsmvGbHw@mail.gmail.com>
	<CAMCXXmoHLPhOc8oO1XiAcsoC9LUN=5yzjrSQh0yqd3G2SM=7dg@mail.gmail.com>
	<CAGx1TMA0B1m=CpbYso3LXQ0wRFte4=d0=Zr2zkq0DNGFgqTU-g@mail.gmail.com>
	<CAGxFJbTJ62UZRZQ4MnBAmo7kigLvJVvQvc-OQ+j1yfgY9ZW0oA@mail.gmail.com>
	<CAGx1TMCKnKaGcfgR6LJnm=VOx2Zgtt1jiHO24OeE6VayaKrQKw@mail.gmail.com>
Message-ID: <CAMCXXmqg3MGSNAE9r9LKdNURMhZHRm_JfOBXiv+b52csMOXKzg@mail.gmail.com>

Hi Richard,

Thanks for demonstrating the usage of layer in latticeExtra. In my current
case I do have multiple panels on one page but only need some universal
annotation text for the whole page. So "sub" argument does the job pretty
well. You have certainly shown a very interesting example to add different
annotation text for each panel. This is very useful when such text is
needed. Thank everyone for the help.

Best regards,

Jun

On Sun, Sep 25, 2016 at 5:18 PM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> Bert,
>
> I interpreted the OP's request as a single panel xyplot.
> The latticeExtra::layer mechanism does work for multiple plots.
>
>
> library(lattice)
> library(latticeExtra)
> tmp <- data.frame(x=1:10, y=1:10, g=rep(c("A","B"), each=5))
>
> xyplot(y ~ x | g, data=tmp)
>
> xyplot(y ~ x | g, data=tmp, main="outside text displayed",
>        par.settings=list(clip=list(panel=FALSE))) +
>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very interesting"))
>
> xyplot(y ~ x | g, data=tmp, main="outside text displayed",
>        par.settings=list(clip=list(panel=FALSE))) +
>   latticeExtra::layer(panel.text(x=2, y=-0.5,
>        label=c("very interesting", "also interesting")[panel.number()]))
>
>
> For the overall lattice display I agree that the mechanisms you
> suggested are approriate.
>
> Rich
>
>
> On Sun, Sep 25, 2016 at 4:34 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > ... but what if there are multiple panels?
> >
> > "The layer mechanism is a method for augmenting a panel function. It
> > allows expressions to be added to the panel function without knowing
> > what the original panel function was. "
> >
> > As I understand it, the OP requested annotation for the entire lattice
> > display, not single panels thereof. This seems more like a "sub" or
> > "legend"  addition.
> >
> > Cheers,
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Sun, Sep 25, 2016 at 11:44 AM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >> library(lattice)
> >> library(latticeExtra)
> >> tmp <- data.frame(x=1:10, y=1:10)
> >>
> >> xyplot(y ~ x, data=tmp)
> >>
> >> xyplot(y ~ x, data=tmp, main="text outside panel clipped") +
> >>   ## "+" must be on same line as first statement.
> >>   ## This use of "+" is from latticeExtra.
> >>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very
> interesting"))
> >>
> >> xyplot(y ~ x, data=tmp, main="outside text displayed",
> >>        par.settings=list(clip=list(panel=FALSE)) ## permit text
> >> outside the panel
> >>                          ) +
> >>   ## "+" must be on same line as first statement.
> >>   ## This use of "+" is from latticeExtra.
> >>   latticeExtra::layer(panel.text(x=2, y=-0.5, label="very
> interesting"))
> >>
> >> ## I use the phrasing "latticeExtra::layer", not the simpler "layer".
> >> ## latticeExtra and ggplot2 both use layer and they use it incompatibly.
> >> ## It is possible for both packages to be loaded at the same time,
> therefore
> >> ## I specify latticeExtra explicitly.
> >>
> >> ## ltext and panel.text are the same.
> >>
> >>
> >> On Sun, Sep 25, 2016 at 12:32 PM, Jun Shen <jun.shen.ut at gmail.com>
> wrote:
> >>> Thanks Bert, sub works pretty well.
> >>>
> >>> Carlos, thanks for the suggestion. As I am not familiar with
> latticeExatra,
> >>> not sure how hard it is to make it work with my plot. I'll try.
> >>>
> >>> On Sat, Sep 24, 2016 at 11:04 AM, Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> No.
> >>>>
> >>>> ltext/panel.text plots text *within* panels; IIUC, the  OP requested
> >>>> text outside the plots. For that see the details for "main" and/or
> >>>> "sub" in ?xyplot. I think it could also be done more flexibly via a
> >>>> legend or a key with a title but no content -- again, see the Help
> >>>> page -- but haven't tried it.
> >>>>
> >>>> Cheers,
> >>>> Bert
> >>>>
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Fri, Sep 23, 2016 at 11:49 PM, Rainer Hurling <rhurlin at gwdg.de>
> wrote:
> >>>> > Hi,
> >>>> >
> >>>> > one possible solution is to use ltext().
> >>>> >
> >>>> > ltext(xcoord, ycoord, label="TEST", adj=c(0.5,0.5))
> >>>> >
> >>>> > You have to know or to find out best fitting coordinates.
> >>>> >
> >>>> > Via adj you can control, if the text should adjust left, center or
> right
> >>>> > to the coords, and above, center or bottom of them.
> >>>> >
> >>>> > HTH,
> >>>> > Rainer Hurling
> >>>> >
> >>>> >
> >>>> > Am 22.09.2016 um 16:04 schrieb Jun Shen:
> >>>> >> Dear list,
> >>>> >>
> >>>> >> Just wonder if there is a way to add annotation text outside an
> xyplot,
> >>>> >> (e.g. the bottom of the plot). the panel.text seems only add text
> within
> >>>> >> the plot. Thanks.
> >>>> >>
> >>>> >> Jun
> >>>> >
> >>>> > ______________________________________________
> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> > PLEASE do read the posting guide http://www.R-project.org/
> >>>> posting-guide.html
> >>>> > and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Sep 26 04:05:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Sep 2016 12:05:47 +1000
Subject: [R] Produce multiple line graphs
In-Reply-To: <57E844F4020000CB00161C11@smtp.medicine.umaryland.edu>
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
	<2091422228.8503672.1474831199161@mail.yahoo.com>
	<CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
	<57E844F4020000CB00161C11@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fW45t+Dh_PRbgFSpV9zhp2bxK8wTZAM1qrPVmqqVRiGBg@mail.gmail.com>

Hi John,
I know this is kind of dumb, but:

plot(0,xlim=range(xx$Nit,na.rm=TRUE),
 ylim=range(xx$CT,na.rm=TRUE),type="n",
 xlab="Nit",ylab="CT")
for(i in unique(xx$PID))
 points(xx$Nit[xx$PID==i],xx$CT[xx$PID==i],
 pch=i,col=i,type="b")

Jim


On Mon, Sep 26, 2016 at 11:43 AM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> I have a data frame that contains data for multiple (seven) subjects. Each subject is represented by a new value of PID.
> I would like to plot the data for all seven subjects. For each subject I want to plot a line showing CT as a function of Nit, with the dots for each subject joined. I have tried to accomplish this using the by function. I get an error message,
> Error in match.fun(panel) :
>   'xx[, "CT"]' is not a function, character or symbol
> I have no idea what is causing the error, nor how to correct the error, nor how to get the dots for each point be connected by a line.
>
>
> Any help would be appreciated!
>
>
> PID <- c( 1 ,  1   ,  1   , 1   , 2, 2, 2, 2, 3   ,   3  ,  3   ,  3   ,  4   ,  4,  4, 4    , 5, 5, 5, 5, 6, 6, 6, 6, 7   ,  7   ,    7  , 7)
> Nit <- c(NA , -9.23,-11.61,-7.88,NA,NA,NA,NA,-5.59,  0.73,-10.55, -9.13,  3.67, NA, NA,-13.26,NA,NA,NA,NA,NA,NA,NA,NA,-9.36,  5.08,  -5.73, 2.02)
> CT  <- c(544,459   ,432   ,NA   ,NA,NA,NA,NA,1398 ,1287  ,1049  , NA   ,543   ,474,507,NA    ,NA,NA,NA,NA,NA,NA,NA,NA,992  ,992   ,1078   ,NA)
> xx  <- data.frame(PID=PID,Nit=Nit,CT=CT)
> xx
> by(xx,as.factor(xx[,"PID"]),plot,xx[,"Nit"],xx[,"CT"])
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From dwinsemius at comcast.net  Mon Sep 26 04:41:08 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 25 Sep 2016 19:41:08 -0700
Subject: [R] Produce multiple line graphs
In-Reply-To: <57E844F4020000CB00161C11@smtp.medicine.umaryland.edu>
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
	<2091422228.8503672.1474831199161@mail.yahoo.com>
	<CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
	<57E844F4020000CB00161C11@smtp.medicine.umaryland.edu>
Message-ID: <AAF6AA71-1E43-47F7-BCCC-BB4EB3D850A3@comcast.net>


> On Sep 25, 2016, at 6:43 PM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
> 
> I have a data frame that contains data for multiple (seven) subjects. Each subject is represented by a new value of PID.
> I would like to plot the data for all seven subjects. For each subject I want to plot a line showing CT as a function of Nit, with the dots for each subject joined. I have tried to accomplish this using the by function. I get an error message, 
> Error in match.fun(panel) : 
>  'xx[, "CT"]' is not a function, character or symbol
> I have no idea what is causing the error, nor how to correct the error, nor how to get the dots for each point be connected by a line.
> 
> 
> Any help would be appreciated!
> 
> 
> PID <- c( 1 ,  1   ,  1   , 1   , 2, 2, 2, 2, 3   ,   3  ,  3   ,  3   ,  4   ,  4,  4, 4    , 5, 5, 5, 5, 6, 6, 6, 6, 7   ,  7   ,    7  , 7)
> Nit <- c(NA , -9.23,-11.61,-7.88,NA,NA,NA,NA,-5.59,  0.73,-10.55, -9.13,  3.67, NA, NA,-13.26,NA,NA,NA,NA,NA,NA,NA,NA,-9.36,  5.08,  -5.73, 2.02)
> CT  <- c(544,459   ,432   ,NA   ,NA,NA,NA,NA,1398 ,1287  ,1049  , NA   ,543   ,474,507,NA    ,NA,NA,NA,NA,NA,NA,NA,NA,992  ,992   ,1078   ,NA)
> xx  <- data.frame(PID=PID,Nit=Nit,CT=CT)
> xx
> by(xx,as.factor(xx[,"PID"]),plot,xx[,"Nit"],xx[,"CT"])

Wouldn't this just be:

library(lattice)
xyplot( CT ~ Nit, group= PID, data=xx, type="b")


-- 
David (MD, MPH)


> John David Sorkin M.D., Ph.D.

David Winsemius
Alameda, CA, USA


From f_j_rod at hotmail.com  Mon Sep 26 17:28:03 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 26 Sep 2016 15:28:03 +0000
Subject: [R] Using lapply in R data table
Message-ID: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Dear all,

I have a R data table like this:

DT <- data.table(
  id = rep(c(2, 5, 7), c(3, 2, 2)),
  fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
  group = rep(c("A", "B", "A"), c(3, 2, 2))  )


I want to construct a new variable "exposure" defined as follows:

1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5


So the desired output would be the following data table:

   id                fini exposure group
1:  2 2005-04-20        1.00        A
2:  2 2005-04-20        1.00        A
3:  2 2005-04-20        1.00        A
4:  5 2006-02-19        0.87        B
5:  5 2006-02-19        0.87        B
6:  7 2006-10-08        0.50        A
7:  7 2006-10-08        0.50        A


I have tried:

DT <- DT[ , list(id, fini, exposure = 0, group)]
DT.new <- lapply(DT, function(exposure){
      exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
      exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
    exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
      exposure  # return value
  })


But I get an error message.

Thanks for any help!!


Frank S.


	[[alternative HTML version deleted]]


From 1101011 at gmx.net  Mon Sep 26 12:29:40 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Mon, 26 Sep 2016 12:29:40 +0200
Subject: [R] 32 and 64 bit R
Message-ID: <trinity-f6ffe222-5575-4c54-a1f4-c1620e6f1dff-1474885780162@3capp-gmx-bs74>


Hello,
?
I have both 32 and 64 bit verions of R installed. What happens if I open a workspace saved from 64 bit R
in the 32 bit version or conversely?
I am fairly careless but never noticed any problems.?
?


From edeveaud at pasteur.fr  Mon Sep 26 13:46:06 2016
From: edeveaud at pasteur.fr (Eric Deveaud)
Date: Mon, 26 Sep 2016 13:46:06 +0200
Subject: [R] src/Makevars ignored ?
Message-ID: <81676230-d171-fccd-5d38-612601ddbef7@pasteur.fr>



	Hello,

as far as I understood the R library generic compilation mechanism, 
compilation of C//C++ sources is controlde

1) at system level by the ocntentos RHOME/etc/Makeconf
2) at user level by the content of ~/.R/Makevars
3) at package level by the content of src/Makevars

Problem I have is that src/Makevars is ignored


see following example:

R is compiled and use the following CC and CFLAGS definition

bigmess:epactsR/src > R CMD config CC
gcc -std=gnu99
bigmess:epactsR/src > R CMD config CFLAGS
-Wall -g

so building C sources lead to the following

bigmess:epactsR/src > R CMD SHLIB index.c
gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG 
-I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o

normal, it uses defintion from RHOME/etc/Makeconf


when I set upp a ~/.R/Makevars that overwrite CC and CFLAGS definition.

bigmess:epactsR/src > cat ~/.R/Makevars
CC=gcc
CFLAGS=-O3
bigmess:epactsR/src > R CMD SHLIB index.c
gcc -I/local/gensoft2/adm/lib64/R/include -DNDEBUG  -I/usr/local/include 
    -fpic  -O3 -c index.c -o index.o
gcc -std=gnu99 -shared -L/usr/local/lib64 -o index.so index.o


OK CC and CFLAGS are honored and set accordingly to ~/.R/Makevars


but when I try to use src/Makevars, it is ignored

bigmess:epactsR/src > cat ~/.R/Makevars
cat: /home/edeveaud/.R/Makevars: No such file or directory
bigmess:epactsR/src > cat ./Makevars
CC = gcc
CFLAGS=-O3
bigmess:epactsR/src > R CMD SHLIB index.c
gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG 
-I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o


what I have missed or is there something wrong ?


PS I tested the ssame behaviour with various version of R from R/2.15 to 
R/3.3

	best regards

	Eric


From gennarotedesco at gmail.com  Sun Sep 25 15:34:38 2016
From: gennarotedesco at gmail.com (Gennaro Tedesco)
Date: Sun, 25 Sep 2016 15:34:38 +0200
Subject: [R] [R-pkgs] package Rdice released
Message-ID: <CAF=y844JFV=pvhysB+mtEYtM8YtNWWbCNtJ45LT5eWp4kmQTfQ@mail.gmail.com>

The package "Rdice" has just been released on CRAN. It contains a
collection of functions to simulate dice rolls and the like. In particular,
experiments and exercises can be performed looking at combinations and
permutations of values in dice rolls and coin flips, together with the
corresponding frequencies of occurrences. When applying each function, the
user has to input the number of times (rolls, flips) to toss the dice.
Moreover, the package provides functions to generate non-transitive sets of
dice (like Efron's) and to check whether a given set of dice is
non-transitive with given probability.

A vignette with example and use cases is provided.

Best regards,
Gennaro

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From tatekorea at gmail.com  Mon Sep 26 17:15:15 2016
From: tatekorea at gmail.com (GwanSeon Kim)
Date: Mon, 26 Sep 2016 11:15:15 -0400
Subject: [R] Problem in "cannot allocate vector of size"
Message-ID: <CAAVy6RKa6BWC8haGOLxCO=ktmhVyTJAVPOjy7HtmH--PssuwZA@mail.gmail.com>

Hi R-Users,
I am running raster to point code in R, but I have an error message that
"cannot allocate vector of size 1.7 Gb". One of my friends run the same
code I used, and it is working with his computer. I am using Window 7
64-bit with 16 GB ram. When I check memory size and limit in RStudio, I
have memory.size() : [1] 11205.57 and memory.limit() : [1] 16341. I already
searched on google to solve this problem, but I could not fix it. Could
anyone possibly help me to solve this problem?
Thanks,

Sun

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Mon Sep 26 18:41:02 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Mon, 26 Sep 2016 19:41:02 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <alpine.BSF.2.00.1609251108250.25794@pedal.dcn.davis.ca.us>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
	<69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>
	<alpine.BSF.2.00.1609251108250.25794@pedal.dcn.davis.ca.us>
Message-ID: <B01C24A6-8652-4DD0-9FC9-1550BFAEB24A@kapsi.fi>

Thank you.

However, I?m having some trouble converting your code to use clka, because the model I was using was:

fit2 <- lm(ruotsi.pist ~ mies + koulu + clka + koulu*clka, data=dta)


> On 25 Sep 2016, at 21:23, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> This illustrates why you need to post a reproducible example. You have a number of confounding factors in your code.
> 
> First, "data" is a commonly-used function... avoid using it for variable names.
> 
> Second, using the attach function this way leads to confusion... best to forget this function until you start building packages.
> 
> Third, clka is linearly dependent on lka, so having them both in the regression is not possible. In this case lm has chosen to ignore clka so that bs("clka") is NA.
> 
> Fourth, curve expects you to give it a function, and instead you have given it a vector.
> 
> Fifth, you are plotting versus lka, but attempting to vary clka in the curve call.
> 
> There are a number of directions you could go with this to get a working output... below is my version.
> 
> dta <- read.table( "http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE )
> fit2 <- lm( ruotsi.pist ~ mies + koulu*lka, data=dta )
> bs <- coef( fit2 )
> rpBylka <- function( lka ) {
>  kouluB <- factor( "B", levels = levels( dta$koulu ) )
>  newdta <- expand.grid( mies=0, koulu=kouluB, lka=lka )
>  predict( fit2, newdata = newdta )
> }
> dtaKouluB <- subset( dta, koulu == "B" )
> varitB <- dtaKouluB$mies
> varitB[ varitB == 0 ] <- 2
> plot( dtaKouluB$lka
>    , dtaKouluB$ruotsi.pist
>    , col=varitB
>    , pch=16
>    , xlab='lka'
>    , ylab='ruotsi.pist'
>    , main='Lukio B'
>    )
> curve( rpBylka, from = min( dta$lka ), max( dta$lka ), add=TRUE, col="red" )
> 
> On Sun, 25 Sep 2016, Matti Viljamaa wrote:
> 
>> 
>>> On 25 Sep 2016, at 19:37, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>>> 
>>> Okay here?s a pretty short code to reproduce it:
>>> 
>>> data <- read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE)
>> 
>> data$clka <- I(data$lka - mean(data$lka))
>> 
>>> attach(data)
>>> 
>>> fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
>>> 
>>> bs <- coef(fit2)
>>> 
>>> varitB <- c(data[koulu == 'B',]$mies)
>>> varitB[varitB == 0] = 2
>>> plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)
>>> 
>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
>>> 
>>> 
>>>> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>> 
>>>> Go directly to C. Do not pass go, do not collect $200.
>>>> 
>>>> You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>>>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>>>> You seem to be confused about what curve is doing vs. what you are
>>>>>> doing.
>>>>> 
>>>>> But my x-range in curve()'s parameters from and to should be the entire
>>>>> 
>>>>> lka vector, since they are from=min(lka) and to=max(lka). Then why does
>>>>> 
>>>>> this not span the entire of lka? Because of duplicate entries or what?
>>>>> 
>>>>> It seems like I cannot use curve(), since my x-axis must be exactly lka
>>>>> 
>>>>> for the function to plot the y value for every lka value.
>>>>> 
>>>>>> A) Compute the points you want to plot and put them into 2 vectors.
>>>>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>>>>> putting that all into one line of code again.
>>>>>> 
>>>>>> B) The predict function is the preferred way to compute points. It
>>>>> may
>>>>>> be educational for you to do the computations by hand at first, but
>>>>> in
>>>>>> the long run using predict will help you avoid problems getting the
>>>>>> equations right in multiple places in your script.
>>>>>> 
>>>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>>>>> ask
>>>>>> your questions with reproducible code and data so we can give you
>>>>>> concrete responses.
>>>>>> 
>>>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>>>> [2]
>>>>>> 
>>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>>> --
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>> 
>>>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi>
>>>>>> wrote:
>>>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>>>> Writing:
>>>>>>>>> 
>>>>>>>>> 
>>>>>>> 
>>>>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>>>> 
>>>>>>>>> i.e. without that being inside curve produces a vector of length
>>>>>>> 375.
>>>>>>>>> 
>>>>>>>>> So now it seems that curve() is really skipping some
>>>>> lka-/x-values.
>>>>>>>> 
>>>>>>>> How could curve() know what the length of lka is?  You're telling
>>>>> it
>>>>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>>>> 
>>>>>>>> curve() is designed to plot expressions or functions, not vectors.
>>>>>>> If
>>>>>>>> you actually want to plot line segments using your original data,
>>>>> use
>>>>>>>> lines().  (You'll likely need to sort your x values into increasing
>>>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>>>> 
>>>>>>>> Duncan Murdoch
>>>>>>> 
>>>>>>> I know that about curve(), but since this function uses lka as a
>>>>>>> parameter, then how should I formulate it for curve so that I don't
>>>>>>> get
>>>>>>> 
>>>>>>> the error about wrong lengths?
>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>>>>> wrote:
>>>>>>>>>> 
>>>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>>>> 
>>>>>>>>>> The way I do it is:
>>>>>>>>>> 
>>>>>>>>>> bs <- coef(fit2)
>>>>>>>>>> 
>>>>>>>>>> and then for example:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>> 
>>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>>>> 
>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>> 
>>>>>>>>>> This above code runs into error:
>>>>>>>>>> 
>>>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>>>>> +
>>>>>>>>>> bs["lka"] *  :
>>>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>>>> In addition: Warning message:
>>>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>>>>> *
>>>>>>> :
>>>>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>>>>> 
>>>>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>>>>> different objects being multiplied or summed.
>>>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>>>> 
>>>>>>>>>> g <-
>>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>>>> 
>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>> 
>>>>>>>>>> returns 101.
>>>>>>>>>> 
>>>>>>>>>> However length(lka) is 375. But perhaps these being different is
>>>>>>> not
>>>>>>>>>> the problem?
>>>>>>>>>> 
>>>>>>>>>> I however do see that the whole range of lka is not plotted, for
>>>>>>> some
>>>>>>>>>> reason. So how can I be sure
>>>>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>>>>> lengths
>>>>>>>>>> of objects inside curve() are correct?
>>>>>>>>>> 
>>>>>>>>>> What can I do?
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>> 
>> 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From mviljamaa at kapsi.fi  Mon Sep 26 18:41:57 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Mon, 26 Sep 2016 19:41:57 +0300
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <B01C24A6-8652-4DD0-9FC9-1550BFAEB24A@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
	<69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>
	<alpine.BSF.2.00.1609251108250.25794@pedal.dcn.davis.ca.us>
	<B01C24A6-8652-4DD0-9FC9-1550BFAEB24A@kapsi.fi>
Message-ID: <D9C66ECE-EEA6-48A0-816C-AEBEBED4DEBF@kapsi.fi>


> On 26 Sep 2016, at 19:41, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> 
> Thank you.
> 
> However, I?m having some trouble converting your code to use clka, because the model I was using was:
> 
> fit2 <- lm(ruotsi.pist ~ mies + koulu + clka + koulu*clka, data=dta)

I mean, not to use clka to replace lka. But to use the above fit2, rather than your fit2.

>> On 25 Sep 2016, at 21:23, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> This illustrates why you need to post a reproducible example. You have a number of confounding factors in your code.
>> 
>> First, "data" is a commonly-used function... avoid using it for variable names.
>> 
>> Second, using the attach function this way leads to confusion... best to forget this function until you start building packages.
>> 
>> Third, clka is linearly dependent on lka, so having them both in the regression is not possible. In this case lm has chosen to ignore clka so that bs("clka") is NA.
>> 
>> Fourth, curve expects you to give it a function, and instead you have given it a vector.
>> 
>> Fifth, you are plotting versus lka, but attempting to vary clka in the curve call.
>> 
>> There are a number of directions you could go with this to get a working output... below is my version.
>> 
>> dta <- read.table( "http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE )
>> fit2 <- lm( ruotsi.pist ~ mies + koulu*lka, data=dta )
>> bs <- coef( fit2 )
>> rpBylka <- function( lka ) {
>> kouluB <- factor( "B", levels = levels( dta$koulu ) )
>> newdta <- expand.grid( mies=0, koulu=kouluB, lka=lka )
>> predict( fit2, newdata = newdta )
>> }
>> dtaKouluB <- subset( dta, koulu == "B" )
>> varitB <- dtaKouluB$mies
>> varitB[ varitB == 0 ] <- 2
>> plot( dtaKouluB$lka
>>   , dtaKouluB$ruotsi.pist
>>   , col=varitB
>>   , pch=16
>>   , xlab='lka'
>>   , ylab='ruotsi.pist'
>>   , main='Lukio B'
>>   )
>> curve( rpBylka, from = min( dta$lka ), max( dta$lka ), add=TRUE, col="red" )
>> 
>> On Sun, 25 Sep 2016, Matti Viljamaa wrote:
>> 
>>> 
>>>> On 25 Sep 2016, at 19:37, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>>>> 
>>>> Okay here?s a pretty short code to reproduce it:
>>>> 
>>>> data <- read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt", header=TRUE)
>>> 
>>> data$clka <- I(data$lka - mean(data$lka))
>>> 
>>>> attach(data)
>>>> 
>>>> fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
>>>> 
>>>> bs <- coef(fit2)
>>>> 
>>>> varitB <- c(data[koulu == 'B',]$mies)
>>>> varitB[varitB == 0] = 2
>>>> plot(data[data$koulu == 'B',]$lka, data[koulu == 'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio B?)
>>>> 
>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
>>>> 
>>>> 
>>>>> On 25 Sep 2016, at 19:24, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>>> 
>>>>> Go directly to C. Do not pass go, do not collect $200.
>>>>> 
>>>>> You think curve does something, but you are missing what it actually does. Since you don't seem to be learning from reading ?curve or from our responses, you need to give us an example you can learn from.
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On September 25, 2016 9:04:09 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>>>>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>>>>> You seem to be confused about what curve is doing vs. what you are
>>>>>>> doing.
>>>>>> 
>>>>>> But my x-range in curve()'s parameters from and to should be the entire
>>>>>> 
>>>>>> lka vector, since they are from=min(lka) and to=max(lka). Then why does
>>>>>> 
>>>>>> this not span the entire of lka? Because of duplicate entries or what?
>>>>>> 
>>>>>> It seems like I cannot use curve(), since my x-axis must be exactly lka
>>>>>> 
>>>>>> for the function to plot the y value for every lka value.
>>>>>> 
>>>>>>> A) Compute the points you want to plot and put them into 2 vectors.
>>>>>>> Then figure out how to plot those vectors. Then (perhaps) consider
>>>>>>> putting that all into one line of code again.
>>>>>>> 
>>>>>>> B) The predict function is the preferred way to compute points. It
>>>>>> may
>>>>>>> be educational for you to do the computations by hand at first, but
>>>>>> in
>>>>>>> the long run using predict will help you avoid problems getting the
>>>>>>> equations right in multiple places in your script.
>>>>>>> 
>>>>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]), and
>>>>>> ask
>>>>>>> your questions with reproducible code and data so we can give you
>>>>>>> concrete responses.
>>>>>>> 
>>>>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>>>>> [2]
>>>>>>> 
>>>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>>>> --
>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>> 
>>>>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa <mviljamaa at kapsi.fi>
>>>>>>> wrote:
>>>>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>>>>> Writing:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>> 
>>>>>> bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>>>>> 
>>>>>>>>>> i.e. without that being inside curve produces a vector of length
>>>>>>>> 375.
>>>>>>>>>> 
>>>>>>>>>> So now it seems that curve() is really skipping some
>>>>>> lka-/x-values.
>>>>>>>>> 
>>>>>>>>> How could curve() know what the length of lka is?  You're telling
>>>>>> it
>>>>>>>>> to set x to a sequence of values of length 101 (the default) from
>>>>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>>>>> 
>>>>>>>>> curve() is designed to plot expressions or functions, not vectors.
>>>>>>>> If
>>>>>>>>> you actually want to plot line segments using your original data,
>>>>>> use
>>>>>>>>> lines().  (You'll likely need to sort your x values into increasing
>>>>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>>>>> 
>>>>>>>>> Duncan Murdoch
>>>>>>>> 
>>>>>>>> I know that about curve(), but since this function uses lka as a
>>>>>>>> parameter, then how should I formulate it for curve so that I don't
>>>>>>>> get
>>>>>>>> 
>>>>>>>> the error about wrong lengths?
>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa <mviljamaa at kapsi.fi>
>>>>>>>> wrote:
>>>>>>>>>>> 
>>>>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>>>>> 
>>>>>>>>>>> The way I do it is:
>>>>>>>>>>> 
>>>>>>>>>>> bs <- coef(fit2)
>>>>>>>>>>> 
>>>>>>>>>>> and then for example:
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>> 
>>>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>>>>> 
>>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>>> 
>>>>>>>>>>> This above code runs into error:
>>>>>>>>>>> 
>>>>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"]
>>>>>> +
>>>>>>>>>>> bs["lka"] *  :
>>>>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>>>>> In addition: Warning message:
>>>>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"]
>>>>>> *
>>>>>>>> :
>>>>>>>>>>> longer object length is not a multiple of shorter object length
>>>>>>>>>>> 
>>>>>>>>>>> Which I?ve investigated might be related to the lengths of the
>>>>>>>>>>> different objects being multiplied or summed.
>>>>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>>>>> 
>>>>>>>>>>> g <-
>>>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>>>>> 
>>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>>> 
>>>>>>>>>>> returns 101.
>>>>>>>>>>> 
>>>>>>>>>>> However length(lka) is 375. But perhaps these being different is
>>>>>>>> not
>>>>>>>>>>> the problem?
>>>>>>>>>>> 
>>>>>>>>>>> I however do see that the whole range of lka is not plotted, for
>>>>>>>> some
>>>>>>>>>>> reason. So how can I be sure
>>>>>>>>>>> that it passes through all x-values in lka? And i.e. that the
>>>>>>>> lengths
>>>>>>>>>>> of objects inside curve() are correct?
>>>>>>>>>>> 
>>>>>>>>>>> What can I do?
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>>> 
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>> 
>>> 
>> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
> 


From istazahn at gmail.com  Mon Sep 26 19:05:51 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 26 Sep 2016 13:05:51 -0400
Subject: [R] Using lapply in R data table
In-Reply-To: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
Message-ID: <CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>

Hi Frank,

lapply(DT) iterates over each column. That doesn't seem to be what you want.

There are probably better ways, but here is one approach.

DT[, exposure := vector(mode = "numeric", length = .N)]
DT[fini < as.Date("2006-01-01"), exposure := 1]
DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
      exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
DT[fini >= as.Date("2006-07-01"), exposure := 0.5]

Best,
Ista

On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
> Dear all,
>
> I have a R data table like this:
>
> DT <- data.table(
>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>
>
> I want to construct a new variable "exposure" defined as follows:
>
> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>
>
> So the desired output would be the following data table:
>
>    id                fini exposure group
> 1:  2 2005-04-20        1.00        A
> 2:  2 2005-04-20        1.00        A
> 3:  2 2005-04-20        1.00        A
> 4:  5 2006-02-19        0.87        B
> 5:  5 2006-02-19        0.87        B
> 6:  7 2006-10-08        0.50        A
> 7:  7 2006-10-08        0.50        A
>
>
> I have tried:
>
> DT <- DT[ , list(id, fini, exposure = 0, group)]
> DT.new <- lapply(DT, function(exposure){
>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>       exposure  # return value
>   })
>
>
> But I get an error message.
>
> Thanks for any help!!
>
>
> Frank S.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep 26 19:59:16 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Sep 2016 10:59:16 -0700
Subject: [R] Using lapply in R data table
In-Reply-To: <CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
Message-ID: <CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>

This seems like a job for cut() .

(I made DT a data frame to avoid loading the data table package. But I
assume it would work with a data table too, Check this, though!)

> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))

> DT
  id       fini group exposure
1  2 2005-04-20     A        1
2  2 2005-04-20     A        1
3  2 2005-04-20     A        1
4  5 2006-02-19     B     0.87
5  5 2006-02-19     B     0.87
6  7 2006-10-08     A      0.5
7  7 2006-10-08     A      0.5


(but note that exposure is a factor, not numeric)


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Frank,
>
> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>
> There are probably better ways, but here is one approach.
>
> DT[, exposure := vector(mode = "numeric", length = .N)]
> DT[fini < as.Date("2006-01-01"), exposure := 1]
> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>
> Best,
> Ista
>
> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>> Dear all,
>>
>> I have a R data table like this:
>>
>> DT <- data.table(
>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>
>>
>> I want to construct a new variable "exposure" defined as follows:
>>
>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>
>>
>> So the desired output would be the following data table:
>>
>>    id                fini exposure group
>> 1:  2 2005-04-20        1.00        A
>> 2:  2 2005-04-20        1.00        A
>> 3:  2 2005-04-20        1.00        A
>> 4:  5 2006-02-19        0.87        B
>> 5:  5 2006-02-19        0.87        B
>> 6:  7 2006-10-08        0.50        A
>> 7:  7 2006-10-08        0.50        A
>>
>>
>> I have tried:
>>
>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>> DT.new <- lapply(DT, function(exposure){
>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>       exposure  # return value
>>   })
>>
>>
>> But I get an error message.
>>
>> Thanks for any help!!
>>
>>
>> Frank S.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Sep 26 20:37:59 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 26 Sep 2016 14:37:59 -0400
Subject: [R] Using lapply in R data table
In-Reply-To: <CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
Message-ID: <CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>

On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> This seems like a job for cut() .

I thought that at first two, but the middle group shouldn't be .87 but rather

exposure" = "2007-01-01" - "fini"

so, I think cut alone won't do it.

Best,
Ista
>
> (I made DT a data frame to avoid loading the data table package. But I
> assume it would work with a data table too, Check this, though!)
>
>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>
>> DT
>   id       fini group exposure
> 1  2 2005-04-20     A        1
> 2  2 2005-04-20     A        1
> 3  2 2005-04-20     A        1
> 4  5 2006-02-19     B     0.87
> 5  5 2006-02-19     B     0.87
> 6  7 2006-10-08     A      0.5
> 7  7 2006-10-08     A      0.5
>
>
> (but note that exposure is a factor, not numeric)
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi Frank,
>>
>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>
>> There are probably better ways, but here is one approach.
>>
>> DT[, exposure := vector(mode = "numeric", length = .N)]
>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>
>> Best,
>> Ista
>>
>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>> Dear all,
>>>
>>> I have a R data table like this:
>>>
>>> DT <- data.table(
>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>
>>>
>>> I want to construct a new variable "exposure" defined as follows:
>>>
>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>
>>>
>>> So the desired output would be the following data table:
>>>
>>>    id                fini exposure group
>>> 1:  2 2005-04-20        1.00        A
>>> 2:  2 2005-04-20        1.00        A
>>> 3:  2 2005-04-20        1.00        A
>>> 4:  5 2006-02-19        0.87        B
>>> 5:  5 2006-02-19        0.87        B
>>> 6:  7 2006-10-08        0.50        A
>>> 7:  7 2006-10-08        0.50        A
>>>
>>>
>>> I have tried:
>>>
>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>> DT.new <- lapply(DT, function(exposure){
>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>       exposure  # return value
>>>   })
>>>
>>>
>>> But I get an error message.
>>>
>>> Thanks for any help!!
>>>
>>>
>>> Frank S.
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep 26 20:48:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Sep 2016 11:48:35 -0700
Subject: [R] Using lapply in R data table
In-Reply-To: <CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
	<CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
Message-ID: <CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>

I thought that that was a typo from the OP, as it disagrees with his
example. But the labels are arbitrary, so in fact cut() will do it
whichever way he meant.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 26, 2016 at 11:37 AM, Ista Zahn <istazahn at gmail.com> wrote:
> On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> This seems like a job for cut() .
>
> I thought that at first two, but the middle group shouldn't be .87 but rather
>
> exposure" = "2007-01-01" - "fini"
>
> so, I think cut alone won't do it.
>
> Best,
> Ista
>>
>> (I made DT a data frame to avoid loading the data table package. But I
>> assume it would work with a data table too, Check this, though!)
>>
>>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>>
>>> DT
>>   id       fini group exposure
>> 1  2 2005-04-20     A        1
>> 2  2 2005-04-20     A        1
>> 3  2 2005-04-20     A        1
>> 4  5 2006-02-19     B     0.87
>> 5  5 2006-02-19     B     0.87
>> 6  7 2006-10-08     A      0.5
>> 7  7 2006-10-08     A      0.5
>>
>>
>> (but note that exposure is a factor, not numeric)
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> Hi Frank,
>>>
>>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>>
>>> There are probably better ways, but here is one approach.
>>>
>>> DT[, exposure := vector(mode = "numeric", length = .N)]
>>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>>
>>> Best,
>>> Ista
>>>
>>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>>> Dear all,
>>>>
>>>> I have a R data table like this:
>>>>
>>>> DT <- data.table(
>>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>>
>>>>
>>>> I want to construct a new variable "exposure" defined as follows:
>>>>
>>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>>
>>>>
>>>> So the desired output would be the following data table:
>>>>
>>>>    id                fini exposure group
>>>> 1:  2 2005-04-20        1.00        A
>>>> 2:  2 2005-04-20        1.00        A
>>>> 3:  2 2005-04-20        1.00        A
>>>> 4:  5 2006-02-19        0.87        B
>>>> 5:  5 2006-02-19        0.87        B
>>>> 6:  7 2006-10-08        0.50        A
>>>> 7:  7 2006-10-08        0.50        A
>>>>
>>>>
>>>> I have tried:
>>>>
>>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>>> DT.new <- lapply(DT, function(exposure){
>>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>>       exposure  # return value
>>>>   })
>>>>
>>>>
>>>> But I get an error message.
>>>>
>>>> Thanks for any help!!
>>>>
>>>>
>>>> Frank S.
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Sep 26 20:52:19 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 26 Sep 2016 12:52:19 -0600
Subject: [R] curve() doesn't seem to use the whole range of x? And
 Error: longer object length is not a multiple of shorter object length
In-Reply-To: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
Message-ID: <CAFEqCdw0c8rNYPQuB603wzy-oJtM8dyLGWVkWVcWqMKRW0BFSQ@mail.gmail.com>

If your goal is to visualize the predicted curve from an lm fit (or
other model fit) then you may want to look at the Predict.Plot and
TkPredict functions from the TeachingDemos package.




On Sun, Sep 25, 2016 at 7:01 AM, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> I?m trying to plot regression lines using curve()
>
> The way I do it is:
>
> bs <- coef(fit2)
>
> and then for example:
>
> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka, from=min(lka), to=max(lka), add=TRUE, col='red')
>
> This above code runs into error:
>
> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>   'expr' did not evaluate to an object of length 'n'
> In addition: Warning message:
> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] + bs["lka"] *  :
>   longer object length is not a multiple of shorter object length
>
> Which I?ve investigated might be related to the lengths of the different objects being multiplied or summed.
> Taking length(g$x) or length(g$y) of
>
> g <- curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x, from=min(lka), to=max(lka), add=TRUE, col='red')
>
> returns 101.
>
> However length(lka) is 375. But perhaps these being different is not the problem?
>
> I however do see that the whole range of lka is not plotted, for some reason. So how can I be sure
> that it passes through all x-values in lka? And i.e. that the lengths of objects inside curve() are correct?
>
> What can I do?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jdnewmil at dcn.davis.ca.us  Mon Sep 26 20:58:15 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Sep 2016 11:58:15 -0700
Subject: [R] curve() doesn't seem to use the whole range of x? And
	Error: longer object length is not a multiple of shorter
	object length
In-Reply-To: <D9C66ECE-EEA6-48A0-816C-AEBEBED4DEBF@kapsi.fi>
References: <C2110AFB-1CC0-4925-B6DF-93DDB57955F6@kapsi.fi>
	<C0121BC3-CBBA-4E3E-874A-D3D7AE602844@kapsi.fi>
	<3fee070b-3c1f-bfd4-02f5-fb3d9bb6c0f7@gmail.com>
	<3b45221f544cf692a599f06726fca469@kapsi.fi>
	<E26B3A2E-FC7F-4221-961F-15E226FE728E@dcn.davis.ca.us>
	<247a1ce098dcfa24df6dc7bb1e7f500b@kapsi.fi>
	<28532DA9-83AC-49CA-BAA1-5BD044C549CA@dcn.davis.ca.us>
	<94EADB6B-66FE-4C79-AA06-7E9B972E9074@kapsi.fi>
	<69CBCFD3-2FF6-4C31-9377-DABE8C7DCED1@kapsi.fi>
	<alpine.BSF.2.00.1609251108250.25794@pedal.dcn.davis.ca.us>
	<B01C24A6-8652-4DD0-9FC9-1550BFAEB24A@kapsi.fi>
	<D9C66ECE-EEA6-48A0-816C-AEBEBED4DEBF@kapsi.fi>
Message-ID: <BE6407FE-51CA-492A-A6B8-C9C43C9A6D5B@dcn.davis.ca.us>

I think you are going to have to be more specific than "having some trouble". Your plot used lka as the x-axis.

FWIW note that

lm(ruotsi.pist ~ mies + koulu + clka + koulu*clka, data=dta)

is the same as

lm(ruotsi.pist ~ mies + koulu*clka, data=dta)
-- 
Sent from my phone. Please excuse my brevity.

On September 26, 2016 9:41:57 AM PDT, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>
>> On 26 Sep 2016, at 19:41, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>> 
>> Thank you.
>> 
>> However, I?m having some trouble converting your code to use clka,
>because the model I was using was:
>> 
>> fit2 <- lm(ruotsi.pist ~ mies + koulu + clka + koulu*clka, data=dta)
>
>I mean, not to use clka to replace lka. But to use the above fit2,
>rather than your fit2.
>
>>> On 25 Sep 2016, at 21:23, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>> 
>>> This illustrates why you need to post a reproducible example. You
>have a number of confounding factors in your code.
>>> 
>>> First, "data" is a commonly-used function... avoid using it for
>variable names.
>>> 
>>> Second, using the attach function this way leads to confusion...
>best to forget this function until you start building packages.
>>> 
>>> Third, clka is linearly dependent on lka, so having them both in the
>regression is not possible. In this case lm has chosen to ignore clka
>so that bs("clka") is NA.
>>> 
>>> Fourth, curve expects you to give it a function, and instead you
>have given it a vector.
>>> 
>>> Fifth, you are plotting versus lka, but attempting to vary clka in
>the curve call.
>>> 
>>> There are a number of directions you could go with this to get a
>working output... below is my version.
>>> 
>>> dta <- read.table(
>"http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt",
>header=TRUE )
>>> fit2 <- lm( ruotsi.pist ~ mies + koulu*lka, data=dta )
>>> bs <- coef( fit2 )
>>> rpBylka <- function( lka ) {
>>> kouluB <- factor( "B", levels = levels( dta$koulu ) )
>>> newdta <- expand.grid( mies=0, koulu=kouluB, lka=lka )
>>> predict( fit2, newdata = newdta )
>>> }
>>> dtaKouluB <- subset( dta, koulu == "B" )
>>> varitB <- dtaKouluB$mies
>>> varitB[ varitB == 0 ] <- 2
>>> plot( dtaKouluB$lka
>>>   , dtaKouluB$ruotsi.pist
>>>   , col=varitB
>>>   , pch=16
>>>   , xlab='lka'
>>>   , ylab='ruotsi.pist'
>>>   , main='Lukio B'
>>>   )
>>> curve( rpBylka, from = min( dta$lka ), max( dta$lka ), add=TRUE,
>col="red" )
>>> 
>>> On Sun, 25 Sep 2016, Matti Viljamaa wrote:
>>> 
>>>> 
>>>>> On 25 Sep 2016, at 19:37, Matti Viljamaa <mviljamaa at kapsi.fi>
>wrote:
>>>>> 
>>>>> Okay here?s a pretty short code to reproduce it:
>>>>> 
>>>>> data <-
>read.table("http://users.jyu.fi/~slahola/files/glm1_datoja/yoruotsi.txt",
>header=TRUE)
>>>> 
>>>> data$clka <- I(data$lka - mean(data$lka))
>>>> 
>>>>> attach(data)
>>>>> 
>>>>> fit2 <- lm(ruotsi.pist ~ mies + koulu + lka + koulu*clka)
>>>>> 
>>>>> bs <- coef(fit2)
>>>>> 
>>>>> varitB <- c(data[koulu == 'B',]$mies)
>>>>> varitB[varitB == 0] = 2
>>>>> plot(data[data$koulu == 'B',]$lka, data[koulu ==
>'B',]$ruotsi.pist, col=varitB, pch=16, xlab='', ylab='', main='Lukio
>B?)
>>>>> 
>>>>>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>> 
>>>>> 
>>>>>> On 25 Sep 2016, at 19:24, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>>>>> 
>>>>>> Go directly to C. Do not pass go, do not collect $200.
>>>>>> 
>>>>>> You think curve does something, but you are missing what it
>actually does. Since you don't seem to be learning from reading ?curve
>or from our responses, you need to give us an example you can learn
>from.
>>>>>> --
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>> 
>>>>>> On September 25, 2016 9:04:09 AM PDT, mviljamaa
><mviljamaa at kapsi.fi> wrote:
>>>>>>> On 2016-09-25 18:52, Jeff Newmiller wrote:
>>>>>>>> You seem to be confused about what curve is doing vs. what you
>are
>>>>>>>> doing.
>>>>>>> 
>>>>>>> But my x-range in curve()'s parameters from and to should be the
>entire
>>>>>>> 
>>>>>>> lka vector, since they are from=min(lka) and to=max(lka). Then
>why does
>>>>>>> 
>>>>>>> this not span the entire of lka? Because of duplicate entries or
>what?
>>>>>>> 
>>>>>>> It seems like I cannot use curve(), since my x-axis must be
>exactly lka
>>>>>>> 
>>>>>>> for the function to plot the y value for every lka value.
>>>>>>> 
>>>>>>>> A) Compute the points you want to plot and put them into 2
>vectors.
>>>>>>>> Then figure out how to plot those vectors. Then (perhaps)
>consider
>>>>>>>> putting that all into one line of code again.
>>>>>>>> 
>>>>>>>> B) The predict function is the preferred way to compute points.
>It
>>>>>>> may
>>>>>>>> be educational for you to do the computations by hand at first,
>but
>>>>>>> in
>>>>>>>> the long run using predict will help you avoid problems getting
>the
>>>>>>>> equations right in multiple places in your script.
>>>>>>>> 
>>>>>>>> C) Learn what makes an example reproducible (e.g. [1] or [2]),
>and
>>>>>>> ask
>>>>>>>> your questions with reproducible code and data so we can give
>you
>>>>>>>> concrete responses.
>>>>>>>> 
>>>>>>>> [1] http://adv-r.had.co.nz/Reproducibility.html
>>>>>>>> [2]
>>>>>>>> 
>>>>>>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>>>>> --
>>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>>> 
>>>>>>>> On September 25, 2016 8:36:49 AM PDT, mviljamaa
><mviljamaa at kapsi.fi>
>>>>>>>> wrote:
>>>>>>>>> On 2016-09-25 18:30, Duncan Murdoch wrote:
>>>>>>>>>> On 25/09/2016 9:10 AM, Matti Viljamaa wrote:
>>>>>>>>>>> Writing:
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>
>bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*lka+bs["kouluB:clka"]*clka
>>>>>>>>>>> 
>>>>>>>>>>> i.e. without that being inside curve produces a vector of
>length
>>>>>>>>> 375.
>>>>>>>>>>> 
>>>>>>>>>>> So now it seems that curve() is really skipping some
>>>>>>> lka-/x-values.
>>>>>>>>>> 
>>>>>>>>>> How could curve() know what the length of lka is?  You're
>telling
>>>>>>> it
>>>>>>>>>> to set x to a sequence of values of length 101 (the default)
>from
>>>>>>>>>> min(lka) to max(lka).  You never tell it to set x to lka.
>>>>>>>>>> 
>>>>>>>>>> curve() is designed to plot expressions or functions, not
>vectors.
>>>>>>>>> If
>>>>>>>>>> you actually want to plot line segments using your original
>data,
>>>>>>> use
>>>>>>>>>> lines().  (You'll likely need to sort your x values into
>increasing
>>>>>>>>>> order if you do that, or you'll get a pretty ugly plot.)
>>>>>>>>>> 
>>>>>>>>>> Duncan Murdoch
>>>>>>>>> 
>>>>>>>>> I know that about curve(), but since this function uses lka as
>a
>>>>>>>>> parameter, then how should I formulate it for curve so that I
>don't
>>>>>>>>> get
>>>>>>>>> 
>>>>>>>>> the error about wrong lengths?
>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>>> On 25 Sep 2016, at 16:01, Matti Viljamaa
><mviljamaa at kapsi.fi>
>>>>>>>>> wrote:
>>>>>>>>>>>> 
>>>>>>>>>>>> I?m trying to plot regression lines using curve()
>>>>>>>>>>>> 
>>>>>>>>>>>> The way I do it is:
>>>>>>>>>>>> 
>>>>>>>>>>>> bs <- coef(fit2)
>>>>>>>>>>>> 
>>>>>>>>>>>> and then for example:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>
>curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x+bs["kouluB:clka"]*clka,
>>>>>>>>> 
>>>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>>>> 
>>>>>>>>>>>> This above code runs into error:
>>>>>>>>>>>> 
>>>>>>>>>>>> Error in curve(bs["(Intercept)"] + bs["mies"] * 0 +
>bs["kouluB"]
>>>>>>> +
>>>>>>>>>>>> bs["lka"] *  :
>>>>>>>>>>>> 'expr' did not evaluate to an object of length 'n'
>>>>>>>>>>>> In addition: Warning message:
>>>>>>>>>>>> In bs["(Intercept)"] + bs["mies"] * 0 + bs["kouluB"] +
>bs["lka"]
>>>>>>> *
>>>>>>>>> :
>>>>>>>>>>>> longer object length is not a multiple of shorter object
>length
>>>>>>>>>>>> 
>>>>>>>>>>>> Which I?ve investigated might be related to the lengths of
>the
>>>>>>>>>>>> different objects being multiplied or summed.
>>>>>>>>>>>> Taking length(g$x) or length(g$y) of
>>>>>>>>>>>> 
>>>>>>>>>>>> g <-
>>>>>>> curve(bs["(Intercept)"]+bs["mies"]*0+bs["kouluB"]+bs["lka"]*x,
>>>>>>>>> 
>>>>>>>>>>>> from=min(lka), to=max(lka), add=TRUE, col='red')
>>>>>>>>>>>> 
>>>>>>>>>>>> returns 101.
>>>>>>>>>>>> 
>>>>>>>>>>>> However length(lka) is 375. But perhaps these being
>different is
>>>>>>>>> not
>>>>>>>>>>>> the problem?
>>>>>>>>>>>> 
>>>>>>>>>>>> I however do see that the whole range of lka is not
>plotted, for
>>>>>>>>> some
>>>>>>>>>>>> reason. So how can I be sure
>>>>>>>>>>>> that it passes through all x-values in lka? And i.e. that
>the
>>>>>>>>> lengths
>>>>>>>>>>>> of objects inside curve() are correct?
>>>>>>>>>>>> 
>>>>>>>>>>>> What can I do?
>>>>>>>>>>> 
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>> 
>>>>> 
>>>> 
>>>> 
>>> 
>>>
>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live Go...
>>>                                     Live:   OO#.. Dead: OO#.. 
>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>>
>---------------------------------------------------------------------------
>>


From istazahn at gmail.com  Mon Sep 26 21:07:11 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 26 Sep 2016 15:07:11 -0400
Subject: [R] Using lapply in R data table
In-Reply-To: <CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
	<CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
	<CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>
Message-ID: <CA+vqiLH5vq8Fe5mPUwdkux9ww2x0H3oaxt=UoBqzF_Q0bSvRvw@mail.gmail.com>

On Mon, Sep 26, 2016 at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I thought that that was a typo from the OP, as it disagrees with his
> example. But the labels are arbitrary, so in fact cut() will do it
> whichever way he meant.

I don't see how cut will do it, at least not conveniently. Consider
this slightly altered example:

library(data.table)
DT <- data.table(
  id = rep(c(2, 5, 7), c(3, 2, 2)),
  fini = rep(as.Date(c('2005-04-20',
                       '2006-02-19',
                       '2006-06-29',
                       '2006-10-08')),
             c(3, 1, 1, 2)),
  group = rep(c("A", "B", "A"), c(3, 2, 2))  )

DT[, exposure := vector(mode = "numeric", length = .N)]
DT[fini < as.Date("2006-01-01"), exposure := 1]
DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
   exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
DT[fini >= as.Date("2006-07-01"), exposure := 0.5]

DT

##    id       fini group  exposure
## 1:  2 2005-04-20     A 1.0000000
## 2:  2 2005-04-20     A 1.0000000
## 3:  2 2005-04-20     A 1.0000000
## 4:  5 2006-02-19     B 0.8651608
## 5:  5 2006-06-29     B 0.5092402
## 6:  7 2006-10-08     A 0.5000000
## 7:  7 2006-10-08     A 0.5000000

Best,
Ista

>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 26, 2016 at 11:37 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> This seems like a job for cut() .
>>
>> I thought that at first two, but the middle group shouldn't be .87 but rather
>>
>> exposure" = "2007-01-01" - "fini"
>>
>> so, I think cut alone won't do it.
>>
>> Best,
>> Ista
>>>
>>> (I made DT a data frame to avoid loading the data table package. But I
>>> assume it would work with a data table too, Check this, though!)
>>>
>>>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>>>
>>>> DT
>>>   id       fini group exposure
>>> 1  2 2005-04-20     A        1
>>> 2  2 2005-04-20     A        1
>>> 3  2 2005-04-20     A        1
>>> 4  5 2006-02-19     B     0.87
>>> 5  5 2006-02-19     B     0.87
>>> 6  7 2006-10-08     A      0.5
>>> 7  7 2006-10-08     A      0.5
>>>
>>>
>>> (but note that exposure is a factor, not numeric)
>>>
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>> Hi Frank,
>>>>
>>>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>>>
>>>> There are probably better ways, but here is one approach.
>>>>
>>>> DT[, exposure := vector(mode = "numeric", length = .N)]
>>>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>>>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>>>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>>>> Dear all,
>>>>>
>>>>> I have a R data table like this:
>>>>>
>>>>> DT <- data.table(
>>>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>>>
>>>>>
>>>>> I want to construct a new variable "exposure" defined as follows:
>>>>>
>>>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>>>
>>>>>
>>>>> So the desired output would be the following data table:
>>>>>
>>>>>    id                fini exposure group
>>>>> 1:  2 2005-04-20        1.00        A
>>>>> 2:  2 2005-04-20        1.00        A
>>>>> 3:  2 2005-04-20        1.00        A
>>>>> 4:  5 2006-02-19        0.87        B
>>>>> 5:  5 2006-02-19        0.87        B
>>>>> 6:  7 2006-10-08        0.50        A
>>>>> 7:  7 2006-10-08        0.50        A
>>>>>
>>>>>
>>>>> I have tried:
>>>>>
>>>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>>>> DT.new <- lapply(DT, function(exposure){
>>>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>>>       exposure  # return value
>>>>>   })
>>>>>
>>>>>
>>>>> But I get an error message.
>>>>>
>>>>> Thanks for any help!!
>>>>>
>>>>>
>>>>> Frank S.
>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Sep 26 21:13:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Sep 2016 15:13:41 -0400
Subject: [R] 32 and 64 bit R
In-Reply-To: <trinity-f6ffe222-5575-4c54-a1f4-c1620e6f1dff-1474885780162@3capp-gmx-bs74>
References: <trinity-f6ffe222-5575-4c54-a1f4-c1620e6f1dff-1474885780162@3capp-gmx-bs74>
Message-ID: <ec1fb60c-a7bd-6a66-f00a-c732dad802e0@gmail.com>

On 26/09/2016 6:29 AM, Mike meyer wrote:
> Hello,
>   
> I have both 32 and 64 bit verions of R installed. What happens if I open a workspace saved from 64 bit R
> in the 32 bit version or conversely?
> I am fairly careless but never noticed any problems.

No problems will arise because of the different word size.

You will possibly see problems if you have the two versions set up to 
use different libraries; occasionally a workspace will fail to load if 
it needs a package that is not installed.  Normally on WIndows the same 
library can be used for both 32 and 64 bit R, but you could always 
choose to break that.

Duncan Murdoch


From bgunter.4567 at gmail.com  Mon Sep 26 22:27:05 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Sep 2016 13:27:05 -0700
Subject: [R] Using lapply in R data table
In-Reply-To: <CA+vqiLH5vq8Fe5mPUwdkux9ww2x0H3oaxt=UoBqzF_Q0bSvRvw@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
	<CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
	<CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>
	<CA+vqiLH5vq8Fe5mPUwdkux9ww2x0H3oaxt=UoBqzF_Q0bSvRvw@mail.gmail.com>
Message-ID: <CAGxFJbQ=VJKh6YZwvhbe3hNLfZZu4qpo=tb-=YrSFNmfdnQp1g@mail.gmail.com>

Ista:

Aha -- now I see the point. My bad. You are right. I was careless.

However, cut() with ifelse() might simplify the code a bit and/or make
it more readable. To be clear, this is just a matter of taste; e.g.
using your data and a data frame instead of a data table:

> DT <- within(DT,
        exposure <- {
          f <-cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")),
              labels= letters[1:3])
          ifelse(f == "a", 1,
                 ifelse( f == "c", .5,
                    difftime(as.Date("2007-01-01"), fini, units="days")/365.25))
}
        )


> DT
  id       fini group  exposure f
1  2 2005-04-20     A 1.0000000 a
2  2 2005-04-20     A 1.0000000 a
3  2 2005-04-20     A 1.0000000 a
4  5 2006-02-19     B 0.8651608 b
5  5 2006-06-29     B 0.5092402 b
6  7 2006-10-08     A 0.5000000 c
7  7 2006-10-08     A 0.5000000 c
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 26, 2016 at 12:07 PM, Ista Zahn <istazahn at gmail.com> wrote:
> On Mon, Sep 26, 2016 at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> I thought that that was a typo from the OP, as it disagrees with his
>> example. But the labels are arbitrary, so in fact cut() will do it
>> whichever way he meant.
>
> I don't see how cut will do it, at least not conveniently. Consider
> this slightly altered example:
>
> library(data.table)
> DT <- data.table(
>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>   fini = rep(as.Date(c('2005-04-20',
>                        '2006-02-19',
>                        '2006-06-29',
>                        '2006-10-08')),
>              c(3, 1, 1, 2)),
>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>
> DT[, exposure := vector(mode = "numeric", length = .N)]
> DT[fini < as.Date("2006-01-01"), exposure := 1]
> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>    exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>
> DT
>
> ##    id       fini group  exposure
> ## 1:  2 2005-04-20     A 1.0000000
> ## 2:  2 2005-04-20     A 1.0000000
> ## 3:  2 2005-04-20     A 1.0000000
> ## 4:  5 2006-02-19     B 0.8651608
> ## 5:  5 2006-06-29     B 0.5092402
> ## 6:  7 2006-10-08     A 0.5000000
> ## 7:  7 2006-10-08     A 0.5000000
>
> Best,
> Ista
>
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Sep 26, 2016 at 11:37 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> This seems like a job for cut() .
>>>
>>> I thought that at first two, but the middle group shouldn't be .87 but rather
>>>
>>> exposure" = "2007-01-01" - "fini"
>>>
>>> so, I think cut alone won't do it.
>>>
>>> Best,
>>> Ista
>>>>
>>>> (I made DT a data frame to avoid loading the data table package. But I
>>>> assume it would work with a data table too, Check this, though!)
>>>>
>>>>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>>>>
>>>>> DT
>>>>   id       fini group exposure
>>>> 1  2 2005-04-20     A        1
>>>> 2  2 2005-04-20     A        1
>>>> 3  2 2005-04-20     A        1
>>>> 4  5 2006-02-19     B     0.87
>>>> 5  5 2006-02-19     B     0.87
>>>> 6  7 2006-10-08     A      0.5
>>>> 7  7 2006-10-08     A      0.5
>>>>
>>>>
>>>> (but note that exposure is a factor, not numeric)
>>>>
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>>> Hi Frank,
>>>>>
>>>>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>>>>
>>>>> There are probably better ways, but here is one approach.
>>>>>
>>>>> DT[, exposure := vector(mode = "numeric", length = .N)]
>>>>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>>>>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>>>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>>>>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>>>>
>>>>> Best,
>>>>> Ista
>>>>>
>>>>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>>>>> Dear all,
>>>>>>
>>>>>> I have a R data table like this:
>>>>>>
>>>>>> DT <- data.table(
>>>>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>>>>
>>>>>>
>>>>>> I want to construct a new variable "exposure" defined as follows:
>>>>>>
>>>>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>>>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>>>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>>>>
>>>>>>
>>>>>> So the desired output would be the following data table:
>>>>>>
>>>>>>    id                fini exposure group
>>>>>> 1:  2 2005-04-20        1.00        A
>>>>>> 2:  2 2005-04-20        1.00        A
>>>>>> 3:  2 2005-04-20        1.00        A
>>>>>> 4:  5 2006-02-19        0.87        B
>>>>>> 5:  5 2006-02-19        0.87        B
>>>>>> 6:  7 2006-10-08        0.50        A
>>>>>> 7:  7 2006-10-08        0.50        A
>>>>>>
>>>>>>
>>>>>> I have tried:
>>>>>>
>>>>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>>>>> DT.new <- lapply(DT, function(exposure){
>>>>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>>>>       exposure  # return value
>>>>>>   })
>>>>>>
>>>>>>
>>>>>> But I get an error message.
>>>>>>
>>>>>> Thanks for any help!!
>>>>>>
>>>>>>
>>>>>> Frank S.
>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep 26 23:18:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Sep 2016 14:18:52 -0700
Subject: [R] Using lapply in R data table
In-Reply-To: <CAGxFJbQ=VJKh6YZwvhbe3hNLfZZu4qpo=tb-=YrSFNmfdnQp1g@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
	<CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
	<CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>
	<CA+vqiLH5vq8Fe5mPUwdkux9ww2x0H3oaxt=UoBqzF_Q0bSvRvw@mail.gmail.com>
	<CAGxFJbQ=VJKh6YZwvhbe3hNLfZZu4qpo=tb-=YrSFNmfdnQp1g@mail.gmail.com>
Message-ID: <CAGxFJbQ6N8=xT3aFjxK_iORoScT+MSX0BK2zj09-8CzvkxPErQ@mail.gmail.com>

... and just for fun, here's an alternative in which mapply() is used
to vectorize switch(); again, whether you like it may be just a matter
of taste, although I suspect it might be less efficient than ifelse(),
which is already vectorized:

DT <- within(DT,
            exposure <- {
              mapply(function(x,fac)switch(as.character(fac),
                          a = 1,
                          b = difftime(as.Date("2007-01-01"), x,
units="days")/365.25,
                          c = .5
                    ),
              x = fini,
              fac =
cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")),
                        labels= letters[1:3])
              )}
      )


> DT
  id       fini group  exposure
1  2 2005-04-20     A 1.0000000
2  2 2005-04-20     A 1.0000000
3  2 2005-04-20     A 1.0000000
4  5 2006-02-19     B 0.8651608
5  5 2006-06-29     B 0.5092402
6  7 2006-10-08     A 0.5000000
7  7 2006-10-08     A 0.5000000


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 26, 2016 at 1:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Ista:
>
> Aha -- now I see the point. My bad. You are right. I was careless.
>
> However, cut() with ifelse() might simplify the code a bit and/or make
> it more readable. To be clear, this is just a matter of taste; e.g.
> using your data and a data frame instead of a data table:
>
>> DT <- within(DT,
>         exposure <- {
>           f <-cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")),
>               labels= letters[1:3])
>           ifelse(f == "a", 1,
>                  ifelse( f == "c", .5,
>                     difftime(as.Date("2007-01-01"), fini, units="days")/365.25))
> }
>         )
>
>
>> DT
>   id       fini group  exposure f
> 1  2 2005-04-20     A 1.0000000 a
> 2  2 2005-04-20     A 1.0000000 a
> 3  2 2005-04-20     A 1.0000000 a
> 4  5 2006-02-19     B 0.8651608 b
> 5  5 2006-06-29     B 0.5092402 b
> 6  7 2006-10-08     A 0.5000000 c
> 7  7 2006-10-08     A 0.5000000 c
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 26, 2016 at 12:07 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> On Mon, Sep 26, 2016 at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> I thought that that was a typo from the OP, as it disagrees with his
>>> example. But the labels are arbitrary, so in fact cut() will do it
>>> whichever way he meant.
>>
>> I don't see how cut will do it, at least not conveniently. Consider
>> this slightly altered example:
>>
>> library(data.table)
>> DT <- data.table(
>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>   fini = rep(as.Date(c('2005-04-20',
>>                        '2006-02-19',
>>                        '2006-06-29',
>>                        '2006-10-08')),
>>              c(3, 1, 1, 2)),
>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>
>> DT[, exposure := vector(mode = "numeric", length = .N)]
>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>    exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>
>> DT
>>
>> ##    id       fini group  exposure
>> ## 1:  2 2005-04-20     A 1.0000000
>> ## 2:  2 2005-04-20     A 1.0000000
>> ## 3:  2 2005-04-20     A 1.0000000
>> ## 4:  5 2006-02-19     B 0.8651608
>> ## 5:  5 2006-06-29     B 0.5092402
>> ## 6:  7 2006-10-08     A 0.5000000
>> ## 7:  7 2006-10-08     A 0.5000000
>>
>> Best,
>> Ista
>>
>>>
>>> -- Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Sep 26, 2016 at 11:37 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>> On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> This seems like a job for cut() .
>>>>
>>>> I thought that at first two, but the middle group shouldn't be .87 but rather
>>>>
>>>> exposure" = "2007-01-01" - "fini"
>>>>
>>>> so, I think cut alone won't do it.
>>>>
>>>> Best,
>>>> Ista
>>>>>
>>>>> (I made DT a data frame to avoid loading the data table package. But I
>>>>> assume it would work with a data table too, Check this, though!)
>>>>>
>>>>>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>>>>>
>>>>>> DT
>>>>>   id       fini group exposure
>>>>> 1  2 2005-04-20     A        1
>>>>> 2  2 2005-04-20     A        1
>>>>> 3  2 2005-04-20     A        1
>>>>> 4  5 2006-02-19     B     0.87
>>>>> 5  5 2006-02-19     B     0.87
>>>>> 6  7 2006-10-08     A      0.5
>>>>> 7  7 2006-10-08     A      0.5
>>>>>
>>>>>
>>>>> (but note that exposure is a factor, not numeric)
>>>>>
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>>>> Hi Frank,
>>>>>>
>>>>>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>>>>>
>>>>>> There are probably better ways, but here is one approach.
>>>>>>
>>>>>> DT[, exposure := vector(mode = "numeric", length = .N)]
>>>>>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>>>>>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>>>>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>>>>>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>>>>>
>>>>>> Best,
>>>>>> Ista
>>>>>>
>>>>>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I have a R data table like this:
>>>>>>>
>>>>>>> DT <- data.table(
>>>>>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>>>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>>>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>>>>>
>>>>>>>
>>>>>>> I want to construct a new variable "exposure" defined as follows:
>>>>>>>
>>>>>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>>>>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>>>>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>>>>>
>>>>>>>
>>>>>>> So the desired output would be the following data table:
>>>>>>>
>>>>>>>    id                fini exposure group
>>>>>>> 1:  2 2005-04-20        1.00        A
>>>>>>> 2:  2 2005-04-20        1.00        A
>>>>>>> 3:  2 2005-04-20        1.00        A
>>>>>>> 4:  5 2006-02-19        0.87        B
>>>>>>> 5:  5 2006-02-19        0.87        B
>>>>>>> 6:  7 2006-10-08        0.50        A
>>>>>>> 7:  7 2006-10-08        0.50        A
>>>>>>>
>>>>>>>
>>>>>>> I have tried:
>>>>>>>
>>>>>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>>>>>> DT.new <- lapply(DT, function(exposure){
>>>>>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>>>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>>>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>>>>>       exposure  # return value
>>>>>>>   })
>>>>>>>
>>>>>>>
>>>>>>> But I get an error message.
>>>>>>>
>>>>>>> Thanks for any help!!
>>>>>>>
>>>>>>>
>>>>>>> Frank S.
>>>>>>>
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Mon Sep 26 23:56:54 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 27 Sep 2016 03:26:54 +0530
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
Message-ID: <CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>

Hi again,

I have been following above suggestion to export data from R to xlsx
file using XLconnect. However recently I am facing Java memory
allocation problem with large dataset (looks like a known issue with
this package) and therefore decided to move to using "xlsx" package.

Now I started facing that same problem of losing my existing formating
when I use xlsx package for data export. Can someone help me with some
pointer on how can I preserve the cell formating after exporting
data.frame to some existing xlsx file using "xlsx" package.

Thanks for your time.

On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
> I think, this is what you are looking for:
>
> http://stackoverflow.com/questions/11228942/write-from-r-into-template-in-excel-while-preserving-formatting
>
> On 11 Jul 2016, at 03:43, Christofer Bogaso <bogaso.christofer at gmail.com>
> wrote:
>
> Hi again,
>
> I am trying to write a data frame to an existing Excel file (xlsx)
> from row 5 and column 6 of the 1st Sheet. I was going through a
> previous instruction which is available here :
>
> http://stackoverflow.com/questions/32632137/using-write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
>
> However trouble is that it is modifying/removing formatting of all the
> affected cells. I have predefined formatting of those cells where data
> to be pasted, and I dont want to modify or remove that formatting.
>
> Any idea if I need to pass some additional argument.
>
> Appreciate your valuable feedback.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From jholtman at gmail.com  Tue Sep 27 00:09:27 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 26 Sep 2016 18:09:27 -0400
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
Message-ID: <CAAxdm-4yGmjSw7FRo19tWiaYsqm2xRhQK+QuZoFxYZonMpBghw@mail.gmail.com>

I use the "openxlsx" package to handle spreadsheets.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Sep 26, 2016 at 5:56 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi again,
>
> I have been following above suggestion to export data from R to xlsx
> file using XLconnect. However recently I am facing Java memory
> allocation problem with large dataset (looks like a known issue with
> this package) and therefore decided to move to using "xlsx" package.
>
> Now I started facing that same problem of losing my existing formating
> when I use xlsx package for data export. Can someone help me with some
> pointer on how can I preserve the cell formating after exporting
> data.frame to some existing xlsx file using "xlsx" package.
>
> Thanks for your time.
>
> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com>
> wrote:
> > I think, this is what you are looking for:
> >
> > http://stackoverflow.com/questions/11228942/write-from-
> r-into-template-in-excel-while-preserving-formatting
> >
> > On 11 Jul 2016, at 03:43, Christofer Bogaso <bogaso.christofer at gmail.com
> >
> > wrote:
> >
> > Hi again,
> >
> > I am trying to write a data frame to an existing Excel file (xlsx)
> > from row 5 and column 6 of the 1st Sheet. I was going through a
> > previous instruction which is available here :
> >
> > http://stackoverflow.com/questions/32632137/using-
> write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
> >
> > However trouble is that it is modifying/removing formatting of all the
> > affected cells. I have predefined formatting of those cells where data
> > to be pasted, and I dont want to modify or remove that formatting.
> >
> > Any idea if I need to pass some additional argument.
> >
> > Appreciate your valuable feedback.
> >
> > Thanks,
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 27 01:11:14 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Sep 2016 16:11:14 -0700
Subject: [R] src/Makevars ignored ?
In-Reply-To: <81676230-d171-fccd-5d38-612601ddbef7@pasteur.fr>
References: <81676230-d171-fccd-5d38-612601ddbef7@pasteur.fr>
Message-ID: <94D51998-F2C6-42F6-87A8-4FA7E6AF1E29@dcn.davis.ca.us>

You failed to read the Posting Guide, which would have told you which mailing list to post this question to. (Hint: not this one.)
-- 
Sent from my phone. Please excuse my brevity.

On September 26, 2016 4:46:06 AM PDT, Eric Deveaud <edeveaud at pasteur.fr> wrote:
>
>
>	Hello,
>
>as far as I understood the R library generic compilation mechanism, 
>compilation of C//C++ sources is controlde
>
>1) at system level by the ocntentos RHOME/etc/Makeconf
>2) at user level by the content of ~/.R/Makevars
>3) at package level by the content of src/Makevars
>
>Problem I have is that src/Makevars is ignored
>
>
>see following example:
>
>R is compiled and use the following CC and CFLAGS definition
>
>bigmess:epactsR/src > R CMD config CC
>gcc -std=gnu99
>bigmess:epactsR/src > R CMD config CFLAGS
>-Wall -g
>
>so building C sources lead to the following
>
>bigmess:epactsR/src > R CMD SHLIB index.c
>gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG 
>-I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o
>
>normal, it uses defintion from RHOME/etc/Makeconf
>
>
>when I set upp a ~/.R/Makevars that overwrite CC and CFLAGS definition.
>
>bigmess:epactsR/src > cat ~/.R/Makevars
>CC=gcc
>CFLAGS=-O3
>bigmess:epactsR/src > R CMD SHLIB index.c
>gcc -I/local/gensoft2/adm/lib64/R/include -DNDEBUG 
>-I/usr/local/include 
>    -fpic  -O3 -c index.c -o index.o
>gcc -std=gnu99 -shared -L/usr/local/lib64 -o index.so index.o
>
>
>OK CC and CFLAGS are honored and set accordingly to ~/.R/Makevars
>
>
>but when I try to use src/Makevars, it is ignored
>
>bigmess:epactsR/src > cat ~/.R/Makevars
>cat: /home/edeveaud/.R/Makevars: No such file or directory
>bigmess:epactsR/src > cat ./Makevars
>CC = gcc
>CFLAGS=-O3
>bigmess:epactsR/src > R CMD SHLIB index.c
>gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG 
>-I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o
>
>
>what I have missed or is there something wrong ?
>
>
>PS I tested the ssame behaviour with various version of R from R/2.15
>to 
>R/3.3
>
>	best regards
>
>	Eric
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From prseye at gmail.com  Tue Sep 27 01:04:25 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 27 Sep 2016 09:04:25 +1000
Subject: [R] ggplot grouped barchart based on marginal proportions
Message-ID: <etPan.57e9a979.3561309f.1a8@gmail.com>

I am trying to create a grouped barplot that uses marginal (row) proportions rather than cell proportions and can't figure out how to change:

y = (..count..)/sum(..count..)
in ggplot to do this.

Using the mtcars dataset as an example and considering two categorical variables (cyl and am - purely for the sake of the example taking cyl as the response and am as the explanatory variable). Can anyone help me to do this:

data(mtcars)
# Get Proportions
mtcars_xtab <- table(mtcars$cyl,mtcars$am)
mtcars_xtab
margin.table(mtcars_xtab, 1) # A frequencies (summed over B) 
margin.table(mtcars_xtab, 2) # B frequencies (summed over A)
prop.table(mtcars_xtab) # cell percentages - THIS IS WHAT'S USED IN THE PLOT
prop.table(mtcars_xtab, 1) # row percentages - THESE ARE WHAT I WANT TO USE IN THE PLOT

# Make Plot
mtcars$cyl <- as.factor(mtcars$cyl) 
mtcars$am <- as.factor(mtcars$am) 
ggplot(mtcars, aes(x=am, fill=cyl)) +
geom_bar(aes(y = (..count..)/sum(..count..)), position = "dodge") +
  scale_fill_brewer(palette="Set2")
Thank you.




	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Tue Sep 27 06:53:24 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 27 Sep 2016 10:23:24 +0530
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <CAAxdm-4yGmjSw7FRo19tWiaYsqm2xRhQK+QuZoFxYZonMpBghw@mail.gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
	<CAAxdm-4yGmjSw7FRo19tWiaYsqm2xRhQK+QuZoFxYZonMpBghw@mail.gmail.com>
Message-ID: <CA+dpOJmFDw5pZXqibcRLxCZUK6Hd5N3jTfdjYUkKVo+JtN87fw@mail.gmail.com>

openxlsx is not solving my problem either. It is corrupting my xlsx file.

I have a large data.frame, which I want to export to an existing xlsx
file, without formatting that existing file. With XLconnect there is
an option "setStyleAction(wb,XLC$"STYLE_ACTION.NONE")" which does it
so. I am looking for a similar codeline for xlsx package which will
enable me to save my data.frame in my existing file without formatting
my xlsx file.

Thanks,

On Tue, Sep 27, 2016 at 3:39 AM, jim holtman <jholtman at gmail.com> wrote:
> I use the "openxlsx" package to handle spreadsheets.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Mon, Sep 26, 2016 at 5:56 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> Hi again,
>>
>> I have been following above suggestion to export data from R to xlsx
>> file using XLconnect. However recently I am facing Java memory
>> allocation problem with large dataset (looks like a known issue with
>> this package) and therefore decided to move to using "xlsx" package.
>>
>> Now I started facing that same problem of losing my existing formating
>> when I use xlsx package for data export. Can someone help me with some
>> pointer on how can I preserve the cell formating after exporting
>> data.frame to some existing xlsx file using "xlsx" package.
>>
>> Thanks for your time.
>>
>> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com>
>> wrote:
>> > I think, this is what you are looking for:
>> >
>> >
>> > http://stackoverflow.com/questions/11228942/write-from-r-into-template-in-excel-while-preserving-formatting
>> >
>> > On 11 Jul 2016, at 03:43, Christofer Bogaso
>> > <bogaso.christofer at gmail.com>
>> > wrote:
>> >
>> > Hi again,
>> >
>> > I am trying to write a data frame to an existing Excel file (xlsx)
>> > from row 5 and column 6 of the 1st Sheet. I was going through a
>> > previous instruction which is available here :
>> >
>> >
>> > http://stackoverflow.com/questions/32632137/using-write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
>> >
>> > However trouble is that it is modifying/removing formatting of all the
>> > affected cells. I have predefined formatting of those cells where data
>> > to be pasted, and I dont want to modify or remove that formatting.
>> >
>> > Any idea if I need to pass some additional argument.
>> >
>> > Appreciate your valuable feedback.
>> >
>> > Thanks,
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From karlneergaard at gmail.com  Tue Sep 27 06:50:30 2016
From: karlneergaard at gmail.com (Karl Neergaard)
Date: Tue, 27 Sep 2016 12:50:30 +0800
Subject: [R] Error in gam() object 'scat' no found
Message-ID: <CAMKhwd8WrqNsTsOGFTJGNpouaaYBNjdXH7hiJ4SLTM+nA0oUZQ@mail.gmail.com>

I received an error message while trying to use family=scat in the GAM
package. The models were working fine yesterday.
The problem is not with my data seeing as the gaussian distribution is
working fine.

mod=gam(RT~s(a) + s(b), data=dat, family=gaussian)
mod=gam(RT~s(a) + s(b), data=dat, family=scat)

Might this problem be unrelated to GAM specifically, and to my R
configuration?
I have removed the gam package and re-installed it several times to no
avail.

Thank you for any assistance,
Karl

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Tue Sep 27 08:36:51 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Mon, 26 Sep 2016 23:36:51 -0700
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
Message-ID: <39a2ee85-addf-17ad-4b13-f3d6120b65fb@gmail.com>

On 9/26/2016 2:56 PM, Christofer Bogaso wrote:
> Hi again,
>
> I have been following above suggestion to export data from R to xlsx
> file using XLconnect. However recently I am facing Java memory
> allocation problem with large dataset (looks like a known issue with
> this package) and therefore decided to move to using "xlsx" package.
>
> Now I started facing that same problem of losing my existing formating
> when I use xlsx package for data export. Can someone help me with some
> pointer on how can I preserve the cell formating after exporting
> data.frame to some existing xlsx file using "xlsx" package.
>
> Thanks for your time.
>
> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
>> I think, this is what you are looking for:
>>
>> http://stackoverflow.com/questions/11228942/write-from-r-into-template-in-excel-while-preserving-formatting
>>
>> On 11 Jul 2016, at 03:43, Christofer Bogaso <bogaso.christofer at gmail.com>
>> wrote:
>>
>> Hi again,
>>
>> I am trying to write a data frame to an existing Excel file (xlsx)
>> from row 5 and column 6 of the 1st Sheet. I was going through a
>> previous instruction which is available here :
>>
>> http://stackoverflow.com/questions/32632137/using-write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
>>
>> However trouble is that it is modifying/removing formatting of all the
>> affected cells. I have predefined formatting of those cells where data
>> to be pasted, and I dont want to modify or remove that formatting.
>>
>> Any idea if I need to pass some additional argument.
>>
>> Appreciate your valuable feedback.
>>
>> Thanks,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

It would help the list to help you if you gave a reproducible example. 
In the absence of that, at least show the actual code you are using to 
write to the Excel (.xlsx) sheet.

But maybe reading about the "create" argument on page 13 of this linked 
document will help:

https://cran.r-project.org/web/packages/xlsx/xlsx.pdf


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From martin.morgan at roswellpark.org  Tue Sep 27 10:38:14 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 27 Sep 2016 04:38:14 -0400
Subject: [R] src/Makevars ignored ?
In-Reply-To: <81676230-d171-fccd-5d38-612601ddbef7@pasteur.fr>
References: <81676230-d171-fccd-5d38-612601ddbef7@pasteur.fr>
Message-ID: <23076bde-a51b-909b-2b89-5d6f296629e2@roswellpark.org>

On 09/26/2016 07:46 AM, Eric Deveaud wrote:
>
>
>     Hello,
>
> as far as I understood the R library generic compilation mechanism,
> compilation of C//C++ sources is controlde
>
> 1) at system level by the ocntentos RHOME/etc/Makeconf
> 2) at user level by the content of ~/.R/Makevars
> 3) at package level by the content of src/Makevars
>
> Problem I have is that src/Makevars is ignored
>
>
> see following example:
>
> R is compiled and use the following CC and CFLAGS definition
>
> bigmess:epactsR/src > R CMD config CC
> gcc -std=gnu99
> bigmess:epactsR/src > R CMD config CFLAGS
> -Wall -g
>
> so building C sources lead to the following
>
> bigmess:epactsR/src > R CMD SHLIB index.c
> gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG
> -I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o
>
> normal, it uses defintion from RHOME/etc/Makeconf
>
>
> when I set upp a ~/.R/Makevars that overwrite CC and CFLAGS definition.
>
> bigmess:epactsR/src > cat ~/.R/Makevars
> CC=gcc
> CFLAGS=-O3
> bigmess:epactsR/src > R CMD SHLIB index.c
> gcc -I/local/gensoft2/adm/lib64/R/include -DNDEBUG  -I/usr/local/include
>    -fpic  -O3 -c index.c -o index.o
> gcc -std=gnu99 -shared -L/usr/local/lib64 -o index.so index.o
>
>
> OK CC and CFLAGS are honored and set accordingly to ~/.R/Makevars
>
>
> but when I try to use src/Makevars, it is ignored
>
> bigmess:epactsR/src > cat ~/.R/Makevars
> cat: /home/edeveaud/.R/Makevars: No such file or directory
> bigmess:epactsR/src > cat ./Makevars
> CC = gcc
> CFLAGS=-O3
> bigmess:epactsR/src > R CMD SHLIB index.c
> gcc -std=gnu99 -I/local/gensoft2/adm/lib64/R/include -DNDEBUG
> -I/usr/local/include    -fpic  -Wall -g  -c index.c -o index.o
>
>
> what I have missed or is there something wrong ?

Use PKG_CFLAGS instead of CFLAGS; CC cannot be changed in Makevars. See 
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Using-Makevars

Martin Morgan

>
>
> PS I tested the ssame behaviour with various version of R from R/2.15 to
> R/3.3
>
>     best regards
>
>     Eric
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or...{{dropped:2}}


From f_j_rod at hotmail.com  Tue Sep 27 12:10:59 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Tue, 27 Sep 2016 10:10:59 +0000
Subject: [R] Using lapply in R data table
In-Reply-To: <CAGxFJbQ6N8=xT3aFjxK_iORoScT+MSX0BK2zj09-8CzvkxPErQ@mail.gmail.com>
References: <AM5PR0402MB268910FFF8FD29EFCAED6E8CBACD0@AM5PR0402MB2689.eurprd04.prod.outlook.com>
	<CA+vqiLE0AakNa1Gym=KbuXkbBCKjWk-N-CPhnzqCV0mbKg2+_Q@mail.gmail.com>
	<CAGxFJbRHwe=NX-0skrU0A7MLCEmLDXP-5KUgzTQTbGUcys57Yw@mail.gmail.com>
	<CA+vqiLFfbDT-4W+7AW4AC-VRAqZvqys6D3PXgbhK3Nw3Ha2E4A@mail.gmail.com>
	<CAGxFJbSE6mSvsGF72yzD+FGO=2o2e_cYy5eaTj_+YKiDVpoW3Q@mail.gmail.com>
	<CA+vqiLH5vq8Fe5mPUwdkux9ww2x0H3oaxt=UoBqzF_Q0bSvRvw@mail.gmail.com>
	<CAGxFJbQ=VJKh6YZwvhbe3hNLfZZu4qpo=tb-=YrSFNmfdnQp1g@mail.gmail.com>,
	<CAGxFJbQ6N8=xT3aFjxK_iORoScT+MSX0BK2zj09-8CzvkxPErQ@mail.gmail.com>
Message-ID: <AM5PR0402MB2689B6B08313C106871B1592BACC0@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Many thanks Ista and Bert for your nice solutions!


As Ista commented in a previous mail, the 0.87 value in my example is not fixed, but for each subject
it depends on the difference "2007-01-01 - fini". However, both of your solutions take into account this
fact.


Frank S.

________________________________
De: Bert Gunter <bgunter.4567 at gmail.com>
Enviat el: dilluns, 26 de setembre de 2016 23:18:52
Per a: Ista Zahn
A/c: Frank S.; r-help at r-project.org
Tema: Re: [R] Using lapply in R data table

... and just for fun, here's an alternative in which mapply() is used
to vectorize switch(); again, whether you like it may be just a matter
of taste, although I suspect it might be less efficient than ifelse(),
which is already vectorized:

DT <- within(DT,
            exposure <- {
              mapply(function(x,fac)switch(as.character(fac),
                          a = 1,
                          b = difftime(as.Date("2007-01-01"), x,
units="days")/365.25,
                          c = .5
                    ),
              x = fini,
              fac =
cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")),
                        labels= letters[1:3])
              )}
      )


> DT
  id       fini group  exposure
1  2 2005-04-20     A 1.0000000
2  2 2005-04-20     A 1.0000000
3  2 2005-04-20     A 1.0000000
4  5 2006-02-19     B 0.8651608
5  5 2006-06-29     B 0.5092402
6  7 2006-10-08     A 0.5000000
7  7 2006-10-08     A 0.5000000


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 26, 2016 at 1:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Ista:
>
> Aha -- now I see the point. My bad. You are right. I was careless.
>
> However, cut() with ifelse() might simplify the code a bit and/or make
> it more readable. To be clear, this is just a matter of taste; e.g.
> using your data and a data frame instead of a data table:
>
>> DT <- within(DT,
>         exposure <- {
>           f <-cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")),
>               labels= letters[1:3])
>           ifelse(f == "a", 1,
>                  ifelse( f == "c", .5,
>                     difftime(as.Date("2007-01-01"), fini, units="days")/365.25))
> }
>         )
>
>
>> DT
>   id       fini group  exposure f
> 1  2 2005-04-20     A 1.0000000 a
> 2  2 2005-04-20     A 1.0000000 a
> 3  2 2005-04-20     A 1.0000000 a
> 4  5 2006-02-19     B 0.8651608 b
> 5  5 2006-06-29     B 0.5092402 b
> 6  7 2006-10-08     A 0.5000000 c
> 7  7 2006-10-08     A 0.5000000 c
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Sep 26, 2016 at 12:07 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> On Mon, Sep 26, 2016 at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> I thought that that was a typo from the OP, as it disagrees with his
>>> example. But the labels are arbitrary, so in fact cut() will do it
>>> whichever way he meant.
>>
>> I don't see how cut will do it, at least not conveniently. Consider
>> this slightly altered example:
>>
>> library(data.table)
>> DT <- data.table(
>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>   fini = rep(as.Date(c('2005-04-20',
>>                        '2006-02-19',
>>                        '2006-06-29',
>>                        '2006-10-08')),
>>              c(3, 1, 1, 2)),
>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>
>> DT[, exposure := vector(mode = "numeric", length = .N)]
>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>    exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>
>> DT
>>
>> ##    id       fini group  exposure
>> ## 1:  2 2005-04-20     A 1.0000000
>> ## 2:  2 2005-04-20     A 1.0000000
>> ## 3:  2 2005-04-20     A 1.0000000
>> ## 4:  5 2006-02-19     B 0.8651608
>> ## 5:  5 2006-06-29     B 0.5092402
>> ## 6:  7 2006-10-08     A 0.5000000
>> ## 7:  7 2006-10-08     A 0.5000000
>>
>> Best,
>> Ista
>>
>>>
>>> -- Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Sep 26, 2016 at 11:37 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>> On Mon, Sep 26, 2016 at 1:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> This seems like a job for cut() .
>>>>
>>>> I thought that at first two, but the middle group shouldn't be .87 but rather
>>>>
>>>> exposure" = "2007-01-01" - "fini"
>>>>
>>>> so, I think cut alone won't do it.
>>>>
>>>> Best,
>>>> Ista
>>>>>
>>>>> (I made DT a data frame to avoid loading the data table package. But I
>>>>> assume it would work with a data table too, Check this, though!)
>>>>>
>>>>>> DT <- within(DT, exposure <- cut(fini,as.Date(c("2000-01-01","2006-01-01","2006-06-30","2006-12-21")), labels= c(1,.87,.5)))
>>>>>
>>>>>> DT
>>>>>   id       fini group exposure
>>>>> 1  2 2005-04-20     A        1
>>>>> 2  2 2005-04-20     A        1
>>>>> 3  2 2005-04-20     A        1
>>>>> 4  5 2006-02-19     B     0.87
>>>>> 5  5 2006-02-19     B     0.87
>>>>> 6  7 2006-10-08     A      0.5
>>>>> 7  7 2006-10-08     A      0.5
>>>>>
>>>>>
>>>>> (but note that exposure is a factor, not numeric)
>>>>>
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Mon, Sep 26, 2016 at 10:05 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>>>> Hi Frank,
>>>>>>
>>>>>> lapply(DT) iterates over each column. That doesn't seem to be what you want.
>>>>>>
>>>>>> There are probably better ways, but here is one approach.
>>>>>>
>>>>>> DT[, exposure := vector(mode = "numeric", length = .N)]
>>>>>> DT[fini < as.Date("2006-01-01"), exposure := 1]
>>>>>> DT[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30"),
>>>>>>       exposure := difftime(as.Date("2007-01-01"), fini, units="days")/365.25]
>>>>>> DT[fini >= as.Date("2006-07-01"), exposure := 0.5]
>>>>>>
>>>>>> Best,
>>>>>> Ista
>>>>>>
>>>>>> On Mon, Sep 26, 2016 at 11:28 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I have a R data table like this:
>>>>>>>
>>>>>>> DT <- data.table(
>>>>>>>   id = rep(c(2, 5, 7), c(3, 2, 2)),
>>>>>>>   fini = rep(as.Date(c('2005-04-20', '2006-02-19', '2006-10-08')), c(3, 2, 2)),
>>>>>>>   group = rep(c("A", "B", "A"), c(3, 2, 2))  )
>>>>>>>
>>>>>>>
>>>>>>> I want to construct a new variable "exposure" defined as follows:
>>>>>>>
>>>>>>> 1) If "fini" earlier than 2006-01-01 --> "exposure" = 1
>>>>>>> 2) If "fini" in [2006-01-01, 2006-06-30] --> "exposure" = "2007-01-01" - "fini"
>>>>>>> 3) If "fini" in [2006-07-01, 2006-12-31] --> "exposure" = 0.5
>>>>>>>
>>>>>>>
>>>>>>> So the desired output would be the following data table:
>>>>>>>
>>>>>>>    id                fini exposure group
>>>>>>> 1:  2 2005-04-20        1.00        A
>>>>>>> 2:  2 2005-04-20        1.00        A
>>>>>>> 3:  2 2005-04-20        1.00        A
>>>>>>> 4:  5 2006-02-19        0.87        B
>>>>>>> 5:  5 2006-02-19        0.87        B
>>>>>>> 6:  7 2006-10-08        0.50        A
>>>>>>> 7:  7 2006-10-08        0.50        A
>>>>>>>
>>>>>>>
>>>>>>> I have tried:
>>>>>>>
>>>>>>> DT <- DT[ , list(id, fini, exposure = 0, group)]
>>>>>>> DT.new <- lapply(DT, function(exposure){
>>>>>>>       exposure[fini < as.Date("2006-01-01")] <- 1   # 1st case
>>>>>>>       exposure[fini >= as.Date("2006-01-01") & fini <= as.Date("2006-06-30")] <- difftime(as.Date("2007-01-01"), fini, units="days")/365.25 # 2nd case
>>>>>>>     exposure[fini >= as.Date("2006-07-01") & fini <= as.Date("2006-12-31")] <- 0.5       # 3rd case
>>>>>>>       exposure  # return value
>>>>>>>   })
>>>>>>>
>>>>>>>
>>>>>>> But I get an error message.
>>>>>>>
[[elided Hotmail spam]]
>>>>>>>
>>>>>>>
>>>>>>> Frank S.
>>>>>>>
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From R.E.Crump at warwick.ac.uk  Tue Sep 27 12:48:35 2016
From: R.E.Crump at warwick.ac.uk (Crump, Ron)
Date: Tue, 27 Sep 2016 10:48:35 +0000
Subject: [R] ggplot grouped barchart based on marginal proportions
Message-ID: <D4100BDF.73D7%lfslbx@live.warwick.ac.uk>

Hi Paul,

Do you want to avoid using prop.table(mtcars_xtab, 1) ?

If not, how about:

ggplot(as.data.frame(prop.table(mtcars_xtab, 1)))+
 geom_bar(aes(x=Var2,y=Freq,fill=Var1), stat="identity", position="dodge")+
 scale_fill_brewer(palette="Set2")


Ron.


From stud1830153714 at sums.ac.ir  Tue Sep 27 10:45:13 2016
From: stud1830153714 at sums.ac.ir (stud1830153714)
Date: Tue, 27 Sep 2016 12:15:13 +0330
Subject: [R] =?utf-8?b?Ui1wYWNrYWdlICjigJxTZUN1cmVkU3VyduKAnSk=?=
Message-ID: <2822cdb2b16ca81b2322bcf917edf047@sums.ac.ir>

 

To whom it may concern 

 I am MS student of Biostatistics. One of my thesis references is the
article" High-Dimensional Variable Selection for Multivariate and
Survival Data with Applications to Brain Imaging and Genetic Association
Studies. "And in the article it mentions that they use the R-package
("SeCuredSurv") but I didn't have found it in your site yet. I will be
really thankful if you could help me to find it. 

Thanks and regards 
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Sep 27 16:01:01 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 27 Sep 2016 10:01:01 -0400
Subject: [R] =?utf-8?b?Ui1wYWNrYWdlICjigJxTZUN1cmVkU3VyduKAnSk=?=
In-Reply-To: <2822cdb2b16ca81b2322bcf917edf047@sums.ac.ir>
References: <2822cdb2b16ca81b2322bcf917edf047@sums.ac.ir>
Message-ID: <CAM_vjun4BHG9HGBQ_ShMtiAozz0ho7TP01_VmgJe0C5pkeFJYQ@mail.gmail.com>

The only google hit appears to be that paper, which is a 2014 PhD
dissertation, and states that the author will be uploading it on CRAN.
Since that hasn't been done, the only thing you can do is try to track
down the author and ask.

Sarah

On Tue, Sep 27, 2016 at 4:45 AM, stud1830153714
<stud1830153714 at sums.ac.ir> wrote:
>
>
> To whom it may concern
>
>  I am MS student of Biostatistics. One of my thesis references is the
> article" High-Dimensional Variable Selection for Multivariate and
> Survival Data with Applications to Brain Imaging and Genetic Association
> Studies. "And in the article it mentions that they use the R-package
> ("SeCuredSurv") but I didn't have found it in your site yet. I will be
> really thankful if you could help me to find it.
>
> Thanks and regards
>         [[alternative HTML version deleted]]

-- 
Sarah Goslee
http://www.functionaldiversity.org


From thierry.onkelinx at inbo.be  Tue Sep 27 16:17:15 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 27 Sep 2016 16:17:15 +0200
Subject: [R] =?utf-8?b?Ui1wYWNrYWdlICjigJxTZUN1cmVkU3VyduKAnSk=?=
In-Reply-To: <2822cdb2b16ca81b2322bcf917edf047@sums.ac.ir>
References: <2822cdb2b16ca81b2322bcf917edf047@sums.ac.ir>
Message-ID: <CAJuCY5xDPR-Y2ZP65MtG_jWPy_F5ZGSqKmS8uKp8TBPwT+EGew@mail.gmail.com>

Dear Anonymous,

It's seems like that package never made it to CRAN. You should contact the
package author or the author of the reference.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-27 10:45 GMT+02:00 stud1830153714 <stud1830153714 at sums.ac.ir>:

>
>
> To whom it may concern
>
>  I am MS student of Biostatistics. One of my thesis references is the
> article" High-Dimensional Variable Selection for Multivariate and
> Survival Data with Applications to Brain Imaging and Genetic Association
> Studies. "And in the article it mentions that they use the R-package
> ("SeCuredSurv") but I didn't have found it in your site yet. I will be
> really thankful if you could help me to find it.
>
> Thanks and regards
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Sep 27 17:15:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 27 Sep 2016 08:15:30 -0700
Subject: [R] Error in gam() object 'scat' no found
In-Reply-To: <CAMKhwd8WrqNsTsOGFTJGNpouaaYBNjdXH7hiJ4SLTM+nA0oUZQ@mail.gmail.com>
References: <CAMKhwd8WrqNsTsOGFTJGNpouaaYBNjdXH7hiJ4SLTM+nA0oUZQ@mail.gmail.com>
Message-ID: <7112F416-CC9A-4F79-A625-7C0C968F25FA@comcast.net>


> On Sep 26, 2016, at 9:50 PM, Karl Neergaard <karlneergaard at gmail.com> wrote:
> 
> I received an error message while trying to use family=scat in the GAM
> package. The models were working fine yesterday.
> The problem is not with my data seeing as the gaussian distribution is
> working fine.
> 
> mod=gam(RT~s(a) + s(b), data=dat, family=gaussian)
> mod=gam(RT~s(a) + s(b), data=dat, family=scat)
> 
> Might this problem be unrelated to GAM specifically, and to my R
> configuration?
> I have removed the gam package and re-installed it several times to no
> avail.

The scat function is in package mgcv. It also has a `gam` function and is generally thought of as the "standard" approach for estimating generalized additive models.


> 
> Thank you for any assistance,
> Karl
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From patrick-breheny at uiowa.edu  Tue Sep 27 16:01:40 2016
From: patrick-breheny at uiowa.edu (Patrick Breheny)
Date: Tue, 27 Sep 2016 09:01:40 -0500
Subject: [R] Statistical Computing & Graphics Student Paper Competition 2017
Message-ID: <c75e8f01-ac3d-532a-8f93-340dc5bd158b@uiowa.edu>

Statistical Computing and Statistical Graphics Sections
American Statistical Association

Student Paper Competition 2017

The Statistical Computing and Statistical Graphics Sections of the ASA 
are co-sponsoring a student paper competition on the topics of 
Statistical Computing and Statistical Graphics. Students are encouraged 
to submit a paper in one of these areas, which might be original 
methodological research, some novel computing or graphical application 
in statistics, or any other suitable contribution (for example, a 
software-related project). The selected winners will present their 
papers in a topic-contributed session at the 2017 Joint Statistical 
Meetings. The prize carries with it a cash award of $1,000.

Anyone who is a student (graduate or undergraduate) on or after 
September 1, 2016 is eligible to participate. An entry must include an 
abstract, a six page manuscript (including figures, tables and 
references; a two-column format is acceptable), blinded versions of the 
abstract and manuscript (with no author names or other information that 
easily identifies the authors), a CV, and a letter from a faculty member 
familiar with the student's work. The applicant must be the first author 
of the paper. The faculty letter must include a verification of the 
applicant's student status and, in the case of joint authorship, should 
indicate what fraction of the contribution is attributable to the 
applicant. We prefer that electronic submissions of papers consist of 
PDF files. All materials must be in English.

Students may submit papers to no more than two sections and may accept 
only one section's award. Students must inform both sections applied to 
when he or she wins and accepts an award, thereby removing the student 
from the award competition for the second section.

All application materials MUST BE RECEIVED by 5:00 PM EST, Thursday, 
December 15, 2016 at the address below. They will be reviewed by the 
Student Paper Competition Award committee of the Statistical Computing 
and Graphics Sections. The selection criteria used by the committee will 
include innovation and significance of the contribution as well as the 
professional quality of the manuscript. Award announcements will be made 
by January 15th.

Additional important information on the competition may be found at
<http://stat-computing.org/awards/student/faq.html> and
<https://www.amstat.org/ASA/Your-Career/Student-Paper-Competitions.aspx>.

Inquiries and application materials should be sent to:

Patrick Breheny
Department of Biostatistics
University of Iowa
patrick-breheny at uiowa.edu


From e_f_sh at yahoo.com  Tue Sep 27 16:18:15 2016
From: e_f_sh at yahoo.com (Elham Fakharizade)
Date: Tue, 27 Sep 2016 14:18:15 +0000 (UTC)
Subject: [R] Fw: R problem
In-Reply-To: <1219385272.5555804.1474985762792@mail.yahoo.com>
References: <1248662213.5486681.1474984582802.ref@mail.yahoo.com>
	<1248662213.5486681.1474984582802@mail.yahoo.com>
	<1219385272.5555804.1474985762792@mail.yahoo.com>
Message-ID: <1709349656.210948.1474985895925@mail.yahoo.com>





HelloI am university student.I should do a R home work. That is writing sen slope code in R and calculate it with out using package. I wrote one but, ?it is wrong. I attache my data and my script. would you please check it.Many thanksSincerely yoursElham

   

   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sen.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160927/909aa035/attachment.txt>

From patzelt at g.harvard.edu  Tue Sep 27 17:05:03 2016
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Tue, 27 Sep 2016 11:05:03 -0400
Subject: [R] Testing significance of individual regression slopes
Message-ID: <CAB9UfhQCsQhBjWtqbcr4sHGZ+yn_J7A-XWeu=zKbweXiOr4gBQ@mail.gmail.com>

Hi R-help,

I have an lmer logistic regression with a within subjects IV and subject as
a random factor:

model <- lmer(optimal_choice ~ level_one_value_difference + (1|subid), data
= dat)

What I want is to test if the individual subject regression coefficient is
significantly different from 0.


-- 
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University
*Computational Cognitive Neuroscience Laboratory
<http://gershmanlab.webfactional.com/>*

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 27 17:27:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Sep 2016 08:27:02 -0700
Subject: [R] Fw: R problem
In-Reply-To: <1709349656.210948.1474985895925@mail.yahoo.com>
References: <1248662213.5486681.1474984582802.ref@mail.yahoo.com>
	<1248662213.5486681.1474984582802@mail.yahoo.com>
	<1219385272.5555804.1474985762792@mail.yahoo.com>
	<1709349656.210948.1474985895925@mail.yahoo.com>
Message-ID: <CAGxFJbQR8qkFfpFj7jqx_NX_5Av8WCFpstwO1E+MH23RSH2Ffw@mail.gmail.com>

This list has a *no homework* policy.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 27, 2016 at 7:18 AM, Elham Fakharizade via R-help
<r-help at r-project.org> wrote:
>
>
>
>
> HelloI am university student.I should do a R home work. That is writing sen slope code in R and calculate it with out using package. I wrote one but,  it is wrong. I attache my data and my script. would you please check it.Many thanksSincerely yoursElham
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pai1981 at gmail.com  Tue Sep 27 18:06:43 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Tue, 27 Sep 2016 10:06:43 -0600
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
Message-ID: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>

Hi all,

I would like to access and subset following OpeNDAP files.
server:
http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/

file name: tmax.01.2014040312.daily.grb2
<http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/tmax.01.2014040312.daily.grb2>
I would like to access and subset the file. Any help will be appreciated.

with regards
-Deb

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 27 18:41:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Sep 2016 09:41:47 -0700
Subject: [R] Testing significance of individual regression slopes
In-Reply-To: <CAB9UfhQCsQhBjWtqbcr4sHGZ+yn_J7A-XWeu=zKbweXiOr4gBQ@mail.gmail.com>
References: <CAB9UfhQCsQhBjWtqbcr4sHGZ+yn_J7A-XWeu=zKbweXiOr4gBQ@mail.gmail.com>
Message-ID: <CAGxFJbTw-pcxCX4OxrVpGoNBbRdX7DJ3Sgb3aX79k9tBYffyqA@mail.gmail.com>

You can't if I understand correctly: there is no individual subject
regression coefficient, only a variance component for a random subject
intercept. Do you mean that you want to "test" whether that component
is nonzero ?(It is, of course).  If so, IIRC, lmer eschews such tests
for technical reasons -- they are based on approximations that lmer's
authors (esp. Doug Bates) contend are unreliable.

However, a web search on "test significance of lmer variance
components" brought up this:

https://www.r-bloggers.com/random-regression-coefficients-using-lme4/

and the "lmerTest" package, both of which seem relevant, again
assuming I have correctly divined your intent. You will have to
consult the literature or seek advice elsewhere (purely statistical
matters are generally OT here) to determine whether they are
appropriate for your situation.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 27, 2016 at 8:05 AM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> Hi R-help,
>
> I have an lmer logistic regression with a within subjects IV and subject as
> a random factor:
>
> model <- lmer(optimal_choice ~ level_one_value_difference + (1|subid), data
> = dat)
>
> What I want is to test if the individual subject regression coefficient is
> significantly different from 0.
>
>
> --
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
> *Computational Cognitive Neuroscience Laboratory
> <http://gershmanlab.webfactional.com/>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e_f_sh at yahoo.com  Tue Sep 27 18:11:06 2016
From: e_f_sh at yahoo.com (Elham Fakharizade)
Date: Tue, 27 Sep 2016 16:11:06 +0000 (UTC)
Subject: [R] Fw: R problem
In-Reply-To: <1709349656.210948.1474985895925@mail.yahoo.com>
References: <1248662213.5486681.1474984582802.ref@mail.yahoo.com>
	<1248662213.5486681.1474984582802@mail.yahoo.com>
	<1219385272.5555804.1474985762792@mail.yahoo.com>
	<1709349656.210948.1474985895925@mail.yahoo.com>
Message-ID: <1845795768.5629510.1474992666932@mail.yahoo.com>




HelloI want to calculate sen slope with out using package. I wrote one but, ?it is wrong. I attache my data and my script. would you please check it.Many thanksSincerely yoursElham

   

   

   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sen.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160927/db76ec59/attachment.txt>

From mkopyt at wne.uw.edu.pl  Tue Sep 27 17:37:34 2016
From: mkopyt at wne.uw.edu.pl (Mateusz Kopyt)
Date: Tue, 27 Sep 2016 17:37:34 +0200
Subject: [R] Researches about using R in economic educational purposes - ask
	for help / cooperation.
Message-ID: <8d3a6073dff72ae26daab5b8eaddf2de@coin.wne.uw.edu.pl>

Dear All,

first of all I'd like to say hello to everybody because it is my first 
post on the list.

I'm the academic teacher (Ph.D) at University of Warsaw, Faculty of 
Economic Sciences and I've been using R for a couple of years during my 
classes and in my scientific work. I'm not the only one person at my 
Faculty who uses R during classes. Except teaching, with my colleague dr 
Tomasz Kopczewski, we also conduct some research in the field of 
economic education. Recently we are working on analyzing of usefulness 
of studying programming / coding in different software (mostly Maxima an 
R-cran) in economic education. In simple words: is it worth of teaching 
and learning coding during studies of economics (but strictly for the 
economic purposes not coding per se)? From the practical point of  view 
the results of our research may help to study and learn R (or Maxima) 
language more effectively (we want to find the minimal set of commands, 
functions which is necessary and enough to teach economics, finance)

To achieve our goals in above mentioned research we are trying - just to 
give you an idea - to analyze R (and Maxima) codes / files used in 
economic education mostly on university level, but may also be on 
secondary school level, with some tools and methods used in linguistic 
analyses (quite often done to analyze foreign natural language 
studying). It means we want to build something what is similar to the 
language corpus for R'dialect' used in economic purposes and then as a 
result to get for example a WordCloud, check this 'dialect' in the light 
of Zipf law etc. To do this  we urgently need a lot of R codes used in 
teaching economics. That's why we decided to ask you for help. If you 
teach economics, finance etc. and you may provide us your files with R 
codes, it would be a great help. We may promise that we never publish 
them or use your codes in other purpose than to conduct above mentioned 
research. As 'a reward' we provide you with our findings and results and 
also we can share with you tools (written in R-cran software - so we 
analyze R with R :) ) which we develop, so you will be able to use them 
later over your files.

Except help with building R economic language corpus, feel free to make 
any comments and if you like - to cooperate with us (if you are also 
interested in this issue). Any time you may contact me 
(mkopyt at wne.uw.edu.pl) or Tomasz Kopczewski (tkopczewski at wne.uw.edu.pl) 
by mail.

Sorry for such long post but we wanted to give you at least an idea of 
our research and purpose we are asking for help.
-- 
Best regards
Mateusz Kopyt
Faculty of Economic Sciences
University of Warsaw


From bogaso.christofer at gmail.com  Tue Sep 27 18:45:50 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 27 Sep 2016 22:15:50 +0530
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <39a2ee85-addf-17ad-4b13-f3d6120b65fb@gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
	<39a2ee85-addf-17ad-4b13-f3d6120b65fb@gmail.com>
Message-ID: <CA+dpOJkmHe-4ZMbiOuG2BaSWLQS-4R_yfKNZvPCNRAOFAcGztQ@mail.gmail.com>

Hi Daniel,

Am attaching an example xlsx file which I need to modify.

I have tried with below code :

library(xlsx)
Data = data.frame(1:20)
wb <- loadWorkbook("asd.xlsx")   ### Assume I saved asd.xlsx in the
working directory
addDataFrame(Data, sheet = getSheets(wb)[['Sheet1']], startRow=5,
startColumn=2, row.names=F, col.names=F)
saveWorkbook(wb, "asd.xlsx")

Basically I am trying to modify the 2nd column with the data of 'Data'
however I do not want to disturb the formatting there in any extend.
However above code removing the cell color, which I do not want.

What could be right code for doing so?

Thanks and regards,

PS: not very sure if R forum would accept my attachment, if not that
file is available in https://ufile.io/50944

On Tue, Sep 27, 2016 at 12:06 PM, Daniel Nordlund <djnordlund at gmail.com> wrote:
> On 9/26/2016 2:56 PM, Christofer Bogaso wrote:
>>
>> Hi again,
>>
>> I have been following above suggestion to export data from R to xlsx
>> file using XLconnect. However recently I am facing Java memory
>> allocation problem with large dataset (looks like a known issue with
>> this package) and therefore decided to move to using "xlsx" package.
>>
>> Now I started facing that same problem of losing my existing formating
>> when I use xlsx package for data export. Can someone help me with some
>> pointer on how can I preserve the cell formating after exporting
>> data.frame to some existing xlsx file using "xlsx" package.
>>
>> Thanks for your time.
>>
>> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com>
>> wrote:
>>>
>>> I think, this is what you are looking for:
>>>
>>>
>>> http://stackoverflow.com/questions/11228942/write-from-r-into-template-in-excel-while-preserving-formatting
>>>
>>> On 11 Jul 2016, at 03:43, Christofer Bogaso <bogaso.christofer at gmail.com>
>>> wrote:
>>>
>>> Hi again,
>>>
>>> I am trying to write a data frame to an existing Excel file (xlsx)
>>> from row 5 and column 6 of the 1st Sheet. I was going through a
>>> previous instruction which is available here :
>>>
>>>
>>> http://stackoverflow.com/questions/32632137/using-write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
>>>
>>> However trouble is that it is modifying/removing formatting of all the
>>> affected cells. I have predefined formatting of those cells where data
>>> to be pasted, and I dont want to modify or remove that formatting.
>>>
>>> Any idea if I need to pass some additional argument.
>>>
>>> Appreciate your valuable feedback.
>>>
>>> Thanks,
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> It would help the list to help you if you gave a reproducible example. In
> the absence of that, at least show the actual code you are using to write to
> the Excel (.xlsx) sheet.
>
> But maybe reading about the "create" argument on page 13 of this linked
> document will help:
>
> https://cran.r-project.org/web/packages/xlsx/xlsx.pdf
>
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From roy.mendelssohn at noaa.gov  Tue Sep 27 19:51:24 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 27 Sep 2016 10:51:24 -0700
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
Message-ID: <20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>

Look at the package ncdf4.  You can use an OPeNDAP URL in place of the file name to perform subsets.,

-Roy

> On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Hi all,
> 
> I would like to access and subset following OpeNDAP files.
> server:
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> 
> file name: tmax.01.2014040312.daily.grb2
> <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/tmax.01.2014040312.daily.grb2>
> I would like to access and subset the file. Any help will be appreciated.
> 
> with regards
> -Deb
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From NordlDJ at dshs.wa.gov  Tue Sep 27 20:27:29 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 27 Sep 2016 18:27:29 +0000
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <CA+dpOJkmHe-4ZMbiOuG2BaSWLQS-4R_yfKNZvPCNRAOFAcGztQ@mail.gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
	<39a2ee85-addf-17ad-4b13-f3d6120b65fb@gmail.com>
	<CA+dpOJkmHe-4ZMbiOuG2BaSWLQS-4R_yfKNZvPCNRAOFAcGztQ@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766309B9C04@WAXMXOLYMB025.WAX.wa.lcl>

Christofer,

I do not really use the xlsx package, so this may not be the 'best' approach.  And based on your spreadsheet, and the code that you supplied, I am not sure what you really intended.  But here is some sample code that will update cells in your spreadsheet without changing the formatting.

library(xlsx)
Data = data.frame(1:20)
wb <- loadWorkbook("asd.xlsx")   ### Assume I saved asd.xlsx in the working directory
sheet <- getSheets(wb)[['Sheet1']]
cb <- CellBlock(sheet, startRow=5, startColumn=2, noRows=20, noColumns=1, create=FALSE)
CB.setColData(cb, x=Data[,1], colIndex=1)
saveWorkbook(wb, "asd.xlsx")


The code uses the CellBlock() function to define the region you want to write data to (I could have defined the cell block region to contain more rows and columns).  Then the CB.setColData() function writes the data to the column within the defined cell block identified by the the colIndex parameter.  colIndex indexes into the cell block region.  So, even though the we want to write to column 2, since column 2 is the first column in the cell block we need to set colIndex=1.  You need to change the rowOffset value if you don't want to start writing in the first row of the cell block region.   I didn't look around much to see if the addDataFrame() function could be used with a cell block region.

You can play with the various functions and parameters to decide if the xlsx package will meet your needs 


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christofer
> Bogaso
> Sent: Tuesday, September 27, 2016 9:46 AM
> To: Daniel Nordlund
> Cc: r-help
> Subject: Re: [R] Writing data onto xlsx file without cell formatting
> 
> Hi Daniel,
> 
> Am attaching an example xlsx file which I need to modify.
> 
> I have tried with below code :
> 
> library(xlsx)
> Data = data.frame(1:20)
> wb <- loadWorkbook("asd.xlsx")   ### Assume I saved asd.xlsx in the
> working directory
> addDataFrame(Data, sheet = getSheets(wb)[['Sheet1']], startRow=5,
> startColumn=2, row.names=F, col.names=F) saveWorkbook(wb, "asd.xlsx")
> 
> Basically I am trying to modify the 2nd column with the data of 'Data'
> however I do not want to disturb the formatting there in any extend.
> However above code removing the cell color, which I do not want.
> 
> What could be right code for doing so?
> 
> Thanks and regards,
> 
> PS: not very sure if R forum would accept my attachment, if not that file is
> available in https://ufile.io/50944
> 
> On Tue, Sep 27, 2016 at 12:06 PM, Daniel Nordlund <djnordlund at gmail.com>
> wrote:
> > On 9/26/2016 2:56 PM, Christofer Bogaso wrote:
> >>
> >> Hi again,
> >>
> >> I have been following above suggestion to export data from R to xlsx
> >> file using XLconnect. However recently I am facing Java memory
> >> allocation problem with large dataset (looks like a known issue with
> >> this package) and therefore decided to move to using "xlsx" package.
> >>
> >> Now I started facing that same problem of losing my existing
> >> formating when I use xlsx package for data export. Can someone help
> >> me with some pointer on how can I preserve the cell formating after
> >> exporting data.frame to some existing xlsx file using "xlsx" package.
> >>
> >> Thanks for your time.
> >>
> >> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN
> >> <sezenismail at gmail.com>
> >> wrote:
> >>>
> >>> I think, this is what you are looking for:
> >>>
> >>>
> >>> http://stackoverflow.com/questions/11228942/write-from-r-into-
> templa
> >>> te-in-excel-while-preserving-formatting
> >>>
> >>> On 11 Jul 2016, at 03:43, Christofer Bogaso
> >>> <bogaso.christofer at gmail.com>
> >>> wrote:
> >>>
> >>> Hi again,
> >>>
> >>> I am trying to write a data frame to an existing Excel file (xlsx)
> >>> from row 5 and column 6 of the 1st Sheet. I was going through a
> >>> previous instruction which is available here :
> >>>
> >>>
> >>> http://stackoverflow.com/questions/32632137/using-write-xlsx-in-r-ho
> >>> w-to-write-in-a-specific-row-or-column-in-excel-file
> >>>
> >>> However trouble is that it is modifying/removing formatting of all
> >>> the affected cells. I have predefined formatting of those cells
> >>> where data to be pasted, and I dont want to modify or remove that
> formatting.
> >>>
> >>> Any idea if I need to pass some additional argument.
> >>>
> >>> Appreciate your valuable feedback.
> >>>
> >>> Thanks,
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > It would help the list to help you if you gave a reproducible example.
> > In the absence of that, at least show the actual code you are using to
> > write to the Excel (.xlsx) sheet.
> >
> > But maybe reading about the "create" argument on page 13 of this
> > linked document will help:
> >
> > https://cran.r-project.org/web/packages/xlsx/xlsx.pdf
> >
> >
> > Dan
> >
> > --
> > Daniel Nordlund
> > Port Townsend, WA  USA
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pai1981 at gmail.com  Tue Sep 27 21:44:26 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Tue, 27 Sep 2016 13:44:26 -0600
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
Message-ID: <CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>

Hi Roy,
Thanks for your response. I have tried according your suggestion but it
doesn't work.
the OPeNDAP link of the data
http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
forecast_ts_9mon/2014/201404/20140403/2014040312/

datafile:
tmax.01.2014040312.daily.grb2

Thanks
-Deb

On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Look at the package ncdf4.  You can use an OPeNDAP URL in place of the
> file name to perform subsets.,
>
> -Roy
>
> > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > I would like to access and subset following OpeNDAP files.
> > server:
> > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2014/201404/20140403/2014040312/
> >
> > file name: tmax.01.2014040312.daily.grb2
> > <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.
> html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/
> 20140403/2014040312/tmax.01.2014040312.daily.grb2>
> > I would like to access and subset the file. Any help will be appreciated.
> >
> > with regards
> > -Deb
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Tue Sep 27 00:22:01 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Mon, 26 Sep 2016 17:22:01 -0500
Subject: [R] Writing data onto xlsx file without cell formatting
In-Reply-To: <CAAxdm-4yGmjSw7FRo19tWiaYsqm2xRhQK+QuZoFxYZonMpBghw@mail.gmail.com>
References: <CA+dpOJ=r=3J5wAc=RvsNtWTdXA3xRNScXMCjQsRSfGvGtZaOOA@mail.gmail.com>
	<ADBC7880-CB61-446F-BAD1-9A95599C5E6C@gmail.com>
	<CA+dpOJnXAD3JDVN7qMw2eX=7dLV8nsnDzaVccFTtfZS=ZaRaFA@mail.gmail.com>
	<CAAxdm-4yGmjSw7FRo19tWiaYsqm2xRhQK+QuZoFxYZonMpBghw@mail.gmail.com>
Message-ID: <bd896470-8ec9-35cc-7fed-114bd73c291f@effectivedefense.org>

I don't know if "openxlsx" will solve Christofer's problem, but it 
solved a problem I encountered recently reading a large data set:


       read.xls{gdata} read 20734 obs. of 141966 rows and stopped 
without warning.  read.xls{fImport} and read_excel{readxl} both read 
65536 rows.  I couldn't get xls.reader{ProjectTemplate} to work.


       read.xlsx{openxlsx} read the file I wanted to read.


       Spencer Graves


On 9/26/2016 5:09 PM, jim holtman wrote:
> I use the "openxlsx" package to handle spreadsheets.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Mon, Sep 26, 2016 at 5:56 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi again,
>>
>> I have been following above suggestion to export data from R to xlsx
>> file using XLconnect. However recently I am facing Java memory
>> allocation problem with large dataset (looks like a known issue with
>> this package) and therefore decided to move to using "xlsx" package.
>>
>> Now I started facing that same problem of losing my existing formating
>> when I use xlsx package for data export. Can someone help me with some
>> pointer on how can I preserve the cell formating after exporting
>> data.frame to some existing xlsx file using "xlsx" package.
>>
>> Thanks for your time.
>>
>> On Mon, Jul 11, 2016 at 10:43 AM, Ismail SEZEN <sezenismail at gmail.com>
>> wrote:
>>> I think, this is what you are looking for:
>>>
>>> http://stackoverflow.com/questions/11228942/write-from-
>> r-into-template-in-excel-while-preserving-formatting
>>> On 11 Jul 2016, at 03:43, Christofer Bogaso <bogaso.christofer at gmail.com
>>>
>>> wrote:
>>>
>>> Hi again,
>>>
>>> I am trying to write a data frame to an existing Excel file (xlsx)
>>> from row 5 and column 6 of the 1st Sheet. I was going through a
>>> previous instruction which is available here :
>>>
>>> http://stackoverflow.com/questions/32632137/using-
>> write-xlsx-in-r-how-to-write-in-a-specific-row-or-column-in-excel-file
>>> However trouble is that it is modifying/removing formatting of all the
>>> affected cells. I have predefined formatting of those cells where data
>>> to be pasted, and I dont want to modify or remove that formatting.
>>>
>>> Any idea if I need to pass some additional argument.
>>>
>>> Appreciate your valuable feedback.
>>>
>>> Thanks,
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Tue Sep 27 22:47:56 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 27 Sep 2016 13:47:56 -0700
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
	<CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
Message-ID: <68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>

Please post the code of what you tried, as I have no idea otherwise what did or did not work for you.

-Roy

> On Sep 27, 2016, at 12:44 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Hi Roy,
> Thanks for your response. I have tried according your suggestion but it doesn't work.
> the OPeNDAP link of the data
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> 
> datafile: 
> tmax.01.2014040312.daily.grb2
> 
> Thanks 
> -Deb
> 
> On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> Look at the package ncdf4.  You can use an OPeNDAP URL in place of the file name to perform subsets.,
> 
> -Roy
> 
> > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> >
> > Hi all,
> >
> > I would like to access and subset following OpeNDAP files.
> > server:
> > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> >
> > file name: tmax.01.2014040312.daily.grb2
> > <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/tmax.01.2014040312.daily.grb2>
> > I would like to access and subset the file. Any help will be appreciated.
> >
> > with regards
> > -Deb
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jrkrideau at inbox.com  Wed Sep 28 03:23:05 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 27 Sep 2016 17:23:05 -0800
Subject: [R] Fw: R problem
In-Reply-To: <1845795768.5629510.1474992666932@mail.yahoo.com>
References: <1709349656.210948.1474985895925@mail.yahoo.com>
	<1248662213.5486681.1474984582802@mail.yahoo.com>
	<1219385272.5555804.1474985762792@mail.yahoo.com>
	<1248662213.5486681.1474984582802.ref@mail.yahoo.com>
Message-ID: <6FAF13C8287.00000C42jrkrideau@inbox.com>

We have a "Do not help with homework" policy on R-help. We think that a student should speak with his or her instructor or tutor if help is needed.  So you are unlikely to get much help here though it is possible.

For future reference, 1. your script did not arrive. The data did. R-help is very fussy about what files it will accept.

It is better include your code (script) and data in the body of the email.  Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example  or 
http://adv-r.had.co.nz/Reproducibility.html 
for some suggestions on how to ask a question here.

Then send a new email with the code and data included in the body of the email. Someone might help.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Tue, 27 Sep 2016 16:11:06 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Fw: R problem
> 
> 
> 
> 
> HelloI want to calculate sen slope with out using package. I wrote one
> but, ?it is wrong. I attache my data and my script. would you please
> check it.Many thanksSincerely yoursElham
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Share photos & screenshots in seconds...
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if1
Works in all emails, instant messengers, blogs, forums and social networks.


From szhan at uoguelph.ca  Wed Sep 28 05:03:25 2016
From: szhan at uoguelph.ca (Shuhua Zhan)
Date: Wed, 28 Sep 2016 03:03:25 +0000
Subject: [R] How to test a difference in ratios of count data in R
Message-ID: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>

Hello R-experts,
I am interested to determine if the ratio of counts from two groups differ across two distinct treatments. For example, we have three replicates of treatment A, and three replicates of treatment B. For each treatment, we have counts X from one group and counts Y from another group. My understanding is that that GLIMMIX procedure in SAS can calculate whether the ratio of counts in one group (X/X+Y) significantly differs between treatments.

I think this is the way you do it in SAS. The replicate and treatment variables are self-explanatory. The first number (n) refers to the total counts X + Y; the second number (X) refers to the counts X. Is there a way to do this in R? Since we have 20,000 datasets to be tested, it may be easier to retrive the significant test as the given dataset below and its p>F value and mean ratios of treatments in R than SAS.


data test;
input replicate treatment$ n X;
datalines;
1 A 32 4
1 B 33 18
2 A 20 6
2 B 21 18
3 A 7 0
3 B 8 4
;

proc glimmix data=test;
class replicate treatment;
model X/n = treatment / solution;
random intercept / subject=replicate;
run;

ods select lsmeans;
proc glimmix data=test;
class replicate treatment;
model X/n = treatment / solution;
random intercept / subject=replicate;
lsmeans treatment / cl ilink;
run;

I appreciate your help in advance!
Joshua


	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Sep 28 05:30:20 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 28 Sep 2016 03:30:20 +0000
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
	<CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
	<68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>
Message-ID: <CAAcGz98bDa8njpY=Cio5ATpdgq2bpyR47QtT4Nh01+iWA-v=KQ@mail.gmail.com>

Opendap won't work on Windows CRAN build of ncdf4, though the rgdal build
does work directly on grib.

Summary: download the files wholus for use on Windows, or set your own
system on Linux.

Building ncdf4 on Windows is not too hard if you know about doing that.

Cheers, Mike

On Wed, 28 Sep 2016, 06:49 Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Please post the code of what you tried, as I have no idea otherwise what
> did or did not work for you.
>
> -Roy
>
> > On Sep 27, 2016, at 12:44 PM, Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
> >
> > Hi Roy,
> > Thanks for your response. I have tried according your suggestion but it
> doesn't work.
> > the OPeNDAP link of the data
> >
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> >
> > datafile:
> > tmax.01.2014040312.daily.grb2
> >
> > Thanks
> > -Deb
> >
> > On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <
> roy.mendelssohn at noaa.gov> wrote:
> > Look at the package ncdf4.  You can use an OPeNDAP URL in place of the
> file name to perform subsets.,
> >
> > -Roy
> >
> > > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
> > >
> > > Hi all,
> > >
> > > I would like to access and subset following OpeNDAP files.
> > > server:
> > >
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> > >
> > > file name: tmax.01.2014040312.daily.grb2
> > > <
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/tmax.01.2014040312.daily.grb2
> >
> > > I would like to access and subset the file. Any help will be
> appreciated.
> > >
> > > with regards
> > > -Deb
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > **********************
> > "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> > **********************
> > Roy Mendelssohn
> > Supervisory Operations Research Analyst
> > NOAA/NMFS
> > Environmental Research Division
> > Southwest Fisheries Science Center
> > ***Note new address and phone***
> > 110 Shaffer Road
> > Santa Cruz, CA 95060
> > Phone: (831)-420-3666
> > Fax: (831) 420-3980
> > e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> >
> > "Old age and treachery will overcome youth and skill."
> > "From those who have been given much, much will be expected"
> > "the arc of the moral universe is long, but it bends toward justice"
> -MLK Jr.
> >
> >
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From karlneergaard at gmail.com  Wed Sep 28 05:11:46 2016
From: karlneergaard at gmail.com (Karl Neergaard)
Date: Wed, 28 Sep 2016 11:11:46 +0800
Subject: [R] Error in gam() object 'scat' no found
Message-ID: <CAMKhwd_ugNVUcy2_0uijJi6sHv0nGHkWZXa-TM7NbTm4P3QHEQ@mail.gmail.com>

Thank you David for taking time to answer my not so helpful question.


On Tue, Sep 27, 2016 at 11:15 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 26, 2016, at 9:50 PM, Karl Neergaard <karlneergaard at gmail.com>
> wrote:
> >
> > I received an error message while trying to use family=scat in the GAM
> > package. The models were working fine yesterday.
> > The problem is not with my data seeing as the gaussian distribution is
> > working fine.
> >
> > mod=gam(RT~s(a) + s(b), data=dat, family=gaussian)
> > mod=gam(RT~s(a) + s(b), data=dat, family=scat)
> >
> > Might this problem be unrelated to GAM specifically, and to my R
> > configuration?
> > I have removed the gam package and re-installed it several times to no
> > avail.
>
> The scat function is in package mgcv. It also has a `gam` function and is
> generally thought of as the "standard" approach for estimating generalized
> additive models.
>
>
> >
> > Thank you for any assistance,
> > Karl
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From albin.blaschka at standortsanalyse.net  Wed Sep 28 15:51:55 2016
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Wed, 28 Sep 2016 15:51:55 +0200
Subject: [R] Help with PCA data file prep and R code
In-Reply-To: <f5c0b6ece41d4422b21d95252681aa3b@exch-2p-mbx-w2.ads.tamu.edu>
References: <CABYg=7YYXahWAG=jCTGK4CmjO-7at6PEfj9-LOTzuVNcK8vT4Q@mail.gmail.com>
	<CABYg=7aPXTJnC1pGCmVdWmVT-ZKvjnaCNy0AzHmpNHg-RE9ZxQ@mail.gmail.com>
	<f5c0b6ece41d4422b21d95252681aa3b@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <ed7d3fbe6f72bc97f81336743f77ad6d@standortsanalyse.net>


Hi,

maybe the package vegan with its tutorials is a good starting point, 
too...

http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf

http://cc.oulu.fi/~jarioksa/opetus/metodi/sessio2.pdf

all the best,
Albin

Am 22.09.2016 10:23 PM, schrieb David L Carlson:
> Looking at your data there are several issues.
> 
> 1. Tank is an integer, but it sounds like you intend to use it as a
> categorical measure. If so that it should be a factor, but factors
> cannot be used in pca. Is Tank 10 10 times more of something than Tank
> 1?
> 
> 2. Date is a factor. That means you are not measuring time, just the
> fact that 2 rows are the same time or different time. Factors cannot
> be used in pca.
> 
> 3. Treatment is a factor, but factors cannot be used in pca.
> 
> 4. Your log transformed data has many 0's and no negative values. Did
> you add 1 to each value before taking logarithms?
> 
> First line of your code after reading the data:
> 
>> meso.pca <- prcomp(mesocleaned, center=TRUE, scale.=TRUE)
> Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
>>                    scale. = TRUE)
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah 
> Stinson
> Sent: Wednesday, September 21, 2016 10:25 AM
> To: r-help at r-project.org
> Subject: Re: [R] Help with PCA data file prep and R code
> 
> Hello DRUGs,
> I'm new to R and would appreciate some expert advice on prepping files 
> for,
> and running, PCA...
> 
> My data set consists of aquatic invertebrate and zooplankton count data 
> and
> physicochemical measurements from an ecotoxicology study. Four chemical
> treatments were applied to mesocosm tanks, 4 replicates per treatment 
> (16
> tanks total), then data were collected weekly over a 3 month period.
> 
> I cleaned the data in excel by removing columns with all zero values, 
> and
> all rows with NA values.
> All zooplankton values were volume normalized, then log normalized. All
> other data was log normalized in excel prior to analysis in R. All 
> vectorss
> are numeric. I've attached the .txt file to this email rather that 
> using
> dput(dataframe).
> 
> My questions are:
> 
> 1. Did I do the cleaning step appropriately? I know that there are ways 
> to
> run PCA's using data that contain NA values (pcaMethods), but wasn't 
> able
> to get the code to work...
> (I understand that this isn't strictly an R question, but any help 
> would be
> appreciated.)
> 2. Does my code look correct for the PCA and visualization (see below)?
> 
> Thanks in advance,
> Sarah
> 
> #read data
> mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")
> 
> #run PCA
> meso.pca <- prcomp(mesocleaned,
>                    center = TRUE,
>                    scale. = TRUE)
> 
> # print method
> print(meso.pca)
> 
> #compute standard deviation of each principal component
> std_dev <- meso.pca$sdev
> 
> #compute variance
> pr_var <- std_dev^2
> 
> #check variance of first 10 components
> pr_var[1:10]
> 
> #proportion of variance explained
> prop_varex <- pr_var/sum(pr_var)
> prop_varex[1:20]
> 
> #The first principal component explains 12.7% of the variance
> #The second explains 8.1%
> 
> #visualize
> biplot(meso.pca)
> 
> #for visualization, make Treatment vector a factor instead of numeric
> meso.treatment <- as.factor(mesocleaned[, 3])
> 
> #ggbiplot to visualize by Treatment group
> #reference: 
> https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
> 
> library(devtools)
> install_github("ggbiplot", "vqv")
> library(ggbiplot)
> 
> print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
> meso.treatment, ellipse = TRUE, circle = TRUE))
> g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
>               groups = meso.treatment, ellipse = TRUE,
>               circle = TRUE)
> g <- g + scale_color_brewer(name = deparse(substitute(Treatments)), 
> palette
> = 'Dark2') #must change meso.treatment to a factor for this to work
> g <- g + theme(legend.direction = 'horizontal',
>                legend.position = 'top')
> print(g)
> 
> #Circle plot
> #plot each variables coefficients inside a unit circle to get insight 
> on a
> possible interpretation for PCs.
> #reference: 
> https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
> 
> theta <- seq(0,2*pi,length.out = 100)
> circle <- data.frame(x = cos(theta), y = sin(theta))
> p <- ggplot(circle,aes(x,y)) + geom_path()
> 
> loadings <- data.frame(meso.pca$rotation,
>                        .names = row.names(meso.pca$rotation))
> p + geom_text(data=loadings,
>               mapping=aes(x = PC1, y = PC2, label = .names, colour =
> .names)) +
>   coord_fixed(ratio=1) +
>   labs(x = "PC1", y = "PC2")
> 
> On Tue, Sep 20, 2016 at 10:28 PM, Sarah Stinson <sastinson at ucdavis.edu>
> wrote:
> 
>> Hello DRUGs,
>> I'm new to R and would appreciate some expert advice on prepping files
>> for, and running, PCA...
>> 
>> My data set consists of aquatic invertebrate and zooplankton count 
>> data
>> and physicochemical measurements from an ecotoxicology study. Four 
>> chemical
>> treatments were applied to mesocosm tanks, 4 replicates per treatment 
>> (16
>> tanks total), then data were collected weekly over a 3 month period.
>> 
>> I cleaned the data in excel by removing columns with all zero values, 
>> and
>> all rows with NA values.
>> All zooplankton values were volume normalized, then log normalized. 
>> All
>> other data was log normalized in excel prior to analysis in R. All 
>> vectorss
>> are numeric. I've attached the .csv file to this email rather that 
>> using
>> dput(dataframe). I hope that's acceptable.
>> 
>> My questions are:
>> 
>> 1. Did I do the cleaning step appropriately? I know that there are 
>> ways to
>> run PCA's using data that contain NA values (pcaMethods), but wasn't 
>> able
>> to get the code to work...
>> (I understand that this isn't strictly an R question, but any help 
>> would
>> be appreciated.)
>> 2. Does my code look correct for the PCA and visualization (see 
>> below)?
>> 
>> Thanks in advance,
>> Sarah
>> 
>> #read data
>> mesocleaned <- read.csv("MesoCleanedforPCA.9.16.16.csv")
>> 
>> #run PCA
>> meso.pca <- prcomp(mesocleaned,
>>                    center = TRUE,
>>                    scale. = TRUE)
>> 
>> # print method
>> print(meso.pca)
>> 
>> #compute standard deviation of each principal component
>> std_dev <- meso.pca$sdev
>> 
>> #compute variance
>> pr_var <- std_dev^2
>> 
>> #check variance of first 10 components
>> pr_var[1:10]
>> 
>> #proportion of variance explained
>> prop_varex <- pr_var/sum(pr_var)
>> prop_varex[1:20]
>> 
>> #The first principal component explains 12.7% of the variance
>> #The second explains 8.1%
>> 
>> #visualize
>> biplot(meso.pca)
>> 
>> #for visualization, make Treatment vector a factor instead of numeric
>> meso.treatment <- as.factor(mesocleaned[, 3])
>> 
>> #ggbiplot to visualize by Treatment group
>> #reference: 
>> https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>> 
>> library(devtools)
>> install_github("ggbiplot", "vqv")
>> library(ggbiplot)
>> 
>> print(ggbiplot(meso.pca, obs.scale = 1, var.scale = 1, groups =
>> meso.treatment, ellipse = TRUE, circle = TRUE))
>> g <- ggbiplot(meso.pca, obs.scale = 1, var.scale = 1,
>>               groups = meso.treatment, ellipse = TRUE,
>>               circle = TRUE)
>> g <- g + scale_color_brewer(name = deparse(substitute(Treatments)),
>> palette = 'Dark2') #must change meso.treatment to a factor for this to 
>> work
>> g <- g + theme(legend.direction = 'horizontal',
>>                legend.position = 'top')
>> print(g)
>> 
>> #Circle plot
>> #plot each variables coefficients inside a unit circle to get insight 
>> on a
>> possible interpretation for PCs.
>> #reference: 
>> https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
>> 
>> theta <- seq(0,2*pi,length.out = 100)
>> circle <- data.frame(x = cos(theta), y = sin(theta))
>> p <- ggplot(circle,aes(x,y)) + geom_path()
>> 
>> loadings <- data.frame(meso.pca$rotation,
>>                        .names = row.names(meso.pca$rotation))
>> p + geom_text(data=loadings,
>>               mapping=aes(x = PC1, y = PC2, label = .names, colour =
>> .names)) +
>>   coord_fixed(ratio=1) +
>>   labs(x = "PC1", y = "PC2")
>> 
>> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
| Dr.rer.nat. Albin Blaschka
| Etrichstrasse 26, A-5020 Salzburg
| * www.standortsanalyse.net *
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From G.Maubach at weinwolf.de  Wed Sep 28 17:02:17 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 28 Sep 2016 17:02:17 +0200
Subject: [R] Putting a bunch of Excel files as data.frames into a list fails
Message-ID: <OF8DFA2136.B13E4F7A-ONC125803C.0051CBEA-C125803C.00529C2E@lotus.hawesko.de>

Hi All,

I need to read a bunch of Excel files and store them in R.

I decided to store the different Excel files in data.frames in a named 
list where the names are the file names of each file (and that is 
different from the sources as far as I can see):

-- cut --
# Sources:
# - 
http://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r
# - 
http://stackoverflow.com/questions/9564489/opening-all-files-in-a-folder-and-applying-a-function
# - 
http://stackoverflow.com/questions/12945687/how-to-read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frame-e

v_file_path <- "H:/2016/Analysen/Neukunden/Input"
v_file_pattern <- "*.xlsx"

v_files <- list.files(path = v_file_path,
                      pattern = v_file_pattern,
                      ignore.case = TRUE)
print(v_files)

v_list_of_files <- list()

for (v_file in v_files) {
  v_list_of_files[v_file] <- openxlsx::read.xlsx(
    file.path(v_file_path,
              v_file))
}

This code does not work cause it stores only the first variable of each 
Excel file in a named list.

What do I need to change to get it running?

Kind regards

Georg


From HDoran at air.org  Wed Sep 28 18:09:21 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 28 Sep 2016 16:09:21 +0000
Subject: [R] Faster Subsetting
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>

I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.

I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.

Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?

Thank you
Harold


tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))

idList <- unique(tmp$id)

### Fast, but not fast enough
system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))

### Not fast at all, a big bottleneck
system.time(replicate(500, subset(tmp, id == idList[1])))


From HDoran at air.org  Wed Sep 28 18:28:56 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 28 Sep 2016 16:28:56 +0000
Subject: [R] Faster Subsetting
In-Reply-To: <CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>

Thank you very much. I don?t know tidyverse, I?ll look at that now. I did some tests with data.table package, but it was much slower on my machine, see examples below

tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))

idList <- unique(tmp$id)

system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))

system.time(replicate(500, subset(tmp, id == idList[1])))


library(data.table)

tmp2 <- as.data.table(tmp)     # data.table

system.time(replicate(500, tmp2[which(tmp$id == idList[1]),]))

system.time(replicate(500, subset(tmp2, id == idList[1])))

From: Dominik Schneider [mailto:dosc3612 at colorado.edu]
Sent: Wednesday, September 28, 2016 12:27 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] Faster Subsetting

I regularly crunch through this amount of data with tidyverse. You can also try the data.table package. They are optimized for speed, as long as you have the memory.
Dominik

On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.

I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.

Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?

Thank you
Harold


tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))

idList <- unique(tmp$id)

### Fast, but not fast enough
system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))

### Not fast at all, a big bottleneck
system.time(replicate(500, subset(tmp, id == idList[1])))

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From 538280 at gmail.com  Wed Sep 28 18:49:49 2016
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 28 Sep 2016 10:49:49 -0600
Subject: [R] How to test a difference in ratios of count data in R
In-Reply-To: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
References: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>

There are multiple ways of doing this, but here are a couple.

To just test the fixed effect of treatment you can use the glm function:

test <- read.table(text="
replicate treatment n X
1 A 32 4
1 B 33 18
2 A 20 6
2 B 21 18
3 A 7 0
3 B 8 4
", header=TRUE)

fit1 <- glm( cbind(X,n-X) ~ treatment, data=test, family=binomial)
summary(fit1)

Note that the default baseline value may differ between R and SAS,
which would result in a reversed sign on the slope coefficient (and
different intercept).

To include replicate as a random effect you need an additional
package, here I use lme4 and the glmer function:

library(lme4)
fit2 <- glmer( cbind(X, n-X) ~ treatment + (1|replicate), data=test,
family=binomial)
summary(fit2)



On Tue, Sep 27, 2016 at 9:03 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
> Hello R-experts,
> I am interested to determine if the ratio of counts from two groups differ across two distinct treatments. For example, we have three replicates of treatment A, and three replicates of treatment B. For each treatment, we have counts X from one group and counts Y from another group. My understanding is that that GLIMMIX procedure in SAS can calculate whether the ratio of counts in one group (X/X+Y) significantly differs between treatments.
>
> I think this is the way you do it in SAS. The replicate and treatment variables are self-explanatory. The first number (n) refers to the total counts X + Y; the second number (X) refers to the counts X. Is there a way to do this in R? Since we have 20,000 datasets to be tested, it may be easier to retrive the significant test as the given dataset below and its p>F value and mean ratios of treatments in R than SAS.
>
>
> data test;
> input replicate treatment$ n X;
> datalines;
> 1 A 32 4
> 1 B 33 18
> 2 A 20 6
> 2 B 21 18
> 3 A 7 0
> 3 B 8 4
> ;
>
> proc glimmix data=test;
> class replicate treatment;
> model X/n = treatment / solution;
> random intercept / subject=replicate;
> run;
>
> ods select lsmeans;
> proc glimmix data=test;
> class replicate treatment;
> model X/n = treatment / solution;
> random intercept / subject=replicate;
> lsmeans treatment / cl ilink;
> run;
>
> I appreciate your help in advance!
> Joshua
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ruipbarradas at sapo.pt  Wed Sep 28 18:57:15 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 28 Sep 2016 17:57:15 +0100
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
Message-ID: <20160928175715.Horde.gZpIeN2ZzF9WG5VlpDbh7CO@mail.sapo.pt>

Hello,

If you work with a matrix instead of a data.frame, it usually runs  
faster, but your column vectors must all be numeric.

> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
    user  system elapsed
    0.05    0.00    0.04
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
    user  system elapsed
    0.07    0.00    0.08
>

# Make it a matrix and use the matrix
> mattmp <- as.matrix(tmp)
> system.time(replicate(500, mattmp[which(mattmp[,"id"] == idList[1]),]))
    user  system elapsed
    0.01    0.00    0.01


Hope this helps,

Rui Barradas




Citando Doran, Harold <HDoran at air.org>:

> I have an extremely large data frame (~13 million rows) that  
> resembles the structure of the object tmp below in the reproducible  
> code. In my real data, the variable, 'id' may or may not be ordered,  
> but I think that is irrelevant.
>
> I have a process that requires subsetting the data by id and then  
> running each smaller data frame through a set of functions. One  
> example below uses indexing and the other uses an explicit call to  
> subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of  
> rows to evaluate the condition and this is expensive and a  
> bottleneck in my code.  I'm curious if anyone can recommend an  
> improvement that would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Sep 28 19:00:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Sep 2016 10:00:54 -0700
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>
Message-ID: <CAGxFJbQGC9osHOaU19j_GZ5vcww6mM5UhoMc+TsBc4BQd=O8ZA@mail.gmail.com>

Don't do it this way. You are reinventing wheels.

1. Look at package dplyr, which has optimized functions to do exactly
this (break into subframes, calculate on subframes, reassemble).  Note
also that dplyr is part of tidyverse. I use base R functionality for
this because I know it and it does what I need, but dplyr may be
better for your needs.

2. In base R, this would be done by by(): so for your example,

by(tmp, tmp$id, FUN,... )

where FUN is a function that does whatever you want on each sub-data
frame. e.g. if you wanted to just take the mean of foo for each
subframe:

by(tmp, tmp$id, function(x)mean(x$foo))

## (but there are better ways of doing such a simple function in base
R or dplyr)


Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 28, 2016 at 9:28 AM, Doran, Harold <HDoran at air.org> wrote:
> Thank you very much. I don?t know tidyverse, I?ll look at that now. I did some tests with data.table package, but it was much slower on my machine, see examples below
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
>
> library(data.table)
>
> tmp2 <- as.data.table(tmp)     # data.table
>
> system.time(replicate(500, tmp2[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp2, id == idList[1])))
>
> From: Dominik Schneider [mailto:dosc3612 at colorado.edu]
> Sent: Wednesday, September 28, 2016 12:27 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] Faster Subsetting
>
> I regularly crunch through this amount of data with tidyverse. You can also try the data.table package. They are optimized for speed, as long as you have the memory.
> Dominik
>
> On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.
>
> I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Wed Sep 28 19:07:36 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 28 Sep 2016 17:07:36 +0000
Subject: [R] Faster Subsetting
In-Reply-To: <97dd0b88-eb7f-c721-4f86-5595cb650797@hhu.de>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>
	<97dd0b88-eb7f-c721-4f86-5595cb650797@hhu.de>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686013584AA72@DC1VEX10MB01.air.org>

Many thanks. I did also try the filter function in dplyr and was also much slower than simply indexing in the original way the code had.

system.time(replicate(500, filter(tmp, id == idList[1])))

I did this on the toy example as well as the real data, finding the same (slower) result each time compared to the indexing method.

Perhaps I'm using it incorrectly?



-----Original Message-----
From: Constantin Weiser [mailto:constantin.weiser at hhu.de] 
Sent: Wednesday, September 28, 2016 12:55 PM
To: r-help at r-project.org
Cc: Doran, Harold <HDoran at air.org>
Subject: Re: [R] Faster Subsetting

I just modified the reproducible example a bit, so it's a bit more realistic. The function "mean" could be "easily" replaced by your analysis.

And here are some possible solutions:

tmp <- data.frame(id = rep(1:2000, each = 100), foo = rnorm(200000)) tmp <- tmp[sample(dim(tmp)[1]),] # re-sampling the dataset

## with specialized packages
require(plyr)
system.time({
   res1 <- ddply(tmp, .(id), summarize, mean=mean(foo))
})

require(dplyr)
system.time({
   res2 <- tmp %>%
     group_by(id) %>%
     summarise(mean = mean(foo))
})

library(data.table)
system.time({
   res3 <- data.table(tmp)[, list(mean=mean(foo)), by=id]
})


## build-in R-methods
system.time({
   res4 <- aggregate(tmp$foo, by = list(id=tmp$id), FUN = mean)
})

system.time({
   res5 <- sapply(unique(tmp$id), simplify = TRUE,
                  FUN = function(x){
                    c(id=x, mean=mean(tmp[which(tmp$id == x), "foo"]))
                  })
})
res5 <- t(res5)

system.time({
   res5 <- sapply(unique(tmp$id), simplify = TRUE,
                  FUN = function(x){
                    sub.tmp <- subset(tmp, tmp$id == x)
                    c(x,mean=mean(sub.tmp[, "foo"]))
                  })
})
res5 <- t(res5)


Yours
Constantin


--
^
|                X
|               /eiser, Dr. Constantin (weiserc at hhu.de)
|              /Chair of Statistics and Econometrics
|             / Heinrich Heine-University of D?sseldorf
| *    /\    /  Universit?tsstra?e 1, 40225 D?sseldorf, Germany
|  \  /  \  /   Oeconomicum (Building 24.31), Room 01.22
|   \/    \/    Tel: 0049 211 81-15307
+----------------------------------------------------------->

Am 28.09.2016 um 18:28 schrieb Doran, Harold:
> Thank you very much. I don?t know tidyverse, I?ll look at that now. I 
> did some tests with data.table package, but it was much slower on my 
> machine, see examples below
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
>
> library(data.table)
>
> tmp2 <- as.data.table(tmp)     # data.table
>
> system.time(replicate(500, tmp2[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp2, id == idList[1])))
>
> From: Dominik Schneider [mailto:dosc3612 at colorado.edu]
> Sent: Wednesday, September 28, 2016 12:27 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] Faster Subsetting
>
> I regularly crunch through this amount of data with tidyverse. You can also try the data.table package. They are optimized for speed, as long as you have the memory.
> Dominik
>
> On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.
>
> I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From bgunter.4567 at gmail.com  Wed Sep 28 19:21:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Sep 2016 10:21:31 -0700
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584AA72@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>
	<97dd0b88-eb7f-c721-4f86-5595cb650797@hhu.de>
	<B08B6AF0CF8CA44F81B9983EEBDCD686013584AA72@DC1VEX10MB01.air.org>
Message-ID: <CAGxFJbSTptYetVis8n6q_6jqcjZ5jBZha_4t0wG_qYPj6zoWBQ@mail.gmail.com>

Note that for base R, by() is considerably faster than aggregate()
(both of which are *must* faster than the sapply() stuff; tapply() is
what is more appropriate here).

(for Constantin's example):

> system.time({
+   res4 <- aggregate(tmp$foo, by = list(id=tmp$id), FUN = mean)
+ })
   user  system elapsed
  0.289   0.006   0.295

> system.time(res6 <-by(tmp,tmp$id,function(x)mean(x$foo)))
   user  system elapsed
  0.124   0.005   0.130


Note, however, that the by() result may need to be manipulated to get
it into the format you want, and so additional time.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 28, 2016 at 10:07 AM, Doran, Harold <HDoran at air.org> wrote:
> Many thanks. I did also try the filter function in dplyr and was also much slower than simply indexing in the original way the code had.
>
> system.time(replicate(500, filter(tmp, id == idList[1])))
>
> I did this on the toy example as well as the real data, finding the same (slower) result each time compared to the indexing method.
>
> Perhaps I'm using it incorrectly?
>
>
>
> -----Original Message-----
> From: Constantin Weiser [mailto:constantin.weiser at hhu.de]
> Sent: Wednesday, September 28, 2016 12:55 PM
> To: r-help at r-project.org
> Cc: Doran, Harold <HDoran at air.org>
> Subject: Re: [R] Faster Subsetting
>
> I just modified the reproducible example a bit, so it's a bit more realistic. The function "mean" could be "easily" replaced by your analysis.
>
> And here are some possible solutions:
>
> tmp <- data.frame(id = rep(1:2000, each = 100), foo = rnorm(200000)) tmp <- tmp[sample(dim(tmp)[1]),] # re-sampling the dataset
>
> ## with specialized packages
> require(plyr)
> system.time({
>    res1 <- ddply(tmp, .(id), summarize, mean=mean(foo))
> })
>
> require(dplyr)
> system.time({
>    res2 <- tmp %>%
>      group_by(id) %>%
>      summarise(mean = mean(foo))
> })
>
> library(data.table)
> system.time({
>    res3 <- data.table(tmp)[, list(mean=mean(foo)), by=id]
> })
>
>
> ## build-in R-methods
> system.time({
>    res4 <- aggregate(tmp$foo, by = list(id=tmp$id), FUN = mean)
> })
>
> system.time({
>    res5 <- sapply(unique(tmp$id), simplify = TRUE,
>                   FUN = function(x){
>                     c(id=x, mean=mean(tmp[which(tmp$id == x), "foo"]))
>                   })
> })
> res5 <- t(res5)
>
> system.time({
>    res5 <- sapply(unique(tmp$id), simplify = TRUE,
>                   FUN = function(x){
>                     sub.tmp <- subset(tmp, tmp$id == x)
>                     c(x,mean=mean(sub.tmp[, "foo"]))
>                   })
> })
> res5 <- t(res5)
>
>
> Yours
> Constantin
>
>
> --
> ^
> |                X
> |               /eiser, Dr. Constantin (weiserc at hhu.de)
> |              /Chair of Statistics and Econometrics
> |             / Heinrich Heine-University of D?sseldorf
> | *    /\    /  Universit?tsstra?e 1, 40225 D?sseldorf, Germany
> |  \  /  \  /   Oeconomicum (Building 24.31), Room 01.22
> |   \/    \/    Tel: 0049 211 81-15307
> +----------------------------------------------------------->
>
> Am 28.09.2016 um 18:28 schrieb Doran, Harold:
>> Thank you very much. I don?t know tidyverse, I?ll look at that now. I
>> did some tests with data.table package, but it was much slower on my
>> machine, see examples below
>>
>> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>>
>> idList <- unique(tmp$id)
>>
>> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>>
>> system.time(replicate(500, subset(tmp, id == idList[1])))
>>
>>
>> library(data.table)
>>
>> tmp2 <- as.data.table(tmp)     # data.table
>>
>> system.time(replicate(500, tmp2[which(tmp$id == idList[1]),]))
>>
>> system.time(replicate(500, subset(tmp2, id == idList[1])))
>>
>> From: Dominik Schneider [mailto:dosc3612 at colorado.edu]
>> Sent: Wednesday, September 28, 2016 12:27 PM
>> To: Doran, Harold <HDoran at air.org>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Faster Subsetting
>>
>> I regularly crunch through this amount of data with tidyverse. You can also try the data.table package. They are optimized for speed, as long as you have the memory.
>> Dominik
>>
>> On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>> I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.
>>
>> I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.
>>
>> Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?
>>
>> Thank you
>> Harold
>>
>>
>> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>>
>> idList <- unique(tmp$id)
>>
>> ### Fast, but not fast enough
>> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>>
>> ### Not fast at all, a big bottleneck
>> system.time(replicate(500, subset(tmp, id == idList[1])))
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roundsjeremiah at gmail.com  Wed Sep 28 20:21:31 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Wed, 28 Sep 2016 11:21:31 -0700
Subject: [R] Putting a bunch of Excel files as data.frames into a list
	fails
In-Reply-To: <OF8DFA2136.B13E4F7A-ONC125803C.0051CBEA-C125803C.00529C2E@lotus.hawesko.de>
References: <OF8DFA2136.B13E4F7A-ONC125803C.0051CBEA-C125803C.00529C2E@lotus.hawesko.de>
Message-ID: <CAOjnRsbc3k8qO921muuK04c092ipjL4tHJUxptGW3EumL5ZzRQ@mail.gmail.com>

Try changing:
v_list_of_files[v_file]
to:
v_list_of_files[[v_file]]

Also are you sure you are not generating warnings? For example,
 l = list()
l["iris"] = iris;

Also, you can change it to lapply(v_files, function(v_file){...})


Have a good one,
Jeremiah

On Wed, Sep 28, 2016 at 8:02 AM, <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> I need to read a bunch of Excel files and store them in R.
>
> I decided to store the different Excel files in data.frames in a named
> list where the names are the file names of each file (and that is
> different from the sources as far as I can see):
>
> -- cut --
> # Sources:
> # -
> http://stackoverflow.com/questions/11433432/importing-
> multiple-csv-files-into-r
> # -
> http://stackoverflow.com/questions/9564489/opening-all-
> files-in-a-folder-and-applying-a-function
> # -
> http://stackoverflow.com/questions/12945687/how-to-
> read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frame-e
>
> v_file_path <- "H:/2016/Analysen/Neukunden/Input"
> v_file_pattern <- "*.xlsx"
>
> v_files <- list.files(path = v_file_path,
>                       pattern = v_file_pattern,
>                       ignore.case = TRUE)
> print(v_files)
>
> v_list_of_files <- list()
>
> for (v_file in v_files) {
>   v_list_of_files[v_file] <- openxlsx::read.xlsx(
>     file.path(v_file_path,
>               v_file))
> }
>
> This code does not work cause it stores only the first variable of each
> Excel file in a named list.
>
> What do I need to change to get it running?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Wed Sep 28 20:30:14 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Wed, 28 Sep 2016 20:30:14 +0200
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	(Harold Doran's message of "Wed, 28 Sep 2016 16:09:21 +0000")
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
Message-ID: <8760pflvwp.fsf@enricoschumann.net>

On Wed, 28 Sep 2016, "Doran, Harold" <HDoran at air.org> writes:

> I have an extremely large data frame (~13 million rows) that resembles
> the structure of the object tmp below in the reproducible code. In my
> real data, the variable, 'id' may or may not be ordered, but I think
> that is irrelevant.
>
> I have a process that requires subsetting the data by id and then
> running each smaller data frame through a set of functions. One
> example below uses indexing and the other uses an explicit call to
> subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of
> rows to evaluate the condition and this is expensive and a bottleneck
> in my code.  I'm curious if anyone can recommend an improvement that
> would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>

If you really need only one column, it will be faster
to extract that column and then to take a subset of it:

  system.time(replicate(500, tmp[[2L]][tmp$id == idList[1L]]))

(A data.frame is a list of atomic vectors, and it is
 typically faster to first extract the component of
 interest, i.e. the specific column, and then to subset
 this vector. The result will, of course, be a vector,
 not a data.frame.)


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From dosc3612 at colorado.edu  Wed Sep 28 18:26:45 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Wed, 28 Sep 2016 10:26:45 -0600
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
Message-ID: <CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>

I regularly crunch through this amount of data with tidyverse. You can also
try the data.table package. They are optimized for speed, as long as you
have the memory.
Dominik

On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org> wrote:

> I have an extremely large data frame (~13 million rows) that resembles the
> structure of the object tmp below in the reproducible code. In my real
> data, the variable, 'id' may or may not be ordered, but I think that is
> irrelevant.
>
> I have a process that requires subsetting the data by id and then running
> each smaller data frame through a set of functions. One example below uses
> indexing and the other uses an explicit call to subset(), both return the
> same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows
> to evaluate the condition and this is expensive and a bottleneck in my
> code.  I'm curious if anyone can recommend an improvement that would
> somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dominik.schneider at colorado.edu  Wed Sep 28 18:29:07 2016
From: dominik.schneider at colorado.edu (Dominik Schneider)
Date: Wed, 28 Sep 2016 10:29:07 -0600
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
Message-ID: <CAF1jk_=iZ_e9Hcg0JMqSQ07jAY44YdnHvO7VsOouin-PAkfCBQ@mail.gmail.com>

I regularly crunch through this amount of data with tidyverse. You can also
try the data.table package. They are optimized for speed, as long as you
have the memory.
Dominik

On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org> wrote:

> I have an extremely large data frame (~13 million rows) that resembles the
> structure of the object tmp below in the reproducible code. In my real
> data, the variable, 'id' may or may not be ordered, but I think that is
> irrelevant.
>
> I have a process that requires subsetting the data by id and then running
> each smaller data frame through a set of functions. One example below uses
> indexing and the other uses an explicit call to subset(), both return the
> same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows
> to evaluate the condition and this is expensive and a bottleneck in my
> code.  I'm curious if anyone can recommend an improvement that would
> somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From constantin.weiser at uni-mainz.de  Wed Sep 28 19:00:57 2016
From: constantin.weiser at uni-mainz.de (Weiser, Dr. Constantin)
Date: Wed, 28 Sep 2016 17:00:57 +0000
Subject: [R] Faster Subsetting
In-Reply-To: <97dd0b88-eb7f-c721-4f86-5595cb650797@hhu.de>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<CAF1jk_naGvx0Xh7s6ySKqtfXFRSss6XrBxKz7=_5Q_91obRYPQ@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686013584A76B@DC1VEX10MB01.air.org>,
	<97dd0b88-eb7f-c721-4f86-5595cb650797@hhu.de>
Message-ID: <8ff93d4539ae447c8c3985efde7d0cc3@uni-mainz.de>

I just modified the reproducible example a bit, so it's a bit more
realistic. The function "mean" could be "easily" replaced by your analysis.

And here are some possible solutions:

tmp <- data.frame(id = rep(1:2000, each = 100), foo = rnorm(200000))
tmp <- tmp[sample(dim(tmp)[1]),] # re-sampling the dataset

## with specialized packages
require(plyr)
system.time({
?? res1 <- ddply(tmp, .(id), summarize, mean=mean(foo))
})

require(dplyr)
system.time({
?? res2 <- tmp %>%
???? group_by(id) %>%
???? summarise(mean = mean(foo))
})

library(data.table)
system.time({
?? res3 <- data.table(tmp)[, list(mean=mean(foo)), by=id]
})


## build-in R-methods
system.time({
?? res4 <- aggregate(tmp$foo, by = list(id=tmp$id), FUN = mean)
})

system.time({
?? res5 <- sapply(unique(tmp$id), simplify = TRUE,
????????????????? FUN = function(x){
??????????????????? c(id=x, mean=mean(tmp[which(tmp$id == x), "foo"]))
????????????????? })
})
res5 <- t(res5)

system.time({
?? res5 <- sapply(unique(tmp$id), simplify = TRUE,
????????????????? FUN = function(x){
??????????????????? sub.tmp <- subset(tmp, tmp$id == x)
??????????????????? c(x,mean=mean(sub.tmp[, "foo"]))
????????????????? })
})
res5 <- t(res5)


Yours
Constantin


--
^
|??????????????? X
|?????????????? /eiser, Dr. Constantin (weiserc at hhu.de)
|????????????? /Chair of Statistics and Econometrics
|???????????? / Heinrich Heine-University of D?sseldorf
| *??? /\??? /? Universit?tsstra?e 1, 40225 D?sseldorf, Germany
|? \? /? \? /?? Oeconomicum (Building 24.31), Room 01.22
|?? \/??? \/??? Tel: 0049 211 81-15307
+----------------------------------------------------------->

Am 28.09.2016 um 18:28 schrieb Doran, Harold:
> Thank you very much. I don?t know tidyverse, I?ll look at that now. I did some tests with data.table package, but it was much slower on my machine, see examples below
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
>
> library(data.table)
>
> tmp2 <- as.data.table(tmp)???? # data.table
>
> system.time(replicate(500, tmp2[which(tmp$id == idList[1]),]))
>
> system.time(replicate(500, subset(tmp2, id == idList[1])))
>
> From: Dominik Schneider [mailto:dosc3612 at colorado.edu]
> Sent: Wednesday, September 28, 2016 12:27 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] Faster Subsetting
>
> I regularly crunch through this amount of data with tidyverse. You can also try the data.table package. They are optimized for speed, as long as you have the memory.
> Dominik
>
> On Wed, Sep 28, 2016 at 10:09 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.
>
> I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.? I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>?????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hpages at fredhutch.org  Wed Sep 28 20:53:01 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 28 Sep 2016 11:53:01 -0700
Subject: [R] Faster Subsetting
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
Message-ID: <1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>

Hi,

I'm surprised nobody suggested split(). Splitting the data.frame
upfront is faster than repeatedly subsetting it:

   tmp <- data.frame(id = rep(1:20000, each = 10), foo = rnorm(200000))
   idList <- unique(tmp$id)

   system.time(for (i in idList) tmp[which(tmp$id == i),])
   #   user  system elapsed
   # 16.286   0.000  16.305

   system.time(split(tmp, tmp$id))
   #   user  system elapsed
   #  5.637   0.004   5.647

Cheers,
H.

On 09/28/2016 09:09 AM, Doran, Harold wrote:
> I have an extremely large data frame (~13 million rows) that resembles the structure of the object tmp below in the reproducible code. In my real data, the variable, 'id' may or may not be ordered, but I think that is irrelevant.
>
> I have a process that requires subsetting the data by id and then running each smaller data frame through a set of functions. One example below uses indexing and the other uses an explicit call to subset(), both return the same result, but indexing is faster.
>
> Problem is in my real data, indexing must parse through millions of rows to evaluate the condition and this is expensive and a bottleneck in my code.  I'm curious if anyone can recommend an improvement that would somehow be less expensive and faster?
>
> Thank you
> Harold
>
>
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>
> idList <- unique(tmp$id)
>
> ### Fast, but not fast enough
> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>
> ### Not fast at all, a big bottleneck
> system.time(replicate(500, subset(tmp, id == idList[1])))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bgunter.4567 at gmail.com  Wed Sep 28 21:44:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Sep 2016 12:44:54 -0700
Subject: [R] Faster Subsetting
In-Reply-To: <1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
Message-ID: <CAGxFJbQxKYr8q662GJAs=YsCV_RvS_txRVWaaOb8heDZXBUd_A@mail.gmail.com>

"I'm surprised nobody suggested split(). "

I did.

by() is a data frame oriented version of tapply(), which uses split().

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 28, 2016 at 11:53 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi,
>
> I'm surprised nobody suggested split(). Splitting the data.frame
> upfront is faster than repeatedly subsetting it:
>
>   tmp <- data.frame(id = rep(1:20000, each = 10), foo = rnorm(200000))
>   idList <- unique(tmp$id)
>
>   system.time(for (i in idList) tmp[which(tmp$id == i),])
>   #   user  system elapsed
>   # 16.286   0.000  16.305
>
>   system.time(split(tmp, tmp$id))
>   #   user  system elapsed
>   #  5.637   0.004   5.647
>
> Cheers,
> H.
>
> On 09/28/2016 09:09 AM, Doran, Harold wrote:
>>
>> I have an extremely large data frame (~13 million rows) that resembles the
>> structure of the object tmp below in the reproducible code. In my real data,
>> the variable, 'id' may or may not be ordered, but I think that is
>> irrelevant.
>>
>> I have a process that requires subsetting the data by id and then running
>> each smaller data frame through a set of functions. One example below uses
>> indexing and the other uses an explicit call to subset(), both return the
>> same result, but indexing is faster.
>>
>> Problem is in my real data, indexing must parse through millions of rows
>> to evaluate the condition and this is expensive and a bottleneck in my code.
>> I'm curious if anyone can recommend an improvement that would somehow be
>> less expensive and faster?
>>
>> Thank you
>> Harold
>>
>>
>> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>>
>> idList <- unique(tmp$id)
>>
>> ### Fast, but not fast enough
>> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>>
>> ### Not fast at all, a big bottleneck
>> system.time(replicate(500, subset(tmp, id == idList[1])))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Sep 28 21:55:57 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Sep 2016 12:55:57 -0700
Subject: [R] Error in gam() object 'scat' no found
In-Reply-To: <CAMKhwd_ugNVUcy2_0uijJi6sHv0nGHkWZXa-TM7NbTm4P3QHEQ@mail.gmail.com>
References: <CAMKhwd_ugNVUcy2_0uijJi6sHv0nGHkWZXa-TM7NbTm4P3QHEQ@mail.gmail.com>
Message-ID: <970BFDF2-3949-4964-A957-154DD4781578@comcast.net>


> On Sep 27, 2016, at 8:11 PM, Karl Neergaard <karlneergaard at gmail.com> wrote:
> 
> Thank you David for taking time to answer my not so helpful question.
> 

I thought your question had sufficient detail for at least a reasonable guess at an answer. When I first started using R I also thought that the gam function would come from the gam package. It would certainly have been better to provide a full question (starting with a library call to you package, creating a dataset, quite possibly using one from the package help files,  and running code with complete text for all errors),  but this was a case where I thought the source of the problem was clear. I'm sure your next question will be more complete and in plain text.

Best;

David,
> 
> On Tue, Sep 27, 2016 at 11:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 26, 2016, at 9:50 PM, Karl Neergaard <karlneergaard at gmail.com> wrote:
> >
> > I received an error message while trying to use family=scat in the GAM
> > package. The models were working fine yesterday.
> > The problem is not with my data seeing as the gaussian distribution is
> > working fine.
> >
> > mod=gam(RT~s(a) + s(b), data=dat, family=gaussian)
> > mod=gam(RT~s(a) + s(b), data=dat, family=scat)
> >
> > Might this problem be unrelated to GAM specifically, and to my R
> > configuration?
> > I have removed the gam package and re-installed it several times to no
> > avail.
> 
> The scat function is in package mgcv. It also has a `gam` function and is generally thought of as the "standard" approach for estimating generalized additive models.
> 
> 
> >
> > Thank you for any assistance,
> > Karl
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From martin.morgan at roswellpark.org  Wed Sep 28 22:37:29 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 28 Sep 2016 16:37:29 -0400
Subject: [R] Faster Subsetting
In-Reply-To: <1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
Message-ID: <a03d5212-2261-dd6c-cac1-bea4b14f6ab0@roswellpark.org>

On 09/28/2016 02:53 PM, Herv? Pag?s wrote:
> Hi,
>
> I'm surprised nobody suggested split(). Splitting the data.frame
> upfront is faster than repeatedly subsetting it:
>
>   tmp <- data.frame(id = rep(1:20000, each = 10), foo = rnorm(200000))
>   idList <- unique(tmp$id)
>
>   system.time(for (i in idList) tmp[which(tmp$id == i),])
>   #   user  system elapsed
>   # 16.286   0.000  16.305
>
>   system.time(split(tmp, tmp$id))
>   #   user  system elapsed
>   #  5.637   0.004   5.647

an odd speed-up is to provide (non-sequential) row names, e.g.,

 > system.time(split(tmp, tmp$id))
    user  system elapsed
   4.472   0.648   5.122
 > row.names(tmp) = rev(seq_len(nrow(tmp)))
 > system.time(split(tmp, tmp$id))
    user  system elapsed
   0.588   0.000   0.587

for reasons explained here

 
http://stackoverflow.com/questions/39545400/why-is-split-inefficient-on-large-data-frames-with-many-groups/39548316#39548316

Martin


>
> Cheers,
> H.
>
> On 09/28/2016 09:09 AM, Doran, Harold wrote:
>> I have an extremely large data frame (~13 million rows) that resembles
>> the structure of the object tmp below in the reproducible code. In my
>> real data, the variable, 'id' may or may not be ordered, but I think
>> that is irrelevant.
>>
>> I have a process that requires subsetting the data by id and then
>> running each smaller data frame through a set of functions. One
>> example below uses indexing and the other uses an explicit call to
>> subset(), both return the same result, but indexing is faster.
>>
>> Problem is in my real data, indexing must parse through millions of
>> rows to evaluate the condition and this is expensive and a bottleneck
>> in my code.  I'm curious if anyone can recommend an improvement that
>> would somehow be less expensive and faster?
>>
>> Thank you
>> Harold
>>
>>
>> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
>>
>> idList <- unique(tmp$id)
>>
>> ### Fast, but not fast enough
>> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
>>
>> ### Not fast at all, a big bottleneck
>> system.time(replicate(500, subset(tmp, id == idList[1])))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


This email message may contain legally privileged and/or...{{dropped:2}}


From kw.stat at gmail.com  Wed Sep 28 22:40:50 2016
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 28 Sep 2016 15:40:50 -0500
Subject: [R] Add annotation text outside of an xyplot (lattice package)
In-Reply-To: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
References: <CAMCXXmquHvrMcmvDVPCbgqaY0NVRDzdDGc1Dpd6JWAwDT_PQ1Q@mail.gmail.com>
Message-ID: <CAKFxdiS+ExjpPJwf8Rxe23UKaTD75hxZa+eT4Y=uHhnv853XPg@mail.gmail.com>

You can find an example of annotating lattice graphics with text anywhere
on the graphics device using the pagenum package.  See the vignette here:

https://cran.r-project.org/web/packages/pagenum/vignettes/pagenum.html

The pagenum package uses the grid package to add viewports for the
annotation.  The R code showing how this works is here:
https://github.com/kwstat/pagenum/blob/master/R/pagenum.r

Kevin Wright

On Thu, Sep 22, 2016 at 9:04 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:

> Dear list,
>
> Just wonder if there is a way to add annotation text outside an xyplot,
> (e.g. the bottom of the plot). the panel.text seems only add text within
> the plot. Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep 28 22:54:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Sep 2016 13:54:46 -0700
Subject: [R] How to test a difference in ratios of count data in R
In-Reply-To: <CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>
References: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
	<CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>
Message-ID: <69100965-060D-44E5-B01A-10171A4300D7@comcast.net>


> On Sep 28, 2016, at 9:49 AM, Greg Snow <538280 at gmail.com> wrote:
> 
> There are multiple ways of doing this, but here are a couple.
> 
> To just test the fixed effect of treatment you can use the glm function:
> 
> test <- read.table(text="
> replicate treatment n X
> 1 A 32 4
> 1 B 33 18
> 2 A 20 6
> 2 B 21 18
> 3 A 7 0
> 3 B 8 4
> ", header=TRUE)
> 
> fit1 <- glm( cbind(X,n-X) ~ treatment, data=test, family=binomial)
> summary(fit1)
> 
> Note that the default baseline value may differ between R and SAS,
> which would result in a reversed sign on the slope coefficient (and
> different intercept).
> 
> To include replicate as a random effect you need an additional
> package, here I use lme4 and the glmer function:
> 
> library(lme4)
> fit2 <- glmer( cbind(X, n-X) ~ treatment + (1|replicate), data=test,
> family=binomial)
> summary(fit2)
> 
> 
> 
> On Tue, Sep 27, 2016 at 9:03 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
>> Hello R-experts,
>> I am interested to determine if the ratio of counts from two groups differ across two distinct treatments. For example, we have three replicates of treatment A, and three replicates of treatment B. For each treatment, we have counts X from one group and counts Y from another group. My understanding is that that GLIMMIX procedure in SAS can calculate whether the ratio of counts in one group (X/X+Y) significantly differs between treatments.
>> 
>> I think this is the way you do it in SAS. The replicate and treatment variables are self-explanatory. The first number (n) refers to the total counts X + Y; the second number (X) refers to the counts X. Is there a way to do this in R? Since we have 20,000 datasets to be tested, it may be easier to retrive the significant test as the given dataset below and its p>F value and mean ratios of treatments in R than SAS.
>> 
>> 
>> data test;
>> input replicate treatment$ n X;
>> datalines;
>> 1 A 32 4
>> 1 B 33 18
>> 2 A 20 6
>> 2 B 21 18
>> 3 A 7 0
>> 3 B 8 4
>> ;
>> 

Greg has already shown you how that is done in R and how to do logistic regression:

#  I usually think of Poisson regression when I hear a desire is to model ratios of counts that have a denominator. The log(sample_size) is supplied as an offset to correct for the variation in size of subsamples.


fit1 <- glm( X ~ treatment+offset(log(n)), data=test, family=poisson)
summary(fit1)

#  And the lme4 analogue with replication:

library(lme4)
fit2 <- glmer( X ~ treatment + offset(log(n))+ (1|replicate), data=test,
family=poisson)
summary(fit2)
#----output----
Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
 [glmerMod]
 Family: poisson  ( log )
Formula: X ~ treatment + offset(log(n)) + (1 | replicate)
   Data: test

     AIC      BIC   logLik deviance df.resid 
    31.9     31.3    -13.0     25.9        3 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.0504 -0.4146 -0.3487  0.3956  1.0791 

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.03159  0.1777  
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -1.7875     0.3372  -5.301 1.15e-07 ***
treatmentB    1.3365     0.3529   3.787 0.000152 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.838

Compare with the binomial model:
#============


 fitBin <- glmer( cbind(X,n-X) ~ treatment +  (1|replicate), data=test,
 family=binomial)
 coef(fitBin)
#----
$replicate
  (Intercept) treatmentB
1  -2.0487694   2.364695
2  -0.9908556   2.364695
3  -2.1844435   2.364695

attr(,"class")
[1] "coef.mer"
#-----
 summary(fitBin)
#---------
Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
 [glmerMod]
 Family: binomial  ( logit )
Formula: cbind(X, n - X) ~ treatment + (1 | replicate)
   Data: test

     AIC      BIC   logLik deviance df.resid 
    30.1     29.4    -12.0     24.1        3 

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-0.88757 -0.35065 -0.03137  0.26897  0.67505 

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.4123   0.6421  
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -1.7442     0.5438  -3.208  0.00134 ** 
treatmentB    2.3647     0.4741   4.988 6.11e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.568

The binomial model has a logit link. Your glimmix procedure appears to have a gaussian/normal distributional assumption and an identity link by default. If we run this using those assumptions in lme4::glmer we get these results (with a warning that in this case we can overlook since the results with lmer turned out to be identical)
#--------
 fitNorm <- glmer( I(X/n) ~ treatment +  (1|replicate), data=test,
                  family=gaussian)

#-------
Warning message:
In glmer(I(X/n) ~ treatment + (1 | replicate), data = test, family = gaussian) :
  calling glmer() with family=gaussian (identity link) as a shortcut to lmer() is deprecated; please call lmer() directly
> coef(fitNorm); summary(fitNorm)
$replicate
  (Intercept) treatmentB
1 0.091096925  0.4925325
2 0.324579602  0.4925325
3 0.009323473  0.4925325

attr(,"class")
[1] "coef.mer"
Linear mixed model fit by REML ['lmerMod']
Formula: I(X/n) ~ treatment + (1 | replicate)
   Data: test

REML criterion at convergence: -4.2

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-0.7864 -0.4278 -0.1152  0.5143  0.8246 

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.027895 0.16702 
 Residual              0.002356 0.04854 
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.14167    0.10042   1.411
treatmentB   0.49253    0.03963  12.427

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.197

That's (probably) the model to compare to your SAS results if my reading of the SAS Proc GLIMMIX manual page is correct.

-- 
David.

>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> run;
>> 
>> ods select lsmeans;
>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> lsmeans treatment / cl ilink;
>> run;
>> 
>> I appreciate your help in advance!
>> Joshua
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From toth.denes at ttk.mta.hu  Thu Sep 29 00:55:32 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Thu, 29 Sep 2016 00:55:32 +0200
Subject: [R] Faster Subsetting
In-Reply-To: <1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686013584A6F4@DC1VEX10MB01.air.org>
	<1b484746-947a-a820-b528-f10ef9e46b51@fredhutch.org>
Message-ID: <57EC4A64.1000908@ttk.mta.hu>

Hi Harold,

Generally: you can not beat data.table, unless you can represent your 
data in a matrix (or array or vector). For some specific cases, Herv?'s 
suggestion might be also competitive.
Your problem is that you did not put any effort to read at least part of 
the very extensive documentation of the data.table package. You should 
start here: https://github.com/Rdatatable/data.table/wiki/Getting-started

To put in a nutshell: use a key which allows binary search instead of 
the much-much slower vector scan. (With the automatic auto-indexing 
feature of the data.table package, you may even skip this step.) The 
point is that creating the key must be done only once, and all 
subsequent subsetting operations which use the key become incredibly 
fast. You missed this point because you replicated the creation of the 
key as well, not only the subsetting in one of your examples.

Here is a version of Herve's example (OK, it is a bit biased because 
data.table has a highly optimized internal version of mean() for 
calculating the group means):

## create a keyed data.table
tmp_dt <- data.table(id = rep(1:20000, each = 10), foo = rnorm(200000), 
key = "id")
system.time(tmp_dt[, .(result = mean(foo)), by = id])
# user system elapsed
# 0.004 0.000 0.005

## subset a keyed data.table
all_ids <- tmp_dt[, unique(id)]
select_id <- sample(all_ids, 1)
system.time(tmp_dt[.(select_id)])
# user system elapsed
# 0.000 0.000 0.001

## or equivalently
system.time(tmp_dt[id == select_id])
# user system elapsed
# 0.000 0.000 0.001

Note: the CRAN version of the data.table package is already very fast, 
but you should try the developmental version ( 
devtools::install_github("Rdatatable/data.table") ) for multi-threaded 
subsetting.


Cheers,
Denes


On 09/28/2016 08:53 PM, Herv? Pag?s wrote:
 > Hi,
 >
 > I'm surprised nobody suggested split(). Splitting the data.frame
 > upfront is faster than repeatedly subsetting it:
 >
 >    tmp <- data.frame(id = rep(1:20000, each = 10), foo = rnorm(200000))
 >    idList <- unique(tmp$id)
 >
 >    system.time(for (i in idList) tmp[which(tmp$id == i),])
 >    #   user  system elapsed
 >    # 16.286   0.000  16.305
 >
 >    system.time(split(tmp, tmp$id))
 >    #   user  system elapsed
 >    #  5.637   0.004   5.647
 >
 > Cheers,
 > H.
 >
 > On 09/28/2016 09:09 AM, Doran, Harold wrote:
 >> I have an extremely large data frame (~13 million rows) that resembles
 >> the structure of the object tmp below in the reproducible code. In my
 >> real data, the variable, 'id' may or may not be ordered, but I think
 >> that is irrelevant.
 >>
 >> I have a process that requires subsetting the data by id and then
 >> running each smaller data frame through a set of functions. One
 >> example below uses indexing and the other uses an explicit call to
 >> subset(), both return the same result, but indexing is faster.
 >>
 >> Problem is in my real data, indexing must parse through millions of
 >> rows to evaluate the condition and this is expensive and a bottleneck
 >> in my code.  I'm curious if anyone can recommend an improvement that
 >> would somehow be less expensive and faster?
 >>
 >> Thank you
 >> Harold
 >>
 >>
 >> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
 >>
 >> idList <- unique(tmp$id)
 >>
 >> ### Fast, but not fast enough
 >> system.time(replicate(500, tmp[which(tmp$id == idList[1]),]))
 >>
 >> ### Not fast at all, a big bottleneck
 >> system.time(replicate(500, subset(tmp, id == idList[1])))
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 >>
 >


From fabien.tarrade at gmail.com  Thu Sep 29 06:32:08 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Thu, 29 Sep 2016 06:32:08 +0200
Subject: [R] remove a "corrupted file" after using download.file() with R on
 Windows 7
Message-ID: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>

Hi there,

Sometime download.file() failed to download the file and I would like to 
remove the correspond file.
The issue is that I am not able to do it and Windows complain that the 
file is use by another application.
I try to closeAllConnections(), or unlink() before removing the file but 
without sucess.

Any idea how I should proceed &

Please find the code below

  # consider warning as an error
   options(warn=2)

   # try to download the file
   tryCatch({
     download.file(url,path_file,mode="wb",quiet=quiet)
     return(0)
   },error = function(e){
     if(verbose){
       print(e)
       print(e$message)
     }
     # close file when it failed
     if (file.exists(path_file)){
       closeAllConnections()
       #unlink(path_file, recursive=TRUE)
       #file.create(path_file,overwrite=TRUE,showWarning=TRUE)
       #system(paste0('open "', path_file, '"'))
       file.remove(path_file,overwrite=TRUE,showWarning=TRUE)
     }
     return(1)
     }
)

Thanks a lot
Cheers
Fabien

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From Pascale.Voirin at hefr.ch  Thu Sep 29 10:59:08 2016
From: Pascale.Voirin at hefr.ch (Voirin Pascale)
Date: Thu, 29 Sep 2016 08:59:08 +0000
Subject: [R] using read.csv2()
Message-ID: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>

Hello,

I have a problem with the variable type defined by reading a csv file with read.csv2.

Here is a test file saved as < test.csv > :
var1;var2;var3
TI;1995;4.5
VD;1990;4.8
FR;1994;3.9
VS;1993;5.1
FR;1995;4.7
FR;1992;5.8

That  I read in R with :
read.csv2("test.csv")->don;don
don$var3
## [1] 4.5 4.8 3.9 5.1 4.7 5.8
## Levels: 3.9 4.5 4.7 4.8 5.1 5.8

as.double(don$var3)
## [1] 2 4 1 5 3 6

Why is it by default a <levels> type ? And how can I get  the decimal value for var3

Thanks a lot for your answer.
With my best regards,

Pascale Voirin

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Thu Sep 29 11:07:46 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 29 Sep 2016 11:07:46 +0200
Subject: [R] using read.csv2()
In-Reply-To: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
	(Voirin Pascale's message of "Thu, 29 Sep 2016 08:59:08 +0000")
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
Message-ID: <m2mvirt6ot.fsf@krugs.de>

Voirin Pascale <Pascale.Voirin at hefr.ch> writes:

> Hello,
>
> I have a problem with the variable type defined by reading a csv file with read.csv2.
>
> Here is a test file saved as < test.csv > :
> var1;var2;var3
> TI;1995;4.5
> VD;1990;4.8
> FR;1994;3.9
> VS;1993;5.1
> FR;1995;4.7
> FR;1992;5.8
>
> That  I read in R with :
> read.csv2("test.csv")->don;don
> don$var3
> ## [1] 4.5 4.8 3.9 5.1 4.7 5.8
> ## Levels: 3.9 4.5 4.7 4.8 5.1 5.8
>
> as.double(don$var3)
> ## [1] 2 4 1 5 3 6
>
> Why is it by default a <levels> type ? And how can I get  the decimal value for var3

You very likely have a character in your column named var3. Just check
your Levels after the import, and you should see it.

Cheers,

Rainer

>
> Thanks a lot for your answer.
> With my best regards,
>
> Pascale Voirin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160929/ecab5bc2/attachment.bin>

From murdoch.duncan at gmail.com  Thu Sep 29 11:40:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Sep 2016 05:40:18 -0400
Subject: [R] using read.csv2()
In-Reply-To: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
Message-ID: <483b2883-e0f0-6582-50a5-b3609773d219@gmail.com>

On 29/09/2016 4:59 AM, Voirin Pascale wrote:
> Hello,
>
> I have a problem with the variable type defined by reading a csv file with read.csv2.
>
> Here is a test file saved as < test.csv > :
> var1;var2;var3
> TI;1995;4.5
> VD;1990;4.8
> FR;1994;3.9
> VS;1993;5.1
> FR;1995;4.7
> FR;1992;5.8
>
> That  I read in R with :
> read.csv2("test.csv")->don;don
> don$var3
> ## [1] 4.5 4.8 3.9 5.1 4.7 5.8
> ## Levels: 3.9 4.5 4.7 4.8 5.1 5.8
>
> as.double(don$var3)
> ## [1] 2 4 1 5 3 6
>
> Why is it by default a <levels> type ? And how can I get  the decimal value for var3

It's a "factor".  read.csv2() defaults to a decimal separator of "," 
rather than ".", so the last column doesn't look like numbers, and 
they're being read as character strings, and then automatically 
converted to a factor.  Reading as

read.csv2("test.csv", dec = ".")

should give you what you want, or you can convert after the fact with

as.numeric(as.character(don$var3))

Duncan Murdoch


>
> Thanks a lot for your answer.
> With my best regards,
>
> Pascale Voirin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Thu Sep 29 12:55:27 2016
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 29 Sep 2016 12:55:27 +0200
Subject: [R] using read.csv2()
In-Reply-To: <483b2883-e0f0-6582-50a5-b3609773d219@gmail.com>
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
	<483b2883-e0f0-6582-50a5-b3609773d219@gmail.com>
Message-ID: <B8FAE399-1C53-4D26-9903-6DEAF77DA9E6@gmail.com>

> On 29 Sep 2016, at 11:40 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> 
> It's a "factor".  read.csv2() defaults to a decimal separator of "," rather than ".", so the last column doesn't look like numbers, and they're being read as character strings, and then automatically converted to a factor.  Reading as
> 

Yep, that's the whole point of read.csv2 -- someone stupidly decided (back in the 90's) that the use of comma as a decimal separator in some languages should extend to storage file formats.  That, of course, ruined the CSV standard use of comma as a field separator and prompted the double-standard situation where .csv files can be comma/period or semicolon/comma style, often depending on languages settings, which in turn can make data transfer between different languages an ungodly mess....

As Duncan points out, R provides settings that will (mostly) let you handle csv files that are written in hybrid formats like semicolon/period. 

From fisher at plessthan.com  Thu Sep 29 15:38:39 2016
From: fisher at plessthan.com (Dennis Fisher)
Date: Thu, 29 Sep 2016 06:38:39 -0700
Subject: [R] Efficient means to link two data frames
Message-ID: <A46C675E-AD4E-44DC-9194-BC80D7B4220E@plessthan.com>

R 3.3.1 
OS X

Colleagues,

I have two large data frames that I am trying to link efficiently.   A small example is as follows:

structure(list(Day = c(1L, 2L, 3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
13L, 14L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L), Value = c(76, 116, 111, 103, 114, 99, 128, 
96, 81, 84, 81, 108, 109, 106, 125, 128, 92, 90, 83, 89, 76, 
89, 101, 93, 98, 77, 92)), .Names = c("Day", "Value"), row.names = c(NA, 
-27L), class = "data.frame")

which becomes:
  Day Value
1    1    76
2    2   116
3    3   111
4    5   103
5    6   114
6    7    99
7    8   128
8    9    96
9   10    81
10  11    84
11  13    81
12  14   108
13  16   109
14  17   106
15  18   125
16  19   128
17  20    92
18  21    90
19  22    83
20  23    89
21  24    76
22  25    89
23  26   101
24  27    93
25  28    98
26  29    77
27  30    92

The second dataframe is merely:
TESTDAYS			<- data.frame(TestDay = c(4, 11, 15))

For each row in the second dataframe, I would like to identify the first row in the first dataframe in which Day is >= TestDay.
For example, for TestDay == 4, Day would equal 5.  I would then append the corresponding ?Value? in the TestValue column
The result would be:
 TestDay TestValue
1       4       103
2      11        84
3      15       109

I can accomplish this with brute force but I suspect that there is some clever day to vectorize this.  Any help would be appreciated.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com <http://www.plessthan.com/>





	[[alternative HTML version deleted]]


From btupper at bigelow.org  Thu Sep 29 16:10:20 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 29 Sep 2016 10:10:20 -0400
Subject: [R] Efficient means to link two data frames
In-Reply-To: <A46C675E-AD4E-44DC-9194-BC80D7B4220E@plessthan.com>
References: <A46C675E-AD4E-44DC-9194-BC80D7B4220E@plessthan.com>
Message-ID: <C9F81E8D-AD77-439B-8369-E17436637E74@bigelow.org>

Hi,

I have a solution based upon findInterval() which depends upon the ordered nature of the 'Day' column.  I can't speak to whether or not it is efficient but it is handy.  I love the findInterval() function but have often wished it works with look up tables in descending order.  This function, find_interval(), is my first reasonable pass at working with descending order.

https://gist.github.com/btupper/5fc6cc4e7d86f39f9e4f

## start
source("find_interval.R")

x <- structure(list(Day = c(1L, 2L, 3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
13L, 14L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L), Value = c(76, 116, 111, 103, 114, 99, 128, 
96, 81, 84, 81, 108, 109, 106, 125, 128, 92, 90, 83, 89, 76, 
89, 101, 93, 98, 77, 92)), .Names = c("Day", "Value"), row.names = c(NA, 
-27L), class = "data.frame")

TESTDAYS <- data.frame(TestDay = c(4, 11, 15))

x <- x[rev(1:nrow(x)),]

ix <- find_interval(TESTDAYS[,'TestDay'], x[,'Day'])

TESTDAYS[,'TestValue'] <- x[ix,'Value']

TESTDAYS
#   TestDay TestValue
# 1       4       103
# 2      11        84
# 3      15       109

### end

Will that do the trick with your large dataset?

Ben


> On Sep 29, 2016, at 9:38 AM, Dennis Fisher <fisher at plessthan.com> wrote:
> 
> R 3.3.1 
> OS X
> 
> Colleagues,
> 
> I have two large data frames that I am trying to link efficiently.   A small example is as follows:
> 
> structure(list(Day = c(1L, 2L, 3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
> 13L, 14L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
> 27L, 28L, 29L, 30L), Value = c(76, 116, 111, 103, 114, 99, 128, 
> 96, 81, 84, 81, 108, 109, 106, 125, 128, 92, 90, 83, 89, 76, 
> 89, 101, 93, 98, 77, 92)), .Names = c("Day", "Value"), row.names = c(NA, 
> -27L), class = "data.frame")
> 
> which becomes:
>  Day Value
> 1    1    76
> 2    2   116
> 3    3   111
> 4    5   103
> 5    6   114
> 6    7    99
> 7    8   128
> 8    9    96
> 9   10    81
> 10  11    84
> 11  13    81
> 12  14   108
> 13  16   109
> 14  17   106
> 15  18   125
> 16  19   128
> 17  20    92
> 18  21    90
> 19  22    83
> 20  23    89
> 21  24    76
> 22  25    89
> 23  26   101
> 24  27    93
> 25  28    98
> 26  29    77
> 27  30    92
> 
> The second dataframe is merely:
> TESTDAYS			<- data.frame(TestDay = c(4, 11, 15))
> 
> For each row in the second dataframe, I would like to identify the first row in the first dataframe in which Day is >= TestDay.
> For example, for TestDay == 4, Day would equal 5.  I would then append the corresponding ?Value? in the TestValue column
> The result would be:
> TestDay TestValue
> 1       4       103
> 2      11        84
> 3      15       109
> 
> I can accomplish this with brute force but I suspect that there is some clever day to vectorize this.  Any help would be appreciated.
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com <http://www.plessthan.com/>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From alain.guillet at uclouvain.be  Thu Sep 29 11:41:53 2016
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Thu, 29 Sep 2016 11:41:53 +0200
Subject: [R] using read.csv2()
In-Reply-To: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
Message-ID: <ff54ba64-0688-7178-c9a6-b8a066865432@uclouvain.be>

Hello,

The defaults in read.csv2 are ";" as the separator and "," as the 
decimal symbol. It seems that the file you import is not a true csv 
since it mixes up two norms.

You can solve your problem in defining the dec option equals to ".":

read.csv2("test.csv",dec=".")->don


Alain

On 29/09/16 10:59, Voirin Pascale wrote:
> Hello,
>
> I have a problem with the variable type defined by reading a csv file with read.csv2.
>
> Here is a test file saved as < test.csv > :
> var1;var2;var3
> TI;1995;4.5
> VD;1990;4.8
> FR;1994;3.9
> VS;1993;5.1
> FR;1995;4.7
> FR;1992;5.8
>
> That  I read in R with :
> read.csv2("test.csv")->don;don
> don$var3
> ## [1] 4.5 4.8 3.9 5.1 4.7 5.8
> ## Levels: 3.9 4.5 4.7 4.8 5.1 5.8
>
> as.double(don$var3)
> ## [1] 2 4 1 5 3 6
>
> Why is it by default a <levels> type ? And how can I get  the decimal value for var3
>
> Thanks a lot for your answer.
> With my best regards,
>
> Pascale Voirin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> .
>

-- 
Alain Guillet
Statistician and Computer Scientist

SMCS - IMMAQ - Universit? catholique de Louvain
http://www.uclouvain.be/smcs

Bureau c.316
Voie du Roman Pays, 20 (bte L1.04.01)
B-1348 Louvain-la-Neuve
Belgium

Tel: +32 10 47 30 50

Acc?s: http://www.uclouvain.be/323631.html


From NordlDJ at dshs.wa.gov  Thu Sep 29 17:12:07 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 29 Sep 2016 15:12:07 +0000
Subject: [R] using read.csv2()
In-Reply-To: <ff54ba64-0688-7178-c9a6-b8a066865432@uclouvain.be>
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
	<ff54ba64-0688-7178-c9a6-b8a066865432@uclouvain.be>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766309BB2EF@WAXMXOLYMB025.WAX.wa.lcl>

Or, you can just use read.csv with sep=';'

read.csv("test.csv", sep=';') -> don


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alain
> Guillet
> Sent: Thursday, September 29, 2016 2:42 AM
> To: r-help at r-project.org
> Subject: Re: [R] using read.csv2()
> 
> Hello,
> 
> The defaults in read.csv2 are ";" as the separator and "," as the decimal
> symbol. It seems that the file you import is not a true csv since it mixes up
> two norms.
> 
> You can solve your problem in defining the dec option equals to ".":
> 
> read.csv2("test.csv",dec=".")->don
> 
> 
> Alain
> 
> On 29/09/16 10:59, Voirin Pascale wrote:
> > Hello,
> >
> > I have a problem with the variable type defined by reading a csv file with
> read.csv2.
> >
> > Here is a test file saved as < test.csv > :
> > var1;var2;var3
> > TI;1995;4.5
> > VD;1990;4.8
> > FR;1994;3.9
> > VS;1993;5.1
> > FR;1995;4.7
> > FR;1992;5.8
> >
> > That  I read in R with :
> > read.csv2("test.csv")->don;don
> > don$var3
> > ## [1] 4.5 4.8 3.9 5.1 4.7 5.8
> > ## Levels: 3.9 4.5 4.7 4.8 5.1 5.8
> >
> > as.double(don$var3)
> > ## [1] 2 4 1 5 3 6
> >
> > Why is it by default a <levels> type ? And how can I get  the decimal
> > value for var3
> >
> > Thanks a lot for your answer.
> > With my best regards,
> >
> > Pascale Voirin
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > .
> >
> 
> --
> Alain Guillet
> Statistician and Computer Scientist
> 
> SMCS - IMMAQ - Universit? catholique de Louvain
> http://www.uclouvain.be/smcs
> 
> Bureau c.316
> Voie du Roman Pays, 20 (bte L1.04.01)
> B-1348 Louvain-la-Neuve
> Belgium
> 
> Tel: +32 10 47 30 50
> 
> Acc?s: http://www.uclouvain.be/323631.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Thu Sep 29 17:31:24 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 29 Sep 2016 16:31:24 +0100
Subject: [R] using read.csv2()
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA2766309BB2EF@WAXMXOLYMB025.WAX.wa.lcl>
References: <3E06FD035776314F8F53333F3379473D0143ADE74A@HEFRMBX01.sofr.hefr.lan>
	<ff54ba64-0688-7178-c9a6-b8a066865432@uclouvain.be>
	<F7E6D18CC2877149AB5296CE54EA2766309BB2EF@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <20160929163124.Horde.fir9AxlHgXlYY8fHd5O4jmU@mail.sapo.pt>

Hello,

No one mentioned that read.csv2 and read.csv are particular cases of  
read.table.


read.table(text = "
var1;var2;var3
TI;1995;4.5
VD;1990;4.8
FR;1994;3.9
VS;1993;5.1
FR;1995;4.7
FR;1992;5.8
", header = TRUE, sep = ";", dec = ".") -> don
str(don)


Rui Barradas


Citando Nordlund, Dan (DSHS/RDA) <NordlDJ at dshs.wa.gov>:

> Or, you can just use read.csv with sep=';'
>
> read.csv("test.csv", sep=';') -> don
>
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alain
>> Guillet
>> Sent: Thursday, September 29, 2016 2:42 AM
>> To: r-help at r-project.org
>> Subject: Re: [R] using read.csv2()
>>
>> Hello,
>>
>> The defaults in read.csv2 are ";" as the separator and "," as the decimal
>> symbol. It seems that the file you import is not a true csv since  
>> it mixes up
>> two norms.
>>
>> You can solve your problem in defining the dec option equals to ".":
>>
>> read.csv2("test.csv",dec=".")->don
>>
>>
>> Alain
>>
>> On 29/09/16 10:59, Voirin Pascale wrote:
>> > Hello,
>> >
>> > I have a problem with the variable type defined by reading a csv file with
>> read.csv2.
>> >
>> > Here is a test file saved as < test.csv > :
>> > var1;var2;var3
>> > TI;1995;4.5
>> > VD;1990;4.8
>> > FR;1994;3.9
>> > VS;1993;5.1
>> > FR;1995;4.7
>> > FR;1992;5.8
>> >
>> > That  I read in R with :
>> > read.csv2("test.csv")->don;don
>> > don$var3
>> > ## [1] 4.5 4.8 3.9 5.1 4.7 5.8
>> > ## Levels: 3.9 4.5 4.7 4.8 5.1 5.8
>> >
>> > as.double(don$var3)
>> > ## [1] 2 4 1 5 3 6
>> >
>> > Why is it by default a <levels> type ? And how can I get  the decimal
>> > value for var3
>> >
>> > Thanks a lot for your answer.
>> > With my best regards,
>> >
>> > Pascale Voirin
>> >
>> > 	[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> > .
>> >
>>
>> --
>> Alain Guillet
>> Statistician and Computer Scientist
>>
>> SMCS - IMMAQ - Universit? catholique de Louvain
>> http://www.uclouvain.be/smcs
>>
>> Bureau c.316
>> Voie du Roman Pays, 20 (bte L1.04.01)
>> B-1348 Louvain-la-Neuve
>> Belgium
>>
>> Tel: +32 10 47 30 50
>>
>> Acc?s: http://www.uclouvain.be/323631.html
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From schubert.seb at gmail.com  Thu Sep 29 18:18:05 2016
From: schubert.seb at gmail.com (Sebastian Schubert)
Date: Thu, 29 Sep 2016 18:18:05 +0200
Subject: [R] R_LIBS_SITE in Renviron ignored (?)
In-Reply-To: <CAMVMZDCYF-0=M_U6R-NS0U0_Aq9XYG4vcWrPevys0kzQAzxB=Q@mail.gmail.com>
References: <CAMVMZDCYF-0=M_U6R-NS0U0_Aq9XYG4vcWrPevys0kzQAzxB=Q@mail.gmail.com>
Message-ID: <CAMVMZDD-E4ULUA+JzVR411XQF6ohcDQgpYUAHcaCvt9=KZwidw@mail.gmail.com>

Hi all,

On 23.09.2016 11:25, Sebastian Schubert wrote:
...
> Maybe I get the documentation wrong but it seems, the variable
> R_LIBS_SITE in Renviron is ignored while, for example, R_LIBS_USER is
> not.
...

For reference, I got a hint here:
http://stackoverflow.com/a/39766163/1463740

I tried setting the variable R_LIBS_SITE before I created the
respective folder. Apparently, R filters non-existent folders...

Cheers,
Sebastian


From joysn71 at gmail.com  Thu Sep 29 20:38:40 2016
From: joysn71 at gmail.com (Joysn71)
Date: Thu, 29 Sep 2016 20:38:40 +0200
Subject: [R] Closed list?
Message-ID: <1475174320.8790.1.camel@gmail.com>

Hello,

a few weeks ago i subscribed to this list and afterwards i send a question. I got a reply that my post needs moderator approval. It never happened.
Then i wrote to the list owners address. No reply.?

How can i proceed?

Thanks in advance,
Joysn


From msharp at txbiomed.org  Thu Sep 29 21:01:38 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Thu, 29 Sep 2016 19:01:38 +0000
Subject: [R] Closed list?
In-Reply-To: <1475174320.8790.1.camel@gmail.com>
References: <1475174320.8790.1.camel@gmail.com>
Message-ID: <74907512-31BE-428C-857F-840E085DF2FD@TxBiomed.org>

Its not closed. Have you read the posting guide?

Mark

R. Mark Sharp, Ph.D.
msharp at TxBiomed.org<mailto:msharp at txbiomed.org>





On Sep 29, 2016, at 1:38 PM, Joysn71 <joysn71 at gmail.com<mailto:joysn71 at gmail.com>> wrote:

Hello,

a few weeks ago i subscribed to this list and afterwards i send a question. I got a reply that my post needs moderator approval. It never happened.
Then i wrote to the list owners address. No reply.

How can i proceed?

Thanks in advance,
Joysn

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:13}}


From bryan.mac24 at gmail.com  Thu Sep 29 20:16:18 2016
From: bryan.mac24 at gmail.com (bryan.mac24)
Date: Thu, 29 Sep 2016 11:16:18 -0700
Subject: [R] Bootstrapping in R
Message-ID: <8yll8w2dbv57arprdpejteuf.1475172978687@email.android.com>

Hi all,
I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
Best,
BM
	[[alternative HTML version deleted]]


From david.paul at statmetrics.biz  Thu Sep 29 18:51:21 2016
From: david.paul at statmetrics.biz (David Paul)
Date: Thu, 29 Sep 2016 09:51:21 -0700
Subject: [R] plotting varclus( ) results
Message-ID: <00f101d21a71$b68b3a10$23a1ae30$@statmetrics.biz>

Hello,

 

I am running R on a Win7 operating system.  Many thanks in advance for any
help.

 

I am using

 

>library(Hmisc)

>library(rms)

>varclus.out <- varclus(~.,data=temp.df, sim = 'hoeffding')

>plot(varclus.out)

 

to generate a plot suitable for feature space dimension reduction.  Is it
possible

to modify the plot so variable names are color-coded?  For example, half of
the

variable names in red and half in blue.

 

 

Kind Regards,

 

     David Paul

 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: PGP.sig
Type: application/pgp-signature
Size: 842 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160929/6d166b22/attachment.bin>

From 538280 at gmail.com  Thu Sep 29 21:06:15 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 29 Sep 2016 13:06:15 -0600
Subject: [R] How to test a difference in ratios of count data in R
In-Reply-To: <YTXPR01MB0127D8E0719A2490E617B5F8A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
References: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
	<CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>
	<YTXPR01MB0127D8E0719A2490E617B5F8A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAFEqCdyBRbWne+00N8Oy4AxkdW5WfDtqFSmptoNwXX9S1Fd=Gg@mail.gmail.com>

It is usually best to keep these discussions on the list.  Someone
else may have a better answer than mine, or be able to respond
quicker, and if I answer on R-help then it is community
service/involvement.  If I respond directly then it is consulting and
then we need a contract and I have to charge you (not that I would see
the money myself, but it would help my budget be a little less red).

For your question, your fit4 and my fit2 are just 2 different ways of
fitting the exact same model to the exact same data, so there is no
surprise that the results match.  Which one to use is personal
preference.

The line that starts with "treatmentB" is the coefficient
(log-odds-ratio) for B compared to A, so that is the main line to look
at for interpretation.

The correlation of the fixed effects is mainly there for diagnostics,
if it is too close to -1 or 1 then that indicates that assumptions may
not hold, or computations may be in doubt.  Your value is not of
concern.


On Wed, Sep 28, 2016 at 2:14 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
> Hi Greg,
> Thank you very much for your help!
> I'd like to use glmer. From the output of summary(fit2) as below, Could I
> draw a conclusion that the treatment B
> significantly increases the counts of x group (p=6.11e-07)? I'm wondering if
> I could know that the treatment B
> significantly increases the ratio of x group (X/n) and how I could obtain
> the mean ratios of treatment A and B.
> To this end, should I fit the model using the ratio of X group (X/n)?  I
> tried it as
> fit4 <- glmer( X/n ~ treatment + (1|replicate), data=test, family=binomial,
> weights=n)
> but summary(fit4) is the same as summary(fit2).
> I also don't know how to interpret "Correlation of Fixed Effects: treatmentB
> -0.568 in the output.
>> summary(fit2)
> Generalized linear mixed model fit by maximum likelihood (Laplace
>   Approximation) [glmerMod]
>  Family: binomial  ( logit )
> Formula: cbind(X, n - X) ~ treatment + (1 | replicate)
>    Data: test
>
>      AIC      BIC   logLik deviance df.resid
>     30.1     29.4    -12.0     24.1        3
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -0.88757 -0.35065 -0.03137  0.26897  0.67505
>
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  replicate (Intercept) 0.4123   0.6421
> Number of obs: 6, groups:  replicate, 3
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -1.7442     0.5438  -3.208  0.00134 **
> treatmentB    2.3647     0.4741   4.988 6.11e-07 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>            (Intr)
> treatmentB -0.568
>
> Thanks again,
> Joshua
>
> ________________________________
> From: Greg Snow <538280 at gmail.com>
> Sent: Wednesday, September 28, 2016 12:49:49 PM
> To: Shuhua Zhan
> Cc: r-help at R-project.org
> Subject: Re: [R] How to test a difference in ratios of count data in R
>
> There are multiple ways of doing this, but here are a couple.
>
> To just test the fixed effect of treatment you can use the glm function:
>
> test <- read.table(text="
> replicate treatment n X
> 1 A 32 4
> 1 B 33 18
> 2 A 20 6
> 2 B 21 18
> 3 A 7 0
> 3 B 8 4
> ", header=TRUE)
>
> fit1 <- glm( cbind(X,n-X) ~ treatment, data=test, family=binomial)
> summary(fit1)
>
> Note that the default baseline value may differ between R and SAS,
> which would result in a reversed sign on the slope coefficient (and
> different intercept).
>
> To include replicate as a random effect you need an additional
> package, here I use lme4 and the glmer function:
>
> library(lme4)
> fit2 <- glmer( cbind(X, n-X) ~ treatment + (1|replicate), data=test,
> family=binomial)
> summary(fit2)
>
>
>
> On Tue, Sep 27, 2016 at 9:03 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
>> Hello R-experts,
>> I am interested to determine if the ratio of counts from two groups differ
>> across two distinct treatments. For example, we have three replicates of
>> treatment A, and three replicates of treatment B. For each treatment, we
>> have counts X from one group and counts Y from another group. My
>> understanding is that that GLIMMIX procedure in SAS can calculate whether
>> the ratio of counts in one group (X/X+Y) significantly differs between
>> treatments.
>>
>> I think this is the way you do it in SAS. The replicate and treatment
>> variables are self-explanatory. The first number (n) refers to the total
>> counts X + Y; the second number (X) refers to the counts X. Is there a way
>> to do this in R? Since we have 20,000 datasets to be tested, it may be
>> easier to retrive the significant test as the given dataset below and its
>> p>F value and mean ratios of treatments in R than SAS.
>>
>>
>> data test;
>> input replicate treatment$ n X;
>> datalines;
>> 1 A 32 4
>> 1 B 33 18
>> 2 A 20 6
>> 2 B 21 18
>> 3 A 7 0
>> 3 B 8 4
>> ;
>>
>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> run;
>>
>> ods select lsmeans;
>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> lsmeans treatment / cl ilink;
>> run;
>>
>> I appreciate your help in advance!
>> Joshua
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ruipbarradas at sapo.pt  Thu Sep 29 21:16:55 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 29 Sep 2016 20:16:55 +0100
Subject: [R] Bootstrapping in R
In-Reply-To: <8yll8w2dbv57arprdpejteuf.1475172978687@email.android.com>
Message-ID: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>

Hello,

Read the help page ?boot::boot.
For instance, try the following.


library(boot)

x <- rnorm(100)
stat <- function(x, f) mean(x[f])
boot(x, stat, R = 100)

Hope this helps,

Rui Barradas



Citando bryan.mac24 <bryan.mac24 at gmail.com>:

> Hi all,
> I am wondering how to conduct bootstrapping in R. I need bootstrap  
> 100 times. The trick I need to figure out is how to do get a random  
> sample of 100 out of the total number of case.
> Best,
> BM
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From utz.ryan at gmail.com  Thu Sep 29 21:29:58 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Thu, 29 Sep 2016 15:29:58 -0400
Subject: [R] Opening or activating a URL to access data,
	alternative to browseURL
Message-ID: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>

Hi all,

I've got a situation that involves activating a URL so that a link to some
data becomes available for download. I can easily use 'browseURL' to do so,
but I'm hoping to make this batch-process-able, and I would prefer to not
have 100s of browser windows open when I go to download multiple data sets.

Here's the example:

#1
browseURL('
http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:
')
# This opens the URL and creates a link to machine-readable data on the
page, which I can then download by simply doing this:

#2
read.delim('
http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt
')

However, I can only get the second line above to work if the thing in line
#1 has been opened in a browser already. Is there any way to allow me to
either 1) close the browser after it's been opened or 2) execute the line
#2 above without having to open a browser? We have hundreds of species that
you can see after the '&kind=' bit of the URL, so I'm trying to keep the
browsing situation sane.

Thanks!
R

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Thu Sep 29 21:35:17 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 29 Sep 2016 14:35:17 -0500
Subject: [R] remove a "corrupted file" after using download.file() with
 R on Windows 7
In-Reply-To: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
References: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
Message-ID: <1148b676-bf8e-4a55-7144-4f36586073e8@atsu.edu>

On 9/28/2016 11:32 PM, Fabien Tarrade wrote:
> Hi there,
>
> Sometime download.file() failed to download the file and I would like 
> to remove the correspond file.
No answers, but a couple of additional questions:
1)  Does the issue persist if you close R or does the file remain locked 
against deletion?
2) If so, is there a related process in the task list if you use 
CTRL-ALT-DEL?
3) Does       print(e$message) yield any useful information when it hangs?

Would debugging in R Studio shed additional light?

> The issue is that I am not able to do it and Windows complain that the 
> file is use by another application.
> I try to closeAllConnections(), or unlink() before removing the file 
> but without sucess.
>
> Any idea how I should proceed &
>
> Please find the code below
>
>  # consider warning as an error
>   options(warn=2)
>
>   # try to download the file
>   tryCatch({
>     download.file(url,path_file,mode="wb",quiet=quiet)
>     return(0)
>   },error = function(e){
>     if(verbose){
>       print(e)
>       print(e$message)
>     }
>     # close file when it failed
>     if (file.exists(path_file)){
>       closeAllConnections()
>       #unlink(path_file, recursive=TRUE)
>       #file.create(path_file,overwrite=TRUE,showWarning=TRUE)
>       #system(paste0('open "', path_file, '"'))
>       file.remove(path_file,overwrite=TRUE,showWarning=TRUE)
>     }
>     return(1)
>     }
> )
>
> Thanks a lot
> Cheers
> Fabien
>

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From bjpmodi2016 at gmail.com  Thu Sep 29 21:53:08 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Thu, 29 Sep 2016 14:53:08 -0500
Subject: [R] Optimization issue - Solution converges for any initial value
Message-ID: <CAPq=xQD983bACPVcyESFz-AUXi1OyUYKmdAH1m36+Zdu4kh-xw@mail.gmail.com>

I have put together a R snippet wherein I am trying to get optimum
values for which error is minimized. The error is the difference
between two matrices.
Every time I run the below code, I don't see any optimization
happening as in the final answer is the same as the initial estimate
regardless of what I mention as initial estimate.
Could you please advise on how can I improve it?
I have also tried using nloptr but to no avail.

To optimize vp.kval




my.data.matrix.prod <- matrix(a,nrow = length(a),1)
Estimated.Qt.mat <- matrix(b,nrow = nrow(my.data.matrix.prod), ncol = 1)
Cum.WInj.matrix <- matrix (c,nrow = nrow(my.data.matrix.prod), ncol = 1)
Koval.tD <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1)  # tD Matrix
Koval.fw <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1) # fw Matrix

Koval.Error.func <- function(vp.kval,n)
{
  #First convert vector(Koval.InitialData.list) to MATRIX and send it
to calculate estimated matrix

  Koval.InitialData.Matrix <- matrix(vp.kval,nrow = 2, 1,byrow = TRUE)
 # Define Koval Parameters Matrix for the "n"

  Qo.Koval <- Qo.Koval(Koval.InitialData.Matrix)  # Get Qo Estimation from Koval

  diff.values <- my.data.matrix.prod[,n] - Qo.Koval  #FIND DIFFERENCE
BETWEEN CAL. MATRIX AND ORIGINAL MATRIX

  Error <- ((colSums ((diff.values^2), na.rm = TRUE, dims =
1))/nrow(my.data.matrix.prod))^0.5    #sum of square root of the diff

  Error   # return error value
}

Qo.Koval <- function(Koval.InitialData.Matrix)
{
  Qo.Koval.Est <- matrix(,nrow(my.data.matrix.prod), 1)
#ncol(my.data.matrix.prod)

  for(rowno in 1:nrow(my.data.matrix.prod)) #number of rows of data
  {
    Koval.tD[rowno,1] = Cum.WInj.matrix[rowno,1] *
Koval.InitialData.Matrix[1,1]   # Evaluate tD matrix

    if(Koval.tD[rowno,1] < (1/Koval.InitialData.Matrix[2,1]))
    {
      Koval.fw[rowno,1] = 0
    }
    else
    {
      if(Koval.tD[rowno,1] > Koval.InitialData.Matrix[2,1])
      {
        Koval.fw[rowno,1] = 1
      }else
      {
        Koval.fw[rowno,1] = (Koval.InitialData.Matrix[2,1] -
sqrt(Koval.InitialData.Matrix[2,1]/Koval.tD[rowno,1]))/(Koval.InitialData.Matrix[2,1]-1)
      }
    }

    Qo.Koval.Est[rowno,1] = Koval.fw[rowno,1] * Estimated.Qt.mat[rowno,1]
  }

  Qo.Koval.Est    # Return Estimated matrix
}

vp.kval <- c(100000,1)  #initial estimate
Koval.lb = c(0,0)
Koval.ub = c(Inf,Inf)
n <- 1
Koval.result <- optim(vp.kval,Koval.Error.func, method = "L-BFGS-B",
lower = Koval.lb,
                     upper = Koval.ub, n=n)
print(paste(Koval.result$convergence))
print(paste(Koval.result$par))


Here is the input data:

a:

structure(c(414, 40, 639, 616, 677, 598, 586, 494, 322, 351,
322, 213, 395, 358, 406, 384, 409, 404, 370, 376, 412, 404, 369,
391, 341, 350, 349, 313, 302, 196, 386, 330, 350, 323, 454, 465,
465, 399, 416, 396, 453, 388, 496, 379, 472, 491, 492, 503, 516,
454, 630, 547, 578, 312, 764, 672, 548, 611, 546, 552, 520, 486,
581, 559, 433, 262, 650, 615, 542, 571, 542, 529, 577, 469, 557,
540, 546, 519, 376, 605, 520, 435, 299, 531, 538, 475, 511, 487,
490, 494, 537, 482, 438, 498, 312, 476, 383, 382), .Dim = c(98L,
1L), .Dimnames = list(NULL, "Q2"))

b:

structure(c(2342.12883525675, 2595.06229039124, 2715.2774272809,
2742.14586849367, 2678.48814516156, 2769.17482063132, 2809.26904957691,
2647.26143288146, 2142.48588931211, 1986.26692938822, 2417.80180308667,
2539.99173834861, 2889.68696098066, 2949.03395956634, 3345.265659123,
3178.09552101488, 3202.97894028497, 3294.04615708455, 3273.96002181006,
3290.59294404149, 3074.57078080845, 2809.00966959208, 2870.20594457832,
2994.89960881099, 3031.51083818418, 2838.72778780229, 2779.83367818986,
2471.70302686638, 2277.52074079803, 2313.67080371772, 2415.57558854185,
2593.57170885689, 2579.65222779155, 2542.47630393453, 2610.16334633228,
2715.1622580481, 2680.04491562794, 2676.08878142995, 2890.5657368073,
2939.98447437336, 2932.41354171428, 2699.29100102243, 2748.9757584712,
2885.90115387751, 2841.03004973532, 3111.28842226602, 3293.09352655985,
3448.16679970445, 3470.58231818316, 3077.6191619663, 2892.81263635983,
2563.00601428125, 2410.40833201752, 2696.80369889632, 3250.95996536945,
3900.33363068933, 3571.89127039948, 3569.09158205254, 3718.94141619046,
3963.05018539626, 4317.67764180387, 4143.2306512351, 4482.33003541385,
4313.47162218783, 4162.58533919444, 4119.75974744111, 4080.01960112015,
4146.78116940934, 3848.98992961189, 3507.00912988581, 3336.3269842557,
3691.50683899193, 3616.0923981163, 3325.14304882807, 3471.79805853069,
3229.60965194249, 3106.05768279943, 3184.66721766981, 3140.79657087168,
3242.97205541341, 3090.78617601495, 3086.74973135927, 3317.74000570974,
3594.90929884806, 3716.02759860505, 3622.91307702134, 3793.8518218782,
3666.82966979173, 3779.4557494045, 3750.98605852729, 3333.45681985961,
3057.22984206785, 3395.04273620089, 3623.47886822009, 3690.34495906538,
3827.97665203175, 3933.61679986677, 3762.82354740958), .Dim = c(98L,
1L))

c:

structure(c(2854.17262019504, 91576.5893971961, 171680.262910889,
257565.867448752, 335812.78671975, 424624.296030534, 510229.898689908,
586994.432148103, 636896.230541501, 691311.784820203, 780382.614051205,
860628.109248455, 961649.745761829, 1055011.51571743, 1162113.22730208,
1255164.70993334, 1352077.97513698, 1457172.94644257, 1554726.68952114,
1657279.26732716, 1745523.14071769, 1821000.62788843, 1911979.2340704,
2005954.86455037, 2101129.54803795, 2182822.62676551, 2258661.15941603,
2325202.52364728, 2387098.71588595, 2460005.26984465, 2535846.63352407,
2622071.03988945, 2701584.84087477, 2776628.22472118, 2859757.87551639,
2944689.28669068, 3026621.7086177, 3109451.02390273, 3200463.68736646,
3293220.09008416, 3380941.82063061, 3456992.53009029, 3541106.87910663,
3635049.74483035, 3721653.58199201, 3823940.56521733, 3931974.7704047,
4040554.293988, 4148875.73758196, 4231424.94909108, 4306157.82023537,
4374820.38189491, 4442080.07977206, 4535051.28823047, 4650928.35668784,
4793084.92990124, 4893067.57046614, 5000047.61946087, 5120237.59556207,
5247211.61097682, 5392662.33159569, 5515394.91894634, 5652397.35652795,
5780590.26125026, 5900471.93425283, 6026783.31719041, 6147868.09782702,
6278602.62144284, 6388178.16489299, 6482065.35854026, 6579907.11054506,
6702412.42037957, 6812043.87236422, 6905604.01572694, 7007786.71329603,
7099980.68361161, 7189071.57372477, 7290368.20702837, 7383139.53472758,
7487014.64958016, 7577849.79802546, 7670318.64215094, 7780726.13033402,
7897750.56237753, 8016910.17077053, 8126173.95193153, 8241923.12215802,
8351438.92663496, 8468551.68021943, 8583900.77567578, 8670079.97000769,
8755816.49103472, 8872115.39013376, 8988383.34061776, 9104971.76148562,
9224368.08502439, 9349766.5439318, 9460826.05419725), .Dim = c(98L,
1L))


From profjcnash at gmail.com  Thu Sep 29 22:47:20 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 29 Sep 2016 16:47:20 -0400
Subject: [R] Optimization issue - Solution converges for any initial
	value
In-Reply-To: <CAPq=xQD983bACPVcyESFz-AUXi1OyUYKmdAH1m36+Zdu4kh-xw@mail.gmail.com>
References: <CAPq=xQD983bACPVcyESFz-AUXi1OyUYKmdAH1m36+Zdu4kh-xw@mail.gmail.com>
Message-ID: <fb22eb0d-9e40-32d2-9b8a-716d7bff634f@gmail.com>

I haven't tried running your code, but a quick read suggests you should

1) set up the input data so your code can be run with source() without any preprocessing.
2) compute the function for several sets of parameters to make sure it is correct. Maybe
create a very simple test case you can more or less hand calculate as a check.
3) rescale the problem. You have the 1st parameter very large compared to the second
4) provide an analytic gradient -- item (3) suggests that the difference in scale of
the parameters could be causing very poor gradient approximations. It's quite possible
that optim() uses a quite simple forward difference approximation. For your problem,
I believe the analytic gradient is "simple" but very tedious.
5) once scaled, you could probably get away with using nmkb from dfoptim, which is a
Nelder-Mead method but with a form of bounds.
6) You might be able to use control$parscale to do the scaling. Do so carefully -- it
is easy to get the scaling the "wrong way round".

FYI, and that of others, there is a new package optimrx on r-forge (optimr on CRAN is
also available, but has few optimizers -- it is there so the name stays available).

http://download.r-forge.r-project.org/src/contrib/optimrx_2016-9.16.tar.gz or

http://download.r-forge.r-project.org/bin/windows/contrib/latest/optimrx_2016-9.16.zip

or https://r-forge.r-project.org/R/?group_id=395 for the project and Subversion access.
This has a function optimr() that uses the optim() syntax throughout for about 20
methods, and parscale control is available for all.

John Nash



On 16-09-29 03:53 PM, Narendra Modi wrote:
> I have put together a R snippet wherein I am trying to get optimum
> values for which error is minimized. The error is the difference
> between two matrices.
> Every time I run the below code, I don't see any optimization
> happening as in the final answer is the same as the initial estimate
> regardless of what I mention as initial estimate.
> Could you please advise on how can I improve it?
> I have also tried using nloptr but to no avail.
> 
> To optimize vp.kval
> 
> 
> 
> 
> my.data.matrix.prod <- matrix(a,nrow = length(a),1)
> Estimated.Qt.mat <- matrix(b,nrow = nrow(my.data.matrix.prod), ncol = 1)
> Cum.WInj.matrix <- matrix (c,nrow = nrow(my.data.matrix.prod), ncol = 1)
> Koval.tD <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1)  # tD Matrix
> Koval.fw <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1) # fw Matrix
> 
> Koval.Error.func <- function(vp.kval,n)
> {
>   #First convert vector(Koval.InitialData.list) to MATRIX and send it
> to calculate estimated matrix
> 
>   Koval.InitialData.Matrix <- matrix(vp.kval,nrow = 2, 1,byrow = TRUE)
>  # Define Koval Parameters Matrix for the "n"
> 
>   Qo.Koval <- Qo.Koval(Koval.InitialData.Matrix)  # Get Qo Estimation from Koval
> 
>   diff.values <- my.data.matrix.prod[,n] - Qo.Koval  #FIND DIFFERENCE
> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
> 
>   Error <- ((colSums ((diff.values^2), na.rm = TRUE, dims =
> 1))/nrow(my.data.matrix.prod))^0.5    #sum of square root of the diff
> 
>   Error   # return error value
> }
> 
> Qo.Koval <- function(Koval.InitialData.Matrix)
> {
>   Qo.Koval.Est <- matrix(,nrow(my.data.matrix.prod), 1)
> #ncol(my.data.matrix.prod)
> 
>   for(rowno in 1:nrow(my.data.matrix.prod)) #number of rows of data
>   {
>     Koval.tD[rowno,1] = Cum.WInj.matrix[rowno,1] *
> Koval.InitialData.Matrix[1,1]   # Evaluate tD matrix
> 
>     if(Koval.tD[rowno,1] < (1/Koval.InitialData.Matrix[2,1]))
>     {
>       Koval.fw[rowno,1] = 0
>     }
>     else
>     {
>       if(Koval.tD[rowno,1] > Koval.InitialData.Matrix[2,1])
>       {
>         Koval.fw[rowno,1] = 1
>       }else
>       {
>         Koval.fw[rowno,1] = (Koval.InitialData.Matrix[2,1] -
> sqrt(Koval.InitialData.Matrix[2,1]/Koval.tD[rowno,1]))/(Koval.InitialData.Matrix[2,1]-1)
>       }
>     }
> 
>     Qo.Koval.Est[rowno,1] = Koval.fw[rowno,1] * Estimated.Qt.mat[rowno,1]
>   }
> 
>   Qo.Koval.Est    # Return Estimated matrix
> }
> 
> vp.kval <- c(100000,1)  #initial estimate
> Koval.lb = c(0,0)
> Koval.ub = c(Inf,Inf)
> n <- 1
> Koval.result <- optim(vp.kval,Koval.Error.func, method = "L-BFGS-B",
> lower = Koval.lb,

>                      upper = Koval.ub, n=n)
> print(paste(Koval.result$convergence))
> print(paste(Koval.result$par))
> 
> 
> Here is the input data:
> 
> a:
> 
> structure(c(414, 40, 639, 616, 677, 598, 586, 494, 322, 351,
> 322, 213, 395, 358, 406, 384, 409, 404, 370, 376, 412, 404, 369,
> 391, 341, 350, 349, 313, 302, 196, 386, 330, 350, 323, 454, 465,
> 465, 399, 416, 396, 453, 388, 496, 379, 472, 491, 492, 503, 516,
> 454, 630, 547, 578, 312, 764, 672, 548, 611, 546, 552, 520, 486,
> 581, 559, 433, 262, 650, 615, 542, 571, 542, 529, 577, 469, 557,
> 540, 546, 519, 376, 605, 520, 435, 299, 531, 538, 475, 511, 487,
> 490, 494, 537, 482, 438, 498, 312, 476, 383, 382), .Dim = c(98L,
> 1L), .Dimnames = list(NULL, "Q2"))
> 
> b:
> 
> structure(c(2342.12883525675, 2595.06229039124, 2715.2774272809,
> 2742.14586849367, 2678.48814516156, 2769.17482063132, 2809.26904957691,
> 2647.26143288146, 2142.48588931211, 1986.26692938822, 2417.80180308667,
> 2539.99173834861, 2889.68696098066, 2949.03395956634, 3345.265659123,
> 3178.09552101488, 3202.97894028497, 3294.04615708455, 3273.96002181006,
> 3290.59294404149, 3074.57078080845, 2809.00966959208, 2870.20594457832,
> 2994.89960881099, 3031.51083818418, 2838.72778780229, 2779.83367818986,
> 2471.70302686638, 2277.52074079803, 2313.67080371772, 2415.57558854185,
> 2593.57170885689, 2579.65222779155, 2542.47630393453, 2610.16334633228,
> 2715.1622580481, 2680.04491562794, 2676.08878142995, 2890.5657368073,
> 2939.98447437336, 2932.41354171428, 2699.29100102243, 2748.9757584712,
> 2885.90115387751, 2841.03004973532, 3111.28842226602, 3293.09352655985,
> 3448.16679970445, 3470.58231818316, 3077.6191619663, 2892.81263635983,
> 2563.00601428125, 2410.40833201752, 2696.80369889632, 3250.95996536945,
> 3900.33363068933, 3571.89127039948, 3569.09158205254, 3718.94141619046,
> 3963.05018539626, 4317.67764180387, 4143.2306512351, 4482.33003541385,
> 4313.47162218783, 4162.58533919444, 4119.75974744111, 4080.01960112015,
> 4146.78116940934, 3848.98992961189, 3507.00912988581, 3336.3269842557,
> 3691.50683899193, 3616.0923981163, 3325.14304882807, 3471.79805853069,
> 3229.60965194249, 3106.05768279943, 3184.66721766981, 3140.79657087168,
> 3242.97205541341, 3090.78617601495, 3086.74973135927, 3317.74000570974,
> 3594.90929884806, 3716.02759860505, 3622.91307702134, 3793.8518218782,
> 3666.82966979173, 3779.4557494045, 3750.98605852729, 3333.45681985961,
> 3057.22984206785, 3395.04273620089, 3623.47886822009, 3690.34495906538,
> 3827.97665203175, 3933.61679986677, 3762.82354740958), .Dim = c(98L,
> 1L))
> 
> c:
> 
> structure(c(2854.17262019504, 91576.5893971961, 171680.262910889,
> 257565.867448752, 335812.78671975, 424624.296030534, 510229.898689908,
> 586994.432148103, 636896.230541501, 691311.784820203, 780382.614051205,
> 860628.109248455, 961649.745761829, 1055011.51571743, 1162113.22730208,
> 1255164.70993334, 1352077.97513698, 1457172.94644257, 1554726.68952114,
> 1657279.26732716, 1745523.14071769, 1821000.62788843, 1911979.2340704,
> 2005954.86455037, 2101129.54803795, 2182822.62676551, 2258661.15941603,
> 2325202.52364728, 2387098.71588595, 2460005.26984465, 2535846.63352407,
> 2622071.03988945, 2701584.84087477, 2776628.22472118, 2859757.87551639,
> 2944689.28669068, 3026621.7086177, 3109451.02390273, 3200463.68736646,
> 3293220.09008416, 3380941.82063061, 3456992.53009029, 3541106.87910663,
> 3635049.74483035, 3721653.58199201, 3823940.56521733, 3931974.7704047,
> 4040554.293988, 4148875.73758196, 4231424.94909108, 4306157.82023537,
> 4374820.38189491, 4442080.07977206, 4535051.28823047, 4650928.35668784,
> 4793084.92990124, 4893067.57046614, 5000047.61946087, 5120237.59556207,
> 5247211.61097682, 5392662.33159569, 5515394.91894634, 5652397.35652795,
> 5780590.26125026, 5900471.93425283, 6026783.31719041, 6147868.09782702,
> 6278602.62144284, 6388178.16489299, 6482065.35854026, 6579907.11054506,
> 6702412.42037957, 6812043.87236422, 6905604.01572694, 7007786.71329603,
> 7099980.68361161, 7189071.57372477, 7290368.20702837, 7383139.53472758,
> 7487014.64958016, 7577849.79802546, 7670318.64215094, 7780726.13033402,
> 7897750.56237753, 8016910.17077053, 8126173.95193153, 8241923.12215802,
> 8351438.92663496, 8468551.68021943, 8583900.77567578, 8670079.97000769,
> 8755816.49103472, 8872115.39013376, 8988383.34061776, 9104971.76148562,
> 9224368.08502439, 9349766.5439318, 9460826.05419725), .Dim = c(98L,
> 1L))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Sep 29 22:47:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 29 Sep 2016 13:47:54 -0700
Subject: [R] Architect from Open Analytics
In-Reply-To: <1473515476.27497.9.camel@gmail.com>
References: <1473515476.27497.9.camel@gmail.com>
Message-ID: <4CBDC152-728B-457C-B352-26E0221930C4@comcast.net>

Your message with a subject heading of "Architect from Open Analytics" appeared on the list on Sept 10. As far as I can tell it got no replies.)  If there was another posting, then you need to submit details sufficient to investigate. All postings by first time posters get moderated. If you use the same email address that you subscribed with then subsequent postings should not be moderated (and I do not think this most recent one was because I have been monitoring the moderation queue frequently today and never saw this one.

-- 
David.


> On Sep 10, 2016, at 6:51 AM, Joysn71 <joysn71 at gmail.com> wrote:
> 
> Hello,
> 
> i am new to R and try to use Architect from Open Analytics (0.9.8 on
> Debian 64bit). 
> 
> Is anybody on this list using this tool?
> I am asking because it seems to have lots of problems, like:
> 
> * not possible to open the package manager
> * not possible to open details from the "About Architect" dialog
> * some commands not supported
> 
>> a <- c(1:10)
>> a
>  [1]  1  2  3  4  5  6  7  8  9 10
>> data.entry(a)
> Error in dataentry(odata, as.list(Modes)) : 
>   X11 dataentry cannot be loaded
> In addition: Warning message:
> In dataentry(odata, as.list(Modes)) :
>   unable to load shared object
> '/opt/architect/stable/20160518101101/plugins/eu.openanalytics.architec
> t.r.server.gtk.linux.x86_64_0.9.8.201511181238/R/modules//R_de.so':
>   libpng12.so.0: cannot open shared object file: No such file or
> directory
> 
> Problems with Eclipse UI:
> 
> eclipse.buildId=unknown
> java.version=1.8.0_102
> java.vendor=Oracle Corporation
> BootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_GB
> Command-line arguments:  -data file:/home/chris/.architect/workspace/
> -os linux -ws gtk -arch x86_64
> 
> org.eclipse.ui
> Error
> Sat Sep 10 15:09:55 CEST 2016
> Unhandled event loop exception
> 
> java.lang.NullPointerException
> 	at
> org.eclipse.swt.widgets.TabFolder.gtk_switch_page(TabFolder.java:490)
> 	at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:2009)
> 	at
> org.eclipse.swt.widgets.Display.windowProc(Display.java:4723)
> 	at org.eclipse.swt.internal.gtk.OS._gtk_widget_show(Native
> Method)
> 	at
> org.eclipse.swt.internal.gtk.OS.gtk_widget_show(OS.java:14727)
> 	at
> org.eclipse.swt.widgets.TabFolder.createItem(TabFolder.java:274)
> 	at
> org.eclipse.swt.widgets.TabItem.createWidget(TabItem.java:123)
> 	at org.eclipse.swt.widgets.TabItem.<init>(TabItem.java:75)
> 	at
> de.walware.statet.r.internal.ui.pkgmanager.RPkgManagerDialog.createDial
> ogContent(RPkgManagerDialog.java:151)
> 	at
> de.walware.statet.nico.ui.util.ToolDialog.createDialogArea(ToolDialog.j
> ava:99)
> 	at
> org.eclipse.jface.dialogs.TitleAreaDialog.createContents(TitleAreaDialo
> g.java:161)
> 	at
> de.walware.statet.r.internal.ui.pkgmanager.RPkgManagerDialog.createCont
> ents(RPkgManagerDialog.java:113)
> 	at org.eclipse.jface.window.Window.create(Window.java:430)
> 	at org.eclipse.jface.dialogs.Dialog.create(Dialog.java:1096)
> 	at org.eclipse.jface.window.Window.open(Window.java:792)
> 
> Maybe somebody has some experience with Architect, any hint is
> appreciated :)
> 
> BR
> Joysn
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Thu Sep 29 22:53:12 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Sep 2016 16:53:12 -0400
Subject: [R] Closed list?
In-Reply-To: <1475174320.8790.1.camel@gmail.com>
References: <1475174320.8790.1.camel@gmail.com>
Message-ID: <0acf83fe-6ff1-dadf-2453-c277a763f293@gmail.com>

On 29/09/2016 2:38 PM, Joysn71 wrote:
> Hello,
>
> a few weeks ago i subscribed to this list and afterwards i send a question. I got a reply that my post needs moderator approval. It never happened.
> Then i wrote to the list owners address. No reply.
>
> How can i proceed?

I see a post from you with subject "[R] Architect from Open Analytics" 
on Sept 10.  No responses to it; I guess nobody else uses that package.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Sep 29 22:59:16 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Sep 2016 16:59:16 -0400
Subject: [R] Opening or activating a URL to access data,
 alternative to browseURL
In-Reply-To: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
References: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
Message-ID: <0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>

On 29/09/2016 3:29 PM, Ryan Utz wrote:
> Hi all,
>
> I've got a situation that involves activating a URL so that a link to some
> data becomes available for download. I can easily use 'browseURL' to do so,
> but I'm hoping to make this batch-process-able, and I would prefer to not
> have 100s of browser windows open when I go to download multiple data sets.
>
> Here's the example:
>
> #1
> browseURL('
> http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:
> ')
> # This opens the URL and creates a link to machine-readable data on the
> page, which I can then download by simply doing this:
>
> #2
> read.delim('
> http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt
> ')
>
> However, I can only get the second line above to work if the thing in line
> #1 has been opened in a browser already. Is there any way to allow me to
> either 1) close the browser after it's been opened or 2) execute the line
> #2 above without having to open a browser? We have hundreds of species that
> you can see after the '&kind=' bit of the URL, so I'm trying to keep the
> browsing situation sane.
>
> Thanks!
> R
>

You'll need to figure out what happens when you open the first page. 
Does it set a cookie?  Does it record your IP address?  Does it just 
build the file but record nothing about you?

If it's one of the simpler versions, you can just read the first page, 
wait a bit, then read the second one.

If you need to manage cookies, you'll need something more complicated. 
I don't know the easiest way to do that.

Duncan Murdoch


From bob at rud.is  Thu Sep 29 23:09:31 2016
From: bob at rud.is (Bob Rudis)
Date: Thu, 29 Sep 2016 17:09:31 -0400
Subject: [R] Opening or activating a URL to access data,
	alternative to browseURL
In-Reply-To: <0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>
References: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
	<0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>
Message-ID: <CAA-FpKVRRZtYtBeKiYHpz9VUW5kZaJ_qiFjeg+TQTCTQ=7rwbA@mail.gmail.com>

The rvest/httr/curl trio can do the cookie management pretty well. Make the
initial connection via rvest::html_session() and then hopefully be able to
use other rvest function calls, but curl and httr calls will use the cached
in-memory handle info seamlessly. You'd need to store and retrieve cookies
if you need them preserved between R sessions.

Failing the above and assuming this would not need to be lightning fast,
use the phantomjs or firefox web driver (either with RSelenium or some new
stuff rOpenSci is cooking up) which will then do what browsers do best and
maintain all this state for you. You can still slurp the page contents up
with xml2::read_html() and use the super handy processing idioms in the
scraping tidyverse (it needs it's own name).

A concrete example (assuming the URLs aren't sensitive) would enable me or
someone else to mock up something for you.


On Thu, Sep 29, 2016 at 4:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 29/09/2016 3:29 PM, Ryan Utz wrote:
>
>> Hi all,
>>
>> I've got a situation that involves activating a URL so that a link to some
>> data becomes available for download. I can easily use 'browseURL' to do
>> so,
>> but I'm hoping to make this batch-process-able, and I would prefer to not
>> have 100s of browser windows open when I go to download multiple data
>> sets.
>>
>> Here's the example:
>>
>> #1
>> browseURL('
>> http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia
>> +fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:
>> ')
>> # This opens the URL and creates a link to machine-readable data on the
>> page, which I can then download by simply doing this:
>>
>> #2
>> read.delim('
>> http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-
>> 83.3_2011,2012,2013.txt
>> ')
>>
>> However, I can only get the second line above to work if the thing in line
>> #1 has been opened in a browser already. Is there any way to allow me to
>> either 1) close the browser after it's been opened or 2) execute the line
>> #2 above without having to open a browser? We have hundreds of species
>> that
>> you can see after the '&kind=' bit of the URL, so I'm trying to keep the
>> browsing situation sane.
>>
>> Thanks!
>> R
>>
>>
> You'll need to figure out what happens when you open the first page. Does
> it set a cookie?  Does it record your IP address?  Does it just build the
> file but record nothing about you?
>
> If it's one of the simpler versions, you can just read the first page,
> wait a bit, then read the second one.
>
> If you need to manage cookies, you'll need something more complicated. I
> don't know the easiest way to do that.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cls3415 at gmail.com  Fri Sep 30 02:58:28 2016
From: cls3415 at gmail.com (SH.Chou)
Date: Thu, 29 Sep 2016 20:58:28 -0400
Subject: [R] How to integrate UMLS to opennlp or NLP package in R
Message-ID: <CAAtNTa7w+X5LuBjxqHL7ehWHs77pA54OTpc476EvqvaF2JT4oQ@mail.gmail.com>

Hi,
I am trying to use R's opennlp package with UMLS (Unified Medical Language
System, https://www.nlm.nih.gov/research/umls/) to analyze physician's
notes, but I couldn't find any hint from Google. Any idea how I can achieve
this goal or any tutorials/books/websites I missed? Thanks!

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Sep 30 04:22:15 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 29 Sep 2016 19:22:15 -0700
Subject: [R] remove a "corrupted file" after using download.file() with
 R on Windows 7
In-Reply-To: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
References: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
Message-ID: <CAFDcVCQruAP-rdYbDxRVOUqZ6n5CKxdGY+T=ZF11HZbbMAHLVQ@mail.gmail.com>

1. It could be that a virus checker locks the file.

2. There are Windows software tools that identify which process locks
a particular file, e.g. LockHunter (http://lockhunter.com/).  Those
should help you figure out what's going on.

3. R.utils::downloadFile() tries it's best to download files
atomically, i.e. it either gives you a fully downloaded file or not
all.  In your case, you might still end up with a temporary corrupt
file, but at least it will have a filename that is different than the
one you ask for.

Hope this helps

/Henrik

On Wed, Sep 28, 2016 at 9:32 PM, Fabien Tarrade
<fabien.tarrade at gmail.com> wrote:
> Hi there,
>
> Sometime download.file() failed to download the file and I would like to
> remove the correspond file.
> The issue is that I am not able to do it and Windows complain that the file
> is use by another application.
> I try to closeAllConnections(), or unlink() before removing the file but
> without sucess.
>
> Any idea how I should proceed &
>
> Please find the code below
>
>  # consider warning as an error
>   options(warn=2)
>
>   # try to download the file
>   tryCatch({
>     download.file(url,path_file,mode="wb",quiet=quiet)
>     return(0)
>   },error = function(e){
>     if(verbose){
>       print(e)
>       print(e$message)
>     }
>     # close file when it failed
>     if (file.exists(path_file)){
>       closeAllConnections()
>       #unlink(path_file, recursive=TRUE)
>       #file.create(path_file,overwrite=TRUE,showWarning=TRUE)
>       #system(paste0('open "', path_file, '"'))
>       file.remove(path_file,overwrite=TRUE,showWarning=TRUE)
>     }
>     return(1)
>     }
> )
>
> Thanks a lot
> Cheers
> Fabien
>
> --
> Dr Fabien Tarrade
>
> Quantitative Analyst/Developer - Data Scientist
>
> Senior data analyst specialised in the modelling, processing and statistical
> treatment of data.
> PhD in Physics, 10 years of experience as researcher at the forefront of
> international scientific research.
> Fascinated by finance and data modelling.
>
> Geneva, Switzerland
>
> Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
> Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
> Phone : +33 (0)6 14 78 70 90
>
> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
> <https://twitter.com/fabtar> Google
> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
> Xing <https://www.xing.com/profile/Fabien_Tarrade>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From markleeds2 at gmail.com  Fri Sep 30 05:57:54 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 29 Sep 2016 23:57:54 -0400
Subject: [R] Closed list?
In-Reply-To: <0acf83fe-6ff1-dadf-2453-c277a763f293@gmail.com>
References: <1475174320.8790.1.camel@gmail.com>
	<0acf83fe-6ff1-dadf-2453-c277a763f293@gmail.com>
Message-ID: <CAHz+bWZO3=0o4+VeaH96_c-k9V_msgYkDT+cFe9=6ZwK_p8bDg@mail.gmail.com>

someone who moderates the list, myself included, may have mistakened it for
spam and rejected it. In that case, it never got to the list.



On Thu, Sep 29, 2016 at 4:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 29/09/2016 2:38 PM, Joysn71 wrote:
>
>> Hello,
>>
>> a few weeks ago i subscribed to this list and afterwards i send a
>> question. I got a reply that my post needs moderator approval. It never
>> happened.
>> Then i wrote to the list owners address. No reply.
>>
>> How can i proceed?
>>
>
> I see a post from you with subject "[R] Architect from Open Analytics" on
> Sept 10.  No responses to it; I guess nobody else uses that package.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Sep 30 06:32:43 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 30 Sep 2016 00:32:43 -0400
Subject: [R] Replacing value with "1"
In-Reply-To: <alpine.BSF.2.00.1609230923140.12422@pedal.dcn.davis.ca.us>
References: <593128637.115496.1474597677212.ref@mail.yahoo.com>
	<593128637.115496.1474597677212@mail.yahoo.com>
	<CA+8X3fVH_AgGqbj8AK6YrbApzGsr9+RgYkWHpXfQFKmLHSy=zA@mail.gmail.com>
	<CAFDcVCTXub_mXLYrAb_tMZs97HFRv0m591X7=VWpHOH3c-Qs5Q@mail.gmail.com>
	<alpine.BSF.2.00.1609230923140.12422@pedal.dcn.davis.ca.us>
Message-ID: <CAGx1TMAShmamaLstkoA-b47+PbnxJA+fHCezTwOkaX+-nQRr+A@mail.gmail.com>

I got the matrix time down by another factor of 4

tmp <- matrix(c(0,0,1,0,0,
                NA,0,1,1,0,
                0,1,0,0,NA,
                1,0,1,0,1), ## last item in row has value 1
              byrow=TRUE, 4, 5)


## Jeff matrix
DF2 <- DF <- tmp
DF2[ , -1 ] <- ifelse(   !is.na( DF[ , -ncol( DF ) ] )
                       & 1 == DF[ , -ncol( DF ) ]
                     , 1
                     , DF[ , -1 ]
                     )
DF2
##
system.time( for (i in 1:1000) {
DF2[ , -1 ] <- ifelse(   !is.na( DF[ , -ncol( DF ) ] )
                       & 1 == DF[ , -ncol( DF ) ]
                     , 1
                     , DF[ , -1 ]
                     )
})
##   user  system elapsed
##  0.027   0.001   0.029



## rmh matrix
DF <- tmp
DF[,-1][(DF[,-ncol(DF)] == 1)] <- 1
DF
##
system.time( for (i in 1:1000) {
DF[,-1][(DF[,-ncol(DF)] == 1)] <- 1
})
##   user  system elapsed
##  0.007   0.000   0.006

On Fri, Sep 23, 2016 at 12:25 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Another approach using in-place replacement and thinking with matrix
> operations instead of vector operations:
>
> DF <- matrix( c( 0,  0, 1, 0, 0
>                , NA, 0, 1, 1, 0
>                , 0,  1, 0, 0, NA )
>             , byrow=TRUE
>             , nrow=3 )
> DF2 <- DF
> DF2[ , -1 ] <- ifelse(   !is.na( DF[ , -ncol( DF ) ] )
>                        & 1 == DF[ , -ncol( DF ) ]
>                      , 1
>                      , DF[ , -1 ]
>                      )
>
>
> On Thu, 22 Sep 2016, Henrik Bengtsson wrote:
>
>> which(df == 1, arr.ind=TRUE) is useful here:
>>
>>> df <- matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA), nrow=3)
>>> df
>>
>>     [,1] [,2] [,3] [,4] [,5]
>> [1,]    0    0    1    0    0
>> [2,]   NA    0    1    1    0
>> [3,]    0    1    0    0   NA
>>
>>> ## Identify (row,col) indices for 1:s
>>> idxs <- which(df == 1, arr.ind=TRUE)
>>> idxs
>>
>>     row col
>> [1,]   3   2
>> [2,]   1   3
>> [3,]   2   3
>> [4,]   2   4
>>
>>> ## Drop any in the last column
>>> idxs <- idxs[idxs[,"col"] < ncol(df), , drop=FALSE]
>>> idxs
>>
>>     row col
>> [1,]   3   2
>> [2,]   1   3
>> [3,]   2   3
>> [4,]   2   4
>>
>>> idxs[,"col"] <- idxs[,"col"] + 1L
>>> idxs
>>
>>     row col
>> [1,]   3   3
>> [2,]   1   4
>> [3,]   2   4
>> [4,]   2   5
>>
>>> df[idxs] <- 1
>>> df
>>
>>     [,1] [,2] [,3] [,4] [,5]
>> [1,]    0    0    1    1    0
>> [2,]   NA    0    1    1    1
>> [3,]    0    1    1    0   NA
>>
>> /Henrik
>>
>> On Thu, Sep 22, 2016 at 8:13 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Saba,
>>> Try this:
>>>
>>> df<-matrix(c(0,NA,0,0,0,1,1,1,0,0,1,0,0,0,NA),nrow=3)
>>> dimdf<-dim(df)
>>> df1<-df==1
>>> df[cbind(rep(FALSE,dimdf[1]),df1[,-dimdf[2]])]<-1
>>>
>>> Jim
>>>
>>>
>>>
>>> On Fri, Sep 23, 2016 at 12:27 PM, Saba Sehrish via R-help
>>> <r-help at r-project.org> wrote:
>>>>
>>>> Hi
>>>>
>>>> I have a matrix that contains 1565 rows and 132 columns. All the
>>>> observations are either "0" or "1". Now I want to keep all the observations
>>>> same but just one change, i.e. whenever there is "1", the very next value in
>>>> the same row should become "1". Please see below as a sample:
>>>>
>>>>> df
>>>>
>>>>
>>>>      0    0    1    0    0
>>>>     NA    0    1    1    0
>>>>      0    1    0    0    NA
>>>>
>>>> What I want is:
>>>>
>>>>
>>>>     0    0    1    1    0
>>>>    NA    0    1    1    1
>>>>     0    1    1    0    NA
>>>>
>>>>
>>>>
>>>> I shall be thankful for the reply.
>>>>
>>>>
>>>> Saba
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Sep 30 06:37:38 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 29 Sep 2016 21:37:38 -0700
Subject: [R] Closed list?
In-Reply-To: <CAHz+bWZO3=0o4+VeaH96_c-k9V_msgYkDT+cFe9=6ZwK_p8bDg@mail.gmail.com>
References: <1475174320.8790.1.camel@gmail.com>
	<0acf83fe-6ff1-dadf-2453-c277a763f293@gmail.com>
	<CAHz+bWZO3=0o4+VeaH96_c-k9V_msgYkDT+cFe9=6ZwK_p8bDg@mail.gmail.com>
Message-ID: <2449A741-9C3C-4CBC-B742-B2A96F90F94F@comcast.net>


> On Sep 29, 2016, at 8:57 PM, Mark Leeds <markleeds2 at gmail.com> wrote:
> 
> someone who moderates the list, myself included, may have mistakened it for
> spam and rejected it. In that case, it never got to the list.
> 

I think the post was accepted and the poster just doesn't realize it:

https://stat.ethz.ch/pipermail/r-help/2016-September/441702.html

(I think I was the one who approved it two weeks+ ago.)

-- 
David.
> 
> 
> On Thu, Sep 29, 2016 at 4:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 29/09/2016 2:38 PM, Joysn71 wrote:
>> 
>>> Hello,
>>> 
>>> a few weeks ago i subscribed to this list and afterwards i send a
>>> question. I got a reply that my post needs moderator approval. It never
>>> happened.
>>> Then i wrote to the list owners address. No reply.
>>> 
>>> How can i proceed?
>>> 
>> 
>> I see a post from you with subject "[R] Architect from Open Analytics" on
>> Sept 10.  No responses to it; I guess nobody else uses that package.
>> 
>> Duncan Murdoch
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From markleeds2 at gmail.com  Fri Sep 30 06:39:05 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 30 Sep 2016 00:39:05 -0400
Subject: [R] Closed list?
In-Reply-To: <2449A741-9C3C-4CBC-B742-B2A96F90F94F@comcast.net>
References: <1475174320.8790.1.camel@gmail.com>
	<0acf83fe-6ff1-dadf-2453-c277a763f293@gmail.com>
	<CAHz+bWZO3=0o4+VeaH96_c-k9V_msgYkDT+cFe9=6ZwK_p8bDg@mail.gmail.com>
	<2449A741-9C3C-4CBC-B742-B2A96F90F94F@comcast.net>
Message-ID: <CAHz+bWaZzvL7pt8bfUyTK=mhS3fPxFMt6NuOpbV5FHE3-MncBQ@mail.gmail.com>

my bad david. thanks for info.

On Fri, Sep 30, 2016 at 12:37 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 29, 2016, at 8:57 PM, Mark Leeds <markleeds2 at gmail.com> wrote:
> >
> > someone who moderates the list, myself included, may have mistakened it
> for
> > spam and rejected it. In that case, it never got to the list.
> >
>
> I think the post was accepted and the poster just doesn't realize it:
>
> https://stat.ethz.ch/pipermail/r-help/2016-September/441702.html
>
> (I think I was the one who approved it two weeks+ ago.)
>
> --
> David.
> >
> >
> > On Thu, Sep 29, 2016 at 4:53 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> > wrote:
> >
> >> On 29/09/2016 2:38 PM, Joysn71 wrote:
> >>
> >>> Hello,
> >>>
> >>> a few weeks ago i subscribed to this list and afterwards i send a
> >>> question. I got a reply that my post needs moderator approval. It never
> >>> happened.
> >>> Then i wrote to the list owners address. No reply.
> >>>
> >>> How can i proceed?
> >>>
> >>
> >> I see a post from you with subject "[R] Architect from Open Analytics"
> on
> >> Sept 10.  No responses to it; I guess nobody else uses that package.
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From daj025 at gmail.com  Fri Sep 30 16:26:27 2016
From: daj025 at gmail.com (David James)
Date: Fri, 30 Sep 2016 10:26:27 -0400
Subject: [R] isssues with predict.coxph, offset, type = "expected",
	and newdata?
Message-ID: <CAFuGCESU3DxUr2NvsEfzMhTgHQGDmwetw9+56-q17PMj6f_u6A@mail.gmail.com>

Hi,

It seems there might be two issues with predict.coxph(), and I'd
appreciate confirmation before submitting a bug report to the package
author.

(1)  predict() seems to produce incorrect predictions when using type
= "expected" from a Cox model with an offset and specifying a new data
for prediction (see Example 1 below).

(2)  predict() produces an error for a call with a null model and a
newdata= argument (see Example 2 below).

Please note that I didn't check these cases with additional
complications, like strata(), cluster(), etc.

SessionInfo() at the bottom of this email (notice I'm using survival
2.39-5, the current version in CRAN).

Thanks,

David

--------------------------------------------------------------------------------------------------------------

Example 1

> library("survival")
> data(lung)
>
> # simulate a three-fold genetic effect (worsening)
> set.seed(123)
> lung$gene.eff <- sample(log(c(1, 3)), size=nrow(lung), replace=TRUE, prob=c(0.5, 0.5))
>
> # fix the gene effect, do not estimate it
> m1 <- coxph(Surv(time, status) ~ age + sex + offset(gene.eff), data = lung)
>
> # two hypothetical individuals differing only on gene.eff
> nd <- expand.grid(time=180, status=1, age=65, sex=1, gene.eff=log(c(1,3)))
>
> p1.lp <- predict(m1, newdata = nd, type = "lp")
> p1.rsk <- predict(m1, newdata = nd, type = "risk")
> p1.exp <- predict(m1, newdata = nd, type = "expected")
>
> # output from type "lp" (linear predictor) and "risk" are ok,
> # but not from type "expected"
> all.equal(3, exp(p1.lp[2]-p1.lp[1]), check.names = FALSE)
[1] TRUE
> all.equal(3, p1.rsk[2]/p1.rsk[1], check.names = FALSE)
[1] TRUE
> all.equal(3, p1.exp[2]/p1.exp[1], check.names = FALSE)
[1] "Mean relative difference: 0.6666667"
>
> # notice that predict() produces the same expected number of
> # events for both hypothetical individuals
> print(p1.exp)
[1] 0.1882663 0.1882663


Example 2

> # null model
> m0 <- coxph(Surv(time, status) ~ 1, data = lung)
>
> # time points at which we want predictions
> nd <- data.frame(time=seq(from=0, to=360, by=30), status=rep(1, 13))
>
> # predictions are produced for types "lp" and "risk", but not "expected"
> p0.lp <- predict(m0, type="lp", newdata = nd)
> p0.rsk <- predict(m0, type="risk", newdata = nd)
> p0.exp <- predict(m0, type="expected", newdata = nd)
Error in newx %*% object$coef :
  requires numeric/complex matrix/vector arguments
>

Session Info:

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] survival_2.39-5

loaded via a namespace (and not attached):
[1] Matrix_1.2-6    tools_3.3.1     splines_3.3.1   grid_3.3.1
lattice_0.20-33


From kynnjo at gmail.com  Fri Sep 30 16:36:12 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Fri, 30 Sep 2016 10:36:12 -0400
Subject: [R] How to implement "zero-overhead" code re-use (a la Python, Perl,
 etc.) in R?
Message-ID: <CAFvQaj6+Vi_HW1-oNyqRygLG1r1aHXhy1H=4A-TuzS=VdgrTjg@mail.gmail.com>

I'm collaborating in a long-running research project that, over the
years, has accummulated source code (written in-house) in several
languages: Python, Perl, Mathematica, MATLAB.

Recently I have started writing source code in R for this project, and
I am having trouble incorporating it into our established work flow.

Our code falls into two broad categories: "scripts" (invoked directly
by the user) and "libraries" (invoked by "client code", i.e. scripts
or other library code).

The library code lives under the top-level subdirectory ./lib of the
git-controlled project directory.  (We keep all our code, along with
the rest of the project's documents, under git control.)

Users of client programs of the code under ./lib are expected to
supply (usually via some global configuration) the appropriate library
path (.e.g PYTHONPATH=$PROJECTDIR/lib/python,
MATLABPATH=$PROJECTDIR/lib/MATLAB, etc.).

With this arrangement, code re-use is extremely simple.  For example,
by just dropping into the ./lib/python directory the file foo.py, with
content

    # foo.py
    def bar():
        # etc.

...its bar function becomes *immediately* available, in a
namespace-safe way, to any other python code in the project, like
this:

    # somescript.py

    import foo

    foo.bar()

I describe this form of code re-use as "zero-overhead", since it
requires only the presence of files that actually hold the code.

Under such a code re-use scheme, updates of library code from the
project's git repo are no different from updates of the project's
content in general.  All that is required is running a command like

    git pull origin master

After such a command, the updated library code becomes immediately
available to client code.

Although I used Python for the example above, the picture is very
similar for the other languages we have been using up to now.

For R, however, the situation is different.  The only form of code
re-use I have found for R is through packages.  AFAICT, R packages are
not "zero-overhead": they entail a host of "meta" and derived files
(in addition to the source code files), together with
build/installation steps after each update.

I'm looking for an alternative to packages for code re-use in R, one
that better approximates the "zero-overhead" code re-use model
described earlier.

The only thing that comes to mind is as follows:

  1. a "module" is an *.R file in the directory specified a suitable
environment variable (e.g. PROJECT_R_LIB), and defining a single
"module object", which is simply a named list.  For example,

    # module foo.R

    foo <- list(
      bar = function (...) ... ,
      baz = function (...) ... ,
      frobozz = function (...) ... ,
      ...
      opts = list(...),
      ...
    )

  2. every *.R file starts with boilerplate in the spirit of the
following (along with adequate error checking/messages, etc.):

    # somescript.R

    import <- function (module_name) {
      path_to_lib <- Sys.getenv("PROJECT_R_LIB")
      path_to_module <- file.path(path_to_lib, paste0(module_name, ".R"))
      source(path_to_module)
    }

    import("foo")
    ...
    import("whatever")

    foo$bar(...)
    if (foo$opts$frobnicate) foo$frobozz(...)


This implementation is very crude (I have very little experience with
R), but I hope it at least conveys clearly what I'm after.

I would appreciate any suggestions/comments on how to implement in R
the "zero-overhead" code re-use model I described earlier.


From bgunter.4567 at gmail.com  Fri Sep 30 18:35:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 30 Sep 2016 09:35:31 -0700
Subject: [R] How to implement "zero-overhead" code re-use (a la Python,
 Perl, etc.) in R?
In-Reply-To: <CAFvQaj6+Vi_HW1-oNyqRygLG1r1aHXhy1H=4A-TuzS=VdgrTjg@mail.gmail.com>
References: <CAFvQaj6+Vi_HW1-oNyqRygLG1r1aHXhy1H=4A-TuzS=VdgrTjg@mail.gmail.com>
Message-ID: <CAGxFJbSbA7W1GUmdpLJp2h7VPesf5aCW-osW2wQ0bKnKEfvy+g@mail.gmail.com>

I believe that you should post this on the R-devel list. I think that
the expertise to give you an authoritative answer is likely to reside
there, and they may not monitor or wish to respond on this list.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 30, 2016 at 7:36 AM, Kynn Jones <kynnjo at gmail.com> wrote:
> I'm collaborating in a long-running research project that, over the
> years, has accummulated source code (written in-house) in several
> languages: Python, Perl, Mathematica, MATLAB.
>
> Recently I have started writing source code in R for this project, and
> I am having trouble incorporating it into our established work flow.
>
> Our code falls into two broad categories: "scripts" (invoked directly
> by the user) and "libraries" (invoked by "client code", i.e. scripts
> or other library code).
>
> The library code lives under the top-level subdirectory ./lib of the
> git-controlled project directory.  (We keep all our code, along with
> the rest of the project's documents, under git control.)
>
> Users of client programs of the code under ./lib are expected to
> supply (usually via some global configuration) the appropriate library
> path (.e.g PYTHONPATH=$PROJECTDIR/lib/python,
> MATLABPATH=$PROJECTDIR/lib/MATLAB, etc.).
>
> With this arrangement, code re-use is extremely simple.  For example,
> by just dropping into the ./lib/python directory the file foo.py, with
> content
>
>     # foo.py
>     def bar():
>         # etc.
>
> ...its bar function becomes *immediately* available, in a
> namespace-safe way, to any other python code in the project, like
> this:
>
>     # somescript.py
>
>     import foo
>
>     foo.bar()
>
> I describe this form of code re-use as "zero-overhead", since it
> requires only the presence of files that actually hold the code.
>
> Under such a code re-use scheme, updates of library code from the
> project's git repo are no different from updates of the project's
> content in general.  All that is required is running a command like
>
>     git pull origin master
>
> After such a command, the updated library code becomes immediately
> available to client code.
>
> Although I used Python for the example above, the picture is very
> similar for the other languages we have been using up to now.
>
> For R, however, the situation is different.  The only form of code
> re-use I have found for R is through packages.  AFAICT, R packages are
> not "zero-overhead": they entail a host of "meta" and derived files
> (in addition to the source code files), together with
> build/installation steps after each update.
>
> I'm looking for an alternative to packages for code re-use in R, one
> that better approximates the "zero-overhead" code re-use model
> described earlier.
>
> The only thing that comes to mind is as follows:
>
>   1. a "module" is an *.R file in the directory specified a suitable
> environment variable (e.g. PROJECT_R_LIB), and defining a single
> "module object", which is simply a named list.  For example,
>
>     # module foo.R
>
>     foo <- list(
>       bar = function (...) ... ,
>       baz = function (...) ... ,
>       frobozz = function (...) ... ,
>       ...
>       opts = list(...),
>       ...
>     )
>
>   2. every *.R file starts with boilerplate in the spirit of the
> following (along with adequate error checking/messages, etc.):
>
>     # somescript.R
>
>     import <- function (module_name) {
>       path_to_lib <- Sys.getenv("PROJECT_R_LIB")
>       path_to_module <- file.path(path_to_lib, paste0(module_name, ".R"))
>       source(path_to_module)
>     }
>
>     import("foo")
>     ...
>     import("whatever")
>
>     foo$bar(...)
>     if (foo$opts$frobnicate) foo$frobozz(...)
>
>
> This implementation is very crude (I have very little experience with
> R), but I hope it at least conveys clearly what I'm after.
>
> I would appreciate any suggestions/comments on how to implement in R
> the "zero-overhead" code re-use model I described earlier.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f_j_rod at hotmail.com  Fri Sep 30 18:38:02 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Fri, 30 Sep 2016 16:38:02 +0000
Subject: [R] Elegant way to get specific dates within prespecified period
Message-ID: <AM5PR0402MB26891E46F281CF6EDF4931DCBAC10@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Dear R users,

I have two dates, ["open", "close"], which can be any dates such "close" is strictly later than "open".
I wanted to write an R code that displays the following:  To construct a vector "v" with all 1st January

days located between "open" and "close" dates:  v = (dp_1, dp_2, ..., dp_n). Moreover:

a) Regard to the first date "dp_1":
    a1) If "open" is on a 1st January day, "dp_1" is on 1st January of the year after "open".
    a2) In case difftime between "open" and the following 1st January is lower than 30 days,
       "dp_1" will be on 1st January of the year after the year of that 1st January.

b) Regard to the last date "dp_n":
   b1) If "close" is on a 1st January day, dp_n is on 1st January of the year before "close"
   b2) In case difftime between "close" and the previous 1st January is lower than 30 days,
       "dp_n" will be on 1st January of the year before the year of that 1st January.

Example 1: [open = 2007-01-01, close = 2011-04-05]
v = (2008-01-01, 2009-01-01, 2010-01-01, 2011-01-01) # Since open is already on a 1st January
                                                                                                   # Since difftime(2011-04-05, 2011-01-01) >= 30 days
Example 2: [open = 2006-12-15, close = 2011-01-19]
v = (2008-01-01, 2009-01-01, 2010-01-01)      # Since difftime(2007-01-01, 2006-12-15) < 30 days
                                                                                 # Since difftime(2011-01-19, 2011-01-01) < 30 days


My code is (for example 2):

open <- as.Date('2006-12-15')
close <- as.Date('2011-01-19')

dp_1 <- as.Date(ifelse(
 as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1, sep = "-")) - open >= 30,
 as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1, sep = "-")),
 as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 2), 1, 1, sep = "-"))),
 origin = "1970-01-01")

dp_n <- as.Date(ifelse(
      close - as.Date(paste(as.character(as.numeric(format(close, "%Y"))), 1, 1, sep = "-")) >= 30,
      as.Date(paste(as.character(as.numeric(format(close, "%Y"))), 1, 1, sep = "-")),
 as.Date(paste(as.character(as.numeric(format(close, "%Y")) - 1), 1, 1, sep = "-"))),
 origin = "1970-01-01")

v <- seq(dp_1, dp_n, by = "year")


However, above code is not too large, so I'm almost sure that there might be a better way of doing it.
Is there a better way to get the vector "v"?

Thanks for any help!

Frank S.

	[[alternative HTML version deleted]]


From szhan at uoguelph.ca  Fri Sep 30 18:40:46 2016
From: szhan at uoguelph.ca (Shuhua Zhan)
Date: Fri, 30 Sep 2016 16:40:46 +0000
Subject: [R] How to test a difference in ratios of count data in R
In-Reply-To: <69100965-060D-44E5-B01A-10171A4300D7@comcast.net>
References: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
	<CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>,
	<69100965-060D-44E5-B01A-10171A4300D7@comcast.net>
Message-ID: <YTXPR01MB012788B835209B2D7CD8C895A1C10@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>


Thank you, David and Greg for your help!

I drew conclusion that the treatment B significantly increases the ratio of x group (X/n) from  based on p values from the treatmentB line of the outputs at logistic reg. and Poisson reg.(p=6.11e-07, Logistic; p=0.000152, Poisson). I'm wondering whether the significance of the (Intercept) line in both outputs affect my conclusion.

Logistic reg.  Fixed effects:

            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.7442     0.5438  -3.208  0.00134 **
treatmentB    2.3647     0.4741   4.988 6.11e-07 ***


Poisson reg. Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.7875     0.3372  -5.301 1.15e-07 ***
treatmentB    1.3365     0.3529   3.787 0.000152 ***


I think I may use the command below to obtain the mean ratios of x group in treatment A and B for Logistic reg. but I have not figured out yet for Poisson reg.


> tapply(predict(fit2, type="response"), test$treatment, mean)
        A         B
0.1620254 0.6404239

I'll appreciate if you know the command for Poisson reg.
Joshua



________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, September 28, 2016 4:54:46 PM
To: Shuhua Zhan
Cc: r-help at R-project.org; Greg Snow
Subject: Re: [R] How to test a difference in ratios of count data in R


> On Sep 28, 2016, at 9:49 AM, Greg Snow <538280 at gmail.com> wrote:
>
> There are multiple ways of doing this, but here are a couple.
>
> To just test the fixed effect of treatment you can use the glm function:
>
> test <- read.table(text="
> replicate treatment n X
> 1 A 32 4
> 1 B 33 18
> 2 A 20 6
> 2 B 21 18
> 3 A 7 0
> 3 B 8 4
> ", header=TRUE)
>
> fit1 <- glm( cbind(X,n-X) ~ treatment, data=test, family=binomial)
> summary(fit1)
>
> Note that the default baseline value may differ between R and SAS,
> which would result in a reversed sign on the slope coefficient (and
> different intercept).
>
> To include replicate as a random effect you need an additional
> package, here I use lme4 and the glmer function:
>
> library(lme4)
> fit2 <- glmer( cbind(X, n-X) ~ treatment + (1|replicate), data=test,
> family=binomial)
> summary(fit2)
>
>
>
> On Tue, Sep 27, 2016 at 9:03 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
>> Hello R-experts,
>> I am interested to determine if the ratio of counts from two groups differ across two distinct treatments. For example, we have three replicates of treatment A, and three replicates of treatment B. For each treatment, we have counts X from one group and counts Y from another group. My understanding is that that GLIMMIX procedure in SAS can calculate whether the ratio of counts in one group (X/X+Y) significantly differs between treatments.
>>
>> I think this is the way you do it in SAS. The replicate and treatment variables are self-explanatory. The first number (n) refers to the total counts X + Y; the second number (X) refers to the counts X. Is there a way to do this in R? Since we have 20,000 datasets to be tested, it may be easier to retrive the significant test as the given dataset below and its p>F value and mean ratios of treatments in R than SAS.
>>
>>
>> data test;
>> input replicate treatment$ n X;
>> datalines;
>> 1 A 32 4
>> 1 B 33 18
>> 2 A 20 6
>> 2 B 21 18
>> 3 A 7 0
>> 3 B 8 4
>> ;
>>

Greg has already shown you how that is done in R and how to do logistic regression:

#  I usually think of Poisson regression when I hear a desire is to model ratios of counts that have a denominator. The log(sample_size) is supplied as an offset to correct for the variation in size of subsamples.


fit1 <- glm( X ~ treatment+offset(log(n)), data=test, family=poisson)
summary(fit1)

#  And the lme4 analogue with replication:

library(lme4)
fit2 <- glmer( X ~ treatment + offset(log(n))+ (1|replicate), data=test,
family=poisson)
summary(fit2)
#----output----
Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
 [glmerMod]
 Family: poisson  ( log )
Formula: X ~ treatment + offset(log(n)) + (1 | replicate)
   Data: test

     AIC      BIC   logLik deviance df.resid
    31.9     31.3    -13.0     25.9        3

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.0504 -0.4146 -0.3487  0.3956  1.0791

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.03159  0.1777
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.7875     0.3372  -5.301 1.15e-07 ***
treatmentB    1.3365     0.3529   3.787 0.000152 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.838

Compare with the binomial model:
#============


 fitBin <- glmer( cbind(X,n-X) ~ treatment +  (1|replicate), data=test,
 family=binomial)
 coef(fitBin)
#----
$replicate
  (Intercept) treatmentB
1  -2.0487694   2.364695
2  -0.9908556   2.364695
3  -2.1844435   2.364695

attr(,"class")
[1] "coef.mer"
#-----
 summary(fitBin)
#---------
Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
 [glmerMod]
 Family: binomial  ( logit )
Formula: cbind(X, n - X) ~ treatment + (1 | replicate)
   Data: test

     AIC      BIC   logLik deviance df.resid
    30.1     29.4    -12.0     24.1        3

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.88757 -0.35065 -0.03137  0.26897  0.67505

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.4123   0.6421
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.7442     0.5438  -3.208  0.00134 **
treatmentB    2.3647     0.4741   4.988 6.11e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.568

The binomial model has a logit link. Your glimmix procedure appears to have a gaussian/normal distributional assumption and an identity link by default. If we run this using those assumptions in lme4::glmer we get these results (with a warning that in this case we can overlook since the results with lmer turned out to be identical)
#--------
 fitNorm <- glmer( I(X/n) ~ treatment +  (1|replicate), data=test,
                  family=gaussian)

#-------
Warning message:
In glmer(I(X/n) ~ treatment + (1 | replicate), data = test, family = gaussian) :
  calling glmer() with family=gaussian (identity link) as a shortcut to lmer() is deprecated; please call lmer() directly
> coef(fitNorm); summary(fitNorm)
$replicate
  (Intercept) treatmentB
1 0.091096925  0.4925325
2 0.324579602  0.4925325
3 0.009323473  0.4925325

attr(,"class")
[1] "coef.mer"
Linear mixed model fit by REML ['lmerMod']
Formula: I(X/n) ~ treatment + (1 | replicate)
   Data: test

REML criterion at convergence: -4.2

Scaled residuals:
    Min      1Q  Median      3Q     Max
-0.7864 -0.4278 -0.1152  0.5143  0.8246

Random effects:
 Groups    Name        Variance Std.Dev.
 replicate (Intercept) 0.027895 0.16702
 Residual              0.002356 0.04854
Number of obs: 6, groups:  replicate, 3

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.14167    0.10042   1.411
treatmentB   0.49253    0.03963  12.427

Correlation of Fixed Effects:
           (Intr)
treatmentB -0.197

That's (probably) the model to compare to your SAS results if my reading of the SAS Proc GLIMMIX manual page is correct.

--
David.

>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> run;
>>
>> ods select lsmeans;
>> proc glimmix data=test;
>> class replicate treatment;
>> model X/n = treatment / solution;
>> random intercept / subject=replicate;
>> lsmeans treatment / cl ilink;
>> run;
>>
>> I appreciate your help in advance!
>> Joshua
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Sep 30 18:56:45 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 30 Sep 2016 16:56:45 +0000
Subject: [R] Elegant way to get specific dates within prespecified period
Message-ID: <D413E543.18763A%macqueen1@llnl.gov>

I would probably try a different strategy.

First, construct a sequence of January 1 dates that is a little bit too
long. For example, start with the January in the same year as "open" and
finish with the January in the same year as "close". You can construct the
vector using seq(), like this:

> seq(as.Date('2007-1-1'), as.Date('2011-1-1'), by='year')
[1] "2007-01-01" "2008-01-01" "2009-01-01" "2010-01-01" "2011-01-01"

Then test all those dates for whether they fit your rules, and remove
those that don't.

I think this will be easier than constructing fancy ifelse statements. It
should certainly be easier to understand the code, i.e., when you come
back and look at it a few years from now. Or if a colleague wants to look
at it and understand it.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/30/16, 9:38 AM, "R-help on behalf of Frank S."
<r-help-bounces at r-project.org on behalf of f_j_rod at hotmail.com> wrote:

>Dear R users,
>
>I have two dates, ["open", "close"], which can be any dates such "close"
>is strictly later than "open".
>I wanted to write an R code that displays the following:  To construct a
>vector "v" with all 1st January
>
>days located between "open" and "close" dates:  v = (dp_1, dp_2, ...,
>dp_n). Moreover:
>
>a) Regard to the first date "dp_1":
>    a1) If "open" is on a 1st January day, "dp_1" is on 1st January of
>the year after "open".
>    a2) In case difftime between "open" and the following 1st January is
>lower than 30 days,
>       "dp_1" will be on 1st January of the year after the year of that
>1st January.
>
>b) Regard to the last date "dp_n":
>   b1) If "close" is on a 1st January day, dp_n is on 1st January of the
>year before "close"
>   b2) In case difftime between "close" and the previous 1st January is
>lower than 30 days,
>       "dp_n" will be on 1st January of the year before the year of that
>1st January.
>
>Example 1: [open = 2007-01-01, close = 2011-04-05]
>v = (2008-01-01, 2009-01-01, 2010-01-01, 2011-01-01) # Since open is
>already on a 1st January
>                  
>                         # Since difftime(2011-04-05, 2011-01-01) >= 30
>days
>Example 2: [open = 2006-12-15, close = 2011-01-19]
>v = (2008-01-01, 2009-01-01, 2010-01-01)      # Since
>difftime(2007-01-01, 2006-12-15) < 30 days
>                  
>       # Since difftime(2011-01-19, 2011-01-01) < 30 days
>
>
>My code is (for example 2):
>
>open <- as.Date('2006-12-15')
>close <- as.Date('2011-01-19')
>
>dp_1 <- as.Date(ifelse(
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1,
>sep = "-")) - open >= 30,
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1,
>sep = "-")),
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 2), 1, 1,
>sep = "-"))),
> origin = "1970-01-01")
>
>dp_n <- as.Date(ifelse(
>      close - as.Date(paste(as.character(as.numeric(format(close,
>"%Y"))), 1, 1, sep = "-")) >= 30,
>      as.Date(paste(as.character(as.numeric(format(close, "%Y"))), 1, 1,
>sep = "-")),
> as.Date(paste(as.character(as.numeric(format(close, "%Y")) - 1), 1, 1,
>sep = "-"))),
> origin = "1970-01-01")
>
>v <- seq(dp_1, dp_n, by = "year")
>
>
>However, above code is not too large, so I'm almost sure that there might
>be a better way of doing it.
>Is there a better way to get the vector "v"?
>
>Thanks for any help!
>
>Frank S.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Sep 30 20:37:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 30 Sep 2016 11:37:01 -0700
Subject: [R] How to test a difference in ratios of count data in R
In-Reply-To: <YTXPR01MB012788B835209B2D7CD8C895A1C10@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
References: <YTXPR01MB0127666C09A5E9FE8F270157A1CF0@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
	<CAFEqCdwuOfcU-QbrT2i-NNSuPToYD7YtGZPgLGPyWUNhs=ePkQ@mail.gmail.com>
	<69100965-060D-44E5-B01A-10171A4300D7@comcast.net>
	<YTXPR01MB012788B835209B2D7CD8C895A1C10@YTXPR01MB0127.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <1E11119E-2462-43AB-BCE5-9B22FC8BD9CB@comcast.net>


> On Sep 30, 2016, at 9:40 AM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
> 
> 
> Thank you, David and Greg for your help!
> I drew conclusion that the treatment B significantly increases the ratio of x group (X/n) from  based on p values from the treatmentB line of the outputs at logistic reg. and Poisson reg.(p=6.11e-07, Logistic; p=0.000152, Poisson). I'm wondering whether the significance of the (Intercept) line in both outputs affect my conclusion.
> Logistic reg.  Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)  -1.7442     0.5438  -3.208  0.00134 ** 

As in most regression situations, the p-value is calculated on the basis of a null hypothesis that the baseline assemblage of covariates will be associated with an "outcome" of one on the transformed scale of analysis. For logistic regression this would imply  an odds ratio of 1.0 and that the baseline covariates would then be associated with a 50:50 split of events and non-events. This is often not a hypothesis of particular interest, so generally the advice is to ignore that p-value.


> treatmentB    2.3647     0.4741   4.988 6.11e-07 ***
> 
> Poisson reg. Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)  -1.7875     0.3372  -5.301 1.15e-07 ***

For Poisson regression the Intercept is the log( rate) at a covariate value of again zero for continuous variables and baseline for factors.  The null hypothesis tested is that the log(rate) is zero. This is often not a meaningful hypothesis, (especially if age is a covariate as it usually is events in a medical settings).


> treatmentB    1.3365     0.3529   3.787 0.000152 ***
> 
> I think I may use the command below to obtain the mean ratios of x group in treatment A and B for Logistic reg. but I have not figured out yet for Poisson reg.
> 
> > tapply(predict(fit2, type="response"), test$treatment, mean)
>         A         B 
> 0.1620254 0.6404239
> 
> I'll appreciate if you know the command for Poisson reg.

Should be the same call but the interpretation is different as mentioned above. The ?predict.glm halp page says " the alternative "response" is on the scale of the response variable. " and that is no limited to logistic regression despite the fact that the next sentence applies that principle to the logistic case.

This is knowledge one would probably get in a third or fourth semester stats course, at least based on my experience 30 year ago. This is really not what the Rhelp mailing list is set up to provide, (nor am I necessarily the most qualified to provide online statistics education) so I'm suggesting you pose any further question to a forum that is designed to address such matters. Go to http://stats.stackexchange.com/  or find an outlet that is designed for self-learning of statistical concepts. 

This is material that I learned by both formal education and study of Breslow and Day's two volume text "Statistical Methods in Cancer Research" which I believe is a classic and still useful resource. It used GLIM as the coding platform, but I found transferring from GLIM to R rather easy. I can also recommend Venables and Ripley's "Modern Applied Statistics with S-Plus" which in it's 4th edition had R-specific annotations. It covers a wide range of applications, but does assume significant prior training. 

I encourage other respondents who have different recommendations for more recent texts suitable for self-study of using R for generalized linear models with replication to chime in here, since I think such recommendations _are_ on-topic. I hesitate to recommend "Mixed Effects Models with S and S-Plus" because so much has been changed in more recent versions of package lme4 that I find it very error prone to use. I wish the effort to write a replacement had continued but my searches have suggested to me that it has not happened. I'd be happy to be corrected.


Best;

David.



> Joshua
> 
> 
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: Wednesday, September 28, 2016 4:54:46 PM
> To: Shuhua Zhan
> Cc: r-help at R-project.org; Greg Snow
> Subject: Re: [R] How to test a difference in ratios of count data in R
>  
> 
> > On Sep 28, 2016, at 9:49 AM, Greg Snow <538280 at gmail.com> wrote:
> > 
> > There are multiple ways of doing this, but here are a couple.
> > 
> > To just test the fixed effect of treatment you can use the glm function:
> > 
> > test <- read.table(text="
> > replicate treatment n X
> > 1 A 32 4
> > 1 B 33 18
> > 2 A 20 6
> > 2 B 21 18
> > 3 A 7 0
> > 3 B 8 4
> > ", header=TRUE)
> > 
> > fit1 <- glm( cbind(X,n-X) ~ treatment, data=test, family=binomial)
> > summary(fit1)
> > 
> > Note that the default baseline value may differ between R and SAS,
> > which would result in a reversed sign on the slope coefficient (and
> > different intercept).
> > 
> > To include replicate as a random effect you need an additional
> > package, here I use lme4 and the glmer function:
> > 
> > library(lme4)
> > fit2 <- glmer( cbind(X, n-X) ~ treatment + (1|replicate), data=test,
> > family=binomial)
> > summary(fit2)
> > 
> > 
> > 
> > On Tue, Sep 27, 2016 at 9:03 PM, Shuhua Zhan <szhan at uoguelph.ca> wrote:
> >> Hello R-experts,
> >> I am interested to determine if the ratio of counts from two groups differ across two distinct treatments. For example, we have three replicates of treatment A, and three replicates of treatment B. For each treatment, we have counts X from one group and counts Y from another group. My understanding is that that GLIMMIX procedure in SAS can calculate whether the ratio of counts in one group (X/X+Y) significantly differs between treatments.
> >> 
> >> I think this is the way you do it in SAS. The replicate and treatment variables are self-explanatory. The first number (n) refers to the total counts X + Y; the second number (X) refers to the counts X. Is there a way to do this in R? Since we have 20,000 datasets to be tested, it may be easier to retrive the significant test as the given dataset below and its p>F value and mean ratios of treatments in R than SAS.
> >> 
> >> 
> >> data test;
> >> input replicate treatment$ n X;
> >> datalines;
> >> 1 A 32 4
> >> 1 B 33 18
> >> 2 A 20 6
> >> 2 B 21 18
> >> 3 A 7 0
> >> 3 B 8 4
> >> ;
> >> 
> 
> Greg has already shown you how that is done in R and how to do logistic regression:
> 
> #  I usually think of Poisson regression when I hear a desire is to model ratios of counts that have a denominator. The log(sample_size) is supplied as an offset to correct for the variation in size of subsamples.
> 
> 
> fit1 <- glm( X ~ treatment+offset(log(n)), data=test, family=poisson)
> summary(fit1)
> 
> #  And the lme4 analogue with replication:
> 
> library(lme4)
> fit2 <- glmer( X ~ treatment + offset(log(n))+ (1|replicate), data=test,
> family=poisson)
> summary(fit2)
> #----output----
> Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
>  [glmerMod]
>  Family: poisson  ( log )
> Formula: X ~ treatment + offset(log(n)) + (1 | replicate)
>    Data: test
> 
>      AIC      BIC   logLik deviance df.resid 
>     31.9     31.3    -13.0     25.9        3 
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -1.0504 -0.4146 -0.3487  0.3956  1.0791 
> 
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  replicate (Intercept) 0.03159  0.1777  
> Number of obs: 6, groups:  replicate, 3
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)  -1.7875     0.3372  -5.301 1.15e-07 ***
> treatmentB    1.3365     0.3529   3.787 0.000152 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>            (Intr)
> treatmentB -0.838
> 
> Compare with the binomial model:
> #============
> 
> 
>  fitBin <- glmer( cbind(X,n-X) ~ treatment +  (1|replicate), data=test,
>  family=binomial)
>  coef(fitBin)
> #----
> $replicate
>   (Intercept) treatmentB
> 1  -2.0487694   2.364695
> 2  -0.9908556   2.364695
> 3  -2.1844435   2.364695
> 
> attr(,"class")
> [1] "coef.mer"
> #-----
>  summary(fitBin)
> #---------
> Generalized linear mixed model fit by maximum likelihood (Laplace  Approximation)
>  [glmerMod]
>  Family: binomial  ( logit )
> Formula: cbind(X, n - X) ~ treatment + (1 | replicate)
>    Data: test
> 
>      AIC      BIC   logLik deviance df.resid 
>     30.1     29.4    -12.0     24.1        3 
> 
> Scaled residuals: 
>      Min       1Q   Median       3Q      Max 
> -0.88757 -0.35065 -0.03137  0.26897  0.67505 
> 
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  replicate (Intercept) 0.4123   0.6421  
> Number of obs: 6, groups:  replicate, 3
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)  -1.7442     0.5438  -3.208  0.00134 ** 
> treatmentB    2.3647     0.4741   4.988 6.11e-07 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>            (Intr)
> treatmentB -0.568
> 
> The binomial model has a logit link. Your glimmix procedure appears to have a gaussian/normal distributional assumption and an identity link by default. If we run this using those assumptions in lme4::glmer we get these results (with a warning that in this case we can overlook since the results with lmer turned out to be identical)
> #--------
>  fitNorm <- glmer( I(X/n) ~ treatment +  (1|replicate), data=test,
>                   family=gaussian)
> 
> #-------
> Warning message:
> In glmer(I(X/n) ~ treatment + (1 | replicate), data = test, family = gaussian) :
>   calling glmer() with family=gaussian (identity link) as a shortcut to lmer() is deprecated; please call lmer() directly
> > coef(fitNorm); summary(fitNorm)
> $replicate
>   (Intercept) treatmentB
> 1 0.091096925  0.4925325
> 2 0.324579602  0.4925325
> 3 0.009323473  0.4925325
> 
> attr(,"class")
> [1] "coef.mer"
> Linear mixed model fit by REML ['lmerMod']
> Formula: I(X/n) ~ treatment + (1 | replicate)
>    Data: test
> 
> REML criterion at convergence: -4.2
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -0.7864 -0.4278 -0.1152  0.5143  0.8246 
> 
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  replicate (Intercept) 0.027895 0.16702 
>  Residual              0.002356 0.04854 
> Number of obs: 6, groups:  replicate, 3
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  0.14167    0.10042   1.411
> treatmentB   0.49253    0.03963  12.427
> 
> Correlation of Fixed Effects:
>            (Intr)
> treatmentB -0.197
> 
> That's (probably) the model to compare to your SAS results if my reading of the SAS Proc GLIMMIX manual page is correct.
> 
> -- 
> David.
> 
> >> proc glimmix data=test;
> >> class replicate treatment;
> >> model X/n = treatment / solution;
> >> random intercept / subject=replicate;
> >> run;
> >> 
> >> ods select lsmeans;
> >> proc glimmix data=test;
> >> class replicate treatment;
> >> model X/n = treatment / solution;
> >> random intercept / subject=replicate;
> >> lsmeans treatment / cl ilink;
> >> run;
> >> 
> >> I appreciate your help in advance!
> >> Joshua
> >> 
> >> 
> >>        [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> > 
> > -- 
> > Gregory (Greg) L. Snow Ph.D.
> > 538280 at gmail.com
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From pgilbert902 at gmail.com  Fri Sep 30 22:41:31 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 30 Sep 2016 16:41:31 -0400
Subject: [R] Optimization issue - Solution converges for any initial value
In-Reply-To: <mailman.5.1475229602.11266.r-help@r-project.org>
References: <mailman.5.1475229602.11266.r-help@r-project.org>
Message-ID: <7700dd56-8603-15df-2221-68435322c4c4@gmail.com>

Narendra

You should check the definition of your objective function, something 
seems to be wrong.  When you evaluate the objective function with your 
initial guess, and then with some different value, you should expect the 
returned value will be different, but it is not:

 > print(Koval.Error.func(vp.kval, n=1), digits=20)
[1] 2767.1357969742521163
 > print(Koval.Error.func(2*vp.kval, n=1), digits=20)
[1] 2767.1357969742521163

So the objective function is flat. Optim converges with the message 
"CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL". Of course, the 
gradient is zero because the objective function is flat.

This would normally be considered a "user error" but perhaps John's 
newer code can catch it?

Paul

> Date: Thu, 29 Sep 2016 14:53:08 -0500
> From: Narendra Modi <bjpmodi2016 at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] Optimization issue - Solution converges for any initial
> 	value
> Message-ID:
> 	<CAPq=xQD983bACPVcyESFz-AUXi1OyUYKmdAH1m36+Zdu4kh-xw at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> I have put together a R snippet wherein I am trying to get optimum
> values for which error is minimized. The error is the difference
> between two matrices.
> Every time I run the below code, I don't see any optimization
> happening as in the final answer is the same as the initial estimate
> regardless of what I mention as initial estimate.
> Could you please advise on how can I improve it?
> I have also tried using nloptr but to no avail.
>
> To optimize vp.kval
>
>
>
>
> my.data.matrix.prod <- matrix(a,nrow = length(a),1)
> Estimated.Qt.mat <- matrix(b,nrow = nrow(my.data.matrix.prod), ncol = 1)
> Cum.WInj.matrix <- matrix (c,nrow = nrow(my.data.matrix.prod), ncol = 1)
> Koval.tD <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1)  # tD Matrix
> Koval.fw <- matrix(,nrow = nrow(my.data.matrix.prod), ncol = 1) # fw Matrix
>
> Koval.Error.func <- function(vp.kval,n)
> {
>   #First convert vector(Koval.InitialData.list) to MATRIX and send it
> to calculate estimated matrix
>
>   Koval.InitialData.Matrix <- matrix(vp.kval,nrow = 2, 1,byrow = TRUE)
>  # Define Koval Parameters Matrix for the "n"
>
>   Qo.Koval <- Qo.Koval(Koval.InitialData.Matrix)  # Get Qo Estimation from Koval
>
>   diff.values <- my.data.matrix.prod[,n] - Qo.Koval  #FIND DIFFERENCE
> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>
>   Error <- ((colSums ((diff.values^2), na.rm = TRUE, dims =
> 1))/nrow(my.data.matrix.prod))^0.5    #sum of square root of the diff
>
>   Error   # return error value
> }
>
> Qo.Koval <- function(Koval.InitialData.Matrix)
> {
>   Qo.Koval.Est <- matrix(,nrow(my.data.matrix.prod), 1)
> #ncol(my.data.matrix.prod)
>
>   for(rowno in 1:nrow(my.data.matrix.prod)) #number of rows of data
>   {
>     Koval.tD[rowno,1] = Cum.WInj.matrix[rowno,1] *
> Koval.InitialData.Matrix[1,1]   # Evaluate tD matrix
>
>     if(Koval.tD[rowno,1] < (1/Koval.InitialData.Matrix[2,1]))
>     {
>       Koval.fw[rowno,1] = 0
>     }
>     else
>     {
>       if(Koval.tD[rowno,1] > Koval.InitialData.Matrix[2,1])
>       {
>         Koval.fw[rowno,1] = 1
>       }else
>       {
>         Koval.fw[rowno,1] = (Koval.InitialData.Matrix[2,1] -
> sqrt(Koval.InitialData.Matrix[2,1]/Koval.tD[rowno,1]))/(Koval.InitialData.Matrix[2,1]-1)
>       }
>     }
>
>     Qo.Koval.Est[rowno,1] = Koval.fw[rowno,1] * Estimated.Qt.mat[rowno,1]
>   }
>
>   Qo.Koval.Est    # Return Estimated matrix
> }
>
> vp.kval <- c(100000,1)  #initial estimate
> Koval.lb = c(0,0)
> Koval.ub = c(Inf,Inf)
> n <- 1
> Koval.result <- optim(vp.kval,Koval.Error.func, method = "L-BFGS-B",
> lower = Koval.lb,
>                      upper = Koval.ub, n=n)
> print(paste(Koval.result$convergence))
> print(paste(Koval.result$par))
>
>
> Here is the input data:
>
> a:
>
> structure(c(414, 40, 639, 616, 677, 598, 586, 494, 322, 351,
> 322, 213, 395, 358, 406, 384, 409, 404, 370, 376, 412, 404, 369,
> 391, 341, 350, 349, 313, 302, 196, 386, 330, 350, 323, 454, 465,
> 465, 399, 416, 396, 453, 388, 496, 379, 472, 491, 492, 503, 516,
> 454, 630, 547, 578, 312, 764, 672, 548, 611, 546, 552, 520, 486,
> 581, 559, 433, 262, 650, 615, 542, 571, 542, 529, 577, 469, 557,
> 540, 546, 519, 376, 605, 520, 435, 299, 531, 538, 475, 511, 487,
> 490, 494, 537, 482, 438, 498, 312, 476, 383, 382), .Dim = c(98L,
> 1L), .Dimnames = list(NULL, "Q2"))
>
> b:
>
> structure(c(2342.12883525675, 2595.06229039124, 2715.2774272809,
> 2742.14586849367, 2678.48814516156, 2769.17482063132, 2809.26904957691,
> 2647.26143288146, 2142.48588931211, 1986.26692938822, 2417.80180308667,
> 2539.99173834861, 2889.68696098066, 2949.03395956634, 3345.265659123,
> 3178.09552101488, 3202.97894028497, 3294.04615708455, 3273.96002181006,
> 3290.59294404149, 3074.57078080845, 2809.00966959208, 2870.20594457832,
> 2994.89960881099, 3031.51083818418, 2838.72778780229, 2779.83367818986,
> 2471.70302686638, 2277.52074079803, 2313.67080371772, 2415.57558854185,
> 2593.57170885689, 2579.65222779155, 2542.47630393453, 2610.16334633228,
> 2715.1622580481, 2680.04491562794, 2676.08878142995, 2890.5657368073,
> 2939.98447437336, 2932.41354171428, 2699.29100102243, 2748.9757584712,
> 2885.90115387751, 2841.03004973532, 3111.28842226602, 3293.09352655985,
> 3448.16679970445, 3470.58231818316, 3077.6191619663, 2892.81263635983,
> 2563.00601428125, 2410.40833201752, 2696.80369889632, 3250.95996536945,
> 3900.33363068933, 3571.89127039948, 3569.09158205254, 3718.94141619046,
> 3963.05018539626, 4317.67764180387, 4143.2306512351, 4482.33003541385,
> 4313.47162218783, 4162.58533919444, 4119.75974744111, 4080.01960112015,
> 4146.78116940934, 3848.98992961189, 3507.00912988581, 3336.3269842557,
> 3691.50683899193, 3616.0923981163, 3325.14304882807, 3471.79805853069,
> 3229.60965194249, 3106.05768279943, 3184.66721766981, 3140.79657087168,
> 3242.97205541341, 3090.78617601495, 3086.74973135927, 3317.74000570974,
> 3594.90929884806, 3716.02759860505, 3622.91307702134, 3793.8518218782,
> 3666.82966979173, 3779.4557494045, 3750.98605852729, 3333.45681985961,
> 3057.22984206785, 3395.04273620089, 3623.47886822009, 3690.34495906538,
> 3827.97665203175, 3933.61679986677, 3762.82354740958), .Dim = c(98L,
> 1L))
>
> c:
>
> structure(c(2854.17262019504, 91576.5893971961, 171680.262910889,
> 257565.867448752, 335812.78671975, 424624.296030534, 510229.898689908,
> 586994.432148103, 636896.230541501, 691311.784820203, 780382.614051205,
> 860628.109248455, 961649.745761829, 1055011.51571743, 1162113.22730208,
> 1255164.70993334, 1352077.97513698, 1457172.94644257, 1554726.68952114,
> 1657279.26732716, 1745523.14071769, 1821000.62788843, 1911979.2340704,
> 2005954.86455037, 2101129.54803795, 2182822.62676551, 2258661.15941603,
> 2325202.52364728, 2387098.71588595, 2460005.26984465, 2535846.63352407,
> 2622071.03988945, 2701584.84087477, 2776628.22472118, 2859757.87551639,
> 2944689.28669068, 3026621.7086177, 3109451.02390273, 3200463.68736646,
> 3293220.09008416, 3380941.82063061, 3456992.53009029, 3541106.87910663,
> 3635049.74483035, 3721653.58199201, 3823940.56521733, 3931974.7704047,
> 4040554.293988, 4148875.73758196, 4231424.94909108, 4306157.82023537,
> 4374820.38189491, 4442080.07977206, 4535051.28823047, 4650928.35668784,
> 4793084.92990124, 4893067.57046614, 5000047.61946087, 5120237.59556207,
> 5247211.61097682, 5392662.33159569, 5515394.91894634, 5652397.35652795,
> 5780590.26125026, 5900471.93425283, 6026783.31719041, 6147868.09782702,
> 6278602.62144284, 6388178.16489299, 6482065.35854026, 6579907.11054506,
> 6702412.42037957, 6812043.87236422, 6905604.01572694, 7007786.71329603,
> 7099980.68361161, 7189071.57372477, 7290368.20702837, 7383139.53472758,
> 7487014.64958016, 7577849.79802546, 7670318.64215094, 7780726.13033402,
> 7897750.56237753, 8016910.17077053, 8126173.95193153, 8241923.12215802,
> 8351438.92663496, 8468551.68021943, 8583900.77567578, 8670079.97000769,
> 8755816.49103472, 8872115.39013376, 8988383.34061776, 9104971.76148562,
> 9224368.08502439, 9349766.5439318, 9460826.05419725), .Dim = c(98L,
> 1L))
>


