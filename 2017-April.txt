From mrguilfoyle at gmail.com  Sat Apr  1 01:18:23 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Sat, 1 Apr 2017 00:18:23 +0100
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
Message-ID: <ADCA3AF5-F603-4704-A8B3-BAB886952E76@gmail.com>

This does the summation you want in one line:

#create example data and column selection
d = as.data.frame(matrix(rnorm(50),ncol=5))
cols = c(1,3)

#sum selected columns and put results in new row
d[nrow(d)+1,cols] = colSums(d[,cols])

However, I would agree with the sentiments that this is a bad idea; far better to have the mean values stored in a new object leaving the original data table untainted.  


> On 31 Mar 2017, at 17:20, Bruce Ratner PhD <br at dmstat1.com> wrote:
> 
> Hi R'ers:
> Given a data.frame of five columns and ten rows. 
> I would like to take the sum of, say, the first and third columns only.
> For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows. 
> 
> Thanks, in advance. 
> Bruce 
> 
> 
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Sat Apr  1 01:11:09 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 31 Mar 2017 19:11:09 -0400
Subject: [R] pull stat out of summary
Message-ID: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>

Continuing my learning curve after 25_ years with using SAS. Want to 
pull the "Mean" forom the summary of something...

test <- rnorm(1000,1.5,1.25)

hold <- summary(test)

names(hold)
[1] "Min."    "1st Qu." "Median"  "Mean"    "3rd Qu." "Max."

OK, so "Mean" is in there.
So, is there a short form answer for why hold$Mean throws an error, and 
hold["Mean"} returns the mean (as desired)?

Silly question I know,  but gotta start somewhere...

Thanks...


From sarah.goslee at gmail.com  Sat Apr  1 01:54:13 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 31 Mar 2017 19:54:13 -0400
Subject: [R] pull stat out of summary
In-Reply-To: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
References: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
Message-ID: <CAM_vjunURNC80BxSb4FmqP4aazJXunCTJMzGFtPe87p44jO_Gw@mail.gmail.com>

The short answer is that hold isn't a list-like object, and $ only
works with list-like objects (lists and data frames, mainly).

You can get the full explanation (VERY full), at
?Extract
or any of its aliases, like
?'$'
or
?'['

Sarah

On Fri, Mar 31, 2017 at 7:11 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
> Continuing my learning curve after 25_ years with using SAS. Want to pull
> the "Mean" forom the summary of something...
>
> test <- rnorm(1000,1.5,1.25)
>
> hold <- summary(test)
>
> names(hold)
> [1] "Min."    "1st Qu." "Median"  "Mean"    "3rd Qu." "Max."
>
> OK, so "Mean" is in there.
> So, is there a short form answer for why hold$Mean throws an error, and
> hold["Mean"} returns the mean (as desired)?
>
> Silly question I know,  but gotta start somewhere...
>
> Thanks...
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Sat Apr  1 01:58:34 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 31 Mar 2017 23:58:34 +0000
Subject: [R] pull stat out of summary
In-Reply-To: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
References: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
Message-ID: <1491004714743.20146@tamu.edu>

This is your answer:

> str(hold)
Classes 'summaryDefault', 'table'  Named num [1:6] -2.602 0.636 1.514 1.54 2.369 ...
  ..- attr(*, "names")= chr [1:6] "Min." "1st Qu." "Median" "Mean" ...

hold is a table of named numbers, i.e. a vector with a names attribute. It is not a data.frame so it does not have column names. The error message sort of tells you this when it says hold is an atomic vector (i.e. not a list or a data frame which are built from other objects such as vectors).

David Carlson
Anthropology Department
Texas A&M University
________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Evan Cooch <evan.cooch at gmail.com>
Sent: Friday, March 31, 2017 6:11 PM
To: r-help at r-project.org
Subject: [R] pull stat out of summary

Continuing my learning curve after 25_ years with using SAS. Want to
pull the "Mean" forom the summary of something...

test <- rnorm(1000,1.5,1.25)

hold <- summary(test)

names(hold)
[1] "Min."    "1st Qu." "Median"  "Mean"    "3rd Qu." "Max."

OK, so "Mean" is in there.
So, is there a short form answer for why hold$Mean throws an error, and
hold["Mean"} returns the mean (as desired)?

Silly question I know,  but gotta start somewhere...

Thanks...

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr  1 01:59:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 31 Mar 2017 16:59:14 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <B3EDDFBE-C1E4-4A5B-9DB7-C2E78E680923@dcn.davis.ca.us>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<CAA99HCwj-qV9rbBG8xaAiUzFrw84a0jsmbQWONQdfYZNSv2vPA@mail.gmail.com>
	<11fcc6a3-39ef-6d93-f1cc-3fbca3b22698@dmstat1.com>
	<CAA99HCwD0oEwi5rOrGK_-rri+=mmU0wvv_wWzSVTQ9fkdtVc_A@mail.gmail.com>
	<B3EDDFBE-C1E4-4A5B-9DB7-C2E78E680923@dcn.davis.ca.us>
Message-ID: <CAGxFJbSC_0iojZS2ohcBUHoEpbHfnA-NeJU34AknDxVc26YpfA@mail.gmail.com>

All:

1. I agree wholeheartedly with prior responses.

2. But let's suppose that for some reason, you *did* want to carry
around some "calculated values" with the data frame. Then one way to
do it is to add them as attributes to the data frame. This way they
cannot "pollute" the data in the way Jeff warned against; e.g.

attr(your_frame,"colsums") <- colSums(your_frame)

This of course calculates them all, but you can of course just attach
some (e.g. colSums(your_frame[,c(1,3)] )

3. This, of course, has the disadvantage of requiring recalculation of
the attribute if the data changes, which is an invitation to problems.
A better approach might be to attach the *function* that does the
calculation as an attribute, which when invoked always uses the
current data:

attr(your_frame,"colsums") <- function(x)colSums(x)

For example:

df <- data.frame(x=1:5,y=21:25)
attr(df,"colsums")<- function(x)colSums(x)

## then:
> attr(df,"colsums")(df)
  x   y
 15 115

## add a row
> df[6,] <- rep(100,2)
> attr(df,"colsums")(df)
  x   y
115 215


This survives changing the name of df:

> dat <- df
> attr(dat,"colsums")(dat)
  x   y
115 215

As it stands, the call: attr(df,"colsums")(df)  is a bit clumsy; one
could easily write a function that does this sort of thing more
cleanly, as, for example, is done via the "selfStart" functionality
for nonlinear models.

But all this presupposes that the OP is familiar with R programming
paradigms, especially the use of functions as first class objects, and
the language in general. While I may have missed this, his posts do
not seem to me to indicate such familiarity, so as others have
suggested, perhaps the best answer is to first spend some time with an
R tutorial or two and *not* try to mimic bad spreadsheet practices in
R.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 31, 2017 at 2:49 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You can also look at the knitr-RMarkdown work flow, or the knitr-latex work flow. In both of these it is reasonable to convert your data frame to a temporary character-only form purely for output purposes. However, one can usually use an existing function to push your results out without damaging your working data.
>
> It is important to separate your data from your output because mixing results (totals) with data makes using the data further extremely difficult. Mixing them is one of the major flaws of the spreadsheet model of computation, and it causes problems there as well as in R.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 31, 2017 1:05:09 PM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>>Again, you should always copy the R-help list on replies to your OP.
>>
>>The short answer is you **shouldn't** replace NAs with blanks in your
>>matrix or dataframe.  NA is the proper designation for those cell
>>positions. Replacing NA with a "blank" in a dataframe will convert
>>that column to a "character" mode, precluding further numeric
>>manipulation of those columns.
>>
>>Consider your workflow:  are you tying to export a table? If so, take
>>a look at installing pander (see 'missing' argument on webpage below):
>>
>>https://cran.r-project.org/web/packages/pander/README.html
>>
>>Finally, please review the Introductory PDF, available here:
>>
>>https://cran.r-project.org/doc/manuals/R-intro.pdf
>>
>>HTH, Bill.
>>
>>William Michels, Ph.D.
>>
>>
>>
>>On Fri, Mar 31, 2017 at 11:21 AM, BR_email <br at dmstat1.com> wrote:
>>> William:
>>> How can I replace the "NAs" with blanks?
>>> Bruce
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>>
>>>
>>> William Michels wrote:
>>>>
>>>> I'm sure there are more efficient ways, but this works:
>>>>
>>>>> test1 <- matrix(runif(50), nrow=10, ncol=5)
>>>>> ## test1 <- as.data.frame(test1)
>>>>> test1 <- rbind(test1, NA)
>>>>> test1[11, c(1,3)] <- colSums(test1[1:10,c(1,3)])
>>>>> test1
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Bill.
>>>>
>>>> William Michels, Ph.D.
>>>>
>>>>
>>>>
>>>> On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com>
>>wrote:
>>>>>
>>>>> Hi R'ers:
>>>>> Given a data.frame of five columns and ten rows.
>>>>> I would like to take the sum of, say, the first and third columns
>>only.
>>>>> For the remaining columns, I do not want any calculations, thus
>>rending
>>>>> their "values" on the "total" row blank. The sum/total row is to be
>>combined
>>>>> to the original data.frame, yielding a data.frame with five columns
>>and
>>>>> eleven rows.
>>>>>
>>>>> Thanks, in advance.
>>>>> Bruce
>>>>>
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr  1 02:14:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 31 Mar 2017 17:14:33 -0700
Subject: [R] pull stat out of summary
In-Reply-To: <CAM_vjunURNC80BxSb4FmqP4aazJXunCTJMzGFtPe87p44jO_Gw@mail.gmail.com>
References: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
	<CAM_vjunURNC80BxSb4FmqP4aazJXunCTJMzGFtPe87p44jO_Gw@mail.gmail.com>
Message-ID: <CAGxFJbRQoYzkM2V6rf7EO-DpQcg0uLHJ_p3hAFXzcS3cteAbdA@mail.gmail.com>

?str

tells you the structure of any object. *Learn to use it!*

It may well be the that you *cannot* do what you describe. As you
should know by now in your "learning curve", invoking

> obj

at the console silently invokes the print method for obj, and what is
printed may in fact be calculated on the fly in the print method and
not stored in an object anywhere.

?print.summary.lm

is such an example:  p-values are calculated and printed, but not stored.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 31, 2017 at 4:54 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> The short answer is that hold isn't a list-like object, and $ only
> works with list-like objects (lists and data frames, mainly).
>
> You can get the full explanation (VERY full), at
> ?Extract
> or any of its aliases, like
> ?'$'
> or
> ?'['
>
> Sarah
>
> On Fri, Mar 31, 2017 at 7:11 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
>> Continuing my learning curve after 25_ years with using SAS. Want to pull
>> the "Mean" forom the summary of something...
>>
>> test <- rnorm(1000,1.5,1.25)
>>
>> hold <- summary(test)
>>
>> names(hold)
>> [1] "Min."    "1st Qu." "Median"  "Mean"    "3rd Qu." "Max."
>>
>> OK, so "Mean" is in there.
>> So, is there a short form answer for why hold$Mean throws an error, and
>> hold["Mean"} returns the mean (as desired)?
>>
>> Silly question I know,  but gotta start somewhere...
>>
>> Thanks...
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sat Apr  1 02:15:21 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 31 Mar 2017 20:15:21 -0400
Subject: [R] Variation of bubble sort (based on divisors)
In-Reply-To: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>
References: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>
Message-ID: <4AF0AE3D-DC40-4FC4-85D6-B94A00350610@utoronto.ca>

This looks opaque and hard to maintain.
It seems to me that a better strategy is to subset your vector with modulo expressions, use a normal sort on each of the subsets, and add the result to each other. 0 and 1 need to be special-cased.


myPrimes <- c(2, 3, 5)
mySource <- sample(0:10)

# special case 0,1
sel <- mySource < 2  
myTarget <- sort(mySource[sel])
mySource <- mySource[!sel]

# Iterate over requested primes
for (num in myPrimes) {
    sel <- !as.logical(mySource %% num)
    myTarget <- c(myTarget, sort(mySource[sel]))
    mySource <- mySource[!sel]
}

# Add remaining elements
myTarget <- c(myTarget, sort(mySource))  


B.






> On Mar 31, 2017, at 2:16 PM, Piotr Koller <pittbox33 at gmail.com> wrote:
> 
> Hi, I'd like to create a function that will sort values of a vector on a
> given basis:
> 
> -zeros
> 
> -ones
> 
> -numbers divisible by 2
> 
> -numbers divisible by 3 (but not by 2)
> 
> -numbers divisible by 5 (but not by 2 and 3)
> 
> etc.
> 
> I also want to omit zeros in those turns. So when I have a given vector of
> c(0:10), I want to receive 0 1 2 4 6 8 10 3 9 5 7 I think it'd be the best
> to use some variation of bubble sort, so it'd look like that
> 
> sort <- function(x) {
> for (j in (length(x)-1):1) {
>   for (i in j:(length(x)-1)) {
>     if (x[i+1]%%divisor==0 && x[i]%%divisor!=0) {
>      temp <- x[i]
>      x[i] <- x[i+1]
>      x[i+1] <- temp
>      }
>    }
>  }
> return(x)}
> 
> This function works out well on a given divisor and incresing sequences.
> 
> sort <- function(x) {
>  for (j in (length(x)-1):1) {
>     for (i in j:(length(x)-1)) {
>       if (x[i+1]%%5==0 && x[i]%%5!=0) {
>        temp <- x[i]
>        x[i] <- x[i+1]
>        x[i+1] <- temp
>       }
>      }
>     }
>  return(x)
> }
> 
> x <- c(1:10)
> print(x)
> print(bubblesort(x))
> 
> This function does its job. It moves values divisible by 5 on the
> beginning. The question is how to increase divisor every "round" ?
> 
> Thanks for any kind of help
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Sat Apr  1 03:52:29 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Fri, 31 Mar 2017 18:52:29 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CAGxFJbSC_0iojZS2ohcBUHoEpbHfnA-NeJU34AknDxVc26YpfA@mail.gmail.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<CAA99HCwj-qV9rbBG8xaAiUzFrw84a0jsmbQWONQdfYZNSv2vPA@mail.gmail.com>
	<11fcc6a3-39ef-6d93-f1cc-3fbca3b22698@dmstat1.com>
	<CAA99HCwD0oEwi5rOrGK_-rri+=mmU0wvv_wWzSVTQ9fkdtVc_A@mail.gmail.com>
	<B3EDDFBE-C1E4-4A5B-9DB7-C2E78E680923@dcn.davis.ca.us>
	<CAGxFJbSC_0iojZS2ohcBUHoEpbHfnA-NeJU34AknDxVc26YpfA@mail.gmail.com>
Message-ID: <CAA99HCz-cKZy80uR0Qmjd=RmTCfa7m_Jw_KotEyWUjHt1Ebq_w@mail.gmail.com>

Thank you Jeff for pointing out bad spreadsheet practices in R,
seconded by Mathew and Bert.

I should have considered creating a second dataframe ("test1_summary")
to distinguish raw from processed data. Those who want to address
memory issues caused by unnecessary duplication, feel free to chime
in.

Finally, thank you Bert for your most informative post on adding
attributes to dataframes. I really learned a lot!

Best Regards,

Bill.

William Michels, Ph.D.



On Fri, Mar 31, 2017 at 4:59 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> All:
>
> 1. I agree wholeheartedly with prior responses.
>
> 2. But let's suppose that for some reason, you *did* want to carry
> around some "calculated values" with the data frame. Then one way to
> do it is to add them as attributes to the data frame. This way they
> cannot "pollute" the data in the way Jeff warned against; e.g.
>
> attr(your_frame,"colsums") <- colSums(your_frame)
>
> This of course calculates them all, but you can of course just attach
> some (e.g. colSums(your_frame[,c(1,3)] )
>
> 3. This, of course, has the disadvantage of requiring recalculation of
> the attribute if the data changes, which is an invitation to problems.
> A better approach might be to attach the *function* that does the
> calculation as an attribute, which when invoked always uses the
> current data:
>
> attr(your_frame,"colsums") <- function(x)colSums(x)
>
> For example:
>
> df <- data.frame(x=1:5,y=21:25)
> attr(df,"colsums")<- function(x)colSums(x)
>
> ## then:
>> attr(df,"colsums")(df)
>   x   y
>  15 115
>
> ## add a row
>> df[6,] <- rep(100,2)
>> attr(df,"colsums")(df)
>   x   y
> 115 215
>
>
> This survives changing the name of df:
>
>> dat <- df
>> attr(dat,"colsums")(dat)
>   x   y
> 115 215
>
> As it stands, the call: attr(df,"colsums")(df)  is a bit clumsy; one
> could easily write a function that does this sort of thing more
> cleanly, as, for example, is done via the "selfStart" functionality
> for nonlinear models.
>
> But all this presupposes that the OP is familiar with R programming
> paradigms, especially the use of functions as first class objects, and
> the language in general. While I may have missed this, his posts do
> not seem to me to indicate such familiarity, so as others have
> suggested, perhaps the best answer is to first spend some time with an
> R tutorial or two and *not* try to mimic bad spreadsheet practices in
> R.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 31, 2017 at 2:49 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> You can also look at the knitr-RMarkdown work flow, or the knitr-latex work flow. In both of these it is reasonable to convert your data frame to a temporary character-only form purely for output purposes. However, one can usually use an existing function to push your results out without damaging your working data.
>>
>> It is important to separate your data from your output because mixing results (totals) with data makes using the data further extremely difficult. Mixing them is one of the major flaws of the spreadsheet model of computation, and it causes problems there as well as in R.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 31, 2017 1:05:09 PM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>>>Again, you should always copy the R-help list on replies to your OP.
>>>
>>>The short answer is you **shouldn't** replace NAs with blanks in your
>>>matrix or dataframe.  NA is the proper designation for those cell
>>>positions. Replacing NA with a "blank" in a dataframe will convert
>>>that column to a "character" mode, precluding further numeric
>>>manipulation of those columns.
>>>
>>>Consider your workflow:  are you tying to export a table? If so, take
>>>a look at installing pander (see 'missing' argument on webpage below):
>>>
>>>https://cran.r-project.org/web/packages/pander/README.html
>>>
>>>Finally, please review the Introductory PDF, available here:
>>>
>>>https://cran.r-project.org/doc/manuals/R-intro.pdf
>>>
>>>HTH, Bill.
>>>
>>>William Michels, Ph.D.
>>>
>>>
>>>
>>>On Fri, Mar 31, 2017 at 11:21 AM, BR_email <br at dmstat1.com> wrote:
>>>> William:
>>>> How can I replace the "NAs" with blanks?
>>>> Bruce
>>>>
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>>
>>>>
>>>> William Michels wrote:
>>>>>
>>>>> I'm sure there are more efficient ways, but this works:
>>>>>
>>>>>> test1 <- matrix(runif(50), nrow=10, ncol=5)
>>>>>> ## test1 <- as.data.frame(test1)
>>>>>> test1 <- rbind(test1, NA)
>>>>>> test1[11, c(1,3)] <- colSums(test1[1:10,c(1,3)])
>>>>>> test1
>>>>>
>>>>>
>>>>> HTH,
>>>>>
>>>>> Bill.
>>>>>
>>>>> William Michels, Ph.D.
>>>>>
>>>>>
>>>>>
>>>>> On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>wrote:
>>>>>>
>>>>>> Hi R'ers:
>>>>>> Given a data.frame of five columns and ten rows.
>>>>>> I would like to take the sum of, say, the first and third columns
>>>only.
>>>>>> For the remaining columns, I do not want any calculations, thus
>>>rending
>>>>>> their "values" on the "total" row blank. The sum/total row is to be
>>>combined
>>>>>> to the original data.frame, yielding a data.frame with five columns
>>>and
>>>>>> eleven rows.
>>>>>>
>>>>>> Thanks, in advance.
>>>>>> Bruce
>>>>>>
>>>>>>
>>>>>> ______________
>>>>>> Bruce Ratner PhD
>>>>>> The Significant Statistician?
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Apr  1 16:08:28 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 1 Apr 2017 16:08:28 +0200
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
	<5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
Message-ID: <8477C961-A283-47E7-8BA0-35D2132DDF8C@gmail.com>

[This is drifting somewhat awy from the original intention of the topic, I think].

This looks like a build dependency. I get 

3.3.2 (yeah, I know, should upgrade):

> (1+2i)/0
[1] NaN+NaNi

R-devel, march 24:

> (1+2i)/0
[1] Inf+Infi

on the *same* machine. The difference is that one is stock CRAN, the other was built locally. So with the toolchain being updated for 3.4.0, this difference would likely go away. Or at least change...

-pd


> On 31 Mar 2017, at 19:15 , Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
> I have noted a difference between R on macOS en on Kubuntu Trusty (64bits) with complex division.
> I don't know what would happen R on Windows.
> 
> R.3.3.3:
> 
> macOS (10.11.6)
> -----------------
>> (1+2i)/0
> [1] NaN+NaNi
>> (-1+2i)/0
> [1] NaN+NaNi
>> 
>> 1i/0
> [1] NaN+NaNi
>> 1i/(0+0i)
> [1] NaN+NaNi
> 
> 
> KubuntuTrusty
> -----------------
>> (1+2i)/0
> [1] Inf+Infi
>> (-1+2i)/0
> [1] -Inf+Infi
>> 
>> 1i/0
> [1] NaN+Infi
>> 1i/(0+0i)
> [1] NaN+Infi
> 
> Interesting to see what R on Windows delivers.
> 
> Berend Hasselman
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Sat Apr  1 16:10:59 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 1 Apr 2017 16:10:59 +0200
Subject: [R] pull stat out of summary
In-Reply-To: <CAM_vjunURNC80BxSb4FmqP4aazJXunCTJMzGFtPe87p44jO_Gw@mail.gmail.com>
References: <7af6d70a-5db8-5068-a50c-c62e86aa0f9b@gmail.com>
	<CAM_vjunURNC80BxSb4FmqP4aazJXunCTJMzGFtPe87p44jO_Gw@mail.gmail.com>
Message-ID: <D72A7DB3-99A6-40BF-BAD2-DC980FF1F912@gmail.com>


> On 01 Apr 2017, at 01:54 , Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> The short answer is that hold isn't a list-like object, and $ only
> works with list-like objects (lists and data frames, mainly).
> 
> You can get the full explanation (VERY full), at
> ?Extract
> or any of its aliases, like
> ?'$'
> or
> ?'['
> 

...and the intermediate answer is: hold["Mean"]

-pd

> Sarah
> 
> On Fri, Mar 31, 2017 at 7:11 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
>> Continuing my learning curve after 25_ years with using SAS. Want to pull
>> the "Mean" forom the summary of something...
>> 
>> test <- rnorm(1000,1.5,1.25)
>> 
>> hold <- summary(test)
>> 
>> names(hold)
>> [1] "Min."    "1st Qu." "Median"  "Mean"    "3rd Qu." "Max."
>> 
>> OK, so "Mean" is in there.
>> So, is there a short form answer for why hold$Mean throws an error, and
>> hold["Mean"} returns the mean (as desired)?
>> 
>> Silly question I know,  but gotta start somewhere...
>> 
>> Thanks...
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From b.rowlingson at lancaster.ac.uk  Sat Apr  1 17:00:30 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 1 Apr 2017 16:00:30 +0100
Subject: [R] Deploying R on the cloud - Help Please
In-Reply-To: <a58846415fdd4fcc83fd8f1a02df8707@EX-0-HT0.lancs.local>
References: <a58846415fdd4fcc83fd8f1a02df8707@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPYGaoqnLYDaC3N6WRzVj0NxRM2-GN3fCSnVfKYWAa0ag@mail.gmail.com>

On Fri, Mar 31, 2017 at 10:43 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> Hello,
>
> I work for a large organization who is looking to productionize (deploy)
> models built in R on the cloud. Currently, we were looking into IBM
> Bluemix, but I?ve been told only Python is supported for model deployment.
>
> I?d appreciate if anyone can point me to the right direction here in terms
> of best practices / companies that support deploying R models on the cloud.

 Where have you looked already? There's a couple of companies you
might have heard of, a little programming outfit called "Microsoft"
and a boutique database business called "Oracle" who have a bit of
expertise in R at scale. Try contacting them.

Barry


From art.tem.us at gmail.com  Sat Apr  1 05:53:28 2017
From: art.tem.us at gmail.com (Art U)
Date: Fri, 31 Mar 2017 23:53:28 -0400
Subject: [R] Correlation between continuous and binary vectors.
Message-ID: <CAKY_brGyLDvX=E-mnpTf1Minvjcx=ud8zLahXL0q0U5hUmumgg@mail.gmail.com>

Hi,
I'm trying to create number of vectors, part of them are binary and part
are continuous. Is there a way in R to generate them with specific
correlation between each pair?
Thank you in advance.
Ariel
-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From usmansuleman at hotmail.com  Sat Apr  1 09:26:27 2017
From: usmansuleman at hotmail.com (Usman Suleman)
Date: Sat, 1 Apr 2017 00:26:27 -0700 (PDT)
Subject: [R] Deploying R on the cloud - Help Please
In-Reply-To: <CAAyVsX+zVVJ-r3GCE=jHvF=wN4LvTPz+sMfd0YH2Ack=ADA6Zg@mail.gmail.com>
References: <CAAyVsX+zVVJ-r3GCE=jHvF=wN4LvTPz+sMfd0YH2Ack=ADA6Zg@mail.gmail.com>
Message-ID: <f8705d12-aa3c-440b-bc95-f546f263cf76@googlegroups.com>

Hello:
You might consider implementing RStudio server on an AWS instance in the 
cloud.
You could purchase the pro version or the opensource version.
I recently installed (for a client) opensource versions of RStudio server 
and Shiny server
on an AWS Ubuntu instance.  It is not that complicated.  A few people have 
written
blogs about it.  Check r-bloggers.com for starters.
Best,
...Usman Suleman

On Friday, March 31, 2017 at 5:44:50 PM UTC-4, Axel Urbiz wrote:
>
> Hello,
>
> I work for a large organization who is looking to productionize (deploy)
> models built in R on the cloud. Currently, we were looking into IBM
> Bluemix, but I?ve been told only Python is supported for model deployment.
>
> I?d appreciate if anyone can point me to the right direction here in terms
> of best practices / companies that support deploying R models on the cloud.
>
> Thank you for your help.
>
> Regards,
>
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From br at dmstat1.com  Sat Apr  1 18:32:58 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 1 Apr 2017 12:32:58 -0400
Subject: [R] How can I delete column yhat AND STILL retain the order of
	Response?
Message-ID: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>

Hi R'ers:
Attached, my R_code, the dataset, and my query.
How can I delete column yhat AND STILL retain the order of Response?
When I remove yhat, the resultant dataset has Response in the original 
order,
                     not the reordered version I created.

Any help is greatly accepted.
Thank you, in advance.

Bruce

-- 

-------------- next part --------------
#How can I delete column yhat AND STILL retain the order of Response?


Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
Response
Response    <- data.frame(Response)
attach(Response)
Response
Response    <- Response[order(-yhat),]
Response    <- Response[rev(order(yhatResponse$yhat)),]
Response


From boris.steipe at utoronto.ca  Sat Apr  1 18:37:58 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 1 Apr 2017 12:37:58 -0400
Subject: [R] Correlation between continuous and binary vectors.
In-Reply-To: <CAKY_brGyLDvX=E-mnpTf1Minvjcx=ud8zLahXL0q0U5hUmumgg@mail.gmail.com>
References: <CAKY_brGyLDvX=E-mnpTf1Minvjcx=ud8zLahXL0q0U5hUmumgg@mail.gmail.com>
Message-ID: <705545BB-5990-4944-9E0C-64651093821F@utoronto.ca>

Yes.



> On Mar 31, 2017, at 11:53 PM, Art U <art.tem.us at gmail.com> wrote:
> 
> Hi,
> I'm trying to create number of vectors, part of them are binary and part
> are continuous. Is there a way in R to generate them with specific
> correlation between each pair?
> Thank you in advance.
> Ariel
> -- 
> *I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
> or plague*... *Whatever*. *No-one left to act normal for. No need to hide
> who I really am. It would be... freeing*. *...*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Sat Apr  1 20:19:07 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 1 Apr 2017 11:19:07 -0700
Subject: [R] The R-help community list was started on this day 20 years ago
Message-ID: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>

Today, it is been 20 years since Martin M?chler started the R-help
community list (https://stat.ethz.ch/pipermail/r-help/). The first
post was written by Ross Ihaka on 1997-04-01:

Subject: R-alpha: R-testers: pmin heisenbug
From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
When: Tue Apr 1 10:35:48 CEST 1997
Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html

This is a post about R's memory model. We're talking R v0.50 beta. I
think that the paragraph at the end provides a nice anecdote on the
importance not to be overwhelmed by problems ahead:

   "(The consumption of one cell per string is perhaps the major
memory problem in R - we didn't design it with large problems in mind.
It is probably fixable, but it will mean a lot of work)."

We all know the story; an endless number of hours has been put in by
many contributors throughout the years, making The R Project and its
community the great experience it is today.

Thank you!

Henrik


From ruipbarradas at sapo.pt  Sat Apr  1 20:59:25 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Apr 2017 19:59:25 +0100
Subject: [R] How can I delete column yhat AND STILL retain the order of
 Response?
In-Reply-To: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
References: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
Message-ID: <58DFF88D.1070809@sapo.pt>

Hello,

1) We don't have access to your file firstRdata.csv so what I'll say is 
just an untested guess. You can post some of your data with the 
following R command.

dput(head(Response, 20))  # paste the output of this in a mail

2) First you use read.csv that outputs a data.frame and then do 
data.frame(Response). Useless. Response already is a df.

3) I believe the trouble you're facing comes from your use of attach(). 
This function is _never_ needed and is cause of all sorts of bugs. In 
particular, what you are ordering is the attached copy of Response, and 
all changes you do to it will only have effect on the copy. The original 
is left as it were.

So run the same code (with the obvious bug yhatResponse$yhat corrected) 
but eliminating the 'attach' instruction. And see if it reorders Response.

Hope this helps,

Rui Barradas


Em 01-04-2017 17:32, BR_email escreveu:
> Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
> Response
> Response    <- data.frame(Response)
> attach(Response)
> Response
> Response    <- Response[order(-yhat),]
> Response    <- Response[rev(order(yhatResponse$yhat)),]
> Response


From br at dmstat1.com  Sat Apr  1 21:13:56 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 1 Apr 2017 15:13:56 -0400
Subject: [R] How can I delete column yhat AND STILL retain the order of
 Response?
In-Reply-To: <58DFF88D.1070809@sapo.pt>
References: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
	<58DFF88D.1070809@sapo.pt>
Message-ID: <9bc0e097-87da-04bd-f158-4256bef4abe1@dmstat1.com>

Rui:
Thanks. I will try it.
FYI: I did attached the data, but here it is re-attached.

Thanks, again.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Rui Barradas wrote:
> Hello,
>
> 1) We don't have access to your file firstRdata.csv so what I'll say 
> is just an untested guess. You can post some of your data with the 
> following R command.
>
> dput(head(Response, 20))  # paste the output of this in a mail
>
> 2) First you use read.csv that outputs a data.frame and then do 
> data.frame(Response). Useless. Response already is a df.
>
> 3) I believe the trouble you're facing comes from your use of 
> attach(). This function is _never_ needed and is cause of all sorts of 
> bugs. In particular, what you are ordering is the attached copy of 
> Response, and all changes you do to it will only have effect on the 
> copy. The original is left as it were.
>
> So run the same code (with the obvious bug yhatResponse$yhat 
> corrected) but eliminating the 'attach' instruction. And see if it 
> reorders Response.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 01-04-2017 17:32, BR_email escreveu:
>> Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", 
>> header=TRUE)
>> Response
>> Response    <- data.frame(Response)
>> attach(Response)
>> Response
>> Response    <- Response[order(-yhat),]
>> Response    <- Response[rev(order(yhatResponse$yhat)),]
>> Response
>
>
>


From br at dmstat1.com  Sat Apr  1 21:18:17 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 1 Apr 2017 15:18:17 -0400
Subject: [R] How can I delete column yhat AND STILL retain the order of
 Response?
In-Reply-To: <58DFF88D.1070809@sapo.pt>
References: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
	<58DFF88D.1070809@sapo.pt>
Message-ID: <5967dfdd-417e-dad8-0938-9328cfb26b0d@dmstat1.com>

Rui:
Success!
Thank you so much.
Bruce

  

Rui Barradas wrote:
> Hello,
>
> 1) We don't have access to your file firstRdata.csv so what I'll say 
> is just an untested guess. You can post some of your data with the 
> following R command.
>
> dput(head(Response, 20))  # paste the output of this in a mail
>
> 2) First you use read.csv that outputs a data.frame and then do 
> data.frame(Response). Useless. Response already is a df.
>
> 3) I believe the trouble you're facing comes from your use of 
> attach(). This function is _never_ needed and is cause of all sorts of 
> bugs. In particular, what you are ordering is the attached copy of 
> Response, and all changes you do to it will only have effect on the 
> copy. The original is left as it were.
>
> So run the same code (with the obvious bug yhatResponse$yhat 
> corrected) but eliminating the 'attach' instruction. And see if it 
> reorders Response.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 01-04-2017 17:32, BR_email escreveu:
>> Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", 
>> header=TRUE)
>> Response
>> Response    <- data.frame(Response)
>> attach(Response)
>> Response
>> Response    <- Response[order(-yhat),]
>> Response    <- Response[rev(order(yhatResponse$yhat)),]
>> Response
>
>
>


From glennmschultz at me.com  Sat Apr  1 19:05:10 2017
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 01 Apr 2017 17:05:10 +0000 (GMT)
Subject: [R] modifying list in loop
Message-ID: <c8265987-fec3-4b65-ac55-49ec57a3ca38@me.com>

All,

I am working on structuring a FHLMC credit risk transfer deal. ?I have the deal modeled as a list of lists as shown below. ?I would like to fill in the CashFlows. ?The first step is simply to assign the current balance to the first position in CashFlow$BeginBal. ?I am using the below function to update the values in the list. ?The function works properly but the list values are not updated. ?Any help is appreciated.

Best,
Glenn

BeginBal <- function(deal,period){
numtranches = length(deal)
tranches = seq(numtranches,1,-1)
for(tranche in seq_along(tranches)){
cashflow <- NULL
if(period == 1) {cashflow <- 
c(deal[[tranche]]$CashFlow$BeginBal, deal[[tranche]]$CurrBal)
} else {
cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, 
deal[[tranche]]$CashFlow$EndingBal[[period -1]])}
deal[[tranche]]$CashFlow$BeginBal <- cashflow
print(deal[[tranche]]$CashFlow$BeginBal)
}
}

for(period in 1:1){
BeginBal(Deal, period)
}

structure(list(OC = structure(list(Tranche = "OC", Cusip = NULL, 
Coupon = 0L, Index = NULL, Margin = NULL, OrigBal = 25905603, 
CurrBal = 25905603, CashFlow = structure(list(BeginBal = list(), 
WriteDown = list(), WriteUp = list(), EndBal = list()), .Names = c("BeginBal", 
"WriteDown", "WriteUp", "EndBal"))), .Names = c("Tranche", 
"Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal", "CashFlow"
)), B2H = structure(list(Tranche = "B2H", Cusip = NULL, Coupon = 10.7794, 
Index = "LIBOR1M", Margin = 10, OrigBal = 152827059, CurrBal = 152827059, 
IssueDate = "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", 
NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", 
CashFlow = structure(list(BeginBal = list(), Interest = list(), 
WriteDown = list(), WriteUp = list(), SeniorReduction = list(), 
SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), B2 = structure(list(
Tranche = "B2", Cusip = NULL, Coupon = 10.77944, Index = "LIBOR1M", 
Margin = 10, OrigBal = 1.7e+07, CurrBal = 1.7e+07, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), B1H = structure(list(
Tranche = "B1H", Cusip = NULL, Coupon = 5.72944, Index = "LIBOR1M", 
Margin = 4.95, OrigBal = 49827059, CurrBal = 49827059, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), B1 = structure(list(
Tranche = "B1", Cusip = NULL, Coupon = 5.72944, Index = "LIBOR1M", 
Margin = 4.95, OrigBal = 1.2e+08, CurrBal = 1.2e+08, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), M2H = structure(list(
Tranche = "M2H", Cusip = NULL, Coupon = 4.02944, Index = "LIBOR1M", 
Margin = 3.25, OrigBal = 151463884, CurrBal = 151463884, 
IssueDate = "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", 
NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", 
CashFlow = structure(list(BeginBal = list(), Interest = list(), 
WriteDown = list(), WriteUp = list(), SeniorReduction = list(), 
SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), M2 = structure(list(
Tranche = "M2", Cusip = NULL, Coupon = 4.02944, Index = "LIBOR1M", 
Margin = 3.25, OrigBal = 3.75e+08, CurrBal = 3.75e+08, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), M1H = structure(list(
Tranche = "M1H", Cusip = NULL, Coupon = 1.97944, Index = "LIBOR1M", 
Margin = 1.2, OrigBal = 117584943, CurrBal = 117584943, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), M1 = structure(list(
Tranche = "M1", Cusip = NULL, Coupon = 1.97944, Index = "LIBOR1M", 
Margin = 1.2, OrigBal = 2.9e+08, CurrBal = 2.9e+08, IssueDate = "02-01-2017", 
DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", 
MaturityDate = "07-25-2029", CashFlow = structure(list(BeginBal = list(), 
Interest = list(), WriteDown = list(), WriteUp = list(), 
SeniorReduction = list(), SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow")), A1H = structure(list(
Tranche = "AH", Cusip = NULL, Coupon = 0L, Index = "LIBOR1M", 
Margin = 1.2, OrigBal = 32691709407, CurrBal = 32691709407, 
IssueDate = "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017", 
NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", 
CashFlow = structure(list(BeginBal = list(), Interest = list(), 
WriteDown = list(), WriteUp = list(), SeniorReduction = list(), 
SubReduction = list(), EndBal = list()), .Names = c("BeginBal", 
"Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction", 
"EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", 
"Margin", "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate", 
"NextPmtDate", "MaturityDate", "CashFlow"))), .Names = c("OC", 
"B2H", "B2", "B1H", "B1", "M2H", "M2", "M1H", "M1", "A1H"))



BeginBal <- function(deal,period){
numtranches = length(deal)
tranches = seq(numtranches,1,-1)
for(tranche in seq_along(tranches)){
cashflow <- NULL
if(period == 1) {cashflow <- 
c(deal[[tranche]]$CashFlow$BeginBal, deal[[tranche]]$CurrBal)
} else {
cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, 
deal[[tranche]]$CashFlow$EndingBal[[period -1]])}
deal[[tranche]]$CashFlow$BeginBal <- cashflow
print(deal[[tranche]]$CashFlow$BeginBal)
}
}

From jdnewmil at dcn.davis.ca.us  Sat Apr  1 21:37:22 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 01 Apr 2017 12:37:22 -0700
Subject: [R] How can I delete column yhat AND STILL retain the order of
	Response?
In-Reply-To: <9bc0e097-87da-04bd-f158-4256bef4abe1@dmstat1.com>
References: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
	<58DFF88D.1070809@sapo.pt>
	<9bc0e097-87da-04bd-f158-4256bef4abe1@dmstat1.com>
Message-ID: <3F33AD6B-52D5-4C39-92FE-5D96365BC5A2@dcn.davis.ca.us>

Eventually you will think to read the Posting Guide, which discusses which attachments are likely to be allowed on the mailing list. Most users find that pasting a minimal amount of data into the main body of the email is the simplest way to be sure the info will get through to someone who can help. 
-- 
Sent from my phone. Please excuse my brevity.

On April 1, 2017 12:13:56 PM PDT, BR_email <br at dmstat1.com> wrote:
>Rui:
>Thanks. I will try it.
>FYI: I did attached the data, but here it is re-attached.
>
>Thanks, again.
>Bruce
>
>Bruce Ratner, Ph.D.
>The Significant Statistician?
>(516) 791-3544
>Statistical Predictive Analtyics -- www.DMSTAT1.com
>Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>  
>
>Rui Barradas wrote:
>> Hello,
>>
>> 1) We don't have access to your file firstRdata.csv so what I'll say 
>> is just an untested guess. You can post some of your data with the 
>> following R command.
>>
>> dput(head(Response, 20))  # paste the output of this in a mail
>>
>> 2) First you use read.csv that outputs a data.frame and then do 
>> data.frame(Response). Useless. Response already is a df.
>>
>> 3) I believe the trouble you're facing comes from your use of 
>> attach(). This function is _never_ needed and is cause of all sorts
>of 
>> bugs. In particular, what you are ordering is the attached copy of 
>> Response, and all changes you do to it will only have effect on the 
>> copy. The original is left as it were.
>>
>> So run the same code (with the obvious bug yhatResponse$yhat 
>> corrected) but eliminating the 'attach' instruction. And see if it 
>> reorders Response.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 01-04-2017 17:32, BR_email escreveu:
>>> Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", 
>>> header=TRUE)
>>> Response
>>> Response    <- data.frame(Response)
>>> attach(Response)
>>> Response
>>> Response    <- Response[order(-yhat),]
>>> Response    <- Response[rev(order(yhatResponse$yhat)),]
>>> Response
>>
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr  1 22:00:29 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Sat, 1 Apr 2017 16:00:29 -0400
Subject: [R] How can I delete column yhat AND STILL retain the order of
	Response?
In-Reply-To: <3F33AD6B-52D5-4C39-92FE-5D96365BC5A2@dcn.davis.ca.us>
References: <0764e25b-8b8f-cf07-ab79-12de421394d0@dmstat1.com>
	<58DFF88D.1070809@sapo.pt>
	<9bc0e097-87da-04bd-f158-4256bef4abe1@dmstat1.com>
	<3F33AD6B-52D5-4C39-92FE-5D96365BC5A2@dcn.davis.ca.us>
Message-ID: <C70BD661-5AE5-4A16-BB57-95FC70031C90@dmstat1.com>

Jeff:
Thanks for the info. Sorry for the misstep.
Bruce 


______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 1, 2017, at 3:37 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Eventually you will think to read the Posting Guide, which discusses which attachments are likely to be allowed on the mailing list. Most users find that pasting a minimal amount of data into the main body of the email is the simplest way to be sure the info will get through to someone who can help. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On April 1, 2017 12:13:56 PM PDT, BR_email <br at dmstat1.com> wrote:
>> Rui:
>> Thanks. I will try it.
>> FYI: I did attached the data, but here it is re-attached.
>> 
>> Thanks, again.
>> Bruce
>> 
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>> 
>> 
>> Rui Barradas wrote:
>>> Hello,
>>> 
>>> 1) We don't have access to your file firstRdata.csv so what I'll say 
>>> is just an untested guess. You can post some of your data with the 
>>> following R command.
>>> 
>>> dput(head(Response, 20))  # paste the output of this in a mail
>>> 
>>> 2) First you use read.csv that outputs a data.frame and then do 
>>> data.frame(Response). Useless. Response already is a df.
>>> 
>>> 3) I believe the trouble you're facing comes from your use of 
>>> attach(). This function is _never_ needed and is cause of all sorts
>> of 
>>> bugs. In particular, what you are ordering is the attached copy of 
>>> Response, and all changes you do to it will only have effect on the 
>>> copy. The original is left as it were.
>>> 
>>> So run the same code (with the obvious bug yhatResponse$yhat 
>>> corrected) but eliminating the 'attach' instruction. And see if it 
>>> reorders Response.
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> 
>>> Em 01-04-2017 17:32, BR_email escreveu:
>>>> Response    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", 
>>>> header=TRUE)
>>>> Response
>>>> Response    <- data.frame(Response)
>>>> attach(Response)
>>>> Response
>>>> Response    <- Response[order(-yhat),]
>>>> Response    <- Response[rev(order(yhatResponse$yhat)),]
>>>> Response
>>> 
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From lorenzo.isella at gmail.com  Sat Apr  1 22:37:57 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 1 Apr 2017 22:37:57 +0200
Subject: [R] Windowing Time Series in The Past
Message-ID: <20170401203757.GB1812@chicca>

Dear All,
I am sure the solution is a one liner, but I am a bit struggling.
Given a time series which starts at a given time t_ini, I would like to set
a initial start time farther away in the past and have NA before t_ini
(I need this to align different time series).
For instance


d<-ts(seq(20), start=1986)

I would like e.g. d to start at 1980 and consist of NA's before 1986.
Ho can I achieve that?
Many thanks

Lorenzo


From dwinsemius at comcast.net  Sat Apr  1 22:42:42 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Apr 2017 13:42:42 -0700
Subject: [R] Correlation between continuous and binary vectors.
In-Reply-To: <CAKY_brGyLDvX=E-mnpTf1Minvjcx=ud8zLahXL0q0U5hUmumgg@mail.gmail.com>
References: <CAKY_brGyLDvX=E-mnpTf1Minvjcx=ud8zLahXL0q0U5hUmumgg@mail.gmail.com>
Message-ID: <EEFFE1CE-BAA4-4435-8198-17DDAF460476@comcast.net>

I suspect this has been discussed in the past in rhelp. My favorite search engine is Markmail

Sent from my iPhone

> On Mar 31, 2017, at 8:53 PM, Art U <art.tem.us at gmail.com> wrote:
> 
> Hi,
> I'm trying to create number of vectors, part of them are binary and part
> are continuous. Is there a way in R to generate them with specific
> correlation between each pair?
> Thank you in advance.
> Ariel
> -- 
> *I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
> or plague*... *Whatever*. *No-one left to act normal for. No need to hide
> who I really am. It would be... freeing*. *...*
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Apr  1 23:07:23 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Apr 2017 22:07:23 +0100
Subject: [R] modifying list in loop
In-Reply-To: <c8265987-fec3-4b65-ac55-49ec57a3ca38@me.com>
References: <c8265987-fec3-4b65-ac55-49ec57a3ca38@me.com>
Message-ID: <58E0168B.3050909@sapo.pt>

Hello,

I don't understand your functions but neither of them returns a value.
And in the loop that calls them

for(period in 1:1){
BeginBal(Deal, period)
}

you don't assign the value of BeginBal to anything, so Deal is never 
updated.

The corrected functions and a way of calling them would be

BeginBal <- function(deal,period){
	numtranches = length(deal)
	tranches = seq(numtranches,1,-1)
	for(tranche in seq_along(tranches)){
		cashflow <- NULL
		if(period == 1) {
			cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, deal[[tranche]]$CurrBal)
		} else {
			cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, 
deal[[tranche]]$CashFlow$EndingBal[[period -1]])
		}
		deal[[tranche]]$CashFlow$BeginBal <- cashflow
		print(deal[[tranche]]$CashFlow$BeginBal)
	}
	deal
}

BeginBal2 <- function(deal,period){
	numtranches = length(deal)
	tranches = seq(numtranches,1,-1)
	for(tranche in seq_along(tranches)){
		cashflow <- NULL
		if(period == 1) {
			cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, deal[[tranche]]$CurrBal)
		} else {
			cashflow <- c(deal[[tranche]]$CashFlow$BeginBal, 
deal[[tranche]]$CashFlow$EndingBal[[period -1]])
		}
		deal[[tranche]]$CashFlow$BeginBal <- cashflow
		print(deal[[tranche]]$CashFlow$BeginBal)
	}
	deal
}


result <- lapply(1:1, function(i) BeginBal(Deal, i))
result


Hope this helps,

Rui Barradas

Em 01-04-2017 18:05, Glenn Schultz escreveu:
> All,
>
> I am working on structuring a FHLMC credit risk transfer deal.  I have
> the deal modeled as a list of lists as shown below.  I would like to
> fill in the CashFlows.  The first step is simply to assign the current
> balance to the first position in CashFlow$BeginBal.  I am using the
> below function to update the values in the list.  The function works
> properly but the list values are not updated.  Any help is appreciated.
>
> Best,
> Glenn
>
> BeginBal <- function(deal,period){
> numtranches = length(deal)
> tranches = seq(numtranches,1,-1)
> for(tranche in seq_along(tranches)){
> cashflow <- NULL
> if(period == 1) {cashflow <- c(deal[[tranche]]$CashFlow$BeginBal,
> deal[[tranche]]$CurrBal)
> } else {
> cashflow <- c(deal[[tranche]]$CashFlow$BeginBal,
> deal[[tranche]]$CashFlow$EndingBal[[period -1]])}
> deal[[tranche]]$CashFlow$BeginBal <- cashflow
> print(deal[[tranche]]$CashFlow$BeginBal)
> }
> }
>
> for(period in 1:1){
> BeginBal(Deal, period)
> }
>
> structure(list(OC = structure(list(Tranche = "OC", Cusip = NULL, Coupon
> = 0L, Index = NULL, Margin = NULL, OrigBal = 25905603, CurrBal =
> 25905603, CashFlow = structure(list(BeginBal = list(), WriteDown =
> list(), WriteUp = list(), EndBal = list()), .Names = c("BeginBal",
> "WriteDown", "WriteUp", "EndBal"))), .Names = c("Tranche", "Cusip",
> "Coupon", "Index", "Margin", "OrigBal", "CurrBal", "CashFlow"
> )), B2H = structure(list(Tranche = "B2H", Cusip = NULL, Coupon =
> 10.7794, Index = "LIBOR1M", Margin = 10, OrigBal = 152827059, CurrBal =
> 152827059, IssueDate = "02-01-2017", DatedDate = "02-01-2017",
> LastPmtDate = "02-01-2017", NextPmtDate = "02-25-2017", MaturityDate =
> "07-25-2029", CashFlow = structure(list(BeginBal = list(), Interest =
> list(), WriteDown = list(), WriteUp = list(), SeniorReduction = list(),
> SubReduction = list(), EndBal = list()), .Names = c("BeginBal",
> "Interest", "WriteDown", "WriteUp", "SeniorReduction", "SubReduction",
> "EndBal"))), .Names = c("Tranche", "Cusip", "Coupon", "Index", "Margin",
> "OrigBal", "CurrBal", "IssueDate", "DatedDate", "LastPmtDate",
> "NextPmtDate", "MaturityDate", "CashFlow")), B2 = structure(list(
> Tranche = "B2", Cusip = NULL, Coupon = 10.77944, Index = "LIBOR1M",
> Margin = 10, OrigBal = 1.7e+07, CurrBal = 1.7e+07, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), B1H = structure(list(
> Tranche = "B1H", Cusip = NULL, Coupon = 5.72944, Index = "LIBOR1M",
> Margin = 4.95, OrigBal = 49827059, CurrBal = 49827059, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), B1 = structure(list(
> Tranche = "B1", Cusip = NULL, Coupon = 5.72944, Index = "LIBOR1M",
> Margin = 4.95, OrigBal = 1.2e+08, CurrBal = 1.2e+08, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), M2H = structure(list(
> Tranche = "M2H", Cusip = NULL, Coupon = 4.02944, Index = "LIBOR1M",
> Margin = 3.25, OrigBal = 151463884, CurrBal = 151463884, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), M2 = structure(list(
> Tranche = "M2", Cusip = NULL, Coupon = 4.02944, Index = "LIBOR1M",
> Margin = 3.25, OrigBal = 3.75e+08, CurrBal = 3.75e+08, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), M1H = structure(list(
> Tranche = "M1H", Cusip = NULL, Coupon = 1.97944, Index = "LIBOR1M",
> Margin = 1.2, OrigBal = 117584943, CurrBal = 117584943, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), M1 = structure(list(
> Tranche = "M1", Cusip = NULL, Coupon = 1.97944, Index = "LIBOR1M",
> Margin = 1.2, OrigBal = 2.9e+08, CurrBal = 2.9e+08, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow")), A1H = structure(list(
> Tranche = "AH", Cusip = NULL, Coupon = 0L, Index = "LIBOR1M", Margin =
> 1.2, OrigBal = 32691709407, CurrBal = 32691709407, IssueDate =
> "02-01-2017", DatedDate = "02-01-2017", LastPmtDate = "02-01-2017",
> NextPmtDate = "02-25-2017", MaturityDate = "07-25-2029", CashFlow =
> structure(list(BeginBal = list(), Interest = list(), WriteDown = list(),
> WriteUp = list(), SeniorReduction = list(), SubReduction = list(),
> EndBal = list()), .Names = c("BeginBal", "Interest", "WriteDown",
> "WriteUp", "SeniorReduction", "SubReduction", "EndBal"))), .Names =
> c("Tranche", "Cusip", "Coupon", "Index", "Margin", "OrigBal", "CurrBal",
> "IssueDate", "DatedDate", "LastPmtDate", "NextPmtDate", "MaturityDate",
> "CashFlow"))), .Names = c("OC", "B2H", "B2", "B1H", "B1", "M2H", "M2",
> "M1H", "M1", "A1H"))
>
>
>
> BeginBal <- function(deal,period){
> numtranches = length(deal)
> tranches = seq(numtranches,1,-1)
> for(tranche in seq_along(tranches)){
> cashflow <- NULL
> if(period == 1) {cashflow <- c(deal[[tranche]]$CashFlow$BeginBal,
> deal[[tranche]]$CurrBal)
> } else {
> cashflow <- c(deal[[tranche]]$CashFlow$BeginBal,
> deal[[tranche]]$CashFlow$EndingBal[[period -1]])}
> deal[[tranche]]$CashFlow$BeginBal <- cashflow
> print(deal[[tranche]]$CashFlow$BeginBal)
> }
> }
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Apr  2 00:32:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 1 Apr 2017 15:32:10 -0700
Subject: [R] Windowing Time Series in The Past
In-Reply-To: <20170401203757.GB1812@chicca>
References: <20170401203757.GB1812@chicca>
Message-ID: <CAGxFJbSZqhxguiGmE_GssTtPnUdBQ2fvSFDOY2c_1owK4BqGpw@mail.gmail.com>

?ts

tells you exactly how to do this.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 1, 2017 at 1:37 PM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> Dear All,
> I am sure the solution is a one liner, but I am a bit struggling.
> Given a time series which starts at a given time t_ini, I would like to set
> a initial start time farther away in the past and have NA before t_ini
> (I need this to align different time series).
> For instance
>
>
> d<-ts(seq(20), start=1986)
>
> I would like e.g. d to start at 1980 and consist of NA's before 1986.
> Ho can I achieve that?
> Many thanks
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Sun Apr  2 08:17:06 2017
From: jwd at surewest.net (John)
Date: Sat, 1 Apr 2017 23:17:06 -0700
Subject: [R] The R-help community list was started on this day 20 years
 ago
In-Reply-To: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
Message-ID: <20170401231706.52bef228@Draco>

On Sat, 1 Apr 2017 11:19:07 -0700
Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:

> Today, it is been 20 years since Martin M?chler started the R-help
> community list (https://stat.ethz.ch/pipermail/r-help/). The first
> post was written by Ross Ihaka on 1997-04-01:
> 
> Subject: R-alpha: R-testers: pmin heisenbug
> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
> When: Tue Apr 1 10:35:48 CEST 1997
> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
> 
> This is a post about R's memory model. We're talking R v0.50 beta. I
> think that the paragraph at the end provides a nice anecdote on the
> importance not to be overwhelmed by problems ahead:
> 
>    "(The consumption of one cell per string is perhaps the major
> memory problem in R - we didn't design it with large problems in mind.
> It is probably fixable, but it will mean a lot of work)."
> 
> We all know the story; an endless number of hours has been put in by
> many contributors throughout the years, making The R Project and its
> community the great experience it is today.
> 
> Thank you!
> 
> Henrik
> 
No fooling?


From pdalgd at gmail.com  Sun Apr  2 11:10:23 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 2 Apr 2017 11:10:23 +0200
Subject: [R] The R-help community list was started on this day 20 years
	ago
In-Reply-To: <20170401231706.52bef228@Draco>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
	<20170401231706.52bef228@Draco>
Message-ID: <98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>

Not fooling, no. 

However, r-help/r-announce/r-devel was a restructuring of the r-testers list. This goes back to March 20, 1996. The first archived post of r-testers is 

	? just a test (the 'archiving' does not yet work) -->> Nr. 2 Martin Maechler

so the actual start may have been a few days before.

...

Incidentally, looking at the last posts of r-testers, it seems that CRAN turned 20 last week:

Date: Wed, 26 Mar 1997 16:20:35 +0100
Message-Id: <199703261520.QAA08097 at aragorn.ci.tuwien.ac.at>
From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
To: r-testers at stat.math.ethz.ch

Subject: R-alpha: ANNOUNCE:  CRAN

This is a first (alpha) announcement for the

		Comprehensive R Archive Network 
			    (CRAN)

project.
...



-pd



> On 02 Apr 2017, at 08:17 , John <jwd at surewest.net> wrote:
> 
> On Sat, 1 Apr 2017 11:19:07 -0700
> Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
>> Today, it is been 20 years since Martin M?chler started the R-help
>> community list (https://stat.ethz.ch/pipermail/r-help/). The first
>> post was written by Ross Ihaka on 1997-04-01:
>> 
>> Subject: R-alpha: R-testers: pmin heisenbug
>> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
>> When: Tue Apr 1 10:35:48 CEST 1997
>> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
>> 
>> This is a post about R's memory model. We're talking R v0.50 beta. I
>> think that the paragraph at the end provides a nice anecdote on the
>> importance not to be overwhelmed by problems ahead:
>> 
>>   "(The consumption of one cell per string is perhaps the major
>> memory problem in R - we didn't design it with large problems in mind.
>> It is probably fixable, but it will mean a lot of work)."
>> 
>> We all know the story; an endless number of hours has been put in by
>> many contributors throughout the years, making The R Project and its
>> community the great experience it is today.
>> 
>> Thank you!
>> 
>> Henrik
>> 
> No fooling?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mviljamaa at kapsi.fi  Sun Apr  2 14:19:32 2017
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 02 Apr 2017 15:19:32 +0300
Subject: [R] How to solve "nlm() non-finite value supplied by 'nlm'" and how
 to constrain parameters to (0, 1)?
Message-ID: <2b5dc1f840da7988640514a9a31e69d9@kapsi.fi>

So I'm getting:

Error in nlm(neglikhood, p = c(0.1, 0.1), hessian = T, x = elinajat) :
   non-finite value supplied by 'nlm'
In addition: There were 50 or more warnings (use warnings() to see the 
first 50)

with the following (neglikelihood of 1-param. Weibull):

neglikhood <- function(theta,x) {
   n <- length(x)
   
-(n*log(theta[2])+n*log(theta[1])+(theta[1]-1)*sum(log(x))-theta[2]*sum(x^theta[1]))
}

> elinajat
  [1]  17.88  28.92  33.00  41.52  42.12  45.60  48.48  51.84  51.96  
54.12  55.56  67.80
[13]  68.64  68.64  68.88  84.12  93.12  98.64 105.12 105.84 127.92 
128.04 173.40

I read somewhere that I might need to constrain my parameters to the 
range (0,1). Is this correct?

For example:

> neglikhood(c(0.1,0.1),elinajat)
[1] 195.3213


From spencer.graves at effectivedefense.org  Sun Apr  2 14:53:50 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sun, 2 Apr 2017 07:53:50 -0500
Subject: [R] The R-help community list was started on this day 20 years
 ago
In-Reply-To: <98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
	<20170401231706.52bef228@Draco>
	<98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>
Message-ID: <6c5442ef-ad7c-05d9-1cab-c0a70671ec5e@effectivedefense.org>



On 2017-04-02 4:10 AM, peter dalgaard wrote:
> Not fooling, no.
>
> However, r-help/r-announce/r-devel was a restructuring of the r-testers list. This goes back to March 20, 1996. The first archived post of r-testers is
>
> 	? just a test (the 'archiving' does not yet work) -->> Nr. 2 Martin Maechler
>
> so the actual start may have been a few days before.


       So R was 11 when we celebrated its tenth birthday in Ames, Iowa, 
August 8-10, 2007?


       Best Wishes,
       Spencer Graves
>
> ...
>
> Incidentally, looking at the last posts of r-testers, it seems that CRAN turned 20 last week:
>
> Date: Wed, 26 Mar 1997 16:20:35 +0100
> Message-Id: <199703261520.QAA08097 at aragorn.ci.tuwien.ac.at>
> From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
> To: r-testers at stat.math.ethz.ch
>
> Subject: R-alpha: ANNOUNCE:  CRAN
>
> This is a first (alpha) announcement for the
>
> 		Comprehensive R Archive Network
> 			    (CRAN)
>
> project.
> ...
>
>
>
> -pd
>
>
>
>> On 02 Apr 2017, at 08:17 , John <jwd at surewest.net> wrote:
>>
>> On Sat, 1 Apr 2017 11:19:07 -0700
>> Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>>> Today, it is been 20 years since Martin M?chler started the R-help
>>> community list (https://stat.ethz.ch/pipermail/r-help/). The first
>>> post was written by Ross Ihaka on 1997-04-01:
>>>
>>> Subject: R-alpha: R-testers: pmin heisenbug
>>> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
>>> When: Tue Apr 1 10:35:48 CEST 1997
>>> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
>>>
>>> This is a post about R's memory model. We're talking R v0.50 beta. I
>>> think that the paragraph at the end provides a nice anecdote on the
>>> importance not to be overwhelmed by problems ahead:
>>>
>>>    "(The consumption of one cell per string is perhaps the major
>>> memory problem in R - we didn't design it with large problems in mind.
>>> It is probably fixable, but it will mean a lot of work)."
>>>
>>> We all know the story; an endless number of hours has been put in by
>>> many contributors throughout the years, making The R Project and its
>>> community the great experience it is today.
>>>
>>> Thank you!
>>>
>>> Henrik
>>>
>> No fooling?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Apr  2 15:42:52 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 2 Apr 2017 15:42:52 +0200
Subject: [R] The R-help community list was started on this day 20 years
	ago
In-Reply-To: <6c5442ef-ad7c-05d9-1cab-c0a70671ec5e@effectivedefense.org>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
	<20170401231706.52bef228@Draco>
	<98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>
	<6c5442ef-ad7c-05d9-1cab-c0a70671ec5e@effectivedefense.org>
Message-ID: <D6036FC2-EEA4-4C7E-BEC1-02EAA6EEC201@gmail.com>


> On 02 Apr 2017, at 14:53 , Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> 
> 
> On 2017-04-02 4:10 AM, peter dalgaard wrote:
>> Not fooling, no.
>> 
>> However, r-help/r-announce/r-devel was a restructuring of the r-testers list. This goes back to March 20, 1996. The first archived post of r-testers is
>> 
>> 	? just a test (the 'archiving' does not yet work) -->> Nr. 2 Martin Maechler
>> 
>> so the actual start may have been a few days before.
> 
> 
>      So R was 11 when we celebrated its tenth birthday in Ames, Iowa, August 8-10, 2007?

No, but the R Core Team was formed in August 1997. 

The birthdate of R itself is not well-defined. It could be June 1995 (GPL release), August 1993 (Announcement on S-news), or some night at the Black Crow Cafe in Auckland in the early 90's.

-pd

> 
> 
>      Best Wishes,
>      Spencer Graves
>> 
>> ...
>> 
>> Incidentally, looking at the last posts of r-testers, it seems that CRAN turned 20 last week:
>> 
>> Date: Wed, 26 Mar 1997 16:20:35 +0100
>> Message-Id: <199703261520.QAA08097 at aragorn.ci.tuwien.ac.at>
>> From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
>> To: r-testers at stat.math.ethz.ch
>> 
>> Subject: R-alpha: ANNOUNCE:  CRAN
>> 
>> This is a first (alpha) announcement for the
>> 
>> 		Comprehensive R Archive Network
>> 			    (CRAN)
>> 
>> project.
>> ...
>> 
>> 
>> 
>> -pd
>> 
>> 
>> 
>>> On 02 Apr 2017, at 08:17 , John <jwd at surewest.net> wrote:
>>> 
>>> On Sat, 1 Apr 2017 11:19:07 -0700
>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>> 
>>>> Today, it is been 20 years since Martin M?chler started the R-help
>>>> community list (https://stat.ethz.ch/pipermail/r-help/). The first
>>>> post was written by Ross Ihaka on 1997-04-01:
>>>> 
>>>> Subject: R-alpha: R-testers: pmin heisenbug
>>>> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
>>>> When: Tue Apr 1 10:35:48 CEST 1997
>>>> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
>>>> 
>>>> This is a post about R's memory model. We're talking R v0.50 beta. I
>>>> think that the paragraph at the end provides a nice anecdote on the
>>>> importance not to be overwhelmed by problems ahead:
>>>> 
>>>>   "(The consumption of one cell per string is perhaps the major
>>>> memory problem in R - we didn't design it with large problems in mind.
>>>> It is probably fixable, but it will mean a lot of work)."
>>>> 
>>>> We all know the story; an endless number of hours has been put in by
>>>> many contributors throughout the years, making The R Project and its
>>>> community the great experience it is today.
>>>> 
>>>> Thank you!
>>>> 
>>>> Henrik
>>>> 
>>> No fooling?
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at effectivedefense.org  Sun Apr  2 19:15:49 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sun, 2 Apr 2017 12:15:49 -0500
Subject: [R] The R-help community list was started on this day 20 years
 ago
In-Reply-To: <D6036FC2-EEA4-4C7E-BEC1-02EAA6EEC201@gmail.com>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
	<20170401231706.52bef228@Draco>
	<98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>
	<6c5442ef-ad7c-05d9-1cab-c0a70671ec5e@effectivedefense.org>
	<D6036FC2-EEA4-4C7E-BEC1-02EAA6EEC201@gmail.com>
Message-ID: <d32c3f92-3f7e-9ac2-3d78-ccc9ce519a82@effectivedefense.org>



On 2017-04-02 8:42 AM, peter dalgaard wrote:
>> On 02 Apr 2017, at 14:53 , Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>
>>
>>
>> On 2017-04-02 4:10 AM, peter dalgaard wrote:
>>> Not fooling, no.
>>>
>>> However, r-help/r-announce/r-devel was a restructuring of the r-testers list. This goes back to March 20, 1996. The first archived post of r-testers is
>>>
>>> 	? just a test (the 'archiving' does not yet work) -->> Nr. 2 Martin Maechler
>>>
>>> so the actual start may have been a few days before.
>>
>>       So R was 11 when we celebrated its tenth birthday in Ames, Iowa, August 8-10, 2007?
> No, but the R Core Team was formed in August 1997.
>
> The birthdate of R itself is not well-defined. It could be June 1995 (GPL release), August 1993 (Announcement on S-news), or some night at the Black Crow Cafe in Auckland in the early 90's.


       The Wikipedia article on "S (programming language)" said it first 
appeared in 1976 for the GCOS operating system.  "In late 1979, S was 
ported from GCOS to UNIX, which would become the new primary platform."  
I remember using S or S-PLUS in the late 1980s, when it was only 
available for UNIX.  In the early 1990s, I got S-PLUS for Windows.  I'm 
pretty sure S-PLUS was NOT available for Macs in the late 1990s.


        Spencer Graves
>
> -pd
>
>>
>>       Best Wishes,
>>       Spencer Graves
>>> ...
>>>
>>> Incidentally, looking at the last posts of r-testers, it seems that CRAN turned 20 last week:
>>>
>>> Date: Wed, 26 Mar 1997 16:20:35 +0100
>>> Message-Id: <199703261520.QAA08097 at aragorn.ci.tuwien.ac.at>
>>> From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
>>> To: r-testers at stat.math.ethz.ch
>>>
>>> Subject: R-alpha: ANNOUNCE:  CRAN
>>>
>>> This is a first (alpha) announcement for the
>>>
>>> 		Comprehensive R Archive Network
>>> 			    (CRAN)
>>>
>>> project.
>>> ...
>>>
>>>
>>>
>>> -pd
>>>
>>>
>>>
>>>> On 02 Apr 2017, at 08:17 , John <jwd at surewest.net> wrote:
>>>>
>>>> On Sat, 1 Apr 2017 11:19:07 -0700
>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>>
>>>>> Today, it is been 20 years since Martin M?chler started the R-help
>>>>> community list (https://stat.ethz.ch/pipermail/r-help/). The first
>>>>> post was written by Ross Ihaka on 1997-04-01:
>>>>>
>>>>> Subject: R-alpha: R-testers: pmin heisenbug
>>>>> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
>>>>> When: Tue Apr 1 10:35:48 CEST 1997
>>>>> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
>>>>>
>>>>> This is a post about R's memory model. We're talking R v0.50 beta. I
>>>>> think that the paragraph at the end provides a nice anecdote on the
>>>>> importance not to be overwhelmed by problems ahead:
>>>>>
>>>>>    "(The consumption of one cell per string is perhaps the major
>>>>> memory problem in R - we didn't design it with large problems in mind.
>>>>> It is probably fixable, but it will mean a lot of work)."
>>>>>
>>>>> We all know the story; an endless number of hours has been put in by
>>>>> many contributors throughout the years, making The R Project and its
>>>>> community the great experience it is today.
>>>>>
>>>>> Thank you!
>>>>>
>>>>> Henrik
>>>>>
>>>> No fooling?
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From John.Nash at uottawa.ca  Sun Apr  2 15:37:45 2017
From: John.Nash at uottawa.ca (John Nash)
Date: Sun, 2 Apr 2017 13:37:45 +0000
Subject: [R] How to solve "nlm() non-finite value supplied by 'nlm'" and
 how to constrain parameters to (0, 1)?
In-Reply-To: <2b5dc1f840da7988640514a9a31e69d9@kapsi.fi>
References: <2b5dc1f840da7988640514a9a31e69d9@kapsi.fi>
Message-ID: <f5e39971-9b2f-0a3b-cae7-f72c8335c5f5@uottawa.ca>

nlm doesn't include bounds so you'd need to transform. nlminb does, as
do a number of codes in optimr (and more in R-forge version optimrx). The latter
packages have a common call which simplifies choosing the solver. My own Rvmmin is an all-R
implementation of the same method (but some details changed) as optim::BFGS but it includes
bounds constraints. Moreover, it is fairly easy to get inside and add some checks if needed.

If you can, I recommend supplying analytic gradients too, though that is often quite a
bit of work. If you do this, remember to check that the code is correct (numDeriv helps).

Since you have only 2 parameters, I think I'd give nmkb (it is from dfoptim or in optimrx).
It handles bounds, but you cannot start on the bound because it uses the transfinite transformation
to handle the bounds. The method is relatively slow and clunky, but for 2 parameters, you are not
going to wait too long.

Best, JN


On 2017-04-02 08:19 AM, mviljamaa wrote:
> So I'm getting:
>
> Error in nlm(neglikhood, p = c(0.1, 0.1), hessian = T, x = elinajat) :
>   non-finite value supplied by 'nlm'
> In addition: There were 50 or more warnings (use warnings() to see the first 50)
>
> with the following (neglikelihood of 1-param. Weibull):
>
> neglikhood <- function(theta,x) {
>   n <- length(x)
>   -(n*log(theta[2])+n*log(theta[1])+(theta[1]-1)*sum(log(x))-theta[2]*sum(x^theta[1]))
> }
>
>> elinajat
>  [1]  17.88  28.92  33.00  41.52  42.12  45.60  48.48  51.84  51.96  54.12  55.56  67.80
> [13]  68.64  68.64  68.88  84.12  93.12  98.64 105.12 105.84 127.92 128.04 173.40
>
> I read somewhere that I might need to constrain my parameters to the range (0,1). Is this correct?
>
> For example:
>
>> neglikhood(c(0.1,0.1),elinajat)
> [1] 195.3213
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From br at dmstat1.com  Sun Apr  2 20:48:00 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 2 Apr 2017 14:48:00 -0400
Subject: [R] Seeking to Dummify Categorical Variables
Message-ID: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>

Hi R'ers:
I need a jump start to obtain my objective.
Assistance is greatly appreciated.
Bruce

*******
#Given Gender Dataset
r1       <- c( 1, 2, 3)
c1       <- c( "male", "female", "NA")
GENDER <- data.frame(r1,c1)
names(d1_3) <- c("ID","Gender")
GENDER
--------------
_OBJECTIVE_: To dummify GENDER,
i.e., to generate two new numeric columns,
         Gender_male and Gender_female,
such that:
when Gender="male"   then Gender_male=1 and Gender_female=0
when Gender="female" then Gender_male=0 and Gender_female=1
when Gender="NA"     then Gender_male=0 and Gender_female=0

So, with the given dataset, the resultant dataset would be as follows:
Desired Extended Gender Dataset
ID Gender Gender_male Gender_female
1      male              1                   0
2   female              0                   1
3       NA               0                   0

-- 
Bruce Ratner, Ph.D.


From dwinsemius at comcast.net  Sun Apr  2 21:19:15 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Apr 2017 12:19:15 -0700
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
Message-ID: <D2517F15-6C56-4E8D-B0CD-519216F16D88@comcast.net>


> On Apr 2, 2017, at 11:48 AM, BR_email <br at dmstat1.com> wrote:
> 
> Hi R'ers:
> I need a jump start to obtain my objective.
> Assistance is greatly appreciated.
> Bruce
> 
> *******
> #Given Gender Dataset
> r1       <- c( 1, 2, 3)
> c1       <- c( "male", "female", "NA")
> GENDER <- data.frame(r1,c1)
> names(d1_3) <- c("ID","Gender")

#ITYM:
names(GENDER) <- c("ID","Gender")

> GENDER
> --------------
> _OBJECTIVE_: To dummify GENDER,
> i.e., to generate two new numeric columns,
>        Gender_male and Gender_female,
> such that:
> when Gender="male"   then Gender_male=1 and Gender_female=0
> when Gender="female" then Gender_male=0 and Gender_female=1
> when Gender="NA"     then Gender_male=0 and Gender_female=0
> 
> So, with the given dataset, the resultant dataset would be as follows:
> Desired Extended Gender Dataset
> ID Gender Gender_male Gender_female
> 1      male              1                   0
> 2   female              0                   1
> 3       NA               0                   0

With that correction I think you might want:

> model.matrix( ID ~ Gender+0, data=GENDER )
  Genderfemale Gendermale GenderNA
1            0          1        0
2            1          0        0
3            0          0        1
attr(,"assign")
[1] 1 1 1
attr(,"contrasts")
attr(,"contrasts")$Gender
[1] "contr.treatment"

If you assigned that to an object name, say "obj" you could get your desired result with:

> obj <- model.matrix( ID ~ Gender+0, data=GENDER )
> cbind(GENDER[ , 1, drop=FALSE], obj[,-3] )
  ID Genderfemale Gendermale
1  1            0          1
2  2            1          0
3  3            0          0


I get the sense that you are trying to replicate a workflow that you developed in some other language and I think it would be more efficient for you to actually learn R rather than trying to write SAS or SPSS in R. If you like getting "into the weeds" of the language then I suggest trying to read the code in the `lm` function. It might help to refer back to Venables and Ripley's "S Programming" or reading Wickham's "Advanced R" pages on the web.

-- 
> Bruce Ratner, Ph.D.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Apr  2 21:22:33 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 02 Apr 2017 20:22:33 +0100
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
Message-ID: <58E14F79.6040309@sapo.pt>

Hello,

Try the following.

GENDER$Gender_male <- as.integer(GENDER$Gender == "male")
GENDER$Gender_female <- as.integer(GENDER$Gender == "female")

Hope this helps,

Rui Barradas

Em 02-04-2017 19:48, BR_email escreveu:
> Hi R'ers:
> I need a jump start to obtain my objective.
> Assistance is greatly appreciated.
> Bruce
>
> *******
> #Given Gender Dataset
> r1       <- c( 1, 2, 3)
> c1       <- c( "male", "female", "NA")
> GENDER <- data.frame(r1,c1)
> names(d1_3) <- c("ID","Gender")
> GENDER
> --------------
> _OBJECTIVE_: To dummify GENDER,
> i.e., to generate two new numeric columns,
>          Gender_male and Gender_female,
> such that:
> when Gender="male"   then Gender_male=1 and Gender_female=0
> when Gender="female" then Gender_male=0 and Gender_female=1
> when Gender="NA"     then Gender_male=0 and Gender_female=0
>
> So, with the given dataset, the resultant dataset would be as follows:
> Desired Extended Gender Dataset
> ID Gender Gender_male Gender_female
> 1      male              1                   0
> 2   female              0                   1
> 3       NA               0                   0
>


From dwinsemius at comcast.net  Sun Apr  2 21:27:34 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Apr 2017 12:27:34 -0700
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <D2517F15-6C56-4E8D-B0CD-519216F16D88@comcast.net>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
	<D2517F15-6C56-4E8D-B0CD-519216F16D88@comcast.net>
Message-ID: <F08D6EAD-4F52-428D-94B2-9F972875FD0A@comcast.net>


> On Apr 2, 2017, at 12:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Apr 2, 2017, at 11:48 AM, BR_email <br at dmstat1.com> wrote:
>> 
>> Hi R'ers:
>> I need a jump start to obtain my objective.
>> Assistance is greatly appreciated.
>> Bruce
>> 
>> *******
>> #Given Gender Dataset
>> r1       <- c( 1, 2, 3)
>> c1       <- c( "male", "female", "NA")

It's also important to realize that this "NA" is not actually a missing value but was rather a character string. If it had not been quoted at the time of data input , it would have been a missing value.

-- 
David
>> GENDER <- data.frame(r1,c1)
>> names(d1_3) <- c("ID","Gender")
> 
> #ITYM:
> names(GENDER) <- c("ID","Gender")
> 
>> GENDER
>> --------------
>> _OBJECTIVE_: To dummify GENDER,
>> i.e., to generate two new numeric columns,
>>       Gender_male and Gender_female,
>> such that:
>> when Gender="male"   then Gender_male=1 and Gender_female=0
>> when Gender="female" then Gender_male=0 and Gender_female=1
>> when Gender="NA"     then Gender_male=0 and Gender_female=0
>> 
>> So, with the given dataset, the resultant dataset would be as follows:
>> Desired Extended Gender Dataset
>> ID Gender Gender_male Gender_female
>> 1      male              1                   0
>> 2   female              0                   1
>> 3       NA               0                   0
> 
> With that correction I think you might want:
> 
>> model.matrix( ID ~ Gender+0, data=GENDER )
>  Genderfemale Gendermale GenderNA
> 1            0          1        0
> 2            1          0        0
> 3            0          0        1
> attr(,"assign")
> [1] 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$Gender
> [1] "contr.treatment"
> 
> If you assigned that to an object name, say "obj" you could get your desired result with:
> 
>> obj <- model.matrix( ID ~ Gender+0, data=GENDER )
>> cbind(GENDER[ , 1, drop=FALSE], obj[,-3] )
>  ID Genderfemale Gendermale
> 1  1            0          1
> 2  2            1          0
> 3  3            0          0
> 
> 
> I get the sense that you are trying to replicate a workflow that you developed in some other language and I think it would be more efficient for you to actually learn R rather than trying to write SAS or SPSS in R. If you like getting "into the weeds" of the language then I suggest trying to read the code in the `lm` function. It might help to refer back to Venables and Ripley's "S Programming" or reading Wickham's "Advanced R" pages on the web.
> 
> -- 
>> Bruce Ratner, Ph.D.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sun Apr  2 22:19:57 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 2 Apr 2017 22:19:57 +0200
Subject: [R] The R-help community list was started on this day 20 years
	ago
In-Reply-To: <d32c3f92-3f7e-9ac2-3d78-ccc9ce519a82@effectivedefense.org>
References: <CAFDcVCS-JaYk7OcHq6fS_ZGppb+QGL_erv5+RKULtg2hax2z0Q@mail.gmail.com>
	<20170401231706.52bef228@Draco>
	<98EA488D-10BC-42F5-B8FC-5FDBB750156A@gmail.com>
	<6c5442ef-ad7c-05d9-1cab-c0a70671ec5e@effectivedefense.org>
	<D6036FC2-EEA4-4C7E-BEC1-02EAA6EEC201@gmail.com>
	<d32c3f92-3f7e-9ac2-3d78-ccc9ce519a82@effectivedefense.org>
Message-ID: <02E2DCF4-0103-435E-9254-96991B116213@gmail.com>


> On 02 Apr 2017, at 19:15 , Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> 
> 
> On 2017-04-02 8:42 AM, peter dalgaard wrote:
>>> On 02 Apr 2017, at 14:53 , Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>> 
>>> 
>>> 
>>> On 2017-04-02 4:10 AM, peter dalgaard wrote:
>>>> Not fooling, no.
>>>> 
>>>> However, r-help/r-announce/r-devel was a restructuring of the r-testers list. This goes back to March 20, 1996. The first archived post of r-testers is
>>>> 
>>>> 	? just a test (the 'archiving' does not yet work) -->> Nr. 2 Martin Maechler
>>>> 
>>>> so the actual start may have been a few days before.
>>> 
>>>      So R was 11 when we celebrated its tenth birthday in Ames, Iowa, August 8-10, 2007?
>> No, but the R Core Team was formed in August 1997.
>> 
>> The birthdate of R itself is not well-defined. It could be June 1995 (GPL release), August 1993 (Announcement on S-news), or some night at the Black Crow Cafe in Auckland in the early 90's.
> 
> 
>      The Wikipedia article on "S (programming language)" said it first appeared in 1976 for the GCOS operating system.  "In late 1979, S was ported from GCOS to UNIX, which would become the new primary platform."  I remember using S or S-PLUS in the late 1980s, when it was only available for UNIX.  In the early 1990s, I got S-PLUS for Windows.  I'm pretty sure S-PLUS was NOT available for Macs in the late 1990s.

Did anyone say that it was?? Anyways, as I recall it, part of the genesis of R was exactly that the Auckland computer labs were Mac-based and R&R wanted a mini-S to run on them.

-pd

> 
> 
>       Spencer Graves
>> 
>> -pd
>> 
>>> 
>>>      Best Wishes,
>>>      Spencer Graves
>>>> ...
>>>> 
>>>> Incidentally, looking at the last posts of r-testers, it seems that CRAN turned 20 last week:
>>>> 
>>>> Date: Wed, 26 Mar 1997 16:20:35 +0100
>>>> Message-Id: <199703261520.QAA08097 at aragorn.ci.tuwien.ac.at>
>>>> From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
>>>> To: r-testers at stat.math.ethz.ch
>>>> 
>>>> Subject: R-alpha: ANNOUNCE:  CRAN
>>>> 
>>>> This is a first (alpha) announcement for the
>>>> 
>>>> 		Comprehensive R Archive Network
>>>> 			    (CRAN)
>>>> 
>>>> project.
>>>> ...
>>>> 
>>>> 
>>>> 
>>>> -pd
>>>> 
>>>> 
>>>> 
>>>>> On 02 Apr 2017, at 08:17 , John <jwd at surewest.net> wrote:
>>>>> 
>>>>> On Sat, 1 Apr 2017 11:19:07 -0700
>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>>> 
>>>>>> Today, it is been 20 years since Martin M?chler started the R-help
>>>>>> community list (https://stat.ethz.ch/pipermail/r-help/). The first
>>>>>> post was written by Ross Ihaka on 1997-04-01:
>>>>>> 
>>>>>> Subject: R-alpha: R-testers: pmin heisenbug
>>>>>> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
>>>>>> When: Tue Apr 1 10:35:48 CEST 1997
>>>>>> Archive: https://stat.ethz.ch/pipermail/r-help/1997-April/001488.html
>>>>>> 
>>>>>> This is a post about R's memory model. We're talking R v0.50 beta. I
>>>>>> think that the paragraph at the end provides a nice anecdote on the
>>>>>> importance not to be overwhelmed by problems ahead:
>>>>>> 
>>>>>>   "(The consumption of one cell per string is perhaps the major
>>>>>> memory problem in R - we didn't design it with large problems in mind.
>>>>>> It is probably fixable, but it will mean a lot of work)."
>>>>>> 
>>>>>> We all know the story; an endless number of hours has been put in by
>>>>>> many contributors throughout the years, making The R Project and its
>>>>>> community the great experience it is today.
>>>>>> 
>>>>>> Thank you!
>>>>>> 
>>>>>> Henrik
>>>>>> 
>>>>> No fooling?
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From br at dmstat1.com  Mon Apr  3 00:49:45 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 2 Apr 2017 18:49:45 -0400
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <D2517F15-6C56-4E8D-B0CD-519216F16D88@comcast.net>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
	<D2517F15-6C56-4E8D-B0CD-519216F16D88@comcast.net>
Message-ID: <7b3724bc-8d29-baf8-a7aa-bcd779c9f699@dmstat1.com>

David:
Thank you. It's perfect.
FYI: regarding your comment about "NA," yes, I filled it in just for the 
example.

Again, thanks for your professional and polite reply.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

David Winsemius wrote:
>> On Apr 2, 2017, at 11:48 AM, BR_email <br at dmstat1.com> wrote:
>>
>> Hi R'ers:
>> I need a jump start to obtain my objective.
>> Assistance is greatly appreciated.
>> Bruce
>>
>> *******
>> #Given Gender Dataset
>> r1       <- c( 1, 2, 3)
>> c1       <- c( "male", "female", "NA")
>> GENDER <- data.frame(r1,c1)
>> names(d1_3) <- c("ID","Gender")
> #ITYM:
> names(GENDER) <- c("ID","Gender")
>
>> GENDER
>> --------------
>> _OBJECTIVE_: To dummify GENDER,
>> i.e., to generate two new numeric columns,
>>         Gender_male and Gender_female,
>> such that:
>> when Gender="male"   then Gender_male=1 and Gender_female=0
>> when Gender="female" then Gender_male=0 and Gender_female=1
>> when Gender="NA"     then Gender_male=0 and Gender_female=0
>>
>> So, with the given dataset, the resultant dataset would be as follows:
>> Desired Extended Gender Dataset
>> ID Gender Gender_male Gender_female
>> 1      male              1                   0
>> 2   female              0                   1
>> 3       NA               0                   0
> With that correction I think you might want:
>
>> model.matrix( ID ~ Gender+0, data=GENDER )
>    Genderfemale Gendermale GenderNA
> 1            0          1        0
> 2            1          0        0
> 3            0          0        1
> attr(,"assign")
> [1] 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$Gender
> [1] "contr.treatment"
>
> If you assigned that to an object name, say "obj" you could get your desired result with:
>
>> obj <- model.matrix( ID ~ Gender+0, data=GENDER )
>> cbind(GENDER[ , 1, drop=FALSE], obj[,-3] )
>    ID Genderfemale Gendermale
> 1  1            0          1
> 2  2            1          0
> 3  3            0          0
>
>
> I get the sense that you are trying to replicate a workflow that you developed in some other language and I think it would be more efficient for you to actually learn R rather than trying to write SAS or SPSS in R. If you like getting "into the weeds" of the language then I suggest trying to read the code in the `lm` function. It might help to refer back to Venables and Ripley's "S Programming" or reading Wickham's "Advanced R" pages on the web.
>


From br at dmstat1.com  Mon Apr  3 00:58:59 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 2 Apr 2017 18:58:59 -0400
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <58E14F79.6040309@sapo.pt>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
	<58E14F79.6040309@sapo.pt>
Message-ID: <bd4893f1-6029-e6b5-586f-1ef0d1cbff46@dmstat1.com>

Rui:
I tried your suggestion, which was not fruitful.
Another R-helper suggested the code below, which worked perfectly.
Thanks for your suggestion and time spent.

Regards,
Bruce

obj <- model.matrix( ID ~ Gender+0, data=GENDER )
cbind(GENDER[ , 1, drop=FALSE], obj[,-3] )


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Rui Barradas wrote:
> Hello,
>
> Try the following.
>
> GENDER$Gender_male <- as.integer(GENDER$Gender == "male")
> GENDER$Gender_female <- as.integer(GENDER$Gender == "female")
>
> Hope this helps,
>
> Rui Barradas
>
> Em 02-04-2017 19:48, BR_email escreveu:
>> Hi R'ers:
>> I need a jump start to obtain my objective.
>> Assistance is greatly appreciated.
>> Bruce
>>
>> *******
>> #Given Gender Dataset
>> r1       <- c( 1, 2, 3)
>> c1       <- c( "male", "female", "NA")
>> GENDER <- data.frame(r1,c1)
>> names(d1_3) <- c("ID","Gender")
>> GENDER
>> --------------
>> _OBJECTIVE_: To dummify GENDER,
>> i.e., to generate two new numeric columns,
>>          Gender_male and Gender_female,
>> such that:
>> when Gender="male"   then Gender_male=1 and Gender_female=0
>> when Gender="female" then Gender_male=0 and Gender_female=1
>> when Gender="NA"     then Gender_male=0 and Gender_female=0
>>
>> So, with the given dataset, the resultant dataset would be as follows:
>> Desired Extended Gender Dataset
>> ID Gender Gender_male Gender_female
>> 1      male              1                   0
>> 2   female              0                   1
>> 3       NA               0                   0
>>
>
>
>


From bgunter.4567 at gmail.com  Mon Apr  3 02:14:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 2 Apr 2017 17:14:21 -0700
Subject: [R] Seeking to Dummify Categorical Variables
In-Reply-To: <bd4893f1-6029-e6b5-586f-1ef0d1cbff46@dmstat1.com>
References: <d349867d-aac6-663a-c25c-7becb566da92@dmstat1.com>
	<58E14F79.6040309@sapo.pt>
	<bd4893f1-6029-e6b5-586f-1ef0d1cbff46@dmstat1.com>
Message-ID: <CAGxFJbRFYyUbZ2JDsrM3eB_x3RWN4AHNL_HFCjB9n5Z=gn3TEQ@mail.gmail.com>

Just to be clear...

I can think of no reason to ever "dummify" categorical variables in R.
i.e. **Do not do this.**

Corollary 1: Learn how R's modeling functionality works: ?formula

Corollary 2: Do not try to do it as is done in SAS or SPSS or whatever
(as David already said)

(possible exception: packages that aren't smart enough to use
model.matrix etc. to do this by themselves. Also, do note that this is
intimately related to the issue of contrasts in linear models. See
?contrasts, ?C)

[nb: I would very much appreciate correction or "adjustment" on my
statement(s) if I am wrong]

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 2, 2017 at 3:58 PM, BR_email <br at dmstat1.com> wrote:
> Rui:
> I tried your suggestion, which was not fruitful.
> Another R-helper suggested the code below, which worked perfectly.
> Thanks for your suggestion and time spent.
>
> Regards,
> Bruce
>
> obj <- model.matrix( ID ~ Gender+0, data=GENDER )
> cbind(GENDER[ , 1, drop=FALSE], obj[,-3] )
>
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
> Rui Barradas wrote:
>>
>> Hello,
>>
>> Try the following.
>>
>> GENDER$Gender_male <- as.integer(GENDER$Gender == "male")
>> GENDER$Gender_female <- as.integer(GENDER$Gender == "female")
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 02-04-2017 19:48, BR_email escreveu:
>>>
>>> Hi R'ers:
>>> I need a jump start to obtain my objective.
>>> Assistance is greatly appreciated.
>>> Bruce
>>>
>>> *******
>>> #Given Gender Dataset
>>> r1       <- c( 1, 2, 3)
>>> c1       <- c( "male", "female", "NA")
>>> GENDER <- data.frame(r1,c1)
>>> names(d1_3) <- c("ID","Gender")
>>> GENDER
>>> --------------
>>> _OBJECTIVE_: To dummify GENDER,
>>> i.e., to generate two new numeric columns,
>>>          Gender_male and Gender_female,
>>> such that:
>>> when Gender="male"   then Gender_male=1 and Gender_female=0
>>> when Gender="female" then Gender_male=0 and Gender_female=1
>>> when Gender="NA"     then Gender_male=0 and Gender_female=0
>>>
>>> So, with the given dataset, the resultant dataset would be as follows:
>>> Desired Extended Gender Dataset
>>> ID Gender Gender_male Gender_female
>>> 1      male              1                   0
>>> 2   female              0                   1
>>> 3       NA               0                   0
>>>
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From art.tem.us at gmail.com  Sun Apr  2 23:02:01 2017
From: art.tem.us at gmail.com (Art U)
Date: Sun, 2 Apr 2017 17:02:01 -0400
Subject: [R] Combine vectors under the names
Message-ID: <CAKY_brFHk2fJ03ZFX+GHy2uARNdmSJu=ctmeNemPxBzLMwGsBg@mail.gmail.com>

Hello,

Lets say I have 2 vectors:
x1=c("a1"=0,"b3"=2,"e2"=-2);
x2=c("c"=3,"d"=4,"f"=5);
and vector of names in specific order:
N=c("a1","b3","d","e2","c","f")
and I want to combine them to vector C:

C=

a1 b3  d e2  c  f
 0  2  4 -2  3  5


Basically, just fill vector N with values from vector x1 and x2. How can I
do that?
Thank you in advance.
Art

-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From lakestay at hotmail.com  Sun Apr  2 23:30:54 2017
From: lakestay at hotmail.com (Vineet Gupta)
Date: Sun, 2 Apr 2017 21:30:54 +0000
Subject: [R] R hangs on startup
Message-ID: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>

Hi,

I have been struggling with this problem with for 2 weeks, but have yet to find a solution on Google.

I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I open R (and RStudio), the R screen freezes and is unusable. Nothing has changed, to trigger this event. I have tried re-installing the software, and downgrading to an older version of R. Nothing seems to work.

If someone could help me, then I would very much appreciate it. At this point, I am at a loss.

Rgds,
Vineet


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Apr  3 03:45:56 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 2 Apr 2017 21:45:56 -0400
Subject: [R] Combine vectors under the names
In-Reply-To: <CAKY_brFHk2fJ03ZFX+GHy2uARNdmSJu=ctmeNemPxBzLMwGsBg@mail.gmail.com>
References: <CAKY_brFHk2fJ03ZFX+GHy2uARNdmSJu=ctmeNemPxBzLMwGsBg@mail.gmail.com>
Message-ID: <BF731D21-4ABB-46EE-A10F-E732ED361711@utoronto.ca>

Your code is syntactically correct but goes against all R style guides I know. I've changed that - but obviously you don't have to.

    x1 <- c(a1 = 0, b3 = 2, e2 = -2)
    x2 <- c(c = 3, d = 4, f = 5)
    N <- c("a1", "b3", "d", "e2", "c", "f")

    x3 <- c(x1, x2)   # concatenate
    x3 <- x3[N]       # re-order

The assumption is that N contains each of names(x1) and names(x2) exactly once.
If that isn't guaranteed, a different approach is needed.


B.



> On Apr 2, 2017, at 5:02 PM, Art U <art.tem.us at gmail.com> wrote:
> 
> Hello,
> 
> Lets say I have 2 vectors:
> x1=c("a1"=0,"b3"=2,"e2"=-2);
> x2=c("c"=3,"d"=4,"f"=5);
> and vector of names in specific order:
> N=c("a1","b3","d","e2","c","f")
> and I want to combine them to vector C:
> 
> C=
> 
> a1 b3  d e2  c  f
> 0  2  4 -2  3  5
> 
> 
> Basically, just fill vector N with values from vector x1 and x2. How can I
> do that?
> Thank you in advance.
> Art
> 
> -- 
> *I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
> or plague*... *Whatever*. *No-one left to act normal for. No need to hide
> who I really am. It would be... freeing*. *...*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Apr  3 06:02:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Apr 2017 21:02:47 -0700
Subject: [R] R hangs on startup
In-Reply-To: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
Message-ID: <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>


> On Apr 2, 2017, at 2:30 PM, Vineet Gupta <lakestay at hotmail.com> wrote:
> 
> Hi,
> 
> I have been struggling with this problem with for 2 weeks, but have yet to find a solution on Google.
> 
> I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I open R (and RStudio), the R screen freezes and is unusable. Nothing has changed, to trigger this event. I have tried re-installing the software, and downgrading to an older version of R. Nothing seems to work.
> 
> If someone could help me, then I would very much appreciate it. At this point, I am at a loss.
> 

Startup difficulties are often the result of a corrupted ,Rdata or .Rhistory file. These are generally hidden files, so you may need to learn how to delete such "dot-files" or whatever term is used to describe files that do no appear on your OS file browser. I don't know where the Windows version of RStudio keeps these files.


> Rgds,
> Vineet
> 
> 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From L.J.Bonnett at liverpool.ac.uk  Mon Apr  3 11:51:43 2017
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Mon, 3 Apr 2017 09:51:43 +0000
Subject: [R] Unexpected error message when making predictions from fitted
 PWP-CP (Cox) model
Message-ID: <C7DB2A0C26C67948A1AEFA4C11851C8E013EC934A1@BHEXMBX1.livad.liv.ac.uk>

Dear all,

I am using R x64 3.3.2 on Windows 10.

I have fitted a Prentice-Williams-Peterson counting process model with a number of covariates as follows:
Coxmod1 <- coxph(Surv(start,stop,status)~var1+var2+factor(var3)+cluster(var4)+strata(var5),data=Lauras)

I would now like to make predictions based on either a subset of patients from the original data set, or a new patient with randomly selected characteristics.
I have used the following code for both scenario:
Original dataset:
Subset1 <- subset(Lauras,(var1=="M") & (var2==2) & (var3<=10))
Output1 <- predict(Coxmod1,Subset1,type="expected",se.fit=TRUE)

New patient:
Subset2 <- (0, 365, 1, "M", 2, 10, "A001", 12)
Output2 <- predict(Coxmod1,Subset2,type="expected",se.fit=TRUE)

In both cases I receive in excess of 50 warnings which all state:
1: In min(diff(time)) : no non-missing arguments to min; returning Inf

The outputted predictions contain a surprisingly high number of 1s, as a result of "returning Inf" I assume.  However, the characteristics for the patients with a prediction of 1 are not unusual i.e. there are no missing values etc.

Can anyone suggest what might be causing these warning messages, and what steps I can take to prevent them reoccurring as they are causing predictions for every patient subgroup to have the same summary statistics.

Kind regards,
Laura



	[[alternative HTML version deleted]]


From vineetgupta410 at gmail.com  Mon Apr  3 11:41:06 2017
From: vineetgupta410 at gmail.com (Vineet Gupta)
Date: Mon, 3 Apr 2017 10:41:06 +0100
Subject: [R] R hangs on startup
In-Reply-To: <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
	<01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
Message-ID: <012201d2ac5e$6af35180$40d9f480$@gmail.com>

David,

Thx for the quick reply. Firstly, apologies for using windows - I need to
switch to Linux!

Do you have any suggestion of a suitable website, that may cover how to do
this? I will look on Google, but I generally find that to be a time
intensive, and low reward endeavour.

Rgds,
Vineet

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 03 April 2017 05:03
To: Vineet Gupta <lakestay at hotmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] R hangs on startup


> On Apr 2, 2017, at 2:30 PM, Vineet Gupta <lakestay at hotmail.com> wrote:
> 
> Hi,
> 
> I have been struggling with this problem with for 2 weeks, but have yet to
find a solution on Google.
> 
> I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I open R
(and RStudio), the R screen freezes and is unusable. Nothing has changed, to
trigger this event. I have tried re-installing the software, and downgrading
to an older version of R. Nothing seems to work.
> 
> If someone could help me, then I would very much appreciate it. At this
point, I am at a loss.
> 

Startup difficulties are often the result of a corrupted ,Rdata or .Rhistory
file. These are generally hidden files, so you may need to learn how to
delete such "dot-files" or whatever term is used to describe files that do
no appear on your OS file browser. I don't know where the Windows version of
RStudio keeps these files.


> Rgds,
> Vineet
> 
> 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Mon Apr  3 18:27:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 3 Apr 2017 09:27:37 -0700
Subject: [R] R hangs on startup
In-Reply-To: <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
	<01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
Message-ID: <CAF8bMcZce=NhEBGjd1BFk0MH88mk+QR07QijJc4a6B4vzvC3Vw@mail.gmail.com>

Starting R with the --vanilla flag will cause it to ignore startup
files.  This is usually a quicker way to rule out such issues than
tracking down where the startup files are stored.  'R --help' tells
about other command line arguments that help home in on which file may
be the problem.

  --no-environ          Don't read the site and user environment files
  --no-site-file        Don't read the site-wide Rprofile
  --no-init-file        Don't read the user R profile
  --restore             Do restore previously saved objects at startup
  --no-restore-data     Don't restore previously saved objects
  --no-restore-history  Don't restore the R history file
  --no-restore          Don't restore anything
  --vanilla             Combine --no-save, --no-restore, --no-site-file,
                        --no-init-file and --no-environ

I don't know of a good way to make R report exactly which file it is
processing as it starts up.  Should --verbose do that?


From macqueen1 at llnl.gov  Mon Apr  3 18:46:00 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 3 Apr 2017 16:46:00 +0000
Subject: [R] How to source a local R file to a remote session.
In-Reply-To: <87k27a9dgp.fsf@gmail.com>
References: <87k27a9dgp.fsf@gmail.com>
Message-ID: <461007FA-5465-4E02-9032-A78BA0DA93A0@llnl.gov>

Strikes me as a good question for the ESS help mailing list (and I'm sorry; I don't remember how/where to subscribe to it).

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 3/27/17, 10:28 PM, "R-help on behalf of Jeremie Juste" <r-help-bounces at r-project.org on behalf of jeremiejuste at gmail.com> wrote:

    
    Hello,
    
    I don't know exactly where to turn to.
    I'm using Emacs speak statistics and I can execute a codes on my local
    computer to a remote session seemlessly.
    
    But I've always wondered how to source a file on local computer to the
    remote session? Till now I have copied the files to the remote host and
    source from there but it complicates the version control process.
    
    
    Any suggestions on this?
    
    
    
    Best regards,
    
    Jeremie
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From ruipbarradas at sapo.pt  Mon Apr  3 18:54:08 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 03 Apr 2017 17:54:08 +0100
Subject: [R] How to source a local R file to a remote session.
In-Reply-To: <461007FA-5465-4E02-9032-A78BA0DA93A0@llnl.gov>
References: <87k27a9dgp.fsf@gmail.com>
	<461007FA-5465-4E02-9032-A78BA0DA93A0@llnl.gov>
Message-ID: <58E27E30.3090809@sapo.pt>

Hello,

I don't use ESS but I can use google. The first hit on "ESS help mailing 
list" was

https://stat.ethz.ch/mailman/listinfo/ess-help

Hope this helps,

Rui Barradas

Em 03-04-2017 17:46, MacQueen, Don escreveu:
> Strikes me as a good question for the ESS help mailing list (and I'm sorry; I don't remember how/where to subscribe to it).
>


From jfox at mcmaster.ca  Mon Apr  3 18:56:25 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 3 Apr 2017 16:56:25 +0000
Subject: [R] R hangs on startup
In-Reply-To: <012201d2ac5e$6af35180$40d9f480$@gmail.com>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
	<01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
	<012201d2ac5e$6af35180$40d9f480$@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>

Dear Vineet,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vineet
> Gupta
> Sent: April 3, 2017 5:41 AM
> To: 'David Winsemius' <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> David,
> 
> Thx for the quick reply. Firstly, apologies for using windows - I need to switch
> to Linux!

It's not obvious that your problem is OS-specific, nor is it necessarily the case that your problem is a bad .RData or .Rhistory file, though it's worth trying to delete them.

BTW, does R work properly outside of RStudio?

> 
> Do you have any suggestion of a suitable website, that may cover how to do
> this? I will look on Google, but I generally find that to be a time intensive, and
> low reward endeavour.

Generally R will save the workspace on exit (if you ask it to) in the working directory. Under RStudio this would normally be the directory of your current project, or, if you're not using a project and haven't changed your working directory, in your Documents folder.

You're looking for files named .RData (the workspace) and .Rhistory. The former may be hidden in Windows Explorer  if you don't display known-to-Windows file extensions, but you'll still see the R icon. .Rhistory isn't a registered extension and should appear in any event. Right click on these files and delete them.

It's generally a good idea *not* to hide file extensions. In the Windows Explorer "View" tab, check "File name extensions."

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> 
> Rgds,
> Vineet
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: 03 April 2017 05:03
> To: Vineet Gupta <lakestay at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> 
> > On Apr 2, 2017, at 2:30 PM, Vineet Gupta <lakestay at hotmail.com> wrote:
> >
> > Hi,
> >
> > I have been struggling with this problem with for 2 weeks, but have yet to
> find a solution on Google.
> >
> > I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I open R
> (and RStudio), the R screen freezes and is unusable. Nothing has changed, to
> trigger this event. I have tried re-installing the software, and downgrading
> to an older version of R. Nothing seems to work.
> >
> > If someone could help me, then I would very much appreciate it. At this
> point, I am at a loss.
> >
> 
> Startup difficulties are often the result of a corrupted ,Rdata or .Rhistory
> file. These are generally hidden files, so you may need to learn how to
> delete such "dot-files" or whatever term is used to describe files that do
> no appear on your OS file browser. I don't know where the Windows version
> of
> RStudio keeps these files.
> 
> 
> > Rgds,
> > Vineet
> >
> >
> > 	[[alternative HTML version deleted]]
> 
> Rhelp is a plain text mailing list.
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr  3 19:28:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 3 Apr 2017 10:28:50 -0700
Subject: [R] How to source a local R file to a remote session.
In-Reply-To: <461007FA-5465-4E02-9032-A78BA0DA93A0@llnl.gov>
References: <87k27a9dgp.fsf@gmail.com>
	<461007FA-5465-4E02-9032-A78BA0DA93A0@llnl.gov>
Message-ID: <CAGxFJbTad0jm-04d9pLHEiBvtU=WTZ06cQgb3vKD49F4mmj31g@mail.gmail.com>

Don:

Just ask Mama Google!  :-o

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 3, 2017 at 9:46 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> Strikes me as a good question for the ESS help mailing list (and I'm sorry; I don't remember how/where to subscribe to it).
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
> On 3/27/17, 10:28 PM, "R-help on behalf of Jeremie Juste" <r-help-bounces at r-project.org on behalf of jeremiejuste at gmail.com> wrote:
>
>
>     Hello,
>
>     I don't know exactly where to turn to.
>     I'm using Emacs speak statistics and I can execute a codes on my local
>     computer to a remote session seemlessly.
>
>     But I've always wondered how to source a file on local computer to the
>     remote session? Till now I have copied the files to the remote host and
>     source from there but it complicates the version control process.
>
>
>     Any suggestions on this?
>
>
>
>     Best regards,
>
>     Jeremie
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Apr  3 21:41:49 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 3 Apr 2017 15:41:49 -0400
Subject: [R] Variation of bubble sort (based on divisors)
In-Reply-To: <CA+0Zh7xH+0hzZVQNLY4J8eF5p9rg2R-MLyZ4KbSTapH3eAOP=A@mail.gmail.com>
References: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>
	<4AF0AE3D-DC40-4FC4-85D6-B94A00350610@utoronto.ca>
	<CA+0Zh7wwgHECp_9+7mt23QcnnzacUUKZ46GN6CrzaNposh96NA@mail.gmail.com>
	<7F742328-7F3B-42CF-8268-1E4A1450B918@utoronto.ca>
	<CA+0Zh7xH+0hzZVQNLY4J8eF5p9rg2R-MLyZ4KbSTapH3eAOP=A@mail.gmail.com>
Message-ID: <B121857F-17C6-404F-B2EE-16701ECDB234@utoronto.ca>

Piotr - keep discussions on-list please.

I generally do not open attachments to eMails.

You are misinterpreting the results:

0:  0
1:  1
2:  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30
3:  3  9 15 21 27  (all even multiples of 3 have been sorted with 2)
5:  5 25  (10, 20, 30 are sorted as multiples of 2; 15 is a multiple of 3)
7:  7 (14, 28 are multiples of 2; 21 is a multiple of 3)
others: 11 13 17 19 23 29


B.






> On Apr 3, 2017, at 3:27 PM, Piotr Koller <pittbox33 at gmail.com> wrote:
> 
> Hi, I've noticed some weird thing about this function. It's not treating one digit numbers as divisible by themselves. For example, In 0:30 sequence
> 
> 
> It prints me a result of: 
> [1]  0  1  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30  3  9 15 21 27  5 25  7 11 13 17
> [29] 19 23 29
> 
> 
> 
> So, it treats 15 as divisible by 5, 21 as divisible by 7, but not 5 as divisible by 5 and 7 as divisble by 7. I've also noticed when I use 1:10 instead of 0:10 sequence, it prints a "double" result
>  0  1  2  4  6  8 10  3  9  5  7  2  4  6  8 10  3  9  5  7
> 
> What's the reason behind those problems? Code is in the attachment.
> 
> 
> 	Wolny od wirus?w. www.avast.com
> 
> On Sat, Apr 1, 2017 at 2:38 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> The modulo operator returns remainder after division. The goal is to select a number if the remainder is zero. Casting a number to logical returns FALSE if it is zero, TRUE otherwise. The "!" operator inverts that.
> 
> 
> (2:9)
> (2:9) %% 3
> as.logical((2:9) %% 3)
> !as.logical((2:9) %% 3)
> 
> 
> B.
> 
> 
> 
> 
> > On Apr 1, 2017, at 8:16 AM, Piotr Koller <pittbox33 at gmail.com> wrote:
> >
> > Thank you very much. You are very helpful. Can you explain what's the general purpose of this" !as.logical " operator in for loop?
> >
> >       Wolny od wirus?w. www.avast.com
> >
> > On Sat, Apr 1, 2017 at 2:15 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > This looks opaque and hard to maintain.
> > It seems to me that a better strategy is to subset your vector with modulo expressions, use a normal sort on each of the subsets, and add the result to each other. 0 and 1 need to be special-cased.
> >
> >
> > myPrimes <- c(2, 3, 5)
> > mySource <- sample(0:10)
> >
> > # special case 0,1
> > sel <- mySource < 2
> > myTarget <- sort(mySource[sel])
> > mySource <- mySource[!sel]
> >
> > # Iterate over requested primes
> > for (num in myPrimes) {
> >     sel <- !as.logical(mySource %% num)
> >     myTarget <- c(myTarget, sort(mySource[sel]))
> >     mySource <- mySource[!sel]
> > }
> >
> > # Add remaining elements
> > myTarget <- c(myTarget, sort(mySource))
> >
> >
> > B.
> >
> >
> >
> >
> >
> >
> > > On Mar 31, 2017, at 2:16 PM, Piotr Koller <pittbox33 at gmail.com> wrote:
> > >
> > > Hi, I'd like to create a function that will sort values of a vector on a
> > > given basis:
> > >
> > > -zeros
> > >
> > > -ones
> > >
> > > -numbers divisible by 2
> > >
> > > -numbers divisible by 3 (but not by 2)
> > >
> > > -numbers divisible by 5 (but not by 2 and 3)
> > >
> > > etc.
> > >
> > > I also want to omit zeros in those turns. So when I have a given vector of
> > > c(0:10), I want to receive 0 1 2 4 6 8 10 3 9 5 7 I think it'd be the best
> > > to use some variation of bubble sort, so it'd look like that
> > >
> > > sort <- function(x) {
> > > for (j in (length(x)-1):1) {
> > >   for (i in j:(length(x)-1)) {
> > >     if (x[i+1]%%divisor==0 && x[i]%%divisor!=0) {
> > >      temp <- x[i]
> > >      x[i] <- x[i+1]
> > >      x[i+1] <- temp
> > >      }
> > >    }
> > >  }
> > > return(x)}
> > >
> > > This function works out well on a given divisor and incresing sequences.
> > >
> > > sort <- function(x) {
> > >  for (j in (length(x)-1):1) {
> > >     for (i in j:(length(x)-1)) {
> > >       if (x[i+1]%%5==0 && x[i]%%5!=0) {
> > >        temp <- x[i]
> > >        x[i] <- x[i+1]
> > >        x[i+1] <- temp
> > >       }
> > >      }
> > >     }
> > >  return(x)
> > > }
> > >
> > > x <- c(1:10)
> > > print(x)
> > > print(bubblesort(x))
> > >
> > > This function does its job. It moves values divisible by 5 on the
> > > beginning. The question is how to increase divisor every "round" ?
> > >
> > > Thanks for any kind of help
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 
> <code.txt>


From hpages at fredhutch.org  Tue Apr  4 00:27:14 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 3 Apr 2017 15:27:14 -0700
Subject: [R] Variation of bubble sort (based on divisors)
In-Reply-To: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>
References: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>
Message-ID: <cf01dab2-8296-630c-e630-1a4fe484238c@fredhutch.org>

Hi Piotr,

On 03/31/2017 11:16 AM, Piotr Koller wrote:
> Hi, I'd like to create a function that will sort values of a vector on a
> given basis:
>
> -zeros
>
> -ones
>
> -numbers divisible by 2
>
> -numbers divisible by 3 (but not by 2)
>
> -numbers divisible by 5 (but not by 2 and 3)

In other words, you want to sort your values by smallest divisor
(not regarding 1 as a divisor). The sorting part is easy if you can
map each value to its smaller divisor (mapping 0 to 0 and 1 to 1):

1) Map the values in 'x' to their smallest divisor:

   x <- as.integer(x)
   smallest_divisor <- sapply(x, smallestDivisor)
   smallest_divisor[x == 0L] <- 0L
   smallest_divisor[x == 1L] <- 1L

2) Then sort 'x' based on the values in 'smallest_divisor':

   x[order(smallest_divisor)]

So the real difficulty here is not the sorting, it's to find the
smallest divisor. Here is a function that does this:

   smallestDivisor <- function(x)
   {
     if (!is.integer(x) || length(x) != 1L || is.na(x))
         stop("'x' must be a single integer")

     ## All prime numbers <= 2*3*5*7 = ND
     pm210 <- as.integer(c(2, 3, 5, 7, 11, 13, 17, 19,
                           23, 29, 31, 37, 41, 43, 47,
                           53, 59, 61, 67, 71, 73, 79,
                           83, 89, 97, 101, 103, 107, 109,
                           113, 127, 131, 137, 139, 149,
                           151, 157, 163, 167, 173, 179,
                           181, 191, 193, 197, 199))
     ans <- which(x %% pm210 == 0L)[1L]
     if (!is.na(ans))
         return(pm210[ans])

     ## Use Sieve of Eratosthenes to prepare the divisors that
     ## are > ND and <= 2*ND.
     pm0 <- c(3L, 5L, 7L)  # must start with 3, not 2
     prod0 <- as.integer(cumprod(pm0)[length(pm0)])
     ND <- 2L * prod0
     div <- 1L + 2L*(0L:(prod0-1L))
     for (p in pm0)
         div <- setdiff(div, p*(1L:(ND%/%p-1L)))
     div <- div + ND
     sqrtx <- sqrt(x)
     while (div[1L] <= sqrtx) {
         ans <- which(x %% div == 0L)[1L]
         if (!is.na(ans))
             return(div[ans])
         div <- div + ND
     }
     x
   }

I'm sure there are faster ways to do this.

Cheers,
H.


>
> etc.
>
> I also want to omit zeros in those turns. So when I have a given vector of
> c(0:10), I want to receive 0 1 2 4 6 8 10 3 9 5 7 I think it'd be the best
> to use some variation of bubble sort, so it'd look like that
>
> sort <- function(x) {
>  for (j in (length(x)-1):1) {
>    for (i in j:(length(x)-1)) {
>      if (x[i+1]%%divisor==0 && x[i]%%divisor!=0) {
>       temp <- x[i]
>       x[i] <- x[i+1]
>       x[i+1] <- temp
>       }
>     }
>   }
>  return(x)}
>
> This function works out well on a given divisor and incresing sequences.
>
> sort <- function(x) {
>   for (j in (length(x)-1):1) {
>      for (i in j:(length(x)-1)) {
>        if (x[i+1]%%5==0 && x[i]%%5!=0) {
>         temp <- x[i]
>         x[i] <- x[i+1]
>         x[i+1] <- temp
>        }
>       }
>      }
>   return(x)
>  }
>
> x <- c(1:10)
> print(x)
> print(bubblesort(x))
>
> This function does its job. It moves values divisible by 5 on the
> beginning. The question is how to increase divisor every "round" ?
>
> Thanks for any kind of help
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AeHAcF7RnhWvQIqG5c2ucgFS0WIOmMFeRheLIeSwu0U&s=xJMmDOJLaQZ0QMmI7rkkNd2T5-zrh843rlJ-R1LQ9G8&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AeHAcF7RnhWvQIqG5c2ucgFS0WIOmMFeRheLIeSwu0U&s=c9IcZitWvur2grg8C54Jnt5LmajX0ODDANY-BGRzMbk&e=
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From vineetgupta410 at gmail.com  Mon Apr  3 19:06:06 2017
From: vineetgupta410 at gmail.com (Vineet Gupta)
Date: Mon, 3 Apr 2017 18:06:06 +0100
Subject: [R] R hangs on startup
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>	<01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
	<012201d2ac5e$6af35180$40d9f480$@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <019b01d2ac9c$95f17270$c1d45750$@gmail.com>

John,

R does not work properly, outside of RStudio.

Vineet

-----Original Message-----
From: Fox, John [mailto:jfox at mcmaster.ca] 
Sent: 03 April 2017 17:56
To: Vineet Gupta <vineetgupta410 at gmail.com>
Cc: r-help at r-project.org; 'David Winsemius' <dwinsemius at comcast.net>
Subject: RE: [R] R hangs on startup

Dear Vineet,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vineet 
> Gupta
> Sent: April 3, 2017 5:41 AM
> To: 'David Winsemius' <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> David,
> 
> Thx for the quick reply. Firstly, apologies for using windows - I need 
> to switch to Linux!

It's not obvious that your problem is OS-specific, nor is it necessarily the
case that your problem is a bad .RData or .Rhistory file, though it's worth
trying to delete them.

BTW, does R work properly outside of RStudio?

> 
> Do you have any suggestion of a suitable website, that may cover how 
> to do this? I will look on Google, but I generally find that to be a 
> time intensive, and low reward endeavour.

Generally R will save the workspace on exit (if you ask it to) in the
working directory. Under RStudio this would normally be the directory of
your current project, or, if you're not using a project and haven't changed
your working directory, in your Documents folder.

You're looking for files named .RData (the workspace) and .Rhistory. The
former may be hidden in Windows Explorer  if you don't display
known-to-Windows file extensions, but you'll still see the R icon. .Rhistory
isn't a registered extension and should appear in any event. Right click on
these files and delete them.

It's generally a good idea *not* to hide file extensions. In the Windows
Explorer "View" tab, check "File name extensions."

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> 
> Rgds,
> Vineet
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: 03 April 2017 05:03
> To: Vineet Gupta <lakestay at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> 
> > On Apr 2, 2017, at 2:30 PM, Vineet Gupta <lakestay at hotmail.com> wrote:
> >
> > Hi,
> >
> > I have been struggling with this problem with for 2 weeks, but have 
> > yet to
> find a solution on Google.
> >
> > I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I 
> > open R
> (and RStudio), the R screen freezes and is unusable. Nothing has 
> changed, to trigger this event. I have tried re-installing the 
> software, and downgrading to an older version of R. Nothing seems to work.
> >
> > If someone could help me, then I would very much appreciate it. At 
> > this
> point, I am at a loss.
> >
> 
> Startup difficulties are often the result of a corrupted ,Rdata or 
> .Rhistory file. These are generally hidden files, so you may need to 
> learn how to delete such "dot-files" or whatever term is used to 
> describe files that do no appear on your OS file browser. I don't know 
> where the Windows version of RStudio keeps these files.
> 
> 
> > Rgds,
> > Vineet
> >
> >
> > 	[[alternative HTML version deleted]]
> 
> Rhelp is a plain text mailing list.
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.


From vineetgupta410 at gmail.com  Mon Apr  3 21:34:51 2017
From: vineetgupta410 at gmail.com (Vineet Gupta)
Date: Mon, 3 Apr 2017 20:34:51 +0100
Subject: [R] R hangs on startup
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>	<01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
	<012201d2ac5e$6af35180$40d9f480$@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <014101d2acb1$5d84f870$188ee950$@gmail.com>

Hi,

Thanks to all of your answers. I have found that when I open a code file
with RStudio, it opens correctly, and the R session appears to work ok.

However, when I startup and R session or an RStudio session, then the R
session hangs.

I will try the other suggestions below to see if I can solve the problem.

Vineet


-----Original Message-----
From: Fox, John [mailto:jfox at mcmaster.ca] 
Sent: 03 April 2017 17:56
To: Vineet Gupta <vineetgupta410 at gmail.com>
Cc: r-help at r-project.org; 'David Winsemius' <dwinsemius at comcast.net>
Subject: RE: [R] R hangs on startup

Dear Vineet,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vineet 
> Gupta
> Sent: April 3, 2017 5:41 AM
> To: 'David Winsemius' <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> David,
> 
> Thx for the quick reply. Firstly, apologies for using windows - I need 
> to switch to Linux!

It's not obvious that your problem is OS-specific, nor is it necessarily the
case that your problem is a bad .RData or .Rhistory file, though it's worth
trying to delete them.

BTW, does R work properly outside of RStudio?

> 
> Do you have any suggestion of a suitable website, that may cover how 
> to do this? I will look on Google, but I generally find that to be a 
> time intensive, and low reward endeavour.

Generally R will save the workspace on exit (if you ask it to) in the
working directory. Under RStudio this would normally be the directory of
your current project, or, if you're not using a project and haven't changed
your working directory, in your Documents folder.

You're looking for files named .RData (the workspace) and .Rhistory. The
former may be hidden in Windows Explorer  if you don't display
known-to-Windows file extensions, but you'll still see the R icon. .Rhistory
isn't a registered extension and should appear in any event. Right click on
these files and delete them.

It's generally a good idea *not* to hide file extensions. In the Windows
Explorer "View" tab, check "File name extensions."

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> 
> Rgds,
> Vineet
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: 03 April 2017 05:03
> To: Vineet Gupta <lakestay at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] R hangs on startup
> 
> 
> > On Apr 2, 2017, at 2:30 PM, Vineet Gupta <lakestay at hotmail.com> wrote:
> >
> > Hi,
> >
> > I have been struggling with this problem with for 2 weeks, but have 
> > yet to
> find a solution on Google.
> >
> > I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I 
> > open R
> (and RStudio), the R screen freezes and is unusable. Nothing has 
> changed, to trigger this event. I have tried re-installing the 
> software, and downgrading to an older version of R. Nothing seems to work.
> >
> > If someone could help me, then I would very much appreciate it. At 
> > this
> point, I am at a loss.
> >
> 
> Startup difficulties are often the result of a corrupted ,Rdata or 
> .Rhistory file. These are generally hidden files, so you may need to 
> learn how to delete such "dot-files" or whatever term is used to 
> describe files that do no appear on your OS file browser. I don't know 
> where the Windows version of RStudio keeps these files.
> 
> 
> > Rgds,
> > Vineet
> >
> >
> > 	[[alternative HTML version deleted]]
> 
> Rhelp is a plain text mailing list.
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.


From rcalinjageman at dom.edu  Mon Apr  3 23:32:06 2017
From: rcalinjageman at dom.edu (Calin-Jageman, Robert)
Date: Mon, 3 Apr 2017 21:32:06 +0000
Subject: [R] matafor package - categorical moderator interpretation question
Message-ID: <BLUPR01MB148944C4B05073ACC967271B6080@BLUPR01MB148.prod.exchangelabs.com>

What does it mean if a categorical moderator is significant overall but has no significant pairwise contrasts between moderator levels?



I'm using metaphor to conduct a meta-analysis with a categorical moderator with 3 levels; this yields a significant result:

              Test of Moderators (coefficient(s) 1,2,3):

      F(df1 = 3, df2 = 37) = 4.6052, p-val = 0.0078


Model Results:
                                          estimate      se    tval    pval    ci.lb   ci.ub
factor(sample_data$Participants)Adults      0.3920  0.2847  1.3771  0.1768  -0.1848  0.9688
factor(sample_data$Participants)Online      0.1403  0.1283  1.0935  0.2812  -0.1197  0.4004
factor(sample_data$Participants)Students    0.2350  0.0717  3.2747  0.0023   0.0896  0.3803  **



But then I conduct contrasts between each moderator level, and none of these are significant (no correction for multiple comparisons applied):



                Linear Hypotheses:

                       Estimate Std. Error z value Pr(>|z|)

      Online - Adults == 0    -0.2517     0.3123  -0.806    0.420

      Students - Adults == 0  -0.1571     0.2936  -0.535    0.593

      Students - Online == 0   0.0946     0.1470   0.643    0.520

      (Adjusted p values reported -- none method)



Any thoughts or guides to interpretation are appreciated!  My code and sample data are at the end of the email.  My interpretation is that while one of the moderator levels may have be a significant factor in the overall analysis, the comparisons between moderator levels are noisier because they test to see if there is a difference in the weights between the two levels.  Given this pattern of results, I conclude the different moderator levels are probably not strong predictors of effect size.  I'm a bit uncertain if this is correct, and would appreciate any feedback.



Bob



========

Robert Calin-Jageman

Professor, Psychology

Neuroscience Program Director

Dominican University

Parmer 210

7900 West Division

River Forest, IL 60305

rcalinjageman at dom.edu

708.524.6581

http://calin-jageman.net



Sample data link:

https://www.dropbox.com/s/hzz9wmt1d9tcxsm/red_effect_males.csv?dl=0

Code:



#load required libraries

library("metafor")

library("multcomp")



sample_data <- read.csv("red_effect_males.csv")



#Overall test of categorical moderator, reports significant result

mod_test = rma(yi, vi, mods = ~factor(sample_data$Participants) - 1, data=sample_data, knha = TRUE)

print(mod_test)



#Now do pairwise contrasts - but these show no significant contrasts....why?

cont_holder <- c(1:length(unique(sample_data$Participants)))

names(cont_holder) <- sort(unique(sample_data$Participants))

print(summary(glht(mod_test, linfct=contrMat(cont_holder, "Tukey")), test=adjusted("none")))





#Now print individual meta-analysis for each subgroub... Effect sizes estimates and CIs aren't the same as in overall analysis...why?

subgroup_list <- split(sample_data, sample_data$Participants, drop=FALSE)

for (subgroup in subgroup_list) {

  print(paste("Individual results for: ", subgroup$Participants[1]))

  print(rma(yi, vi, data=subgroup, knha=TRUE))

}





	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Apr  4 05:57:07 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 3 Apr 2017 22:57:07 -0500
Subject: [R] system call removes special characters from text output
Message-ID: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>

Hello,

I am writing an R package, and I am using system() to call a perl script.
The output of the perl script is correct except for "[A/B]" is output as
"AB". Can someone explain this behavior. I would like to try and fix this.
many thanks,

Stephen Sefick

-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr  4 06:23:20 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 03 Apr 2017 21:23:20 -0700
Subject: [R] system call removes special characters from text output
In-Reply-To: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
Message-ID: <1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>

Sorry, RPsychic package not found. Please install package reprex, apply it to your problem and try again. Note that if this problem can only be produced from within a package then there is an R-package-devel mailing list that would be a more appropriate place to ask. Also, if the problem is actually in the perl code or in the shell (this seems likely to me) then you probably need to look even further afield for help. 
-- 
Sent from my phone. Please excuse my brevity.

On April 3, 2017 8:57:07 PM PDT, stephen sefick <ssefick at gmail.com> wrote:
>Hello,
>
>I am writing an R package, and I am using system() to call a perl
>script.
>The output of the perl script is correct except for "[A/B]" is output
>as
>"AB". Can someone explain this behavior. I would like to try and fix
>this.
>many thanks,
>
>Stephen Sefick


From ssefick at gmail.com  Tue Apr  4 06:44:48 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 3 Apr 2017 23:44:48 -0500
Subject: [R] system call removes special characters from text output
In-Reply-To: <1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
	<1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>
Message-ID: <CADKEMqj19646MiFqdLa3rMpdkYh_iWKFUrs5XFngCpxL2Qfb4g@mail.gmail.com>

Hi Jeff,

My apologies for not providing enough information. The perl code works as
expected at the shell (without calling it from R). I have tried the system
call inside of an ESS R session and at a the shell. Both of these produce
the unexpected result. I can provide whatever information that is needed.
kindest regards,

Stephen

On Mon, Apr 3, 2017 at 11:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Sorry, RPsychic package not found. Please install package reprex, apply it
> to your problem and try again. Note that if this problem can only be
> produced from within a package then there is an R-package-devel mailing
> list that would be a more appropriate place to ask. Also, if the problem is
> actually in the perl code or in the shell (this seems likely to me) then
> you probably need to look even further afield for help.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 3, 2017 8:57:07 PM PDT, stephen sefick <ssefick at gmail.com> wrote:
> >Hello,
> >
> >I am writing an R package, and I am using system() to call a perl
> >script.
> >The output of the perl script is correct except for "[A/B]" is output
> >as
> >"AB". Can someone explain this behavior. I would like to try and fix
> >this.
> >many thanks,
> >
> >Stephen Sefick
>



-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jwd at surewest.net  Tue Apr  4 07:15:26 2017
From: jwd at surewest.net (John)
Date: Mon, 3 Apr 2017 22:15:26 -0700
Subject: [R] R hangs on startup
In-Reply-To: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
Message-ID: <20170403221526.01668632@Draco>

On Sun, 2 Apr 2017 21:30:54 +0000
Vineet Gupta <lakestay at hotmail.com> wrote:

> Hi,
> 
> I have been struggling with this problem with for 2 weeks, but have
> yet to find a solution on Google.
> 
> I am running R 3.3.3 on Windows 10. For the past 2 weeks, when I open
> R (and RStudio), the R screen freezes and is unusable. Nothing has
> changed, to trigger this event. I have tried re-installing the
> software, and downgrading to an older version of R. Nothing seems to
> work.
> 
> If someone could help me, then I would very much appreciate it. At
> this point, I am at a loss.
> 
> Rgds,
> Vineet

When you say you start R AND R-Studio but the R screen freezes, are you
saying that R-Studio freezes, or is a separate instance of R freezing,
or?  From your post this is not precisely clear.

JWDougherty


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr  4 08:41:28 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Tue, 4 Apr 2017 06:41:28 +0000
Subject: [R] matafor package - categorical moderator interpretation
	question
In-Reply-To: <BLUPR01MB148944C4B05073ACC967271B6080@BLUPR01MB148.prod.exchangelabs.com>
References: <BLUPR01MB148944C4B05073ACC967271B6080@BLUPR01MB148.prod.exchangelabs.com>
Message-ID: <81073fce4f41456799a7b6d9882e6db2@UM-MAIL3216.unimaas.nl>

You are not conducting a proper test of the moderator. When you use 'mods = ~factor(sample_data$Participants) - 1', the model does not include an intercept term but dummy variables corresponding to all levels of the moderator. The omnibus test you are getting therefore tests the null hypothesis that the model coefficients corresponding to the dummy variables are all simultaenously equal to zero. What you want to do is test the null hypothesis that the coefficients are equal to each other. The easiest way to obtain this test is to use 'mods = ~factor(sample_data$Participants)'.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Calin-Jageman, Robert
Sent: Monday, April 03, 2017 23:32
To: r-help at r-project.org
Subject: [R] matafor package - categorical moderator interpretation question

What does it mean if a categorical moderator is significant overall but has no significant pairwise contrasts between moderator levels?

I'm using metaphor to conduct a meta-analysis with a categorical moderator with 3 levels; this yields a significant result:

Test of Moderators (coefficient(s) 1,2,3):
F(df1 = 3, df2 = 37) = 4.6052, p-val = 0.0078

Model Results:
                                          estimate      se    tval    pval    ci.lb   ci.ub
factor(sample_data$Participants)Adults      0.3920  0.2847  1.3771  0.1768  -0.1848  0.9688
factor(sample_data$Participants)Online      0.1403  0.1283  1.0935  0.2812  -0.1197  0.4004
factor(sample_data$Participants)Students    0.2350  0.0717  3.2747  0.0023   0.0896  0.3803  **

But then I conduct contrasts between each moderator level, and none of these are significant (no correction for multiple comparisons applied):

Linear Hypotheses:

                       Estimate Std. Error z value Pr(>|z|)
Online - Adults == 0    -0.2517     0.3123  -0.806    0.420
Students - Adults == 0  -0.1571     0.2936  -0.535    0.593
Students - Online == 0   0.0946     0.1470   0.643    0.520
(Adjusted p values reported -- none method)

Any thoughts or guides to interpretation are appreciated!  My code and sample data are at the end of the email.  My interpretation is that while one of the moderator levels may have be a significant factor in the overall analysis, the comparisons between moderator levels are noisier because they test to see if there is a difference in the weights between the two levels.  Given this pattern of results, I conclude the different moderator levels are probably not strong predictors of effect size.  I'm a bit uncertain if this is correct, and would appreciate any feedback.

Bob

========

Robert Calin-Jageman
Professor, Psychology
Neuroscience Program Director
Dominican University
Parmer 210
7900 West Division
River Forest, IL 60305
rcalinjageman at dom.edu
708.524.6581
http://calin-jageman.net

Sample data link:

https://www.dropbox.com/s/hzz9wmt1d9tcxsm/red_effect_males.csv?dl=0

Code:

#load required libraries
library("metafor")
library("multcomp")

sample_data <- read.csv("red_effect_males.csv")

#Overall test of categorical moderator, reports significant result
mod_test = rma(yi, vi, mods = ~factor(sample_data$Participants) - 1, data=sample_data, knha = TRUE)
print(mod_test)

#Now do pairwise contrasts - but these show no significant contrasts....why?
cont_holder <- c(1:length(unique(sample_data$Participants)))
names(cont_holder) <- sort(unique(sample_data$Participants))
print(summary(glht(mod_test, linfct=contrMat(cont_holder, "Tukey")), test=adjusted("none")))

#Now print individual meta-analysis for each subgroub... Effect sizes estimates and CIs aren't the same as in overall analysis...why?
subgroup_list <- split(sample_data, sample_data$Participants, drop=FALSE)

for (subgroup in subgroup_list) {
  print(paste("Individual results for: ", subgroup$Participants[1]))
  print(rma(yi, vi, data=subgroup, knha=TRUE))
}


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr  4 08:41:28 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Tue, 4 Apr 2017 06:41:28 +0000
Subject: [R] matafor package - categorical moderator interpretation
	question
In-Reply-To: <BLUPR01MB148944C4B05073ACC967271B6080@BLUPR01MB148.prod.exchangelabs.com>
References: <BLUPR01MB148944C4B05073ACC967271B6080@BLUPR01MB148.prod.exchangelabs.com>
Message-ID: <81073fce4f41456799a7b6d9882e6db2@UM-MAIL3216.unimaas.nl>

You are not conducting a proper test of the moderator. When you use 'mods = ~factor(sample_data$Participants) - 1', the model does not include an intercept term but dummy variables corresponding to all levels of the moderator. The omnibus test you are getting therefore tests the null hypothesis that the model coefficients corresponding to the dummy variables are all simultaenously equal to zero. What you want to do is test the null hypothesis that the coefficients are equal to each other. The easiest way to obtain this test is to use 'mods = ~factor(sample_data$Participants)'.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Calin-Jageman, Robert
Sent: Monday, April 03, 2017 23:32
To: r-help at r-project.org
Subject: [R] matafor package - categorical moderator interpretation question

What does it mean if a categorical moderator is significant overall but has no significant pairwise contrasts between moderator levels?

I'm using metaphor to conduct a meta-analysis with a categorical moderator with 3 levels; this yields a significant result:

Test of Moderators (coefficient(s) 1,2,3):
F(df1 = 3, df2 = 37) = 4.6052, p-val = 0.0078

Model Results:
                                          estimate      se    tval    pval    ci.lb   ci.ub
factor(sample_data$Participants)Adults      0.3920  0.2847  1.3771  0.1768  -0.1848  0.9688
factor(sample_data$Participants)Online      0.1403  0.1283  1.0935  0.2812  -0.1197  0.4004
factor(sample_data$Participants)Students    0.2350  0.0717  3.2747  0.0023   0.0896  0.3803  **

But then I conduct contrasts between each moderator level, and none of these are significant (no correction for multiple comparisons applied):

Linear Hypotheses:

                       Estimate Std. Error z value Pr(>|z|)
Online - Adults == 0    -0.2517     0.3123  -0.806    0.420
Students - Adults == 0  -0.1571     0.2936  -0.535    0.593
Students - Online == 0   0.0946     0.1470   0.643    0.520
(Adjusted p values reported -- none method)

Any thoughts or guides to interpretation are appreciated!  My code and sample data are at the end of the email.  My interpretation is that while one of the moderator levels may have be a significant factor in the overall analysis, the comparisons between moderator levels are noisier because they test to see if there is a difference in the weights between the two levels.  Given this pattern of results, I conclude the different moderator levels are probably not strong predictors of effect size.  I'm a bit uncertain if this is correct, and would appreciate any feedback.

Bob

========

Robert Calin-Jageman
Professor, Psychology
Neuroscience Program Director
Dominican University
Parmer 210
7900 West Division
River Forest, IL 60305
rcalinjageman at dom.edu
708.524.6581
http://calin-jageman.net

Sample data link:

https://www.dropbox.com/s/hzz9wmt1d9tcxsm/red_effect_males.csv?dl=0

Code:

#load required libraries
library("metafor")
library("multcomp")

sample_data <- read.csv("red_effect_males.csv")

#Overall test of categorical moderator, reports significant result
mod_test = rma(yi, vi, mods = ~factor(sample_data$Participants) - 1, data=sample_data, knha = TRUE)
print(mod_test)

#Now do pairwise contrasts - but these show no significant contrasts....why?
cont_holder <- c(1:length(unique(sample_data$Participants)))
names(cont_holder) <- sort(unique(sample_data$Participants))
print(summary(glht(mod_test, linfct=contrMat(cont_holder, "Tukey")), test=adjusted("none")))

#Now print individual meta-analysis for each subgroub... Effect sizes estimates and CIs aren't the same as in overall analysis...why?
subgroup_list <- split(sample_data, sample_data$Participants, drop=FALSE)

for (subgroup in subgroup_list) {
  print(paste("Individual results for: ", subgroup$Participants[1]))
  print(rma(yi, vi, data=subgroup, knha=TRUE))
}


From danprec at hotmail.com  Tue Apr  4 10:50:43 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 08:50:43 +0000
Subject: [R] R function stopped working
Message-ID: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

The following function is supposed to search the workspace and save
plots??(i.e. listing all objects in the workspace named "Figs", which
are all ggplot2 plots, and saving them as png files)

SaveFigs <- function()
{
	for (i in ls(pattern="_Figs_"))
	{
		filename = paste(Plots_Path, i, ".png", sep="")
		png(filename)
		print(eval(as.name(i)))
		dev.off()
	}
}


It was working perfectly until some days ago, but now nothing happens
when the function is called. No error, no output, no result, no files,
nothing at all. Completely useless.

If I run the for loop inside alone, without the function, it works
perfectly and produces the expected result (png files in the defined
folder). But running it as a function doesn't do anything at all.

Can anyone explain why did this function simply and suddenly stopped
working?

(using R version 3.3.3 on an ubuntu 16.10, if that is of any help)

From danprec at hotmail.com  Tue Apr  4 10:50:43 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 08:50:43 +0000
Subject: [R] R function stopped working
Message-ID: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

The following function is supposed to search the workspace and save
plots??(i.e. listing all objects in the workspace named "Figs", which
are all ggplot2 plots, and saving them as png files)

SaveFigs <- function()
{
	for (i in ls(pattern="_Figs_"))
	{
		filename = paste(Plots_Path, i, ".png", sep="")
		png(filename)
		print(eval(as.name(i)))
		dev.off()
	}
}


It was working perfectly until some days ago, but now nothing happens
when the function is called. No error, no output, no result, no files,
nothing at all. Completely useless.

If I run the for loop inside alone, without the function, it works
perfectly and produces the expected result (png files in the defined
folder). But running it as a function doesn't do anything at all.

Can anyone explain why did this function simply and suddenly stopped
working?

(using R version 3.3.3 on an ubuntu 16.10, if that is of any help)

From pdalgd at gmail.com  Tue Apr  4 11:21:36 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Apr 2017 11:21:36 +0200
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>

How about inserting print() statements on the output of "ls()" and the value of "filename". In particular, is the value of Plots_path the same as last week?

-pd


> On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com> wrote:
> 
> The following function is supposed to search the workspace and save
> plots  (i.e. listing all objects in the workspace named "Figs", which
> are all ggplot2 plots, and saving them as png files)
> 
> SaveFigs <- function()
> {
> 	for (i in ls(pattern="_Figs_"))
> 	{
> 		filename = paste(Plots_Path, i, ".png", sep="")
> 		png(filename)
> 		print(eval(as.name(i)))
> 		dev.off()
> 	}
> }
> 
> 
> It was working perfectly until some days ago, but now nothing happens
> when the function is called. No error, no output, no result, no files,
> nothing at all. Completely useless.
> 
> If I run the for loop inside alone, without the function, it works
> perfectly and produces the expected result (png files in the defined
> folder). But running it as a function doesn't do anything at all.
> 
> Can anyone explain why did this function simply and suddenly stopped
> working?
> 
> (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Apr  4 11:21:36 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Apr 2017 11:21:36 +0200
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>

How about inserting print() statements on the output of "ls()" and the value of "filename". In particular, is the value of Plots_path the same as last week?

-pd


> On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com> wrote:
> 
> The following function is supposed to search the workspace and save
> plots  (i.e. listing all objects in the workspace named "Figs", which
> are all ggplot2 plots, and saving them as png files)
> 
> SaveFigs <- function()
> {
> 	for (i in ls(pattern="_Figs_"))
> 	{
> 		filename = paste(Plots_Path, i, ".png", sep="")
> 		png(filename)
> 		print(eval(as.name(i)))
> 		dev.off()
> 	}
> }
> 
> 
> It was working perfectly until some days ago, but now nothing happens
> when the function is called. No error, no output, no result, no files,
> nothing at all. Completely useless.
> 
> If I run the for loop inside alone, without the function, it works
> perfectly and produces the expected result (png files in the defined
> folder). But running it as a function doesn't do anything at all.
> 
> Can anyone explain why did this function simply and suddenly stopped
> working?
> 
> (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From danprec at hotmail.com  Tue Apr  4 12:27:30 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 10:27:30 +0000
Subject: [R] R function stopped working
In-Reply-To: <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
Message-ID: <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

Thanks, but printing doesn't work within the function either. (i.e, no
result or output, or error). Also, like I said, the loop is working
fine on its own (so the path, name, filename, and all other variables
called from the function exist, are available and are recognized just
fine). It just doesn't do anything (anymore) if the loop is inside a
function.


On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:
> How about inserting print() statements on the output of "ls()" and
> the value of "filename". In particular, is the value of Plots_path
> the same as last week?
> 
> -pd
> 
> 
> > On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com>
> > wrote:
> > 
> > The following function is supposed to search the workspace and save
> > plots??(i.e. listing all objects in the workspace named "Figs",
> > which
> > are all ggplot2 plots, and saving them as png files)
> > 
> > SaveFigs <- function()
> > {
> > 	for (i in ls(pattern="_Figs_"))
> > 	{
> > 		filename = paste(Plots_Path, i, ".png", sep="")
> > 		png(filename)
> > 		print(eval(as.name(i)))
> > 		dev.off()
> > 	}
> > }
> > 
> > 
> > It was working perfectly until some days ago, but now nothing
> > happens
> > when the function is called. No error, no output, no result, no
> > files,
> > nothing at all. Completely useless.
> > 
> > If I run the for loop inside alone, without the function, it works
> > perfectly and produces the expected result (png files in the
> > defined
> > folder). But running it as a function doesn't do anything at all.
> > 
> > Can anyone explain why did this function simply and suddenly
> > stopped
> > working?
> > 
> > (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-g
> > uide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 

From danprec at hotmail.com  Tue Apr  4 12:27:30 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 10:27:30 +0000
Subject: [R] R function stopped working
In-Reply-To: <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
Message-ID: <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

Thanks, but printing doesn't work within the function either. (i.e, no
result or output, or error). Also, like I said, the loop is working
fine on its own (so the path, name, filename, and all other variables
called from the function exist, are available and are recognized just
fine). It just doesn't do anything (anymore) if the loop is inside a
function.


On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:
> How about inserting print() statements on the output of "ls()" and
> the value of "filename". In particular, is the value of Plots_path
> the same as last week?
> 
> -pd
> 
> 
> > On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com>
> > wrote:
> > 
> > The following function is supposed to search the workspace and save
> > plots??(i.e. listing all objects in the workspace named "Figs",
> > which
> > are all ggplot2 plots, and saving them as png files)
> > 
> > SaveFigs <- function()
> > {
> > 	for (i in ls(pattern="_Figs_"))
> > 	{
> > 		filename = paste(Plots_Path, i, ".png", sep="")
> > 		png(filename)
> > 		print(eval(as.name(i)))
> > 		dev.off()
> > 	}
> > }
> > 
> > 
> > It was working perfectly until some days ago, but now nothing
> > happens
> > when the function is called. No error, no output, no result, no
> > files,
> > nothing at all. Completely useless.
> > 
> > If I run the for loop inside alone, without the function, it works
> > perfectly and produces the expected result (png files in the
> > defined
> > folder). But running it as a function doesn't do anything at all.
> > 
> > Can anyone explain why did this function simply and suddenly
> > stopped
> > working?
> > 
> > (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-g
> > uide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 

From pdalgd at gmail.com  Tue Apr  4 15:26:20 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Apr 2017 15:26:20 +0200
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>

Given the following little experiment

> foobar <- 1
> f <- function() ls()
> f()
character(0)
> f <- function(x) ls()
> f(2)
[1] "x"
> 

... I am pretty sure that your code _never_ actually worked. 

It probably helps if you tell ls() which environment to list, as in:

> f <- function() ls(.GlobalEnv)
> f()
[1] "f"      "foobar"


> On 4 Apr 2017, at 12:27 , DANIEL PRECIADO <danprec at hotmail.com> wrote:
> 
> Thanks, but printing doesn't work within the function either. (i.e, no
> result or output, or error). Also, like I said, the loop is working
> fine on its own (so the path, name, filename, and all other variables
> called from the function exist, are available and are recognized just
> fine). It just doesn't do anything (anymore) if the loop is inside a
> function.
> 
> 
> On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:
>> How about inserting print() statements on the output of "ls()" and
>> the value of "filename". In particular, is the value of Plots_path
>> the same as last week?
>> 
>> -pd
>> 
>> 
>>> On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com>
>>> wrote:
>>> 
>>> The following function is supposed to search the workspace and save
>>> plots  (i.e. listing all objects in the workspace named "Figs",
>>> which
>>> are all ggplot2 plots, and saving them as png files)
>>> 
>>> SaveFigs <- function()
>>> {
>>> 	for (i in ls(pattern="_Figs_"))
>>> 	{
>>> 		filename = paste(Plots_Path, i, ".png", sep="")
>>> 		png(filename)
>>> 		print(eval(as.name(i)))
>>> 		dev.off()
>>> 	}
>>> }
>>> 
>>> 
>>> It was working perfectly until some days ago, but now nothing
>>> happens
>>> when the function is called. No error, no output, no result, no
>>> files,
>>> nothing at all. Completely useless.
>>> 
>>> If I run the for loop inside alone, without the function, it works
>>> perfectly and produces the expected result (png files in the
>>> defined
>>> folder). But running it as a function doesn't do anything at all.
>>> 
>>> Can anyone explain why did this function simply and suddenly
>>> stopped
>>> working?
>>> 
>>> (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-g
>>> uide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tungakantarci at gmail.com  Tue Apr  4 15:51:05 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Tue, 4 Apr 2017 15:51:05 +0200
Subject: [R] Converting date vector into a serial date number
Message-ID: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>

I have a data frame. One column (call this column a) contains years,
like 1871, and another column (call this column b) contains months,
like 2. I need to convert these year-month combinations, stored in
these two date vectors, into a single serial date number. E.g. year
1871 and month 2, stored in different vectors, should return 683429.
Meanwhile, when I check the class type of columns a and b, they are
both integer.

In MATLAB this can easily be done using the syntax

output = datenum(a,b,1)

In R, I have tried the as.POSIXct function but did not succeed. I also
tried the ISOdatetime function but that returned NA for all entries.
It should be a simple operation but I cannot seem to figure it out.


From danprec at hotmail.com  Tue Apr  4 16:09:24 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 14:09:24 +0000
Subject: [R] R function stopped working
In-Reply-To: <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
Message-ID: <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

To your first comment: Yes, the function used to work, and the loop inside it still does (as indicated in my first email). I wouldn't bother asking otherwise.
To your second, no, specifying the environment in the ls() call doesn't help, the problem persist.


On Tue, 2017-04-04 at 15:26 +0200, peter dalgaard wrote:

Given the following little experiment



foobar <- 1
f <- function() ls()
f()


character(0)


f <- function(x) ls()
f(2)


[1] "x"






... I am pretty sure that your code _never_ actually worked.

It probably helps if you tell ls() which environment to list, as in:



f <- function() ls(.GlobalEnv)
f()


[1] "f"      "foobar"




On 4 Apr 2017, at 12:27 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com>> wrote:

Thanks, but printing doesn't work within the function either. (i.e, no
result or output, or error). Also, like I said, the loop is working
fine on its own (so the path, name, filename, and all other variables
called from the function exist, are available and are recognized just
fine). It just doesn't do anything (anymore) if the loop is inside a
function.


On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:


How about inserting print() statements on the output of "ls()" and
the value of "filename". In particular, is the value of Plots_path
the same as last week?

-pd




On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com>>
wrote:

The following function is supposed to search the workspace and save
plots  (i.e. listing all objects in the workspace named "Figs",
which
are all ggplot2 plots, and saving them as png files)

SaveFigs <- function()
{
        for (i in ls(pattern="_Figs_"))
        {
                filename = paste(Plots_Path, i, ".png", sep="")
                png(filename)
                print(eval(as.name(i)))
                dev.off()
        }
}


It was working perfectly until some days ago, but now nothing
happens
when the function is called. No error, no output, no result, no
files,
nothing at all. Completely useless.

If I run the for loop inside alone, without the function, it works
perfectly and produces the expected result (png files in the
defined
folder). But running it as a function doesn't do anything at all.

Can anyone explain why did this function simply and suddenly
stopped
working?

(using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-g
uide.html
and provide commented, minimal, self-contained, reproducible code.











	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue Apr  4 16:19:51 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 4 Apr 2017 10:19:51 -0400
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
 <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <EECE3DDD-2DDB-40B1-96E6-4548F26F1B3E@utoronto.ca>

I discourage the use of print() for debugging.
Put a browser() statement into your loop and when execution takes you to the debugger interface, examine your variables and expressions one by one.


B.




> On Apr 4, 2017, at 10:09 AM, DANIEL PRECIADO <danprec at hotmail.com> wrote:
> 
> To your first comment: Yes, the function used to work, and the loop inside it still does (as indicated in my first email). I wouldn't bother asking otherwise.
> To your second, no, specifying the environment in the ls() call doesn't help, the problem persist.
> 
> 
> On Tue, 2017-04-04 at 15:26 +0200, peter dalgaard wrote:
> 
> Given the following little experiment
> 
> 
> 
> foobar <- 1
> f <- function() ls()
> f()
> 
> 
> character(0)
> 
> 
> f <- function(x) ls()
> f(2)
> 
> 
> [1] "x"
> 
> 
> 
> 
> 
> 
> ... I am pretty sure that your code _never_ actually worked.
> 
> It probably helps if you tell ls() which environment to list, as in:
> 
> 
> 
> f <- function() ls(.GlobalEnv)
> f()
> 
> 
> [1] "f"      "foobar"
> 
> 
> 
> 
> On 4 Apr 2017, at 12:27 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com>> wrote:
> 
> Thanks, but printing doesn't work within the function either. (i.e, no
> result or output, or error). Also, like I said, the loop is working
> fine on its own (so the path, name, filename, and all other variables
> called from the function exist, are available and are recognized just
> fine). It just doesn't do anything (anymore) if the loop is inside a
> function.
> 
> 
> On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:
> 
> 
> How about inserting print() statements on the output of "ls()" and
> the value of "filename". In particular, is the value of Plots_path
> the same as last week?
> 
> -pd
> 
> 
> 
> 
> On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com>>
> wrote:
> 
> The following function is supposed to search the workspace and save
> plots  (i.e. listing all objects in the workspace named "Figs",
> which
> are all ggplot2 plots, and saving them as png files)
> 
> SaveFigs <- function()
> {
>        for (i in ls(pattern="_Figs_"))
>        {
>                filename = paste(Plots_Path, i, ".png", sep="")
>                png(filename)
>                print(eval(as.name(i)))
>                dev.off()
>        }
> }
> 
> 
> It was working perfectly until some days ago, but now nothing
> happens
> when the function is called. No error, no output, no result, no
> files,
> nothing at all. Completely useless.
> 
> If I run the for loop inside alone, without the function, it works
> perfectly and produces the expected result (png files in the
> defined
> folder). But running it as a function doesn't do anything at all.
> 
> Can anyone explain why did this function simply and suddenly
> stopped
> working?
> 
> (using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-g
> uide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Tue Apr  4 16:38:12 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 4 Apr 2017 15:38:12 +0100
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
 <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E2672405711568A3@GBTEDVPEXCMB04.corp.lgc-group.com>

Maybe a daft question arising from lack of reproducible example, but have you run ls() manually to make sure there are objects that _exactly_ match "_Figs_" ?
The simplest explanation for a loop doing nothing is that there are no cases.

S Ellison

> The following function is supposed to search the workspace and save plots
> (i.e. listing all objects in the workspace named "Figs", which are all ggplot2
> plots, and saving them as png files)
> 
> SaveFigs <- function()
> {
>         for (i in ls(pattern="_Figs_"))
>         {
>                 filename = paste(Plots_Path, i, ".png", sep="")
>                 png(filename)
>                 print(eval(as.name(i)))
>                 dev.off()
>         }
> }
> 
> 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From marc_schwartz at me.com  Tue Apr  4 17:00:25 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 04 Apr 2017 10:00:25 -0500
Subject: [R] Converting date vector into a serial date number
In-Reply-To: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>
References: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>
Message-ID: <EEFCD186-453E-4650-951B-E8644A064B8E@me.com>


> On Apr 4, 2017, at 8:51 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> I have a data frame. One column (call this column a) contains years,
> like 1871, and another column (call this column b) contains months,
> like 2. I need to convert these year-month combinations, stored in
> these two date vectors, into a single serial date number. E.g. year
> 1871 and month 2, stored in different vectors, should return 683429.
> Meanwhile, when I check the class type of columns a and b, they are
> both integer.
> 
> In MATLAB this can easily be done using the syntax
> 
> output = datenum(a,b,1)
> 
> In R, I have tried the as.POSIXct function but did not succeed. I also
> tried the ISOdatetime function but that returned NA for all entries.
> It should be a simple operation but I cannot seem to figure it out.

Hi,

The standard date classes in R require the full date (day, month, year) and the date/time classes require a correct time as well.

Looking at the help page for ?as.Date, there is information pertaining to MATLAB's date origin of 0000-01-01, as compared to R's of 1970-01-01. The difference is an offset of 719529.

Taking your number above of 683429, that would yield:

 > as.Date(683429, origin = "1970-01-01") - 719529
[1] "1871-03-01"

So your 'b' should be 3, not 2, presuming the first of the month is inferred. Otherwise:

> as.Date(683401, origin = "1970-01-01") - 719529
[1] "1871-02-01"

So, to reverse it, would be:

a <- 1871
b <- 3

> paste(a, b, 1, sep = "-")
[1] "1871-3-1"

> as.Date(paste(a, b, 1, sep = "-"))
[1] "1871-03-01"

> as.numeric(as.Date(paste(a, b, 1, sep = "-"))) + 719529
[1] 683429
  
The last step takes the date and coerces it to a numeric value in the number of days since the origin.

More generally, if you Google for R MATLAB, there are some online references that provide varying levels of function mappings between the two languages that you may find helpful.

Regards,

Marc Schwartz


From bgunter.4567 at gmail.com  Tue Apr  4 16:55:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 4 Apr 2017 07:55:46 -0700
Subject: [R] Converting date vector into a serial date number
In-Reply-To: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>
References: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>
Message-ID: <CAGxFJbTg1NU5EXJH0zPOqmueZ9tYSF_xuT7Y0=oEH+xLOjpEOA@mail.gmail.com>

?strptime  and ?paste (to combine your 2 date vector pieces)

Cheers,

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 4, 2017 at 6:51 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> I have a data frame. One column (call this column a) contains years,
> like 1871, and another column (call this column b) contains months,
> like 2. I need to convert these year-month combinations, stored in
> these two date vectors, into a single serial date number. E.g. year
> 1871 and month 2, stored in different vectors, should return 683429.
> Meanwhile, when I check the class type of columns a and b, they are
> both integer.
>
> In MATLAB this can easily be done using the syntax
>
> output = datenum(a,b,1)
>
> In R, I have tried the as.POSIXct function but did not succeed. I also
> tried the ISOdatetime function but that returned NA for all entries.
> It should be a simple operation but I cannot seem to figure it out.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tungakantarci at gmail.com  Tue Apr  4 17:14:26 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Tue, 4 Apr 2017 17:14:26 +0200
Subject: [R] Converting date vector into a serial date number
Message-ID: <CAMDpC=vWq0coLNk61ZhFkYQdSpGWu-ueCHuC-zaTsb6QjObN8Q@mail.gmail.com>

Marc, thank you for this excellent answer.


From jdnewmil at dcn.davis.ca.us  Tue Apr  4 17:16:02 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 04 Apr 2017 08:16:02 -0700
Subject: [R] Converting date vector into a serial date number
In-Reply-To: <EEFCD186-453E-4650-951B-E8644A064B8E@me.com>
References: <CAMDpC=tsqS8zfrzaprhjfzsb-u+96LD10irSFDZvNa2WwuUS3Q@mail.gmail.com>
 <EEFCD186-453E-4650-951B-E8644A064B8E@me.com>
Message-ID: <BDEE2DD4-2A4A-4A0F-B916-FBC53ED78D84@dcn.davis.ca.us>

I think it is important to point out that treating dates or times as serial numbers should only be done for importing or exporting data. Rather, once the conversion to one of the ?DateTimeClasses has occurred you are better off leaving it as such to reduce the brittleness of your code. For one thing, you should not be writing code that makes assumptions about the epoch (zero offset) everywhere in your code. 
-- 
Sent from my phone. Please excuse my brevity.

On April 4, 2017 8:00:25 AM PDT, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Apr 4, 2017, at 8:51 AM, Tunga Kantarc? <tungakantarci at gmail.com>
>wrote:
>> 
>> I have a data frame. One column (call this column a) contains years,
>> like 1871, and another column (call this column b) contains months,
>> like 2. I need to convert these year-month combinations, stored in
>> these two date vectors, into a single serial date number. E.g. year
>> 1871 and month 2, stored in different vectors, should return 683429.
>> Meanwhile, when I check the class type of columns a and b, they are
>> both integer.
>> 
>> In MATLAB this can easily be done using the syntax
>> 
>> output = datenum(a,b,1)
>> 
>> In R, I have tried the as.POSIXct function but did not succeed. I
>also
>> tried the ISOdatetime function but that returned NA for all entries.
>> It should be a simple operation but I cannot seem to figure it out.
>
>Hi,
>
>The standard date classes in R require the full date (day, month, year)
>and the date/time classes require a correct time as well.
>
>Looking at the help page for ?as.Date, there is information pertaining
>to MATLAB's date origin of 0000-01-01, as compared to R's of
>1970-01-01. The difference is an offset of 719529.
>
>Taking your number above of 683429, that would yield:
>
> > as.Date(683429, origin = "1970-01-01") - 719529
>[1] "1871-03-01"
>
>So your 'b' should be 3, not 2, presuming the first of the month is
>inferred. Otherwise:
>
>> as.Date(683401, origin = "1970-01-01") - 719529
>[1] "1871-02-01"
>
>So, to reverse it, would be:
>
>a <- 1871
>b <- 3
>
>> paste(a, b, 1, sep = "-")
>[1] "1871-3-1"
>
>> as.Date(paste(a, b, 1, sep = "-"))
>[1] "1871-03-01"
>
>> as.numeric(as.Date(paste(a, b, 1, sep = "-"))) + 719529
>[1] 683429
>  
>The last step takes the date and coerces it to a numeric value in the
>number of days since the origin.
>
>More generally, if you Google for R MATLAB, there are some online
>references that provide varying levels of function mappings between the
>two languages that you may find helpful.
>
>Regards,
>
>Marc Schwartz
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From danprec at hotmail.com  Tue Apr  4 17:19:36 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 4 Apr 2017 15:19:36 +0000
Subject: [R] R function stopped working
In-Reply-To: <EECE3DDD-2DDB-40B1-96E6-4548F26F1B3E@utoronto.ca>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
 <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <EECE3DDD-2DDB-40B1-96E6-4548F26F1B3E@utoronto.ca>
Message-ID: <MWHPR08MB2608878B92EEEDE08ED9C1DFA00B0@MWHPR08MB2608.namprd08.prod.outlook.com>

Thanks! I was not aware of the browser() function, seems pretty useful for debugging.
However, for this particular case, adding it to the mentioned function doesn't do much: Again I get no errors, no output in the terminal and no files are created.

If I include browser() within the for-loop (not defining it as a function, but running it directly), I do get to examine every step of the way, and it runs fine (as expected). But if the exact same for-loop is sitting inside a function, it doesn't do anything at all, with or without browser().

D.

On Tue, 2017-04-04 at 10:19 -0400, Boris Steipe wrote:

I discourage the use of print() for debugging.
Put a browser() statement into your loop and when execution takes you to the debugger interface, examine your variables and expressions one by one.


B.






On Apr 4, 2017, at 10:09 AM, DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com>> wrote:

To your first comment: Yes, the function used to work, and the loop inside it still does (as indicated in my first email). I wouldn't bother asking otherwise.
To your second, no, specifying the environment in the ls() call doesn't help, the problem persist.


On Tue, 2017-04-04 at 15:26 +0200, peter dalgaard wrote:

Given the following little experiment



foobar <- 1
f <- function() ls()
f()


character(0)


f <- function(x) ls()
f(2)


[1] "x"






... I am pretty sure that your code _never_ actually worked.

It probably helps if you tell ls() which environment to list, as in:



f <- function() ls(.GlobalEnv)
f()


[1] "f"      "foobar"




On 4 Apr 2017, at 12:27 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com><mailto:danprec at hotmail.com>> wrote:

Thanks, but printing doesn't work within the function either. (i.e, no
result or output, or error). Also, like I said, the loop is working
fine on its own (so the path, name, filename, and all other variables
called from the function exist, are available and are recognized just
fine). It just doesn't do anything (anymore) if the loop is inside a
function.


On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:


How about inserting print() statements on the output of "ls()" and
the value of "filename". In particular, is the value of Plots_path
the same as last week?

-pd




On 4 Apr 2017, at 10:50 , DANIEL PRECIADO <danprec at hotmail.com<mailto:danprec at hotmail.com><mailto:danprec at hotmail.com>>
wrote:

The following function is supposed to search the workspace and save
plots  (i.e. listing all objects in the workspace named "Figs",
which
are all ggplot2 plots, and saving them as png files)

SaveFigs <- function()
{
       for (i in ls(pattern="_Figs_"))
       {
               filename = paste(Plots_Path, i, ".png", sep="")
               png(filename)
               print(eval(as.name(i)))
               dev.off()
       }
}


It was working perfectly until some days ago, but now nothing
happens
when the function is called. No error, no output, no result, no
files,
nothing at all. Completely useless.

If I run the for loop inside alone, without the function, it works
perfectly and produces the expected result (png files in the
defined
folder). But running it as a function doesn't do anything at all.

Can anyone explain why did this function simply and suddenly
stopped
working?

(using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-g
uide.html
and provide commented, minimal, self-contained, reproducible code.











        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr  4 17:51:45 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 04 Apr 2017 08:51:45 -0700
Subject: [R] R function stopped working
In-Reply-To: <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608C6DF1185ED05C7426267A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <968E1D5A-C0F2-464F-A66A-4ED17BDFDA05@gmail.com>
 <MWHPR08MB2608F52B82011F0C21191975A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
 <8855E7E2-16BD-4F9F-A71D-EE270BE8220D@gmail.com>
 <MWHPR08MB2608C9530E8DCFFC4BBE2B64A00B0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <987FC510-74DE-466F-BFCC-43D06EF79DFF@dcn.davis.ca.us>

Daniel, if you wish to learn from your mistakes them you must listen. Peter is not someone whose input you should dismiss. The function you have showed us never worked as you have described it. However, if you give .GlobalEnv as the first argument in the call to ls() then it should work.

You will find it helpful to remember that "workspace" is not a precise description of how variables are stored in R... there are chains of "environments".  Invocation of a function creates a new environment that the ls function looks in by default, and ls does not follow the search path up to the global environment automatically. So, the code AS YOU PRESENTED IT could not have worked in spite of your assertions. Perhaps you had a fixed version somewhere that you lost? 
-- 
Sent from my phone. Please excuse my brevity.

On April 4, 2017 7:09:24 AM PDT, DANIEL PRECIADO <danprec at hotmail.com> wrote:
>To your first comment: Yes, the function used to work, and the loop
>inside it still does (as indicated in my first email). I wouldn't
>bother asking otherwise.
>To your second, no, specifying the environment in the ls() call doesn't
>help, the problem persist.
>
>
>On Tue, 2017-04-04 at 15:26 +0200, peter dalgaard wrote:
>
>Given the following little experiment
>
>
>
>foobar <- 1
>f <- function() ls()
>f()
>
>
>character(0)
>
>
>f <- function(x) ls()
>f(2)
>
>
>[1] "x"
>
>
>
>
>
>
>... I am pretty sure that your code _never_ actually worked.
>
>It probably helps if you tell ls() which environment to list, as in:
>
>
>
>f <- function() ls(.GlobalEnv)
>f()
>
>
>[1] "f"      "foobar"
>
>
>
>
>On 4 Apr 2017, at 12:27 , DANIEL PRECIADO
><danprec at hotmail.com<mailto:danprec at hotmail.com>> wrote:
>
>Thanks, but printing doesn't work within the function either. (i.e, no
>result or output, or error). Also, like I said, the loop is working
>fine on its own (so the path, name, filename, and all other variables
>called from the function exist, are available and are recognized just
>fine). It just doesn't do anything (anymore) if the loop is inside a
>function.
>
>
>On Tue, 2017-04-04 at 11:21 +0200, peter dalgaard wrote:
>
>
>How about inserting print() statements on the output of "ls()" and
>the value of "filename". In particular, is the value of Plots_path
>the same as last week?
>
>-pd
>
>
>
>
>On 4 Apr 2017, at 10:50 , DANIEL PRECIADO
><danprec at hotmail.com<mailto:danprec at hotmail.com>>
>wrote:
>
>The following function is supposed to search the workspace and save
>plots  (i.e. listing all objects in the workspace named "Figs",
>which
>are all ggplot2 plots, and saving them as png files)
>
>SaveFigs <- function()
>{
>        for (i in ls(pattern="_Figs_"))
>        {
>                filename = paste(Plots_Path, i, ".png", sep="")
>                png(filename)
>                print(eval(as.name(i)))
>                dev.off()
>        }
>}
>
>
>It was working perfectly until some days ago, but now nothing
>happens
>when the function is called. No error, no output, no result, no
>files,
>nothing at all. Completely useless.
>
>If I run the for loop inside alone, without the function, it works
>perfectly and produces the expected result (png files in the
>defined
>folder). But running it as a function doesn't do anything at all.
>
>Can anyone explain why did this function simply and suddenly
>stopped
>working?
>
>(using R version 3.3.3 on an ubuntu 16.10, if that is of any help)
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-g
>uide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Apr  4 18:01:04 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 4 Apr 2017 12:01:04 -0400
Subject: [R] system call removes special characters from text output
In-Reply-To: <CADKEMqj19646MiFqdLa3rMpdkYh_iWKFUrs5XFngCpxL2Qfb4g@mail.gmail.com>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
 <1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>
 <CADKEMqj19646MiFqdLa3rMpdkYh_iWKFUrs5XFngCpxL2Qfb4g@mail.gmail.com>
Message-ID: <1956B2E4-8C8C-4CCC-8323-D2E70872B654@utoronto.ca>

The "whatever information" would be the usual minimal reproducible example.

Since you think your code works at the shell level, make up an example with a system call to "echo".
Then state what you expect to happen and what happens instead.

B.



> On Apr 4, 2017, at 12:44 AM, stephen sefick <ssefick at gmail.com> wrote:
> 
> Hi Jeff,
> 
> My apologies for not providing enough information. The perl code works as
> expected at the shell (without calling it from R). I have tried the system
> call inside of an ESS R session and at a the shell. Both of these produce
> the unexpected result. I can provide whatever information that is needed.
> kindest regards,
> 
> Stephen
> 
> On Mon, Apr 3, 2017 at 11:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> Sorry, RPsychic package not found. Please install package reprex, apply it
>> to your problem and try again. Note that if this problem can only be
>> produced from within a package then there is an R-package-devel mailing
>> list that would be a more appropriate place to ask. Also, if the problem is
>> actually in the perl code or in the shell (this seems likely to me) then
>> you probably need to look even further afield for help.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On April 3, 2017 8:57:07 PM PDT, stephen sefick <ssefick at gmail.com> wrote:
>>> Hello,
>>> 
>>> I am writing an R package, and I am using system() to call a perl
>>> script.
>>> The output of the perl script is correct except for "[A/B]" is output
>>> as
>>> "AB". Can someone explain this behavior. I would like to try and fix
>>> this.
>>> many thanks,
>>> 
>>> Stephen Sefick
>> 
> 
> 
> 
> -- 
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
> 
>                                -K. Mullis
> 
> "A big computer, a complex algorithm and a long time does not equal
> science."
> 
>                              -Robert Gentleman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Tue Apr  4 18:28:48 2017
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 4 Apr 2017 11:28:48 -0500
Subject: [R] system call removes special characters from text output
In-Reply-To: <1956B2E4-8C8C-4CCC-8323-D2E70872B654@utoronto.ca>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
 <1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>
 <CADKEMqj19646MiFqdLa3rMpdkYh_iWKFUrs5XFngCpxL2Qfb4g@mail.gmail.com>
 <1956B2E4-8C8C-4CCC-8323-D2E70872B654@utoronto.ca>
Message-ID: <CADKEMqjBH6Y+W8EvCoupJ=fGaYem8twSw1APx2cZK38SvdZ+Uw@mail.gmail.com>

Hello everyone,

Again, I apologize for not providing a reproducible example. There was a
small (but important) bug in my R code having nothing to do with system(),
this is now fixed, and everything is working as expected this morning. The
lesson for me is time to stop coding after 10 PM. Thank you for all of the
help.
kindest regards,

Stephen

On Tue, Apr 4, 2017 at 11:01 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> The "whatever information" would be the usual minimal reproducible example.
>
> Since you think your code works at the shell level, make up an example
> with a system call to "echo".
> Then state what you expect to happen and what happens instead.
>
> B.
>
>
>
> > On Apr 4, 2017, at 12:44 AM, stephen sefick <ssefick at gmail.com> wrote:
> >
> > Hi Jeff,
> >
> > My apologies for not providing enough information. The perl code works as
> > expected at the shell (without calling it from R). I have tried the
> system
> > call inside of an ESS R session and at a the shell. Both of these produce
> > the unexpected result. I can provide whatever information that is needed.
> > kindest regards,
> >
> > Stephen
> >
> > On Mon, Apr 3, 2017 at 11:23 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> Sorry, RPsychic package not found. Please install package reprex, apply
> it
> >> to your problem and try again. Note that if this problem can only be
> >> produced from within a package then there is an R-package-devel mailing
> >> list that would be a more appropriate place to ask. Also, if the
> problem is
> >> actually in the perl code or in the shell (this seems likely to me) then
> >> you probably need to look even further afield for help.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On April 3, 2017 8:57:07 PM PDT, stephen sefick <ssefick at gmail.com>
> wrote:
> >>> Hello,
> >>>
> >>> I am writing an R package, and I am using system() to call a perl
> >>> script.
> >>> The output of the perl script is correct except for "[A/B]" is output
> >>> as
> >>> "AB". Can someone explain this behavior. I would like to try and fix
> >>> this.
> >>> many thanks,
> >>>
> >>> Stephen Sefick
> >>
> >
> >
> >
> > --
> > Let's not spend our time and resources thinking about things that are so
> > little or so large that all they really do for us is puff us up and make
> us
> > feel like gods.  We are mammals, and have not exhausted the annoying
> little
> > problems of being mammals.
> >
> >                                -K. Mullis
> >
> > "A big computer, a complex algorithm and a long time does not equal
> > science."
> >
> >                              -Robert Gentleman
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr  4 18:52:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 4 Apr 2017 09:52:58 -0700
Subject: [R] system call removes special characters from text output
In-Reply-To: <CADKEMqjBH6Y+W8EvCoupJ=fGaYem8twSw1APx2cZK38SvdZ+Uw@mail.gmail.com>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
 <1C1639FF-BE81-49C9-B9D4-3AF0D9DA55C7@dcn.davis.ca.us>
 <CADKEMqj19646MiFqdLa3rMpdkYh_iWKFUrs5XFngCpxL2Qfb4g@mail.gmail.com>
 <1956B2E4-8C8C-4CCC-8323-D2E70872B654@utoronto.ca>
 <CADKEMqjBH6Y+W8EvCoupJ=fGaYem8twSw1APx2cZK38SvdZ+Uw@mail.gmail.com>
Message-ID: <CAGxFJbRJkH=KMrg=0x9NkKaocUuWPAWg4Qc2PaM750Ri=w5rFg@mail.gmail.com>

... and perhaps worth noting (again) is that one of the benefits of
producing a repro ex is that it often reveals such bugs to the
prospective poster, thus obviating the need to post.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 4, 2017 at 9:28 AM, stephen sefick <ssefick at gmail.com> wrote:
> Hello everyone,
>
> Again, I apologize for not providing a reproducible example. There was a
> small (but important) bug in my R code having nothing to do with system(),
> this is now fixed, and everything is working as expected this morning. The
> lesson for me is time to stop coding after 10 PM. Thank you for all of the
> help.
> kindest regards,
>
> Stephen
>
> On Tue, Apr 4, 2017 at 11:01 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> The "whatever information" would be the usual minimal reproducible example.
>>
>> Since you think your code works at the shell level, make up an example
>> with a system call to "echo".
>> Then state what you expect to happen and what happens instead.
>>
>> B.
>>
>>
>>
>> > On Apr 4, 2017, at 12:44 AM, stephen sefick <ssefick at gmail.com> wrote:
>> >
>> > Hi Jeff,
>> >
>> > My apologies for not providing enough information. The perl code works as
>> > expected at the shell (without calling it from R). I have tried the
>> system
>> > call inside of an ESS R session and at a the shell. Both of these produce
>> > the unexpected result. I can provide whatever information that is needed.
>> > kindest regards,
>> >
>> > Stephen
>> >
>> > On Mon, Apr 3, 2017 at 11:23 PM, Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us>
>> > wrote:
>> >
>> >> Sorry, RPsychic package not found. Please install package reprex, apply
>> it
>> >> to your problem and try again. Note that if this problem can only be
>> >> produced from within a package then there is an R-package-devel mailing
>> >> list that would be a more appropriate place to ask. Also, if the
>> problem is
>> >> actually in the perl code or in the shell (this seems likely to me) then
>> >> you probably need to look even further afield for help.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On April 3, 2017 8:57:07 PM PDT, stephen sefick <ssefick at gmail.com>
>> wrote:
>> >>> Hello,
>> >>>
>> >>> I am writing an R package, and I am using system() to call a perl
>> >>> script.
>> >>> The output of the perl script is correct except for "[A/B]" is output
>> >>> as
>> >>> "AB". Can someone explain this behavior. I would like to try and fix
>> >>> this.
>> >>> many thanks,
>> >>>
>> >>> Stephen Sefick
>> >>
>> >
>> >
>> >
>> > --
>> > Let's not spend our time and resources thinking about things that are so
>> > little or so large that all they really do for us is puff us up and make
>> us
>> > feel like gods.  We are mammals, and have not exhausted the annoying
>> little
>> > problems of being mammals.
>> >
>> >                                -K. Mullis
>> >
>> > "A big computer, a complex algorithm and a long time does not equal
>> > science."
>> >
>> >                              -Robert Gentleman
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From louisa_reynolds at yahoo.co.uk  Tue Apr  4 13:47:03 2017
From: louisa_reynolds at yahoo.co.uk (Louisa Reynolds)
Date: Tue, 4 Apr 2017 11:47:03 +0000 (UTC)
Subject: [R] taking a small piece of large tiff
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
Message-ID: <1219060776.17600479.1491306423713@mail.yahoo.com>

Dear Forum?
I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files. ?I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
Thanks in advance.
	[[alternative HTML version deleted]]


From louisa_reynolds at yahoo.co.uk  Tue Apr  4 13:47:03 2017
From: louisa_reynolds at yahoo.co.uk (Louisa Reynolds)
Date: Tue, 4 Apr 2017 11:47:03 +0000 (UTC)
Subject: [R] taking a small piece of large tiff
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
Message-ID: <1219060776.17600479.1491306423713@mail.yahoo.com>

Dear Forum?
I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files. ?I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
Thanks in advance.
	[[alternative HTML version deleted]]


From jholtman at gmail.com  Tue Apr  4 19:37:11 2017
From: jholtman at gmail.com (jim holtman)
Date: Tue, 4 Apr 2017 13:37:11 -0400
Subject: [R] taking a small piece of large tiff
In-Reply-To: <1219060776.17600479.1491306423713@mail.yahoo.com>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
Message-ID: <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>

How big is 'large'?

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
<r-help at r-project.org> wrote:
> Dear Forum
> I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files.  I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
> Thanks in advance.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shukla.kank at gmail.com  Tue Apr  4 22:26:55 2017
From: shukla.kank at gmail.com (Kankana Shukla)
Date: Tue, 4 Apr 2017 15:26:55 -0500
Subject: [R] Using R and Python together
In-Reply-To: <CAKyN3iB-Xr7xwUfU0tsb5RjDDSOG3voWvLOfHPUEevxOSCEeNw@mail.gmail.com>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
 <986012A3-CA97-47CF-B7CB-D83DE73A2285@collocations.de>
 <CAN8Bj0nOO-FCPucGXC_x0AtdYzFAsECv7ifKsXQnO4M1aHY=GQ@mail.gmail.com>
 <CAKyN3iB-Xr7xwUfU0tsb5RjDDSOG3voWvLOfHPUEevxOSCEeNw@mail.gmail.com>
Message-ID: <CAN8Bj0nU1eqEu69o+N6qC-iBok-aWSyObYrYTH-wRjf1NfetuA@mail.gmail.com>

Installation of pyper gives me error code 1.  I used pip install on my
ubuntu machine.  How to install Pyper correctly?

Here is the debug log file:

------------------------------------------------------------
/usr/bin/pip run on Tue Apr  4 15:07:58 2017
Downloading/unpacking pyper
  Getting page https://pypi.python.org/simple/pyper/
  URLs to search for versions for pyper:
  * https://pypi.python.org/simple/pyper/
YV  Analyzing links from page https://pypi.python.org/simple/pyper/
    Found link
https://pypi.python.org/packages/0f/46/47a5ebf039d1982a5cf7ed4f53ef1dcfccf57358566da973732cfc2ac31d/PypeR-1.1.1.tar.gz#md5=8f1708b06e1cdd73d3f03b4342c7c948
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/4f/c2/957c9eb9ced95cedd04e6330ac446485d6e48f2d198f21f30aba0fe637cc/PypeR-1.0.1.tar.gz#md5=fc05ad098ef370deb7fffee34497fa82
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/56/fa/d6d58ace212c2dac27c08fe03c603eede4f1190a46d11917946db74bd1e8/PypeR-1.1.0.tar.gz#md5=6a186b5399d75f32f0eb29275c7e01b3
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/6c/87/a19361e922311aa86697edcbd95f3af85c69240350836136c629b7b29b38/PypeR-1.0.2.tar.gz#md5=73dd5f4b5dac2bd0a29425853c8de125
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/7e/4d/8167a3f7b3897b15ac5c2424886579cefa852705ac4c925dbdb8740f8838/PypeR-1.0.tar.gz#md5=eb05aa5ccee55e5175ea8f36e2d42591
(from https://pypi.python.org/simpl$
    Found link
https://pypi.python.org/packages/7f/44/4c063481bed01a9f18e34b823c796af7b8f59f458a8e67fd171263a96488/PypeR-1.0.3.tar.gz#md5=b8b9535e825d88dc6f15aff13c6e180c
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/e6/3e/4ed8b7c23333f7a1d3b18ecb37b09b4867fee95151a3a59c43c20376678e/PypeR-1.1.2.tar.gz#md5=d056a481a13d07300a5ffc6848b34d1e
(from https://pypi.python.org/sim$
    Found link
https://pypi.python.org/packages/eb/5a/2991b67ad276c55234ffff04b77eeb9c30e01cbda9920c9da9b20d656dc2/PypeR-1.0.4.tar.gz#md5=40b0ccaa645c7b936cc25ce86527aba6
(from https://pypi.python.org/sim$
  Using version 1.1.2 (newest of versions: 1.1.2, 1.1.1, 1.1.0, 1.0.4,
1.0.3, 1.0.2, 1.0.1, 1.0)
  Downloading PypeR-1.1.2.tar.gz
  Downloading from URL
https://pypi.python.org/packages/e6/3e/4ed8b7c23333f7a1d3b18ecb37b09b4867fee95151a3a59c43c20376678e/PypeR-1.1.2.tar.gz#md5=d056a481a13d07300a5ffc6848b34d1e
(from https://pypi.python$
  Running setup.py (path:/tmp/pip_build_root/pyper/setup.py) egg_info for
package pyper
    Traceback (most recent call last):
      File "<string>", line 17, in <module>
      File "/tmp/pip_build_root/pyper/setup.py", line 13, in <module>
        py_modules=['pyper'], # copy to site-packages
      File "/usr/lib/python2.7/distutils/core.py", line 111, in setup
        _setup_distribution = dist = klass(attrs)
      File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py",
line 320, in __init__
        _Distribution.__init__(self, attrs)
      File "/usr/lib/python2.7/distutils/dist.py", line 287, in __init__
        self.finalize_options()
      File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py",
line 386, in finalize_options
        ep.require(installer=self.fetch_build_egg)
      File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 2100,
in require
        working_set.resolve(self.dist.requires(self.extras),env,installer)))
      File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 620,
in resolve
        dist = best[req.key] = env.best_match(req, ws, installer)
      File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 858,
in best_match
        return self.obtain(req, installer) # try and download/install
      File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 870,
in obtain
        return installer(requirement)
      File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py",
line 416, in fetch_build_egg
        from setuptools.command.easy_install import easy_install
      File
"/usr/local/lib/python2.7/dist-packages/setuptools/command/easy_install.py",
line 51, in <module>
        from setuptools.archive_util import unpack_archive
      File
"/usr/local/lib/python2.7/dist-packages/setuptools/archive_util.py", line
11, in <module>
        from pkg_resources import ensure_directory, ContextualZipFile
    ImportError: cannot import name ContextualZipFile
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):

  File "<string>", line 17, in <module>

  File "/tmp/pip_build_root/pyper/setup.py", line 13, in <module>
    py_modules=['pyper'], # copy to site-packages

  File "/usr/lib/python2.7/distutils/core.py", line 111, in setup

    _setup_distribution = dist = klass(attrs)

  File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py", line
320, in __init__

    _Distribution.__init__(self, attrs)

  File "/usr/lib/python2.7/distutils/dist.py", line 287, in __init__

    self.finalize_options()

  File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py", line
386, in finalize_options

    ep.require(installer=self.fetch_build_egg)

  File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 2100, in
require

    working_set.resolve(self.dist.requires(self.extras),env,installer)))

  File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 620, in
resolve

    dist = best[req.key] = env.best_match(req, ws, installer)

  File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 858, in
best_match


    return self.obtain(req, installer) # try and download/install

  File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 870, in
obtain

    return installer(requirement)

  File "/usr/local/lib/python2.7/dist-packages/setuptools/dist.py", line
416, in fetch_build_egg

    from setuptools.command.easy_install import easy_install

  File
"/usr/local/lib/python2.7/dist-packages/setuptools/command/easy_install.py",
line 51, in <module>

    from setuptools.archive_util import unpack_archive

  File "/usr/local/lib/python2.7/dist-packages/setuptools/archive_util.py",
line 11, in <module>

    from pkg_resources import ensure_directory, ContextualZipFile

ImportError: cannot import name ContextualZipFile

----------------------------------------
Cleaning up...
  Removing temporary dir /tmp/pip_build_root...
Command python setup.py egg_info failed with error code 1 in
/tmp/pip_build_root/pyper
Exception information:
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/pip/basecommand.py", line 122, in
main
    status = self.run(options, args)
  File "/usr/lib/python2.7/dist-packages/pip/commands/install.py", line
278, in run
    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle,
bundle=self.bundle)
  File "/usr/lib/python2.7/dist-packages/pip/req.py", line 1230, in
prepare_files
    req_to_install.run_egg_info()
  File "/usr/lib/python2.7/dist-packages/pip/req.py", line 326, in
run_egg_info
    command_desc='python setup.py egg_info')
  File "/usr/lib/python2.7/dist-packages/pip/util.py", line 715, in
call_subprocess
    % (command_desc, proc.returncode, cwd))
InstallationError: Command python setup.py egg_info failed with error code
1 in /tmp/pip_build_root/pyper

-------------------------------------------

On Fri, Mar 31, 2017 at 1:35 PM, Wensui Liu <liuwensui at gmail.com> wrote:

> In https://statcompute.wordpress.com/?s=rpy2, you can find examples of
> rpy2.
>
> In https://statcompute.wordpress.com/?s=pyper, you can find examples of
> pyper.
>
> On Fri, Mar 31, 2017 at 11:38 AM, Kankana Shukla <shukla.kank at gmail.com>
> wrote:
> > I'm not great at rpy2.  Are there any good examples I could see to learn
> > how to do that?  My R code is very long and complicated.
> >
> > On Fri, Mar 31, 2017 at 7:08 AM, Stefan Evert <stefanML at collocations.de>
> > wrote:
> >
> >>
> >> > On 30 Mar 2017, at 23:37, Kankana Shukla <shukla.kank at gmail.com>
> wrote:
> >> >
> >> > I have searched for examples using R and Python together, and rpy2
> seems
> >> > like the way to go, but is there another (easier) way to do it?
> >>
> >> Rpy2 would seem to be a very easy and convenient solution.  What do you
> >> need that can't easily be down with rpy2?
> >>
> >> Best regards,
> >> Stefan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jwd at surewest.net  Tue Apr  4 22:53:25 2017
From: jwd at surewest.net (John)
Date: Tue, 4 Apr 2017 13:53:25 -0700
Subject: [R] R hangs on startup
In-Reply-To: <019b01d2ac9c$95f17270$c1d45750$@gmail.com>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
 <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
 <012201d2ac5e$6af35180$40d9f480$@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
 <019b01d2ac9c$95f17270$c1d45750$@gmail.com>
Message-ID: <20170404135325.7bfc087f@Draco>

On Mon, 3 Apr 2017 18:06:06 +0100
"Vineet Gupta" <vineetgupta410 at gmail.com> wrote:

> John,
> 
> R does not work properly, outside of RStudio.
> 
> Vineet
> 
That is what I thought you might be saying.  Does it work outside
if RStudio is not loaded?  Windows can occasionally be flaky
about multiple instances of a single program. 

John


From wdunlap at tibco.com  Tue Apr  4 23:06:32 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Apr 2017 14:06:32 -0700
Subject: [R] R hangs on startup
In-Reply-To: <20170404135325.7bfc087f@Draco>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
 <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
 <012201d2ac5e$6af35180$40d9f480$@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
 <019b01d2ac9c$95f17270$c1d45750$@gmail.com> <20170404135325.7bfc087f@Draco>
Message-ID: <CAF8bMcZzT3aKgFy7Nw_Vxrq9RAixrZB7TDbfc+c0mxGsMAHbkQ@mail.gmail.com>

Does R work if started with the --vanilla flag?
(Add it after ...\Rgui.exe in the Target line of
the Windows shortcut or on the command line.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Apr 4, 2017 at 1:53 PM, John <jwd at surewest.net> wrote:
> On Mon, 3 Apr 2017 18:06:06 +0100
> "Vineet Gupta" <vineetgupta410 at gmail.com> wrote:
>
>> John,
>>
>> R does not work properly, outside of RStudio.
>>
>> Vineet
>>
> That is what I thought you might be saying.  Does it work outside
> if RStudio is not loaded?  Windows can occasionally be flaky
> about multiple instances of a single program.
>
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Apr  4 23:39:19 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 04 Apr 2017 14:39:19 -0700
Subject: [R] R hangs on startup
In-Reply-To: <20170404135325.7bfc087f@Draco>
References: <AM5P18901MB01462C7786BE7B13522D2359D3090@AM5P18901MB0146.EURP189.PROD.OUTLOOK.COM>
 <01F0A99C-717B-44C2-8007-984F5D8608F7@comcast.net>
 <012201d2ac5e$6af35180$40d9f480$@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8366247D3@FHSDB2D11-2.csu.mcmaster.ca>
 <019b01d2ac9c$95f17270$c1d45750$@gmail.com> <20170404135325.7bfc087f@Draco>
Message-ID: <3BC7A6F4-DF80-42A9-ADED-E428D0EB1CD0@dcn.davis.ca.us>

> Windows can occasionally be flaky
> about multiple instances of a single
> program. 

John... I run multiple instances of R and RStudio on Win7 regularly. About the only poor behaviour I encounter has to do with updating packages used by those other instances.

However, I would never run R as Administrator under Windows. Too many bad things can happen if you do that. 

Vineet... please be specific about what command line you are using that leads to trouble. Look in the shortcut properties to figure this out if that is how you are starting it. Using the command line directly will let you try out different options such as --vanilla more easily. You may also need to look at your PATH environment variable (Sys.getenv("PATH")) to make sure of which version you are invoking. 
-- 
Sent from my phone. Please excuse my brevity.

On April 4, 2017 1:53:25 PM PDT, John <jwd at surewest.net> wrote:
>On Mon, 3 Apr 2017 18:06:06 +0100
>"Vineet Gupta" <vineetgupta410 at gmail.com> wrote:
>
>> John,
>> 
>> R does not work properly, outside of RStudio.
>> 
>> Vineet
>> 
>That is what I thought you might be saying.  Does it work outside
>if RStudio is not loaded?  Windows can occasionally be flaky
>about multiple instances of a single program. 
>
>John
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Wed Apr  5 04:47:25 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Tue, 4 Apr 2017 19:47:25 -0700
Subject: [R] differential use of R version
Message-ID: <CA+JEM01GUopS1VOXYawJJBxUT2eb-_BWkxmPLKx8twg67eZr1g@mail.gmail.com>

Dear all,

please could you advise me on the following :

on a server, in a folder "x86_64-redhat-linux-gnu-library", i have 2
versions of R (below), with the corresponding BioC libraries :

> 3.2
> 3.3

how could i preferentially use an R version or the other (with the related
BioC libraries) ?

thank you,

-- bogdan

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Wed Apr  5 11:56:46 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Wed, 5 Apr 2017 02:56:46 -0700
Subject: [R] differential use of R version
In-Reply-To: <58E4BE75.4030404@sapo.pt>
References: <CA+JEM01GUopS1VOXYawJJBxUT2eb-_BWkxmPLKx8twg67eZr1g@mail.gmail.com>
 <58E4BE75.4030404@sapo.pt>
Message-ID: <CA+JEM00LGcq-a7o5gm3pKt6h9n4Tiy+-CDFJmOpjzFjqAh2rxQ@mail.gmail.com>

Thank you Rui. I have been using a package (TitanCNA) in BioC on an older
version of R (3.3.1);
now after switching to R3.3.3, I am getting an error (below), and I do not
know how to fix it. Any suggestions are welcome.

Error in `[<-.data.frame`(`*tmp*`, indRef, "refCount", value = NULL) :
  replacement has length zero

On Wed, Apr 5, 2017 at 2:52 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Unless you have strong reasons why not, use the most recent one, R 3.3.
>
> Hope this helps,
>
> Rui barradas
>
>
> Em 05-04-2017 03:47, Bogdan Tanasa escreveu:
>
>> Dear all,
>>
>> please could you advise me on the following :
>>
>> on a server, in a folder "x86_64-redhat-linux-gnu-library", i have 2
>> versions of R (below), with the corresponding BioC libraries :
>>
>> 3.2
>>> 3.3
>>>
>>
>> how could i preferentially use an R version or the other (with the related
>> BioC libraries) ?
>>
>> thank you,
>>
>> -- bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Apr  5 12:13:35 2017
From: jholtman at gmail.com (jim holtman)
Date: Wed, 5 Apr 2017 06:13:35 -0400
Subject: [R] taking a small piece of large tiff
In-Reply-To: <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
 <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
 <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
Message-ID: <CAAxdm-6VUQ9-J5tOxDUBmfPd02eyv81ByF=8SMfF0hBAD1fm1Q@mail.gmail.com>

if you have 8GB of memory it should be easy to handle.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Apr 5, 2017 at 3:23 AM, Louisa Reynolds
<louisa_reynolds at yahoo.co.uk> wrote:
> Ok. I have a tiff of size over 2GB. It covers a sixth of the Earth's surface and I'm trying to cut a UK piece out of it. The tiff I start with seems to be too large for R to handle.
>
>
> Sent from my iPhone
>
>> On 4 Apr 2017, at 18:37, jim holtman <jholtman at gmail.com> wrote:
>>
>> How big is 'large'?
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
>> <r-help at r-project.org> wrote:
>>> Dear Forum
>>> I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files.  I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
>>> Thanks in advance.
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From tungakantarci at gmail.com  Wed Apr  5 15:00:20 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 5 Apr 2017 15:00:20 +0200
Subject: [R] Yield to maturity calculation - bndyield equivalent of MATLAB
	in R
Message-ID: <CAMDpC=stAifFRVzQaysP19wZgqK=VkhZOdPqjM3SwyQD9zk9NQ@mail.gmail.com>

I have the MATLAB code pasted below that calculates yields to maturity.

IRR = zeros(length(c),length(M))

The ith row and jth column is the price of the bond with coupon c(i)
and maturity M(j).

for i = 1:3
    for j = 1:3
        if j == 1
            IRR(i,j) =
bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2026');
        elseif j == 2
            IRR(i,j) =
bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2036');
        elseif j == 3
            IRR(i,j) =
bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2046');
        end
    end
end;

mPricecon represents the prices calculated from zero coupon bond
prices, and c_org represents the coupon payments. This then gives IRR.

I need to convert this MATLAB code to R code, and ideally one to one.
The problem is that bndyield is a MATLAB function and there does not
seem be an exact equivalent in R. What is the best way to go?


From marc_schwartz at me.com  Wed Apr  5 15:52:53 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Apr 2017 08:52:53 -0500
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
In-Reply-To: <CAMDpC=stAifFRVzQaysP19wZgqK=VkhZOdPqjM3SwyQD9zk9NQ@mail.gmail.com>
References: <CAMDpC=stAifFRVzQaysP19wZgqK=VkhZOdPqjM3SwyQD9zk9NQ@mail.gmail.com>
Message-ID: <BA89BE5C-5616-4871-9BE0-663132CF6A41@me.com>


> On Apr 5, 2017, at 8:00 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> I have the MATLAB code pasted below that calculates yields to maturity.
> 
> IRR = zeros(length(c),length(M))
> 
> The ith row and jth column is the price of the bond with coupon c(i)
> and maturity M(j).
> 
> for i = 1:3
>    for j = 1:3
>        if j == 1
>            IRR(i,j) =
> bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2026');
>        elseif j == 2
>            IRR(i,j) =
> bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2036');
>        elseif j == 3
>            IRR(i,j) =
> bndyield(mPricecon(i,j),c_org(i),'07-Apr-2016','07-Apr-2046');
>        end
>    end
> end;
> 
> mPricecon represents the prices calculated from zero coupon bond
> prices, and c_org represents the coupon payments. This then gives IRR.
> 
> I need to convert this MATLAB code to R code, and ideally one to one.
> The problem is that bndyield is a MATLAB function and there does not
> seem be an exact equivalent in R. What is the best way to go?


Hi,

First, from a high-level view, you rarely want to convert code from another language to R on a one-to-one or line by line basis. R's underlying philosophy is to take a whole object approach to solving problems by using vectorized code, rather than loops, much less nested loops, albeit, sometimes there are exceptions.

An initial step would be to use Google or rseek.org <http://rseek.org/>, the latter being a dedicated R search resource, where you can use keywords such as " R Yield to Maturity" to identify possible solutions, CRAN packages that may make sense and prior discussions in the list archives.

I am not in finance, so would defer to others with specific knowledge in the domain, but another resource would be CRAN Task Views:

  https://cran.r-project.org/web/views/ <https://cran.r-project.org/web/views/>

where there are Econometrics and Finance views that have focused resources with links to CRAN packages that may be relevant (more so the latter view). From the latter view, the fBonds package on CRAN seems to be possibly relevant:

  https://cran.r-project.org/web/packages/fBonds/index.html <https://cran.r-project.org/web/packages/fBonds/index.html>

as does the jrvFinance package:

  https://cran.r-project.org/web/packages/jrvFinance/

with some others having 'yield' as keyword in their descriptions.

Also, there are a number of domain specific R e-mail lists, including one for Finance:

  https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>

and you would avail yourself of a focused audience in the domain using that list, as opposed to R-Help for these types of questions.

Hopefully this will get you moving forward.

Regards,

Marc Schwartz


	[[alternative HTML version deleted]]


From samantha.fundetta at gmail.com  Tue Apr  4 21:14:57 2017
From: samantha.fundetta at gmail.com (davide f)
Date: Tue, 4 Apr 2017 21:14:57 +0200
Subject: [R] help with package ranks
Message-ID: <CA+CquxFdxCvyMc-2Yh-fqo_sd3MyaH0WS6H-icV7_JtWatR6XA@mail.gmail.com>

Hello, I'm Davide.
I'm using the package RANKS, in particular the functions do.GBA, do.RW,
do.RANKS. To the funcs are given 2 different Matrix. One is a a simmetryc
adjacency Matrix(called "M"), where rows and columns are protein, and the
other is an annotation Matrix(called "ann"), where protein are rows(the
same of the first Matrix) and and the annotations are columns.

I write a script in order to filter both the matrices, choosing only
protein with 5 or more annotations.

To be more specific, using the functions, data=M, labels=ann.

But, running the script, it gives me an error message about the functions
of interest:

Error in apply(W[, ind.positives], 1, sum) :
  dim(X) deve avere lunghezza positiva


In paritcular it gives me the error during the FOR cycle, when it
works on the 6th column.


How can I resolve it? what is the reason?


Thank you in advance, best regards,

Davide.

	[[alternative HTML version deleted]]


From ruchikasalwan80 at gmail.com  Wed Apr  5 06:28:32 2017
From: ruchikasalwan80 at gmail.com (Ruchika Salwan)
Date: Wed, 5 Apr 2017 09:58:32 +0530
Subject: [R] Package Query
Message-ID: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>

Hey,

Is there any package in R that handles graph decomposition? A package
created specifically for flat/hierarchical decomposition of graphs.

Thanks,

	[[alternative HTML version deleted]]


From louisa_reynolds at yahoo.co.uk  Wed Apr  5 09:23:51 2017
From: louisa_reynolds at yahoo.co.uk (Louisa Reynolds)
Date: Wed, 5 Apr 2017 08:23:51 +0100
Subject: [R] taking a small piece of large tiff
In-Reply-To: <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
 <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
Message-ID: <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>

Ok. I have a tiff of size over 2GB. It covers a sixth of the Earth's surface and I'm trying to cut a UK piece out of it. The tiff I start with seems to be too large for R to handle. 


Sent from my iPhone

> On 4 Apr 2017, at 18:37, jim holtman <jholtman at gmail.com> wrote:
> 
> How big is 'large'?
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
> <r-help at r-project.org> wrote:
>> Dear Forum
>> I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files.  I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
>> Thanks in advance.
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Apr  5 11:52:53 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 05 Apr 2017 10:52:53 +0100
Subject: [R] differential use of R version
In-Reply-To: <CA+JEM01GUopS1VOXYawJJBxUT2eb-_BWkxmPLKx8twg67eZr1g@mail.gmail.com>
References: <CA+JEM01GUopS1VOXYawJJBxUT2eb-_BWkxmPLKx8twg67eZr1g@mail.gmail.com>
Message-ID: <58E4BE75.4030404@sapo.pt>

Hello,

Unless you have strong reasons why not, use the most recent one, R 3.3.

Hope this helps,

Rui barradas

Em 05-04-2017 03:47, Bogdan Tanasa escreveu:
> Dear all,
>
> please could you advise me on the following :
>
> on a server, in a folder "x86_64-redhat-linux-gnu-library", i have 2
> versions of R (below), with the corresponding BioC libraries :
>
>> 3.2
>> 3.3
>
> how could i preferentially use an R version or the other (with the related
> BioC libraries) ?
>
> thank you,
>
> -- bogdan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Apr  5 17:07:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Apr 2017 08:07:33 -0700
Subject: [R] Package Query
In-Reply-To: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
References: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
Message-ID: <CAGxFJbTNTxV-WPihcMWRx_-RTfcNt7XSMBGJV7sAR-QG00y1pA@mail.gmail.com>

On the rseek.org   search site,

"graph decomposition"

brought up what looked like some relevant hits. So search there if you
haven't done so already.

-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 4, 2017 at 9:28 PM, Ruchika Salwan
<ruchikasalwan80 at gmail.com> wrote:
> Hey,
>
> Is there any package in R that handles graph decomposition? A package
> created specifically for flat/hierarchical decomposition of graphs.
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Apr  5 17:08:14 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 05 Apr 2017 08:08:14 -0700
Subject: [R] Package Query
In-Reply-To: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
References: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
Message-ID: <43B71B25-D1D4-4F9A-8F3B-8793A694169B@dcn.davis.ca.us>

There is a package called sos that helps you answer such questions yourself. There are also Task View pages on CRAN that help you identify useful packages. 
-- 
Sent from my phone. Please excuse my brevity.

On April 4, 2017 9:28:32 PM PDT, Ruchika Salwan <ruchikasalwan80 at gmail.com> wrote:
>Hey,
>
>Is there any package in R that handles graph decomposition? A package
>created specifically for flat/hierarchical decomposition of graphs.
>
>Thanks,
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Wed Apr  5 17:08:48 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 5 Apr 2017 11:08:48 -0400
Subject: [R] taking a small piece of large tiff
In-Reply-To: <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
 <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
 <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
Message-ID: <825F1164-0DC9-4A27-9FE7-4737ECDE98D7@bigelow.org>

Hi,

You'll get a lot of help if you take this question to the R-sig-geo list 

https://stat.ethz.ch/mailman/listinfo/r-sig-geo

In the meantime, you might want to try reading this using raster::raster() and then cropping to your desired region. Here's a discussion that may help you...

https://stat.ethz.ch/pipermail/r-sig-geo/2010-July/008838.html

You will find many other useful bits using Rseek.org - try http://rseek.org/?q=subset+large+geotif

Cheers,
Ben

> On Apr 5, 2017, at 3:23 AM, Louisa Reynolds via R-help <r-help at r-project.org> wrote:
> 
> Ok. I have a tiff of size over 2GB. It covers a sixth of the Earth's surface and I'm trying to cut a UK piece out of it. The tiff I start with seems to be too large for R to handle. 
> 
> 
> Sent from my iPhone
> 
>> On 4 Apr 2017, at 18:37, jim holtman <jholtman at gmail.com> wrote:
>> 
>> How big is 'large'?
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> 
>> On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
>> <r-help at r-project.org> wrote:
>>> Dear Forum
>>> I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files.  I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
>>> Thanks in advance.
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From sebastien.moretti at unil.ch  Wed Apr  5 17:21:24 2017
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Wed, 5 Apr 2017 17:21:24 +0200
Subject: [R] as.POSIXct character string is not in a standard unambiguous
	format
Message-ID: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>

Hi

I have lots of issues when I try to install R 3.3.3 during the "make 
check" step.

Every time a call to as.POSIXct is done in test scripts, I got the same 
error message:
e.g. x <- as.POSIXct("2002-02-02 02:02")
Error in as.POSIXlt.character(x, tz, ...) :
   character string is not in a standard unambiguous format


It looks to be linked to localtime but when I compiled R 3.3.2  6 months 
ago, the same test scripts were there and succeeded.


Is there an environmental variable to use to change the as.POSIXct behavior?

Regards

--
S?bastien


From zadig_1 at excite.com  Wed Apr  5 17:26:12 2017
From: zadig_1 at excite.com (ce)
Date: Wed, 05 Apr 2017 11:26:12 -0400
Subject: [R] differential use of R version
Message-ID: <20170405112612.4696@web006.roc2.bluetie.com>


Maybe you can use .libPaths to choose a different library

.libPaths("/myhome/Documents/R/R-3.0.2/library")

Or /usr/bin/R command in linux is a shell script, you can edit some paths and make it work. ( I haven't tried it though) 


-----Original Message-----
From: "Bogdan Tanasa" [tanasa at gmail.com]
Date: 04/04/2017 10:47 PM
To: "r-help" <r-help at r-project.org>
Subject: [R] differential use of R version

Dear all,

please could you advise me on the following :

on a server, in a folder "x86_64-redhat-linux-gnu-library", i have 2
versions of R (below), with the corresponding BioC libraries :

> 3.2
> 3.3

how could i preferentially use an R version or the other (with the related
BioC libraries) ?

thank you,

-- bogdan

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Wed Apr  5 17:30:20 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 05 Apr 2017 15:30:20 +0000
Subject: [R] taking a small piece of large tiff
In-Reply-To: <CAAxdm-6VUQ9-J5tOxDUBmfPd02eyv81ByF=8SMfF0hBAD1fm1Q@mail.gmail.com>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
 <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
 <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
 <CAAxdm-6VUQ9-J5tOxDUBmfPd02eyv81ByF=8SMfF0hBAD1fm1Q@mail.gmail.com>
Message-ID: <CAAcGz998gcPHUcSOqsV3rB3MM0T5OJ1NLhqVyeArTuF3k5tggg@mail.gmail.com>

On Wed, 5 Apr 2017 at 20:13 jim holtman <jholtman at gmail.com> wrote:

> if you have 8GB of memory it should be easy to handle.
>
>
>
TIFF is a container format and may be compressed internally, and so could
expand out  as a matrix it might be very many times larger than the file
size implies.

(Follow Ben's advice and use raster, which in turn uses rgdal to read
TIFF/GeoTIFF. It's ridiculously good).


Something like

library(raster)
r <- raster("/path/to/myfile.tif")
print(r)  ## to see the units of the extent

## enter the singleton-values for xmin/xmax/ymin/ymax that you want here:
b <- crop(r, extent(xmin, xmax, ymin, ymax))

Note that the extent values must be in the coordinate system used by the
raster itself, it might be in longitude-latitude or in some
"eastings-northings" map projection (CRS, or coordinate reference system).
The print out of print(r) will tell you, and projection(r) if you need to
use it directly.

There's no need to do your own transformations from world-space to pixel
index space. but the price of that convenience is you have to interact with
the data via the raster package's design and interfaces. You can get a
matrix out but it's well worth learning the higher level abstractions
available as well.


Cheers, Mike.



> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Wed, Apr 5, 2017 at 3:23 AM, Louisa Reynolds
> <louisa_reynolds at yahoo.co.uk> wrote:
> > Ok. I have a tiff of size over 2GB. It covers a sixth of the Earth's
> surface and I'm trying to cut a UK piece out of it. The tiff I start with
> seems to be too large for R to handle.
> >
> >
> > Sent from my iPhone
> >
> >> On 4 Apr 2017, at 18:37, jim holtman <jholtman at gmail.com> wrote:
> >>
> >> How big is 'large'?
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >>
> >> On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
> >> <r-help at r-project.org> wrote:
> >>> Dear Forum
> >>> I am trying to cut out a small section of a very large 2-dimensional
> grayscale image as a tiff in R, but it is having difficulty handling such
> large files.  I have looked at bigmemory and ff packages but it is unclear
> how I can use these packages with tiffs. Can anyone please suggest
> something? I have tried tiff and rtiff libraries.
> >>> Thanks in advance.
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tungakantarci at gmail.com  Wed Apr  5 18:34:09 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 5 Apr 2017 18:34:09 +0200
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
Message-ID: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>

Thanks a lot Marc, for informing that R is object oriented, implying
that one should always try to vectorise the code (although I am not so
clear why this should be the case) but also for all the references you
provide.


From tungakantarci at gmail.com  Wed Apr  5 18:41:39 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 5 Apr 2017 18:41:39 +0200
Subject: [R] Replying to replies in the forum
Message-ID: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>

OK I cannot figure this out clearly in the guidelines of posting. When
I reply to a message I should out "Re:" in front of the subject line
of the original post. So if the subject line of the original post it
is "this is a post", then I should use "Re: this is a post" in the
subject line, for my reply to appear under the original post, and not
in the forum as a new message.

But then I cannot figure out what subject line I should use to reply
to a given reply. That is, suppose the original subject line is "this
is a post" and there are replies under the post, and that I want to
reply to one of the replies. How I specify in the subject line so that
my reply appears under the reply of a certain person? Or do I have to
use the reply features of gmail?

Meanwhile, why the guidelines is implicit about this?


From marc_schwartz at me.com  Wed Apr  5 19:28:59 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Apr 2017 12:28:59 -0500
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
In-Reply-To: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>
References: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>
Message-ID: <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>


> On Apr 5, 2017, at 11:34 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> Thanks a lot Marc, for informing that R is object oriented, implying
> that one should always try to vectorise the code (although I am not so
> clear why this should be the case) but also for all the references you
> provide.



Hi,

The reason for taking an object oriented approach using vectorized code, is that frequently, the R code that you write is internally calling compiled C code to perform the actual iterations over the object structure. Thus, being that compiled C code is much faster than interpreted R code, there is significant efficiency to be achieved by taking an object oriented approach to key operations. 

In addition, when used, a single line of vectorized code and/or a vectorized function can replace multiple lines of code in a different language. Thus, from a coding efficiency and readability standpoint, it is far more efficient.

Regards,

Marc


From bgunter.4567 at gmail.com  Wed Apr  5 19:43:17 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Apr 2017 10:43:17 -0700
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
In-Reply-To: <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>
References: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>
 <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>
Message-ID: <CAGxFJbSKSGEZb2DTAz6X_ph1A17mRGFkFP6F-RPeyFivSmOtNg@mail.gmail.com>

... Probably need to distinguish "whole object approach" from "object
oriented" approach. They are different and almost orthogonal in R. R
tutorials discuss such matters, and there are many good ones on the
Web, including the "Intro to R" tutorial that ships with R. The OP
should spend some time with one or more to learn more about this. This
list cannot provide such extended explanation.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 5, 2017 at 10:28 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Apr 5, 2017, at 11:34 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
>>
>> Thanks a lot Marc, for informing that R is object oriented, implying
>> that one should always try to vectorise the code (although I am not so
>> clear why this should be the case) but also for all the references you
>> provide.
>
>
>
> Hi,
>
> The reason for taking an object oriented approach using vectorized code, is that frequently, the R code that you write is internally calling compiled C code to perform the actual iterations over the object structure. Thus, being that compiled C code is much faster than interpreted R code, there is significant efficiency to be achieved by taking an object oriented approach to key operations.
>
> In addition, when used, a single line of vectorized code and/or a vectorized function can replace multiple lines of code in a different language. Thus, from a coding efficiency and readability standpoint, it is far more efficient.
>
> Regards,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Wed Apr  5 19:46:13 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Apr 2017 12:46:13 -0500
Subject: [R] Replying to replies in the forum
In-Reply-To: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
References: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
Message-ID: <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>


> On Apr 5, 2017, at 11:41 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> OK I cannot figure this out clearly in the guidelines of posting. When
> I reply to a message I should out "Re:" in front of the subject line
> of the original post. So if the subject line of the original post it
> is "this is a post", then I should use "Re: this is a post" in the
> subject line, for my reply to appear under the original post, and not
> in the forum as a new message.
> 
> But then I cannot figure out what subject line I should use to reply
> to a given reply. That is, suppose the original subject line is "this
> is a post" and there are replies under the post, and that I want to
> reply to one of the replies. How I specify in the subject line so that
> my reply appears under the reply of a certain person? Or do I have to
> use the reply features of gmail?
> 
> Meanwhile, why the guidelines is implicit about this?

Hi,

There is an R Posting Guide here:

  https://www.r-project.org/posting-guide.html

which is a good place to start.

Generally, if you want to reply to a post and keep the thread intact, always use "reply-all" and that will keep thread participants copied, the post sent to all list subscribers, and the posts in the public archives for future use. 

Most e-mail clients (stand alone or web based) will add the "re:" prefix automatically, if not already present.

Threads are not kept intact in the list archives based upon the subject line alone, even though some e-mail clients may do so. This is why there can be a change in the subject line when using reply-all and the reply post will be kept with the original thread.

If, on the other hand, you create a new e-mail and just use "re: the original subject line" in the subject, that will start a new thread in the archive.

Don't use "reply" only to a post, unless specifically asked, as that will only copy one person, not the list nor the archives, and the communication will only be between you and that person, which is frowned upon.

Regards,

Marc


From marc_schwartz at me.com  Wed Apr  5 19:48:38 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Apr 2017 12:48:38 -0500
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
In-Reply-To: <CAGxFJbSKSGEZb2DTAz6X_ph1A17mRGFkFP6F-RPeyFivSmOtNg@mail.gmail.com>
References: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>
 <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>
 <CAGxFJbSKSGEZb2DTAz6X_ph1A17mRGFkFP6F-RPeyFivSmOtNg@mail.gmail.com>
Message-ID: <0ED3A6A9-B003-4D59-814D-EBA03643C273@me.com>

Bert,

Good distinction...

For clarification, I was referring to the "whole object approach" versus an "object oriented" approach.

Regards,

Marc


> On Apr 5, 2017, at 12:43 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... Probably need to distinguish "whole object approach" from "object
> oriented" approach. They are different and almost orthogonal in R. R
> tutorials discuss such matters, and there are many good ones on the
> Web, including the "Intro to R" tutorial that ships with R. The OP
> should spend some time with one or more to learn more about this. This
> list cannot provide such extended explanation.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Apr 5, 2017 at 10:28 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>>> On Apr 5, 2017, at 11:34 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
>>> 
>>> Thanks a lot Marc, for informing that R is object oriented, implying
>>> that one should always try to vectorise the code (although I am not so
>>> clear why this should be the case) but also for all the references you
>>> provide.
>> 
>> 
>> 
>> Hi,
>> 
>> The reason for taking an object oriented approach using vectorized code, is that frequently, the R code that you write is internally calling compiled C code to perform the actual iterations over the object structure. Thus, being that compiled C code is much faster than interpreted R code, there is significant efficiency to be achieved by taking an object oriented approach to key operations.
>> 
>> In addition, when used, a single line of vectorized code and/or a vectorized function can replace multiple lines of code in a different language. Thus, from a coding efficiency and readability standpoint, it is far more efficient.
>> 
>> Regards,
>> 
>> Marc
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From tungakantarci at gmail.com  Wed Apr  5 20:26:27 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 5 Apr 2017 20:26:27 +0200
Subject: [R] Replying to replies in the forum
In-Reply-To: <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>
References: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
 <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>
Message-ID: <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>

My question is specifically about what I should use in the subject
line when replying, because I do not trust mail clients, or to myself
as I use different clients sometimes. Hence, I wanted to learn a
client free solution to correctly send replies. Now, the posting guide
is not explicit about this. Hence my question. So what should I type
in the subject line if I want to reply to a specific reply, and not to
another reply, so that my reply is nested in the reply I want to
reply. That I cannot figure out from the posting guide.

On Wed, Apr 5, 2017 at 7:46 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Apr 5, 2017, at 11:41 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
>>
>> OK I cannot figure this out clearly in the guidelines of posting. When
>> I reply to a message I should out "Re:" in front of the subject line
>> of the original post. So if the subject line of the original post it
>> is "this is a post", then I should use "Re: this is a post" in the
>> subject line, for my reply to appear under the original post, and not
>> in the forum as a new message.
>>
>> But then I cannot figure out what subject line I should use to reply
>> to a given reply. That is, suppose the original subject line is "this
>> is a post" and there are replies under the post, and that I want to
>> reply to one of the replies. How I specify in the subject line so that
>> my reply appears under the reply of a certain person? Or do I have to
>> use the reply features of gmail?
>>
>> Meanwhile, why the guidelines is implicit about this?
>
> Hi,
>
> There is an R Posting Guide here:
>
>   https://www.r-project.org/posting-guide.html
>
> which is a good place to start.
>
> Generally, if you want to reply to a post and keep the thread intact, always use "reply-all" and that will keep thread participants copied, the post sent to all list subscribers, and the posts in the public archives for future use.
>
> Most e-mail clients (stand alone or web based) will add the "re:" prefix automatically, if not already present.
>
> Threads are not kept intact in the list archives based upon the subject line alone, even though some e-mail clients may do so. This is why there can be a change in the subject line when using reply-all and the reply post will be kept with the original thread.
>
> If, on the other hand, you create a new e-mail and just use "re: the original subject line" in the subject, that will start a new thread in the archive.
>
> Don't use "reply" only to a post, unless specifically asked, as that will only copy one person, not the list nor the archives, and the communication will only be between you and that person, which is frowned upon.
>
> Regards,
>
> Marc
>


From tungakantarci at gmail.com  Wed Apr  5 20:38:30 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 5 Apr 2017 20:38:30 +0200
Subject: [R] Yield to maturity calculation - bndyield equivalent of
 MATLAB in R
In-Reply-To: <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>
References: <CAMDpC=usOdUqHZ=D4byDanWFNZGAekrE4QGnoKtyMCR3L7vPqA@mail.gmail.com>
 <DC36A063-400A-47F4-B0B7-74E7323037E5@me.com>
Message-ID: <CAMDpC=vwNe2PeKfsPh7dabKKzS4xSUwLrDuvTy4tJVyDCkmPrw@mail.gmail.com>

OK this confused me. I thought object oriented coding should be
preferred because it allows cleaner, more efficient coding. But your
reply suggests it should be preferred because "R" is more efficient in
that way. Anyhow, this thread should indeed not become a discussion
point for this and I should read about it.


On Wed, Apr 5, 2017 at 7:28 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Apr 5, 2017, at 11:34 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
>>
>> Thanks a lot Marc, for informing that R is object oriented, implying
>> that one should always try to vectorise the code (although I am not so
>> clear why this should be the case) but also for all the references you
>> provide.
>
>
>
> Hi,
>
> The reason for taking an object oriented approach using vectorized code, is that frequently, the R code that you write is internally calling compiled C code to perform the actual iterations over the object structure. Thus, being that compiled C code is much faster than interpreted R code, there is significant efficiency to be achieved by taking an object oriented approach to key operations.
>
> In addition, when used, a single line of vectorized code and/or a vectorized function can replace multiple lines of code in a different language. Thus, from a coding efficiency and readability standpoint, it is far more efficient.
>
> Regards,
>
> Marc
>


From santosh2005 at gmail.com  Wed Apr  5 20:50:02 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 5 Apr 2017 11:50:02 -0700
Subject: [R] ggplot2 question plot mean/error bars
Message-ID: <CAN_e6XsjYGPt9szry7cDtdsDCAGJG=LgzQ6b3=kAw2c+-Xop_Q@mail.gmail.com>

Hello Rxperts..
I am trying to generate a mean+/- error plot.. using ggplot2.. with filled
black and white circles and black lines, but no overlap  of lines and
circles (symbols). Also, with no top and right lines of the plot box. I
remember having done this before.. unable to reproduce how I did!

Yes, there are many ways of generating the plot.. Would high appreciate it
if you could help debug this piece of code.

Attaching sample code for your convenience..
Best,
Santosh

q <-
 data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(seq(10),15),b=round(runif(150,10,20)))
q$r <- q$b*0.1
q2 <- q[order(q$G,q$D,q$a,q$t),]

  q3 <-
as.data.frame(as.matrix(with(q2,aggregate(list(b=b),list(D=D,t=t),function(x)
c(mean=mean(x),sd=sd(x),se=(sd(x)/sqrt(length(x))))))),stringsAsFactors=F)
  q3$t <- as.numeric(q3$t)
  q3$b.mean <- as.numeric(q3$b.mean)
  q3$b.sd <- as.numeric(q3$b.sd)
  q3$b.se <- as.numeric(q3$b.se)

ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,fill=D,col=D,group=D))
+     geom_point(shape=21,size=4) +
    geom_line() +
geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
    scale_shape_manual(values = c(16,21)) +
    scale_fill_manual(values=c("black","white")) +
    scale_color_manual(values=c("black","black")) +
    +legend.position = c(.8,.8))

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Apr  5 22:23:38 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 05 Apr 2017 13:23:38 -0700
Subject: [R] Replying to replies in the forum
In-Reply-To: <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>
References: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
 <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>
 <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>
Message-ID: <3A50481F-FF7E-402C-BD5D-AC12477BD5B8@dcn.davis.ca.us>

There is no conclusively client-free solution, which is why it is not in the Posting Guide. 

However, as a general rule, start with a fresh email to start a thread, and reply-to-all to the message you want to reply to.  The threading is managed by hidden message ids, not subjects. 
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2017 11:26:27 AM PDT, "Tunga Kantarc?" <tungakantarci at gmail.com> wrote:
>My question is specifically about what I should use in the subject
>line when replying, because I do not trust mail clients, or to myself
>as I use different clients sometimes. Hence, I wanted to learn a
>client free solution to correctly send replies. Now, the posting guide
>is not explicit about this. Hence my question. So what should I type
>in the subject line if I want to reply to a specific reply, and not to
>another reply, so that my reply is nested in the reply I want to
>reply. That I cannot figure out from the posting guide.
>
>On Wed, Apr 5, 2017 at 7:46 PM, Marc Schwartz <marc_schwartz at me.com>
>wrote:
>>
>>> On Apr 5, 2017, at 11:41 AM, Tunga Kantarc?
><tungakantarci at gmail.com> wrote:
>>>
>>> OK I cannot figure this out clearly in the guidelines of posting.
>When
>>> I reply to a message I should out "Re:" in front of the subject line
>>> of the original post. So if the subject line of the original post it
>>> is "this is a post", then I should use "Re: this is a post" in the
>>> subject line, for my reply to appear under the original post, and
>not
>>> in the forum as a new message.
>>>
>>> But then I cannot figure out what subject line I should use to reply
>>> to a given reply. That is, suppose the original subject line is
>"this
>>> is a post" and there are replies under the post, and that I want to
>>> reply to one of the replies. How I specify in the subject line so
>that
>>> my reply appears under the reply of a certain person? Or do I have
>to
>>> use the reply features of gmail?
>>>
>>> Meanwhile, why the guidelines is implicit about this?
>>
>> Hi,
>>
>> There is an R Posting Guide here:
>>
>>   https://www.r-project.org/posting-guide.html
>>
>> which is a good place to start.
>>
>> Generally, if you want to reply to a post and keep the thread intact,
>always use "reply-all" and that will keep thread participants copied,
>the post sent to all list subscribers, and the posts in the public
>archives for future use.
>>
>> Most e-mail clients (stand alone or web based) will add the "re:"
>prefix automatically, if not already present.
>>
>> Threads are not kept intact in the list archives based upon the
>subject line alone, even though some e-mail clients may do so. This is
>why there can be a change in the subject line when using reply-all and
>the reply post will be kept with the original thread.
>>
>> If, on the other hand, you create a new e-mail and just use "re: the
>original subject line" in the subject, that will start a new thread in
>the archive.
>>
>> Don't use "reply" only to a post, unless specifically asked, as that
>will only copy one person, not the list nor the archives, and the
>communication will only be between you and that person, which is
>frowned upon.
>>
>> Regards,
>>
>> Marc
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Wed Apr  5 22:27:53 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Apr 2017 15:27:53 -0500
Subject: [R] Replying to replies in the forum
In-Reply-To: <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>
References: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
 <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>
 <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>
Message-ID: <E72350E0-0B67-44B7-9A0A-95F763C89017@me.com>


> On Apr 5, 2017, at 1:26 PM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> My question is specifically about what I should use in the subject
> line when replying, because I do not trust mail clients, or to myself
> as I use different clients sometimes. Hence, I wanted to learn a
> client free solution to correctly send replies. Now, the posting guide
> is not explicit about this. Hence my question. So what should I type
> in the subject line if I want to reply to a specific reply, and not to
> another reply, so that my reply is nested in the reply I want to
> reply. That I cannot figure out from the posting guide.



<snip>

Hi,

Perhaps I am confused.

If you have a copy of the post that you want to reply to in any modern e-mail client (desktop or web based), you can just use reply-all. The subject line will be retained, and if not already present, which would be the case for the first post in the thread, the "Re:" prefix will be added. 

The e-mails of those participating in that particular post will also be retained, as will the list e-mail address.

Are you referring to a situation where you no longer have a copy of the post that you want to reply to in your e-mail client, so that you cannot just use reply-all to that specific post?

If so, that is a more cumbersome process...

Regards,

Marc


From btupper at bigelow.org  Wed Apr  5 22:51:00 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 5 Apr 2017 16:51:00 -0400
Subject: [R] as.POSIXct character string is not in a standard
	unambiguous format
In-Reply-To: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
Message-ID: <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>

Hi,

I can't answer the question about R 3.3.3, but I don't see anything in the update notes. 

http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html

In the meantime, would it skirt your issue if you explicitly stated the format?

x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")

Ben



> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
> 
> Hi
> 
> I have lots of issues when I try to install R 3.3.3 during the "make check" step.
> 
> Every time a call to as.POSIXct is done in test scripts, I got the same error message:
> e.g. x <- as.POSIXct("2002-02-02 02:02")
> Error in as.POSIXlt.character(x, tz, ...) :
>  character string is not in a standard unambiguous format
> 
> 
> It looks to be linked to localtime but when I compiled R 3.3.2  6 months ago, the same test scripts were there and succeeded.
> 
> 
> Is there an environmental variable to use to change the as.POSIXct behavior?
> 
> Regards
> 
> --
> S?bastien
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From santosh2005 at gmail.com  Wed Apr  5 23:05:55 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 5 Apr 2017 14:05:55 -0700
Subject: [R] ggplot2 question plot mean/error bars
In-Reply-To: <CAN_e6XsjYGPt9szry7cDtdsDCAGJG=LgzQ6b3=kAw2c+-Xop_Q@mail.gmail.com>
References: <CAN_e6XsjYGPt9szry7cDtdsDCAGJG=LgzQ6b3=kAw2c+-Xop_Q@mail.gmail.com>
Message-ID: <CAN_e6Xs0dDdxqkXBLhLxQ99MAL49J0y8fDk2NHNSeAJMqR4w4w@mail.gmail.com>

Dear Rxperts..
Here is the updated code.. to the above example.. how do I make the white
circles as "white filled" so that lines in the circles are not shown.?

Thanks and much appreciated....
Santosh

q <-  data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(
paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(
seq(10),15),b=round(runif(150,10,20)))
q$r <- q$b*0.1
q2 <- q[order(q$G,q$D,q$a,q$t),]

  q3 <- as.data.frame(as.matrix(with(q2,aggregate(list(b=b),list(D=D,t=t),function(x)
c(mean=mean(x),sd=sd(x),se=(sd(x)/sqrt(length(x))))))),stringsAsFactors=F)
  q3$t <- as.numeric(q3$t)
  q3$b.mean <- as.numeric(q3$b.mean)
  q3$b.sd <- as.numeric(q3$b.sd)
  q3$b.se <- as.numeric(q3$b.se)

ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,group=D,col=D,fill=D))
+  geom_point(shape=21,size=4) + #,color=IP))
  geom_line() +
  # geom_point(data=ipthd.f[ipthd.f$IP=="Cinacalcet",],fill='white')+
  geom_errorbar(width=.2,aes(ymin=b.mean-b.se,ymax=b.mean+b.se)) +
  scale_shape_manual(values = c(16,21)) +
  # scale_shape(solid = T)+
  # scale_shape_identity() +
  # scale_shape_discrete(solid = T) +
   scale_fill_manual(values=c("black","white")) +
   scale_color_manual(values=c("black","black"))

On Wed, Apr 5, 2017 at 11:50 AM, Santosh <santosh2005 at gmail.com> wrote:

> Hello Rxperts..
> I am trying to generate a mean+/- error plot.. using ggplot2.. with filled
> black and white circles and black lines, but no overlap  of lines and
> circles (symbols). Also, with no top and right lines of the plot box. I
> remember having done this before.. unable to reproduce how I did!
>
> Yes, there are many ways of generating the plot.. Would high appreciate it
> if you could help debug this piece of code.
>
> Attaching sample code for your convenience..
> Best,
> Santosh
>
> q <-  data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(
> paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(
> seq(10),15),b=round(runif(150,10,20)))
> q$r <- q$b*0.1
> q2 <- q[order(q$G,q$D,q$a,q$t),]
>
>   q3 <- as.data.frame(as.matrix(with(q2,aggregate(list(b=b),list(D=D,t=t),function(x)
> c(mean=mean(x),sd=sd(x),se=(sd(x)/sqrt(length(x))))))),stringsAsFactors=F)
>   q3$t <- as.numeric(q3$t)
>   q3$b.mean <- as.numeric(q3$b.mean)
>   q3$b.sd <- as.numeric(q3$b.sd)
>   q3$b.se <- as.numeric(q3$b.se)
>
> ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,fill=D,col=D,group=D))
> +     geom_point(shape=21,size=4) +
>     geom_line() +
> geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
> geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
>     scale_shape_manual(values = c(16,21)) +
>     scale_fill_manual(values=c("black","white")) +
>     scale_color_manual(values=c("black","black")) +
>     +legend.position = c(.8,.8))
>
>
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Apr  5 23:06:41 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 5 Apr 2017 21:06:41 +0000
Subject: [R] system call removes special characters from text output
In-Reply-To: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
Message-ID: <34AE9603-5EEF-469B-AE30-54B6C74D32B5@llnl.gov>

I can't reproduce this.

On my system, the contents of an executable file named tmp.pl:

#! /opt/local/bin/perl
print "[A/B]\n";

At a shell prompt:

[72]% ./tmp.pl
[A/B]

Inside R:

> system(' ./tmp.pl')
[A/B]


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 4/3/17, 8:57 PM, "R-help on behalf of stephen sefick" <r-help-bounces at r-project.org on behalf of ssefick at gmail.com> wrote:

    Hello,
    
    I am writing an R package, and I am using system() to call a perl script.
    The output of the perl script is correct except for "[A/B]" is output as
    "AB". Can someone explain this behavior. I would like to try and fix this.
    many thanks,
    
    Stephen Sefick
    
    -- 
    Let's not spend our time and resources thinking about things that are so
    little or so large that all they really do for us is puff us up and make us
    feel like gods.  We are mammals, and have not exhausted the annoying little
    problems of being mammals.
    
                                    -K. Mullis
    
    "A big computer, a complex algorithm and a long time does not equal
    science."
    
                                  -Robert Gentleman
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From br at dmstat1.com  Wed Apr  5 23:09:26 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 5 Apr 2017 17:09:26 -0400
Subject: [R] How can output tables be converted to data files?
Message-ID: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>

Hi R'ers:
This code produces: 3x3 rcorr matrix, one-element vector, and 3x3 
p-value matrix.
I would like to use these outputs as data files.
How can these output tables be converted to data files?
Any assistance is appreciated.
Thanks. Bruce

library(Hmisc)
mtcars5 <- mtcars[sample(1:nrow(mtcars), 5, replace=FALSE),]
X<- as.matrix(mtcars5[, c(1,2,3)])
print(X)
rcorr(as.matrix(X))

--


From ssefick at gmail.com  Wed Apr  5 23:20:11 2017
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 5 Apr 2017 16:20:11 -0500
Subject: [R] system call removes special characters from text output
In-Reply-To: <34AE9603-5EEF-469B-AE30-54B6C74D32B5@llnl.gov>
References: <CADKEMqhUZcUu_fGXHzkpoFiW+faNjzaNud5tBjT18wNF4c8FHw@mail.gmail.com>
 <34AE9603-5EEF-469B-AE30-54B6C74D32B5@llnl.gov>
Message-ID: <CADKEMqjK9ACuLocZ+xjfhsELJNLG+39MzruxQ=vE3NC2Z86FjA@mail.gmail.com>

Don,

Thank you for your reply. I found no problems in the perl script, but I
found that I had inadvertently swapped file names in my call to system("
script.pl file1 file2") works as expected system(script.pl file2 file1)
produces the output that formed my original query.

Thanks so much, and I learned to not code after 10 PM.
kindest regards,

Stephen

On Wed, Apr 5, 2017 at 4:06 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> I can't reproduce this.
>
> On my system, the contents of an executable file named tmp.pl:
>
> #! /opt/local/bin/perl
> print "[A/B]\n";
>
> At a shell prompt:
>
> [72]% ./tmp.pl
> [A/B]
>
> Inside R:
>
> > system(' ./tmp.pl')
> [A/B]
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
> On 4/3/17, 8:57 PM, "R-help on behalf of stephen sefick" <
> r-help-bounces at r-project.org on behalf of ssefick at gmail.com> wrote:
>
>     Hello,
>
>     I am writing an R package, and I am using system() to call a perl
> script.
>     The output of the perl script is correct except for "[A/B]" is output
> as
>     "AB". Can someone explain this behavior. I would like to try and fix
> this.
>     many thanks,
>
>     Stephen Sefick
>
>     --
>     Let's not spend our time and resources thinking about things that are
> so
>     little or so large that all they really do for us is puff us up and
> make us
>     feel like gods.  We are mammals, and have not exhausted the annoying
> little
>     problems of being mammals.
>
>                                     -K. Mullis
>
>     "A big computer, a complex algorithm and a long time does not equal
>     science."
>
>                                   -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Apr  5 23:49:10 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 5 Apr 2017 21:49:10 +0000
Subject: [R] How can output tables be converted to data files?
In-Reply-To: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>
References: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>
Message-ID: <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>

Data files is pretty vague. If you save the output of a function such as rcorr(), you can extract any of the parts you need. Step 1 is to read the documentation:

?rcorr

Under the section labeled "Value" you will see that rcorr() returns a list with 3 matrices named r, n, and P:

> Y <- rcorr(as.matrix(X))
> str(Y)
List of 3
 $ r: num [1:3, 1:3] 1 -0.934 -0.814 -0.934 1 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
 $ n: int [1:3, 1:3] 5 5 5 5 5 5 5 5 5
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
 $ P: num [1:3, 1:3] NA 0.0201 0.0937 0.0201 NA ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
 - attr(*, "class")= chr "rcorr"
> Y$r
            mpg        cyl       disp
mpg   1.0000000 -0.9341083 -0.8138289
cyl  -0.9341083  1.0000000  0.9342174
disp -0.8138289  0.9342174  1.0000000
> Y$n
     mpg cyl disp
mpg    5   5    5
cyl    5   5    5
disp   5   5    5
> Y$P
            mpg        cyl       disp
mpg          NA 0.02010207 0.09368854
cyl  0.02010207         NA 0.02005248
disp 0.09368854 0.02005248         NA

You can save the whole list with save() or write individual matrices as .csv files with write.csv().

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
Sent: Wednesday, April 5, 2017 4:09 PM
To: r-help at r-project.org
Subject: [R] How can output tables be converted to data files?

Hi R'ers:
This code produces: 3x3 rcorr matrix, one-element vector, and 3x3 
p-value matrix.
I would like to use these outputs as data files.
How can these output tables be converted to data files?
Any assistance is appreciated.
Thanks. Bruce

library(Hmisc)
mtcars5 <- mtcars[sample(1:nrow(mtcars), 5, replace=FALSE),]
X<- as.matrix(mtcars5[, c(1,2,3)])
print(X)
rcorr(as.matrix(X))

--

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Apr  6 00:06:47 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 6 Apr 2017 08:06:47 +1000
Subject: [R] help with package ranks
In-Reply-To: <CA+CquxFdxCvyMc-2Yh-fqo_sd3MyaH0WS6H-icV7_JtWatR6XA@mail.gmail.com>
References: <CA+CquxFdxCvyMc-2Yh-fqo_sd3MyaH0WS6H-icV7_JtWatR6XA@mail.gmail.com>
Message-ID: <CA+8X3fUd1v7ELH6fb70xZF1W06BiR7Auv606Nr6Tns_t9ofOSQ@mail.gmail.com>

Hi Davide,
The error message is probably due to a zero length dimension in:

W[,ind.positives]

I would look at W (data frame?) to see where this might occur. That
is, does W have a set of proteins with _no_ annotations? Perhaps
manually removing that set will get the function running.

Jim


On Wed, Apr 5, 2017 at 5:14 AM, davide f <samantha.fundetta at gmail.com> wrote:
> Hello, I'm Davide.
> I'm using the package RANKS, in particular the functions do.GBA, do.RW,
> do.RANKS. To the funcs are given 2 different Matrix. One is a a simmetryc
> adjacency Matrix(called "M"), where rows and columns are protein, and the
> other is an annotation Matrix(called "ann"), where protein are rows(the
> same of the first Matrix) and and the annotations are columns.
>
> I write a script in order to filter both the matrices, choosing only
> protein with 5 or more annotations.
>
> To be more specific, using the functions, data=M, labels=ann.
>
> But, running the script, it gives me an error message about the functions
> of interest:
>
> Error in apply(W[, ind.positives], 1, sum) :
>   dim(X) deve avere lunghezza positiva
>
>
> In paritcular it gives me the error during the FOR cycle, when it
> works on the 6th column.
>
>
> How can I resolve it? what is the reason?
>
>
> Thank you in advance, best regards,
>
> Davide.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Apr  6 00:07:17 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Wed, 5 Apr 2017 18:07:17 -0400
Subject: [R] How can output tables be converted to data files?
In-Reply-To: <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>
References: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>
 <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CD9B060B-1093-4263-BD52-92D9018B5E05@dmstat1.com>

Thanks, David. 

______________
Bruce Ratner PhD



> On Apr 5, 2017, at 5:49 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Data files is pretty vague. If you save the output of a function such as rcorr(), you can extract any of the parts you need. Step 1 is to read the documentation:
> 
> ?rcorr
> 
> Under the section labeled "Value" you will see that rcorr() returns a list with 3 matrices named r, n, and P:
> 
>> Y <- rcorr(as.matrix(X))
>> str(Y)
> List of 3
> $ r: num [1:3, 1:3] 1 -0.934 -0.814 -0.934 1 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
> $ n: int [1:3, 1:3] 5 5 5 5 5 5 5 5 5
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
> $ P: num [1:3, 1:3] NA 0.0201 0.0937 0.0201 NA ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
>  .. ..$ : chr [1:3] "mpg" "cyl" "disp"
> - attr(*, "class")= chr "rcorr"
>> Y$r
>            mpg        cyl       disp
> mpg   1.0000000 -0.9341083 -0.8138289
> cyl  -0.9341083  1.0000000  0.9342174
> disp -0.8138289  0.9342174  1.0000000
>> Y$n
>     mpg cyl disp
> mpg    5   5    5
> cyl    5   5    5
> disp   5   5    5
>> Y$P
>            mpg        cyl       disp
> mpg          NA 0.02010207 0.09368854
> cyl  0.02010207         NA 0.02005248
> disp 0.09368854 0.02005248         NA
> 
> You can save the whole list with save() or write individual matrices as .csv files with write.csv().
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Wednesday, April 5, 2017 4:09 PM
> To: r-help at r-project.org
> Subject: [R] How can output tables be converted to data files?
> 
> Hi R'ers:
> This code produces: 3x3 rcorr matrix, one-element vector, and 3x3 
> p-value matrix.
> I would like to use these outputs as data files.
> How can these output tables be converted to data files?
> Any assistance is appreciated.
> Thanks. Bruce
> 
> library(Hmisc)
> mtcars5 <- mtcars[sample(1:nrow(mtcars), 5, replace=FALSE),]
> X<- as.matrix(mtcars5[, c(1,2,3)])
> print(X)
> rcorr(as.matrix(X))
> 
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From tungakantarci at gmail.com  Thu Apr  6 00:24:35 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Thu, 6 Apr 2017 00:24:35 +0200
Subject: [R] Replying to replies in the forum
In-Reply-To: <3A50481F-FF7E-402C-BD5D-AC12477BD5B8@dcn.davis.ca.us>
References: <CAMDpC=v2PHKQ=BLSjz2Fa396naZ4U95uEVgYqqHXUXhcNeFGFQ@mail.gmail.com>
 <7A730539-D667-429B-94CB-2DCAA107AD62@me.com>
 <CAMDpC=vs_1r5iCdj_3EZmmc1WMYWKL_NniZwYPXBzG6V=MSyAw@mail.gmail.com>
 <3A50481F-FF7E-402C-BD5D-AC12477BD5B8@dcn.davis.ca.us>
Message-ID: <CAMDpC=uwiFqv81mMrmhFMT_12n6p8b68E7xzDnFUffiaz6HqMw@mail.gmail.com>

Thanks a lot.

On Wed, Apr 5, 2017 at 10:23 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> There is no conclusively client-free solution, which is why it is not in the Posting Guide.
>
> However, as a general rule, start with a fresh email to start a thread, and reply-to-all to the message you want to reply to.  The threading is managed by hidden message ids, not subjects.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 5, 2017 11:26:27 AM PDT, "Tunga Kantarc?" <tungakantarci at gmail.com> wrote:
>>My question is specifically about what I should use in the subject
>>line when replying, because I do not trust mail clients, or to myself
>>as I use different clients sometimes. Hence, I wanted to learn a
>>client free solution to correctly send replies. Now, the posting guide
>>is not explicit about this. Hence my question. So what should I type
>>in the subject line if I want to reply to a specific reply, and not to
>>another reply, so that my reply is nested in the reply I want to
>>reply. That I cannot figure out from the posting guide.
>>
>>On Wed, Apr 5, 2017 at 7:46 PM, Marc Schwartz <marc_schwartz at me.com>
>>wrote:
>>>
>>>> On Apr 5, 2017, at 11:41 AM, Tunga Kantarc?
>><tungakantarci at gmail.com> wrote:
>>>>
>>>> OK I cannot figure this out clearly in the guidelines of posting.
>>When
>>>> I reply to a message I should out "Re:" in front of the subject line
>>>> of the original post. So if the subject line of the original post it
>>>> is "this is a post", then I should use "Re: this is a post" in the
>>>> subject line, for my reply to appear under the original post, and
>>not
>>>> in the forum as a new message.
>>>>
>>>> But then I cannot figure out what subject line I should use to reply
>>>> to a given reply. That is, suppose the original subject line is
>>"this
>>>> is a post" and there are replies under the post, and that I want to
>>>> reply to one of the replies. How I specify in the subject line so
>>that
>>>> my reply appears under the reply of a certain person? Or do I have
>>to
>>>> use the reply features of gmail?
>>>>
>>>> Meanwhile, why the guidelines is implicit about this?
>>>
>>> Hi,
>>>
>>> There is an R Posting Guide here:
>>>
>>>   https://www.r-project.org/posting-guide.html
>>>
>>> which is a good place to start.
>>>
>>> Generally, if you want to reply to a post and keep the thread intact,
>>always use "reply-all" and that will keep thread participants copied,
>>the post sent to all list subscribers, and the posts in the public
>>archives for future use.
>>>
>>> Most e-mail clients (stand alone or web based) will add the "re:"
>>prefix automatically, if not already present.
>>>
>>> Threads are not kept intact in the list archives based upon the
>>subject line alone, even though some e-mail clients may do so. This is
>>why there can be a change in the subject line when using reply-all and
>>the reply post will be kept with the original thread.
>>>
>>> If, on the other hand, you create a new e-mail and just use "re: the
>>original subject line" in the subject, that will start a new thread in
>>the archive.
>>>
>>> Don't use "reply" only to a post, unless specifically asked, as that
>>will only copy one person, not the list nor the archives, and the
>>communication will only be between you and that person, which is
>>frowned upon.
>>>
>>> Regards,
>>>
>>> Marc
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Apr  6 01:07:43 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 6 Apr 2017 09:07:43 +1000
Subject: [R] Package Query
In-Reply-To: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
References: <CAJ5GzRprD=nLZvjMRH+q1uL7w1y+c5o8CngQH8tSF6Y=+O164g@mail.gmail.com>
Message-ID: <CA+8X3fWHmTq6_EoT3vW2wt+EzEjiGauighpJ8kgYXVy-fME-gA@mail.gmail.com>

Hi Ruchika,
Maybe the hdeco package will help.

Jim


On Wed, Apr 5, 2017 at 2:28 PM, Ruchika Salwan
<ruchikasalwan80 at gmail.com> wrote:
> Hey,
>
> Is there any package in R that handles graph decomposition? A package
> created specifically for flat/hierarchical decomposition of graphs.
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Apr  6 01:22:09 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 5 Apr 2017 19:22:09 -0400
Subject: [R] How can output tables be converted to data files?
In-Reply-To: <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>
References: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>
 <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <5bbab8a0-0225-e09f-1677-1ee9bd6989d5@dmstat1.com>

David:
If I may, I was successful in writing csv files for rcorr, n, but not 
pvalue, which is empty.
I set digits=5, thinking the small numbers might not show with default 
setting.
Here's the code I used. Do you see a bug?
Thanks. Bruce

Y <- rcorr(as.matrix(X))
digits=5
write.csv(Y$p, file = "c:/R_data/pvalue.csv",row.names=FALSE, na="") - empty
write.csv(Y$n, file = "c:/R_data/nsize.csv",row.names=FALSE, na="") - okay
write.csv(Y$r, file = "c:/R_data/rcorr.csv",row.names=FALSE, na="") - okay

  

David L Carlson wrote:
> Y <- rcorr(as.matrix(X))


From alqamy at gmail.com  Thu Apr  6 01:34:34 2017
From: alqamy at gmail.com (Husam El Alqamy)
Date: Wed, 5 Apr 2017 16:34:34 -0700
Subject: [R] plotting gam plots from mgcv package
Message-ID: <CAOP-15u1A_4So_pftnfdqCsvLVQEXyB_EB_QRuVUknn_BPuXZg@mail.gmail.com>

Dear List
I am fitting some GAM models using the package mgcv. When plotting the
response curves of the individual predictors using gam.plot I get a dotted
line of the confidence interval around the fitted line. Does anybody know a
way to make these as grey area around the fitted lined instead of the
dotted lines/ Thanks in advance
Regards

*BCTS*

GIS

*Hossameldin ELALKAMY, **MPhill., PhD.*

*GIS Analyst *

BC Timber Sales |  Prince George

Ministry of Forests, Lands and Natural Resource Operations

P. 250.614.7521 C. 778.896.3229 | 2000 Ospika Blvd.  PG, BC., V2N 4W5



Webpage <https://www.for.gov.bc.ca/bcts/> | GIS Requests
<https://spc-bcts.gov.bc.ca/BCTSNGG/SitePages/TPG%20Prince%20George.aspx> |
Profile <https://www.linkedin.com/in/husam-el-alqamy-82212b6a/>

[image: BC FLNRO]

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Apr  6 01:35:51 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Apr 2017 16:35:51 -0700
Subject: [R] How can output tables be converted to data files?
In-Reply-To: <5bbab8a0-0225-e09f-1677-1ee9bd6989d5@dmstat1.com>
References: <a8b4955e-6de2-ab78-c48f-ebc330568ca1@dmstat1.com>
 <cc0ca68ce24b45f280135284d776ec72@exch-2p-mbx-w2.ads.tamu.edu>
 <5bbab8a0-0225-e09f-1677-1ee9bd6989d5@dmstat1.com>
Message-ID: <CAGxFJbTbHffiFArx9+0pNGzarWCX75p3XLd=UEGYWj3uBPaXUQ@mail.gmail.com>

Yes. "p" is not "P" .

Re-read the "value" section of the ?rcorr if this is not clear.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 5, 2017 at 4:22 PM, BR_email <br at dmstat1.com> wrote:
> David:
> If I may, I was successful in writing csv files for rcorr, n, but not
> pvalue, which is empty.
> I set digits=5, thinking the small numbers might not show with default
> setting.
> Here's the code I used. Do you see a bug?
> Thanks. Bruce
>
> Y <- rcorr(as.matrix(X))
> digits=5
> write.csv(Y$p, file = "c:/R_data/pvalue.csv",row.names=FALSE, na="") - empty
> write.csv(Y$n, file = "c:/R_data/nsize.csv",row.names=FALSE, na="") - okay
> write.csv(Y$r, file = "c:/R_data/rcorr.csv",row.names=FALSE, na="") - okay
>
>
> David L Carlson wrote:
>>
>> Y <- rcorr(as.matrix(X))
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Apr  6 08:08:34 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 6 Apr 2017 06:08:34 +0000
Subject: [R] ggplot2 question plot mean/error bars
In-Reply-To: <CAN_e6Xs0dDdxqkXBLhLxQ99MAL49J0y8fDk2NHNSeAJMqR4w4w@mail.gmail.com>
References: <CAN_e6XsjYGPt9szry7cDtdsDCAGJG=LgzQ6b3=kAw2c+-Xop_Q@mail.gmail.com>
 <CAN_e6Xs0dDdxqkXBLhLxQ99MAL49J0y8fDk2NHNSeAJMqR4w4w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1F986@SRVEXCHCM301.precheza.cz>

Hi

Put geom point call to the end of the commands

p<-ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,group=D,col=D,fill=D))
p+  geom_line() + geom_errorbar(width=.2,aes(ymin=b.mean-b.se,ymax=b.mean+b.se)) +
  scale_shape_manual(values = c(16,21)) +
   scale_fill_manual(values=c("black","white")) +
   scale_color_manual(values=c("black","black"))+
   geom_point(shape=21,size=4)

Cheers
Petr


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Santosh
Sent: Wednesday, April 5, 2017 11:06 PM
To: r-help <r-help at r-project.org>
Subject: Re: [R] ggplot2 question plot mean/error bars

Dear Rxperts..
Here is the updated code.. to the above example.. how do I make the white
circles as "white filled" so that lines in the circles are not shown.?

Thanks and much appreciated....
Santosh

q <-  data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(
paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(
seq(10),15),b=round(runif(150,10,20)))
q$r <- q$b*0.1
q2 <- q[order(q$G,q$D,q$a,q$t),]

  q3 <- as.data.frame(as.matrix(with(q2,aggregate(list(b=b),list(D=D,t=t),function(x)
c(mean=mean(x),sd=sd(x),se=(sd(x)/sqrt(length(x))))))),stringsAsFactors=F)
  q3$t <- as.numeric(q3$t)
  q3$b.mean <- as.numeric(q3$b.mean)
  q3$b.sd <- as.numeric(q3$b.sd)
  q3$b.se <- as.numeric(q3$b.se)

ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,group=D,col=D,fill=D))
+  geom_point(shape=21,size=4) + #,color=IP))
  geom_line() +
  # geom_point(data=ipthd.f[ipthd.f$IP=="Cinacalcet",],fill='white')+
  geom_errorbar(width=.2,aes(ymin=b.mean-b.se,ymax=b.mean+b.se)) +
  scale_shape_manual(values = c(16,21)) +
  # scale_shape(solid = T)+
  # scale_shape_identity() +
  # scale_shape_discrete(solid = T) +
   scale_fill_manual(values=c("black","white")) +
   scale_color_manual(values=c("black","black"))

On Wed, Apr 5, 2017 at 11:50 AM, Santosh <santosh2005 at gmail.com> wrote:

> Hello Rxperts..
> I am trying to generate a mean+/- error plot.. using ggplot2.. with filled
> black and white circles and black lines, but no overlap  of lines and
> circles (symbols). Also, with no top and right lines of the plot box. I
> remember having done this before.. unable to reproduce how I did!
>
> Yes, there are many ways of generating the plot.. Would high appreciate it
> if you could help debug this piece of code.
>
> Attaching sample code for your convenience..
> Best,
> Santosh
>
> q <-  data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(
> paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(
> seq(10),15),b=round(runif(150,10,20)))
> q$r <- q$b*0.1
> q2 <- q[order(q$G,q$D,q$a,q$t),]
>
>   q3 <- as.data.frame(as.matrix(with(q2,aggregate(list(b=b),list(D=D,t=t),function(x)
> c(mean=mean(x),sd=sd(x),se=(sd(x)/sqrt(length(x))))))),stringsAsFactors=F)
>   q3$t <- as.numeric(q3$t)
>   q3$b.mean <- as.numeric(q3$b.mean)
>   q3$b.sd <- as.numeric(q3$b.sd)
>   q3$b.se <- as.numeric(q3$b.se)
>
> ggplot(q3[as.character(q3$D)%in%c("D1","D2"),],aes(x=t,y=b.mean,fill=D,col=D,group=D))
> +     geom_point(shape=21,size=4) +
>     geom_line() +
> geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
> geom_errorbar(width=1,aes(ymin=Mean-SE,ymax=Mean+SE)) +
>     scale_shape_manual(values = c(16,21)) +
>     scale_fill_manual(values=c("black","white")) +
>     scale_color_manual(values=c("black","black")) +
>     +legend.position = c(.8,.8))
>
>
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sebastien.moretti at unil.ch  Thu Apr  6 08:55:34 2017
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 6 Apr 2017 08:55:34 +0200
Subject: [R] as.POSIXct character string is not in a standard
 unambiguous format
In-Reply-To: <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
Message-ID: <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>

Hi Ben

Thanks for your answer
I have already tried this, as well as
     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
It works! But it does not fix it widely for all tests used during the 
"make check" step at compile time. Unless I patch all of them.

There is something with localtime but I cannot find what.

On another machine with another Linux OS, and the same environmental 
variables
    x <- as.POSIXct("2002-02-02 02:02")
works fine.

S?bastien

> Hi,
>
> I can't answer the question about R 3.3.3, but I don't see anything in the update notes.
>
> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>
> In the meantime, would it skirt your issue if you explicitly stated the format?
>
> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>
> Ben
>
>
>
>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>>
>> Hi
>>
>> I have lots of issues when I try to install R 3.3.3 during the "make check" step.
>>
>> Every time a call to as.POSIXct is done in test scripts, I got the same error message:
>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>> Error in as.POSIXlt.character(x, tz, ...) :
>>  character string is not in a standard unambiguous format
>>
>>
>> It looks to be linked to localtime but when I compiled R 3.3.2  6 months ago, the same test scripts were there and succeeded.
>>
>>
>> Is there an environmental variable to use to change the as.POSIXct behavior?
>>
>> Regards
>>
>> --
>> S?bastien
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org


From e.packer at elifesciences.org  Wed Apr  5 17:33:07 2017
From: e.packer at elifesciences.org (Emily Packer)
Date: Wed, 5 Apr 2017 16:33:07 +0100
Subject: [R] =?utf-8?q?Using_R_Markdown_for_creating_reproducible_manuscri?=
	=?utf-8?q?pts_=E2=80=93_new_blog_post_from_eLife_Labs?=
Message-ID: <CAErc9sLfx3eWioX1-HEB69S3azCqMWuC-c7VjWoB7yzQWR7HvA@mail.gmail.com>

[With apologies for cross-posting]

Hi all,

We have today published a blog post on eLife Labs about how scientists can
use the dynamic document language, R Markdown, for creating reproducible
manuscripts.

At eLife, we aim to make the communication of results more beneficial for
the scientific community as a whole, by operating a platform for presenting
research that encourages and recognises the most responsible behaviours in
science. These ?responsible behaviours? include the reproducibility of
research results, which is a cornerstone of science. For example, the
development of new drugs and medical treatments relies on the ability to
replicate the results of preclinical research.

Chris Hartgerink, a metascience researcher at Tilburg University, the
Netherlands, describes how R Markdown provides a simple solution for
creating reproducible manuscripts here:
https://elifesciences.org/elife-news/composing-reproducible-manuscripts-using-r-markdown?utm_source=Labs&utm_campaign=Rhelp


If you?d like more information, please don?t hesitate to contact me.

Kind regards,

Emily

-- 

*eLife's early-career researcher travel grants 2017 are now open for
applications.
Visit https://elifesciences.org/elife-news/inside-elife-2017-travel-grants-early-career-researchers-now-open-applications
<https://elifesciences.org/elife-news/inside-elife-2017-travel-grants-early-career-researchers-now-open-applications>.*


Emily Packer
Press Officer

+44 1223 855373 (office)

http://elifesciences.org

eLife Sciences Publications, Ltd is a limited liability non-profit
non-stock corporation incorporated in the State of Delaware, USA, with
company number 5030732, and is registered in the UK with company number
FC030576 and branch number BR015634 at the address First Floor, 24 Hills
Road, Cambridge CB2 1JP.

	[[alternative HTML version deleted]]


From maitra at email.com  Wed Apr  5 18:40:44 2017
From: maitra at email.com (Ranjan Maitra)
Date: Wed, 5 Apr 2017 11:40:44 -0500
Subject: [R] taking a small piece of large tiff
In-Reply-To: <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
References: <1219060776.17600479.1491306423713.ref@mail.yahoo.com>
 <1219060776.17600479.1491306423713@mail.yahoo.com>
 <CAAxdm-5YHkExd_=MHRr-=yNK90X0VxnTUTVcTbuyEK=7Hz_icw@mail.gmail.com>
 <B22AC68E-52A2-47E2-90B5-0E30188D98F4@yahoo.co.uk>
Message-ID: <20170405114044.b7f457076ed3d4ee2f1f81d5@email.com>

Hello Louisa,

THis is not a R solution but would it not be easier to use ImageMagick to do what you are wanting to do? Look up
https://www.imagemagick.org/script/index.php

HTH,
Ranjan

On Wed, 5 Apr 2017 08:23:51 +0100 Louisa Reynolds via R-help <r-help at r-project.org> wrote:

> Ok. I have a tiff of size over 2GB. It covers a sixth of the Earth's surface and I'm trying to cut a UK piece out of it. The tiff I start with seems to be too large for R to handle. 
> 
> 
> Sent from my iPhone
> 
> > On 4 Apr 2017, at 18:37, jim holtman <jholtman at gmail.com> wrote:
> > 
> > How big is 'large'?
> > 
> > Jim Holtman
> > Data Munger Guru
> > 
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> > 
> > 
> > On Tue, Apr 4, 2017 at 7:47 AM, Louisa Reynolds via R-help
> > <r-help at r-project.org> wrote:
> >> Dear Forum
> >> I am trying to cut out a small section of a very large 2-dimensional grayscale image as a tiff in R, but it is having difficulty handling such large files.  I have looked at bigmemory and ff packages but it is unclear how I can use these packages with tiffs. Can anyone please suggest something? I have tried tiff and rtiff libraries.
> >> Thanks in advance.
> >>        [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From massimo.bressan at arpa.veneto.it  Thu Apr  6 10:51:26 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 6 Apr 2017 10:51:26 +0200 (CEST)
Subject: [R] average at specific hour "endpoints" of the day
Message-ID: <314883398.18601927.1491468686554.JavaMail.zimbra@arpa.veneto.it>

hello 

given my reproducible example 

#--- 
date<-seq(ISOdate(2017,1, 1, 0), by="hour", length.out = 48) 
v1<-1:48 
df<-data.frame(date,v1) 

#-- 

I need to calculate the average of variable v1 at specific hour "endpoints" of the day: i.e. at hours 6.00 and 22.00 respectively 

the desired result is 

date v1 
01/01/17 22:00 15.5 
02/01/17 06:00 27.5 
02/01/17 22:00 39.5 

at hour 06:00 of each day the average is calculated by considering the 8 previous records (hours from 23:00 to 6:00) 
at hour 22:00 of each day the average is calculated by considering the 16 previous records (hours from 7:00 to 22:00) 

any hint please? 

I've been trying with some functions within the "xts" package but withouth much result... 

thanks for the help 



	[[alternative HTML version deleted]]


From simon.wood at bath.edu  Thu Apr  6 14:22:05 2017
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 6 Apr 2017 13:22:05 +0100
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
 <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
 <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
 <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>
Message-ID: <b0d6a85d-69e1-104c-e2c2-3a9dd76f30a0@bath.edu>

If 'subjIndexF' is a factor for subject, then s(subjIndexF, bs="re") 
will produce a random effect for subject. i.e. each subject will be 
given its own random intercept term, which is a way that repeated 
measures data like this are often handled.

The reason for the s(subjIndexF, bs="re") syntax is that smooths can be 
viewed as Gaussian random effects, so simple Gaussian random effects can 
also be viewed as (0-dimensional) smooths. In general s(x,z,w,bs="re") 
just appends the columns of model.matrix(~x:z:w-1) to the gam model 
matrix, and treats the associated coefficients as i.i.d. Gaussian random 
effects with a common variance (to be estimated). In principle this 
works with any number of arguments to s(...,bs="re").

See ?random.effects (and its linked help files) in mgcv for more.

There are mechanisms for allowing random smooth curves for each subject, 
(e.g. ?factor.smooth.interaction), but I would only use these if simpler 
approaches really aren't adequate here.

best,
Simon



On 30/03/17 17:06, David Winsemius wrote:
>> On Mar 30, 2017, at 6:56 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>
>> David
>>
>> Thank you for your reply. I apologize if I posted in the wrong forum, as I really couldn't decide which forum is the best place for my question and I saw similar questions asked before in this forum.
>>
>> I agree that a sample of ~30 subjects (70 scans in total), the model can be too complicated. Based on that, I did the following:
>> (1) ignored the gender effect, as we have less females than males.
>> (2) corrected chronological age based on their gestational age, that is, we subtracted an infant's chronological age by 2 weeks, if the infant's gestational age is 38 weeks instead of 40weeks.
>>
>> When I ran the model with corrected age, gestational age and their interactions modeled, I found the main effect of gestational age and the interaction between the two are gone.
>>
>> So, my final model will look something like this:
>> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re"), method="REML", data=mydata)
>>
>> Does this look more reasonable?
> I'm still having difficulty understand how a "smoothing" function would be used to handle repeated measures without some sort of "group-within" indicator.
>
> I would have imagined (and this is because I have no experience with using this package for repeated measures) something along the lines of:
>
>   ...+s(correctedAg|subjIndexF)
>
> I see this statement in the docs:
>
>
> smooth.construct.re.smooth.spec {mgcv}	
>
> "gam can deal with simple independent random effects, by exploiting the link between smooths and random effects to treat random effects as smooths. s(x,bs="re") implements this."
>
> But I don't see that as applying to the dependency between individuals measured repeatedly. I find no examples of repeated measures problems being solve by gam(). There is also a note on the same page:
>
> "Note that smooth ids are not supported for random effect terms. Unlike most smooth terms, side conditions are never applied to random effect terms in the event of nesting (since they are identifiable without side conditions)."
>
> When I do a search on "using gam mgcv formula mixed effects" I am referred to packages 'gamm' and 'gamm4' produced by the same author (Simon Wood) as pkg 'mgcv', or to package `nlme`.
>
>
>> Yes, I am relatively new to the mixed model. We originally applied functional data analysis (PACE) on the data, but want to see the results using a different approach. Also, I couldn't find the Mixed Models list, do you mind sending me a link?
> This is a link to the main mailing lists page:
>
> https://www.r-project.org/mail.html
>
> Found with a search on Google with "R mailing lists"
>
>
>> Thank you!
>> Longchuan
>>
>>
>> On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>>
>>> Hi, R experts
>>>
>>> I am new to R & GAM toolbox and would like to get inputs from you all on my
>>> models. The question I have is as follows:
>>> I have 30 subjects with each subject being scanned from one to three times
>>> in the first year of life. The brain volume from each scan was measured.
>>> The scan time was randomly distributed from birth to 1 year.
>>> Each subject has different gestational age ranging from 38 to 41 weeks
>>> Each subject has chronological age from birth to 1 year old
>>> Each subject has gender category.
>>> Now, I want to look at how predictors, such as subject's chronological age,
>>> gestational age and gender will explain the changes in brain volume. I also
>>> want to include interactions between gender and age, gestational and
>>> chronological age. Random effects are also included in the model to account
>>> for subject variability. My model looks like the follows:
>>>
>>> gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge +
>>> sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML", data=mydata)
>>>
>>> Are there any obvious mistakes in the model? Any suggestions will be
>>> greatly appreciated!
>> I'm not seeing mistakes in the syntax but I would question whether 30 subjects is sufficient to adequately support estimates in a a model of this complexity. I would also think that the 's(age)' and 'sex' terms would get aliased out in a model with "+ s(age, by=sex)". Most R regression functions handle removal of over-parametrization automatically.
>>
>> You also have a variable number of measurements per subject. I am unable to comment on the effort to account for the implicit and variably measured correlation and auto-correlation of values within subjects using a "smooth" on subjIndexF, since that is not an approach I was familiar with.  But I am getting concerned whether you are also new to statistical modeling in addition to your use of R and GAM being "new to you"?
>>
>> (Perhaps Simon or one of the mixed-effects experts can correct the gaps in my understanding of how to model repeated measures in the context of small numbers of subjects and irregular emasurements.)
>>
>> Please read the Posting Guide and the pages of candidate mailing lists. Rhelp is not really the place to go when you need statistical advice. I'm not sure if this is really in the center of concerns that get discussed on the Mixed Models list, but to my eyes it would be a better fit there.
>>
>> --
>> David.
>>> L
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From sebastien.moretti at unil.ch  Thu Apr  6 14:29:08 2017
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 6 Apr 2017 14:29:08 +0200
Subject: [R] as.POSIXct character string is not in a standard
 unambiguous format
In-Reply-To: <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
Message-ID: <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>

I have just found the solution.

We have a custom Linux distribution that allows us to have several R (+ 
glibc and others) versions in parallel for tools related to our job domain.

We have another etc/ folder for those tools and R looks for the 
localtime file there, not in /etc/.
So linking /etc/localtime to our etc/ folder makes R happy and
     x <- as.POSIXct("2002-02-02 02:02")
works fine!

S?bastien

> Hi Ben
>
> Thanks for your answer
> I have already tried this, as well as
>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
> It works! But it does not fix it widely for all tests used during the
> "make check" step at compile time. Unless I patch all of them.
>
> There is something with localtime but I cannot find what.
>
> On another machine with another Linux OS, and the same environmental
> variables
>    x <- as.POSIXct("2002-02-02 02:02")
> works fine.
>
> S?bastien
>
>> Hi,
>>
>> I can't answer the question about R 3.3.3, but I don't see anything in
>> the update notes.
>>
>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>>
>> In the meantime, would it skirt your issue if you explicitly stated
>> the format?
>>
>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>>
>> Ben
>>
>>
>>
>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
>>> <sebastien.moretti at unil.ch> wrote:
>>>
>>> Hi
>>>
>>> I have lots of issues when I try to install R 3.3.3 during the "make
>>> check" step.
>>>
>>> Every time a call to as.POSIXct is done in test scripts, I got the
>>> same error message:
>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>>> Error in as.POSIXlt.character(x, tz, ...) :
>>>  character string is not in a standard unambiguous format
>>>
>>>
>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
>>> months ago, the same test scripts were there and succeeded.
>>>
>>>
>>> Is there an environmental variable to use to change the as.POSIXct
>>> behavior?
>>>
>>> Regards
>>>
>>> --
>>> S?bastien


From simon.wood at bath.edu  Thu Apr  6 14:40:34 2017
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 6 Apr 2017 13:40:34 +0100
Subject: [R] conditional regression with mgcv
In-Reply-To: <CAEd09GSbJ1D6j6exLuR3X66=aOAvgXvjLwtvwVaZ8TY3yezg3A@mail.gmail.com>
References: <CAEd09GSbJ1D6j6exLuR3X66=aOAvgXvjLwtvwVaZ8TY3yezg3A@mail.gmail.com>
Message-ID: <7b7660ed-3c5c-cb53-431d-ad72cd488b44@bath.edu>

My guess is that the model has identifiability problems and that this is 
then causing a problem (not caught properly) in the model fitting 
optimizer. Is there any chance you could send data that produces the 
problem (off list) and I can try it out (I will only use any data for 
this investigation, of course - but if the data is confidential then any 
suitably messed up version that also fails would be just as useful).

best,
Simon

On 31/03/17 16:58, Dean Force wrote:
> Hello,
>
>
> As a part of a larger project, I am trying to run a conditional logistic
> regression to look at whether maternal age is implicated in the risk of
> developing gestational diabetes. I am using a matched case-control design,
> where mothers with GDM were individually matched with up to 6 controls
> based on several parameters.
>
>
> I run the following model:
>
>
> model <- gam(gdm ~ s(maternal_age, bs="cr") + strata(risk_set) +
> as.factor(district) + as.factor(riskfactor1)+as.factor(riskfactor2), data =
> dt, family=cox.ph(), weights = wt)
>
>
>
> weights are defined as 0 for censoring, 1 for event, and each subject has
> one event/censoring time and one row of covariate values. In total there
> are 1000 cases, matched to 5500 controls, so there are 1000 risk_set that I
> define as strata.
>
> When running the model, I keep getting the following error: ?Error in
> xat[[i]] : subscript out of bounds?. Am I doing something wrong?
>
> Using mgcv_1.8.
>
>
>
> Thank you!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From simon.wood at bath.edu  Thu Apr  6 14:41:51 2017
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 6 Apr 2017 13:41:51 +0100
Subject: [R] plotting gam plots from mgcv package
In-Reply-To: <CAOP-15u1A_4So_pftnfdqCsvLVQEXyB_EB_QRuVUknn_BPuXZg@mail.gmail.com>
References: <CAOP-15u1A_4So_pftnfdqCsvLVQEXyB_EB_QRuVUknn_BPuXZg@mail.gmail.com>
Message-ID: <b8e15747-c895-040f-ac6c-e5a0e5c8b60e@bath.edu>

See 'shade' parameter in ?plot.gam (mgcv)

On 06/04/17 00:34, Husam El Alqamy wrote:
> Dear List
> I am fitting some GAM models using the package mgcv. When plotting the
> response curves of the individual predictors using gam.plot I get a dotted
> line of the confidence interval around the fitted line. Does anybody know a
> way to make these as grey area around the fitted lined instead of the
> dotted lines/ Thanks in advance
> Regards
>
> *BCTS*
>
> GIS
>
> *Hossameldin ELALKAMY, **MPhill., PhD.*
>
> *GIS Analyst *
>
> BC Timber Sales |  Prince George
>
> Ministry of Forests, Lands and Natural Resource Operations
>
> P. 250.614.7521 C. 778.896.3229 | 2000 Ospika Blvd.  PG, BC., V2N 4W5
>
>
>
> Webpage <https://www.for.gov.bc.ca/bcts/> | GIS Requests
> <https://spc-bcts.gov.bc.ca/BCTSNGG/SitePages/TPG%20Prince%20George.aspx> |
> Profile <https://www.linkedin.com/in/husam-el-alqamy-82212b6a/>
>
> [image: BC FLNRO]
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From btupper at bigelow.org  Thu Apr  6 16:40:50 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 6 Apr 2017 10:40:50 -0400
Subject: [R] readr to generate tibble from a character matrix
Message-ID: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>

Hello,

I have a workflow yields a character matrix that I convert to a tibble. Here is a simple example.

library(tibble)
library(readr)

m <- matrix(c(letters[1:12], 1:4, (11:14 + 0.2)), ncol = 5)
colnames(m) <- LETTERS[1:5]

x <- as_tibble(m)

# # A tibble: 4 ? 5
#       A     B     C     D     E
#   <chr> <chr> <chr> <chr> <chr>
# 1     a     e     i     1  11.2
# 2     b     f     j     2  12.2
# 3     c     g     k     3  13.2
# 4     d     h     l     4  14.2

The workflow output columns can be a mix of a known set column outputs.  Some of the columns really should be converted to non-character types before I proceed.  Right now I explictly set the column classes with something like this...

mode(x[['D']]) <- 'integer'
mode(x[['E']]) <- 'numeric'

# # A tibble: 4 ? 5
#       A     B     C     D     E
#   <chr> <chr> <chr> <int> <dbl>
# 1     a     e     i     1  11.2
# 2     b     f     j     2  12.2
# 3     c     g     k     3  13.2
# 4     d     h     l     4  14.2


I wonder if there is a way to use the read_* functions in the readr package to read the character matrix into a tibble directly which would leverage readr's excellent column class guessing. I can see in the vignette ( https://cran.r-project.org/web/packages/readr/vignettes/readr.html ) that I'm not too far off in thinking this could be done (step 1 tantalizingly says 'The flat file is parsed into a rectangular matrix of strings.')  

I know that I could either write the matrix to a file or paste it all into a character vector and then use read_* functions, but I confess I am looking for a straighter path by simply passing the matrix to a function like readr::read_matrix() or the like.

Thanks!
Ben

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From jdnewmil at dcn.davis.ca.us  Thu Apr  6 16:43:25 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 6 Apr 2017 07:43:25 -0700
Subject: [R] as.POSIXct character string is not in a standard
	unambiguous format
In-Reply-To: <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
Message-ID: <F96A0891-903F-41F4-B4D3-9D4518FC72EF@dcn.davis.ca.us>

You always need to set your timezone somehow when converting to POSIXt. Technically the method for doing this varies by OS, but on all environments I have worked with you can set the default timezone with something like 

Sys.setenv( TZ="Etc/GMT+5" )

In your example, some timezones supporting daylight savings would regard that time as invalid (clock "jumps forward"). If the default ("system") timezone on a particular server does not match the data you are working with, use the above command to make it easy to work with data from the desired timezone temporarily. Read ?timezones.
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2017 11:55:34 PM PDT, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>Hi Ben
>
>Thanks for your answer
>I have already tried this, as well as
>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
>It works! But it does not fix it widely for all tests used during the 
>"make check" step at compile time. Unless I patch all of them.
>
>There is something with localtime but I cannot find what.
>
>On another machine with another Linux OS, and the same environmental 
>variables
>    x <- as.POSIXct("2002-02-02 02:02")
>works fine.
>
>S?bastien
>
>> Hi,
>>
>> I can't answer the question about R 3.3.3, but I don't see anything
>in the update notes.
>>
>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>>
>> In the meantime, would it skirt your issue if you explicitly stated
>the format?
>>
>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>>
>> Ben
>>
>>
>>
>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
><sebastien.moretti at unil.ch> wrote:
>>>
>>> Hi
>>>
>>> I have lots of issues when I try to install R 3.3.3 during the "make
>check" step.
>>>
>>> Every time a call to as.POSIXct is done in test scripts, I got the
>same error message:
>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>>> Error in as.POSIXlt.character(x, tz, ...) :
>>>  character string is not in a standard unambiguous format
>>>
>>>
>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
>months ago, the same test scripts were there and succeeded.
>>>
>>>
>>> Is there an environmental variable to use to change the as.POSIXct
>behavior?
>>>
>>> Regards
>>>
>>> --
>>> S?bastien
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Apr  6 16:43:25 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 06 Apr 2017 07:43:25 -0700
Subject: [R] as.POSIXct character string is not in a standard
	unambiguous format
In-Reply-To: <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
Message-ID: <F96A0891-903F-41F4-B4D3-9D4518FC72EF@dcn.davis.ca.us>

You always need to set your timezone somehow when converting to POSIXt. Technically the method for doing this varies by OS, but on all environments I have worked with you can set the default timezone with something like 

Sys.setenv( TZ="Etc/GMT+5" )

In your example, some timezones supporting daylight savings would regard that time as invalid (clock "jumps forward"). If the default ("system") timezone on a particular server does not match the data you are working with, use the above command to make it easy to work with data from the desired timezone temporarily. Read ?timezones.
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2017 11:55:34 PM PDT, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>Hi Ben
>
>Thanks for your answer
>I have already tried this, as well as
>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
>It works! But it does not fix it widely for all tests used during the 
>"make check" step at compile time. Unless I patch all of them.
>
>There is something with localtime but I cannot find what.
>
>On another machine with another Linux OS, and the same environmental 
>variables
>    x <- as.POSIXct("2002-02-02 02:02")
>works fine.
>
>S?bastien
>
>> Hi,
>>
>> I can't answer the question about R 3.3.3, but I don't see anything
>in the update notes.
>>
>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>>
>> In the meantime, would it skirt your issue if you explicitly stated
>the format?
>>
>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>>
>> Ben
>>
>>
>>
>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
><sebastien.moretti at unil.ch> wrote:
>>>
>>> Hi
>>>
>>> I have lots of issues when I try to install R 3.3.3 during the "make
>check" step.
>>>
>>> Every time a call to as.POSIXct is done in test scripts, I got the
>same error message:
>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>>> Error in as.POSIXlt.character(x, tz, ...) :
>>>  character string is not in a standard unambiguous format
>>>
>>>
>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
>months ago, the same test scripts were there and succeeded.
>>>
>>>
>>> Is there an environmental variable to use to change the as.POSIXct
>behavior?
>>>
>>> Regards
>>>
>>> --
>>> S?bastien
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From simon.wood at bath.edu  Thu Apr  6 16:44:53 2017
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 6 Apr 2017 15:44:53 +0100
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <CAJDdXgZ1UtYxpdNtHcyyiwfjXhHOuXmGFSbEAf8+2qy=HUpRJA@mail.gmail.com>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
 <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
 <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
 <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>
 <b0d6a85d-69e1-104c-e2c2-3a9dd76f30a0@bath.edu>
 <CAJDdXgZ1UtYxpdNtHcyyiwfjXhHOuXmGFSbEAf8+2qy=HUpRJA@mail.gmail.com>
Message-ID: <86cab2b2-af56-a25e-dbba-639145fe74fc@bath.edu>

>
> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re") + 
> s(subjIndexF, correctedAge, bs="re"), method="REML", data=mydata), 
> where subjIndexF is a factor for each subject. I was thrown an error 
> saying "more coefficients than data".
>
--- I'm not sure exactly  how many scans and subjects you have. The 
above model will have 10 + 2*(number of subjects ) coeffs. If that is 
more than the number of scans then gam will not handle it. Depending on 
the numbers involved you could reduce the k parameter to 
s(correctedAge), to fix the problem. (e.g. with 31 subjects and 70 scans 
s(correctedAge=8) should work).

> However, when I tried to model similar (please correct me if they are 
> not similar) things using GAMM based on description in 
> ?factor.smooth.interaction:
>  gamm1=gamm(BrainVolume~ s(correctedAge) + s(correctedAge, subjIndexF, 
> bs="fs", k=5), data=mydata)
--- It's not the same model. You now have a random smooth curve per 
subject. You can add random effects in gamm using the list form of the 
syntax for specifying random effects in lme. see ?gamm. Random 
intercepts and slopes can be added that way.

> The model ran.  When I plotted the data using plot(gamm1), I got two 
> figures: the left one is the group mean and 95%CI, which I assume is 
> the results by gamm1$gam model. The right one shows 30 lines (the 
> number of subjects in my data) fluctuating around 0, which I assume is 
> the random effects (gamm1$lme) modeled within each subject that can be 
> added onto the group mean for individual curves. Is my understanding 
> correct? If so, how can I extract these curves from gamm1$lme?
>
--- I would extract the fitted curves using predict(gamm1$gam,..., 
type="terms") supplying the factor levels and correctedAges at which you 
want to evaluate the curves.

> Many thanks!
> L
>
>
>
> On Thu, Apr 6, 2017 at 8:22 AM, Simon Wood <simon.wood at bath.edu 
> <mailto:simon.wood at bath.edu>> wrote:
>
>     If 'subjIndexF' is a factor for subject, then s(subjIndexF,
>     bs="re") will produce a random effect for subject. i.e. each
>     subject will be given its own random intercept term, which is a
>     way that repeated measures data like this are often handled.
>
>     The reason for the s(subjIndexF, bs="re") syntax is that smooths
>     can be viewed as Gaussian random effects, so simple Gaussian
>     random effects can also be viewed as (0-dimensional) smooths. In
>     general s(x,z,w,bs="re") just appends the columns of
>     model.matrix(~x:z:w-1) to the gam model matrix, and treats the
>     associated coefficients as i.i.d. Gaussian random effects with a
>     common variance (to be estimated). In principle this works with
>     any number of arguments to s(...,bs="re").
>
>     See ?random.effects (and its linked help files) in mgcv for more.
>
>     There are mechanisms for allowing random smooth curves for each
>     subject, (e.g. ?factor.smooth.interaction), but I would only use
>     these if simpler approaches really aren't adequate here.
>
>     best,
>     Simon
>
>
>
>
>     On 30/03/17 17:06, David Winsemius wrote:
>
>             On Mar 30, 2017, at 6:56 AM, Leon Lee
>             <bhamlion78 at gmail.com <mailto:bhamlion78 at gmail.com>> wrote:
>
>             David
>
>             Thank you for your reply. I apologize if I posted in the
>             wrong forum, as I really couldn't decide which forum is
>             the best place for my question and I saw similar questions
>             asked before in this forum.
>
>             I agree that a sample of ~30 subjects (70 scans in total),
>             the model can be too complicated. Based on that, I did the
>             following:
>             (1) ignored the gender effect, as we have less females
>             than males.
>             (2) corrected chronological age based on their gestational
>             age, that is, we subtracted an infant's chronological age
>             by 2 weeks, if the infant's gestational age is 38 weeks
>             instead of 40weeks.
>
>             When I ran the model with corrected age, gestational age
>             and their interactions modeled, I found the main effect of
>             gestational age and the interaction between the two are gone.
>
>             So, my final model will look something like this:
>             gamObj=gam(brainVolume~ s(correctedAge) + s(subjIndexF,
>             bs="re"), method="REML", data=mydata)
>
>             Does this look more reasonable?
>
>         I'm still having difficulty understand how a "smoothing"
>         function would be used to handle repeated measures without
>         some sort of "group-within" indicator.
>
>         I would have imagined (and this is because I have no
>         experience with using this package for repeated measures)
>         something along the lines of:
>
>           ...+s(correctedAg|subjIndexF)
>
>         I see this statement in the docs:
>
>
>         smooth.construct.re.smooth.spec {mgcv}
>
>         "gam can deal with simple independent random effects, by
>         exploiting the link between smooths and random effects to
>         treat random effects as smooths. s(x,bs="re") implements this."
>
>         But I don't see that as applying to the dependency between
>         individuals measured repeatedly. I find no examples of
>         repeated measures problems being solve by gam(). There is also
>         a note on the same page:
>
>         "Note that smooth ids are not supported for random effect
>         terms. Unlike most smooth terms, side conditions are never
>         applied to random effect terms in the event of nesting (since
>         they are identifiable without side conditions)."
>
>         When I do a search on "using gam mgcv formula mixed effects" I
>         am referred to packages 'gamm' and 'gamm4' produced by the
>         same author (Simon Wood) as pkg 'mgcv', or to package `nlme`.
>
>
>             Yes, I am relatively new to the mixed model. We originally
>             applied functional data analysis (PACE) on the data, but
>             want to see the results using a different approach. Also,
>             I couldn't find the Mixed Models list, do you mind sending
>             me a link?
>
>         This is a link to the main mailing lists page:
>
>         https://www.r-project.org/mail.html
>         <https://www.r-project.org/mail.html>
>
>         Found with a search on Google with "R mailing lists"
>
>
>             Thank you!
>             Longchuan
>
>
>             On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius
>             <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>>
>             wrote:
>
>                 On Mar 28, 2017, at 9:32 AM, Leon Lee
>                 <bhamlion78 at gmail.com <mailto:bhamlion78 at gmail.com>>
>                 wrote:
>
>                 Hi, R experts
>
>                 I am new to R & GAM toolbox and would like to get
>                 inputs from you all on my
>                 models. The question I have is as follows:
>                 I have 30 subjects with each subject being scanned
>                 from one to three times
>                 in the first year of life. The brain volume from each
>                 scan was measured.
>                 The scan time was randomly distributed from birth to 1
>                 year.
>                 Each subject has different gestational age ranging
>                 from 38 to 41 weeks
>                 Each subject has chronological age from birth to 1
>                 year old
>                 Each subject has gender category.
>                 Now, I want to look at how predictors, such as
>                 subject's chronological age,
>                 gestational age and gender will explain the changes in
>                 brain volume. I also
>                 want to include interactions between gender and age,
>                 gestational and
>                 chronological age. Random effects are also included in
>                 the model to account
>                 for subject variability. My model looks like the follows:
>
>                 gam=gam(brainVolume~ s(age) + ti(age, gestationalAge)
>                 + gestationalAge +
>                 sex + s(age, by=sex) +  s(subjIndexF, bs="re"),
>                 method="REML", data=mydata)
>
>                 Are there any obvious mistakes in the model? Any
>                 suggestions will be
>                 greatly appreciated!
>
>             I'm not seeing mistakes in the syntax but I would question
>             whether 30 subjects is sufficient to adequately support
>             estimates in a a model of this complexity. I would also
>             think that the 's(age)' and 'sex' terms would get aliased
>             out in a model with "+ s(age, by=sex)". Most R regression
>             functions handle removal of over-parametrization
>             automatically.
>
>             You also have a variable number of measurements per
>             subject. I am unable to comment on the effort to account
>             for the implicit and variably measured correlation and
>             auto-correlation of values within subjects using a
>             "smooth" on subjIndexF, since that is not an approach I
>             was familiar with.  But I am getting concerned whether you
>             are also new to statistical modeling in addition to your
>             use of R and GAM being "new to you"?
>
>             (Perhaps Simon or one of the mixed-effects experts can
>             correct the gaps in my understanding of how to model
>             repeated measures in the context of small numbers of
>             subjects and irregular emasurements.)
>
>             Please read the Posting Guide and the pages of candidate
>             mailing lists. Rhelp is not really the place to go when
>             you need statistical advice. I'm not sure if this is
>             really in the center of concerns that get discussed on the
>             Mixed Models list, but to my eyes it would be a better fit
>             there.
>
>             --
>             David.
>
>                 L
>
>                        [[alternative HTML version deleted]]
>
>                 ______________________________________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list -- To UNSUBSCRIBE and more, see
>                 https://stat.ethz.ch/mailman/listinfo/r-help
>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>                 PLEASE do read the posting guide
>                 http://www.R-project.org/posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
>
>             David Winsemius
>             Alameda, CA, USA
>
>
>         David Winsemius
>         Alameda, CA, USA
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     -- 
>     Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>     +44 (0)117 33 18273 <tel:%2B44%20%280%29117%2033%2018273>
>     http://www.maths.bris.ac.uk/~sw15190
>     <http://www.maths.bris.ac.uk/%7Esw15190>
>
>


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Apr  6 16:45:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 06 Apr 2017 07:45:50 -0700
Subject: [R] as.POSIXct character string is not in a standard
	unambiguous format
In-Reply-To: <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
 <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
Message-ID: <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>

I cannot imagine a less desirable solution.  This is the opposite of portable programming. 
-- 
Sent from my phone. Please excuse my brevity.

On April 6, 2017 5:29:08 AM PDT, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>I have just found the solution.
>
>We have a custom Linux distribution that allows us to have several R (+
>
>glibc and others) versions in parallel for tools related to our job
>domain.
>
>We have another etc/ folder for those tools and R looks for the 
>localtime file there, not in /etc/.
>So linking /etc/localtime to our etc/ folder makes R happy and
>     x <- as.POSIXct("2002-02-02 02:02")
>works fine!
>
>S?bastien
>
>> Hi Ben
>>
>> Thanks for your answer
>> I have already tried this, as well as
>>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
>> It works! But it does not fix it widely for all tests used during the
>> "make check" step at compile time. Unless I patch all of them.
>>
>> There is something with localtime but I cannot find what.
>>
>> On another machine with another Linux OS, and the same environmental
>> variables
>>    x <- as.POSIXct("2002-02-02 02:02")
>> works fine.
>>
>> S?bastien
>>
>>> Hi,
>>>
>>> I can't answer the question about R 3.3.3, but I don't see anything
>in
>>> the update notes.
>>>
>>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>>>
>>> In the meantime, would it skirt your issue if you explicitly stated
>>> the format?
>>>
>>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>>>
>>> Ben
>>>
>>>
>>>
>>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
>>>> <sebastien.moretti at unil.ch> wrote:
>>>>
>>>> Hi
>>>>
>>>> I have lots of issues when I try to install R 3.3.3 during the
>"make
>>>> check" step.
>>>>
>>>> Every time a call to as.POSIXct is done in test scripts, I got the
>>>> same error message:
>>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>>>> Error in as.POSIXlt.character(x, tz, ...) :
>>>>  character string is not in a standard unambiguous format
>>>>
>>>>
>>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
>>>> months ago, the same test scripts were there and succeeded.
>>>>
>>>>
>>>> Is there an environmental variable to use to change the as.POSIXct
>>>> behavior?
>>>>
>>>> Regards
>>>>
>>>> --
>>>> S?bastien
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Apr  6 16:45:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 6 Apr 2017 07:45:50 -0700
Subject: [R] as.POSIXct character string is not in a standard
	unambiguous format
In-Reply-To: <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
 <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
Message-ID: <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>

I cannot imagine a less desirable solution.  This is the opposite of portable programming. 
-- 
Sent from my phone. Please excuse my brevity.

On April 6, 2017 5:29:08 AM PDT, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>I have just found the solution.
>
>We have a custom Linux distribution that allows us to have several R (+
>
>glibc and others) versions in parallel for tools related to our job
>domain.
>
>We have another etc/ folder for those tools and R looks for the 
>localtime file there, not in /etc/.
>So linking /etc/localtime to our etc/ folder makes R happy and
>     x <- as.POSIXct("2002-02-02 02:02")
>works fine!
>
>S?bastien
>
>> Hi Ben
>>
>> Thanks for your answer
>> I have already tried this, as well as
>>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
>> It works! But it does not fix it widely for all tests used during the
>> "make check" step at compile time. Unless I patch all of them.
>>
>> There is something with localtime but I cannot find what.
>>
>> On another machine with another Linux OS, and the same environmental
>> variables
>>    x <- as.POSIXct("2002-02-02 02:02")
>> works fine.
>>
>> S?bastien
>>
>>> Hi,
>>>
>>> I can't answer the question about R 3.3.3, but I don't see anything
>in
>>> the update notes.
>>>
>>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
>>>
>>> In the meantime, would it skirt your issue if you explicitly stated
>>> the format?
>>>
>>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
>>>
>>> Ben
>>>
>>>
>>>
>>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
>>>> <sebastien.moretti at unil.ch> wrote:
>>>>
>>>> Hi
>>>>
>>>> I have lots of issues when I try to install R 3.3.3 during the
>"make
>>>> check" step.
>>>>
>>>> Every time a call to as.POSIXct is done in test scripts, I got the
>>>> same error message:
>>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
>>>> Error in as.POSIXlt.character(x, tz, ...) :
>>>>  character string is not in a standard unambiguous format
>>>>
>>>>
>>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
>>>> months ago, the same test scripts were there and succeeded.
>>>>
>>>>
>>>> Is there an environmental variable to use to change the as.POSIXct
>>>> behavior?
>>>>
>>>> Regards
>>>>
>>>> --
>>>> S?bastien
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sebastien.moretti at unil.ch  Thu Apr  6 16:51:47 2017
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 6 Apr 2017 16:51:47 +0200
Subject: [R] as.POSIXct character string is not in a standard
 unambiguous format
In-Reply-To: <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
 <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
 <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>
Message-ID: <2cfc9a63-9990-1f39-2e45-b7fe67850a43@unil.ch>

This is far from portable programming but as R looks to search for 
/etc/localtime it is simpler for me do like that.
I will not patch R source code to make "make check" step works.

Then for my own code, I will use
     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
or
     Sys.setenv( TZ="Etc/GMT+5" )

instead of ambiguous
     x <- as.POSIXct("2002-02-02 02:02")

S?bastien


> I cannot imagine a less desirable solution.  This is the opposite of portable programming.
-- 
Sent from my phone. Please excuse my brevity.

On April 6, 2017 5:29:08 AM PDT, Sebastien Moretti 
<sebastien.moretti at unil.ch> wrote:
 > I have just found the solution.
 >
 > We have a custom Linux distribution that allows us to have several R (+
 >
 > glibc and others) versions in parallel for tools related to our job
 > domain.
 >
 > We have another etc/ folder for those tools and R looks for the
 > localtime file there, not in /etc/.
 > So linking /etc/localtime to our etc/ folder makes R happy and
 >     x <- as.POSIXct("2002-02-02 02:02")
 > works fine!
 >
 > S?bastien
 >
 >> Hi Ben
 >>
 >> Thanks for your answer
 >> I have already tried this, as well as
 >>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
 >> It works! But it does not fix it widely for all tests used during the
 >> "make check" step at compile time. Unless I patch all of them.
 >>
 >> There is something with localtime but I cannot find what.
 >>
 >> On another machine with another Linux OS, and the same environmental
 >> variables
 >>    x <- as.POSIXct("2002-02-02 02:02")
 >> works fine.
 >>
 >> S?bastien
 >>
 >>> Hi,
 >>>
 >>> I can't answer the question about R 3.3.3, but I don't see anything
 > in
 >>> the update notes.
 >>>
 >>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
 >>>
 >>> In the meantime, would it skirt your issue if you explicitly stated
 >>> the format?
 >>>
 >>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
 >>>
 >>> Ben
 >>>
 >>>
 >>>
 >>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
 >>>> <sebastien.moretti at unil.ch> wrote:
 >>>>
 >>>> Hi
 >>>>
 >>>> I have lots of issues when I try to install R 3.3.3 during the
 > "make
 >>>> check" step.
 >>>>
 >>>> Every time a call to as.POSIXct is done in test scripts, I got the
 >>>> same error message:
 >>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
 >>>> Error in as.POSIXlt.character(x, tz, ...) :
 >>>>  character string is not in a standard unambiguous format
 >>>>
 >>>>
 >>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
 >>>> months ago, the same test scripts were there and succeeded.
 >>>>
 >>>>
 >>>> Is there an environmental variable to use to change the as.POSIXct
 >>>> behavior?
 >>>>
 >>>> Regards
 >>>>
 >>>> --
 >>>> S?bastien


From sebastien.moretti at unil.ch  Thu Apr  6 16:51:47 2017
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 6 Apr 2017 16:51:47 +0200
Subject: [R] as.POSIXct character string is not in a standard
 unambiguous format
In-Reply-To: <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>
References: <616beecd-28f0-1dc3-7b5e-6d993788f4bd@unil.ch>
 <E4CD3E78-4F01-4352-A3C7-050CD14683BE@bigelow.org>
 <d19b71b2-c031-2133-e2f8-74cd4a3318d9@unil.ch>
 <e89e1ba5-fd33-4fce-653a-8e57f493afe4@unil.ch>
 <DC84FFAB-2455-4AD9-AD72-5A883F9C6FC4@dcn.davis.ca.us>
Message-ID: <2cfc9a63-9990-1f39-2e45-b7fe67850a43@unil.ch>

This is far from portable programming but as R looks to search for 
/etc/localtime it is simpler for me do like that.
I will not patch R source code to make "make check" step works.

Then for my own code, I will use
     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
or
     Sys.setenv( TZ="Etc/GMT+5" )

instead of ambiguous
     x <- as.POSIXct("2002-02-02 02:02")

S?bastien


> I cannot imagine a less desirable solution.  This is the opposite of portable programming.
-- 
Sent from my phone. Please excuse my brevity.

On April 6, 2017 5:29:08 AM PDT, Sebastien Moretti 
<sebastien.moretti at unil.ch> wrote:
 > I have just found the solution.
 >
 > We have a custom Linux distribution that allows us to have several R (+
 >
 > glibc and others) versions in parallel for tools related to our job
 > domain.
 >
 > We have another etc/ folder for those tools and R looks for the
 > localtime file there, not in /etc/.
 > So linking /etc/localtime to our etc/ folder makes R happy and
 >     x <- as.POSIXct("2002-02-02 02:02")
 > works fine!
 >
 > S?bastien
 >
 >> Hi Ben
 >>
 >> Thanks for your answer
 >> I have already tried this, as well as
 >>     x <- as.POSIXct(strptime("2002-02-02 02:02", "%Y-%m-%d %H:%M"))
 >> It works! But it does not fix it widely for all tests used during the
 >> "make check" step at compile time. Unless I patch all of them.
 >>
 >> There is something with localtime but I cannot find what.
 >>
 >> On another machine with another Linux OS, and the same environmental
 >> variables
 >>    x <- as.POSIXct("2002-02-02 02:02")
 >> works fine.
 >>
 >> S?bastien
 >>
 >>> Hi,
 >>>
 >>> I can't answer the question about R 3.3.3, but I don't see anything
 > in
 >>> the update notes.
 >>>
 >>> http://mirror.its.dal.ca/cran/doc/manuals/r-release/NEWS.html
 >>>
 >>> In the meantime, would it skirt your issue if you explicitly stated
 >>> the format?
 >>>
 >>> x <- as.POSIXct("2002-02-02 02:02", format = "%Y-%m-%d %H:%M")
 >>>
 >>> Ben
 >>>
 >>>
 >>>
 >>>> On Apr 5, 2017, at 11:21 AM, Sebastien Moretti
 >>>> <sebastien.moretti at unil.ch> wrote:
 >>>>
 >>>> Hi
 >>>>
 >>>> I have lots of issues when I try to install R 3.3.3 during the
 > "make
 >>>> check" step.
 >>>>
 >>>> Every time a call to as.POSIXct is done in test scripts, I got the
 >>>> same error message:
 >>>> e.g. x <- as.POSIXct("2002-02-02 02:02")
 >>>> Error in as.POSIXlt.character(x, tz, ...) :
 >>>>  character string is not in a standard unambiguous format
 >>>>
 >>>>
 >>>> It looks to be linked to localtime but when I compiled R 3.3.2  6
 >>>> months ago, the same test scripts were there and succeeded.
 >>>>
 >>>>
 >>>> Is there an environmental variable to use to change the as.POSIXct
 >>>> behavior?
 >>>>
 >>>> Regards
 >>>>
 >>>> --
 >>>> S?bastien


From ulrik.stervbo at gmail.com  Thu Apr  6 17:15:36 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 06 Apr 2017 15:15:36 +0000
Subject: [R] readr to generate tibble from a character matrix
In-Reply-To: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>
References: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>
Message-ID: <CAKVAULNGCo13D7YenC9feM8qQEZc-qfKiO9N9NfpPnJaM8-whA@mail.gmail.com>

Hi Ben,

type.convert should do the trick:

m %>%
  as_tibble() %>%
  lapply(type.convert) %>%
  as_tibble()

I am not too happy about to double 'as_tibble' but it get the job done.

HTH
Ulrik

On Thu, 6 Apr 2017 at 16:41 Ben Tupper <btupper at bigelow.org> wrote:

> Hello,
>
> I have a workflow yields a character matrix that I convert to a tibble.
> Here is a simple example.
>
> library(tibble)
> library(readr)
>
> m <- matrix(c(letters[1:12], 1:4, (11:14 + 0.2)), ncol = 5)
> colnames(m) <- LETTERS[1:5]
>
> x <- as_tibble(m)
>
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <chr> <chr>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
>
> The workflow output columns can be a mix of a known set column outputs.
> Some of the columns really should be converted to non-character types
> before I proceed.  Right now I explictly set the column classes with
> something like this...
>
> mode(x[['D']]) <- 'integer'
> mode(x[['E']]) <- 'numeric'
>
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <int> <dbl>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
>
>
> I wonder if there is a way to use the read_* functions in the readr
> package to read the character matrix into a tibble directly which would
> leverage readr's excellent column class guessing. I can see in the vignette
> ( https://cran.r-project.org/web/packages/readr/vignettes/readr.html )
> that I'm not too far off in thinking this could be done (step 1
> tantalizingly says 'The flat file is parsed into a rectangular matrix of
> strings.')
>
> I know that I could either write the matrix to a file or paste it all into
> a character vector and then use read_* functions, but I confess I am
> looking for a straighter path by simply passing the matrix to a function
> like readr::read_matrix() or the like.
>
> Thanks!
> Ben
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Apr  6 18:19:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 6 Apr 2017 09:19:29 -0700 (PDT)
Subject: [R] average at specific hour "endpoints" of the day
In-Reply-To: <314883398.18601927.1491468686554.JavaMail.zimbra@arpa.veneto.it>
References: <314883398.18601927.1491468686554.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <alpine.BSF.2.00.1704060858450.5422@pedal.dcn.davis.ca.us>

On Thu, 6 Apr 2017, Massimo Bressan wrote:

> hello
>
> given my reproducible example
>
> #---
> date<-seq(ISOdate(2017,1, 1, 0), by="hour", length.out = 48)
> v1<-1:48
> df<-data.frame(date,v1)
>
> #--

"date" and "df" are functions in base R... best to avoid hiding them by 
re-using those names in the global environment

ISOdate forces GMT, which many data sets that you might work with do NOT 
use. It is better to use ISOdatetime to avoid letting hidden code 
determine the timezone that is applied to (or compared with) your data.

>
> I need to calculate the average of variable v1 at specific hour "endpoints" of the day: i.e. at hours 6.00 and 22.00 respectively
>
> the desired result is
>
> date v1
> 01/01/17 22:00 15.5
> 02/01/17 06:00 27.5
> 02/01/17 22:00 39.5
>
> at hour 06:00 of each day the average is calculated by considering the 8 previous records (hours from 23:00 to 6:00)
> at hour 22:00 of each day the average is calculated by considering the 16 previous records (hours from 7:00 to 22:00)
>
> any hint please?
>
> I've been trying with some functions within the "xts" package but withouth much result...

I am not sure how I would do this with xts, but the below code is one 
fairly literal approach (implemented two ways) to translate your 
requirements that is also potentially extensible if the data or 
requirements change.

### Base R....

Sys.setenv( TZ = "Etc/GMT+5" ) # selected arbitrarily here but not left to
                                # the system to decide
dta <- data.frame( datetime = seq( ISOdatetime( 2017,1, 1, 0, 0, 0 )
                                  , by="hour"
                                  , length.out = 48
                                  )
                  , v1 = 1:48
                  )
dta$nrec <- 1
dta$date <- as.POSIXct( trunc.POSIXt( dta$datetime, units="days" ) )
dta$tod <- as.numeric( dta$datetime - dta$date, units = "hours" )
dta$timeslot <- factor( ifelse( 6 < dta$tod & dta$tod <= 22
                               , "Day"
                               , "Night"
                               )
                       , levels = c( "Night", "Day" )
                       )
dta$slotdatetime <- dta$date + as.difftime( ifelse( "Day" == dta$timeslot
                                                   , 22
                                                   , ifelse( 22 < dta$tod
                                                           , 24+6
                                                           , 6
                                                           )
                                                   )
                                           , units="hours"
                                           )
dta2 <- aggregate( dta[ , c( "v1", "nrec" ) ]
                  , dta[ , c( "timeslot", "slotdatetime" ), drop=FALSE ]
                  , FUN = sum
                  )
dta2 <- subset( dta2, nrec == ifelse( "Day"==timeslot, 16, 8 ) )
dta2$v1mean <- dta2$v1 / dta2$nrec

#### or if you don't mind the tidyverse....

library(dplyr) # wonderland of non-standard evaluation... beware, Alice!
Sys.setenv( TZ = "Etc/GMT+5" ) # selected arbitrarily here but not left to
                                # the system to decide
dta <- data.frame( datetime = seq( ISOdatetime( 2017,1, 1, 0, 0, 0 )
                                  , by="hour"
                                  , length.out = 48
                                  )
                  , v1 = 1:48
                  )
dta2 <- (   dta
         %>% mutate( date = as.POSIXct( trunc.POSIXt( datetime
                                                    , units="days"
                                                    )
                                      )
                   , tod = as.numeric( datetime - date, units = "hours" )
                   , timeslot = factor( ifelse( 6 < tod & tod <= 22
                                              , "Day"
                                              , "Night"
                                              )
                                      , levels = c( "Night", "Day" )
                                      )
                   , slotdatetime = date +
                            as.difftime( ifelse( "Day" == timeslot
                                               , 22
                                               , ifelse( 22 < tod
                                                       , 24+6
                                                       , 6
                                                       )
                                               )
                                       , units="hours"
                                       )
                   )
         %>% group_by( slotdatetime, timeslot )
         %>% summarise( v1mean = mean( v1 )
                      , nrec = n()
                      )
         %>% filter( nrec == ifelse( "Day"==timeslot, 16, 8 ) )
         )




> thanks for the help
> 	[[alternative HTML version deleted]]

This is a plain-text mailing list. Your chances of communicating 
successfully when you post HTML format email are much worse than if you 
post plain text using the "plain text" option in your mail program.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From btupper at bigelow.org  Thu Apr  6 18:41:57 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 6 Apr 2017 12:41:57 -0400
Subject: [R] readr to generate tibble from a character matrix
In-Reply-To: <CAKVAULNGCo13D7YenC9feM8qQEZc-qfKiO9N9NfpPnJaM8-whA@mail.gmail.com>
References: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>
 <CAKVAULNGCo13D7YenC9feM8qQEZc-qfKiO9N9NfpPnJaM8-whA@mail.gmail.com>
Message-ID: <AD5CF45A-6A5B-4715-9A42-99B02A3AA492@bigelow.org>

Hi,

Thanks for this solution!  Very slick! 

I see what you mean about the two calls to as_tibble(). I suppose I could do the following, but I doubt it is a gain...

mm <- lapply(colnames(m), function(nm, m) type.convert(m[,nm], as.is = TRUE), m=m)
names(mm) <- colnames(m)
as_tibble(mm)

# # A tibble: 4 ? 5
#       A     B     C     D     E
#   <chr> <chr> <chr> <int> <dbl>
# 1     a     e     i     1  11.2
# 2     b     f     j     2  12.2
# 3     c     g     k     3  13.2
# 4     d     h     l     4  14.2

I'll benchmark these with writing to a temporary file and pasting together a string.

Cheers and thanks,
Ben

On Apr 6, 2017, at 11:15 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Ben,
> 
> type.convert should do the trick:
> 
> m %>%
>   as_tibble() %>% 
>   lapply(type.convert) %>% 
>   as_tibble()
> 
> I am not too happy about to double 'as_tibble' but it get the job done.
> 
> HTH
> Ulrik
> 
> On Thu, 6 Apr 2017 at 16:41 Ben Tupper <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
> Hello,
> 
> I have a workflow yields a character matrix that I convert to a tibble. Here is a simple example.
> 
> library(tibble)
> library(readr)
> 
> m <- matrix(c(letters[1:12], 1:4, (11:14 + 0.2)), ncol = 5)
> colnames(m) <- LETTERS[1:5]
> 
> x <- as_tibble(m)
> 
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <chr> <chr>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
> 
> The workflow output columns can be a mix of a known set column outputs.  Some of the columns really should be converted to non-character types before I proceed.  Right now I explictly set the column classes with something like this...
> 
> mode(x[['D']]) <- 'integer'
> mode(x[['E']]) <- 'numeric'
> 
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <int> <dbl>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
> 
> 
> I wonder if there is a way to use the read_* functions in the readr package to read the character matrix into a tibble directly which would leverage readr's excellent column class guessing. I can see in the vignette ( https://cran.r-project.org/web/packages/readr/vignettes/readr.html <https://cran.r-project.org/web/packages/readr/vignettes/readr.html> ) that I'm not too far off in thinking this could be done (step 1 tantalizingly says 'The flat file is parsed into a rectangular matrix of strings.')
> 
> I know that I could either write the matrix to a file or paste it all into a character vector and then use read_* functions, but I confess I am looking for a straighter path by simply passing the matrix to a function like readr::read_matrix() or the like.
> 
> Thanks!
> Ben
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




	[[alternative HTML version deleted]]


From bpschn01 at gmail.com  Thu Apr  6 20:59:03 2017
From: bpschn01 at gmail.com (Brad P)
Date: Thu, 6 Apr 2017 14:59:03 -0400
Subject: [R] Is there a way to get R script line number
Message-ID: <CAMAcwjz+mZ4RHX5hhj-2r8V=4KrRjSk5t6souWzYdYna7Z6J-A@mail.gmail.com>

Hello,

Is there a way to get the current line number in an R script?

As a silly example, if I have the following script and a function called
getLineNumber (suppose one exists!), then the result would be 3.

1 # This is start of script
2
3 print( getLineNumber() )
4
5 # End of script

Thanks for any ideas!

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Apr  6 21:30:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 6 Apr 2017 12:30:39 -0700
Subject: [R] Is there a way to get R script line number
In-Reply-To: <CAMAcwjz+mZ4RHX5hhj-2r8V=4KrRjSk5t6souWzYdYna7Z6J-A@mail.gmail.com>
References: <CAMAcwjz+mZ4RHX5hhj-2r8V=4KrRjSk5t6souWzYdYna7Z6J-A@mail.gmail.com>
Message-ID: <CAGxFJbS9GwZWU+mVQ5w=nsktbv3vbksfzQ-pv5OxEu_diau6vw@mail.gmail.com>

I believe the answer is: No. "Line number" is an ambiguous concept.
Does it mean physical line on a display of a given width? a line of
code demarcated by e.g. <CR> ; a step in the execution of script (that
might display over several physical lines?)

However, various IDE's have and display "line numbers," so you might
try researching whichever one that you use.

(Note: Correction/clarification requested if I am wrong on this).

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 6, 2017 at 11:59 AM, Brad P <bpschn01 at gmail.com> wrote:
> Hello,
>
> Is there a way to get the current line number in an R script?
>
> As a silly example, if I have the following script and a function called
> getLineNumber (suppose one exists!), then the result would be 3.
>
> 1 # This is start of script
> 2
> 3 print( getLineNumber() )
> 4
> 5 # End of script
>
> Thanks for any ideas!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Apr  6 21:34:58 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 6 Apr 2017 19:34:58 +0000
Subject: [R] readr to generate tibble from a character matrix
In-Reply-To: <AD5CF45A-6A5B-4715-9A42-99B02A3AA492@bigelow.org>
References: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>
 <CAKVAULNGCo13D7YenC9feM8qQEZc-qfKiO9N9NfpPnJaM8-whA@mail.gmail.com>
 <AD5CF45A-6A5B-4715-9A42-99B02A3AA492@bigelow.org>
Message-ID: <37cabab3dd8b4cf4b7ba907ede726331@exch-2p-mbx-w2.ads.tamu.edu>

Ulrik's solution gives you factors. To get them as characters, add as.is=TRUE:

> m %>%
+    as_tibble() %>% 
+    lapply(type.convert, as.is=TRUE) %>% 
+    as_tibble()
# A tibble: 4 ? 5
      A     B     C     D     E
  <chr> <chr> <chr> <int> <dbl>
1     a     e     i     1  11.2
2     b     f     j     2  12.2
3     c     g     k     3  13.2
4     d     h     l     4  14.2

Other possibilities:

> mm <- lapply(data.frame(m, stringsAsFactors=FALSE), type.convert, as.is=TRUE)
> as_tibble(mm)
# Your solution simplified by converting to a data.frame

> as_tibble(lapply(as_tibble(m), type.convert, as.is=TRUE))
# Ulrik's solution but without the pipes. Shows why you need 2 as_tibbles()

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Tupper
Sent: Thursday, April 6, 2017 11:42 AM
To: Ulrik Stervbo <ulrik.stervbo at gmail.com>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] readr to generate tibble from a character matrix

Hi,

Thanks for this solution!  Very slick! 

I see what you mean about the two calls to as_tibble(). I suppose I could do the following, but I doubt it is a gain...

mm <- lapply(colnames(m), function(nm, m) type.convert(m[,nm], as.is = TRUE), m=m)
names(mm) <- colnames(m)
as_tibble(mm)

# # A tibble: 4 ? 5
#       A     B     C     D     E
#   <chr> <chr> <chr> <int> <dbl>
# 1     a     e     i     1  11.2
# 2     b     f     j     2  12.2
# 3     c     g     k     3  13.2
# 4     d     h     l     4  14.2

I'll benchmark these with writing to a temporary file and pasting together a string.

Cheers and thanks,
Ben

On Apr 6, 2017, at 11:15 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Ben,
> 
> type.convert should do the trick:
> 
> m %>%
>   as_tibble() %>% 
>   lapply(type.convert) %>% 
>   as_tibble()
> 
> I am not too happy about to double 'as_tibble' but it get the job done.
> 
> HTH
> Ulrik
> 
> On Thu, 6 Apr 2017 at 16:41 Ben Tupper <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
> Hello,
> 
> I have a workflow yields a character matrix that I convert to a tibble. Here is a simple example.
> 
> library(tibble)
> library(readr)
> 
> m <- matrix(c(letters[1:12], 1:4, (11:14 + 0.2)), ncol = 5)
> colnames(m) <- LETTERS[1:5]
> 
> x <- as_tibble(m)
> 
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <chr> <chr>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
> 
> The workflow output columns can be a mix of a known set column outputs.  Some of the columns really should be converted to non-character types before I proceed.  Right now I explictly set the column classes with something like this...
> 
> mode(x[['D']]) <- 'integer'
> mode(x[['E']]) <- 'numeric'
> 
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <int> <dbl>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
> 
> 
> I wonder if there is a way to use the read_* functions in the readr package to read the character matrix into a tibble directly which would leverage readr's excellent column class guessing. I can see in the vignette ( https://cran.r-project.org/web/packages/readr/vignettes/readr.html <https://cran.r-project.org/web/packages/readr/vignettes/readr.html> ) that I'm not too far off in thinking this could be done (step 1 tantalizingly says 'The flat file is parsed into a rectangular matrix of strings.')
> 
> I know that I could either write the matrix to a file or paste it all into a character vector and then use read_* functions, but I confess I am looking for a straighter path by simply passing the matrix to a function like readr::read_matrix() or the like.
> 
> Thanks!
> Ben
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From soni.archit1989 at gmail.com  Thu Apr  6 23:36:38 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Fri, 7 Apr 2017 03:06:38 +0530
Subject: [R] Add local image as inline embedded Image
In-Reply-To: <CAJ7HxBy_UT4TBSdn_i6KQ=Kh7xK=7eMwEEzypwgc7KGLnvow+Q@mail.gmail.com>
References: <CAJ7HxBz1LqwuV-_GKnSpxRSK5gpjHBa=-E6vhUv+feMik9dtkw@mail.gmail.com>
 <CAJ7HxBwkddwHD9CYEHU8wxKqabti9ZhW9LOHLV_P_wBLam0sJQ@mail.gmail.com>
 <CAJ7HxBxDxy1xoZAkU325Dwm21F7VL=Q06XRk_1TqU4puNAJDpg@mail.gmail.com>
 <CAJ7HxBzsrUTzNuZfrSJafGwsZ91YFjZRv_Lk7fJt5fhLx7tkYQ@mail.gmail.com>
 <CAJ7HxBy_UT4TBSdn_i6KQ=Kh7xK=7eMwEEzypwgc7KGLnvow+Q@mail.gmail.com>
Message-ID: <CAJ7HxBzPaKn-051k+dAqrVAMP=j+aDyR6x6hv4g06fKMLoVY9A@mail.gmail.com>

Hi All,

I am using mailR package to send emails by attaching my local image files.
However the image still refers to my file location and never truly embeds
the image in the email.

This came up in testing when my colleague was getting a red cross instead
of an image.

Any thoughts to resolve this?
Thanks,
A

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Fri Apr  7 08:19:31 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Fri, 7 Apr 2017 08:19:31 +0200
Subject: [R] problems in vectors of dates_times
Message-ID: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>

Dear friends - I have further problems  handling dates_times, as 
demonstrated below where concatenating two formatted vectors of 
date_times results in errors.
I wonder why this happens and what was wrong in trying to take these two 
vectors together
All best wishes
Troels Ring
Aalborg, Denmark
Windows
R version 3.3.2 (2016-10-31)


A <- structure(c(1364450400, 1364450400, 1364536800, 1364623200, 
1364709600,
1364796000, 1364882400, 1364968800, 1365055200, 1365141600, 1365228000,
1365314400, 1365400800), class = c("POSIXct", "POSIXt"), tzone = "UTC")
A
B <- structure(c(1365141600, 1365228000, 1365314400, 1365400800, 
1365487200,
1365573600, 1365660000, 1365746400, 1365832800, 1365919200, 1366005600,
1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
B
C <- c(A,B)
C


From ulrik.stervbo at gmail.com  Fri Apr  7 08:27:01 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 07 Apr 2017 06:27:01 +0000
Subject: [R] problems in vectors of dates_times
In-Reply-To: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
Message-ID: <CAKVAULPM_bQ4XO53BGCpXT6wfUSi02CGWemBE29DsWJO4Gm-NQ@mail.gmail.com>

Hi Troels,

I get no error. I think we need more information to be of any help.

Best wishes,
Ulrik

On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - I have further problems  handling dates_times, as
> demonstrated below where concatenating two formatted vectors of
> date_times results in errors.
> I wonder why this happens and what was wrong in trying to take these two
> vectors together
> All best wishes
> Troels Ring
> Aalborg, Denmark
> Windows
> R version 3.3.2 (2016-10-31)
>
>
> A <- structure(c(1364450400, 1364450400, 1364536800, 1364623200,
> 1364709600,
> 1364796000, 1364882400, 1364968800, 1365055200, 1365141600, 1365228000,
> 1365314400, 1365400800), class = c("POSIXct", "POSIXt"), tzone = "UTC")
> A
> B <- structure(c(1365141600, 1365228000, 1365314400, 1365400800,
> 1365487200,
> 1365573600, 1365660000, 1365746400, 1365832800, 1365919200, 1366005600,
> 1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
> B
> C <- c(A,B)
> C
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Fri Apr  7 09:00:52 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Fri, 7 Apr 2017 09:00:52 +0200
Subject: [R] problems in vectors of dates_times
In-Reply-To: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
Message-ID: <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>

Thanks a  lot - perhaps it is just understanding how times dates are 
handled, sorry to bother if that is just the case

C[1]==A[1]  # TRUE

but

C[1]
[1] "2013-03-28 07:00:00 CET"
A[1]
[1] "2013-03-28 06:00:00 UTC"





Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
> Hi Troels,
>
> I get no error. I think we need more information to be of any help.
>
> Best wishes,
> Ulrik
>
> On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk> wrote:
>
>> Dear friends - I have further problems  handling dates_times, as
>> demonstrated below where concatenating two formatted vectors of
>> date_times results in errors.
>> I wonder why this happens and what was wrong in trying to take these two
>> vectors together
>> All best wishes
>> Troels Ring
>> Aalborg, Denmark
>> Windows
>> R version 3.3.2 (2016-10-31)
>>
>>
>> A <- structure(c(1364450400, 1364450400, 1364536800, 1364623200,
>> 1364709600,
>> 1364796000, 1364882400, 1364968800, 1365055200, 1365141600, 1365228000,
>> 1365314400, 1365400800), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>> A
>> B <- structure(c(1365141600, 1365228000, 1365314400, 1365400800,
>> 1365487200,
>> 1365573600, 1365660000, 1365746400, 1365832800, 1365919200, 1366005600,
>> 1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>> B
>> C <- c(A,B)
>> C
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tring at gvdnet.dk  Fri Apr  7 09:48:20 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Fri, 7 Apr 2017 09:48:20 +0200
Subject: [R] problems in vectors of dates_times
In-Reply-To: <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
 <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
Message-ID: <352c69f0-0783-85fb-04a3-ba2f98a52b92@gvdnet.dk>

Thanks a lot - good idea:

I put

Sys.setenv(TZ = "UTC")

ahead of the code - solves the problem!

Thanks a lot


Den 07-04-2017 kl. 09:26 skrev Mark Leeds:
> Hi Troels: This is off-list so as to not clog the list with my noise 
> because my suggestion may not work. I really don't know that much
> about time-zones. but.   I ran your code and it "worked" but all the 
> times were correctly time stamped but they changed from UTC to GMT.
> in time-zone. In your
> case, they changed to something and the time got shifted it looks 
> like. So, definitely it has to do with how your time-zones are set. In 
> my .Rprofile, I have something.
> Let me check. ... time passes .....  I have below in my .Rprofile. So 
> my guess is that, if you want things to remain UTC, then put below
> in your .Rprofile but change it from "GMT" to "UTC". Others may have 
> different solutions but that might work. If you don't have that, then 
> R decides what to use and I'm not sure how it decides.
>
> Sys.setenv(TZ = "GMT")
>
> #print("LOADING MASS LIBRARY")
> #ibrary("MASS")
> #print("LOADING LATTICE LIBRARY")
> #library("lattice")
>
>
>
>
> :~>
>
> On Fri, Apr 7, 2017 at 3:00 AM, Troels Ring <tring at gvdnet.dk 
> <mailto:tring at gvdnet.dk>> wrote:
>
>     Thanks a lot - perhaps it is just understanding how times dates
>     are handled, sorry to bother if that is just the case
>
>     C[1]==A[1]  # TRUE
>
>     but
>
>     C[1]
>     [1] "2013-03-28 07:00:00 CET"
>     A[1]
>     [1] "2013-03-28 06:00:00 UTC"
>
>
>
>
>
>
>     Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
>
>         Hi Troels,
>
>         I get no error. I think we need more information to be of any
>         help.
>
>         Best wishes,
>         Ulrik
>
>         On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk
>         <mailto:tring at gvdnet.dk>> wrote:
>
>             Dear friends - I have further problems  handling
>             dates_times, as
>             demonstrated below where concatenating two formatted
>             vectors of
>             date_times results in errors.
>             I wonder why this happens and what was wrong in trying to
>             take these two
>             vectors together
>             All best wishes
>             Troels Ring
>             Aalborg, Denmark
>             Windows
>             R version 3.3.2 (2016-10-31)
>
>
>             A <- structure(c(1364450400, 1364450400, 1364536800,
>             1364623200,
>             1364709600,
>             1364796000, 1364882400, 1364968800, 1365055200,
>             1365141600, 1365228000,
>             1365314400, 1365400800), class = c("POSIXct", "POSIXt"),
>             tzone = "UTC")
>             A
>             B <- structure(c(1365141600, 1365228000, 1365314400,
>             1365400800,
>             1365487200,
>             1365573600, 1365660000, 1365746400, 1365832800,
>             1365919200, 1366005600,
>             1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>             B
>             C <- c(A,B)
>             C
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained,
>             reproducible code.
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Apr  7 09:52:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 07 Apr 2017 00:52:42 -0700
Subject: [R] problems in vectors of dates_times
In-Reply-To: <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
 <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
Message-ID: <E0FEA557-E6B3-4FFD-9F12-FC11403C974D@dcn.davis.ca.us>

R does a poor job of supporting timezone-specific objects... you have to transfer the necessary attributes explicitly for many operations.  (It does no job of supporting element-specific timezones so don't go there.)

The good news is that R is pretty good at working with points in time, since the default behavior of implementing time with numeric values in GMT always means you can specify whatever timezone you want input or output to use, and the timestamps are always ordered correctly in time.

I find that using the default empty string for tz attributes on POSIXt objects (meaning use whatever is default) and letting the TZ environment variable control the "current default" timezone is the most effective way to avoid frustration with this. Don't hesitate to change that variable when you need to convert to or from character or POSIXlt..

Sys.setenv( TZ="Etc/GMT+5" ) # read ?Olson
x <- as.POSIXct( "2017-03-31 19:00:00" )
Sys.setenv( TZ="Etc/GMT+8" )
y <- as.POSIXct( "2017-03-31 16:00:00" )
Sys.setenv( TZ="GMT" )
print( x )
print( y )
-- 
Sent from my phone. Please excuse my brevity.

On April 7, 2017 12:00:52 AM PDT, Troels Ring <tring at gvdnet.dk> wrote:
>Thanks a  lot - perhaps it is just understanding how times dates are 
>handled, sorry to bother if that is just the case
>
>C[1]==A[1]  # TRUE
>
>but
>
>C[1]
>[1] "2013-03-28 07:00:00 CET"
>A[1]
>[1] "2013-03-28 06:00:00 UTC"
>
>
>
>
>
>Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
>> Hi Troels,
>>
>> I get no error. I think we need more information to be of any help.
>>
>> Best wishes,
>> Ulrik
>>
>> On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk> wrote:
>>
>>> Dear friends - I have further problems  handling dates_times, as
>>> demonstrated below where concatenating two formatted vectors of
>>> date_times results in errors.
>>> I wonder why this happens and what was wrong in trying to take these
>two
>>> vectors together
>>> All best wishes
>>> Troels Ring
>>> Aalborg, Denmark
>>> Windows
>>> R version 3.3.2 (2016-10-31)
>>>
>>>
>>> A <- structure(c(1364450400, 1364450400, 1364536800, 1364623200,
>>> 1364709600,
>>> 1364796000, 1364882400, 1364968800, 1365055200, 1365141600,
>1365228000,
>>> 1365314400, 1365400800), class = c("POSIXct", "POSIXt"), tzone =
>"UTC")
>>> A
>>> B <- structure(c(1365141600, 1365228000, 1365314400, 1365400800,
>>> 1365487200,
>>> 1365573600, 1365660000, 1365746400, 1365832800, 1365919200,
>1366005600,
>>> 1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>>> B
>>> C <- c(A,B)
>>> C
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Fri Apr  7 10:30:04 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Fri, 7 Apr 2017 01:30:04 -0700
Subject: [R] problems in vectors of dates_times
In-Reply-To: <E0FEA557-E6B3-4FFD-9F12-FC11403C974D@dcn.davis.ca.us>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
 <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
 <E0FEA557-E6B3-4FFD-9F12-FC11403C974D@dcn.davis.ca.us>
Message-ID: <CAA99HCxpHQSZHDaiQa9qRdzgQwmPN3eLw=mywn68LiLWXexOEQ@mail.gmail.com>

I believe the lubridate package does a good job with time zones.

> install.packages("lubridate")
> library(lubridate)


Look at the supplied functions  with_tz()  and  force_tz().

HTH,

Bill.

William J. Michels, Ph.D.



On Fri, Apr 7, 2017 at 12:52 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> R does a poor job of supporting timezone-specific objects... you have to transfer the necessary attributes explicitly for many operations.  (It does no job of supporting element-specific timezones so don't go there.)
>
> The good news is that R is pretty good at working with points in time, since the default behavior of implementing time with numeric values in GMT always means you can specify whatever timezone you want input or output to use, and the timestamps are always ordered correctly in time.
>
> I find that using the default empty string for tz attributes on POSIXt objects (meaning use whatever is default) and letting the TZ environment variable control the "current default" timezone is the most effective way to avoid frustration with this. Don't hesitate to change that variable when you need to convert to or from character or POSIXlt..
>
> Sys.setenv( TZ="Etc/GMT+5" ) # read ?Olson
> x <- as.POSIXct( "2017-03-31 19:00:00" )
> Sys.setenv( TZ="Etc/GMT+8" )
> y <- as.POSIXct( "2017-03-31 16:00:00" )
> Sys.setenv( TZ="GMT" )
> print( x )
> print( y )
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 7, 2017 12:00:52 AM PDT, Troels Ring <tring at gvdnet.dk> wrote:
>>Thanks a  lot - perhaps it is just understanding how times dates are
>>handled, sorry to bother if that is just the case
>>
>>C[1]==A[1]  # TRUE
>>
>>but
>>
>>C[1]
>>[1] "2013-03-28 07:00:00 CET"
>>A[1]
>>[1] "2013-03-28 06:00:00 UTC"
>>
>>
>>
>>
>>
>>Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
>>> Hi Troels,
>>>
>>> I get no error. I think we need more information to be of any help.
>>>
>>> Best wishes,
>>> Ulrik
>>>
>>> On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk> wrote:
>>>
>>>> Dear friends - I have further problems  handling dates_times, as
>>>> demonstrated below where concatenating two formatted vectors of
>>>> date_times results in errors.
>>>> I wonder why this happens and what was wrong in trying to take these
>>two
>>>> vectors together
>>>> All best wishes
>>>> Troels Ring
>>>> Aalborg, Denmark
>>>> Windows
>>>> R version 3.3.2 (2016-10-31)
>>>>
>>>>
>>>> A <- structure(c(1364450400, 1364450400, 1364536800, 1364623200,
>>>> 1364709600,
>>>> 1364796000, 1364882400, 1364968800, 1365055200, 1365141600,
>>1365228000,
>>>> 1365314400, 1365400800), class = c("POSIXct", "POSIXt"), tzone =
>>"UTC")
>>>> A
>>>> B <- structure(c(1365141600, 1365228000, 1365314400, 1365400800,
>>>> 1365487200,
>>>> 1365573600, 1365660000, 1365746400, 1365832800, 1365919200,
>>1366005600,
>>>> 1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>>>> B
>>>> C <- c(A,B)
>>>> C
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gagnonjoel24 at gmail.com  Thu Apr  6 18:32:53 2017
From: gagnonjoel24 at gmail.com (Joel Gagnon)
Date: Thu, 6 Apr 2017 12:32:53 -0400
Subject: [R] Paired sample t-test with mi.t.test
Message-ID: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>

Dear all,

It is my first time posting on this list so forgive me for any rookie
mistakes I could make.

I want to conduct t-tests on a dataset that has been imputed using the mice
package:
imput_pps <- mice(pps, m=20, maxit=20, meth='pmm') # pps is my dataset. It
contains items from an 11-item questionnaire gather at pre and post test.
So the data set has 22 columns.

I then proceed to compute the total scores for the pre and post test on my
imputed datasets:

long_pps <- complete(imput_pps, action ="long", include = TRUE)
long_pps$pre_test <- rowSums(long_pps[ ,c(3:13)])
long_pps$post_test <- rowSums(long_pps[ , c(14:24)])

I then used as.mids to convert back to mids object:
mids_pps <- as.mids(long_pps)

Next, I created an imputation list object using mitools:
implist <- lapply(seq(mids_pps$m), function(im) complete(mids_pps, im))
implist <- imputationList(implist)

Now, I want to conduct t-tests using the mi.t.test package. I tried the
following code:
mi.t.test(implist, implist$pre_test, implist$post_test, alternative =
"greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)

When I run this code, R tells me that Y is missing. I know this may sound
stupid, but I thought that I specified Y with this line: implist$pre_test,
implist$post_test - with implist$pre_test being X and implist$post_test
being Y - like I usually do for a normal t-test using the t.test function.

It seems I don't quite understand what the Y variable is supposed to
represent. Could someone help me figure out what I am doing wrong? You
help would be very much appreciated.

Best regards,

Joel Gagnon, Ph.D(c),
Department of Psychology,
Universit? du Qu?bec ? Trois-Rivi?res
Qu?bec, Canada

	[[alternative HTML version deleted]]


From twah256 at gmail.com  Thu Apr  6 13:02:07 2017
From: twah256 at gmail.com (Tintin)
Date: Thu, 6 Apr 2017 04:02:07 -0700 (PDT)
Subject: [R] list with element "Class 'Date' num"
Message-ID: <9b527595-de93-435e-bbee-a12cb888157e@googlegroups.com>

Hi

How do I create an element with specificiation " Class 'Date' num "

The problem arises when I try to construct my own data structure set in the 
"termstrc" package. The model list should look like:

R> str(govbonds$GERMANY)
List of 8
$ ISIN
: chr [1:52] "DE0001141414" "DE0001137131" "DE0001141422" ...
$ MATURITYDATE:Class ' Date ' num [1:52] 13924 13952 13980 14043 ...
$ ISSUEDATE
:Class ' Date ' num [1:52] 11913 13215 12153 13298 ...
$ COUPONRATE : num [1:52] 0.0425 0.03 0.03 0.0325 ...
$ PRICE
: num [1:52] 100 99.9 99.8 99.8 ...
$ ACCRUED
: num [1:52] 4.09 2.66 2.43 2.07 ...
$ CASHFLOWS
:List of 3
..$ ISIN: chr [1:384] "DE0001141414" "DE0001137131" "DE0001141422" ...
..$ CF : num [1:384] 104 103 103 103 ...
..$ DATE:Class ' Date ' num [1:384] 13924 13952 13980 14043 ...
$ TODAY
:Class ' Date ' num 13908

I am trying to create my own basis data.I can create list elements of the 
type "Date", but not of type " Class 'Date' num ".

This seems to block further methods of this package to work properly.

Can someone help?

Thanks,

Tintin

From bhamlion78 at gmail.com  Thu Apr  6 20:16:09 2017
From: bhamlion78 at gmail.com (Leon Lee)
Date: Thu, 6 Apr 2017 14:16:09 -0400
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <86cab2b2-af56-a25e-dbba-639145fe74fc@bath.edu>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
 <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
 <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
 <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>
 <b0d6a85d-69e1-104c-e2c2-3a9dd76f30a0@bath.edu>
 <CAJDdXgZ1UtYxpdNtHcyyiwfjXhHOuXmGFSbEAf8+2qy=HUpRJA@mail.gmail.com>
 <86cab2b2-af56-a25e-dbba-639145fe74fc@bath.edu>
Message-ID: <CAJDdXgb_KrVAafOqOPkymh5cgQ+X=i-mWNQjjrd9Y95cUV+CJQ@mail.gmail.com>

Hi, Simon

Thank you for your explanation! I followed the instructions and
successfully get the predicted values with both fixed and random effects
incorporated: pred.new=predict.gam(gamm1$gam,newdata,type="response").

Also, what I meant to say was "plot(gamm1$gam, pages=1)" for left and right
figures. I didn't attach any figures.

Thank you very much for the help!
L

On Thu, Apr 6, 2017 at 10:44 AM, Simon Wood <simon.wood at bath.edu> wrote:

>
> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re") +
> s(subjIndexF, correctedAge, bs="re"), method="REML", data=mydata), where
> subjIndexF is a factor for each subject. I was thrown an error saying "more
> coefficients than data".
>
> --- I'm not sure exactly  how many scans and subjects you have. The above
> model will have 10 + 2*(number of subjects ) coeffs. If that is more than
> the number of scans then gam will not handle it. Depending on the numbers
> involved you could reduce the k parameter to s(correctedAge), to fix the
> problem. (e.g. with 31 subjects and 70 scans s(correctedAge=8) should work
> ).
>
> However, when I tried to model similar (please correct me if they are not
> similar) things using GAMM based on description in
> ?factor.smooth.interaction:
>  gamm1=gamm(BrainVolume~ s(correctedAge) + s(correctedAge, subjIndexF,
> bs="fs", k=5), data=mydata)
>
> --- It's not the same model. You now have a random smooth curve per
> subject. You can add random effects in gamm using the list form of the
> syntax for specifying random effects in lme. see ?gamm. Random intercepts
> and slopes can be added that way.
>
> The model ran.  When I plotted the data using plot(gamm1), I got two
> figures: the left one is the group mean and 95%CI, which I assume is the
> results by gamm1$gam model. The right one shows 30 lines (the number of
> subjects in my data) fluctuating around 0, which I assume is the random
> effects (gamm1$lme) modeled within each subject that can be added onto the
> group mean for individual curves. Is my understanding correct? If so, how
> can I extract these curves from gamm1$lme?
>
> --- I would extract the fitted curves using predict(gamm1$gam,...,
> type="terms") supplying the factor levels and correctedAges at which you
> want to evaluate the curves.
>
> Many thanks!
> L
>
>
>
> On Thu, Apr 6, 2017 at 8:22 AM, Simon Wood <simon.wood at bath.edu> wrote:
>
>> If 'subjIndexF' is a factor for subject, then s(subjIndexF, bs="re") will
>> produce a random effect for subject. i.e. each subject will be given its
>> own random intercept term, which is a way that repeated measures data like
>> this are often handled.
>>
>> The reason for the s(subjIndexF, bs="re") syntax is that smooths can be
>> viewed as Gaussian random effects, so simple Gaussian random effects can
>> also be viewed as (0-dimensional) smooths. In general s(x,z,w,bs="re") just
>> appends the columns of model.matrix(~x:z:w-1) to the gam model matrix, and
>> treats the associated coefficients as i.i.d. Gaussian random effects with a
>> common variance (to be estimated). In principle this works with any number
>> of arguments to s(...,bs="re").
>>
>> See ?random.effects (and its linked help files) in mgcv for more.
>>
>> There are mechanisms for allowing random smooth curves for each subject,
>> (e.g. ?factor.smooth.interaction), but I would only use these if simpler
>> approaches really aren't adequate here.
>>
>> best,
>> Simon
>>
>>
>>
>>
>> On 30/03/17 17:06, David Winsemius wrote:
>>
>>> On Mar 30, 2017, at 6:56 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>>>
>>>> David
>>>>
>>>> Thank you for your reply. I apologize if I posted in the wrong forum,
>>>> as I really couldn't decide which forum is the best place for my question
>>>> and I saw similar questions asked before in this forum.
>>>>
>>>> I agree that a sample of ~30 subjects (70 scans in total), the model
>>>> can be too complicated. Based on that, I did the following:
>>>> (1) ignored the gender effect, as we have less females than males.
>>>> (2) corrected chronological age based on their gestational age, that
>>>> is, we subtracted an infant's chronological age by 2 weeks, if the infant's
>>>> gestational age is 38 weeks instead of 40weeks.
>>>>
>>>> When I ran the model with corrected age, gestational age and their
>>>> interactions modeled, I found the main effect of gestational age and the
>>>> interaction between the two are gone.
>>>>
>>>> So, my final model will look something like this:
>>>> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re"),
>>>> method="REML", data=mydata)
>>>>
>>>> Does this look more reasonable?
>>>>
>>> I'm still having difficulty understand how a "smoothing" function would
>>> be used to handle repeated measures without some sort of "group-within"
>>> indicator.
>>>
>>> I would have imagined (and this is because I have no experience with
>>> using this package for repeated measures) something along the lines of:
>>>
>>>   ...+s(correctedAg|subjIndexF)
>>>
>>> I see this statement in the docs:
>>>
>>>
>>> smooth.construct.re.smooth.spec {mgcv}
>>>
>>> "gam can deal with simple independent random effects, by exploiting the
>>> link between smooths and random effects to treat random effects as smooths.
>>> s(x,bs="re") implements this."
>>>
>>> But I don't see that as applying to the dependency between individuals
>>> measured repeatedly. I find no examples of repeated measures problems being
>>> solve by gam(). There is also a note on the same page:
>>>
>>> "Note that smooth ids are not supported for random effect terms. Unlike
>>> most smooth terms, side conditions are never applied to random effect terms
>>> in the event of nesting (since they are identifiable without side
>>> conditions)."
>>>
>>> When I do a search on "using gam mgcv formula mixed effects" I am
>>> referred to packages 'gamm' and 'gamm4' produced by the same author (Simon
>>> Wood) as pkg 'mgcv', or to package `nlme`.
>>>
>>>
>>> Yes, I am relatively new to the mixed model. We originally applied
>>>> functional data analysis (PACE) on the data, but want to see the results
>>>> using a different approach. Also, I couldn't find the Mixed Models list, do
>>>> you mind sending me a link?
>>>>
>>> This is a link to the main mailing lists page:
>>>
>>> https://www.r-project.org/mail.html
>>>
>>> Found with a search on Google with "R mailing lists"
>>>
>>>
>>> Thank you!
>>>> Longchuan
>>>>
>>>>
>>>> On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius <
>>>> dwinsemius at comcast.net> wrote:
>>>>
>>>> On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>>>>
>>>>> Hi, R experts
>>>>>
>>>>> I am new to R & GAM toolbox and would like to get inputs from you all
>>>>> on my
>>>>> models. The question I have is as follows:
>>>>> I have 30 subjects with each subject being scanned from one to three
>>>>> times
>>>>> in the first year of life. The brain volume from each scan was
>>>>> measured.
>>>>> The scan time was randomly distributed from birth to 1 year.
>>>>> Each subject has different gestational age ranging from 38 to 41 weeks
>>>>> Each subject has chronological age from birth to 1 year old
>>>>> Each subject has gender category.
>>>>> Now, I want to look at how predictors, such as subject's chronological
>>>>> age,
>>>>> gestational age and gender will explain the changes in brain volume. I
>>>>> also
>>>>> want to include interactions between gender and age, gestational and
>>>>> chronological age. Random effects are also included in the model to
>>>>> account
>>>>> for subject variability. My model looks like the follows:
>>>>>
>>>>> gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge
>>>>> +
>>>>> sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML",
>>>>> data=mydata)
>>>>>
>>>>> Are there any obvious mistakes in the model? Any suggestions will be
>>>>> greatly appreciated!
>>>>>
>>>> I'm not seeing mistakes in the syntax but I would question whether 30
>>>> subjects is sufficient to adequately support estimates in a a model of this
>>>> complexity. I would also think that the 's(age)' and 'sex' terms would get
>>>> aliased out in a model with "+ s(age, by=sex)". Most R regression functions
>>>> handle removal of over-parametrization automatically.
>>>>
>>>> You also have a variable number of measurements per subject. I am
>>>> unable to comment on the effort to account for the implicit and variably
>>>> measured correlation and auto-correlation of values within subjects using a
>>>> "smooth" on subjIndexF, since that is not an approach I was familiar with.
>>>> But I am getting concerned whether you are also new to statistical modeling
>>>> in addition to your use of R and GAM being "new to you"?
>>>>
>>>> (Perhaps Simon or one of the mixed-effects experts can correct the gaps
>>>> in my understanding of how to model repeated measures in the context of
>>>> small numbers of subjects and irregular emasurements.)
>>>>
>>>> Please read the Posting Guide and the pages of candidate mailing lists.
>>>> Rhelp is not really the place to go when you need statistical advice. I'm
>>>> not sure if this is really in the center of concerns that get discussed on
>>>> the Mixed Models list, but to my eyes it would be a better fit there.
>>>>
>>>> --
>>>> David.
>>>>
>>>>> L
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>>
>>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>> +44 (0)117 33 18273 <%2B44%20%280%29117%2033%2018273>
>> http://www.maths.bris.ac.uk/~sw15190
>>
>>
>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Fri Apr  7 10:05:45 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 7 Apr 2017 16:05:45 +0800
Subject: [R] difference metric info of same font on different device
Message-ID: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>

Hi there,

I try to plot with custom fonts, which have good shape Latin and CJK 
characters. I set up all the fonts correctly. However, when I plot the 
same code on png() and postscript(), I get different result. The main 
problem is the space between characters is narrower in postscript() than 
that in png(), and some character also overlap in postscript().  You can 
see the differences from the attached png files.

Is there any way to get the same plot using postscript() and png()? 
Thanks in advance.

Best,
Jinsong

The code I used is here:

windowsFonts(song = windowsFont("SourceHanSerifSC-Regular"),
              hei  = windowsFont("SourceHanSansSC-Regular"),
              hwhei  = windowsFont("SourceHanSansHWSC-Regular"),
              fzsong  = windowsFont("FZShuSong-Z01"),
              fzhei = windowsFont("FZHei-B01"))

postscriptFonts(song = CIDFont("SourceHanSerifSC-Regular", 
"UniSourceHanSerifCN-UTF8-H", "UTF-8", ""),
                 hei  = CIDFont("SourceHanSansSC-Regular", 
"UniSourceHanSansCN-UTF8-H", "UTF-8", ""),
                 hwhei  = CIDFont("SourceHanSansHWSC-Regular", 
"UniSourceHanSansHWCN-UTF8-H", "UTF-8", ""),
                 fzsong  = CIDFont("FZShuSong-Z01",    "GBK-EUC-H", 
"GBK", ""),
                 fzhei = CIDFont("FZHei-B01", "GBK-EUC-H", "GBK", ""))

fa <- c("sans", "serif", "song", "hei", "hwhei", "fzsong", "fzhei")

postscript("font.eps", fonts = fa, onefile = FALSE, width = 4, height = 
4, horizontal = FALSE)

#png("font.png", width=4*300, height=4*300, res =300)

plot(0,xlab="",ylab="",type="n")
text(1, -0.75, expression(CO[2]-Hei), family = "hei")
text(1, -0.5, expression(CO[2]-HWHei), family = "hwhei")
text(1, -0.25, expression(CO[2]-FZHei), family = "fzhei")
text(1, 0.0, expression(CO[2]-Sans), family = "sans")
text(1, 0.25, expression(CO[2]-FZSong), family = "fzsong")
text(1, 0.5, expression(CO[2]-Song), family = "song")
text(1, 0.75, expression(CO[2]-Serif), family = "serif")

dev.off()
-------------- next part --------------
A non-text attachment was scrubbed...
Name: postscript.png
Type: image/png
Size: 6388 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170407/af6f7b62/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: png.png
Type: image/png
Size: 21368 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170407/af6f7b62/attachment-0001.png>

From jsorkin at som.umaryland.edu  Fri Apr  7 02:00:18 2017
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Fri, 7 Apr 2017 00:00:18 +0000
Subject: [R] Piecewise continuous Poisson regression
Message-ID: <BLUPR03MB486C1CB88F954140F8C9660E20D0@BLUPR03MB486.namprd03.prod.outlook.com>

Is there an R package that will perform a piecewise continuous Poisson regression? I want to model two linear segments that intersect at a common knot.
Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Fri Apr  7 11:28:04 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Fri, 7 Apr 2017 02:28:04 -0700
Subject: [R] Is there a way to get R script line number
In-Reply-To: <CAGxFJbS9GwZWU+mVQ5w=nsktbv3vbksfzQ-pv5OxEu_diau6vw@mail.gmail.com>
References: <CAMAcwjz+mZ4RHX5hhj-2r8V=4KrRjSk5t6souWzYdYna7Z6J-A@mail.gmail.com>
 <CAGxFJbS9GwZWU+mVQ5w=nsktbv3vbksfzQ-pv5OxEu_diau6vw@mail.gmail.com>
Message-ID: <CAA99HCxwCw9cBxiXtTZwzJc6jENv21HH80_6yBSyRY8xmWjvdw@mail.gmail.com>

Hi Brad,

Some of the debugging functions may be of use. You can look at trace()
or setBreakpoint(). But I believe Bert is correct in saying your
concept of a "Line Number" and R's concept of a "Line Number" will
differ.

Finally, you can look at the function findLineNum(), which can be
called external to your source code file (not embedded as in your
example).

>?debug

HTH,

Bill

William J. Michels, Ph.D.



On Thu, Apr 6, 2017 at 12:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I believe the answer is: No. "Line number" is an ambiguous concept.
> Does it mean physical line on a display of a given width? a line of
> code demarcated by e.g. <CR> ; a step in the execution of script (that
> might display over several physical lines?)
>
> However, various IDE's have and display "line numbers," so you might
> try researching whichever one that you use.
>
> (Note: Correction/clarification requested if I am wrong on this).
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Apr 6, 2017 at 11:59 AM, Brad P <bpschn01 at gmail.com> wrote:
>> Hello,
>>
>> Is there a way to get the current line number in an R script?
>>
>> As a silly example, if I have the following script and a function called
>> getLineNumber (suppose one exists!), then the result would be 3.
>>
>> 1 # This is start of script
>> 2
>> 3 print( getLineNumber() )
>> 4
>> 5 # End of script
>>
>> Thanks for any ideas!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Fri Apr  7 13:55:28 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 7 Apr 2017 13:55:28 +0200
Subject: [R] Paired sample t-test with mi.t.test
In-Reply-To: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>
References: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>
Message-ID: <1b95dd22-1259-31c1-dfe6-981773c29240@math.uni-giessen.de>

Hi, Joel,

I think, according to the help page of mi.t.test,

mi.t.test(implist, x = "pre_test", y = "post_test",
   alternative = "greater", paired = TRUE, var.equal = TRUE,
   conf.level = 0.95)

should do it (untested).

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 06.04.2017 um 18:32 schrieb Joel Gagnon:
> Dear all,
>
> It is my first time posting on this list so forgive me for any rookie
> mistakes I could make.
>
> I want to conduct t-tests on a dataset that has been imputed using the mice
> package:
> imput_pps <- mice(pps, m=20, maxit=20, meth='pmm') # pps is my dataset. It
> contains items from an 11-item questionnaire gather at pre and post test.
> So the data set has 22 columns.
>
> I then proceed to compute the total scores for the pre and post test on my
> imputed datasets:
>
> long_pps <- complete(imput_pps, action ="long", include = TRUE)
> long_pps$pre_test <- rowSums(long_pps[ ,c(3:13)])
> long_pps$post_test <- rowSums(long_pps[ , c(14:24)])
>
> I then used as.mids to convert back to mids object:
> mids_pps <- as.mids(long_pps)
>
> Next, I created an imputation list object using mitools:
> implist <- lapply(seq(mids_pps$m), function(im) complete(mids_pps, im))
> implist <- imputationList(implist)
>
> Now, I want to conduct t-tests using the mi.t.test package. I tried the
> following code:
> mi.t.test(implist, implist$pre_test, implist$post_test, alternative =
> "greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)
>
> When I run this code, R tells me that Y is missing. I know this may sound
> stupid, but I thought that I specified Y with this line: implist$pre_test,
> implist$post_test - with implist$pre_test being X and implist$post_test
> being Y - like I usually do for a normal t-test using the t.test function.
>
> It seems I don't quite understand what the Y variable is supposed to
> represent. Could someone help me figure out what I am doing wrong? You
> help would be very much appreciated.
>
> Best regards,
>
> Joel Gagnon, Ph.D(c),
> Department of Psychology,
> Universit? du Qu?bec ? Trois-Rivi?res
> Qu?bec, Canada
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nstefi at gmail.com  Fri Apr  7 14:48:11 2017
From: nstefi at gmail.com (Steven Nagy)
Date: Fri, 7 Apr 2017 08:48:11 -0400
Subject: [R] Content Management System Built on R
Message-ID: <000801d2af9d$37819090$a684b1b0$@gmail.com>

Hi everyone,

 

I'm still new to R, and I like that's it's so compact, you can do so much in
just a few lines of code.

I wondered if there is any Content Management System built on R. I have
created websites for my clients, and I prefer to set it up in a CMS instead
and give them control to edit their own content.

So far the CMS I like the best is DotNetNuke, recently they call it DNN. I
also tried Joomla, but I didn't like that is not very easy to find the
content page to edit. In DNN, you just navigate to the page, press Edit, and
you get in to edit mode (instead of searching through all your articles,
like in Joomla).

It would be nice to have a similar platform and I could use R in the back
end.

I searched on Google and I found a CMS called "RSuite CMS", but on their
website they say is based on MarkLogic, and I haven't heard mentioning
anything about R. Not sure where the "R" in the name "RSuite" comes from.

I also remember seeing another CMS where you could drag modules/widgets on
the page around and place them anywhere you want. It was very flexible. But
I can't remember the name. But it wasn't related to R.

Let me know if you know any user friendly CMS built on R.

 

Thanks,

Steven


	[[alternative HTML version deleted]]


From btupper at bigelow.org  Fri Apr  7 15:08:27 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 7 Apr 2017 09:08:27 -0400
Subject: [R] readr to generate tibble from a character matrix
In-Reply-To: <37cabab3dd8b4cf4b7ba907ede726331@exch-2p-mbx-w2.ads.tamu.edu>
References: <F3E68146-DE4F-4F2A-A66A-4C391F41FFD4@bigelow.org>
 <CAKVAULNGCo13D7YenC9feM8qQEZc-qfKiO9N9NfpPnJaM8-whA@mail.gmail.com>
 <AD5CF45A-6A5B-4715-9A42-99B02A3AA492@bigelow.org>
 <37cabab3dd8b4cf4b7ba907ede726331@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <E1E55862-30BC-4344-B1C4-752958006C0C@bigelow.org>

Thanks!

I made up a little test for converting from character matrix to tibble: dumping to file and reading back, pasting up a big string, using pipes, using as.data.frame and using a pipeless version.  By far and away it is worth using Ulrik's or your solution compared to dumping the matrix to a file and then reading back OR pasting the matrix into one honking big string.

There is a difference in how the various methods interpret date-time inputs, but otherwise the results are all identical.

Cheers,
Ben

#### START
library(nycflights13)
library(tibble)
library(magrittr)
library(readr)
library(microbenchmark)


m <- as.matrix(flights)

via_file <- function(m){
    filename = tempfile(fileext = '.csv')
    write.csv(m, file = filename, row.names = FALSE, quote = FALSE)
    readr::read_csv(filename)
}

via_paste <- function(m){
    s <- paste(
        c(paste(colnames(m), collapse = ","), apply(m, 1, paste, collapse = ",")), 
        collapse = "\n")
    readr::read_csv(s)
}

via_pipes <- function(m){
    m %>%
        tibble::as_tibble() %>% 
        lapply(type.convert, as.is = TRUE) %>% 
        tibble::as_tibble()
}

via_dataframe <- function(m){
    mm <- lapply(data.frame(m, stringsAsFactors=FALSE), type.convert, as.is=TRUE)
    tibble::as_tibble(mm)
}

via_pipeless <- function(m){
    tibble::as_tibble(lapply(tibble::as_tibble(m), type.convert, as.is=TRUE))
}

X <- list(
    file=via_file(m),
    paste=via_paste(m),
    pipes=via_pipes(m),
    dataframe=via_dataframe(m),
    pipeless=via_pipeless(m))
    
sapply(names(X), function(n) all.equal(X[[n]], X[[1]]))

# $file
# [1] TRUE

# $paste
# [1] TRUE

# $pipes
# [1] "Incompatible type for column time_hour1: x character, y POSIXct" "Incompatible type for column time_hour2: x character, y POSIXt" 

# $dataframe
# [1] "Incompatible type for column time_hour1: x character, y POSIXct" "Incompatible type for column time_hour2: x character, y POSIXt" 

# $pipeless
# [1] "Incompatible type for column time_hour1: x character, y POSIXct" "Incompatible type for column time_hour2: x character, y POSIXt" 
    
microbenchmark(
    via_file(m),
    via_paste(m),
    via_pipes(m),
    via_dataframe(m),
    via_pipeless(m),
    times = 5
)

#Unit: milliseconds
#             expr       min        lq      mean    median        uq       max neval
#      via_file(m) 2362.7778 2396.2277 2415.9207 2413.0772 2439.5752 2467.9457     5
#     via_paste(m) 5287.8176 5305.6228 5622.1432 5666.0165 5919.3568 5931.9023     5
#     via_pipes(m)  461.4782  464.5656  506.4157  509.5532  542.1091  554.3726     5
# via_dataframe(m)  507.4674  514.2550  553.1791  515.9132  518.0807  710.1794     5
#  via_pipeless(m)  448.9529  470.1074  499.4392  470.6874  500.6027  606.8459     5

sessionInfo()
# R version 3.3.1 (2016-06-21)
# Platform: x86_64-apple-darwin13.4.0 (64-bit)
# Running under: OS X 10.11.6 (El Capitan)

# locale:
# [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base     

# other attached packages:
# [1] microbenchmark_1.4-2.1 readr_1.0.0            magrittr_1.5           tibble_1.2             nycflights13_0.2.0    

# loaded via a namespace (and not attached):
 # [1] colorspace_1.2-6 scales_0.4.1     plyr_1.8.4       assertthat_0.1   tools_3.3.1      gtable_0.2.0     Rcpp_0.12.9      ggplot2_2.1.0    grid_3.3.1       munsell_0.4.3  


### END
 



> On Apr 6, 2017, at 3:34 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Ulrik's solution gives you factors. To get them as characters, add as.is=TRUE:
> 
>> m %>%
> +    as_tibble() %>% 
> +    lapply(type.convert, as.is=TRUE) %>% 
> +    as_tibble()
> # A tibble: 4 ? 5
>      A     B     C     D     E
>  <chr> <chr> <chr> <int> <dbl>
> 1     a     e     i     1  11.2
> 2     b     f     j     2  12.2
> 3     c     g     k     3  13.2
> 4     d     h     l     4  14.2
> 
> Other possibilities:
> 
>> mm <- lapply(data.frame(m, stringsAsFactors=FALSE), type.convert, as.is=TRUE)
>> as_tibble(mm)
> # Your solution simplified by converting to a data.frame
> 
>> as_tibble(lapply(as_tibble(m), type.convert, as.is=TRUE))
> # Ulrik's solution but without the pipes. Shows why you need 2 as_tibbles()
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Tupper
> Sent: Thursday, April 6, 2017 11:42 AM
> To: Ulrik Stervbo <ulrik.stervbo at gmail.com>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] readr to generate tibble from a character matrix
> 
> Hi,
> 
> Thanks for this solution!  Very slick! 
> 
> I see what you mean about the two calls to as_tibble(). I suppose I could do the following, but I doubt it is a gain...
> 
> mm <- lapply(colnames(m), function(nm, m) type.convert(m[,nm], as.is = TRUE), m=m)
> names(mm) <- colnames(m)
> as_tibble(mm)
> 
> # # A tibble: 4 ? 5
> #       A     B     C     D     E
> #   <chr> <chr> <chr> <int> <dbl>
> # 1     a     e     i     1  11.2
> # 2     b     f     j     2  12.2
> # 3     c     g     k     3  13.2
> # 4     d     h     l     4  14.2
> 
> I'll benchmark these with writing to a temporary file and pasting together a string.
> 
> Cheers and thanks,
> Ben
> 
> On Apr 6, 2017, at 11:15 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> 
>> Hi Ben,
>> 
>> type.convert should do the trick:
>> 
>> m %>%
>>  as_tibble() %>% 
>>  lapply(type.convert) %>% 
>>  as_tibble()
>> 
>> I am not too happy about to double 'as_tibble' but it get the job done.
>> 
>> HTH
>> Ulrik
>> 
>> On Thu, 6 Apr 2017 at 16:41 Ben Tupper <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
>> Hello,
>> 
>> I have a workflow yields a character matrix that I convert to a tibble. Here is a simple example.
>> 
>> library(tibble)
>> library(readr)
>> 
>> m <- matrix(c(letters[1:12], 1:4, (11:14 + 0.2)), ncol = 5)
>> colnames(m) <- LETTERS[1:5]
>> 
>> x <- as_tibble(m)
>> 
>> # # A tibble: 4 ? 5
>> #       A     B     C     D     E
>> #   <chr> <chr> <chr> <chr> <chr>
>> # 1     a     e     i     1  11.2
>> # 2     b     f     j     2  12.2
>> # 3     c     g     k     3  13.2
>> # 4     d     h     l     4  14.2
>> 
>> The workflow output columns can be a mix of a known set column outputs.  Some of the columns really should be converted to non-character types before I proceed. Right now I explictly set the column classes with something like this...
>> 
>> mode(x[['D']]) <- 'integer'
>> mode(x[['E']]) <- 'numeric'
>> 
>> # # A tibble: 4 ? 5
>> #       A     B     C     D     E
>> #   <chr> <chr> <chr> <int> <dbl>
>> # 1     a     e     i     1  11.2
>> # 2     b     f     j     2  12.2
>> # 3     c     g     k     3  13.2
>> # 4     d     h     l     4  14.2
>> 
>> 
>> I wonder if there is a way to use the read_* functions in the readr package to read the character matrix into a tibble directly which would leverage readr's excellent column class guessing. I can see in the vignette ( https://cran.r-project.org/web/packages/readr/vignettes/readr.html <https://cran.r-project.org/web/packages/readr/vignettes/readr.html> ) that I'm not too far off in thinking this could be done (step 1 tantalizingly says 'The flat file is parsed into a rectangular matrix of strings.')
>> 
>> I know that I could either write the matrix to a file or paste it all into a character vector and then use read_* functions, but I confess I am looking for a straighter path by simply passing the matrix to a function like readr::read_matrix() or the like.
>> 
>> Thanks!
>> Ben
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org <http://www.bigelow.org/>
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From massimo.bressan at arpa.veneto.it  Fri Apr  7 16:02:22 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 7 Apr 2017 16:02:22 +0200 (CEST)
Subject: [R] average at specific hour "endpoints" of the day
In-Reply-To: <alpine.BSF.2.00.1704060858450.5422@pedal.dcn.davis.ca.us>
References: <314883398.18601927.1491468686554.JavaMail.zimbra@arpa.veneto.it>
 <alpine.BSF.2.00.1704060858450.5422@pedal.dcn.davis.ca.us>
Message-ID: <561296195.18908605.1491573742294.JavaMail.zimbra@arpa.veneto.it>

hi jeff

thank you for your code, there is lot to think about it...

In the meanwhile I've managed to work out a (sort of) solution but I'm still not completely satisfied with it

I would like to keep it all more elegant and possibly general

here it is, so far...

####

mydate<-seq(ISOdatetime(2017,1, 1, 0, 0, 0), by="hour", length.out = 48)
v1<-1:48
mydf<-data.frame(mydate,v1)

library(zoo)

z<-zoo(mydf[,-1], mydf[,1])

z8<-rollapply(z, width=8, FUN=mean, align="right")
iz8<-which(as.numeric(strftime(index(z8), '%H'))==6)
z8<-z8[iz8]

z16<-rollapply(z, width=16, FUN=mean, align="right")
iz16<-which(as.numeric(strftime(index(z16), '%H'))==22)
z16<-z16[iz16]

fortify.zoo(z16)
fortify.zoo(z8)

#and then any sort of manipulation with dataframes

####

bye

----- Messaggio originale -----
Da: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
Cc: "r-help" <r-help at r-project.org>
Inviato: Gioved?, 6 aprile 2017 18:19:29
Oggetto: Re: [R] average at specific hour "endpoints" of the day

On Thu, 6 Apr 2017, Massimo Bressan wrote:

> hello
>
> given my reproducible example
>
> #---
> date<-seq(ISOdate(2017,1, 1, 0), by="hour", length.out = 48)
> v1<-1:48
> df<-data.frame(date,v1)
>
> #--

"date" and "df" are functions in base R... best to avoid hiding them by 
re-using those names in the global environment

ISOdate forces GMT, which many data sets that you might work with do NOT 
use. It is better to use ISOdatetime to avoid letting hidden code 
determine the timezone that is applied to (or compared with) your data.

>
> I need to calculate the average of variable v1 at specific hour "endpoints" of the day: i.e. at hours 6.00 and 22.00 respectively
>
> the desired result is
>
> date v1
> 01/01/17 22:00 15.5
> 02/01/17 06:00 27.5
> 02/01/17 22:00 39.5
>
> at hour 06:00 of each day the average is calculated by considering the 8 previous records (hours from 23:00 to 6:00)
> at hour 22:00 of each day the average is calculated by considering the 16 previous records (hours from 7:00 to 22:00)
>
> any hint please?
>
> I've been trying with some functions within the "xts" package but withouth much result...

I am not sure how I would do this with xts, but the below code is one 
fairly literal approach (implemented two ways) to translate your 
requirements that is also potentially extensible if the data or 
requirements change.

### Base R....

Sys.setenv( TZ = "Etc/GMT+5" ) # selected arbitrarily here but not left to
                                # the system to decide
dta <- data.frame( datetime = seq( ISOdatetime( 2017,1, 1, 0, 0, 0 )
                                  , by="hour"
                                  , length.out = 48
                                  )
                  , v1 = 1:48
                  )
dta$nrec <- 1
dta$date <- as.POSIXct( trunc.POSIXt( dta$datetime, units="days" ) )
dta$tod <- as.numeric( dta$datetime - dta$date, units = "hours" )
dta$timeslot <- factor( ifelse( 6 < dta$tod & dta$tod <= 22
                               , "Day"
                               , "Night"
                               )
                       , levels = c( "Night", "Day" )
                       )
dta$slotdatetime <- dta$date + as.difftime( ifelse( "Day" == dta$timeslot
                                                   , 22
                                                   , ifelse( 22 < dta$tod
                                                           , 24+6
                                                           , 6
                                                           )
                                                   )
                                           , units="hours"
                                           )
dta2 <- aggregate( dta[ , c( "v1", "nrec" ) ]
                  , dta[ , c( "timeslot", "slotdatetime" ), drop=FALSE ]
                  , FUN = sum
                  )
dta2 <- subset( dta2, nrec == ifelse( "Day"==timeslot, 16, 8 ) )
dta2$v1mean <- dta2$v1 / dta2$nrec

#### or if you don't mind the tidyverse....

library(dplyr) # wonderland of non-standard evaluation... beware, Alice!
Sys.setenv( TZ = "Etc/GMT+5" ) # selected arbitrarily here but not left to
                                # the system to decide
dta <- data.frame( datetime = seq( ISOdatetime( 2017,1, 1, 0, 0, 0 )
                                  , by="hour"
                                  , length.out = 48
                                  )
                  , v1 = 1:48
                  )
dta2 <- (   dta
         %>% mutate( date = as.POSIXct( trunc.POSIXt( datetime
                                                    , units="days"
                                                    )
                                      )
                   , tod = as.numeric( datetime - date, units = "hours" )
                   , timeslot = factor( ifelse( 6 < tod & tod <= 22
                                              , "Day"
                                              , "Night"
                                              )
                                      , levels = c( "Night", "Day" )
                                      )
                   , slotdatetime = date +
                            as.difftime( ifelse( "Day" == timeslot
                                               , 22
                                               , ifelse( 22 < tod
                                                       , 24+6
                                                       , 6
                                                       )
                                               )
                                       , units="hours"
                                       )
                   )
         %>% group_by( slotdatetime, timeslot )
         %>% summarise( v1mean = mean( v1 )
                      , nrec = n()
                      )
         %>% filter( nrec == ifelse( "Day"==timeslot, 16, 8 ) )
         )




> thanks for the help
> 	[[alternative HTML version deleted]]

This is a plain-text mailing list. Your chances of communicating 
successfully when you post HTML format email are much worse than if you 
post plain text using the "plain text" option in your mail program.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From vito.muggeo at unipa.it  Fri Apr  7 17:03:05 2017
From: vito.muggeo at unipa.it (Vito Michele Rosario Muggeo)
Date: Fri, 07 Apr 2017 15:03:05 +0000
Subject: [R] Piecewise continuous Poisson regression
In-Reply-To: <BLUPR03MB486C1CB88F954140F8C9660E20D0@BLUPR03MB486.namprd03.prod.outlook.com>
Message-ID: <20170407150305.Horde.nHCJP4AeGJjGWnU6_stpHj6@webmail.unipa.it>

dear John,
The package segmented can help you. ?plot.segmented includes a Poisson example

best,
vito




"Sorkin, John" <jsorkin at som.umaryland.edu> ha scritto:

> Is there an R package that will perform a piecewise continuous  
> Poisson regression? I want to model two linear segments that  
> intersect at a common knot.
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology  
> and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Apr  7 17:13:26 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 07 Apr 2017 08:13:26 -0700
Subject: [R] difference metric info of same font on different device
In-Reply-To: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
References: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
Message-ID: <5F93881C-258C-41C6-A704-2B2206C7594C@dcn.davis.ca.us>

I think it is a fundamental characteristic of graphics drivers that output will look different in the details... you are on a wild goose chase. Postscript in particular has a huge advantage in font presentation over other graphics output mechanisms. 
-- 
Sent from my phone. Please excuse my brevity.

On April 7, 2017 1:05:45 AM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>Hi there,
>
>I try to plot with custom fonts, which have good shape Latin and CJK 
>characters. I set up all the fonts correctly. However, when I plot the 
>same code on png() and postscript(), I get different result. The main 
>problem is the space between characters is narrower in postscript()
>than 
>that in png(), and some character also overlap in postscript().  You
>can 
>see the differences from the attached png files.
>
>Is there any way to get the same plot using postscript() and png()? 
>Thanks in advance.
>
>Best,
>Jinsong
>
>The code I used is here:
>
>windowsFonts(song = windowsFont("SourceHanSerifSC-Regular"),
>              hei  = windowsFont("SourceHanSansSC-Regular"),
>              hwhei  = windowsFont("SourceHanSansHWSC-Regular"),
>              fzsong  = windowsFont("FZShuSong-Z01"),
>              fzhei = windowsFont("FZHei-B01"))
>
>postscriptFonts(song = CIDFont("SourceHanSerifSC-Regular", 
>"UniSourceHanSerifCN-UTF8-H", "UTF-8", ""),
>                 hei  = CIDFont("SourceHanSansSC-Regular", 
>"UniSourceHanSansCN-UTF8-H", "UTF-8", ""),
>                 hwhei  = CIDFont("SourceHanSansHWSC-Regular", 
>"UniSourceHanSansHWCN-UTF8-H", "UTF-8", ""),
>                 fzsong  = CIDFont("FZShuSong-Z01",    "GBK-EUC-H", 
>"GBK", ""),
>                 fzhei = CIDFont("FZHei-B01", "GBK-EUC-H", "GBK", ""))
>
>fa <- c("sans", "serif", "song", "hei", "hwhei", "fzsong", "fzhei")
>
>postscript("font.eps", fonts = fa, onefile = FALSE, width = 4, height =
>
>4, horizontal = FALSE)
>
>#png("font.png", width=4*300, height=4*300, res =300)
>
>plot(0,xlab="",ylab="",type="n")
>text(1, -0.75, expression(CO[2]-Hei), family = "hei")
>text(1, -0.5, expression(CO[2]-HWHei), family = "hwhei")
>text(1, -0.25, expression(CO[2]-FZHei), family = "fzhei")
>text(1, 0.0, expression(CO[2]-Sans), family = "sans")
>text(1, 0.25, expression(CO[2]-FZSong), family = "fzsong")
>text(1, 0.5, expression(CO[2]-Song), family = "song")
>text(1, 0.75, expression(CO[2]-Serif), family = "serif")
>
>dev.off()


From jdnewmil at dcn.davis.ca.us  Fri Apr  7 17:50:33 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 7 Apr 2017 08:50:33 -0700 (PDT)
Subject: [R] list with element "Class 'Date' num"
In-Reply-To: <9b527595-de93-435e-bbee-a12cb888157e@googlegroups.com>
References: <9b527595-de93-435e-bbee-a12cb888157e@googlegroups.com>
Message-ID: <alpine.BSF.2.00.1704070830540.81503@pedal.dcn.davis.ca.us>

On Thu, 6 Apr 2017, Tintin wrote:

> Hi
>
> How do I create an element with specificiation " Class 'Date' num "
>
> The problem arises when I try to construct my own data structure set in the
> "termstrc" package. The model list should look like:
>
> R> str(govbonds$GERMANY)
> List of 8
> $ ISIN
> : chr [1:52] "DE0001141414" "DE0001137131" "DE0001141422" ...
> $ MATURITYDATE:Class ' Date ' num [1:52] 13924 13952 13980 14043 ...
> $ ISSUEDATE
> :Class ' Date ' num [1:52] 11913 13215 12153 13298 ...
> $ COUPONRATE : num [1:52] 0.0425 0.03 0.03 0.0325 ...
> $ PRICE
> : num [1:52] 100 99.9 99.8 99.8 ...
> $ ACCRUED
> : num [1:52] 4.09 2.66 2.43 2.07 ...
> $ CASHFLOWS
> :List of 3
> ..$ ISIN: chr [1:384] "DE0001141414" "DE0001137131" "DE0001141422" ...
> ..$ CF : num [1:384] 104 103 103 103 ...
> ..$ DATE:Class ' Date ' num [1:384] 13924 13952 13980 14043 ...
> $ TODAY
> :Class ' Date ' num 13908
>
> I am trying to create my own basis data.I can create list elements of the
> type "Date", but not of type " Class 'Date' num ".

a) Date objects are numeric, so this does not seem so far off target.

b) I do not get the same output from str() as you do.

#########################
> library(termstrc)
> data("govbonds")
> str(govbonds$GERMANY)
List of 8
  $ ISIN        : chr [1:52] "DE0001141414" "DE0001137131" "DE0001141422" 
"DE0001137149" ...
  $ MATURITYDATE: Date[1:52], format: "2008-02-15" "2008-03-14" 
"2008-04-11" "2008-06-13" ...
  $ ISSUEDATE   : Date[1:52], format: "2002-08-14" "2006-03-08" 
"2003-04-11" "2006-05-30" ...
  $ COUPONRATE  : num [1:52] 0.0425 0.03 0.03 0.0325 0.0413 ...
  $ PRICE       : num [1:52] 100 99.9 99.8 99.8 100.1 ...
  $ ACCRUED     : num [1:52] 4.09 2.66 2.43 2.07 2.39 ...
  $ CASHFLOWS   :List of 3
   ..$ ISIN: chr [1:384] "DE0001141414" "DE0001137131" "DE0001141422" 
"DE0001137149" ...
   ..$ CF  : num [1:384] 104 103 103 103 104 ...
   ..$ DATE: Date[1:384], format: "2008-02-15" "2008-03-14" "2008-04-11" 
"2008-06-13" ...
  $ TODAY       : Date[1:1], format: "2008-01-30"
####################

c) I observe that your output has "Class ' Date ' num", not " Class 'Date' 
num ". This suggests there might be something going on with your character 
encoding of the class name, but that could be in your email creation steps 
rather than in R. Or, it could be related to a bug in the package or in 
R... but you will need to give more info to convince anyone of those 
possibilities.

d) You may just need to update R or your packages. My configuration for 
this test was:

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 
LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C 
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] termstrc_1.3.7

loaded via a namespace (and not attached):
  [1] zoo_1.7-14      sandwich_2.3-4  tools_3.3.3     Rcpp_0.12.10 
nlme_3.1-131    urca_1.3-0
  [7] grid_3.3.3      lmtest_0.9-35   rgl_0.93.996    lattice_0.20-35


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Fri Apr  7 18:29:31 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 7 Apr 2017 09:29:31 -0700 (PDT)
Subject: [R] Add local image as inline embedded Image
In-Reply-To: <CAJ7HxBzPaKn-051k+dAqrVAMP=j+aDyR6x6hv4g06fKMLoVY9A@mail.gmail.com>
References: <CAJ7HxBz1LqwuV-_GKnSpxRSK5gpjHBa=-E6vhUv+feMik9dtkw@mail.gmail.com>
 <CAJ7HxBwkddwHD9CYEHU8wxKqabti9ZhW9LOHLV_P_wBLam0sJQ@mail.gmail.com>
 <CAJ7HxBxDxy1xoZAkU325Dwm21F7VL=Q06XRk_1TqU4puNAJDpg@mail.gmail.com>
 <CAJ7HxBzsrUTzNuZfrSJafGwsZ91YFjZRv_Lk7fJt5fhLx7tkYQ@mail.gmail.com>
 <CAJ7HxBy_UT4TBSdn_i6KQ=Kh7xK=7eMwEEzypwgc7KGLnvow+Q@mail.gmail.com>
 <CAJ7HxBzPaKn-051k+dAqrVAMP=j+aDyR6x6hv4g06fKMLoVY9A@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1704070914210.81503@pedal.dcn.davis.ca.us>

a) The email I am replying to should have been a reply to your original 
email [1]... it is not a complete picture of your problem, and you are not 
maintaining a thread of conversation.

b) I don't compose emails in R so I don't know what R package(s) you 
should use/look for. I recommend package "sos" or Google.

c) You need to spend some time learning how email works so you will 
understand what the email body needs to look like when you have finished 
constructing it (e.g. [2]). Study the MIME format [3]. If a package 
doesn't exist that helps, you can at least construct it yourself by 
pasting together the various pieces, but this is not the right forum to be 
asking questions about MIME.

[1] https://stat.ethz.ch/pipermail/r-help/2017-March/445787.html

[2] 
http://stackoverflow.com/questions/4018709/how-to-create-an-email-with-embedded-images-that-is-compatible-with-the-most-mai

[3] https://en.wikipedia.org/wiki/MIME


On Fri, 7 Apr 2017, Archit Soni wrote:

> Hi All,
>
> I am using mailR package to send emails by attaching my local image files.
> However the image still refers to my file location and never truly embeds
> the image in the email.
>
> This came up in testing when my colleague was getting a red cross instead
> of an image.
>
> Any thoughts to resolve this?
> Thanks,
> A
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From Achim.Zeileis at R-project.org  Fri Apr  7 13:58:37 2017
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Fri, 7 Apr 2017 13:58:37 +0200 (CEST)
Subject: [R] Piecewise continuous Poisson regression
In-Reply-To: <BLUPR03MB486C1CB88F954140F8C9660E20D0@BLUPR03MB486.namprd03.prod.outlook.com>
References: <BLUPR03MB486C1CB88F954140F8C9660E20D0@BLUPR03MB486.namprd03.prod.outlook.com>
Message-ID: <alpine.DEB.2.20.1704071357500.17047@paninaro>

On Fri, 7 Apr 2017, Sorkin, John wrote:

> Is there an R package that will perform a piecewise continuous Poisson 
> regression? I want to model two linear segments that intersect at a 
> common knot.

The "segmented" package implements such broken stick regressions based on 
either "lm" or "glm" models. The latter include Poisson regression.

> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Matthias.Kohl at stamats.de  Fri Apr  7 21:26:55 2017
From: Matthias.Kohl at stamats.de (Prof. Dr. Matthias Kohl)
Date: Fri, 7 Apr 2017 21:26:55 +0200
Subject: [R] Paired sample t-test with mi.t.test
In-Reply-To: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>
References: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>
Message-ID: <4aabf597-9947-8a26-66ec-3961ee5d25e6@stamats.de>

Dear Joel,

are you trying to apply function mi.t.test from my package MKmisc?

Could you please try:
mi.t.test(implist, "pre_test", "post_test", alternative =
"greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)

x and y are the names of the variables, not the variables themselves.

Best
Matthias

Am 06.04.2017 um 18:32 schrieb Joel Gagnon:
> Dear all,
>
> It is my first time posting on this list so forgive me for any rookie
> mistakes I could make.
>
> I want to conduct t-tests on a dataset that has been imputed using the mice
> package:
> imput_pps <- mice(pps, m=20, maxit=20, meth='pmm') # pps is my dataset. It
> contains items from an 11-item questionnaire gather at pre and post test.
> So the data set has 22 columns.
>
> I then proceed to compute the total scores for the pre and post test on my
> imputed datasets:
>
> long_pps <- complete(imput_pps, action ="long", include = TRUE)
> long_pps$pre_test <- rowSums(long_pps[ ,c(3:13)])
> long_pps$post_test <- rowSums(long_pps[ , c(14:24)])
>
> I then used as.mids to convert back to mids object:
> mids_pps <- as.mids(long_pps)
>
> Next, I created an imputation list object using mitools:
> implist <- lapply(seq(mids_pps$m), function(im) complete(mids_pps, im))
> implist <- imputationList(implist)
>
> Now, I want to conduct t-tests using the mi.t.test package. I tried the
> following code:
> mi.t.test(implist, implist$pre_test, implist$post_test, alternative =
> "greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)
>
> When I run this code, R tells me that Y is missing. I know this may sound
> stupid, but I thought that I specified Y with this line: implist$pre_test,
> implist$post_test - with implist$pre_test being X and implist$post_test
> being Y - like I usually do for a normal t-test using the t.test function.
>
> It seems I don't quite understand what the Y variable is supposed to
> represent. Could someone help me figure out what I am doing wrong? You
> help would be very much appreciated.
>
> Best regards,
>
> Joel Gagnon, Ph.D(c),
> Department of Psychology,
> Universit? du Qu?bec ? Trois-Rivi?res
> Qu?bec, Canada
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Prof. Dr. Matthias Kohl
www.stamats.de


From macqueen1 at llnl.gov  Sat Apr  8 00:19:08 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 7 Apr 2017 22:19:08 +0000
Subject: [R] Is there a way to get R script line number
In-Reply-To: <CAGxFJbS9GwZWU+mVQ5w=nsktbv3vbksfzQ-pv5OxEu_diau6vw@mail.gmail.com>
References: <CAMAcwjz+mZ4RHX5hhj-2r8V=4KrRjSk5t6souWzYdYna7Z6J-A@mail.gmail.com>
 <CAGxFJbS9GwZWU+mVQ5w=nsktbv3vbksfzQ-pv5OxEu_diau6vw@mail.gmail.com>
Message-ID: <BD10289D-BAA0-4AE1-ACA2-5BED3ECE8EE9@llnl.gov>

Possible clarification/correction...(apologies in advance if I'm being redundant)

If I put the following four lines in a script whose file name is "junk.r":

log(3)
log(4)
log('a')
log(5)

then it generates an error message, as expected:

> source('junk.r')
Error in log("a") (from junk.r#3) : non-numeric argument to mathematical function

Note that the error message references the line number (correctly).

So there must be something somewhere that keeps track of the script's line numbers. Finding it, however, is more than I'm ready to tackle.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 4/6/17, 12:30 PM, "R-help on behalf of Bert Gunter" <r-help-bounces at r-project.org on behalf of bgunter.4567 at gmail.com> wrote:

    I believe the answer is: No. "Line number" is an ambiguous concept.
    Does it mean physical line on a display of a given width? a line of
    code demarcated by e.g. <CR> ; a step in the execution of script (that
    might display over several physical lines?)
    
    However, various IDE's have and display "line numbers," so you might
    try researching whichever one that you use.
    
    (Note: Correction/clarification requested if I am wrong on this).
    
    -- Bert
    
    
    Bert Gunter
    
    "The trouble with having an open mind is that people keep coming along
    and sticking things into it."
    -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    
    
    On Thu, Apr 6, 2017 at 11:59 AM, Brad P <bpschn01 at gmail.com> wrote:
    > Hello,
    >
    > Is there a way to get the current line number in an R script?
    >
    > As a silly example, if I have the following script and a function called
    > getLineNumber (suppose one exists!), then the result would be 3.
    >
    > 1 # This is start of script
    > 2
    > 3 print( getLineNumber() )
    > 4
    > 5 # End of script
    >
    > Thanks for any ideas!
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From macqueen1 at llnl.gov  Sat Apr  8 00:33:00 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 7 Apr 2017 22:33:00 +0000
Subject: [R] problems in vectors of dates_times
In-Reply-To: <352c69f0-0783-85fb-04a3-ba2f98a52b92@gvdnet.dk>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
 <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
 <352c69f0-0783-85fb-04a3-ba2f98a52b92@gvdnet.dk>
Message-ID: <18CCC67D-A744-4A7F-95F7-5E3D387BDE5F@llnl.gov>

I think a more illuminating inspection is this:

> attributes(A)
$class
[1] "POSIXct" "POSIXt" 

$tzone
[1] "UTC"

> attributes(B)
$class
[1] "POSIXct" "POSIXt" 

$tzone
[1] "UTC"

> attributes(C)
$class
[1] "POSIXct" "POSIXt" 

Note that the operation c(A,B) loses the $tzone attribute.

Note also that C[1] and A[1] are actually the same point in time -- my default time zone, PDT, is 7 hours behind UTC -- but they display differently, due to the different tzone attribute.
> C[1]
[1] "2013-03-27 23:00:00 PDT"
> A[1]
[1] "2013-03-28 06:00:00 UTC"

> A[1]==C[1]
[1] TRUE

Finally, if I do this:
attributes(C)$tzone <- attributes(A)$tzone

Then they display the same:
> C[1]
[1] "2013-03-28 06:00:00 UTC"
> A[1]
[1] "2013-03-28 06:00:00 UTC"

It's a tossup whether resetting the lost attribute is preferable to setting the system timezone.

Then there's the design question of whether the c() operation should lose the tzone attribute. In this case it would be nice if it didn't, but what should happen if we use c() on two objects with  different tzone attributed??

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 4/7/17, 12:48 AM, "R-help on behalf of Troels Ring" <r-help-bounces at r-project.org on behalf of tring at gvdnet.dk> wrote:

    Thanks a lot - good idea:
    
    I put
    
    Sys.setenv(TZ = "UTC")
    
    ahead of the code - solves the problem!
    
    Thanks a lot
    
    
    Den 07-04-2017 kl. 09:26 skrev Mark Leeds:
    > Hi Troels: This is off-list so as to not clog the list with my noise 
    > because my suggestion may not work. I really don't know that much
    > about time-zones. but.   I ran your code and it "worked" but all the 
    > times were correctly time stamped but they changed from UTC to GMT.
    > in time-zone. In your
    > case, they changed to something and the time got shifted it looks 
    > like. So, definitely it has to do with how your time-zones are set. In 
    > my .Rprofile, I have something.
    > Let me check. ... time passes .....  I have below in my .Rprofile. So 
    > my guess is that, if you want things to remain UTC, then put below
    > in your .Rprofile but change it from "GMT" to "UTC". Others may have 
    > different solutions but that might work. If you don't have that, then 
    > R decides what to use and I'm not sure how it decides.
    >
    > Sys.setenv(TZ = "GMT")
    >
    > #print("LOADING MASS LIBRARY")
    > #ibrary("MASS")
    > #print("LOADING LATTICE LIBRARY")
    > #library("lattice")
    >
    >
    >
    >
    > :~>
    >
    > On Fri, Apr 7, 2017 at 3:00 AM, Troels Ring <tring at gvdnet.dk 
    > <mailto:tring at gvdnet.dk>> wrote:
    >
    >     Thanks a lot - perhaps it is just understanding how times dates
    >     are handled, sorry to bother if that is just the case
    >
    >     C[1]==A[1]  # TRUE
    >
    >     but
    >
    >     C[1]
    >     [1] "2013-03-28 07:00:00 CET"
    >     A[1]
    >     [1] "2013-03-28 06:00:00 UTC"
    >
    >
    >
    >
    >
    >
    >     Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
    >
    >         Hi Troels,
    >
    >         I get no error. I think we need more information to be of any
    >         help.
    >
    >         Best wishes,
    >         Ulrik
    >
    >         On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk
    >         <mailto:tring at gvdnet.dk>> wrote:
    >
    >             Dear friends - I have further problems  handling
    >             dates_times, as
    >             demonstrated below where concatenating two formatted
    >             vectors of
    >             date_times results in errors.
    >             I wonder why this happens and what was wrong in trying to
    >             take these two
    >             vectors together
    >             All best wishes
    >             Troels Ring
    >             Aalborg, Denmark
    >             Windows
    >             R version 3.3.2 (2016-10-31)
    >
    >
    >             A <- structure(c(1364450400, 1364450400, 1364536800,
    >             1364623200,
    >             1364709600,
    >             1364796000, 1364882400, 1364968800, 1365055200,
    >             1365141600, 1365228000,
    >             1365314400, 1365400800), class = c("POSIXct", "POSIXt"),
    >             tzone = "UTC")
    >             A
    >             B <- structure(c(1365141600, 1365228000, 1365314400,
    >             1365400800,
    >             1365487200,
    >             1365573600, 1365660000, 1365746400, 1365832800,
    >             1365919200, 1366005600,
    >             1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
    >             B
    >             C <- c(A,B)
    >             C
    >
    >             ______________________________________________
    >             R-help at r-project.org <mailto:R-help at r-project.org> mailing
    >             list -- To UNSUBSCRIBE and more, see
    >             https://stat.ethz.ch/mailman/listinfo/r-help
    >             <https://stat.ethz.ch/mailman/listinfo/r-help>
    >             PLEASE do read the posting guide
    >             http://www.R-project.org/posting-guide.html
    >             <http://www.R-project.org/posting-guide.html>
    >             and provide commented, minimal, self-contained,
    >             reproducible code.
    >
    >                 [[alternative HTML version deleted]]
    >
    >         ______________________________________________
    >         R-help at r-project.org <mailto:R-help at r-project.org> mailing
    >         list -- To UNSUBSCRIBE and more, see
    >         https://stat.ethz.ch/mailman/listinfo/r-help
    >         <https://stat.ethz.ch/mailman/listinfo/r-help>
    >         PLEASE do read the posting guide
    >         http://www.R-project.org/posting-guide.html
    >         <http://www.R-project.org/posting-guide.html>
    >         and provide commented, minimal, self-contained, reproducible code.
    >
    >
    >     ______________________________________________
    >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
    >     To UNSUBSCRIBE and more, see
    >     https://stat.ethz.ch/mailman/listinfo/r-help
    >     <https://stat.ethz.ch/mailman/listinfo/r-help>
    >     PLEASE do read the posting guide
    >     http://www.R-project.org/posting-guide.html
    >     <http://www.R-project.org/posting-guide.html>
    >     and provide commented, minimal, self-contained, reproducible code.
    >
    >
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From rmh at temple.edu  Sat Apr  8 00:59:06 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 7 Apr 2017 18:59:06 -0400
Subject: [R] problems in vectors of dates_times
In-Reply-To: <18CCC67D-A744-4A7F-95F7-5E3D387BDE5F@llnl.gov>
References: <d8d00b7b-2167-8b3b-c3c7-ea962f074e89@gvdnet.dk>
 <fc23c89f-4037-c1db-cd1c-e48548c4e17b@gvdnet.dk>
 <352c69f0-0783-85fb-04a3-ba2f98a52b92@gvdnet.dk>
 <18CCC67D-A744-4A7F-95F7-5E3D387BDE5F@llnl.gov>
Message-ID: <CAGx1TMAnFA=w4cVFDp3315NcWyoK4e=TXgpHGDYx4tUijOeSTQ@mail.gmail.com>

Don asks a good question.  Here is the analogy from the grid package.

> library(grid)
> unit(12, "in")
[1] 12in
> unit(12, "cm")
[1] 12cm
> unit.c(unit(12, "in"), unit(12, "cm"))
[1] 12in 12cm
> c(unit(12, "in"), unit(12, "cm"))
[1] 12 12
> ?unit
> convertUnit(c(unit(12, "in"), unit(12, "cm")), "in")
Error in convertUnit(c(unit(12, "in"), unit(12, "cm")), "in") :
  'x' argument must be a unit object
> convertUnit(unit.c(unit(12, "in"), unit(12, "cm")), "in")
[1] 12in              4.7244094488189in
>

On Fri, Apr 7, 2017 at 6:33 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> I think a more illuminating inspection is this:
>
>> attributes(A)
> $class
> [1] "POSIXct" "POSIXt"
>
> $tzone
> [1] "UTC"
>
>> attributes(B)
> $class
> [1] "POSIXct" "POSIXt"
>
> $tzone
> [1] "UTC"
>
>> attributes(C)
> $class
> [1] "POSIXct" "POSIXt"
>
> Note that the operation c(A,B) loses the $tzone attribute.
>
> Note also that C[1] and A[1] are actually the same point in time -- my default time zone, PDT, is 7 hours behind UTC -- but they display differently, due to the different tzone attribute.
>> C[1]
> [1] "2013-03-27 23:00:00 PDT"
>> A[1]
> [1] "2013-03-28 06:00:00 UTC"
>
>> A[1]==C[1]
> [1] TRUE
>
> Finally, if I do this:
> attributes(C)$tzone <- attributes(A)$tzone
>
> Then they display the same:
>> C[1]
> [1] "2013-03-28 06:00:00 UTC"
>> A[1]
> [1] "2013-03-28 06:00:00 UTC"
>
> It's a tossup whether resetting the lost attribute is preferable to setting the system timezone.
>
> Then there's the design question of whether the c() operation should lose the tzone attribute. In this case it would be nice if it didn't, but what should happen if we use c() on two objects with  different tzone attributed??
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
> On 4/7/17, 12:48 AM, "R-help on behalf of Troels Ring" <r-help-bounces at r-project.org on behalf of tring at gvdnet.dk> wrote:
>
>     Thanks a lot - good idea:
>
>     I put
>
>     Sys.setenv(TZ = "UTC")
>
>     ahead of the code - solves the problem!
>
>     Thanks a lot
>
>
>     Den 07-04-2017 kl. 09:26 skrev Mark Leeds:
>     > Hi Troels: This is off-list so as to not clog the list with my noise
>     > because my suggestion may not work. I really don't know that much
>     > about time-zones. but.   I ran your code and it "worked" but all the
>     > times were correctly time stamped but they changed from UTC to GMT.
>     > in time-zone. In your
>     > case, they changed to something and the time got shifted it looks
>     > like. So, definitely it has to do with how your time-zones are set. In
>     > my .Rprofile, I have something.
>     > Let me check. ... time passes .....  I have below in my .Rprofile. So
>     > my guess is that, if you want things to remain UTC, then put below
>     > in your .Rprofile but change it from "GMT" to "UTC". Others may have
>     > different solutions but that might work. If you don't have that, then
>     > R decides what to use and I'm not sure how it decides.
>     >
>     > Sys.setenv(TZ = "GMT")
>     >
>     > #print("LOADING MASS LIBRARY")
>     > #ibrary("MASS")
>     > #print("LOADING LATTICE LIBRARY")
>     > #library("lattice")
>     >
>     >
>     >
>     >
>     > :~>
>     >
>     > On Fri, Apr 7, 2017 at 3:00 AM, Troels Ring <tring at gvdnet.dk
>     > <mailto:tring at gvdnet.dk>> wrote:
>     >
>     >     Thanks a lot - perhaps it is just understanding how times dates
>     >     are handled, sorry to bother if that is just the case
>     >
>     >     C[1]==A[1]  # TRUE
>     >
>     >     but
>     >
>     >     C[1]
>     >     [1] "2013-03-28 07:00:00 CET"
>     >     A[1]
>     >     [1] "2013-03-28 06:00:00 UTC"
>     >
>     >
>     >
>     >
>     >
>     >
>     >     Den 07-04-2017 kl. 08:27 skrev Ulrik Stervbo:
>     >
>     >         Hi Troels,
>     >
>     >         I get no error. I think we need more information to be of any
>     >         help.
>     >
>     >         Best wishes,
>     >         Ulrik
>     >
>     >         On Fri, 7 Apr 2017 at 08:17 Troels Ring <tring at gvdnet.dk
>     >         <mailto:tring at gvdnet.dk>> wrote:
>     >
>     >             Dear friends - I have further problems  handling
>     >             dates_times, as
>     >             demonstrated below where concatenating two formatted
>     >             vectors of
>     >             date_times results in errors.
>     >             I wonder why this happens and what was wrong in trying to
>     >             take these two
>     >             vectors together
>     >             All best wishes
>     >             Troels Ring
>     >             Aalborg, Denmark
>     >             Windows
>     >             R version 3.3.2 (2016-10-31)
>     >
>     >
>     >             A <- structure(c(1364450400, 1364450400, 1364536800,
>     >             1364623200,
>     >             1364709600,
>     >             1364796000, 1364882400, 1364968800, 1365055200,
>     >             1365141600, 1365228000,
>     >             1365314400, 1365400800), class = c("POSIXct", "POSIXt"),
>     >             tzone = "UTC")
>     >             A
>     >             B <- structure(c(1365141600, 1365228000, 1365314400,
>     >             1365400800,
>     >             1365487200,
>     >             1365573600, 1365660000, 1365746400, 1365832800,
>     >             1365919200, 1366005600,
>     >             1366092000), class = c("POSIXct", "POSIXt"), tzone = "UTC")
>     >             B
>     >             C <- c(A,B)
>     >             C
>     >
>     >             ______________________________________________
>     >             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     >             list -- To UNSUBSCRIBE and more, see
>     >             https://stat.ethz.ch/mailman/listinfo/r-help
>     >             <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >             PLEASE do read the posting guide
>     >             http://www.R-project.org/posting-guide.html
>     >             <http://www.R-project.org/posting-guide.html>
>     >             and provide commented, minimal, self-contained,
>     >             reproducible code.
>     >
>     >                 [[alternative HTML version deleted]]
>     >
>     >         ______________________________________________
>     >         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     >         list -- To UNSUBSCRIBE and more, see
>     >         https://stat.ethz.ch/mailman/listinfo/r-help
>     >         <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >         PLEASE do read the posting guide
>     >         http://www.R-project.org/posting-guide.html
>     >         <http://www.R-project.org/posting-guide.html>
>     >         and provide commented, minimal, self-contained, reproducible code.
>     >
>     >
>     >     ______________________________________________
>     >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     >     To UNSUBSCRIBE and more, see
>     >     https://stat.ethz.ch/mailman/listinfo/r-help
>     >     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >     PLEASE do read the posting guide
>     >     http://www.R-project.org/posting-guide.html
>     >     <http://www.R-project.org/posting-guide.html>
>     >     and provide commented, minimal, self-contained, reproducible code.
>     >
>     >
>
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhamlion78 at gmail.com  Sat Apr  8 02:41:58 2017
From: bhamlion78 at gmail.com (Leon Lee)
Date: Fri, 7 Apr 2017 20:41:58 -0400
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <CAJDdXgb_KrVAafOqOPkymh5cgQ+X=i-mWNQjjrd9Y95cUV+CJQ@mail.gmail.com>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
 <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
 <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
 <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>
 <b0d6a85d-69e1-104c-e2c2-3a9dd76f30a0@bath.edu>
 <CAJDdXgZ1UtYxpdNtHcyyiwfjXhHOuXmGFSbEAf8+2qy=HUpRJA@mail.gmail.com>
 <86cab2b2-af56-a25e-dbba-639145fe74fc@bath.edu>
 <CAJDdXgb_KrVAafOqOPkymh5cgQ+X=i-mWNQjjrd9Y95cUV+CJQ@mail.gmail.com>
Message-ID: <CAJDdXgabmuy5rcteCA2jdsdGxKGzGM-c4iF8SwHOgZ677ugJmw@mail.gmail.com>

Simon

I wonder whether I can take advantage of this thread and ask you another
related question. Now, I want to get the 95%CI of the fit and their
derivatives as well. For the original fitted curves, It is straightforward
as the option "type=terms" can be used to get the CI for the fixed effect.
Now, I want to get the CI for the fixed effect in the first derivative as
well. I tried to follow your example in the predict.gam() and got stuck
here:

%------------- predict.gam example-------------------------
    dat <- gamSim(1,n=300,scale=sig)
    b<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
     plot(b,pages=1)

     ## now evaluate derivatives of smooths with associated standard
     ## errors, by finite differencing...
     x.mesh <- seq(0,1,length=200) ## where to evaluate derivatives
     newd <- data.frame(x0 = x.mesh,x1 = x.mesh, x2=x.mesh,x3=x.mesh)
     X0 <- predict(b,newd,type="lpmatrix")

     eps <- 1e-7 ## finite difference interval
     x.mesh <- x.mesh + eps ## shift the evaluation mesh
     newd <- data.frame(x0 = x.mesh,x1 = x.mesh, x2=x.mesh,x3=x.mesh)
     X1 <- predict(b,newd,type="lpmatrix")

     Xp <- (X1-X0)/eps ## maps coefficients to (fd approx.) derivatives
     colnames(Xp)      ## can check which cols relate to which smooth

     par(mfrow=c(2,2))
     Xi <- Xp*0
     Xi[,1:9+1] <- Xp[,1:9+1] ## Xi%*%coef(b) = smooth deriv i
     df <- Xi%*%coef(b)              ## ith smooth derivative
     df.sd <- rowSums(Xi%*%b$Vp*Xi)^.5 ## cheap diag(Xi%*%b$Vp%*%t(Xi))^.5
%-----------------predict.gam example-----------------------

Am I right that df.sd is the standard error for the derivatives and I can
get the 95% CI by 1.96*df.sd? If so, is this the CI for the fixed effect or
fixed + random effects for the predictions that have random effects
modeled? as I mentioned earlier, my model includes both fixed and random
effects:
gamm1=gamm(BrainVolume~ s(correctedAge) + s(correctedAge, subjIndexF,
bs="fs", k=5), data=mydata)

For the newd in the predict(), I constructed a data frame with all the time
points for all subjects and fed it into the predict.gam() function. If I
only want to get the CI for the fixed effect only for the derivatives, what
should I change here?

Many thanks in advance!

L

On Thu, Apr 6, 2017 at 2:16 PM, Leon Lee <bhamlion78 at gmail.com> wrote:

> Hi, Simon
>
> Thank you for your explanation! I followed the instructions and
> successfully get the predicted values with both fixed and random effects
> incorporated: pred.new=predict.gam(gamm1$gam,newdata,type="response").
>
> Also, what I meant to say was "plot(gamm1$gam, pages=1)" for left and
> right figures. I didn't attach any figures.
>
> Thank you very much for the help!
> L
>
> On Thu, Apr 6, 2017 at 10:44 AM, Simon Wood <simon.wood at bath.edu> wrote:
>
>>
>> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re") +
>> s(subjIndexF, correctedAge, bs="re"), method="REML", data=mydata), where
>> subjIndexF is a factor for each subject. I was thrown an error saying "more
>> coefficients than data".
>>
>> --- I'm not sure exactly  how many scans and subjects you have. The above
>> model will have 10 + 2*(number of subjects ) coeffs. If that is more than
>> the number of scans then gam will not handle it. Depending on the numbers
>> involved you could reduce the k parameter to s(correctedAge), to fix the
>> problem. (e.g. with 31 subjects and 70 scans s(correctedAge=8) should
>> work).
>>
>> However, when I tried to model similar (please correct me if they are not
>> similar) things using GAMM based on description in
>> ?factor.smooth.interaction:
>>  gamm1=gamm(BrainVolume~ s(correctedAge) + s(correctedAge, subjIndexF,
>> bs="fs", k=5), data=mydata)
>>
>> --- It's not the same model. You now have a random smooth curve per
>> subject. You can add random effects in gamm using the list form of the
>> syntax for specifying random effects in lme. see ?gamm. Random intercepts
>> and slopes can be added that way.
>>
>> The model ran.  When I plotted the data using plot(gamm1), I got two
>> figures: the left one is the group mean and 95%CI, which I assume is the
>> results by gamm1$gam model. The right one shows 30 lines (the number of
>> subjects in my data) fluctuating around 0, which I assume is the random
>> effects (gamm1$lme) modeled within each subject that can be added onto the
>> group mean for individual curves. Is my understanding correct? If so, how
>> can I extract these curves from gamm1$lme?
>>
>> --- I would extract the fitted curves using predict(gamm1$gam,...,
>> type="terms") supplying the factor levels and correctedAges at which you
>> want to evaluate the curves.
>>
>> Many thanks!
>> L
>>
>>
>>
>> On Thu, Apr 6, 2017 at 8:22 AM, Simon Wood <simon.wood at bath.edu> wrote:
>>
>>> If 'subjIndexF' is a factor for subject, then s(subjIndexF, bs="re")
>>> will produce a random effect for subject. i.e. each subject will be given
>>> its own random intercept term, which is a way that repeated measures data
>>> like this are often handled.
>>>
>>> The reason for the s(subjIndexF, bs="re") syntax is that smooths can be
>>> viewed as Gaussian random effects, so simple Gaussian random effects can
>>> also be viewed as (0-dimensional) smooths. In general s(x,z,w,bs="re") just
>>> appends the columns of model.matrix(~x:z:w-1) to the gam model matrix, and
>>> treats the associated coefficients as i.i.d. Gaussian random effects with a
>>> common variance (to be estimated). In principle this works with any number
>>> of arguments to s(...,bs="re").
>>>
>>> See ?random.effects (and its linked help files) in mgcv for more.
>>>
>>> There are mechanisms for allowing random smooth curves for each subject,
>>> (e.g. ?factor.smooth.interaction), but I would only use these if simpler
>>> approaches really aren't adequate here.
>>>
>>> best,
>>> Simon
>>>
>>>
>>>
>>>
>>> On 30/03/17 17:06, David Winsemius wrote:
>>>
>>>> On Mar 30, 2017, at 6:56 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>>>>
>>>>> David
>>>>>
>>>>> Thank you for your reply. I apologize if I posted in the wrong forum,
>>>>> as I really couldn't decide which forum is the best place for my question
>>>>> and I saw similar questions asked before in this forum.
>>>>>
>>>>> I agree that a sample of ~30 subjects (70 scans in total), the model
>>>>> can be too complicated. Based on that, I did the following:
>>>>> (1) ignored the gender effect, as we have less females than males.
>>>>> (2) corrected chronological age based on their gestational age, that
>>>>> is, we subtracted an infant's chronological age by 2 weeks, if the infant's
>>>>> gestational age is 38 weeks instead of 40weeks.
>>>>>
>>>>> When I ran the model with corrected age, gestational age and their
>>>>> interactions modeled, I found the main effect of gestational age and the
>>>>> interaction between the two are gone.
>>>>>
>>>>> So, my final model will look something like this:
>>>>> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re"),
>>>>> method="REML", data=mydata)
>>>>>
>>>>> Does this look more reasonable?
>>>>>
>>>> I'm still having difficulty understand how a "smoothing" function would
>>>> be used to handle repeated measures without some sort of "group-within"
>>>> indicator.
>>>>
>>>> I would have imagined (and this is because I have no experience with
>>>> using this package for repeated measures) something along the lines of:
>>>>
>>>>   ...+s(correctedAg|subjIndexF)
>>>>
>>>> I see this statement in the docs:
>>>>
>>>>
>>>> smooth.construct.re.smooth.spec {mgcv}
>>>>
>>>> "gam can deal with simple independent random effects, by exploiting the
>>>> link between smooths and random effects to treat random effects as smooths.
>>>> s(x,bs="re") implements this."
>>>>
>>>> But I don't see that as applying to the dependency between individuals
>>>> measured repeatedly. I find no examples of repeated measures problems being
>>>> solve by gam(). There is also a note on the same page:
>>>>
>>>> "Note that smooth ids are not supported for random effect terms. Unlike
>>>> most smooth terms, side conditions are never applied to random effect terms
>>>> in the event of nesting (since they are identifiable without side
>>>> conditions)."
>>>>
>>>> When I do a search on "using gam mgcv formula mixed effects" I am
>>>> referred to packages 'gamm' and 'gamm4' produced by the same author (Simon
>>>> Wood) as pkg 'mgcv', or to package `nlme`.
>>>>
>>>>
>>>> Yes, I am relatively new to the mixed model. We originally applied
>>>>> functional data analysis (PACE) on the data, but want to see the results
>>>>> using a different approach. Also, I couldn't find the Mixed Models list, do
>>>>> you mind sending me a link?
>>>>>
>>>> This is a link to the main mailing lists page:
>>>>
>>>> https://www.r-project.org/mail.html
>>>>
>>>> Found with a search on Google with "R mailing lists"
>>>>
>>>>
>>>> Thank you!
>>>>> Longchuan
>>>>>
>>>>>
>>>>> On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius <
>>>>> dwinsemius at comcast.net> wrote:
>>>>>
>>>>> On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
>>>>>>
>>>>>> Hi, R experts
>>>>>>
>>>>>> I am new to R & GAM toolbox and would like to get inputs from you all
>>>>>> on my
>>>>>> models. The question I have is as follows:
>>>>>> I have 30 subjects with each subject being scanned from one to three
>>>>>> times
>>>>>> in the first year of life. The brain volume from each scan was
>>>>>> measured.
>>>>>> The scan time was randomly distributed from birth to 1 year.
>>>>>> Each subject has different gestational age ranging from 38 to 41 weeks
>>>>>> Each subject has chronological age from birth to 1 year old
>>>>>> Each subject has gender category.
>>>>>> Now, I want to look at how predictors, such as subject's
>>>>>> chronological age,
>>>>>> gestational age and gender will explain the changes in brain volume.
>>>>>> I also
>>>>>> want to include interactions between gender and age, gestational and
>>>>>> chronological age. Random effects are also included in the model to
>>>>>> account
>>>>>> for subject variability. My model looks like the follows:
>>>>>>
>>>>>> gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) +
>>>>>> gestationalAge +
>>>>>> sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML",
>>>>>> data=mydata)
>>>>>>
>>>>>> Are there any obvious mistakes in the model? Any suggestions will be
>>>>>> greatly appreciated!
>>>>>>
>>>>> I'm not seeing mistakes in the syntax but I would question whether 30
>>>>> subjects is sufficient to adequately support estimates in a a model of this
>>>>> complexity. I would also think that the 's(age)' and 'sex' terms would get
>>>>> aliased out in a model with "+ s(age, by=sex)". Most R regression functions
>>>>> handle removal of over-parametrization automatically.
>>>>>
>>>>> You also have a variable number of measurements per subject. I am
>>>>> unable to comment on the effort to account for the implicit and variably
>>>>> measured correlation and auto-correlation of values within subjects using a
>>>>> "smooth" on subjIndexF, since that is not an approach I was familiar with.
>>>>> But I am getting concerned whether you are also new to statistical modeling
>>>>> in addition to your use of R and GAM being "new to you"?
>>>>>
>>>>> (Perhaps Simon or one of the mixed-effects experts can correct the
>>>>> gaps in my understanding of how to model repeated measures in the context
>>>>> of small numbers of subjects and irregular emasurements.)
>>>>>
>>>>> Please read the Posting Guide and the pages of candidate mailing
>>>>> lists. Rhelp is not really the place to go when you need statistical
>>>>> advice. I'm not sure if this is really in the center of concerns that get
>>>>> discussed on the Mixed Models list, but to my eyes it would be a better fit
>>>>> there.
>>>>>
>>>>> --
>>>>> David.
>>>>>
>>>>>> L
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>>> ng-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>>>
>>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>>> +44 (0)117 33 18273 <%2B44%20%280%29117%2033%2018273>
>>> http://www.maths.bris.ac.uk/~sw15190
>>>
>>>
>>
>>
>> --
>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>>
>>
>

	[[alternative HTML version deleted]]


From G.Maubach at gmx.de  Sat Apr  8 09:04:00 2017
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Sat, 8 Apr 2017 09:04:00 +0200
Subject: [R] Archive format
In-Reply-To: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
Message-ID: <trinity-6620bce2-ae65-4c8a-b8df-4e311c506e63-1491418150499@3capp-gmx-bs47>

Hi Joe,

I have read your question with great interest. I am a little bit astonished to read about your project. There is a big national institute in Germany called GESIS (https://de.wikipedia.org/wiki/GESIS_%E2%80%93_Leibniz-Institut_f%C3%BCr_Sozialwissenschaften) which does the same job you are trying to set-up since 1986 now. You could try to exchange ideas with them.

Your subject is very complex with regard to reproducible research. You might want to have a look at

(1) https://cran.r-project.org/web/views/ReproducibleResearch.html
(2) Gandrud, Christopher: Reproducible Research with R and R Studio (https://www.amazon.com/Reproducible-Research-Studio-Second-Chapman/dp/1498715370)

Kind regards

Georg

> Gesendet: Mittwoch, 29. M?rz 2017 um 10:44 Uhr
> Von: "Joe Gain" <joe.gain at uni-konstanz.de>
> An: R-help at r-project.org
> Cc: bwfdm-info at lists.kit.edu
> Betreff: [R] Archive format
>
> Hello,
> 
> we are collecting information on the subject of research data management 
> in German on the webplatform:
> 
> www.forschungsdaten.info
> 
> One of the topics, which we are writing about, is how to *archive* data. 
> Unfortunately, none of us in the project is an expert with respect to R 
> and so I would like to ask the list, what they recommend? A related 
> question is to do with the sharing of data. We have already asked some 
> academics, who have basically replied that they don't really know other 
> than to strongly recommend a plain text format.
> 
> We would also like to know, if members of the list recommend converting 
> formats from commercial software such as S-Plus, Terr, SPSS etc. to an 
> R-compatible format for long term archivation? Are there any general 
> rules and best practices, when it comes to archiving (and sharing) 
> statistical data and statistical programs?
> 
> Any comments would be much appreciated!
> Joe
> 
> -- 
> B 1003
> Kommunikations-, Informations-, Medienzentrum (KIM)
> Universitaet Konstanz
> 
> t: ++49-7531-883234
> e: joe.gain at uni-konstanz.de
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mcardeal at ufba.br  Sat Apr  8 13:16:20 2017
From: mcardeal at ufba.br (Mauricio Cardeal)
Date: Sat, 8 Apr 2017 08:16:20 -0300
Subject: [R] Code to construct table with paired data
Message-ID: <8437bad0-e5e6-0ddb-47aa-4f5a3c2979ef@ufba.br>

Hi!

Is it possible to automatically construct a table like this:

#                        treat B
#                       improvement
#                         +       -
#treat A improvement  +   1       3
#                     -   2       1

 From these data:

pair  <- c(1,1,2,2,3,3,4,4,5,5,6,6,7,7)  # identification
treat <- c(1,0,1,0,1,0,1,0,1,0,1,0,1,0) # treatament 1 (A) or 0 (B)
impr  <- c(1,0,1,0,1,0,0,1,0,1,0,0,1,1) # improvement 1 (yes) 0 (no)

treatfac <- factor(treat)
levels(treatfac)<-list("A"=1,"B"=0 )
imprfac <- factor(impr)
levels(imprfac)<-list("+"=1,"-"=0)

data.frame(pair,treatfac,imprfac)

    pair treatfac imprfac

1     1      A     +
2     1      B     -
3     2      A     +
4     2      B     -
5     3      A     +
6     3      B     -
7     4      A     -
8     4      B     +
9     5      A     -
10    5      B     +
11    6      A     -
12    6      B     -
13    7      A     +
14    7      B     +

I tried some functions like table or even xtabs, but the results doesn't 
show the pairs combinations.


Thanks in advance,


Maur?cio Cardeal

Federal University of Bahia, Brazil




	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Apr  8 14:11:01 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 8 Apr 2017 14:11:01 +0200
Subject: [R] Code to construct table with paired data
In-Reply-To: <8437bad0-e5e6-0ddb-47aa-4f5a3c2979ef@ufba.br>
References: <8437bad0-e5e6-0ddb-47aa-4f5a3c2979ef@ufba.br>
Message-ID: <9C2D9947-AAE1-4AFC-BDE1-AB325D7ED7D5@gmail.com>

Here's one way:

> ddw <- reshape(dd, direction="wide", idvar="pair", timevar="treatfac")
> names(ddw)
[1] "pair"      "imprfac.A" "imprfac.B"
> xtabs(~ imprfac.A + imprfac.B, ddw)
         imprfac.B
imprfac.A + -
        + 1 3
        - 2 1

(reshape() is a bit of a pain to wrap one's mind around; possibly, the tidyversalists can come up with something easier.)

With a bit stronger assumptions on the data set (all pairs complete and in same order for both treatments), there is also

> table(A=imprfac[treatfac=="A"], B=imprfac[treatfac=="B"])
   B
A   + -
  + 1 3
  - 2 1



> On 08 Apr 2017, at 13:16 , Mauricio Cardeal <mcardeal at ufba.br> wrote:
> 
> Hi!
> 
> Is it possible to automatically construct a table like this:
> 
> #                        treat B
> #                       improvement
> #                         +       -
> #treat A improvement  +   1       3
> #                     -   2       1
> 
> From these data:
> 
> pair  <- c(1,1,2,2,3,3,4,4,5,5,6,6,7,7)  # identification
> treat <- c(1,0,1,0,1,0,1,0,1,0,1,0,1,0) # treatament 1 (A) or 0 (B)
> impr  <- c(1,0,1,0,1,0,0,1,0,1,0,0,1,1) # improvement 1 (yes) 0 (no)
> 
> treatfac <- factor(treat)
> levels(treatfac)<-list("A"=1,"B"=0 )
> imprfac <- factor(impr)
> levels(imprfac)<-list("+"=1,"-"=0)
> 
> data.frame(pair,treatfac,imprfac)
> 
>    pair treatfac imprfac
> 
> 1     1      A     +
> 2     1      B     -
> 3     2      A     +
> 4     2      B     -
> 5     3      A     +
> 6     3      B     -
> 7     4      A     -
> 8     4      B     +
> 9     5      A     -
> 10    5      B     +
> 11    6      A     -
> 12    6      B     -
> 13    7      A     +
> 14    7      B     +
> 
> I tried some functions like table or even xtabs, but the results doesn't 
> show the pairs combinations.
> 
> 
> Thanks in advance,
> 
> 
> Maur?cio Cardeal
> 
> Federal University of Bahia, Brazil
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mrguilfoyle at gmail.com  Sat Apr  8 16:24:48 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Sat, 8 Apr 2017 15:24:48 +0100
Subject: [R] mgcv gam/bam model selection with random effects and AR terms
References: <060C6D75-EE3C-49B5-9708-B4768E5DCEC2@gmail.com>
Message-ID: <87D9D695-951C-41DC-AC17-EDB906BD21FF@gmail.com>

Would be grateful for advice on gam/bam model selection incorporating random effects and autoregressive terms.

I have a multivariate time series recorded on ~500 subjects at ~100 time points.  One of the variables (A) is the dependent and four others (B to E) are predictors.  My basic formula is:

[model 1]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E))

I've then included a random intercept and a random effect for time as the pattern of A over time is highly variable across subjects.

[model 2]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E)+s(id, bs='re')+s(id,time, bs='re'))

I expect there is also potential for autocorrelation within the time series. So:

[model 3]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E)+s(id, bs='re')+s(id,time, bs='re'), AR.start = startindex, rho = 0.52)

The rho value of 0.52 was settled on by trial-and-error minimising fREML/ML (side question: am I correct in understanding that bam can only use a fixed rho rather than taking this as a value to optimise as in gamm?)

The lowest fREML or ML values are obtained by model 3 (71674 vs 72099) for model 2) but the highest adjusted R2/deviance explained is with model 2 (37.7 vs 42.1%).  Model 1 is inferior to both the others on all measures.

Is it better to select the model including the AR term given the lower ML or is it legitimate to go with the 'simpler' model 2 that has higher R2/deviance explained?

I am unable to provide a fully reproducible example as I don't know how to generate sample data with these specific characteristics.

Many thanks

From gagnonjoel24 at gmail.com  Sat Apr  8 16:53:53 2017
From: gagnonjoel24 at gmail.com (Joel Gagnon)
Date: Sat, 8 Apr 2017 10:53:53 -0400
Subject: [R] Paired sample t-test with mi.t.test
In-Reply-To: <4aabf597-9947-8a26-66ec-3961ee5d25e6@stamats.de>
References: <CAEaR0_1eUyAs8TpGe6JGr5gBO7tAM4PUq19+fbG9y4Z6Vn9AHQ@mail.gmail.com>
 <4aabf597-9947-8a26-66ec-3961ee5d25e6@stamats.de>
Message-ID: <CAEaR0_1GPW7hbBN1t=p1i8x4GnjmszjfR4LGy0ti7at8b1m+Ow@mail.gmail.com>

Dear Dr. Eichner and Dr. Kohl,

First, thank you for your response. I tried your code and R it worked
perfectly I just had to add: mi.t.test(implist*$imputation,* "pre_test",
"post_test", alternative = "greater", paired = TRUE, var.equal = TRUE,
conf.level = 0.95) for the code to run.

Thank you very much again for taking the time.
Best,
Joel

On Fri, Apr 7, 2017 at 3:26 PM, Prof. Dr. Matthias Kohl <
Matthias.Kohl at stamats.de> wrote:

> Dear Joel,
>
> are you trying to apply function mi.t.test from my package MKmisc?
>
> Could you please try:
> mi.t.test(implist, "pre_test", "post_test", alternative =
> "greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)
>
> x and y are the names of the variables, not the variables themselves.
>
> Best
> Matthias
>
> Am 06.04.2017 um 18:32 schrieb Joel Gagnon:
>
>> Dear all,
>>
>> It is my first time posting on this list so forgive me for any rookie
>> mistakes I could make.
>>
>> I want to conduct t-tests on a dataset that has been imputed using the
>> mice
>> package:
>> imput_pps <- mice(pps, m=20, maxit=20, meth='pmm') # pps is my dataset. It
>> contains items from an 11-item questionnaire gather at pre and post test.
>> So the data set has 22 columns.
>>
>> I then proceed to compute the total scores for the pre and post test on my
>> imputed datasets:
>>
>> long_pps <- complete(imput_pps, action ="long", include = TRUE)
>> long_pps$pre_test <- rowSums(long_pps[ ,c(3:13)])
>> long_pps$post_test <- rowSums(long_pps[ , c(14:24)])
>>
>> I then used as.mids to convert back to mids object:
>> mids_pps <- as.mids(long_pps)
>>
>> Next, I created an imputation list object using mitools:
>> implist <- lapply(seq(mids_pps$m), function(im) complete(mids_pps, im))
>> implist <- imputationList(implist)
>>
>> Now, I want to conduct t-tests using the mi.t.test package. I tried the
>> following code:
>> mi.t.test(implist, implist$pre_test, implist$post_test, alternative =
>> "greater", paired = TRUE, var.equal = TRUE, conf.level = 0.95)
>>
>> When I run this code, R tells me that Y is missing. I know this may sound
>> stupid, but I thought that I specified Y with this line: implist$pre_test,
>> implist$post_test - with implist$pre_test being X and implist$post_test
>> being Y - like I usually do for a normal t-test using the t.test function.
>>
>> It seems I don't quite understand what the Y variable is supposed to
>> represent. Could someone help me figure out what I am doing wrong? You
>> help would be very much appreciated.
>>
>> Best regards,
>>
>> Joel Gagnon, Ph.D(c),
>> Department of Psychology,
>> Universit? du Qu?bec ? Trois-Rivi?res
>> Qu?bec, Canada
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Prof. Dr. Matthias Kohl
> www.stamats.de
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Sat Apr  8 09:19:14 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sat, 8 Apr 2017 15:19:14 +0800
Subject: [R] difference metric info of same font on different device
In-Reply-To: <5F93881C-258C-41C6-A704-2B2206C7594C@dcn.davis.ca.us>
References: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
 <5F93881C-258C-41C6-A704-2B2206C7594C@dcn.davis.ca.us>
Message-ID: <530653cf-f8df-6b45-9fa7-f689c23f3a44@yeah.net>

On 2017/4/7 23:13, Jeff Newmiller wrote:
> I think it is a fundamental characteristic of graphics drivers that output will look different in the details... you are on a wild goose chase. Postscript in particular has a huge advantage in font presentation over other graphics output mechanisms.
>

Well, the problem stems from the MetricInfo of CID-keyed fonts, which 
are intended only for use for the glyphs of East Asian languages, which 
are all monospaced and are all treated as filling the same bounding box. 
(from the help page of CIDFont)

However, is it possible to use the same MetricInfo of CID-keyed fonts as 
that for png() or windows()?

Best,
Jinsong


From jszhao at yeah.net  Sat Apr  8 18:18:49 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sun, 9 Apr 2017 00:18:49 +0800
Subject: [R] difference metric info of same font on different device
In-Reply-To: <5F93881C-258C-41C6-A704-2B2206C7594C@dcn.davis.ca.us>
References: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
 <5F93881C-258C-41C6-A704-2B2206C7594C@dcn.davis.ca.us>
Message-ID: <041c6e38-e93f-67a3-dc6c-6a68bff8bdbd@yeah.net>

On 2017/4/7 23:13, Jeff Newmiller wrote:
> I think it is a fundamental characteristic of graphics drivers that output will look different in the details... you are on a wild goose chase. Postscript in particular has a huge advantage in font presentation over other graphics output mechanisms.
>

I agreed with your opinion on Postscript.

However, as shown in the attached plots in previous post, the glyph 
metric info for any CID-keyed font is based on assumption in R. In fact, 
it's not possible to get the metric info of a CID-keyed font without 
accessing the actual font which may be in truetype or opentype/CFF 
format. And, I don't think R could find the actual font.

Best,
Jinsong


From zhengda1936 at gmail.com  Sat Apr  8 19:40:13 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 8 Apr 2017 13:40:13 -0400
Subject: [R] change the R home directory
Message-ID: <CAFLer82PCwhEHb1OZCZawDQQ+=JrdiHUA0g_nWWujthOVkP-mg@mail.gmail.com>

Hello,

By default, the home directory of R is "/usr/lib/R" in Ubuntu.
Everything works fine.

However, when I installed Jupyter notebook and the R kernel with
anaconda2, it seems the R home directory is changed to some directory
in anaconda2. This messes up compilation and linking. I wonder how I
change the R home directory back to the default directory.

I tried to set R_HOME directly, When I start R, I see a warning message:
WARNING: ignoring environment value of R_HOME

I don't understand why R wants to ignore the environment value.
Of course, the R home directory isn't changed.
> R.home()
[1] "/home/zhengda/anaconda2/lib/R"

What is the right way of changing the R home directory?

Thanks,
Da


From jdnewmil at dcn.davis.ca.us  Sat Apr  8 20:10:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 08 Apr 2017 11:10:50 -0700
Subject: [R] change the R home directory
In-Reply-To: <CAFLer82PCwhEHb1OZCZawDQQ+=JrdiHUA0g_nWWujthOVkP-mg@mail.gmail.com>
References: <CAFLer82PCwhEHb1OZCZawDQQ+=JrdiHUA0g_nWWujthOVkP-mg@mail.gmail.com>
Message-ID: <09F7AE34-AF6B-45F6-A59C-B69BEC9FB99D@dcn.davis.ca.us>

Change to the desired directory before starting R.
-- 
Sent from my phone. Please excuse my brevity.

On April 8, 2017 10:40:13 AM PDT, Da Zheng <zhengda1936 at gmail.com> wrote:
>Hello,
>
>By default, the home directory of R is "/usr/lib/R" in Ubuntu.
>Everything works fine.
>
>However, when I installed Jupyter notebook and the R kernel with
>anaconda2, it seems the R home directory is changed to some directory
>in anaconda2. This messes up compilation and linking. I wonder how I
>change the R home directory back to the default directory.
>
>I tried to set R_HOME directly, When I start R, I see a warning
>message:
>WARNING: ignoring environment value of R_HOME
>
>I don't understand why R wants to ignore the environment value.
>Of course, the R home directory isn't changed.
>> R.home()
>[1] "/home/zhengda/anaconda2/lib/R"
>
>What is the right way of changing the R home directory?
>
>Thanks,
>Da
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mcardeal at ufba.br  Sat Apr  8 21:11:49 2017
From: mcardeal at ufba.br (Mauricio Cardeal)
Date: Sat, 8 Apr 2017 16:11:49 -0300
Subject: [R] Code to construct table with paired data
In-Reply-To: <9C2D9947-AAE1-4AFC-BDE1-AB325D7ED7D5@gmail.com>
References: <8437bad0-e5e6-0ddb-47aa-4f5a3c2979ef@ufba.br>
 <9C2D9947-AAE1-4AFC-BDE1-AB325D7ED7D5@gmail.com>
Message-ID: <6a3fa97a-adeb-0b3b-9378-e87ad8bccabe@ufba.br>

Thank you Peter!

Great solutions! That's exactly what I was looking for.

Maur?cio Cardeal


Em 08/04/2017 09:11, peter dalgaard escreveu:
> Here's one way:
>
>> ddw <- reshape(dd, direction="wide", idvar="pair", timevar="treatfac")
>> names(ddw)
> [1] "pair"      "imprfac.A" "imprfac.B"
>> xtabs(~ imprfac.A + imprfac.B, ddw)
>           imprfac.B
> imprfac.A + -
>          + 1 3
>          - 2 1
>
> (reshape() is a bit of a pain to wrap one's mind around; possibly, the tidyversalists can come up with something easier.)
>
> With a bit stronger assumptions on the data set (all pairs complete and in same order for both treatments), there is also
>
>> table(A=imprfac[treatfac=="A"], B=imprfac[treatfac=="B"])
>     B
> A   + -
>    + 1 3
>    - 2 1
>
>
>
>> On 08 Apr 2017, at 13:16 , Mauricio Cardeal <mcardeal at ufba.br> wrote:
>>
>> Hi!
>>
>> Is it possible to automatically construct a table like this:
>>
>> #                        treat B
>> #                       improvement
>> #                         +       -
>> #treat A improvement  +   1       3
>> #                     -   2       1
>>
>>  From these data:
>>
>> pair  <- c(1,1,2,2,3,3,4,4,5,5,6,6,7,7)  # identification
>> treat <- c(1,0,1,0,1,0,1,0,1,0,1,0,1,0) # treatament 1 (A) or 0 (B)
>> impr  <- c(1,0,1,0,1,0,0,1,0,1,0,0,1,1) # improvement 1 (yes) 0 (no)
>>
>> treatfac <- factor(treat)
>> levels(treatfac)<-list("A"=1,"B"=0 )
>> imprfac <- factor(impr)
>> levels(imprfac)<-list("+"=1,"-"=0)
>>
>> data.frame(pair,treatfac,imprfac)
>>
>>     pair treatfac imprfac
>>
>> 1     1      A     +
>> 2     1      B     -
>> 3     2      A     +
>> 4     2      B     -
>> 5     3      A     +
>> 6     3      B     -
>> 7     4      A     -
>> 8     4      B     +
>> 9     5      A     -
>> 10    5      B     +
>> 11    6      A     -
>> 12    6      B     -
>> 13    7      A     +
>> 14    7      B     +
>>
>> I tried some functions like table or even xtabs, but the results doesn't
>> show the pairs combinations.
>>
>>
>> Thanks in advance,
>>
>>
>> Maur?cio Cardeal
>>
>> Federal University of Bahia, Brazil
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From cristanchocc at gmail.com  Sun Apr  9 02:21:00 2017
From: cristanchocc at gmail.com (Rodrigo Andres Cristancho Castellanos)
Date: Sat, 8 Apr 2017 19:21:00 -0500
Subject: [R] nlminb error
Message-ID: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>

Hi, I?m having troubel using nlminb this is the warning that shows up.

Warning: Cholesky factorization 'dpotrf' exited with status: 1
Variance of the prediction error can not be computed.
Warning: Cholesky factorization 'dpotrf' exited with status: 1
Determinant of the variance of the prediction error can not be computed.

I?m trying to optimize a likelihood function. The code is a little messy,
you can find it at the end of the email.

I?ll appreciate any kind of help.

Regards.

Rodrigo Cristancho.



library(foreach)
library(FKF)
library(ggplot2)
library(gridExtra)

# Model setup
#3 Factor Independent Model

delta1<- c(0.006, 0.003, 0.007)
kappa <- c(0.001, 0.002, 0.004)
sigma <- c(0.002, 0.005, 0.003)
rc    <- c(0.00002)
r1    <- c(0.00002)
r2    <- c(0.5)

#All other parameters
T         <- 110  # years
delta_t   <- 1 # monthly zeros observations
dt        <- 1 # monthly r simulations
n         <- T/dt # number of r simulations
r_0       <- delta1
measurement_error <- 0.001 # for zero-coupon rates
m         <- length(delta1)   # dimension of state variables
# maturity  <- c(1/12 ,1/4, 1/2, 10) # zeros for 1 factor simulation
# maturity  <- c(1/12 ,1/4, 1/2, 1, 2, 3, 5, 7, 10) # zeros for 2 factor
simulation

maturity  <- 61-xc #
d         <- length(maturity)   # dimension of observations
N         <- T/delta_t # number of observations
premubar1=list(premubar)

# PARAMETER ESTIMATION
# ----------------------------------------------------------
# Random initialization of parameters
init_params_if <- function()
{
  delta1_init <<- runif(m, min=0.0, max=0.05)
  kappa_init <<- runif(m, min=0.0, max=0.05)
  sigma_init <<- runif(m, min=0.0, max=0.05)
  rc_init <<- runif(1, min=0.0, max=0.001)
  r1_init <<- runif(1, min=0.0, max=0.001)
  r2_init <<- runif(1, min=0.0, max=0.001)
}
# optimization parameter bounds

upper_bound <- c(rep(c(1.0, 1.0, 1.0, 1.0),each=m), rep(0.1,d))
lower_bound <- c(rep(c(0.0001, 0.0001, 0.0001,-1.0 ),each=m), rep(0.0001,d))
actual_param <- c(kappa=kappa, delta1=delta1, sigma=sigma, rc=rep(rc,1),
r1=rep(r1,1), r2=rep(r2,1))

#
#------------------------------------------------------------------------------------------------------------
#


#Kalman Filter for 3 Factor Indipendent Model
Ind_Fact_KF <- function(delta1, kappa, sigma, rc, r1, r2, observations)
{
  # initial state variable (a0: m x 1)
  #r_init <- as.vector(delta1)                    # unconditional mean of
state variable

  r_init <- as.vector(c(rep(0,m)))

  # variance of state variable (P0: m x m)
  #P_init <- (sigma^2/(2*(delta1^3)))*diag(1,m,m)   # unconditional
variance of state variable

  P_init <- (sigma^2/(2*(delta1)))*diag(1,m,m)

  # intercept of state transition equation (dt: m x 1)
  C <- matrix(0,nrow = m,ncol = 1)

  # factor of transition equation (Tt: m x m x 1)
  F_ <- array(exp(-kappa*delta_t)*diag(m),dim=c(m,m,1))

  # factor of measurement equation (Zt: d x m x 1)
  B <-
array(1/matrix(rep(delta1,d),d,byrow=TRUE)*(1-exp(-matrix(rep(delta1,d),d,byrow=TRUE)
* matrix(rep(maturity,m),d))),dim=c(d,m,1))

  # intercept of measurement equation (ct: d x 1)

  A <-
(1/2)*t(sigma^2/delta1^3)%*%t(((1/2)*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))))

 -2*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d))))
          -(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))

  A <- matrix(-t(A)/maturity,nrow=length(maturity))

  B <- array(B[,,1]/matrix(rep(maturity,m),d),dim=c(d,m,1))

  # variance of innovations of transition (HHt: m x m x 1)
  Q <-
array(sigma^2/(2*kappa)*(1-exp(-2*kappa*delta_t))*diag(m),dim=c(m,m,1))

  # variance of measurement error (GGt: d x d x 1)

  R <- array(diag(d)*(rc+r1*exp(r2)),dim=c(d,d,1))
  #R <- array(diag(d)*(rc),dim=c(d,d,1))

  ##Funcion de filtro de Kalman rapido con base al desarrollo del modelo
arriba
  filtered_process <- fkf(a0=r_init, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B,
HHt=Q, GGt=R, yt=observations)
  return(filtered_process)
}

#aaaa=fkf(a0=r_i(nit, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B, HHt=Q, GGt=R,
yt=t(premubar))
aaaa=Ind_Fact_KF(delta1, kappa, sigma, rc, r1, r2,observations=t(premubar))
aaaa$logLik
aaaa$Ft

# Retrieve short rates using Kalman Filter
retrieve_short_rates_if <- function(rates, optim_controls,
lower_bound=NULL, upper_bound=NULL)
{
  observations <- rates
  init_params_if()
  initial_param <<- c(delta1=delta1_init,kappa=kappa_init,
sigma=sigma_init, rc=rc_init, r1=r1_init, r2=r2_init)

  if_KF_loglik <- function(x)
  {
    delta1 <- x[1:m]; kappa <- x[(m+1):(2*m)]; sigma <- x[(2*m+1):(3*m)];
rc <- x[(3*m+1):(3*m+1)]; r1 <- x[(3*m+2):(3*m+2)];r2 <-
x[(3*m+3):length(x)]
    return(-Ind_Fact_KF(delta1,kappa,sigma,rc,r1,r2,observations)$logLik)
  }

  # optimization of log likelihood function
  fitted_model <- nlminb(initial_param, if_KF_loglik,
control=optim_controls, lower=lower_bound, upper=upper_bound)
  return(fitted_model)
}

rrif=retrieve_short_rates_if(rates=t(premubar),optim_controls=optim_controls,upper=upper_bound,lower=lower_bound)

	[[alternative HTML version deleted]]


From sraman9757 at gmail.com  Sun Apr  9 04:22:07 2017
From: sraman9757 at gmail.com (Sivakumaran Raman)
Date: Sat, 8 Apr 2017 21:22:07 -0500
Subject: [R] New free book to help learn the basics of data analysis with R
 in a single day
Message-ID: <bc6e3134-9747-189f-70a6-29b715f414a6@gmail.com>

I have written a book to help new users of R, who are familiar with at 
least one programming other
than R, learn the basics of data analysis in a single day. The book is 
free and released under the
most non-restrictive of the creative commons licenses. There is R code 
that accompanies the book.

The book is available in eReader formats on Smashwords
(https://www.smashwords.com/books/view/713592) and Barnes and Noble
(http://www.barnesandnoble.com/w/just-enough-r-sivakumaran-raman/1126163491). 
A pretty-printed PDF
is downloadable from here: 
http://www.dropbox.com/s/obhg7e6b5g0926t/Just_Enough_R.pdf?dl=0

Feedback is welcome. I hope the book will be a useful resource for newbies.

Thanks,
Siv Raman


From bgunter.4567 at gmail.com  Sun Apr  9 19:18:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Apr 2017 10:18:49 -0700
Subject: [R] nlminb error
In-Reply-To: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>
References: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>
Message-ID: <CAGxFJbQLgojCK83y6GSy7JiT+2qVe2YOoQTCW1pMP8=ZARxrAA@mail.gmail.com>

I suspect, as you hinted,  there's little to no hope that anyone will
be willing or able to navigate your code. **Usually** (whatever that
means!)  these sorts of problems can be traced back to
overparameterization -- too few data, which could also mean a lot of
"correlated" data, chasing too many parameters (leading to ridges in
the surface or problems near the boundaries). This is the bane of
numerical optimizers.

Try fitting simpler models with fewer parameters if possible, at least
to see if convergence can be achieved.  Better starting values, other
optimizers, and/or use of analytical gradients and hessians can also
sometimes help.

Sorry I can't be more specific. Perhaps someone more knowledgeable
than I can be.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 8, 2017 at 5:21 PM, Rodrigo Andres Cristancho Castellanos
<cristanchocc at gmail.com> wrote:
> Hi, I?m having troubel using nlminb this is the warning that shows up.
>
> Warning: Cholesky factorization 'dpotrf' exited with status: 1
> Variance of the prediction error can not be computed.
> Warning: Cholesky factorization 'dpotrf' exited with status: 1
> Determinant of the variance of the prediction error can not be computed.
>
> I?m trying to optimize a likelihood function. The code is a little messy,
> you can find it at the end of the email.
>
> I?ll appreciate any kind of help.
>
> Regards.
>
> Rodrigo Cristancho.
>
>
>
> library(foreach)
> library(FKF)
> library(ggplot2)
> library(gridExtra)
>
> # Model setup
> #3 Factor Independent Model
>
> delta1<- c(0.006, 0.003, 0.007)
> kappa <- c(0.001, 0.002, 0.004)
> sigma <- c(0.002, 0.005, 0.003)
> rc    <- c(0.00002)
> r1    <- c(0.00002)
> r2    <- c(0.5)
>
> #All other parameters
> T         <- 110  # years
> delta_t   <- 1 # monthly zeros observations
> dt        <- 1 # monthly r simulations
> n         <- T/dt # number of r simulations
> r_0       <- delta1
> measurement_error <- 0.001 # for zero-coupon rates
> m         <- length(delta1)   # dimension of state variables
> # maturity  <- c(1/12 ,1/4, 1/2, 10) # zeros for 1 factor simulation
> # maturity  <- c(1/12 ,1/4, 1/2, 1, 2, 3, 5, 7, 10) # zeros for 2 factor
> simulation
>
> maturity  <- 61-xc #
> d         <- length(maturity)   # dimension of observations
> N         <- T/delta_t # number of observations
> premubar1=list(premubar)
>
> # PARAMETER ESTIMATION
> # ----------------------------------------------------------
> # Random initialization of parameters
> init_params_if <- function()
> {
>   delta1_init <<- runif(m, min=0.0, max=0.05)
>   kappa_init <<- runif(m, min=0.0, max=0.05)
>   sigma_init <<- runif(m, min=0.0, max=0.05)
>   rc_init <<- runif(1, min=0.0, max=0.001)
>   r1_init <<- runif(1, min=0.0, max=0.001)
>   r2_init <<- runif(1, min=0.0, max=0.001)
> }
> # optimization parameter bounds
>
> upper_bound <- c(rep(c(1.0, 1.0, 1.0, 1.0),each=m), rep(0.1,d))
> lower_bound <- c(rep(c(0.0001, 0.0001, 0.0001,-1.0 ),each=m), rep(0.0001,d))
> actual_param <- c(kappa=kappa, delta1=delta1, sigma=sigma, rc=rep(rc,1),
> r1=rep(r1,1), r2=rep(r2,1))
>
> #
> #------------------------------------------------------------------------------------------------------------
> #
>
>
> #Kalman Filter for 3 Factor Indipendent Model
> Ind_Fact_KF <- function(delta1, kappa, sigma, rc, r1, r2, observations)
> {
>   # initial state variable (a0: m x 1)
>   #r_init <- as.vector(delta1)                    # unconditional mean of
> state variable
>
>   r_init <- as.vector(c(rep(0,m)))
>
>   # variance of state variable (P0: m x m)
>   #P_init <- (sigma^2/(2*(delta1^3)))*diag(1,m,m)   # unconditional
> variance of state variable
>
>   P_init <- (sigma^2/(2*(delta1)))*diag(1,m,m)
>
>   # intercept of state transition equation (dt: m x 1)
>   C <- matrix(0,nrow = m,ncol = 1)
>
>   # factor of transition equation (Tt: m x m x 1)
>   F_ <- array(exp(-kappa*delta_t)*diag(m),dim=c(m,m,1))
>
>   # factor of measurement equation (Zt: d x m x 1)
>   B <-
> array(1/matrix(rep(delta1,d),d,byrow=TRUE)*(1-exp(-matrix(rep(delta1,d),d,byrow=TRUE)
> * matrix(rep(maturity,m),d))),dim=c(d,m,1))
>
>   # intercept of measurement equation (ct: d x 1)
>
>   A <-
> (1/2)*t(sigma^2/delta1^3)%*%t(((1/2)*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))))
>
>  -2*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d))))
>           -(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))
>
>   A <- matrix(-t(A)/maturity,nrow=length(maturity))
>
>   B <- array(B[,,1]/matrix(rep(maturity,m),d),dim=c(d,m,1))
>
>   # variance of innovations of transition (HHt: m x m x 1)
>   Q <-
> array(sigma^2/(2*kappa)*(1-exp(-2*kappa*delta_t))*diag(m),dim=c(m,m,1))
>
>   # variance of measurement error (GGt: d x d x 1)
>
>   R <- array(diag(d)*(rc+r1*exp(r2)),dim=c(d,d,1))
>   #R <- array(diag(d)*(rc),dim=c(d,d,1))
>
>   ##Funcion de filtro de Kalman rapido con base al desarrollo del modelo
> arriba
>   filtered_process <- fkf(a0=r_init, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B,
> HHt=Q, GGt=R, yt=observations)
>   return(filtered_process)
> }
>
> #aaaa=fkf(a0=r_i(nit, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B, HHt=Q, GGt=R,
> yt=t(premubar))
> aaaa=Ind_Fact_KF(delta1, kappa, sigma, rc, r1, r2,observations=t(premubar))
> aaaa$logLik
> aaaa$Ft
>
> # Retrieve short rates using Kalman Filter
> retrieve_short_rates_if <- function(rates, optim_controls,
> lower_bound=NULL, upper_bound=NULL)
> {
>   observations <- rates
>   init_params_if()
>   initial_param <<- c(delta1=delta1_init,kappa=kappa_init,
> sigma=sigma_init, rc=rc_init, r1=r1_init, r2=r2_init)
>
>   if_KF_loglik <- function(x)
>   {
>     delta1 <- x[1:m]; kappa <- x[(m+1):(2*m)]; sigma <- x[(2*m+1):(3*m)];
> rc <- x[(3*m+1):(3*m+1)]; r1 <- x[(3*m+2):(3*m+2)];r2 <-
> x[(3*m+3):length(x)]
>     return(-Ind_Fact_KF(delta1,kappa,sigma,rc,r1,r2,observations)$logLik)
>   }
>
>   # optimization of log likelihood function
>   fitted_model <- nlminb(initial_param, if_KF_loglik,
> control=optim_controls, lower=lower_bound, upper=upper_bound)
>   return(fitted_model)
> }
>
> rrif=retrieve_short_rates_if(rates=t(premubar),optim_controls=optim_controls,upper=upper_bound,lower=lower_bound)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Sun Apr  9 22:28:22 2017
From: hannah.hlx at gmail.com (li li)
Date: Sun, 9 Apr 2017 16:28:22 -0400
Subject: [R] Looking for
Message-ID: <CAHLnndbUhLDokya4Q1SfHH6+mYeN-O1YSnNjg82bnE=jxLEMpA@mail.gmail.com>

Dear all,
  For a piecewise function F similar to the attached graph, I would like to
find
                                        inf{x| F(x) >=0}.


 I tried to uniroot. It does not seem to work. Any suggestions?
 Thank you very much!!
    Hanna
-------------- next part --------------
A non-text attachment was scrubbed...
Name: F.pdf
Type: application/pdf
Size: 58857 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170409/f6dacaef/attachment.pdf>

From bgunter.4567 at gmail.com  Sun Apr  9 22:55:16 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Apr 2017 13:55:16 -0700
Subject: [R] Looking for
In-Reply-To: <CAHLnndbUhLDokya4Q1SfHH6+mYeN-O1YSnNjg82bnE=jxLEMpA@mail.gmail.com>
References: <CAHLnndbUhLDokya4Q1SfHH6+mYeN-O1YSnNjg82bnE=jxLEMpA@mail.gmail.com>
Message-ID: <CAGxFJbQ6fGhLoHUutSNzPDDaLM7wMyKzcc2gVQ5nsDgy3w0D1g@mail.gmail.com>

Details matter!

1. Are the points of discontinuity known? This is critical.

2. Can we assume monotonic increasing, as is shown?


-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
> Dear all,
>   For a piecewise function F similar to the attached graph, I would like to
> find
>                                         inf{x| F(x) >=0}.
>
>
>  I tried to uniroot. It does not seem to work. Any suggestions?
>  Thank you very much!!
>     Hanna
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Mon Apr 10 02:38:24 2017
From: hannah.hlx at gmail.com (li li)
Date: Sun, 9 Apr 2017 20:38:24 -0400
Subject: [R] Finding Infimum in R
Message-ID: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>

Hi Burt,
    Yes, the function is monotone increasing and points of discontinuity
are all known.
They are all numbers between 0 and 1.  Thanks very much!
   Hanna


2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Details matter!
>
> 1. Are the points of discontinuity known? This is critical.
>
> 2. Can we assume monotonic increasing, as is shown?
>
>
> -- Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
> > Dear all,
> >   For a piecewise function F similar to the attached graph, I would like
> to
> > find
> >                                         inf{x| F(x) >=0}.
> >
> >
> >  I tried to uniroot. It does not seem to work. Any suggestions?
> >  Thank you very much!!
> >     Hanna
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Apr 10 03:18:30 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 9 Apr 2017 21:18:30 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
Message-ID: <F80B0865-6395-4A20-A684-08F11823EEFC@utoronto.ca>

Is the function linear between the discontinuities?
Can you give an example of how the function is specified?

B.



> On Apr 9, 2017, at 8:38 PM, li li <hannah.hlx at gmail.com> wrote:
> 
> Hi Burt,
>    Yes, the function is monotone increasing and points of discontinuity
> are all known.
> They are all numbers between 0 and 1.  Thanks very much!
>   Hanna
> 
> 
> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Details matter!
>> 
>> 1. Are the points of discontinuity known? This is critical.
>> 
>> 2. Can we assume monotonic increasing, as is shown?
>> 
>> 
>> -- Bert
>> 
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>> Dear all,
>>>  For a piecewise function F similar to the attached graph, I would like
>> to
>>> find
>>>                                        inf{x| F(x) >=0}.
>>> 
>>> 
>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>> Thank you very much!!
>>>    Hanna
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul at stat.auckland.ac.nz  Mon Apr 10 04:06:53 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 10 Apr 2017 14:06:53 +1200
Subject: [R] [FORGED] difference metric info of same font on different
 device
In-Reply-To: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
References: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
Message-ID: <5392628f-bb83-2c95-a1b0-71c92ab1cf01@stat.auckland.ac.nz>

Hi

I think you are hitting the limit of what R's PostScript device can do 
with CID fonts (particularly with Latin characters).

Have you tried the cairo_ps() device ?

Paul

On 7/04/2017 8:05 p.m., Jinsong Zhao wrote:
> Hi there,
>
> I try to plot with custom fonts, which have good shape Latin and CJK
> characters. I set up all the fonts correctly. However, when I plot the
> same code on png() and postscript(), I get different result. The main
> problem is the space between characters is narrower in postscript() than
> that in png(), and some character also overlap in postscript().  You can
> see the differences from the attached png files.
>
> Is there any way to get the same plot using postscript() and png()?
> Thanks in advance.
>
> Best,
> Jinsong
>
> The code I used is here:
>
> windowsFonts(song = windowsFont("SourceHanSerifSC-Regular"),
>              hei  = windowsFont("SourceHanSansSC-Regular"),
>              hwhei  = windowsFont("SourceHanSansHWSC-Regular"),
>              fzsong  = windowsFont("FZShuSong-Z01"),
>              fzhei = windowsFont("FZHei-B01"))
>
> postscriptFonts(song = CIDFont("SourceHanSerifSC-Regular",
> "UniSourceHanSerifCN-UTF8-H", "UTF-8", ""),
>                 hei  = CIDFont("SourceHanSansSC-Regular",
> "UniSourceHanSansCN-UTF8-H", "UTF-8", ""),
>                 hwhei  = CIDFont("SourceHanSansHWSC-Regular",
> "UniSourceHanSansHWCN-UTF8-H", "UTF-8", ""),
>                 fzsong  = CIDFont("FZShuSong-Z01",    "GBK-EUC-H",
> "GBK", ""),
>                 fzhei = CIDFont("FZHei-B01", "GBK-EUC-H", "GBK", ""))
>
> fa <- c("sans", "serif", "song", "hei", "hwhei", "fzsong", "fzhei")
>
> postscript("font.eps", fonts = fa, onefile = FALSE, width = 4, height =
> 4, horizontal = FALSE)
>
> #png("font.png", width=4*300, height=4*300, res =300)
>
> plot(0,xlab="",ylab="",type="n")
> text(1, -0.75, expression(CO[2]-Hei), family = "hei")
> text(1, -0.5, expression(CO[2]-HWHei), family = "hwhei")
> text(1, -0.25, expression(CO[2]-FZHei), family = "fzhei")
> text(1, 0.0, expression(CO[2]-Sans), family = "sans")
> text(1, 0.25, expression(CO[2]-FZSong), family = "fzsong")
> text(1, 0.5, expression(CO[2]-Song), family = "song")
> text(1, 0.75, expression(CO[2]-Serif), family = "serif")
>
> dev.off()
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From bgunter.4567 at gmail.com  Mon Apr 10 06:34:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Apr 2017 21:34:18 -0700
Subject: [R] Finding Infimum in R
In-Reply-To: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
Message-ID: <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>

Then it's trivial. Check values at the discontinuities and find the
first where it's <0 at the left discontinuity and >0 at the right, if
such exists. Then just use zero finding on that interval (or fit a
line if everything's linear). If none exists, then just find the first
discontinuity where it's > 0.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
> Hi Burt,
>     Yes, the function is monotone increasing and points of discontinuity are
> all known.
> They are all numbers between 0 and 1.  Thanks very much!
>    Hanna
>
>
> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>> Details matter!
>>
>> 1. Are the points of discontinuity known? This is critical.
>>
>> 2. Can we assume monotonic increasing, as is shown?
>>
>>
>> -- Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>> > Dear all,
>> >   For a piecewise function F similar to the attached graph, I would like
>> > to
>> > find
>> >                                         inf{x| F(x) >=0}.
>> >
>> >
>> >  I tried to uniroot. It does not seem to work. Any suggestions?
>> >  Thank you very much!!
>> >     Hanna
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From bgunter.4567 at gmail.com  Mon Apr 10 06:43:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Apr 2017 21:43:39 -0700
Subject: [R] nlminb error
In-Reply-To: <CAKaa7QgnTz-9=KYm09S9Ov3qSkMnii7SLtTYaFXHpvVw=5xXdA@mail.gmail.com>
References: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>
 <CAGxFJbQLgojCK83y6GSy7JiT+2qVe2YOoQTCW1pMP8=ZARxrAA@mail.gmail.com>
 <CAKaa7QgnTz-9=KYm09S9Ov3qSkMnii7SLtTYaFXHpvVw=5xXdA@mail.gmail.com>
Message-ID: <CAGxFJbRwp_bsU4HxF80as1KWwhJxLhYy4xAApw61=9BxFXN5Gg@mail.gmail.com>

Whether you have converged to a global optimum or not depends on the
nature of the likelihood surface. Have you tried different starting
values? As for the warning, I leave that to Prof. Nash, as he *is*
(way) more knowledgeable. However, I suspect the answer is yes, it is
concerning. Are you at a boundary?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 9, 2017 at 5:55 PM, Rodrigo Andres Cristancho Castellanos
<cristanchocc at gmail.com> wrote:
> Hi Bert and JC, thanks for the quick response.
>
> Thinking about what Bert mentions as posible "issues" I think the three of
> them are feasible explanations of the error.
>
> Anyway, I believe I have already found a work around, I just replace the
> function "nlminb" with the function "optim". Even though, the warning
> persits the result seems to converge without other issues, given that it
> indicates that the convergence is succesfully completed.
>
> The only question that comes to me with this lucky strike, is, do I need
> keep worring about the warning ?
>
> Thank you both for your help.
>
> Regards,
>
> Rodrigo Cristancho
>
>
>
> 2017-04-09 12:18 GMT-05:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>> I suspect, as you hinted,  there's little to no hope that anyone will
>> be willing or able to navigate your code. **Usually** (whatever that
>> means!)  these sorts of problems can be traced back to
>> overparameterization -- too few data, which could also mean a lot of
>> "correlated" data, chasing too many parameters (leading to ridges in
>> the surface or problems near the boundaries). This is the bane of
>> numerical optimizers.
>>
>> Try fitting simpler models with fewer parameters if possible, at least
>> to see if convergence can be achieved.  Better starting values, other
>> optimizers, and/or use of analytical gradients and hessians can also
>> sometimes help.
>>
>> Sorry I can't be more specific. Perhaps someone more knowledgeable
>> than I can be.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Apr 8, 2017 at 5:21 PM, Rodrigo Andres Cristancho Castellanos
>> <cristanchocc at gmail.com> wrote:
>> > Hi, I?m having troubel using nlminb this is the warning that shows up.
>> >
>> > Warning: Cholesky factorization 'dpotrf' exited with status: 1
>> > Variance of the prediction error can not be computed.
>> > Warning: Cholesky factorization 'dpotrf' exited with status: 1
>> > Determinant of the variance of the prediction error can not be computed.
>> >
>> > I?m trying to optimize a likelihood function. The code is a little
>> > messy,
>> > you can find it at the end of the email.
>> >
>> > I?ll appreciate any kind of help.
>> >
>> > Regards.
>> >
>> > Rodrigo Cristancho.
>> >
>> >
>> >
>> > library(foreach)
>> > library(FKF)
>> > library(ggplot2)
>> > library(gridExtra)
>> >
>> > # Model setup
>> > #3 Factor Independent Model
>> >
>> > delta1<- c(0.006, 0.003, 0.007)
>> > kappa <- c(0.001, 0.002, 0.004)
>> > sigma <- c(0.002, 0.005, 0.003)
>> > rc    <- c(0.00002)
>> > r1    <- c(0.00002)
>> > r2    <- c(0.5)
>> >
>> > #All other parameters
>> > T         <- 110  # years
>> > delta_t   <- 1 # monthly zeros observations
>> > dt        <- 1 # monthly r simulations
>> > n         <- T/dt # number of r simulations
>> > r_0       <- delta1
>> > measurement_error <- 0.001 # for zero-coupon rates
>> > m         <- length(delta1)   # dimension of state variables
>> > # maturity  <- c(1/12 ,1/4, 1/2, 10) # zeros for 1 factor simulation
>> > # maturity  <- c(1/12 ,1/4, 1/2, 1, 2, 3, 5, 7, 10) # zeros for 2 factor
>> > simulation
>> >
>> > maturity  <- 61-xc #
>> > d         <- length(maturity)   # dimension of observations
>> > N         <- T/delta_t # number of observations
>> > premubar1=list(premubar)
>> >
>> > # PARAMETER ESTIMATION
>> > # ----------------------------------------------------------
>> > # Random initialization of parameters
>> > init_params_if <- function()
>> > {
>> >   delta1_init <<- runif(m, min=0.0, max=0.05)
>> >   kappa_init <<- runif(m, min=0.0, max=0.05)
>> >   sigma_init <<- runif(m, min=0.0, max=0.05)
>> >   rc_init <<- runif(1, min=0.0, max=0.001)
>> >   r1_init <<- runif(1, min=0.0, max=0.001)
>> >   r2_init <<- runif(1, min=0.0, max=0.001)
>> > }
>> > # optimization parameter bounds
>> >
>> > upper_bound <- c(rep(c(1.0, 1.0, 1.0, 1.0),each=m), rep(0.1,d))
>> > lower_bound <- c(rep(c(0.0001, 0.0001, 0.0001,-1.0 ),each=m),
>> > rep(0.0001,d))
>> > actual_param <- c(kappa=kappa, delta1=delta1, sigma=sigma, rc=rep(rc,1),
>> > r1=rep(r1,1), r2=rep(r2,1))
>> >
>> > #
>> >
>> > #------------------------------------------------------------------------------------------------------------
>> > #
>> >
>> >
>> > #Kalman Filter for 3 Factor Indipendent Model
>> > Ind_Fact_KF <- function(delta1, kappa, sigma, rc, r1, r2, observations)
>> > {
>> >   # initial state variable (a0: m x 1)
>> >   #r_init <- as.vector(delta1)                    # unconditional mean
>> > of
>> > state variable
>> >
>> >   r_init <- as.vector(c(rep(0,m)))
>> >
>> >   # variance of state variable (P0: m x m)
>> >   #P_init <- (sigma^2/(2*(delta1^3)))*diag(1,m,m)   # unconditional
>> > variance of state variable
>> >
>> >   P_init <- (sigma^2/(2*(delta1)))*diag(1,m,m)
>> >
>> >   # intercept of state transition equation (dt: m x 1)
>> >   C <- matrix(0,nrow = m,ncol = 1)
>> >
>> >   # factor of transition equation (Tt: m x m x 1)
>> >   F_ <- array(exp(-kappa*delta_t)*diag(m),dim=c(m,m,1))
>> >
>> >   # factor of measurement equation (Zt: d x m x 1)
>> >   B <-
>> >
>> > array(1/matrix(rep(delta1,d),d,byrow=TRUE)*(1-exp(-matrix(rep(delta1,d),d,byrow=TRUE)
>> > * matrix(rep(maturity,m),d))),dim=c(d,m,1))
>> >
>> >   # intercept of measurement equation (ct: d x 1)
>> >
>> >   A <-
>> >
>> > (1/2)*t(sigma^2/delta1^3)%*%t(((1/2)*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))))
>> >
>> >
>> > -2*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d))))
>> >
>> > -(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))
>> >
>> >   A <- matrix(-t(A)/maturity,nrow=length(maturity))
>> >
>> >   B <- array(B[,,1]/matrix(rep(maturity,m),d),dim=c(d,m,1))
>> >
>> >   # variance of innovations of transition (HHt: m x m x 1)
>> >   Q <-
>> > array(sigma^2/(2*kappa)*(1-exp(-2*kappa*delta_t))*diag(m),dim=c(m,m,1))
>> >
>> >   # variance of measurement error (GGt: d x d x 1)
>> >
>> >   R <- array(diag(d)*(rc+r1*exp(r2)),dim=c(d,d,1))
>> >   #R <- array(diag(d)*(rc),dim=c(d,d,1))
>> >
>> >   ##Funcion de filtro de Kalman rapido con base al desarrollo del modelo
>> > arriba
>> >   filtered_process <- fkf(a0=r_init, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B,
>> > HHt=Q, GGt=R, yt=observations)
>> >   return(filtered_process)
>> > }
>> >
>> > #aaaa=fkf(a0=r_i(nit, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B, HHt=Q, GGt=R,
>> > yt=t(premubar))
>> > aaaa=Ind_Fact_KF(delta1, kappa, sigma, rc, r1,
>> > r2,observations=t(premubar))
>> > aaaa$logLik
>> > aaaa$Ft
>> >
>> > # Retrieve short rates using Kalman Filter
>> > retrieve_short_rates_if <- function(rates, optim_controls,
>> > lower_bound=NULL, upper_bound=NULL)
>> > {
>> >   observations <- rates
>> >   init_params_if()
>> >   initial_param <<- c(delta1=delta1_init,kappa=kappa_init,
>> > sigma=sigma_init, rc=rc_init, r1=r1_init, r2=r2_init)
>> >
>> >   if_KF_loglik <- function(x)
>> >   {
>> >     delta1 <- x[1:m]; kappa <- x[(m+1):(2*m)]; sigma <-
>> > x[(2*m+1):(3*m)];
>> > rc <- x[(3*m+1):(3*m+1)]; r1 <- x[(3*m+2):(3*m+2)];r2 <-
>> > x[(3*m+3):length(x)]
>> >
>> > return(-Ind_Fact_KF(delta1,kappa,sigma,rc,r1,r2,observations)$logLik)
>> >   }
>> >
>> >   # optimization of log likelihood function
>> >   fitted_model <- nlminb(initial_param, if_KF_loglik,
>> > control=optim_controls, lower=lower_bound, upper=upper_bound)
>> >   return(fitted_model)
>> > }
>> >
>> >
>> > rrif=retrieve_short_rates_if(rates=t(premubar),optim_controls=optim_controls,upper=upper_bound,lower=lower_bound)
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From boris.steipe at utoronto.ca  Mon Apr 10 10:57:49 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 04:57:49 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
Message-ID: <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>

Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so. 

B.




> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Then it's trivial. Check values at the discontinuities and find the
> first where it's <0 at the left discontinuity and >0 at the right, if
> such exists. Then just use zero finding on that interval (or fit a
> line if everything's linear). If none exists, then just find the first
> discontinuity where it's > 0.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>> Hi Burt,
>>    Yes, the function is monotone increasing and points of discontinuity are
>> all known.
>> They are all numbers between 0 and 1.  Thanks very much!
>>   Hanna
>> 
>> 
>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>> 
>>> Details matter!
>>> 
>>> 1. Are the points of discontinuity known? This is critical.
>>> 
>>> 2. Can we assume monotonic increasing, as is shown?
>>> 
>>> 
>>> -- Bert
>>> 
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>> Dear all,
>>>>  For a piecewise function F similar to the attached graph, I would like
>>>> to
>>>> find
>>>>                                        inf{x| F(x) >=0}.
>>>> 
>>>> 
>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>> Thank you very much!!
>>>>    Hanna
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From elfatihabdelrahman at gmail.com  Mon Apr 10 11:35:53 2017
From: elfatihabdelrahman at gmail.com (Elfatih AbdelRahman)
Date: Mon, 10 Apr 2017 12:35:53 +0300
Subject: [R]  hier.part limitation
Message-ID: <CAM-f72qBufKfWNKeAHrBdPJDWSMp9VDkSho6zJ-yAogmL+8-EQ@mail.gmail.com>

Dear all,



Does the package ?hier.part? limited to only 12 predictor variables. I was
trying to use it to partition (select) the most relevant predictor
variables our of 30 ones, and I always get an error message says:



?Error: Number of variables must be < 13 for current implementation?



Thanks in advance for your assistance.



Regards

Elfatih
_________________________________________________________________
Elfatih Mohamed Abdel-Rahman
Postdoctoral Fellow
Geo-information Unit
Environmental Health Theme
International Center for Insect Physiology and Ecology (*icipe*)
Kasarani, Off-Thika Road
P. O. BOX 30772, Nairobi 00100
Kenya
Cell phone: +254(0)701215292
Fax: +254(20)8632001
SKYPE: alfatih100

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Apr 10 11:56:22 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 10 Apr 2017 21:56:22 +1200
Subject: [R] Finding Infimum in R
In-Reply-To: <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
Message-ID: <aa11d2c4-d79c-d3ac-050c-ccaba5d3f676@auckland.ac.nz>


On 10/04/17 20:57, Boris Steipe wrote:

> Are you sure this is trivial? I have the impression the combination
> of an ill-posed problem and digital representation of numbers might
> just create the illusion that is so.


Fortune nomination.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From aurora.gonzalez2 at um.es  Mon Apr 10 14:27:59 2017
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Mon, 10 Apr 2017 14:27:59 +0200
Subject: [R] GA package integer hyperparameters optimization
Message-ID: <20170410142759.Horde.h87CpkCth4253nKuVSEgxw1@webmail.um.es>

Hello everybody.

I am? using the GA package[1] in order to optimize the hyperparameter of
SVM like in this example is done:
http://stackoverflow.com/questions/32026436/how-to-optimize-parameters-using-genetic-algorithms

However, when I try to adapt the example for random forest, it takes very
very long to optimize. It might be because the hyperparameter of random
forest are integers (ntree, mtry, nodes) but I don't know if there is a way
to specify it in the algorithm. Any suggestion would be very much
appreciated. Thank you!

The code:

library(GA)
library("randomForest")

data(Ozone, package="mlbench")
Data <- na.omit(Ozone)

# Setup the data for cross-validation
K = 5 # 5-fold cross-validation
fold_inds <- sample(1:K, nrow(Data), replace = TRUE)
lst_CV_data <- lapply(1:K, function(i) list(
? train_data = Data[fold_inds != i, , drop = FALSE],
? test_data = Data[fold_inds == i, , drop = FALSE]))

# Given the values of parameters 'ntree', 'mtry' and 'nodesize', return the
rmse of the model over the test data
evalParamsRF <- function(train_data, test_data, ntree, mtry, nodesize) {
? # Train
? model <- randomForest(V4 ~ ., data = train_data, ntree = ntree, mtry =
mtry, nodesize = nodesize
??????????????????????? , proximity=T)
? # Test
? rmse <- mean((predict(model, newdata = test_data) - test_data$V4) ^ 2)
? return (rmse)
}

fitnessFuncRF <- function(x, Lst_CV_Data) {
? # Retrieve the RF parameters
? ntree_val <- x[1]
? mtry_val <- x[2]
? nodesize_val <- x[3]
?
? # Use cross-validation to estimate the RMSE for each split of the
dataset
? rmse_vals <- sapply(Lst_CV_Data, function(in_data) with(in_data,
?????????????????????????????????????????????????????????
evalParamsRF(train_data, test_data, ntree_val
??????????????????????????????????????????????????????????????????????
, mtry_val, nodesize_val)))
?
? # As fitness measure, return minus the average rmse (over the
cross-validation folds),
? # so that by maximizing fitness we are minimizing the rmse
? return (-mean(rmse_vals))
}

theta_min <- c(ntree = 100, mtry = 2, nodesize = 3)
theta_max <- c(ntree = 1000, mtry = 7, nodesize = 20)

# Run the genetic algorithm
results <- ga(type = "real-valued", fitness = fitnessFuncRF, lst_CV_data,
????????????? names = names(theta_min),
????????????? min = theta_min, max = theta_max,
????????????? popSize = 50, maxiter = 10)

summary(results)
summary(results)$solution



Links:
------
[1] https://cran.r-project.org/web/packages/GA/index.html


------
Aurora Gonz?lez Vidal
Ph.D. student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
sae.saiblogs.inf.um.es

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Apr 10 16:38:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Apr 2017 07:38:29 -0700
Subject: [R] Finding Infimum in R
In-Reply-To: <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
Message-ID: <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>

Given what she said, how does the procedure I suggested fail?

(Always happy to be corrected).

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>
> B.
>
>
>
>
>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Then it's trivial. Check values at the discontinuities and find the
>> first where it's <0 at the left discontinuity and >0 at the right, if
>> such exists. Then just use zero finding on that interval (or fit a
>> line if everything's linear). If none exists, then just find the first
>> discontinuity where it's > 0.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>> Hi Burt,
>>>    Yes, the function is monotone increasing and points of discontinuity are
>>> all known.
>>> They are all numbers between 0 and 1.  Thanks very much!
>>>   Hanna
>>>
>>>
>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>
>>>> Details matter!
>>>>
>>>> 1. Are the points of discontinuity known? This is critical.
>>>>
>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>
>>>>
>>>> -- Bert
>>>>
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>> Dear all,
>>>>>  For a piecewise function F similar to the attached graph, I would like
>>>>> to
>>>>> find
>>>>>                                        inf{x| F(x) >=0}.
>>>>>
>>>>>
>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>> Thank you very much!!
>>>>>    Hanna
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Mon Apr 10 16:45:27 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 10 Apr 2017 16:45:27 +0200
Subject: [R] Antwort: Re: Antwort: Re: Way to Plot Multiple Variables and
 Change Color
In-Reply-To: <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
 <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
 <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
 <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>
Message-ID: <OF779EC1FB.95EE8CEC-ONC12580FE.00503181-C12580FE.005112BC@lotus.hawesko.de>

Hi Ulrik,

many thanks for your reply. I had to take an unplanned break and was not 
in the office during the last two weeks. Thus my late reply.

I followed your advice and converted the variable in argument "fill" to 
factor. Now the color change works:

-- cut --

d_result <- structure(list("variable" = c("Item 1 (? = 3.3) ", "Item 1 (? 
= 3.3) ",
                                        "Item 1 (? = 3.3) ", "Item 1 (? = 
3.3) ", "Item 1 (? = 3.3) ",
                                        "Item 1 (? = 3.3) ", "Item 2 (? = 
3.8) ", "Item 2 (? = 3.8) ",
                                        "Item 2 (? = 3.8) ", "Item 2 (? = 
3.8) ", "Item 2 (? = 3.8) ",
                                        "Item 2 (? = 3.8) ", "Item 3 (? = 
3.4) ", "Item 3 (? = 3.4) ",
                                        "Item 3 (? = 3.4) ", "Item 3 (? = 
3.4) ", "Item 3 (? = 3.4) ",
                                        "Item 3 (? = 3.4) ", "Item 4 (? = 
3.4) ", "Item 4 (? = 3.4) ",
                                        "Item 4 (? = 3.4) ", "Item 4 (? = 
3.4) ", "Item 4 (? = 3.4) ",
                                        "Item 4 (? = 3.4) ", "Item 5 (? = 
3.5) ", "Item 5 (? = 3.5) ",
                                        "Item 5 (? = 3.5) ", "Item 5 (? = 
3.5) ", "Item 5 (? = 3.5) ",
                                        "Item 5 (? = 3.5) ", "Item 6 (? = 
3.5) ", "Item 6 (? = 3.5) ",
                                        "Item 6 (? = 3.5) ", "Item 6 (? = 
3.5) ", "Item 6 (? = 3.5) ",
                                        "Item 6 (? = 3.5) ", "Item 7 (? = 
3.4) ", "Item 7 (? = 3.4) ",
                                        "Item 7 (? = 3.4) ", "Item 7 (? = 
3.4) ", "Item 7 (? = 3.4) ",
                                        "Item 7 (? = 3.4) ", "Item 8 (? = 
3.3) ", "Item 8 (? = 3.3) ",
                                        "Item 8 (? = 3.3) ", "Item 8 (? = 
3.3) ", "Item 8 (? = 3.3) ",
                                        "Item 8 (? = 3.3) "), value = 
structure(c(1L, 2L, 3L, 4L, 5L,
        6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
        4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L,
        2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("1 = very 
satisfied",
                                                                "2", "3", 
"4", "5", "6 = very dissatified"), class = "factor"),
                           n = c(14L, 20L, 24L, 14L, 16L, 14L, 9L, 15L, 
21L, 20L, 14L,
                                 23L, 19L, 17L, 16L, 14L, 16L, 20L, 22L, 
17L, 15L, 16L, 20L,
                                 12L, 19L, 15L, 16L, 15L, 18L, 19L, 18L, 
15L, 18L, 18L, 16L,
                                 17L, 17L, 20L, 17L, 17L, 14L, 16L, 16L, 
25L, 16L, 17L, 8L,
                                 20L)), .Names = c("variable", "value", 
"n"), row.names =
                        c(NA,
                          -48L), vars = list("variable"), drop = TRUE, 
indices =
                        list(0:5,
                             6:11, 12:17, 18:23, 24:29, 30:35, 36:41, 
42:47),
                      group_sizes = c(6L,
                                      6L, 6L, 6L, 6L, 6L, 6L, 6L),
                      biggest_group_size = 6L,
                      labels = structure(list(
                        "variable" = structure(1:8, .Label = c("Item 1 (? 
= 3.3) ",
                                                             "Item 2 (? = 
3.8) ", "Item 3 (? = 3.4) ", "Item 4 (? = 3.4) ",
                                                             "Item 5 (? = 
3.5) ", "Item 6 (? = 3.5) ", "Item 7 (? = 3.4) ",
                                                             "Item 8 (? = 
3.3) "), class = "factor")),
                        row.names = c(NA,
                                      -8L), class = "data.frame", vars = 
list("variable"),
                        drop = TRUE, .Names = "variable"),
                      class = c("grouped_df",
                                "tbl_df", "tbl", "data.frame"))

ggplot(
  d_result,
  aes(x = variable, y = n, fill = rev(factor(value)))) +
  geom_bar(
    stat = "identity") +
  coord_cartesian(ylim = c(0,100)) +
  coord_flip() +
  scale_y_continuous(name = "Percent") +
  scale_fill_manual(
    values = rev(
      c(
        "forestgreen", "limegreen",
        "gold", "orange1",
        "tomato3", "darkred"))) +
  ggtitle(
    paste(
      "Question 8: Satisfaction?")) +
  labs(fill = "Rating") +
  scale_x_discrete(
    name = element_blank()) +
  # scale_color_manual(
  #   values = rev(
  #     c(
  #       "forestgreen", "limegreen",
  #       "gold", "orange1",
  #       "tomato3", "darkred"))) +
  geom_text(
    aes(label = n),
    color = "white",
    position = position_stack(vjust = 0.5)) +
  theme_minimal() +
  theme(
    legend.position = "right")

-- cut --

I tried to change the order of the items on the y-axis,  e.g. Item 8 
should be last and Item 1 first. I tried to reverse the order of the items 
within ggplot using rev() and relevel(). But neither of them worked. Is 
there a way to do it?

I also tried to adjust the color palette for the legend, e.g. 1 = very 
satisfied is green, 6 = very dissatified is red instead of vice versa as 
it is now. The result should ensure the item naming for 1 = satisfied and 
6 = unsatifies cause this is the way it was asked in the questionnaire.

Thus my question is:

1. How can I change the order of the sequence for the y-axis?

2. How can I adjust the color palette of the legend that it matches the 
correct items?

Can you give me a hint which functions I could use to do it?

Kind regards

Georg




Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
An:     G.Maubach at weinwolf.de, "Richard M. Heiberger" <rmh at temple.edu>, 
Kopie:  r-help <r-help at r-project.org>
Datum:  28.03.2017 18:32
Betreff:        Re: [R] Antwort: Re: Way to Plot Multiple Variables and 
Change Color



Hi Georg,

you were on the right path - it is all about scale_fill*

The 'problem' as you've discovered is that value is continuous, but 
applying scale_fill_manual or others (except scale_fill_gradient) expects 
discrete values.

The solution is simply to set the fill with that by using factor():

ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
or: 
 ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("red","blue", "green", "purple"))

When using colorBrewer (which I highly recommend), I use scale_*_brewer 
rather than setting the colour manually:

ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Blues ")

Best,
Ulrik
 

On Tue, 28 Mar 2017 at 18:21 <G.Maubach at weinwolf.de> wrote:
Hi Richard,

many thanks for your reply.

Your solution is not exactly what I was looking for. I would like to know
how I can change the colors of the stacked bars in my plot and not use the
default values. How can this be done?

Kind regards

Georg




Von:    "Richard M. Heiberger" <rmh at temple.edu>
An:     G.Maubach at weinwolf.de,
Kopie:  r-help <r-help at r-project.org>
Datum:  28.03.2017 17:40
Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color



I think you are looking for the likert function in the HH package.
>From ?likert


Diverging stacked barcharts for Likert, semantic differential, rating
scale data, and population pyramids.


This will get you started.  Much more fine control is available.  See
the examples and demo.

## install.packages("HH") ## if not yet on your system.

library(HH)

AA <- dfr[,-9]

labels <- sort(unique(as.vector(data.matrix(AA))))
result.template <- integer(length(labels))
names(result.template) <- labels

BB <- apply(AA, 2, function(x, result=result.template) {
  tx <- table(x)
  result[names(tx)] <- tx
  result
}
)

BB

likert(t(BB), ReferenceZero=0, horizontal=FALSE)


On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I have to plot a whole bunch of related variables
> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
Power,
> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>
> I need to present the results as stacked bar charts where the variables
> are columns and the percentages of the scales values (1 .. 4) are the
> chunks of the stacked bar for each variable. To do this I have
transformed
> my data from wide to long and calculated the percentage for each
variable
> and value. The code for this is as follows:
>
> -- cut --
>
> dfr <- structure(
>   list(
>     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>                4, 4, 4, 1, 1, 3, 3, 4),
>     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>     v07_03 = c(3, 2, 2, 1, 4, 1,
>                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>     v07_04 = c(3, 1, 1,
>                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>     v07_05 = c(1,
>                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>     v07_06 = c(1,
>                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>     v07_07 = c(3,
>                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>     v07_08 = c(3,
>                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>     cased_id = structure(
>       1:20,
>       .Label = c(
>         "1",
>         "2",
>         "3",
>         "4",
>         "5",
>         "6",
>         "7",
>         "8",
>         "9",
>         "10",
>         "11",
>         "12",
>         "13",
>         "14",
>         "15",
>         "16",
>         "17",
>         "18",
>         "19",
>         "20"
>       ),
>       class = "factor"
>     )
>   ),
>   .Names = c(
>     "v07_01",
>     "v07_02",
>     "v07_03",
>     "v07_04",
>     "v07_05",
>     "v07_06",
>     "v07_07",
>     "v07_08",
>     "cased_id"
>   ),
>   row.names = c(NA, -20L),
>   class = c("tbl_df", "tbl",
>             "data.frame")
> )
>
> mdf <- melt(df)
> d_result <- mdf  %>%
>   dplyr::group_by(variable) %>%
>   count(value)
>
> ggplot(
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100))
>
> -- cut --
>
> Is there an easier way of doing this, i. e. a way without need to
> transform the data?
>
> How can I change the colors for the data points 1 .. 4?
>
> I tried
>
> -- cut --
>
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100)) +
>   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>
> -- cut -
>
> but this does not work cause I am mixing continuous and descrete values.
>
> How can I change the colors for the bars?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Apr 10 16:56:46 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 10:56:46 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
Message-ID: <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>

Well - the _procedure_ will give a result.

But think of f(x) = {-1; x <= 1/3 and 1; x > 1/3 

What should inf{x| F(x) >= 0} be?
What should the procedure return?





> On Apr 10, 2017, at 10:38 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Given what she said, how does the procedure I suggested fail?
> 
> (Always happy to be corrected).
> 
> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>> 
>> B.
>> 
>> 
>> 
>> 
>>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> Then it's trivial. Check values at the discontinuities and find the
>>> first where it's <0 at the left discontinuity and >0 at the right, if
>>> such exists. Then just use zero finding on that interval (or fit a
>>> line if everything's linear). If none exists, then just find the first
>>> discontinuity where it's > 0.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>>> Hi Burt,
>>>>   Yes, the function is monotone increasing and points of discontinuity are
>>>> all known.
>>>> They are all numbers between 0 and 1.  Thanks very much!
>>>>  Hanna
>>>> 
>>>> 
>>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>> 
>>>>> Details matter!
>>>>> 
>>>>> 1. Are the points of discontinuity known? This is critical.
>>>>> 
>>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>> 
>>>>> 
>>>>> -- Bert
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>> Dear all,
>>>>>> For a piecewise function F similar to the attached graph, I would like
>>>>>> to
>>>>>> find
>>>>>>                                       inf{x| F(x) >=0}.
>>>>>> 
>>>>>> 
>>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>>> Thank you very much!!
>>>>>>   Hanna
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 


From bgunter.4567 at gmail.com  Mon Apr 10 17:01:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Apr 2017 08:01:32 -0700
Subject: [R] Finding Infimum in R
In-Reply-To: <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
Message-ID: <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>

Yup, she can decide.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 10, 2017 at 7:56 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Well - the _procedure_ will give a result.
>
> But think of f(x) = {-1; x <= 1/3 and 1; x > 1/3
>
> What should inf{x| F(x) >= 0} be?
> What should the procedure return?
>
>
>
>
>
>> On Apr 10, 2017, at 10:38 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Given what she said, how does the procedure I suggested fail?
>>
>> (Always happy to be corrected).
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>>>
>>> B.
>>>
>>>
>>>
>>>
>>>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>
>>>> Then it's trivial. Check values at the discontinuities and find the
>>>> first where it's <0 at the left discontinuity and >0 at the right, if
>>>> such exists. Then just use zero finding on that interval (or fit a
>>>> line if everything's linear). If none exists, then just find the first
>>>> discontinuity where it's > 0.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>> Hi Burt,
>>>>>   Yes, the function is monotone increasing and points of discontinuity are
>>>>> all known.
>>>>> They are all numbers between 0 and 1.  Thanks very much!
>>>>>  Hanna
>>>>>
>>>>>
>>>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>>>
>>>>>> Details matter!
>>>>>>
>>>>>> 1. Are the points of discontinuity known? This is critical.
>>>>>>
>>>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>>>
>>>>>>
>>>>>> -- Bert
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>>> Dear all,
>>>>>>> For a piecewise function F similar to the attached graph, I would like
>>>>>>> to
>>>>>>> find
>>>>>>>                                       inf{x| F(x) >=0}.
>>>>>>>
>>>>>>>
>>>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>>>> Thank you very much!!
>>>>>>>   Hanna
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From boris.steipe at utoronto.ca  Mon Apr 10 17:09:13 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 11:09:13 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
 <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>
Message-ID: <8873D723-8293-4784-907C-6895951B5FB1@utoronto.ca>

Hannah - sorry if this is oblique.

The problem is that the question as given is ill-posed (in the mathematical sense); all the more so since there is no guarantee that the numbers that define your discontinuities can even be exactly represented in a computer. This could both be fixed if you can discretize your x-axis and accept an error on x. But without knowing more about your problem, it's hard to say how to do this correctly.

B.



> On Apr 10, 2017, at 11:01 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Yup, she can decide.
> 
> -- Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Apr 10, 2017 at 7:56 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Well - the _procedure_ will give a result.
>> 
>> But think of f(x) = {-1; x <= 1/3 and 1; x > 1/3
>> 
>> What should inf{x| F(x) >= 0} be?
>> What should the procedure return?
>> 
>> 
>> 
>> 
>> 
>>> On Apr 10, 2017, at 10:38 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> Given what she said, how does the procedure I suggested fail?
>>> 
>>> (Always happy to be corrected).
>>> 
>>> -- Bert
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>>>> 
>>>> B.
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> 
>>>>> Then it's trivial. Check values at the discontinuities and find the
>>>>> first where it's <0 at the left discontinuity and >0 at the right, if
>>>>> such exists. Then just use zero finding on that interval (or fit a
>>>>> line if everything's linear). If none exists, then just find the first
>>>>> discontinuity where it's > 0.
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>> Hi Burt,
>>>>>>  Yes, the function is monotone increasing and points of discontinuity are
>>>>>> all known.
>>>>>> They are all numbers between 0 and 1.  Thanks very much!
>>>>>> Hanna
>>>>>> 
>>>>>> 
>>>>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>>>> 
>>>>>>> Details matter!
>>>>>>> 
>>>>>>> 1. Are the points of discontinuity known? This is critical.
>>>>>>> 
>>>>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>>>> 
>>>>>>> 
>>>>>>> -- Bert
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>>> and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>> 
>>>>>>> 
>>>>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>>>> Dear all,
>>>>>>>> For a piecewise function F similar to the attached graph, I would like
>>>>>>>> to
>>>>>>>> find
>>>>>>>>                                      inf{x| F(x) >=0}.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>>>>> Thank you very much!!
>>>>>>>>  Hanna
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>> 


From profjcnash at gmail.com  Sun Apr  9 22:14:15 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 9 Apr 2017 16:14:15 -0400
Subject: [R] nlminb error
In-Reply-To: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>
References: <CAKaa7Qi+r-L1Cb=b8jVfVxA=Vx92UhsPy4Fx24n7qjTRCEPiTw@mail.gmail.com>
Message-ID: <859c5433-7745-a533-cbf6-99f540d7a8fe@gmail.com>

Bert has already suggested that your code is too spaghetti to let us follow it.
I tried and got a msg that PKF isn't available for R 3.3.3.

Do you actually have a test that the function can be evaluated? That's often the main issue.

And it does help to try a few parameter sets to see if you have a reasonable function.

JN

On 2017-04-08 08:21 PM, Rodrigo Andres Cristancho Castellanos wrote:
> Hi, I?m having troubel using nlminb this is the warning that shows up.
>
> Warning: Cholesky factorization 'dpotrf' exited with status: 1
> Variance of the prediction error can not be computed.
> Warning: Cholesky factorization 'dpotrf' exited with status: 1
> Determinant of the variance of the prediction error can not be computed.
>
> I?m trying to optimize a likelihood function. The code is a little messy,
> you can find it at the end of the email.
>
> I?ll appreciate any kind of help.
>
> Regards.
>
> Rodrigo Cristancho.
>
>
>
> library(foreach)
> library(FKF)
> library(ggplot2)
> library(gridExtra)
>
> # Model setup
> #3 Factor Independent Model
>
> delta1<- c(0.006, 0.003, 0.007)
> kappa <- c(0.001, 0.002, 0.004)
> sigma <- c(0.002, 0.005, 0.003)
> rc    <- c(0.00002)
> r1    <- c(0.00002)
> r2    <- c(0.5)
>
> #All other parameters
> T         <- 110  # years
> delta_t   <- 1 # monthly zeros observations
> dt        <- 1 # monthly r simulations
> n         <- T/dt # number of r simulations
> r_0       <- delta1
> measurement_error <- 0.001 # for zero-coupon rates
> m         <- length(delta1)   # dimension of state variables
> # maturity  <- c(1/12 ,1/4, 1/2, 10) # zeros for 1 factor simulation
> # maturity  <- c(1/12 ,1/4, 1/2, 1, 2, 3, 5, 7, 10) # zeros for 2 factor
> simulation
>
> maturity  <- 61-xc #
> d         <- length(maturity)   # dimension of observations
> N         <- T/delta_t # number of observations
> premubar1=list(premubar)
>
> # PARAMETER ESTIMATION
> # ----------------------------------------------------------
> # Random initialization of parameters
> init_params_if <- function()
> {
>   delta1_init <<- runif(m, min=0.0, max=0.05)
>   kappa_init <<- runif(m, min=0.0, max=0.05)
>   sigma_init <<- runif(m, min=0.0, max=0.05)
>   rc_init <<- runif(1, min=0.0, max=0.001)
>   r1_init <<- runif(1, min=0.0, max=0.001)
>   r2_init <<- runif(1, min=0.0, max=0.001)
> }
> # optimization parameter bounds
>
> upper_bound <- c(rep(c(1.0, 1.0, 1.0, 1.0),each=m), rep(0.1,d))
> lower_bound <- c(rep(c(0.0001, 0.0001, 0.0001,-1.0 ),each=m), rep(0.0001,d))
> actual_param <- c(kappa=kappa, delta1=delta1, sigma=sigma, rc=rep(rc,1),
> r1=rep(r1,1), r2=rep(r2,1))
>
> #
> #------------------------------------------------------------------------------------------------------------
> #
>
>
> #Kalman Filter for 3 Factor Indipendent Model
> Ind_Fact_KF <- function(delta1, kappa, sigma, rc, r1, r2, observations)
> {
>   # initial state variable (a0: m x 1)
>   #r_init <- as.vector(delta1)                    # unconditional mean of
> state variable
>
>   r_init <- as.vector(c(rep(0,m)))
>
>   # variance of state variable (P0: m x m)
>   #P_init <- (sigma^2/(2*(delta1^3)))*diag(1,m,m)   # unconditional
> variance of state variable
>
>   P_init <- (sigma^2/(2*(delta1)))*diag(1,m,m)
>
>   # intercept of state transition equation (dt: m x 1)
>   C <- matrix(0,nrow = m,ncol = 1)
>
>   # factor of transition equation (Tt: m x m x 1)
>   F_ <- array(exp(-kappa*delta_t)*diag(m),dim=c(m,m,1))
>
>   # factor of measurement equation (Zt: d x m x 1)
>   B <-
> array(1/matrix(rep(delta1,d),d,byrow=TRUE)*(1-exp(-matrix(rep(delta1,d),d,byrow=TRUE)
> * matrix(rep(maturity,m),d))),dim=c(d,m,1))
>
>   # intercept of measurement equation (ct: d x 1)
>
>   A <-
> (1/2)*t(sigma^2/delta1^3)%*%t(((1/2)*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))))
>
>  -2*(1-exp(-2*(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d))))
>           -(matrix(rep(delta1,d),d,byrow=TRUE)*matrix(rep(maturity,m),d)))
>
>   A <- matrix(-t(A)/maturity,nrow=length(maturity))
>
>   B <- array(B[,,1]/matrix(rep(maturity,m),d),dim=c(d,m,1))
>
>   # variance of innovations of transition (HHt: m x m x 1)
>   Q <-
> array(sigma^2/(2*kappa)*(1-exp(-2*kappa*delta_t))*diag(m),dim=c(m,m,1))
>
>   # variance of measurement error (GGt: d x d x 1)
>
>   R <- array(diag(d)*(rc+r1*exp(r2)),dim=c(d,d,1))
>   #R <- array(diag(d)*(rc),dim=c(d,d,1))
>
>   ##Funcion de filtro de Kalman rapido con base al desarrollo del modelo
> arriba
>   filtered_process <- fkf(a0=r_init, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B,
> HHt=Q, GGt=R, yt=observations)
>   return(filtered_process)
> }
>
> #aaaa=fkf(a0=r_i(nit, P0=P_init, dt=C, ct=A, Tt=F_, Zt=B, HHt=Q, GGt=R,
> yt=t(premubar))
> aaaa=Ind_Fact_KF(delta1, kappa, sigma, rc, r1, r2,observations=t(premubar))
> aaaa$logLik
> aaaa$Ft
>
> # Retrieve short rates using Kalman Filter
> retrieve_short_rates_if <- function(rates, optim_controls,
> lower_bound=NULL, upper_bound=NULL)
> {
>   observations <- rates
>   init_params_if()
>   initial_param <<- c(delta1=delta1_init,kappa=kappa_init,
> sigma=sigma_init, rc=rc_init, r1=r1_init, r2=r2_init)
>
>   if_KF_loglik <- function(x)
>   {
>     delta1 <- x[1:m]; kappa <- x[(m+1):(2*m)]; sigma <- x[(2*m+1):(3*m)];
> rc <- x[(3*m+1):(3*m+1)]; r1 <- x[(3*m+2):(3*m+2)];r2 <-
> x[(3*m+3):length(x)]
>     return(-Ind_Fact_KF(delta1,kappa,sigma,rc,r1,r2,observations)$logLik)
>   }
>
>   # optimization of log likelihood function
>   fitted_model <- nlminb(initial_param, if_KF_loglik,
> control=optim_controls, lower=lower_bound, upper=upper_bound)
>   return(fitted_model)
> }
>
> rrif=retrieve_short_rates_if(rates=t(premubar),optim_controls=optim_controls,upper=upper_bound,lower=lower_bound)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jszhao at yeah.net  Mon Apr 10 07:26:43 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 10 Apr 2017 13:26:43 +0800
Subject: [R] [FORGED] difference metric info of same font on different
 device
In-Reply-To: <5392628f-bb83-2c95-a1b0-71c92ab1cf01@stat.auckland.ac.nz>
References: <93f4c906-7e4c-3397-21ba-f6e08c366a88@yeah.net>
 <5392628f-bb83-2c95-a1b0-71c92ab1cf01@stat.auckland.ac.nz>
Message-ID: <e5c65824-ae57-4dc3-e41b-2ab6b4a31158@yeah.net>

On 2017/4/10 10:06, Paul Murrell wrote:
> Hi
>
> I think you are hitting the limit of what R's PostScript device can do
> with CID fonts (particularly with Latin characters).
>
> Have you tried the cairo_ps() device ?
>
> Paul

Thank you very much. It works very well. It's more simple than 
postscript() with CIDFont setting.

Best,
Jinsong

>
> On 7/04/2017 8:05 p.m., Jinsong Zhao wrote:
>> Hi there,
>>
>> I try to plot with custom fonts, which have good shape Latin and CJK
>> characters. I set up all the fonts correctly. However, when I plot the
>> same code on png() and postscript(), I get different result. The main
>> problem is the space between characters is narrower in postscript() than
>> that in png(), and some character also overlap in postscript().  You can
>> see the differences from the attached png files.
>>
>> Is there any way to get the same plot using postscript() and png()?
>> Thanks in advance.
>>
>> Best,
>> Jinsong
>>
>> The code I used is here:
>>
>> windowsFonts(song = windowsFont("SourceHanSerifSC-Regular"),
>>              hei  = windowsFont("SourceHanSansSC-Regular"),
>>              hwhei  = windowsFont("SourceHanSansHWSC-Regular"),
>>              fzsong  = windowsFont("FZShuSong-Z01"),
>>              fzhei = windowsFont("FZHei-B01"))
>>
>> postscriptFonts(song = CIDFont("SourceHanSerifSC-Regular",
>> "UniSourceHanSerifCN-UTF8-H", "UTF-8", ""),
>>                 hei  = CIDFont("SourceHanSansSC-Regular",
>> "UniSourceHanSansCN-UTF8-H", "UTF-8", ""),
>>                 hwhei  = CIDFont("SourceHanSansHWSC-Regular",
>> "UniSourceHanSansHWCN-UTF8-H", "UTF-8", ""),
>>                 fzsong  = CIDFont("FZShuSong-Z01",    "GBK-EUC-H",
>> "GBK", ""),
>>                 fzhei = CIDFont("FZHei-B01", "GBK-EUC-H", "GBK", ""))
>>
>> fa <- c("sans", "serif", "song", "hei", "hwhei", "fzsong", "fzhei")
>>
>> postscript("font.eps", fonts = fa, onefile = FALSE, width = 4, height =
>> 4, horizontal = FALSE)
>>
>> #png("font.png", width=4*300, height=4*300, res =300)
>>
>> plot(0,xlab="",ylab="",type="n")
>> text(1, -0.75, expression(CO[2]-Hei), family = "hei")
>> text(1, -0.5, expression(CO[2]-HWHei), family = "hwhei")
>> text(1, -0.25, expression(CO[2]-FZHei), family = "fzhei")
>> text(1, 0.0, expression(CO[2]-Sans), family = "sans")
>> text(1, 0.25, expression(CO[2]-FZSong), family = "fzsong")
>> text(1, 0.5, expression(CO[2]-Song), family = "song")
>> text(1, 0.75, expression(CO[2]-Serif), family = "serif")
>>
>> dev.off()
>>


From joe.gain at uni-konstanz.de  Mon Apr 10 10:15:29 2017
From: joe.gain at uni-konstanz.de (Joe Gain)
Date: Mon, 10 Apr 2017 10:15:29 +0200
Subject: [R] Archive format
In-Reply-To: <trinity-6620bce2-ae65-4c8a-b8df-4e311c506e63-1491418150499@3capp-gmx-bs47>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
 <trinity-6620bce2-ae65-4c8a-b8df-4e311c506e63-1491418150499@3capp-gmx-bs47>
Message-ID: <d4c4b429-2eae-9712-2e41-def87efda006@uni-konstanz.de>

Hi Georg,


On 08.04.2017 09:04, G.Maubach at gmx.de wrote:
> Hi Joe,
>
> I have read your question with great interest. I am a little bit astonished to read about your project. There is a big national institute in Germany called GESIS (https://de.wikipedia.org/wiki/GESIS_%E2%80%93_Leibniz-Institut_f%C3%BCr_Sozialwissenschaften) which does the same job you are trying to set-up since 1986 now. You could try to exchange ideas with them.

we've already had some contact with GESIS. I agree that it would be a 
good idea to communicate and cooperate more with GESIS-- although there 
are many interesting organisations, which are all doing their own thing 
and it's not always easy to do so.

We organised a confernce in Heidelberg, "The E-Science Tage", and I was 
at the GESIS presentation, which was very good.

> Your subject is very complex with regard to reproducible research. You might want to have a look at

> (1) https://cran.r-project.org/web/views/ReproducibleResearch.html
> (2) Gandrud, Christopher: Reproducible Research with R and R Studio (https://www.amazon.com/Reproducible-Research-Studio-Second-Chapman/dp/1498715370)

Thanks for the useful links. (There's a whole book about R and 
reproducible research!)

The general goal of the web platform is to increase the awareness of 
researchers in Research Data Management.

The topic _is_ very complicated and it's difficult to write a general 
approach, especially, when you consider the different research 
disciplines, etc. nevertheless, that is what we are trying to do. Where 
it's possible and when the information becomes to specific we will 
include links to further resources (such as those, you have recommended 
above). Also, the project is to some extent dependent on the feedback of 
users, especially when they are able to provide us with information, 
which improves the content of the web platform.


> Kind regards
>
> Georg
>

Thanks for taking the time to reply to my question.

All the best,
Joe

>> Gesendet: Mittwoch, 29. M?rz 2017 um 10:44 Uhr
>> Von: "Joe Gain" <joe.gain at uni-konstanz.de>
>> An: R-help at r-project.org
>> Cc: bwfdm-info at lists.kit.edu
>> Betreff: [R] Archive format
>>
>> Hello,
>>
>> we are collecting information on the subject of research data management
>> in German on the webplatform:
>>
>> www.forschungsdaten.info
>>
>> One of the topics, which we are writing about, is how to *archive* data.
>> Unfortunately, none of us in the project is an expert with respect to R
>> and so I would like to ask the list, what they recommend? A related
>> question is to do with the sharing of data. We have already asked some
>> academics, who have basically replied that they don't really know other
>> than to strongly recommend a plain text format.
>>
>> We would also like to know, if members of the list recommend converting
>> formats from commercial software such as S-Plus, Terr, SPSS etc. to an
>> R-compatible format for long term archivation? Are there any general
>> rules and best practices, when it comes to archiving (and sharing)
>> statistical data and statistical programs?
>>
>> Any comments would be much appreciated!
>> Joe
>>
>> --
>> B 1003
>> Kommunikations-, Informations-, Medienzentrum (KIM)
>> Universitaet Konstanz
>>
>> t: ++49-7531-883234
>> e: joe.gain at uni-konstanz.de
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


-- 
B 1003
Kommunikations-, Informations-, Medienzentrum (KIM)
Universitaet Konstanz

t: ++49-7531-883234
e: joe.gain at uni-konstanz.de


From eabdel-Rahman at icipe.org  Mon Apr 10 11:33:40 2017
From: eabdel-Rahman at icipe.org (Abdel-Rahman, Elfatih)
Date: Mon, 10 Apr 2017 09:33:40 +0000
Subject: [R]  hier.part limitation
Message-ID: <AM4PR0701MB217735457C2D5B7F4BFA70BFE7010@AM4PR0701MB2177.eurprd07.prod.outlook.com>

Dear all,

Does the package "hier.part" limited to only 12 predictor variables. I was trying to use it to partition (select) the most relevant predictor variables our of 30 ones, and I always get an error message says:

"Error: Number of variables must be < 13 for current implementation"

Thanks in advance for your assistance.

Regards
Elfatih
_____________________________________
Elfatih Mohamed Abdel-Rahman
Postdoctoral Fellow
Geo-information Unit
Environmental Health Theme
International Center for Insect Physiology and Ecology (icipe)
Kasarani, Off-Thika Road
P. O. BOX 30772, Nairobi 00100
Kenya
Cell phone: +254(0)701215292
Fax: +254(20)8632001
SKYPE: alfatih100


	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 10 19:08:20 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 10 Apr 2017 13:08:20 -0400
Subject: [R] Too strange that I cannot install several packages
Message-ID: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>

Hi Rers:
Is there anything I can check for as to why I cannot install several 
packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?

The error message I get is:

>install.packages("sample") Installing package into 
?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is 
unspecified) Warning in install.packages :
   package ?sample? is not available (for R version 3.3.3)


Thanks.
Bruce


From HDoran at air.org  Mon Apr 10 19:11:43 2017
From: HDoran at air.org (Doran, Harold)
Date: Mon, 10 Apr 2017 17:11:43 +0000
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>

You really need to stop spamming this list and take time to learn R basics. You sent me emails directly on this and asked me this specific question before. 

These are not packages, but are functions and you do not work with R this way.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
Sent: Monday, April 10, 2017 1:08 PM
To: r-help at r-project.org
Subject: [R] Too strange that I cannot install several packages

Hi Rers:
Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?

The error message I get is:

>install.packages("sample") Installing package into
?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
unspecified) Warning in install.packages :
   package ?sample? is not available (for R version 3.3.3)


Thanks.
Bruce

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jacob-simmering at uiowa.edu  Mon Apr 10 19:15:04 2017
From: jacob-simmering at uiowa.edu (Simmering, Jacob E)
Date: Mon, 10 Apr 2017 17:15:04 +0000
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
Message-ID: <48F426F0-0EE6-482F-B2CC-7A74D7A112AF@uiowa.edu>

Bruce,

`sample` doesn?t appear to be an R package. `resample` installed for me. `apply` and `sapply` aren?t packages either. 

`sample`, `apply` and `sapply` are all functions, however. 



> On Apr 10, 2017, at 12:08 PM, BR_email <br at dmstat1.com> wrote:
> 
> Hi Rers:
> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
> 
> The error message I get is:
> 
>> install.packages("sample") Installing package into 
> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is unspecified) Warning in install.packages :
>  package ?sample? is not available (for R version 3.3.3)
> 
> 
> Thanks.
> Bruce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Apr 10 19:15:44 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Mon, 10 Apr 2017 19:15:44 +0200
Subject: [R] Finding Infimum in R
In-Reply-To: <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
Message-ID: <4D055394-4794-4DB9-9C2C-E3C4ACEFD025@gmail.com>

Er, 1/3, of course? (assuming that F is f). The infimum of a set is not necessarily a member of the set.

-pd

> On 10 Apr 2017, at 16:56 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> Well - the _procedure_ will give a result.
> 
> But think of f(x) = {-1; x <= 1/3 and 1; x > 1/3 
> 
> What should inf{x| F(x) >= 0} be?
> What should the procedure return?
> 
> 
> 
> 
> 
>> On Apr 10, 2017, at 10:38 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Given what she said, how does the procedure I suggested fail?
>> 
>> (Always happy to be corrected).
>> 
>> -- Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>>> 
>>> B.
>>> 
>>> 
>>> 
>>> 
>>>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> 
>>>> Then it's trivial. Check values at the discontinuities and find the
>>>> first where it's <0 at the left discontinuity and >0 at the right, if
>>>> such exists. Then just use zero finding on that interval (or fit a
>>>> line if everything's linear). If none exists, then just find the first
>>>> discontinuity where it's > 0.
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>> Hi Burt,
>>>>>  Yes, the function is monotone increasing and points of discontinuity are
>>>>> all known.
>>>>> They are all numbers between 0 and 1.  Thanks very much!
>>>>> Hanna
>>>>> 
>>>>> 
>>>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>>> 
>>>>>> Details matter!
>>>>>> 
>>>>>> 1. Are the points of discontinuity known? This is critical.
>>>>>> 
>>>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>>> 
>>>>>> 
>>>>>> -- Bert
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Bert Gunter
>>>>>> 
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>> 
>>>>>> 
>>>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>>> Dear all,
>>>>>>> For a piecewise function F similar to the attached graph, I would like
>>>>>>> to
>>>>>>> find
>>>>>>>                                      inf{x| F(x) >=0}.
>>>>>>> 
>>>>>>> 
>>>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>>>> Thank you very much!!
>>>>>>>  Hanna
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From boris.steipe at utoronto.ca  Mon Apr 10 19:28:31 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 13:28:31 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <4D055394-4794-4DB9-9C2C-E3C4ACEFD025@gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
 <4D055394-4794-4DB9-9C2C-E3C4ACEFD025@gmail.com>
Message-ID: <072D9928-347E-4289-80D8-27BB169CC63A@utoronto.ca>

Analytically speaking. But we are (presumably) looking for a numerical algorithm, and that is constrained by numerical accuracy, and in that realm we have  0.3333333333333333148296 on the left, and 0.3333333333333333703408 on the right.

And the left-side representable number is what gets returned for x <- 1/3. Whether this number, which is less than the defined discontinuity, is a correct solution depends on aspects of the problem that have not been disclosed.

No?



B.




> On Apr 10, 2017, at 1:15 PM, Peter Dalgaard <pdalgd at gmail.com> wrote:
> 
> Er, 1/3, of course? (assuming that F is f). The infimum of a set is not necessarily a member of the set.
> 
> -pd
> 
>> On 10 Apr 2017, at 16:56 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> 
>> Well - the _procedure_ will give a result.
>> 
>> But think of f(x) = {-1; x <= 1/3 and 1; x > 1/3 
>> 
>> What should inf{x| F(x) >= 0} be?
>> What should the procedure return?
>> 
>> 
>> 
>> 
>> 
>>> On Apr 10, 2017, at 10:38 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> Given what she said, how does the procedure I suggested fail?
>>> 
>>> (Always happy to be corrected).
>>> 
>>> -- Bert
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Mon, Apr 10, 2017 at 1:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>> Are you sure this is trivial? I have the impression the combination of an ill-posed problem and digital representation of numbers might just create the illusion that is so.
>>>> 
>>>> B.
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> On Apr 10, 2017, at 12:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> 
>>>>> Then it's trivial. Check values at the discontinuities and find the
>>>>> first where it's <0 at the left discontinuity and >0 at the right, if
>>>>> such exists. Then just use zero finding on that interval (or fit a
>>>>> line if everything's linear). If none exists, then just find the first
>>>>> discontinuity where it's > 0.
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Sun, Apr 9, 2017 at 5:38 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>> Hi Burt,
>>>>>> Yes, the function is monotone increasing and points of discontinuity are
>>>>>> all known.
>>>>>> They are all numbers between 0 and 1.  Thanks very much!
>>>>>> Hanna
>>>>>> 
>>>>>> 
>>>>>> 2017-04-09 16:55 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>>>> 
>>>>>>> Details matter!
>>>>>>> 
>>>>>>> 1. Are the points of discontinuity known? This is critical.
>>>>>>> 
>>>>>>> 2. Can we assume monotonic increasing, as is shown?
>>>>>>> 
>>>>>>> 
>>>>>>> -- Bert
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>>> and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>> 
>>>>>>> 
>>>>>>> On Sun, Apr 9, 2017 at 1:28 PM, li li <hannah.hlx at gmail.com> wrote:
>>>>>>>> Dear all,
>>>>>>>> For a piecewise function F similar to the attached graph, I would like
>>>>>>>> to
>>>>>>>> find
>>>>>>>>                                     inf{x| F(x) >=0}.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> I tried to uniroot. It does not seem to work. Any suggestions?
>>>>>>>> Thank you very much!!
>>>>>>>> Hanna
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From br at dmstat1.com  Mon Apr 10 19:50:11 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 10 Apr 2017 13:50:11 -0400
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <48F426F0-0EE6-482F-B2CC-7A74D7A112AF@uiowa.edu>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
 <48F426F0-0EE6-482F-B2CC-7A74D7A112AF@uiowa.edu>
Message-ID: <6cfc62bb-3eeb-ec53-0a00-1e47cff7247a@dmstat1.com>

Thanks, Jacob.
Bruce

  

Simmering, Jacob E wrote:
> Bruce,
>
> `sample` doesn?t appear to be an R package. `resample` installed for me. `apply` and `sapply` aren?t packages either.
>
> `sample`, `apply` and `sapply` are all functions, however.
>
>
>
>> On Apr 10, 2017, at 12:08 PM, BR_email <br at dmstat1.com> wrote:
>>
>> Hi Rers:
>> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
>>
>> The error message I get is:
>>
>>> install.packages("sample") Installing package into
>> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is unspecified) Warning in install.packages :
>>   package ?sample? is not available (for R version 3.3.3)
>>
>>
>> Thanks.
>> Bruce
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr 10 20:08:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Apr 2017 11:08:07 -0700
Subject: [R] Finding Infimum in R
In-Reply-To: <CAHLnndY7ZK7J2950iTKmr0DccMzjRebpjiMjs56=5BMiTC5nkQ@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
 <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>
 <8873D723-8293-4784-907C-6895951B5FB1@utoronto.ca>
 <CAHLnnda8MX6r1SEAR9TJwAeatCLtuKmMq4sG_iTT4YfXjc2-Xw@mail.gmail.com>
 <CAHLnndY7ZK7J2950iTKmr0DccMzjRebpjiMjs56=5BMiTC5nkQ@mail.gmail.com>
Message-ID: <CAGxFJbR4j3kUHAwx3a9BE5_rZ+u2CWLALSygcYg6VOCD7s8CVQ@mail.gmail.com>

Well, I haven't checked carefully, but  of course this does not find infs
or sups at all, just mins or maxes in the sample, which are not the same.

You'll have to do your own full testing  and debugging, however. I do not
provide such a service.

-- Bert

	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 10 20:12:48 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Mon, 10 Apr 2017 14:12:48 -0400
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>
Message-ID: <2BF5B7FF-C294-437C-B2BF-255206627295@dmstat1.com>

Dear Harold:
If you do not want to answer my questions, then do not reply. 
Warmest Regards, 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 10, 2017, at 1:11 PM, Doran, Harold <HDoran at air.org> wrote:
> 
> You really need to stop spamming this list and take time to learn R basics. You sent me emails directly on this and asked me this specific question before. 
> 
> These are not packages, but are functions and you do not work with R this way.
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Monday, April 10, 2017 1:08 PM
> To: r-help at r-project.org
> Subject: [R] Too strange that I cannot install several packages
> 
> Hi Rers:
> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
> 
> The error message I get is:
> 
>> install.packages("sample") Installing package into
> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning in install.packages :
>   package ?sample? is not available (for R version 3.3.3)
> 
> 
> Thanks.
> Bruce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Mon Apr 10 20:15:12 2017
From: HDoran at air.org (Doran, Harold)
Date: Mon, 10 Apr 2017 18:15:12 +0000
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <2BF5B7FF-C294-437C-B2BF-255206627295@dmstat1.com>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>
 <2BF5B7FF-C294-437C-B2BF-255206627295@dmstat1.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41521@DC1VEX10MB01.air.org>

I did answer this question quite a few weeks ago. You then continued to email me directly off list asking the exact question you posted below and at that time I gave you the answer on how to solve.

Your unwillingness to do even the basic study on R clogs this list unnecessarily. 

-----Original Message-----
From: Bruce Ratner PhD [mailto:br at dmstat1.com] 
Sent: Monday, April 10, 2017 2:13 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] Too strange that I cannot install several packages

Dear Harold:
If you do not want to answer my questions, then do not reply. 
Warmest Regards,
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 10, 2017, at 1:11 PM, Doran, Harold <HDoran at air.org> wrote:
> 
> You really need to stop spamming this list and take time to learn R basics. You sent me emails directly on this and asked me this specific question before. 
> 
> These are not packages, but are functions and you do not work with R this way.
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> BR_email
> Sent: Monday, April 10, 2017 1:08 PM
> To: r-help at r-project.org
> Subject: [R] Too strange that I cannot install several packages
> 
> Hi Rers:
> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
> 
> The error message I get is:
> 
>> install.packages("sample") Installing package into
> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning in install.packages :
>   package ?sample? is not available (for R version 3.3.3)
> 
> 
> Thanks.
> Bruce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Mon Apr 10 20:17:40 2017
From: hannah.hlx at gmail.com (li li)
Date: Mon, 10 Apr 2017 14:17:40 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAGxFJbR4j3kUHAwx3a9BE5_rZ+u2CWLALSygcYg6VOCD7s8CVQ@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
 <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>
 <8873D723-8293-4784-907C-6895951B5FB1@utoronto.ca>
 <CAHLnnda8MX6r1SEAR9TJwAeatCLtuKmMq4sG_iTT4YfXjc2-Xw@mail.gmail.com>
 <CAHLnndY7ZK7J2950iTKmr0DccMzjRebpjiMjs56=5BMiTC5nkQ@mail.gmail.com>
 <CAGxFJbR4j3kUHAwx3a9BE5_rZ+u2CWLALSygcYg6VOCD7s8CVQ@mail.gmail.com>
Message-ID: <CAHLnndbtDQuvEi0CgXCCy1w4Yq6BddGwXe15=Nispk7QsX4r+w@mail.gmail.com>

Yes. If the function f takes the value zero at some discontinuity point,
then the code gives the inf of the set I described.
Otherwise, it is an approximation since we need to worry about numerical
accuracy.

2017-04-10 14:08 GMT-04:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Well, I haven't checked carefully, but  of course this does not find infs
> or sups at all, just mins or maxes in the sample, which are not the same.
>
> You'll have to do your own full testing  and debugging, however. I do not
> provide such a service.
>
> -- Bert
>
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Apr 10 20:21:03 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 14:21:03 -0400
Subject: [R] Finding Infimum in R
In-Reply-To: <CAHLnndY7ZK7J2950iTKmr0DccMzjRebpjiMjs56=5BMiTC5nkQ@mail.gmail.com>
References: <CAHLnndbymbEPjuHZJLaqjn3ZE2OwL0OAQmxOF_xd5YAkrxzPXw@mail.gmail.com>
 <CAGxFJbRqpuVt-oO_R53u_R6J_iXTRO+b43=ggJeDSqdcpbhR1A@mail.gmail.com>
 <1421F857-E104-4902-A894-F07EB31780FD@utoronto.ca>
 <CAGxFJbSr3mnNBdK1Pwu+SAmBHLVg3QoOC82Z4EVOM3y2E2=Kzg@mail.gmail.com>
 <9EEB3E26-3392-43B1-9750-9F74E144F91A@utoronto.ca>
 <CAGxFJbSeyjtUAWFhRbTyWqTmvONYs0-Vec2mQcSAd56ieEZksg@mail.gmail.com>
 <8873D723-8293-4784-907C-6895951B5FB1@utoronto.ca>
 <CAHLnnda8MX6r1SEAR9TJwAeatCLtuKmMq4sG_iTT4YfXjc2-Xw@mail.gmail.com>
 <CAHLnndY7ZK7J2950iTKmr0DccMzjRebpjiMjs56=5BMiTC5nkQ@mail.gmail.com>
Message-ID: <2D1A59BF-AAE4-48C5-92D8-FCD818378159@utoronto.ca>

Here's my crossword-puzzle for the day:

# A sample monotonous discontinuous function with a single root
# (vectorized)

F <- function(x) {
    return((as.numeric(x >= 0.112233445566778899) * 2) - 1)
}


discRoot <- function(xL, xR, F, k = 10) {
    # Return the interval containing a single root of the monotonous
    # increasing function F() in the range [xL, xR] to k-digits
    # accuracy.
    myK <- 1
    while (myK <= k) {
        x <- seq(xL, xR, length.out = 11)  # ten intervals
        y <- F(x)                          # evaluate F
        i <- min(which(y >= 0))            # find index of first positive y
        xR <- x[i]                         # make this the right bound
        xL <- x[max((i - 1), 1)]           # left bound, but prevent xL < 1
        myK <- myK + 1                     # increase resolution
    }
    return(c(xL, xR))
}

R > print(discRoot(0, 1, F), digits = 22)
[1] 0.1122334455000000147384 0.1122334456000000091347
R > print(discRoot(0, 1, F, k = 5), digits = 22)
[1] 0.1122300000000000103073 0.1122400000000000064304
R > print(discRoot(0, 1, F, k = 15), digits = 22)
[1] 0.1122334455667780145349 0.1122334455667790137356
R > print(discRoot(0, 1, F, k = 22), digits = 22)
[1] 0.1122334455667788888356 0.1122334455667789027133
R > print(discRoot(0, 1, F, k = 30), digits = 22)
[1] 0.1122334455667788888356 0.1122334455667789027133


Try it on your own function

Cheers,
B.




> On Apr 10, 2017, at 1:53 PM, li li <hannah.hlx at gmail.com> wrote:
> 
> Here are the codes again. I made an error in the previous email.
> Thanks very much.
> 
> 
> ##points of discontinuity
> pts <- seq(0,1,by=0.2)
> n <- length(pts)
> 
> 
> ##g is the step function
> g <- function(x){
>     val <- numeric(n)
>     for (i in 1:(n-1)){val[i] <- pts[i]*((x>=pts[i])&&(pts[i+1])>x)}
>     val[n] <- pts[n]*(x>=pts[n])
>     sum(val)}
> ##f is the piecewise function
> f <- function(x){x+g(x)-1}
> 
> ##values of f at the discontinuity points
> z <- pts
> for (i in 1:n){z[i]<- f(pts[i])}
> 
> ##find the root
> 
> if(any(z==0)=="TRUE") {
>     res <- pts[which(z==0)]
> } else {
>     l <- pts[max(which(z<0))] 
>     r <- pts[min(which(z>0))] 
>     res <- uniroot(f, c(l,r))$root
> }
> 
> ##check the root
> 
> f(res)
> 
> 
> 2017-04-10 13:41 GMT-04:00 li li <hannah.hlx at gmail.com>:
> Hi Burt and all,
>  Thanks so much for your reply.
>   Here is an example.
>   Consider the points (0, 0.2, 0.4, 0.6, 0.8,1) and denote them as c_1, ..., c_5.
> The piecewise function is defined as  f(x)=x+g(x)-1, x >=0, where
> g is a step function defined as follows:
> 
>   <image.png>
> 
>    Below  is the code to find inf{x | f(x) >=0} according to your suggestion.
> If there is any suggestion to make the code simpler, please let me know.
> Thanks so much for your help.
>                                                     Hannah
> 
> 
> 
> 
> ##points of discontinuity
> pts <- seq(0,1,by=0.2)
> n <- length(pts)
> 
> 
> ##g is the step function
> g <- function(x){
>     val <- numeric(n)
>     for (i in 1:(n-1)){val[i] <- pts[i]*((x>=pts[i])&&(pts[i+1])>x)}
>     val[n] <- pts[n]*(x>=pts[n])
>     sum(val)}
> ##f is the piecewise function
> f <- function(x){x+g(x)-1}
> 
> ##values of f at the discontinuity points
> z <- pts
> for (i in 1:n){z[i]<- f(pts[i])}
> 
> ##find the root
> 
> if(any(z==0)=="TRUE") {
>     res <- pts[max(which(z==0))]
> } else {
>     l <- pts[max(which(z<0))] 
>     r <- pts[min(which(z>0))] 
>     res <- uniroot(f, c(l,r))$root
> }
> 
> ##check the root
> 
> f(res)
> 
>      Hanna
> 
> 


From wjm1 at caa.columbia.edu  Mon Apr 10 21:07:18 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Mon, 10 Apr 2017 12:07:18 -0700
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41521@DC1VEX10MB01.air.org>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>
 <2BF5B7FF-C294-437C-B2BF-255206627295@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41521@DC1VEX10MB01.air.org>
Message-ID: <CAA99HCwrddxC7dyOWgTVWn2jZFgugQyaYHN6UZYV6JMJPA+nmg@mail.gmail.com>

For a base-R installation, you can print out multiple help pages
(function indices) like so:

> for(i in 1:length(sessionInfo()$basePkgs)) {
print(library(help = sessionInfo()$basePkgs[i], character.only = TRUE)) }

HTH,

Bill.

William Michels, Ph.D.



On Mon, Apr 10, 2017 at 11:15 AM, Doran, Harold <HDoran at air.org> wrote:
> I did answer this question quite a few weeks ago. You then continued to email me directly off list asking the exact question you posted below and at that time I gave you the answer on how to solve.
>
> Your unwillingness to do even the basic study on R clogs this list unnecessarily.
>
> -----Original Message-----
> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
> Sent: Monday, April 10, 2017 2:13 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] Too strange that I cannot install several packages
>
> Dear Harold:
> If you do not want to answer my questions, then do not reply.
> Warmest Regards,
> Bruce
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 10, 2017, at 1:11 PM, Doran, Harold <HDoran at air.org> wrote:
>>
>> You really need to stop spamming this list and take time to learn R basics. You sent me emails directly on this and asked me this specific question before.
>>
>> These are not packages, but are functions and you do not work with R this way.
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> BR_email
>> Sent: Monday, April 10, 2017 1:08 PM
>> To: r-help at r-project.org
>> Subject: [R] Too strange that I cannot install several packages
>>
>> Hi Rers:
>> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
>>
>> The error message I get is:
>>
>>> install.packages("sample") Installing package into
>> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
>> unspecified) Warning in install.packages :
>>   package ?sample? is not available (for R version 3.3.3)
>>
>>
>> Thanks.
>> Bruce
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Mon Apr 10 21:16:35 2017
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 10 Apr 2017 19:16:35 +0000
Subject: [R] Revolutions blog: March 2017 roundup
Message-ID: <CY1PR0301MB21059B40C83413455DCE22CDC8010@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of March:

A tutorial and comparison of the SparkR, sparklyr, rsparkling, and
RevoScaleR packages for using R with Spark:
http://blog.revolutionanalytics.com/2017/03/tutorial-scaling-r.html

An analysis of Scrabble games between AI players:
http://blog.revolutionanalytics.com/2017/03/scrabblr.html

The doAzureParallel package, a backend to "foreach" for parallel
computations on Azure-based clusters:
http://blog.revolutionanalytics.com/2017/03/doazureparallel.html

The UK government project to automate reporting of official statistics
with R: http://blog.revolutionanalytics.com/2017/03/uk-statistics.html

Data science languages R and Python rank highly in the latest Redmond
popularity rankings:
http://blog.revolutionanalytics.com/2017/03/redmonk-jan-2017.html

FiveThirtyEight used R to find clusters of similar subreddits:
http://blog.revolutionanalytics.com/2017/03/comparing-subreddits.html

RTVS 1.0, which provides R support to Visual Studio, is now available:
http://blog.revolutionanalytics.com/2017/03/announcing-r-tools-10-for-visual-studio-2015.html

The mrsdeploy package (part of Microsoft R Server) facilitates
publishing an R function as a web service on Azure:
http://blog.revolutionanalytics.com/2017/03/running-your-r-code-azure.html

The Call for Papers for the EARL conferences in London and San
Francisco closes on April 14:
http://blog.revolutionanalytics.com/2017/03/give-a-talk-about-an-application-of-r-at-earl.html

Alteryx Designer has been integrated with Microsoft R:
http://blog.revolutionanalytics.com/2017/03/alteryx-integrates-with-microsoft-r.html

StitchFix, the personal styling service, uses R and Python as part of
their data science process:
http://blog.revolutionanalytics.com/2017/03/data-science-at-stitchfix.html

A review of "Testing R Code", by Richie Cotton:
http://blog.revolutionanalytics.com/2017/03/review-testing-r-code.html

On the connection between AUC and the Mann-Whitney U-Statistic:
http://blog.revolutionanalytics.com/2017/03/auc-meets-u-stat.html

An overview of neural networks and R packages to train them:
http://blog.revolutionanalytics.com/2017/03/neural-networks-r.html

Performance benchmarks of rxNeuralNetwork (in the MicrosoftML
package):
http://blog.revolutionanalytics.com/2017/03/benchmarking-rxneuralnet.html

Updates to the Data Science Virtual Machine for Linux:
http://blog.revolutionanalytics.com/2017/03/dsvm-linux-updates.html

A timelapse of the founding of cities since 3500BC:
http://blog.revolutionanalytics.com/2017/03/the-rise-of-civilization-visualized-with-r.html

A set of R scripts and sample data to predict employee attrition:
http://blog.revolutionanalytics.com/2017/03/employee-retention.html

R 3.3.3 is now available:
http://blog.revolutionanalytics.com/2017/03/r-333-now-available.html

The htmlwidgets gallery provides indexes interactive web-based charts
for R:
http://blog.revolutionanalytics.com/2017/03/htmlwidgets-gallery.html

R-based analyses to predict the length of a hospital stay:
http://blog.revolutionanalytics.com/2017/03/hospital-length-of-stay.html

Scholarships to encourage diversity at useR!2017:
http://blog.revolutionanalytics.com/2017/03/diversity-scholarships.html

And some general interest stories (not necessarily related to R): 
* Simulating the galaxy
http://blog.revolutionanalytics.com/2017/03/because-its-friday-universe-time-lapse.html
* A poor showing at Crufts
http://blog.revolutionanalytics.com/2017/03/because-its-friday-run-ollie-run.html
* Why some memes survive better than others
http://blog.revolutionanalytics.com/2017/03/because-its-friday-memes.html
* A digital clock made in Life:
http://blog.revolutionanalytics.com/2017/03/because-its-friday-timelife.html
* A tongue-in-cheek guide to reading sheet music:
http://blog.revolutionanalytics.com/2017/03/because-its-friday-how-to-read-music.html

As always, thanks for the comments and please keep sending suggestions
to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From br at dmstat1.com  Mon Apr 10 21:29:02 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Mon, 10 Apr 2017 15:29:02 -0400
Subject: [R] Too strange that I cannot install several packages
In-Reply-To: <CAA99HCwrddxC7dyOWgTVWn2jZFgugQyaYHN6UZYV6JMJPA+nmg@mail.gmail.com>
References: <4bcb681c-8d95-40e5-c2ad-655b77fd92c3@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41363@DC1VEX10MB01.air.org>
 <2BF5B7FF-C294-437C-B2BF-255206627295@dmstat1.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D41521@DC1VEX10MB01.air.org>
 <CAA99HCwrddxC7dyOWgTVWn2jZFgugQyaYHN6UZYV6JMJPA+nmg@mail.gmail.com>
Message-ID: <941F6B96-7634-4C82-8D14-394C6683BEC2@dmstat1.com>

Dear William:
Thank you for your informative reply. 
I simply got lost in the forest, as I have indeed been reading several R books.
As I tell my students, "every bright mind has a dull spot."

Best Regards,
Bruce


______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 10, 2017, at 3:07 PM, William Michels <wjm1 at caa.columbia.edu> wrote:
> 
> For a base-R installation, you can print out multiple help pages
> (function indices) like so:
> 
>> for(i in 1:length(sessionInfo()$basePkgs)) {
> print(library(help = sessionInfo()$basePkgs[i], character.only = TRUE)) }
> 
> HTH,
> 
> Bill.
> 
> William Michels, Ph.D.
> 
> 
> 
>> On Mon, Apr 10, 2017 at 11:15 AM, Doran, Harold <HDoran at air.org> wrote:
>> I did answer this question quite a few weeks ago. You then continued to email me directly off list asking the exact question you posted below and at that time I gave you the answer on how to solve.
>> 
>> Your unwillingness to do even the basic study on R clogs this list unnecessarily.
>> 
>> -----Original Message-----
>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>> Sent: Monday, April 10, 2017 2:13 PM
>> To: Doran, Harold <HDoran at air.org>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Too strange that I cannot install several packages
>> 
>> Dear Harold:
>> If you do not want to answer my questions, then do not reply.
>> Warmest Regards,
>> Bruce
>> 
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com Machine-Learning Data Mining -- www.GenIQ.net
>> 
>> 
>> 
>>> On Apr 10, 2017, at 1:11 PM, Doran, Harold <HDoran at air.org> wrote:
>>> 
>>> You really need to stop spamming this list and take time to learn R basics. You sent me emails directly on this and asked me this specific question before.
>>> 
>>> These are not packages, but are functions and you do not work with R this way.
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> BR_email
>>> Sent: Monday, April 10, 2017 1:08 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Too strange that I cannot install several packages
>>> 
>>> Hi Rers:
>>> Is there anything I can check for as to why I cannot install several packages, i.e., sample, resample, resample_bootstrap, apply, sapply, ...?
>>> 
>>> The error message I get is:
>>> 
>>>> install.packages("sample") Installing package into
>>> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
>>> unspecified) Warning in install.packages :
>>>  package ?sample? is not available (for R version 3.3.3)
>>> 
>>> 
>>> Thanks.
>>> Bruce
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From dwinsemius at comcast.net  Mon Apr 10 22:06:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Apr 2017 13:06:11 -0700
Subject: [R] Antwort: Re: Antwort: Re: Way to Plot Multiple Variables
	and Change Color
In-Reply-To: <OF779EC1FB.95EE8CEC-ONC12580FE.00503181-C12580FE.005112BC@lotus.hawesko.de>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
 <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
 <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
 <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>
 <OF779EC1FB.95EE8CEC-ONC12580FE.00503181-C12580FE.005112BC@lotus.hawesko.de>
Message-ID: <638BA55D-3D17-4D87-A806-90B894D36FF3@comcast.net>


> On Apr 10, 2017, at 7:45 AM, G.Maubach at weinwolf.de wrote:
> 
> Hi Ulrik,
> 
> many thanks for your reply. I had to take an unplanned break and was not 
> in the office during the last two weeks. Thus my late reply.
> 
> I followed your advice and converted the variable in argument "fill" to 
> factor. Now the color change works:
> 
> -- cut --
> 
> d_result <- structure(list("variable" = c("Item 1 (? = 3.3) ", "Item 1 (? 
> = 3.3) ",
>                                        "Item 1 (? = 3.3) ", "Item 1 (? = 
> 3.3) ", "Item 1 (? = 3.3) ",
>                                        "Item 1 (? = 3.3) ", "Item 2 (? = 
> 3.8) ", "Item 2 (? = 3.8) ",
>                                        "Item 2 (? = 3.8) ", "Item 2 (? = 
> 3.8) ", "Item 2 (? = 3.8) ",
>                                        "Item 2 (? = 3.8) ", "Item 3 (? = 
> 3.4) ", "Item 3 (? = 3.4) ",
>                                        "Item 3 (? = 3.4) ", "Item 3 (? = 
> 3.4) ", "Item 3 (? = 3.4) ",
>                                        "Item 3 (? = 3.4) ", "Item 4 (? = 
> 3.4) ", "Item 4 (? = 3.4) ",
>                                        "Item 4 (? = 3.4) ", "Item 4 (? = 
> 3.4) ", "Item 4 (? = 3.4) ",
>                                        "Item 4 (? = 3.4) ", "Item 5 (? = 
> 3.5) ", "Item 5 (? = 3.5) ",
>                                        "Item 5 (? = 3.5) ", "Item 5 (? = 
> 3.5) ", "Item 5 (? = 3.5) ",
>                                        "Item 5 (? = 3.5) ", "Item 6 (? = 
> 3.5) ", "Item 6 (? = 3.5) ",
>                                        "Item 6 (? = 3.5) ", "Item 6 (? = 
> 3.5) ", "Item 6 (? = 3.5) ",
>                                        "Item 6 (? = 3.5) ", "Item 7 (? = 
> 3.4) ", "Item 7 (? = 3.4) ",
>                                        "Item 7 (? = 3.4) ", "Item 7 (? = 
> 3.4) ", "Item 7 (? = 3.4) ",
>                                        "Item 7 (? = 3.4) ", "Item 8 (? = 
> 3.3) ", "Item 8 (? = 3.3) ",
>                                        "Item 8 (? = 3.3) ", "Item 8 (? = 
> 3.3) ", "Item 8 (? = 3.3) ",
>                                        "Item 8 (? = 3.3) "), value = 
> structure(c(1L, 2L, 3L, 4L, 5L,
>        6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
>        4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L,
>        2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("1 = very 
> satisfied",
>                                                                "2", "3", 
> "4", "5", "6 = very dissatified"), class = "factor"),
>                           n = c(14L, 20L, 24L, 14L, 16L, 14L, 9L, 15L, 
> 21L, 20L, 14L,
>                                 23L, 19L, 17L, 16L, 14L, 16L, 20L, 22L, 
> 17L, 15L, 16L, 20L,
>                                 12L, 19L, 15L, 16L, 15L, 18L, 19L, 18L, 
> 15L, 18L, 18L, 16L,
>                                 17L, 17L, 20L, 17L, 17L, 14L, 16L, 16L, 
> 25L, 16L, 17L, 8L,
>                                 20L)), .Names = c("variable", "value", 
> "n"), row.names =
>                        c(NA,
>                          -48L), vars = list("variable"), drop = TRUE, 
> indices =
>                        list(0:5,
>                             6:11, 12:17, 18:23, 24:29, 30:35, 36:41, 
> 42:47),
>                      group_sizes = c(6L,
>                                      6L, 6L, 6L, 6L, 6L, 6L, 6L),
>                      biggest_group_size = 6L,
>                      labels = structure(list(
>                        "variable" = structure(1:8, .Label = c("Item 1 (? 
> = 3.3) ",
>                                                             "Item 2 (? = 
> 3.8) ", "Item 3 (? = 3.4) ", "Item 4 (? = 3.4) ",
>                                                             "Item 5 (? = 
> 3.5) ", "Item 6 (? = 3.5) ", "Item 7 (? = 3.4) ",
>                                                             "Item 8 (? = 
> 3.3) "), class = "factor")),
>                        row.names = c(NA,
>                                      -8L), class = "data.frame", vars = 
> list("variable"),
>                        drop = TRUE, .Names = "variable"),
>                      class = c("grouped_df",
>                                "tbl_df", "tbl", "data.frame"))
> 
> ggplot(
>  d_result,
>  aes(x = variable, y = n, fill = rev(factor(value)))) +
>  geom_bar(
>    stat = "identity") +
>  coord_cartesian(ylim = c(0,100)) +
>  coord_flip() +
>  scale_y_continuous(name = "Percent") +
>  scale_fill_manual(
>    values = rev(
>      c(
>        "forestgreen", "limegreen",
>        "gold", "orange1",
>        "tomato3", "darkred"))) +
>  ggtitle(
>    paste(
>      "Question 8: Satisfaction?")) +
>  labs(fill = "Rating") +
>  scale_x_discrete(
>    name = element_blank()) +
>  # scale_color_manual(
>  #   values = rev(
>  #     c(
>  #       "forestgreen", "limegreen",
>  #       "gold", "orange1",
>  #       "tomato3", "darkred"))) +
>  geom_text(
>    aes(label = n),
>    color = "white",
>    position = position_stack(vjust = 0.5)) +
>  theme_minimal() +
>  theme(
>    legend.position = "right")
> 
> -- cut --
> 
> I tried to change the order of the items on the y-axis,  e.g. Item 8 
> should be last and Item 1 first.

"First" and "last" apparently mean "top" and "bottom" to you. Since the $variable column is character, and ordering is typically done by setting levels of factors, try:

d_result$variable <- factor(d_result$variable, levels=rev(unique(d_result$variable)))


# changes ordering so the "Item 1"'s are at the top.


> I tried to reverse the order of the items 
> within ggplot using rev() and relevel(). But neither of them worked. Is 
> there a way to do it?

I don't think you can relevel a character column.
> 
> I also tried to adjust the color palette for the legend, e.g. 1 = very 
> satisfied is green, 6 = very dissatified is red instead of vice versa as 
> it is now. The result should ensure the item naming for 1 = satisfied and 
> 6 = unsatifies cause this is the way it was asked in the questionnaire.
> 
> Thus my question is:
> 
> 1. How can I change the order of the sequence for the y-axis?
> 
> 2. How can I adjust the color palette of the legend that it matches the 
> correct items?

You probably could use relevel sinc `value` was a factor but I found it easier to simply repeat the relevelling code and change the target column name:

d_result$value <- factor(d_result$value, levels=rev(unique(d_result$value)))

I did find the appearance of the final result stange because there was irregular use of "\n" in the "variable" character values. that created more items than I think you wanted to appear.

HTH;
David.
> 
> Can you give me a hint which functions I could use to do it?
> 
> Kind regards
> 
> Georg
> 
> 
> 
> 
> Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
> An:     G.Maubach at weinwolf.de, "Richard M. Heiberger" <rmh at temple.edu>, 
> Kopie:  r-help <r-help at r-project.org>
> Datum:  28.03.2017 18:32
> Betreff:        Re: [R] Antwort: Re: Way to Plot Multiple Variables and 
> Change Color
> 
> 
> 
> Hi Georg,
> 
> you were on the right path - it is all about scale_fill*
> 
> The 'problem' as you've discovered is that value is continuous, but 
> applying scale_fill_manual or others (except scale_fill_gradient) expects 
> discrete values.
> 
> The solution is simply to set the fill with that by using factor():
> 
> ggplot(
>  d_result,
>  aes(variable, y = n, fill = factor(value))) +
>  geom_bar(stat = "identity") +
> scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
> or: 
> ggplot(
>  d_result,
>  aes(variable, y = n, fill = factor(value))) +
>  geom_bar(stat = "identity") +
>  scale_fill_manual(values = c("red","blue", "green", "purple"))
> 
> When using colorBrewer (which I highly recommend), I use scale_*_brewer 
> rather than setting the colour manually:
> 
> ggplot(
>  d_result,
>  aes(variable, y = n, fill = factor(value))) +
>  geom_bar(stat = "identity") +
>  scale_fill_brewer(palette = "Blues ")
> 
> Best,
> Ulrik
> 
> 
> On Tue, 28 Mar 2017 at 18:21 <G.Maubach at weinwolf.de> wrote:
> Hi Richard,
> 
> many thanks for your reply.
> 
> Your solution is not exactly what I was looking for. I would like to know
> how I can change the colors of the stacked bars in my plot and not use the
> default values. How can this be done?
> 
> Kind regards
> 
> Georg
> 
> 
> 
> 
> Von:    "Richard M. Heiberger" <rmh at temple.edu>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  28.03.2017 17:40
> Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color
> 
> 
> 
> I think you are looking for the likert function in the HH package.
>> From ?likert
> 
> 
> Diverging stacked barcharts for Likert, semantic differential, rating
> scale data, and population pyramids.
> 
> 
> This will get you started.  Much more fine control is available.  See
> the examples and demo.
> 
> ## install.packages("HH") ## if not yet on your system.
> 
> library(HH)
> 
> AA <- dfr[,-9]
> 
> labels <- sort(unique(as.vector(data.matrix(AA))))
> result.template <- integer(length(labels))
> names(result.template) <- labels
> 
> BB <- apply(AA, 2, function(x, result=result.template) {
>  tx <- table(x)
>  result[names(tx)] <- tx
>  result
> }
> )
> 
> BB
> 
> likert(t(BB), ReferenceZero=0, horizontal=FALSE)
> 
> 
> On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>> 
>> in my current project I have to plot a whole bunch of related variables
>> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
> Power,
>> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>> 
>> I need to present the results as stacked bar charts where the variables
>> are columns and the percentages of the scales values (1 .. 4) are the
>> chunks of the stacked bar for each variable. To do this I have
> transformed
>> my data from wide to long and calculated the percentage for each
> variable
>> and value. The code for this is as follows:
>> 
>> -- cut --
>> 
>> dfr <- structure(
>>  list(
>>    v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>>               4, 4, 4, 1, 1, 3, 3, 4),
>>    v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>>               4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>>    v07_03 = c(3, 2, 2, 1, 4, 1,
>>               2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>>    v07_04 = c(3, 1, 1,
>>               4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>>    v07_05 = c(1,
>>               2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>>    v07_06 = c(1,
>>               2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>>    v07_07 = c(3,
>>               2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>>    v07_08 = c(3,
>>               2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>>    cased_id = structure(
>>      1:20,
>>      .Label = c(
>>        "1",
>>        "2",
>>        "3",
>>        "4",
>>        "5",
>>        "6",
>>        "7",
>>        "8",
>>        "9",
>>        "10",
>>        "11",
>>        "12",
>>        "13",
>>        "14",
>>        "15",
>>        "16",
>>        "17",
>>        "18",
>>        "19",
>>        "20"
>>      ),
>>      class = "factor"
>>    )
>>  ),
>>  .Names = c(
>>    "v07_01",
>>    "v07_02",
>>    "v07_03",
>>    "v07_04",
>>    "v07_05",
>>    "v07_06",
>>    "v07_07",
>>    "v07_08",
>>    "cased_id"
>>  ),
>>  row.names = c(NA, -20L),
>>  class = c("tbl_df", "tbl",
>>            "data.frame")
>> )
>> 
>> mdf <- melt(df)
>> d_result <- mdf  %>%
>>  dplyr::group_by(variable) %>%
>>  count(value)
>> 
>> ggplot(
>>  d_result,
>>  aes(variable, y = n, fill = value)) +
>>  geom_bar(stat = "identity") +
>>  coord_cartesian(ylim = c(0,100))
>> 
>> -- cut --
>> 
>> Is there an easier way of doing this, i. e. a way without need to
>> transform the data?
>> 
>> How can I change the colors for the data points 1 .. 4?
>> 
>> I tried
>> 
>> -- cut --
>> 
>>  d_result,
>>  aes(variable, y = n, fill = value)) +
>>  geom_bar(stat = "identity") +
>>  coord_cartesian(ylim = c(0,100)) +
>>  scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>> 
>> -- cut -
>> 
>> but this does not work cause I am mixing continuous and descrete values.
>> 
>> How can I change the colors for the bars?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Apr 10 22:21:46 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Apr 2017 13:21:46 -0700
Subject: [R] Antwort: Re: Antwort: Re: Way to Plot Multiple Variables
	and Change Color
In-Reply-To: <638BA55D-3D17-4D87-A806-90B894D36FF3@comcast.net>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
 <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
 <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
 <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>
 <OF779EC1FB.95EE8CEC-ONC12580FE.00503181-C12580FE.005112BC@lotus.hawesko.de>
 <638BA55D-3D17-4D87-A806-90B894D36FF3@comcast.net>
Message-ID: <1FA85D6E-65D5-4DC7-87E8-C5A1AE762B87@comcast.net>


> On Apr 10, 2017, at 1:06 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 10, 2017, at 7:45 AM, G.Maubach at weinwolf.de wrote:
>> 
>> Hi Ulrik,
>> 
>> many thanks for your reply. I had to take an unplanned break and was not 
>> in the office during the last two weeks. Thus my late reply.
>> 
>> I followed your advice and converted the variable in argument "fill" to 
>> factor. Now the color change works:
>> 
>> -- cut --
>> 
>> d_result <- structure(list("variable" = c("Item 1 (? = 3.3) ", "Item 1 (? = 3.3) ",
>>                                       "Item 1 (? = 3.3) ", "Item 1 (? = 3.3) ", "Item 1 (? = 3.3) ",
>>                                       "Item 1 (? = 3.3) ", "Item 2 (? = 3.8) ", "Item 2 (? = 3.8) ",
>>                                       "Item 2 (? = 3.8) ", "Item 2 (? = 3.8) ", "Item 2 (? = 3.8) ",
>>                                       "Item 2 (? = 3.8) ", "Item 3 (? = 3.4) ", "Item 3 (? = 3.4) ",
>>                                       "Item 3 (? = 3.4) ", "Item 3 (? = 3.4) ", "Item 3 (? = 3.4) ",
>>                                       "Item 3 (? = 3.4) ", "Item 4 (? = 3.4) ", "Item 4 (? = 3.4) ",
>>                                       "Item 4 (? = 3.4) ", "Item 4 (? = 3.4) ", "Item 4 (? = 3.4) ",
>>                                       "Item 4 (? = 3.4) ", "Item 5 (? = 3.5) ", "Item 5 (? = 3.5) ",
>>                                       "Item 5 (? = 3.5) ", "Item 5 (? = 3.5) ", "Item 5 (? = 3.5) ",
>>                                       "Item 5 (? = 3.5) ", "Item 6 (? = 3.5) ", "Item 6 (? = 3.5) ",
>>                                       "Item 6 (? = 3.5) ", "Item 6 (? = 3.5) ", "Item 6 (? = 3.5) ",
>>                                       "Item 6 (? = 3.5) ", "Item 7 (? = 3.4) ", "Item 7 (? = 3.4) ",
>>                                       "Item 7 (? = 3.4) ", "Item 7 (? = 3.4) ", "Item 7 (? = 3.4) ",
>>                                       "Item 7 (? = 3.4) ", "Item 8 (? = 3.3) ", "Item 8 (? = 3.3) ",
>>                                       "Item 8 (? = 3.3) ", "Item 8 (? = 3.3) ", "Item 8 (? = 3.3) ",
>>                                       "Item 8 (? = 3.3) "), value = 
>> structure(c(1L, 2L, 3L, 4L, 5L,
>>       6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
>>       4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L,
>>       2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("1 = very 
>> satisfied",
>>                                                               "2", "3", 
>> "4", "5", "6 = very dissatified"), class = "factor"),
>>                          n = c(14L, 20L, 24L, 14L, 16L, 14L, 9L, 15L, 
>> 21L, 20L, 14L,
>>                                23L, 19L, 17L, 16L, 14L, 16L, 20L, 22L, 
>> 17L, 15L, 16L, 20L,
>>                                12L, 19L, 15L, 16L, 15L, 18L, 19L, 18L, 
>> 15L, 18L, 18L, 16L,
>>                                17L, 17L, 20L, 17L, 17L, 14L, 16L, 16L, 
>> 25L, 16L, 17L, 8L,
>>                                20L)), .Names = c("variable", "value", 
>> "n"), row.names =
>>                       c(NA,
>>                         -48L), vars = list("variable"), drop = TRUE, 
>> indices =
>>                       list(0:5,
>>                            6:11, 12:17, 18:23, 24:29, 30:35, 36:41, 
>> 42:47),
>>                     group_sizes = c(6L,
>>                                     6L, 6L, 6L, 6L, 6L, 6L, 6L),
>>                     biggest_group_size = 6L,
>>                     labels = structure(list(
>>                       "variable" = structure(1:8, .Label = c("Item 1 (? 
>> = 3.3) ",
>>                                                            "Item 2 (? = 
>> 3.8) ", "Item 3 (? = 3.4) ", "Item 4 (? = 3.4) ",
>>                                                            "Item 5 (? = 
>> 3.5) ", "Item 6 (? = 3.5) ", "Item 7 (? = 3.4) ",
>>                                                            "Item 8 (? = 
>> 3.3) "), class = "factor")),
>>                       row.names = c(NA,
>>                                     -8L), class = "data.frame", vars = 
>> list("variable"),
>>                       drop = TRUE, .Names = "variable"),
>>                     class = c("grouped_df",
>>                               "tbl_df", "tbl", "data.frame"))
>> 
>> ggplot(
>> d_result,
>> aes(x = variable, y = n, fill = rev(factor(value)))) +
>> geom_bar(
>>   stat = "identity") +
>> coord_cartesian(ylim = c(0,100)) +
>> coord_flip() +
>> scale_y_continuous(name = "Percent") +
>> scale_fill_manual(
>>   values = rev(
>>     c(
>>       "forestgreen", "limegreen",
>>       "gold", "orange1",
>>       "tomato3", "darkred"))) +
>> ggtitle(
>>   paste(
>>     "Question 8: Satisfaction?")) +
>> labs(fill = "Rating") +
>> scale_x_discrete(
>>   name = element_blank()) +
>> # scale_color_manual(
>> #   values = rev(
>> #     c(
>> #       "forestgreen", "limegreen",
>> #       "gold", "orange1",
>> #       "tomato3", "darkred"))) +
>> geom_text(
>>   aes(label = n),
>>   color = "white",
>>   position = position_stack(vjust = 0.5)) +
>> theme_minimal() +
>> theme(
>>   legend.position = "right")
>> 
>> -- cut --
>> 
>> I tried to change the order of the items on the y-axis,  e.g. Item 8 
>> should be last and Item 1 first.
> 
> "First" and "last" apparently mean "top" and "bottom" to you. Since the $variable column is character, and ordering is typically done by setting levels of factors, try:
> 
> d_result$variable <- factor(d_result$variable, levels=rev(unique(d_result$variable)))
> 
> 
> # changes ordering so the "Item 1"'s are at the top.
> 
> 
>> I tried to reverse the order of the items 
>> within ggplot using rev() and relevel(). But neither of them worked. Is 
>> there a way to do it?
> 
> I don't think you can relevel a character column.
>> 
>> I also tried to adjust the color palette for the legend, e.g. 1 = very 
>> satisfied is green, 6 = very dissatified is red instead of vice versa as 
>> it is now. The result should ensure the item naming for 1 = satisfied and 
>> 6 = unsatifies cause this is the way it was asked in the questionnaire.
>> 
>> Thus my question is:
>> 
>> 1. How can I change the order of the sequence for the y-axis?
>> 
>> 2. How can I adjust the color palette of the legend that it matches the 
>> correct items?
> 
> You probably could use relevel sinc `value` was a factor but I found it easier to simply repeat the relevelling code and change the target column name:
> 
> d_result$value <- factor(d_result$value, levels=rev(unique(d_result$value)))
> 
> I did find the appearance of the final result stange because there was irregular use of "\n" in the "variable" character values. that created more items than I think you wanted to appear.

I edited the code above to take out the inadvertent linefeeds (which got inserted by some part of the mail-processing chain) and then ran the ggplot call inside pdf() and print(...):
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 5539 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170410/346c3c9b/attachment.pdf>
-------------- next part --------------



HTH;
David.


>> 
>> Can you give me a hint which functions I could use to do it?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> 
>> 
>> 
>> Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
>> An:     G.Maubach at weinwolf.de, "Richard M. Heiberger" <rmh at temple.edu>, 
>> Kopie:  r-help <r-help at r-project.org>
>> Datum:  28.03.2017 18:32
>> Betreff:        Re: [R] Antwort: Re: Way to Plot Multiple Variables and 
>> Change Color
>> 
>> 
>> 
>> Hi Georg,
>> 
>> you were on the right path - it is all about scale_fill*
>> 
>> The 'problem' as you've discovered is that value is continuous, but 
>> applying scale_fill_manual or others (except scale_fill_gradient) expects 
>> discrete values.
>> 
>> The solution is simply to set the fill with that by using factor():
>> 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>> or: 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_manual(values = c("red","blue", "green", "purple"))
>> 
>> When using colorBrewer (which I highly recommend), I use scale_*_brewer 
>> rather than setting the colour manually:
>> 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_brewer(palette = "Blues ")
>> 
>> Best,
>> Ulrik
>> 
>> 
>> On Tue, 28 Mar 2017 at 18:21 <G.Maubach at weinwolf.de> wrote:
>> Hi Richard,
>> 
>> many thanks for your reply.
>> 
>> Your solution is not exactly what I was looking for. I would like to know
>> how I can change the colors of the stacked bars in my plot and not use the
>> default values. How can this be done?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> 
>> 
>> 
>> Von:    "Richard M. Heiberger" <rmh at temple.edu>
>> An:     G.Maubach at weinwolf.de,
>> Kopie:  r-help <r-help at r-project.org>
>> Datum:  28.03.2017 17:40
>> Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color
>> 
>> 
>> 
>> I think you are looking for the likert function in the HH package.
>>> From ?likert
>> 
>> 
>> Diverging stacked barcharts for Likert, semantic differential, rating
>> scale data, and population pyramids.
>> 
>> 
>> This will get you started.  Much more fine control is available.  See
>> the examples and demo.
>> 
>> ## install.packages("HH") ## if not yet on your system.
>> 
>> library(HH)
>> 
>> AA <- dfr[,-9]
>> 
>> labels <- sort(unique(as.vector(data.matrix(AA))))
>> result.template <- integer(length(labels))
>> names(result.template) <- labels
>> 
>> BB <- apply(AA, 2, function(x, result=result.template) {
>> tx <- table(x)
>> result[names(tx)] <- tx
>> result
>> }
>> )
>> 
>> BB
>> 
>> likert(t(BB), ReferenceZero=0, horizontal=FALSE)
>> 
>> 
>> On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
>>> Hi All,
>>> 
>>> in my current project I have to plot a whole bunch of related variables
>>> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
>> Power,
>>> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>>> 
>>> I need to present the results as stacked bar charts where the variables
>>> are columns and the percentages of the scales values (1 .. 4) are the
>>> chunks of the stacked bar for each variable. To do this I have
>> transformed
>>> my data from wide to long and calculated the percentage for each
>> variable
>>> and value. The code for this is as follows:
>>> 
>>> -- cut --
>>> 
>>> dfr <- structure(
>>> list(
>>>   v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>>>              4, 4, 4, 1, 1, 3, 3, 4),
>>>   v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>>>              4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>>>   v07_03 = c(3, 2, 2, 1, 4, 1,
>>>              2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>>>   v07_04 = c(3, 1, 1,
>>>              4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>>>   v07_05 = c(1,
>>>              2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>>>   v07_06 = c(1,
>>>              2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>>>   v07_07 = c(3,
>>>              2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>>>   v07_08 = c(3,
>>>              2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>>>   cased_id = structure(
>>>     1:20,
>>>     .Label = c(
>>>       "1",
>>>       "2",
>>>       "3",
>>>       "4",
>>>       "5",
>>>       "6",
>>>       "7",
>>>       "8",
>>>       "9",
>>>       "10",
>>>       "11",
>>>       "12",
>>>       "13",
>>>       "14",
>>>       "15",
>>>       "16",
>>>       "17",
>>>       "18",
>>>       "19",
>>>       "20"
>>>     ),
>>>     class = "factor"
>>>   )
>>> ),
>>> .Names = c(
>>>   "v07_01",
>>>   "v07_02",
>>>   "v07_03",
>>>   "v07_04",
>>>   "v07_05",
>>>   "v07_06",
>>>   "v07_07",
>>>   "v07_08",
>>>   "cased_id"
>>> ),
>>> row.names = c(NA, -20L),
>>> class = c("tbl_df", "tbl",
>>>           "data.frame")
>>> )
>>> 
>>> mdf <- melt(df)
>>> d_result <- mdf  %>%
>>> dplyr::group_by(variable) %>%
>>> count(value)
>>> 
>>> ggplot(
>>> d_result,
>>> aes(variable, y = n, fill = value)) +
>>> geom_bar(stat = "identity") +
>>> coord_cartesian(ylim = c(0,100))
>>> 
>>> -- cut --
>>> 
>>> Is there an easier way of doing this, i. e. a way without need to
>>> transform the data?
>>> 
>>> How can I change the colors for the data points 1 .. 4?
>>> 
>>> I tried
>>> 
>>> -- cut --
>>> 
>>> d_result,
>>> aes(variable, y = n, fill = value)) +
>>> geom_bar(stat = "identity") +
>>> coord_cartesian(ylim = c(0,100)) +
>>> scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>>> 
>>> -- cut -
>>> 
>>> but this does not work cause I am mixing continuous and descrete values.
>>> 
>>> How can I change the colors for the bars?
>>> 
>>> Kind regards
>>> 
>>> Georg
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Mon Apr 10 22:38:50 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 11 Apr 2017 08:38:50 +1200
Subject: [R] [FORGED]  hier.part limitation
In-Reply-To: <AM4PR0701MB217735457C2D5B7F4BFA70BFE7010@AM4PR0701MB2177.eurprd07.prod.outlook.com>
References: <AM4PR0701MB217735457C2D5B7F4BFA70BFE7010@AM4PR0701MB2177.eurprd07.prod.outlook.com>
Message-ID: <48159df3-ff7d-90cb-8601-79351cce978d@auckland.ac.nz>

On 10/04/17 21:33, Abdel-Rahman, Elfatih wrote:
> Dear all,
>
> Does the package "hier.part" limited to only 12 predictor variables.
> I  was trying to use it to partition (select) the most relevant predictor
> variables our of 30 ones, and I always get an error message says:
> "Error: Number of variables must be < 13 for current implementation"

Uh, why do you suppose that the function puts out that error message?

If you want a function that handles 13 or more variables you'll have to 
write it yourself.

cheers,

Rolf Turner

P. S. I have no knowledge whatever of hier.part(), so I have no insight 
as to why that restriction is there, but I imagine there's a good 
reason, for some value of "good".

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From axel.urbiz at gmail.com  Tue Apr 11 00:55:11 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 10 Apr 2017 18:55:11 -0400
Subject: [R] Combining grid::grid.raster plots
Message-ID: <CAAyVsXKbAn7pat0WjQjdy_LfJxpMyK4qcKFUz2Acu=LwNmZpSw@mail.gmail.com>

Dear Group,

I'd like to combine many grid::grid.raster plots into a single layout.

Here's my attempt, which does not work (i.e., does not combine the 9 images
into a single plot layout).

require(grid)

random_image <- function() {

  r <- matrix(sample(1:255, 32 * 32, replace = TRUE), nrow = 32, ncol = 32)
  g <- matrix(sample(1:255, 32 * 32, replace = TRUE), nrow = 32, ncol = 32)
  b <- matrix(sample(1:255, 32 * 32, replace = TRUE), nrow = 32, ncol = 32)
  img <- rgb(r, g, b, maxColorValue = 255)
  dim(img) <- c(32, 32)
  img

}

set.seed(1)
layout(matrix(1:9,nr=3,byr=T))
for (i in 1:9) {
 image <- random_image()
 grid.raster(image)
}

Any guidance would be highly appreciated.

Best,
Axel.

	[[alternative HTML version deleted]]


From eabdel-Rahman at icipe.org  Mon Apr 10 22:47:03 2017
From: eabdel-Rahman at icipe.org (Abdel-Rahman, Elfatih)
Date: Mon, 10 Apr 2017 20:47:03 +0000
Subject: [R] [FORGED]  hier.part limitation
In-Reply-To: <48159df3-ff7d-90cb-8601-79351cce978d@auckland.ac.nz>
References: <AM4PR0701MB217735457C2D5B7F4BFA70BFE7010@AM4PR0701MB2177.eurprd07.prod.outlook.com>
 <48159df3-ff7d-90cb-8601-79351cce978d@auckland.ac.nz>
Message-ID: <AM4PR0701MB2177D57C18DA3F74E6BE2B6FE7010@AM4PR0701MB2177.eurprd07.prod.outlook.com>

Dear Rolf Turner,

Thank you so much for your prompt and useful reply.

Regards
Elfatih

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Monday, April 10, 2017 11:39 PM
To: Abdel-Rahman, Elfatih
Cc: r-help at stat.math.ethz.ch
Subject: Re: [FORGED] [R] hier.part limitation

On 10/04/17 21:33, Abdel-Rahman, Elfatih wrote:
> Dear all,
>
> Does the package "hier.part" limited to only 12 predictor variables.
> I  was trying to use it to partition (select) the most relevant 
> predictor variables our of 30 ones, and I always get an error message says:
> "Error: Number of variables must be < 13 for current implementation"

Uh, why do you suppose that the function puts out that error message?

If you want a function that handles 13 or more variables you'll have to write it yourself.

cheers,

Rolf Turner

P. S. I have no knowledge whatever of hier.part(), so I have no insight as to why that restriction is there, but I imagine there's a good reason, for some value of "good".

R. T.

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From justinenasejje at gmail.com  Mon Apr 10 22:59:17 2017
From: justinenasejje at gmail.com (Justine Nasejje)
Date: Mon, 10 Apr 2017 22:59:17 +0200
Subject: [R] Help
Message-ID: <CAGjsBx2CydROrDb18xX31MpTZ4HkdjQgzUDH+h6G_icrZEU-RA@mail.gmail.com>

Hello,
      How can one extract variance of the survival curve estimates from
Random survival forests.Thanks in advance.

	[[alternative HTML version deleted]]


From mael.lenoc at txstate.edu  Tue Apr 11 00:27:29 2017
From: mael.lenoc at txstate.edu (=?UTF-8?Q?Ma=c3=abl_Le_Noc?=)
Date: Mon, 10 Apr 2017 17:27:29 -0500
Subject: [R] dnearneigh() from spdep: Points with the exact same location
 are not considered neighbours.
Message-ID: <b6eb276d-db3d-07d9-4d79-a41c7c0179a6@txstate.edu>

Dear List

As I was working on a project, I realized that when I use dnearneigh
from spdep, two (or more) points that have the exact same coordinates
are not considered neighbours and thus are not linked (even when the
lower bound is put to 0 or even to -1). See below for an example.

Does the function behave the same way for you? Am I missing something?
Is this an expected behavior? And if so, if there a way to change that ?

In the example below, points 1 and 2 are not connected to each other/are
not neighbours (as you can see since the both have only one link, to 3),
even though they have the exact same coordinates (and are thus less than
25km apart), while point 3 is connected to both point 1 and 2.
If I want to assess autocorelation using, for instance joincount.test,
this is then an issue...

> library(data.table)
> library(spdep)
> pointstable <- data.table(XCoord=c(13.667029,13.667029,13.667028),
YCoord=c(42.772396,42.772396,42.772396))
> print(pointstable)
     XCoord  YCoord
1: 13.667029 42.772396
2: 13.667029 42.772396
3: 13.667028 42.772396
> coords <-cbind(pointstable$XCoord, pointstable$YCoord)
> nbLocal<- dnearneigh(coords, d1=0, d2=25, longlat = TRUE)
> nbLocal<- dnearneigh(coords, d1=-1, d2=25, longlat = TRUE) #both lines
produce the same output
> summary(nbLocal)
Neighbour list object:
Number of regions: 3
Number of nonzero links: 4
Percentage nonzero weights: 44.44444
Average number of links: 1.333333
Link number distribution:

1 2
2 1
2 least connected regions:
1 2 with 1 link
1 most connected region:
3 with 2 links
>

Thanks
Ma?l


From oluola2011 at yahoo.com  Tue Apr 11 01:11:30 2017
From: oluola2011 at yahoo.com (Olu Ola)
Date: Mon, 10 Apr 2017 23:11:30 +0000 (UTC)
Subject: [R] Eliminating numbers, period, and space from a string
References: <1281621691.129231.1491865890457.ref@mail.yahoo.com>
Message-ID: <1281621691.129231.1491865890457@mail.yahoo.com>

 Hello,I have a column of my?data of the Following format
10. Arnold125. Jessica1. Romeo117. Juliet
I need to eliminate the numbers, period, and the space before the names so that I have the following:
ArnoldJessicaRomeoJuliet
I tried using the gsub function but my code came up with errors.
Any help will be appreciated.
Thank you.


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue Apr 11 04:51:08 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 10 Apr 2017 22:51:08 -0400
Subject: [R] Eliminating numbers, period, and space from a string
In-Reply-To: <1281621691.129231.1491865890457@mail.yahoo.com>
References: <1281621691.129231.1491865890457.ref@mail.yahoo.com>
 <1281621691.129231.1491865890457@mail.yahoo.com>
Message-ID: <5B0397D6-03E6-412E-A5A7-03C1017990BD@utoronto.ca>

Fie, knave, dost thou bid us do thine homework!

gsub("[^A-Za-z]", "", <string>)



> On Apr 10, 2017, at 7:11 PM, Olu Ola via R-help <r-help at r-project.org> wrote:
> 
> Hello,I have a column of my data of the Following format
> 10. Arnold125. Jessica1. Romeo117. Juliet
> I need to eliminate the numbers, period, and the space before the names so that I have the following:
> ArnoldJessicaRomeoJuliet
> I tried using the gsub function but my code came up with errors.
> Any help will be appreciated.
> Thank you.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue Apr 11 14:03:18 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 11 Apr 2017 14:03:18 +0200
Subject: [R] Antwort: Re: Antwort: Re: Antwort: Re: Way to Plot Multiple
 Variables and Change Color (SOLVED)
In-Reply-To: <1FA85D6E-65D5-4DC7-87E8-C5A1AE762B87@comcast.net>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
 <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
 <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
 <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>
 <OF779EC1FB.95EE8CEC-ONC12580FE.00503181-C12580FE.005112BC@lotus.hawesko.de>
 <638BA55D-3D17-4D87-A806-90B894D36FF3@comcast.net>
 <1FA85D6E-65D5-4DC7-87E8-C5A1AE762B87@comcast.net>
Message-ID: <OF7C801E9D.AA330BD7-ONC12580FF.00417F13-C12580FF.004237F1@lotus.hawesko.de>

Hi David,

many thanks for your answer.

I followed your suggesting and came up with the following code:

-- cut --

ggplot(
  d_result,
  aes(x = variable, y = n, fill = value)) +
  geom_bar(
    stat = "identity") +
  coord_cartesian(ylim = c(0,100)) +
  coord_flip() +
  scale_y_continuous(name = "Percent") +
  scale_fill_manual(
    values = rev(
      c(
        "forestgreen", "limegreen",
        "gold", "orange1",
        "tomato3", "darkred"))) +
  ggtitle(
    paste(
      "Question 8: Some Text")) +
  labs(fill = "Rating") +
  scale_x_discrete(
    name = element_blank(),
    drop = FALSE) +  # keep factor levels if no value exists
  geom_text(
    aes(label = n),
    color = "white",
    position = position_stack(vjust = 0.5)) +
  theme_minimal() +
  theme(
    legend.position = "right") +
  guides(fill = guide_legend(reverse = TRUE))

-- cut --

In addition to your suggestion I changed "fill = rev(factor(value))" to 
"fill = value" and I added

guides(fill = guide_legend(reverse = TRUE))

to get the legend in the order from 1 .. 6 instead of 6 .. 1.

In my data I added the counts (n) before the mean value in the labels of 
the left hand side. Now it looks to me as a version conforming to the 
ESOMAR and BVM standards.

Many thanks again for your help.

Kind regards

Georg




Von:    David Winsemius <dwinsemius at comcast.net>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help at r-project.org
Datum:  10.04.2017 22:21
Betreff:        Re: [R] Antwort: Re: Antwort: Re: Way to Plot Multiple 
Variables and Change Color




> On Apr 10, 2017, at 1:06 PM, David Winsemius <dwinsemius at comcast.net> 
wrote:
> 
> 
>> On Apr 10, 2017, at 7:45 AM, G.Maubach at weinwolf.de wrote:
>> 
>> Hi Ulrik,
>> 
>> many thanks for your reply. I had to take an unplanned break and was 
not 
>> in the office during the last two weeks. Thus my late reply.
>> 
>> I followed your advice and converted the variable in argument "fill" to 

>> factor. Now the color change works:
>> 
>> -- cut --
>> 
>> d_result <- structure(list("variable" = c("Item 1 (? = 3.3) ", "Item 1 
(? = 3.3) ",
>>                                       "Item 1 (? = 3.3) ", "Item 1 (? = 
3.3) ", "Item 1 (? = 3.3) ",
>>                                       "Item 1 (? = 3.3) ", "Item 2 (? = 
3.8) ", "Item 2 (? = 3.8) ",
>>                                       "Item 2 (? = 3.8) ", "Item 2 (? = 
3.8) ", "Item 2 (? = 3.8) ",
>>                                       "Item 2 (? = 3.8) ", "Item 3 (? = 
3.4) ", "Item 3 (? = 3.4) ",
>>                                       "Item 3 (? = 3.4) ", "Item 3 (? = 
3.4) ", "Item 3 (? = 3.4) ",
>>                                       "Item 3 (? = 3.4) ", "Item 4 (? = 
3.4) ", "Item 4 (? = 3.4) ",
>>                                       "Item 4 (? = 3.4) ", "Item 4 (? = 
3.4) ", "Item 4 (? = 3.4) ",
>>                                       "Item 4 (? = 3.4) ", "Item 5 (? = 
3.5) ", "Item 5 (? = 3.5) ",
>>                                       "Item 5 (? = 3.5) ", "Item 5 (? = 
3.5) ", "Item 5 (? = 3.5) ",
>>                                       "Item 5 (? = 3.5) ", "Item 6 (? = 
3.5) ", "Item 6 (? = 3.5) ",
>>                                       "Item 6 (? = 3.5) ", "Item 6 (? = 
3.5) ", "Item 6 (? = 3.5) ",
>>                                       "Item 6 (? = 3.5) ", "Item 7 (? = 
3.4) ", "Item 7 (? = 3.4) ",
>>                                       "Item 7 (? = 3.4) ", "Item 7 (? = 
3.4) ", "Item 7 (? = 3.4) ",
>>                                       "Item 7 (? = 3.4) ", "Item 8 (? = 
3.3) ", "Item 8 (? = 3.3) ",
>>                                       "Item 8 (? = 3.3) ", "Item 8 (? = 
3.3) ", "Item 8 (? = 3.3) ",
>>                                       "Item 8 (? = 3.3) "), value = 
>> structure(c(1L, 2L, 3L, 4L, 5L,
>>       6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
>>       4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L, 1L,
>>       2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("1 = very 

>> satisfied",
>>                                                               "2", "3", 

>> "4", "5", "6 = very dissatified"), class = "factor"),
>>                          n = c(14L, 20L, 24L, 14L, 16L, 14L, 9L, 15L, 
>> 21L, 20L, 14L,
>>                                23L, 19L, 17L, 16L, 14L, 16L, 20L, 22L, 
>> 17L, 15L, 16L, 20L,
>>                                12L, 19L, 15L, 16L, 15L, 18L, 19L, 18L, 
>> 15L, 18L, 18L, 16L,
>>                                17L, 17L, 20L, 17L, 17L, 14L, 16L, 16L, 
>> 25L, 16L, 17L, 8L,
>>                                20L)), .Names = c("variable", "value", 
>> "n"), row.names =
>>                       c(NA,
>>                         -48L), vars = list("variable"), drop = TRUE, 
>> indices =
>>                       list(0:5,
>>                            6:11, 12:17, 18:23, 24:29, 30:35, 36:41, 
>> 42:47),
>>                     group_sizes = c(6L,
>>                                     6L, 6L, 6L, 6L, 6L, 6L, 6L),
>>                     biggest_group_size = 6L,
>>                     labels = structure(list(
>>                       "variable" = structure(1:8, .Label = c("Item 1 (? 

>> = 3.3) ",
>>                                                            "Item 2 (? = 

>> 3.8) ", "Item 3 (? = 3.4) ", "Item 4 (? = 3.4) ",
>>                                                            "Item 5 (? = 

>> 3.5) ", "Item 6 (? = 3.5) ", "Item 7 (? = 3.4) ",
>>                                                            "Item 8 (? = 

>> 3.3) "), class = "factor")),
>>                       row.names = c(NA,
>>                                     -8L), class = "data.frame", vars = 
>> list("variable"),
>>                       drop = TRUE, .Names = "variable"),
>>                     class = c("grouped_df",
>>                               "tbl_df", "tbl", "data.frame"))
>> 
>> ggplot(
>> d_result,
>> aes(x = variable, y = n, fill = rev(factor(value)))) +
>> geom_bar(
>>   stat = "identity") +
>> coord_cartesian(ylim = c(0,100)) +
>> coord_flip() +
>> scale_y_continuous(name = "Percent") +
>> scale_fill_manual(
>>   values = rev(
>>     c(
>>       "forestgreen", "limegreen",
>>       "gold", "orange1",
>>       "tomato3", "darkred"))) +
>> ggtitle(
>>   paste(
>>     "Question 8: Satisfaction?")) +
>> labs(fill = "Rating") +
>> scale_x_discrete(
>>   name = element_blank()) +
>> # scale_color_manual(
>> #   values = rev(
>> #     c(
>> #       "forestgreen", "limegreen",
>> #       "gold", "orange1",
>> #       "tomato3", "darkred"))) +
>> geom_text(
>>   aes(label = n),
>>   color = "white",
>>   position = position_stack(vjust = 0.5)) +
>> theme_minimal() +
>> theme(
>>   legend.position = "right")
>> 
>> -- cut --
>> 
>> I tried to change the order of the items on the y-axis,  e.g. Item 8 
>> should be last and Item 1 first.
> 
> "First" and "last" apparently mean "top" and "bottom" to you. Since the 
$variable column is character, and ordering is typically done by setting 
levels of factors, try:
> 
> d_result$variable <- factor(d_result$variable, 
levels=rev(unique(d_result$variable)))
> 
> 
> # changes ordering so the "Item 1"'s are at the top.
> 
> 
>> I tried to reverse the order of the items 
>> within ggplot using rev() and relevel(). But neither of them worked. Is 

>> there a way to do it?
> 
> I don't think you can relevel a character column.
>> 
>> I also tried to adjust the color palette for the legend, e.g. 1 = very 
>> satisfied is green, 6 = very dissatified is red instead of vice versa 
as 
>> it is now. The result should ensure the item naming for 1 = satisfied 
and 
>> 6 = unsatifies cause this is the way it was asked in the questionnaire.
>> 
>> Thus my question is:
>> 
>> 1. How can I change the order of the sequence for the y-axis?
>> 
>> 2. How can I adjust the color palette of the legend that it matches the 

>> correct items?
> 
> You probably could use relevel sinc `value` was a factor but I found it 
easier to simply repeat the relevelling code and change the target column 
name:
> 
> d_result$value <- factor(d_result$value, 
levels=rev(unique(d_result$value)))
> 
> I did find the appearance of the final result stange because there was 
irregular use of "\n" in the "variable" character values. that created 
more items than I think you wanted to appear.

I edited the code above to take out the inadvertent linefeeds (which got 
inserted by some part of the mail-processing chain) and then ran the 
ggplot call inside pdf() and print(...):
[Anhang "Rplots.pdf" gel?scht von Georg Maubach/WWBO/WW/HAW] 


HTH;
David.


>> 
>> Can you give me a hint which functions I could use to do it?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> 
>> 
>> 
>> Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
>> An:     G.Maubach at weinwolf.de, "Richard M. Heiberger" <rmh at temple.edu>, 

>> Kopie:  r-help <r-help at r-project.org>
>> Datum:  28.03.2017 18:32
>> Betreff:        Re: [R] Antwort: Re: Way to Plot Multiple Variables and 

>> Change Color
>> 
>> 
>> 
>> Hi Georg,
>> 
>> you were on the right path - it is all about scale_fill*
>> 
>> The 'problem' as you've discovered is that value is continuous, but 
>> applying scale_fill_manual or others (except scale_fill_gradient) 
expects 
>> discrete values.
>> 
>> The solution is simply to set the fill with that by using factor():
>> 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>> or: 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_manual(values = c("red","blue", "green", "purple"))
>> 
>> When using colorBrewer (which I highly recommend), I use scale_*_brewer 

>> rather than setting the colour manually:
>> 
>> ggplot(
>> d_result,
>> aes(variable, y = n, fill = factor(value))) +
>> geom_bar(stat = "identity") +
>> scale_fill_brewer(palette = "Blues ")
>> 
>> Best,
>> Ulrik
>> 
>> 
>> On Tue, 28 Mar 2017 at 18:21 <G.Maubach at weinwolf.de> wrote:
>> Hi Richard,
>> 
>> many thanks for your reply.
>> 
>> Your solution is not exactly what I was looking for. I would like to 
know
>> how I can change the colors of the stacked bars in my plot and not use 
the
>> default values. How can this be done?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> 
>> 
>> 
>> Von:    "Richard M. Heiberger" <rmh at temple.edu>
>> An:     G.Maubach at weinwolf.de,
>> Kopie:  r-help <r-help at r-project.org>
>> Datum:  28.03.2017 17:40
>> Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color
>> 
>> 
>> 
>> I think you are looking for the likert function in the HH package.
>>> From ?likert
>> 
>> 
>> Diverging stacked barcharts for Likert, semantic differential, rating
>> scale data, and population pyramids.
>> 
>> 
>> This will get you started.  Much more fine control is available.  See
>> the examples and demo.
>> 
>> ## install.packages("HH") ## if not yet on your system.
>> 
>> library(HH)
>> 
>> AA <- dfr[,-9]
>> 
>> labels <- sort(unique(as.vector(data.matrix(AA))))
>> result.template <- integer(length(labels))
>> names(result.template) <- labels
>> 
>> BB <- apply(AA, 2, function(x, result=result.template) {
>> tx <- table(x)
>> result[names(tx)] <- tx
>> result
>> }
>> )
>> 
>> BB
>> 
>> likert(t(BB), ReferenceZero=0, horizontal=FALSE)
>> 
>> 
>> On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
>>> Hi All,
>>> 
>>> in my current project I have to plot a whole bunch of related 
variables
>>> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
>> Power,
>>> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>>> 
>>> I need to present the results as stacked bar charts where the 
variables
>>> are columns and the percentages of the scales values (1 .. 4) are the
>>> chunks of the stacked bar for each variable. To do this I have
>> transformed
>>> my data from wide to long and calculated the percentage for each
>> variable
>>> and value. The code for this is as follows:
>>> 
>>> -- cut --
>>> 
>>> dfr <- structure(
>>> list(
>>>   v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>>>              4, 4, 4, 1, 1, 3, 3, 4),
>>>   v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>>>              4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>>>   v07_03 = c(3, 2, 2, 1, 4, 1,
>>>              2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>>>   v07_04 = c(3, 1, 1,
>>>              4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>>>   v07_05 = c(1,
>>>              2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>>>   v07_06 = c(1,
>>>              2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>>>   v07_07 = c(3,
>>>              2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>>>   v07_08 = c(3,
>>>              2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>>>   cased_id = structure(
>>>     1:20,
>>>     .Label = c(
>>>       "1",
>>>       "2",
>>>       "3",
>>>       "4",
>>>       "5",
>>>       "6",
>>>       "7",
>>>       "8",
>>>       "9",
>>>       "10",
>>>       "11",
>>>       "12",
>>>       "13",
>>>       "14",
>>>       "15",
>>>       "16",
>>>       "17",
>>>       "18",
>>>       "19",
>>>       "20"
>>>     ),
>>>     class = "factor"
>>>   )
>>> ),
>>> .Names = c(
>>>   "v07_01",
>>>   "v07_02",
>>>   "v07_03",
>>>   "v07_04",
>>>   "v07_05",
>>>   "v07_06",
>>>   "v07_07",
>>>   "v07_08",
>>>   "cased_id"
>>> ),
>>> row.names = c(NA, -20L),
>>> class = c("tbl_df", "tbl",
>>>           "data.frame")
>>> )
>>> 
>>> mdf <- melt(df)
>>> d_result <- mdf  %>%
>>> dplyr::group_by(variable) %>%
>>> count(value)
>>> 
>>> ggplot(
>>> d_result,
>>> aes(variable, y = n, fill = value)) +
>>> geom_bar(stat = "identity") +
>>> coord_cartesian(ylim = c(0,100))
>>> 
>>> -- cut --
>>> 
>>> Is there an easier way of doing this, i. e. a way without need to
>>> transform the data?
>>> 
>>> How can I change the colors for the data points 1 .. 4?
>>> 
>>> I tried
>>> 
>>> -- cut --
>>> 
>>> d_result,
>>> aes(variable, y = n, fill = value)) +
>>> geom_bar(stat = "identity") +
>>> coord_cartesian(ylim = c(0,100)) +
>>> scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>>> 
>>> -- cut -
>>> 
>>> but this does not work cause I am mixing continuous and descrete 
values.
>>> 
>>> How can I change the colors for the bars?
>>> 
>>> Kind regards
>>> 
>>> Georg
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dncdd at aliyun.com  Tue Apr 11 08:16:54 2017
From: dncdd at aliyun.com (dncdd)
Date: Tue, 11 Apr 2017 14:16:54 +0800
Subject: [R] =?utf-8?q?how_to_plot_three_dimension_data_to_filled_contour_?=
 =?utf-8?q?plot_or_surface_plot_in_R__Ask_Question?=
Message-ID: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>

ENV?

R?3.3.2

When?I?have?data?like:

????rdn<-c(0.8,1.8,2.8)
????tdn<-c(1,2,3,4,5,6,7,8,9)
????
????idn<-matrix(c(0.3,?0.3,?0.3,?0.2,?0.2,?0.4,?0.1,?0.1,?0.5,?0,?0.2,?0.5,?0,?0.3,?0.6,?0,?0.4,?0.6,?0,?0.4,?0.6,?0,?0.5,?0.7,?0,?0.5,?0.7),?nrow=9,?ncol=3,?byrow=T)

And?the?matrix?looks?like(3*9?=?27?data?elements):

????0.3,?0.3,?0.3,?
????0.2,?0.2,?0.4,?
????0.1,?0.1,?0.5,?
????0,?0.2,?0.5,?
????0,?0.3,?0.6,?
????0,?0.4,?0.6,?
????0,?0.4,?0.6,?
????0,?0.5,?0.7,?
????0,?0.5,?0.7

Then?I?can?get?a?filled.contour?with?parameters?x,y,z.?x?is?tdn,?y?is?rdn,?z?is?the?matrix.?I?already?get?this.

?
**My?current?problem**?is:

What?If?I?have?three?dimension?data

????r1dn<-c(0.8,1.8,2.8)
????r2dn<-c(0.8,1.8,2.8)
????tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)

And?(3*3*9?=?81?data?elements):

?????0.8??????????????????1.8??????????????????2.8
????0.8??1.8??2.8???????0.8??1.8??2.8????????0.8??1.8??2.8

????---------------?81?----?elements?----------------------

????0.3,?0.3,?0.3,??????0.3,?0.3,?0.5,???????0.3,?0.3,?0.3,?
????0.2,?0.2,?0.4,??????0.2,?0.4,?0.4,???????0.4,?0.2,?0.5,
????0.1,?0.1,?0.5,??????0.2,?0.3,?0.5,???????0.4,?0.4,?0.5,?
????0,?0.2,?0.5,????????0.2,?0.2,?0.6,???????0.4,?0.5,?0.6,?
????0,?0.3,?0.6,????????0.3,?0.3,?0.6,???????0.5,?0.5,?0.7,?
????0,?0.4,?0.6,????????0.2,?0.5,?0.7,???????0.5,?0.6,?0.7,?
????0,?0.4,?0.6,????????0,?0.5,?0.6,?????????0.5,?0.6,?0.9,??
????0,?0.5,?0.7,????????0,?0.6,?0.8,?????????0.5,?0.7,?0.8,?
????0,?0.5,?0.7?????????0,?0.6,?0.8??????????0.5,?0.8,?0.9???????


I?googled?many?surface?and?contour?codes?but?I?still?not?find?some?code?for?three?dimension?data?yet.?How?to?do?that?in?R??Say,?x?is?r1dn,?y?is?r2dn,?z?is?tdn,?what?about?the?three?dimension?data??Does?ggplot?can?plot?three?dimension?filled?contour?or?surface?plot??Or?another?alternative?solutions?

All?I?expected?is?a?3d?plot?with?color?changes?smoothly?and?no?grid?on?it.

Looks?like:

?
no?grid?for?next?three?figures

?
?
?
Those?should?be?3d?filled?contour?or?3d?surface?plot.

Thanks?for?your?time.


??[1]:?https://i.stack.imgur.com/z6u3p.png
??[2]:?https://i.stack.imgur.com/MEnFn.png
??[3]:?https://i.stack.imgur.com/Ri29w.png
??[4]:?https://i.stack.imgur.com/CdCqL.jpg
??[5]:?https://i.stack.imgur.com/Pt1Nw.jpg
	[[alternative HTML version deleted]]


From sam.albers at gmail.com  Mon Apr 10 18:42:48 2017
From: sam.albers at gmail.com (Sam Albers)
Date: Mon, 10 Apr 2017 09:42:48 -0700
Subject: [R] [R-pkgs] Introducing the rsoi package
Message-ID: <CAKru3AA=Z10d-ww-gMdK-4YhWp9j0s5s-jdFumasfPu9zEvAJA@mail.gmail.com>

Hi folks,

I am pleased to announce that the rsoi is now up on CRAN (v0.2.1
https://CRAN.R-project.org/package=rsoi). rsoi is a minimal but
hopefully useful package to folks that are looking for easy access in
R to Southern Oscillation Index and Oceanic Nino Index data.

rsoi uses data collected by the National Oceanic Atmospheric
Administration. Their data are usually updated monthly. Data are
downloaded and formatted for use in R by the `download_enso()`
function. El Nino, La Nina and neutral periods of ENSO are categorized
by temperature anomalies from a 30 year base period in the Central
South Pacific Ocean.

Suggestions and contributions are very much welcome at the rsoi github
page: https://github.com/boshek/rsoi

-Sam

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewmil at dcn.davis.ca.us  Tue Apr 11 16:27:25 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 11 Apr 2017 07:27:25 -0700
Subject: [R] how to plot three dimension data to filled contour plot or
	surface plot in R Ask Question
In-Reply-To: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
Message-ID: <6C5816F7-E49A-49F7-90F2-533B6E0152E9@dcn.davis.ca.us>

Ggplot does not do xyz. Look at package lattice or package rgl instead.
-- 
Sent from my phone. Please excuse my brevity.

On April 10, 2017 11:16:54 PM PDT, dncdd via R-help <r-help at r-project.org> wrote:
>ENV?
>
>R?3.3.2
>
>When?I?have?data?like:
>
>????rdn<-c(0.8,1.8,2.8)
>????tdn<-c(1,2,3,4,5,6,7,8,9)
>????
>????idn<-matrix(c(0.3,?0.3,?0.3,?0.2,?0.2,?0.4,?0.1,?0.1,?0.5,?0,?0.2,?0.5,?0,?0.3,?0.6,?0,?0.4,?0.6,?0,?0.4,?0.6,?0,?0.5,?0.7,?0,?0.5,?0.7),?nrow=9,?ncol=3,?byrow=T)
>
>And?the?matrix?looks?like(3*9?=?27?data?elements):
>
>????0.3,?0.3,?0.3,?
>????0.2,?0.2,?0.4,?
>????0.1,?0.1,?0.5,?
>????0,?0.2,?0.5,?
>????0,?0.3,?0.6,?
>????0,?0.4,?0.6,?
>????0,?0.4,?0.6,?
>????0,?0.5,?0.7,?
>????0,?0.5,?0.7
>
>Then?I?can?get?a?filled.contour?with?parameters?x,y,z.?x?is?tdn,?y?is?rdn,?z?is?the?matrix.?I?already?get?this.
>
>?
>**My?current?problem**?is:
>
>What?If?I?have?three?dimension?data
>
>????r1dn<-c(0.8,1.8,2.8)
>????r2dn<-c(0.8,1.8,2.8)
>????tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)
>
>And?(3*3*9?=?81?data?elements):
>
>?????0.8??????????????????1.8??????????????????2.8
>????0.8??1.8??2.8???????0.8??1.8??2.8????????0.8??1.8??2.8
>
>????---------------?81?----?elements?----------------------
>
>????0.3,?0.3,?0.3,??????0.3,?0.3,?0.5,???????0.3,?0.3,?0.3,?
>????0.2,?0.2,?0.4,??????0.2,?0.4,?0.4,???????0.4,?0.2,?0.5,
>????0.1,?0.1,?0.5,??????0.2,?0.3,?0.5,???????0.4,?0.4,?0.5,?
>????0,?0.2,?0.5,????????0.2,?0.2,?0.6,???????0.4,?0.5,?0.6,?
>????0,?0.3,?0.6,????????0.3,?0.3,?0.6,???????0.5,?0.5,?0.7,?
>????0,?0.4,?0.6,????????0.2,?0.5,?0.7,???????0.5,?0.6,?0.7,?
>????0,?0.4,?0.6,????????0,?0.5,?0.6,?????????0.5,?0.6,?0.9,??
>????0,?0.5,?0.7,????????0,?0.6,?0.8,?????????0.5,?0.7,?0.8,?
>????0,?0.5,?0.7?????????0,?0.6,?0.8??????????0.5,?0.8,?0.9???????
>
>
>I?googled?many?surface?and?contour?codes?but?I?still?not?find?some?code?for?three?dimension?data?yet.?How?to?do?that?in?R??Say,?x?is?r1dn,?y?is?r2dn,?z?is?tdn,?what?about?the?three?dimension?data??Does?ggplot?can?plot?three?dimension?filled?contour?or?surface?plot??Or?another?alternative?solutions?
>
>All?I?expected?is?a?3d?plot?with?color?changes?smoothly?and?no?grid?on?it.
>
>Looks?like:
>
>?
>no?grid?for?next?three?figures
>
>?
>?
>?
>Those?should?be?3d?filled?contour?or?3d?surface?plot.
>
>Thanks?for?your?time.
>
>
>??[1]:?https://i.stack.imgur.com/z6u3p.png
>??[2]:?https://i.stack.imgur.com/MEnFn.png
>??[3]:?https://i.stack.imgur.com/Ri29w.png
>??[4]:?https://i.stack.imgur.com/CdCqL.jpg
>??[5]:?https://i.stack.imgur.com/Pt1Nw.jpg
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Tue Apr 11 18:48:42 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 11 Apr 2017 19:48:42 +0300
Subject: [R] how to plot three dimension data to filled contour plot or
 surface plot in R Ask Question
In-Reply-To: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
Message-ID: <2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com>

After lon long search, my best shot was to use filled.contour + lattice::levelplot together [a] to represent 3 dimensional data on a flat surface. 

a) http://r.789695.n4.nabble.com/Creating-smooth-color-regions-with-panel-contourplot-td866253.html <http://r.789695.n4.nabble.com/Creating-smooth-color-regions-with-panel-contourplot-td866253.html>

Some Details:

> On 11 Apr 2017, at 09:16, dncdd via R-help <r-help at r-project.org> wrote:
> 
> ENV 
> 
> R 3.3.2
> 
> When I have data like:
> 
>     rdn<-c(0.8,1.8,2.8)
>     tdn<-c(1,2,3,4,5,6,7,8,9)
>     
>     idn<-matrix(c(0.3, 0.3, 0.3, 0.2, 0.2, 0.4, 0.1, 0.1, 0.5, 0, 0.2, 0.5, 0, 0.3, 0.6, 0, 0.4, 0.6, 0, 0.4, 0.6, 0, 0.5, 0.7, 0, 0.5, 0.7), nrow=9, ncol=3, byrow=T)
> 
> And the matrix looks like(3*9 = 27 data elements):
> 
>     0.3, 0.3, 0.3, 
>     0.2, 0.2, 0.4, 
>     0.1, 0.1, 0.5, 
>     0, 0.2, 0.5, 
>     0, 0.3, 0.6, 
>     0, 0.4, 0.6, 
>     0, 0.4, 0.6, 
>     0, 0.5, 0.7, 
>     0, 0.5, 0.7
> 
> Then I can get a filled.contour with parameters x,y,z. x is tdn, y is rdn, z is the matrix. I already get this.

If you have a rectangular data like matrix, you can use filled.contour (the best one) or rasterVis::levelplot.

> 
>  
> **My current problem** is:
> 
> What If I have three dimension data
> 
>     r1dn<-c(0.8,1.8,2.8)
>     r2dn<-c(0.8,1.8,2.8)
>     tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)

At this point, you have to expand your data to x,y,z data pairs. I mean you have to reshaphe your data as a z value for each x and y point. 

data <- expand.grid(x = x, y = y)
dta$z <- z 

Now, you have 3 columns + 9 rows data. You can use this data in lattice::levelplot by awesome formula interface.

> 
> I googled many surface and contour codes but I still not find some code for three dimension data yet. 

Actually you found but they didn?t fill you requirements.

> How to do that in R? Say, x is r1dn, y is r2dn, z is tdn, what about the three dimension data? Does ggplot can plot three dimension filled contour or surface plot? Or another alternative solutions?

The problem here is, you want a filled/contour plot on a flat surface or 3D perspective visualisation? If you want 3D perspective visualisation, your only chances are rgl and misc3d packages. (as far as I know)

> 
> All I expected is a 3d plot with color changes smoothly and no grid on it.

All the solutions above may have (or not) smooth colour change and grid depending on your settings. What do you mean exactly "no grid on it?? If you choose that you don?t have a grid, then you don?t. You only need to search a bit more.

> 
> Looks like: 
> no grid for next three figures
> Those should be 3d filled contour or 3d surface plot.
> Thanks for your time.
> 
>   [1]: https://i.stack.imgur.com/z6u3p.png
>   [2]: https://i.stack.imgur.com/MEnFn.png
>   [3]: https://i.stack.imgur.com/Ri29w.png
>   [4]: https://i.stack.imgur.com/CdCqL.jpg
>   [5]: https://i.stack.imgur.com/Pt1Nw.jpg
> 	[[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue Apr 11 21:15:06 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 11 Apr 2017 22:15:06 +0300
Subject: [R] how to plot three dimension data to filled contour plot or
 surface plot in R Ask Question
In-Reply-To: <4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
 <2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com>
 <4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>
Message-ID: <D43F01AF-92EB-40E8-B4F7-7AE340386F64@gmail.com>


> On 11 Apr 2017, at 20:55, dncdd <dncdd at aliyun.com <mailto:dncdd at aliyun.com>> wrote:
> 
> Thank you Ismail SEZEN.
> The link you give is filled.contour code which only works with my first mini data .

filled.contour + lattice::levelplot solution can handle either matrix or a 3 column (x,y,z) data.frame by using the formula z ~ x + y. 

> 
> The code in the link for R 3.3.2 is :
> ****** code ***** in **** link **** for R 3.3.2 ****
> panel.filledcontour <- function(x, y, z, subscripts, at, col.regions = 
> cm.colors, 
>                                 col = col.regions(length(at) - 1), ...) 
> { 
>   stopifnot(require("gridBase")) 
>   z <- matrix(z[subscripts], 
>               nrow = length(unique(x[subscripts])), 
>               ncol = length(unique(y[subscripts]))) 
>   if (!is.double(z)) storage.mode(z) <- "double" 
>   opar <- par(no.readonly = TRUE) 
>   on.exit(par(opar)) 
>   if (panel.number() > 1) par(new = TRUE) 
>   par(fig = gridFIG(), omi = c(0, 0, 0, 0), mai = c(0, 0, 0, 0)) 
>   cpl <- current.panel.limits() 
>   plot.window(xlim = cpl$xlim, ylim = cpl$ylim, 
>               log = "", xaxs = "i", yaxs = "i") 
>   # paint the color contour regions 
>   .filled.contour(as.double(do.breaks(cpl$xlim, nrow(z) - 1)), 
>                           as.double(do.breaks(cpl$ylim, ncol(z) - 1)), 
>                           z, levels = as.double(at), col = col)
>   # add contour lines 
>   contour(as.double(do.breaks(cpl$xlim, nrow(z) - 1)), 
>           as.double(do.breaks(cpl$ylim, ncol(z) - 1)), 
>           z, levels = as.double(at), add=T, 
>           col = "gray", # color of the lines 
>           drawlabels=F  # add labels or not 
>          ) 
> } 
> plot.new() 
> 
> print(levelplot(volcano, panel = panel.filledcontour, 
>           col.regions = terrain.colors, 
>           cuts = 10, 
>           plot.args = list(newpage = FALSE)))
> *** END *** code *** in *** link *** for R 3.3.2 *** 
> 
> first mini data
> which should be a three dimensinal data either and the data in matrix is not a function of rdn and tdn
> which means z matrix is not function of x,y. 


Here we are not interested in z is function of x and y but at the and, if you want to plot a 3D data on a flat surface, you need x and y for each z in the 3D space.

> 
>     rdn<-c(0.8,1.8,2.8)
>     tdn<-c(1,2,3,4,5,6,7,8,9)
>     
>     idn<-matrix(c(0.3, 0.3, 0.3, 0.2, 0.2, 0.4, 0.1, 0.1, 0.5, 0, 0.2, 0.5, 0, 0.3, 0.6, 0, 0.4, 0.6, 0, 0.4, 0.6, 0, 0.5, 0.7, 0, 0.5, 0.7), nrow=9, ncol=3, byrow=T)
> 
> And the matrix looks like(3*9 = 27 data elements):
> 
>     0.3, 0.3, 0.3, 
>     0.2, 0.2, 0.4, 
>     0.1, 0.1, 0.5, 
>     0, 0.2, 0.5, 
>     0, 0.3, 0.6, 
>     0, 0.4, 0.6, 
>     0, 0.4, 0.6, 
>     0, 0.5, 0.7, 
>     0, 0.5, 0.7

As I mentioned above, you have z values for each x and y values in the space. one of elements of z might be NA/NaN but at last you have.

> 
> 
> Well, now I realized that the second data might (my current problem) be afour dimensional data:
> 
> r1dn<-c(0.8,1.8,2.8)
> r2dn<-c(0.8,1.8,2.8)
> tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)


Thing are changed now. We are living in a 4D space (at least that we can sense) and there are only 2 ways to visualize 4D data on a flat surface. These are your only chance.

1- 3D perspective plotting (one of rgl, misc3d, scatterplot3d). Plot 'points' in the 3D space and set 4th dimension as color for each point.  Does it make sense? I don?t know, it?s up to you.

2- for the (x,y,z,v) dimensions, plot contours of (x,y,v) for each z. I mean, assume z is height, slice it and plot each slice by filled.contour/levelplot or what ever you want.

> 
> And (3*3*9 = 81 data elements):
> 
>      0.8                  1.8                  2.8
>     0.8  1.8  2.8       0.8  1.8  2.8        0.8  1.8  2.8
> 
>     --------------- 81 ---- elements ------three matrix----------------
> 
>     0.3, 0.3, 0.3,      0.3, 0.3, 0.5,       0.3, 0.3, 0.3, 
>     0.2, 0.2, 0.4,      0.2, 0.4, 0.4,       0.4, 0.2, 0.5,
>     0.1, 0.1, 0.5,      0.2, 0.3, 0.5,       0.4, 0.4, 0.5, 
>     0, 0.2, 0.5,        0.2, 0.2, 0.6,       0.4, 0.5, 0.6, 
>     0, 0.3, 0.6,        0.3, 0.3, 0.6,       0.5, 0.5, 0.7, 
>     0, 0.4, 0.6,        0.2, 0.5, 0.7,       0.5, 0.6, 0.7, 
>     0, 0.4, 0.6,        0, 0.5, 0.6,         0.5, 0.6, 0.9,  
>     0, 0.5, 0.7,        0, 0.6, 0.8,         0.5, 0.7, 0.8, 
>     0, 0.5, 0.7         0, 0.6, 0.8          0.5, 0.8, 0.9  
> 
> The three matrix is not the function of r1dn, r2dn, tdn.  r1dn, r2dn, tdn can be labels. So there are four dimensional data. x is r1dn, y is r2dn, z is tdn and the three matrix is, let's say, vdn.
> Four dimension: r1dn r2dn tdn fdn as x,y,z,v.  And v is not the function of x,y,z. So there are might need a 3d filled.contour. But I did not find it. All the code I found is that x,y,z and z is a function of x,y. Another situation I found is that x,y,z,v and v is function of x,y,z. But in my data, v is not a function of x,y,z.


Actually, you need to detail (in your mind and to us) what do you mean by being function of. A point can be represented by 4 points in 4D space (x,y,z,t). According to this; v is short for value (measurement); v(x,y,z,t) can represent a value in space and time. So this is a 5D data I assume. We mostly use one or 2 or 3 of this dimensions. So, v is function of (x, y, z, t) and change by (x, y, z, t). For instance, if v is not function of time (t), it is always constant and does not change in time. Hence, I dont need 4th dimension (t here) and I don?t need to plot v in a 4D space. This is what I know about being function of.
	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Apr 11 23:47:56 2017
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 11 Apr 2017 16:47:56 -0500
Subject: [R] colorspace namespace problem with R CMD check --as-cran
Message-ID: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>

I am at a loss. I do not know how to make this reproducible without
providing the package sourced. I am receiving a warning when issuing

R --vanilla CMD check --as-cran --no-restore

The description file has
Imports: methods, reshape2, plyr, doBy, zoo

this is in 00install.out
** R
** data
*** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
Warning: namespace ?colorspace? is not available and has been replaced
by .GlobalEnv when processing object ?plot.index?
Warning: namespace ?colorspace? is not available and has been replaced
by .GlobalEnv when processing object ?plot.index?
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded


Thank you for any help in advance.
kindest regards,

Stephen Sefick

-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Apr 12 00:15:42 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 11 Apr 2017 15:15:42 -0700
Subject: [R] colorspace namespace problem with R CMD check --as-cran
In-Reply-To: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>
References: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>
Message-ID: <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>

Does one of the objects in pkg/data (or pkg/R) include a function made
by one of the functions in package:colorspace?  Such a function would
have the environment getNamespace("colorspace").
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Apr 11, 2017 at 2:47 PM, stephen sefick <ssefick at gmail.com> wrote:
> I am at a loss. I do not know how to make this reproducible without
> providing the package sourced. I am receiving a warning when issuing
>
> R --vanilla CMD check --as-cran --no-restore
>
> The description file has
> Imports: methods, reshape2, plyr, doBy, zoo
>
> this is in 00install.out
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> Warning: namespace ?colorspace? is not available and has been replaced
> by .GlobalEnv when processing object ?plot.index?
> Warning: namespace ?colorspace? is not available and has been replaced
> by .GlobalEnv when processing object ?plot.index?
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
>
>
> Thank you for any help in advance.
> kindest regards,
>
> Stephen Sefick
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Wed Apr 12 01:06:02 2017
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 11 Apr 2017 18:06:02 -0500
Subject: [R] colorspace namespace problem with R CMD check --as-cran
In-Reply-To: <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>
References: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>
 <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>
Message-ID: <CADKEMqgwbjjnSQ+-2DbNtzJhcFaf3fvj6bWZP2Jwaw21KvA6VA@mail.gmail.com>

Thank you for the quick reply.

here is what I tried:
I used environment(fxn) to look at all of the functions and data in the
package. I all of the functions have the namespace of the package. The
generic functions have a namespace like <environment: 0x5ea4fc0>. The data
loaded with data(pkg_data) have and environment of NULL.

colorspace is attached when the package is loaded. Is it possible that a
function that I am using from another package is causing this problem?

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Scientific Linux 7.3 (Nitrogen)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] genotypeR_0.0.0.9000

loaded via a namespace (and not attached):
 [1] zoo_1.7-14       colorspace_1.3-2 MASS_7.3-45      magrittr_1.5
 [5] plyr_1.8.4       Matrix_1.2-8     tools_3.3.3      reshape2_1.4.2
 [9] Rcpp_0.12.10     stringi_1.1.3    grid_3.3.3       doBy_4.5-15
[13] stringr_1.2.0    lattice_0.20-35

On Tue, Apr 11, 2017 at 5:15 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Does one of the objects in pkg/data (or pkg/R) include a function made
> by one of the functions in package:colorspace?  Such a function would
> have the environment getNamespace("colorspace").
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Apr 11, 2017 at 2:47 PM, stephen sefick <ssefick at gmail.com> wrote:
> > I am at a loss. I do not know how to make this reproducible without
> > providing the package sourced. I am receiving a warning when issuing
> >
> > R --vanilla CMD check --as-cran --no-restore
> >
> > The description file has
> > Imports: methods, reshape2, plyr, doBy, zoo
> >
> > this is in 00install.out
> > ** R
> > ** data
> > *** moving datasets to lazyload DB
> > ** inst
> > ** preparing package for lazy loading
> > Warning: namespace ?colorspace? is not available and has been replaced
> > by .GlobalEnv when processing object ?plot.index?
> > Warning: namespace ?colorspace? is not available and has been replaced
> > by .GlobalEnv when processing object ?plot.index?
> > ** help
> > *** installing help indices
> > ** building package indices
> > ** testing if installed package can be loaded
> >
> >
> > Thank you for any help in advance.
> > kindest regards,
> >
> > Stephen Sefick
> >
> > --
> > Let's not spend our time and resources thinking about things that are so
> > little or so large that all they really do for us is puff us up and make
> us
> > feel like gods.  We are mammals, and have not exhausted the annoying
> little
> > problems of being mammals.
> >
> >                                 -K. Mullis
> >
> > "A big computer, a complex algorithm and a long time does not equal
> > science."
> >
> >                               -Robert Gentleman
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Wed Apr 12 01:26:42 2017
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 11 Apr 2017 18:26:42 -0500
Subject: [R] colorspace namespace problem with R CMD check --as-cran
In-Reply-To: <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>
References: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>
 <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>
Message-ID: <CADKEMqi0aNGt+U=p8Eg+fHVfQogFFkZV4FKFnpoP8VtVnnuojQ@mail.gmail.com>

Here is the relevant snippett from devtools::check() logs. I searched every
file in pkg/R, and there is no call to plot.index (or plot at all).

Warning: namespace ?colorspace? is not available and has been replaced
by .GlobalEnv when processing object ?plot.index?
Warning: namespace ?colorspace? is not available and has been replaced
by .GlobalEnv when processing object ?plot.index?


On Tue, Apr 11, 2017 at 5:15 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Does one of the objects in pkg/data (or pkg/R) include a function made
> by one of the functions in package:colorspace?  Such a function would
> have the environment getNamespace("colorspace").
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Apr 11, 2017 at 2:47 PM, stephen sefick <ssefick at gmail.com> wrote:
> > I am at a loss. I do not know how to make this reproducible without
> > providing the package sourced. I am receiving a warning when issuing
> >
> > R --vanilla CMD check --as-cran --no-restore
> >
> > The description file has
> > Imports: methods, reshape2, plyr, doBy, zoo
> >
> > this is in 00install.out
> > ** R
> > ** data
> > *** moving datasets to lazyload DB
> > ** inst
> > ** preparing package for lazy loading
> > Warning: namespace ?colorspace? is not available and has been replaced
> > by .GlobalEnv when processing object ?plot.index?
> > Warning: namespace ?colorspace? is not available and has been replaced
> > by .GlobalEnv when processing object ?plot.index?
> > ** help
> > *** installing help indices
> > ** building package indices
> > ** testing if installed package can be loaded
> >
> >
> > Thank you for any help in advance.
> > kindest regards,
> >
> > Stephen Sefick
> >
> > --
> > Let's not spend our time and resources thinking about things that are so
> > little or so large that all they really do for us is puff us up and make
> us
> > feel like gods.  We are mammals, and have not exhausted the annoying
> little
> > problems of being mammals.
> >
> >                                 -K. Mullis
> >
> > "A big computer, a complex algorithm and a long time does not equal
> > science."
> >
> >                               -Robert Gentleman
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Tue Apr 11 18:39:52 2017
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Tue, 11 Apr 2017 18:39:52 +0200
Subject: [R] Peformance question
Message-ID: <4c841014-fc27-4590-891a-9b8b1304f1cf@Spark>

Hi y?all,

I?m working on a book on how to implement functional data structures in R, and in particular on a chapter on implementing queues. You get get the current version here?https://www.dropbox.com/s/9c2yk3a67p1ypmr/book.pdf?dl=0 and the relevant pages are 50-59. I?ve implemented three versions of the same idea, implementing a queue using two linked lists. One list contains the elements you add to the end of a list, the other contains the elements at the front of the list, and when you try to get an element from a list and the front-list is empty you move elements from the back-list to the front. The asymptotic analysis is explained in this figure?https://www.dropbox.com/s/tzi84zmyq16hdx0/queue-amortized-linear-bound.png?dl=0 and all my implementations do get a linear time complexity when I evaluate them on a linear number of operations. However, the two implementations that uses environments seem to be almost twice as fast as the implementation that gives me a persistent data structure (see?https://www.dropbox.com/s/i9dyab9ordkm0xj/queue-comparisons.png?dl=0), and I cannot figure out why.

The code below contains the implementation of all three versions of the queue plus the code I use to measure their performances. I?m sorry it is a little long, but it is a minimal implementation of all three variants, the comments just make it look longer than it really is.

Since the three implementations are doing basically the same things, I am a little stumped about why the performance is so consistently different.

Can anyone shed some light on this, or help me figure out how to explore this further?

Cheers

?Thomas



## Implementations of queues ##################

#' Test if a data structure is empty
#' @param x The data structure
#' @return TRUE if x is empty.
#' @export
is_empty <- function(x) UseMethod("is_empty")

#' Add an element to a queue
#' @param x A queue
#' @param elm An element
#' @return an updated queue where the element has been added
#' @export
enqueue <- function(x, elm) UseMethod("enqueue")

#' Get the front element of a queue
#' @param x A queue
#' @return the front element of the queue
#' @export
front <- function(x) UseMethod("front")

#' Remove the front element of a queue
#' @param x The queue
#' @return The updated queue
#' @export
dequeue <- function(x) UseMethod("dequeue")

## Linked lists #########################

#' Add a head item to a linked list.
#' @param elem ?The item to put at the head of the list.
#' @param lst ? The list -- it will become the tail of the new list.
#' @return a new linked list.
#' @export
list_cons <- function(elem, lst)
? structure(list(head = elem, tail = lst), class = "linked_list")

list_nil <- list_cons(NA, NULL)

#' @method is_empty linked_list
#' @export
is_empty.linked_list <- function(x) identical(x, list_nil)

#' Create an empty linked list.
#' @return an empty linked list.
#' @export
empty_list <- function() list_nil


#' Get the item at the head of a linked list.
#' @param lst The list
#' @return The element at the head of the list.
#' @export
list_head <- function(lst) lst$head

#' Get the tail of a linked list.
#' @param lst The list
#' @return The tail of the list
#' @export
list_tail <- function(lst) lst$tail

#' Reverse a list
#' @param lst A list
#' @return the reverse of lst
#' @export
list_reverse <- function(lst) {
? acc <- empty_list()
? while (!is_empty(lst)) {
? ? acc <- list_cons(list_head(lst), acc)
? ? lst <- list_tail(lst)
? }
? acc
}


## Environment queues #################################################

queue_environment <- function(front, back) {
? e <- new.env(parent = emptyenv())
? e$front <- front
? e$back <- back
? class(e) <- c("env_queue", "environment")
? e
}

#' Construct an empty closure based queue
#' @return an empty queue
#' @export
empty_env_queue <- function()
? queue_environment(empty_list(), empty_list())

#' @method is_empty env_queue
#' @export
is_empty.env_queue <- function(x)
? is_empty(x$front) && is_empty(x$back)

#' @method enqueue env_queue
#' @export
enqueue.env_queue <- function(x, elm) {
? x$back <- list_cons(elm, x$back)
? x
}

#' @method front env_queue
#' @export
front.env_queue <- function(x) {
? if (is_empty(x$front)) {
? ? x$front <- list_reverse(x$back)
? ? x$back <- empty_list()
? }
? list_head(x$front)
}

#' @method dequeue env_queue
#' @export
dequeue.env_queue <- function(x) {
? if (is_empty(x$front)) {
? ? x$front <- list_reverse(x$back)
? ? x$back <- empty_list()
? }
? x$front <- list_tail(x$front)
? x
}



## Closure queues #####################################################

queue <- function(front, back)
? list(front = front, back = back)

queue_closure <- function() {
? q <- queue(empty_list(), empty_list())

? get_queue <- function() q

? queue_is_empty <- function() is_empty(q$front) && is_empty(q$back)

? enqueue <- function(elm) {
? ? q <<- queue(q$front, list_cons(elm, q$back))
? }

? front <- function() {
? ? if (queue_is_empty()) stop("Taking the front of an empty list")
? ? if (is_empty(q$front)) {
? ? ? q <<- queue(list_reverse(q$back), empty_list())
? ? }
? ? list_head(q$front)
? }

? dequeue <- function() {
? ? if (queue_is_empty()) stop("Taking the front of an empty list")
? ? if (is_empty(q$front)) {
? ? ? q <<- queue(list_tail(list_reverse(q$back)), empty_list())
? ? } else {
? ? ? q <<- queue(list_tail(q$front), q$back)
? ? }
? }

? structure(list(is_empty = queue_is_empty,
? ? ? ? ? ? ? ? ?get_queue = get_queue,
? ? ? ? ? ? ? ? ?enqueue = enqueue,
? ? ? ? ? ? ? ? ?front = front,
? ? ? ? ? ? ? ? ?dequeue = dequeue),
? ? ? ? ? ? class = "closure_queue")
}

#' Construct an empty closure based queue
#' @return an empty queue
#' @export
empty_closure_queue <- function() queue_closure()

#' @method is_empty closure_queue
#' @export
is_empty.closure_queue <- function(x) x$is_empty()

#' @method enqueue closure_queue
#' @export
enqueue.closure_queue <- function(x, elm) {
? x$enqueue(elm)
? x
}

#' @method front closure_queue
#' @export
front.closure_queue <- function(x) x$front()

#' @method dequeue closure_queue
#' @export
dequeue.closure_queue <- function(x) {
? x$dequeue()
? x
}

## Extended (purely functional) queues ################################
queue_extended <- function(x, front, back)
? structure(list(x = x, front = front, back = back),
? ? ? ? ? ? class = "extended_queue")


#' Construct an empty extended queue
#'
#' This is just a queue that doesn't use a closure to be able to update
#' the data structure when front is called.
#'
#' @return an empty queue
#' @export
empty_extended_queue <- function() queue_extended(NA, empty_list(), empty_list())

#' @method is_empty extended_queue
#' @export
is_empty.extended_queue <- function(x)
? is_empty(x$front) && is_empty(x$back)

#' @method enqueue extended_queue
#' @export
enqueue.extended_queue <- function(x, elm)
? queue_extended(ifelse(is_empty(x$back), elm, x$x),
? ? ? ? ? ? ? ? ?x$front, list_cons(elm, x$back))

#' @method front extended_queue
#' @export
front.extended_queue <- function(x) {
? if (is_empty(x)) stop("Taking the front of an empty list")
? if (is_empty(x$front)) x$x
? else list_head(x$front)
}

#' @method dequeue extended_queue
#' @export
dequeue.extended_queue <- function(x) {
? if (is_empty(x)) stop("Taking the front of an empty list")
? if (is_empty(x$front))
? ? x <- queue_extended(NA, list_reverse(x$back), empty_list())
? queue_extended(x$x, list_tail(x$front), x$back)
}

## Performance experiments ######################

library(microbenchmark)
library(tibble)
library(ggplot2)

get_performance_n <- function(
? algo
? , n
? , setup
? , evaluate
? , times
? , ...) {

? config <- setup(n)
? benchmarks <- microbenchmark(evaluate(n, config), times = times)
? tibble(algo = algo, n = n, time = benchmarks$time / 1e9) # time in sec
}

get_performance <- function(
? algo
? , ns
? , setup
? , evaluate
? , times = 10
? , ...) {
? f <- function(n)
? ? get_performance_n(algo, n, setup, evaluate, times = times, ...)
? results <- Map(f, ns)
? do.call('rbind', results)
}


setup <- function(n) n
evaluate <- function(empty) function(n, x) {
? elements <- 1:n
? queue <- empty
? for (elm in elements) {
? ? queue <- enqueue(queue, elm)
? }
? for (i in seq_along(elements)) {
? ? queue <- dequeue(queue)
? }
}

ns <- seq(5000, 10000, by = 1000)
performance <- rbind(get_performance("explicity environment", ns, setup, evaluate(empty_env_queue())),
? ? ? ? ? ? ? ? ? ? ?get_performance("closure environment", ns, setup, evaluate(empty_closure_queue())),
? ? ? ? ? ? ? ? ? ? ?get_performance("functional queue", ns, setup, evaluate(empty_extended_queue())))

ggplot(performance, aes(x = as.factor(n), y = time / n, fill = algo)) +
? geom_boxplot() +
? scale_fill_grey("Data structure") +
? xlab(quote(n)) + ylab(expression(Time / n)) + theme_minimal()




	[[alternative HTML version deleted]]


From dncdd at aliyun.com  Tue Apr 11 19:55:15 2017
From: dncdd at aliyun.com (dncdd)
Date: Wed, 12 Apr 2017 01:55:15 +0800
Subject: [R] =?utf-8?b?5Zue5aSN77yaIGhvdyB0byBwbG90IHRocmVlIGRpbWVuc2lv?=
 =?utf-8?q?n_data_to_filled_contour_plot_or_surface_plot_in_R__Ask_Questio?=
 =?utf-8?q?n?=
In-Reply-To: 2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>,
 2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com
Message-ID: <4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>

Thank you Ismail SEZEN.The link you give is filled.contour code which only works with my?first mini data?.
The code in the link for R 3.3.2 is :****** code ***** in **** link **** for R 3.3.2 ****panel.filledcontour?<-?function(x,?y,?z,?subscripts,?at,?col.regions?=?
cm.colors,?
????????????????????????????????col?=?col.regions(length(at)?-?1),?...)?
{?
??stopifnot(require("gridBase"))?
??z?<-?matrix(z[subscripts],?
??????????????nrow?=?length(unique(x[subscripts])),?
??????????????ncol?=?length(unique(y[subscripts])))?
??if?(!is.double(z))?storage.mode(z)?<-?"double"?
??opar?<-?par(no.readonly?=?TRUE)?
??on.exit(par(opar))?
??if?(panel.number()?>?1)?par(new?=?TRUE)?
??par(fig?=?gridFIG(),?omi?=?c(0,?0,?0,?0),?mai?=?c(0,?0,?0,?0))?
??cpl?<-?current.panel.limits()?
??plot.window(xlim?=?cpl$xlim,?ylim?=?cpl$ylim,?
??????????????log?=?"",?xaxs?=?"i",?yaxs?=?"i")?
??#?paint?the?color?contour?regions?
??.filled.contour(as.double(do.breaks(cpl$xlim,?nrow(z)?-?1)),?
??????????????????????????as.double(do.breaks(cpl$ylim,?ncol(z)?-?1)),?
??????????????????????????z,?levels?=?as.double(at),?col?=?col)
??#?add?contour?lines?
??contour(as.double(do.breaks(cpl$xlim,?nrow(z)?-?1)),?
??????????as.double(do.breaks(cpl$ylim,?ncol(z)?-?1)),?
??????????z,?levels?=?as.double(at),?add=T,?
??????????col?=?"gray",?#?color?of?the?lines?
??????????drawlabels=F??#?add?labels?or?not?
?????????)?
}?
plot.new()?

print(levelplot(volcano,?panel?=?panel.filledcontour,?
??????????col.regions?=?terrain.colors,?
??????????cuts?=?10,?
??????????plot.args?=?list(newpage?=?FALSE)))*** END ***?code *** in *** link *** for R 3.3.2 ***?
first mini datawhich should be a three dimensinal data either and the data in matrix is not a function of rdn and tdnwhich means z matrix is not function of x,y.?
? ? rdn<-c(0.8,1.8,2.8)
????tdn<-c(1,2,3,4,5,6,7,8,9)
????
????idn<-matrix(c(0.3,?0.3,?0.3,?0.2,?0.2,?0.4,?0.1,?0.1,?0.5,?0,?0.2,?0.5,?0,?0.3,?0.6,?0,?0.4,?0.6,?0,?0.4,?0.6,?0,?0.5,?0.7,?0,?0.5,?0.7),?nrow=9,?ncol=3,?byrow=T)

And?the?matrix?looks?like(3*9?=?27?data?elements):

????0.3,?0.3,?0.3,?
????0.2,?0.2,?0.4,?
????0.1,?0.1,?0.5,?
????0,?0.2,?0.5,?
????0,?0.3,?0.6,?
????0,?0.4,?0.6,?
????0,?0.4,?0.6,?
????0,?0.5,?0.7,?
????0,?0.5,?0.7

Well, now I realized that?the second data?might (my current problem) be afour?dimensional data:
r1dn<-c(0.8,1.8,2.8)
r2dn<-c(0.8,1.8,2.8)
tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)

And?(3*3*9?=?81?data?elements):

? ? ?0.8??????????????????1.8??????????????????2.8
? ? 0.8??1.8??2.8???????0.8??1.8??2.8????????0.8??1.8??2.8

? ? ---------------?81?----?elements?------three matrix----------------

? ? 0.3,?0.3,?0.3,??????0.3,?0.3,?0.5,???????0.3,?0.3,?0.3,?
? ? 0.2,?0.2,?0.4,??????0.2,?0.4,?0.4,???????0.4,?0.2,?0.5,
? ? 0.1,?0.1,?0.5,??????0.2,?0.3,?0.5,???????0.4,?0.4,?0.5,?
? ? 0,?0.2,?0.5,????????0.2,?0.2,?0.6,???????0.4,?0.5,?0.6,?
? ? 0,?0.3,?0.6,????????0.3,?0.3,?0.6,???????0.5,?0.5,?0.7,?
? ? 0,?0.4,?0.6,????????0.2,?0.5,?0.7,???????0.5,?0.6,?0.7,?
? ? 0,?0.4,?0.6,????????0,?0.5,?0.6,?????????0.5,?0.6,?0.9,??
? ? 0,?0.5,?0.7,????????0,?0.6,?0.8,?????????0.5,?0.7,?0.8,?
? ? 0,?0.5,?0.7?????????0,?0.6,?0.8??????????0.5,?0.8,?0.9??
The three matrix is not the function of r1dn, r2dn, tdn. ?r1dn, r2dn, tdn can be labels. So there are four dimensional data. x is r1dn, y is r2dn, z is tdn and the three matrix is, let's say, vdn.Four dimension: r1dn r2dn tdn fdn as x,y,z,v. ?And v is not the function of x,y,z. So there are might need a 3d filled.contour. But I did not find it. All the code I found is that x,y,z and z is a function of x,y. Another situation I found is that x,y,z,v and v is function of x,y,z. But in my data, v is not a function of x,y,z.
------------------------------------------------------------------????Ismail SEZEN <sezenismail at gmail.com>?????2017?4?12?(???) 00:48????dncdd <dncdd at aliyun.com>????r-help <r-help at r-project.org>????Re: [R] how to plot three dimension data to filled contour plot or surface plot in R  Ask Question
After lon long search, my best shot was to use filled.contour + lattice::levelplot together [a] to represent 3 dimensional data on a flat surface.?
a)?http://r.789695.n4.nabble.com/Creating-smooth-color-regions-with-panel-contourplot-td866253.html
Some Details:
On 11 Apr 2017, at 09:16, dncdd via R-help <r-help at r-project.org> wrote:
ENV?

R?3.3.2

When?I?have?data?like:

????rdn<-c(0.8,1.8,2.8)
????tdn<-c(1,2,3,4,5,6,7,8,9)
????
????idn<-matrix(c(0.3,?0.3,?0.3,?0.2,?0.2,?0.4,?0.1,?0.1,?0.5,?0,?0.2,?0.5,?0,?0.3,?0.6,?0,?0.4,?0.6,?0,?0.4,?0.6,?0,?0.5,?0.7,?0,?0.5,?0.7),?nrow=9,?ncol=3,?byrow=T)

And?the?matrix?looks?like(3*9?=?27?data?elements):

????0.3,?0.3,?0.3,?
????0.2,?0.2,?0.4,?
????0.1,?0.1,?0.5,?
????0,?0.2,?0.5,?
????0,?0.3,?0.6,?
????0,?0.4,?0.6,?
????0,?0.4,?0.6,?
????0,?0.5,?0.7,?
????0,?0.5,?0.7

Then?I?can?get?a?filled.contour?with?parameters?x,y,z.?x?is?tdn,?y?is?rdn,?z?is?the?matrix.?I?already?get?this.

If you have a rectangular data like matrix, you can use filled.contour (the best one) or rasterVis::levelplot.

?
**My?current?problem**?is:

What?If?I?have?three?dimension?data

????r1dn<-c(0.8,1.8,2.8)
????r2dn<-c(0.8,1.8,2.8)
????tdn<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)

At this point, you have to expand your data to x,y,z data pairs. I mean you have to reshaphe your data as a z value for each x and y point.?
data <- expand.grid(x = x, y = y)dta$z <- z?
Now, you have 3 columns + 9 rows data. You can use this data in lattice::levelplot by awesome formula interface.

I?googled?many?surface?and?contour?codes?but?I?still?not?find?some?code?for?three?dimension?data?yet.?
Actually you found but they didn?t fill you requirements.
How?to?do?that?in?R??Say,?x?is?r1dn,?y?is?r2dn,?z?is?tdn,?what?about?the?three?dimension?data??Does?ggplot?can?plot?three?dimension?filled?contour?or?surface?plot??Or?another?alternative?solutions?

The problem here is, you want a filled/contour plot on a flat surface or 3D perspective visualisation? If you want 3D perspective visualisation, your only chances are rgl and misc3d packages. (as far as I know)

All?I?expected?is?a?3d?plot?with?color?changes?smoothly?and?no?grid?on?it.

All the solutions above may have (or not) smooth colour change and grid depending on your settings. What do you mean exactly "no grid on it?? If you choose that you don?t have a grid, then you don?t. You only need to search a bit more.

Looks?like:?
no?grid?for?next?three?figures
Those?should?be?3d?filled?contour?or?3d?surface?plot.
Thanks?for?your?time.

??[1]:?https://i.stack.imgur.com/z6u3p.png
??[2]:?https://i.stack.imgur.com/MEnFn.png
??[3]:?https://i.stack.imgur.com/Ri29w.png
??[4]:?https://i.stack.imgur.com/CdCqL.jpg
??[5]:?https://i.stack.imgur.com/Pt1Nw.jpg
	[[alternative HTML version deleted]]



	[[alternative HTML version deleted]]


From andrew.scotchmer at gmail.com  Tue Apr 11 21:29:32 2017
From: andrew.scotchmer at gmail.com (Andrew Scotchmer)
Date: Tue, 11 Apr 2017 12:29:32 -0700 (PDT)
Subject: [R] R in a real time MS BI environment
Message-ID: <9a6ac624-bd03-4fda-89de-698bbbec6296@googlegroups.com>

Hi

Hope someone can help with the best way forward for a project I am working 
on.

My employer uses the MS BI stack - SSRS, SSIS, SQLServer, etc - and the 
developers have built a web portal in C# and ASP.Net to display real time 
management reports in a dashboard format using the bootstrap theme. 

I have developed a prototype dashboard with R and Shiny running on an 
Ubuntu virtual server which is more graphical and includes reactive 
components and machine learning analytics. Everyone is very impressed with 
the dashboard and want to incorporate the analytics and graphical 
components (ggplot with plotly) into the existing portal.  As it was only a 
prototype however it uses files that are created in SQL server and exported 
nightly as csv's into a folder shared with Ubuntu.  So far we have just 
created iframes that point to the shiny server but management are not happy 
with this approach.  They want to integrate the R models and graphics into 
the real time portal.

I know SQL Server 2016 bundles R services, but how do you incorporate real 
time R analytics and graphics in the existing MS/.Net stack?

Cheers
Andrew

From rinni at inventati.org  Wed Apr 12 06:40:39 2017
From: rinni at inventati.org (Philip Rinn)
Date: Wed, 12 Apr 2017 06:40:39 +0200 (CEST)
Subject: [R] rdb and rds files include abolute file paths / help
 understanding how lazy-load dbs are created
Message-ID: <1264449572.41534.1491972039736@office.mailbox.org>

Hi,

I'm trying to understand why/how absolute file paths are stored in .rdb[1] and
.rds[2] files during package installation. As a consequence building the same r
package in different directories does not produce identical .rdb and .rds files.

The background is that I work on reproducible builds[3] of R packages. I think
this is important from an engineering point of view but also from a scientists
perspective (that's actually my point). I want to be sure that my research results
are reproducible and therefore I need software that builds reproducible.

To investigate further I'd like to ask for some help. From what I understand so
far the lazy-load databases are built by code in
src/library/tools/R/makeLazyLoad.R. The code path is not very clear to me but the
main problem I have now is that it's hard to follow the code path used to install
a package. Could someone enlighten me by pointing me to some docs or by briefly
describing the path?

Any help/comments are very welcome.

Best,
Philip

PS: could you CC me, I'm not on the list. Thanks.

[1] at least in <PKG>/R/<PKG>.rdb and <PKG>/help/<PKG>.rdb
[2] at least in <PKG>/help/paths.rds
[3] https://reproducible-builds.org


From jdnewmil at dcn.davis.ca.us  Wed Apr 12 08:09:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 11 Apr 2017 23:09:48 -0700
Subject: [R] rdb and rds files include abolute file paths / help
	understanding how lazy-load dbs are created
In-Reply-To: <1264449572.41534.1491972039736@office.mailbox.org>
References: <1264449572.41534.1491972039736@office.mailbox.org>
Message-ID: <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>

Someone might respond here anyway, but I think this is more of an R-devel question.

Anyway, as long as the package file after installation has appropriate file names for where it is installed, what does it matter what is in the files before installation? 
-- 
Sent from my phone. Please excuse my brevity.

On April 11, 2017 9:40:39 PM PDT, Philip Rinn <rinni at inventati.org> wrote:
>Hi,
>
>I'm trying to understand why/how absolute file paths are stored in
>.rdb[1] and
>.rds[2] files during package installation. As a consequence building
>the same r
>package in different directories does not produce identical .rdb and
>.rds files.
>
>The background is that I work on reproducible builds[3] of R packages.
>I think
>this is important from an engineering point of view but also from a
>scientists
>perspective (that's actually my point). I want to be sure that my
>research results
>are reproducible and therefore I need software that builds
>reproducible.
>
>To investigate further I'd like to ask for some help. From what I
>understand so
>far the lazy-load databases are built by code in
>src/library/tools/R/makeLazyLoad.R. The code path is not very clear to
>me but the
>main problem I have now is that it's hard to follow the code path used
>to install
>a package. Could someone enlighten me by pointing me to some docs or by
>briefly
>describing the path?
>
>Any help/comments are very welcome.
>
>Best,
>Philip
>
>PS: could you CC me, I'm not on the list. Thanks.
>
>[1] at least in <PKG>/R/<PKG>.rdb and <PKG>/help/<PKG>.rdb
>[2] at least in <PKG>/help/paths.rds
>[3] https://reproducible-builds.org
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From infojomy at gmail.com  Wed Apr 12 12:20:30 2017
From: infojomy at gmail.com (Jomy Jose)
Date: Wed, 12 Apr 2017 15:50:30 +0530
Subject: [R] Sample size using residual standard deviation
Message-ID: <CADGufDHvJsmNOft0vVaWGKkhBaO-B4Ja6kc1wGf0nUrs2wBEVA@mail.gmail.com>

In R how to calculate sample size,where power,residual standard deviation
and treatment difference is given.?

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Apr 12 16:09:23 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 12 Apr 2017 09:09:23 -0500
Subject: [R] R forecasting using ses model
Message-ID: <CAMOcQfPnXjN+H4_SLyrriqtJfwauMN7rYvwMAT9Fec-7EvyPgw@mail.gmail.com>

Dear Everyone,

Hope you are doing great. I get the following error when trying to generate
forecasts fitting a ses model. I would have thought that historical data
from october 1985 up to september 2016 would be enough to generate
forecasts.

How many monthly observations does the ses model requires in order to
generate forecasts?

I know the message couldn?t be clearer, but would like to know if someone
knows how many past observations (do I need as a minimum for the ses model
to work).

>data<-read.csv("01_PaulData.csv")
>
> tsdata<-ts(data, start=c(1985,10), end=c(2016,9), frequency=12)
>
> sesModel<-ses(tsdata)
>
> sesForecast<-forecast(sesModel, h=12)
Error in forecast.forecast(sesModel, h = 12) :
  Please select a longer horizon when the forecasts are first computed

	[[alternative HTML version deleted]]


From zapata at zib.de  Wed Apr 12 13:39:49 2017
From: zapata at zib.de (zapata at zib.de)
Date: Wed, 12 Apr 2017 13:39:49 +0200
Subject: [R] R crashing with ggplot 2d histogram
Message-ID: <2ff38a444c6b47939ce305a9eeaa30a3.squirrel@imap.zib.de>

Hi! R newbie here. I wrote a script for a correlation plot, a 2d histogram
(heatmap-like) with ggplot. I've run it before with a smaller dataset and
it runs on my laptop and does what I want. Now I've extended my dataset
and R is crashing after the last line which is to generate the plot I
guess. I get the R session aborted / fatal error message.

My new dataset is composed of time series for two variables. For each
variable there are 50 time series with 15.000 values each, so it's in
total 15000*50= 7.5E5 coordinates for this 2d histogram. Do I have a
memory problem here or is it just a script issue? Any suggestion to make
it run? An eli5 answer would be appreciated, my R experience is relatively
low, I just use it here and there for plotting. Thanks!

Carlos Zapata


From Servet.Ahmet.Cizmeli at USherbrooke.ca  Wed Apr 12 14:17:57 2017
From: Servet.Ahmet.Cizmeli at USherbrooke.ca (=?UTF-8?Q?Servet_Ahmet_=C3=87izmeli?=)
Date: Wed, 12 Apr 2017 08:17:57 -0400
Subject: [R] CRAN package submission failed on solaris : timezone problem
Message-ID: <18f104a2f07191361cbbc531053c54cf@courriel-fec.usherbrooke.ca>

 

Hi everyone 

I just submitted my new package to CRAN. All checks passed on all
platforms, except one in solaris : 

as(df2, "Spectra") 

Error: tz1.set == tz2.set is not TRUE 

More details on :
https://cran.r-project.org/web/checks/check_results_geoSpectral.html 

In this package I defined an S4 class named "Spectra" that provides a
slot with xts object and another slot with a POSIXct object. Example of
the setAs method fails while I coerce a data.frame to Spectra. 

I tried to replicate the problem on my ubuntu-windows-mac machines and
no luck. I then created a solaris virtual machine and installed
everything, I still cannot replicate the error. All checks pass on the
VM too. 

Searching this list gave nothing. When I google the error message
"Error: tz1.set == tz2.set is not TRUE", my package name comes first...
which leads me to think that not that many people already had a similar
problem. I also changed the timezone of the solaris VM to an arbitrary
timezone. No luck. 

I am at loss. I can't replicate the problem that occurred in CRAN's
solaris servers. 

Can you please help me? 

regards 

Servet 

 
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Apr 12 18:32:12 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Apr 2017 09:32:12 -0700
Subject: [R] Sample size using residual standard deviation
In-Reply-To: <CADGufDHvJsmNOft0vVaWGKkhBaO-B4Ja6kc1wGf0nUrs2wBEVA@mail.gmail.com>
References: <CADGufDHvJsmNOft0vVaWGKkhBaO-B4Ja6kc1wGf0nUrs2wBEVA@mail.gmail.com>
Message-ID: <66996905-CE4B-43FB-B245-30C56692CC3F@comcast.net>


> On Apr 12, 2017, at 3:20 AM, Jomy Jose <infojomy at gmail.com> wrote:
> 
> In R how to calculate sample size,where power,residual standard deviation
> and treatment difference is given.?

Use the non-central t-distribution. The help page has further advice:

?pt


> 
> 	[[alternative HTML version deleted]]

Please read the Posting Guide before any further replies.
______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

\/\/\/\/\/\/\/\/\/\/\/
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
^^^^^^^^^^^^^^^^^^^^^^
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Wed Apr 12 18:40:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 12 Apr 2017 09:40:39 -0700
Subject: [R] R crashing with ggplot 2d histogram
In-Reply-To: <2ff38a444c6b47939ce305a9eeaa30a3.squirrel@imap.zib.de>
References: <2ff38a444c6b47939ce305a9eeaa30a3.squirrel@imap.zib.de>
Message-ID: <CAGxFJbQ6eu5RTtrapVapiXVnHNjmmSqM_ZwxWG-gJfDO5CTKOA@mail.gmail.com>

You will much improve your chance of getting useful help if you read
and follow the posting guide (below). In particular:

1. Versions of R and packages?

2. Show us the (minimal) code that "crashes." Can you create a minimal
artificial data set that does this that we can run?

3. Are there error messages? If so, what are they?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 12, 2017 at 4:39 AM,  <zapata at zib.de> wrote:
> Hi! R newbie here. I wrote a script for a correlation plot, a 2d histogram
> (heatmap-like) with ggplot. I've run it before with a smaller dataset and
> it runs on my laptop and does what I want. Now I've extended my dataset
> and R is crashing after the last line which is to generate the plot I
> guess. I get the R session aborted / fatal error message.
>
> My new dataset is composed of time series for two variables. For each
> variable there are 50 time series with 15.000 values each, so it's in
> total 15000*50= 7.5E5 coordinates for this 2d histogram. Do I have a
> memory problem here or is it just a script issue? Any suggestion to make
> it run? An eli5 answer would be appreciated, my R experience is relatively
> low, I just use it here and there for plotting. Thanks!
>
> Carlos Zapata
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Apr 12 18:44:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 12 Apr 2017 09:44:26 -0700
Subject: [R] Sample size using residual standard deviation
In-Reply-To: <66996905-CE4B-43FB-B245-30C56692CC3F@comcast.net>
References: <CADGufDHvJsmNOft0vVaWGKkhBaO-B4Ja6kc1wGf0nUrs2wBEVA@mail.gmail.com>
 <66996905-CE4B-43FB-B245-30C56692CC3F@comcast.net>
Message-ID: <CAGxFJbQwr9s9gL+V154VrYvt4kGa=cmmVsyqVZOSgX5JgLWbag@mail.gmail.com>

Search "sample size power" on rseek.org. Many useful hits, including
"samplesize" package.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 12, 2017 at 9:32 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Apr 12, 2017, at 3:20 AM, Jomy Jose <infojomy at gmail.com> wrote:
>>
>> In R how to calculate sample size,where power,residual standard deviation
>> and treatment difference is given.?
>
> Use the non-central t-distribution. The help page has further advice:
>
> ?pt
>
>
>>
>>       [[alternative HTML version deleted]]
>
> Please read the Posting Guide before any further replies.
> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
> \/\/\/\/\/\/\/\/\/\/\/
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> ^^^^^^^^^^^^^^^^^^^^^^
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Wed Apr 12 19:22:06 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 12 Apr 2017 22:52:06 +0530
Subject: [R] Could not load Package 'rgl'
Message-ID: <CA+dpOJkt+jH2eia7zE4mjHZi0dN_4DsMPY8Qx5Q=eQsREuRfMA@mail.gmail.com>

Hi again,

I could not load the 'rgl' package with below Error details :

> library(rgl)
Error : .onLoad failed in loadNamespace() for 'rgl', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so,
6): Library not loaded: /opt/X11/lib/libGLU.1.dylib
  Referenced from:
/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so
  Reason: image not found
Error: package or namespace load failed for ?rgl?

I am using R under below environment:

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

Could you please help how to resolve this error.

Thanks for your time.


From pdalgd at gmail.com  Wed Apr 12 19:35:55 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 12 Apr 2017 19:35:55 +0200
Subject: [R] Sample size using residual standard deviation
In-Reply-To: <CAGxFJbQwr9s9gL+V154VrYvt4kGa=cmmVsyqVZOSgX5JgLWbag@mail.gmail.com>
References: <CADGufDHvJsmNOft0vVaWGKkhBaO-B4Ja6kc1wGf0nUrs2wBEVA@mail.gmail.com>
 <66996905-CE4B-43FB-B245-30C56692CC3F@comcast.net>
 <CAGxFJbQwr9s9gL+V154VrYvt4kGa=cmmVsyqVZOSgX5JgLWbag@mail.gmail.com>
Message-ID: <62DD6F06-D7A9-435B-BDA7-5424ACE3D550@gmail.com>

Or power.t.test()

-pd

> On 12 Apr 2017, at 18:44 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Search "sample size power" on rseek.org. Many useful hits, including
> "samplesize" package.
> 
> -- Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Apr 12, 2017 at 9:32 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Apr 12, 2017, at 3:20 AM, Jomy Jose <infojomy at gmail.com> wrote:
>>> 
>>> In R how to calculate sample size,where power,residual standard deviation
>>> and treatment difference is given.?
>> 
>> Use the non-central t-distribution. The help page has further advice:
>> 
>> ?pt
>> 
>> 
>>> 
>>>      [[alternative HTML version deleted]]
>> 
>> Please read the Posting Guide before any further replies.
>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> 
>> \/\/\/\/\/\/\/\/\/\/\/
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> ^^^^^^^^^^^^^^^^^^^^^^
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jacob-simmering at uiowa.edu  Wed Apr 12 20:18:58 2017
From: jacob-simmering at uiowa.edu (Simmering, Jacob E)
Date: Wed, 12 Apr 2017 18:18:58 +0000
Subject: [R] Could not load Package 'rgl'
In-Reply-To: <CA+dpOJkt+jH2eia7zE4mjHZi0dN_4DsMPY8Qx5Q=eQsREuRfMA@mail.gmail.com>
References: <CA+dpOJkt+jH2eia7zE4mjHZi0dN_4DsMPY8Qx5Q=eQsREuRfMA@mail.gmail.com>
Message-ID: <C5CA9C8E-A7FC-48A9-8DEE-6CD6D64FA060@uiowa.edu>

Christofer,

This SO thread may be helpful:

http://stackoverflow.com/questions/33634871/installing-rgl-package-in-r-mac-osx-el-captian-fixed


On Apr 12, 2017, at 12:22 PM, Christofer Bogaso <bogaso.christofer at gmail.com<mailto:bogaso.christofer at gmail.com>> wrote:

Hi again,

I could not load the 'rgl' package with below Error details :

library(rgl)
Error : .onLoad failed in loadNamespace() for 'rgl', details:
 call: dyn.load(file, DLLpath = DLLpath, ...)
 error: unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so':
 dlopen(/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so,
6): Library not loaded: /opt/X11/lib/libGLU.1.dylib
 Referenced from:
/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/libs/rgl.so
 Reason: image not found
Error: package or namespace load failed for ?rgl?

I am using R under below environment:

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

Could you please help how to resolve this error.

Thanks for your time.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Apr 12 20:57:13 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 12 Apr 2017 13:57:13 -0500
Subject: [R] CRAN package submission failed on solaris : timezone problem
In-Reply-To: <18f104a2f07191361cbbc531053c54cf@courriel-fec.usherbrooke.ca>
References: <18f104a2f07191361cbbc531053c54cf@courriel-fec.usherbrooke.ca>
Message-ID: <CAPPM_gQXbn5j36R8oaxAjDvRWVL_5WJS_eZyvjARVitrwp3KUQ@mail.gmail.com>

On Wed, Apr 12, 2017 at 7:17 AM, Servet Ahmet ?izmeli
<Servet.Ahmet.Cizmeli at usherbrooke.ca> wrote:
>
>
> Hi everyone
>
> I just submitted my new package to CRAN. All checks passed on all
> platforms, except one in solaris :
>
> as(df2, "Spectra")
>
> Error: tz1.set == tz2.set is not TRUE
>
> More details on :
> https://cran.r-project.org/web/checks/check_results_geoSpectral.html
>
> In this package I defined an S4 class named "Spectra" that provides a
> slot with xts object and another slot with a POSIXct object. Example of
> the setAs method fails while I coerce a data.frame to Spectra.
>
It's not clear whether the setAs method is failing or the show method
is failing, because that line in the example is doing 2 things: it
calls the setAs method and then auto-prints.

If I had to guess, I would suspect it's this line causing issues:
tz = format(time(object at time[1]),format="%Z")

Possibly in combination with whether or not the CRAN Solaris machines
are using the OS' timezone code or R's internal version when
formatting the timezone.

> I tried to replicate the problem on my ubuntu-windows-mac machines and
> no luck. I then created a solaris virtual machine and installed
> everything, I still cannot replicate the error. All checks pass on the
> VM too.
>
> Searching this list gave nothing. When I google the error message
> "Error: tz1.set == tz2.set is not TRUE", my package name comes first...
> which leads me to think that not that many people already had a similar
> problem. I also changed the timezone of the solaris VM to an arbitrary
> timezone. No luck.
>
> I am at loss. I can't replicate the problem that occurred in CRAN's
> solaris servers.
>
> Can you please help me?
>
> regards
>
> Servet
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From valkremk at gmail.com  Thu Apr 13 03:28:24 2017
From: valkremk at gmail.com (Val)
Date: Wed, 12 Apr 2017 20:28:24 -0500
Subject: [R] combination
Message-ID: <CAJOiR6b5SG7qdCzyWpvtFt=e+-OFcrb5yM+kkDjCamCHscbY6g@mail.gmail.com>

Hi all,
I have two variables x and y. X has five observation and y has three.
I want combine each element of x to  each element of y values to
produce 15  observation. Below is my sample data and desired output

data
x   Y
1   A
2   B
3   C
4
5

Output
1  A
1  B
1  C
2  A
2  B
2  C
3  A
3  B
3  C
4  A
4  B
4  C
5  A
5  B
5  C

Thank you in advance


From bgunter.4567 at gmail.com  Thu Apr 13 03:47:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 12 Apr 2017 18:47:03 -0700
Subject: [R] combination
In-Reply-To: <CAJOiR6b5SG7qdCzyWpvtFt=e+-OFcrb5yM+kkDjCamCHscbY6g@mail.gmail.com>
References: <CAJOiR6b5SG7qdCzyWpvtFt=e+-OFcrb5yM+kkDjCamCHscbY6g@mail.gmail.com>
Message-ID: <CAGxFJbRvQdS4RB8WP-dUqT7g5BGC_PwJ_0ugjsRGCOvwnizgCQ@mail.gmail.com>

Is this homework? We don't do homework here.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 12, 2017 at 6:28 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
> I have two variables x and y. X has five observation and y has three.
> I want combine each element of x to  each element of y values to
> produce 15  observation. Below is my sample data and desired output
>
> data
> x   Y
> 1   A
> 2   B
> 3   C
> 4
> 5
>
> Output
> 1  A
> 1  B
> 1  C
> 2  A
> 2  B
> 2  C
> 3  A
> 3  B
> 3  C
> 4  A
> 4  B
> 4  C
> 5  A
> 5  B
> 5  C
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Apr 13 03:49:04 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 12 Apr 2017 18:49:04 -0700
Subject: [R] combination
In-Reply-To: <CAJOiR6b5SG7qdCzyWpvtFt=e+-OFcrb5yM+kkDjCamCHscbY6g@mail.gmail.com>
References: <CAJOiR6b5SG7qdCzyWpvtFt=e+-OFcrb5yM+kkDjCamCHscbY6g@mail.gmail.com>
Message-ID: <2A438415-A4AF-4467-BDD0-82BC0110AB8B@dcn.davis.ca.us>

?expand.grid
-- 
Sent from my phone. Please excuse my brevity.

On April 12, 2017 6:28:24 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi all,
>I have two variables x and y. X has five observation and y has three.
>I want combine each element of x to  each element of y values to
>produce 15  observation. Below is my sample data and desired output
>
>data
>x   Y
>1   A
>2   B
>3   C
>4
>5
>
>Output
>1  A
>1  B
>1  C
>2  A
>2  B
>2  C
>3  A
>3  B
>3  C
>4  A
>4  B
>4  C
>5  A
>5  B
>5  C
>
>Thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Thu Apr 13 04:05:20 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 13 Apr 2017 05:05:20 +0300
Subject: [R] how to plot three dimension data to filled contour plot or
 surface plot in R Ask Question
In-Reply-To: <7bfab9c4-6eea-4818-9608-bb51cce616ae.dncdd@aliyun.com>
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
 <2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com,
 4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>
 <7bfab9c4-6eea-4818-9608-bb51cce616ae.dncdd@aliyun.com>
Message-ID: <696A3281-B9ED-46A3-A31A-56A9288D05A6@gmail.com>


> On 12 Apr 2017, at 09:08, dncdd <dncdd at aliyun.com> wrote:
> 
> Sorry, I might make the question complicated. 
> 
> I can use filled.contour() to plot mini data 1(three dimension on flat surface). Now my problem is on mini data 2. Let's unfold the mini data 2.
> 
> 
>   r1dn   r2dn   tdn    fdn
>      x,     y,     z,     v
>     0.8    0.8    0.1    0.3
>     0.8    0.8    0.2    0.2
>     0.8    0.8    0.3    0.1
>     0.8    0.8    0.4    0
>     0.8    0.8    0.5    0
>     0.8    0.8    0.6    0
>     0.8    0.8    0.7    0
>     0.8    0.8    0.8    0
>     0.8    0.8    0.9    0
>     0.8    1.8    0.1    0.3
>     0.8    1.8    0.2    0.2
>     0.8    1.8    0.3    0.1
>     0.8    1.8    0.4    0.2
>     0.8    1.8    0.5    0.3
>     0.8    1.8    0.6    0.4
>     0.8    1.8    0.7    0.4
>     0.8    1.8    0.8    0.5
>     0.8    1.8    0.9    0.5
>     0.8    2.8    0.1    0.3
>     0.8    2.8    0.2    0.4
>     0.8    2.8    0.3    0.5
>     0.8    2.8    0.4    0.5
>     0.8    2.8    0.5    0.6
>     0.8    2.8    0.6    0.6
>     0.8    2.8    0.7    0.6
>     0.8    2.8    0.8    0.7
>     0.8    2.8    0.9    0.7
>     1.8    0.8    0.1    0.3
>     1.8    0.8    0.2    0.2
>     1.8    0.8    0.3    0.2
>     1.8    0.8    0.4    0.2
>     1.8    0.8    0.5    0.3
>     1.8    0.8    0.6    0.2
>     1.8    0.8    0.7    0
>     1.8    0.8    0.8    0
>     1.8    0.8    0.9    0
>     1.8    1.8    0.1    0.3
>     1.8    1.8    0.2    0.4
>     1.8    1.8    0.3    0.3
>     1.8    1.8    0.4    0.2
>     1.8    1.8    0.5    0.3
>     1.8    1.8    0.6    0.5
>     1.8    1.8    0.7    0.5
>     1.8    1.8    0.8    0.6
>     1.8    1.8    0.9    0.6
>     1.8    2.8    0.1    0.5
>     1.8    2.8    0.2    0.4
>     1.8    2.8    0.3    0.5
>     1.8    2.8    0.4    0.6
>     1.8    2.8    0.5    0.6
>     1.8    2.8    0.6    0.7
>     1.8    2.8    0.7    0.6
>     1.8    2.8    0.8    0.8
>     1.8    2.8    0.9    0.8
>     2.8    0.8    0.1    0.3
>     2.8    0.8    0.2    0.4
>     2.8    0.8    0.3    0.4
>     2.8    0.8    0.4    0.4
>     2.8    0.8    0.5    0.5
>     2.8    0.8    0.6    0.5
>     2.8    0.8    0.7    0.5
>     2.8    0.8    0.8    0.5
>     2.8    0.8    0.9    0.5
>     2.8    1.8    0.1    0.3
>     2.8    1.8    0.2    0.2
>     2.8    1.8    0.3    0.4
>     2.8    1.8    0.4    0.5
>     2.8    1.8    0.5    0.5
>     2.8    1.8    0.6    0.6
>     2.8    1.8    0.7    0.6
>     2.8    1.8    0.8    0.7
>     2.8    1.8    0.9    0.8
>     2.8    2.8    0.1    0.3
>     2.8    2.8    0.2    0.5
>     2.8    2.8    0.3    0.5
>     2.8    2.8    0.4    0.6
>     2.8    2.8    0.5    0.7
>     2.8    2.8    0.6    0.7
>     2.8    2.8    0.7    0.9
>     2.8    2.8    0.8    0.8
>     2.8    2.8    0.9    0.9
> 
> 
> When x is 0.8, y is 0.8, z is 0.1, then v is 0.3.  So v is not limited by a function like v ~ f(x,y,z). I mean x,y,z is just like labels on the 3d space.
> You have give me many suggestions. I think that maybe scatterplot with colors on v on 3d space is a solution. I will try it later. At the beginning, I was wondering 
> a 3d surface plot or 3d filled.contour on 3d space. I am not sure whether it is possble.


First of all, v is function of x,y,z according to sample above wheter you accept or not.  Because x,y,z represents coordinates of v in the 3D space and if someone wants to plot contours between those points, he/she needs a v(x,y,z) function that can calculate values (v) between x,y,z coordinates. Let?s get back to main question.

I think you want something like as [1] and [2]. Your best shot is misc3d package. I created a simple example how to plot isosurfaces and you can find different strategies to plot 4D data in 3D space at [3].

#??????????
library(misc3d)
# let's create a function to create a sample data to visualize
f <- function(x, y, z) sin(x) * sin(y) * sin(z)
x <- z <- seq(0, pi, length.out = 15)
y <- seq(-pi, pi, length.out = 15)
d <- expand.grid(x, y, z)
colnames(d) <- c("x", "y", "z")
d$v <- with(d, f(x, y, z))

# this is your initial data
head(d)

k <- 16 # number of contours
alpha_min_max <- c(0.2, 0.6)
colf <- colorRampPalette(rev(RColorBrewer::brewer.pal(11, "RdBu")))

# isosurfaces are at here
lev <- seq(min(d$v), max(d$v), length.out = k)
# inner isosurfaces are more solid, outer ones are more transparent.
# So, we can see inner isosurfaces by x-ray vision.
alpha <- seq(alpha_min_max[1], alpha_min_max[2], length.out = k)

rgl::plot3d(x, y, z, type = "n", aspect = TRUE) # create scene
misc3d::contour3d(f, lev, x, y, z, color = colf(k), alpha = alpha,
          smooth = 3, engine = "rgl", add = TRUE)
rgl::aspect3d(1, 2, 1) # set aspect, y is different from x and z.
#??????????


1- http://stackoverflow.com/a/11319175/557884 <http://stackoverflow.com/a/11319175/557884>
2- http://mathematica.stackexchange.com/a/19819 <http://mathematica.stackexchange.com/a/19819>
3- https://www.jstatsoft.org/article/view/v028i01 <https://www.jstatsoft.org/article/view/v028i01>






	[[alternative HTML version deleted]]


From dncdd at aliyun.com  Thu Apr 13 11:15:33 2017
From: dncdd at aliyun.com (dncdd)
Date: Thu, 13 Apr 2017 17:15:33 +0800
Subject: [R] =?utf-8?b?5Zue5aSN77yaIGhvdyB0byBwbG90IHRocmVlIGRpbWVuc2lv?=
 =?utf-8?q?n_data_to_filled_contour_plot_or_surface_plot_in_R__Ask_Questio?=
 =?utf-8?q?n?=
In-Reply-To: 696A3281-B9ED-46A3-A31A-56A9288D05A6@gmail.com
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
 <2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com,
 4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>
 <7bfab9c4-6eea-4818-9608-bb51cce616ae.dncdd@aliyun.com>,
 696A3281-B9ED-46A3-A31A-56A9288D05A6@gmail.com
Message-ID: <a98e98be-f58a-4c85-aea8-536985d175e8.dncdd@aliyun.com>

This can be a solution. Thank you. Thanks for your time.
------------------------------------------------------------------????Ismail SEZEN <sezenismail at gmail.com>?????2017?4?13?(???) 10:05????dncdd <dncdd at aliyun.com>????r-help <r-help at r-project.org>????Re: [R] how to plot three dimension data to filled contour plot or surface plot in R  Ask Question

On 12 Apr 2017, at 09:08, dncdd <dncdd at aliyun.com> wrote:
Sorry, I might make the question complicated.?
I can use filled.contour() to plot mini data 1(three dimension on flat surface). Now my problem is on mini data 2. Let's unfold the mini data 2.

??r1dn???r2dn???tdn????fdn
?????x,?????y,?????z, ? ? v
????0.8????0.8????0.1????0.3
????0.8????0.8????0.2????0.2
????0.8????0.8????0.3????0.1
????0.8????0.8????0.4????0
????0.8????0.8????0.5????0
????0.8????0.8????0.6????0
????0.8????0.8????0.7????0
????0.8????0.8????0.8????0
????0.8????0.8????0.9????0
????0.8????1.8????0.1????0.3
????0.8????1.8????0.2????0.2
????0.8????1.8????0.3????0.1
????0.8????1.8????0.4????0.2
????0.8????1.8????0.5????0.3
????0.8????1.8????0.6????0.4
????0.8????1.8????0.7????0.4
????0.8????1.8????0.8????0.5
????0.8????1.8????0.9????0.5
????0.8????2.8????0.1????0.3
????0.8????2.8????0.2????0.4
????0.8????2.8????0.3????0.5
????0.8????2.8????0.4????0.5
????0.8????2.8????0.5????0.6
????0.8????2.8????0.6????0.6
????0.8????2.8????0.7????0.6
????0.8????2.8????0.8????0.7
????0.8????2.8????0.9????0.7
????1.8????0.8????0.1????0.3
????1.8????0.8????0.2????0.2
????1.8????0.8????0.3????0.2
????1.8????0.8????0.4????0.2
????1.8????0.8????0.5????0.3
????1.8????0.8????0.6????0.2
????1.8????0.8????0.7????0
????1.8????0.8????0.8????0
????1.8????0.8????0.9????0
????1.8????1.8????0.1????0.3
????1.8????1.8????0.2????0.4
????1.8????1.8????0.3????0.3
????1.8????1.8????0.4????0.2
????1.8????1.8????0.5????0.3
????1.8????1.8????0.6????0.5
????1.8????1.8????0.7????0.5
????1.8????1.8????0.8????0.6
????1.8????1.8????0.9????0.6
????1.8????2.8????0.1????0.5
????1.8????2.8????0.2????0.4
????1.8????2.8????0.3????0.5
????1.8????2.8????0.4????0.6
????1.8????2.8????0.5????0.6
????1.8????2.8????0.6????0.7
????1.8????2.8????0.7????0.6
????1.8????2.8????0.8????0.8
????1.8????2.8????0.9????0.8
????2.8????0.8????0.1????0.3
????2.8????0.8????0.2????0.4
????2.8????0.8????0.3????0.4
????2.8????0.8????0.4????0.4
????2.8????0.8????0.5????0.5
????2.8????0.8????0.6????0.5
????2.8????0.8????0.7????0.5
????2.8????0.8????0.8????0.5
????2.8????0.8????0.9????0.5
????2.8????1.8????0.1????0.3
????2.8????1.8????0.2????0.2
????2.8????1.8????0.3????0.4
????2.8????1.8????0.4????0.5
????2.8????1.8????0.5????0.5
????2.8????1.8????0.6????0.6
????2.8????1.8????0.7????0.6
????2.8????1.8????0.8????0.7
????2.8????1.8????0.9????0.8
????2.8????2.8????0.1????0.3
????2.8????2.8????0.2????0.5
????2.8????2.8????0.3????0.5
????2.8????2.8????0.4????0.6
????2.8????2.8????0.5????0.7
????2.8????2.8????0.6????0.7
????2.8????2.8????0.7????0.9
????2.8????2.8????0.8????0.8
????2.8????2.8????0.9????0.9

When x is 0.8, y is 0.8, z is 0.1, then v is 0.3. ?So v is not limited by a function like v ~ f(x,y,z). I mean x,y,z is just like labels on the 3d space.You have give me many suggestions. I think that maybe scatterplot with colors on v on 3d space is a solution. I will try it later. At the beginning, I was wondering?a 3d surface plot or 3d filled.contour on 3d space. I am not sure whether it is possble.

First of all, v is function of x,y,z according to sample above wheter you accept or not. ?Because x,y,z represents coordinates of v in the 3D space and if someone wants to plot contours between those points, he/she needs a v(x,y,z) function that can calculate values (v) between x,y,z coordinates. Let?s get back to main question.
I think you want something like as [1] and [2]. Your best shot is misc3d package. I created a simple example how to plot isosurfaces and you can find different strategies to plot 4D data in 3D space at [3].
#??????????library(misc3d)# let's create a function to create a sample data to visualizef <- function(x, y, z) sin(x) * sin(y) * sin(z)x <- z <- seq(0, pi, length.out = 15)y <- seq(-pi, pi, length.out = 15)d <- expand.grid(x, y, z)colnames(d) <- c("x", "y", "z")d$v <- with(d, f(x, y, z))
# this is your initial datahead(d)
k <- 16 # number of contoursalpha_min_max <- c(0.2, 0.6)colf <- colorRampPalette(rev(RColorBrewer::brewer.pal(11, "RdBu")))
# isosurfaces are at herelev <- seq(min(d$v), max(d$v), length.out = k)# inner isosurfaces are more solid, outer ones are more transparent.# So, we can see inner isosurfaces by x-ray vision.alpha <- seq(alpha_min_max[1], alpha_min_max[2], length.out = k)
rgl::plot3d(x, y, z, type = "n", aspect = TRUE) # create scenemisc3d::contour3d(f, lev, x, y, z, color = colf(k), alpha = alpha,? ? ? ? ? smooth = 3, engine = "rgl", add = TRUE)rgl::aspect3d(1, 2, 1) # set aspect, y is different from x and z.#??????????

1-?http://stackoverflow.com/a/11319175/5578842-?http://mathematica.stackexchange.com/a/198193-?https://www.jstatsoft.org/article/view/v028i01






	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Thu Apr 13 17:06:04 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Thu, 13 Apr 2017 20:36:04 +0530
Subject: [R] Wait for batch file to execute
Message-ID: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>

Hi All,

I am using below code to execute a batch file on server to get me data from
an API

it looks like:

shell.exec('<<path name>>\\file.bat')
#do next step

The problem is that this function shell.exec doesn't wait for the batch
file to execute completely and jumps to next line of code.

Any ideas how can I hold R to go for next line of code until and unless
batch file has completed its execution.

Many thanks.

P.S: I tried to use shell() but it says could not find function shell

-- 
Regards
Archit

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Apr 13 17:19:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 13 Apr 2017 08:19:40 -0700
Subject: [R] Wait for batch file to execute
In-Reply-To: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
References: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
Message-ID: <CAGxFJbQaFTj-qvvh95eG+yyM7U3pbjeOiaeAxTuRQm_jABOBeQ@mail.gmail.com>

?system or ?system2

Note the "wait" argument


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 13, 2017 at 8:06 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> Hi All,
>
> I am using below code to execute a batch file on server to get me data from
> an API
>
> it looks like:
>
> shell.exec('<<path name>>\\file.bat')
> #do next step
>
> The problem is that this function shell.exec doesn't wait for the batch
> file to execute completely and jumps to next line of code.
>
> Any ideas how can I hold R to go for next line of code until and unless
> batch file has completed its execution.
>
> Many thanks.
>
> P.S: I tried to use shell() but it says could not find function shell
>
> --
> Regards
> Archit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Apr 13 17:24:13 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 13 Apr 2017 08:24:13 -0700
Subject: [R] Wait for batch file to execute
In-Reply-To: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
References: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
Message-ID: <05238872-9F1C-458A-8107-5E50096A3409@dcn.davis.ca.us>

For future reference, this kind of question should usually be accompanied by information about your OS such as the sessionInfo function returns... but in this case just read about the wait argument to ?system2.
-- 
Sent from my phone. Please excuse my brevity.

On April 13, 2017 8:06:04 AM PDT, Archit Soni <soni.archit1989 at gmail.com> wrote:
>Hi All,
>
>I am using below code to execute a batch file on server to get me data
>from
>an API
>
>it looks like:
>
>shell.exec('<<path name>>\\file.bat')
>#do next step
>
>The problem is that this function shell.exec doesn't wait for the batch
>file to execute completely and jumps to next line of code.
>
>Any ideas how can I hold R to go for next line of code until and unless
>batch file has completed its execution.
>
>Many thanks.
>
>P.S: I tried to use shell() but it says could not find function shell


From soni.archit1989 at gmail.com  Thu Apr 13 17:26:34 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Thu, 13 Apr 2017 20:56:34 +0530
Subject: [R] Wait for batch file to execute
In-Reply-To: <CAGxFJbQaFTj-qvvh95eG+yyM7U3pbjeOiaeAxTuRQm_jABOBeQ@mail.gmail.com>
References: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
 <CAGxFJbQaFTj-qvvh95eG+yyM7U3pbjeOiaeAxTuRQm_jABOBeQ@mail.gmail.com>
Message-ID: <CAJ7HxBy=jMP-NSFET=+T4V-f3ChsEk9BJF4q1jgqCLMVMvGvWg@mail.gmail.com>

Awesome.. Thanks Bert. You saved a lot tension and hours.

Thanks again :)

On Apr 13, 2017 20:49, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> ?system or ?system2
>
> Note the "wait" argument
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Apr 13, 2017 at 8:06 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> > Hi All,
> >
> > I am using below code to execute a batch file on server to get me data
> from
> > an API
> >
> > it looks like:
> >
> > shell.exec('<<path name>>\\file.bat')
> > #do next step
> >
> > The problem is that this function shell.exec doesn't wait for the batch
> > file to execute completely and jumps to next line of code.
> >
> > Any ideas how can I hold R to go for next line of code until and unless
> > batch file has completed its execution.
> >
> > Many thanks.
> >
> > P.S: I tried to use shell() but it says could not find function shell
> >
> > --
> > Regards
> > Archit
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Thu Apr 13 17:27:28 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Thu, 13 Apr 2017 20:57:28 +0530
Subject: [R] Wait for batch file to execute
In-Reply-To: <05238872-9F1C-458A-8107-5E50096A3409@dcn.davis.ca.us>
References: <CAJ7HxByf8YtW5=F4o5iyQEVV4RPH=soq7GC83NVj8g=DwQT+Vg@mail.gmail.com>
 <05238872-9F1C-458A-8107-5E50096A3409@dcn.davis.ca.us>
Message-ID: <CAJ7HxBws-F1JxRooGBTr0+-4oVMyYo4ainaFAQOQ9hvcW80Abw@mail.gmail.com>

Thanks Jeff.. Will keep in mind.

On Apr 13, 2017 20:54, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

> For future reference, this kind of question should usually be accompanied
> by information about your OS such as the sessionInfo function returns...
> but in this case just read about the wait argument to ?system2.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 13, 2017 8:06:04 AM PDT, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> >Hi All,
> >
> >I am using below code to execute a batch file on server to get me data
> >from
> >an API
> >
> >it looks like:
> >
> >shell.exec('<<path name>>\\file.bat')
> >#do next step
> >
> >The problem is that this function shell.exec doesn't wait for the batch
> >file to execute completely and jumps to next line of code.
> >
> >Any ideas how can I hold R to go for next line of code until and unless
> >batch file has completed its execution.
> >
> >Many thanks.
> >
> >P.S: I tried to use shell() but it says could not find function shell
>

	[[alternative HTML version deleted]]


From dncdd at aliyun.com  Thu Apr 13 13:25:34 2017
From: dncdd at aliyun.com (dncdd)
Date: Thu, 13 Apr 2017 19:25:34 +0800
Subject: [R] =?utf-8?b?5Zue5aSN77yaIOWbnuWkje+8miBob3cgdG8gcGxvdCB0aHJl?=
 =?utf-8?q?e_dimension_data_to_filled_contour_plot_or_surface_plot_in_R__A?=
 =?utf-8?q?sk_Question?=
In-Reply-To: a98e98be-f58a-4c85-aea8-536985d175e8.dncdd@aliyun.com
References: <67429e6e-2c23-46fd-9823-91fcc2e114fe.dncdd@aliyun.com>
 <2C63138E-5613-4053-9B78-B3C4B7C7199F@gmail.com,
 4f452436-055e-4701-a7cd-c072efe944f1.dncdd@aliyun.com>
 <7bfab9c4-6eea-4818-9608-bb51cce616ae.dncdd@aliyun.com>,
 696A3281-B9ED-46A3-A31A-56A9288D05A6@gmail.com,
 a98e98be-f58a-4c85-aea8-536985d175e8.dncdd@aliyun.com
Message-ID: <f884921f-8e6f-469f-9d95-8211498bea25.dncdd@aliyun.com>



x<-c(0.8,1.8,2.8)?
y<-c(0.8,1.8,2.8)?
z<-c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)?
nx<-sprintf("x%s",x)
ny<-sprintf("y%s",y)
nz<-sprintf("z%s",z)

v<-c(
?????0.3,?0.2,?0.1,?0,?0,?0,?0,?0,?0,
?????0.3,?0.2,?0.1,?0.2,?0.3,?0.4,?0.4,?0.5,?0.5,
?????0.3,?0.4,?0.5,?0.5,?0.6,?0.6,?0.6,?0.7,?0.7,
?????0.3,?0.2,?0.2,?0.2,?0.3,?0.2,?0,?0,?0,
?????0.3,?0.4,?0.3,?0.2,?0.3,?0.5,?0.5,?0.6,?0.6,
?????0.5,?0.4,?0.5,?0.6,?0.6,?0.7,?0.6,?0.8,?0.8,
?????0.3,?0.4,?0.4,?0.4,?0.5,?0.5,?0.5,?0.5,?0.5,
?????0.3,?0.2,?0.4,?0.5,?0.5,?0.6,?0.6,?0.7,?0.8,
?????0.3,?0.5,?0.5,?0.6,?0.7,?0.7,?0.9,?0.8,?0.9)
myarray<-array(v,?c(length(z),?length(y),?length(x)),?dimnames=list(z,y,x))
odftarget<-as.data.frame.table(myarray)
names(odftarget)?<-?c('z',?'y',?'x',?'v')
dftarget?<-?data.frame(
????z=as.numeric(as.character(odftarget$z)),
????y=as.numeric(as.character(odftarget$y)),?
????x=as.numeric(as.character(odftarget$x)),?
????v=odftarget$v
)
head(dftarget)

k?<-?16?#?number?of?contours
alpha_min_max?<-?c(0.2,?0.6)
colf?<-?colorRampPalette(rev(RColorBrewer::brewer.pal(11,?"RdBu")))
colf?<-?colorRampPalette(colpal)

#?isosurfaces?are?at?here
lev?<-?seq(min(dftarget$v),?max(dftarget$v),?length.out?=?k)
#?inner?isosurfaces?are?more?solid,?outer?ones?are?more?transparent.
#?So,?we?can?see?inner?isosurfaces?by?x-ray?vision.
alpha?<-?seq(alpha_min_max[1],?alpha_min_max[2],?length.out?=?k)

rgl::plot3d(z,?y,?x,?type?=?"n",?aspect?=?TRUE)?#?create?scene# I am using the array here.
misc3d::contour3d(myarray,?lev,?z,?y,?x,?color?=?colf(k),?alpha?=?alpha, smooth?=?3,?engine?=?"rgl",?add?=?TRUE)?
rgl::aspect3d(2,?1,?1)?



It works.Thank you.


------------------------------------------------------------------????dncdd via R-help <r-help at r-project.org>?????2017?4?13?(???) 18:07????Ismail SEZEN <sezenismail at gmail.com>????r-help <r-help at r-project.org>????[R] ??? how to plot three dimension data to filled contour plot or surface plot in R  Ask Question
This?can?be?a?solution.?Thank?you.?Thanks?for?your?time.
------------------------------------------------------------------????Ismail?SEZEN?<sezenismail at gmail.com>?????2017?4?13?(???)?10:05????dncdd?<dncdd at aliyun.com>????r-help?<r-help at r-project.org>????Re:?[R]?how?to?plot?three?dimension?data?to?filled?contour?plot?or?surface?plot?in?R??Ask?Question

On?12?Apr?2017,?at?09:08,?dncdd?<dncdd at aliyun.com>?wrote:
Sorry,?I?might?make?the?question?complicated.?
I?can?use?filled.contour()?to?plot?mini?data?1(three?dimension?on?flat?surface).?Now?my?problem?is?on?mini?data?2.?Let's?unfold?the?mini?data?2.

??r1dn???r2dn???tdn????fdn
?????x,?????y,?????z,?????v
????0.8????0.8????0.1????0.3
????0.8????0.8????0.2????0.2
????0.8????0.8????0.3????0.1
????0.8????0.8????0.4????0
????0.8????0.8????0.5????0
????0.8????0.8????0.6????0
????0.8????0.8????0.7????0
????0.8????0.8????0.8????0
????0.8????0.8????0.9????0
????0.8????1.8????0.1????0.3
????0.8????1.8????0.2????0.2
????0.8????1.8????0.3????0.1
????0.8????1.8????0.4????0.2
????0.8????1.8????0.5????0.3
????0.8????1.8????0.6????0.4
????0.8????1.8????0.7????0.4
????0.8????1.8????0.8????0.5
????0.8????1.8????0.9????0.5
????0.8????2.8????0.1????0.3
????0.8????2.8????0.2????0.4
????0.8????2.8????0.3????0.5
????0.8????2.8????0.4????0.5
????0.8????2.8????0.5????0.6
????0.8????2.8????0.6????0.6
????0.8????2.8????0.7????0.6
????0.8????2.8????0.8????0.7
????0.8????2.8????0.9????0.7
????1.8????0.8????0.1????0.3
????1.8????0.8????0.2????0.2
????1.8????0.8????0.3????0.2
????1.8????0.8????0.4????0.2
????1.8????0.8????0.5????0.3
????1.8????0.8????0.6????0.2
????1.8????0.8????0.7????0
????1.8????0.8????0.8????0
????1.8????0.8????0.9????0
????1.8????1.8????0.1????0.3
????1.8????1.8????0.2????0.4
????1.8????1.8????0.3????0.3
????1.8????1.8????0.4????0.2
????1.8????1.8????0.5????0.3
????1.8????1.8????0.6????0.5
????1.8????1.8????0.7????0.5
????1.8????1.8????0.8????0.6
????1.8????1.8????0.9????0.6
????1.8????2.8????0.1????0.5
????1.8????2.8????0.2????0.4
????1.8????2.8????0.3????0.5
????1.8????2.8????0.4????0.6
????1.8????2.8????0.5????0.6
????1.8????2.8????0.6????0.7
????1.8????2.8????0.7????0.6
????1.8????2.8????0.8????0.8
????1.8????2.8????0.9????0.8
????2.8????0.8????0.1????0.3
????2.8????0.8????0.2????0.4
????2.8????0.8????0.3????0.4
????2.8????0.8????0.4????0.4
????2.8????0.8????0.5????0.5
????2.8????0.8????0.6????0.5
????2.8????0.8????0.7????0.5
????2.8????0.8????0.8????0.5
????2.8????0.8????0.9????0.5
????2.8????1.8????0.1????0.3
????2.8????1.8????0.2????0.2
????2.8????1.8????0.3????0.4
????2.8????1.8????0.4????0.5
????2.8????1.8????0.5????0.5
????2.8????1.8????0.6????0.6
????2.8????1.8????0.7????0.6
????2.8????1.8????0.8????0.7
????2.8????1.8????0.9????0.8
????2.8????2.8????0.1????0.3
????2.8????2.8????0.2????0.5
????2.8????2.8????0.3????0.5
????2.8????2.8????0.4????0.6
????2.8????2.8????0.5????0.7
????2.8????2.8????0.6????0.7
????2.8????2.8????0.7????0.9
????2.8????2.8????0.8????0.8
????2.8????2.8????0.9????0.9

When?x?is?0.8,?y?is?0.8,?z?is?0.1,?then?v?is?0.3.??So?v?is?not?limited?by?a?function?like?v?~?f(x,y,z).?I?mean?x,y,z?is?just?like?labels?on?the?3d?space.You?have?give?me?many?suggestions.?I?think?that?maybe?scatterplot?with?colors?on?v?on?3d?space?is?a?solution.?I?will?try?it?later.?At?the?beginning,?I?was?wondering?a?3d?surface?plot?or?3d?filled.contour?on?3d?space.?I?am?not?sure?whether?it?is?possble.

First?of?all,?v?is?function?of?x,y,z?according?to?sample?above?wheter?you?accept?or?not.??Because?x,y,z?represents?coordinates?of?v?in?the?3D?space?and?if?someone?wants?to?plot?contours?between?those?points,?he/she?needs?a?v(x,y,z)?function?that?can?calculate?values?(v)?between?x,y,z?coordinates.?Let?s?get?back?to?main?question.
I?think?you?want?something?like?as?[1]?and?[2].?Your?best?shot?is?misc3d?package.?I?created?a?simple?example?how?to?plot?isosurfaces?and?you?can?find?different?strategies?to?plot?4D?data?in?3D?space?at?[3].
#??????????library(misc3d)#?let's?create?a?function?to?create?a?sample?data?to?visualizef?<-?function(x,?y,?z)?sin(x)?*?sin(y)?*?sin(z)x?<-?z?<-?seq(0,?pi,?length.out?=?15)y?<-?seq(-pi,?pi,?length.out?=?15)d?<-?expand.grid(x,?y,?z)colnames(d)?<-?c("x",?"y",?"z")d$v?<-?with(d,?f(x,?y,?z))
#?this?is?your?initial?datahead(d)
k?<-?16?#?number?of?contoursalpha_min_max?<-?c(0.2,?0.6)colf?<-?colorRampPalette(rev(RColorBrewer::brewer.pal(11,?"RdBu")))
#?isosurfaces?are?at?herelev?<-?seq(min(d$v),?max(d$v),?length.out?=?k)#?inner?isosurfaces?are?more?solid,?outer?ones?are?more?transparent.#?So,?we?can?see?inner?isosurfaces?by?x-ray?vision.alpha?<-?seq(alpha_min_max[1],?alpha_min_max[2],?length.out?=?k)
rgl::plot3d(x,?y,?z,?type?=?"n",?aspect?=?TRUE)?#?create?scenemisc3d::contour3d(f,?lev,?x,?y,?z,?color?=?colf(k),?alpha?=?alpha,??????????smooth?=?3,?engine?=?"rgl",?add?=?TRUE)rgl::aspect3d(1,?2,?1)?#?set?aspect,?y?is?different?from?x?and?z.#??????????

1-?http://stackoverflow.com/a/11319175/5578842-?http://mathematica.stackexchange.com/a/198193-?https://www.jstatsoft.org/article/view/v028i01






?[[alternative?HTML?version?deleted]]

______________________________________________
R-help at r-project.org?mailing?list?--?To?UNSUBSCRIBE?and?more,?see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE?do?read?the?posting?guide?http://www.R-project.org/posting-guide.html
and?provide?commented,?minimal,?self-contained,?reproducible?code.

	[[alternative HTML version deleted]]


From r-packages at r-project.org  Tue Apr 11 16:19:19 2017
From: r-packages at r-project.org (brodie gaslam via R-packages)
Date: Tue, 11 Apr 2017 14:19:19 +0000
Subject: [R] [R-pkgs] Announcing 'unitizer': Interactive Unit Tests
References: <1408192736.562858.1491920359684.ref@mail.yahoo.com>
Message-ID: <1408192736.562858.1491920359684@mail.yahoo.com>

`unitizer` is a unit testing framework for tests that produce non-trivial output.  It is conceptually similar to using ".Rout.save" files, except we save the actual R objects and conditions, and we streamline the update/test/debug cycle via an interactive interface.  A non-interactive mode is available for R CMD check runs.

* unitizer 1.4.2 on CRAN: https://cran.r-project.org/package=unitizer

* A demo screencast: http://htmlpreview.github.io/?https://github.com/brodieG/unitizer/blob/rc/extra/gifshow.html


Feedback welcome (github: https://github.com/brodieG/unitizer).

Also, a big thank you to Uwe Ligges and Kurt Hornik for maintaining CRAN and for their patience with my submission.


Best regards,


Brodie Gaslam.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From frymor at gmail.com  Thu Apr 13 16:47:11 2017
From: frymor at gmail.com (Assa Yeroslaviz)
Date: Thu, 13 Apr 2017 14:47:11 +0000
Subject: [R] convert a text file into a list (of lists)
Message-ID: <CA+8XemzMYG7T7pJ-k9=SbOT4TAJ7P3t5mQA2ZtAKZcnqe9=QHA@mail.gmail.com>

Hi,

I have a text file i would like to read into a list structure in R.

the files is something like that (which might be describe as a list of data
frames):

[[1]]
                   NAME  MEM.SHIP
FBgn0037415 FBgn0037415 0.8035441
FBgn0010812 FBgn0010812 0.6579683
FBgn0265351 FBgn0265351 0.6443309

[[3]]
                   NAME  MEM.SHIP
FBgn0037227 FBgn0037227 0.9997242
FBgn0040682 FBgn0040682 0.9997242
[[9]]
                   NAME  MEM.SHIP
FBgn0026620 FBgn0026620 0.5241095
FBgn0263619 FBgn0263619 0.5420427
FBgn0263353 FBgn0263353 0.9812295
FBgn0037424 FBgn0037424 0.9793901
FBgn0037428 FBgn0037428 0.9779420
FBgn0037430 FBgn0037430 0.9540148
FBgn0004777 FBgn0004777 0.8962534
FBgn0004778 FBgn0004778 0.9810570
...

I would like it to have a list structure like that at the end:

> str(INPUT)
List of 3
 $ : Factor w/ 223 levels "GENE1",..: 194 129 222 213 42 130 45 131 132 133
...
 $ : Factor w/ 210 levels "GENE4",..: 185 109 110 146 171 175 111 17 112
209 ...
 $ : Factor w/ 343 levels "GENE7",..: 27 296 326 228 229 263 19 39 230 26

I am reading the file in with scan, but I just get a character vector of
all the elements together.
I was wondering if there is a way to split the text file into a list by the
pattern [[.*]] and than extract only the first  column from each data frame.

thanks in advance
Assa

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Thu Apr 13 16:56:37 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 13 Apr 2017 14:56:37 +0000 (UTC)
Subject: [R] Merge list element by name
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
Message-ID: <567195758.1270617.1492095397619@mail.yahoo.com>

Hi, 
I have a list like 
kk<- list (a = 1:5, b = 6:10, c = 4:11)

Now i want to merger (Union) the list element "a" and "c" by name .

My expected outcome is 
kk1<- list(a_c = 1:11, b = 6:10)


I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.
Thanks in advance. 
 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 


From mashranga at yahoo.com  Thu Apr 13 16:59:48 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 13 Apr 2017 14:59:48 +0000 (UTC)
Subject: [R] Merge selected list element by name
In-Reply-To: <567195758.1270617.1492095397619@mail.yahoo.com>
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
 <567195758.1270617.1492095397619@mail.yahoo.com>
Message-ID: <1024932152.1281623.1492095588077@mail.yahoo.com>


Hi, 

I have a list like 

kk<- list (a = 1:5, b = 6:10, c = 4:11)


Now i want to merger (Union) the list element "a" and "c" by name .


My expected outcome is 

kk1<- list(a_c = 1:11, b = 6:10)



I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.

Thanks in advance. 


Tanvir Ahamed 

G?teborg, Sweden  |  mashranga at yahoo.com 


From ruipbarradas at sapo.pt  Thu Apr 13 18:37:06 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 13 Apr 2017 17:37:06 +0100
Subject: [R] Merge selected list element by name
In-Reply-To: <1024932152.1281623.1492095588077@mail.yahoo.com>
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
 <567195758.1270617.1492095397619@mail.yahoo.com>
 <1024932152.1281623.1492095588077@mail.yahoo.com>
Message-ID: <58EFA932.6050507@sapo.pt>

Hello,

There's no need to send the same question twice, we've got it at the 
first try.
Maybe I don't understand but is this it?

kk1 <- list(a_c = union(kk$a, kk$c), b = kk$b)
kk1
$a_c
  [1]  1  2  3  4  5  6  7  8  9 10 11

$b
[1]  6  7  8  9 10


Hope this helps,

Rui Barradas

Em 13-04-2017 15:59, Mohammad Tanvir Ahamed via R-help escreveu:
>
> Hi,
>
> I have a list like
>
> kk<- list (a = 1:5, b = 6:10, c = 4:11)
>
>
> Now i want to merger (Union) the list element "a" and "c" by name .
>
>
> My expected outcome is
>
> kk1<- list(a_c = 1:11, b = 6:10)
>
>
>
> I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.
>
> Thanks in advance.
>
>
> Tanvir Ahamed
>
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mashranga at yahoo.com  Thu Apr 13 19:33:06 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 13 Apr 2017 17:33:06 +0000 (UTC)
Subject: [R] Merge selected list element by name
In-Reply-To: <58EFA932.6050507@sapo.pt>
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
 <567195758.1270617.1492095397619@mail.yahoo.com>
 <1024932152.1281623.1492095588077@mail.yahoo.com> <58EFA932.6050507@sapo.pt>
Message-ID: <660044294.1398968.1492104786541@mail.yahoo.com>

Thanks for your code. 
But this is not the way i am expecting . 

I want to merge (Union) "a" and "c" and my expected output is 

> kk1
$a_c
 [1]  1  2  3  4  5  6  7  8  9 10 11

$b
[1]  6  7  8  9 10


Note : I worte the code kk1<- list(a_c = 1:11, b = 6:10) just to show by expected outcome. But i am expecting the resulting code will naming "a_c" by itself also.
Hope i can make clear about problem. 

 

 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 



________________________________
From: Rui Barradas <ruipbarradas at sapo.pt>

lp at r-project.org> 
Sent: Thursday, 13 April 2017, 18:37
Subject: Re: [R] Merge selected list element by name



Hello,

There's no need to send the same question twice, we've got it at the 
first try.
Maybe I don't understand but is this it?

kk1 <- list(a_c = union(kk$a, kk$c), b = kk$b)
kk1
$a_c
  [1]  1  2  3  4  5  6  7  8  9 10 11

$b
[1]  6  7  8  9 10


Hope this helps,

Rui Barradas


Em 13-04-2017 15:59, Mohammad Tanvir Ahamed via R-help escreveu:
>
> Hi,
>
> I have a list like
>
> kk<- list (a = 1:5, b = 6:10, c = 4:11)
>
>
> Now i want to merger (Union) the list element "a" and "c" by name .
>
>
> My expected outcome is
>
> kk1<- list(a_c = 1:11, b = 6:10)
>
>
>
> I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.
>
> Thanks in advance.
>
>
> Tanvir Ahamed
>

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>


From bgunter.4567 at gmail.com  Thu Apr 13 23:08:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 13 Apr 2017 14:08:58 -0700
Subject: [R] Merge selected list element by name
In-Reply-To: <660044294.1398968.1492104786541@mail.yahoo.com>
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
 <567195758.1270617.1492095397619@mail.yahoo.com>
 <1024932152.1281623.1492095588077@mail.yahoo.com>
 <58EFA932.6050507@sapo.pt> <660044294.1398968.1492104786541@mail.yahoo.com>
Message-ID: <CAGxFJbSo1U=m5gQAG9PVjwv=+gU_amHmV9JoEptjgjY8fhJx5A@mail.gmail.com>

So do you mean like this:

> kk<- list (a = 1:5, b = 6:10, c = 4:11)
> kk1 <- list(union(kk$a,kk$c),kk$b)
> names(kk1)<- c(paste(names(kk)[c(1,3)],collapse="_"),names(kk)[2])
> kk1
$a_c
 [1]  1  2  3  4  5  6  7  8  9 10 11

$b
[1]  6  7  8  9 10

??

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 13, 2017 at 10:33 AM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Thanks for your code.
> But this is not the way i am expecting .
>
> I want to merge (Union) "a" and "c" and my expected output is
>
>> kk1
> $a_c
>  [1]  1  2  3  4  5  6  7  8  9 10 11
>
> $b
> [1]  6  7  8  9 10
>
>
> Note : I worte the code kk1<- list(a_c = 1:11, b = 6:10) just to show by expected outcome. But i am expecting the resulting code will naming "a_c" by itself also.
> Hope i can make clear about problem.
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
>
>
> ________________________________
> From: Rui Barradas <ruipbarradas at sapo.pt>
>
> lp at r-project.org>
> Sent: Thursday, 13 April 2017, 18:37
> Subject: Re: [R] Merge selected list element by name
>
>
>
> Hello,
>
> There's no need to send the same question twice, we've got it at the
> first try.
> Maybe I don't understand but is this it?
>
> kk1 <- list(a_c = union(kk$a, kk$c), b = kk$b)
> kk1
> $a_c
>   [1]  1  2  3  4  5  6  7  8  9 10 11
>
> $b
> [1]  6  7  8  9 10
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 13-04-2017 15:59, Mohammad Tanvir Ahamed via R-help escreveu:
>>
>> Hi,
>>
>> I have a list like
>>
>> kk<- list (a = 1:5, b = 6:10, c = 4:11)
>>
>>
>> Now i want to merger (Union) the list element "a" and "c" by name .
>>
>>
>> My expected outcome is
>>
>> kk1<- list(a_c = 1:11, b = 6:10)
>>
>>
>>
>> I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.
>>
>> Thanks in advance.
>>
>>
>> Tanvir Ahamed
>>
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Apr 14 00:13:21 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Apr 2017 15:13:21 -0700
Subject: [R] Merge list element by name
In-Reply-To: <567195758.1270617.1492095397619@mail.yahoo.com>
References: <567195758.1270617.1492095397619.ref@mail.yahoo.com>
 <567195758.1270617.1492095397619@mail.yahoo.com>
Message-ID: <2D31D0ED-03ED-4E87-B154-96B544EC4FC7@comcast.net>


> On Apr 13, 2017, at 7:56 AM, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
> 
> Hi, 
> I have a list like 
> kk<- list (a = 1:5, b = 6:10, c = 4:11)
> 
> Now i want to merger (Union) the list element "a" and "c" by name .
> 
> My expected outcome is 
> kk1<- list(a_c = 1:11, b = 6:10)
> 
> 
> I can do it with several lines of code. But can any one have idea to do efficiently/ quickly on a big data with less code.

Given that you used the term in your problem specification, it's hard to understand how you missed finding the `union` function :

kk1 <- with( kk, list( a_c <- union(a,c), b=b)  )
 kk1
#-----
[[1]]
 [1]  1  2  3  4  5 11 10  9  8  7  6

$b
[1] 10  9  8  7  6
#-----

(It's not a `merge`.)

I thought this would remove any factor-stored information, since the code (before bytecode compilation) is:

function (x, y) 
unique(c(as.vector(x), as.vector(y)))

But 'as.vector' does the equivalent of 'as.character' on factor vectors, so you would be "safe" from that concern.


-- 
David.

> Thanks in advance. 
> 
> Tanvir Ahamed 
> G?teborg, Sweden  |  mashranga at yahoo.com 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ssefick at gmail.com  Fri Apr 14 00:44:49 2017
From: ssefick at gmail.com (stephen sefick)
Date: Thu, 13 Apr 2017 17:44:49 -0500
Subject: [R] colorspace namespace problem with R CMD check --as-cran
In-Reply-To: <CADKEMqi0aNGt+U=p8Eg+fHVfQogFFkZV4FKFnpoP8VtVnnuojQ@mail.gmail.com>
References: <CADKEMqjFNcqjDJ399QSoUxjxyzkZxt2zhCT2tkbrPPQ03QG50A@mail.gmail.com>
 <CAF8bMcaM25DYYBbo6rZrZsTJh_RaMCk5PgbTyaYbex=U5onpCw@mail.gmail.com>
 <CADKEMqi0aNGt+U=p8Eg+fHVfQogFFkZV4FKFnpoP8VtVnnuojQ@mail.gmail.com>
Message-ID: <CADKEMqiAhAT=6QvR+VcyUsRpqbNMzLmkq3ar2WbNA-cH7zXLPQ@mail.gmail.com>

For those interested, I fixed this problem by adding LazyLoad: yes to the
DESCRIPTION file (I overlooked this because LazyData was there). I found
the answer in this exchange between Dr. Ripley and Wickham (
http://r.789695.n4.nabble.com/checking-whether-the-name-space-can-be-loaded-with-stated-dependencies-td918313.html#a918314
).

Thanks for the help.
kindest regards,

Stephen Sefick

On Tue, Apr 11, 2017 at 6:26 PM, stephen sefick <ssefick at gmail.com> wrote:

> Here is the relevant snippett from devtools::check() logs. I searched
> every file in pkg/R, and there is no call to plot.index (or plot at all).
>
> Warning: namespace ?colorspace? is not available and has been replaced
> by .GlobalEnv when processing object ?plot.index?
> Warning: namespace ?colorspace? is not available and has been replaced
> by .GlobalEnv when processing object ?plot.index?
>
>
> On Tue, Apr 11, 2017 at 5:15 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> Does one of the objects in pkg/data (or pkg/R) include a function made
>> by one of the functions in package:colorspace?  Such a function would
>> have the environment getNamespace("colorspace").
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Apr 11, 2017 at 2:47 PM, stephen sefick <ssefick at gmail.com>
>> wrote:
>> > I am at a loss. I do not know how to make this reproducible without
>> > providing the package sourced. I am receiving a warning when issuing
>> >
>> > R --vanilla CMD check --as-cran --no-restore
>> >
>> > The description file has
>> > Imports: methods, reshape2, plyr, doBy, zoo
>> >
>> > this is in 00install.out
>> > ** R
>> > ** data
>> > *** moving datasets to lazyload DB
>> > ** inst
>> > ** preparing package for lazy loading
>> > Warning: namespace ?colorspace? is not available and has been replaced
>> > by .GlobalEnv when processing object ?plot.index?
>> > Warning: namespace ?colorspace? is not available and has been replaced
>> > by .GlobalEnv when processing object ?plot.index?
>> > ** help
>> > *** installing help indices
>> > ** building package indices
>> > ** testing if installed package can be loaded
>> >
>> >
>> > Thank you for any help in advance.
>> > kindest regards,
>> >
>> > Stephen Sefick
>> >
>> > --
>> > Let's not spend our time and resources thinking about things that are so
>> > little or so large that all they really do for us is puff us up and
>> make us
>> > feel like gods.  We are mammals, and have not exhausted the annoying
>> little
>> > problems of being mammals.
>> >
>> >                                 -K. Mullis
>> >
>> > "A big computer, a complex algorithm and a long time does not equal
>> > science."
>> >
>> >                               -Robert Gentleman
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Fri Apr 14 17:08:47 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 14 Apr 2017 11:08:47 -0400
Subject: [R] Can this be done in ggplot?
Message-ID: <CAAyVsXK6dej5TXPwFM91fGJLc+Vi1UeCUov7WfVM_Hw8hkPJGQ@mail.gmail.com>

Hi,

I need to bars to display in order based on the values of "v" within each
group "g". Is this possible?

library(ggplot2)
set.seed(1)
df <- expand.grid(g = 1:4, f = factor(c("a", "b", "c")))
df <- df[-1, ] # some factors are not present in certain groups
df$v <- runif(nrow(df))

ggplot(df, aes(x = g, y = v, fill = f)) +
  geom_bar(position="dodge", stat = "identity")

Thanks,
Axel.

	[[alternative HTML version deleted]]


From suttoncarl at ymail.com  Fri Apr 14 23:55:48 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 14 Apr 2017 21:55:48 +0000 (UTC)
Subject: [R] seq argument along.with
References: <1306046561.624340.1492206948730.ref@mail.yahoo.com>
Message-ID: <1306046561.624340.1492206948730@mail.yahoo.com>



Hi


just messing around today and am now perplexed by the seq argument "along.with".    


Please, I am just just seeking some knowledge here.  Obviously I missed a point 

and would like to know what it is.

seq(1,10,length.out = 2)  makes sense
seq(1,10,by = 2)  makes sense
seq(1,10, along.with = 2)  What is the purpose of this argument????

per "help" page
 along.with
take the length from the length of this argument (assuming "length" here 
refers to length of output).  Would that not mean I should get two 

numbers?  


Regardless of the value of the along.with argument, it just returns 1.  Which 

then leads me to be believe that the output will be the number (length) of arguments,i.e., length of the along.with argument, which indeed it does.

seq(1,10,along.with = c(1,3,5,7))  yields 1 4 7 10

seq(1,10,along.with = c(111,13,5555,7) yields 1 4 7 10

seq(1,10,along.with = c("a","b","c","d")) yields 1 4 7 10


Obviously the authors of this function saw a need for this argument, but I am 
just not bright enough to figure out what that purpose was.  It appears 
to me that length.out does the same thing in a much more straightforward 
manner, but then I am probably missing some point, subtle or otherwise.

Carl Sutton


From jdnewmil at dcn.davis.ca.us  Sat Apr 15 00:54:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 14 Apr 2017 15:54:49 -0700
Subject: [R] seq argument along.with
In-Reply-To: <1306046561.624340.1492206948730@mail.yahoo.com>
References: <1306046561.624340.1492206948730.ref@mail.yahoo.com>
 <1306046561.624340.1492206948730@mail.yahoo.com>
Message-ID: <B4C6FCCB-CE0D-4A96-99E4-734FFF6D04A6@dcn.davis.ca.us>

Have you ever used the seq_along() function?

If you want to delegate the decision of how many elements you want to process to some earlier point in your (or someone else's) code, then the most logical way to create a result vector that is the same size as some input vector, even if that vector is of zero length, is to show that vector to the seq function as an example of how long to make the result. 
-- 
Sent from my phone. Please excuse my brevity.

On April 14, 2017 2:55:48 PM PDT, Carl Sutton via R-help <r-help at r-project.org> wrote:
>
>
>Hi
>
>
>just messing around today and am now perplexed by the seq argument
>"along.with".    
>
>
>Please, I am just just seeking some knowledge here.  Obviously I missed
>a point 
>
>and would like to know what it is.
>
>seq(1,10,length.out = 2)  makes sense
>seq(1,10,by = 2)  makes sense
>seq(1,10, along.with = 2)  What is the purpose of this argument????
>
>per "help" page
> along.with
>take the length from the length of this argument (assuming "length"
>here 
>refers to length of output).  Would that not mean I should get two 
>
>numbers?  
>
>
>Regardless of the value of the along.with argument, it just returns 1. 
>Which 
>
>then leads me to be believe that the output will be the number (length)
>of arguments,i.e., length of the along.with argument, which indeed it
>does.
>
>seq(1,10,along.with = c(1,3,5,7))  yields 1 4 7 10
>
>seq(1,10,along.with = c(111,13,5555,7) yields 1 4 7 10
>
>seq(1,10,along.with = c("a","b","c","d")) yields 1 4 7 10
>
>
>Obviously the authors of this function saw a need for this argument,
>but I am 
>just not bright enough to figure out what that purpose was.  It appears
>
>to me that length.out does the same thing in a much more
>straightforward 
>manner, but then I am probably missing some point, subtle or otherwise.
>
>Carl Sutton
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Apr 15 06:02:08 2017
From: sewashm at gmail.com (Ashta)
Date: Fri, 14 Apr 2017 23:02:08 -0500
Subject: [R] Non date value
Message-ID: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>

Hi all,
I am reading  a field data that contains several variables. The sample
of the data with the first two variables is shown below.  I wanted to
know the minimum  and maximum recording date   However, I have some
problem.


Name      Rdate     V1 to  V20
Alex1    01/03/2015
Alex2    01/03/2014
Alex3    31/12/2012
Alex4    15/01/2011
Alex150  22/01/2010
Alex151  15/02/2011



DF1=DF1[!is.na(DF1$Rdate),]
range(DF1$Rdate, na.rm=TRUE)

Warning message:
In is.na(DF1$Rdate) :
  is.na() applied to non-(list or vector) of type 'NULL'
Error in DF1$Rdate : $ operator is invalid for atomic vectors
Execution halted

I am expecting the Rdate field should contain  recording dates. I  am
suspecting there might be a non date  value in that columns. How do I
remove that row if it is not a date format?


Thank you.


From suttoncarl at ymail.com  Sat Apr 15 01:58:48 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 14 Apr 2017 23:58:48 +0000 (UTC)
Subject: [R] seq argument along.with
In-Reply-To: <B4C6FCCB-CE0D-4A96-99E4-734FFF6D04A6@dcn.davis.ca.us>
References: <1306046561.624340.1492206948730.ref@mail.yahoo.com>
 <1306046561.624340.1492206948730@mail.yahoo.com>
 <B4C6FCCB-CE0D-4A96-99E4-734FFF6D04A6@dcn.davis.ca.us>
Message-ID: <1383720775.685826.1492214328903@mail.yahoo.com>

Hi Jeff
I have seen the seq_along function but never knew the what or why of it.? Your response is much appreciated and just shows how brilliant the creators of R were/are.
Thank you for enlightening me.?Carl Sutton 

    On Friday, April 14, 2017 3:54 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 Have you ever used the seq_along() function?

If you want to delegate the decision of how many elements you want to process to some earlier point in your (or someone else's) code, then the most logical way to create a result vector that is the same size as some input vector, even if that vector is of zero length, is to show that vector to the seq function as an example of how long to make the result. 
-- 
Sent from my phone. Please excuse my brevity.

On April 14, 2017 2:55:48 PM PDT, Carl Sutton via R-help <r-help at r-project.org> wrote:
>
>
>Hi
>
>
>just messing around today and am now perplexed by the seq argument
>"along.with".? ? 
>
>
>Please, I am just just seeking some knowledge here.? Obviously I missed
>a point 
>
>and would like to know what it is.
>
>seq(1,10,length.out = 2)? makes sense
>seq(1,10,by = 2)? makes sense
>seq(1,10, along.with = 2)? What is the purpose of this argument????
>
>per "help" page
> along.with
>take the length from the length of this argument (assuming "length"
>here 
>refers to length of output).? Would that not mean I should get two 
>
>numbers?? 
>
>
>Regardless of the value of the along.with argument, it just returns 1. 
>Which 
>
>then leads me to be believe that the output will be the number (length)
>of arguments,i.e., length of the along.with argument, which indeed it
>does.
>
>seq(1,10,along.with = c(1,3,5,7))? yields 1 4 7 10
>
>seq(1,10,along.with = c(111,13,5555,7) yields 1 4 7 10
>
>seq(1,10,along.with = c("a","b","c","d")) yields 1 4 7 10
>
>
>Obviously the authors of this function saw a need for this argument,
>but I am 
>just not bright enough to figure out what that purpose was.? It appears
>
>to me that length.out does the same thing in a much more
>straightforward 
>manner, but then I am probably missing some point, subtle or otherwise.
>
>Carl Sutton
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From krcabrer at une.net.co  Sat Apr 15 04:40:00 2017
From: krcabrer at une.net.co (Kenneth Roy Cabrera Torres)
Date: Fri, 14 Apr 2017 21:40:00 -0500
Subject: [R] Can this be done in ggplot?
In-Reply-To: <CAAyVsXK6dej5TXPwFM91fGJLc+Vi1UeCUov7WfVM_Hw8hkPJGQ@mail.gmail.com>
References: <CAAyVsXK6dej5TXPwFM91fGJLc+Vi1UeCUov7WfVM_Hw8hkPJGQ@mail.gmail.com>
Message-ID: <d0a2e4c1-ce06-2921-eb11-fd13c016f5ae@une.net.co>

A very dirty solution.

I hope someone can give a better solution:

library(ggplot2)
set.seed(1)
df <- expand.grid(g = factor(1:4), f = factor(c("a", "b", "c")))
df <- df[-1, ] # some factors are not present in certain groups
df$v <- runif(nrow(df))

library(dplyr)

df <- df %>% arrange(g, desc(v))
df$nv <- with(df, factor(paste(g,f)))
df$nv <- factor(df$nv, levels = df$nv)

ggplot(df, aes(x = nv , y = v, fill = f)) +
   geom_bar(position="dodge", stat = "identity")


El 14/04/17 a las 10:08, Axel Urbiz escribi?:
> Hi,
>
> I need to bars to display in order based on the values of "v" within each
> group "g". Is this possible?
>
> library(ggplot2)
> set.seed(1)
> df <- expand.grid(g = 1:4, f = factor(c("a", "b", "c")))
> df <- df[-1, ] # some factors are not present in certain groups
> df$v <- runif(nrow(df))
>
> ggplot(df, aes(x = g, y = v, fill = f)) +
>    geom_bar(position="dodge", stat = "identity")
>
> Thanks,
> Axel.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Apr 15 06:24:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 14 Apr 2017 21:24:12 -0700
Subject: [R] Non date value
In-Reply-To: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>
References: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>
Message-ID: <CAGxFJbRHGMx1Te1Z6QvKKoCZ-VRPe53V=kn-PmXmMd7J4owu-Q@mail.gmail.com>

Show us str(DF1) . It is not a data frame.

-- Bert




On Fri, Apr 14, 2017 at 9:02 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
> I am reading  a field data that contains several variables. The sample
> of the data with the first two variables is shown below.  I wanted to
> know the minimum  and maximum recording date   However, I have some
> problem.
>
>
> Name      Rdate     V1 to  V20
> Alex1    01/03/2015
> Alex2    01/03/2014
> Alex3    31/12/2012
> Alex4    15/01/2011
> Alex150  22/01/2010
> Alex151  15/02/2011
>
>
>
> DF1=DF1[!is.na(DF1$Rdate),]
> range(DF1$Rdate, na.rm=TRUE)
>
> Warning message:
> In is.na(DF1$Rdate) :
>   is.na() applied to non-(list or vector) of type 'NULL'
> Error in DF1$Rdate : $ operator is invalid for atomic vectors
> Execution halted
>
> I am expecting the Rdate field should contain  recording dates. I  am
> suspecting there might be a non date  value in that columns. How do I
> remove that row if it is not a date format?
>
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Apr 15 06:39:30 2017
From: sewashm at gmail.com (Ashta)
Date: Fri, 14 Apr 2017 23:39:30 -0500
Subject: [R] Non date value
In-Reply-To: <CAGxFJbRHGMx1Te1Z6QvKKoCZ-VRPe53V=kn-PmXmMd7J4owu-Q@mail.gmail.com>
References: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>
 <CAGxFJbRHGMx1Te1Z6QvKKoCZ-VRPe53V=kn-PmXmMd7J4owu-Q@mail.gmail.com>
Message-ID: <CADDFq33C8drtsRJ3yQ+spmMCXj3Lh-TW8br0CpTqO9ZrL0JAKw@mail.gmail.com>

DF1 is a data frame.   I am suspecting there might be non date value
in that column. My question is how to  remove  a non date values  from
 that field.
example if Alex152 has  12253,. This value is not a date format.


On Fri, Apr 14, 2017 at 11:24 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Show us str(DF1) . It is not a data frame.
>
> -- Bert
>
>
>
>
> On Fri, Apr 14, 2017 at 9:02 PM, Ashta <sewashm at gmail.com> wrote:
>> Hi all,
>> I am reading  a field data that contains several variables. The sample
>> of the data with the first two variables is shown below.  I wanted to
>> know the minimum  and maximum recording date   However, I have some
>> problem.
>>
>>
>> Name      Rdate     V1 to  V20
>> Alex1    01/03/2015
>> Alex2    01/03/2014
>> Alex3    31/12/2012
>> Alex4    15/01/2011
>> Alex150  22/01/2010
>> Alex151  15/02/2011
>>
>>
>>
>> DF1=DF1[!is.na(DF1$Rdate),]
>> range(DF1$Rdate, na.rm=TRUE)
>>
>> Warning message:
>> In is.na(DF1$Rdate) :
>>   is.na() applied to non-(list or vector) of type 'NULL'
>> Error in DF1$Rdate : $ operator is invalid for atomic vectors
>> Execution halted
>>
>> I am expecting the Rdate field should contain  recording dates. I  am
>> suspecting there might be a non date  value in that columns. How do I
>> remove that row if it is not a date format?
>>
>>
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Apr 15 07:04:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 14 Apr 2017 22:04:16 -0700
Subject: [R] Non date value
In-Reply-To: <CADDFq33C8drtsRJ3yQ+spmMCXj3Lh-TW8br0CpTqO9ZrL0JAKw@mail.gmail.com>
References: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>
 <CAGxFJbRHGMx1Te1Z6QvKKoCZ-VRPe53V=kn-PmXmMd7J4owu-Q@mail.gmail.com>
 <CADDFq33C8drtsRJ3yQ+spmMCXj3Lh-TW8br0CpTqO9ZrL0JAKw@mail.gmail.com>
Message-ID: <0504ED0F-740F-40F8-9B1B-6B3DD8791E66@dcn.davis.ca.us>

You don't follow instructions very well. Read the Posting Guide more carefully. 
-- 
Sent from my phone. Please excuse my brevity.

On April 14, 2017 9:39:30 PM PDT, Ashta <sewashm at gmail.com> wrote:
>DF1 is a data frame.   I am suspecting there might be non date value
>in that column. My question is how to  remove  a non date values  from
> that field.
>example if Alex152 has  12253,. This value is not a date format.
>
>
>On Fri, Apr 14, 2017 at 11:24 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> Show us str(DF1) . It is not a data frame.
>>
>> -- Bert
>>
>>
>>
>>
>> On Fri, Apr 14, 2017 at 9:02 PM, Ashta <sewashm at gmail.com> wrote:
>>> Hi all,
>>> I am reading  a field data that contains several variables. The
>sample
>>> of the data with the first two variables is shown below.  I wanted
>to
>>> know the minimum  and maximum recording date   However, I have some
>>> problem.
>>>
>>>
>>> Name      Rdate     V1 to  V20
>>> Alex1    01/03/2015
>>> Alex2    01/03/2014
>>> Alex3    31/12/2012
>>> Alex4    15/01/2011
>>> Alex150  22/01/2010
>>> Alex151  15/02/2011
>>>
>>>
>>>
>>> DF1=DF1[!is.na(DF1$Rdate),]
>>> range(DF1$Rdate, na.rm=TRUE)
>>>
>>> Warning message:
>>> In is.na(DF1$Rdate) :
>>>   is.na() applied to non-(list or vector) of type 'NULL'
>>> Error in DF1$Rdate : $ operator is invalid for atomic vectors
>>> Execution halted
>>>
>>> I am expecting the Rdate field should contain  recording dates. I 
>am
>>> suspecting there might be a non date  value in that columns. How do
>I
>>> remove that row if it is not a date format?
>>>
>>>
>>> Thank you.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Apr 15 12:53:03 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 15 Apr 2017 11:53:03 +0100
Subject: [R] seq argument along.with
In-Reply-To: <1383720775.685826.1492214328903@mail.yahoo.com>
References: <1306046561.624340.1492206948730.ref@mail.yahoo.com>
 <1306046561.624340.1492206948730@mail.yahoo.com>
 <B4C6FCCB-CE0D-4A96-99E4-734FFF6D04A6@dcn.davis.ca.us>
 <1383720775.685826.1492214328903@mail.yahoo.com>
Message-ID: <58F1FB8F.2030406@sapo.pt>

Hello,

A good example of a use case of seq_along is to avoid constructs such as 
1:length(x) that don't make sense and are a source for bugs whenever x 
is of length zero. See for instance loops where careless coders do

for(i in 1:length(x)){
	x[i] <- some computation
}

If x is of length zero the loop above will execute 2 times but the 
second time through it will throw an error because it will refer to 
x[0], which is illegal.
To avoid this, use

for(i in seq_along(x)){
	[...]
}

With a zero-length x, the loop will execute zero times, the intended 
behaviour.
If it's the first time you've came across this function, I can guarantee 
you that it is really, really usefull.

Hope this helps,

Rui Barradas

Em 15-04-2017 00:58, Carl Sutton via R-help escreveu:
> Hi Jeff
> I have seen the seq_along function but never knew the what or why of it.  Your response is much appreciated and just shows how brilliant the creators of R were/are.
> Thank you for enlightening me. Carl Sutton
>
>      On Friday, April 14, 2017 3:54 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>
>   Have you ever used the seq_along() function?
>
> If you want to delegate the decision of how many elements you want to process to some earlier point in your (or someone else's) code, then the most logical way to create a result vector that is the same size as some input vector, even if that vector is of zero length, is to show that vector to the seq function as an example of how long to make the result.
>


From axel.urbiz at gmail.com  Sat Apr 15 13:21:51 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 15 Apr 2017 07:21:51 -0400
Subject: [R] Can this be done in ggplot?
In-Reply-To: <d0a2e4c1-ce06-2921-eb11-fd13c016f5ae@une.net.co>
References: <CAAyVsXK6dej5TXPwFM91fGJLc+Vi1UeCUov7WfVM_Hw8hkPJGQ@mail.gmail.com>
 <d0a2e4c1-ce06-2921-eb11-fd13c016f5ae@une.net.co>
Message-ID: <19D7257E-E25F-4EDC-80F0-22B0F2F8FA1B@gmail.com>

Thanks Kenneth. That is the right idea for what I?m after. However, creating a combined factor based on ?g? and ?f? is creating unwanted spaces between the bars in the plot (I?d like to keep them adjacent within levels of ?g? as shown in my first plot). 

I had the idea that ordering bars in ggplot with respect to a variable within factor levels would be easier, but looks it is not.

Thanks again,
Axe. 



> On Apr 14, 2017, at 10:40 PM, Kenneth Roy Cabrera Torres <krcabrer at une.net.co> wrote:
> 
> A very dirty solution.
> 
> I hope someone can give a better solution:
> 
> library(ggplot2)
> set.seed(1)
> df <- expand.grid(g = factor(1:4), f = factor(c("a", "b", "c")))
> df <- df[-1, ] # some factors are not present in certain groups
> df$v <- runif(nrow(df))
> 
> library(dplyr)
> 
> df <- df %>% arrange(g, desc(v))
> df$nv <- with(df, factor(paste(g,f)))
> df$nv <- factor(df$nv, levels = df$nv)
> 
> ggplot(df, aes(x = nv , y = v, fill = f)) +
>   geom_bar(position="dodge", stat = "identity")
> 
> 
> El 14/04/17 a las 10:08, Axel Urbiz escribi?:
>> Hi,
>> 
>> I need to bars to display in order based on the values of "v" within each
>> group "g". Is this possible?
>> 
>> library(ggplot2)
>> set.seed(1)
>> df <- expand.grid(g = 1:4, f = factor(c("a", "b", "c")))
>> df <- df[-1, ] # some factors are not present in certain groups
>> df$v <- runif(nrow(df))
>> 
>> ggplot(df, aes(x = g, y = v, fill = f)) +
>>   geom_bar(position="dodge", stat = "identity")
>> 
>> Thanks,
>> Axel.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Apr 15 16:14:33 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 15 Apr 2017 09:14:33 -0500
Subject: [R] Non date value
In-Reply-To: <0504ED0F-740F-40F8-9B1B-6B3DD8791E66@dcn.davis.ca.us>
References: <CADDFq31_=iDsnP8GxF9MjH+jT_QDa0STuPjczU807-s7EKN=og@mail.gmail.com>
 <CAGxFJbRHGMx1Te1Z6QvKKoCZ-VRPe53V=kn-PmXmMd7J4owu-Q@mail.gmail.com>
 <CADDFq33C8drtsRJ3yQ+spmMCXj3Lh-TW8br0CpTqO9ZrL0JAKw@mail.gmail.com>
 <0504ED0F-740F-40F8-9B1B-6B3DD8791E66@dcn.davis.ca.us>
Message-ID: <CADDFq30BEs4s8JpS6+7tTeFbbQWDszcbt8j2NZ8EDCRFVnCMxQ@mail.gmail.com>

Jeff,

I am sorry for that.


On Sat, Apr 15, 2017 at 12:04 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You don't follow instructions very well. Read the Posting Guide more carefully.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 14, 2017 9:39:30 PM PDT, Ashta <sewashm at gmail.com> wrote:
>>DF1 is a data frame.   I am suspecting there might be non date value
>>in that column. My question is how to  remove  a non date values  from
>> that field.
>>example if Alex152 has  12253,. This value is not a date format.
>>
>>
>>On Fri, Apr 14, 2017 at 11:24 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>wrote:
>>> Show us str(DF1) . It is not a data frame.
>>>
>>> -- Bert
>>>
>>>
>>>
>>>
>>> On Fri, Apr 14, 2017 at 9:02 PM, Ashta <sewashm at gmail.com> wrote:
>>>> Hi all,
>>>> I am reading  a field data that contains several variables. The
>>sample
>>>> of the data with the first two variables is shown below.  I wanted
>>to
>>>> know the minimum  and maximum recording date   However, I have some
>>>> problem.
>>>>
>>>>
>>>> Name      Rdate     V1 to  V20
>>>> Alex1    01/03/2015
>>>> Alex2    01/03/2014
>>>> Alex3    31/12/2012
>>>> Alex4    15/01/2011
>>>> Alex150  22/01/2010
>>>> Alex151  15/02/2011
>>>>
>>>>
>>>>
>>>> DF1=DF1[!is.na(DF1$Rdate),]
>>>> range(DF1$Rdate, na.rm=TRUE)
>>>>
>>>> Warning message:
>>>> In is.na(DF1$Rdate) :
>>>>   is.na() applied to non-(list or vector) of type 'NULL'
>>>> Error in DF1$Rdate : $ operator is invalid for atomic vectors
>>>> Execution halted
>>>>
>>>> I am expecting the Rdate field should contain  recording dates. I
>>am
>>>> suspecting there might be a non date  value in that columns. How do
>>I
>>>> remove that row if it is not a date format?
>>>>
>>>>
>>>> Thank you.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Sat Apr 15 17:25:02 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 15 Apr 2017 15:25:02 +0000
Subject: [R] Can this be done in ggplot?
In-Reply-To: <d0a2e4c1-ce06-2921-eb11-fd13c016f5ae@une.net.co>
References: <CAAyVsXK6dej5TXPwFM91fGJLc+Vi1UeCUov7WfVM_Hw8hkPJGQ@mail.gmail.com>
 <d0a2e4c1-ce06-2921-eb11-fd13c016f5ae@une.net.co>
Message-ID: <CAAyVsXJhxGbzri155s1ZgQwwCgYHLZkhph=gMM-eBS-tu2ZhWw@mail.gmail.com>

Thanks Kenneth. That is the right idea for what I?m after. However,
creating a combined factor based on ?g? and ?f? is creating unwanted spaces
between the bars in the plot (I?d like to keep them adjacent within levels
of ?g? as shown in my first plot).

I had the idea that ordering bars in ggplot with respect to a variable
within factor levels would be easier, but looks it is not.

Thanks again,
Axe.



On Apr 14, 2017, at 10:40 PM, Kenneth Roy Cabrera Torres <
krcabrer at une.net.co> wrote:

A very dirty solution.

I hope someone can give a better solution:

library(ggplot2)
set.seed(1)
df <- expand.grid(g = factor(1:4), f = factor(c("a", "b", "c")))
df <- df[-1, ] # some factors are not present in certain groups
df$v <- runif(nrow(df))

library(dplyr)

df <- df %>% arrange(g, desc(v))
df$nv <- with(df, factor(paste(g,f)))
df$nv <- factor(df$nv, levels = df$nv)

ggplot(df, aes(x = nv , y = v, fill = f)) +
  geom_bar(position="dodge", stat = "identity")


El 14/04/17 a las 10:08, Axel Urbiz escribi?:


Hi,

I need to bars to display in order based on the values of "v" within each
group "g". Is this possible?

library(ggplot2)
set.seed(1)
df <- expand.grid(g = 1:4, f = factor(c("a", "b", "c")))
df <- df[-1, ] # some factors are not present in certain groups
df$v <- runif(nrow(df))

ggplot(df, aes(x = g, y = v, fill = f)) +
  geom_bar(position="dodge", stat = "identity")

Thanks,
Axel.

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Sat Apr 15 18:06:16 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 15 Apr 2017 12:06:16 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
Message-ID: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>

Hi R-helpers:
Can you offer assistance in my getting .Rprofile and .Rprofile.site to 
run in RStudio?
When I start RStudio nothing happens.
I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].

Below, the info I believe you need to know.
Thanks, in advance, for any help.
Bruce

The .Rprofile and .Rprofile.site are R-type files, which contain the two 
lines below.
Also, I tried the profile files as text files.
options(prompt="R> ")
set.seed(12345)

>Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"


--


From wdunlap at tibco.com  Sat Apr 15 20:44:23 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 15 Apr 2017 11:44:23 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
Message-ID: <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>

I think the site-specific R profile should be, using R syntax
   file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
The personal R profile will be
   file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
but if a local R profile,
   file.path(getwd(), ".Rprofile") # there is a dot before capital R
exists it will be used and the one in HOME will not be.  (getwd() should
be the startup directory.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
> Hi R-helpers:
> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
> in RStudio?
> When I start RStudio nothing happens.
> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>
> Below, the info I believe you need to know.
> Thanks, in advance, for any help.
> Bruce
>
> The .Rprofile and .Rprofile.site are R-type files, which contain the two
> lines below.
> Also, I tried the profile files as text files.
> options(prompt="R> ")
> set.seed(12345)
>
>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>
>
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr 15 21:14:32 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 15 Apr 2017 15:14:32 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
Message-ID: <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>

Bill:
Thanks for reply.
Sorry, I do not understand it.
For example, where do I put "file.path(getwd(), ".Rprofile")" ?

Bruce

  

William Dunlap wrote:
> I think the site-specific R profile should be, using R syntax
>     file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
> The personal R profile will be
>     file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
> but if a local R profile,
>     file.path(getwd(), ".Rprofile") # there is a dot before capital R
> exists it will be used and the one in HOME will not be.  (getwd() should
> be the startup directory.)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>> Hi R-helpers:
>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>> in RStudio?
>> When I start RStudio nothing happens.
>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>
>> Below, the info I believe you need to know.
>> Thanks, in advance, for any help.
>> Bruce
>>
>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>> lines below.
>> Also, I tried the profile files as text files.
>> options(prompt="R> ")
>> set.seed(12345)
>>
>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>
>>
>> --
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Sat Apr 15 21:34:10 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Apr 2017 12:34:10 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
Message-ID: <012D5B94-9D88-4847-9ED8-7AB1ACA8334B@comcast.net>


> On Apr 15, 2017, at 12:14 PM, BR_email <br at dmstat1.com> wrote:
> 
> Bill:
> Thanks for reply.
> Sorry, I do not understand it.
> For example, where do I put "file.path(getwd(), ".Rprofile")" ?

This is not the correct venue for questions about RStudio setup. Instead this questions should go to:

https://support.rstudio.com/hc/en-us

-- 
David.

> 
> Bruce
> 
> 
> William Dunlap wrote:
>> I think the site-specific R profile should be, using R syntax
>>    file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
>> The personal R profile will be
>>    file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
>> but if a local R profile,
>>    file.path(getwd(), ".Rprofile") # there is a dot before capital R
>> exists it will be used and the one in HOME will not be.  (getwd() should
>> be the startup directory.)
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>> Hi R-helpers:
>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>>> in RStudio?
>>> When I start RStudio nothing happens.
>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>> 
>>> Below, the info I believe you need to know.
>>> Thanks, in advance, for any help.
>>> Bruce
>>> 
>>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>>> lines below.
>>> Also, I tried the profile files as text files.
>>> options(prompt="R> ")
>>> set.seed(12345)
>>> 
>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>> 
>>> 
>>> --
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From boris.steipe at utoronto.ca  Sat Apr 15 21:46:33 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 15 Apr 2017 15:46:33 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
Message-ID: <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>

As with R, do with RStudio: Read The Beautiful Manual, and peruse The Google. For example, searching Google with the two (admittedly hard to guess) cryptograms:
  "RStudio Rprofile"

will present more than a dozen most enlightening links to fulfil your desire.

Perhaps the following link works better for you though:
  https://www.bing.com/search?q=rstudio+rprofile

B.


> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com> wrote:
> 
> Bill:
> Thanks for reply.
> Sorry, I do not understand it.
> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
> 
> Bruce
> 
> 
> William Dunlap wrote:
>> I think the site-specific R profile should be, using R syntax
>>    file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
>> The personal R profile will be
>>    file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
>> but if a local R profile,
>>    file.path(getwd(), ".Rprofile") # there is a dot before capital R
>> exists it will be used and the one in HOME will not be.  (getwd() should
>> be the startup directory.)
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>> Hi R-helpers:
>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>>> in RStudio?
>>> When I start RStudio nothing happens.
>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>> 
>>> Below, the info I believe you need to know.
>>> Thanks, in advance, for any help.
>>> Bruce
>>> 
>>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>>> lines below.
>>> Also, I tried the profile files as text files.
>>> options(prompt="R> ")
>>> set.seed(12345)
>>> 
>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>> 
>>> 
>>> --
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr 15 21:52:04 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 15 Apr 2017 15:52:04 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <012D5B94-9D88-4847-9ED8-7AB1ACA8334B@comcast.net>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <012D5B94-9D88-4847-9ED8-7AB1ACA8334B@comcast.net>
Message-ID: <6efd84d2-2b97-018a-8896-81932382a561@dmstat1.com>

David:
Thank you.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

David Winsemius wrote:
>> On Apr 15, 2017, at 12:14 PM, BR_email <br at dmstat1.com> wrote:
>>
>> Bill:
>> Thanks for reply.
>> Sorry, I do not understand it.
>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
> This is not the correct venue for questions about RStudio setup. Instead this questions should go to:
>
> https://support.rstudio.com/hc/en-us
>


From br at dmstat1.com  Sat Apr 15 21:57:37 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 15 Apr 2017 15:57:37 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
Message-ID: <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>

Boris:
As before, you assume that I, Bruce Ratner, just asks questions without 
first trying it myself.
FYI: I purchased and read four RStudio books, as well as all the links I 
found in the web.
I will not take your maligning me.
Please try to assist me, but do not bully me.
Bruce Ratner, Ph.D.

  

Boris Steipe wrote:
> As with R, do with RStudio: Read The Beautiful Manual, and peruse The Google. For example, searching Google with the two (admittedly hard to guess) cryptograms:
>    "RStudio Rprofile"
>
> will present more than a dozen most enlightening links to fulfil your desire.
>
> Perhaps the following link works better for you though:
>    https://www.bing.com/search?q=rstudio+rprofile
>
> B.
>
>
>> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com> wrote:
>>
>> Bill:
>> Thanks for reply.
>> Sorry, I do not understand it.
>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
>>
>> Bruce
>>
>>
>> William Dunlap wrote:
>>> I think the site-specific R profile should be, using R syntax
>>>     file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
>>> The personal R profile will be
>>>     file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
>>> but if a local R profile,
>>>     file.path(getwd(), ".Rprofile") # there is a dot before capital R
>>> exists it will be used and the one in HOME will not be.  (getwd() should
>>> be the startup directory.)
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>>> Hi R-helpers:
>>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>>>> in RStudio?
>>>> When I start RStudio nothing happens.
>>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>>>
>>>> Below, the info I believe you need to know.
>>>> Thanks, in advance, for any help.
>>>> Bruce
>>>>
>>>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>>>> lines below.
>>>> Also, I tried the profile files as text files.
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>>
>>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>>>
>>>> --
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From jdnewmil at dcn.davis.ca.us  Sat Apr 15 22:09:07 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 15 Apr 2017 13:09:07 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
Message-ID: <161F62BF-D71E-455D-819D-2270F50F36CB@dcn.davis.ca.us>

You type each expression interactively at the R console and look at the path it prints. Then you know where to look, or if no file exists there then you know where to put the file you want to be there. 
-- 
Sent from my phone. Please excuse my brevity.

On April 15, 2017 12:14:32 PM PDT, BR_email <br at dmstat1.com> wrote:
>Bill:
>Thanks for reply.
>Sorry, I do not understand it.
>For example, where do I put "file.path(getwd(), ".Rprofile")" ?
>
>Bruce
>
>  
>
>William Dunlap wrote:
>> I think the site-specific R profile should be, using R syntax
>>     file.path(R.home("etc"), "Rprofile.site") # no dot before the
>capital R
>> The personal R profile will be
>>     file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot
>before capital R
>> but if a local R profile,
>>     file.path(getwd(), ".Rprofile") # there is a dot before capital R
>> exists it will be used and the one in HOME will not be.  (getwd()
>should
>> be the startup directory.)
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>> Hi R-helpers:
>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site
>to run
>>> in RStudio?
>>> When I start RStudio nothing happens.
>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>>
>>> Below, the info I believe you need to know.
>>> Thanks, in advance, for any help.
>>> Bruce
>>>
>>> The .Rprofile and .Rprofile.site are R-type files, which contain the
>two
>>> lines below.
>>> Also, I tried the profile files as text files.
>>> options(prompt="R> ")
>>> set.seed(12345)
>>>
>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>>
>>>
>>> --
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Apr 15 22:10:28 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Apr 2017 13:10:28 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
Message-ID: <B806A5AB-9F53-4F30-A34F-7DF61E61D882@comcast.net>


> On Apr 15, 2017, at 12:46 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> As with R, do with RStudio: Read The Beautiful Manual, and peruse The Google. For example, searching Google with the two (admittedly hard to guess) cryptograms:
>  "RStudio Rprofile"
> 
> will present more than a dozen most enlightening links to fulfil your desire.
> 
> Perhaps the following link works better for you though:
>  https://www.bing.com/search?q=rstudio+rprofile

Another promising search strategy would be SO with "[rstudio]" in the tags:

http://stackoverflow.com/search?q=%5Brstudio%5D+rprofile+windows

-- 
david.
> 
> B.
> 
> 
>> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com> wrote:
>> 
>> Bill:
>> Thanks for reply.
>> Sorry, I do not understand it.
>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
>> 
>> Bruce
>> 
>> 
>> William Dunlap wrote:
>>> I think the site-specific R profile should be, using R syntax
>>>   file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
>>> The personal R profile will be
>>>   file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
>>> but if a local R profile,
>>>   file.path(getwd(), ".Rprofile") # there is a dot before capital R
>>> exists it will be used and the one in HOME will not be.  (getwd() should
>>> be the startup directory.)
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>>> Hi R-helpers:
>>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>>>> in RStudio?
>>>> When I start RStudio nothing happens.
>>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>>> 
>>>> Below, the info I believe you need to know.
>>>> Thanks, in advance, for any help.
>>>> Bruce
>>>> 
>>>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>>>> lines below.
>>>> Also, I tried the profile files as text files.
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>> 
>>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>>> 
>>>> 
>>>> --
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mcx890109 at gmail.com  Sat Apr 15 17:56:24 2017
From: mcx890109 at gmail.com (=?UTF-8?B?5a6T6L6w576y?=)
Date: Sat, 15 Apr 2017 08:56:24 -0700 (PDT)
Subject: [R] output of filled.contour
Message-ID: <acde2b0e-45c3-4d6a-8fbc-5f0eacb51d99@googlegroups.com>

Dear all:

     I used the argument of filled.contour for drawing. I just wonder how to shorten 
the spacing between the key and the picture?


    Attached below is the output. Thanks very much for the kind help!


Best Cheers
  Chenxi  

From henrik.bengtsson at gmail.com  Sun Apr 16 00:19:13 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 15 Apr 2017 15:19:13 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <B806A5AB-9F53-4F30-A34F-7DF61E61D882@comcast.net>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <B806A5AB-9F53-4F30-A34F-7DF61E61D882@comcast.net>
Message-ID: <CAFDcVCQAaDJHKmGabQfwAiiQq-ByjvxSdTv4f_Pf4bGonwEGMg@mail.gmail.com>

Hi.

First, there should be no difference in where and how R and RStudio
locate the R startup file.

Second, if there is an .Rprofile in the working directory (i.e.
./.Rprofile), then that file with have higher priority than the file
located in ~/.Rprofile.  You can use the following R calls, also on
Windows, to check if you have either of these two files:

> file <- normalizePath("./.Rprofile")
> file
> file.exist(file)

> file <- normalizePath("~/.Rprofile")
> file
> file.exist(file)

In my case, my working directory is C:/Users/hb/Documents/Projects/, I
have a ~/.Rprofile file, but not a .Rprofile in the working directory.
So, I get:

> file <- normalizePath("./.Rprofile")
> file
[1] "C:\\Users\\hb\\Documents\\Projects\\.Rprofile"
> file.exists(file)
[1] FALSE

> file <- normalizePath("~/.Rprofile")
> file
[1] "C:\\Users\\hb\\Documents\\.Rprofile"
> file.exists(file)
[1] TRUE

This tells me that my startup file that R tries to load / source
during startup is "C:\\Users\\hb\\Documents\\.Rprofile" and that's the
one I should edit.

BTW, the value of normalizePath("~/.Rprofile") and
file.path(Sys.getenv("HOME"), ".Rprofile") should point to the same
file, expect that normalizePath() makes all backward slashed on
Windows; the former is just a neater version to use:

> normalizePath("~/.Rprofile")
[1] "C:\\Users\\hb\\Documents\\.Rprofile"

> file.path(Sys.getenv("HOME"), ".Rprofile")
[1] "C:/Users/hb/Documents/.Rprofile"

> normalizePath(file.path(Sys.getenv("HOME"), ".Rprofile"))
[1] "C:\\Users\\hb\\Documents\\.Rprofile"

(all of the above reference the same file).

So, if file.exists(normalizePath("~/.Rprofile")) gives FALSE, then you
don't have that file.  If you think you've edited that, then it might
be that you hit the peculiar Windows property where it hides the
filename extension from you in the Explorer.  It might be that you
instead have created / edited the file:

normalizePath("~/.Rprofile.txt")

That often happens when one uses Notepad and saves the file as
.Rprofile - Notepad simply add a *.txt filename extension unless you
save it with quotation marks in the Save-As panel.

Now, if you indeed have the file:

normalizePath("~/.Rprofile")

then there is one last annoyance in R that you might have hit.   If you're last
line in that file does not have a newline, the the file will be
silently ignored by R when R start.  There won't be a warning - not
even a message.  That is true for all OSes.  It's a "feature" that
should really be fixed, because I keep seeing it tricking beginners
and advanced R users all the times.  The easiest way to check if this
is your problem, use readLines() to read in the content; readLines()
will give a warning if the last line doesn't have a new line, e.g.

> readLines(normalizePath("~/.Rprofile"))
[1] "options(prompt=\"R> \")" "set.seed(12345)"
Warning message:
In readLines(normalizePath("~/.Rprofile")) :
  incomplete final line found on 'C:\Users\hb\Documents\.Rprofile'

If you don't see the warning message, you should be fine.

Finally, an easy way to setup a ~/.Rprofile startup file is to do it
from within R, e.g.

> cat('options(prompt="R> ")\n', file = "~/.Rprofile")
> cat('set.seed(12345)\n', file = "~/.Rprofile", append = TRUE)

The '\n' at the end of each string represents a newline character, so
make sure you don't forget those.

Hope this help

Henrik



On Sat, Apr 15, 2017 at 1:10 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Apr 15, 2017, at 12:46 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>> As with R, do with RStudio: Read The Beautiful Manual, and peruse The Google. For example, searching Google with the two (admittedly hard to guess) cryptograms:
>>  "RStudio Rprofile"
>>
>> will present more than a dozen most enlightening links to fulfil your desire.
>>
>> Perhaps the following link works better for you though:
>>  https://www.bing.com/search?q=rstudio+rprofile
>
> Another promising search strategy would be SO with "[rstudio]" in the tags:
>
> http://stackoverflow.com/search?q=%5Brstudio%5D+rprofile+windows
>
> --
> david.
>>
>> B.
>>
>>
>>> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com> wrote:
>>>
>>> Bill:
>>> Thanks for reply.
>>> Sorry, I do not understand it.
>>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
>>>
>>> Bruce
>>>
>>>
>>> William Dunlap wrote:
>>>> I think the site-specific R profile should be, using R syntax
>>>>   file.path(R.home("etc"), "Rprofile.site") # no dot before the capital R
>>>> The personal R profile will be
>>>>   file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before capital R
>>>> but if a local R profile,
>>>>   file.path(getwd(), ".Rprofile") # there is a dot before capital R
>>>> exists it will be used and the one in HOME will not be.  (getwd() should
>>>> be the startup directory.)
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
>>>>> Hi R-helpers:
>>>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site to run
>>>>> in RStudio?
>>>>> When I start RStudio nothing happens.
>>>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>>>>>
>>>>> Below, the info I believe you need to know.
>>>>> Thanks, in advance, for any help.
>>>>> Bruce
>>>>>
>>>>> The .Rprofile and .Rprofile.site are R-type files, which contain the two
>>>>> lines below.
>>>>> Also, I tried the profile files as text files.
>>>>> options(prompt="R> ")
>>>>> set.seed(12345)
>>>>>
>>>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>>>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>>>>>
>>>>>
>>>>> --
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Sun Apr 16 01:16:40 2017
From: frainj at gmail.com (John C Frain)
Date: Sun, 16 Apr 2017 00:16:40 +0100
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAFDcVCQAaDJHKmGabQfwAiiQq-ByjvxSdTv4f_Pf4bGonwEGMg@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <B806A5AB-9F53-4F30-A34F-7DF61E61D882@comcast.net>
 <CAFDcVCQAaDJHKmGabQfwAiiQq-ByjvxSdTv4f_Pf4bGonwEGMg@mail.gmail.com>
Message-ID: <CAHrK517bm76J41vRheznmsWYhf719TJtmpLMQ6CErXCPiypAnA@mail.gmail.com>

If you have your Rprofile.site file in the default place you will need to
start whatever editor you are using in administrator mode to save your
changes. At least that is so on my PC with windows 10 with R installed in
the default directory. I use notepad++ in administrator mode. I presume
that you could do the same with rstudio.

If you think that answers are short or to the point remember that someone
is giving of his time to help you. I think that you owe someone an apology.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 15 April 2017 at 23:19, Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> Hi.
>
> First, there should be no difference in where and how R and RStudio
> locate the R startup file.
>
> Second, if there is an .Rprofile in the working directory (i.e.
> ./.Rprofile), then that file with have higher priority than the file
> located in ~/.Rprofile.  You can use the following R calls, also on
> Windows, to check if you have either of these two files:
>
> > file <- normalizePath("./.Rprofile")
> > file
> > file.exist(file)
>
> > file <- normalizePath("~/.Rprofile")
> > file
> > file.exist(file)
>
> In my case, my working directory is C:/Users/hb/Documents/Projects/, I
> have a ~/.Rprofile file, but not a .Rprofile in the working directory.
> So, I get:
>
> > file <- normalizePath("./.Rprofile")
> > file
> [1] "C:\\Users\\hb\\Documents\\Projects\\.Rprofile"
> > file.exists(file)
> [1] FALSE
>
> > file <- normalizePath("~/.Rprofile")
> > file
> [1] "C:\\Users\\hb\\Documents\\.Rprofile"
> > file.exists(file)
> [1] TRUE
>
> This tells me that my startup file that R tries to load / source
> during startup is "C:\\Users\\hb\\Documents\\.Rprofile" and that's the
> one I should edit.
>
> BTW, the value of normalizePath("~/.Rprofile") and
> file.path(Sys.getenv("HOME"), ".Rprofile") should point to the same
> file, expect that normalizePath() makes all backward slashed on
> Windows; the former is just a neater version to use:
>
> > normalizePath("~/.Rprofile")
> [1] "C:\\Users\\hb\\Documents\\.Rprofile"
>
> > file.path(Sys.getenv("HOME"), ".Rprofile")
> [1] "C:/Users/hb/Documents/.Rprofile"
>
> > normalizePath(file.path(Sys.getenv("HOME"), ".Rprofile"))
> [1] "C:\\Users\\hb\\Documents\\.Rprofile"
>
> (all of the above reference the same file).
>
> So, if file.exists(normalizePath("~/.Rprofile")) gives FALSE, then you
> don't have that file.  If you think you've edited that, then it might
> be that you hit the peculiar Windows property where it hides the
> filename extension from you in the Explorer.  It might be that you
> instead have created / edited the file:
>
> normalizePath("~/.Rprofile.txt")
>
> That often happens when one uses Notepad and saves the file as
> .Rprofile - Notepad simply add a *.txt filename extension unless you
> save it with quotation marks in the Save-As panel.
>
> Now, if you indeed have the file:
>
> normalizePath("~/.Rprofile")
>
> then there is one last annoyance in R that you might have hit.   If you're
> last
> line in that file does not have a newline, the the file will be
> silently ignored by R when R start.  There won't be a warning - not
> even a message.  That is true for all OSes.  It's a "feature" that
> should really be fixed, because I keep seeing it tricking beginners
> and advanced R users all the times.  The easiest way to check if this
> is your problem, use readLines() to read in the content; readLines()
> will give a warning if the last line doesn't have a new line, e.g.
>
> > readLines(normalizePath("~/.Rprofile"))
> [1] "options(prompt=\"R> \")" "set.seed(12345)"
> Warning message:
> In readLines(normalizePath("~/.Rprofile")) :
>   incomplete final line found on 'C:\Users\hb\Documents\.Rprofile'
>
> If you don't see the warning message, you should be fine.
>
> Finally, an easy way to setup a ~/.Rprofile startup file is to do it
> from within R, e.g.
>
> > cat('options(prompt="R> ")\n', file = "~/.Rprofile")
> > cat('set.seed(12345)\n', file = "~/.Rprofile", append = TRUE)
>
> The '\n' at the end of each string represents a newline character, so
> make sure you don't forget those.
>
> Hope this help
>
> Henrik
>
>
>
> On Sat, Apr 15, 2017 at 1:10 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >> On Apr 15, 2017, at 12:46 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >>
> >> As with R, do with RStudio: Read The Beautiful Manual, and peruse The
> Google. For example, searching Google with the two (admittedly hard to
> guess) cryptograms:
> >>  "RStudio Rprofile"
> >>
> >> will present more than a dozen most enlightening links to fulfil your
> desire.
> >>
> >> Perhaps the following link works better for you though:
> >>  https://www.bing.com/search?q=rstudio+rprofile
> >
> > Another promising search strategy would be SO with "[rstudio]" in the
> tags:
> >
> > http://stackoverflow.com/search?q=%5Brstudio%5D+rprofile+windows
> >
> > --
> > david.
> >>
> >> B.
> >>
> >>
> >>> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com> wrote:
> >>>
> >>> Bill:
> >>> Thanks for reply.
> >>> Sorry, I do not understand it.
> >>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
> >>>
> >>> Bruce
> >>>
> >>>
> >>> William Dunlap wrote:
> >>>> I think the site-specific R profile should be, using R syntax
> >>>>   file.path(R.home("etc"), "Rprofile.site") # no dot before the
> capital R
> >>>> The personal R profile will be
> >>>>   file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot before
> capital R
> >>>> but if a local R profile,
> >>>>   file.path(getwd(), ".Rprofile") # there is a dot before capital R
> >>>> exists it will be used and the one in HOME will not be.  (getwd()
> should
> >>>> be the startup directory.)
> >>>>
> >>>>
> >>>> Bill Dunlap
> >>>> TIBCO Software
> >>>> wdunlap tibco.com
> >>>>
> >>>>
> >>>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com> wrote:
> >>>>> Hi R-helpers:
> >>>>> Can you offer assistance in my getting .Rprofile and .Rprofile.site
> to run
> >>>>> in RStudio?
> >>>>> When I start RStudio nothing happens.
> >>>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
> >>>>>
> >>>>> Below, the info I believe you need to know.
> >>>>> Thanks, in advance, for any help.
> >>>>> Bruce
> >>>>>
> >>>>> The .Rprofile and .Rprofile.site are R-type files, which contain the
> two
> >>>>> lines below.
> >>>>> Also, I tried the profile files as text files.
> >>>>> options(prompt="R> ")
> >>>>> set.seed(12345)
> >>>>>
> >>>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
> >>>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
> >>>>>
> >>>>>
> >>>>> --
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Apr 16 01:24:06 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 16 Apr 2017 11:24:06 +1200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
Message-ID: <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>

On 16/04/17 07:57, BR_email wrote:
> Boris:
> As before, you assume that I, Bruce Ratner, just asks questions without
> first trying it myself.
> FYI: I purchased and read four RStudio books, as well as all the links I
> found in the web.
> I will not take your maligning me.
> Please try to assist me, but do not bully me.
> Bruce Ratner, Ph.D.

Bruce, you are being preciously hypersensitive.  Boris's comment was 
completely appropriate and betrayed not the slightest trace of 
"bullying".  If you had indeed done your homework in the manner that 
Boris recommended you would had no need to clutter this mailing list 
with your (off-topic) question.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From br at dmstat1.com  Sun Apr 16 01:45:59 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 15 Apr 2017 19:45:59 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAHrK517bm76J41vRheznmsWYhf719TJtmpLMQ6CErXCPiypAnA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <B806A5AB-9F53-4F30-A34F-7DF61E61D882@comcast.net>
 <CAFDcVCQAaDJHKmGabQfwAiiQq-ByjvxSdTv4f_Pf4bGonwEGMg@mail.gmail.com>
 <CAHrK517bm76J41vRheznmsWYhf719TJtmpLMQ6CErXCPiypAnA@mail.gmail.com>
Message-ID: <b0bc9203-b13a-5754-11fb-eb19018cefbc@dmstat1.com>

John:
Thanks for your help.

Regarding an apology to Boris. No. He is a condescending person.
On the three requests for help, which I made since starting with R, he 
tells me to read the manuals, blogs, etc.,
while persons like you offer help. That is not strange?
My three questions Boris replies with nothing, yet others feel my 
request is genuine and offer assistance.

I spend hours and hours reading the manuals, blogs, and purchasing and 
reading multiple books on R and RStudio.
After that, when I am stuck, I go to the r-help.

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

John C Frain wrote:
> If you have your Rprofile.site file in the default place you will need 
> to start whatever editor you are using in administrator mode to save 
> your changes. At least that is so on my PC with windows 10 with R 
> installed in the default directory. I use notepad++ in administrator 
> mode. I presume that you could do the same with rstudio.
>
> If you think that answers are short or to the point remember that 
> someone is giving of his time to help you. I think that you owe 
> someone an apology.
>
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html 
> <http://www.tcd.ie/Economics/staff/frainj/home.html>
> mailto:frainj at tcd.ie <mailto:frainj at tcd.ie>
> mailto:frainj at gmail.com <mailto:frainj at gmail.com>
>
> On 15 April 2017 at 23:19, Henrik Bengtsson 
> <henrik.bengtsson at gmail.com <mailto:henrik.bengtsson at gmail.com>> wrote:
>
>     Hi.
>
>     First, there should be no difference in where and how R and RStudio
>     locate the R startup file.
>
>     Second, if there is an .Rprofile in the working directory (i.e.
>     ./.Rprofile), then that file with have higher priority than the file
>     located in ~/.Rprofile.  You can use the following R calls, also on
>     Windows, to check if you have either of these two files:
>
>     > file <- normalizePath("./.Rprofile")
>     > file
>     > file.exist(file)
>
>     > file <- normalizePath("~/.Rprofile")
>     > file
>     > file.exist(file)
>
>     In my case, my working directory is C:/Users/hb/Documents/Projects/, I
>     have a ~/.Rprofile file, but not a .Rprofile in the working directory.
>     So, I get:
>
>     > file <- normalizePath("./.Rprofile")
>     > file
>     [1] "C:\\Users\\hb\\Documents\\Projects\\.Rprofile"
>     > file.exists(file)
>     [1] FALSE
>
>     > file <- normalizePath("~/.Rprofile")
>     > file
>     [1] "C:\\Users\\hb\\Documents\\.Rprofile"
>     > file.exists(file)
>     [1] TRUE
>
>     This tells me that my startup file that R tries to load / source
>     during startup is "C:\\Users\\hb\\Documents\\.Rprofile" and that's the
>     one I should edit.
>
>     BTW, the value of normalizePath("~/.Rprofile") and
>     file.path(Sys.getenv("HOME"), ".Rprofile") should point to the same
>     file, expect that normalizePath() makes all backward slashed on
>     Windows; the former is just a neater version to use:
>
>     > normalizePath("~/.Rprofile")
>     [1] "C:\\Users\\hb\\Documents\\.Rprofile"
>
>     > file.path(Sys.getenv("HOME"), ".Rprofile")
>     [1] "C:/Users/hb/Documents/.Rprofile"
>
>     > normalizePath(file.path(Sys.getenv("HOME"), ".Rprofile"))
>     [1] "C:\\Users\\hb\\Documents\\.Rprofile"
>
>     (all of the above reference the same file).
>
>     So, if file.exists(normalizePath("~/.Rprofile")) gives FALSE, then you
>     don't have that file.  If you think you've edited that, then it might
>     be that you hit the peculiar Windows property where it hides the
>     filename extension from you in the Explorer.  It might be that you
>     instead have created / edited the file:
>
>     normalizePath("~/.Rprofile.txt")
>
>     That often happens when one uses Notepad and saves the file as
>     .Rprofile - Notepad simply add a *.txt filename extension unless you
>     save it with quotation marks in the Save-As panel.
>
>     Now, if you indeed have the file:
>
>     normalizePath("~/.Rprofile")
>
>     then there is one last annoyance in R that you might have hit. 
>      If you're last
>     line in that file does not have a newline, the the file will be
>     silently ignored by R when R start.  There won't be a warning - not
>     even a message.  That is true for all OSes.  It's a "feature" that
>     should really be fixed, because I keep seeing it tricking beginners
>     and advanced R users all the times.  The easiest way to check if this
>     is your problem, use readLines() to read in the content; readLines()
>     will give a warning if the last line doesn't have a new line, e.g.
>
>     > readLines(normalizePath("~/.Rprofile"))
>     [1] "options(prompt=\"R> \")" "set.seed(12345)"
>     Warning message:
>     In readLines(normalizePath("~/.Rprofile")) :
>       incomplete final line found on 'C:\Users\hb\Documents\.Rprofile'
>
>     If you don't see the warning message, you should be fine.
>
>     Finally, an easy way to setup a ~/.Rprofile startup file is to do it
>     from within R, e.g.
>
>     > cat('options(prompt="R> ")\n', file = "~/.Rprofile")
>     > cat('set.seed(12345)\n', file = "~/.Rprofile", append = TRUE)
>
>     The '\n' at the end of each string represents a newline character, so
>     make sure you don't forget those.
>
>     Hope this help
>
>     Henrik
>
>
>
>     On Sat, Apr 15, 2017 at 1:10 PM, David Winsemius
>     <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>     >
>     >> On Apr 15, 2017, at 12:46 PM, Boris Steipe
>     <boris.steipe at utoronto.ca <mailto:boris.steipe at utoronto.ca>> wrote:
>     >>
>     >> As with R, do with RStudio: Read The Beautiful Manual, and
>     peruse The Google. For example, searching Google with the two
>     (admittedly hard to guess) cryptograms:
>     >>  "RStudio Rprofile"
>     >>
>     >> will present more than a dozen most enlightening links to
>     fulfil your desire.
>     >>
>     >> Perhaps the following link works better for you though:
>     >> https://www.bing.com/search?q=rstudio+rprofile
>     <https://www.bing.com/search?q=rstudio+rprofile>
>     >
>     > Another promising search strategy would be SO with "[rstudio]"
>     in the tags:
>     >
>     > http://stackoverflow.com/search?q=%5Brstudio%5D+rprofile+windows
>     <http://stackoverflow.com/search?q=%5Brstudio%5D+rprofile+windows>
>     >
>     > --
>     > david.
>     >>
>     >> B.
>     >>
>     >>
>     >>> On Apr 15, 2017, at 3:14 PM, BR_email <br at dmstat1.com
>     <mailto:br at dmstat1.com>> wrote:
>     >>>
>     >>> Bill:
>     >>> Thanks for reply.
>     >>> Sorry, I do not understand it.
>     >>> For example, where do I put "file.path(getwd(), ".Rprofile")" ?
>     >>>
>     >>> Bruce
>     >>>
>     >>>
>     >>> William Dunlap wrote:
>     >>>> I think the site-specific R profile should be, using R syntax
>     >>>>   file.path(R.home("etc"), "Rprofile.site") # no dot before
>     the capital R
>     >>>> The personal R profile will be
>     >>>>   file.path(Sys.getenv("HOME"), ".Rprofile") # there is a dot
>     before capital R
>     >>>> but if a local R profile,
>     >>>>   file.path(getwd(), ".Rprofile") # there is a dot before
>     capital R
>     >>>> exists it will be used and the one in HOME will not be. 
>     (getwd() should
>     >>>> be the startup directory.)
>     >>>>
>     >>>>
>     >>>> Bill Dunlap
>     >>>> TIBCO Software
>     >>>> wdunlap tibco.com <http://tibco.com>
>     >>>>
>     >>>>
>     >>>> On Sat, Apr 15, 2017 at 9:06 AM, BR_email <br at dmstat1.com
>     <mailto:br at dmstat1.com>> wrote:
>     >>>>> Hi R-helpers:
>     >>>>> Can you offer assistance in my getting .Rprofile and
>     .Rprofile.site to run
>     >>>>> in RStudio?
>     >>>>> When I start RStudio nothing happens.
>     >>>>> I have put .Rprofile in [1] and [2], and .Rprofile.site in [2].
>     >>>>>
>     >>>>> Below, the info I believe you need to know.
>     >>>>> Thanks, in advance, for any help.
>     >>>>> Bruce
>     >>>>>
>     >>>>> The .Rprofile and .Rprofile.site are R-type files, which
>     contain the two
>     >>>>> lines below.
>     >>>>> Also, I tried the profile files as text files.
>     >>>>> options(prompt="R> ")
>     >>>>> set.seed(12345)
>     >>>>>
>     >>>>>> Sys.getenv("HOME") [1] "C:/Users/BruceRatner/Documents"
>     >>>>>> Sys.getenv("R_HOME") [2] "C:/PROGRA~1/R/R-33~1.3"
>     >>>>>
>     >>>>>
>     >>>>> --
>     >>>>>
>     >>>>> ______________________________________________
>     >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>     >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >>>>> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >>>>> and provide commented, minimal, self-contained, reproducible
>     code.
>     >>>>
>     >>>>
>     >>>
>     >>> ______________________________________________
>     >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >>> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >>> and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >
>     > David Winsemius
>     > Alameda, CA, USA
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Sun Apr 16 01:57:02 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 15 Apr 2017 16:57:02 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
Message-ID: <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>

Well, to be fair, .Rprofile is an R configuration file, so it was merely the subject line that was off-topic.
-- 
Sent from my phone. Please excuse my brevity.

On April 15, 2017 4:24:06 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 16/04/17 07:57, BR_email wrote:
>> Boris:
>> As before, you assume that I, Bruce Ratner, just asks questions
>without
>> first trying it myself.
>> FYI: I purchased and read four RStudio books, as well as all the
>links I
>> found in the web.
>> I will not take your maligning me.
>> Please try to assist me, but do not bully me.
>> Bruce Ratner, Ph.D.
>
>Bruce, you are being preciously hypersensitive.  Boris's comment was 
>completely appropriate and betrayed not the slightest trace of 
>"bullying".  If you had indeed done your homework in the manner that 
>Boris recommended you would had no need to clutter this mailing list 
>with your (off-topic) question.
>
>cheers,
>
>Rolf Turner


From suttoncarl at ymail.com  Sun Apr 16 02:18:43 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Sun, 16 Apr 2017 00:18:43 +0000 (UTC)
Subject: [R] the difference between "-" and "!" between base and data.table
 package
References: <1959072457.1072158.1492301923883.ref@mail.yahoo.com>
Message-ID: <1959072457.1072158.1492301923883@mail.yahoo.com>

Hi 


I normally use package data.table but today was doing some base R coding.  Had a problem for a bit which I finally resolved.  I was attempting to separate a data frame between train and test sets, and in base R was using the "!" to exclude training set indices from the data frame.  All I was getting was zero observations.  Changed to using "-" and it worked.  I recalled that in data.table the "!" function worked, so created this little bit of code.

#  Base R Functions
str(mtcars)
train_indices <- sample(nrow(mtcars), round(0.75*nrow(mtcars)))
train <- mtcars[train_indices,]
mode(train_indices); class(train_indices)
test <- mtcars[!train_indices,]  #  the "!" function returning 0 observations
test_1 <- mtcars[-train_indices,]
identical(test, test_1)

#  Using data.table package
library(data.table)
dt1 <- data.table(mtcars)
train_indices <- sample(nrow(dt1), round(0.75*nrow(dt1)))
train <- dt1[train_indices,]
mode(train_indices); class(train_indices)
test <- dt1[!train_indices,]  #  the "!" function
test_1 <- dt1[-train_indices,]
identical(test, test_1)
The documentation appears to me to accept "!" in base, so do I have some kind of ridiculous error or ..??
Carl Sutton


From allantanaka11 at yahoo.com  Sun Apr 16 04:27:09 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Sun, 16 Apr 2017 02:27:09 +0000 (UTC)
Subject: [R]  How to integrate OpenBLAS LAPACK to my RStudio in WINDOWS 7?
References: <1632534021.1143784.1492309629761.ref@mail.yahoo.com>
Message-ID: <1632534021.1143784.1492309629761@mail.yahoo.com>

Hi.
I have installed OpenBLAS and LAPACK. It's working correctly in Python. 
I also want OpenBLAS and LAPACK to be used in R to speed up computational time but i can't find the installation guide for RStudio in Windows7. Does it mean that RStudio automatically detect the installed OpenBLAS and use it?

Please let me know.
THANKS

*Note: I Have installed RTools but i don't set R's mingw, cygwn in the environment path because i have installed those two beforehand. My RSTUDIO=3.4


From dwinsemius at comcast.net  Sun Apr 16 09:34:37 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Apr 2017 00:34:37 -0700
Subject: [R] How to integrate OpenBLAS LAPACK to my RStudio in WINDOWS 7?
In-Reply-To: <1632534021.1143784.1492309629761@mail.yahoo.com>
References: <1632534021.1143784.1492309629761.ref@mail.yahoo.com>
 <1632534021.1143784.1492309629761@mail.yahoo.com>
Message-ID: <D69B9B29-8190-4970-9A53-68C5FE4B6356@comcast.net>


> On Apr 15, 2017, at 7:27 PM, Allan Tanaka via R-help <r-help at r-project.org> wrote:
> 
> Hi.
> I have installed OpenBLAS and LAPACK. It's working correctly in Python. 
> I also want OpenBLAS and LAPACK to be used in R to speed up computational time but i can't find the installation guide for RStudio in Windows7. Does it mean that RStudio automatically detect the installed OpenBLAS and use it?

Seems unlikely that RStudio has much to do with this matter. I'm reasonably sure that you would need to compile R to link to OpenBLAS but I think LAPACK is the default math package (although you can use an "external" version).

Search for:
A.3.1.3 Goto and OpenBLAS   # in the 'R Installation and Administration' manual

And
A.3.2 LAPACK


> 
> Please let me know.
> THANKS
> 
> *Note: I Have installed RTools but i don't set R's mingw, cygwn in the environment path because i have installed those two beforehand. My RSTUDIO=3.4

I thought R's binary wasn't set up to run under Cygwin?

And I didn't change my mind after reading Section:
C.8 Cygwin

I think follow-up question on this matter would be more appropriate on R-devel, but they really do expect you to RTM.

-- 
David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sun Apr 16 09:51:28 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 16 Apr 2017 00:51:28 -0700
Subject: [R] the difference between "-" and "!" between base and
	data.table package
In-Reply-To: <1959072457.1072158.1492301923883@mail.yahoo.com>
References: <1959072457.1072158.1492301923883.ref@mail.yahoo.com>
 <1959072457.1072158.1492301923883@mail.yahoo.com>
Message-ID: <375C4F8D-1E91-4FD0-9AD7-34D18D463E39@dcn.davis.ca.us>

! is a logical operator... it means "not". When you write

lidx <- seq_along( mtcars[[ 1 ]] ) %in% train_indices

you end up with a vector of logical values for which ! makes sense. Since R supports logical indexing this can be a very convenient way to select one group or the other. 

If you give an integer to the ! operator, any non-zero value is treated as TRUE, which can be useful sometimes but not in this case, since all of the train_indices are greater than zero. Look at what !train_indices actually is.

As the Introduction to R document says, integer indexing always starts at 1 instead of zero as in many other languages. This makes it feasible to let negative integers as indexes represent the idea of excluding those positions. Thus

identical( mtcars[ !lidx, ], mtcars[ -train_indices, ] )

The ItoR document is really quite informative to re-read occasionally. For example, look up indexing with a matrix as the index. 
-- 
Sent from my phone. Please excuse my brevity.

On April 15, 2017 5:18:43 PM PDT, Carl Sutton via R-help <r-help at r-project.org> wrote:
>Hi 
>
>
>I normally use package data.table but today was doing some base R
>coding.  Had a problem for a bit which I finally resolved.  I was
>attempting to separate a data frame between train and test sets, and in
>base R was using the "!" to exclude training set indices from the data
>frame.  All I was getting was zero observations.  Changed to using "-"
>and it worked.  I recalled that in data.table the "!" function worked,
>so created this little bit of code.
>
>#  Base R Functions
>str(mtcars)
>train_indices <- sample(nrow(mtcars), round(0.75*nrow(mtcars)))
>train <- mtcars[train_indices,]
>mode(train_indices); class(train_indices)
>test <- mtcars[!train_indices,]  #  the "!" function returning 0
>observations
>test_1 <- mtcars[-train_indices,]
>identical(test, test_1)
>
>#  Using data.table package
>library(data.table)
>dt1 <- data.table(mtcars)
>train_indices <- sample(nrow(dt1), round(0.75*nrow(dt1)))
>train <- dt1[train_indices,]
>mode(train_indices); class(train_indices)
>test <- dt1[!train_indices,]  #  the "!" function
>test_1 <- dt1[-train_indices,]
>identical(test, test_1)
>The documentation appears to me to accept "!" in base, so do I have
>some kind of ridiculous error or ..??
>Carl Sutton
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Apr 16 10:00:09 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Apr 2017 01:00:09 -0700
Subject: [R] the difference between "-" and "!" between base and
	data.table package
In-Reply-To: <1959072457.1072158.1492301923883@mail.yahoo.com>
References: <1959072457.1072158.1492301923883.ref@mail.yahoo.com>
 <1959072457.1072158.1492301923883@mail.yahoo.com>
Message-ID: <7948E174-EB50-44F8-ABE3-5CE2721D7C74@comcast.net>


> On Apr 15, 2017, at 5:18 PM, Carl Sutton via R-help <r-help at r-project.org> wrote:
> 
> Hi 
> 
> 
> I normally use package data.table but today was doing some base R coding.  Had a problem for a bit which I finally resolved.  I was attempting to separate a data frame between train and test sets, and in base R was using the "!" to exclude training set indices from the data frame.  All I was getting was zero observations.  Changed to using "-" and it worked.  I recalled that in data.table the "!" function worked, so created this little bit of code.
> 
> #  Base R Functions
> str(mtcars)
> train_indices <- sample(nrow(mtcars), round(0.75*nrow(mtcars)))
> train <- mtcars[train_indices,]
> mode(train_indices); class(train_indices)
> test <- mtcars[!train_indices,]  #  the "!" function returning 0 observations

The arguments you are supplying:

> table( !train_indices )

FALSE 
   24 


> test_1 <- mtcars[-train_indices,]
> identical(test, test_1)
> 
> #  Using data.table package
> library(data.table)
> dt1 <- data.table(mtcars)
> train_indices <- sample(nrow(dt1), round(0.75*nrow(dt1)))
> train <- dt1[train_indices,]

The data.table "[" function has very different syntax and evaluation rules than does the data.frame "[" function, but I guess you know that.


> mode(train_indices); class(train_indices)
> test <- dt1[!train_indices,]  #  the "!" function
> test_1 <- dt1[-train_indices,]
> identical(test, test_1)
> The documentation appears to me to accept "!" in base, so do I have some kind of ridiculous error or ..??

Not sure about "ridiculous" and you have not actually said what it was that _you_ were questioning.
If it is the lack of any return from `test <- mtcars[!train_indices,]` than it could be argued that was a ridiculous expectation at least according to the rules of vector evaluation in row selection that I thought I understood. Giving a vector of FALSE values to `[.data.frame` would not reasonably be expected to return anything. Whether giving a vector of only FALSE's to `[.data.table` and actually getting something back does seem kind of unexpected to me, but clearly it didn't seem ridiculous to Matt Dowle. Clearly the recycling rules for `[.data.table are different than those of `[.data.frame`. Data.tables don't use rownames.


The results from:

> dt1[rep(FALSE,24), ]
Error in `[.data.table`(dt1, rep(FALSE, 24), ) : 
  i evaluates to a logical vector length 24 but there are 32 rows. Recycling of logical i is no longer allowed as it hides more bugs than is worth the rare convenience. Explicitly use rep(...,length=.N) if you really need to recycle.

... is different than from 

dt1[!train_indices, ] # get 8 rows.

To me that doesn't make sense.


I generally use %in% for row selection. But many people would also find this pair of results "ridiculous":

> mtcars[ which( train_indices %in% 50:100), ]
 [1] mpg  cyl  disp hp   drat wt   qsec vs   am   gear carb
<0 rows> (or 0-length row.names)
> mtcars[ -which( train_indices %in% 50:100), ]   # bad idea to use minus before which()
 [1] mpg  cyl  disp hp   drat wt   qsec vs   am   gear carb
<0 rows> (or 0-length row.names)

Yes, I know that some people think the `which` is not needed. I'm not one of them.

-- 
David.


> Carl Sutton
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From suttoncarl at ymail.com  Sun Apr 16 19:05:50 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Sun, 16 Apr 2017 17:05:50 +0000 (UTC)
Subject: [R] seq argument alomg.with
References: <284843104.1339035.1492362350824.ref@mail.yahoo.com>
Message-ID: <284843104.1339035.1492362350824@mail.yahoo.com>

Hi


Thank you gentlemen for sharing your knowledge.  It makes perfect sense and using seq_along prevents errors that could be perplexing and time consuming to discover.

Thank you

 Carl Sutton


From suttoncarl at ymail.com  Sun Apr 16 19:44:42 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Sun, 16 Apr 2017 17:44:42 +0000 (UTC)
Subject: [R] the difference between "-" and "!" between base and
 data.table package
In-Reply-To: <7948E174-EB50-44F8-ABE3-5CE2721D7C74@comcast.net>
References: <1959072457.1072158.1492301923883.ref@mail.yahoo.com>
 <1959072457.1072158.1492301923883@mail.yahoo.com>
 <7948E174-EB50-44F8-ABE3-5CE2721D7C74@comcast.net>
Message-ID: <131018110.1307500.1492364682396@mail.yahoo.com>

Hi


Thank you all for your input.  But I must apologize.  When I was searching the help page I went this far and stopped
Logic {base}	R Documentation
Logical Operators

Description

These operators act on raw, logical and number-like vectors.

Usage

! x
x & y
x && y
x | y
x || y
xor(x, y)

isTRUE(x)
Arguments

x, y 
raw or logical or ?number-like? vectors (i.e., of types double (class numeric), integer and complex)), or objects for which methods have been written.

At that point I took a look at train_indices and it was indeed a vector of integers, so directed my inquiry to the list.

After reading the answers it was fairly obvious I had missed something, and in the details is
    
    Numeric and complex vectors will be coerced to logical values, with zero being false and all non-zero     values being true. Raw vectors are handled without any coercion for !, &, | and xor, with these     operators being applied bitwise (so ! is the 1s-complement).
I was truly lax in my search of the documentation
Again, thank for you for your time and expertise, I will try to be more complete in my research in the future
 
Carl Sutton


On Sunday, April 16, 2017 1:00 AM, David Winsemius <dwinsemius at comcast.net> wrote:




> On Apr 15, 2017, at 5:18 PM, Carl Sutton via R-help <r-help at r-project.org> wrote:
> 
> Hi 
> 
> 
> I normally use package data.table but today was doing some base R coding.  Had a problem for a bit which I finally resolved.  I was attempting to separate a data frame between train and test sets, and in base R was using the "!" to exclude training set indices from the data frame.  All I was getting was zero observations.  Changed to using "-" and it worked.  I recalled that in data.table the "!" function worked, so created this little bit of code.
> 
> #  Base R Functions
> str(mtcars)
> train_indices <- sample(nrow(mtcars), round(0.75*nrow(mtcars)))
> train <- mtcars[train_indices,]
> mode(train_indices); class(train_indices)
> test <- mtcars[!train_indices,]  #  the "!" function returning 0 observations

The arguments you are supplying:

> table( !train_indices )

FALSE 
   24 


> test_1 <- mtcars[-train_indices,]
> identical(test, test_1)
> 
> #  Using data.table package
> library(data.table)
> dt1 <- data.table(mtcars)
> train_indices <- sample(nrow(dt1), round(0.75*nrow(dt1)))
> train <- dt1[train_indices,]

The data.table "[" function has very different syntax and evaluation rules than does the data.frame "[" function, but I guess you know that.


> mode(train_indices); class(train_indices)
> test <- dt1[!train_indices,]  #  the "!" function
> test_1 <- dt1[-train_indices,]
> identical(test, test_1)
> The documentation appears to me to accept "!" in base, so do I have some kind of ridiculous error or ..??

Not sure about "ridiculous" and you have not actually said what it was that _you_ were questioning.
If it is the lack of any return from `test <- mtcars[!train_indices,]` than it could be argued that was a ridiculous expectation at least according to the rules of vector evaluation in row selection that I thought I understood. Giving a vector of FALSE values to `[.data.frame` would not reasonably be expected to return anything. Whether giving a vector of only FALSE's to `[.data.table` and actually getting something back does seem kind of unexpected to me, but clearly it didn't seem ridiculous to Matt Dowle. Clearly the recycling rules for `[.data.table are different than those of `[.data.frame`. Data.tables don't use rownames.


The results from:

> dt1[rep(FALSE,24), ]
Error in `[.data.table`(dt1, rep(FALSE, 24), ) : 
  i evaluates to a logical vector length 24 but there are 32 rows. Recycling of logical i is no longer allowed as it hides more bugs than is worth the rare convenience. Explicitly use rep(...,length=.N) if you really need to recycle.

... is different than from 

dt1[!train_indices, ] # get 8 rows.

To me that doesn't make sense.


I generally use %in% for row selection. But many people would also find this pair of results "ridiculous":

> mtcars[ which( train_indices %in% 50:100), ]
[1] mpg  cyl  disp hp   drat wt   qsec vs   am   gear carb
<0 rows> (or 0-length row.names)
> mtcars[ -which( train_indices %in% 50:100), ]   # bad idea to use minus before which()
[1] mpg  cyl  disp hp   drat wt   qsec vs   am   gear carb
<0 rows> (or 0-length row.names)

Yes, I know that some people think the `which` is not needed. I'm not one of them.

-- 
David.



> Carl Sutton
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ramnik.bansal at gmail.com  Sun Apr 16 20:03:25 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sun, 16 Apr 2017 23:33:25 +0530
Subject: [R] what does this syntax mean in R
Message-ID: <CAMLd9E5bff94394dfeQuu2x-4aT3PD8wQqy0WSJPzQdHt5bY3g@mail.gmail.com>

?I am not able to understand the output of the following lines of code.

*if(TRUE)(print("A"))?*

Versus

*if(TRUE){print("A"))*

*In first case I get the ooutput as *
*>[1]  "A"*
*>[1]  "A"*

*Why does the first case print "A" twice *

*Why does it not happen with the statement **if(TRUE){print("A"))*

*Thanks *
*Ramnik*

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Apr 16 20:14:57 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 16 Apr 2017 14:14:57 -0400
Subject: [R] what does this syntax mean in R
In-Reply-To: <CAMLd9E5bff94394dfeQuu2x-4aT3PD8wQqy0WSJPzQdHt5bY3g@mail.gmail.com>
References: <CAMLd9E5bff94394dfeQuu2x-4aT3PD8wQqy0WSJPzQdHt5bY3g@mail.gmail.com>
Message-ID: <f45179de-a797-370a-d52b-ee378f57cfcc@gmail.com>

On 16/04/2017 2:03 PM, Ramnik Bansal wrote:
> ?I am not able to understand the output of the following lines of code.
>
> *if(TRUE)(print("A"))?*
>
> Versus
>
> *if(TRUE){print("A"))*

I assume you have a typo here (or maybe your posting in HTML has done 
more damage than usual.  This line should be

if(TRUE){print("A")}


>
> *In first case I get the ooutput as *
> *>[1]  "A"*
> *>[1]  "A"*

This happens because the print() function both prints the value that was 
passed to it, and also returns it, marked as "invisible". The printing 
gives you the first line.  The parentheses remove the invisibility, so 
the result of the whole expression is "A", *not* marked as invisible, 
and auto-printing gives you the second line.

>
> *Why does the first case print "A" twice *
>
> *Why does it not happen with the statement **if(TRUE){print("A"))*

Because braces don't affect invisibility.  Auto-printing ignores objects 
that are marked as invisible.  You would get two lines printed if you 
asked for explicit printing, e.g.

print( if(TRUE){print("A")} )

or remove the invisibility later, e.g.

( if(TRUE){print("A")} )

Duncan Murdoch

>
> *Thanks *
> *Ramnik*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From frainj at gmail.com  Sun Apr 16 22:46:51 2017
From: frainj at gmail.com (John C Frain)
Date: Sun, 16 Apr 2017 21:46:51 +0100
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
Message-ID: <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>

Bruce

The official documentation for these startup files can be obtained with the
command

Help(Startup)

at the R prompt or through search help in R studio.  I have used R in
various versions of Windows and Linux using the console version of R and
various IDEs including Rstudio and these have always worked as expected.
Rstudio has no specific effect on the location or use of these files. Now,
I only have access to PCs with windows 10 and can not check if there is any
specific problem with windows 7.  I did use the startup files in earlier
versions of windows and have no recollection of any problems. There are
some peculiarities with Windows that you might check.

Henrik has outlined some of the problems that may arise with file name
extensions. Windows does not display extensions for file names with known
extensions. Many windows programs add their file extension to files when
they save them. I used to recommend to students that they configure windows
explorer to display file extensions. This is relatively easy to do in
Windows explorer in any version of windows. needless to say many students
ignored this advice and later ran into problems.

Windows may have problems saving files that start with a period. I use
notepad++ as a general test editor. On my system notepad++ can save files
whose names start with a period. The editor in Rstudio can also do so on my
system. I do remember having problems with an earlier version of Windows.

On windows 10  one must right click on the notepad++ or other editor icon
and select run as administrator to edit a file in the Program Files
directory.  I don't remember to what extent this applies to Windows 7.

I have worked over the years with many people who were not native English
speakers even though they spoke very good English. The tone of their
interventions could sometimes cause problems. I think that the links that
you were given would have gone some way to solving your problem. I don't
think that the language used was intended to bully or cause offence. I
still think that an apology is in order. If someone volunteers an answer
look at its content rather than its brevity, tone or use of language. This
list depends on volunteers and they should be thanked rather than maligned.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 16 April 2017 at 00:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Well, to be fair, .Rprofile is an R configuration file, so it was merely
> the subject line that was off-topic.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 15, 2017 4:24:06 PM PDT, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >On 16/04/17 07:57, BR_email wrote:
> >> Boris:
> >> As before, you assume that I, Bruce Ratner, just asks questions
> >without
> >> first trying it myself.
> >> FYI: I purchased and read four RStudio books, as well as all the
> >links I
> >> found in the web.
> >> I will not take your maligning me.
> >> Please try to assist me, but do not bully me.
> >> Bruce Ratner, Ph.D.
> >
> >Bruce, you are being preciously hypersensitive.  Boris's comment was
> >completely appropriate and betrayed not the slightest trace of
> >"bullying".  If you had indeed done your homework in the manner that
> >Boris recommended you would had no need to clutter this mailing list
> >with your (off-topic) question.
> >
> >cheers,
> >
> >Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From br at dmstat1.com  Sun Apr 16 23:55:12 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Sun, 16 Apr 2017 17:55:12 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
Message-ID: <3D8F490A-7037-44B8-9EE8-4E4FFB5DC00F@dmstat1.com>

Dear John:
Thank you so much for your continued support. You are exceptional. 
I have followed everything you stated with no success. 
Prior to asking a question, I promise you my style is "to solve it myself."
I read everything on the web, and purchased and read $200 in books. 

I hate to repeat, but on the only three questions I ever submitted to R-help , since I started with R, I received several technical suggestions of what to do. 
Yet, Boris replied all three times with "read the manuals, go to websites, and stop spamming."
I'm sorry, but Boris' implies that I haven't done the basics and I want someone to just give me the answer to my question. 

Those who reply with positive suggestions vs. Boris who tells me that he's not going to do my due diligence - indicates Boris' condescending attitude. I don't know why he responds to my last two questions, given I politely informed him that I have done the basic reading, etc?

Regardless, you are professional, helpful, and very proper. 
Unfortunately, I don't think I will use R-help, in fear of Boris. 

Bruce
______________
Bruce Ratner PhD
The Significant Statistician?
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 16, 2017, at 4:46 PM, John C Frain <frainj at gmail.com> wrote:
> 
> Bruce
> 
> The official documentation for these startup files can be obtained with the command
> 
> Help(Startup)
> 
> at the R prompt or through search help in R studio.  I have used R in various versions of Windows and Linux using the console version of R and various IDEs including Rstudio and these have always worked as expected. Rstudio has no specific effect on the location or use of these files. Now, I only have access to PCs with windows 10 and can not check if there is any specific problem with windows 7.  I did use the startup files in earlier versions of windows and have no recollection of any problems. There are some peculiarities with Windows that you might check.
> 
> Henrik has outlined some of the problems that may arise with file name extensions. Windows does not display extensions for file names with known extensions. Many windows programs add their file extension to files when they save them. I used to recommend to students that they configure windows explorer to display file extensions. This is relatively easy to do in Windows explorer in any version of windows. needless to say many students ignored this advice and later ran into problems.
> 
> Windows may have problems saving files that start with a period. I use notepad++ as a general test editor. On my system notepad++ can save files whose names start with a period. The editor in Rstudio can also do so on my system. I do remember having problems with an earlier version of Windows.
> 
> On windows 10  one must right click on the notepad++ or other editor icon and select run as administrator to edit a file in the Program Files directory.  I don't remember to what extent this applies to Windows 7.
> 
> I have worked over the years with many people who were not native English speakers even though they spoke very good English. The tone of their interventions could sometimes cause problems. I think that the links that you were given would have gone some way to solving your problem. I don't think that the language used was intended to bully or cause offence. I still think that an apology is in order. If someone volunteers an answer look at its content rather than its brevity, tone or use of language. This list depends on volunteers and they should be thanked rather than maligned. 
> 
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
> 
>> On 16 April 2017 at 00:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> Well, to be fair, .Rprofile is an R configuration file, so it was merely the subject line that was off-topic.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On April 15, 2017 4:24:06 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> >On 16/04/17 07:57, BR_email wrote:
>> >> Boris:
>> >> As before, you assume that I, Bruce Ratner, just asks questions
>> >without
>> >> first trying it myself.
>> >> FYI: I purchased and read four RStudio books, as well as all the
>> >links I
>> >> found in the web.
>> >> I will not take your maligning me.
>> >> Please try to assist me, but do not bully me.
>> >> Bruce Ratner, Ph.D.
>> >
>> >Bruce, you are being preciously hypersensitive.  Boris's comment was
>> >completely appropriate and betrayed not the slightest trace of
>> >"bullying".  If you had indeed done your homework in the manner that
>> >Boris recommended you would had no need to clutter this mailing list
>> >with your (off-topic) question.
>> >
>> >cheers,
>> >
>> >Rolf Turner
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Apr 17 00:08:26 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 17 Apr 2017 10:08:26 +1200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
Message-ID: <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>


On 17/04/17 08:46, John C Frain wrote:

> Bruce
>
> The official documentation for these startup files can be obtained with
> the command
>
> Help(Startup)


Minor point of order, Mr. Chairman.  That should be:

     help(Startup)

There is (as far as I know) no such function as "Help()".  It is 
important to remember that R is case sensitive.

Another point that is worthy of thought is "How in God's name would any 
beginner know or find out about the usage help(Startup)?"  Unless they 
were explicitly told about it, in the manner which you just 
demonstrated.  The usage gets a mention in "An Introduction to R" --- 
but I had to search for it.

To me the word "startup" is not terribly intuitive.  I would tend to 
search for "starting" rather than "startup", I think, but I'm not sure 
what the average beginner would search for.  A search of "An 
Introduction to R" for "starting" gets seven or eight hits, one of which 
is relevant.  So it all takes patience and persistence.

Also note that "An Introduction to R" mostly uses the word "startup" 
(lower case "s") and only uses "Startup" twice.  Note also that

     help(startup)

fails.  You have to get that initial "S" right.

This isn't a criticism of the documentation.  I'm just pointing out that 
there are problems, mostly insoluble.  Until some clever Johnny gets on 
with developing that mind_read() function referred to in fortune(182).

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pdalgd at gmail.com  Mon Apr 17 00:13:17 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 17 Apr 2017 00:13:17 +0200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
Message-ID: <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>

Um, tried help(.Rprofile) lately?

-pd

> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 17/04/17 08:46, John C Frain wrote:
> 
>> Bruce
>> 
>> The official documentation for these startup files can be obtained with
>> the command
>> 
>> Help(Startup)
> 
> 
> Minor point of order, Mr. Chairman.  That should be:
> 
>    help(Startup)
> 
> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
> 
> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
> 
> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
> 
> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
> 
>    help(startup)
> 
> fails.  You have to get that initial "S" right.
> 
> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From br at dmstat1.com  Mon Apr 17 00:43:30 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 16 Apr 2017 18:43:30 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
Message-ID: <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>

Peter:
Thanks for reply and suggestion.
Sorry, I am not sure how to assess.
The doc is too technical for me to understand.
I found multiple instructions online and in R and RStudio books.
I'm doing what it says, but no success.
The instructions are simple as a-b-c, but some setting within the 
Windows system must be the culprit.

Regards,
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

peter dalgaard wrote:
> Um, tried help(.Rprofile) lately?
>
> -pd
>
>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> On 17/04/17 08:46, John C Frain wrote:
>>
>>> Bruce
>>>
>>> The official documentation for these startup files can be obtained with
>>> the command
>>>
>>> Help(Startup)
>>
>> Minor point of order, Mr. Chairman.  That should be:
>>
>>     help(Startup)
>>
>> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
>>
>> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
>>
>> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
>>
>> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
>>
>>     help(startup)
>>
>> fails.  You have to get that initial "S" right.
>>
>> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
>>
>> cheers,
>>
>> Rolf Turner
>>
>> -- 
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Apr 17 01:19:08 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 17 Apr 2017 01:19:08 +0200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
Message-ID: <764F9AE0-656A-431D-A2D2-E3E45E6B8CD0@gmail.com>

That was aimed at Rolf...

For the actual question, I think the best approach would be to follow up on Bill Dunlap's suggestion. The mails from Jeff and Henrik pretty much tell you step by step what to try to find out which files on yours system are being checked in order to find startup code.

-pd



> On 17 Apr 2017, at 00:43 , BR_email <br at dmstat1.com> wrote:
> 
> Peter:
> Thanks for reply and suggestion.
> Sorry, I am not sure how to assess.
> The doc is too technical for me to understand.
> I found multiple instructions online and in R and RStudio books.
> I'm doing what it says, but no success.
> The instructions are simple as a-b-c, but some setting within the Windows system must be the culprit.
> 
> Regards,
> Bruce
> 
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
> 
> peter dalgaard wrote:
>> Um, tried help(.Rprofile) lately?
>> 
>> -pd
>> 
>>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> On 17/04/17 08:46, John C Frain wrote:
>>> 
>>>> Bruce
>>>> 
>>>> The official documentation for these startup files can be obtained with
>>>> the command
>>>> 
>>>> Help(Startup)
>>> 
>>> Minor point of order, Mr. Chairman.  That should be:
>>> 
>>>    help(Startup)
>>> 
>>> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
>>> 
>>> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
>>> 
>>> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
>>> 
>>> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
>>> 
>>>    help(startup)
>>> 
>>> fails.  You have to get that initial "S" right.
>>> 
>>> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>>> 
>>> -- 
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Mon Apr 17 01:34:18 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Apr 2017 16:34:18 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
Message-ID: <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>


> On Apr 16, 2017, at 3:43 PM, BR_email <br at dmstat1.com> wrote:
> 
> Peter:
> Thanks for reply and suggestion.
> Sorry, I am not sure how to assess.
> The doc is too technical for me to understand.
> I found multiple instructions online and in R and RStudio books.
> I'm doing what it says, but no success.

What is "it" and what is "lack of success"?

> The instructions are simple as a-b-c, but some setting within the Windows system must be the culprit.

Although the RStudio page immediately below was done with a Mac, I suspect there are similar selection panels and dialogs on the Windows version of RStudio.

https://support.rstudio.com/hc/en-us/articles/200549016#general

When I look at the Windows installation advice I see near the top: "When installing on a 64-bit version of Windows the options will include 32- or 64-bit versions of R (and the default is to install both)." So is it possible that RStudio is looking at a different version of R than you believe it should be, perhaps at the 32 bit R versus the 64 bit one? The result at the beginning of this thread makes me think you got the 32-bit one connected to RStudio.

And I say again: I believe problems in configuring RStudio are off-topic for Rhelp and you should have been searching or posting question either to the RStudio support or StackOverflow. Looking at the responses to the queries above and the ones found below, it appears to me that there are RStudio-specific issues that go beyond what is in the `help(Startup)` or equivalent `help(.Rprofile)` page.  I gave an instance of an SO search upthread and I offer another SO search:

http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20environment%20variables%20windows

I thought that this one below had potentially useful information, but I am not a Windows user (and you have not shown an inclination in offering a complete description of your efforts at following that advice. At any rate it would have been more appropriate to respond to the SO answers that were ineffective or to post a question there with full description of your efforts and content of your .Rprofile file and your current environment variable settings.)

http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20rprofile%20windows

-- 
David

> 
> Regards,
> Bruce
> 
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
> 
> peter dalgaard wrote:
>> Um, tried help(.Rprofile) lately?
>> 
>> -pd
>> 
>>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> On 17/04/17 08:46, John C Frain wrote:
>>> 
>>>> Bruce
>>>> 
>>>> The official documentation for these startup files can be obtained with
>>>> the command
>>>> 
>>>> Help(Startup)
>>> 
>>> Minor point of order, Mr. Chairman.  That should be:
>>> 
>>>    help(Startup)
>>> 
>>> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
>>> 
>>> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
>>> 
>>> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
>>> 
>>> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
>>> 
>>>    help(startup)
>>> 
>>> fails.  You have to get that initial "S" right.
>>> 
>>> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>>> 
>>> -- 
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sophie.dubois at anastats.fr  Sun Apr 16 15:46:52 2017
From: sophie.dubois at anastats.fr (Sophie Dubois)
Date: Sun, 16 Apr 2017 15:46:52 +0200
Subject: [R] question about the anova() function for deviance analysis
Message-ID: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>

Dear Maintener,
> I have recently had a bad experience with the anova() function.
> Indeed, I wanted to process a deviance analysis between 2 mixed linear
> models and I was really surprise to see that depending on the ordre in
> which I gave my models, the function did not the same thing: once it
> makes the anova of the first model and in the other ordre, it makes a
> deviance analysis.
> I make lots of formations to researchers who are not always very
> comfortable either with R or with some statistical analysis and they
> were really very disturbed by that.
> Could this be possible to "secure" this anova function in order that
> it does the same thing whatever the order in which the models are given? 
> Hope I was clear enought and many thanks in advance for your regard
> about my question.
> Best regards, Sophie

--
Sophie Dubois
ANASTATS
sophie.dubois at anastats.fr



---
L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From mmsaifuddin09 at gmail.com  Mon Apr 17 00:49:07 2017
From: mmsaifuddin09 at gmail.com (M.M saifuddin)
Date: Sun, 16 Apr 2017 15:49:07 -0700 (PDT)
Subject: [R] help on readBin in R
Message-ID: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>

I need to view the attached  binary file. but can not read it, instead am 
getting very weird( i think garbage) numbers. 

The values are Temperature data so it should be somewhat in between 250 to 
500.

Can any altruist view it and give me the R code to view it.

I am attaching the file. Please help me if you can.

TIA

From bgunter.4567 at gmail.com  Mon Apr 17 03:16:22 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 16 Apr 2017 18:16:22 -0700
Subject: [R] question about the anova() function for deviance analysis
In-Reply-To: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
References: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
Message-ID: <CAGxFJbTRB4hpGMMJ=iLTdK-orzPryPX4zQfUk-f1_kxdvtBjSw@mail.gmail.com>

This list is about R programming; your question seems mostly about
statistics, and is therefore off topic here. I suggest you consult a
local statistical expert who *is* comfortable with such statistical
analyses. In general, partitions of sums of squares in statistical
models can depend on the order of model terms, but you have provided
so little information that I doubt that anyone can guess to what
exactly you refer.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 16, 2017 at 6:46 AM, Sophie Dubois
<sophie.dubois at anastats.fr> wrote:
> Dear Maintener,
>> I have recently had a bad experience with the anova() function.
>> Indeed, I wanted to process a deviance analysis between 2 mixed linear
>> models and I was really surprise to see that depending on the ordre in
>> which I gave my models, the function did not the same thing: once it
>> makes the anova of the first model and in the other ordre, it makes a
>> deviance analysis.
>> I make lots of formations to researchers who are not always very
>> comfortable either with R or with some statistical analysis and they
>> were really very disturbed by that.
>> Could this be possible to "secure" this anova function in order that
>> it does the same thing whatever the order in which the models are given?
>> Hope I was clear enought and many thanks in advance for your regard
>> about my question.
>> Best regards, Sophie
>
> --
> Sophie Dubois
> ANASTATS
> sophie.dubois at anastats.fr
>
>
>
> ---
> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.
> https://www.avast.com/antivirus
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Apr 17 03:21:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 16 Apr 2017 18:21:54 -0700
Subject: [R] help on readBin in R
In-Reply-To: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>
References: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>
Message-ID: <EAF0A4FF-1866-4581-A914-161D059003AC@dcn.davis.ca.us>

The mailing list has tight restrictions on attachments, so your attachment was not let through. Read the Posting Guide, and note that sometimes success requires some extended understanding of how your mail software works, and we probably don't know the details either. You might have success changing the file extension or sending a link to the file on a file storage website like Google Drive or Dropbox.
-- 
Sent from my phone. Please excuse my brevity.

On April 16, 2017 3:49:07 PM PDT, "M.M saifuddin" <mmsaifuddin09 at gmail.com> wrote:
>I need to view the attached  binary file. but can not read it, instead
>am 
>getting very weird( i think garbage) numbers. 
>
>The values are Temperature data so it should be somewhat in between 250
>to 
>500.
>
>Can any altruist view it and give me the R code to view it.
>
>I am attaching the file. Please help me if you can.
>
>TIA
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Apr 17 03:48:32 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 16 Apr 2017 18:48:32 -0700
Subject: [R] question about the anova() function for deviance analysis
In-Reply-To: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
References: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
Message-ID: <6B56C183-1EE4-4E39-9E7F-14D96DD4AC6D@dcn.davis.ca.us>

You are sending your email to a whole mailing list of volunteers, not a specific "maintainer" (and I am not one). However, your assertions convey unfamiliarity with statistics rather than deficiencies in R, and this mailing list is not a stats tutoring list. I did a quick Google search and found  [1], which might help you get started though. 

Also, your description should have included a minimal working example, so no it was not complete. It is difficult to discuss technical questions online without having very specific examples of what you did and what you expected (and perhaps why you expected that).  Read the Posting Guide for more advice on using the R mailing lists.

Don't forget that there are 10000+ contributed packages for use with R, and among them you may find alternate algorithms that suit your application better.  Try the "sos" search package or just use Google to find such options. If course, you have to have some understanding of the theory you are interested in to find them, but it isn't a good idea to treat any software as a black box so that should not really be an impediment if you are doing good quality research. 

[1] http://goanna.cs.rmit.edu.au/~fscholer/anova.php
-- 
Sent from my phone. Please excuse my brevity.

On April 16, 2017 6:46:52 AM PDT, Sophie Dubois <sophie.dubois at anastats.fr> wrote:
>Dear Maintener,
>> I have recently had a bad experience with the anova() function.
>> Indeed, I wanted to process a deviance analysis between 2 mixed
>linear
>> models and I was really surprise to see that depending on the ordre
>in
>> which I gave my models, the function did not the same thing: once it
>> makes the anova of the first model and in the other ordre, it makes a
>> deviance analysis.
>> I make lots of formations to researchers who are not always very
>> comfortable either with R or with some statistical analysis and they
>> were really very disturbed by that.
>> Could this be possible to "secure" this anova function in order that
>> it does the same thing whatever the order in which the models are
>given? 
>> Hope I was clear enought and many thanks in advance for your regard
>> about my question.
>> Best regards, Sophie
>
>--
>Sophie Dubois
>ANASTATS
>sophie.dubois at anastats.fr
>
>
>
>---
>L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le
>logiciel antivirus Avast.
>https://www.avast.com/antivirus
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Mon Apr 17 04:26:04 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Mon, 17 Apr 2017 07:56:04 +0530
Subject: [R] Return value from function with For loop
Message-ID: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>

In the code below


*ff <- function(n){ for(i in 1:n) (i+1)}*

*n<-3;ff(n)->op;print(op)*

Why doesnt *print(op) * print 4 and instead prints NULL.
Isnt the last line of code executed is *i+1 * and therefore that should be
returned instead of NULL

instead if I say
*ff <- function(n){ (n+1) }*

Then
*n<-3;ff(n)->op;rm(n);print(op)*
gives 4 as output.

My question is *Which *is considered as the last line in a functoin for the
purpsoe of default return ? And under what conditions ?

-Thanks,
Ramnik

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Apr 17 04:33:06 2017
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Apr 2017 22:33:06 -0400
Subject: [R] help on readBin in R
In-Reply-To: <EAF0A4FF-1866-4581-A914-161D059003AC@dcn.davis.ca.us>
References: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>
 <EAF0A4FF-1866-4581-A914-161D059003AC@dcn.davis.ca.us>
Message-ID: <CAAxdm-5EmmnkHvFeQ3aQsH47Kyb5WZmffZptdHfJr4AR2cs2yA@mail.gmail.com>

If the file is not too large, just change the extension to '.txt' and
attach it.  Also include the code that you are using to read it in and
a definition of the what the data is; e.g., first two byte are
temperature, next four bytes are a station ID, ....

Here is an example of reading in a binary file and I know that the
'raw' output matches the bytes that are in the file:

> infile <- file("test.txt", 'rb')
>
> input <- readBin(infile, raw(), 100)
>
> input
  [1] 50 4b 03 04 14 00 04 00 08 00 47 95 90 4a 9f 00 7a a0 99 01 00
00 7a 08 00 00 13 00 75 00 5b 43 6f
 [34] 6e 74 65 6e 74 5f 54 79 70 65 73 5d 2e 78 6d 6c 53 44 60 00 a4
00 00 00 00 08 00 32 fa a9 3f 63 64
 [67] 60 69 11 61 60 60 30 00 62 10 f0 01 62 46 56 30 93 55 14 48 55
e8 cd 15 fe e5 cf a3 df 6c ab ed 66
[100] b1
>

here is the dump:

$ od -a -t x --endian=big test.txt
0000000   P   K etx eot dc4 nul eot nul  bs nul   G nak dle   J  us nul
               504b0304        14000400        08004795        904a9f00
0000020   z  sp  em soh nul nul   z  bs nul nul dc3 nul   u nul   [   C
               7aa09901        00007a08        00001300        75005b43
0000040   o   n   t   e   n   t   _   T   y   p   e   s   ]   .   x   m
               6f6e7465        6e745f54        79706573        5d2e786d

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Apr 16, 2017 at 9:21 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The mailing list has tight restrictions on attachments, so your attachment was not let through. Read the Posting Guide, and note that sometimes success requires some extended understanding of how your mail software works, and we probably don't know the details either. You might have success changing the file extension or sending a link to the file on a file storage website like Google Drive or Dropbox.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 16, 2017 3:49:07 PM PDT, "M.M saifuddin" <mmsaifuddin09 at gmail.com> wrote:
>>I need to view the attached  binary file. but can not read it, instead
>>am
>>getting very weird( i think garbage) numbers.
>>
>>The values are Temperature data so it should be somewhat in between 250
>>to
>>500.
>>
>>Can any altruist view it and give me the R code to view it.
>>
>>I am attaching the file. Please help me if you can.
>>
>>TIA
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Apr 17 04:39:57 2017
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Apr 2017 22:39:57 -0400
Subject: [R] Return value from function with For loop
In-Reply-To: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
Message-ID: <CAAxdm-4CVoqjYJw1+kT9-66sXZPv1AFg9BrUpDFyq4SRMqrOEg@mail.gmail.com>

In the first case you have a "for" and it is the statement after the
'for' that is the return value and it is a NULL.  For example:

> print(for (i in 1:4) i+1)
NULL

In the second case, the last statement if the expression '(n+1)' which
give you the correct value:

> xx <- function(n) n+1
> print(xx(3))
[1] 4
>




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Apr 16, 2017 at 10:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> In the code below
>
>
> *ff <- function(n){ for(i in 1:n) (i+1)}*
>
> *n<-3;ff(n)->op;print(op)*
>
> Why doesnt *print(op) * print 4 and instead prints NULL.
> Isnt the last line of code executed is *i+1 * and therefore that should be
> returned instead of NULL
>
> instead if I say
> *ff <- function(n){ (n+1) }*
>
> Then
> *n<-3;ff(n)->op;rm(n);print(op)*
> gives 4 as output.
>
> My question is *Which *is considered as the last line in a functoin for the
> purpsoe of default return ? And under what conditions ?
>
> -Thanks,
> Ramnik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Apr 17 05:12:41 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Apr 2017 20:12:41 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
Message-ID: <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>


> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> 
> In the code below
> 
> 
> *ff <- function(n){ for(i in 1:n) (i+1)}*
> 
> *n<-3;ff(n)->op;print(op)*
> 
> Why doesnt *print(op) * print 4 and instead prints NULL.
> Isnt the last line of code executed is *i+1 * and therefore that should be
> returned instead of NULL
> 
> instead if I say
> *ff <- function(n){ (n+1) }*
> 
> Then
> *n<-3;ff(n)->op;rm(n);print(op)*
> gives 4 as output.
> 
> My question is *Which *is considered as the last line in a functoin for the
> purpsoe of default return ? And under what conditions ?

It's probably a good thing that you are confused. It suggests that you are actually "getting" the R-paradigm. Unfortunately for the new user of R, there are several levels of understanding to pass through. First, you realize that function-results need to be assigned to names in order to persist. Then there is the next level where you discover that there are exceptions to that rule: this levels is the level where you realize that the `for` function is different from most other R functions.  It is really a side-effect-fucntion. The assignments made within its body actually persist in the global environment. AND it returns NULL. It shares this anomalous behavior with `while` and `repeat`.n Almost all functions are invoked with a possibly empty argument list.  The next and break functions have implicit paired (empty) parentheses. 

(My personal opinion is that this is not adequately advertised. Perhaps it is an attempt to get people to migrate away from "Fortran-coding" behavior?)

-- 
David.


> 
> -Thanks,
> Ramnik
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Mon Apr 17 05:13:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 16 Apr 2017 20:13:49 -0700
Subject: [R] help on readBin in R
In-Reply-To: <CAAxdm-5EmmnkHvFeQ3aQsH47Kyb5WZmffZptdHfJr4AR2cs2yA@mail.gmail.com>
References: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>
 <EAF0A4FF-1866-4581-A914-161D059003AC@dcn.davis.ca.us>
 <CAAxdm-5EmmnkHvFeQ3aQsH47Kyb5WZmffZptdHfJr4AR2cs2yA@mail.gmail.com>
Message-ID: <FA849B49-58D9-454B-8AF6-B2F0C52247B6@dcn.davis.ca.us>

That may or may not work, since text file newlines get altered in them. May have more luck with a "png" extension? 
-- 
Sent from my phone. Please excuse my brevity.

On April 16, 2017 7:33:06 PM PDT, jim holtman <jholtman at gmail.com> wrote:
>If the file is not too large, just change the extension to '.txt' and
>attach it.  Also include the code that you are using to read it in and
>a definition of the what the data is; e.g., first two byte are
>temperature, next four bytes are a station ID, ....
>
>Here is an example of reading in a binary file and I know that the
>'raw' output matches the bytes that are in the file:
>
>> infile <- file("test.txt", 'rb')
>>
>> input <- readBin(infile, raw(), 100)
>>
>> input
>  [1] 50 4b 03 04 14 00 04 00 08 00 47 95 90 4a 9f 00 7a a0 99 01 00
>00 7a 08 00 00 13 00 75 00 5b 43 6f
> [34] 6e 74 65 6e 74 5f 54 79 70 65 73 5d 2e 78 6d 6c 53 44 60 00 a4
>00 00 00 00 08 00 32 fa a9 3f 63 64
> [67] 60 69 11 61 60 60 30 00 62 10 f0 01 62 46 56 30 93 55 14 48 55
>e8 cd 15 fe e5 cf a3 df 6c ab ed 66
>[100] b1
>>
>
>here is the dump:
>
>$ od -a -t x --endian=big test.txt
>0000000   P   K etx eot dc4 nul eot nul  bs nul   G nak dle   J  us nul
>               504b0304        14000400        08004795        904a9f00
>0000020   z  sp  em soh nul nul   z  bs nul nul dc3 nul   u nul   [   C
>               7aa09901        00007a08        00001300        75005b43
>0000040   o   n   t   e   n   t   _   T   y   p   e   s   ]   .   x   m
>               6f6e7465        6e745f54        79706573        5d2e786d
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>
>On Sun, Apr 16, 2017 at 9:21 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> The mailing list has tight restrictions on attachments, so your
>attachment was not let through. Read the Posting Guide, and note that
>sometimes success requires some extended understanding of how your mail
>software works, and we probably don't know the details either. You
>might have success changing the file extension or sending a link to the
>file on a file storage website like Google Drive or Dropbox.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 16, 2017 3:49:07 PM PDT, "M.M saifuddin"
><mmsaifuddin09 at gmail.com> wrote:
>>>I need to view the attached  binary file. but can not read it,
>instead
>>>am
>>>getting very weird( i think garbage) numbers.
>>>
>>>The values are Temperature data so it should be somewhat in between
>250
>>>to
>>>500.
>>>
>>>Can any altruist view it and give me the R code to view it.
>>>
>>>I am attaching the file. Please help me if you can.
>>>
>>>TIA
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr 17 06:50:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 16 Apr 2017 21:50:36 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
Message-ID: <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>

David et. al.:

"this levels is the level where you realize that the `for` function is
different from most other R functions.  It is really a
side-effect-fucntion. "

for(), while(), if(), next, etc. are *not* functions.

?for says: "These are the basic control-flow constructs of the R language."

They do not "return" values. They control program flow, whence what
you call "side effects" are actually expressions that are parsed and
evaluated

viz.

> if(TRUE)10
[1] 10

## but

>if(FALSE) 5
## nothing is returned, not even NULL
> for(i in 1:3) i
## Ditto

>  z <- NULL
> z <- for(i in 1:3)i
> z
NULL ## still

Cheers,
Bert




Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>>
>> In the code below
>>
>>
>> *ff <- function(n){ for(i in 1:n) (i+1)}*
>>
>> *n<-3;ff(n)->op;print(op)*
>>
>> Why doesnt *print(op) * print 4 and instead prints NULL.
>> Isnt the last line of code executed is *i+1 * and therefore that should be
>> returned instead of NULL
>>
>> instead if I say
>> *ff <- function(n){ (n+1) }*
>>
>> Then
>> *n<-3;ff(n)->op;rm(n);print(op)*
>> gives 4 as output.
>>
>> My question is *Which *is considered as the last line in a functoin for the
>> purpsoe of default return ? And under what conditions ?
>
> It's probably a good thing that you are confused. It suggests that you are actually "getting" the R-paradigm. Unfortunately for the new user of R, there are several levels of understanding to pass through. First, you realize that function-results need to be assigned to names in order to persist. Then there is the next level where you discover that there are exceptions to that rule: this levels is the level where you realize that the `for` function is different from most other R functions.  It is really a side-effect-fucntion. The assignments made within its body actually persist in the global environment. AND it returns NULL. It shares this anomalous behavior with `while` and `repeat`.n Almost all functions are invoked with a possibly empty argument list.  The next and break functions have implicit paired (empty) parentheses.
>
> (My personal opinion is that this is not adequately advertised. Perhaps it is an attempt to get people to migrate away from "Fortran-coding" behavior?)
>
> --
> David.
>
>
>>
>> -Thanks,
>> Ramnik
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Apr 17 08:36:12 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Apr 2017 23:36:12 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
Message-ID: <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>

Both 'for' and 'next' return TRUE from is.function 

is.function('for')
is.function('next')

Not at an R console at the moment but I did check this earlier today. Thinking of it as different is definitely the way to think about it. (ISTR Bert and I have had this exchange in the past.)

-- 
Best
David

Sent from my iPhone

> On Apr 16, 2017, at 9:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> David et. al.:
> 
> "this levels is the level where you realize that the `for` function is
> different from most other R functions.  It is really a
> side-effect-fucntion. "
> 
> for(), while(), if(), next, etc. are *not* functions.
> 
> ?for says: "These are the basic control-flow constructs of the R language."
> 
> They do not "return" values. They control program flow, whence what
> you call "side effects" are actually expressions that are parsed and
> evaluated
> 
> viz.
> 
>> if(TRUE)10
> [1] 10
> 
> ## but
> 
>> if(FALSE) 5
> ## nothing is returned, not even NULL
>> for(i in 1:3) i
> ## Ditto
> 
>> z <- NULL
>> z <- for(i in 1:3)i
>> z
> NULL ## still
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>>> 
>>> In the code below
>>> 
>>> 
>>> *ff <- function(n){ for(i in 1:n) (i+1)}*
>>> 
>>> *n<-3;ff(n)->op;print(op)*
>>> 
>>> Why doesnt *print(op) * print 4 and instead prints NULL.
>>> Isnt the last line of code executed is *i+1 * and therefore that should be
>>> returned instead of NULL
>>> 
>>> instead if I say
>>> *ff <- function(n){ (n+1) }*
>>> 
>>> Then
>>> *n<-3;ff(n)->op;rm(n);print(op)*
>>> gives 4 as output.
>>> 
>>> My question is *Which *is considered as the last line in a functoin for the
>>> purpsoe of default return ? And under what conditions ?
>> 
>> It's probably a good thing that you are confused. It suggests that you are actually "getting" the R-paradigm. Unfortunately for the new user of R, there are several levels of understanding to pass through. First, you realize that function-results need to be assigned to names in order to persist. Then there is the next level where you discover that there are exceptions to that rule: this levels is the level where you realize that the `for` function is different from most other R functions.  It is really a side-effect-fucntion. The assignments made within its body actually persist in the global environment. AND it returns NULL. It shares this anomalous behavior with `while` and `repeat`.n Almost all functions are invoked with a possibly empty argument list.  The next and break functions have implicit paired (empty) parentheses.
>> 
>> (My personal opinion is that this is not adequately advertised. Perhaps it is an attempt to get people to migrate away from "Fortran-coding" behavior?)
>> 
>> --
>> David.
>> 
>> 
>>> 
>>> -Thanks,
>>> Ramnik
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Mon Apr 17 10:04:36 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Mon, 17 Apr 2017 13:34:36 +0530
Subject: [R] Return value from function with For loop
In-Reply-To: <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
 <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>
Message-ID: <CAMLd9E4FhRUJzcG2dhRxL-KikCEXT33GsoYEwGWRyqc8NooLaw@mail.gmail.com>

This is my output for is.function

> is.function("for")
[1] FALSE
> is.function(for)
Error: unexpected ')' in "is.function(for)"
> is.function("next")
[1] FALSE
> is.function(next)
Error: no loop for break/next, jumping to top level

*I did not get the TRUE value. R version 3.3.3 on Mac. What am I doing
different ?*

Packages detail
> search()
 [1] ".GlobalEnv"        "package:pryr"
 [3] "tools:RGUI"        "package:stats"
 [5] "package:graphics"  "package:grDevices"
 [7] "package:utils"     "package:datasets"
 [9] "package:methods"   "Autoloads"
[11] "package:base"

thanks
Ramnik

On Mon, Apr 17, 2017 at 12:06 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

> Both 'for' and 'next' return TRUE from is.function
>
> is.function('for')
> is.function('next')
>
> Not at an R console at the moment but I did check this earlier today.
> Thinking of it as different is definitely the way to think about it. (ISTR
> Bert and I have had this exchange in the past.)
>
> --
> Best
> David
>
> Sent from my iPhone
>
> > On Apr 16, 2017, at 9:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > David et. al.:
> >
> > "this levels is the level where you realize that the `for` function is
> > different from most other R functions.  It is really a
> > side-effect-fucntion. "
> >
> > for(), while(), if(), next, etc. are *not* functions.
> >
> > ?for says: "These are the basic control-flow constructs of the R
> language."
> >
> > They do not "return" values. They control program flow, whence what
> > you call "side effects" are actually expressions that are parsed and
> > evaluated
> >
> > viz.
> >
> >> if(TRUE)10
> > [1] 10
> >
> > ## but
> >
> >> if(FALSE) 5
> > ## nothing is returned, not even NULL
> >> for(i in 1:3) i
> > ## Ditto
> >
> >> z <- NULL
> >> z <- for(i in 1:3)i
> >> z
> > NULL ## still
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> >>
> >>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com>
> wrote:
> >>>
> >>> In the code below
> >>>
> >>>
> >>> *ff <- function(n){ for(i in 1:n) (i+1)}*
> >>>
> >>> *n<-3;ff(n)->op;print(op)*
> >>>
> >>> Why doesnt *print(op) * print 4 and instead prints NULL.
> >>> Isnt the last line of code executed is *i+1 * and therefore that
> should be
> >>> returned instead of NULL
> >>>
> >>> instead if I say
> >>> *ff <- function(n){ (n+1) }*
> >>>
> >>> Then
> >>> *n<-3;ff(n)->op;rm(n);print(op)*
> >>> gives 4 as output.
> >>>
> >>> My question is *Which *is considered as the last line in a functoin
> for the
> >>> purpsoe of default return ? And under what conditions ?
> >>
> >> It's probably a good thing that you are confused. It suggests that you
> are actually "getting" the R-paradigm. Unfortunately for the new user of R,
> there are several levels of understanding to pass through. First, you
> realize that function-results need to be assigned to names in order to
> persist. Then there is the next level where you discover that there are
> exceptions to that rule: this levels is the level where you realize that
> the `for` function is different from most other R functions.  It is really
> a side-effect-fucntion. The assignments made within its body actually
> persist in the global environment. AND it returns NULL. It shares this
> anomalous behavior with `while` and `repeat`.n Almost all functions are
> invoked with a possibly empty argument list.  The next and break functions
> have implicit paired (empty) parentheses.
> >>
> >> (My personal opinion is that this is not adequately advertised. Perhaps
> it is an attempt to get people to migrate away from "Fortran-coding"
> behavior?)
> >>
> >> --
> >> David.
> >>
> >>
> >>>
> >>> -Thanks,
> >>> Ramnik
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 17 12:06:45 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Mon, 17 Apr 2017 06:06:45 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
Message-ID: <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>

David:
When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 16, 2017, at 3:43 PM, BR_email <br at dmstat1.com> wrote:
>> 
>> Peter:
>> Thanks for reply and suggestion.
>> Sorry, I am not sure how to assess.
>> The doc is too technical for me to understand.
>> I found multiple instructions online and in R and RStudio books.
>> I'm doing what it says, but no success.
> 
> What is "it" and what is "lack of success"?
> 
>> The instructions are simple as a-b-c, but some setting within the Windows system must be the culprit.
> 
> Although the RStudio page immediately below was done with a Mac, I suspect there are similar selection panels and dialogs on the Windows version of RStudio.
> 
> https://support.rstudio.com/hc/en-us/articles/200549016#general
> 
> When I look at the Windows installation advice I see near the top: "When installing on a 64-bit version of Windows the options will include 32- or 64-bit versions of R (and the default is to install both)." So is it possible that RStudio is looking at a different version of R than you believe it should be, perhaps at the 32 bit R versus the 64 bit one? The result at the beginning of this thread makes me think you got the 32-bit one connected to RStudio.
> 
> And I say again: I believe problems in configuring RStudio are off-topic for Rhelp and you should have been searching or posting question either to the RStudio support or StackOverflow. Looking at the responses to the queries above and the ones found below, it appears to me that there are RStudio-specific issues that go beyond what is in the `help(Startup)` or equivalent `help(.Rprofile)` page.  I gave an instance of an SO search upthread and I offer another SO search:
> 
> http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20environment%20variables%20windows
> 
> I thought that this one below had potentially useful information, but I am not a Windows user (and you have not shown an inclination in offering a complete description of your efforts at following that advice. At any rate it would have been more appropriate to respond to the SO answers that were ineffective or to post a question there with full description of your efforts and content of your .Rprofile file and your current environment variable settings.)
> 
> http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20rprofile%20windows
> 
> -- 
> David
> 
>> 
>> Regards,
>> Bruce
>> 
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>> 
>> peter dalgaard wrote:
>>> Um, tried help(.Rprofile) lately?
>>> 
>>> -pd
>>> 
>>>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>> 
>>>> 
>>>>> On 17/04/17 08:46, John C Frain wrote:
>>>>> 
>>>>> Bruce
>>>>> 
>>>>> The official documentation for these startup files can be obtained with
>>>>> the command
>>>>> 
>>>>> Help(Startup)
>>>> 
>>>> Minor point of order, Mr. Chairman.  That should be:
>>>> 
>>>>   help(Startup)
>>>> 
>>>> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
>>>> 
>>>> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
>>>> 
>>>> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
>>>> 
>>>> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
>>>> 
>>>>   help(startup)
>>>> 
>>>> fails.  You have to get that initial "S" right.
>>>> 
>>>> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf Turner
>>>> 
>>>> -- 
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 


From b.rowlingson at lancaster.ac.uk  Mon Apr 17 12:55:32 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 17 Apr 2017 11:55:32 +0100
Subject: [R] help on readBin in R
In-Reply-To: <1ca08c1e1347472d9421a6df73a94145@EX-0-HT0.lancs.local>
References: <c9b3b67b-3e6a-406e-8d3b-a1d6d030313d@googlegroups.com>
 <EAF0A4FF-1866-4581-A914-161D059003AC@dcn.davis.ca.us>
 <CAAxdm-5EmmnkHvFeQ3aQsH47Kyb5WZmffZptdHfJr4AR2cs2yA@mail.gmail.com>
 <1ca08c1e1347472d9421a6df73a94145@EX-0-HT0.lancs.local>
Message-ID: <CANVKczM6HQAE7dTPSU6Yi6F+M28d+GXniS7a16UD6A94-SS41g@mail.gmail.com>

There's very little justification for attaching binary files to a
mailing list these days - share it on Dropbox, or Box, or Hubic, or
whatever MS or Google's cloud storage is, or simply tell us where it
was obtained from originally.

And to the original poster - some more context is very useful - where
did you get it from, what area is it supposed to cover, etc etc.

I hope you don't want to do any serious science with a data file that
you have no provenance for.



On Mon, Apr 17, 2017 at 4:13 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> That may or may not work, since text file newlines get altered in them. May have more luck with a "png" extension?
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 16, 2017 7:33:06 PM PDT, jim holtman <jholtman at gmail.com> wrote:
>>If the file is not too large, just change the extension to '.txt' and
>>attach it.  Also include the code that you are using to read it in and
>>a definition of the what the data is; e.g., first two byte are
>>temperature, next four bytes are a station ID, ....
>>
>>Here is an example of reading in a binary file and I know that the
>>'raw' output matches the bytes that are in the file:
>>
>>> infile <- file("test.txt", 'rb')
>>>
>>> input <- readBin(infile, raw(), 100)
>>>
>>> input
>>  [1] 50 4b 03 04 14 00 04 00 08 00 47 95 90 4a 9f 00 7a a0 99 01 00
>>00 7a 08 00 00 13 00 75 00 5b 43 6f
>> [34] 6e 74 65 6e 74 5f 54 79 70 65 73 5d 2e 78 6d 6c 53 44 60 00 a4
>>00 00 00 00 08 00 32 fa a9 3f 63 64
>> [67] 60 69 11 61 60 60 30 00 62 10 f0 01 62 46 56 30 93 55 14 48 55
>>e8 cd 15 fe e5 cf a3 df 6c ab ed 66
>>[100] b1
>>>
>>
>>here is the dump:
>>
>>$ od -a -t x --endian=big test.txt
>>0000000   P   K etx eot dc4 nul eot nul  bs nul   G nak dle   J  us nul
>>               504b0304        14000400        08004795        904a9f00
>>0000020   z  sp  em soh nul nul   z  bs nul nul dc3 nul   u nul   [   C
>>               7aa09901        00007a08        00001300        75005b43
>>0000040   o   n   t   e   n   t   _   T   y   p   e   s   ]   .   x   m
>>               6f6e7465        6e745f54        79706573        5d2e786d
>>
>>Jim Holtman
>>Data Munger Guru
>>
>>What is the problem that you are trying to solve?
>>Tell me what you want to do, not how you want to do it.
>>
>>
>>On Sun, Apr 16, 2017 at 9:21 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> The mailing list has tight restrictions on attachments, so your
>>attachment was not let through. Read the Posting Guide, and note that
>>sometimes success requires some extended understanding of how your mail
>>software works, and we probably don't know the details either. You
>>might have success changing the file extension or sending a link to the
>>file on a file storage website like Google Drive or Dropbox.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 16, 2017 3:49:07 PM PDT, "M.M saifuddin"
>><mmsaifuddin09 at gmail.com> wrote:
>>>>I need to view the attached  binary file. but can not read it,
>>instead
>>>>am
>>>>getting very weird( i think garbage) numbers.
>>>>
>>>>The values are Temperature data so it should be somewhat in between
>>250
>>>>to
>>>>500.
>>>>
>>>>Can any altruist view it and give me the R code to view it.
>>>>
>>>>I am attaching the file. Please help me if you can.
>>>>
>>>>TIA
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Mon Apr 17 14:58:21 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 17 Apr 2017 18:28:21 +0530
Subject: [R] qqplot for binomial distribution
Message-ID: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>

Dear All,

set.seed(123)
qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )

I expect to see 1 clear line,but I don't. What am I misunderstanding?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Mon Apr 17 15:01:47 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Mon, 17 Apr 2017 08:01:47 -0500
Subject: [R] qqplot for binomial distribution
In-Reply-To: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
Message-ID: <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>



On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
> Dear All,
>
> set.seed(123)
> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
>
> I expect to see 1 clear line,but I don't. What am I misunderstanding?


       The distribution is discrete, and points are superimposed. Try 
the following:


set.seed(123)
qqplot(jitter(rbinom(n=100,size=100,p=.05)),
        jitter(rbinom(n=100,size=100,p=.05) ))


       Spencer Graves
>
> Best Regards,
> Ashim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Mon Apr 17 15:15:36 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 17 Apr 2017 18:45:36 +0530
Subject: [R] qqplot for binomial distribution
In-Reply-To: <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
Message-ID: <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>

Dear Spencer,

Okay. Many thanks. My next query is how do I use qqline?

When I try

> qqline(rbinom(n=100,size=100,p=.05))

I don't get the line in the right place.

Best Regards,
Ashim

On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
>
>> Dear All,
>>
>> set.seed(123)
>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
>>
>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
>>
>
>
>       The distribution is discrete, and points are superimposed. Try the
> following:
>
>
> set.seed(123)
> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
>        jitter(rbinom(n=100,size=100,p=.05) ))
>
>
>       Spencer Graves
>
>>
>> Best Regards,
>> Ashim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Apr 17 15:15:37 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 17 Apr 2017 09:15:37 -0400
Subject: [R] qqplot for binomial distribution
In-Reply-To: <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
Message-ID: <74CEEBC3-A873-4E9E-BE5D-9E82B96FFF62@utoronto.ca>

Moreover, setting the seed once, then evaluating two functions means you are sampling from the same distributions, but you do in fact have different values. Outliers in the rarefied tails of the distribution may lie quite considerably off the expected diagonal. Try

set.seed(123)
qqplot(rbinom(n=1000, size=1000, p=0.05),
       rbinom(n=1000, size=1000, p=0.05))

and you will find that you approximate the "1 clear line" quite well - for most of the values.


B.




> On Apr 17, 2017, at 9:01 AM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> 
> 
> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
>> Dear All,
>> 
>> set.seed(123)
>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
>> 
>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
> 
> 
>      The distribution is discrete, and points are superimposed. Try the following:
> 
> 
> set.seed(123)
> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
>       jitter(rbinom(n=100,size=100,p=.05) ))
> 
> 
>      Spencer Graves
>> 
>> Best Regards,
>> Ashim
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Mon Apr 17 15:26:13 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 17 Apr 2017 18:56:13 +0530
Subject: [R] qqplot for binomial distribution
In-Reply-To: <74CEEBC3-A873-4E9E-BE5D-9E82B96FFF62@utoronto.ca>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <74CEEBC3-A873-4E9E-BE5D-9E82B96FFF62@utoronto.ca>
Message-ID: <CAC8=1eo72XjJvtinVxr1dJ4a6C=aUGY+-wJYUMdowZi7UyP3Jg@mail.gmail.com>

Dear Boris,

Okay and Thanks.

Best,
Ashim

On Mon, Apr 17, 2017 at 6:45 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Moreover, setting the seed once, then evaluating two functions means you
> are sampling from the same distributions, but you do in fact have different
> values. Outliers in the rarefied tails of the distribution may lie quite
> considerably off the expected diagonal. Try
>
> set.seed(123)
> qqplot(rbinom(n=1000, size=1000, p=0.05),
>        rbinom(n=1000, size=1000, p=0.05))
>
> and you will find that you approximate the "1 clear line" quite well - for
> most of the values.
>
>
> B.
>
>
>
>
> > On Apr 17, 2017, at 9:01 AM, Spencer Graves <spencer.graves@
> effectivedefense.org> wrote:
> >
> >
> >
> > On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
> >> Dear All,
> >>
> >> set.seed(123)
> >> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
> >>
> >> I expect to see 1 clear line,but I don't. What am I misunderstanding?
> >
> >
> >      The distribution is discrete, and points are superimposed. Try the
> following:
> >
> >
> > set.seed(123)
> > qqplot(jitter(rbinom(n=100,size=100,p=.05)),
> >       jitter(rbinom(n=100,size=100,p=.05) ))
> >
> >
> >      Spencer Graves
> >>
> >> Best Regards,
> >> Ashim
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Apr 17 15:46:02 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 17 Apr 2017 15:46:02 +0200
Subject: [R] Return value from function with For loop
In-Reply-To: <CAMLd9E4FhRUJzcG2dhRxL-KikCEXT33GsoYEwGWRyqc8NooLaw@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
 <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>
 <CAMLd9E4FhRUJzcG2dhRxL-KikCEXT33GsoYEwGWRyqc8NooLaw@mail.gmail.com>
Message-ID: <20457CA8-8E28-4742-8CDF-A02765D16902@gmail.com>


> On 17 Apr 2017, at 10:04 , Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> 
> This is my output for is.function
> 
>> is.function("for")
> [1] FALSE
>> is.function(for)
> Error: unexpected ')' in "is.function(for)"
>> is.function("next")
> [1] FALSE
>> is.function(next)
> Error: no loop for break/next, jumping to top level
> 
> *I did not get the TRUE value. R version 3.3.3 on Mac. What am I doing
> different ?*

You need backticks:

> is.function(`for`)
[1] TRUE
> is.function(`next`)
[1] TRUE
> `for`
.Primitive("for")
> `next`
.Primitive("next")

David either should have typed backticks, or he did type them, only to have a friendly e-mail client autocorrect them into quotes...

-pd

> 
> Packages detail
>> search()
> [1] ".GlobalEnv"        "package:pryr"
> [3] "tools:RGUI"        "package:stats"
> [5] "package:graphics"  "package:grDevices"
> [7] "package:utils"     "package:datasets"
> [9] "package:methods"   "Autoloads"
> [11] "package:base"
> 
> thanks
> Ramnik
> 
> On Mon, Apr 17, 2017 at 12:06 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> Both 'for' and 'next' return TRUE from is.function
>> 
>> is.function('for')
>> is.function('next')
>> 
>> Not at an R console at the moment but I did check this earlier today.
>> Thinking of it as different is definitely the way to think about it. (ISTR
>> Bert and I have had this exchange in the past.)
>> 
>> --
>> Best
>> David
>> 
>> Sent from my iPhone
>> 
>>> On Apr 16, 2017, at 9:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> David et. al.:
>>> 
>>> "this levels is the level where you realize that the `for` function is
>>> different from most other R functions.  It is really a
>>> side-effect-fucntion. "
>>> 
>>> for(), while(), if(), next, etc. are *not* functions.
>>> 
>>> ?for says: "These are the basic control-flow constructs of the R
>> language."
>>> 
>>> They do not "return" values. They control program flow, whence what
>>> you call "side effects" are actually expressions that are parsed and
>>> evaluated
>>> 
>>> viz.
>>> 
>>>> if(TRUE)10
>>> [1] 10
>>> 
>>> ## but
>>> 
>>>> if(FALSE) 5
>>> ## nothing is returned, not even NULL
>>>> for(i in 1:3) i
>>> ## Ditto
>>> 
>>>> z <- NULL
>>>> z <- for(i in 1:3)i
>>>> z
>>> NULL ## still
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>>> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <
>> dwinsemius at comcast.net> wrote:
>>>> 
>>>>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com>
>> wrote:
>>>>> 
>>>>> In the code below
>>>>> 
>>>>> 
>>>>> *ff <- function(n){ for(i in 1:n) (i+1)}*
>>>>> 
>>>>> *n<-3;ff(n)->op;print(op)*
>>>>> 
>>>>> Why doesnt *print(op) * print 4 and instead prints NULL.
>>>>> Isnt the last line of code executed is *i+1 * and therefore that
>> should be
>>>>> returned instead of NULL
>>>>> 
>>>>> instead if I say
>>>>> *ff <- function(n){ (n+1) }*
>>>>> 
>>>>> Then
>>>>> *n<-3;ff(n)->op;rm(n);print(op)*
>>>>> gives 4 as output.
>>>>> 
>>>>> My question is *Which *is considered as the last line in a functoin
>> for the
>>>>> purpsoe of default return ? And under what conditions ?
>>>> 
>>>> It's probably a good thing that you are confused. It suggests that you
>> are actually "getting" the R-paradigm. Unfortunately for the new user of R,
>> there are several levels of understanding to pass through. First, you
>> realize that function-results need to be assigned to names in order to
>> persist. Then there is the next level where you discover that there are
>> exceptions to that rule: this levels is the level where you realize that
>> the `for` function is different from most other R functions.  It is really
>> a side-effect-fucntion. The assignments made within its body actually
>> persist in the global environment. AND it returns NULL. It shares this
>> anomalous behavior with `while` and `repeat`.n Almost all functions are
>> invoked with a possibly empty argument list.  The next and break functions
>> have implicit paired (empty) parentheses.
>>>> 
>>>> (My personal opinion is that this is not adequately advertised. Perhaps
>> it is an attempt to get people to migrate away from "Fortran-coding"
>> behavior?)
>>>> 
>>>> --
>>>> David.
>>>> 
>>>> 
>>>>> 
>>>>> -Thanks,
>>>>> Ramnik
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter.4567 at gmail.com  Mon Apr 17 16:13:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 07:13:19 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
 <794A1F68-3F64-403D-8E66-A76CCB122D23@comcast.net>
Message-ID: <CAGxFJbQfYaheBBgyxxLw0m=XWSbfKvqxbiPcF5nyLJNqORAaUw@mail.gmail.com>

OK. I stand corrected. Thanks.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 16, 2017 at 11:36 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
> Both 'for' and 'next' return TRUE from is.function
>
> is.function('for')
> is.function('next')
>
> Not at an R console at the moment but I did check this earlier today. Thinking of it as different is definitely the way to think about it. (ISTR Bert and I have had this exchange in the past.)
>
> --
> Best
> David
>
> Sent from my iPhone
>
>> On Apr 16, 2017, at 9:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> David et. al.:
>>
>> "this levels is the level where you realize that the `for` function is
>> different from most other R functions.  It is really a
>> side-effect-fucntion. "
>>
>> for(), while(), if(), next, etc. are *not* functions.
>>
>> ?for says: "These are the basic control-flow constructs of the R language."
>>
>> They do not "return" values. They control program flow, whence what
>> you call "side effects" are actually expressions that are parsed and
>> evaluated
>>
>> viz.
>>
>>> if(TRUE)10
>> [1] 10
>>
>> ## but
>>
>>> if(FALSE) 5
>> ## nothing is returned, not even NULL
>>> for(i in 1:3) i
>> ## Ditto
>>
>>> z <- NULL
>>> z <- for(i in 1:3)i
>>> z
>> NULL ## still
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>>>>
>>>> In the code below
>>>>
>>>>
>>>> *ff <- function(n){ for(i in 1:n) (i+1)}*
>>>>
>>>> *n<-3;ff(n)->op;print(op)*
>>>>
>>>> Why doesnt *print(op) * print 4 and instead prints NULL.
>>>> Isnt the last line of code executed is *i+1 * and therefore that should be
>>>> returned instead of NULL
>>>>
>>>> instead if I say
>>>> *ff <- function(n){ (n+1) }*
>>>>
>>>> Then
>>>> *n<-3;ff(n)->op;rm(n);print(op)*
>>>> gives 4 as output.
>>>>
>>>> My question is *Which *is considered as the last line in a functoin for the
>>>> purpsoe of default return ? And under what conditions ?
>>>
>>> It's probably a good thing that you are confused. It suggests that you are actually "getting" the R-paradigm. Unfortunately for the new user of R, there are several levels of understanding to pass through. First, you realize that function-results need to be assigned to names in order to persist. Then there is the next level where you discover that there are exceptions to that rule: this levels is the level where you realize that the `for` function is different from most other R functions.  It is really a side-effect-fucntion. The assignments made within its body actually persist in the global environment. AND it returns NULL. It shares this anomalous behavior with `while` and `repeat`.n Almost all functions are invoked with a possibly empty argument list.  The next and break functions have implicit paired (empty) parentheses.
>>>
>>> (My personal opinion is that this is not adequately advertised. Perhaps it is an attempt to get people to migrate away from "Fortran-coding" behavior?)
>>>
>>> --
>>> David.
>>>
>>>
>>>>
>>>> -Thanks,
>>>> Ramnik
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Mon Apr 17 16:21:11 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 17 Apr 2017 10:21:11 -0400
Subject: [R] qqplot for binomial distribution
In-Reply-To: <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
Message-ID: <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>

That's not how qqline() works. The line is drawn with respect to a _reference_distribution_ which is the normal distribution by default. For the binomial distribution, you need to specify the distribution argument. There is an example in the help page that shows you how this is done for qchisq(). for qbinom() it is:


set.seed(123)
qqplot(rbinom(n=100, size=100, p=0.05), 
       rbinom(n=100, size=100, p=0.05) )
 
qqline(rbinom(n=100,size=100,p=.05),
       distribution = function(probs) { qbinom(probs, size=100, prob=0.05) },
       col = "red",
       lwd = 0.5)




B.


> On Apr 17, 2017, at 9:15 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear Spencer,
> 
> Okay. Many thanks. My next query is how do I use qqline?
> 
> When I try
> 
>> qqline(rbinom(n=100,size=100,p=.05))
> 
> I don't get the line in the right place.
> 
> Best Regards,
> Ashim
> 
> On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
> spencer.graves at effectivedefense.org> wrote:
> 
>> 
>> 
>> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
>> 
>>> Dear All,
>>> 
>>> set.seed(123)
>>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
>>> 
>>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
>>> 
>> 
>> 
>>      The distribution is discrete, and points are superimposed. Try the
>> following:
>> 
>> 
>> set.seed(123)
>> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
>>       jitter(rbinom(n=100,size=100,p=.05) ))
>> 
>> 
>>      Spencer Graves
>> 
>>> 
>>> Best Regards,
>>> Ashim
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr 17 16:25:48 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 07:25:48 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <CAMLd9E7khuOhzD324HOkvG71FA2kq1W50Hh5Ran_aT1f3vEsBA@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
 <CAMLd9E7khuOhzD324HOkvG71FA2kq1W50Hh5Ran_aT1f3vEsBA@mail.gmail.com>
Message-ID: <CAGxFJbQjTA=Z4vh-+eq9ejpCbg6sZPNDLcU_-C8cNNBR2s9rqg@mail.gmail.com>

(Apparently I hit "send" too early)

1. I have cc'ed this to the list, as others may well have some good
suggestions re: books.

2. The posting guide is your best resource as to what is appropriate
for the list. I defer to others re: conventions, as I have have been
accused of violating them from time to time.

3. R resources abound. RStudio has some recommendations for web
resource on their site worth checking out:

https://www.rstudio.com/online-learning/#R

But there are many others that a search would reveal.

Hadley Wickham has written a couple of books worth checking. I think
that the O'Reilly series might have one or more. It is of course
difficult to judge what "a good book for a newbie" would be in your
mind, but it is hard for me to believe that there aren't at least
several out there.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 1:06 AM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> Thanks Bert for the reply. It cleared my confusion .
>
> Also am new to the mailing list. Can you please guide me to the mailing list
> norms. For e.g. when I get a reply to my query which imparts me a better
> understanding on the topic, is it a norm to thank the individuals who
> responded, thru a personal mail ? Or it is kind of taken for granted that
> the question has been replied to and an individual thanks-reply to reply is
> not even expected as it will increase the number of mails.
>
> Also what seems to be missing is a good book on R which talks about all
> these nuances even for a newbie who wants to master R. Or maybe am unaware
> of one such book.
>
> -Best
> Ramnik
>
>
> On Mon, Apr 17, 2017 at 10:20 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> David et. al.:
>>
>> "this levels is the level where you realize that the `for` function is
>> different from most other R functions.  It is really a
>> side-effect-fucntion. "
>>
>> for(), while(), if(), next, etc. are *not* functions.
>>
>> ?for says: "These are the basic control-flow constructs of the R
>> language."
>>
>> They do not "return" values. They control program flow, whence what
>> you call "side effects" are actually expressions that are parsed and
>> evaluated
>>
>> viz.
>>
>> > if(TRUE)10
>> [1] 10
>>
>> ## but
>>
>> >if(FALSE) 5
>> ## nothing is returned, not even NULL
>> > for(i in 1:3) i
>> ## Ditto
>>
>> >  z <- NULL
>> > z <- for(i in 1:3)i
>> > z
>> NULL ## still
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> >
>> >> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com>
>> >> wrote:
>> >>
>> >> In the code below
>> >>
>> >>
>> >> *ff <- function(n){ for(i in 1:n) (i+1)}*
>> >>
>> >> *n<-3;ff(n)->op;print(op)*
>> >>
>> >> Why doesnt *print(op) * print 4 and instead prints NULL.
>> >> Isnt the last line of code executed is *i+1 * and therefore that should
>> >> be
>> >> returned instead of NULL
>> >>
>> >> instead if I say
>> >> *ff <- function(n){ (n+1) }*
>> >>
>> >> Then
>> >> *n<-3;ff(n)->op;rm(n);print(op)*
>> >> gives 4 as output.
>> >>
>> >> My question is *Which *is considered as the last line in a functoin for
>> >> the
>> >> purpsoe of default return ? And under what conditions ?
>> >
>> > It's probably a good thing that you are confused. It suggests that you
>> > are actually "getting" the R-paradigm. Unfortunately for the new user of R,
>> > there are several levels of understanding to pass through. First, you
>> > realize that function-results need to be assigned to names in order to
>> > persist. Then there is the next level where you discover that there are
>> > exceptions to that rule: this levels is the level where you realize that the
>> > `for` function is different from most other R functions.  It is really a
>> > side-effect-fucntion. The assignments made within its body actually persist
>> > in the global environment. AND it returns NULL. It shares this anomalous
>> > behavior with `while` and `repeat`.n Almost all functions are invoked with a
>> > possibly empty argument list.  The next and break functions have implicit
>> > paired (empty) parentheses.
>> >
>> > (My personal opinion is that this is not adequately advertised. Perhaps
>> > it is an attempt to get people to migrate away from "Fortran-coding"
>> > behavior?)
>> >
>> > --
>> > David.
>> >
>> >
>> >>
>> >> -Thanks,
>> >> Ramnik
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From bgunter.4567 at gmail.com  Mon Apr 17 16:30:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 07:30:57 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
Message-ID: <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>

I cannot add to the instructions that you have already been given
regarding .Rprofile.

But what code did you use in your .Rprofile to set the prompt? The
posting guide explicitly requests that you provide your code, although
maybe you already did earlier in this extensive thread.

?options

is how it can be set. Did you do this?

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> David:
> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
> Bruce
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Apr 16, 2017, at 3:43 PM, BR_email <br at dmstat1.com> wrote:
>>>
>>> Peter:
>>> Thanks for reply and suggestion.
>>> Sorry, I am not sure how to assess.
>>> The doc is too technical for me to understand.
>>> I found multiple instructions online and in R and RStudio books.
>>> I'm doing what it says, but no success.
>>
>> What is "it" and what is "lack of success"?
>>
>>> The instructions are simple as a-b-c, but some setting within the Windows system must be the culprit.
>>
>> Although the RStudio page immediately below was done with a Mac, I suspect there are similar selection panels and dialogs on the Windows version of RStudio.
>>
>> https://support.rstudio.com/hc/en-us/articles/200549016#general
>>
>> When I look at the Windows installation advice I see near the top: "When installing on a 64-bit version of Windows the options will include 32- or 64-bit versions of R (and the default is to install both)." So is it possible that RStudio is looking at a different version of R than you believe it should be, perhaps at the 32 bit R versus the 64 bit one? The result at the beginning of this thread makes me think you got the 32-bit one connected to RStudio.
>>
>> And I say again: I believe problems in configuring RStudio are off-topic for Rhelp and you should have been searching or posting question either to the RStudio support or StackOverflow. Looking at the responses to the queries above and the ones found below, it appears to me that there are RStudio-specific issues that go beyond what is in the `help(Startup)` or equivalent `help(.Rprofile)` page.  I gave an instance of an SO search upthread and I offer another SO search:
>>
>> http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20environment%20variables%20windows
>>
>> I thought that this one below had potentially useful information, but I am not a Windows user (and you have not shown an inclination in offering a complete description of your efforts at following that advice. At any rate it would have been more appropriate to respond to the SO answers that were ineffective or to post a question there with full description of your efforts and content of your .Rprofile file and your current environment variable settings.)
>>
>> http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20rprofile%20windows
>>
>> --
>> David
>>
>>>
>>> Regards,
>>> Bruce
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>> peter dalgaard wrote:
>>>> Um, tried help(.Rprofile) lately?
>>>>
>>>> -pd
>>>>
>>>>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>>
>>>>>
>>>>>> On 17/04/17 08:46, John C Frain wrote:
>>>>>>
>>>>>> Bruce
>>>>>>
>>>>>> The official documentation for these startup files can be obtained with
>>>>>> the command
>>>>>>
>>>>>> Help(Startup)
>>>>>
>>>>> Minor point of order, Mr. Chairman.  That should be:
>>>>>
>>>>>   help(Startup)
>>>>>
>>>>> There is (as far as I know) no such function as "Help()".  It is important to remember that R is case sensitive.
>>>>>
>>>>> Another point that is worthy of thought is "How in God's name would any beginner know or find out about the usage help(Startup)?"  Unless they were explicitly told about it, in the manner which you just demonstrated.  The usage gets a mention in "An Introduction to R" --- but I had to search for it.
>>>>>
>>>>> To me the word "startup" is not terribly intuitive.  I would tend to search for "starting" rather than "startup", I think, but I'm not sure what the average beginner would search for.  A search of "An Introduction to R" for "starting" gets seven or eight hits, one of which is relevant.  So it all takes patience and persistence.
>>>>>
>>>>> Also note that "An Introduction to R" mostly uses the word "startup" (lower case "s") and only uses "Startup" twice.  Note also that
>>>>>
>>>>>   help(startup)
>>>>>
>>>>> fails.  You have to get that initial "S" right.
>>>>>
>>>>> This isn't a criticism of the documentation.  I'm just pointing out that there are problems, mostly insoluble.  Until some clever Johnny gets on with developing that mind_read() function referred to in fortune(182).
>>>>>
>>>>> cheers,
>>>>>
>>>>> Rolf Turner
>>>>>
>>>>> --
>>>>> Technical Editor ANZJS
>>>>> Department of Statistics
>>>>> University of Auckland
>>>>> Phone: +64-9-373-7599 ext. 88276
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Apr 17 16:36:28 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 17 Apr 2017 10:36:28 -0400
Subject: [R] Return value from function with For loop
In-Reply-To: <CAGxFJbQjTA=Z4vh-+eq9ejpCbg6sZPNDLcU_-C8cNNBR2s9rqg@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
 <EDC7D8AE-7A3B-4858-8C63-6C78AC796498@comcast.net>
 <CAGxFJbRhi_1zReRZG5Kkjo-sr7KLDnLt2YW5uO3X+rUvLCyddA@mail.gmail.com>
 <CAMLd9E7khuOhzD324HOkvG71FA2kq1W50Hh5Ran_aT1f3vEsBA@mail.gmail.com>
 <CAGxFJbQjTA=Z4vh-+eq9ejpCbg6sZPNDLcU_-C8cNNBR2s9rqg@mail.gmail.com>
Message-ID: <E31D3E0E-76AD-4E5D-9107-696642BF6624@utoronto.ca>

Ramnik,
a final mail is actually really important: this is to document in the archives, for the benefit of those who found the thread at a later time, that the responses indeed solved the problem. 

Other than that, the single most important advice is to
- provide a minimal working example of the problem;
- state clearly what you expect;
- state explicitly what happened instead.

Apparently you're doing fine in that regard.


B.


> On Apr 17, 2017, at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> (Apparently I hit "send" too early)
> 
> 1. I have cc'ed this to the list, as others may well have some good
> suggestions re: books.
> 
> 2. The posting guide is your best resource as to what is appropriate
> for the list. I defer to others re: conventions, as I have have been
> accused of violating them from time to time.
> 
> 3. R resources abound. RStudio has some recommendations for web
> resource on their site worth checking out:
> 
> https://www.rstudio.com/online-learning/#R
> 
> But there are many others that a search would reveal.
> 
> Hadley Wickham has written a couple of books worth checking. I think
> that the O'Reilly series might have one or more. It is of course
> difficult to judge what "a good book for a newbie" would be in your
> mind, but it is hard for me to believe that there aren't at least
> several out there.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Apr 17, 2017 at 1:06 AM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>> Thanks Bert for the reply. It cleared my confusion .
>> 
>> Also am new to the mailing list. Can you please guide me to the mailing list
>> norms. For e.g. when I get a reply to my query which imparts me a better
>> understanding on the topic, is it a norm to thank the individuals who
>> responded, thru a personal mail ? Or it is kind of taken for granted that
>> the question has been replied to and an individual thanks-reply to reply is
>> not even expected as it will increase the number of mails.
>> 
>> Also what seems to be missing is a good book on R which talks about all
>> these nuances even for a newbie who wants to master R. Or maybe am unaware
>> of one such book.
>> 
>> -Best
>> Ramnik
>> 
>> 
>> On Mon, Apr 17, 2017 at 10:20 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>> 
>>> David et. al.:
>>> 
>>> "this levels is the level where you realize that the `for` function is
>>> different from most other R functions.  It is really a
>>> side-effect-fucntion. "
>>> 
>>> for(), while(), if(), next, etc. are *not* functions.
>>> 
>>> ?for says: "These are the basic control-flow constructs of the R
>>> language."
>>> 
>>> They do not "return" values. They control program flow, whence what
>>> you call "side effects" are actually expressions that are parsed and
>>> evaluated
>>> 
>>> viz.
>>> 
>>>> if(TRUE)10
>>> [1] 10
>>> 
>>> ## but
>>> 
>>>> if(FALSE) 5
>>> ## nothing is returned, not even NULL
>>>> for(i in 1:3) i
>>> ## Ditto
>>> 
>>>> z <- NULL
>>>> z <- for(i in 1:3)i
>>>> z
>>> NULL ## still
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, Apr 16, 2017 at 8:12 PM, David Winsemius <dwinsemius at comcast.net>
>>> wrote:
>>>> 
>>>>> On Apr 16, 2017, at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>> wrote:
>>>>> 
>>>>> In the code below
>>>>> 
>>>>> 
>>>>> *ff <- function(n){ for(i in 1:n) (i+1)}*
>>>>> 
>>>>> *n<-3;ff(n)->op;print(op)*
>>>>> 
>>>>> Why doesnt *print(op) * print 4 and instead prints NULL.
>>>>> Isnt the last line of code executed is *i+1 * and therefore that should
>>>>> be
>>>>> returned instead of NULL
>>>>> 
>>>>> instead if I say
>>>>> *ff <- function(n){ (n+1) }*
>>>>> 
>>>>> Then
>>>>> *n<-3;ff(n)->op;rm(n);print(op)*
>>>>> gives 4 as output.
>>>>> 
>>>>> My question is *Which *is considered as the last line in a functoin for
>>>>> the
>>>>> purpsoe of default return ? And under what conditions ?
>>>> 
>>>> It's probably a good thing that you are confused. It suggests that you
>>>> are actually "getting" the R-paradigm. Unfortunately for the new user of R,
>>>> there are several levels of understanding to pass through. First, you
>>>> realize that function-results need to be assigned to names in order to
>>>> persist. Then there is the next level where you discover that there are
>>>> exceptions to that rule: this levels is the level where you realize that the
>>>> `for` function is different from most other R functions.  It is really a
>>>> side-effect-fucntion. The assignments made within its body actually persist
>>>> in the global environment. AND it returns NULL. It shares this anomalous
>>>> behavior with `while` and `repeat`.n Almost all functions are invoked with a
>>>> possibly empty argument list.  The next and break functions have implicit
>>>> paired (empty) parentheses.
>>>> 
>>>> (My personal opinion is that this is not adequately advertised. Perhaps
>>>> it is an attempt to get people to migrate away from "Fortran-coding"
>>>> behavior?)
>>>> 
>>>> --
>>>> David.
>>>> 
>>>> 
>>>>> 
>>>>> -Thanks,
>>>>> Ramnik
>>>>> 
>>>>>      [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Mon Apr 17 16:41:18 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Mon, 17 Apr 2017 10:41:18 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
Message-ID: <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>

Bert:
I used note pad under Administrator. The code:
options(prompt="R> ")
set.seed(12345)

Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I cannot add to the instructions that you have already been given
> regarding .Rprofile.
> 
> But what code did you use in your .Rprofile to set the prompt? The
> posting guide explicitly requests that you provide your code, although
> maybe you already did earlier in this extensive thread.
> 
> ?options
> 
> is how it can be set. Did you do this?
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> David:
>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
>> Bruce
>> 
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>> 
>> 
>> 
>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
> 


From murdoch.duncan at gmail.com  Mon Apr 17 16:43:53 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 17 Apr 2017 10:43:53 -0400
Subject: [R] question about the anova() function for deviance analysis
In-Reply-To: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
References: <00e7de8a-cab6-6627-e0eb-ca640ea737f1@anastats.fr>
Message-ID: <d361b470-47ad-2bd0-bf07-9ee4f446c9e8@gmail.com>

On 16/04/2017 9:46 AM, Sophie Dubois wrote:
> Dear Maintener,
>> I have recently had a bad experience with the anova() function.
>> Indeed, I wanted to process a deviance analysis between 2 mixed linear
>> models and I was really surprise to see that depending on the ordre in
>> which I gave my models, the function did not the same thing: once it
>> makes the anova of the first model and in the other ordre, it makes a
>> deviance analysis.
>> I make lots of formations to researchers who are not always very
>> comfortable either with R or with some statistical analysis and they
>> were really very disturbed by that.
>> Could this be possible to "secure" this anova function in order that
>> it does the same thing whatever the order in which the models are given?
>> Hope I was clear enought and many thanks in advance for your regard
>> about my question.

Could you please post a simple example?  I am guessing that the models 
you are comparing are from different modelling functions, so different 
anova methods were called (it's the first argument that determines what 
is called), but I'm not at all sure without seeing an example.

It doesn't need to be your original data, in fact simpler is better, but 
it should be code that anyone can run.

Duncan Murdoch


From wdunlap at tibco.com  Mon Apr 17 17:06:45 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:06:45 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
Message-ID: <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>

I believe someone already mentioned it, but notepad makes it hard to
save a file without the ".txt" extension to its name.  R does not do
anything with .Rprofile.txt, only .Rprofile, so you must figure out a
way to work around notepad's mangling of the file name.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> Bert:
> I used note pad under Administrator. The code:
> options(prompt="R> ")
> set.seed(12345)
>
> Bruce
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> I cannot add to the instructions that you have already been given
>> regarding .Rprofile.
>>
>> But what code did you use in your .Rprofile to set the prompt? The
>> posting guide explicitly requests that you provide your code, although
>> maybe you already did earlier in this extensive thread.
>>
>> ?options
>>
>> is how it can be set. Did you do this?
>>
>> -- Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>> David:
>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
>>> Bruce
>>>
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Mon Apr 17 17:12:02 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 17 Apr 2017 08:12:02 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
Message-ID: <CAFDcVCROr0mV=feZhhZDfZmHzSqgYtq=z9meEEMxUDbxWm=Wsg@mail.gmail.com>

Did you try any of the troubleshooting I suggested? If you do that, I'm
99.99% certain it'll help you to resolve this.

Henrik


On Apr 17, 2017 03:07, "Bruce Ratner PhD" <br at dmstat1.com> wrote:

David:
When I launch Rstudio the effects of the Rprofile do not show, e.g., I want
the prompt to be "R> " instead of the default "> ". The former doesn't show.
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
wrote:
>
>
>> On Apr 16, 2017, at 3:43 PM, BR_email <br at dmstat1.com> wrote:
>>
>> Peter:
>> Thanks for reply and suggestion.
>> Sorry, I am not sure how to assess.
>> The doc is too technical for me to understand.
>> I found multiple instructions online and in R and RStudio books.
>> I'm doing what it says, but no success.
>
> What is "it" and what is "lack of success"?
>
>> The instructions are simple as a-b-c, but some setting within the
Windows system must be the culprit.
>
> Although the RStudio page immediately below was done with a Mac, I
suspect there are similar selection panels and dialogs on the Windows
version of RStudio.
>
> https://support.rstudio.com/hc/en-us/articles/200549016#general
>
> When I look at the Windows installation advice I see near the top: "When
installing on a 64-bit version of Windows the options will include 32- or
64-bit versions of R (and the default is to install both)." So is it
possible that RStudio is looking at a different version of R than you
believe it should be, perhaps at the 32 bit R versus the 64 bit one? The
result at the beginning of this thread makes me think you got the 32-bit
one connected to RStudio.
>
> And I say again: I believe problems in configuring RStudio are off-topic
for Rhelp and you should have been searching or posting question either to
the RStudio support or StackOverflow. Looking at the responses to the
queries above and the ones found below, it appears to me that there are
RStudio-specific issues that go beyond what is in the `help(Startup)` or
equivalent `help(.Rprofile)` page.  I gave an instance of an SO search
upthread and I offer another SO search:
>
> http://stackoverflow.com/search?tab=votes&q=%5brstudio%
5d%20environment%20variables%20windows
>
> I thought that this one below had potentially useful information, but I
am not a Windows user (and you have not shown an inclination in offering a
complete description of your efforts at following that advice. At any rate
it would have been more appropriate to respond to the SO answers that were
ineffective or to post a question there with full description of your
efforts and content of your .Rprofile file and your current environment
variable settings.)
>
> http://stackoverflow.com/search?tab=votes&q=%5brstudio%
5d%20rprofile%20windows
>
> --
> David
>
>>
>> Regards,
>> Bruce
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>> peter dalgaard wrote:
>>> Um, tried help(.Rprofile) lately?
>>>
>>> -pd
>>>
>>>> On 17 Apr 2017, at 00:08 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>>
>>>>> On 17/04/17 08:46, John C Frain wrote:
>>>>>
>>>>> Bruce
>>>>>
>>>>> The official documentation for these startup files can be obtained
with
>>>>> the command
>>>>>
>>>>> Help(Startup)
>>>>
>>>> Minor point of order, Mr. Chairman.  That should be:
>>>>
>>>>   help(Startup)
>>>>
>>>> There is (as far as I know) no such function as "Help()".  It is
important to remember that R is case sensitive.
>>>>
>>>> Another point that is worthy of thought is "How in God's name would
any beginner know or find out about the usage help(Startup)?"  Unless they
were explicitly told about it, in the manner which you just demonstrated.
The usage gets a mention in "An Introduction to R" --- but I had to search
for it.
>>>>
>>>> To me the word "startup" is not terribly intuitive.  I would tend to
search for "starting" rather than "startup", I think, but I'm not sure what
the average beginner would search for.  A search of "An Introduction to R"
for "starting" gets seven or eight hits, one of which is relevant.  So it
all takes patience and persistence.
>>>>
>>>> Also note that "An Introduction to R" mostly uses the word "startup"
(lower case "s") and only uses "Startup" twice.  Note also that
>>>>
>>>>   help(startup)
>>>>
>>>> fails.  You have to get that initial "S" right.
>>>>
>>>> This isn't a criticism of the documentation.  I'm just pointing out
that there are problems, mostly insoluble.  Until some clever Johnny gets
on with developing that mind_read() function referred to in fortune(182).
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 17 17:13:49 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:13:49 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
Message-ID: <9a6137a5-4d56-7366-93b2-4c4ecdc22ab4@dmstat1.com>

Bill:
I did workaround. I created the Rprofile files with file type R, not txt.
Bruce

  

William Dunlap wrote:
> I believe someone already mentioned it, but notepad makes it hard to
> save a file without the ".txt" extension to its name.  R does not do
> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
> way to work around notepad's mangling of the file name.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> Bert:
>> I used note pad under Administrator. The code:
>> options(prompt="R> ")
>> set.seed(12345)
>>
>> Bruce
>>
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>>
>>
>>
>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> I cannot add to the instructions that you have already been given
>>> regarding .Rprofile.
>>>
>>> But what code did you use in your .Rprofile to set the prompt? The
>>> posting guide explicitly requests that you provide your code, although
>>> maybe you already did earlier in this extensive thread.
>>>
>>> ?options
>>>
>>> is how it can be set. Did you do this?
>>>
>>> -- Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>> David:
>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>
>>>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Mon Apr 17 17:13:47 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 17 Apr 2017 08:13:47 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
Message-ID: <51CA796B-BBD0-4418-A247-102A9D1FAD74@dcn.davis.ca.us>

Doing anything as Administrator means you are probably already in file permissions hell. R works great if you avoid Administrator mode entirely... using it raises the complexity of every step you take drastically.
-- 
Sent from my phone. Please excuse my brevity.

On April 17, 2017 7:41:18 AM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>Bert:
>I used note pad under Administrator. The code:
>options(prompt="R> ")
>set.seed(12345)
>
>Bruce
>
>______________
>Bruce Ratner PhD
>The Significant Statistician?
>(516) 791-3544
>Statistical Predictive Analytics -- www.DMSTAT1.com
>Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> 
>> I cannot add to the instructions that you have already been given
>> regarding .Rprofile.
>> 
>> But what code did you use in your .Rprofile to set the prompt? The
>> posting guide explicitly requests that you provide your code,
>although
>> maybe you already did earlier in this extensive thread.
>> 
>> ?options
>> 
>> is how it can be set. Did you do this?
>> 
>> -- Bert
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>wrote:
>>> David:
>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>I want the prompt to be "R> " instead of the default "> ". The former
>doesn't show.
>>> Bruce
>>> 
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>> 
>>> 
>>> 
>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
><dwinsemius at comcast.net> wrote:
>>>> 
>>>> 
>> 
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Mon Apr 17 17:19:19 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:19:19 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAFDcVCROr0mV=feZhhZDfZmHzSqgYtq=z9meEEMxUDbxWm=Wsg@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAFDcVCROr0mV=feZhhZDfZmHzSqgYtq=z9meEEMxUDbxWm=Wsg@mail.gmail.com>
Message-ID: <22c50119-6cd7-b708-5214-66412a8d7d11@dmstat1.com>

Henrik:
The Rprofile file is there, I see it.

Bruce Ratner, Ph.D.

  

Henrik Bengtsson wrote:
> Did you try any of the troubleshooting I suggested? If you do that, 
> I'm 99.99% certain it'll help you to resolve this.
>
> Henrik
>
>
> On Apr 17, 2017 03:07, "Bruce Ratner PhD" <br at dmstat1.com 
> <mailto:br at dmstat1.com>> wrote:
>
>     David:
>     When I launch Rstudio the effects of the Rprofile do not show,
>     e.g., I want the prompt to be "R> " instead of the default "> ".
>     The former doesn't show.
>     Bruce
>
>     ______________
>     Bruce Ratner PhD
>     The Significant Statistician?
>     (516) 791-3544 <tel:%28516%29%20791-3544>
>     Statistical Predictive Analytics -- www.DMSTAT1.com
>     <http://www.DMSTAT1.com>
>     Machine-Learning Data Mining -- www.GenIQ.net <http://www.GenIQ.net>
>
>
>
>     > On Apr 16, 2017, at 7:34 PM, David Winsemius
>     <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>     >
>     >
>     >> On Apr 16, 2017, at 3:43 PM, BR_email <br at dmstat1.com
>     <mailto:br at dmstat1.com>> wrote:
>     >>
>     >> Peter:
>     >> Thanks for reply and suggestion.
>     >> Sorry, I am not sure how to assess.
>     >> The doc is too technical for me to understand.
>     >> I found multiple instructions online and in R and RStudio books.
>     >> I'm doing what it says, but no success.
>     >
>     > What is "it" and what is "lack of success"?
>     >
>     >> The instructions are simple as a-b-c, but some setting within
>     the Windows system must be the culprit.
>     >
>     > Although the RStudio page immediately below was done with a Mac,
>     I suspect there are similar selection panels and dialogs on the
>     Windows version of RStudio.
>     >
>     > https://support.rstudio.com/hc/en-us/articles/200549016#general
>     <https://support.rstudio.com/hc/en-us/articles/200549016#general>
>     >
>     > When I look at the Windows installation advice I see near the
>     top: "When installing on a 64-bit version of Windows the options
>     will include 32- or 64-bit versions of R (and the default is to
>     install both)." So is it possible that RStudio is looking at a
>     different version of R than you believe it should be, perhaps at
>     the 32 bit R versus the 64 bit one? The result at the beginning of
>     this thread makes me think you got the 32-bit one connected to
>     RStudio.
>     >
>     > And I say again: I believe problems in configuring RStudio are
>     off-topic for Rhelp and you should have been searching or posting
>     question either to the RStudio support or StackOverflow. Looking
>     at the responses to the queries above and the ones found below, it
>     appears to me that there are RStudio-specific issues that go
>     beyond what is in the `help(Startup)` or equivalent
>     `help(.Rprofile)` page. I gave an instance of an SO search
>     upthread and I offer another SO search:
>     >
>     >
>     http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20environment%20variables%20windows
>     <http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20environment%20variables%20windows>
>     >
>     > I thought that this one below had potentially useful
>     information, but I am not a Windows user (and you have not shown
>     an inclination in offering a complete description of your efforts
>     at following that advice. At any rate it would have been more
>     appropriate to respond to the SO answers that were ineffective or
>     to post a question there with full description of your efforts and
>     content of your .Rprofile file and your current environment
>     variable settings.)
>     >
>     >
>     http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20rprofile%20windows
>     <http://stackoverflow.com/search?tab=votes&q=%5brstudio%5d%20rprofile%20windows>
>     >
>     > --
>     > David
>     >
>     >>
>     >> Regards,
>     >> Bruce
>     >>
>     >> Bruce Ratner, Ph.D.
>     >> The Significant Statistician?
>     >> (516) 791-3544 <tel:%28516%29%20791-3544>
>     >> Statistical Predictive Analtyics -- www.DMSTAT1.com
>     <http://www.DMSTAT1.com>
>     >> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>     <http://www.GenIQ.net>
>     >>
>     >> peter dalgaard wrote:
>     >>> Um, tried help(.Rprofile) lately?
>     >>>
>     >>> -pd
>     >>>
>     >>>> On 17 Apr 2017, at 00:08 , Rolf Turner
>     <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz>> wrote:
>     >>>>
>     >>>>
>     >>>>> On 17/04/17 08:46, John C Frain wrote:
>     >>>>>
>     >>>>> Bruce
>     >>>>>
>     >>>>> The official documentation for these startup files can be
>     obtained with
>     >>>>> the command
>     >>>>>
>     >>>>> Help(Startup)
>     >>>>
>     >>>> Minor point of order, Mr. Chairman. That should be:
>     >>>>
>     >>>>   help(Startup)
>     >>>>
>     >>>> There is (as far as I know) no such function as "Help()".  It
>     is important to remember that R is case sensitive.
>     >>>>
>     >>>> Another point that is worthy of thought is "How in God's name
>     would any beginner know or find out about the usage
>     help(Startup)?"  Unless they were explicitly told about it, in the
>     manner which you just demonstrated.  The usage gets a mention in
>     "An Introduction to R" --- but I had to search for it.
>     >>>>
>     >>>> To me the word "startup" is not terribly intuitive.  I would
>     tend to search for "starting" rather than "startup", I think, but
>     I'm not sure what the average beginner would search for.  A search
>     of "An Introduction to R" for "starting" gets seven or eight hits,
>     one of which is relevant.  So it all takes patience and persistence.
>     >>>>
>     >>>> Also note that "An Introduction to R" mostly uses the word
>     "startup" (lower case "s") and only uses "Startup" twice.  Note
>     also that
>     >>>>
>     >>>>   help(startup)
>     >>>>
>     >>>> fails.  You have to get that initial "S" right.
>     >>>>
>     >>>> This isn't a criticism of the documentation.  I'm just
>     pointing out that there are problems, mostly insoluble.  Until
>     some clever Johnny gets on with developing that mind_read()
>     function referred to in fortune(182).
>     >>>>
>     >>>> cheers,
>     >>>>
>     >>>> Rolf Turner
>     >>>>
>     >>>> --
>     >>>> Technical Editor ANZJS
>     >>>> Department of Statistics
>     >>>> University of Auckland
>     >>>> Phone: +64-9-373-7599 ext. 88276
>     <tel:%2B64-9-373-7599%20ext.%2088276>
>     >>>>
>     >>>> ______________________________________________
>     >>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>     >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >>>> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >>>> and provide commented, minimal, self-contained, reproducible
>     code.
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >
>     > David Winsemius
>     > Alameda, CA, USA
>     >
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From wdunlap at tibco.com  Mon Apr 17 17:20:46 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:20:46 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
Message-ID: <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>

Use the R command
  dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
to see if there are any file names with the unwanted ".txt" and use
file.rename() to fix them up.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com> wrote:
> I believe someone already mentioned it, but notepad makes it hard to
> save a file without the ".txt" extension to its name.  R does not do
> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
> way to work around notepad's mangling of the file name.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> Bert:
>> I used note pad under Administrator. The code:
>> options(prompt="R> ")
>> set.seed(12345)
>>
>> Bruce
>>
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>>
>>
>>
>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> I cannot add to the instructions that you have already been given
>>> regarding .Rprofile.
>>>
>>> But what code did you use in your .Rprofile to set the prompt? The
>>> posting guide explicitly requests that you provide your code, although
>>> maybe you already did earlier in this extensive thread.
>>>
>>> ?options
>>>
>>> is how it can be set. Did you do this?
>>>
>>> -- Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>> David:
>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>
>>>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Apr 17 17:21:35 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:21:35 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <9a6137a5-4d56-7366-93b2-4c4ecdc22ab4@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <9a6137a5-4d56-7366-93b2-4c4ecdc22ab4@dmstat1.com>
Message-ID: <CAF8bMcbUKos5QG_n=TPzwR8OqoD8xu6BjG444V-_A_r3gddqmg@mail.gmail.com>

Not file exention ".R" - no file exention at all.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 8:13 AM, BR_email <br at dmstat1.com> wrote:
> Bill:
> I did workaround. I created the Rprofile files with file type R, not txt.
> Bruce
>
>
>
> William Dunlap wrote:
>>
>> I believe someone already mentioned it, but notepad makes it hard to
>> save a file without the ".txt" extension to its name.  R does not do
>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>> way to work around notepad's mangling of the file name.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>
>>> Bert:
>>> I used note pad under Administrator. The code:
>>> options(prompt="R> ")
>>> set.seed(12345)
>>>
>>> Bruce
>>>
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>
>>>> I cannot add to the instructions that you have already been given
>>>> regarding .Rprofile.
>>>>
>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>> posting guide explicitly requests that you provide your code, although
>>>> maybe you already did earlier in this extensive thread.
>>>>
>>>> ?options
>>>>
>>>> is how it can be set. Did you do this?
>>>>
>>>> -- Bert
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>> wrote:
>>>>> David:
>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I
>>>>> want the prompt to be "R> " instead of the default "> ". The former doesn't
>>>>> show.
>>>>> Bruce
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>
>>>>>
>>>>>
>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
>>>>>> wrote:
>>>>>>
>>>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>


From br at dmstat1.com  Mon Apr 17 17:21:59 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:21:59 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <51CA796B-BBD0-4418-A247-102A9D1FAD74@dcn.davis.ca.us>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <51CA796B-BBD0-4418-A247-102A9D1FAD74@dcn.davis.ca.us>
Message-ID: <d8494274-5023-20a9-0671-0a89c5f64546@dmstat1.com>

I did it both ways, with and without: no success.

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Jeff Newmiller wrote:
> Doing anything as Administrator means you are probably already in file permissions hell. R works great if you avoid Administrator mode entirely... using it raises the complexity of every step you take drastically.


From datamagicpro2017 at gmail.com  Mon Apr 17 09:18:36 2017
From: datamagicpro2017 at gmail.com (Data MagicPro)
Date: Mon, 17 Apr 2017 12:48:36 +0530
Subject: [R] Difference between console output of cat and print
Message-ID: <CALX87Ug53QwijrK=jQKcOUQpvjyMz3LoYTPmbh01Bwkzw9nC0Q@mail.gmail.com>

Since both *cat * as well as * print * create a character vector for
outputing on the screen. Still both give different results as apparant
below. My query is why so ?


> cat(10)
10
> print(10)
[1] 10

Why is the [1] of index number missing in case of *cat *?

Thanks
Ramnik

	[[alternative HTML version deleted]]


From justinenasejje at gmail.com  Mon Apr 17 12:36:05 2017
From: justinenasejje at gmail.com (Justine Nasejje)
Date: Mon, 17 Apr 2017 12:36:05 +0200
Subject: [R] Simulating survival data with co-variate interactions
Message-ID: <CAGjsBx1=2+Zqy0LCxmtgukZ6CESnJVF9GWr=cw1cRtwobvrptA@mail.gmail.com>

Dear list members,
             Can you please share your knowledge with me on how to simulate
survival data with covariate interactions? Your help will be highly
appreciated.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 17 17:24:21 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:24:21 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
Message-ID: <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>

Bill:
Here's what I got:

dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1] "Rprofile.site"


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

William Dunlap wrote:
> Use the R command
>    dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
> to see if there are any file names with the unwanted ".txt" and use
> file.rename() to fix them up.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> I believe someone already mentioned it, but notepad makes it hard to
>> save a file without the ".txt" extension to its name.  R does not do
>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>> way to work around notepad's mangling of the file name.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>> Bert:
>>> I used note pad under Administrator. The code:
>>> options(prompt="R> ")
>>> set.seed(12345)
>>>
>>> Bruce
>>>
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>
>>>> I cannot add to the instructions that you have already been given
>>>> regarding .Rprofile.
>>>>
>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>> posting guide explicitly requests that you provide your code, although
>>>> maybe you already did earlier in this extensive thread.
>>>>
>>>> ?options
>>>>
>>>> is how it can be set. Did you do this?
>>>>
>>>> -- Bert
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>>> David:
>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I want the prompt to be "R> " instead of the default "> ". The former doesn't show.
>>>>> Bruce
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>
>>>>>
>>>>>
>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>>
>>>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>


From br at dmstat1.com  Mon Apr 17 17:26:12 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:26:12 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcbUKos5QG_n=TPzwR8OqoD8xu6BjG444V-_A_r3gddqmg@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <9a6137a5-4d56-7366-93b2-4c4ecdc22ab4@dmstat1.com>
 <CAF8bMcbUKos5QG_n=TPzwR8OqoD8xu6BjG444V-_A_r3gddqmg@mail.gmail.com>
Message-ID: <285b1a75-c602-9265-96c6-891410acdcbd@dmstat1.com>

I used not extension, but R extension shows up.

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

William Dunlap wrote:
> Not file exention ".R" - no file exention at all.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 8:13 AM, BR_email <br at dmstat1.com> wrote:
>> Bill:
>> I did workaround. I created the Rprofile files with file type R, not txt.
>> Bruce
>>
>>
>>
>> William Dunlap wrote:
>>> I believe someone already mentioned it, but notepad makes it hard to
>>> save a file without the ".txt" extension to its name.  R does not do
>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>> way to work around notepad's mangling of the file name.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>> Bert:
>>>> I used note pad under Administrator. The code:
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>>
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> I cannot add to the instructions that you have already been given
>>>>> regarding .Rprofile.
>>>>>
>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>> posting guide explicitly requests that you provide your code, although
>>>>> maybe you already did earlier in this extensive thread.
>>>>>
>>>>> ?options
>>>>>
>>>>> is how it can be set. Did you do this?
>>>>>
>>>>> -- Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>> wrote:
>>>>>> David:
>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I
>>>>>> want the prompt to be "R> " instead of the default "> ". The former doesn't
>>>>>> show.
>>>>>> Bruce
>>>>>>
>>>>>> ______________
>>>>>> Bruce Ratner PhD
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>
>>>>>>
>>>>>>
>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
>>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From wdunlap at tibco.com  Mon Apr 17 17:30:41 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:30:41 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMca8EwhB4PbWcWML2pot843VnEf3yv-v06K+ROBRjS0bJw@mail.gmail.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
Message-ID: <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>

I should haved added full.names=TRUE to the dir() call.  I you add
that I'd expect that you would see ".../etc/Rprofile.site".  What do
you see when you do

     writeLines(readLines(".../etc/Rprofile.site")

and
     source(echo=TRUE, ".../etc/Rprofile.site")

(replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
> Bill:
> Here's what I got:
>
> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
> "Rprofile.site"
>
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> William Dunlap wrote:
>>
>> Use the R command
>>    dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>> to see if there are any file names with the unwanted ".txt" and use
>> file.rename() to fix them up.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>> I believe someone already mentioned it, but notepad makes it hard to
>>> save a file without the ".txt" extension to its name.  R does not do
>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>> way to work around notepad's mangling of the file name.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>>
>>>> Bert:
>>>> I used note pad under Administrator. The code:
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>>
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> I cannot add to the instructions that you have already been given
>>>>> regarding .Rprofile.
>>>>>
>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>> posting guide explicitly requests that you provide your code, although
>>>>> maybe you already did earlier in this extensive thread.
>>>>>
>>>>> ?options
>>>>>
>>>>> is how it can be set. Did you do this?
>>>>>
>>>>> -- Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>> wrote:
>>>>>> David:
>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I
>>>>>> want the prompt to be "R> " instead of the default "> ". The former doesn't
>>>>>> show.
>>>>>> Bruce
>>>>>>
>>>>>> ______________
>>>>>> Bruce Ratner PhD
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>
>>>>>>
>>>>>>
>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
>>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>


From wdunlap at tibco.com  Mon Apr 17 17:32:10 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:32:10 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <285b1a75-c602-9265-96c6-891410acdcbd@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <3007ec0a-7578-479d-d9b0-208936cb4076@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <9a6137a5-4d56-7366-93b2-4c4ecdc22ab4@dmstat1.com>
 <CAF8bMcbUKos5QG_n=TPzwR8OqoD8xu6BjG444V-_A_r3gddqmg@mail.gmail.com>
 <285b1a75-c602-9265-96c6-891410acdcbd@dmstat1.com>
Message-ID: <CAF8bMcY=ED8=0XX4E=go1_ohPA=bBTfE68tjyfHZ7mz2vUGXiQ@mail.gmail.com>

Use another editor or go to file explorer, turn on the 'show file
extensions' option and rename the file so it does not have the .R
extension.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 8:26 AM, BR_email <br at dmstat1.com> wrote:
> I used not extension, but R extension shows up.
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
> William Dunlap wrote:
>>
>> Not file exention ".R" - no file exention at all.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 8:13 AM, BR_email <br at dmstat1.com> wrote:
>>>
>>> Bill:
>>> I did workaround. I created the Rprofile files with file type R, not txt.
>>> Bruce
>>>
>>>
>>>
>>> William Dunlap wrote:
>>>>
>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>> save a file without the ".txt" extension to its name.  R does not do
>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>> way to work around notepad's mangling of the file name.
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>> wrote:
>>>>>
>>>>> Bert:
>>>>> I used note pad under Administrator. The code:
>>>>> options(prompt="R> ")
>>>>> set.seed(12345)
>>>>>
>>>>> Bruce
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>
>>>>>
>>>>>
>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> I cannot add to the instructions that you have already been given
>>>>>> regarding .Rprofile.
>>>>>>
>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>> posting guide explicitly requests that you provide your code, although
>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>
>>>>>> ?options
>>>>>>
>>>>>> is how it can be set. Did you do this?
>>>>>>
>>>>>> -- Bert
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>> wrote:
>>>>>>> David:
>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>>>>>>> I
>>>>>>> want the prompt to be "R> " instead of the default "> ". The former
>>>>>>> doesn't
>>>>>>> show.
>>>>>>> Bruce
>>>>>>>
>>>>>>> ______________
>>>>>>> Bruce Ratner PhD
>>>>>>> The Significant Statistician?
>>>>>>> (516) 791-3544
>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>
>>
>


From br at dmstat1.com  Mon Apr 17 17:36:53 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 11:36:53 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
Message-ID: <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>

Bill:
I feel you are nailing it for me.
Can I please call you, but I am getting a little lost, and losing your 
valuable help?
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

William Dunlap wrote:
> I should haved added full.names=TRUE to the dir() call.  I you add
> that I'd expect that you would see ".../etc/Rprofile.site".  What do
> you see when you do
>
>       writeLines(readLines(".../etc/Rprofile.site")
>
> and
>       source(echo=TRUE, ".../etc/Rprofile.site")
>
> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>> Bill:
>> Here's what I got:
>>
>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
>> "Rprofile.site"
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>>
>> William Dunlap wrote:
>>> Use the R command
>>>     dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>>> to see if there are any file names with the unwanted ".txt" and use
>>> file.rename() to fix them up.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>> save a file without the ".txt" extension to its name.  R does not do
>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>> way to work around notepad's mangling of the file name.
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>>> Bert:
>>>>> I used note pad under Administrator. The code:
>>>>> options(prompt="R> ")
>>>>> set.seed(12345)
>>>>>
>>>>> Bruce
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>
>>>>>
>>>>>
>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> I cannot add to the instructions that you have already been given
>>>>>> regarding .Rprofile.
>>>>>>
>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>> posting guide explicitly requests that you provide your code, although
>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>
>>>>>> ?options
>>>>>>
>>>>>> is how it can be set. Did you do this?
>>>>>>
>>>>>> -- Bert
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>> wrote:
>>>>>>> David:
>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g., I
>>>>>>> want the prompt to be "R> " instead of the default "> ". The former doesn't
>>>>>>> show.
>>>>>>> Bruce
>>>>>>>
>>>>>>> ______________
>>>>>>> Bruce Ratner PhD
>>>>>>> The Significant Statistician?
>>>>>>> (516) 791-3544
>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From bgunter.4567 at gmail.com  Mon Apr 17 17:52:30 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 08:52:30 -0700
Subject: [R] Simulating survival data with co-variate interactions
In-Reply-To: <CAGjsBx1=2+Zqy0LCxmtgukZ6CESnJVF9GWr=cw1cRtwobvrptA@mail.gmail.com>
References: <CAGjsBx1=2+Zqy0LCxmtgukZ6CESnJVF9GWr=cw1cRtwobvrptA@mail.gmail.com>
Message-ID: <CAGxFJbQgbdSc15OhLnmx5pdzLRKaefAb40NMKxf7iOOgDU6pEg@mail.gmail.com>

This appears to fall into the realm of statistical questions, which
are mainly off topic for this list, which is about R programming
questions (subsequent posts here *may* be appropriate after you have
resolved the statistical questions). You might try posting on a
statistical list like stats.stackexchange.com.  Note: You will likely
have to provide far greater detail to get helpful replies, though they
may be able to refer you to approriate resources, e.g. texts.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 3:36 AM, Justine Nasejje
<justinenasejje at gmail.com> wrote:
> Dear list members,
>              Can you please share your knowledge with me on how to simulate
> survival data with covariate interactions? Your help will be highly
> appreciated.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Apr 17 17:53:59 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 08:53:59 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <AD3BDB81-225E-4324-A02D-FB3D966981EF@utoronto.ca>
 <b6e8abc1-6c4b-f4d9-5713-cb392477294f@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
Message-ID: <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>

No calls please.  Just show the group what .../etc/Rprofile-site contained.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
> Bill:
> I feel you are nailing it for me.
> Can I please call you, but I am getting a little lost, and losing your
> valuable help?
> Bruce
>
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
> William Dunlap wrote:
>>
>> I should haved added full.names=TRUE to the dir() call.  I you add
>> that I'd expect that you would see ".../etc/Rprofile.site".  What do
>> you see when you do
>>
>>       writeLines(readLines(".../etc/Rprofile.site")
>>
>> and
>>       source(echo=TRUE, ".../etc/Rprofile.site")
>>
>> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>
>>> Bill:
>>> Here's what I got:
>>>
>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
>>> "Rprofile.site"
>>>
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>>
>>> William Dunlap wrote:
>>>>
>>>> Use the R command
>>>>     dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>>>> to see if there are any file names with the unwanted ".txt" and use
>>>> file.rename() to fix them up.
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com>
>>>> wrote:
>>>>>
>>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>>> save a file without the ".txt" extension to its name.  R does not do
>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>>> way to work around notepad's mangling of the file name.
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>> wrote:
>>>>>>
>>>>>> Bert:
>>>>>> I used note pad under Administrator. The code:
>>>>>> options(prompt="R> ")
>>>>>> set.seed(12345)
>>>>>>
>>>>>> Bruce
>>>>>>
>>>>>> ______________
>>>>>> Bruce Ratner PhD
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>
>>>>>>
>>>>>>
>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>> I cannot add to the instructions that you have already been given
>>>>>>> regarding .Rprofile.
>>>>>>>
>>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>> although
>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>
>>>>>>> ?options
>>>>>>>
>>>>>>> is how it can be set. Did you do this?
>>>>>>>
>>>>>>> -- Bert
>>>>>>>
>>>>>>> Bert Gunter
>>>>>>>
>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>> along
>>>>>>> and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>>
>>>>>>>
>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>>> wrote:
>>>>>>>> David:
>>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>>>>>>>> I
>>>>>>>> want the prompt to be "R> " instead of the default "> ". The former
>>>>>>>> doesn't
>>>>>>>> show.
>>>>>>>> Bruce
>>>>>>>>
>>>>>>>> ______________
>>>>>>>> Bruce Ratner PhD
>>>>>>>> The Significant Statistician?
>>>>>>>> (516) 791-3544
>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>
>>
>


From br at dmstat1.com  Mon Apr 17 18:02:13 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 12:02:13 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
Message-ID: <c9347d84-395b-0ff8-0f2f-0a8ded8a5114@dmstat1.com>

Sorry for the phone suggestion.
Bill, I do not know what type of editor to use, can you suggest?
BR

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

William Dunlap wrote:
> No calls please.  Just show the group what .../etc/Rprofile-site contained.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
>> Bill:
>> I feel you are nailing it for me.
>> Can I please call you, but I am getting a little lost, and losing your
>> valuable help?
>> Bruce
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>> William Dunlap wrote:
>>> I should haved added full.names=TRUE to the dir() call.  I you add
>>> that I'd expect that you would see ".../etc/Rprofile.site".  What do
>>> you see when you do
>>>
>>>        writeLines(readLines(".../etc/Rprofile.site")
>>>
>>> and
>>>        source(echo=TRUE, ".../etc/Rprofile.site")
>>>
>>> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>> Bill:
>>>> Here's what I got:
>>>>
>>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
>>>> "Rprofile.site"
>>>>
>>>>
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>
>>>>
>>>> William Dunlap wrote:
>>>>> Use the R command
>>>>>      dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>>>>> to see if there are any file names with the unwanted ".txt" and use
>>>>> file.rename() to fix them up.
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com>
>>>>> wrote:
>>>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>>>> save a file without the ".txt" extension to its name.  R does not do
>>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>>>> way to work around notepad's mangling of the file name.
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>>
>>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>> wrote:
>>>>>>> Bert:
>>>>>>> I used note pad under Administrator. The code:
>>>>>>> options(prompt="R> ")
>>>>>>> set.seed(12345)
>>>>>>>
>>>>>>> Bruce
>>>>>>>
>>>>>>> ______________
>>>>>>> Bruce Ratner PhD
>>>>>>> The Significant Statistician?
>>>>>>> (516) 791-3544
>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>> I cannot add to the instructions that you have already been given
>>>>>>>> regarding .Rprofile.
>>>>>>>>
>>>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>>> although
>>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>>
>>>>>>>> ?options
>>>>>>>>
>>>>>>>> is how it can be set. Did you do this?
>>>>>>>>
>>>>>>>> -- Bert
>>>>>>>>
>>>>>>>> Bert Gunter
>>>>>>>>
>>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>>> along
>>>>>>>> and sticking things into it."
>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>>>
>>>>>>>>
>>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>>>> wrote:
>>>>>>>>> David:
>>>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>>>>>>>>> I
>>>>>>>>> want the prompt to be "R> " instead of the default "> ". The former
>>>>>>>>> doesn't
>>>>>>>>> show.
>>>>>>>>> Bruce
>>>>>>>>>
>>>>>>>>> ______________
>>>>>>>>> Bruce Ratner PhD
>>>>>>>>> The Significant Statistician?
>>>>>>>>> (516) 791-3544
>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>>> wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>
>
>


From br at dmstat1.com  Mon Apr 17 18:36:10 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 12:36:10 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <6e91a9fb-ca5d-6180-72be-42383a50b74e@auckland.ac.nz>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
Message-ID: <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>

Bill:
Success, almost there:

>writeLines(readLines("C:/Users/BruceRatner/Documents/.Rprofile.site")) options(prompt="R> ")
set.seed(12345)
rm(list=ls())

 >


Yet, still not affecting the launch, as "R>" is not there.
Any suggestions, please. "So close, yet far away, ... " - Carly Simon


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

William Dunlap wrote:
> No calls please.  Just show the group what .../etc/Rprofile-site contained.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
>> Bill:
>> I feel you are nailing it for me.
>> Can I please call you, but I am getting a little lost, and losing your
>> valuable help?
>> Bruce
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>> William Dunlap wrote:
>>> I should haved added full.names=TRUE to the dir() call.  I you add
>>> that I'd expect that you would see ".../etc/Rprofile.site".  What do
>>> you see when you do
>>>
>>>        writeLines(readLines(".../etc/Rprofile.site")
>>>
>>> and
>>>        source(echo=TRUE, ".../etc/Rprofile.site")
>>>
>>> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>> Bill:
>>>> Here's what I got:
>>>>
>>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
>>>> "Rprofile.site"
>>>>
>>>>
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>
>>>>
>>>> William Dunlap wrote:
>>>>> Use the R command
>>>>>      dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>>>>> to see if there are any file names with the unwanted ".txt" and use
>>>>> file.rename() to fix them up.
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com>
>>>>> wrote:
>>>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>>>> save a file without the ".txt" extension to its name.  R does not do
>>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>>>> way to work around notepad's mangling of the file name.
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>>
>>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>> wrote:
>>>>>>> Bert:
>>>>>>> I used note pad under Administrator. The code:
>>>>>>> options(prompt="R> ")
>>>>>>> set.seed(12345)
>>>>>>>
>>>>>>> Bruce
>>>>>>>
>>>>>>> ______________
>>>>>>> Bruce Ratner PhD
>>>>>>> The Significant Statistician?
>>>>>>> (516) 791-3544
>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>> I cannot add to the instructions that you have already been given
>>>>>>>> regarding .Rprofile.
>>>>>>>>
>>>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>>> although
>>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>>
>>>>>>>> ?options
>>>>>>>>
>>>>>>>> is how it can be set. Did you do this?
>>>>>>>>
>>>>>>>> -- Bert
>>>>>>>>
>>>>>>>> Bert Gunter
>>>>>>>>
>>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>>> along
>>>>>>>> and sticking things into it."
>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>>>
>>>>>>>>
>>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>>>> wrote:
>>>>>>>>> David:
>>>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>>>>>>>>> I
>>>>>>>>> want the prompt to be "R> " instead of the default "> ". The former
>>>>>>>>> doesn't
>>>>>>>>> show.
>>>>>>>>> Bruce
>>>>>>>>>
>>>>>>>>> ______________
>>>>>>>>> Bruce Ratner PhD
>>>>>>>>> The Significant Statistician?
>>>>>>>>> (516) 791-3544
>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>>> wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>
>
>


From br at dmstat1.com  Mon Apr 17 18:39:50 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 12:39:50 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
Message-ID: <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>

Bill, part II:

>source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site") 
Error: unexpected symbol in "source(echo=TRUE, ""C"

 >


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

BR_email wrote:
> Bill:
> Success, almost there:
>
>> writeLines(readLines("C:/Users/BruceRatner/Documents/.Rprofile.site")) 
>> options(prompt="R> ")
> set.seed(12345)
> rm(list=ls())
>
> >
>
>
> Yet, still not affecting the launch, as "R>" is not there.
> Any suggestions, please. "So close, yet far away, ... " - Carly Simon
>
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> William Dunlap wrote:
>> No calls please.  Just show the group what .../etc/Rprofile-site 
>> contained.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
>>> Bill:
>>> I feel you are nailing it for me.
>>> Can I please call you, but I am getting a little lost, and losing your
>>> valuable help?
>>> Bruce
>>>
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>> William Dunlap wrote:
>>>> I should haved added full.names=TRUE to the dir() call.  I you add
>>>> that I'd expect that you would see ".../etc/Rprofile.site". What do
>>>> you see when you do
>>>>
>>>>        writeLines(readLines(".../etc/Rprofile.site")
>>>>
>>>> and
>>>>        source(echo=TRUE, ".../etc/Rprofile.site")
>>>>
>>>> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>>> Bill:
>>>>> Here's what I got:
>>>>>
>>>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") 
>>>>> [1]
>>>>> "Rprofile.site"
>>>>>
>>>>>
>>>>> Bruce Ratner, Ph.D.
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>>
>>>>>
>>>>> William Dunlap wrote:
>>>>>> Use the R command
>>>>>>      dir(c(".", Sys.getenv("HOME"), R.home("etc")), 
>>>>>> pattern="Rprofile")
>>>>>> to see if there are any file names with the unwanted ".txt" and use
>>>>>> file.rename() to fix them up.
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>>
>>>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com>
>>>>>> wrote:
>>>>>>> I believe someone already mentioned it, but notepad makes it 
>>>>>>> hard to
>>>>>>> save a file without the ".txt" extension to its name. R does not do
>>>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure 
>>>>>>> out a
>>>>>>> way to work around notepad's mangling of the file name.
>>>>>>> Bill Dunlap
>>>>>>> TIBCO Software
>>>>>>> wdunlap tibco.com
>>>>>>>
>>>>>>>
>>>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>> wrote:
>>>>>>>> Bert:
>>>>>>>> I used note pad under Administrator. The code:
>>>>>>>> options(prompt="R> ")
>>>>>>>> set.seed(12345)
>>>>>>>>
>>>>>>>> Bruce
>>>>>>>>
>>>>>>>> ______________
>>>>>>>> Bruce Ratner PhD
>>>>>>>> The Significant Statistician?
>>>>>>>> (516) 791-3544
>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter 
>>>>>>>>> <bgunter.4567 at gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> I cannot add to the instructions that you have already been given
>>>>>>>>> regarding .Rprofile.
>>>>>>>>>
>>>>>>>>> But what code did you use in your .Rprofile to set the prompt? 
>>>>>>>>> The
>>>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>>>> although
>>>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>>>
>>>>>>>>> ?options
>>>>>>>>>
>>>>>>>>> is how it can be set. Did you do this?
>>>>>>>>>
>>>>>>>>> -- Bert
>>>>>>>>>
>>>>>>>>> Bert Gunter
>>>>>>>>>
>>>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>>>> along
>>>>>>>>> and sticking things into it."
>>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic 
>>>>>>>>> strip )
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD 
>>>>>>>>>> <br at dmstat1.com>
>>>>>>>>>> wrote:
>>>>>>>>>> David:
>>>>>>>>>> When I launch Rstudio the effects of the Rprofile do not 
>>>>>>>>>> show, e.g.,
>>>>>>>>>> I
>>>>>>>>>> want the prompt to be "R> " instead of the default "> ". The 
>>>>>>>>>> former
>>>>>>>>>> doesn't
>>>>>>>>>> show.
>>>>>>>>>> Bruce
>>>>>>>>>>
>>>>>>>>>> ______________
>>>>>>>>>> Bruce Ratner PhD
>>>>>>>>>> The Significant Statistician?
>>>>>>>>>> (516) 791-3544
>>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>>>> wrote:
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>
>>
>>
>


From bhh at xs4all.nl  Mon Apr 17 18:54:12 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 17 Apr 2017 18:54:12 +0200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <945C00C5-B811-409C-AC21-327B69400AEA@dcn.davis.ca.us>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com> <c615b
 b31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
Message-ID: <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>


> On 17 Apr 2017, at 18:39, BR_email <br at dmstat1.com> wrote:
> 
> Bill, part II:
> 
>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site") 
> Error: unexpected symbol in "source(echo=TRUE, ""C"
> 

You have a double quote sign ("") preceding C:/.
Make it a single double quote so that you get "C:/...."

Berend

> >
> 
> 
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
> 
> BR_email wrote:
>> Bill:
>> Success, almost there:
>> 
>>> writeLines(readLines("C:/Users/BruceRatner/Documents/.Rprofile.site")) options(prompt="R> ")
>> set.seed(12345)
>> rm(list=ls())
>> 
>> >
>> 
>> 
>> Yet, still not affecting the launch, as "R>" is not there.
>> Any suggestions, please. "So close, yet far away, ... " - Carly Simon
>> 
>> 
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>> 
>> 
>> William Dunlap wrote:
>>> No calls please.  Just show the group what .../etc/Rprofile-site contained.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>> On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
>>>> Bill:
>>>> I feel you are nailing it for me.
>>>> Can I please call you, but I am getting a little lost, and losing your
>>>> valuable help?
>>>> Bruce
>>>> 
>>>> 
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>> 
>>>> William Dunlap wrote:
>>>>> I should haved added full.names=TRUE to the dir() call.  I you add
>>>>> that I'd expect that you would see ".../etc/Rprofile.site". What do
>>>>> you see when you do
>>>>> 
>>>>>       writeLines(readLines(".../etc/Rprofile.site")
>>>>> 
>>>>> and
>>>>>       source(echo=TRUE, ".../etc/Rprofile.site")
>>>>> 
>>>>> (replace the ellipsis by whatever dir(full.names=TRUE,...) showed).
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>> 
>>>>> 
>>>>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>>>> Bill:
>>>>>> Here's what I got:
>>>>>> 
>>>>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile") [1]
>>>>>> "Rprofile.site"
>>>>>> 
>>>>>> 
>>>>>> Bruce Ratner, Ph.D.
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>>> 
>>>>>> 
>>>>>> William Dunlap wrote:
>>>>>>> Use the R command
>>>>>>>     dir(c(".", Sys.getenv("HOME"), R.home("etc")), pattern="Rprofile")
>>>>>>> to see if there are any file names with the unwanted ".txt" and use
>>>>>>> file.rename() to fix them up.
>>>>>>> Bill Dunlap
>>>>>>> TIBCO Software
>>>>>>> wdunlap tibco.com
>>>>>>> 
>>>>>>> 
>>>>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap <wdunlap at tibco.com>
>>>>>>> wrote:
>>>>>>>> I believe someone already mentioned it, but notepad makes it hard to
>>>>>>>> save a file without the ".txt" extension to its name. R does not do
>>>>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure out a
>>>>>>>> way to work around notepad's mangling of the file name.
>>>>>>>> Bill Dunlap
>>>>>>>> TIBCO Software
>>>>>>>> wdunlap tibco.com
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>>> wrote:
>>>>>>>>> Bert:
>>>>>>>>> I used note pad under Administrator. The code:
>>>>>>>>> options(prompt="R> ")
>>>>>>>>> set.seed(12345)
>>>>>>>>> 
>>>>>>>>> Bruce
>>>>>>>>> 
>>>>>>>>> ______________
>>>>>>>>> Bruce Ratner PhD
>>>>>>>>> The Significant Statistician?
>>>>>>>>> (516) 791-3544
>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>>>>> wrote:
>>>>>>>>>> 
>>>>>>>>>> I cannot add to the instructions that you have already been given
>>>>>>>>>> regarding .Rprofile.
>>>>>>>>>> 
>>>>>>>>>> But what code did you use in your .Rprofile to set the prompt? The
>>>>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>>>>> although
>>>>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>>>> 
>>>>>>>>>> ?options
>>>>>>>>>> 
>>>>>>>>>> is how it can be set. Did you do this?
>>>>>>>>>> 
>>>>>>>>>> -- Bert
>>>>>>>>>> 
>>>>>>>>>> Bert Gunter
>>>>>>>>>> 
>>>>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>>>>> along
>>>>>>>>>> and sticking things into it."
>>>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD <br at dmstat1.com>
>>>>>>>>>>> wrote:
>>>>>>>>>>> David:
>>>>>>>>>>> When I launch Rstudio the effects of the Rprofile do not show, e.g.,
>>>>>>>>>>> I
>>>>>>>>>>> want the prompt to be "R> " instead of the default "> ". The former
>>>>>>>>>>> doesn't
>>>>>>>>>>> show.
>>>>>>>>>>> Bruce
>>>>>>>>>>> 
>>>>>>>>>>> ______________
>>>>>>>>>>> Bruce Ratner PhD
>>>>>>>>>>> The Significant Statistician?
>>>>>>>>>>> (516) 791-3544
>>>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>>>>> wrote:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> 
>>>>> 
>>> 
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Mon Apr 17 19:01:50 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 13:01:50 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
Message-ID: <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>

Berend: Something looks good, but RStudio still Rprofile still doees not 
affect the launch.

>source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
> options(prompt="R> ")

> set.seed(12345)

> rm(list=ls())

R>


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Berend Hasselman wrote:
> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")


From jdnewmil at dcn.davis.ca.us  Mon Apr 17 19:18:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 17 Apr 2017 10:18:48 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAHrK516_ikdL0G_Vi0zamd9aSuYJBkmW=+vsRmcHXuzQVKc8nA@mail.gmail.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
Message-ID: <8E101DE7-B069-4331-9AA1-CC2FE307BF69@dcn.davis.ca.us>

".Rprofile.site" is not looked for in "C:/Users/BruceRatner/Documents/". That file belongs in the R.home("etc") directory.  I suggest you stay away from the system wide configuration and focus on your personal configuration file ""C:/Users/BruceRatner/Documents/.Rprofile".

I also recommend putting the arguments in the order given in ?source unless you name every single argument.
-- 
Sent from my phone. Please excuse my brevity.

On April 17, 2017 9:39:50 AM PDT, BR_email <br at dmstat1.com> wrote:
>Bill, part II:
>
>>source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site") 
>Error: unexpected symbol in "source(echo=TRUE, ""C"
>
> >
>
>
>Bruce Ratner, Ph.D.
>The Significant Statistician?
>(516) 791-3544
>Statistical Predictive Analtyics -- www.DMSTAT1.com
>Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>  
>
>BR_email wrote:
>> Bill:
>> Success, almost there:
>>
>>>
>writeLines(readLines("C:/Users/BruceRatner/Documents/.Rprofile.site")) 
>>> options(prompt="R> ")
>> set.seed(12345)
>> rm(list=ls())
>>
>> >
>>
>>
>> Yet, still not affecting the launch, as "R>" is not there.
>> Any suggestions, please. "So close, yet far away, ... " - Carly Simon
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>>
>> William Dunlap wrote:
>>> No calls please.  Just show the group what .../etc/Rprofile-site 
>>> contained.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Mon, Apr 17, 2017 at 8:36 AM, BR_email <br at dmstat1.com> wrote:
>>>> Bill:
>>>> I feel you are nailing it for me.
>>>> Can I please call you, but I am getting a little lost, and losing
>your
>>>> valuable help?
>>>> Bruce
>>>>
>>>>
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>
>>>> William Dunlap wrote:
>>>>> I should haved added full.names=TRUE to the dir() call.  I you add
>>>>> that I'd expect that you would see ".../etc/Rprofile.site". What
>do
>>>>> you see when you do
>>>>>
>>>>>        writeLines(readLines(".../etc/Rprofile.site")
>>>>>
>>>>> and
>>>>>        source(echo=TRUE, ".../etc/Rprofile.site")
>>>>>
>>>>> (replace the ellipsis by whatever dir(full.names=TRUE,...)
>showed).
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Mon, Apr 17, 2017 at 8:24 AM, BR_email <br at dmstat1.com> wrote:
>>>>>> Bill:
>>>>>> Here's what I got:
>>>>>>
>>>>>> dir(c(".", Sys.getenv("HOME"), R.home("etc")),
>pattern="Rprofile") 
>>>>>> [1]
>>>>>> "Rprofile.site"
>>>>>>
>>>>>>
>>>>>> Bruce Ratner, Ph.D.
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>>>
>>>>>>
>>>>>> William Dunlap wrote:
>>>>>>> Use the R command
>>>>>>>      dir(c(".", Sys.getenv("HOME"), R.home("etc")), 
>>>>>>> pattern="Rprofile")
>>>>>>> to see if there are any file names with the unwanted ".txt" and
>use
>>>>>>> file.rename() to fix them up.
>>>>>>> Bill Dunlap
>>>>>>> TIBCO Software
>>>>>>> wdunlap tibco.com
>>>>>>>
>>>>>>>
>>>>>>> On Mon, Apr 17, 2017 at 8:06 AM, William Dunlap
><wdunlap at tibco.com>
>>>>>>> wrote:
>>>>>>>> I believe someone already mentioned it, but notepad makes it 
>>>>>>>> hard to
>>>>>>>> save a file without the ".txt" extension to its name. R does
>not do
>>>>>>>> anything with .Rprofile.txt, only .Rprofile, so you must figure
>
>>>>>>>> out a
>>>>>>>> way to work around notepad's mangling of the file name.
>>>>>>>> Bill Dunlap
>>>>>>>> TIBCO Software
>>>>>>>> wdunlap tibco.com
>>>>>>>>
>>>>>>>>
>>>>>>>> On Mon, Apr 17, 2017 at 7:41 AM, Bruce Ratner PhD
><br at dmstat1.com>
>>>>>>>> wrote:
>>>>>>>>> Bert:
>>>>>>>>> I used note pad under Administrator. The code:
>>>>>>>>> options(prompt="R> ")
>>>>>>>>> set.seed(12345)
>>>>>>>>>
>>>>>>>>> Bruce
>>>>>>>>>
>>>>>>>>> ______________
>>>>>>>>> Bruce Ratner PhD
>>>>>>>>> The Significant Statistician?
>>>>>>>>> (516) 791-3544
>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> On Apr 17, 2017, at 10:30 AM, Bert Gunter 
>>>>>>>>>> <bgunter.4567 at gmail.com>
>>>>>>>>>> wrote:
>>>>>>>>>>
>>>>>>>>>> I cannot add to the instructions that you have already been
>given
>>>>>>>>>> regarding .Rprofile.
>>>>>>>>>>
>>>>>>>>>> But what code did you use in your .Rprofile to set the
>prompt? 
>>>>>>>>>> The
>>>>>>>>>> posting guide explicitly requests that you provide your code,
>>>>>>>>>> although
>>>>>>>>>> maybe you already did earlier in this extensive thread.
>>>>>>>>>>
>>>>>>>>>> ?options
>>>>>>>>>>
>>>>>>>>>> is how it can be set. Did you do this?
>>>>>>>>>>
>>>>>>>>>> -- Bert
>>>>>>>>>>
>>>>>>>>>> Bert Gunter
>>>>>>>>>>
>>>>>>>>>> "The trouble with having an open mind is that people keep
>coming
>>>>>>>>>> along
>>>>>>>>>> and sticking things into it."
>>>>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic 
>>>>>>>>>> strip )
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> On Mon, Apr 17, 2017 at 3:06 AM, Bruce Ratner PhD 
>>>>>>>>>>> <br at dmstat1.com>
>>>>>>>>>>> wrote:
>>>>>>>>>>> David:
>>>>>>>>>>> When I launch Rstudio the effects of the Rprofile do not 
>>>>>>>>>>> show, e.g.,
>>>>>>>>>>> I
>>>>>>>>>>> want the prompt to be "R> " instead of the default "> ". The
>
>>>>>>>>>>> former
>>>>>>>>>>> doesn't
>>>>>>>>>>> show.
>>>>>>>>>>> Bruce
>>>>>>>>>>>
>>>>>>>>>>> ______________
>>>>>>>>>>> Bruce Ratner PhD
>>>>>>>>>>> The Significant Statistician?
>>>>>>>>>>> (516) 791-3544
>>>>>>>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>>>>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> On Apr 16, 2017, at 7:34 PM, David Winsemius
>>>>>>>>>>>> <dwinsemius at comcast.net>
>>>>>>>>>>>> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>>>
>>>>>>>
>>>>>
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Apr 17 19:26:14 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Mon, 17 Apr 2017 19:26:14 +0200
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <236ad30f-9d1a-3852-447d-618851926926@auckland.ac.nz>
 <963AC48E-8863-4D5F-B9EE-507112D0AEC8@gmail.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
Message-ID: <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>


> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
> 
> Berend: Something looks good, but RStudio still Rprofile still doees not affect the launch.
> 
>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>> options(prompt="R> ")
> 
>> set.seed(12345)
> 
>> rm(list=ls())
> 
> R>
> 
> 
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
> 
> Berend Hasselman wrote:
>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
> 

According to the gospel of St.Henrik, that filename is wrong, and possibly the directory too.

So try his suggestions. What is the output (show us!) of

normalizePath("./.Rprofile")
normalizePath("~/.Rprofile")

Assuming that the former is 

"C:/Users/BruceRatner/Documents/.Rprofile"

you could try renaming the .Rprofile.site file to that. If need be, use file.rename, as in

file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site", to="C:/Users/BruceRatner/Documents/.Rprofile")

(and restart, obviously).

[I wouldn't set the seed in a .Rprofile file, nor would I use rm() there, but that is a different kettle of fish.]

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Eli.Ateljevich at water.ca.gov  Mon Apr 17 19:38:40 2017
From: Eli.Ateljevich at water.ca.gov (Ateljevich, Eli@DWR)
Date: Mon, 17 Apr 2017 17:38:40 +0000
Subject: [R] ssa gapfill of series with large window and sparse gaps with
	Rssa
Message-ID: <BLUPR09MB01368979B75D68545C3D852FBA060@BLUPR09MB0136.namprd09.prod.outlook.com>

I have several years of univariate wind speed data to which I would like to apply singular spectrum analysis. The data are sampled every 15min and a year is a fundamental periodicity, which suggests L=35,040 values.


I would like to fill the gaps. The missing values are scattered at low density throughout the series.  I doubt there is a block of even one month that doesn't have at least a couple pieces of missing data, but I'd surprised to learn the total number are prohibitive.


The filling routines in Rssa like igapfill assume a shaped ssa object, so it seems I need to run ssa successfully first before I can fill. When I try this with L=35,040 or anything above about 2,000 I get an error message
Nothing to decompose: the given field shape is empty
and warnings like
Some field elements were not covered by shaped window. 42646 elements will be ommited.


This is frustrating, because if I manually fill missing data with the series mean, which I understand as being the first step of igapfill, the decomposition succeeds with L=35040. The operation seems efficient and the spectral components look as expected. But since I have manually created a series with no missing data,  this doesn't help me with gap filling.


To concoct a shaped ssa object with the original missing pattern, I invoked force.decompose=FALSE. At that point I can bring my task to completion, but I don't know what I'm doing.  The only examples I see in the docs are not explained and are in 2D.


Can someone familiar with this kind of use case explain what the purpose of force.decompose and explain the best practice given my missing data situation? Are there consequences to my workaround? Thanks.


	[[alternative HTML version deleted]]


From br at dmstat1.com  Mon Apr 17 19:47:03 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 13:47:03 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <2c329286-5aca-670c-b065-8664af775749@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
Message-ID: <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>

TO _ALL_:
THANK YOU. THANK YOU. THANK YOU.
After hours, and hours, and hours, and ... , and hours: Success.
To all who helped, thanks.
My quest was minor, but major for me, as I learn from the path of one, 
whether big or small begets another.

I never look down at anyone, except to help him/her up.

With gratitude,
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Peter Dalgaard wrote:
>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>
>> Berend: Something looks good, but RStudio still Rprofile still doees not affect the launch.
>>
>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>> options(prompt="R> ")
>>> set.seed(12345)
>>> rm(list=ls())
>> R>
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>> Berend Hasselman wrote:
>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
> According to the gospel of St.Henrik, that filename is wrong, and possibly the directory too.
>
> So try his suggestions. What is the output (show us!) of
>
> normalizePath("./.Rprofile")
> normalizePath("~/.Rprofile")
>
> Assuming that the former is
>
> "C:/Users/BruceRatner/Documents/.Rprofile"
>
> you could try renaming the .Rprofile.site file to that. If need be, use file.rename, as in
>
> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site", to="C:/Users/BruceRatner/Documents/.Rprofile")
>
> (and restart, obviously).
>
> [I wouldn't set the seed in a .Rprofile file, nor would I use rm() there, but that is a different kettle of fish.]
>


From wdunlap at tibco.com  Mon Apr 17 19:59:33 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Apr 2017 10:59:33 -0700
Subject: [R] Return value from function with For loop
In-Reply-To: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
References: <CAMLd9E4r5i88fgMztGP1GxQUD9vhq1O_M+pMGONP9kV7kk1uzw@mail.gmail.com>
Message-ID: <CAF8bMcb_urZHeu-Q3Ui0XQ4MuKPeh6HF-dCzHDZatK8cp7wORQ@mail.gmail.com>

A long time ago (before the mid-1990's?) with S or S+
   ff <- function(n){ for(i in 1:n) (i+1)
   op <- ff(3)
would result in 'op' being 4, since a for-loop's value
was the value of the last expression executed in the
body of the loop.  The presence of a 'next' or 'break'
in the loop body would affect the return value.

This made the primitive garbage collection used the time
not work so well and was one reason that for-loops with
lots of iterations ran slowly.  Almost no one used
the return value of a for-loop so, to avoid memory issues,
for was changed to always return NULL.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Apr 16, 2017 at 7:26 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> In the code below
>
>
> *ff <- function(n){ for(i in 1:n) (i+1)}*
>
> *n<-3;ff(n)->op;print(op)*
>
> Why doesnt *print(op) * print 4 and instead prints NULL.
> Isnt the last line of code executed is *i+1 * and therefore that should be
> returned instead of NULL
>
> instead if I say
> *ff <- function(n){ (n+1) }*
>
> Then
> *n<-3;ff(n)->op;rm(n);print(op)*
> gives 4 as output.
>
> My question is *Which *is considered as the last line in a functoin for the
> purpsoe of default return ? And under what conditions ?
>
> -Thanks,
> Ramnik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr 17 20:49:43 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 11:49:43 -0700
Subject: [R] ssa gapfill of series with large window and sparse gaps
	with Rssa
In-Reply-To: <BLUPR09MB01368979B75D68545C3D852FBA060@BLUPR09MB0136.namprd09.prod.outlook.com>
References: <BLUPR09MB01368979B75D68545C3D852FBA060@BLUPR09MB0136.namprd09.prod.outlook.com>
Message-ID: <CAGxFJbQ46W31svNxe-AA1PCn+Jttb+QaiFRaJNTuis+Abq6CZA@mail.gmail.com>

 ... "and explain the best practice given my missing data situation?"

I cannot speak to your other issues, but the above is definitely off
topic for this list, which is about R programming, not statistical
matters. Missing data are certainly a complex issue: you might try a
statistical list like stats.stackexchange.com for opinions on the
above.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 10:38 AM, Ateljevich, Eli at DWR
<Eli.Ateljevich at water.ca.gov> wrote:
> I have several years of univariate wind speed data to which I would like to apply singular spectrum analysis. The data are sampled every 15min and a year is a fundamental periodicity, which suggests L=35,040 values.
>
>
> I would like to fill the gaps. The missing values are scattered at low density throughout the series.  I doubt there is a block of even one month that doesn't have at least a couple pieces of missing data, but I'd surprised to learn the total number are prohibitive.
>
>
> The filling routines in Rssa like igapfill assume a shaped ssa object, so it seems I need to run ssa successfully first before I can fill. When I try this with L=35,040 or anything above about 2,000 I get an error message
> Nothing to decompose: the given field shape is empty
> and warnings like
> Some field elements were not covered by shaped window. 42646 elements will be ommited.
>
>
> This is frustrating, because if I manually fill missing data with the series mean, which I understand as being the first step of igapfill, the decomposition succeeds with L=35040. The operation seems efficient and the spectral components look as expected. But since I have manually created a series with no missing data,  this doesn't help me with gap filling.
>
>
> To concoct a shaped ssa object with the original missing pattern, I invoked force.decompose=FALSE. At that point I can bring my task to completion, but I don't know what I'm doing.  The only examples I see in the docs are not explained and are in 2D.
>
>
> Can someone familiar with this kind of use case explain what the purpose of force.decompose and explain the best practice given my missing data situation? Are there consequences to my workaround? Thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr 17 21:20:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 12:20:21 -0700
Subject: [R] ssa gapfill of series with large window and sparse gaps
	with Rssa
In-Reply-To: <BLUPR09MB01368979B75D68545C3D852FBA060@BLUPR09MB0136.namprd09.prod.outlook.com>
References: <BLUPR09MB01368979B75D68545C3D852FBA060@BLUPR09MB0136.namprd09.prod.outlook.com>
Message-ID: <CAGxFJbTonFd1P6hOrOtWXr_ed5C7XUeft+KUDRBONsMxy+GaCg@mail.gmail.com>

I should probably have added that you should have a look at R's time
series task view:

https://cran.r-project.org/web/views/TimeSeries.html

including anything there on irregular times series (e.g. irts() from
tseries package) and imputation.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 10:38 AM, Ateljevich, Eli at DWR
<Eli.Ateljevich at water.ca.gov> wrote:
> I have several years of univariate wind speed data to which I would like to apply singular spectrum analysis. The data are sampled every 15min and a year is a fundamental periodicity, which suggests L=35,040 values.
>
>
> I would like to fill the gaps. The missing values are scattered at low density throughout the series.  I doubt there is a block of even one month that doesn't have at least a couple pieces of missing data, but I'd surprised to learn the total number are prohibitive.
>
>
> The filling routines in Rssa like igapfill assume a shaped ssa object, so it seems I need to run ssa successfully first before I can fill. When I try this with L=35,040 or anything above about 2,000 I get an error message
> Nothing to decompose: the given field shape is empty
> and warnings like
> Some field elements were not covered by shaped window. 42646 elements will be ommited.
>
>
> This is frustrating, because if I manually fill missing data with the series mean, which I understand as being the first step of igapfill, the decomposition succeeds with L=35040. The operation seems efficient and the spectral components look as expected. But since I have manually created a series with no missing data,  this doesn't help me with gap filling.
>
>
> To concoct a shaped ssa object with the original missing pattern, I invoked force.decompose=FALSE. At that point I can bring my task to completion, but I don't know what I'm doing.  The only examples I see in the docs are not explained and are in 2D.
>
>
> Can someone familiar with this kind of use case explain what the purpose of force.decompose and explain the best practice given my missing data situation? Are there consequences to my workaround? Thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Apr 17 22:43:20 2017
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 17 Apr 2017 14:43:20 -0600
Subject: [R] Plot Arrows with Angle and length
In-Reply-To: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
References: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
Message-ID: <CAFEqCdwnYvL1J5G9yxZ-NKRVRCUv+CnpuMNbDssXTqDTmcxn0A@mail.gmail.com>

You can also look at the my.symbols and ms.arrows functions in the
TeachingDemos package.


On Wed, Mar 29, 2017 at 7:44 AM, julio cesar oliveira <oliveirajc at ufv.br> wrote:
> Dears,
>
> The arrows command uses the start and end coordinates of each vector, but I
> have the starting coordinates, azimuth, and length.
>
> So, There are package that plot this arrows?
>
> Example:
>
>> x<- c(1,2,4)
>> y<- c(2,3,5)
>> Azimuth<- c(45,90,180)
>> Length<- c(1,0.5,1)
>
>
> Thanks,
>
> Julio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From prtkpande at gmail.com  Mon Apr 17 21:20:47 2017
From: prtkpande at gmail.com (prateek pande)
Date: Tue, 18 Apr 2017 00:50:47 +0530
Subject: [R] Binning Data and Event rates
Message-ID: <CAGAjD9=37854f0emFJJFGAXWwvS4FNXMkDovmSjmD+0VVd7Pnw@mail.gmail.com>

I have a data, in the form mentioned below.

Values Churn
21          1
22          1
31.2       1
32          1
35          0
43          1
45           0
67          1
67           0
76           0
89           1

Now i want to bin the values variables into bins and corresponding that
want the churn percentage, like mentioned below
   Binned data  churn%
  (20.9,43.7]    0.83
  (43.7,66.3]    0
  (66.3,89.1]    0.50

Please help

? Return to Rcom-l <http://r.789695.n4.nabble.com/Rcom-l-f930477.html>  |  3
v

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Apr 17 23:58:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 18 Apr 2017 07:58:44 +1000
Subject: [R] Binning Data and Event rates
In-Reply-To: <CAGAjD9=37854f0emFJJFGAXWwvS4FNXMkDovmSjmD+0VVd7Pnw@mail.gmail.com>
References: <CAGAjD9=37854f0emFJJFGAXWwvS4FNXMkDovmSjmD+0VVd7Pnw@mail.gmail.com>
Message-ID: <CA+8X3fU2Wn17xhmPv7D8j3ihTXNuOk_Fcr656hRJDjodXC0djw@mail.gmail.com>

Hi Pateek,
Try this:
ppdat<-read.table(text="Values Churn
 21          1
 22          1
 31.2       1
 32          1
 35          0
 43          1
 45           0
 67          1
 67           0
 76           0
 89           1",
 header=TRUE)
ppdat$Valbin<-cut(ppdat$Values,breaks=c(20.9,43.7,66.3,89.1))
binPct<-function(x) return(100*sum(x)/length(x))
binnedPct<-by(ppdat$Churn,ppdat$Valbin,binPct)
bpctdf<-data.frame('Binned data'=names(binnedPct),
 'churn%'=as.vector(binnedPct))
bpctdf

Jim

On Tue, Apr 18, 2017 at 5:20 AM, prateek pande <prtkpande at gmail.com> wrote:
> I have a data, in the form mentioned below.
>
> Values Churn
> 21          1
> 22          1
> 31.2       1
> 32          1
> 35          0
> 43          1
> 45           0
> 67          1
> 67           0
> 76           0
> 89           1
>
> Now i want to bin the values variables into bins and corresponding that
> want the churn percentage, like mentioned below
>    Binned data  churn%
>   (20.9,43.7]    0.83
>   (43.7,66.3]    0
>   (66.3,89.1]    0.50
>
> Please help
>
> ? Return to Rcom-l <http://r.789695.n4.nabble.com/Rcom-l-f930477.html>  |  3
> v
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Apr 18 00:01:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 17 Apr 2017 15:01:30 -0700
Subject: [R] Difference between console output of cat and print
In-Reply-To: <CALX87Ug53QwijrK=jQKcOUQpvjyMz3LoYTPmbh01Bwkzw9nC0Q@mail.gmail.com>
References: <CALX87Ug53QwijrK=jQKcOUQpvjyMz3LoYTPmbh01Bwkzw9nC0Q@mail.gmail.com>
Message-ID: <CF04C63B-F024-44B0-B74B-FA67544A5C1D@dcn.davis.ca.us>

Please stop posting html email per the Posting Guide. You are only going to reduce the chance of successfully communicating your questions to experienced users on this list.

Re cat vs print: the purpose of print is to show values much as they are entered in source code, so quotes and escaped characters such as "\n" are shown. Cat is intended to provide a way to send characters straight to the console so the effects of special characters can be visible (i.e. getting text on the next line when a "\n" occurs in a string). Thus the element numbering is not relevant there.
-- 
Sent from my phone. Please excuse my brevity.

On April 17, 2017 12:18:36 AM PDT, Data MagicPro <datamagicpro2017 at gmail.com> wrote:
>Since both *cat * as well as * print * create a character vector for
>outputing on the screen. Still both give different results as apparant
>below. My query is why so ?
>
>
>> cat(10)
>10
>> print(10)
>[1] 10
>
>Why is the [1] of index number missing in case of *cat *?
>
>Thanks
>Ramnik
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Tue Apr 18 00:04:29 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 17 Apr 2017 18:04:29 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
Message-ID: <f80dd350-4105-aacf-3ceb-ebb504b27c83@dmstat1.com>

To _ALL_ who helped me.
In the final analysis, I was doing everything correctly, as per the 
manuals, the links, and the books I bought.
However, in all the material, it never read mention of creating of the 
.Rprofile file
with a programmer/developer text editor, which allows for no extension, 
no R, no txt.

You guys drilled down, and hit solid gold for me,
which lead to my understanding the issue, at least as I see it.

Pure GOLD Medal team work.
Again, I truly thank you.
Bruce

  

BR_email wrote:
> TO _ALL_:
> THANK YOU. THANK YOU. THANK YOU.
> After hours, and hours, and hours, and ... , and hours: Success.
> To all who helped, thanks.
> My quest was minor, but major for me, as I learn from the path of one, 
> whether big or small begets another.
>
> I never look down at anyone, except to help him/her up.
>
> With gratitude,
> Bruce
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> Peter Dalgaard wrote:
>>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>>
>>> Berend: Something looks good, but RStudio still Rprofile still doees 
>>> not affect the launch.
>>>
>>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>> rm(list=ls())
>>> R>
>>>
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>> Berend Hasselman wrote:
>>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
>> According to the gospel of St.Henrik, that filename is wrong, and 
>> possibly the directory too.
>>
>> So try his suggestions. What is the output (show us!) of
>>
>> normalizePath("./.Rprofile")
>> normalizePath("~/.Rprofile")
>>
>> Assuming that the former is
>>
>> "C:/Users/BruceRatner/Documents/.Rprofile"
>>
>> you could try renaming the .Rprofile.site file to that. If need be, 
>> use file.rename, as in
>>
>> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site", 
>> to="C:/Users/BruceRatner/Documents/.Rprofile")
>>
>> (and restart, obviously).
>>
>> [I wouldn't set the seed in a .Rprofile file, nor would I use rm() 
>> there, but that is a different kettle of fish.]
>>
>


From bgunter.4567 at gmail.com  Tue Apr 18 00:30:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Apr 2017 15:30:27 -0700
Subject: [R] Difference between console output of cat and print
In-Reply-To: <CF04C63B-F024-44B0-B74B-FA67544A5C1D@dcn.davis.ca.us>
References: <CALX87Ug53QwijrK=jQKcOUQpvjyMz3LoYTPmbh01Bwkzw9nC0Q@mail.gmail.com>
 <CF04C63B-F024-44B0-B74B-FA67544A5C1D@dcn.davis.ca.us>
Message-ID: <CAGxFJbSy+=qCfju91h2gBL0+FWC3cZVogqYin7cH1vLL9sYGmw@mail.gmail.com>

Well,...

cat() is as Jeff describes.

However, print() is a generic function (see ?UseMethod) for which
there are literally hundreds of different methods that may do far
more/different than merely output character strings. For example, the
print method for trellis objects, print.trellis, draws a graph of the
object.

The print method  called for print(10) is the default method, for
which ?print.default should be consulted: it is actually printing a
vector of length 1, and the print method for vectors labels each line
with the index of the first item printed.

Please read An Intro to R or other R tutorial to learn about S3 methods.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 17, 2017 at 3:01 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Please stop posting html email per the Posting Guide. You are only going to reduce the chance of successfully communicating your questions to experienced users on this list.
>
> Re cat vs print: the purpose of print is to show values much as they are entered in source code, so quotes and escaped characters such as "\n" are shown. Cat is intended to provide a way to send characters straight to the console so the effects of special characters can be visible (i.e. getting text on the next line when a "\n" occurs in a string). Thus the element numbering is not relevant there.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 17, 2017 12:18:36 AM PDT, Data MagicPro <datamagicpro2017 at gmail.com> wrote:
>>Since both *cat * as well as * print * create a character vector for
>>outputing on the screen. Still both give different results as apparant
>>below. My query is why so ?
>>
>>
>>> cat(10)
>>10
>>> print(10)
>>[1] 10
>>
>>Why is the [1] of index number missing in case of *cat *?
>>
>>Thanks
>>Ramnik
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Apr 18 05:20:38 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 18 Apr 2017 13:20:38 +1000
Subject: [R] Strip height in latticeExtra:::useOuterStrips
Message-ID: <000b01d2b7f2$c0630850$412918f0$@bigpond.com>

Hi all

I use latticeExtra::useOuterStrips quite a bit.
The problem of strip height using useOuterStrips came up some time ago but
did not have the time then to work something out so made do with the
default layout.heights of strip = 1

#Data:

df2 <- structure(list(a = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("1", "2"), class = "factor"), 
    b = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 
    2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 
    2L, 2L, 1L, 1L, 2L, 2L), .Label = c("1", "2"), class = "factor"), 
    c = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 
    1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 
    1L, 1L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"), 
    d = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"), 
    rep = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"), 
    x = c(-0.626453810742333, 0.183643324222082, -0.835628612410047, 
    1.59528080213779, 0.329507771815361, -0.820468384118015, 
    0.487429052428485, 0.738324705129217, 0.575781351653492, 
    -0.305388387156356, 1.51178116845085, 0.389843236411431, 
    -0.621240580541804, -2.2146998871775, 1.12493091814311,
-0.0449336090152308, 
    -0.0161902630989461, 0.943836210685299, 0.821221195098089, 
    0.593901321217509, 0.918977371608218, 0.782136300731067, 
    0.0745649833651906, -1.98935169586337, 0.61982574789471, 
    -0.0561287395290008, -0.155795506705329, -1.47075238389927, 
    -0.47815005510862, 0.417941560199702, 1.35867955152904,
-0.102787727342996
    )), .Names = c("a", "b", "c", "d", "rep", "x"), out.attrs =
structure(list(
    dim = structure(c(2L, 2L, 2L, 2L, 2L), .Names = c("a", "b", 
    "c", "d", "rep")), dimnames = structure(list(a = c("a=1", 
    "a=2"), b = c("b=1", "b=2"), c = c("c=1", "c=2"), d = c("d=1", 
    "d=2"), rep = c("rep=1", "rep=2")), .Names = c("a", "b", 
    "c", "d", "rep"))), .Names = c("dim", "dimnames")), row.names = c(NA, 
-32L), class = "data.frame")

str(df2)

library(lattice)
library(laticeExtra)

# This is as per normal
xyplot(x~d|paste(a,b)*c, data = df2)

# Increase strip height to use atop later on for 2 lines of text/panel in
strip
# works OK
xyplot(x~d|paste(a,b)*c, data = df2, 
       par.settings = list(layout.heights = list(strip = 2.2)))
# no change in strip height
useOuterStrips(xyplot(x~d|paste(a,b)*c, data = df2, 
               par.settings = list(layout.heights = list(strip = 2.2))))

I have played around with various vector and list combinations for strip in
layout.heights to no avail
Does any one have an answer?

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


From swbueno at gmail.com  Tue Apr 18 05:28:56 2017
From: swbueno at gmail.com (Santiago Bueno)
Date: Mon, 17 Apr 2017 23:28:56 -0400
Subject: [R] R help
Message-ID: <CAGfmZu73wFTqg_F3LK=dBOuBcs6s0R3ScveGzWXnd0fv51wukQ@mail.gmail.com>

I need help with R, and although I have posted my questions, no one seems
to care. Can some one coach me in formulating a correct question?

Regards,

Santiago

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Apr 18 05:43:48 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 17 Apr 2017 23:43:48 -0400
Subject: [R] Strip height in latticeExtra:::useOuterStrips
In-Reply-To: <000b01d2b7f2$c0630850$412918f0$@bigpond.com>
References: <000b01d2b7f2$c0630850$412918f0$@bigpond.com>
Message-ID: <CAGx1TMBvADYqFOgUbSU9=0SpSvp11hFup3ERU6vtsa9Gf3fTvQ@mail.gmail.com>

You had a typo.

library(latticeExtra)

Try this.  I am solving what I think is a problem related to yours.  I set it up
as a three-way plot instead of pasting two of the measures together.

## install.packages("HH") ## if necessary
library(HH)
tmp <- xyplot(x ~ d | a*b*c, data = df2,
       par.settings = list(layout.heights = list(strip = 2.2)))
useOuterStripsT2L1(tmp)

Rich

On Mon, Apr 17, 2017 at 11:20 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi all
>
> I use latticeExtra::useOuterStrips quite a bit.
> The problem of strip height using useOuterStrips came up some time ago but
> did not have the time then to work something out so made do with the
> default layout.heights of strip = 1
>
> #Data:
>
> df2 <- structure(list(a = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("1", "2"), class = "factor"),
>     b = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
>     2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
>     2L, 2L, 1L, 1L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
>     c = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>     1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L,
>     1L, 1L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
>     d = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
>     rep = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
>     x = c(-0.626453810742333, 0.183643324222082, -0.835628612410047,
>     1.59528080213779, 0.329507771815361, -0.820468384118015,
>     0.487429052428485, 0.738324705129217, 0.575781351653492,
>     -0.305388387156356, 1.51178116845085, 0.389843236411431,
>     -0.621240580541804, -2.2146998871775, 1.12493091814311,
> -0.0449336090152308,
>     -0.0161902630989461, 0.943836210685299, 0.821221195098089,
>     0.593901321217509, 0.918977371608218, 0.782136300731067,
>     0.0745649833651906, -1.98935169586337, 0.61982574789471,
>     -0.0561287395290008, -0.155795506705329, -1.47075238389927,
>     -0.47815005510862, 0.417941560199702, 1.35867955152904,
> -0.102787727342996
>     )), .Names = c("a", "b", "c", "d", "rep", "x"), out.attrs =
> structure(list(
>     dim = structure(c(2L, 2L, 2L, 2L, 2L), .Names = c("a", "b",
>     "c", "d", "rep")), dimnames = structure(list(a = c("a=1",
>     "a=2"), b = c("b=1", "b=2"), c = c("c=1", "c=2"), d = c("d=1",
>     "d=2"), rep = c("rep=1", "rep=2")), .Names = c("a", "b",
>     "c", "d", "rep"))), .Names = c("dim", "dimnames")), row.names = c(NA,
> -32L), class = "data.frame")
>
> str(df2)
>
> library(lattice)
> library(laticeExtra)
>
> # This is as per normal
> xyplot(x~d|paste(a,b)*c, data = df2)
>
> # Increase strip height to use atop later on for 2 lines of text/panel in
> strip
> # works OK
> xyplot(x~d|paste(a,b)*c, data = df2,
>        par.settings = list(layout.heights = list(strip = 2.2)))
> # no change in strip height
> useOuterStrips(xyplot(x~d|paste(a,b)*c, data = df2,
>                par.settings = list(layout.heights = list(strip = 2.2))))
>
> I have played around with various vector and list combinations for strip in
> layout.heights to no avail
> Does any one have an answer?
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Tue Apr 18 05:46:37 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 18 Apr 2017 06:46:37 +0300
Subject: [R] Strip height in latticeExtra:::useOuterStrips
In-Reply-To: <000b01d2b7f2$c0630850$412918f0$@bigpond.com>
References: <000b01d2b7f2$c0630850$412918f0$@bigpond.com>
Message-ID: <472031A0-EE67-4E5D-9315-D68D1C436CC4@gmail.com>


> On 18 Apr 2017, at 06:20, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> Hi all
> 
> I use latticeExtra::useOuterStrips quite a bit.
> The problem of strip height using useOuterStrips came up some time ago but
> did not have the time then to work something out so made do with the
> default layout.heights of strip = 1

?useOuterStrips gives the following function body:

useOuterStrips(x,
               strip = strip.default,
               strip.left = strip.custom(horizontal = FALSE),
               strip.lines = 1,
               strip.left.lines = strip.lines)

and set strip.lines = 4. Is this what you want?


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Apr 18 05:50:43 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Apr 2017 03:50:43 +0000
Subject: [R] Binning Data and Event rates
In-Reply-To: <CA+8X3fU2Wn17xhmPv7D8j3ihTXNuOk_Fcr656hRJDjodXC0djw@mail.gmail.com>
References: <CAGAjD9=37854f0emFJJFGAXWwvS4FNXMkDovmSjmD+0VVd7Pnw@mail.gmail.com>
 <CA+8X3fU2Wn17xhmPv7D8j3ihTXNuOk_Fcr656hRJDjodXC0djw@mail.gmail.com>
Message-ID: <15e314db8ec446418dd6518ca827ad87@exch-2p-mbx-w2.ads.tamu.edu>

After creating ppdat and ppdat$Valbin, aggregate() will get you the churn proportions:

> aggregate(Churn~Valbin, ppdat, mean)
       Valbin     Churn
1 (20.9,43.7] 0.8333333
2 (43.7,66.3] 0.0000000
3 (66.3,89.1] 0.5000000


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Monday, April 17, 2017 4:59 PM
To: prateek pande <prtkpande at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Binning Data and Event rates

Hi Pateek,
Try this:
ppdat<-read.table(text="Values Churn
 21          1
 22          1
 31.2       1
 32          1
 35          0
 43          1
 45           0
 67          1
 67           0
 76           0
 89           1",
 header=TRUE)
ppdat$Valbin<-cut(ppdat$Values,breaks=c(20.9,43.7,66.3,89.1))
binPct<-function(x) return(100*sum(x)/length(x))
binnedPct<-by(ppdat$Churn,ppdat$Valbin,binPct)
bpctdf<-data.frame('Binned data'=names(binnedPct),
 'churn%'=as.vector(binnedPct))
bpctdf

Jim

On Tue, Apr 18, 2017 at 5:20 AM, prateek pande <prtkpande at gmail.com> wrote:
> I have a data, in the form mentioned below.
>
> Values Churn
> 21          1
> 22          1
> 31.2       1
> 32          1
> 35          0
> 43          1
> 45           0
> 67          1
> 67           0
> 76           0
> 89           1
>
> Now i want to bin the values variables into bins and corresponding that
> want the churn percentage, like mentioned below
>    Binned data  churn%
>   (20.9,43.7]    0.83
>   (43.7,66.3]    0
>   (66.3,89.1]    0.50
>
> Please help
>
> ? Return to Rcom-l <http://r.789695.n4.nabble.com/Rcom-l-f930477.html>  |  3
> v
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Tue Apr 18 06:26:52 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Apr 2017 04:26:52 +0000
Subject: [R] R help
In-Reply-To: <CAGfmZu73wFTqg_F3LK=dBOuBcs6s0R3ScveGzWXnd0fv51wukQ@mail.gmail.com>
References: <CAGfmZu73wFTqg_F3LK=dBOuBcs6s0R3ScveGzWXnd0fv51wukQ@mail.gmail.com>
Message-ID: <26dfa228adaa4206bd539aad300449cc@exch-2p-mbx-w2.ads.tamu.edu>

The only recent question that I can see you posted (Mar 22) was tagged onto an existing thread so it is possible people assumed you were answering the question raised by the original poster.

Do not use html - learn how to send emails as plain text.

If you have a question, start a new thread, do not add it as a reply to an existing question.

And the usual, post a reproducible example with data and code. Your last question did that. Try posting again, in plain text and creating a new subject line. Use dput() to send your data to the list. Just listing it with print can leave out important information.


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Santiago Bueno
Sent: Monday, April 17, 2017 10:29 PM
To: R-help at r-project.org
Subject: [R] R help

I need help with R, and although I have posted my questions, no one seems
to care. Can some one coach me in formulating a correct question?

Regards,

Santiago

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Tue Apr 18 06:47:01 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Tue, 18 Apr 2017 10:17:01 +0530
Subject: [R] qqplot for binomial distribution
In-Reply-To: <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
 <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>
Message-ID: <CAC8=1ep2=8+hgxqS3CCfCO2OTWq+iv=OtnS0JtWYJBxS62ZifQ@mail.gmail.com>

Dear Boris,

Thank you for your reply.

> dput(count1_vector)
c(5, 6, 4, 4, 6, 5, 4, 5, 3, 7, 5, 5, 3, 4, 8, 6, 10, 2, 4, 6,
8, 4, 4, 6, 8, 5, 6, 3, 7, 9, 4, 7, 5, 7, 3, 4, 5, 2, 11, 7,
8, 5, 5, 6, 3, 2, 3, 5, 9, 6, 5, 6, 7, 3, 10, 7, 6, 4, 9, 5,
7, 3, 7, 3, 2, 3, 4, 5, 10, 4, 5, 5, 6, 7, 4, 8, 7, 5, 5, 4,
8, 7, 9, 4, 4, 4, 7, 5, 4, 10, 4, 5, 6, 1, 3, 5, 4, 7, 4, 6)

set.seed(123)
qqplot(count1_vector,rbinom(n=100,size=100,p=.05))
qqline(count1_vector,distribution = function(probs) { qbinom(probs,
size=100, prob=0.05) },
       col = "red",
       lwd = 0.5)

When I do this, the line does not pass through the center of my data.I do
expect count1_vector to be 100 samples of binomial with n=100 and p=.05.

Any comments or suggestions for me ?

Note : I built a 95% Confidence interval for my data and I counted how
often out of 100 times did the data fall outside the CI.This I expect to be
binomial with n=100,p=.05. I repeated this a 100 times and obtained
count1_vector.

Best Regards,
Ashim.


On Mon, Apr 17, 2017 at 7:51 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> That's not how qqline() works. The line is drawn with respect to a
> _reference_distribution_ which is the normal distribution by default. For
> the binomial distribution, you need to specify the distribution argument.
> There is an example in the help page that shows you how this is done for
> qchisq(). for qbinom() it is:
>
>
> set.seed(123)
> qqplot(rbinom(n=100, size=100, p=0.05),
>        rbinom(n=100, size=100, p=0.05) )
>
> qqline(rbinom(n=100,size=100,p=.05),
>        distribution = function(probs) { qbinom(probs, size=100, prob=0.05)
> },
>        col = "red",
>        lwd = 0.5)
>
>
>
>
> B.
>
>
> > On Apr 17, 2017, at 9:15 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear Spencer,
> >
> > Okay. Many thanks. My next query is how do I use qqline?
> >
> > When I try
> >
> >> qqline(rbinom(n=100,size=100,p=.05))
> >
> > I don't get the line in the right place.
> >
> > Best Regards,
> > Ashim
> >
> > On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
> > spencer.graves at effectivedefense.org> wrote:
> >
> >>
> >>
> >> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
> >>
> >>> Dear All,
> >>>
> >>> set.seed(123)
> >>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
> >>>
> >>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
> >>>
> >>
> >>
> >>      The distribution is discrete, and points are superimposed. Try the
> >> following:
> >>
> >>
> >> set.seed(123)
> >> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
> >>       jitter(rbinom(n=100,size=100,p=.05) ))
> >>
> >>
> >>      Spencer Graves
> >>
> >>>
> >>> Best Regards,
> >>> Ashim
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr 18 06:50:28 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 17 Apr 2017 21:50:28 -0700
Subject: [R] R help
In-Reply-To: <CAGfmZu73wFTqg_F3LK=dBOuBcs6s0R3ScveGzWXnd0fv51wukQ@mail.gmail.com>
References: <CAGfmZu73wFTqg_F3LK=dBOuBcs6s0R3ScveGzWXnd0fv51wukQ@mail.gmail.com>
Message-ID: <2D1D8138-3A16-44D1-AA0F-7FEA00E028EA@dcn.davis.ca.us>

I am assuming that you are referring to your emails from last October and last month regarding nlme.

A) Read the Posting Guide, which mentions things like the fact that you should set your email program to send plain text when posting on this mailing list , and that there is a dedicated R-sig-mixed-models mailing list where questions about nlme would be more on topic. (The plain text thing is important to avoid us receiving a corrupted version of what you sent, so it is important if we are to understand you.)

B) Don't reply to an existing message on the list with a completely different question... start a fresh email with an informative subject line and all of the replies will show up together in many email programs and in the archives. Hijacked email threads tend to get overlooked, which is not in your best interest. 

C) Make sure your example is reproducible. See for example [1] or [2] or [3] (or all three).

D) A course in linear regression should address when it is reasonable to remove terms, but it is beyond the scope of this list to go into that. Removing the intercept due to large p-values is hardly ever justified. Mixed models of the complexity you are trying to use typically require a lot more data than you showed last month to give significant results. You should probably consult with a local statistician on your experimental design.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
[2] http://adv-r.had.co.nz/Reproducibility.html
[3] https://cran.r-project.org/web/packages/reprex/index.html

-- 
Sent from my phone. Please excuse my brevity.

On April 17, 2017 8:28:56 PM PDT, Santiago Bueno <swbueno at gmail.com> wrote:
>I need help with R, and although I have posted my questions, no one
>seems
>to care. Can some one coach me in formulating a correct question?
>
>Regards,
>
>Santiago
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From d.a.molinari at gmail.com  Tue Apr 18 00:20:30 2017
From: d.a.molinari at gmail.com (Daniel Molinari)
Date: Mon, 17 Apr 2017 19:20:30 -0300
Subject: [R] Question on accessing foreign files
Message-ID: <CAKS2kSW-0GA7Ff8gBg_=94OTP8TPbpDk4godEyJrMZdj1ZAtqg@mail.gmail.com>

Hi all,

I have several data files provided in mtw format (Minitab) and sdd format
(S-Plus) and I need to read them in R.

I do not have access either to Minitab or to S-Plus.

How can I accomplish this task ?

Thank you,
Daniel

	[[alternative HTML version deleted]]


From John.Nash at uottawa.ca  Tue Apr 18 00:41:46 2017
From: John.Nash at uottawa.ca (John Nash)
Date: Mon, 17 Apr 2017 22:41:46 +0000
Subject: [R] Fwd: Re: Setting .Rprofile for RStudio on a Windows 7 x64bit /
 Windows file extension hiding
In-Reply-To: <0d012826-cdb5-ce53-7bbe-22d6713b6083@uottawa.ca>
References: <0d012826-cdb5-ce53-7bbe-22d6713b6083@uottawa.ca>
Message-ID: <370b36f5-c91b-979c-e756-6bce5d6a0926@uottawa.ca>


The very large amount of noise on this topic seems to be the result of allowing
Windows to hide file extensions. We have had to put up with millions of malware
infections because someone in M$ thought this would be a nice idea. I've seen it
cause lots of problems over the years, including among my own family.

Perhaps someone can create a check and repair that automatically turns this "feature" off
whenever R is run. One reason among the many why I run Linux.

JN

From murdoch.duncan at gmail.com  Tue Apr 18 15:12:44 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Apr 2017 09:12:44 -0400
Subject: [R] Fwd: Re: Setting .Rprofile for RStudio on a Windows 7
 x64bit / Windows file extension hiding
In-Reply-To: <370b36f5-c91b-979c-e756-6bce5d6a0926@uottawa.ca>
References: <0d012826-cdb5-ce53-7bbe-22d6713b6083@uottawa.ca>
 <370b36f5-c91b-979c-e756-6bce5d6a0926@uottawa.ca>
Message-ID: <04bc4f16-7277-ee31-dc0b-7c77f7ca6eb4@gmail.com>

On 17/04/2017 6:41 PM, John Nash wrote:
>
> The very large amount of noise on this topic seems to be the result of allowing
> Windows to hide file extensions. We have had to put up with millions of malware
> infections because someone in M$ thought this would be a nice idea. I've seen it
> cause lots of problems over the years, including among my own family.
>
> Perhaps someone can create a check and repair that automatically turns this "feature" off
> whenever R is run. One reason among the many why I run Linux.
>

MacOS does this now too, though it feels less aggressive than Windows. 
This page tells how to disable it there: 
https://support.apple.com/kb/ph19072?locale=en_US

There's little point providing a link to a Microsoft page for doing this 
on Windows, because their help page links are not very durable.  The 
main one that Google finds describes itself as obsolete.

Duncan Murdoch


From jspark4 at uic.edu  Tue Apr 18 15:52:26 2017
From: jspark4 at uic.edu (Sparks, John James)
Date: Tue, 18 Apr 2017 08:52:26 -0500
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
Message-ID: <eb847f67de5c4b5cd765b8912e1d5b2d.squirrel@webmail.uic.edu>

Bruce,

Do you think that you could post the final solution to the problem?  That
way it would be stored with this thread and the next person who has the
same problem would be able to locate the FINAL solution.

--JJS


On Mon, April 17, 2017 12:47 pm, BR_email wrote:
> TO _ALL_:
> THANK YOU. THANK YOU. THANK YOU.
> After hours, and hours, and hours, and ... , and hours: Success.
> To all who helped, thanks.
> My quest was minor, but major for me, as I learn from the path of one,
> whether big or small begets another.
>
> I never look down at anyone, except to help him/her up.
>
> With gratitude,
> Bruce
>
> Bruce Ratner, Ph.D.
> The Significant Statistician???
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> Peter Dalgaard wrote:
>>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>>
>>> Berend: Something looks good, but RStudio still Rprofile still doees
>>> not affect the launch.
>>>
>>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>> options(prompt="R> ")
>>>> set.seed(12345)
>>>> rm(list=ls())
>>> R>
>>>
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician???
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>> Berend Hasselman wrote:
>>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
>> According to the gospel of St.Henrik, that filename is wrong, and
>> possibly the directory too.
>>
>> So try his suggestions. What is the output (show us!) of
>>
>> normalizePath("./.Rprofile")
>> normalizePath("~/.Rprofile")
>>
>> Assuming that the former is
>>
>> "C:/Users/BruceRatner/Documents/.Rprofile"
>>
>> you could try renaming the .Rprofile.site file to that. If need be, use
>> file.rename, as in
>>
>> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site",
>> to="C:/Users/BruceRatner/Documents/.Rprofile")
>>
>> (and restart, obviously).
>>
>> [I wouldn't set the seed in a .Rprofile file, nor would I use rm()
>> there, but that is a different kettle of fish.]
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Apr 18 16:26:40 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 18 Apr 2017 10:26:40 -0400
Subject: [R] qqplot for binomial distribution
In-Reply-To: <CAC8=1ep2=8+hgxqS3CCfCO2OTWq+iv=OtnS0JtWYJBxS62ZifQ@mail.gmail.com>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
 <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>
 <CAC8=1ep2=8+hgxqS3CCfCO2OTWq+iv=OtnS0JtWYJBxS62ZifQ@mail.gmail.com>
Message-ID: <2575DB8F-9ACD-48D6-B6DD-5AEA9D709AEB@utoronto.ca>

As per the help pages, the data samples are expected in the second argument, "y".

So try 
  qqplot(rbinom(n=100, size=100, p=0.05), count1_vector)

... and then plot your qqline()

Alternatively, try

qqline(count1_vector,
       distribution = function(probs) { qbinom(probs, size=100, prob=0.05) },
       datax = TRUE, # <- logical. Should data values be on the x-axis?
       col = "red",
       lwd = 0.5)
... and use your original qqplot()


B.


> On Apr 18, 2017, at 12:47 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear Boris,
> 
> Thank you for your reply. 
> 
> > dput(count1_vector)
> c(5, 6, 4, 4, 6, 5, 4, 5, 3, 7, 5, 5, 3, 4, 8, 6, 10, 2, 4, 6, 
> 8, 4, 4, 6, 8, 5, 6, 3, 7, 9, 4, 7, 5, 7, 3, 4, 5, 2, 11, 7, 
> 8, 5, 5, 6, 3, 2, 3, 5, 9, 6, 5, 6, 7, 3, 10, 7, 6, 4, 9, 5, 
> 7, 3, 7, 3, 2, 3, 4, 5, 10, 4, 5, 5, 6, 7, 4, 8, 7, 5, 5, 4, 
> 8, 7, 9, 4, 4, 4, 7, 5, 4, 10, 4, 5, 6, 1, 3, 5, 4, 7, 4, 6)
> 
> set.seed(123)
> qqplot(count1_vector,rbinom(n=100,size=100,p=.05))
> qqline(count1_vector,distribution = function(probs) { qbinom(probs, size=100, prob=0.05) },
>        col = "red",
>        lwd = 0.5)
> 
> When I do this, the line does not pass through the center of my data.I do expect count1_vector to be 100 samples of binomial with n=100 and p=.05. 
> 
> Any comments or suggestions for me ? 
> 
> Note : I built a 95% Confidence interval for my data and I counted how often out of 100 times did the data fall outside the CI.This I expect to be binomial with n=100,p=.05. I repeated this a 100 times and obtained count1_vector.
> 
> Best Regards,
> Ashim. 
> 
> 
> On Mon, Apr 17, 2017 at 7:51 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> That's not how qqline() works. The line is drawn with respect to a _reference_distribution_ which is the normal distribution by default. For the binomial distribution, you need to specify the distribution argument. There is an example in the help page that shows you how this is done for qchisq(). for qbinom() it is:
> 
> 
> set.seed(123)
> qqplot(rbinom(n=100, size=100, p=0.05),
>        rbinom(n=100, size=100, p=0.05) )
> 
> qqline(rbinom(n=100,size=100,p=.05),
>        distribution = function(probs) { qbinom(probs, size=100, prob=0.05) },
>        col = "red",
>        lwd = 0.5)
> 
> 
> 
> 
> B.
> 
> 
> > On Apr 17, 2017, at 9:15 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear Spencer,
> >
> > Okay. Many thanks. My next query is how do I use qqline?
> >
> > When I try
> >
> >> qqline(rbinom(n=100,size=100,p=.05))
> >
> > I don't get the line in the right place.
> >
> > Best Regards,
> > Ashim
> >
> > On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
> > spencer.graves at effectivedefense.org> wrote:
> >
> >>
> >>
> >> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
> >>
> >>> Dear All,
> >>>
> >>> set.seed(123)
> >>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
> >>>
> >>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
> >>>
> >>
> >>
> >>      The distribution is discrete, and points are superimposed. Try the
> >> following:
> >>
> >>
> >> set.seed(123)
> >> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
> >>       jitter(rbinom(n=100,size=100,p=.05) ))
> >>
> >>
> >>      Spencer Graves
> >>
> >>>
> >>> Best Regards,
> >>> Ashim
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From br at dmstat1.com  Tue Apr 18 17:26:51 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Tue, 18 Apr 2017 11:26:51 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <eb847f67de5c4b5cd765b8912e1d5b2d.squirrel@webmail.uic.edu>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com> <eb847f67de5c4b5cd765b89!
 12e1d5b2d.squirrel@webmail.uic.edu>
Message-ID: <E438190D-7685-448B-B106-683F8FCA1E32@dmstat1.com>

Dear John:
My pleasure to respond to your request. 
Problem: Cannot get the .Rprofile file to take affect in either R (or RStudio). 
As to "what" can be in put into a  .Rprofile file is abound, many examples in the manuals, blogs, links, and books. 

The "how to" write the file was the real issue, not clearly covered in any material I could find or purchase.

I read that any notepad-type app can be used to create the .Rprofile file: 
1. with or without a txt/R extension, and/or
2. with or without Administrator permission. 

Not being a professional programmer/developer, I did not know about text editors that can create files with no extension, which was the problem at hand.

After many back and forth drilling down by R-helpers with trouble shooting queries, it became clear that I was not using a developer's text editor. 

Solution: I found an editor online, EditPad Pro 7 (for Windows), with which I created my .Rprofile file. 

The result was complete success, and gratitude to all R-helpers who stuck by me, 
understanding I am new to R, with non professional programming skills. As a statistician (or if you prefer data scientist) for twenty plus years, clearly I must know how to program, but not at the pro level or pro understanding. 

John, I hope this write up is satisfactory, if not please let let me know, as I will rewrite until you are happy with it.

It is a nice surprise to hear your wanting to archive the problem-solution, which almost did me in, and which created ill feelings among several R-helpers towards me. 

Regards, 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 18, 2017, at 9:52 AM, Sparks, John James <jspark4 at uic.edu> wrote:
> 
> Bruce,
> 
> Do you think that you could post the final solution to the problem?  That
> way it would be stored with this thread and the next person who has the
> same problem would be able to locate the FINAL solution.
> 
> --JJS
> 
> 
>> On Mon, April 17, 2017 12:47 pm, BR_email wrote:
>> TO _ALL_:
>> THANK YOU. THANK YOU. THANK YOU.
>> After hours, and hours, and hours, and ... , and hours: Success.
>> To all who helped, thanks.
>> My quest was minor, but major for me, as I learn from the path of one,
>> whether big or small begets another.
>> 
>> I never look down at anyone, except to help him/her up.
>> 
>> With gratitude,
>> Bruce
>> 
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>> 
>> 
>> Peter Dalgaard wrote:
>>>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>>> 
>>>> Berend: Something looks good, but RStudio still Rprofile still doees
>>>> not affect the launch.
>>>> 
>>>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>>> options(prompt="R> ")
>>>>> set.seed(12345)
>>>>> rm(list=ls())
>>>> R>
>>>> 
>>>> 
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>> 
>>>> Berend Hasselman wrote:
>>>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
>>> According to the gospel of St.Henrik, that filename is wrong, and
>>> possibly the directory too.
>>> 
>>> So try his suggestions. What is the output (show us!) of
>>> 
>>> normalizePath("./.Rprofile")
>>> normalizePath("~/.Rprofile")
>>> 
>>> Assuming that the former is
>>> 
>>> "C:/Users/BruceRatner/Documents/.Rprofile"
>>> 
>>> you could try renaming the .Rprofile.site file to that. If need be, use
>>> file.rename, as in
>>> 
>>> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site",
>>> to="C:/Users/BruceRatner/Documents/.Rprofile")
>>> 
>>> (and restart, obviously).
>>> 
>>> [I wouldn't set the seed in a .Rprofile file, nor would I use rm()
>>> there, but that is a different kettle of fish.]
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From bogaso.christofer at gmail.com  Tue Apr 18 18:14:29 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 18 Apr 2017 21:44:29 +0530
Subject: [R] Quantmod cant download data
Message-ID: <CA+dpOJm4ANVFoUxbs_R8PXy7K_BhmuwoNP0-fTF1d=4b1KqjYg@mail.gmail.com>

Hi again,

I generally use Quantmod package to download stock data. However
recently I observed that it is unable to download the data although
Source file is available.

Below is Error I found when I use Quantmod :

> library(quantmod)
> getSymbols("^NSEI")
Error in download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
  cannot open URL
'http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv'

However the Source file
"http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv"
is available for manual download.

R version :

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantmod_0.4-7    TTR_0.23-1        xts_0.9-7         zoo_1.8-0
     data.table_1.10.0

loaded via a namespace (and not attached):
[1] grid_3.3.2      lattice_0.20-35

Could you please help to resolve this issue.

Thanks for your time.


From josh.m.ulrich at gmail.com  Tue Apr 18 18:16:16 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 18 Apr 2017 11:16:16 -0500
Subject: [R] Quantmod cant download data
In-Reply-To: <CA+dpOJm4ANVFoUxbs_R8PXy7K_BhmuwoNP0-fTF1d=4b1KqjYg@mail.gmail.com>
References: <CA+dpOJm4ANVFoUxbs_R8PXy7K_BhmuwoNP0-fTF1d=4b1KqjYg@mail.gmail.com>
Message-ID: <CAPPM_gTeYnqQ1R1dWh1Y-kD1Hz=-BEjoy8TgEuLQpz43R-YGFw@mail.gmail.com>

See https://github.com/joshuaulrich/quantmod/issues/149

On Tue, Apr 18, 2017 at 11:14 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I generally use Quantmod package to download stock data. However
> recently I observed that it is unable to download the data although
> Source file is available.
>
> Below is Error I found when I use Quantmod :
>
>> library(quantmod)
>> getSymbols("^NSEI")
> Error in download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=", from.m,  :
>   cannot open URL
> 'http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv'
>
> However the Source file
> "http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv"
> is available for manual download.
>
> R version :
>
> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: macOS Sierra 10.12.3
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] quantmod_0.4-7    TTR_0.23-1        xts_0.9-7         zoo_1.8-0
>      data.table_1.10.0
>
> loaded via a namespace (and not attached):
> [1] grid_3.3.2      lattice_0.20-35
>
> Could you please help to resolve this issue.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From wdunlap at tibco.com  Tue Apr 18 18:31:54 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 18 Apr 2017 09:31:54 -0700
Subject: [R] Question on accessing foreign files
In-Reply-To: <CAKS2kSW-0GA7Ff8gBg_=94OTP8TPbpDk4godEyJrMZdj1ZAtqg@mail.gmail.com>
References: <CAKS2kSW-0GA7Ff8gBg_=94OTP8TPbpDk4godEyJrMZdj1ZAtqg@mail.gmail.com>
Message-ID: <CAF8bMcaKyX+mayEnG+cfrzWpUMGg1Q0mQ4bWhMvGHox7rmr6RA@mail.gmail.com>

I've attached data.restore4.txt, containing the function
data.restore4(), which has the same argument list as
foreign::data.restore() and is mean to be called by the latter if the
first line of the file is "## Dump S Version 4 Dump".   It can read
version 4 of the 'S data dump' format, which for which S+ uses the
file extension ".sdd".  It stores the objects it reads in the
environment specified by the 'env' argument/.

I think it works pretty well; please report any issues to me.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 17, 2017 at 3:20 PM, Daniel Molinari <d.a.molinari at gmail.com> wrote:
> Hi all,
>
> I have several data files provided in mtw format (Minitab) and sdd format
> (S-Plus) and I need to read them in R.
>
> I do not have access either to Minitab or to S-Plus.
>
> How can I accomplish this task ?
>
> Thank you,
> Daniel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
data.restore4 <- function(file, print = FALSE, verbose = FALSE, env = .GlobalEnv)
{
    # Like foreign::data.restore, but for S Version 4 data.dump format
    # TODO: when creating functions within functions or expressions, make the inner
    #    ones calls to function(), not already-created functions.  Splus does
    #    not have lexical scoping so this should not affect behavior, but makes
    #    the new  function more R-like.
    #    Dumping the function to a file and sourcing it back in would have the same
    #    effect.
    # TODO: deal with stored Splus objects that have an implicit class
    #    but no "class" attribute.  Except for "matrix" and "array" I don't
    #    think Splus creates such objects, but they exist in the 'data' package
    #    and they depend on getOldClass() to map the class field in the data.dump
    #    to a class vector in the object.  E.g., get("wafer", where="data") has
    #    class 'design' which should become attribute class=c("design", "data.frame").
    #    Some 'ordered' objects are analogous - no class attribute and class field is 'ordered' so you
    #    have to know that 'ordered' means class=c("ordered","factor").
    #    "factor" and "ordered" may also be stored without a named ".Label" attribute.
    #    (I have dealt with the factor the matrix/array objects are commonly stored without
    #    named attributes - I assume that the structure has length 3 and the attributes
    #    are ".Dims" and ".Dimnames".)
    origFile <- file
    if (!inherits(file, "connection")) {
        file <- file(file, "r")
        on.exit(close(file))
    }
    lineNo <- 0
    nextLine <- function(n = 1) {
        lineNo <<- lineNo + n
        readLines(file, n = n)
    }
    Verbosely <- function(...) {
        if (verbose) {
            message(simpleMessage(paste("(object ", objName, ", line ", lineNo, ") ", paste(..., collapse = " ", sep = ""), sep = ""), sys.call(-1)))
        }
    }
    Stop <- function(...) {
        stop(simpleError(paste(paste(..., collapse = " ", sep = ""), sep = "",
            " (object ", objName, ", file ", deparse(summary(file)$description), ", line ", lineNo, ")"), sys.call(-1)))
    }
    Recurse <- function(length) {
        # Never call 'blah <- .data.restore4()' directly as it may return a missing
        # argument object, which will break '<-' but not lapply.
        lapply(seq_len(length), function(i) { .data.restore4() })
    }
    constructMissingArgument <- function() formals(function(x)NULL)$x
    txt <- nextLine()
    objName <- "<none yet>"
    if (length(txt) != 1) {
        Stop("File is empty")
    }
    if (txt != "## Dump S Version 4 Dump ##") {
        Stop("File does not start with '## Dump S Version 4 Dump', so this is not a SV4 data.dump file")
    }
    .data.restore4 <- function()
    {
        class <- nextLine()
        mode <- nextLine()
        length <- as.numeric(tmp <- nextLine())
        if (is.na(length) || length%%1 != 0 || length < 0) {
            Stop("Expected nonnegative integer 'length' at line ", lineNo, " but got ", deparse(tmp))
        }
        if (mode == "character") {
            ret <- nextLine(length)
            # convert \\n to newline, \\t to tab, etc. by using parse()
            vapply(ret, function(string)parse(text=paste0("\"", string, "\""))[[1]], FUN.VALUE="", USE.NAMES=FALSE)
        } else if (mode == "logical") {
            txt <- nextLine(length)
            lglVector <- rep(NA, length)
            lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
            lglVector
        } else if (mode %in% c("integer", "single", "numeric")) {
            txt <- nextLine(length)
            txt[txt == "M"] <- "NaN"
            txt[txt == "I"] <- "Inf"
            txt[txt == "J"] <- "-Inf"
            if (mode == "single") {
                mode <- "numeric"
            }
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "complex") {
            txt <- nextLine(length)
            txt <- gsub("M", "NaN", txt)
            txt <- gsub("\\<I\\>", "Inf", txt)
            txt <- gsub("\\<J\\>", "-Inf", txt)
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "list") {
            vectors <- Recurse(length)
            vectors
        } else if (mode == "NULL") {
            NULL
        } else if (mode == "structure") {
            vectors <- Recurse(length)
            if (class == ".named_I" || class == "named") {
                if (length != 2) {
                    Stop("expected length of '.named_I' component is 2, but got ", length)
                } else if (!is.character(vectors[[2]])) {
                    Stop("expected second component of '.named_I' to be character, but got ", deparse(mode(vectors[[2]])))
                }
                vector <- vectors[[1]]
                names <- vectors[[2]]
                if (is.call(vector) && identical(vector[[1]], as.name("for"))) {
                    if (length(names) != 3 || !all(names[2:3]  == "")) {
                        Stop("expected only first entry of 'names' for 'for' to be non-blank, but got ", deparse(names))
                    }
                    vector[[2]] <- as.name(names[1])
                    vector
                } else if (is.call(vector) && identical(vector[[1]], as.name(".Call"))) {
                    if (length(vector) - 1 != length(names)) {
                        Stop("expected lengths of names and .Call to be the same, but got ", length(vector) - 1, " and ", length(names))
                    }
                    vector[[2]] <- names[1]
                    names[1] <- ""
                    if (any(names != "")) {
                        names(vector) <- c("", names)
                    }
                    vector
                } else if (is.call(vector) && identical(vector[[1]], as.name(".Internal"))) {
                    if (length(vector) - 1 != length(names)) {
                        Stop("expected lengths of names and .Internal to be the same, but got ", length(vector) - 1, " and ", length(names))
                    }
                    Verbosely("Splus call to '.Internal' will not work in R (or TERR)\n")
                    vector[[3]] <- names[2]
                    vector
                } else if (is.call(vector) && identical(vector[[1]], as.name("function"))) {
                    if (length(vector) - 1 != length(names)) {
                        Stop("expected lengths of argument names and function to be the same, but got ", length(vector) - 1, " and ", length(names))
                    }
                    func <- function()NULL
                    formals(func) <- as.pairlist( structure(as.list(vector)[-c(1,length(vector))], names=names[-length(names)]) )
                    body(func) <- vector[[length(vector)]]
                    environment(func) <- env
                    func
                } else if (is.call(vector) && identical(vector[[1]], as.name("return"))) {
                    # In Splus, names are added to return(x,y) when return has more than one argument
                    Verbosely("Multi-argument returns will fail in R (or TERR): changing return(...) to return(list(...))\n")
                    if (length(vector)-1  != length(names)) {
                        Stop("expected number of returned items length of their name to be the same, but got ", length(vector)-1, " and ", length(names))
                    }
                    if (any(names != "")) {
                        names(vector) <- c("", names)
                    }
                    vector[[1]] <- as.name("list")
                    call("return", vector)
                } else {
                    # finally, attributes
                    if (length(vector) != length(names)) {
                        Stop("expected lengths of '.named_I' components to be the same, but got ", length(vector), " and ", length(names))
                    }
                    names(vector) <- names
                    if (identical(names[1], ".Data")) { # a hack - really want to know if vector had mode "structure" or not
                        if (".Tsp" %in% names) {
                            # ancient Splus objects have dates in .Tsp rounded to 6 significant digits
                            i <- which(".Tsp" == names)
                            if (length(i) != 1) {
                                Stop("Multiple '.Tsp' attributes on object")
                            }
                            tsp <- vector[[i]]
                            if (length(tsp) != 3 || !is.numeric(tsp)) {
                                Stop("'.Tsp' attribute should contain 3 numbers, but got ", deparse(tsp))
                            }
                            n <- round( (tsp[2] - tsp[1]) * tsp[3] + 1)
                            vector[[i]] <- c(tsp[1], tsp[1] + (n-1) / tsp[3], tsp[3])
                            if ( abs(tsp[2] - vector[[i]][2])/abs(tsp[2]) > 1e-8 ) {
                                Verbosely("Fixed up rounded '.Tsp' from ", deparse(tsp), " to ", deparse(vector[[i]]))
                            }
                        }
                        do.call(structure, vector, quote = TRUE)
                    } else {
                        vector
                    }
                }
            } else if (class %in% c("matrix", "array")) {
                if (length != 3) {
                    Stop("Expected 'matrix' or 'array' structures to have length 3, but got ", length)
                }
                array(vectors[[1]], dim=vectors[[2]], dimnames=vectors[[3]])
            } else {
                vectors # TODO: this is ok within a .Named_I/structure object, but otherwise means we omitted a known class (like 'factor' or 'ordered')
            }
        } else if (mode == "name") {
            if (length != 1) {
                Stop("expected length of 'name' objects is 1, but got", length)
            }
            name <- as.name(nextLine())
            # NULL is the NULL object itself in R, but a name bound to it in Splus
            if (identical(name, as.name("NULL"))) {
                NULL
            } else {
                name
            }
        } else if (mode == "call") {
            callList <- Recurse(length)
            as.call(callList)
        } else if (mode == "expression") {
            exprList <- Recurse(length)
            as.expression(exprList)
        } else if (mode %in% c("<-", "=", "<<-", "if", "{", "while", "repeat", "break", "next", "return")) {
            if (mode == "<<-") {
                Verbosely("The '<<-' operator acts differently in R (or TERR) and Splus")
            }
            as.call(c(list(as.name(mode)), Recurse(length)))
        } else if (mode == "for") {
            # Splus: list(loopVar = NULL, quote(sequenceCall), quote(bodyCall))
            # R: list(as.name("for"), as.name("loopVar"), quote(sequenceCall), quote(bodyCall))
            # In Splus, the loopVar is a name for the list, which gets added later by .named_I
            as.call(c(list(as.name(mode)), Recurse(length)))
        } else if (mode == "function") {
            # As with "for", this will be further processed by .named_I (if it has any arguments)
            if (length > 1) {
                as.call(c(list(as.name(mode)), Recurse(length)))
            } else {
                func <- function()NULL
                # body(func) <- .data.restore4()
                body(func) <- Recurse(length)[[1]]
                environment(func) <- env
                func
            }
        } else if (mode == ".Call") {
            # again, must finish processing via .named_I (the C function name will be in names(call))
            as.call(c(list(as.name(mode)), Recurse(length)))
        } else if (mode == "internal") {
            # again, must finish processing via .named_I (the C function name will be in names(call))
            as.call(c(list(as.name(".Internal")), Recurse(length)))
        } else if (mode == "missing") {
            constructMissingArgument()
        } else if (mode == "call with ...") {
            if (length != 1) {
                Stop("Expected length of 'call with ...' item to be 1, but it was ", length)
            }
            # call <- .data.restore4()
            call <- Recurse(length)[[1]]
            if (!is.call(call)) {
                Stop("Expected child to 'call with ...' to be a call, but it is a ", mode(call), "\n")
            }
            call
        } else if (mode == "comment expression") {
            if (length != 2) {
                Stop("Expected length of 'comment expression' is 2, but it was ", length)
            }
            commExprList <- Recurse(length)
            if (!is.character(commExprList[[1]])) {
                Stop("Expected first component of 'comment expression' to be character, but it was ", mode(commExprList[[1]]))
            }
            commExprList[[2]]
        } else if (mode == "(") {
            callExpr <- Recurse(length)
            as.call(callExpr)
        } else {
            # What else did I miss?
            Stop("Unimplemented mode: ", deparse(mode))
        }
    }
    while (length(objName <- nextLine()) == 1) {
        if (print) {
            cat(deparse(objName), ":\n", sep="")
        }
        Verbosely("Starting to read\n")
        obj <- .data.restore4()
        Verbosely("  class=", deparse(class(obj)), ", size=", object.size(obj), "\n")
        assign(objName, obj, envir=env)
        if (print) {
            cat("    ", class(obj), "\n", sep="")
        }
    }
    origFile
}

From G.Maubach at weinwolf.de  Tue Apr 18 19:06:47 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 18 Apr 2017 19:06:47 +0200
Subject: [R] ggplot2: ..n.. and ..count.. in geom_text
Message-ID: <OF4E9AA0C6.4590035E-ONC1258106.005D7DCE-C1258106.005E02C1@lotus.hawesko.de>

Hi All,

I have the following code:

-- cut 

(g03_02_p02 <- ggplot(data = d_kzb_input) +
  geom_bar(
    mapping = aes(x = v03_02_r01, y = round(..prop.. * 100, 0)),
    fill = c_ww_palette["blue"]) +
  scale_y_continuous(limits = c(0, c_y_limit)) +
  theme_classic() +
  ggtitle(paste0("Question 3",
    "(n = ", <<cases>>, ")")) +  # How can I refer to the number of cases 
for this plot? Is there something like "..n.."?
  xlab("Orders") +
  ylab("Percent") +
  geom_text(
    aes(label = ..count..),  # How can I refer to the counts for the 
labels of the columns?
    color = "white",
    position = position_stack(vjust = 0.5)))

-- cut --

I would like to refer to the internal statistics of the geom_bar():

How can I refer to the number of cases for this plot? Is there something 
like "..n.."?
How can I refer to the counts for the labels of the columns?

Kind regards

Georg


From NordlDJ at dshs.wa.gov  Tue Apr 18 19:13:13 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 18 Apr 2017 17:13:13 +0000
Subject: [R] Quantmod cant download data
In-Reply-To: <CAPPM_gTeYnqQ1R1dWh1Y-kD1Hz=-BEjoy8TgEuLQpz43R-YGFw@mail.gmail.com>
References: <CA+dpOJm4ANVFoUxbs_R8PXy7K_BhmuwoNP0-fTF1d=4b1KqjYg@mail.gmail.com>
 <CAPPM_gTeYnqQ1R1dWh1Y-kD1Hz=-BEjoy8TgEuLQpz43R-YGFw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E9CD9D@WAXMXOLYMB025.WAX.wa.lcl>

The download works for me without any warning message.  The following is my session info.

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] quantmod_0.4-7 TTR_0.23-1     xts_0.9-7      zoo_1.7-14    

loaded via a namespace (and not attached):
[1] tools_3.3.3     grid_3.3.3      lattice_0.20-35
>

And here is the download result.


> getSymbols("SPY", verbose = TRUE)
    As of 0.4-0, 'getSymbols' uses env=parent.frame() and
 auto.assign=TRUE by default.

 This  behavior  will be  phased out in 0.5-0  when the call  will
 default to use auto.assign=FALSE. getOption("getSymbols.env") and 
 getOptions("getSymbols.auto.assign") are now checked for alternate defaults

 This message is shown once per session and may be disabled by setting 
 options("getSymbols.warning4.0"=FALSE). See ?getSymbols for more details.
downloading  SPY .....

trying URL 'http://ichart.finance.yahoo.com/table.csv?s=SPY&a=0&b=01&c=2007&d=3&e=18&f=2017&g=d&q=q&y=0&z=SPY&x=.csv'
Content type 'text/csv' length unknown
downloaded 187 KB

done.
[1] "SPY"
>


Hope this is useful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joshua
> Ulrich
> Sent: Tuesday, April 18, 2017 9:16 AM
> To: Christofer Bogaso
> Cc: r-help
> Subject: Re: [R] Quantmod cant download data
> 
> See https://github.com/joshuaulrich/quantmod/issues/149
> 
> On Tue, Apr 18, 2017 at 11:14 AM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
> > Hi again,
> >
> > I generally use Quantmod package to download stock data. However
> > recently I observed that it is unable to download the data although
> > Source file is available.
> >
> > Below is Error I found when I use Quantmod :
> >
> >> library(quantmod)
> >> getSymbols("^NSEI")
> > Error in download.file(paste(yahoo.URL, "s=", Symbols.name, "&a=",
> from.m,  :
> >   cannot open URL
> >
> 'http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=
> 3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv'
> >
> > However the Source file
> >
> "http://ichart.finance.yahoo.com/table.csv?s=^NSEI&a=0&b=01&c=2007&d=
> 3&e=18&f=2017&g=d&q=q&y=0&z=^NSEI&x=.csv"
> > is available for manual download.
> >
> > R version :
> >
> > R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> > Copyright (C) 2016 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >
> >> sessionInfo()
> > R version 3.3.2 (2016-10-31)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > Running under: macOS Sierra 10.12.3
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-
> 8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] quantmod_0.4-7    TTR_0.23-1        xts_0.9-7         zoo_1.8-0
> >      data.table_1.10.0
> >
> > loaded via a namespace (and not attached):
> > [1] grid_3.3.2      lattice_0.20-35
> >
> > Could you please help to resolve this issue.
> >
> > Thanks for your time.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2017 | www.rinfinance.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Tue Apr 18 19:32:52 2017
From: profjcnash at gmail.com (J C Nash)
Date: Tue, 18 Apr 2017 13:32:52 -0400
Subject: [R] Safeguarded Newton method for function minimization
Message-ID: <b32d3912-5c46-1281-3df5-10def9093ef1@gmail.com>

Recently Marie Boehnstedt reported a bug in the nlm() function for function minimization
when both gradient and hessian are provided. She has provided a work-around for some
cases and it seems this will get incorporated into the R function eventually.

However, despite the great number of packages on CRAN, there does not appear to be a
straightforward Newton approach to function minimization. This may be because providing
the code for a hessian (the matrix of second derivatives) is a lot of work and error-prone.
(R could also use some good tools for Automatic Differentiation). I have also noted that
a number of researchers try to implement textbook methods and run into trouble when maths
and computing are not quite in sync. Therefore, I wrote a simple safeguarded Newton and
put a small package on R-forge at

https://r-forge.r-project.org/R/?group_id=395

Note that Newton's method is used to solve nonlinear equations. In fact, for function
minimization, we apply it to solve g(x) = 0 where g is the gradient and x is the vector
of parameters. In part, safeguards ensure we reduce the function f(x) at each step to avoid
some of the difficulties that may arise from a non-positive-definite hessian.

In the package, I have a very simple quadratic test, the Rosenbrock test function and
the Wood test function. The method fails on the last function -- the hessian is not
positive definite where it stops.

Before submitting this package to CRAN, I would like to see its behaviour on other
test problems, but am lazy enough to wish to avoid creating the hessian code. If anyone
has such code, it would be very welcome. Please contact me off-list. If I get some workable
examples that are open for public view, I'll report back here.

John Nash


From swbueno at gmail.com  Tue Apr 18 20:16:48 2017
From: swbueno at gmail.com (Santiago Bueno)
Date: Tue, 18 Apr 2017 14:16:48 -0400
Subject: [R] Prediction plots
Message-ID: <CAGfmZu6engkO7zmJmG0Ag8z3hUbShYL2s6Gj9Eok9SRkwO1RnQ@mail.gmail.com>

Thanks Boris, the following is an extract of my data. I have developed
biomass models using codes like:

start <- coef (lm(log(Btot)~I(log(dbh**2*haut)),data=dat[dat$Btot>0,]))

start[1] <- exp(start[1])

names(start) <- c("a","b")

M1 <- nls(Btot~a*(dbh**2*haut)**b,data=dat,start=start,weights=1/dat$dbh**4)


start <- coef(lm(log(Btot)~I(log(dbh))+I(log(haut)),data=dat[dat$Btot>0,]))

start[1] <- exp(start[1])

names(start) <- c("a","b1","b2")

M2 <- nls(Btot~a*dbh**b1*haut**b2,data=dat,start=start,weights=1/dat$dbh**4)


Tree No dbh haut Btot
1 35.00 18.90 0.535
2 25.00 16.60 0.248
3 23.00 19.50 0.228
4 13.50 15.60 0.080
5 20.00 18.80 0.172
6 23.00 17.40 0.190
7 29.00 19.90 0.559
8 17.60 18.20 0.117
9 31.00 25.30 0.645
10 26.00 23.50 0.394
11 13.00 13.00 0.038
12 32.00 20.70 0.443
It is my interest to get prediction plots for the models. I have tried to
use the following codes with no success: Let m be one of the fitted models
with dbh as the only entry. To construct a plot of the predictions made by
this model I have tried:
with(dat,plot(dbh,Btot,xlab="Dbh(cm)",ylab="Biomass (t)"))
D <- seq(par("usr")[1],par("usr")[2],length=200)
lines(D,predict(m,newdata=data.frame(dbh=D)),col="red")
For a model m that has dbh and height as entries, I have tried to get its
predictions as follows:
D <- seq(0,180,length=20)
H <- seq(0,61,length=20)
B <- matrix(predict(m,newdata=expand.grid(dbh=D,height=H)),length(D))

Can someone provide help please!!!


Best regards,

Santiago Bueno

	[[alternative HTML version deleted]]


From ess.forall at yahoo.com  Tue Apr 18 19:33:56 2017
From: ess.forall at yahoo.com (Ralf Pfeiffer)
Date: Tue, 18 Apr 2017 17:33:56 +0000 (UTC)
Subject: [R] difference-in-difference method for estimating causal impact,
In-Reply-To: <1789899543.43158.1492533329611@mail.yahoo.com>
References: <1789899543.43158.1492533329611.ref@mail.yahoo.com>
 <1789899543.43158.1492533329611@mail.yahoo.com>
Message-ID: <56055803.3008783.1492536836070@mail.yahoo.com>




Hello, 

i want to estimate the causal impact on a scale variable, using the difference-in-difference-method and the following 4 groups
- control- and treatment group (counterfactual analysis) 
- two periods, measurement before and after treatment.? 

After discovering and estimating the causal effect (of course, only if existing) i like to make deeper analysis, causal mediation analysis, and fixed effects analyisis.??

Does anyone know a package or packages, with which one can do this estimations, calculation and graphics?
Thanks a? lot for any information.
iksmax


   
	[[alternative HTML version deleted]]


From raqueldourado at hotmail.com  Tue Apr 18 20:38:10 2017
From: raqueldourado at hotmail.com (Raquel D.)
Date: Tue, 18 Apr 2017 18:38:10 +0000
Subject: [R] Twitter Analytics Using streamR - subscript out of bounds
Message-ID: <BN6PR2001MB09774AF83E442C6FA8067280B7190@BN6PR2001MB0977.namprd20.prod.outlook.com>

can someone help me? How fix this error?

My code:

library("ROAuth")
library("streamR")
library("rjson")
library("twitteR")

apiKey <- "xxx"
apiSecret <- "xxx"
accessToken <- "xxx"
accessSecret <- "xxx"
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"

my_oauth <- OAuthFactory$new(consumerKey = apiKey, consumerSecret = apiSecret,
                         requestURL = requestURL, accessURL = accessURL, authURL = authURL)


my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))


save(my_oauth, file = "my_oauth.Rdata")

load("my_oauth.Rdata")
filterStream("tweets.json", track = "kinoplex", timeout = 180,
         oauth = my_oauth)


tweets.df <- parseTweets("tweets.json", simplify = TRUE)

ERROR: tweets.df <- parseTweets("tweets.json", simplify = TRUE) Error in results.list[[1]] : subscript out of bounds


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr 18 21:23:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 18 Apr 2017 12:23:50 -0700
Subject: [R] Twitter Analytics Using streamR - subscript out of bounds
In-Reply-To: <BN6PR2001MB09774AF83E442C6FA8067280B7190@BN6PR2001MB0977.namprd20.prod.outlook.com>
References: <BN6PR2001MB09774AF83E442C6FA8067280B7190@BN6PR2001MB0977.namprd20.prod.outlook.com>
Message-ID: <66F076DE-D5C0-4D88-B606-2FB2A5D1BDEB@dcn.davis.ca.us>

I am no expert, but I think any attempt to save your OAuth data is doomed to fail. Solution is don't do it. 
-- 
Sent from my phone. Please excuse my brevity.

On April 18, 2017 11:38:10 AM PDT, "Raquel D." <raqueldourado at hotmail.com> wrote:
>can someone help me? How fix this error?
>
>My code:
>
>library("ROAuth")
>library("streamR")
>library("rjson")
>library("twitteR")
>
>apiKey <- "xxx"
>apiSecret <- "xxx"
>accessToken <- "xxx"
>accessSecret <- "xxx"
>requestURL <- "https://api.twitter.com/oauth/request_token"
>accessURL <- "https://api.twitter.com/oauth/access_token"
>authURL <- "https://api.twitter.com/oauth/authorize"
>
>my_oauth <- OAuthFactory$new(consumerKey = apiKey, consumerSecret =
>apiSecret,
>     requestURL = requestURL, accessURL = accessURL, authURL = authURL)
>
>
>my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem",
>package = "RCurl"))
>
>
>save(my_oauth, file = "my_oauth.Rdata")
>
>load("my_oauth.Rdata")
>filterStream("tweets.json", track = "kinoplex", timeout = 180,
>         oauth = my_oauth)
>
>
>tweets.df <- parseTweets("tweets.json", simplify = TRUE)
>
>ERROR: tweets.df <- parseTweets("tweets.json", simplify = TRUE) Error
>in results.list[[1]] : subscript out of bounds
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From raqueldourado at hotmail.com  Tue Apr 18 22:22:42 2017
From: raqueldourado at hotmail.com (Raquel D.)
Date: Tue, 18 Apr 2017 20:22:42 +0000
Subject: [R] Twitter Analytics Using streamR - subscript out of bounds
In-Reply-To: <66F076DE-D5C0-4D88-B606-2FB2A5D1BDEB@dcn.davis.ca.us>
References: <BN6PR2001MB09774AF83E442C6FA8067280B7190@BN6PR2001MB0977.namprd20.prod.outlook.com>,
 <66F076DE-D5C0-4D88-B606-2FB2A5D1BDEB@dcn.davis.ca.us>
Message-ID: <BN6PR2001MB0977E20464E5CF8BFAD01A96B7190@BN6PR2001MB0977.namprd20.prod.outlook.com>

I have tried this. Same error.


Att;


________________________________
De: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Enviado: ter?a-feira, 18 de abril de 2017 19:23
Para: r-help at r-project.org; Raquel D.; r-help at r-project.org
Assunto: Re: [R] Twitter Analytics Using streamR - subscript out of bounds

I am no expert, but I think any attempt to save your OAuth data is doomed to fail. Solution is don't do it.
--
Sent from my phone. Please excuse my brevity.

On April 18, 2017 11:38:10 AM PDT, "Raquel D." <raqueldourado at hotmail.com> wrote:
>can someone help me? How fix this error?
>
>My code:
>
>library("ROAuth")
>library("streamR")
>library("rjson")
>library("twitteR")
>
>apiKey <- "xxx"
>apiSecret <- "xxx"
>accessToken <- "xxx"
>accessSecret <- "xxx"
>requestURL <- "https://api.twitter.com/oauth/request_token"
>accessURL <- "https://api.twitter.com/oauth/access_token"
>authURL <- "https://api.twitter.com/oauth/authorize"
>
>my_oauth <- OAuthFactory$new(consumerKey = apiKey, consumerSecret =
>apiSecret,
>     requestURL = requestURL, accessURL = accessURL, authURL = authURL)
>
>
>my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem",
>package = "RCurl"))
>
>
>save(my_oauth, file = "my_oauth.Rdata")
>
>load("my_oauth.Rdata")
>filterStream("tweets.json", track = "kinoplex", timeout = 180,
>         oauth = my_oauth)
>
>
>tweets.df <- parseTweets("tweets.json", simplify = TRUE)
>
>ERROR: tweets.df <- parseTweets("tweets.json", simplify = TRUE) Error
>in results.list[[1]] : subscript out of bounds
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From frainj at gmail.com  Tue Apr 18 23:44:26 2017
From: frainj at gmail.com (John C Frain)
Date: Tue, 18 Apr 2017 22:44:26 +0100
Subject: [R] Fwd: Re: Setting .Rprofile for RStudio on a Windows 7
 x64bit / Windows file extension hiding
In-Reply-To: <04bc4f16-7277-ee31-dc0b-7c77f7ca6eb4@gmail.com>
References: <0d012826-cdb5-ce53-7bbe-22d6713b6083@uottawa.ca>
 <370b36f5-c91b-979c-e756-6bce5d6a0926@uottawa.ca>
 <04bc4f16-7277-ee31-dc0b-7c77f7ca6eb4@gmail.com>
Message-ID: <CAHrK517Efv-H_NTSj_Cp6NSUfXKFkW7FYkEX+_dnbDZ4j8w69Q@mail.gmail.com>

At the risk of adding again to the noise on this point I would recommend
that all users of MS Windows enable the display of file name extensions.
This can be done in Windows 10 by opening Windows explorer under the view
item on the ribbon tick file name extensions. At least this will then
display any extensions added by programs when saving files. If a program
does add an extension then you can at least rename the file. Doing this
helps avoid these problems.

The same think can be done in earlier versions of windows explorer which do
not have the ribbon. I think that it is under the View menu item remove the
tick from the box "hide extensions for known file types". Save the revised
options. I don't have exact details as all the PCs that I can access at the
moment have windows 10.

You should note that this problem has consequences for most programs (e.g.
Matlab, Mathematica, Stata, Rats and many others). It is not specific to R.
It appears to work well with MS Office and similar programs in that it is
set up so that their users do not need any knowledge of file name
extensions.

 Under windows 10 if you use notepad when you select "Save As" There is a
save as type option below the file name. The default is Save as text
(*.txt) - in which case the file is saved as filename .txt.  If you select
save as type - all files (*.*) the file is save as filename with out
extension if that is what you want. Even if you edit the file filename and
choose the wrong type the .txt extension may be added.  There is a similar
provision with many other programs. I don't use notepad myself but would
prefer to use notepad++ to edit text files

In Windows 10 any editors that I have used (including notepad, emacs,
rstudio, octave gui and others) can save files starting with a period. The
original MS DOS had 8.3 filenames and a filename starting with a period (.)
was not allowed. This practice continued to some extent in various version
of windows and it was often difficult to use filenames starting with a
period. As different versions of windows and different programs imposed
different restrictions.  I have  encountered such problems over the years.
Possible solutions included using emacs, notepad++ or the windows console
to solve the problem. For various versions of windows google search will
offer a solution.

Again the problem is not with R or Matlab or Octave or Mathematica  or
Stata or Rats or .... but with Windows which pretends to be a very
user-friendly operating system  by hiding many aspects of what it is doing.
When one needs to do serious work one need to understand some of these
hidden aspects. In Linux many of these aspects are on the surface and it
may appear that one need more knowledge to work with Linux.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 18 April 2017 at 14:12, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 17/04/2017 6:41 PM, John Nash wrote:
>
>>
>> The very large amount of noise on this topic seems to be the result of
>> allowing
>> Windows to hide file extensions. We have had to put up with millions of
>> malware
>> infections because someone in M$ thought this would be a nice idea. I've
>> seen it
>> cause lots of problems over the years, including among my own family.
>>
>> Perhaps someone can create a check and repair that automatically turns
>> this "feature" off
>> whenever R is run. One reason among the many why I run Linux.
>>
>>
> MacOS does this now too, though it feels less aggressive than Windows.
> This page tells how to disable it there: https://support.apple.com/kb/p
> h19072?locale=en_US
>
> There's little point providing a link to a Microsoft page for doing this
> on Windows, because their help page links are not very durable.  The main
> one that Google finds describes itself as obsolete.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From robira at clipper.ens.fr  Wed Apr 19 03:55:39 2017
From: robira at clipper.ens.fr (Benjamin Robira)
Date: Wed, 19 Apr 2017 03:55:39 +0200
Subject: [R] Unknown anomaly
Message-ID: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>

Dear Sir,

I writting to you as I am facing an irregularity in R that I do not know
the origin. When doing a sequence from 0 to 1 by 0.02 and assigning it to
a vector (i.e. code: a <- seq(from=0, to=1, by=0.02)) then, when I try to
use the 36th element (and two others behave the same way) it is not
recognized correctly. For instance a[36]==0.7, what should give TRUE,
gives instead FALSE. However, this works fine for element 35 and 37 and
all other elements but two.
I do not know the reason. I restarted my R session and tried on another
computer. This has been the same. None of my colleagues had an answer. I
hope that you would be able to help me fix that as it must be a pretty
straightforward error that I do not realise.

I would be thankful for any help,
With my very Best Regards,
Benjamin.


From sairasaleem550 at gmail.com  Tue Apr 18 21:45:58 2017
From: sairasaleem550 at gmail.com (SAIRA SALEEM)
Date: Tue, 18 Apr 2017 12:45:58 -0700 (PDT)
Subject: [R] r codes
Message-ID: <c02b8e20-2ea3-4f51-9c89-78f915c03907@googlegroups.com>

i required r codes to calculate partial least squares and ridge regression 

From boris.steipe at utoronto.ca  Wed Apr 19 04:53:23 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 18 Apr 2017 22:53:23 -0400
Subject: [R] Unknown anomaly
In-Reply-To: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
References: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
Message-ID: <2ABC4181-12AC-45CA-B96B-457831FC36FD@utoronto.ca>

The concept of equality for numbers that are represented on a computer is frequently misapplied. Consider:

a <- seq(from=0, to=1, by=0.02)

print(a[36])
[1] 0.7

a[36] == 0.7
[1] FALSE

print(a[36], digits=22)
[1] 0.7000000000000000666134

a[36] == 0.7000000000000001
[1] TRUE

All clear?


B.



> On Apr 18, 2017, at 9:55 PM, Benjamin Robira <robira at clipper.ens.fr> wrote:
> 
> Dear Sir,
> 
> I writting to you as I am facing an irregularity in R that I do not know
> the origin. When doing a sequence from 0 to 1 by 0.02 and assigning it to
> a vector (i.e. code: a <- seq(from=0, to=1, by=0.02)) then, when I try to
> use the 36th element (and two others behave the same way) it is not
> recognized correctly. For instance a[36]==0.7, what should give TRUE,
> gives instead FALSE. However, this works fine for element 35 and 37 and
> all other elements but two.
> I do not know the reason. I restarted my R session and tried on another
> computer. This has been the same. None of my colleagues had an answer. I
> hope that you would be able to help me fix that as it must be a pretty
> straightforward error that I do not realise.
> 
> I would be thankful for any help,
> With my very Best Regards,
> Benjamin.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Apr 19 04:59:34 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 18 Apr 2017 22:59:34 -0400
Subject: [R] r codes
In-Reply-To: <c02b8e20-2ea3-4f51-9c89-78f915c03907@googlegroups.com>
References: <c02b8e20-2ea3-4f51-9c89-78f915c03907@googlegroups.com>
Message-ID: <BB1C10E6-2D56-4907-A8B4-767A13DB3A00@utoronto.ca>

Here you go:

https://www.google.ca/search?q=r+partial+least+squares
https://www.google.ca/search?q=r+ridge+regression




> On Apr 18, 2017, at 3:45 PM, SAIRA SALEEM <sairasaleem550 at gmail.com> wrote:
> 
> i required r codes to calculate partial least squares and ridge regression 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Apr 19 06:13:26 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 19 Apr 2017 16:13:26 +1200
Subject: [R] Unknown anomaly
In-Reply-To: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
References: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
Message-ID: <500c22af-0ec0-d35a-a8bb-9322c1084f26@auckland.ac.nz>

On 19/04/17 13:55, Benjamin Robira wrote:
> Dear Sir,
>
> I writting to you as I am facing an irregularity in R that I do not know
> the origin. When doing a sequence from 0 to 1 by 0.02 and assigning it to
> a vector (i.e. code: a <- seq(from=0, to=1, by=0.02)) then, when I try to
> use the 36th element (and two others behave the same way) it is not
> recognized correctly. For instance a[36]==0.7, what should give TRUE,
> gives instead FALSE. However, this works fine for element 35 and 37 and
> all other elements but two.
> I do not know the reason. I restarted my R session and tried on another
> computer. This has been the same. None of my colleagues had an answer. I
> hope that you would be able to help me fix that as it must be a pretty
> straightforward error that I do not realise.
>
> I would be thankful for any help.


See FAQ 7.31.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From tring at gvdnet.dk  Wed Apr 19 07:10:07 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 19 Apr 2017 07:10:07 +0200
Subject: [R] Fwd: Re: Setting .Rprofile for RStudio on a Windows 7
 x64bit / Windows file extension hiding
In-Reply-To: <04bc4f16-7277-ee31-dc0b-7c77f7ca6eb4@gmail.com>
References: <0d012826-cdb5-ce53-7bbe-22d6713b6083@uottawa.ca>
 <370b36f5-c91b-979c-e756-6bce5d6a0926@uottawa.ca>
 <04bc4f16-7277-ee31-dc0b-7c77f7ca6eb4@gmail.com>
Message-ID: <9d111541-c3b8-f540-8949-87f73cd637aa@gvdnet.dk>

Here it is how to make extensions visible before Windows 10

https://support.microsoft.com/en-us/help/865219/how-to-show-or-hide-file-name-extensions-in-windows-explorer

BW

Troels



Den 18-04-2017 kl. 23:44 skrev John C Frain:
> At the risk of adding again to the noise on this point I would recommend
> that all users of MS Windows enable the display of file name extensions.
> This can be done in Windows 10 by opening Windows explorer under the view
> item on the ribbon tick file name extensions. At least this will then
> display any extensions added by programs when saving files. If a program
> does add an extension then you can at least rename the file. Doing this
> helps avoid these problems.
>
> The same think can be done in earlier versions of windows explorer which do
> not have the ribbon. I think that it is under the View menu item remove the
> tick from the box "hide extensions for known file types". Save the revised
> options. I don't have exact details as all the PCs that I can access at the
> moment have windows 10.
>
> You should note that this problem has consequences for most programs (e.g.
> Matlab, Mathematica, Stata, Rats and many others). It is not specific to R.
> It appears to work well with MS Office and similar programs in that it is
> set up so that their users do not need any knowledge of file name
> extensions.
>
>   Under windows 10 if you use notepad when you select "Save As" There is a
> save as type option below the file name. The default is Save as text
> (*.txt) - in which case the file is saved as filename .txt.  If you select
> save as type - all files (*.*) the file is save as filename with out
> extension if that is what you want. Even if you edit the file filename and
> choose the wrong type the .txt extension may be added.  There is a similar
> provision with many other programs. I don't use notepad myself but would
> prefer to use notepad++ to edit text files
>
> In Windows 10 any editors that I have used (including notepad, emacs,
> rstudio, octave gui and others) can save files starting with a period. The
> original MS DOS had 8.3 filenames and a filename starting with a period (.)
> was not allowed. This practice continued to some extent in various version
> of windows and it was often difficult to use filenames starting with a
> period. As different versions of windows and different programs imposed
> different restrictions.  I have  encountered such problems over the years.
> Possible solutions included using emacs, notepad++ or the windows console
> to solve the problem. For various versions of windows google search will
> offer a solution.
>
> Again the problem is not with R or Matlab or Octave or Mathematica  or
> Stata or Rats or .... but with Windows which pretends to be a very
> user-friendly operating system  by hiding many aspects of what it is doing.
> When one needs to do serious work one need to understand some of these
> hidden aspects. In Linux many of these aspects are on the surface and it
> may appear that one need more knowledge to work with Linux.
>
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
> On 18 April 2017 at 14:12, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 17/04/2017 6:41 PM, John Nash wrote:
>>
>>> The very large amount of noise on this topic seems to be the result of
>>> allowing
>>> Windows to hide file extensions. We have had to put up with millions of
>>> malware
>>> infections because someone in M$ thought this would be a nice idea. I've
>>> seen it
>>> cause lots of problems over the years, including among my own family.
>>>
>>> Perhaps someone can create a check and repair that automatically turns
>>> this "feature" off
>>> whenever R is run. One reason among the many why I run Linux.
>>>
>>>
>> MacOS does this now too, though it feels less aggressive than Windows.
>> This page tells how to disable it there: https://support.apple.com/kb/p
>> h19072?locale=en_US
>>
>> There's little point providing a link to a Microsoft page for doing this
>> on Windows, because their help page links are not very durable.  The main
>> one that Google finds describes itself as obsolete.
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Wed Apr 19 04:55:02 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 18 Apr 2017 22:55:02 -0400
Subject: [R] Unknown anomaly
In-Reply-To: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
References: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
Message-ID: <CAGx1TMC48-h5-Hx3sQ9uA8NN1WDwBUDMSpwQsdKGjVtAyx1wjw@mail.gmail.com>

This is the standard behavior of floating point arithmetic on a
digital computer.  Computers use 53-bit finite precision arithmetic.
They do not use infinite precision real numbers. Please see FAQ 7.31
for details.

The FAQ is in the R documentation on your computer in file
   system.file("../../doc/FAQ")
Locate the file from the R prompt and then open in your favorite text editor.


On Tue, Apr 18, 2017 at 9:55 PM, Benjamin Robira <robira at clipper.ens.fr> wrote:
> Dear Sir,
>
> I writting to you as I am facing an irregularity in R that I do not know
> the origin. When doing a sequence from 0 to 1 by 0.02 and assigning it to
> a vector (i.e. code: a <- seq(from=0, to=1, by=0.02)) then, when I try to
> use the 36th element (and two others behave the same way) it is not
> recognized correctly. For instance a[36]==0.7, what should give TRUE,
> gives instead FALSE. However, this works fine for element 35 and 37 and
> all other elements but two.
> I do not know the reason. I restarted my R session and tried on another
> computer. This has been the same. None of my colleagues had an answer. I
> hope that you would be able to help me fix that as it must be a pretty
> straightforward error that I do not realise.
>
> I would be thankful for any help,
> With my very Best Regards,
> Benjamin.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Apr 19 05:12:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 18 Apr 2017 20:12:58 -0700
Subject: [R] Unknown anomaly
In-Reply-To: <2ABC4181-12AC-45CA-B96B-457831FC36FD@utoronto.ca>
References: <d08d5b36d30c05fd27a2162fd3262593.squirrel@squirrelmail.eleves.ens.fr>
 <2ABC4181-12AC-45CA-B96B-457831FC36FD@utoronto.ca>
Message-ID: <CAGxFJbRsuBK5CUTTfhay9kaLapRk9wpnBRw6m3uqAyvDHiRypA@mail.gmail.com>

FAQ 7.31.

-- Bert

(The FAQ's exist for a reason. You should read them!)

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 18, 2017 at 7:53 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> The concept of equality for numbers that are represented on a computer is frequently misapplied. Consider:
>
> a <- seq(from=0, to=1, by=0.02)
>
> print(a[36])
> [1] 0.7
>
> a[36] == 0.7
> [1] FALSE
>
> print(a[36], digits=22)
> [1] 0.7000000000000000666134
>
> a[36] == 0.7000000000000001
> [1] TRUE
>
> All clear?
>
>
> B.
>
>
>
>> On Apr 18, 2017, at 9:55 PM, Benjamin Robira <robira at clipper.ens.fr> wrote:
>>
>> Dear Sir,
>>
>> I writting to you as I am facing an irregularity in R that I do not know
>> the origin. When doing a sequence from 0 to 1 by 0.02 and assigning it to
>> a vector (i.e. code: a <- seq(from=0, to=1, by=0.02)) then, when I try to
>> use the 36th element (and two others behave the same way) it is not
>> recognized correctly. For instance a[36]==0.7, what should give TRUE,
>> gives instead FALSE. However, this works fine for element 35 and 37 and
>> all other elements but two.
>> I do not know the reason. I restarted my R session and tried on another
>> computer. This has been the same. None of my colleagues had an answer. I
>> hope that you would be able to help me fix that as it must be a pretty
>> straightforward error that I do not realise.
>>
>> I would be thankful for any help,
>> With my very Best Regards,
>> Benjamin.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shadymutu at gmail.com  Wed Apr 19 05:18:01 2017
From: shadymutu at gmail.com (Shadrack Mutuku)
Date: Tue, 18 Apr 2017 20:18:01 -0700 (PDT)
Subject: [R] Installing Cardinal Workflows
Message-ID: <42adff2c-9c6d-4afc-8e1f-0c1c6806337f@googlegroups.com>

I have successfully installed the cardinal package but having issues 
installing cardinal workflows.  I am getting the following error message on 
my console:

> source("http://bioconductor.org/biocLite.R")
Bioconductor version 3.4 (BiocInstaller 1.24.0), ?biocLite for help
> biocLite("CardinalWorkflows")
BioC_mirror: https://bioconductor.org
Using Bioconductor 3.4 (BiocInstaller 1.24.0), R 3.3.3 (2017-03-06).
Installing package(s) ?CardinalWorkflows?
installing the source package ?CardinalWorkflows?

trying URL 
'https://bioconductor.org/packages/3.4/data/experiment/src/contrib/CardinalWorkflows_1.6.0.tar.gz'
Content type 'application/x-gzip' length 150031609 bytes (143.1 MB)
downloaded 143.1 MB

'C:\Program' is not recognized as an internal or external command,
operable program or batch file.

The downloaded source packages are in
?C:\Users\a1708277\AppData\Local\Temp\RtmpIbY3aM\downloaded_packages?
installation path not writeable, unable to update packages: cluster, 
lattice,
  survival
Warning messages:
1: running command '"C:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL -l 
"\\UOFA\USERS$\users7\a1708277\R\win-library\3.3" 
C:\Users\a1708277\AppData\Local\Temp\RtmpIbY3aM/downloaded_packages/CardinalWorkflows_1.6.0.tar.gz' 
had status 1 
2: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?CardinalWorkflows? had non-zero exit status
> library(CardinalWorkflows)
Error in library(CardinalWorkflows) : 
  there is no package called ?CardinalWorkflows?

*Please help. Thanks*

From jdnewmil at dcn.davis.ca.us  Wed Apr 19 08:22:11 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 18 Apr 2017 23:22:11 -0700
Subject: [R] Installing Cardinal Workflows
In-Reply-To: <42adff2c-9c6d-4afc-8e1f-0c1c6806337f@googlegroups.com>
References: <42adff2c-9c6d-4afc-8e1f-0c1c6806337f@googlegroups.com>
Message-ID: <122BA825-532C-4C43-8356-FEEC49BE0BE4@dcn.davis.ca.us>

See http://bfy.tw/BIkn

For next time I recommend reading the Posting Guide mentioned in the footer of this and every post on this list. 
-- 
Sent from my phone. Please excuse my brevity.

On April 18, 2017 8:18:01 PM PDT, Shadrack Mutuku <shadymutu at gmail.com> wrote:
>I have successfully installed the cardinal package but having issues 
>installing cardinal workflows.  I am getting the following error
>message on 
>my console:
>
>> source("http://bioconductor.org/biocLite.R")
>Bioconductor version 3.4 (BiocInstaller 1.24.0), ?biocLite for help
>> biocLite("CardinalWorkflows")
>BioC_mirror: https://bioconductor.org
>Using Bioconductor 3.4 (BiocInstaller 1.24.0), R 3.3.3 (2017-03-06).
>Installing package(s) ?CardinalWorkflows?
>installing the source package ?CardinalWorkflows?
>
>trying URL 
>'https://bioconductor.org/packages/3.4/data/experiment/src/contrib/CardinalWorkflows_1.6.0.tar.gz'
>Content type 'application/x-gzip' length 150031609 bytes (143.1 MB)
>downloaded 143.1 MB
>
>'C:\Program' is not recognized as an internal or external command,
>operable program or batch file.
>
>The downloaded source packages are in
>?C:\Users\a1708277\AppData\Local\Temp\RtmpIbY3aM\downloaded_packages?
>installation path not writeable, unable to update packages: cluster, 
>lattice,
>  survival
>Warning messages:
>1: running command '"C:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL
>-l 
>"\\UOFA\USERS$\users7\a1708277\R\win-library\3.3" 
>C:\Users\a1708277\AppData\Local\Temp\RtmpIbY3aM/downloaded_packages/CardinalWorkflows_1.6.0.tar.gz'
>
>had status 1 
>2: In install.packages(pkgs = doing, lib = lib, ...) :
>  installation of package ?CardinalWorkflows? had non-zero exit status
>> library(CardinalWorkflows)
>Error in library(CardinalWorkflows) : 
>  there is no package called ?CardinalWorkflows?
>
>*Please help. Thanks*
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Wed Apr 19 09:02:57 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 19 Apr 2017 12:32:57 +0530
Subject: [R] qqplot for binomial distribution
In-Reply-To: <2575DB8F-9ACD-48D6-B6DD-5AEA9D709AEB@utoronto.ca>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
 <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>
 <CAC8=1ep2=8+hgxqS3CCfCO2OTWq+iv=OtnS0JtWYJBxS62ZifQ@mail.gmail.com>
 <2575DB8F-9ACD-48D6-B6DD-5AEA9D709AEB@utoronto.ca>
Message-ID: <CAC8=1er8tmxhHoFqvOrMBkwmSLbvkje8aS2dGK7C2d9vRG9Nog@mail.gmail.com>

Dear Boris,

Many thanks,
Ashim

On Tue, Apr 18, 2017 at 7:56 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> As per the help pages, the data samples are expected in the second
> argument, "y".
>
> So try
>   qqplot(rbinom(n=100, size=100, p=0.05), count1_vector)
>
> ... and then plot your qqline()
>
> Alternatively, try
>
> qqline(count1_vector,
>        distribution = function(probs) { qbinom(probs, size=100, prob=0.05)
> },
>        datax = TRUE, # <- logical. Should data values be on the x-axis?
>        col = "red",
>        lwd = 0.5)
> ... and use your original qqplot()
>
>
> B.
>
>
> > On Apr 18, 2017, at 12:47 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> >
> > Dear Boris,
> >
> > Thank you for your reply.
> >
> > > dput(count1_vector)
> > c(5, 6, 4, 4, 6, 5, 4, 5, 3, 7, 5, 5, 3, 4, 8, 6, 10, 2, 4, 6,
> > 8, 4, 4, 6, 8, 5, 6, 3, 7, 9, 4, 7, 5, 7, 3, 4, 5, 2, 11, 7,
> > 8, 5, 5, 6, 3, 2, 3, 5, 9, 6, 5, 6, 7, 3, 10, 7, 6, 4, 9, 5,
> > 7, 3, 7, 3, 2, 3, 4, 5, 10, 4, 5, 5, 6, 7, 4, 8, 7, 5, 5, 4,
> > 8, 7, 9, 4, 4, 4, 7, 5, 4, 10, 4, 5, 6, 1, 3, 5, 4, 7, 4, 6)
> >
> > set.seed(123)
> > qqplot(count1_vector,rbinom(n=100,size=100,p=.05))
> > qqline(count1_vector,distribution = function(probs) { qbinom(probs,
> size=100, prob=0.05) },
> >        col = "red",
> >        lwd = 0.5)
> >
> > When I do this, the line does not pass through the center of my data.I
> do expect count1_vector to be 100 samples of binomial with n=100 and p=.05.
> >
> > Any comments or suggestions for me ?
> >
> > Note : I built a 95% Confidence interval for my data and I counted how
> often out of 100 times did the data fall outside the CI.This I expect to be
> binomial with n=100,p=.05. I repeated this a 100 times and obtained
> count1_vector.
> >
> > Best Regards,
> > Ashim.
> >
> >
> > On Mon, Apr 17, 2017 at 7:51 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> > That's not how qqline() works. The line is drawn with respect to a
> _reference_distribution_ which is the normal distribution by default. For
> the binomial distribution, you need to specify the distribution argument.
> There is an example in the help page that shows you how this is done for
> qchisq(). for qbinom() it is:
> >
> >
> > set.seed(123)
> > qqplot(rbinom(n=100, size=100, p=0.05),
> >        rbinom(n=100, size=100, p=0.05) )
> >
> > qqline(rbinom(n=100,size=100,p=.05),
> >        distribution = function(probs) { qbinom(probs, size=100,
> prob=0.05) },
> >        col = "red",
> >        lwd = 0.5)
> >
> >
> >
> >
> > B.
> >
> >
> > > On Apr 17, 2017, at 9:15 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> > >
> > > Dear Spencer,
> > >
> > > Okay. Many thanks. My next query is how do I use qqline?
> > >
> > > When I try
> > >
> > >> qqline(rbinom(n=100,size=100,p=.05))
> > >
> > > I don't get the line in the right place.
> > >
> > > Best Regards,
> > > Ashim
> > >
> > > On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
> > > spencer.graves at effectivedefense.org> wrote:
> > >
> > >>
> > >>
> > >> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
> > >>
> > >>> Dear All,
> > >>>
> > >>> set.seed(123)
> > >>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
> > >>>
> > >>> I expect to see 1 clear line,but I don't. What am I misunderstanding?
> > >>>
> > >>
> > >>
> > >>      The distribution is discrete, and points are superimposed. Try
> the
> > >> following:
> > >>
> > >>
> > >> set.seed(123)
> > >> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
> > >>       jitter(rbinom(n=100,size=100,p=.05) ))
> > >>
> > >>
> > >>      Spencer Graves
> > >>
> > >>>
> > >>> Best Regards,
> > >>> Ashim
> > >>>
> > >>>        [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/posti
> > >>> ng-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posti
> > >> ng-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Apr 19 09:48:32 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 19 Apr 2017 19:48:32 +1200
Subject: [R] A new <expletive deleted>-up?
Message-ID: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>


Now that this mailing list seems to have managed to eliminate the malign 
influence of nabble, some clever Johnny seems to have come up with a new 
way to cloud the lines of communication.  I have started receiving 
r-help emails from r-help-archive at googlegroups.com.  It seems
that one cannot reply to this address --- at least I can't.  I tried a 
couple of times and got bounces.

However I just received from r-help at r-project.org a reply by Jeff 
Newmiller to one of the posts that I received  via "r-help-archive".  So 
it seems that *Jeff* can reply to these things.

So am I doing something wrong, or is "r-help-archive" messing things up 
for other people as well?  And if the latter, can something be done to 
remove its malign influence?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bhh at xs4all.nl  Wed Apr 19 10:00:03 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Apr 2017 10:00:03 +0200
Subject: [R] A new <expletive deleted>-up?
In-Reply-To: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
References: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
Message-ID: <44BB8B38-999F-4FFE-A6E4-12D38A30D1B1@xs4all.nl>


> On 19 Apr 2017, at 09:48, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Now that this mailing list seems to have managed to eliminate the malign influence of nabble, some clever Johnny seems to have come up with a new way to cloud the lines of communication.  I have started receiving r-help emails from r-help-archive at googlegroups.com.  It seems
> that one cannot reply to this address --- at least I can't.  I tried a couple of times and got bounces.
> 
> However I just received from r-help at r-project.org a reply by Jeff Newmiller to one of the posts that I received  via "r-help-archive".  So it seems that *Jeff* can reply to these things.
> 
> So am I doing something wrong, or is "r-help-archive" messing things up for other people as well?  And if the latter, can something be done to remove its malign influence?
> 

I have also received several messages addressed to r-help-archive at googlegroups.com.
I junked most of these.

I have not tried to reply to any of these messages.
I did send a message some time ago to a poster on  r-help-archive at googlegroups.com to stop doing this and to use the official help.
Apparently to no avail.

Seems like a good idea to give these mails the same treatment as stuff from nabble.


Berend Hasselman

> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Apr 19 10:01:44 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 19 Apr 2017 10:01:44 +0200
Subject: [R] A new <expletive deleted>-up?
In-Reply-To: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
References: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
Message-ID: <A5649ADA-1D5A-45E0-8B33-25CC001D267C@gmail.com>

I believe that the list maintainer is hunting this down. As I understood it, it was more due to incompetence than to actual malice.

-pd

> On 19 Apr 2017, at 09:48 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Now that this mailing list seems to have managed to eliminate the malign influence of nabble, some clever Johnny seems to have come up with a new way to cloud the lines of communication.  I have started receiving r-help emails from r-help-archive at googlegroups.com.  It seems
> that one cannot reply to this address --- at least I can't.  I tried a couple of times and got bounces.
> 
> However I just received from r-help at r-project.org a reply by Jeff Newmiller to one of the posts that I received  via "r-help-archive".  So it seems that *Jeff* can reply to these things.
> 
> So am I doing something wrong, or is "r-help-archive" messing things up for other people as well?  And if the latter, can something be done to remove its malign influence?
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From G.Maubach at weinwolf.de  Wed Apr 19 10:15:05 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 19 Apr 2017 10:15:05 +0200
Subject: [R] Follow-up: RStudio: Place for Storing Options (as plain text)
Message-ID: <OF6C77EF90.2B856139-ONC1258107.002CEF5D-C1258107.002D53E4@lotus.hawesko.de>

Hi All,

some time ago I asded a question about the places where RStudio stores it 
configuration information. I came across this posting

https://support.rstudio.com/hc/en-us/articles/206382178?version=1.0.136&mode=desktop

explaining RStudio keybindings (predefined and customized). At the end of 
the article is the information that RStudio stores keybindings in

~/.R/rstudio/keybindings/rstudio_commands.json
~/.R/rstudio/keybindings/editor_commands.json

I want to share this with you.

Kind regards

Georg


----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 19.04.2017 10:10 
-----

Von:    Georg Maubach/WWBO/WW/HAW
An:     R-help mailing list <r-help at r-project.org>, 
Kopie:  Martin Maechler <maechler at stat.math.ethz.ch>, Jeff Newmiller 
<jdnewmil at dcn.davis.ca.us>
Datum:  08.03.2017 08:59
Betreff:        Follow-up: [R] RStudio: Place for Storing Options (as 
plain text)



Hi All,

I got a late reply from RStudio Support concerning the question where 
RStudio store options and configurations:

-- cut --

The post RStudio Config Files has a new comment. 
. . .
Unfortunately, it's unlikely that we'll be able to provide a programmatic 
R interface in the near future -- the way we lay out and store RStudio's 
client state does not make it as amenable to public consumption as we 
might hope.
That said, you can generally copy everything within that folder to a new 
machine (at the same relative path from the user home directory), and 
expect preferences to be respected + restored as you might expect.
. . .
--cut --

The result of the discussion is:

We can copy the complete RStudio directory for storing options and 
configurations under

%localappdata%\RStudio-Desktop or 
C:\Users\<username>\AppData\Local\RStudio-Desktop

and copy it completely to a new installation of RStudio.

A programmatic approach to edit RStudio options and configurations is not 
possible due to design decisions.

The purpose of the initial question was to find a way to save RStudio 
options and configurations, e g. on git/github or similar. This is 
possible by initialising the above given directory with git or similar.

An open question is what happens if a new RStudio release makes changes to 
the options and configurations. If the stored directory can be completely 
used would need additional clearification, i.e. for each new version.

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An: 
Kopie:   <G.Maubach at weinwolf.de>,
Datum:  23.02.2017 08:37
Betreff:        Re: [R] RStudio: Place for Storing Options



>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Sat, 11 Feb 2017 08:09:36 -0800 writes:

    > For the record, then, Google listened to my incantation of
    > "rstudio configuration file" and the second result was:

    > 
https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State


    > RStudio Desktop is also open source, so you can download
    > the source code and look at the operating-system-specific
    > bits (for "where") if the above link goes out of date or
    > disappears.

Thanks a lot, Jeff!

And for the archives:  On reasonable OS's,  the hidden
directory/folder containing all the info is
                                  ~/.rstudio-desktop/
and if "things are broken" the recommendation is to rename that
   mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
and (zip and) send along with your e-mail to the experts for diagnosis.


    > On Thu, 9 Feb 2017, Martin Maechler wrote:

    >> 
    >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
    >>>>>>> Feb 2017 14:37:57 +0000 writes:
    >> 
    >> > Hi Georg, > maybe someone here knows, but I think you
    >> are more likely to get answers to > Rstudio related
    >> questions with RStudio support: >
    >> https://support.rstudio.com/hc/en-us
    >> 
    >> > Best, > Ulrik
    >> 
    >> Indeed, thank you, Ulrik.
    >> 
    >> In this special case, however, I'm quite sure many
    >> readers of R-help would be interested in the answer; so
    >> once you receive an answer, please post it (or a link to
    >> a public URL with it) here on R-help, thank you in
    >> advance.
    >> 
    >> We would like to be able to *save*, or sometimes *set* /
    >> *reset* such options "in a scripted manner", e.g. for
    >> controlled exam sessions.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
    >> wrote:
    >> 
    >> >> Hi All, >> I would like to make a backup of my RStudio
    >> IDE options I configure using >> "Tools/Global Options"
    >> from the menu bar. Searching the >> web did not reveal
    >> anything.
    >> 
    >> >> Can you tell me where RStudio IDE does store its
    >> configuration?
    >> 
    >> >> Kind regards >> Georg
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > 
---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    >


From r.turner at auckland.ac.nz  Wed Apr 19 10:32:43 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 19 Apr 2017 20:32:43 +1200
Subject: [R] A new <expletive deleted>-up?
In-Reply-To: <A5649ADA-1D5A-45E0-8B33-25CC001D267C@gmail.com>
References: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
 <A5649ADA-1D5A-45E0-8B33-25CC001D267C@gmail.com>
Message-ID: <aeb90c79-588a-e2d5-e6ff-a88ce5428249@auckland.ac.nz>


On 19/04/17 20:01, peter dalgaard wrote:

> I believe that the list maintainer is hunting this down. As I
> understood it, it was more due to incompetence than to actual malice.

Years ago I ran across an aphorism that very much appealed to me: 
"Never attribute to malice that which may be adequately explained by 
stupidity."

More recently I saw the same sentiment, expressed only slightly 
differently, in someone's signature file --- can't remember whose.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From unwin at math.uni-augsburg.de  Wed Apr 19 12:24:24 2017
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Wed, 19 Apr 2017 12:24:24 +0200
Subject: [R] R Course in Dublin (May 24th-May 26th,
	2017) Introductory -> Modern
Message-ID: <6DD2C4FA-50E8-4C87-9213-FF79BFF3F398@math.uni-augsburg.de>

An R course from introductory to modern will be given by

Louis Aslett (Durham University, author of the packages PhaseType and ReliabilityTheory)
and
Antony Unwin (author of the book ?Graphical Data Analysis with R? CRC Press 2015  http://www.gradaanwr.net <http://www.gradaanwr.net/>).

The course will be held in Dublin at the IPA on Lansdowne Road (next to the Rugby ground) from May 24th to May 26th, 2017.

Details at  

http://insightsc.ie/training/r-statistical-software/ <http://insightsc.ie/training/r-statistical-software/>

or send an email to training at insightsc.ie <mailto:training at insightsc.ie> for further information

Antony Unwin
Insight Statistical Consulting, Dublin, Ireland
University of Augsburg, Germany
	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Apr 19 14:56:46 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Apr 2017 14:56:46 +0200
Subject: [R] Safeguarded Newton method for function minimization
In-Reply-To: <b32d3912-5c46-1281-3df5-10def9093ef1@gmail.com>
References: <b32d3912-5c46-1281-3df5-10def9093ef1@gmail.com>
Message-ID: <22775.24206.871320.977039@stat.math.ethz.ch>

>>>>> J C Nash <profjcnash at gmail.com>
>>>>>     on Tue, 18 Apr 2017 13:32:52 -0400 writes:

    > Recently Marie Boehnstedt reported a bug in the nlm()
    > function for function minimization when both gradient and
    > hessian are provided.
Indeed, on R's Bugzilla here :
	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17249

    > She has provided a work-around for some cases and it seems
    > this will get incorporated into the R function eventually.

indeed.... the first part -- fixing the wrong choldc() -- in the C code has
been in my version of R-devel for a while now.

See my follow up
    https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17249#c4  and #c5

including my attachment which is an extended version of Marie's original :
    https://bugs.r-project.org/bugzilla/attachment.cgi?id=2246

As that mentions _and_ shows: Fixing choldc() solves the problem
for the 2D Rosenbrook example, but _not_ the  4D Wood example.

    > However, despite the great number of packages on CRAN,
    > there does not appear to be a straightforward Newton
    > approach to function minimization. This may be because
    > providing the code for a hessian (the matrix of second
    > derivatives) is a lot of work and error-prone.

    > (R could also use some good tools for Automatic Differentiation).

The last part of what you say above is not at all true:
R -- and S (& S+ | S-PLUS) before it! -- always had deriv() and deriv3()
and my attachment above _shows_ you how to use  deriv3() to get
both the gradient and the hessian  via a version of automatic
differentiation completely effortlessly !!

For ease of readers, that part here, with an example:

##' Wood function (4 arguments 'x1' ... 'x4')
fwood <- function(x1,x2,x3,x4) {
  100*(x1^2-x2)^2 + (1-x1)^2 + 90*(x3^2-x4)^2 + (1-x3)^2 +
    10.1*((1-x2)^2 + (1-x4)^2) + 19.8*(1-x2)*(1-x4)
}
## automatically construct correct gradient and hessian:
woodf.gh <- function(x) {
  stopifnot(is.numeric(x))
  woodGH <- deriv3(body(fwood)[[2]],
                   c("x1","x2","x3","x4"), function.arg=TRUE)
  if(length(x) == 4)
    woodGH(x[1],x[2],x[3],x[4])
  else if(is.matrix(x) && ncol(x) == 4)
    woodGH(x[,1], x[,2], x[,3], x[,4])
  else stop("'x' must have length 4 or be a matrix with 4 columns")
}

and now get both the function f(x), gradient g(x) and Hessian H(x) 
for
     x = (0 0 0 0),
     x = (1 1 1 1), and
     x = (1 2 3 4)

with such a simple calle :
     
  > woodf.gh(rbind(0, 1, 1:4))
  [1]   42.0    0.0 2514.4
  attr(,"gradient")
	 x1    x2   x3     x4
  [1,]   -2 -40.0   -2  -40.0
  [2,]    0   0.0    0    0.0
  [3,] -400 279.6 5404 -819.6
  attr(,"hessian")
  , , x1

	x1   x2 x3 x4
  [1,]   2    0  0  0
  [2,] 802 -400  0  0
  [3,] 402 -400  0  0

  , , x2

	 x1    x2 x3   x4
  [1,]    0 220.2  0 19.8
  [2,] -400 220.2  0 19.8
  [3,] -400 220.2  0 19.8

  , , x3

       x1 x2   x3    x4
  [1,]  0  0    2     0
  [2,]  0  0  722  -360
  [3,]  0  0 8282 -1080

  , , x4

       x1   x2    x3    x4
  [1,]  0 19.8     0 200.2
  [2,]  0 19.8  -360 200.2
  [3,]  0 19.8 -1080 200.2

  > 

    > I have also noted that a number of researchers try to
    > implement textbook methods and run into trouble when maths
    > and computing are not quite in sync. Therefore, I wrote a
    > simple safeguarded Newton and put a small package on
    > R-forge at

    > https://r-forge.r-project.org/R/?group_id=395

    > Note that Newton's method is used to solve nonlinear
    > equations. In fact, for function minimization, we apply it
    > to solve g(x) = 0 where g is the gradient and x is the
    > vector of parameters. In part, safeguards ensure we reduce
    > the function f(x) at each step to avoid some of the
    > difficulties that may arise from a non-positive-definite
    > hessian.

    > In the package, I have a very simple quadratic test, the
    > Rosenbrock test function and the Wood test function. The
    > method fails on the last function -- the hessian is not
    > positive definite where it stops.

    > Before submitting this package to CRAN, I would like to
    > see its behaviour on other test problems, but am lazy
    > enough to wish to avoid creating the hessian code. If
    > anyone has such code, it would be very welcome. Please
    > contact me off-list. If I get some workable examples that
    > are open for public view, I'll report back here.

    > John Nash

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From prtkpande at gmail.com  Wed Apr 19 15:05:41 2017
From: prtkpande at gmail.com (prateek pande)
Date: Wed, 19 Apr 2017 18:35:41 +0530
Subject: [R] Multiple Histograms in R
Message-ID: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>

Hi,

I have a data as mentioned below(at the bottom)

Now out of that data i have to create multiple histograms in a single view
in  R. On that histogram i need on x -axis binned data with Breaks 10 and
on y axis event rate . Here churn is dependent variable.


*for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
and on y - axis in need Churn%age. *
*Bins(mou_mean)*

*Churn %age*
23-43                                          0.23%
33-53                                          0.5%
43-63                                           0.3%
53-73                                           0.4%
63-83                                           0.7%
83-103                                        0.8%

Please help


*mou_mean*

*totalmrc_mean*

*rev_range*

*mou_range*

*Churn*

23

24

25

27

1

45

46

47

49

1

43

44

45

47

1

45

46

47

49

0

56

57

58

60

0

67

68

69

71

1

67

68

69

71

0

44

45

46

48

1

33

34

35

37

0

90

91

92

94

1

87

88

89

91

1

76

77

78

80

1

33

34

35

37

1

44

45

46

48

1

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Apr 19 15:20:44 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 19 Apr 2017 14:20:44 +0100
Subject: [R] Multiple Histograms in R
In-Reply-To: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
Message-ID: <58F7642C.90903@sapo.pt>

Hello,

Maybe package psych, function multi.hist is what you want.

https://cran.r-project.org/web/packages/psych/index.html

And don't post in HTML, your data is unreadable.

Hope this helps,

Rui Barradas

Em 19-04-2017 14:05, prateek pande escreveu:
> Hi,
>
> I have a data as mentioned below(at the bottom)
>
> Now out of that data i have to create multiple histograms in a single view
> in  R. On that histogram i need on x -axis binned data with Breaks 10 and
> on y axis event rate . Here churn is dependent variable.
>
>
> *for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
> and on y - axis in need Churn%age. *
> *Bins(mou_mean)*
>
> *Churn %age*
> 23-43                                          0.23%
> 33-53                                          0.5%
> 43-63                                           0.3%
> 53-73                                           0.4%
> 63-83                                           0.7%
> 83-103                                        0.8%
>
> Please help
>
>
> *mou_mean*
>
> *totalmrc_mean*
>
> *rev_range*
>
> *mou_range*
>
> *Churn*
>
> 23
>
> 24
>
> 25
>
> 27
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 1
>
> 43
>
> 44
>
> 45
>
> 47
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 0
>
> 56
>
> 57
>
> 58
>
> 60
>
> 0
>
> 67
>
> 68
>
> 69
>
> 71
>
> 1
>
> 67
>
> 68
>
> 69
>
> 71
>
> 0
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 0
>
> 90
>
> 91
>
> 92
>
> 94
>
> 1
>
> 87
>
> 88
>
> 89
>
> 91
>
> 1
>
> 76
>
> 77
>
> 78
>
> 80
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 1
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From profjcnash at gmail.com  Wed Apr 19 16:06:13 2017
From: profjcnash at gmail.com (J C Nash)
Date: Wed, 19 Apr 2017 10:06:13 -0400
Subject: [R] Safeguarded Newton method for function minimization
In-Reply-To: <22775.24206.871320.977039@stat.math.ethz.ch>
References: <b32d3912-5c46-1281-3df5-10def9093ef1@gmail.com>
 <22775.24206.871320.977039@stat.math.ethz.ch>
Message-ID: <ad1adf9c-d306-bf33-50b5-e1dc830dfad7@gmail.com>

I should have given a more detailed explanation about Automatic Differentiation.
As Martin points out, there are some AD elements in deriv etc., but to my view
they are related more to symbolic differentiation, and not in the same space
as AD Model Builder or its successor whose name eludes me at the moment.
Nor like ADIFOR or ADOLC that can provide the derivative of a subprogram.

However, Martin's example of the Wood function shows what can be done, and this
is a valuable case. Indeed it shows a syntax of which I was previously unaware!
Because it is fairly complicated, I'm not sure I would say "effortlessly", but I
will certainly be copying it. Thanks. Previously, I've done the steps to get the
function partly manually to get to the functional form, as in Chapter 10 of my
Nonlinear Parameter Optimization book.

Note that there are functions all in R that are similar to the deriv() and deriv3()
in package nlsr by Duncan Murdoch and me. There is a facility to extend the derivatives
table to new functions. We can also generate the R gradient functions from expressions.

I'll take this chance to note that the Wood problem is NOT solved by nlm() with
analytic hessian, nor by a safeguarded or unsafeguarded Newton. And I ran a version
of the Fortran code UNCMIN that is the origin of nlm() and got a similar early termination.
But the hessian when these codes halt is not positive definite, so we are outside
the assumed conditions for these methods. Dealing with a non-pos-def hessian in
function minimization has created a small industry in Ph Ds for researchers in
optimization.

Thanks again for Martin's work.

JN




On 2017-04-19 08:56 AM, Martin Maechler wrote:
>>>>>> J C Nash <profjcnash at gmail.com>
>>>>>>     on Tue, 18 Apr 2017 13:32:52 -0400 writes:
>
>     > Recently Marie Boehnstedt reported a bug in the nlm()
>     > function for function minimization when both gradient and
>     > hessian are provided.
> Indeed, on R's Bugzilla here :
> 	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17249
>
>     > She has provided a work-around for some cases and it seems
>     > this will get incorporated into the R function eventually.
>
> indeed.... the first part -- fixing the wrong choldc() -- in the C code has
> been in my version of R-devel for a while now.
>
> See my follow up
>     https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17249#c4  and #c5
>
> including my attachment which is an extended version of Marie's original :
>     https://bugs.r-project.org/bugzilla/attachment.cgi?id=2246
>
> As that mentions _and_ shows: Fixing choldc() solves the problem
> for the 2D Rosenbrook example, but _not_ the  4D Wood example.
>
>     > However, despite the great number of packages on CRAN,
>     > there does not appear to be a straightforward Newton
>     > approach to function minimization. This may be because
>     > providing the code for a hessian (the matrix of second
>     > derivatives) is a lot of work and error-prone.
>
>     > (R could also use some good tools for Automatic Differentiation).
>
> The last part of what you say above is not at all true:
> R -- and S (& S+ | S-PLUS) before it! -- always had deriv() and deriv3()
> and my attachment above _shows_ you how to use  deriv3() to get
> both the gradient and the hessian  via a version of automatic
> differentiation completely effortlessly !!
>
> For ease of readers, that part here, with an example:
>
> ##' Wood function (4 arguments 'x1' ... 'x4')
> fwood <- function(x1,x2,x3,x4) {
>   100*(x1^2-x2)^2 + (1-x1)^2 + 90*(x3^2-x4)^2 + (1-x3)^2 +
>     10.1*((1-x2)^2 + (1-x4)^2) + 19.8*(1-x2)*(1-x4)
> }
> ## automatically construct correct gradient and hessian:
> woodf.gh <- function(x) {
>   stopifnot(is.numeric(x))
>   woodGH <- deriv3(body(fwood)[[2]],
>                    c("x1","x2","x3","x4"), function.arg=TRUE)
>   if(length(x) == 4)
>     woodGH(x[1],x[2],x[3],x[4])
>   else if(is.matrix(x) && ncol(x) == 4)
>     woodGH(x[,1], x[,2], x[,3], x[,4])
>   else stop("'x' must have length 4 or be a matrix with 4 columns")
> }
>
> and now get both the function f(x), gradient g(x) and Hessian H(x)
> for
>      x = (0 0 0 0),
>      x = (1 1 1 1), and
>      x = (1 2 3 4)
>
> with such a simple calle :
>
>   > woodf.gh(rbind(0, 1, 1:4))
>   [1]   42.0    0.0 2514.4
>   attr(,"gradient")
> 	 x1    x2   x3     x4
>   [1,]   -2 -40.0   -2  -40.0
>   [2,]    0   0.0    0    0.0
>   [3,] -400 279.6 5404 -819.6
>   attr(,"hessian")
>   , , x1
>
> 	x1   x2 x3 x4
>   [1,]   2    0  0  0
>   [2,] 802 -400  0  0
>   [3,] 402 -400  0  0
>
>   , , x2
>
> 	 x1    x2 x3   x4
>   [1,]    0 220.2  0 19.8
>   [2,] -400 220.2  0 19.8
>   [3,] -400 220.2  0 19.8
>
>   , , x3
>
>        x1 x2   x3    x4
>   [1,]  0  0    2     0
>   [2,]  0  0  722  -360
>   [3,]  0  0 8282 -1080
>
>   , , x4
>
>        x1   x2    x3    x4
>   [1,]  0 19.8     0 200.2
>   [2,]  0 19.8  -360 200.2
>   [3,]  0 19.8 -1080 200.2
>
>   >
>
>     > I have also noted that a number of researchers try to
>     > implement textbook methods and run into trouble when maths
>     > and computing are not quite in sync. Therefore, I wrote a
>     > simple safeguarded Newton and put a small package on
>     > R-forge at
>
>     > https://r-forge.r-project.org/R/?group_id=395
>
>     > Note that Newton's method is used to solve nonlinear
>     > equations. In fact, for function minimization, we apply it
>     > to solve g(x) = 0 where g is the gradient and x is the
>     > vector of parameters. In part, safeguards ensure we reduce
>     > the function f(x) at each step to avoid some of the
>     > difficulties that may arise from a non-positive-definite
>     > hessian.
>
>     > In the package, I have a very simple quadratic test, the
>     > Rosenbrock test function and the Wood test function. The
>     > method fails on the last function -- the hessian is not
>     > positive definite where it stops.
>
>     > Before submitting this package to CRAN, I would like to
>     > see its behaviour on other test problems, but am lazy
>     > enough to wish to avoid creating the hessian code. If
>     > anyone has such code, it would be very welcome. Please
>     > contact me off-list. If I get some workable examples that
>     > are open for public view, I'll report back here.
>
>     > John Nash
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Apr 19 16:46:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 19 Apr 2017 07:46:19 -0700
Subject: [R] Multiple Histograms in R
In-Reply-To: <58F7642C.90903@sapo.pt>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
 <58F7642C.90903@sapo.pt>
Message-ID: <CAGxFJbShnLZUvaUVUmJzB-0o-vDZfVW1Y=dO0xA6=xAdfx8fPg@mail.gmail.com>

Also, *if* this is homework, don't post at all, as this list is not
for doing homework (though, for better or worse, sometimes such help
is provided).


-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 19, 2017 at 6:20 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Maybe package psych, function multi.hist is what you want.
>
> https://cran.r-project.org/web/packages/psych/index.html
>
> And don't post in HTML, your data is unreadable.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 19-04-2017 14:05, prateek pande escreveu:
>>
>> Hi,
>>
>> I have a data as mentioned below(at the bottom)
>>
>> Now out of that data i have to create multiple histograms in a single view
>> in  R. On that histogram i need on x -axis binned data with Breaks 10 and
>> on y axis event rate . Here churn is dependent variable.
>>
>>
>> *for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
>> and on y - axis in need Churn%age. *
>> *Bins(mou_mean)*
>>
>> *Churn %age*
>> 23-43                                          0.23%
>> 33-53                                          0.5%
>> 43-63                                           0.3%
>> 53-73                                           0.4%
>> 63-83                                           0.7%
>> 83-103                                        0.8%
>>
>> Please help
>>
>>
>> *mou_mean*
>>
>> *totalmrc_mean*
>>
>> *rev_range*
>>
>> *mou_range*
>>
>> *Churn*
>>
>> 23
>>
>> 24
>>
>> 25
>>
>> 27
>>
>> 1
>>
>> 45
>>
>> 46
>>
>> 47
>>
>> 49
>>
>> 1
>>
>> 43
>>
>> 44
>>
>> 45
>>
>> 47
>>
>> 1
>>
>> 45
>>
>> 46
>>
>> 47
>>
>> 49
>>
>> 0
>>
>> 56
>>
>> 57
>>
>> 58
>>
>> 60
>>
>> 0
>>
>> 67
>>
>> 68
>>
>> 69
>>
>> 71
>>
>> 1
>>
>> 67
>>
>> 68
>>
>> 69
>>
>> 71
>>
>> 0
>>
>> 44
>>
>> 45
>>
>> 46
>>
>> 48
>>
>> 1
>>
>> 33
>>
>> 34
>>
>> 35
>>
>> 37
>>
>> 0
>>
>> 90
>>
>> 91
>>
>> 92
>>
>> 94
>>
>> 1
>>
>> 87
>>
>> 88
>>
>> 89
>>
>> 91
>>
>> 1
>>
>> 76
>>
>> 77
>>
>> 78
>>
>> 80
>>
>> 1
>>
>> 33
>>
>> 34
>>
>> 35
>>
>> 37
>>
>> 1
>>
>> 44
>>
>> 45
>>
>> 46
>>
>> 48
>>
>> 1
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Wed Apr 19 16:55:48 2017
From: profjcnash at gmail.com (J C Nash)
Date: Wed, 19 Apr 2017 10:55:48 -0400
Subject: [R] A new <expletive deleted>-up? / mailing list woes
In-Reply-To: <aeb90c79-588a-e2d5-e6ff-a88ce5428249@auckland.ac.nz>
References: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
 <A5649ADA-1D5A-45E0-8B33-25CC001D267C@gmail.com>
 <aeb90c79-588a-e2d5-e6ff-a88ce5428249@auckland.ac.nz>
Message-ID: <43c1146c-67f5-1dbc-78a2-96a9f029e254@gmail.com>

A slightly different mailing list problem was preventing me from posting without going to moderation. Talking with Paul 
Gilbert, I realized that my email (handled by Thunderbird) was using an outgoing server that was not the one normally 
associated with my R-help subscription address. Changing that setting allowed unmoderated contributions -- like this 
one. I've suggested to Martin M that a note about this might be worth adding to the subscription page, since a lot of 
folk have multiple emails handled by clients like Thunderbird that may use a common outgoing SMTP server.

Sorry that this is not precisely about R, but it does concern R-help and other lists we use, and like the Windows/Mac 
"hide file extensions of common file types", the glitches keep us from doing real work.

JN


On 2017-04-19 04:32 AM, Rolf Turner wrote:
>
> On 19/04/17 20:01, peter dalgaard wrote:
>
>> I believe that the list maintainer is hunting this down. As I
>> understood it, it was more due to incompetence than to actual malice.
>
> Years ago I ran across an aphorism that very much appealed to me: "Never attribute to malice that which may be
> adequately explained by stupidity."
>
> More recently I saw the same sentiment, expressed only slightly differently, in someone's signature file --- can't
> remember whose.
>
> cheers,
>
> Rolf
>


From bpschn01 at gmail.com  Wed Apr 19 17:44:00 2017
From: bpschn01 at gmail.com (Brad P)
Date: Wed, 19 Apr 2017 11:44:00 -0400
Subject: [R]  Is there a way to open R terminal running in the background
Message-ID: <CAMAcwjyZvP0kBn_Y=kUZXo1SGkNHR0YHHSLzNUMT45eKGoJbXA@mail.gmail.com>

Hello,

I am working on a GUI, which is working well so far.
I am working on a Windows 7 machine with 64 bit R (Microsoft R Open 3.3.2)

Essentially:
1) a VBS executable is used to open the GUI leaving the R terminal running
in the background but not showing using:

CreateObject("Wscript.Shell").Run R.exe CMD BATCH MyGUI.R , 0, TRUE

2) for the GUI I use code similar to that shown below

My question is, when the GUI is opened, an instance of R runs in the
background.
Is there a way to show ('open') that R terminal?  And similarly put it back
as invisible.
I am imagining that I can write an R function to either open this directly
or by using Windows OS commands

I have found  a way to open a terminal using the code at this link, but it
is not ideal (I want an actual R terminal):
http://freesourcecode.net/rprojects/104/sourcecode/ex-RGtk2-terminal.R



# MyGUI.R ##################################################################
library(RGtk2)

# initiate main window
main_window <<- gtkWindow(show = FALSE)
main_window["title"] <- "My GUI"
main_window$setDefaultSize(800, 600) # (width, height)

# problem: red [X] in top-right leaves underlying R instance open
main_window$deletable <- FALSE  # makes the top-right [X] delete option not
work ...
# Can this button be reprogrammed??

# function to read in data file
open_cb <- function(widget, window) {
  dialog <- gtkFileChooserDialog("Choose a CSV file", window, "open",
                                 "gtk-cancel", GtkResponseType["cancel"],
"gtk-open",
                                 GtkResponseType["accept"])
  if (dialog$run() == GtkResponseType["accept"]) {
    fileName <<- dialog$getFilename()
    dat <<- read.csv(fileName, header=TRUE, na.strings=c("","NA"))
  }
  dialog$destroy()
  statusbar$push(info, paste("Dataset", fileName, "is currently loaded."))
}

# variable to indicate whether it is time to stop R
StopNOW <<- 0

quit_cb <- function(widget, window){
  StopNOW <<- 1
  window$destroy()
  quit(save = "no")
}

# Lists actions in dropdown or toolbar menus
actions <- list(
  list("FileMenu", NULL, "Input File"),
  list("Open", "gtk-open", "_Import CSV File", "<control>O",
       "Select a CSV file to load as a spreadsheet", open_cb),
  list("Quit", "gtk-quit", "_Quit", "<control>Q",
       "Quit the application", quit_cb)
)
action_group <- gtkActionGroup("spreadsheetActions")
action_group$addActions(actions, main_window)

ui_manager <- gtkUIManager()
ui_manager$insertActionGroup(action_group, 0)
merge <- ui_manager$newMergeId()
ui_manager$addUi(merge.id = merge, path = "/", name = "menubar", action =
NULL, type = "menubar", top = FALSE)
ui_manager$addUi(merge, "/menubar", "file", "FileMenu", "menu", FALSE)
ui_manager$addUi(merge, "/menubar/file", "open", "Open", "menuitem", FALSE)
ui_manager$addUi(merge, "/", "toolbar", NULL, "toolbar", FALSE)
ui_manager$addUi(merge, "/toolbar", "quit", "Quit", "toolitem", FALSE)

menubar <- ui_manager$getWidget("/menubar")
toolbar <- ui_manager$getWidget("/toolbar")
main_window$addAccelGroup(ui_manager$getAccelGroup())

# Status bar shown at bottom left of GUI
statusbar <- gtkStatusbar()
info <- statusbar$getContextId("info")
statusbar$push(info, "Ready")

notebook <- gtkNotebook()
notebook$setTabPos("bottom")

vbox <- gtkVBox(homogeneous = FALSE, spacing = 0)
vbox$packStart(menubar, expand = FALSE, fill = FALSE, padding = 0)
vbox$packStart(toolbar, FALSE, FALSE, 0) # Uncomment if toolbar is used
vbox$packStart(notebook, TRUE, TRUE, 0)
vbox$packStart(statusbar, FALSE, FALSE, 0)
main_window$add(vbox)

# open GUI window
main_window$show()

gtkWidgetGrabFocus(main_window)

# This repeat loop & stopNOW variable keeps the GUI window open until closed
repeat {
Sys.sleep(0.001)
    if (StopNOW == 1) break
  }
# End GUI Code

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr 19 18:14:00 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Apr 2017 12:14:00 -0400
Subject: [R] Is there a way to open R terminal running in the background
In-Reply-To: <CAMAcwjyZvP0kBn_Y=kUZXo1SGkNHR0YHHSLzNUMT45eKGoJbXA@mail.gmail.com>
References: <CAMAcwjyZvP0kBn_Y=kUZXo1SGkNHR0YHHSLzNUMT45eKGoJbXA@mail.gmail.com>
Message-ID: <ee8f2ef2-1c77-6b0e-b269-4b0896429d31@gmail.com>

On 19/04/2017 11:44 AM, Brad P wrote:
> Hello,
>
> I am working on a GUI, which is working well so far.
> I am working on a Windows 7 machine with 64 bit R (Microsoft R Open 3.3.2)
>
> Essentially:
> 1) a VBS executable is used to open the GUI leaving the R terminal running
> in the background but not showing using:
>
> CreateObject("Wscript.Shell").Run R.exe CMD BATCH MyGUI.R , 0, TRUE

I think this is more of a Microsoft question than anything specific to 
R.  How do you ask VBS to show you a process that it is running?

No idea where to go with VBS questions.

Duncan Murdoch

>
> 2) for the GUI I use code similar to that shown below
>
> My question is, when the GUI is opened, an instance of R runs in the
> background.
> Is there a way to show ('open') that R terminal?  And similarly put it back
> as invisible.
> I am imagining that I can write an R function to either open this directly
> or by using Windows OS commands
>
> I have found  a way to open a terminal using the code at this link, but it
> is not ideal (I want an actual R terminal):
> http://freesourcecode.net/rprojects/104/sourcecode/ex-RGtk2-terminal.R
>
>
>
> # MyGUI.R ##################################################################
> library(RGtk2)
>
> # initiate main window
> main_window <<- gtkWindow(show = FALSE)
> main_window["title"] <- "My GUI"
> main_window$setDefaultSize(800, 600) # (width, height)
>
> # problem: red [X] in top-right leaves underlying R instance open
> main_window$deletable <- FALSE  # makes the top-right [X] delete option not
> work ...
> # Can this button be reprogrammed??
>
> # function to read in data file
> open_cb <- function(widget, window) {
>   dialog <- gtkFileChooserDialog("Choose a CSV file", window, "open",
>                                  "gtk-cancel", GtkResponseType["cancel"],
> "gtk-open",
>                                  GtkResponseType["accept"])
>   if (dialog$run() == GtkResponseType["accept"]) {
>     fileName <<- dialog$getFilename()
>     dat <<- read.csv(fileName, header=TRUE, na.strings=c("","NA"))
>   }
>   dialog$destroy()
>   statusbar$push(info, paste("Dataset", fileName, "is currently loaded."))
> }
>
> # variable to indicate whether it is time to stop R
> StopNOW <<- 0
>
> quit_cb <- function(widget, window){
>   StopNOW <<- 1
>   window$destroy()
>   quit(save = "no")
> }
>
> # Lists actions in dropdown or toolbar menus
> actions <- list(
>   list("FileMenu", NULL, "Input File"),
>   list("Open", "gtk-open", "_Import CSV File", "<control>O",
>        "Select a CSV file to load as a spreadsheet", open_cb),
>   list("Quit", "gtk-quit", "_Quit", "<control>Q",
>        "Quit the application", quit_cb)
> )
> action_group <- gtkActionGroup("spreadsheetActions")
> action_group$addActions(actions, main_window)
>
> ui_manager <- gtkUIManager()
> ui_manager$insertActionGroup(action_group, 0)
> merge <- ui_manager$newMergeId()
> ui_manager$addUi(merge.id = merge, path = "/", name = "menubar", action =
> NULL, type = "menubar", top = FALSE)
> ui_manager$addUi(merge, "/menubar", "file", "FileMenu", "menu", FALSE)
> ui_manager$addUi(merge, "/menubar/file", "open", "Open", "menuitem", FALSE)
> ui_manager$addUi(merge, "/", "toolbar", NULL, "toolbar", FALSE)
> ui_manager$addUi(merge, "/toolbar", "quit", "Quit", "toolitem", FALSE)
>
> menubar <- ui_manager$getWidget("/menubar")
> toolbar <- ui_manager$getWidget("/toolbar")
> main_window$addAccelGroup(ui_manager$getAccelGroup())
>
> # Status bar shown at bottom left of GUI
> statusbar <- gtkStatusbar()
> info <- statusbar$getContextId("info")
> statusbar$push(info, "Ready")
>
> notebook <- gtkNotebook()
> notebook$setTabPos("bottom")
>
> vbox <- gtkVBox(homogeneous = FALSE, spacing = 0)
> vbox$packStart(menubar, expand = FALSE, fill = FALSE, padding = 0)
> vbox$packStart(toolbar, FALSE, FALSE, 0) # Uncomment if toolbar is used
> vbox$packStart(notebook, TRUE, TRUE, 0)
> vbox$packStart(statusbar, FALSE, FALSE, 0)
> main_window$add(vbox)
>
> # open GUI window
> main_window$show()
>
> gtkWidgetGrabFocus(main_window)
>
> # This repeat loop & stopNOW variable keeps the GUI window open until closed
> repeat {
> Sys.sleep(0.001)
>     if (StopNOW == 1) break
>   }
> # End GUI Code
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Wed Apr 19 18:20:34 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 19 Apr 2017 12:20:34 -0400
Subject: [R] Prediction plots
In-Reply-To: <CAGfmZu6engkO7zmJmG0Ag8z3hUbShYL2s6Gj9Eok9SRkwO1RnQ@mail.gmail.com>
References: <CAGfmZu6engkO7zmJmG0Ag8z3hUbShYL2s6Gj9Eok9SRkwO1RnQ@mail.gmail.com>
Message-ID: <7CE9B9B0-AB29-4144-BE2D-58DE8F0B9E11@utoronto.ca>

Can you provide a small reproducible example and explain what exactly is going wrong?

Just a handful of data points will do.


B.



> On Apr 18, 2017, at 2:16 PM, Santiago Bueno <swbueno at gmail.com> wrote:
> 
> Thanks Boris, the following is an extract of my data. I have developed
> biomass models using codes like:
> 
> start <- coef (lm(log(Btot)~I(log(dbh**2*haut)),data=dat[dat$Btot>0,]))
> 
> start[1] <- exp(start[1])
> 
> names(start) <- c("a","b")
> 
> M1 <- nls(Btot~a*(dbh**2*haut)**b,data=dat,start=start,weights=1/dat$dbh**4)
> 
> 
> start <- coef(lm(log(Btot)~I(log(dbh))+I(log(haut)),data=dat[dat$Btot>0,]))
> 
> start[1] <- exp(start[1])
> 
> names(start) <- c("a","b1","b2")
> 
> M2 <- nls(Btot~a*dbh**b1*haut**b2,data=dat,start=start,weights=1/dat$dbh**4)
> 
> 
> Tree No dbh haut Btot
> 1 35.00 18.90 0.535
> 2 25.00 16.60 0.248
> 3 23.00 19.50 0.228
> 4 13.50 15.60 0.080
> 5 20.00 18.80 0.172
> 6 23.00 17.40 0.190
> 7 29.00 19.90 0.559
> 8 17.60 18.20 0.117
> 9 31.00 25.30 0.645
> 10 26.00 23.50 0.394
> 11 13.00 13.00 0.038
> 12 32.00 20.70 0.443
> It is my interest to get prediction plots for the models. I have tried to
> use the following codes with no success: Let m be one of the fitted models
> with dbh as the only entry. To construct a plot of the predictions made by
> this model I have tried:
> with(dat,plot(dbh,Btot,xlab="Dbh(cm)",ylab="Biomass (t)"))
> D <- seq(par("usr")[1],par("usr")[2],length=200)
> lines(D,predict(m,newdata=data.frame(dbh=D)),col="red")
> For a model m that has dbh and height as entries, I have tried to get its
> predictions as follows:
> D <- seq(0,180,length=20)
> H <- seq(0,61,length=20)
> B <- matrix(predict(m,newdata=expand.grid(dbh=D,height=H)),length(D))
> 
> Can someone provide help please!!!
> 
> 
> Best regards,
> 
> Santiago Bueno
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bpschn01 at gmail.com  Wed Apr 19 18:45:39 2017
From: bpschn01 at gmail.com (Brad P)
Date: Wed, 19 Apr 2017 12:45:39 -0400
Subject: [R] Is there a way to open R terminal running in the background
In-Reply-To: <ee8f2ef2-1c77-6b0e-b269-4b0896429d31@gmail.com>
References: <CAMAcwjyZvP0kBn_Y=kUZXo1SGkNHR0YHHSLzNUMT45eKGoJbXA@mail.gmail.com>
 <ee8f2ef2-1c77-6b0e-b269-4b0896429d31@gmail.com>
Message-ID: <CAMAcwjwhUCafY=JVCi0rOTvZoeje1e-6uWQh3JTTemzyOxz1EA@mail.gmail.com>

Duncan,

I was thinking to have an additional button in the GUI which would use an R
function to open the window/process running in the background.
I don't think this is a VBS question, as it is simply used to start the GUI
without opening R and calling it directly.
I suppose this may be considered a Windows question - I will look further
into opening a process running in the background using DOS commands.

Thank you for your time.


On Wed, Apr 19, 2017 at 12:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/04/2017 11:44 AM, Brad P wrote:
>
>> Hello,
>>
>> I am working on a GUI, which is working well so far.
>> I am working on a Windows 7 machine with 64 bit R (Microsoft R Open 3.3.2)
>>
>> Essentially:
>> 1) a VBS executable is used to open the GUI leaving the R terminal running
>> in the background but not showing using:
>>
>> CreateObject("Wscript.Shell").Run R.exe CMD BATCH MyGUI.R , 0, TRUE
>>
>
> I think this is more of a Microsoft question than anything specific to R.
> How do you ask VBS to show you a process that it is running?
>
> No idea where to go with VBS questions.
>
> Duncan Murdoch
>
>
>> 2) for the GUI I use code similar to that shown below
>>
>> My question is, when the GUI is opened, an instance of R runs in the
>> background.
>> Is there a way to show ('open') that R terminal?  And similarly put it
>> back
>> as invisible.
>> I am imagining that I can write an R function to either open this directly
>> or by using Windows OS commands
>>
>> I have found  a way to open a terminal using the code at this link, but it
>> is not ideal (I want an actual R terminal):
>> http://freesourcecode.net/rprojects/104/sourcecode/ex-RGtk2-terminal.R
>>
>>
>>
>> # MyGUI.R ############################################################
>> ######
>> library(RGtk2)
>>
>> # initiate main window
>> main_window <<- gtkWindow(show = FALSE)
>> main_window["title"] <- "My GUI"
>> main_window$setDefaultSize(800, 600) # (width, height)
>>
>> # problem: red [X] in top-right leaves underlying R instance open
>> main_window$deletable <- FALSE  # makes the top-right [X] delete option
>> not
>> work ...
>> # Can this button be reprogrammed??
>>
>> # function to read in data file
>> open_cb <- function(widget, window) {
>>   dialog <- gtkFileChooserDialog("Choose a CSV file", window, "open",
>>                                  "gtk-cancel", GtkResponseType["cancel"],
>> "gtk-open",
>>                                  GtkResponseType["accept"])
>>   if (dialog$run() == GtkResponseType["accept"]) {
>>     fileName <<- dialog$getFilename()
>>     dat <<- read.csv(fileName, header=TRUE, na.strings=c("","NA"))
>>   }
>>   dialog$destroy()
>>   statusbar$push(info, paste("Dataset", fileName, "is currently loaded."))
>> }
>>
>> # variable to indicate whether it is time to stop R
>> StopNOW <<- 0
>>
>> quit_cb <- function(widget, window){
>>   StopNOW <<- 1
>>   window$destroy()
>>   quit(save = "no")
>> }
>>
>> # Lists actions in dropdown or toolbar menus
>> actions <- list(
>>   list("FileMenu", NULL, "Input File"),
>>   list("Open", "gtk-open", "_Import CSV File", "<control>O",
>>        "Select a CSV file to load as a spreadsheet", open_cb),
>>   list("Quit", "gtk-quit", "_Quit", "<control>Q",
>>        "Quit the application", quit_cb)
>> )
>> action_group <- gtkActionGroup("spreadsheetActions")
>> action_group$addActions(actions, main_window)
>>
>> ui_manager <- gtkUIManager()
>> ui_manager$insertActionGroup(action_group, 0)
>> merge <- ui_manager$newMergeId()
>> ui_manager$addUi(merge.id = merge, path = "/", name = "menubar", action =
>> NULL, type = "menubar", top = FALSE)
>> ui_manager$addUi(merge, "/menubar", "file", "FileMenu", "menu", FALSE)
>> ui_manager$addUi(merge, "/menubar/file", "open", "Open", "menuitem",
>> FALSE)
>> ui_manager$addUi(merge, "/", "toolbar", NULL, "toolbar", FALSE)
>> ui_manager$addUi(merge, "/toolbar", "quit", "Quit", "toolitem", FALSE)
>>
>> menubar <- ui_manager$getWidget("/menubar")
>> toolbar <- ui_manager$getWidget("/toolbar")
>> main_window$addAccelGroup(ui_manager$getAccelGroup())
>>
>> # Status bar shown at bottom left of GUI
>> statusbar <- gtkStatusbar()
>> info <- statusbar$getContextId("info")
>> statusbar$push(info, "Ready")
>>
>> notebook <- gtkNotebook()
>> notebook$setTabPos("bottom")
>>
>> vbox <- gtkVBox(homogeneous = FALSE, spacing = 0)
>> vbox$packStart(menubar, expand = FALSE, fill = FALSE, padding = 0)
>> vbox$packStart(toolbar, FALSE, FALSE, 0) # Uncomment if toolbar is used
>> vbox$packStart(notebook, TRUE, TRUE, 0)
>> vbox$packStart(statusbar, FALSE, FALSE, 0)
>> main_window$add(vbox)
>>
>> # open GUI window
>> main_window$show()
>>
>> gtkWidgetGrabFocus(main_window)
>>
>> # This repeat loop & stopNOW variable keeps the GUI window open until
>> closed
>> repeat {
>> Sys.sleep(0.001)
>>     if (StopNOW == 1) break
>>   }
>> # End GUI Code
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr 19 18:53:30 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Apr 2017 12:53:30 -0400
Subject: [R] Is there a way to open R terminal running in the background
In-Reply-To: <CAMAcwjwhUCafY=JVCi0rOTvZoeje1e-6uWQh3JTTemzyOxz1EA@mail.gmail.com>
References: <CAMAcwjyZvP0kBn_Y=kUZXo1SGkNHR0YHHSLzNUMT45eKGoJbXA@mail.gmail.com>
 <ee8f2ef2-1c77-6b0e-b269-4b0896429d31@gmail.com>
 <CAMAcwjwhUCafY=JVCi0rOTvZoeje1e-6uWQh3JTTemzyOxz1EA@mail.gmail.com>
Message-ID: <859714b6-661b-3ad1-3b48-0b8ffabd0665@gmail.com>

On 19/04/2017 12:45 PM, Brad P wrote:
> Duncan,
>
> I was thinking to have an additional button in the GUI which would use
> an R function to open the window/process running in the background.
> I don't think this is a VBS question, as it is simply used to start the
> GUI without opening R and calling it directly.
> I suppose this may be considered a Windows question - I will look
> further into opening a process running in the background using DOS commands.

If you run "R.exe CMD BATCH MyGUI.R", then R doesn't maintain a window 
at all.  It just reads input and writes output.  So I think it really is 
the higher level thing (VBS in your case, cmd.exe if you run that at a 
prompt) that might have the ability to do what you want.

Duncan Murdoch

>
> Thank you for your time.
>
>
> On Wed, Apr 19, 2017 at 12:14 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 19/04/2017 11:44 AM, Brad P wrote:
>
>         Hello,
>
>         I am working on a GUI, which is working well so far.
>         I am working on a Windows 7 machine with 64 bit R (Microsoft R
>         Open 3.3.2)
>
>         Essentially:
>         1) a VBS executable is used to open the GUI leaving the R
>         terminal running
>         in the background but not showing using:
>
>         CreateObject("Wscript.Shell").Run R.exe CMD BATCH MyGUI.R , 0, TRUE
>
>
>     I think this is more of a Microsoft question than anything specific
>     to R.  How do you ask VBS to show you a process that it is running?
>
>     No idea where to go with VBS questions.
>
>     Duncan Murdoch
>
>
>         2) for the GUI I use code similar to that shown below
>
>         My question is, when the GUI is opened, an instance of R runs in the
>         background.
>         Is there a way to show ('open') that R terminal?  And similarly
>         put it back
>         as invisible.
>         I am imagining that I can write an R function to either open
>         this directly
>         or by using Windows OS commands
>
>         I have found  a way to open a terminal using the code at this
>         link, but it
>         is not ideal (I want an actual R terminal):
>         http://freesourcecode.net/rprojects/104/sourcecode/ex-RGtk2-terminal.R
>         <http://freesourcecode.net/rprojects/104/sourcecode/ex-RGtk2-terminal.R>
>
>
>
>         # MyGUI.R
>         ##################################################################
>         library(RGtk2)
>
>         # initiate main window
>         main_window <<- gtkWindow(show = FALSE)
>         main_window["title"] <- "My GUI"
>         main_window$setDefaultSize(800, 600) # (width, height)
>
>         # problem: red [X] in top-right leaves underlying R instance open
>         main_window$deletable <- FALSE  # makes the top-right [X] delete
>         option not
>         work ...
>         # Can this button be reprogrammed??
>
>         # function to read in data file
>         open_cb <- function(widget, window) {
>           dialog <- gtkFileChooserDialog("Choose a CSV file", window,
>         "open",
>                                          "gtk-cancel",
>         GtkResponseType["cancel"],
>         "gtk-open",
>                                          GtkResponseType["accept"])
>           if (dialog$run() == GtkResponseType["accept"]) {
>             fileName <<- dialog$getFilename()
>             dat <<- read.csv(fileName, header=TRUE, na.strings=c("","NA"))
>           }
>           dialog$destroy()
>           statusbar$push(info, paste("Dataset", fileName, "is currently
>         loaded."))
>         }
>
>         # variable to indicate whether it is time to stop R
>         StopNOW <<- 0
>
>         quit_cb <- function(widget, window){
>           StopNOW <<- 1
>           window$destroy()
>           quit(save = "no")
>         }
>
>         # Lists actions in dropdown or toolbar menus
>         actions <- list(
>           list("FileMenu", NULL, "Input File"),
>           list("Open", "gtk-open", "_Import CSV File", "<control>O",
>                "Select a CSV file to load as a spreadsheet", open_cb),
>           list("Quit", "gtk-quit", "_Quit", "<control>Q",
>                "Quit the application", quit_cb)
>         )
>         action_group <- gtkActionGroup("spreadsheetActions")
>         action_group$addActions(actions, main_window)
>
>         ui_manager <- gtkUIManager()
>         ui_manager$insertActionGroup(action_group, 0)
>         merge <- ui_manager$newMergeId()
>         ui_manager$addUi(merge.id <http://merge.id> = merge, path = "/",
>         name = "menubar", action =
>         NULL, type = "menubar", top = FALSE)
>         ui_manager$addUi(merge, "/menubar", "file", "FileMenu", "menu",
>         FALSE)
>         ui_manager$addUi(merge, "/menubar/file", "open", "Open",
>         "menuitem", FALSE)
>         ui_manager$addUi(merge, "/", "toolbar", NULL, "toolbar", FALSE)
>         ui_manager$addUi(merge, "/toolbar", "quit", "Quit", "toolitem",
>         FALSE)
>
>         menubar <- ui_manager$getWidget("/menubar")
>         toolbar <- ui_manager$getWidget("/toolbar")
>         main_window$addAccelGroup(ui_manager$getAccelGroup())
>
>         # Status bar shown at bottom left of GUI
>         statusbar <- gtkStatusbar()
>         info <- statusbar$getContextId("info")
>         statusbar$push(info, "Ready")
>
>         notebook <- gtkNotebook()
>         notebook$setTabPos("bottom")
>
>         vbox <- gtkVBox(homogeneous = FALSE, spacing = 0)
>         vbox$packStart(menubar, expand = FALSE, fill = FALSE, padding = 0)
>         vbox$packStart(toolbar, FALSE, FALSE, 0) # Uncomment if toolbar
>         is used
>         vbox$packStart(notebook, TRUE, TRUE, 0)
>         vbox$packStart(statusbar, FALSE, FALSE, 0)
>         main_window$add(vbox)
>
>         # open GUI window
>         main_window$show()
>
>         gtkWidgetGrabFocus(main_window)
>
>         # This repeat loop & stopNOW variable keeps the GUI window open
>         until closed
>         repeat {
>         Sys.sleep(0.001)
>             if (StopNOW == 1) break
>           }
>         # End GUI Code
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From santosh2005 at gmail.com  Wed Apr 19 19:20:15 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 19 Apr 2017 10:20:15 -0700
Subject: [R] A new <expletive deleted>-up?
In-Reply-To: <aeb90c79-588a-e2d5-e6ff-a88ce5428249@auckland.ac.nz>
References: <ebec72a2-e1c0-a83f-b481-dd373351a9fc@auckland.ac.nz>
 <A5649ADA-1D5A-45E0-8B33-25CC001D267C@gmail.com>
 <aeb90c79-588a-e2d5-e6ff-a88ce5428249@auckland.ac.nz>
Message-ID: <CAN_e6Xt2qiCecLPBuCUghR9ErB6dc7cKbDKWf6QXS2GNOFWhTw@mail.gmail.com>

otherwise explain it as unexplained "random variable"/ "residual error" :)

Santosh

On Wed, Apr 19, 2017 at 1:32 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> On 19/04/17 20:01, peter dalgaard wrote:
>
> I believe that the list maintainer is hunting this down. As I
>> understood it, it was more due to incompetence than to actual malice.
>>
>
> Years ago I ran across an aphorism that very much appealed to me: "Never
> attribute to malice that which may be adequately explained by stupidity."
>
> More recently I saw the same sentiment, expressed only slightly
> differently, in someone's signature file --- can't remember whose.
>
> cheers,
>
> Rolf
>
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Apr 19 21:38:59 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 19 Apr 2017 12:38:59 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <E438190D-7685-448B-B106-683F8FCA1E32@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <99A1DB21-CE82-458C-85A0-03D053CF91F6@comcast.net>
 <EAFF45B3-04AF-4033-8FD3-D2243FB3F985@dmstat1.com>
 <CAGxFJbSvpif-OGA3xcu8quuBVvSa0seygdF3vNY+_iXmHPXamA@mail.gmail.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
 <eb847f67de5c4b5cd765b8912e1d5b2d.squirrel@webmail.uic.edu>
 <E438190D-7685-448B-B106-683F8FCA1E32@dmstat1.com>
Message-ID: <CAFDcVCQ8Y1XEr=M+F=LhgLm8rBseEODDgaA_hctNuvBm8aJ95g@mail.gmail.com>

I'd be really surprised if basically not all text editors could be
used here; it more that some have quirks making it less obvious.  For
instance, with plain old Notepad that comes with all Windows distros
you can put (double) quotes around the file name in the Save As...
dialog to prevent Notepad from adding it's own default *.txt extension
(when the extension is missing).  BTW, since you're using RStudio, you
can also use that to create your .Rprofile file; RStudio's Save As...
does not mess with the filename - it saves the file as you specify.

Bruce, what I think would have helped helping you here early on is if
you had given a bit more details on what you did / tried.  There was a
lot of "does not work" early on, which gives little clues.  It wasn't
clear where you saved the files.  Maybe you weren't sure yourself, but
even knowing so would have helped help you.  It was also not clear how
much experience you had with R, which caused confusion - knowing "new
to R, with non professional programming skills" would probably have
cut some corners.  As a helper, here and on other forums, it's often
hard to guess this and to provide a proper reply is then hard - like
trying to give a scientific presentation when you don't know who's in
the audience.  This happens all the time and most people quickly picks
up what the expectations are and then get a smoother ride going
forward.

/Henrik

PS. With the risk of adding confusion, unless you already do so, you
should focus on only using/editing your
C:/Users/BruceRatner/Documents/.Rprofile (also referred to as
~/.Rprofile) file.  That one does not require any Administrative
rights to edit and has the advantage of working also when you update R
later.   The C:/PROGRA~1/R/R-33~1.3/etc/.Rprofile.site file requires
Admin to edit and will have to be recreated/reedited whenever you
update R (e.g. R 3.4.0 will install in a different directory).  A
regular R user should never have to edit the latter.  It's mostly used
for system admins who wish to set common startup settings for multiple
users in a location file.  The *.site part of .Rprofile.site suggests
site-wide settings.  So, use ~/.Rprofile to control your R startup
settings.


On Tue, Apr 18, 2017 at 8:26 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> Dear John:
> My pleasure to respond to your request.
> Problem: Cannot get the .Rprofile file to take affect in either R (or RStudio).
> As to "what" can be in put into a  .Rprofile file is abound, many examples in the manuals, blogs, links, and books.
>
> The "how to" write the file was the real issue, not clearly covered in any material I could find or purchase.
>
> I read that any notepad-type app can be used to create the .Rprofile file:
> 1. with or without a txt/R extension, and/or
> 2. with or without Administrator permission.
>
> Not being a professional programmer/developer, I did not know about text editors that can create files with no extension, which was the problem at hand.
>
> After many back and forth drilling down by R-helpers with trouble shooting queries, it became clear that I was not using a developer's text editor.
>
> Solution: I found an editor online, EditPad Pro 7 (for Windows), with which I created my .Rprofile file.
>
> The result was complete success, and gratitude to all R-helpers who stuck by me,
> understanding I am new to R, with non professional programming skills. As a statistician (or if you prefer data scientist) for twenty plus years, clearly I must know how to program, but not at the pro level or pro understanding.
>
> John, I hope this write up is satisfactory, if not please let let me know, as I will rewrite until you are happy with it.
>
> It is a nice surprise to hear your wanting to archive the problem-solution, which almost did me in, and which created ill feelings among several R-helpers towards me.
>
> Regards,
> Bruce
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 18, 2017, at 9:52 AM, Sparks, John James <jspark4 at uic.edu> wrote:
>>
>> Bruce,
>>
>> Do you think that you could post the final solution to the problem?  That
>> way it would be stored with this thread and the next person who has the
>> same problem would be able to locate the FINAL solution.
>>
>> --JJS
>>
>>
>>> On Mon, April 17, 2017 12:47 pm, BR_email wrote:
>>> TO _ALL_:
>>> THANK YOU. THANK YOU. THANK YOU.
>>> After hours, and hours, and hours, and ... , and hours: Success.
>>> To all who helped, thanks.
>>> My quest was minor, but major for me, as I learn from the path of one,
>>> whether big or small begets another.
>>>
>>> I never look down at anyone, except to help him/her up.
>>>
>>> With gratitude,
>>> Bruce
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>>
>>> Peter Dalgaard wrote:
>>>>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>>>>
>>>>> Berend: Something looks good, but RStudio still Rprofile still doees
>>>>> not affect the launch.
>>>>>
>>>>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>>>> options(prompt="R> ")
>>>>>> set.seed(12345)
>>>>>> rm(list=ls())
>>>>> R>
>>>>>
>>>>>
>>>>> Bruce Ratner, Ph.D.
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>>
>>>>> Berend Hasselman wrote:
>>>>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>> According to the gospel of St.Henrik, that filename is wrong, and
>>>> possibly the directory too.
>>>>
>>>> So try his suggestions. What is the output (show us!) of
>>>>
>>>> normalizePath("./.Rprofile")
>>>> normalizePath("~/.Rprofile")
>>>>
>>>> Assuming that the former is
>>>>
>>>> "C:/Users/BruceRatner/Documents/.Rprofile"
>>>>
>>>> you could try renaming the .Rprofile.site file to that. If need be, use
>>>> file.rename, as in
>>>>
>>>> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site",
>>>> to="C:/Users/BruceRatner/Documents/.Rprofile")
>>>>
>>>> (and restart, obviously).
>>>>
>>>> [I wouldn't set the seed in a .Rprofile file, nor would I use rm()
>>>> there, but that is a different kettle of fish.]
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From swbueno at gmail.com  Wed Apr 19 21:56:51 2017
From: swbueno at gmail.com (Santiago Bueno)
Date: Wed, 19 Apr 2017 15:56:51 -0400
Subject: [R] Asking for help
Message-ID: <CAGfmZu4VHrL94+7vBfHhtObR0vHx_QoH2rFDBjSXVTrAV4mYmw@mail.gmail.com>

I have tried to ask for help ragarding R software but it seems that I do
not know how to send my questions. Can someone "PLEASE" tutor me on how to
structure my messages?

Best regards,

Santiago

	[[alternative HTML version deleted]]


From br at dmstat1.com  Wed Apr 19 21:57:42 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 19 Apr 2017 15:57:42 -0400
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <CAFDcVCQ8Y1XEr=M+F=LhgLm8rBseEODDgaA_hctNuvBm8aJ95g@mail.gmail.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <202F75D5-6449-4DB7-84E9-5BD3FF8F4548@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
 <eb847f67de5c4b5cd765b8912e1d5b2d.squirrel@webmail.uic.edu>
 <E438190D-7685-448B-B106-683F8FCA1E32@dmstat1.com>
 <CAFDcVCQ8Y1XEr=M+F=LhgLm8rBseEODDgaA_hctNuvBm8aJ95g@mail.gmail.com>
Message-ID: <7b540a27-5959-0d12-3b8e-8cb0e2d6bd21@dmstat1.com>

Henrik:
Your points are well taken.
My biggest mistake was that I thought my question was an easy one.
But as you rightly stated, I did not explicitly provide my background.
I assumed my question implied how much I did not know, beyond being new 
to R.
It's like Einstein teaching arithmetic, he would know his audience and 
teach accordingly.

It was tough on me (mentally draining) because I want to learn R
and just couldn't break through until I believe either you or Peter 
picked up on my using notepad.

Well, I am glad you guys really want to help and must as I needed it.

Regards,
Bruce

  

Henrik Bengtsson wrote:
> I'd be really surprised if basically not all text editors could be
> used here; it more that some have quirks making it less obvious.  For
> instance, with plain old Notepad that comes with all Windows distros
> you can put (double) quotes around the file name in the Save As...
> dialog to prevent Notepad from adding it's own default *.txt extension
> (when the extension is missing).  BTW, since you're using RStudio, you
> can also use that to create your .Rprofile file; RStudio's Save As...
> does not mess with the filename - it saves the file as you specify.
>
> Bruce, what I think would have helped helping you here early on is if
> you had given a bit more details on what you did / tried.  There was a
> lot of "does not work" early on, which gives little clues.  It wasn't
> clear where you saved the files.  Maybe you weren't sure yourself, but
> even knowing so would have helped help you.  It was also not clear how
> much experience you had with R, which caused confusion - knowing "new
> to R, with non professional programming skills" would probably have
> cut some corners.  As a helper, here and on other forums, it's often
> hard to guess this and to provide a proper reply is then hard - like
> trying to give a scientific presentation when you don't know who's in
> the audience.  This happens all the time and most people quickly picks
> up what the expectations are and then get a smoother ride going
> forward.
>
> /Henrik
>
> PS. With the risk of adding confusion, unless you already do so, you
> should focus on only using/editing your
> C:/Users/BruceRatner/Documents/.Rprofile (also referred to as
> ~/.Rprofile) file.  That one does not require any Administrative
> rights to edit and has the advantage of working also when you update R
> later.   The C:/PROGRA~1/R/R-33~1.3/etc/.Rprofile.site file requires
> Admin to edit and will have to be recreated/reedited whenever you
> update R (e.g. R 3.4.0 will install in a different directory).  A
> regular R user should never have to edit the latter.  It's mostly used
> for system admins who wish to set common startup settings for multiple
> users in a location file.  The *.site part of .Rprofile.site suggests
> site-wide settings.  So, use ~/.Rprofile to control your R startup
> settings.
>
>
> On Tue, Apr 18, 2017 at 8:26 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> Dear John:
>> My pleasure to respond to your request.
>> Problem: Cannot get the .Rprofile file to take affect in either R (or RStudio).
>> As to "what" can be in put into a  .Rprofile file is abound, many examples in the manuals, blogs, links, and books.
>>
>> The "how to" write the file was the real issue, not clearly covered in any material I could find or purchase.
>>
>> I read that any notepad-type app can be used to create the .Rprofile file:
>> 1. with or without a txt/R extension, and/or
>> 2. with or without Administrator permission.
>>
>> Not being a professional programmer/developer, I did not know about text editors that can create files with no extension, which was the problem at hand.
>>
>> After many back and forth drilling down by R-helpers with trouble shooting queries, it became clear that I was not using a developer's text editor.
>>
>> Solution: I found an editor online, EditPad Pro 7 (for Windows), with which I created my .Rprofile file.
>>
>> The result was complete success, and gratitude to all R-helpers who stuck by me,
>> understanding I am new to R, with non professional programming skills. As a statistician (or if you prefer data scientist) for twenty plus years, clearly I must know how to program, but not at the pro level or pro understanding.
>>
>> John, I hope this write up is satisfactory, if not please let let me know, as I will rewrite until you are happy with it.
>>
>> It is a nice surprise to hear your wanting to archive the problem-solution, which almost did me in, and which created ill feelings among several R-helpers towards me.
>>
>> Regards,
>> Bruce
>>
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>>
>>
>>
>>> On Apr 18, 2017, at 9:52 AM, Sparks, John James <jspark4 at uic.edu> wrote:
>>>
>>> Bruce,
>>>
>>> Do you think that you could post the final solution to the problem?  That
>>> way it would be stored with this thread and the next person who has the
>>> same problem would be able to locate the FINAL solution.
>>>
>>> --JJS
>>>
>>>
>>>> On Mon, April 17, 2017 12:47 pm, BR_email wrote:
>>>> TO _ALL_:
>>>> THANK YOU. THANK YOU. THANK YOU.
>>>> After hours, and hours, and hours, and ... , and hours: Success.
>>>> To all who helped, thanks.
>>>> My quest was minor, but major for me, as I learn from the path of one,
>>>> whether big or small begets another.
>>>>
>>>> I never look down at anyone, except to help him/her up.
>>>>
>>>> With gratitude,
>>>> Bruce
>>>>
>>>> Bruce Ratner, Ph.D.
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>
>>>>
>>>> Peter Dalgaard wrote:
>>>>>> On 17 Apr 2017, at 19:01 , BR_email <br at dmstat1.com> wrote:
>>>>>>
>>>>>> Berend: Something looks good, but RStudio still Rprofile still doees
>>>>>> not affect the launch.
>>>>>>
>>>>>>> source(echo=TRUE, "C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>>>>> options(prompt="R> ")
>>>>>>> set.seed(12345)
>>>>>>> rm(list=ls())
>>>>>> R>
>>>>>>
>>>>>>
>>>>>> Bruce Ratner, Ph.D.
>>>>>> The Significant Statistician?
>>>>>> (516) 791-3544
>>>>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>>>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>>>>
>>>>>> Berend Hasselman wrote:
>>>>>>> source(echo=TRUE, ""C:/Users/BruceRatner/Documents/.Rprofile.site")
>>>>> According to the gospel of St.Henrik, that filename is wrong, and
>>>>> possibly the directory too.
>>>>>
>>>>> So try his suggestions. What is the output (show us!) of
>>>>>
>>>>> normalizePath("./.Rprofile")
>>>>> normalizePath("~/.Rprofile")
>>>>>
>>>>> Assuming that the former is
>>>>>
>>>>> "C:/Users/BruceRatner/Documents/.Rprofile"
>>>>>
>>>>> you could try renaming the .Rprofile.site file to that. If need be, use
>>>>> file.rename, as in
>>>>>
>>>>> file.rename(from="C:/Users/BruceRatner/Documents/.Rprofile.site",
>>>>> to="C:/Users/BruceRatner/Documents/.Rprofile")
>>>>>
>>>>> (and restart, obviously).
>>>>>
>>>>> [I wouldn't set the seed in a .Rprofile file, nor would I use rm()
>>>>> there, but that is a different kettle of fish.]
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From istazahn at gmail.com  Wed Apr 19 22:13:27 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 19 Apr 2017 16:13:27 -0400
Subject: [R] Asking for help
In-Reply-To: <CAGfmZu4VHrL94+7vBfHhtObR0vHx_QoH2rFDBjSXVTrAV4mYmw@mail.gmail.com>
References: <CAGfmZu4VHrL94+7vBfHhtObR0vHx_QoH2rFDBjSXVTrAV4mYmw@mail.gmail.com>
Message-ID: <CA+vqiLGQpXrXLWVRePNUSk+7EWwqLN+bc55_bAABsnke1rSKvA@mail.gmail.com>

For help in formulating your question in a way that makes it easy to
help you see http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

When asking for help on the R-help mailing list in particular, make
sure to send plain-text email.

Best,
Ista

On Wed, Apr 19, 2017 at 3:56 PM, Santiago Bueno <swbueno at gmail.com> wrote:
> I have tried to ask for help ragarding R software but it seems that I do
> not know how to send my questions. Can someone "PLEASE" tutor me on how to
> structure my messages?
>
> Best regards,
>
> Santiago
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Apr 19 22:16:10 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 19 Apr 2017 16:16:10 -0400
Subject: [R] Asking for help
In-Reply-To: <CA+vqiLGQpXrXLWVRePNUSk+7EWwqLN+bc55_bAABsnke1rSKvA@mail.gmail.com>
References: <CAGfmZu4VHrL94+7vBfHhtObR0vHx_QoH2rFDBjSXVTrAV4mYmw@mail.gmail.com>
 <CA+vqiLGQpXrXLWVRePNUSk+7EWwqLN+bc55_bAABsnke1rSKvA@mail.gmail.com>
Message-ID: <47215732-D3BC-403C-BDCF-EEC50E1A7A5A@utoronto.ca>

What about the advice I sent you this morning?


B.


> On Apr 19, 2017, at 1:49 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> No attachments please. Use the dput() function. And keep the correspondence on the list, there are many colleagues who are far more knowledgeable than I am.
> 
> Cheers,
> Boris
> 
> 
> 
> 
>> On Apr 19, 2017, at 1:47 PM, Santiago Bueno <swbueno at gmail.com> wrote:
>> 
>> Thanks a lot Mr. Steipe. I have attached to this email an Excel file with 48 observations.  The problem is that when I try to get the prediction plot for the following model:
>> start <- coef (lm(log(Btot)~I(log(dbh**2*haut)),data=dat[dat$Btot>0,]))
>> start[1] <- exp(start[1])
>> names(start) <- c("a","b")
>> model18 <- nls(Btot~a*(dbh**2*haut)**b,data=dat,start=start,weights=1/dat$dbh**4)
>> summary(model18)
>> 
>> using this code:
>> 
>> with(dat,plot(dbh**2*haut,Btot,xlab="dbh^2*H(cm^2.m)",ylab="Biomass (t)", pch=19))
>> D <- seq(0,180,length=20)
>> H <- seq(0,61,length=20)
>> 
>> abline(model18, lwd=3)
>> 
>> I get the data points but not the prediction line (see below)
>> 
>> <image.png>
>> If you can help me in getting this line, I will be eternaly grateful..
>> 
>> Best regards,
>> 
>> Santiago Bueno
>> 
>> On Wed, Apr 19, 2017 at 12:20 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Can you provide a small reproducible example and explain what exactly is going wrong?
>> 
>> Just a handful of data points will do.
>> 
>> 
>> B.
>> 
>> 
>> 
>>> On Apr 18, 2017, at 2:16 PM, Santiago Bueno <swbueno at gmail.com> wrote:
>>> 
>>> Thanks Boris, the following is an extract of my data. I have developed
>>> biomass models using codes like:
>>> 
>>> start <- coef (lm(log(Btot)~I(log(dbh**2*haut)),data=dat[dat$Btot>0,]))
>>> 
>>> start[1] <- exp(start[1])
>>> 
>>> names(start) <- c("a","b")
>>> 
>>> M1 <- nls(Btot~a*(dbh**2*haut)**b,data=dat,start=start,weights=1/dat$dbh**4)
>>> 
>>> 
>>> start <- coef(lm(log(Btot)~I(log(dbh))+I(log(haut)),data=dat[dat$Btot>0,]))
>>> 
>>> start[1] <- exp(start[1])
>>> 
>>> names(start) <- c("a","b1","b2")
>>> 
>>> M2 <- nls(Btot~a*dbh**b1*haut**b2,data=dat,start=start,weights=1/dat$dbh**4)
>>> 
>>> 
>>> Tree No dbh haut Btot
>>> 1 35.00 18.90 0.535
>>> 2 25.00 16.60 0.248
>>> 3 23.00 19.50 0.228
>>> 4 13.50 15.60 0.080
>>> 5 20.00 18.80 0.172
>>> 6 23.00 17.40 0.190
>>> 7 29.00 19.90 0.559
>>> 8 17.60 18.20 0.117
>>> 9 31.00 25.30 0.645
>>> 10 26.00 23.50 0.394
>>> 11 13.00 13.00 0.038
>>> 12 32.00 20.70 0.443
>>> It is my interest to get prediction plots for the models. I have tried to
>>> use the following codes with no success: Let m be one of the fitted models
>>> with dbh as the only entry. To construct a plot of the predictions made by
>>> this model I have tried:
>>> with(dat,plot(dbh,Btot,xlab="Dbh(cm)",ylab="Biomass (t)"))
>>> D <- seq(par("usr")[1],par("usr")[2],length=200)
>>> lines(D,predict(m,newdata=data.frame(dbh=D)),col="red")
>>> For a model m that has dbh and height as entries, I have tried to get its
>>> predictions as follows:
>>> D <- seq(0,180,length=20)
>>> H <- seq(0,61,length=20)
>>> B <- matrix(predict(m,newdata=expand.grid(dbh=D,height=H)),length(D))
>>> 
>>> Can someone provide help please!!!
>>> 
>>> 
>>> Best regards,
>>> 
>>> Santiago Bueno
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> <Biomasa_Total.xls>
> 

> On Apr 19, 2017, at 4:13 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> For help in formulating your question in a way that makes it easy to
> help you see http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
> When asking for help on the R-help mailing list in particular, make
> sure to send plain-text email.
> 
> Best,
> Ista
> 
> On Wed, Apr 19, 2017 at 3:56 PM, Santiago Bueno <swbueno at gmail.com> wrote:
>> I have tried to ask for help ragarding R software but it seems that I do
>> not know how to send my questions. Can someone "PLEASE" tutor me on how to
>> structure my messages?
>> 
>> Best regards,
>> 
>> Santiago
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Thu Apr 20 00:04:48 2017
From: jwd at surewest.net (John)
Date: Wed, 19 Apr 2017 15:04:48 -0700
Subject: [R] Setting .Rprofile for RStudio on a Windows 7 x64bit
In-Reply-To: <7b540a27-5959-0d12-3b8e-8cb0e2d6bd21@dmstat1.com>
References: <83b0fa34-df1f-0016-f7b6-1029bcba03c1@dmstat1.com>
 <CAF8bMcb=LLH7Og=Xzx8bfF5ZnpCc9R6taH8JKMGmw+R346MUkA@mail.gmail.com>
 <CAF8bMcameoO6ACdZ6pHjhKimp4j59=VQVNWt61XcOdVkOgzjfw@mail.gmail.com>
 <598b4e08-a1c5-1f72-c875-dce3a4b76997@dmstat1.com>
 <CAF8bMcbR37AYsw3fDUd1v+AtpSfXX476uFg40LHiqPRi22ndaw@mail.gmail.com>
 <b2dbcd58-fb20-3097-79e0-46685edd9c7c@dmstat1.com>
 <CAF8bMcZFgd_QCm3dMsH8+KcpCqePLBTzKcojPYvbKs0OTvAW5w@mail.gmail.com>
 <c55651bb-39d9-20fb-76ae-f45cafec64b8@dmstat1.com>
 <c615bb31-c210-5de1-5157-6fc2d2d45d51@dmstat1.com>
 <142A4256-7F84-45BA-8562-72A207365F6B@xs4all.nl>
 <117384ec-4265-8978-181e-4eea7da5db94@dmstat1.com>
 <CFC8A813-A4A6-4E95-A187-4DCF81CAE387@gmail.com>
 <68bc3546-fe0a-190a-b45b-21cee02ffb11@dmstat1.com>
 <eb847f67de5c4b5cd765b8912e1d5b2d.squirrel@webmail.uic.edu>
 <E438190D-7685-448B-B106-683F8FCA1E32@dmstat1.com>
 <CAFDcVCQ8Y1XEr=M+F=LhgLm8rBseEODDgaA_hctNuvBm8aJ95g@mail.gmail.com>
 <7b540a27-5959-0d12-3b8e-8cb0e2d6bd21@dmstat1.com>
Message-ID: <20170419150448.31920e47@Draco>

On Wed, 19 Apr 2017 15:57:42 -0400
BR_email <br at dmstat1.com> wrote:

> Henrik:
> Your points are well taken.
> My biggest mistake was that I thought my question was an easy one.
> But as you rightly stated, I did not explicitly provide my background.
> I assumed my question implied how much I did not know, beyond being
> new to R.
> It's like Einstein teaching arithmetic, he would know his audience
> and teach accordingly.
> 
> It was tough on me (mentally draining) because I want to learn R
> and just couldn't break through until I believe either you or Peter 
> picked up on my using notepad.
> 
> Well, I am glad you guys really want to help and must as I needed it.
> 
> Regards,
> Bruce
> 
Henrik's point about editors is very important since it has implications
well beyond editing something like .Rprofile.  Depending on the scale
and kinds of data you work with, you may conclude that one of
the easiest means of getting data into R is through delimited, plain
text files.  I tend to prefer tab-delimited files because the data I use
often contains descriptive fields that are useful to have, but often
contain commas, ruling out standard csv files.  Many "text" editors in
both Windows and Linux routinely and quietly convert tabs to some
standard number of spaces.  You want an editor that will produce
precisely what you tell it to.  While you can pull delimited files into
Excel, a good text editor, not Notepad or Wordpad, such as Notepad++ in
Windows or Kwrite in Linux (both of which will save a tab as a tab
(though Kwrite needs to set to do so) and speed data formatting and
editing immensely.  Also, if you are using RStudio you should consider
using the "project" capability.  You will then never have to worry
about .Rproject again.

JWDougherty


From jdnewmil at dcn.davis.ca.us  Thu Apr 20 00:32:08 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Apr 2017 15:32:08 -0700
Subject: [R] rdb and rds files include abolute file paths / help
	understanding how lazy-load dbs are created
In-Reply-To: <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
References: <1264449572.41534.1491972039736@office.mailbox.org>
 <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
 <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
Message-ID: <B9F28939-7C53-401A-B514-24FCF82B9EDA@dcn.davis.ca.us>

I think we are (I certainly am) going to need a more concrete example. As in, point us at a specific package and filename in this package that illustrates your concern. Such precision would also be expected on R-devel, so the lack of response may have been self-inflicted. 

Are you aware of the system.file and file.path functions?  File names that YOU enter into your package code should be referenced using these functions. I have been assuming so far that you were referring to filenames picked up by R as it builds the package, which appear to be handled just fine however they are stored though I don't know the details. 
-- 
Sent from my phone. Please excuse my brevity.

On April 19, 2017 2:40:05 PM PDT, Philip Rinn <rinni at inventati.org> wrote:
>Hi,
>
>On 12.04.2017 at 08:09, Jeff Newmiller wrote:
>
>> Someone might respond here anyway, but I think this is more of an
>R-devel
>> question.
>
>I tired R-devel before[1] with no response :(.
>
>> Anyway, as long as the package file after installation has
>appropriate file
>> names for where it is installed, what does it matter what is in the
>files
>> before installation?
>
>That's actually the point. In the installed .rd[bs] files the absolute
>file paths
>are still present but often[2] the referenced files don't even exist on
>the
>computer the packaged is installed. My approach therefore is to replace
>those
>absolute paths by relative[3] paths. But to do so I need to understand
>where
>exactly those absolute paths are injected in the files - that's why I
>asked for
>help in my fist mail - sorry for not being clear enough.
>
>Best,
>Philip
>
>
>[1] https://stat.ethz.ch/pipermail/r-devel/2017-April/074016.html
>[2] At least on Linux for packages installed via the distribution
>packages system.
>And I think this also holds for prebuild windows/mac builds from cran.
>[3] Relative to teh root directory of the package source


From drjimlemon at gmail.com  Thu Apr 20 07:02:29 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 20 Apr 2017 15:02:29 +1000
Subject: [R] Multiple Histograms in R
In-Reply-To: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
Message-ID: <CA+8X3fU1YUgwZx=oqN2PZtsTMCUOM9SXAOS5NSTcDXDdQpb76A@mail.gmail.com>

Hi Prateek,
There is some difficulty with including the empty categories in the
factors generated. I couldn't get these even with drop=FALSE, so I had
to go through the "xtab" function. You can do it with the "table"
function in the base package, but it is a little more trouble. See if
this is what you want>

ppdat<-read.table(text="mou_mean,totalmrc_mean,rev_range,mou_range,Churn
23,24,25,27,1
45,46,47,49,1
43,44,45,47,1
45,46,47,49,0
56,57,58,60,0
67,68,69,71,1
67,68,69,71,0
44,45,46,48,1
33,34,35,37,0
90,91,92,94,1
87,88,89,91,1
76,77,78,80,1
33,34,35,37,1
44,45,46,48,1",
sep=",",header=TRUE)
ppdat$mou_mean_cut<-cut(ppdat$mou_mean,breaks=seq(23,103,10),include.lowest=TRUE)
ppdat$totalmrc_mean_cut<-cut(ppdat$totalmrc_mean,breaks=seq(23,103,10))
ppdat$rev_range_cut<-cut(ppdat$rev_range,breaks=seq(23,103,10))
ppdat$mou_range_cut<-cut(ppdat$mou_range,breaks=seq(23,103,10))
library(prettyR)
ppx<-xtab(Churn~mou_mean_cut,ppdat)
mou_mean_agg<-100*ppx$counts[2,]/colSums(ppx$counts)
mou_mean_agg[is.nan(mou_mean_agg)]<-0
ppx<-xtab(Churn~totalmrc_mean_cut,ppdat)
totalmrc_mean_agg<-100*ppx$counts[2,]/colSums(ppx$counts)
totalmrc_mean_agg[is.nan(totalmrc_mean_agg)]<-0
ppx<-xtab(Churn~rev_range_cut,ppdat)
rev_range_agg<-100*ppx$counts[2,]/colSums(ppx$counts)
rev_range_agg[is.nan(rev_range_agg)]<-0
ppx<-xtab(Churn~mou_range_cut,ppdat)
mou_range_agg<-100*ppx$counts[2,]/colSums(ppx$counts)
mou_range_agg[is.nan(mou_range_agg)]<-0
ppmat<-matrix(c(mou_mean_agg,totalmrc_mean_agg,rev_range_agg,
 mou_range_agg),nrow=4,byrow=TRUE)
library(plotrix)
barp(ppmat,col=rainbow(4),main="Multiple histogram",ylim=c(0,105),
 names.arg=levels(ppdat$mou_mean_cut),ylab="Percent churn")
legend(2.5,107,c("mou_mean","totalmrc_mean","rev_range","mou_range"),
 fill=rainbow(4))

Jim


On Wed, Apr 19, 2017 at 11:05 PM, prateek pande <prtkpande at gmail.com> wrote:
> Hi,
>
> I have a data as mentioned below(at the bottom)
>
> Now out of that data i have to create multiple histograms in a single view
> in  R. On that histogram i need on x -axis binned data with Breaks 10 and
> on y axis event rate . Here churn is dependent variable.
>
>
> *for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
> and on y - axis in need Churn%age. *
> *Bins(mou_mean)*
>
> *Churn %age*
> 23-43                                          0.23%
> 33-53                                          0.5%
> 43-63                                           0.3%
> 53-73                                           0.4%
> 63-83                                           0.7%
> 83-103                                        0.8%
>
> Please help
>
>
> *mou_mean*
>
> *totalmrc_mean*
>
> *rev_range*
>
> *mou_range*
>
> *Churn*
>
> 23
>
> 24
>
> 25
>
> 27
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 1
>
> 43
>
> 44
>
> 45
>
> 47
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 0
>
> 56
>
> 57
>
> 58
>
> 60
>
> 0
>
> 67
>
> 68
>
> 69
>
> 71
>
> 1
>
> 67
>
> 68
>
> 69
>
> 71
>
> 0
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 0
>
> 90
>
> 91
>
> 92
>
> 94
>
> 1
>
> 87
>
> 88
>
> 89
>
> 91
>
> 1
>
> 76
>
> 77
>
> 78
>
> 80
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 1
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hasan.diwan at gmail.com  Thu Apr 20 07:17:24 2017
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 19 Apr 2017 22:17:24 -0700
Subject: [R] Multiple Histograms in R
In-Reply-To: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
Message-ID: <CAP+bYWDHPVjqpW33dn9Bhj1i+3h=tJwo+bAT6kAiU_ijcEdk5w@mail.gmail.com>

Prateek,
I'm shocked this isn't answered previously, but you can try the par command
(mfrow and mfcol parameters) and par(mfrow=n, mfcol=m) will generate n
plots per row and m rows per column. For subsequent questions, please do a
search through the archives before asking. -- H

On 19 April 2017 at 06:05, prateek pande <prtkpande at gmail.com> wrote:

> Hi,
>
> I have a data as mentioned below(at the bottom)
>
> Now out of that data i have to create multiple histograms in a single view
> in  R. On that histogram i need on x -axis binned data with Breaks 10 and
> on y axis event rate . Here churn is dependent variable.
>
>
> *for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
> and on y - axis in need Churn%age. *
> *Bins(mou_mean)*
>
> *Churn %age*
> 23-43                                          0.23%
> 33-53                                          0.5%
> 43-63                                           0.3%
> 53-73                                           0.4%
> 63-83                                           0.7%
> 83-103                                        0.8%
>
> Please help
>
>
> *mou_mean*
>
> *totalmrc_mean*
>
> *rev_range*
>
> *mou_range*
>
> *Churn*
>
> 23
>
> 24
>
> 25
>
> 27
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 1
>
> 43
>
> 44
>
> 45
>
> 47
>
> 1
>
> 45
>
> 46
>
> 47
>
> 49
>
> 0
>
> 56
>
> 57
>
> 58
>
> 60
>
> 0
>
> 67
>
> 68
>
> 69
>
> 71
>
> 1
>
> 67
>
> 68
>
> 69
>
> 71
>
> 0
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 0
>
> 90
>
> 91
>
> 92
>
> 94
>
> 1
>
> 87
>
> 88
>
> 89
>
> 91
>
> 1
>
> 76
>
> 77
>
> 78
>
> 80
>
> 1
>
> 33
>
> 34
>
> 35
>
> 37
>
> 1
>
> 44
>
> 45
>
> 46
>
> 48
>
> 1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
http://bit.ly/hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a
http://bit.ly/hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From prtkpande at gmail.com  Thu Apr 20 13:24:35 2017
From: prtkpande at gmail.com (prateek pande)
Date: Thu, 20 Apr 2017 16:54:35 +0530
Subject: [R] Multiple Histograms in R
In-Reply-To: <CAP+bYWDHPVjqpW33dn9Bhj1i+3h=tJwo+bAT6kAiU_ijcEdk5w@mail.gmail.com>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
 <CAP+bYWDHPVjqpW33dn9Bhj1i+3h=tJwo+bAT6kAiU_ijcEdk5w@mail.gmail.com>
Message-ID: <CAGAjD9nzM31+L9AwJ5x-GWUoHfTCFi9SRs-JLp7po-YH+Go-ow@mail.gmail.com>

HI Hasan,

Thanks for sharing the solution. Really appreciate it.

But i was reading somewhere that we cannot use par with ggplot 2 . we can
only use grid extra to have multiple plots in a single view.

Is it right?

Regards
Prateek

On Thu, Apr 20, 2017 at 10:47 AM, Hasan Diwan <hasan.diwan at gmail.com> wrote:

> Prateek,
> I'm shocked this isn't answered previously, but you can try the par
> command (mfrow and mfcol parameters) and par(mfrow=n, mfcol=m) will
> generate n plots per row and m rows per column. For subsequent questions,
> please do a search through the archives before asking. -- H
>
> On 19 April 2017 at 06:05, prateek pande <prtkpande at gmail.com> wrote:
>
>> Hi,
>>
>> I have a data as mentioned below(at the bottom)
>>
>> Now out of that data i have to create multiple histograms in a single view
>> in  R. On that histogram i need on x -axis binned data with Breaks 10 and
>> on y axis event rate . Here churn is dependent variable.
>>
>>
>> *for example, for mou_mean , on x -axis on histogram i need Bins(mou_mean)
>> and on y - axis in need Churn%age. *
>> *Bins(mou_mean)*
>>
>> *Churn %age*
>> 23-43                                          0.23%
>> 33-53                                          0.5%
>> 43-63                                           0.3%
>> 53-73                                           0.4%
>> 63-83                                           0.7%
>> 83-103                                        0.8%
>>
>> Please help
>>
>>
>> *mou_mean*
>>
>> *totalmrc_mean*
>>
>> *rev_range*
>>
>> *mou_range*
>>
>> *Churn*
>>
>> 23
>>
>> 24
>>
>> 25
>>
>> 27
>>
>> 1
>>
>> 45
>>
>> 46
>>
>> 47
>>
>> 49
>>
>> 1
>>
>> 43
>>
>> 44
>>
>> 45
>>
>> 47
>>
>> 1
>>
>> 45
>>
>> 46
>>
>> 47
>>
>> 49
>>
>> 0
>>
>> 56
>>
>> 57
>>
>> 58
>>
>> 60
>>
>> 0
>>
>> 67
>>
>> 68
>>
>> 69
>>
>> 71
>>
>> 1
>>
>> 67
>>
>> 68
>>
>> 69
>>
>> 71
>>
>> 0
>>
>> 44
>>
>> 45
>>
>> 46
>>
>> 48
>>
>> 1
>>
>> 33
>>
>> 34
>>
>> 35
>>
>> 37
>>
>> 0
>>
>> 90
>>
>> 91
>>
>> 92
>>
>> 94
>>
>> 1
>>
>> 87
>>
>> 88
>>
>> 89
>>
>> 91
>>
>> 1
>>
>> 76
>>
>> 77
>>
>> 78
>>
>> 80
>>
>> 1
>>
>> 33
>>
>> 34
>>
>> 35
>>
>> 37
>>
>> 1
>>
>> 44
>>
>> 45
>>
>> 46
>>
>> 48
>>
>> 1
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> OpenPGP: https://sks-keyservers.net/pks/lookup?op=
> get&search=0xFEBAD7FFD041BBA1
> If you wish to request my time, please do so using http://bit.ly/
> hd1ScheduleRequest.
> Si vous voudrais faire connnaisance, allez a http://bit.ly/
> hd1ScheduleRequest.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
> from my mobile device
> Envoye de mon portable
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Apr 20 14:26:47 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 20 Apr 2017 12:26:47 +0000
Subject: [R] Multiple Histograms in R
In-Reply-To: <CAGAjD9nzM31+L9AwJ5x-GWUoHfTCFi9SRs-JLp7po-YH+Go-ow@mail.gmail.com>
References: <CAGAjD9mfsma8KHSFaK2zUzv0MsLT7X0bMDQN0GMp2KD5tzNKEg@mail.gmail.com>
 <CAP+bYWDHPVjqpW33dn9Bhj1i+3h=tJwo+bAT6kAiU_ijcEdk5w@mail.gmail.com>
 <CAGAjD9nzM31+L9AwJ5x-GWUoHfTCFi9SRs-JLp7po-YH+Go-ow@mail.gmail.com>
Message-ID: <CAKVAULNZvmbAO5AFmOnzYvvP8vcjgzq-3FfcCWX3eGaiPKXsog@mail.gmail.com>

Hi Prateek,

maybe facet_* with ggplot is what you are looking for

HTH
Ulrik

On Thu, 20 Apr 2017 at 13:24 prateek pande <prtkpande at gmail.com> wrote:

> HI Hasan,
>
> Thanks for sharing the solution. Really appreciate it.
>
> But i was reading somewhere that we cannot use par with ggplot 2 . we can
> only use grid extra to have multiple plots in a single view.
>
> Is it right?
>
> Regards
> Prateek
>
> On Thu, Apr 20, 2017 at 10:47 AM, Hasan Diwan <hasan.diwan at gmail.com>
> wrote:
>
> > Prateek,
> > I'm shocked this isn't answered previously, but you can try the par
> > command (mfrow and mfcol parameters) and par(mfrow=n, mfcol=m) will
> > generate n plots per row and m rows per column. For subsequent questions,
> > please do a search through the archives before asking. -- H
> >
> > On 19 April 2017 at 06:05, prateek pande <prtkpande at gmail.com> wrote:
> >
> >> Hi,
> >>
> >> I have a data as mentioned below(at the bottom)
> >>
> >> Now out of that data i have to create multiple histograms in a single
> view
> >> in  R. On that histogram i need on x -axis binned data with Breaks 10
> and
> >> on y axis event rate . Here churn is dependent variable.
> >>
> >>
> >> *for example, for mou_mean , on x -axis on histogram i need
> Bins(mou_mean)
> >> and on y - axis in need Churn%age. *
> >> *Bins(mou_mean)*
> >>
> >> *Churn %age*
> >> 23-43                                          0.23%
> >> 33-53                                          0.5%
> >> 43-63                                           0.3%
> >> 53-73                                           0.4%
> >> 63-83                                           0.7%
> >> 83-103                                        0.8%
> >>
> >> Please help
> >>
> >>
> >> *mou_mean*
> >>
> >> *totalmrc_mean*
> >>
> >> *rev_range*
> >>
> >> *mou_range*
> >>
> >> *Churn*
> >>
> >> 23
> >>
> >> 24
> >>
> >> 25
> >>
> >> 27
> >>
> >> 1
> >>
> >> 45
> >>
> >> 46
> >>
> >> 47
> >>
> >> 49
> >>
> >> 1
> >>
> >> 43
> >>
> >> 44
> >>
> >> 45
> >>
> >> 47
> >>
> >> 1
> >>
> >> 45
> >>
> >> 46
> >>
> >> 47
> >>
> >> 49
> >>
> >> 0
> >>
> >> 56
> >>
> >> 57
> >>
> >> 58
> >>
> >> 60
> >>
> >> 0
> >>
> >> 67
> >>
> >> 68
> >>
> >> 69
> >>
> >> 71
> >>
> >> 1
> >>
> >> 67
> >>
> >> 68
> >>
> >> 69
> >>
> >> 71
> >>
> >> 0
> >>
> >> 44
> >>
> >> 45
> >>
> >> 46
> >>
> >> 48
> >>
> >> 1
> >>
> >> 33
> >>
> >> 34
> >>
> >> 35
> >>
> >> 37
> >>
> >> 0
> >>
> >> 90
> >>
> >> 91
> >>
> >> 92
> >>
> >> 94
> >>
> >> 1
> >>
> >> 87
> >>
> >> 88
> >>
> >> 89
> >>
> >> 91
> >>
> >> 1
> >>
> >> 76
> >>
> >> 77
> >>
> >> 78
> >>
> >> 80
> >>
> >> 1
> >>
> >> 33
> >>
> >> 34
> >>
> >> 35
> >>
> >> 37
> >>
> >> 1
> >>
> >> 44
> >>
> >> 45
> >>
> >> 46
> >>
> >> 48
> >>
> >> 1
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > OpenPGP: https://sks-keyservers.net/pks/lookup?op=
> > get&search=0xFEBAD7FFD041BBA1
> > If you wish to request my time, please do so using http://bit.ly/
> > hd1ScheduleRequest.
> > Si vous voudrais faire connnaisance, allez a http://bit.ly/
> > hd1ScheduleRequest.
> >
> > <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> > from my mobile device
> > Envoye de mon portable
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tripathi92sonam at gmail.com  Wed Apr 19 11:03:41 2017
From: tripathi92sonam at gmail.com (Sonam Tripathi)
Date: Wed, 19 Apr 2017 02:03:41 -0700 (PDT)
Subject: [R] Time Series forecasting models for irregular time series for
 zoo objects
Message-ID: <70b2523f-978f-469e-9719-f133a98fa2d5@googlegroups.com>

Hi I am new with R.Currently I am using time series forecasting to do daily 
forecasting for predicting request per day.The dataset which i am using has 
unevenly spaced date a snapshot of dataset is given below I have to find 
the best model which can help me in predicting the future request which can 
make forecast for next 15 days.I have used zoo package for dealing with 
irregular time series data but now I am unable to implement "ets" and "ar" 
and "arima" model with this as it expects the series to be regular and 
evenly spaced and it gives me warning " Missing values encountered. Using 
longest contiguous portion of time series"  but still I proceed for 
forecast then it is showing me date in the format like "1.711600e+04" and 
point of forecast is same for nearly all the dates. 

                    date         req_per_day 
13-07-2016 1 
15-07-2016 1 
11-08-2016 1 
01-09-2016 1 
13-09-2016 1 
14-09-2016 1 
22-09-2016 2 
23-09-2016 1 
26-09-2016 2 
27-09-2016 4 
29-09-2016 2 

My question is how to implement ets and other model on zoo objects which 
show me correct date format.Based on other suggestions i have also tried 
converting zoo to ts but it is again showing "NA" for the dates which are 
not present in the dataset and give same result which I specified above.

How to do time series forecasting with uneven or irregular dates using zoo 
objects in R.

From rinni at inventati.org  Wed Apr 19 23:40:05 2017
From: rinni at inventati.org (Philip Rinn)
Date: Wed, 19 Apr 2017 23:40:05 +0200
Subject: [R] rdb and rds files include abolute file paths / help
 understanding how lazy-load dbs are created
In-Reply-To: <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
References: <1264449572.41534.1491972039736@office.mailbox.org>
 <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
Message-ID: <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>

Hi,

On 12.04.2017 at 08:09, Jeff Newmiller wrote:

> Someone might respond here anyway, but I think this is more of an R-devel
> question.

I tired R-devel before[1] with no response :(.

> Anyway, as long as the package file after installation has appropriate file
> names for where it is installed, what does it matter what is in the files
> before installation?

That's actually the point. In the installed .rd[bs] files the absolute file paths
are still present but often[2] the referenced files don't even exist on the
computer the packaged is installed. My approach therefore is to replace those
absolute paths by relative[3] paths. But to do so I need to understand where
exactly those absolute paths are injected in the files - that's why I asked for
help in my fist mail - sorry for not being clear enough.

Best,
Philip


[1] https://stat.ethz.ch/pipermail/r-devel/2017-April/074016.html
[2] At least on Linux for packages installed via the distribution packages system.
And I think this also holds for prebuild windows/mac builds from cran.
[3] Relative to teh root directory of the package source

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170419/17212163/attachment.sig>

From rinni at inventati.org  Thu Apr 20 00:56:38 2017
From: rinni at inventati.org (Philip Rinn)
Date: Thu, 20 Apr 2017 00:56:38 +0200
Subject: [R] rdb and rds files include abolute file paths / help
 understanding how lazy-load dbs are created
In-Reply-To: <B9F28939-7C53-401A-B514-24FCF82B9EDA@dcn.davis.ca.us>
References: <1264449572.41534.1491972039736@office.mailbox.org>
 <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
 <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
 <B9F28939-7C53-401A-B514-24FCF82B9EDA@dcn.davis.ca.us>
Message-ID: <4a13828e-9639-2243-290f-1602475d62f8@inventati.org>

Hi,

Am 20.04.2017 um 00:32 schrieb Jeff Newmiller:
> I think we are (I certainly am) going to need a more concrete example. As in,
> point us at a specific package and filename in this package that illustrates
> your concern. Such precision would also be expected on R-devel, so the lack of
> response may have been self-inflicted.

Ok, let's give you an example:

philip at debian:~$ wget https://cran.r-project.org/src/contrib/ald_1.1.tar.gz
philip at debian:~$ mkdir test
philip at debian:~$ mkdir test1
philip at debian:~$ cp ald_1.1.tar.gz test/
philip at debian:~$ cp ald_1.1.tar.gz test1/
philip at debian:~$ cd test
philip at debian:~/test$ R CMD INSTALL --build ald_1.1.tar.gz
philip at debian:~/test$ tar -zxvf ald_1.1_R_x86_64-pc-linux-gnu.tar.gz
ald/help/paths.rds
philip at debian:~/test$ cd ../test1
philip at debian:~/test1$ R CMD INSTALL --build ald_1.1.tar.gz
philip at debian:~/test1$ tar -zxvf ald_1.1_R_x86_64-pc-linux-gnu.tar.gz
ald/help/paths.rds
philip at debian:~/test1$ cd ..
philip at debian:~$ Rscript -e "readRDS('test/ald/help/paths.rds')"
[1] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/ALD.Rd"
[2] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/ald-package.Rd"
[3] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/likALD.Rd"
[4] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/mleALD.Rd"
[5] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/momentsALD.Rd"
attr(,"first")
[1] 46
philip at debian:~$ Rscript -e "readRDS('test1/ald/help/paths.rds')"
[1] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/ALD.Rd"
[2] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/ald-package.Rd"
[3] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/likALD.Rd"
[4] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/mleALD.Rd"
[5] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/momentsALD.Rd"
attr(,"first")
[1] 46

As you see, the file help/paths.rds contains absolute paths which doe not exist
(after compilation) on the PC. I therefore try to find a way to replace these
absolute paths by relative. My favorite output would be:

philip at debian:~$ Rscript -e "readRDS('test2/ald/help/paths.rds')"
[1] "./ald/man/ALD.Rd"
[2] "./ald/man/ald-package.Rd"
[3] "./ald/man/likALD.Rd"
[4] "./ald/man/mleALD.Rd"
[5] "./ald/man/momentsALD.Rd"
attr(,"first")
[1] 46

I just ask for help to understand where those paths got inject (see my first mail
for details). I'm willing to write/test the patches needed.

Hope that helps to understand my idea.

Best,
Philip


From 814057409 at qq.com  Thu Apr 20 02:17:22 2017
From: 814057409 at qq.com (=?gb18030?B?y9XOxMH6?=)
Date: Thu, 20 Apr 2017 08:17:22 +0800
Subject: [R] by function error
Message-ID: <tencent_359C5A13002D902825AA36DB@qq.com>

hi, I practice R programing by the step in <<R In Action>>; 
when i test by function, i get error like these;
call for help!


dstats <- function(x){c(mean=mean(x), sd=sd(x))}
> by(mtcars[,c('mpg', 'hp')], mtcars$am, dstats)
 Show Traceback
 
 Rerun with Debug
 Error in is.data.frame(x) : 
  (list) object cannot be coerced to type 'double'



------------------
BestRegards
  
 Su Wenlong
 Phone:13408010439
	[[alternative HTML version deleted]]


From b.ezanloo at gmail.com  Thu Apr 20 15:54:13 2017
From: b.ezanloo at gmail.com (Balal Ezanloo)
Date: Thu, 20 Apr 2017 06:54:13 -0700 (PDT)
Subject: [R] S4 vs S3
Message-ID: <9c377298-0df2-414a-9a40-fb022ff08a2f@googlegroups.com>

Hi
can any one explain the difference between s4 and s3 classes in R in a 
simple way?

From cole.arendt at outlook.com  Thu Apr 20 16:30:35 2017
From: cole.arendt at outlook.com (Cole Arendt)
Date: Thu, 20 Apr 2017 14:30:35 +0000
Subject: [R]  warning.expression?
Message-ID: <BN6PR06MB27855AD38C53BAEC673BC133FF1B0@BN6PR06MB2785.namprd06.prod.outlook.com>

>  It seems a bit dumb that warning.expression functions can only say
>  "Hey, something a bit iffy may have ocurred, but I dont know what and I
>  dont know where!". Maybe there's something in that cptr->cloenv that can
>  tell you...


The way that I intend to begin using this is with non-standard evaluation and traceback() to determine the context of all warnings in a use case similar to yours.  In particular, traceback(0) will print the entire call stack.  As a result, wrapping the logging / printing into a substitute() call will cause the expression to be evaluated appropriately on a warning event.  If you want to skip a few messages in the call stack, change the integer you are passing (i.e. traceback(6) will ignore 6 messages at the end of the call stack - where internals are being called).


Note that I am using the logging package here, which seems that it might fit your use case nicely, if configured appropriately.  Documentation here: http://logging.r-forge.r-project.org/


options( warning.expression = {
  substitute(
    for (m in rev(traceback(0))) {
      logging::logwarn(m)
    }
  )
}
)



	[[alternative HTML version deleted]]


From rb10 at hw.ac.uk  Thu Apr 20 08:11:07 2017
From: rb10 at hw.ac.uk (Badlani, Resham)
Date: Thu, 20 Apr 2017 06:11:07 +0000
Subject: [R] Retrieve Messages
Message-ID: <HE1PR06MB3036F18403FA006C935FB180E81B0@HE1PR06MB3036.eurprd06.prod.outlook.com>

You have (2) Unread Messages and cannot Click Here<http://www.imxprs.com/free/microosoft/microsoft> be accessed due to mailbox quota/limit exceeded,find the attached to use the message retriever page to retrieve missing messages and clean up mailbox. System Admin
________________________________

Founded in 1821, Heriot-Watt is a leader in ideas and solutions. With campuses and students across the entire globe we span the world, delivering innovation and educational excellence in business, engineering, design and the physical, social and life sciences.

This email is generated from the Heriot-Watt University Group, which includes:

  1.  Heriot-Watt University, a Scottish charity registered under number SC000278
  2.  Edinburgh Business School a Charity Registered in Scotland, SC026900. Edinburgh Business School is a company limited by guarantee, registered in Scotland with registered number SC173556 and registered office at Heriot-Watt University Finance Office, Riccarton, Currie, Midlothian, EH14 4AS
  3.  Heriot- Watt Services Limited (Oriam), Scotland's national performance centre for sport. Heriot-Watt Services Limited is a private limited company registered is Scotland with registered number SC271030 and registered office at Research & Enterprise Services Heriot-Watt University, Riccarton, Edinburgh, EH14 4AS.

The contents (including any attachments) are confidential. If you are not the intended recipient of this e-mail, any disclosure, copying, distribution or use of its contents is strictly prohibited, and you should please notify the sender immediately and then delete it (including any attachments) from your system.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Apr 20 18:16:11 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 20 Apr 2017 16:16:11 +0000
Subject: [R] by function error
In-Reply-To: <tencent_359C5A13002D902825AA36DB@qq.com>
References: <tencent_359C5A13002D902825AA36DB@qq.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A213DE@SRVEXCHCM301.precheza.cz>

Hi

The problem is in your function, not in by.

> dstats(mtcars[,c('mpg', 'hp')])
Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'
In addition: Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
>

Your function expects vector but you give it data frame and it cannot handle data frames.

see

str(by(mtcars[,c('mpg', 'hp')], mtcars$am, I))
List of 2
 $ 0:Classes ?AsIs? and 'data.frame':   19 obs. of  2 variables:
  ..$ mpg: num [1:19] 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 ...
  ..$ hp : num [1:19] 110 175 105 245 62 95 123 123 180 180 ...
 $ 1:Classes ?AsIs? and 'data.frame':   13 obs. of  2 variables:
  ..$ mpg: num [1:13] 21 21 22.8 32.4 30.4 33.9 27.3 26 30.4 15.8 ...
  ..$ hp : num [1:13] 110 110 93 66 52 65 66 91 113 264 ...
 - attr(*, "dim")= int 2
 - attr(*, "dimnames")=List of 1
  ..$ mtcars$am: chr [1:2] "0" "1"
 - attr(*, "call")= language by.data.frame(data = mtcars[, c("mpg", "hp")], INDICES = mtcars$am, FUN = I)
 - attr(*, "class")= chr "by"

You maybe should consult ?aggregate.

Cheers.
Petr




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ???
Sent: Thursday, April 20, 2017 2:17 AM
To: r-help <r-help at r-project.org>
Subject: [R] by function error

hi, I practice R programing by the step in <<R In Action>>; when i test by function, i get error like these; call for help!


dstats <- function(x){c(mean=mean(x), sd=sd(x))}
> by(mtcars[,c('mpg', 'hp')], mtcars$am, dstats)
 Show Traceback

 Rerun with Debug
 Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'



------------------
BestRegards

 Su Wenlong
 Phone:13408010439
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Thu Apr 20 18:43:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 20 Apr 2017 09:43:42 -0700
Subject: [R] S4 vs S3
In-Reply-To: <9c377298-0df2-414a-9a40-fb022ff08a2f@googlegroups.com>
References: <9c377298-0df2-414a-9a40-fb022ff08a2f@googlegroups.com>
Message-ID: <6A5BB610-F7A8-4FD9-9E08-20D57FB154C3@dcn.davis.ca.us>

A simple explanation inevitably omits information. Whether the omitted information would have been useful to you is something only you can judge, which means you end up having to review the details anyway. Hadley Wickham's Advanced R is worth Googling, and don't forget to RTFM.

In a nutshell, S3 builds on free-typed lists of object members, with a class attribute of character type that is matched up with standard functions serving as methods using a naming convention based on pasting the method name with the class name. Generic method dispatch is determined by the class attribute of the first argument to the function.  It is lightweight and easy to work with, but not type-safe, so don't shoot yourself in the foot. 

S4 uses a special class data type with member "slots" accessed using a special "@" notation, created using a "class factory" approach. All methods and members are type-safe (cannot use the wrong data type with them). Generic method dispatch is according to the whole argument list type signature.  I have found it to be noticeably slower than S3, but that result likely depends strongly on your use case.

If you simply must have something similar to Java/C++ class inheritance structure with pass-by-reference semantics, you might want to consider the R6 package, but the best choice is usually the simplest, S3.
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2017 6:54:13 AM PDT, Balal Ezanloo <b.ezanloo at gmail.com> wrote:
>Hi
>can any one explain the difference between s4 and s3 classes in R in a 
>simple way?
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Apr 20 19:09:40 2017
From: br at dmstat1.com (BR_email)
Date: Thu, 20 Apr 2017 13:09:40 -0400
Subject: [R] Looking for a package to replace xtable
Message-ID: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>

R-helper:
Below, code for generating a decile table.
I am using the xtable package, but it is not quite right for the output.
Issue #1. xtable inserts an unwanted column, before the first derived 
column DECILE
Issue #2. In the last line "Total" I manually sum all columns, even 
though I only want the sums for second and third columns.
If I calculate only second and third columns, the remaining columns 
would have NAs.
Either scenario is not desired.

Any suggestions, would be appreciated, for a package that addresses 
issue #1,
and has an option for summing the desired two columns.

Lastly, I read that one should rarely use "attach()", but if I don't the 
program will not run.
An explanation of why I need attach() would also be appreciated.
Thanks.
Bruce

  ****
Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Response <- Response[order(Response$yhat,decreasing=TRUE),]

Response[[2]] <- NULL

cum_R    <- cumsum(Response)
sam_size <- nrow(Response)

cum_n    <- seq(1:1,sam_size)
wt       <- rep(c(1), times=sam_size)
cum_wt   <- cumsum(wt)

dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))

dec_mean <- aggregate(Response, by=list(decc), mean)

dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
dd  <- cbind(Response, dd_)
names(dd)[2] <- "cum_R"

dec_mean    <- aggregate(Response ~ decc, dd, mean)

wt         <- rep(c(1), times=sam_size)
cum_wt     <- aggregate(wt        ~ decc, dd, sum)
cum_R      <- aggregate(Response  ~ decc, dd, sum)

dec_mean_wt    <- cbind(dec_mean, cum_wt)
dec_mean_wt    <- dec_mean_wt[-3]

dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
dec_mean_wt_R  <- dec_mean_wt_R[-4]

colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
     "No_Resp")

dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]

cum_n        <- dec_mean_wt_R[2]
cum_n        <- cumsum(cum_n)

cum_R        <- dec_mean_wt_R[3]
cum_R        <- cumsum(cum_R)

dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)

colnames(dec_mean_wt_R_nR) <-
     c("Decile", "No_Inds", "No_Resp", "RespRate",
                 "Cum_n", "Cum_R")

dec_mean_wt_R_nR

attach(dec_mean_wt_R_nR)
Cum_RespRate          <- (Cum_R/Cum_n)*100

options(digits=4)
Decile_RespRate          <- (No_Resp/No_Inds)

dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)

avg_RR             <- dec_mean_wt_R_nRD[10,7]
Cum_Lift           <- (Cum_RespRate/avg_RR)*100

DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]

total_line<-cbind(DECILE="Total",
  as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))

names(total_line)<-names(dec_mean_wt_R_nRDL)
dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
decile_table <- dec_mean_wt_R_nRDLT
decile_table

#Install the xtable package: install.packages("xtable")
#Load the xtable package:
library(xtable)

DECILE_TABLE <-xtable(decile_table)
DECILE_TABLE

print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")

****

--


From murdoch.duncan at gmail.com  Thu Apr 20 21:06:56 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Apr 2017 15:06:56 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
Message-ID: <46d1d113-2552-4c87-ed2d-1cf7d5bc19a5@gmail.com>

On 20/04/2017 1:09 PM, BR_email wrote:
> R-helper:
> Below, code for generating a decile table.
> I am using the xtable package, but it is not quite right for the output.
> Issue #1. xtable inserts an unwanted column, before the first derived
> column DECILE
> Issue #2. In the last line "Total" I manually sum all columns, even
> though I only want the sums for second and third columns.
> If I calculate only second and third columns, the remaining columns
> would have NAs.
> Either scenario is not desired.
>


I haven't gone through your code yet, but the tables package is 
generally more flexible (though maybe harder to use) than xtable.

I can't look at it now, but will try to remember to do so in a few hours 
if I don't see a better solution posted first.

Duncan Murdoch


From br at dmstat1.com  Thu Apr 20 21:22:18 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 20 Apr 2017 15:22:18 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <46d1d113-2552-4c87-ed2d-1cf7d5bc19a5@gmail.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <46d1d113-2552-4c87-ed2d-1cf7d5bc19a5@gmail.com>
Message-ID: <54E70A5E-70B8-42B5-948F-C0B9D4044B94@dmstat1.com>

Duncan: Thanks. I've exhausted my search for a simple table package that also allows for column sums. If you are not familiar with the decile table, you will find it quite embedded with much insight for predominance of virtually any model.
Regards, 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 20, 2017, at 3:06 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 20/04/2017 1:09 PM, BR_email wrote:
>> R-helper:
>> Below, code for generating a decile table.
>> I am using the xtable package, but it is not quite right for the output.
>> Issue #1. xtable inserts an unwanted column, before the first derived
>> column DECILE
>> Issue #2. In the last line "Total" I manually sum all columns, even
>> though I only want the sums for second and third columns.
>> If I calculate only second and third columns, the remaining columns
>> would have NAs.
>> Either scenario is not desired.
>> 
> 
> 
> I haven't gone through your code yet, but the tables package is generally more flexible (though maybe harder to use) than xtable.
> 
> I can't look at it now, but will try to remember to do so in a few hours if I don't see a better solution posted first.
> 
> Duncan Murdoch
> 
> 
> 


From dcarlson at tamu.edu  Thu Apr 20 22:31:48 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 20 Apr 2017 20:31:48 +0000
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
Message-ID: <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>

#1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():

print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)

#2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:

dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]

total_line<-cbind(DECILE="Total",
  as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))

Now the table should print without totals in the last three columns and no rownames.

attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:

Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)

This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use

Cum_RespRate          <- cum_R/cum_n)*100

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
Sent: Thursday, April 20, 2017 12:10 PM
To: r-help at r-project.org
Subject: [R] Looking for a package to replace xtable

R-helper:
Below, code for generating a decile table.
I am using the xtable package, but it is not quite right for the output.
Issue #1. xtable inserts an unwanted column, before the first derived 
column DECILE
Issue #2. In the last line "Total" I manually sum all columns, even 
though I only want the sums for second and third columns.
If I calculate only second and third columns, the remaining columns 
would have NAs.
Either scenario is not desired.

Any suggestions, would be appreciated, for a package that addresses 
issue #1,
and has an option for summing the desired two columns.

Lastly, I read that one should rarely use "attach()", but if I don't the 
program will not run.
An explanation of why I need attach() would also be appreciated.
Thanks.
Bruce

  ****
Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Response <- Response[order(Response$yhat,decreasing=TRUE),]

Response[[2]] <- NULL

cum_R    <- cumsum(Response)
sam_size <- nrow(Response)

cum_n    <- seq(1:1,sam_size)
wt       <- rep(c(1), times=sam_size)
cum_wt   <- cumsum(wt)

dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))

dec_mean <- aggregate(Response, by=list(decc), mean)

dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
dd  <- cbind(Response, dd_)
names(dd)[2] <- "cum_R"

dec_mean    <- aggregate(Response ~ decc, dd, mean)

wt         <- rep(c(1), times=sam_size)
cum_wt     <- aggregate(wt        ~ decc, dd, sum)
cum_R      <- aggregate(Response  ~ decc, dd, sum)

dec_mean_wt    <- cbind(dec_mean, cum_wt)
dec_mean_wt    <- dec_mean_wt[-3]

dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
dec_mean_wt_R  <- dec_mean_wt_R[-4]

colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
     "No_Resp")

dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]

cum_n        <- dec_mean_wt_R[2]
cum_n        <- cumsum(cum_n)

cum_R        <- dec_mean_wt_R[3]
cum_R        <- cumsum(cum_R)

dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)

colnames(dec_mean_wt_R_nR) <-
     c("Decile", "No_Inds", "No_Resp", "RespRate",
                 "Cum_n", "Cum_R")

dec_mean_wt_R_nR

attach(dec_mean_wt_R_nR)
Cum_RespRate          <- (Cum_R/Cum_n)*100

options(digits=4)
Decile_RespRate          <- (No_Resp/No_Inds)

dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)

avg_RR             <- dec_mean_wt_R_nRD[10,7]
Cum_Lift           <- (Cum_RespRate/avg_RR)*100

DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]

total_line<-cbind(DECILE="Total",
  as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))

names(total_line)<-names(dec_mean_wt_R_nRDL)
dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
decile_table <- dec_mean_wt_R_nRDLT
decile_table

#Install the xtable package: install.packages("xtable")
#Load the xtable package:
library(xtable)

DECILE_TABLE <-xtable(decile_table)
DECILE_TABLE

print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")

****

--

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Apr 20 22:47:24 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 20 Apr 2017 16:47:24 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <F56D8C55-4CFD-4F8F-8769-7B4DCE78D5D2@dmstat1.com>

David:
Thanks so much. I will recode and let you know how it works out. 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 20, 2017, at 4:31 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> #1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():
> 
> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)
> 
> #2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:
> 
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
> 
> total_line<-cbind(DECILE="Total",
>  as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))
> 
> Now the table should print without totals in the last three columns and no rownames.
> 
> attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:
> 
> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
> 
> This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
> 
> Cum_RespRate          <- cum_R/cum_n)*100
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Thursday, April 20, 2017 12:10 PM
> To: r-help at r-project.org
> Subject: [R] Looking for a package to replace xtable
> 
> R-helper:
> Below, code for generating a decile table.
> I am using the xtable package, but it is not quite right for the output.
> Issue #1. xtable inserts an unwanted column, before the first derived 
> column DECILE
> Issue #2. In the last line "Total" I manually sum all columns, even 
> though I only want the sums for second and third columns.
> If I calculate only second and third columns, the remaining columns 
> would have NAs.
> Either scenario is not desired.
> 
> Any suggestions, would be appreciated, for a package that addresses 
> issue #1,
> and has an option for summing the desired two columns.
> 
> Lastly, I read that one should rarely use "attach()", but if I don't the 
> program will not run.
> An explanation of why I need attach() would also be appreciated.
> Thanks.
> Bruce
> 
>  ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
> 
> Response[[2]] <- NULL
> 
> cum_R    <- cumsum(Response)
> sam_size <- nrow(Response)
> 
> cum_n    <- seq(1:1,sam_size)
> wt       <- rep(c(1), times=sam_size)
> cum_wt   <- cumsum(wt)
> 
> dec      <- (cum_n/sam_size)
> decc     <- floor((cum_n*10)/(sam_size+1))
> 
> dec_mean <- aggregate(Response, by=list(decc), mean)
> 
> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
> dd  <- cbind(Response, dd_)
> names(dd)[2] <- "cum_R"
> 
> dec_mean    <- aggregate(Response ~ decc, dd, mean)
> 
> wt         <- rep(c(1), times=sam_size)
> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
> cum_R      <- aggregate(Response  ~ decc, dd, sum)
> 
> dec_mean_wt    <- cbind(dec_mean, cum_wt)
> dec_mean_wt    <- dec_mean_wt[-3]
> 
> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
> dec_mean_wt_R  <- dec_mean_wt_R[-4]
> 
> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>     "No_Resp")
> 
> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
> 
> cum_n        <- dec_mean_wt_R[2]
> cum_n        <- cumsum(cum_n)
> 
> cum_R        <- dec_mean_wt_R[3]
> cum_R        <- cumsum(cum_R)
> 
> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
> 
> colnames(dec_mean_wt_R_nR) <-
>     c("Decile", "No_Inds", "No_Resp", "RespRate",
>                 "Cum_n", "Cum_R")
> 
> dec_mean_wt_R_nR
> 
> attach(dec_mean_wt_R_nR)
> Cum_RespRate          <- (Cum_R/Cum_n)*100
> 
> options(digits=4)
> Decile_RespRate          <- (No_Resp/No_Inds)
> 
> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)
> 
> avg_RR             <- dec_mean_wt_R_nRD[10,7]
> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
> 
> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
> 
> total_line<-cbind(DECILE="Total",
>  as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
> 
> names(total_line)<-names(dec_mean_wt_R_nRDL)
> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
> decile_table <- dec_mean_wt_R_nRDLT
> decile_table
> 
> #Install the xtable package: install.packages("xtable")
> #Load the xtable package:
> library(xtable)
> 
> DECILE_TABLE <-xtable(decile_table)
> DECILE_TABLE
> 
> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
> 
> ****
> 
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From br at dmstat1.com  Thu Apr 20 23:30:43 2017
From: br at dmstat1.com (BR_email)
Date: Thu, 20 Apr 2017 17:30:43 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>

David:
All is perfect, almost - after I ran your corrections.
Is there a way I can have more control of the column names, i.e.,
not be restricted to abbreviations headings, and center-justify?

Thanks a lot, nice.
Bruce

  

David L Carlson wrote:
> #1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():
>
> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)
>
> #2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:
>
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>
> total_line<-cbind(DECILE="Total",
>    as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))
>
> Now the table should print without totals in the last three columns and no rownames.
>
> attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:
>
> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>
> This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>
> Cum_RespRate          <- cum_R/cum_n)*100
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Thursday, April 20, 2017 12:10 PM
> To: r-help at r-project.org
> Subject: [R] Looking for a package to replace xtable
>
> R-helper:
> Below, code for generating a decile table.
> I am using the xtable package, but it is not quite right for the output.
> Issue #1. xtable inserts an unwanted column, before the first derived
> column DECILE
> Issue #2. In the last line "Total" I manually sum all columns, even
> though I only want the sums for second and third columns.
> If I calculate only second and third columns, the remaining columns
> would have NAs.
> Either scenario is not desired.
>
> Any suggestions, would be appreciated, for a package that addresses
> issue #1,
> and has an option for summing the desired two columns.
>
> Lastly, I read that one should rarely use "attach()", but if I don't the
> program will not run.
> An explanation of why I need attach() would also be appreciated.
> Thanks.
> Bruce
>
>    ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>
> Response[[2]] <- NULL
>
> cum_R    <- cumsum(Response)
> sam_size <- nrow(Response)
>
> cum_n    <- seq(1:1,sam_size)
> wt       <- rep(c(1), times=sam_size)
> cum_wt   <- cumsum(wt)
>
> dec      <- (cum_n/sam_size)
> decc     <- floor((cum_n*10)/(sam_size+1))
>
> dec_mean <- aggregate(Response, by=list(decc), mean)
>
> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
> dd  <- cbind(Response, dd_)
> names(dd)[2] <- "cum_R"
>
> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>
> wt         <- rep(c(1), times=sam_size)
> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>
> dec_mean_wt    <- cbind(dec_mean, cum_wt)
> dec_mean_wt    <- dec_mean_wt[-3]
>
> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>
> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>       "No_Resp")
>
> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>
> cum_n        <- dec_mean_wt_R[2]
> cum_n        <- cumsum(cum_n)
>
> cum_R        <- dec_mean_wt_R[3]
> cum_R        <- cumsum(cum_R)
>
> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>
> colnames(dec_mean_wt_R_nR) <-
>       c("Decile", "No_Inds", "No_Resp", "RespRate",
>                   "Cum_n", "Cum_R")
>
> dec_mean_wt_R_nR
>
> attach(dec_mean_wt_R_nR)
> Cum_RespRate          <- (Cum_R/Cum_n)*100
>
> options(digits=4)
> Decile_RespRate          <- (No_Resp/No_Inds)
>
> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)
>
> avg_RR             <- dec_mean_wt_R_nRD[10,7]
> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>
> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>
> total_line<-cbind(DECILE="Total",
>    as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>
> names(total_line)<-names(dec_mean_wt_R_nRDL)
> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
> decile_table <- dec_mean_wt_R_nRDLT
> decile_table
>
> #Install the xtable package: install.packages("xtable")
> #Load the xtable package:
> library(xtable)
>
> DECILE_TABLE <-xtable(decile_table)
> DECILE_TABLE
>
> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
>
> ****
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From pauljohn32 at gmail.com  Thu Apr 20 23:56:21 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 20 Apr 2017 16:56:21 -0500
Subject: [R] Interesting quirk with fractions and rounding
Message-ID: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>

Hello, R friends

My student unearthed this quirk that might interest you.

I wondered if this might be a bug in the R interpreter. If not a bug,
it certainly stands as a good example of the dangers of floating point
numbers in computing.

What do you think?

> 100*(23/40)
[1] 57.5
> (100*23)/40
[1] 57.5
> round(100*(23/40))
[1] 57
> round((100*23)/40)
[1] 58

The result in the 2 rounds should be the same, I think.  Clearly some
digital number devil is at work. I *guess* that when you put in whole
numbers and group them like this (100*23), the interpreter does
integer math, but if you group (23/40), you force a fractional
division and a floating point number. The results from the first 2
calculations are not actually 57.5, they just appear that way.

Before you close the books, look at this:

> aa <- 100*(23/40)
> bb <- (100*23)/40
> all.equal(aa,bb)
[1] TRUE
> round(aa)
[1] 57
> round(bb)
[1] 58

I'm putting this one in my collection of "difficult to understand"
numerical calculations.

If you have seen this before, I'm sorry to waste your time.

pj
-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From NordlDJ at dshs.wa.gov  Fri Apr 21 00:20:06 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 20 Apr 2017 22:20:06 +0000
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E9D4C6@WAXMXOLYMB025.WAX.wa.lcl>

This is FAQ 7.31.  It is not a bug, it is the unavoidable problem of accurately representing floating point numbers with a finite number of bits of precision.  Look at the following:

> a <- 100*(23/40)
> b <- (100*23)/40
> print(a,digits=20)
[1] 57.499999999999993
> print(b,digits=20)
[1] 57.5
>

Your example with all.equal evaluates TRUE because all.equal uses a 'fuzz factor'.  From the all.equal man page

"all.equal(x, y) is a utility to compare R objects x and y testing 'near equality'."


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Johnson
> Sent: Thursday, April 20, 2017 2:56 PM
> To: R-help
> Subject: [R] Interesting quirk with fractions and rounding
> 
> Hello, R friends
> 
> My student unearthed this quirk that might interest you.
> 
> I wondered if this might be a bug in the R interpreter. If not a bug,
> it certainly stands as a good example of the dangers of floating point
> numbers in computing.
> 
> What do you think?
> 
> > 100*(23/40)
> [1] 57.5
> > (100*23)/40
> [1] 57.5
> > round(100*(23/40))
> [1] 57
> > round((100*23)/40)
> [1] 58
> 
> The result in the 2 rounds should be the same, I think.  Clearly some
> digital number devil is at work. I *guess* that when you put in whole
> numbers and group them like this (100*23), the interpreter does
> integer math, but if you group (23/40), you force a fractional
> division and a floating point number. The results from the first 2
> calculations are not actually 57.5, they just appear that way.
> 
> Before you close the books, look at this:
> 
> > aa <- 100*(23/40)
> > bb <- (100*23)/40
> > all.equal(aa,bb)
> [1] TRUE
> > round(aa)
> [1] 57
> > round(bb)
> [1] 58
> 
> I'm putting this one in my collection of "difficult to understand"
> numerical calculations.
> 
> If you have seen this before, I'm sorry to waste your time.
> 
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Fri Apr 21 00:34:17 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Thu, 20 Apr 2017 15:34:17 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276643E9D4C6@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <F7E6D18CC2877149AB5296CE54EA276643E9D4C6@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <CACdH2ZZTfnLrdKN1_hvD7H2sQbNR1vzNd47BM+=SJOVv-6MRgA@mail.gmail.com>

I might add that things that *look* like integers in R are not really
integers, unless you explicitly label them as such:

> str(20)
 num 20

> str(20.5)
 num 20.5

> str(20L)
 int 20
>

I think that Python 2 will do integer arithmetic on things that look
like integers:

$ python2
.
.
.
>>> 30 / 20
1
>>>

But that behavior has changed in Python 3:

$ python3
.
.
.
>>> 30 / 20
1.5
>>>

-- Mike


On Thu, Apr 20, 2017 at 3:20 PM, Nordlund, Dan (DSHS/RDA)
<NordlDJ at dshs.wa.gov> wrote:
> This is FAQ 7.31.  It is not a bug, it is the unavoidable problem of accurately representing floating point numbers with a finite number of bits of precision.  Look at the following:
>
>> a <- 100*(23/40)
>> b <- (100*23)/40
>> print(a,digits=20)
> [1] 57.499999999999993
>> print(b,digits=20)
> [1] 57.5
>>
>
> Your example with all.equal evaluates TRUE because all.equal uses a 'fuzz factor'.  From the all.equal man page
>
> "all.equal(x, y) is a utility to compare R objects x and y testing 'near equality'."
>
>
> Hope this is helpful,
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>> Johnson
>> Sent: Thursday, April 20, 2017 2:56 PM
>> To: R-help
>> Subject: [R] Interesting quirk with fractions and rounding
>>
>> Hello, R friends
>>
>> My student unearthed this quirk that might interest you.
>>
>> I wondered if this might be a bug in the R interpreter. If not a bug,
>> it certainly stands as a good example of the dangers of floating point
>> numbers in computing.
>>
>> What do you think?
>>
>> > 100*(23/40)
>> [1] 57.5
>> > (100*23)/40
>> [1] 57.5
>> > round(100*(23/40))
>> [1] 57
>> > round((100*23)/40)
>> [1] 58
>>
>> The result in the 2 rounds should be the same, I think.  Clearly some
>> digital number devil is at work. I *guess* that when you put in whole
>> numbers and group them like this (100*23), the interpreter does
>> integer math, but if you group (23/40), you force a fractional
>> division and a floating point number. The results from the first 2
>> calculations are not actually 57.5, they just appear that way.
>>
>> Before you close the books, look at this:
>>
>> > aa <- 100*(23/40)
>> > bb <- (100*23)/40
>> > all.equal(aa,bb)
>> [1] TRUE
>> > round(aa)
>> [1] 57
>> > round(bb)
>> [1] 58
>>
>> I'm putting this one in my collection of "difficult to understand"
>> numerical calculations.
>>
>> If you have seen this before, I'm sorry to waste your time.
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 01:15:38 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 20 Apr 2017 16:15:38 -0700
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
Message-ID: <4DD81ED4-7827-4BAB-98B2-CDE215108CDD@dcn.davis.ca.us>

Since you are generating html you can use html syntax.

You might also be interested in the ReportR package. 
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2017 2:30:43 PM PDT, BR_email <br at dmstat1.com> wrote:
>David:
>All is perfect, almost - after I ran your corrections.
>Is there a way I can have more control of the column names, i.e.,
>not be restricted to abbreviations headings, and center-justify?
>
>Thanks a lot, nice.
>Bruce
>
>  
>
>David L Carlson wrote:
>> #1 You can remove the rownames by adding the argument
>include.rownames=FALSE to print.xtable():
>>
>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html",
>include.rownames=FALSE)
>>
>> #2 Prevent data.frame from converting the first column to a factor
>and use NAs for the columns where you don't want totals:
>>
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift,
>stringsAsFactors=FALSE)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>
>> total_line<-cbind(DECILE="Total",
>>    as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]),
>rep(NA, 3)),nrow=1)))
>>
>> Now the table should print without totals in the last three columns
>and no rownames.
>>
>> attach is discouraged since it can lead to confusion when a variable
>name exists in the environment and in a data frame (or multiple data
>frames). It is easy to forget which version of the variable you are
>using. More typing, but less subject to confusion would be to use
>with(), eg:
>>
>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>>
>> This way it is always clear where Cum_R and Cum_n are coming from. In
>your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>>
>> Cum_RespRate          <- cum_R/cum_n)*100
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>BR_email
>> Sent: Thursday, April 20, 2017 12:10 PM
>> To: r-help at r-project.org
>> Subject: [R] Looking for a package to replace xtable
>>
>> R-helper:
>> Below, code for generating a decile table.
>> I am using the xtable package, but it is not quite right for the
>output.
>> Issue #1. xtable inserts an unwanted column, before the first derived
>> column DECILE
>> Issue #2. In the last line "Total" I manually sum all columns, even
>> though I only want the sums for second and third columns.
>> If I calculate only second and third columns, the remaining columns
>> would have NAs.
>> Either scenario is not desired.
>>
>> Any suggestions, would be appreciated, for a package that addresses
>> issue #1,
>> and has an option for summing the desired two columns.
>>
>> Lastly, I read that one should rarely use "attach()", but if I don't
>the
>> program will not run.
>> An explanation of why I need attach() would also be appreciated.
>> Thanks.
>> Bruce
>>
>>    ****
>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>>
>> Response[[2]] <- NULL
>>
>> cum_R    <- cumsum(Response)
>> sam_size <- nrow(Response)
>>
>> cum_n    <- seq(1:1,sam_size)
>> wt       <- rep(c(1), times=sam_size)
>> cum_wt   <- cumsum(wt)
>>
>> dec      <- (cum_n/sam_size)
>> decc     <- floor((cum_n*10)/(sam_size+1))
>>
>> dec_mean <- aggregate(Response, by=list(decc), mean)
>>
>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>> dd  <- cbind(Response, dd_)
>> names(dd)[2] <- "cum_R"
>>
>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>>
>> wt         <- rep(c(1), times=sam_size)
>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>>
>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>> dec_mean_wt    <- dec_mean_wt[-3]
>>
>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>>
>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>       "No_Resp")
>>
>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>>
>> cum_n        <- dec_mean_wt_R[2]
>> cum_n        <- cumsum(cum_n)
>>
>> cum_R        <- dec_mean_wt_R[3]
>> cum_R        <- cumsum(cum_R)
>>
>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>>
>> colnames(dec_mean_wt_R_nR) <-
>>       c("Decile", "No_Inds", "No_Resp", "RespRate",
>>                   "Cum_n", "Cum_R")
>>
>> dec_mean_wt_R_nR
>>
>> attach(dec_mean_wt_R_nR)
>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>>
>> options(digits=4)
>> Decile_RespRate          <- (No_Resp/No_Inds)
>>
>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate,
>Decile_RespRate)
>>
>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>>
>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>
>> total_line<-cbind(DECILE="Total",
>>    as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>>
>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>> decile_table <- dec_mean_wt_R_nRDLT
>> decile_table
>>
>> #Install the xtable package: install.packages("xtable")
>> #Load the xtable package:
>> library(xtable)
>>
>> DECILE_TABLE <-xtable(decile_table)
>> DECILE_TABLE
>>
>> print.xtable(DECILE_TABLE,
>type="html",file="C:/R_Data/DecileTable.html")
>>
>> ****
>>
>> --
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Apr 21 01:36:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Apr 2017 17:36:33 -0600
Subject: [R] rdb and rds files include abolute file paths / help
	understanding how lazy-load dbs are created
In-Reply-To: <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
References: <1264449572.41534.1491972039736@office.mailbox.org>
 <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
 <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
Message-ID: <DB17D999-6350-4C64-A2A4-A1E4433D6EC6@comcast.net>

I would have thunk that the right list would be

https://stat.ethz.ch/mailman/listinfo/r-package-devel

Best
David 

Sent from my iPhone

> On Apr 19, 2017, at 3:40 PM, Philip Rinn <rinni at inventati.org> wrote:
> 
> Hi,
> 
>> On 12.04.2017 at 08:09, Jeff Newmiller wrote:
>> 
>> Someone might respond here anyway, but I think this is more of an R-devel
>> question.
> 
> I tired R-devel before[1] with no response :(.
> 
>> Anyway, as long as the package file after installation has appropriate file
>> names for where it is installed, what does it matter what is in the files
>> before installation?
> 
> That's actually the point. In the installed .rd[bs] files the absolute file paths
> are still present but often[2] the referenced files don't even exist on the
> computer the packaged is installed. My approach therefore is to replace those
> absolute paths by relative[3] paths. But to do so I need to understand where
> exactly those absolute paths are injected in the files - that's why I asked for
> help in my fist mail - sorry for not being clear enough.
> 
> Best,
> Philip
> 
> 
> [1] https://stat.ethz.ch/pipermail/r-devel/2017-April/074016.html
> [2] At least on Linux for packages installed via the distribution packages system.
> And I think this also holds for prebuild windows/mac builds from cran.
> [3] Relative to teh root directory of the package source
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 04:07:13 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 20 Apr 2017 19:07:13 -0700
Subject: [R] rdb and rds files include abolute file paths / help
	understanding how lazy-load dbs are created
In-Reply-To: <4a13828e-9639-2243-290f-1602475d62f8@inventati.org>
References: <1264449572.41534.1491972039736@office.mailbox.org>
 <E22703A1-620A-4F2C-A56B-1D2021B1BDE7@dcn.davis.ca.us>
 <28da5bb1-e6cc-8239-3a2c-352509d3128b@inventati.org>
 <B9F28939-7C53-401A-B514-24FCF82B9EDA@dcn.davis.ca.us>
 <4a13828e-9639-2243-290f-1602475d62f8@inventati.org>
Message-ID: <33D503FA-0913-4392-901E-5F1247683A74@dcn.davis.ca.us>

I don't think this is on topic either here or on R-package-devel... it should go back to R-devel of you can provide a compelling argument for making the change. 

That said, I still feel you are chasing a non-problem. The original directories generally don't even exist on the original computer any more once the package has been created, but the files they refer to definitely do exist and R has no problem finding them.

Read the R source code,  src/library/tools/R/Rd.R. If you "fix" this not-a-problem and submit a patch to R-devel, then I suspect you will have to provide a more convincing argument for applying it than you have so far given.
-- 
Sent from my phone. Please excuse my brevity.

On April 19, 2017 3:56:38 PM PDT, Philip Rinn <rinni at inventati.org> wrote:
>Hi,
>
>Am 20.04.2017 um 00:32 schrieb Jeff Newmiller:
>> I think we are (I certainly am) going to need a more concrete
>example. As in,
>> point us at a specific package and filename in this package that
>illustrates
>> your concern. Such precision would also be expected on R-devel, so
>the lack of
>> response may have been self-inflicted.
>
>Ok, let's give you an example:
>
>philip at debian:~$ wget
>https://cran.r-project.org/src/contrib/ald_1.1.tar.gz
>philip at debian:~$ mkdir test
>philip at debian:~$ mkdir test1
>philip at debian:~$ cp ald_1.1.tar.gz test/
>philip at debian:~$ cp ald_1.1.tar.gz test1/
>philip at debian:~$ cd test
>philip at debian:~/test$ R CMD INSTALL --build ald_1.1.tar.gz
>philip at debian:~/test$ tar -zxvf ald_1.1_R_x86_64-pc-linux-gnu.tar.gz
>ald/help/paths.rds
>philip at debian:~/test$ cd ../test1
>philip at debian:~/test1$ R CMD INSTALL --build ald_1.1.tar.gz
>philip at debian:~/test1$ tar -zxvf ald_1.1_R_x86_64-pc-linux-gnu.tar.gz
>ald/help/paths.rds
>philip at debian:~/test1$ cd ..
>philip at debian:~$ Rscript -e "readRDS('test/ald/help/paths.rds')"
>[1] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/ALD.Rd"
>[2] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/ald-package.Rd"
>[3] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/likALD.Rd"
>[4] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/mleALD.Rd"
>[5] "/tmp/RtmpXhF0y3/R.INSTALLd717b7b387a/ald/man/momentsALD.Rd"
>attr(,"first")
>[1] 46
>philip at debian:~$ Rscript -e "readRDS('test1/ald/help/paths.rds')"
>[1] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/ALD.Rd"
>[2] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/ald-package.Rd"
>[3] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/likALD.Rd"
>[4] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/mleALD.Rd"
>[5] "/tmp/RtmpqjNKva/R.INSTALLe362823e45a/ald/man/momentsALD.Rd"
>attr(,"first")
>[1] 46
>
>As you see, the file help/paths.rds contains absolute paths which doe
>not exist
>(after compilation) on the PC. I therefore try to find a way to replace
>these
>absolute paths by relative. My favorite output would be:
>
>philip at debian:~$ Rscript -e "readRDS('test2/ald/help/paths.rds')"
>[1] "./ald/man/ALD.Rd"
>[2] "./ald/man/ald-package.Rd"
>[3] "./ald/man/likALD.Rd"
>[4] "./ald/man/mleALD.Rd"
>[5] "./ald/man/momentsALD.Rd"
>attr(,"first")
>[1] 46
>
>I just ask for help to understand where those paths got inject (see my
>first mail
>for details). I'm willing to write/test the patches needed.
>
>Hope that helps to understand my idea.
>
>Best,
>Philip


From wdunlap at tibco.com  Fri Apr 21 04:09:21 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 20 Apr 2017 19:09:21 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
Message-ID: <CAF8bMca8oZjUF5uDU7bC9j9E3yZ+HGdCwhRA5UTVg7iFgt7q1g@mail.gmail.com>

Use all.equal(tolerance=0, aa, bb) to check for exact equality:

   > aa <- 100*(23/40)
   > bb <- (100*23)/40
   > all.equal(aa,bb)
   [1] TRUE
   > all.equal(aa,bb,tolerance=0)
   [1] "Mean relative difference: 1.235726e-16"
   > aa < bb
   [1] TRUE

The numbers there are rounded to 52 binary digits (16+ decimal digits) for
storage and rounding is not a linear or associative operation.  Think of
doing arithmetic by hand where you store all numbers, include intermediate
results, with only 2 significant decimal digits:
   (3 * 1) / 3 -> 3 / 3 -> 1
   3 * (1/3) -> 3 * 0.33 -> 0.99


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 20, 2017 at 2:56 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> Hello, R friends
>
> My student unearthed this quirk that might interest you.
>
> I wondered if this might be a bug in the R interpreter. If not a bug,
> it certainly stands as a good example of the dangers of floating point
> numbers in computing.
>
> What do you think?
>
> > 100*(23/40)
> [1] 57.5
> > (100*23)/40
> [1] 57.5
> > round(100*(23/40))
> [1] 57
> > round((100*23)/40)
> [1] 58
>
> The result in the 2 rounds should be the same, I think.  Clearly some
> digital number devil is at work. I *guess* that when you put in whole
> numbers and group them like this (100*23), the interpreter does
> integer math, but if you group (23/40), you force a fractional
> division and a floating point number. The results from the first 2
> calculations are not actually 57.5, they just appear that way.
>
> Before you close the books, look at this:
>
> > aa <- 100*(23/40)
> > bb <- (100*23)/40
> > all.equal(aa,bb)
> [1] TRUE
> > round(aa)
> [1] 57
> > round(bb)
> [1] 58
>
> I'm putting this one in my collection of "difficult to understand"
> numerical calculations.
>
> If you have seen this before, I'm sorry to waste your time.
>
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri Apr 21 05:08:29 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 20 Apr 2017 20:08:29 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CACdH2ZZTfnLrdKN1_hvD7H2sQbNR1vzNd47BM+=SJOVv-6MRgA@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <F7E6D18CC2877149AB5296CE54EA276643E9D4C6@WAXMXOLYMB025.WAX.wa.lcl>
 <CACdH2ZZTfnLrdKN1_hvD7H2sQbNR1vzNd47BM+=SJOVv-6MRgA@mail.gmail.com>
Message-ID: <166d3399-554e-0a9d-8450-236d563b14e5@fredhutch.org>

Also note that we see the same thing in Ruby:

   irb(main):001:0> 100*(23/40)
   => 0
   irb(main):002:0> 100.0*(23.0/40.0)
   => 57.49999999999999
   irb(main):003:0> (100.0*23.0)/40.0
   => 57.5

and in C:

   hpages at latitude:~$ cat test.c
   #include <stdio.h>
   main() {
     printf("%.15f\n", 100.0 * (23.0 / 40.0));
     printf("%.15f\n", (100.0 * 23.0) / 40.0);
   }

   hpages at latitude:~$ gcc test.c

   hpages at latitude:~$ ./a.out
   57.499999999999993
   57.500000000000000

These rounding errors are intrinsically related to how computers
do floating point arithmetic.

H.

On 04/20/2017 03:34 PM, Michael Hannon wrote:
> I might add that things that *look* like integers in R are not really
> integers, unless you explicitly label them as such:
>
>> str(20)
>  num 20
>
>> str(20.5)
>  num 20.5
>
>> str(20L)
>  int 20
>>
>
> I think that Python 2 will do integer arithmetic on things that look
> like integers:
>
> $ python2
> .
> .
> .
>>>> 30 / 20
> 1
>>>>
>
> But that behavior has changed in Python 3:
>
> $ python3
> .
> .
> .
>>>> 30 / 20
> 1.5
>>>>
>
> -- Mike
>
>
> On Thu, Apr 20, 2017 at 3:20 PM, Nordlund, Dan (DSHS/RDA)
> <NordlDJ at dshs.wa.gov> wrote:
>> This is FAQ 7.31.  It is not a bug, it is the unavoidable problem of accurately representing floating point numbers with a finite number of bits of precision.  Look at the following:
>>
>>> a <- 100*(23/40)
>>> b <- (100*23)/40
>>> print(a,digits=20)
>> [1] 57.499999999999993
>>> print(b,digits=20)
>> [1] 57.5
>>>
>>
>> Your example with all.equal evaluates TRUE because all.equal uses a 'fuzz factor'.  From the all.equal man page
>>
>> "all.equal(x, y) is a utility to compare R objects x and y testing 'near equality'."
>>
>>
>> Hope this is helpful,
>>
>> Dan
>>
>> Daniel Nordlund, PhD
>> Research and Data Analysis Division
>> Services & Enterprise Support Administration
>> Washington State Department of Social and Health Services
>>
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>>> Johnson
>>> Sent: Thursday, April 20, 2017 2:56 PM
>>> To: R-help
>>> Subject: [R] Interesting quirk with fractions and rounding
>>>
>>> Hello, R friends
>>>
>>> My student unearthed this quirk that might interest you.
>>>
>>> I wondered if this might be a bug in the R interpreter. If not a bug,
>>> it certainly stands as a good example of the dangers of floating point
>>> numbers in computing.
>>>
>>> What do you think?
>>>
>>>> 100*(23/40)
>>> [1] 57.5
>>>> (100*23)/40
>>> [1] 57.5
>>>> round(100*(23/40))
>>> [1] 57
>>>> round((100*23)/40)
>>> [1] 58
>>>
>>> The result in the 2 rounds should be the same, I think.  Clearly some
>>> digital number devil is at work. I *guess* that when you put in whole
>>> numbers and group them like this (100*23), the interpreter does
>>> integer math, but if you group (23/40), you force a fractional
>>> division and a floating point number. The results from the first 2
>>> calculations are not actually 57.5, they just appear that way.
>>>
>>> Before you close the books, look at this:
>>>
>>>> aa <- 100*(23/40)
>>>> bb <- (100*23)/40
>>>> all.equal(aa,bb)
>>> [1] TRUE
>>>> round(aa)
>>> [1] 57
>>>> round(bb)
>>> [1] 58
>>>
>>> I'm putting this one in my collection of "difficult to understand"
>>> numerical calculations.
>>>
>>> If you have seen this before, I'm sorry to waste your time.
>>>
>>> pj
>>> --
>>> Paul E. Johnson   https://urldefense.proofpoint.com/v2/url?u=http-3A__pj.freefaculty.org&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=mCvk8xBulYqnlArSRFzabdeCvvmH9UFJ0kxrxsNC0SE&e=
>>> Director, Center for Research Methods and Data Analysis
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__crmda.ku.edu&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=rtQq4X4vty_dsRAWEsD_-ZZh7UDdnlLKyBllAl3i5eY&e=
>>>
>>> To write to me directly, please address me at pauljohn at ku.edu.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=efyHNH41uiy_mo_2RYV1aQU3sMi2yKoAfK7LMdoK5eM&e=
>>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2D&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=ZmY65_nfgCDuDwZFHVL0QcFn1ttVyyj8UY4XADgtDm0&e=
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=efyHNH41uiy_mo_2RYV1aQU3sMi2yKoAfK7LMdoK5eM&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=0CaeomvoF9oO4LmfDFSjbfMQn4TufgUA-mqqIP7VFno&e=
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=efyHNH41uiy_mo_2RYV1aQU3sMi2yKoAfK7LMdoK5eM&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=h2uDuHofumYjJ48NvOaART10-esHowpTtp37cGtD3yQ&s=0CaeomvoF9oO4LmfDFSjbfMQn4TufgUA-mqqIP7VFno&e=
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From petr.pikal at precheza.cz  Fri Apr 21 07:02:13 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 21 Apr 2017 05:02:13 +0000
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>

Hi

The problem is that people using Excel or probably other such spreadsheets do not encounter this behaviour as Excel silently rounds all your calculations and makes approximate comparison without telling it does so. Therefore most people usually do not have any knowledge of floating point numbers representation.

 Cheers
Petr

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Johnson
Sent: Thursday, April 20, 2017 11:56 PM
To: R-help <r-help at r-project.org>
Subject: [R] Interesting quirk with fractions and rounding

Hello, R friends

My student unearthed this quirk that might interest you.

I wondered if this might be a bug in the R interpreter. If not a bug, it certainly stands as a good example of the dangers of floating point numbers in computing.

What do you think?

> 100*(23/40)
[1] 57.5
> (100*23)/40
[1] 57.5
> round(100*(23/40))
[1] 57
> round((100*23)/40)
[1] 58

The result in the 2 rounds should be the same, I think.  Clearly some digital number devil is at work. I *guess* that when you put in whole numbers and group them like this (100*23), the interpreter does integer math, but if you group (23/40), you force a fractional division and a floating point number. The results from the first 2 calculations are not actually 57.5, they just appear that way.

Before you close the books, look at this:

> aa <- 100*(23/40)
> bb <- (100*23)/40
> all.equal(aa,bb)
[1] TRUE
> round(aa)
[1] 57
> round(bb)
[1] 58

I'm putting this one in my collection of "difficult to understand"
numerical calculations.

If you have seen this before, I'm sorry to waste your time.

pj
--
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From br at dmstat1.com  Fri Apr 21 11:40:13 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 21 Apr 2017 05:40:13 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <4DD81ED4-7827-4BAB-98B2-CDE215108CDD@dcn.davis.ca.us>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <4DD81ED4-7827-4BAB-98B2-CDE215108CDD@dcn.davis.ca.us>
Message-ID: <5633F7D8-2149-49A1-B626-287DD60FB277@dmstat1.com>

Thanks, Jeff. 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 20, 2017, at 7:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> ReportR package


From pauljohn32 at gmail.com  Fri Apr 21 12:38:40 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 21 Apr 2017 05:38:40 -0500
Subject: [R] Prediction plots
In-Reply-To: <CAGfmZu6engkO7zmJmG0Ag8z3hUbShYL2s6Gj9Eok9SRkwO1RnQ@mail.gmail.com>
References: <CAGfmZu6engkO7zmJmG0Ag8z3hUbShYL2s6Gj9Eok9SRkwO1RnQ@mail.gmail.com>
Message-ID: <CAErODj_Rpk6jW1rssnZA=Z7ZV9QwKt7CNP63UHvftmwaKSdU+g@mail.gmail.com>

I have done this a lot. Would you mind installing my pkg rockchalk and then
run example(plotSlope) and example(plotCurve)? If the output is close to
what you want, you can adjust my code. The vignette explains.

1. Create newdata object
2. Run that through predict
3. Make plot

None of this is rocket science, but it does help students here.

PJ

On Apr 18, 2017 1:17 PM, "Santiago Bueno" <swbueno at gmail.com> wrote:

> Thanks Boris, the following is an extract of my data. I have developed
> biomass models using codes like:
>
> start <- coef (lm(log(Btot)~I(log(dbh**2*haut)),data=dat[dat$Btot>0,]))
>
> start[1] <- exp(start[1])
>
> names(start) <- c("a","b")
>
> M1 <- nls(Btot~a*(dbh**2*haut)**b,data=dat,start=start,weights=
> 1/dat$dbh**4)
>
>
> start <- coef(lm(log(Btot)~I(log(dbh))+I(log(haut)),data=dat[dat$
> Btot>0,]))
>
> start[1] <- exp(start[1])
>
> names(start) <- c("a","b1","b2")
>
> M2 <- nls(Btot~a*dbh**b1*haut**b2,data=dat,start=start,weights=
> 1/dat$dbh**4)
>
>
> Tree No dbh haut Btot
> 1 35.00 18.90 0.535
> 2 25.00 16.60 0.248
> 3 23.00 19.50 0.228
> 4 13.50 15.60 0.080
> 5 20.00 18.80 0.172
> 6 23.00 17.40 0.190
> 7 29.00 19.90 0.559
> 8 17.60 18.20 0.117
> 9 31.00 25.30 0.645
> 10 26.00 23.50 0.394
> 11 13.00 13.00 0.038
> 12 32.00 20.70 0.443
> It is my interest to get prediction plots for the models. I have tried to
> use the following codes with no success: Let m be one of the fitted models
> with dbh as the only entry. To construct a plot of the predictions made by
> this model I have tried:
> with(dat,plot(dbh,Btot,xlab="Dbh(cm)",ylab="Biomass (t)"))
> D <- seq(par("usr")[1],par("usr")[2],length=200)
> lines(D,predict(m,newdata=data.frame(dbh=D)),col="red")
> For a model m that has dbh and height as entries, I have tried to get its
> predictions as follows:
> D <- seq(0,180,length=20)
> H <- seq(0,61,length=20)
> B <- matrix(predict(m,newdata=expand.grid(dbh=D,height=H)),length(D))
>
> Can someone provide help please!!!
>
>
> Best regards,
>
> Santiago Bueno
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Fri Apr 21 13:20:50 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 21 Apr 2017 06:20:50 -0500
Subject: [R] Peformance question
In-Reply-To: <4c841014-fc27-4590-891a-9b8b1304f1cf@Spark>
References: <4c841014-fc27-4590-891a-9b8b1304f1cf@Spark>
Message-ID: <CAErODj8YX+urx=xz1+4KkMfAR_-_vvLa7CTG+tFFKVP6GUYS2g@mail.gmail.com>

I dont understand your code. But I do have suggestion. Run the functions in
the profiler, maybe differences will point at the enemy.

Know what I mean?

Rprof('check.out')
#run code
Rprof(NULL)
summaryRprof('check.out')

Do that for each method. That may be uninformative.

I wondered if you tried to compile your functions? In some cases it helps
erase differences like this. Norman Matloff has examples like that in Art
of R Programming.

I keep a list of things that are slow, if we can put finger on problem, I
will add to list. I suspect slow here is in runtime object lookup. The
environment ones have info located more quickly by the runtime, I expect.
Also, passing info back and forth from the R runtime system using [ is a
common cause of slow. It is why everybody yells 'vectorize' and 'use
lapply' all the time.  Then again, I'm guessing because I dont understand
your code:)

Good luck,
PJ


On Apr 11, 2017 7:44 PM, "Thomas Mailund" <thomas.mailund at gmail.com> wrote:

Hi y?all,

I?m working on a book on how to implement functional data structures in R,
and in particular on a chapter on implementing queues. You get get the
current version here https://www.dropbox.com/s/9c2yk3a67p1ypmr/book.pdf?dl=0
and the relevant pages are 50-59. I?ve implemented three versions of the
same idea, implementing a queue using two linked lists. One list contains
the elements you add to the end of a list, the other contains the elements
at the front of the list, and when you try to get an element from a list
and the front-list is empty you move elements from the back-list to the
front. The asymptotic analysis is explained in this figure
https://www.dropbox.com/s/tzi84zmyq16hdx0/queue-
amortized-linear-bound.png?dl=0 and all my implementations do get a linear
time complexity when I evaluate them on a linear number of operations.
However, the two implementations that uses environments seem to be almost
twice as fast as the implementation that gives me a persistent data
structure (see https://www.dropbox.com/s/i9dyab9ordkm0xj/queue-
comparisons.png?dl=0), and I cannot figure out why.

The code below contains the implementation of all three versions of the
queue plus the code I use to measure their performances. I?m sorry it is a
little long, but it is a minimal implementation of all three variants, the
comments just make it look longer than it really is.

Since the three implementations are doing basically the same things, I am a
little stumped about why the performance is so consistently different.

Can anyone shed some light on this, or help me figure out how to explore
this further?

Cheers

Thomas



## Implementations of queues ##################

#' Test if a data structure is empty
#' @param x The data structure
#' @return TRUE if x is empty.
#' @export
is_empty <- function(x) UseMethod("is_empty")

#' Add an element to a queue
#' @param x A queue
#' @param elm An element
#' @return an updated queue where the element has been added
#' @export
enqueue <- function(x, elm) UseMethod("enqueue")

#' Get the front element of a queue
#' @param x A queue
#' @return the front element of the queue
#' @export
front <- function(x) UseMethod("front")

#' Remove the front element of a queue
#' @param x The queue
#' @return The updated queue
#' @export
dequeue <- function(x) UseMethod("dequeue")

## Linked lists #########################

#' Add a head item to a linked list.
#' @param elem  The item to put at the head of the list.
#' @param lst   The list -- it will become the tail of the new list.
#' @return a new linked list.
#' @export
list_cons <- function(elem, lst)
  structure(list(head = elem, tail = lst), class = "linked_list")

list_nil <- list_cons(NA, NULL)

#' @method is_empty linked_list
#' @export
is_empty.linked_list <- function(x) identical(x, list_nil)

#' Create an empty linked list.
#' @return an empty linked list.
#' @export
empty_list <- function() list_nil


#' Get the item at the head of a linked list.
#' @param lst The list
#' @return The element at the head of the list.
#' @export
list_head <- function(lst) lst$head

#' Get the tail of a linked list.
#' @param lst The list
#' @return The tail of the list
#' @export
list_tail <- function(lst) lst$tail

#' Reverse a list
#' @param lst A list
#' @return the reverse of lst
#' @export
list_reverse <- function(lst) {
  acc <- empty_list()
  while (!is_empty(lst)) {
    acc <- list_cons(list_head(lst), acc)
    lst <- list_tail(lst)
  }
  acc
}


## Environment queues #################################################

queue_environment <- function(front, back) {
  e <- new.env(parent = emptyenv())
  e$front <- front
  e$back <- back
  class(e) <- c("env_queue", "environment")
  e
}

#' Construct an empty closure based queue
#' @return an empty queue
#' @export
empty_env_queue <- function()
  queue_environment(empty_list(), empty_list())

#' @method is_empty env_queue
#' @export
is_empty.env_queue <- function(x)
  is_empty(x$front) && is_empty(x$back)

#' @method enqueue env_queue
#' @export
enqueue.env_queue <- function(x, elm) {
  x$back <- list_cons(elm, x$back)
  x
}

#' @method front env_queue
#' @export
front.env_queue <- function(x) {
  if (is_empty(x$front)) {
    x$front <- list_reverse(x$back)
    x$back <- empty_list()
  }
  list_head(x$front)
}

#' @method dequeue env_queue
#' @export
dequeue.env_queue <- function(x) {
  if (is_empty(x$front)) {
    x$front <- list_reverse(x$back)
    x$back <- empty_list()
  }
  x$front <- list_tail(x$front)
  x
}



## Closure queues #####################################################

queue <- function(front, back)
  list(front = front, back = back)

queue_closure <- function() {
  q <- queue(empty_list(), empty_list())

  get_queue <- function() q

  queue_is_empty <- function() is_empty(q$front) && is_empty(q$back)

  enqueue <- function(elm) {
    q <<- queue(q$front, list_cons(elm, q$back))
  }

  front <- function() {
    if (queue_is_empty()) stop("Taking the front of an empty list")
    if (is_empty(q$front)) {
      q <<- queue(list_reverse(q$back), empty_list())
    }
    list_head(q$front)
  }

  dequeue <- function() {
    if (queue_is_empty()) stop("Taking the front of an empty list")
    if (is_empty(q$front)) {
      q <<- queue(list_tail(list_reverse(q$back)), empty_list())
    } else {
      q <<- queue(list_tail(q$front), q$back)
    }
  }

  structure(list(is_empty = queue_is_empty,
                 get_queue = get_queue,
                 enqueue = enqueue,
                 front = front,
                 dequeue = dequeue),
            class = "closure_queue")
}

#' Construct an empty closure based queue
#' @return an empty queue
#' @export
empty_closure_queue <- function() queue_closure()

#' @method is_empty closure_queue
#' @export
is_empty.closure_queue <- function(x) x$is_empty()

#' @method enqueue closure_queue
#' @export
enqueue.closure_queue <- function(x, elm) {
  x$enqueue(elm)
  x
}

#' @method front closure_queue
#' @export
front.closure_queue <- function(x) x$front()

#' @method dequeue closure_queue
#' @export
dequeue.closure_queue <- function(x) {
  x$dequeue()
  x
}

## Extended (purely functional) queues ################################
queue_extended <- function(x, front, back)
  structure(list(x = x, front = front, back = back),
            class = "extended_queue")


#' Construct an empty extended queue
#'
#' This is just a queue that doesn't use a closure to be able to update
#' the data structure when front is called.
#'
#' @return an empty queue
#' @export
empty_extended_queue <- function() queue_extended(NA, empty_list(),
empty_list())

#' @method is_empty extended_queue
#' @export
is_empty.extended_queue <- function(x)
  is_empty(x$front) && is_empty(x$back)

#' @method enqueue extended_queue
#' @export
enqueue.extended_queue <- function(x, elm)
  queue_extended(ifelse(is_empty(x$back), elm, x$x),
                 x$front, list_cons(elm, x$back))

#' @method front extended_queue
#' @export
front.extended_queue <- function(x) {
  if (is_empty(x)) stop("Taking the front of an empty list")
  if (is_empty(x$front)) x$x
  else list_head(x$front)
}

#' @method dequeue extended_queue
#' @export
dequeue.extended_queue <- function(x) {
  if (is_empty(x)) stop("Taking the front of an empty list")
  if (is_empty(x$front))
    x <- queue_extended(NA, list_reverse(x$back), empty_list())
  queue_extended(x$x, list_tail(x$front), x$back)
}

## Performance experiments ######################

library(microbenchmark)
library(tibble)
library(ggplot2)

get_performance_n <- function(
  algo
  , n
  , setup
  , evaluate
  , times
  , ...) {

  config <- setup(n)
  benchmarks <- microbenchmark(evaluate(n, config), times = times)
  tibble(algo = algo, n = n, time = benchmarks$time / 1e9) # time in sec
}

get_performance <- function(
  algo
  , ns
  , setup
  , evaluate
  , times = 10
  , ...) {
  f <- function(n)
    get_performance_n(algo, n, setup, evaluate, times = times, ...)
  results <- Map(f, ns)
  do.call('rbind', results)
}


setup <- function(n) n
evaluate <- function(empty) function(n, x) {
  elements <- 1:n
  queue <- empty
  for (elm in elements) {
    queue <- enqueue(queue, elm)
  }
  for (i in seq_along(elements)) {
    queue <- dequeue(queue)
  }
}

ns <- seq(5000, 10000, by = 1000)
performance <- rbind(get_performance("explicity environment", ns, setup,
evaluate(empty_env_queue())),
                     get_performance("closure environment", ns, setup,
evaluate(empty_closure_queue())),
                     get_performance("functional queue", ns, setup,
evaluate(empty_extended_queue())))

ggplot(performance, aes(x = as.factor(n), y = time / n, fill = algo)) +
  geom_boxplot() +
  scale_fill_grey("Data structure") +
  xlab(quote(n)) + ylab(expression(Time / n)) + theme_minimal()




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From gdraisma at xs4all.nl  Fri Apr 21 14:07:21 2017
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Fri, 21 Apr 2017 14:07:21 +0200
Subject: [R] Multiple Histograms in R
In-Reply-To: <mailman.3.1492768801.39296.r-help@r-project.org>
References: <mailman.3.1492768801.39296.r-help@r-project.org>
Message-ID: <c24d2bda-6483-a0af-d0cd-44c2e6f1ea74@xs4all.nl>

Prateek,
Does lattice do what you want?
HTH Gerrit

ppdat<-read.table(text="mou_mean,totalmrc_mean,rev_range,mou_range,Churn
23,24,25,27,1
45,46,47,49,1
43,44,45,47,1
45,46,47,49,0
56,57,58,60,0
67,68,69,71,1
67,68,69,71,0
44,45,46,48,1
33,34,35,37,0
90,91,92,94,1
87,88,89,91,1
76,77,78,80,1
33,34,35,37,1
44,45,46,48,1",
sep=",",header=TRUE)
library(lattice)
ppdat <- reshape(ppdat,times=names(ppdat)[1:4],
		 varying=list(names(ppdat)[1:4]),
		 direction="long",
		 timevar="Characteristic",
		 v.name="Value")
histogram(Churn~Value|Characteristic,nint=10,data=ppdat)


>  Message: 1
> Date: Thu, 20 Apr 2017 16:54:35 +0530
> From: prateek pande <prtkpande at gmail.com>
> To: Hasan Diwan <hasan.diwan at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Multiple Histograms in R
> Message-ID:
> 	<CAGAjD9nzM31+L9AwJ5x-GWUoHfTCFi9SRs-JLp7po-YH+Go-ow at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> HI Hasan,
> 
> Thanks for sharing the solution. Really appreciate it.
> 
> But i was reading somewhere that we cannot use par with ggplot 2 . we can
> only use grid extra to have multiple plots in a single view.
> 
> Is it right?
> 
> Regards
> Prateek
> Message: 2
> Date: Thu, 20 Apr 2017 12:26:47 +0000
> From: Ulrik Stervbo <ulrik.stervbo at gmail.com>
> To: prateek pande <prtkpande at gmail.com>, Hasan Diwan
> 	<hasan.diwan at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Multiple Histograms in R
> Message-ID:
> 	<CAKVAULNZvmbAO5AFmOnzYvvP8vcjgzq-3FfcCWX3eGaiPKXsog at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Hi Prateek,
> 
> maybe facet_* with ggplot is what you are looking for
> 
> HTH
> Ulrik
>


From pauljohn32 at gmail.com  Fri Apr 21 14:19:10 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 21 Apr 2017 07:19:10 -0500
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
Message-ID: <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>

We all agree it is a problem with digital computing, not unique to R. I
don't think that is the right place to stop.

What to do? The round example arose in a real funded project where 2 R
programs differed in results and cause was  that one person got 57 and
another got 58. The explanation was found, but its less clear how to
prevent similar in future. Guidelines, anyone?

So far, these are my guidelines.

1. Insert L on numbers to signal that you really mean INTEGER. In R,
forgetting the L in a single number will usually promote whole calculation
to floats.
2. S3 variables are called 'numeric' if they are integer or double storage.
So avoid "is.numeric" and prefer "is.double".
3. == is a total fail on floats
4. Run print with digits=20 so we can see the less rounded number. Perhaps
start sessions with "options(digits=20)"
5. all.equal does what it promises, but one must be cautious.

Are there math habits we should follow?

For example, Is it generally true in R that (100*x)/y is more accurate than
100*(x/y), if x > y?   (If that is generally true, couldn't the R
interpreter do it for the user?)

I've seen this problem before. In later editions of the game theory program
Gambit, extraordinary effort was taken to keep values symbolically as
integers as long as possible. Avoid division until the last steps. Same in
Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
Machine along those lines, showing accidents from trusting floats.

I wonder now if all uses of > or < with numeric variables are suspect.

Oh well. If everybody posts their advice, I will write a summary.

Paul Johnson
University of Kansas

On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

> Hi
>
> The problem is that people using Excel or probably other such spreadsheets
> do not encounter this behaviour as Excel silently rounds all your
> calculations and makes approximate comparison without telling it does so.
> Therefore most people usually do not have any knowledge of floating point
> numbers representation.
>
>  Cheers
> Petr
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Johnson
> Sent: Thursday, April 20, 2017 11:56 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] Interesting quirk with fractions and rounding
>
> Hello, R friends
>
> My student unearthed this quirk that might interest you.
>
> I wondered if this might be a bug in the R interpreter. If not a bug, it
> certainly stands as a good example of the dangers of floating point numbers
> in computing.
>
> What do you think?
>
> > 100*(23/40)
> [1] 57.5
> > (100*23)/40
> [1] 57.5
> > round(100*(23/40))
> [1] 57
> > round((100*23)/40)
> [1] 58
>
> The result in the 2 rounds should be the same, I think.  Clearly some
> digital number devil is at work. I *guess* that when you put in whole
> numbers and group them like this (100*23), the interpreter does integer
> math, but if you group (23/40), you force a fractional division and a
> floating point number. The results from the first 2 calculations are not
> actually 57.5, they just appear that way.
>
> Before you close the books, look at this:
>
> > aa <- 100*(23/40)
> > bb <- (100*23)/40
> > all.equal(aa,bb)
> [1] TRUE
> > round(aa)
> [1] 57
> > round(bb)
> [1] 58
>
> I'm putting this one in my collection of "difficult to understand"
> numerical calculations.
>
> If you have seen this before, I'm sorry to waste your time.
>
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From M.Tripoli at aifa.gov.it  Fri Apr 21 14:37:19 2017
From: M.Tripoli at aifa.gov.it (Tripoli Massimiliano)
Date: Fri, 21 Apr 2017 12:37:19 +0000
Subject: [R] Wilcoxon Test
Message-ID: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>

Dear R users,
Why the result of Wilcoxon sum rank test by R is different from sas 

https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_npar1way_sect022.htm

The code is next:

sampleA <- c(1.94, 1.94, 2.92, 2.92, 2.92, 2.92, 3.27, 3.27, 3.27, 3.27, 
        3.7, 3.7, 3.74)

sampleB <- c(3.27, 3.27, 3.27, 3.7, 3.7, 3.74)
wilcox.test(A,B,paired = F)


Thanks in advance


From Achim.Zeileis at uibk.ac.at  Fri Apr 21 14:54:39 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 21 Apr 2017 14:54:39 +0200 (CEST)
Subject: [R] Wilcoxon Test
In-Reply-To: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
References: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
Message-ID: <alpine.DEB.2.20.1704211446010.24985@paninaro>

On Fri, 21 Apr 2017, Tripoli Massimiliano wrote:

> Dear R users,
> Why the result of Wilcoxon sum rank test by R is different from sas
>
> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_npar1way_sect022.htm
>
> The code is next:
>
> sampleA <- c(1.94, 1.94, 2.92, 2.92, 2.92, 2.92, 3.27, 3.27, 3.27, 3.27,
>        3.7, 3.7, 3.74)
>
> sampleB <- c(3.27, 3.27, 3.27, 3.7, 3.7, 3.74)
> wilcox.test(A,B,paired = F)

There are different ways how to compute or approximate the asymptotic or 
exact conditional distribution of the test statistic:

SAS reports an asymptotic normal approximation (apparently without 
continuity correction along with an asymptotic t approximation and the 
exact conditional distribution.

Base R's stats::wilcox.test can either report the exact conditional 
distribution (but only if there are no ties) or the asymptotic normal 
distribution (with or without continuity correction). In small samples the 
default is to use the former but a warning is issued when there are ties 
(as in your case).

Furthermore, coin::wilcox_test can report either the asymptotic normal 
distribution (without continuity correction) or the exact conditional 
distribution (even in the presence of ties).

Thus:

## collect data in data.frame
d <- data.frame(
   y = c(sampleA, sampleB),
   x = factor(rep(0:1, c(length(sampleA), length(sampleB))))
)

## asymptotic normal distribution without continuity correction
## (p = 0.0764)
stats::wilcox.test(y ~ x, data = d, exact = FALSE, correct = FALSE)
coin::wilcox_test(y ~ x, data = d, distribution = "asymptotic")

## exact conditional distribution (p = 0.1054)
coin::wilcox_test(y ~ x, data = d, distribution = "exact")

These match SAS's results. The default result of stats::wilcox.test is 
different as explained by the warning issued.

hth,
Z


From calandra at rgzm.de  Fri Apr 21 14:58:06 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Fri, 21 Apr 2017 14:58:06 +0200
Subject: [R] Wilcoxon Test
In-Reply-To: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
References: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
Message-ID: <10158bce-cdc6-b9e3-6f73-6f39f42fc777@rgzm.de>

Try setting the 'correct' argument to FALSE (similar to CORRECT=NO 
option in the SAS documentation).

The p-values are then identical, although the W values are different.

Additionally I cannot understand why you get a warning from R that it 
cannot compute exact p-values because of ties, while the SAS 
documentation states that "Because the sample size is small, the 
large-sample normal approximation might not be adequate, and it is 
appropriate to compute the exact test."
And yet, the p-value from R is identical to the two-sided p-values with 
the normal approximation...?!

Another oddity is the legend of the SAS output, which does not 
correspond to the data in the output itself (but corresponds to the R 
values with correct=TRUE)!

Could the SAS documentation have some errors? I don't have SAS installed 
so cannot test the code.

Ivan

--
Dr. Ivan Calandra
TraCEr, Laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 21/04/2017 14:37, Tripoli Massimiliano wrote:
> Dear R users,
> Why the result of Wilcoxon sum rank test by R is different from sas
>
> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_npar1way_sect022.htm
>
> The code is next:
>
> sampleA <- c(1.94, 1.94, 2.92, 2.92, 2.92, 2.92, 3.27, 3.27, 3.27, 3.27,
>          3.7, 3.7, 3.74)
>
> sampleB <- c(3.27, 3.27, 3.27, 3.7, 3.7, 3.74)
> wilcox.test(A,B,paired = F)
>
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Fri Apr 21 15:05:40 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Apr 2017 15:05:40 +0200
Subject: [R] Wilcoxon Test
In-Reply-To: <alpine.DEB.2.20.1704211446010.24985@paninaro>
References: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
 <alpine.DEB.2.20.1704211446010.24985@paninaro>
Message-ID: <96FA4B41-FBD1-48E4-89EC-579E4CE3DE0B@gmail.com>

Also, as far as I know just for historical consistency, the test statistic in R is the rank sum of the first group MINUS its minimum possible value: W = 110.5 - sum(1:13) = 19.5

-pd

> On 21 Apr 2017, at 14:54 , Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> 
> On Fri, 21 Apr 2017, Tripoli Massimiliano wrote:
> 
>> Dear R users,
>> Why the result of Wilcoxon sum rank test by R is different from sas
>> 
>> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_npar1way_sect022.htm
>> 
>> The code is next:
>> 
>> sampleA <- c(1.94, 1.94, 2.92, 2.92, 2.92, 2.92, 3.27, 3.27, 3.27, 3.27,
>>       3.7, 3.7, 3.74)
>> 
>> sampleB <- c(3.27, 3.27, 3.27, 3.7, 3.7, 3.74)
>> wilcox.test(A,B,paired = F)
> 
> There are different ways how to compute or approximate the asymptotic or exact conditional distribution of the test statistic:
> 
> SAS reports an asymptotic normal approximation (apparently without continuity correction along with an asymptotic t approximation and the exact conditional distribution.
> 
> Base R's stats::wilcox.test can either report the exact conditional distribution (but only if there are no ties) or the asymptotic normal distribution (with or without continuity correction). In small samples the default is to use the former but a warning is issued when there are ties (as in your case).
> 
> Furthermore, coin::wilcox_test can report either the asymptotic normal distribution (without continuity correction) or the exact conditional distribution (even in the presence of ties).
> 
> Thus:
> 
> ## collect data in data.frame
> d <- data.frame(
>  y = c(sampleA, sampleB),
>  x = factor(rep(0:1, c(length(sampleA), length(sampleB))))
> )
> 
> ## asymptotic normal distribution without continuity correction
> ## (p = 0.0764)
> stats::wilcox.test(y ~ x, data = d, exact = FALSE, correct = FALSE)
> coin::wilcox_test(y ~ x, data = d, distribution = "asymptotic")
> 
> ## exact conditional distribution (p = 0.1054)
> coin::wilcox_test(y ~ x, data = d, distribution = "exact")
> 
> These match SAS's results. The default result of stats::wilcox.test is different as explained by the warning issued.
> 
> hth,
> Z
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Achim.Zeileis at uibk.ac.at  Fri Apr 21 15:26:39 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 21 Apr 2017 15:26:39 +0200 (CEST)
Subject: [R] Wilcoxon Test
In-Reply-To: <96FA4B41-FBD1-48E4-89EC-579E4CE3DE0B@gmail.com>
References: <876CEB8A3E7326488D0125D8D973B5DC2CFC6B57@SRVMBX02.aifa.lan>
 <alpine.DEB.2.20.1704211446010.24985@paninaro>
 <96FA4B41-FBD1-48E4-89EC-579E4CE3DE0B@gmail.com>
Message-ID: <alpine.DEB.2.20.1704211524100.24985@paninaro>

On Fri, 21 Apr 2017, peter dalgaard wrote:

> Also, as far as I know just for historical consistency, the test 
> statistic in R is the rank sum of the first group MINUS its minimum 
> possible value: W = 110.5 - sum(1:13) = 19.5

Ah, yes, I meant to add that remark. And coin::wilcox_test always computes 
a standardized test statistic as opposed to the (adjusted) rank sum. But 
these are all "simple" transformations of the test statistic and hence do 
not influence the p-values.

See also the "Note" in ?wilcox.test on the difference between so-called 
Wilcoxon and Mann-Whitney statistics.

>> On 21 Apr 2017, at 14:54 , Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>>
>> On Fri, 21 Apr 2017, Tripoli Massimiliano wrote:
>>
>>> Dear R users,
>>> Why the result of Wilcoxon sum rank test by R is different from sas
>>>
>>> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_npar1way_sect022.htm
>>>
>>> The code is next:
>>>
>>> sampleA <- c(1.94, 1.94, 2.92, 2.92, 2.92, 2.92, 3.27, 3.27, 3.27, 3.27,
>>>       3.7, 3.7, 3.74)
>>>
>>> sampleB <- c(3.27, 3.27, 3.27, 3.7, 3.7, 3.74)
>>> wilcox.test(A,B,paired = F)
>>
>> There are different ways how to compute or approximate the asymptotic or exact conditional distribution of the test statistic:
>>
>> SAS reports an asymptotic normal approximation (apparently without continuity correction along with an asymptotic t approximation and the exact conditional distribution.
>>
>> Base R's stats::wilcox.test can either report the exact conditional distribution (but only if there are no ties) or the asymptotic normal distribution (with or without continuity correction). In small samples the default is to use the former but a warning is issued when there are ties (as in your case).
>>
>> Furthermore, coin::wilcox_test can report either the asymptotic normal distribution (without continuity correction) or the exact conditional distribution (even in the presence of ties).
>>
>> Thus:
>>
>> ## collect data in data.frame
>> d <- data.frame(
>>  y = c(sampleA, sampleB),
>>  x = factor(rep(0:1, c(length(sampleA), length(sampleB))))
>> )
>>
>> ## asymptotic normal distribution without continuity correction
>> ## (p = 0.0764)
>> stats::wilcox.test(y ~ x, data = d, exact = FALSE, correct = FALSE)
>> coin::wilcox_test(y ~ x, data = d, distribution = "asymptotic")
>>
>> ## exact conditional distribution (p = 0.1054)
>> coin::wilcox_test(y ~ x, data = d, distribution = "exact")
>>
>> These match SAS's results. The default result of stats::wilcox.test is different as explained by the warning issued.
>>
>> hth,
>> Z
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


From pd.mes at cbs.dk  Fri Apr 21 16:19:04 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 21 Apr 2017 14:19:04 +0000
Subject: [R] R 3.4.0 is released
Message-ID: <17812175-D135-4EA4-BE87-C4E491B49009@cbs.dk>

The build system rolled up R-3.4.0.tar.gz (codename "You Stupid Darkness") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.4.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 0c53e7275ad2057cdc60448f4a71f354
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = ea102623c183b5b8ad93306db6a4f6b6
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 71562183d75dd2080d86c42bbf733bb7
MD5 (R-latest.tar.gz) = 75083c23d507b9c16d5c6afbd7a827e7
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = 7a8c309440689143c16e8586128523e8
MD5 (R-3/R-3.4.0.tar.gz) = 75083c23d507b9c16d5c6afbd7a827e7


6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
33bd1a8295b3af3e2e8b77c870799e991ced02356df50469b2e688b3cc593ebc  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
1798e1bb08e63dca195970600b107e4d6d5a07135da5bec9bcbe16a9c0f408db  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
a10f84be31f897456a31d31690df2fdc3f21a197f28b4d04332cc85005dcd0d2  NEWS.2
288e9ed42457c47720780433b3d5c3c20983048b789291cc6a7baa11f9428b91  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
2613962d473138a6ddbd10949fff9dfa61160ce6c64b7b2808172857bdd62527  VERSION-INFO.dcf
288e9ed42457c47720780433b3d5c3c20983048b789291cc6a7baa11f9428b91  R-3/R-3.4.0.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 3.4.0:

 SIGNIFICANT USER-VISIBLE CHANGES:

   * (Unix-alike) The default methods for download.file() and url()
     now choose "libcurl" except for file:// URLs.  There will be
     small changes in the format and wording of messages, including in
     rare cases if an issue is a warning or an error.  For example,
     when HTTP re-direction occurs, some messages refer to the final
     URL rather than the specified one.

     Those who use proxies should check that their settings are
     compatible (see ?download.file: the most commonly used forms work
     for both "internal" and "libcurl").

   * table() has been amended to be more internally consistent and
     become back compatible to R <= 2.7.2 again.  Consequently,
     table(1:2, exclude = NULL) no longer contains a zero count for
     <NA>, but useNA = "always" continues to do so.

   * summary.default() no longer rounds, but its print method does
     resulting in less extraneous rounding, notably of numbers in the
     ten thousands.

   * factor(x, exclude = L) behaves more rationally when x or L are
     character vectors.  Further, exclude = <factor> now behaves as
     documented for long.

   * Arithmetic, logic (&, |) and comparison (aka 'relational', e.g.,
     <, ==) operations with arrays now behave consistently, notably
     for arrays of length zero.

     Arithmetic between length-1 arrays and longer non-arrays had
     silently dropped the array attributes and recycled.  This now
     gives a warning and will signal an error in the future, as it has
     always for logic and comparison operations in these cases (e.g.,
     compare matrix(1,1) + 2:3 and matrix(1,1) < 2:3).

   * The JIT ('Just In Time') byte-code compiler is now enabled by
     default at its level 3. This means functions will be compiled on
     first or second use and top-level loops will be compiled and then
     run.  (Thanks to Tomas Kalibera for extensive work to make this
     possible.)

     For now, the compiler will not compile code containing explicit
     calls to browser(): this is to support single stepping from the
     browser() call.

     JIT compilation can be disabled for the rest of the session using
     compiler::enableJIT(0) or by setting environment variable
     R_ENABLE_JIT to 0.

   * xtabs() works more consistently with NAs, also in its result no
     longer setting them to 0.  Further, a new logical option addNA
     allows to count NAs where appropriate.  Additionally, for the
     case sparse = TRUE, the result's dimnames are identical to the
     default case's.

   * Matrix products now consistently bypass BLAS when the inputs have
     NaN/Inf values. Performance of the check of inputs has been
     improved. Performance when BLAS is used is improved for
     matrix/vector and vector/matrix multiplication (DGEMV is now used
     instead of DGEMM).

     One can now choose from alternative matrix product
     implementations _via_ options(matprod = ).  The "internal"
     implementation is not optimized for speed but consistent in
     precision with other summations in R (using long double
     accumulators where available).  "blas" calls BLAS directly for
     best speed, but usually with undefined behavior for inputs with
     NaN/Inf.

   * factor() now uses order() to sort its levels, not sort.list().
     This makes factor() support custom vector-like objects if methods
     for the appropriate generics are defined. This change has the
     side effect of making factor() succeed on empty or length-one
     non-atomic vector(-like) types (e.g., list), where it failed
     before.

 NEW FEATURES:

   * User errors such as integrate(f, 0:1, 2) are now caught.

   * Add signature argument to debug(), debugonce(), undebug() and
     isdebugged() for more conveniently debugging S3 and S4 methods.
     (Based on a patch by Gabe Becker.)

   * Add utils::debugcall() and utils::undebugcall() for debugging the
     function that would be called by evaluating the given expression.
     When the call is to an S4 generic or standard S3 generic,
     debugcall() debugs the method that would be dispatched. A number
     of internal utilities were added to support this, most notably
     utils::isS3stdGeneric().  (Based on a patch by Gabe Becker.)

   * Add utils::strcapture(). Given a character vector and a regular
     expression containing capture expressions, strcapture() will
     extract the captured tokens into a tabular data structure,
     typically a data.frame.

   * str() and strOptions() get a new option drop.deparse.attr with
     improved but _changed_ default behaviour for expressions.  For
     expression objects x, str(x) now may remove extraneous white
     space and truncate long lines.

   * str(<looooooooong_string>) is no longer very slow; inspired by
     Mikko Korpela's proposal in PR#16527.

   * str(x)'s default method is more "accurate" and hence somewhat
     more generous in displaying character vectors; this will
     occasionally change R outputs (and need changes to some
     *.Rout(.save) files).

     For a classed integer vector such as x <- xtabs(~ c(1,9,9,9)),
     str(x) now shows both the class and "int", instead of only the
     latter.

   * isSymmetric(m) is much faster for large asymmetric matrices m
     _via_ pre-tests and a new option tol1 (with which strict back
     compatibility is possible but not the default).

   * The result of eigen() now is of class "eigen" in the default case
     when eigenvectors are computed.

   * Zero-length date and date-time objects (of classes "POSIX[cl]?t")
     now print() "recognizably".

   * xy.coords() and xyz.coords() get a new setLab option.

   * The method argument of sort.list(), order() and sort.int() gains
     an "auto" option (the default) which should behave the same as
     before when method was not supplied.

   * stopifnot(E, ..) now reports differences when E is a call to
     all.equal() and that is not true.

   * boxplot(<formula>, *) gain optional arguments drop, sep, and
     lex.order to pass to split.default() which itself gains an
     argument lex.order to pass to interaction() for more flexibility.

   * The plot() method for ppr() has enhanced default labels (xmin and
     main).

   * sample.int() gains an explicit useHash option (with a back
     compatible default).

   * identical() gains an ignore.srcref option which drops "srcref"
     and similar attributes when true (as by default).

   * diag(x, nrow = n) now preserves typeof(x), also for logical,
     integer and raw x (and as previously for complex and numeric).

   * smooth.spline() now allows direct specification of lambda, gets a
     hatvalues() method and keeps tol in the result, and optionally
     parts of the internal matrix computations.

   * addNA() is faster now, e.g. when applied twice.  (Part of
     PR#16895.)

   * New option rstandard(<lm>, type = "predicted") provides the
     "PRESS"-related leave-one-out cross-validation errors for linear
     models.

   * After seven years of deprecation, duplicated factor levels now
     produce a warning when printed and an error in levels<- instead
     of a warning.

   * Invalid factors, e.g., with duplicated levels (invalid but
     constructable) now give a warning when printed, _via_ new
     function .valid.factor().

   * sessionInfo() has been updated for Apple's change in OS naming as
     from '10.12' ('macOS Sierra' _vs_ 'OS X El Capitan').

     Its toLatex() method now includes the running component.

   * options(interrupt=) can be used to specify a default action for
     user interrupts.  For now, if this option is not set and the
     error option is set, then an unhandled user interrupt invokes the
     error option.  (This may be dropped in the future as interrupt
     conditions are not error conditions.)

   * In most cases user interrupt handlers will be called with a
     "resume" restart available.  Handlers can invoke this restart to
     resume computation. At the browser prompt the r command will
     invoke a "resume" restart if one is available. Some read
     operations cannot be resumed properly when interrupted and do not
     provide a "resume" restart.

   * Radix sort is now chosen by method = "auto" for sort.int() for
     double vectors (and hence used for sort() for unclassed double
     vectors), excluding 'long' vectors.

     sort.int(method = "radix") no longer rounds double vectors.

   * The default and data.frame methods for stack() preserve the names
     of empty elements in the levels of the ind column of the return
     value.  Set the new drop argument to TRUE for the previous
     behavior.

   * Speedup in simplify2array() and hence sapply() and mapply() (for
     the case of names and common length > 1), thanks to Suharto
     Anggono's PR#17118.

   * table(x, exclude = NULL) now sets useNA = "ifany" (instead of
     "always").  Together with the bug fixes for this case, this
     recovers more consistent behaviour compatible to older versions
     of R.  As a consequence, summary() for a logical vector no longer
     reports (zero) counts for NA when there are no NAs.

   * dump.frames() gets a new option include.GlobalEnv which allows to
     also dump the global environment, thanks to Andreas Kersting's
     proposal in PR#17116.

   * system.time() now uses message() instead of cat() when terminated
     early, such that suppressMessages() has an effect; suggested by
     Ben Bolker.

   * citation() supports inst/CITATION files from package source
     trees, with lib.loc pointing to the directory containing the
     package.

   * try() gains a new argument outFile with a default that can be
     modified _via_ options(try.outFile = .), useful notably for
     Sweave.

   * The unexported low-level functions in package parallel for
     passing serialized R objects to and from forked children now
     support long vectors on 64-bit platforms.  This removes some
     limits on higher-level functions such as mclapply() (but
     returning gigabyte results from forked processes _via_
     serialization should be avoided if at all possible).

   * Connections now print() without error even if invalid, e.g. after
     having been destroyed.

   * apropos() and find(simple.words = FALSE) no longer match object
     names starting with . which are known to be internal objects
     (such as .__S3MethodsTable__.).

   * Convenience function hasName() has been added; it is intended to
     replace the common idiom !is.null(x$name) without the usually
     unintended partial name matching.

   * strcapture() no longer fixes column names nor coerces strings to
     factors (suggested by Bill Dunlap).

   * strcapture() returns NA for non-matching values in x (suggested
     by Bill Dunlap).

   * source() gets new optional arguments, notably exprs; this is made
     use of in the new utility function withAutoprint().

   * sys.source() gets a new toplevel.env argument.  This argument is
     useful for frameworks running package tests; contributed by Tomas
     Kalibera.

   * Sys.setFileTime() and file.copy(copy.date = TRUE) will set
     timestamps with fractions of seconds on platforms/filesystems
     which support this.

   * (Windows only.) file.info() now returns file timestamps including
     fractions of seconds; it has done so on other platforms since R
     2.14.0.  (NB: some filesystems do not record modification and
     access timestamps to sub-second resolution.)

   * The license check enabled by options(checkPackageLicense = TRUE)
     is now done when the package's namespace is first loaded.

   * ppr() and supsmu() get an optional trace argument, and ppr(..,
     sm.method = ..spline) is no longer limited to sample size n <=
     2500.

   * The POSIXct method for print() gets optional tz and usetz
     arguments, thanks to a report from Jennifer S. Lyon.

   * New function check_packages_in_dir_details() in package tools for
     analyzing package-check log files to obtain check details.

   * Package tools now exports function CRAN_package_db() for
     obtaining information about current packages in the CRAN package
     repository, and several functions for obtaining the check status
     of these packages.

   * The (default) Stangle driver Rtangle allows annotate to be a
     function and gets a new drop.evalFALSE option.

   * The default method for quantile(x, prob) should now be monotone
     in prob, even in border cases, see PR#16672.

   * bug.report() now tries to extract an email address from a
     BugReports field, and if there is none, from a Contacts field.

   * The format() and print() methods for object.size() results get
     new options standard and digits; notably, standard = "IEC" and
     standard = "SI" allow more standard (but less common)
     abbreviations than the default ones, e.g. for kilobytes.  (From
     contributions by Henrik Bengtsson.)

   * If a reference class has a validity method, validObject will be
     called automatically from the default initialization method for
     reference classes.

   * tapply() gets new option default = NA allowing to change the
     previously hardcoded value.

   * read.dcf() now consistently interprets any 'whitespace' to be
     stripped to include newlines.

   * The maximum number of DLLs that can be loaded into R e.g. _via_
     dyn.load() can now be increased by setting the environment
     variable R_MAX_NUM_DLLS before starting R.

   * Assigning to an element of a vector beyond the current length now
     over-allocates by a small fraction. The new vector is marked
     internally as growable, and the true length of the new vector is
     stored in the truelength field. This makes building up a vector
     result by assigning to the next element beyond the current length
     more efficient, though pre-allocating is still preferred.  The
     implementation is subject to change and not intended to be used
     in packages at this time.

   * Loading the parallel package namespace no longer sets or changes
     the .Random.seed, even if R_PARALLEL_PORT is unset.

     NB: This can break reproducibility of output, and did for a CRAN
     package.

   * Methods "wget" and "curl" for download.file() now give an R error
     rather than a non-zero return value when the external command has
     a non-zero status.

   * Encoding name "utf8" is mapped to "UTF-8".  Many implementations
     of iconv accept "utf8", but not GNU libiconv (including the late
     2016 version 1.15).

   * sessionInfo() shows the full paths to the library or executable
     files providing the BLAS/LAPACK implementations currently in use
     (not available on Windows).

   * The binning algorithm used by bandwidth selectors bw.ucv(),
     bw.bcv() and bw.SJ() switches to a version linear in the input
     size n for n > nb/2.  (The calculations are the same, but for
     larger n/nb it is worth doing the binning in advance.)

   * There is a new option PCRE_study which controls when grep(perl =
     TRUE) and friends 'study' the compiled pattern.  Previously this
     was done for 11 or more input strings: it now defaults to 10 or
     more (but most examples need many more for the difference from
     studying to be noticeable).

   * grep(perl = TRUE) and friends can now make use of PCRE's
     Just-In-Time mechanism, for PCRE >= 8.20 on platforms where JIT
     is supported.  It is used by default whenever the pattern is
     studied (see the previous item).  (Based on a patch from Mikko
     Korpela.)

     This is controlled by a new option PCRE_use_JIT.

     Note that in general this makes little difference to the speed,
     and may take a little longer: its benefits are most evident on
     strings of thousands of characters.  As a side effect it reduces
     the chances of C stack overflow in the PCRE library on very long
     strings (millions of characters, but see next item).

     Warning: segfaults were seen using PCRE with JIT enabled on
     64-bit Sparc builds.

   * There is a new option PCRE_limit_recursion for grep(perl = TRUE)
     and friends to set a recursion limit taking into account R's
     estimate of the remaining C stack space (or 10000 if that is not
     available).  This reduces the chance of C stack overflow, but
     because it is conservative may report a non-match (with a
     warning) in examples that matched before.  By default it is
     enabled if any input string has 1000 or more bytes.  (PR#16757)

   * getGraphicsEvent() now works on X11(type = "cairo") devices.
     Thanks to Frederick Eaton (for reviving an earlier patch).

   * There is a new argument onIdle for getGraphicsEvent(), which
     allows an R function to be run whenever there are no pending
     graphics events.  This is currently only supported on X11
     devices.  Thanks to Frederick Eaton.

   * The deriv() and similar functions now can compute derivatives of
     log1p(), sinpi() and similar one-argument functions, thanks to a
     contribution by Jerry Lewis.

   * median() gains a formal ... argument, so methods with extra
     arguments can be provided.

   * strwrap() reduces indent if it is more than half width rather
     than giving an error.  (Suggested by Bill Dunlap.)

   * When the condition code in if(.) or while(.) is not of length
     one, an error instead of a warning may be triggered by setting an
     environment variable, see the help page.

   * Formatting and printing of bibliography entries (bibentry) is
     more flexible and better documented.  Apart from setting
     options(citation.bibtex.max = 99) you can also use
     print(<citation>, bibtex=TRUE) (or format(..)) to get the BibTeX
     entries in the case of more than one entry.  This also affects
     citation().  Contributions to enable style = "html+bibtex" are
     welcome.

 C-LEVEL FACILITIES:

   * Entry points R_MakeExternalPtrFn and R_ExternalPtrFn are now
     declared in header Rinternals.h to facilitate creating and
     retrieving an R external pointer from a C function pointer
     without ISO C warnings about the conversion of function pointers.

   * There was an exception for the native Solaris C++ compiler to the
     dropping (in R 3.3.0) of legacy C++ headers from headers such as
     R.h and Rmath.h - this has now been removed.  That compiler has
     strict C++98 compliance hence does not include extensions in its
     (non-legacy) C++ headers: some packages will need to request
     C++11 or replace non-C++98 calls such as lgamma: see SS1.6.4 of
     'Writing R Extensions'.

     Because it is needed by about 70 CRAN packages, headers R.h and
     Rmath.h still declare

     use namespace std;

     when included on Solaris.

   * When included from C++, the R headers now use forms such as
     std::FILE directly rather than including the line

     using std::FILE;

     C++ code including these headers might be relying on the latter.

   * Headers R_ext/BLAS.h and R_ext/Lapack.h have many improved
     declarations including const for double-precision complex
     routines. _Inter alia_ this avoids warnings when passing 'string
     literal' arguments from C++11 code.

   * Headers for Unix-only facilities R_ext/GetX11Image.h,
     R_ext/QuartzDevice.h and R_ext/eventloop.h are no longer
     installed on Windows.

   * No-longer-installed headers GraphicsBase.h, RGraphics.h,
     Rmodules/RX11.h and Rmodules/Rlapack.h which had a LGPL license
     no longer do so.

   * HAVE_UINTPTR_T is now defined where appropriate by Rconfig.h so
     that it can be included before Rinterface.h when CSTACK_DEFNS is
     defined and a C compiler (not C++) is in use.  Rinterface.h now
     includes C header stdint.h or C++11 header cstdint where needed.

   * Package tools has a new function
     package_native_routine_registration_skeleton() to assist adding
     native-symbol registration to a package.  See its help and SS5.4.1
     of 'Writing R Extensions' for how to use it.  (At the time it was
     added it successfully automated adding registration to over 90%
     of CRAN packages which lacked it.  Many of the failures were
     newly-detected bugs in the packages, e.g. 50 packages called
     entry points with varying numbers of arguments and 65 packages
     called entry points not in the package.)

 INSTALLATION on a UNIX-ALIKE:

   * readline headers (and not just the library) are required unless
     configuring with --with-readline=no.

   * configure now adds a compiler switch for C++11 code, even if the
     compiler supports C++11 by default.  (This ensures that g++ 6.x
     uses C++11 mode and not its default mode of C++14 with 'GNU
     extensions'.)

     The tests for C++11 compliance are now much more comprehensive.
     For gcc < 4.8, the tests from R 3.3.0 are used in order to
     maintain the same behaviour on Linux distributions with long-term
     support.

   * An alternative compiler for C++11 is now specified with CXX11,
     not CXX1X. Likewise C++11 flags are specified with CXX11FLAGS and
     the standard (e.g., -std=gnu++11 is specified with CXX11STD.

   * configure now tests for a C++14-compliant compiler by testing
     some basic features.  This by default tries flags for the
     compiler specified by CXX11, but an alternative compiler, options
     and standard can be specified by variables CXX14, CXX14FLAGS and
     CXX14STD (e.g., -std=gnu++14).

   * There is a new macro CXXSTD to help specify the standard for C++
     code, e.g. -std=c++98.  This makes it easier to work with
     compilers which default to a later standard: for example, with
     CXX=g++6 CXXSTD=-std=c++98 configure will select commands for g++
     6.x which conform to C++11 and C++14 where specified but
     otherwise use C++98.

   * Support for the defunct IRIX and OSF/1 OSes and Alpha CPU has
     been removed.

   * configure checks that the compiler specified by $CXX $CXXFLAGS is
     able to compile C++ code.

   * configure checks for the required header sys/select.h (or
     sys/time.h on legacy systems) and system call select and aborts
     if they are not found.

   * If available, the POSIX 2008 system call utimensat will be used
     by Sys.setFileTime() and file.copy(copy.date = TRUE).  This may
     result in slightly more accurate file times.  (It is available on
     Linux and FreeBSD but not macOS.)

   * The minimum version requirement for libcurl has been reduced to
     7.22.0, although at least 7.28.0 is preferred and earlier
     versions are little tested.  (This is to support Debian 7
     'Wheezy' LTS and Ubuntu 'Precise' 12.04 LTS, although the latter
     is close to end-of-life.)

   * configure tests for a C++17-compliant compiler.  The tests are
     experimental and subject to change in the future.

 INCLUDED SOFTWARE:

   * (Windows only) Tcl/Tk version 8.6.4 is now included in the binary
     builds.  The tcltk*.chm help file is no longer included; please
     consult the online help at <URL: http://www.tcl.tk/man/> instead.

   * The version of LAPACK included in the sources has been updated to
     3.7.0: no new routines have been added to R.

 PACKAGE INSTALLATION:

   * There is support for compiling C++14 or C++17 code in packages on
     suitable platforms: see 'Writing R Extensions' for how to request
     this.

   * The order of flags when LinkingTo other packages has been changed
     so their include directories come earlier, before those specified
     in CPPFLAGS.  This will only have an effect if non-system include
     directories are included with -I flags in CPPFLAGS (and so not
     the default -I/usr/local/include which is treated as a system
     include directory on most platforms).

   * Packages which register native routines for .C or .Fortran need
     to be re-installed for this version (unless installed with
     R-devel SVN revision r72375 or later).

   * Make variables with names containing CXX1X are deprecated in
     favour of those using CXX11, but for the time being are still
     made available _via_ file etc/Makeconf.  Packages using them
     should be converted to the new forms and made dependent on R (>=
     3.4.0).

 UTILITIES:

   * Running R CMD check --as-cran with _R_CHECK_CRAN_INCOMING_REMOTE_
     false now skips tests that require remote access.  The remaining
     (local) tests typically run quickly compared to the remote tests.

   * R CMD build will now give priority to vignettes produced from
     files in the vignettes directory over those in the inst/doc
     directory, with a warning that the latter are being ignored.

   * R CMD config gains a --all option for printing names and values
     of all basic configure variables.

     It now knows about all the variables used for the C++98, C++11
     and C++14 standards.

   * R CMD check now checks that output files in inst/doc are newer
     than the source files in vignettes.

   * For consistency with other package subdirectories, files named
     *.r in the tests directory are now recognized as tests by R CMD
     check. (Wish of PR#17143.)

   * R CMD build and R CMD check now use the _union_ of R_LIBS and
     .libPaths().  They may not be equivalent, e.g., when the latter
     is determined by R_PROFILE.

   * R CMD build now preserves dates when it copies files in preparing
     the tarball.  (Previously on Windows it changed the dates on all
     files; on Unix, it changed some dates when installing vignettes.)

   * The new option R CMD check --no-stop-on-test-error allows running
     the remaining tests (under tests/) even if one gave an error.

   * Check customization _via_ environment variables to detect side
     effects of .Call() and .External() calls which alter their
     arguments is described in SS8 of the 'R Internals' manual.

   * R CMD check now checks any BugReports field to be non-empty and a
     suitable single URL.

   * R CMD check --as-cran now NOTEs if the package does not register
     its native routines or does not declare its intentions on
     (native) symbol search.  (This will become a WARNING in due
     course.)

 DEPRECATED AND DEFUNCT:

   * (Windows only) Function setInternet2() is defunct.

   * Installation support for readline emulations based on editline
     (aka libedit) is deprecated.

   * Use of the C/C++ macro NO_C_HEADERS is defunct and silently
     ignored.

   * unix.time(), a traditional synonym for system.time(), has been
     deprecated.

   * structure(NULL, ..) is now deprecated as you cannot set
     attributes on NULL.

   * Header Rconfig.h no longer defines SUPPORT_OPENMP; instead use
     _OPENMP (as documented for a long time).

   * (C-level Native routine registration.)  The deprecated styles
     member of the R_CMethodDef and R_FortranMethodDef structures has
     been removed.  Packages using these will need to be re-installed
     for R 3.4.0.

   * The deprecated support for PCRE versions older than 8.20 will be
     removed in R 3.4.1. (Versions 8.20-8.31 will still be accepted
     but remain deprecated.)

 BUG FIXES:

   * Getting or setting body() or formals() on non-functions for now
     signals a warning and may become an error for setting.

   * match(x, t), duplicated(x) and unique(x) work as documented for
     complex numbers with NAs or NaNs, where all those containing NA
     do match, whereas in the case of NaN's both real and imaginary
     parts must match, compatibly with how print() and format() work
     for complex numbers.

   * deparse(<complex>, options = "digits17") prints more nicely now,
     mostly thanks to a suggestion by Richie Cotton.

   * Rotated symbols in plotmath expressions are now positioned
     correctly on x11(type = "Xlib"). (PR#16948)

   * as<-() avoids an infinite loop when a virtual class is interposed
     between a subclass and an actual superclass.

   * Fix level propagation in unlist() when the list contains
     zero-length lists or factors.

   * Fix S3 dispatch on S4 objects when the methods package is not
     attached.

   * Internal S4 dispatch sets .Generic in the method frame for
     consistency with standardGeneric().  (PR#16929)

   * Fix order(x, decreasing = TRUE) when x is an integer vector
     containing MAX_INT.  Ported from a fix Matt Dowle made to
     data.table.

   * Fix caching by callNextMethod(), resolves PR#16973 and PR#16974.

   * grouping() puts NAs last, to be consistent with the default
     behavior of order().

   * Point mass limit cases: qpois(-2, 0) now gives NaN with a warning
     and qgeom(1, 1) is 0.  (PR#16972)

   * table() no longer drops an "NaN" factor level, and better obeys
     exclude = <chr>, thanks to Suharto Anggono's patch for PR#16936.
     Also, in the case of exclude = NULL and NAs, these are tabulated
     correctly (again).

     Further, table(1:2, exclude = 1, useNA = "ifany") no longer
     erroneously reports <NA> counts.

     Additionally, all cases of empty exclude are equivalent, and
     useNA is not overwritten when specified (as it was by exclude =
     NULL).

   * wilcox.test(x, conf.int=TRUE) no longer errors out in cases where
     the confidence interval is not available, such as for x = 0:2.

   * droplevels(f) now keeps <NA> levels when present.

   * In integer arithmetic, NULL is now treated as integer(0) whereas
     it was previously treated as double(0).

   * The radix sort considers NA_real_ and NaN to be equivalent in
     rank (like the other sort algorithms).

   * When index.return=TRUE is passed to sort.int(), the radix sort
     treats NAs like sort.list() does (like the other sort
     algorithms).

   * When in tabulate(bin, nbin) length(bin) is larger than the
     maximal integer, the result is now of type double and hence no
     longer silently overflows to wrong values.  (PR#17140)

   * as.character.factor() respects S4 inheritance when checking the
     type of its argument. (PR#17141)

   * The factor method for print() no longer sets the class of the
     factor to NULL, which would violate a basic constraint of an S4
     object.

   * formatC(x, flag = f) allows two new flags, and signals an error
     for invalid flags also in the case of character formatting.

   * Reading from file("stdin") now also closes the connection and
     hence no longer leaks memory when reading from a full pipe,
     thanks to G'abor Cs'ardi, see thread starting at <URL:
     https://stat.ethz.ch/pipermail/r-devel/2016-November/073360.html>.

   * Failure to create file in tempdir() for compressed pdf() graphics
     device no longer errors (then later segfaults).  There is now a
     warning instead of error and compression is turned off for the
     device.  Thanks to Alec Wysoker (PR#17191).

   * Asking for methods() on "|" returns only S3 methods. See <URL:
     https://stat.ethz.ch/pipermail/r-devel/2016-December/073476.html>.

   * dev.capture() using Quartz Cocoa device (macOS) returned invalid
     components if the back-end chose to use ARGB instead of RGBA
     image format. (Reported by Noam Ross.)

   * seq("2", "5") now works too, equivalently to "2":"5" and
     seq.int().

   * seq.int(to = 1, by = 1) is now correct, other cases are integer
     (instead of double) when seq() is integer too, and the
     "non-finite" error messages are consistent between seq.default()
     and seq.int(), no longer mentioning NaN etc.

   * rep(x, times) and rep.int(x, times) now work when times is larger
     than the largest value representable in an integer vector.
     (PR#16932)

   * download.file(method = "libcurl") does not check for URL
     existence before attempting downloads; this is more robust to
     servers that do not support HEAD or range-based retrieval, but
     may create empty or incomplete files for aborted download
     requests.

   * Bandwidth selectors bw.ucv(), bw.bcv() and bw.SJ() now avoid
     integer overflow for large sample sizes.

   * str() no longer shows "list output truncated", in cases that list
     was not shown at all.  Thanks to Neal Fultz (PR#17219)

   * Fix for cairo_pdf() (and svg() and cairo_ps()) when replaying a
     saved display list that contains a mix of grid and graphics
     output.  (Report by Yihui Xie.)

   * The str() and as.hclust() methods for "dendrogram" now also work
     for deeply nested dendrograms thanks to non-recursive
     implementations by Bradley Broom.

   * sample() now uses two uniforms for added precision when the
     uniform generator is Knuth-TAOCP, Knuth-TAOCP-2002, or a
     user-defined generator and the population size is 2^25 or
     greater.

   * If a vignette in the vignettes directory is listed in
     .Rbuildignore, R CMD build would not include it in the tarball,
     but would include it in the vignette database, leading to a check
     warning.  (PR#17246)

   * tools::latexToUtf8() infinite looped on certain inputs.
     (PR#17138)

   * terms.formula() ignored argument names when determining whether
     two terms were identical.  (PR#17235)

   * callNextMethod() was broken when called from a method that
     augments the formal arguments of a primitive generic.

   * Coercion of an S4 object to a vector during sub-assignment into a
     vector failed to dispatch through the as.vector() generic (often
     leading to a segfault).

   * Fix problems in command completion: Crash (PR#17222) and junk
     display in Windows, handling special characters in filenames on
     all systems.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com











-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From dcarlson at tamu.edu  Fri Apr 21 16:56:36 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 21 Apr 2017 14:56:36 +0000
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
Message-ID: <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>

You can rename the columns with colnames() before passing it to xtable. This will let you use characters that data.frame would automatically convert. 

I don't see an easy way to center the columns when printing an html file. If you are not making too many of these, you could open the .html file into a WYSIWIG html editor such as BlueGriffon, make the changes and save the file. If you have Microsoft Excel and Word, another fallback solution is to read the .html file into Excel where you have a wide variety of styles.

David C

-----Original Message-----
From: BR_email [mailto:br at dmstat1.com] 
Sent: Thursday, April 20, 2017 4:31 PM
To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
Subject: Re: [R] Looking for a package to replace xtable

David:
All is perfect, almost - after I ran your corrections.
Is there a way I can have more control of the column names, i.e.,
not be restricted to abbreviations headings, and center-justify?

Thanks a lot, nice.
Bruce

  

David L Carlson wrote:
> #1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():
>
> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)
>
> #2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:
>
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>
> total_line<-cbind(DECILE="Total",
>    as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))
>
> Now the table should print without totals in the last three columns and no rownames.
>
> attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:
>
> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>
> This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>
> Cum_RespRate          <- cum_R/cum_n)*100
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Thursday, April 20, 2017 12:10 PM
> To: r-help at r-project.org
> Subject: [R] Looking for a package to replace xtable
>
> R-helper:
> Below, code for generating a decile table.
> I am using the xtable package, but it is not quite right for the output.
> Issue #1. xtable inserts an unwanted column, before the first derived
> column DECILE
> Issue #2. In the last line "Total" I manually sum all columns, even
> though I only want the sums for second and third columns.
> If I calculate only second and third columns, the remaining columns
> would have NAs.
> Either scenario is not desired.
>
> Any suggestions, would be appreciated, for a package that addresses
> issue #1,
> and has an option for summing the desired two columns.
>
> Lastly, I read that one should rarely use "attach()", but if I don't the
> program will not run.
> An explanation of why I need attach() would also be appreciated.
> Thanks.
> Bruce
>
>    ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>
> Response[[2]] <- NULL
>
> cum_R    <- cumsum(Response)
> sam_size <- nrow(Response)
>
> cum_n    <- seq(1:1,sam_size)
> wt       <- rep(c(1), times=sam_size)
> cum_wt   <- cumsum(wt)
>
> dec      <- (cum_n/sam_size)
> decc     <- floor((cum_n*10)/(sam_size+1))
>
> dec_mean <- aggregate(Response, by=list(decc), mean)
>
> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
> dd  <- cbind(Response, dd_)
> names(dd)[2] <- "cum_R"
>
> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>
> wt         <- rep(c(1), times=sam_size)
> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>
> dec_mean_wt    <- cbind(dec_mean, cum_wt)
> dec_mean_wt    <- dec_mean_wt[-3]
>
> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>
> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>       "No_Resp")
>
> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>
> cum_n        <- dec_mean_wt_R[2]
> cum_n        <- cumsum(cum_n)
>
> cum_R        <- dec_mean_wt_R[3]
> cum_R        <- cumsum(cum_R)
>
> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>
> colnames(dec_mean_wt_R_nR) <-
>       c("Decile", "No_Inds", "No_Resp", "RespRate",
>                   "Cum_n", "Cum_R")
>
> dec_mean_wt_R_nR
>
> attach(dec_mean_wt_R_nR)
> Cum_RespRate          <- (Cum_R/Cum_n)*100
>
> options(digits=4)
> Decile_RespRate          <- (No_Resp/No_Inds)
>
> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)
>
> avg_RR             <- dec_mean_wt_R_nRD[10,7]
> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>
> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>
> total_line<-cbind(DECILE="Total",
>    as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>
> names(total_line)<-names(dec_mean_wt_R_nRDL)
> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
> decile_table <- dec_mean_wt_R_nRDLT
> decile_table
>
> #Install the xtable package: install.packages("xtable")
> #Load the xtable package:
> library(xtable)
>
> DECILE_TABLE <-xtable(decile_table)
> DECILE_TABLE
>
> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
>
> ****
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From br at dmstat1.com  Fri Apr 21 16:58:41 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 21 Apr 2017 10:58:41 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <151953CF-DD84-4ED8-A533-4F2E3CE315C7@dmstat1.com>

David:
Got it!
Thanks, again. 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 21, 2017, at 10:56 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> You can rename the columns with colnames() before passing it to xtable. This will let you use characters that data.frame would automatically convert. 
> 
> I don't see an easy way to center the columns when printing an html file. If you are not making too many of these, you could open the .html file into a WYSIWIG html editor such as BlueGriffon, make the changes and save the file. If you have Microsoft Excel and Word, another fallback solution is to read the .html file into Excel where you have a wide variety of styles.
> 
> David C
> 
> -----Original Message-----
> From: BR_email [mailto:br at dmstat1.com] 
> Sent: Thursday, April 20, 2017 4:31 PM
> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
> Subject: Re: [R] Looking for a package to replace xtable
> 
> David:
> All is perfect, almost - after I ran your corrections.
> Is there a way I can have more control of the column names, i.e.,
> not be restricted to abbreviations headings, and center-justify?
> 
> Thanks a lot, nice.
> Bruce
> 
> 
> 
> David L Carlson wrote:
>> #1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():
>> 
>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)
>> 
>> #2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:
>> 
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>> 
>> total_line<-cbind(DECILE="Total",
>>   as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))
>> 
>> Now the table should print without totals in the last three columns and no rownames.
>> 
>> attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:
>> 
>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>> 
>> This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>> 
>> Cum_RespRate          <- cum_R/cum_n)*100
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
>> Sent: Thursday, April 20, 2017 12:10 PM
>> To: r-help at r-project.org
>> Subject: [R] Looking for a package to replace xtable
>> 
>> R-helper:
>> Below, code for generating a decile table.
>> I am using the xtable package, but it is not quite right for the output.
>> Issue #1. xtable inserts an unwanted column, before the first derived
>> column DECILE
>> Issue #2. In the last line "Total" I manually sum all columns, even
>> though I only want the sums for second and third columns.
>> If I calculate only second and third columns, the remaining columns
>> would have NAs.
>> Either scenario is not desired.
>> 
>> Any suggestions, would be appreciated, for a package that addresses
>> issue #1,
>> and has an option for summing the desired two columns.
>> 
>> Lastly, I read that one should rarely use "attach()", but if I don't the
>> program will not run.
>> An explanation of why I need attach() would also be appreciated.
>> Thanks.
>> Bruce
>> 
>>   ****
>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>> 
>> Response[[2]] <- NULL
>> 
>> cum_R    <- cumsum(Response)
>> sam_size <- nrow(Response)
>> 
>> cum_n    <- seq(1:1,sam_size)
>> wt       <- rep(c(1), times=sam_size)
>> cum_wt   <- cumsum(wt)
>> 
>> dec      <- (cum_n/sam_size)
>> decc     <- floor((cum_n*10)/(sam_size+1))
>> 
>> dec_mean <- aggregate(Response, by=list(decc), mean)
>> 
>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>> dd  <- cbind(Response, dd_)
>> names(dd)[2] <- "cum_R"
>> 
>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>> 
>> wt         <- rep(c(1), times=sam_size)
>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>> 
>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>> dec_mean_wt    <- dec_mean_wt[-3]
>> 
>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>> 
>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>      "No_Resp")
>> 
>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>> 
>> cum_n        <- dec_mean_wt_R[2]
>> cum_n        <- cumsum(cum_n)
>> 
>> cum_R        <- dec_mean_wt_R[3]
>> cum_R        <- cumsum(cum_R)
>> 
>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>> 
>> colnames(dec_mean_wt_R_nR) <-
>>      c("Decile", "No_Inds", "No_Resp", "RespRate",
>>                  "Cum_n", "Cum_R")
>> 
>> dec_mean_wt_R_nR
>> 
>> attach(dec_mean_wt_R_nR)
>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>> 
>> options(digits=4)
>> Decile_RespRate          <- (No_Resp/No_Inds)
>> 
>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)
>> 
>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>> 
>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>> 
>> total_line<-cbind(DECILE="Total",
>>   as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>> 
>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>> decile_table <- dec_mean_wt_R_nRDLT
>> decile_table
>> 
>> #Install the xtable package: install.packages("xtable")
>> #Load the xtable package:
>> library(xtable)
>> 
>> DECILE_TABLE <-xtable(decile_table)
>> DECILE_TABLE
>> 
>> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
>> 
>> ****
>> 
>> --
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 


From bgunter.4567 at gmail.com  Fri Apr 21 16:59:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 21 Apr 2017 07:59:18 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
Message-ID: <CAGxFJbT74rB=etthL+z7o63OK28Oit_Gg0bQvwUhJcwAcEE0Ww@mail.gmail.com>

I suggest you read some basic books on numerical analysis and/or talk
with a numerical analyst. You are (like most of us) an amateur at this
sort of thing trying to reinvent wheels. If you are concerned with
details, talk with experts. Don't assume what you don't know. This
list is *not* a reliable source of such expertise, although there
*are* individuals in the R universe with considerable knowledge who
may or may not choose to respond.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 21, 2017 at 5:19 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> We all agree it is a problem with digital computing, not unique to R. I
> don't think that is the right place to stop.
>
> What to do? The round example arose in a real funded project where 2 R
> programs differed in results and cause was  that one person got 57 and
> another got 58. The explanation was found, but its less clear how to
> prevent similar in future. Guidelines, anyone?
>
> So far, these are my guidelines.
>
> 1. Insert L on numbers to signal that you really mean INTEGER. In R,
> forgetting the L in a single number will usually promote whole calculation
> to floats.
> 2. S3 variables are called 'numeric' if they are integer or double storage.
> So avoid "is.numeric" and prefer "is.double".
> 3. == is a total fail on floats
> 4. Run print with digits=20 so we can see the less rounded number. Perhaps
> start sessions with "options(digits=20)"
> 5. all.equal does what it promises, but one must be cautious.
>
> Are there math habits we should follow?
>
> For example, Is it generally true in R that (100*x)/y is more accurate than
> 100*(x/y), if x > y?   (If that is generally true, couldn't the R
> interpreter do it for the user?)
>
> I've seen this problem before. In later editions of the game theory program
> Gambit, extraordinary effort was taken to keep values symbolically as
> integers as long as possible. Avoid division until the last steps. Same in
> Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
> Machine along those lines, showing accidents from trusting floats.
>
> I wonder now if all uses of > or < with numeric variables are suspect.
>
> Oh well. If everybody posts their advice, I will write a summary.
>
> Paul Johnson
> University of Kansas
>
> On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> The problem is that people using Excel or probably other such spreadsheets
>> do not encounter this behaviour as Excel silently rounds all your
>> calculations and makes approximate comparison without telling it does so.
>> Therefore most people usually do not have any knowledge of floating point
>> numbers representation.
>>
>>  Cheers
>> Petr
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>> Johnson
>> Sent: Thursday, April 20, 2017 11:56 PM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] Interesting quirk with fractions and rounding
>>
>> Hello, R friends
>>
>> My student unearthed this quirk that might interest you.
>>
>> I wondered if this might be a bug in the R interpreter. If not a bug, it
>> certainly stands as a good example of the dangers of floating point numbers
>> in computing.
>>
>> What do you think?
>>
>> > 100*(23/40)
>> [1] 57.5
>> > (100*23)/40
>> [1] 57.5
>> > round(100*(23/40))
>> [1] 57
>> > round((100*23)/40)
>> [1] 58
>>
>> The result in the 2 rounds should be the same, I think.  Clearly some
>> digital number devil is at work. I *guess* that when you put in whole
>> numbers and group them like this (100*23), the interpreter does integer
>> math, but if you group (23/40), you force a fractional division and a
>> floating point number. The results from the first 2 calculations are not
>> actually 57.5, they just appear that way.
>>
>> Before you close the books, look at this:
>>
>> > aa <- 100*(23/40)
>> > bb <- (100*23)/40
>> > all.equal(aa,bb)
>> [1] TRUE
>> > round(aa)
>> [1] 57
>> > round(bb)
>> [1] 58
>>
>> I'm putting this one in my collection of "difficult to understand"
>> numerical calculations.
>>
>> If you have seen this before, I'm sorry to waste your time.
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From george.trojan at noaa.gov  Fri Apr 21 17:27:20 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Fri, 21 Apr 2017 15:27:20 +0000
Subject: [R] Wireframe plot inside a function
Message-ID: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>

Consider the following example:

library("kdecopula")
library("mvtnorm")

pobs <- function(x) rank(x) / (length(x) + 1)

n <- 1000

sigma1 <- diag(x = 1, 2, 2)
x1 <- rmvnorm(n, sigma = sigma1)
xx1 <- apply(x1, 2, pobs)
cop1 <- kdecop(xx1)

eps <- 0.8
sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
x2 <- rmvnorm(n, sigma = sigma2)
xx2 <- apply(x2, 2, pobs)
cop2 <- kdecop(xx2)

x11()
plot(cop1, main = "cop1 main")
x11()
plot(cop2, main = "cop2 main")

cplot <- function(cop1, cop2) {
  x11()
  plot(cop1, main = "cop1 function")
  x11()
  plot(cop2, main = "cop2 function")
}

cplot(cop1, cop2)

cat("Press <Enter> to quit")
readLines(file("stdin"), n
? ?
=
? ?
1)
quit()

When I run it with Rscript all four x11 windows pop up, however the one
that should display "cop1 function" is blank, the wireframe is not plotted.
This is R 3.3.1, on Fedora 20.
I see similar behaviour on Fedora 24, R 3.3.3 when I run the code from
RStudio (the most recent one).

George

	[[alternative HTML version deleted]]


From george.trojan at noaa.gov  Fri Apr 21 17:54:37 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Fri, 21 Apr 2017 15:54:37 +0000
Subject: [R] Interesting quirk with fractions and rounding
Message-ID: <CABie7_rogYiiyWV4FTSpWJ5phfvY+jb9D+sjTh9xM9vUqn=zmA@mail.gmail.com>

The subject is messy. I vaguely remember learning this stuff on my
first numerical analysis course over 40 years ago. The classic
reference material (much newer, only 25 years old) is:
What Every Computer Scientist Should Know About Floating-Point
Arithmetic, David Goldberg, ACM Computing Surveys, Vol 23, No 1, 1991.
Available here:  http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768


George

I suggest you read some basic books on numerical analysis and/or talk
> with a numerical analyst. You are (like most of us) an amateur at this
> sort of thing trying to reinvent wheels. If you are concerned with
> details, talk with experts. Don't assume what you don't know. This
> list is *not* a reliable source of such expertise, although there
> *are* individuals in the R universe with considerable knowledge who
> may or may not choose to respond.
> Cheers,
> Bert
> Bert Gunter
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



On Fri, Apr 21, 2017 at 5:19 AM, Paul Johnson <pauljohn32 at gmail.com
<https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
>* We all agree it is a problem with digital computing, not unique to R. I
*>* don't think that is the right place to stop.
*>>* What to do? The round example arose in a real funded project where 2 R
*>* programs differed in results and cause was  that one person got 57 and
*>* another got 58. The explanation was found, but its less clear how to
*>* prevent similar in future. Guidelines, anyone?
*>>* So far, these are my guidelines.
*>>* 1. Insert L on numbers to signal that you really mean INTEGER. In R,
*>* forgetting the L in a single number will usually promote whole calculation
*>* to floats.
*>* 2. S3 variables are called 'numeric' if they are integer or double storage.
*>* So avoid "is.numeric" and prefer "is.double".
*>* 3. == is a total fail on floats
*>* 4. Run print with digits=20 so we can see the less rounded number. Perhaps
*>* start sessions with "options(digits=20)"
*>* 5. all.equal does what it promises, but one must be cautious.
*>>* Are there math habits we should follow?
*>>* For example, Is it generally true in R that (100*x)/y is more accurate than
*>* 100*(x/y), if x > y?   (If that is generally true, couldn't the R
*>* interpreter do it for the user?)
*>>* I've seen this problem before. In later editions of the game theory program
*>* Gambit, extraordinary effort was taken to keep values symbolically as
*>* integers as long as possible. Avoid division until the last steps. Same in
*>* Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
*>* Machine along those lines, showing accidents from trusting floats.
*>>* I wonder now if all uses of > or < with numeric variables are suspect.
*>>* Oh well. If everybody posts their advice, I will write a summary.
*>>* Paul Johnson
*>* University of Kansas
*>>* On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz
<https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
*>>>* Hi
*>>>>* The problem is that people using Excel or probably other such
spreadsheets
*>>* do not encounter this behaviour as Excel silently rounds all your
*>>* calculations and makes approximate comparison without telling it does so.
*>>* Therefore most people usually do not have any knowledge of floating point
*>>* numbers representation.
*>>>>*  Cheers
*>>* Petr
*>>>>* -----Original Message-----
*>>* From: R-help [mailto:r-help-bounces at r-project.org
<https://stat.ethz.ch/mailman/listinfo/r-help>] On Behalf Of Paul
*>>* Johnson
*>>* Sent: Thursday, April 20, 2017 11:56 PM
*>>* To: R-help <r-help at r-project.org
<https://stat.ethz.ch/mailman/listinfo/r-help>>
*>>* Subject: [R] Interesting quirk with fractions and rounding
*>>>>* Hello, R friends
*>>>>* My student unearthed this quirk that might interest you.
*>>>>* I wondered if this might be a bug in the R interpreter. If not a bug, it
*>>* certainly stands as a good example of the dangers of floating point numbers
*>>* in computing.
*>>>>* What do you think?
*>>>>* > 100*(23/40)
*>>* [1] 57.5
*>>* > (100*23)/40
*>>* [1] 57.5
*>>* > round(100*(23/40))
*>>* [1] 57
*>>* > round((100*23)/40)
*>>* [1] 58
*>>>>* The result in the 2 rounds should be the same, I think.  Clearly some
*>>* digital number devil is at work. I *guess* that when you put in whole
*>>* numbers and group them like this (100*23), the interpreter does integer
*>>* math, but if you group (23/40), you force a fractional division and a
*>>* floating point number. The results from the first 2 calculations are not
*>>* actually 57.5, they just appear that way.
*>>>>* Before you close the books, look at this:
*>>>>* > aa <- 100*(23/40)
*>>* > bb <- (100*23)/40
*>>* > all.equal(aa,bb)
*>>* [1] TRUE
*>>* > round(aa)
*>>* [1] 57
*>>* > round(bb)
*>>* [1] 58
*>>>>* I'm putting this one in my collection of "difficult to understand"
*>>* numerical calculations.
*>>>>* If you have seen this before, I'm sorry to waste your time.
*>>>>* pj
*>>* --
*>>* Paul E. Johnson   http://pj.freefaculty.org <http://pj.freefaculty.org>
*>>* Director, Center for Research Methods and Data Analysis
*>>* http://crmda.ku.edu <http://crmda.ku.edu>
*>>>>* To write to me directly, please address me at pauljohn at
ku.edu <http://ku.edu>.
*>>>>* ______________________________________________
*>>* R-help at r-project.org
<https://stat.ethz.ch/mailman/listinfo/r-help> mailing list -- To
UNSUBSCRIBE and more, see
*>>* https://stat.ethz.ch/mailman/listinfo/r-help
<https://stat.ethz.ch/mailman/listinfo/r-help>
*>>* PLEASE do read the posting guide http://www.R-project.org/
<http://www.R-project.org/>
*>>* posting-guide.html
*>>* and provide commented, minimal, self-contained, reproducible code.
*>>>>* ________________________________
*>>* Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
*>>* ur?eny pouze jeho adres?t?m.
*>>* Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
*>>* neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
*>>* vyma?te ze sv?ho syst?mu.
*>>* Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
*>>* jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
*>>* Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
*>>* ?i zpo?d?n?m p?enosu e-mailu.
*>>>>* V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
*>>* - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
*>>* smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
*>>* - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
*>>* Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
*>>* p??jemce s dodatkem ?i odchylkou.
*>>* - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
*>>* v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
*>>* - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
*>>* spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
*>>* nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
*>>* emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
*>>* existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
*>>>>* This e-mail and any documents attached to it may be confidential and are
*>>* intended only for its intended recipients.
*>>* If you received this e-mail by mistake, please immediately inform its
*>>* sender. Delete the contents of this e-mail with all attachments and its
*>>* copies from your system.
*>>* If you are not the intended recipient of this e-mail, you are not
*>>* authorized to use, disseminate, copy or disclose this e-mail in any manner.
*>>* The sender of this e-mail shall not be liable for any possible damage
*>>* caused by modifications of the e-mail or by delay with transfer of the
*>>* email.
*>>>>* In case that this e-mail forms part of business dealings:
*>>* - the sender reserves the right to end negotiations about entering into a
*>>* contract in any time, for any reason, and without stating any reasoning.
*>>* - if the e-mail contains an offer, the recipient is entitled to
*>>* immediately accept such offer; The sender of this e-mail (offer) excludes
*>>* any acceptance of the offer on the part of the recipient containing any
*>>* amendment or variation.
*>>* - the sender insists on that the respective contract is concluded only
*>>* upon an express mutual agreement on all its aspects.
*>>* - the sender of this e-mail informs that he/she is not authorized to enter
*>>* into any contracts on behalf of the company except for cases in which
*>>* he/she is expressly authorized to do so in writing, and such authorization
*>>* or power of attorney is submitted to the recipient or the person
*>>* represented by the recipient, or the existence of such authorization is
*>>* known to the recipient of the person represented by the recipient.
*>>>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 18:17:17 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 21 Apr 2017 09:17:17 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
Message-ID: <4AE58752-4042-4BD8-A47F-71CA30C0B510@dcn.davis.ca.us>

Your guideline #1 is invalid for R... compare 5L/3L to 5L %/% 3L. If you want to avoid automatic conversion to double then you have to be cautious which operators/functions you apply to them... merely throwing in L everywhere is not going to help. 

#2 refers to S3, but that is a completely different concept. I am not sure why you think you should "prefer is.double", since is.numeric is perfectly useful for everyday analysis.

I think that numbers that represent input data can be numeric (either integer or double) but should be treated as though they were always approximate. That means don't spend time printing them out with 20 digits of precision except for illustration... just always assume that they could be slightly different than they look when printed. Which means (for example) that you have to be cautious about whether you want to ROUND or TRUNCATE when binning. If you do this you will stop feeling surprised by this kind of result. Of all groups of people who have to deal with floating point numbers, shouldn't statisticians be able to work effectively with approximate values?

Numbers that represent internally-generated indexes and factors should be created as and treated like integers. All you have to do is remember which of these two categories each numeric vector has and you will tend to avoid abusing them and being surprised by the results. 

I don't think (100*x)/y is necessarily more accurate than 100*(x/y)... they just have different approximations in some cases. Each sub-expression has the same number of bits in the mantissa, so the uncertainty propagates the same in both cases. Of more concern is things like c1+c2*x+c3*x*x versus c1+x*(c2+c3*x), but these are numerical analysis concerns for which there are whole courses to explain the issue, and are not specific to R or on-topic here. 

-- 
Sent from my phone. Please excuse my brevity.

On April 21, 2017 5:19:10 AM PDT, Paul Johnson <pauljohn32 at gmail.com> wrote:
>We all agree it is a problem with digital computing, not unique to R. I
>don't think that is the right place to stop.
>
>What to do? The round example arose in a real funded project where 2 R
>programs differed in results and cause was  that one person got 57 and
>another got 58. The explanation was found, but its less clear how to
>prevent similar in future. Guidelines, anyone?
>
>So far, these are my guidelines.
>
>1. Insert L on numbers to signal that you really mean INTEGER. In R,
>forgetting the L in a single number will usually promote whole
>calculation
>to floats.
>2. S3 variables are called 'numeric' if they are integer or double
>storage.
>So avoid "is.numeric" and prefer "is.double".
>3. == is a total fail on floats
>4. Run print with digits=20 so we can see the less rounded number.
>Perhaps
>start sessions with "options(digits=20)"
>5. all.equal does what it promises, but one must be cautious.
>
>Are there math habits we should follow?
>
>For example, Is it generally true in R that (100*x)/y is more accurate
>than
>100*(x/y), if x > y?   (If that is generally true, couldn't the R
>interpreter do it for the user?)
>
>I've seen this problem before. In later editions of the game theory
>program
>Gambit, extraordinary effort was taken to keep values symbolically as
>integers as long as possible. Avoid division until the last steps. Same
>in
>Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
>Machine along those lines, showing accidents from trusting floats.
>
>I wonder now if all uses of > or < with numeric variables are suspect.
>
>Oh well. If everybody posts their advice, I will write a summary.
>
>Paul Johnson
>University of Kansas
>
>On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> The problem is that people using Excel or probably other such
>spreadsheets
>> do not encounter this behaviour as Excel silently rounds all your
>> calculations and makes approximate comparison without telling it does
>so.
>> Therefore most people usually do not have any knowledge of floating
>point
>> numbers representation.
>>
>>  Cheers
>> Petr
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>> Johnson
>> Sent: Thursday, April 20, 2017 11:56 PM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] Interesting quirk with fractions and rounding
>>
>> Hello, R friends
>>
>> My student unearthed this quirk that might interest you.
>>
>> I wondered if this might be a bug in the R interpreter. If not a bug,
>it
>> certainly stands as a good example of the dangers of floating point
>numbers
>> in computing.
>>
>> What do you think?
>>
>> > 100*(23/40)
>> [1] 57.5
>> > (100*23)/40
>> [1] 57.5
>> > round(100*(23/40))
>> [1] 57
>> > round((100*23)/40)
>> [1] 58
>>
>> The result in the 2 rounds should be the same, I think.  Clearly some
>> digital number devil is at work. I *guess* that when you put in whole
>> numbers and group them like this (100*23), the interpreter does
>integer
>> math, but if you group (23/40), you force a fractional division and a
>> floating point number. The results from the first 2 calculations are
>not
>> actually 57.5, they just appear that way.
>>
>> Before you close the books, look at this:
>>
>> > aa <- 100*(23/40)
>> > bb <- (100*23)/40
>> > all.equal(aa,bb)
>> [1] TRUE
>> > round(aa)
>> [1] 57
>> > round(bb)
>> [1] 58
>>
>> I'm putting this one in my collection of "difficult to understand"
>> numerical calculations.
>>
>> If you have seen this before, I'm sorry to waste your time.
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and
>are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and
>its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of
>the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering
>into a
>> contract in any time, for any reason, and without stating any
>reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer)
>excludes
>> any acceptance of the offer on the part of the recipient containing
>any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded
>only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such
>authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization
>is
>> known to the recipient of the person represented by the recipient.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 18:27:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 21 Apr 2017 09:27:10 -0700
Subject: [R] Wireframe plot inside a function
In-Reply-To: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
Message-ID: <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>

FAQ 7.22
And don't send HTML email... you are the one making it difficult for us to read your question. 

-- 
Sent from my phone. Please excuse my brevity.

On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>Consider the following example:
>
>library("kdecopula")
>library("mvtnorm")
>
>pobs <- function(x) rank(x) / (length(x) + 1)
>
>n <- 1000
>
>sigma1 <- diag(x = 1, 2, 2)
>x1 <- rmvnorm(n, sigma = sigma1)
>xx1 <- apply(x1, 2, pobs)
>cop1 <- kdecop(xx1)
>
>eps <- 0.8
>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>x2 <- rmvnorm(n, sigma = sigma2)
>xx2 <- apply(x2, 2, pobs)
>cop2 <- kdecop(xx2)
>
>x11()
>plot(cop1, main = "cop1 main")
>x11()
>plot(cop2, main = "cop2 main")
>
>cplot <- function(cop1, cop2) {
>  x11()
>  plot(cop1, main = "cop1 function")
>  x11()
>  plot(cop2, main = "cop2 function")
>}
>
>cplot(cop1, cop2)
>
>cat("Press <Enter> to quit")
>readLines(file("stdin"), n
>? ?
>=
>? ?
>1)
>quit()
>
>When I run it with Rscript all four x11 windows pop up, however the one
>that should display "cop1 function" is blank, the wireframe is not
>plotted.
>This is R 3.3.1, on Fedora 20.
>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code from
>RStudio (the most recent one).
>
>George
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Fri Apr 21 18:56:01 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 21 Apr 2017 09:56:01 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
Message-ID: <1e9710c8-5293-acac-ea92-cd8d63841de2@fredhutch.org>

On 04/21/2017 05:19 AM, Paul Johnson wrote:
> We all agree it is a problem with digital computing, not unique to R. I
> don't think that is the right place to stop.
>
> What to do? The round example arose in a real funded project where 2 R
> programs differed in results and cause was  that one person got 57 and
> another got 58. The explanation was found, but its less clear how to
> prevent similar in future. Guidelines, anyone?

Note that the error is amplified by the use of round() at the end of the
calculation. Whoever wrote that code should know that by doing this the
result will possibly differ by 1 across users. So, ideally, s/he should
document this in his/her function to minimize the "surprise effect" on
the user side.

Another option is to not round() the final result and leave that
responsibility to the end user. That's what I would do.

H.

>
> So far, these are my guidelines.
>
> 1. Insert L on numbers to signal that you really mean INTEGER. In R,
> forgetting the L in a single number will usually promote whole calculation
> to floats.
> 2. S3 variables are called 'numeric' if they are integer or double storage.
> So avoid "is.numeric" and prefer "is.double".
> 3. == is a total fail on floats
> 4. Run print with digits=20 so we can see the less rounded number. Perhaps
> start sessions with "options(digits=20)"
> 5. all.equal does what it promises, but one must be cautious.
>
> Are there math habits we should follow?
>
> For example, Is it generally true in R that (100*x)/y is more accurate than
> 100*(x/y), if x > y?   (If that is generally true, couldn't the R
> interpreter do it for the user?)
>
> I've seen this problem before. In later editions of the game theory program
> Gambit, extraordinary effort was taken to keep values symbolically as
> integers as long as possible. Avoid division until the last steps. Same in
> Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
> Machine along those lines, showing accidents from trusting floats.
>
> I wonder now if all uses of > or < with numeric variables are suspect.
>
> Oh well. If everybody posts their advice, I will write a summary.
>
> Paul Johnson
> University of Kansas
>
> On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> The problem is that people using Excel or probably other such spreadsheets
>> do not encounter this behaviour as Excel silently rounds all your
>> calculations and makes approximate comparison without telling it does so.
>> Therefore most people usually do not have any knowledge of floating point
>> numbers representation.
>>
>>  Cheers
>> Petr
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>> Johnson
>> Sent: Thursday, April 20, 2017 11:56 PM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] Interesting quirk with fractions and rounding
>>
>> Hello, R friends
>>
>> My student unearthed this quirk that might interest you.
>>
>> I wondered if this might be a bug in the R interpreter. If not a bug, it
>> certainly stands as a good example of the dangers of floating point numbers
>> in computing.
>>
>> What do you think?
>>
>>> 100*(23/40)
>> [1] 57.5
>>> (100*23)/40
>> [1] 57.5
>>> round(100*(23/40))
>> [1] 57
>>> round((100*23)/40)
>> [1] 58
>>
>> The result in the 2 rounds should be the same, I think.  Clearly some
>> digital number devil is at work. I *guess* that when you put in whole
>> numbers and group them like this (100*23), the interpreter does integer
>> math, but if you group (23/40), you force a fractional division and a
>> floating point number. The results from the first 2 calculations are not
>> actually 57.5, they just appear that way.
>>
>> Before you close the books, look at this:
>>
>>> aa <- 100*(23/40)
>>> bb <- (100*23)/40
>>> all.equal(aa,bb)
>> [1] TRUE
>>> round(aa)
>> [1] 57
>>> round(bb)
>> [1] 58
>>
>> I'm putting this one in my collection of "difficult to understand"
>> numerical calculations.
>>
>> If you have seen this before, I'm sorry to waste your time.
>>
>> pj
>> --
>> Paul E. Johnson   https://urldefense.proofpoint.com/v2/url?u=http-3A__pj.freefaculty.org&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=iJyBC6GWjCxIv2vLzCBFL9KSP7jdm7aNxv00SLVJ7P0&e=
>> Director, Center for Research Methods and Data Analysis
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__crmda.ku.edu&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=enQ7hFGHB0hmVSmc-Ey3B_421i62QzFsaiN8faqRiSc&e=
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=lhpXJFzjB4p_pEFeUijjWa8Xd7IQ9ZOIzh5grUd7DQg&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=ekbaqk4VTBEMyCFXosKWt561I1fiM0OVZDw5p8spUaI&e=
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=lhpXJFzjB4p_pEFeUijjWa8Xd7IQ9ZOIzh5grUd7DQg&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=1JaAU8JTsAs-1eiwcWXgFMF6An1cjDHTSOjin674VRk&s=Gg8ShT8jT0TS19y42_4tYW23RMUgqeewiCRAW-TbXT0&e=
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From loesljrg at accucom.net  Fri Apr 21 14:48:15 2017
From: loesljrg at accucom.net (JRG)
Date: Fri, 21 Apr 2017 08:48:15 -0400
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
Message-ID: <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>

A good part of the problem in the specific case you initially presented
is that some non-integer numbers have an exact representation in the
binary floating point arithmetic being used.  Basically, if the
fractional part is of the form 1/2^k for some integer k > 0, there is an
exact representation in the binary floating point scheme.

> options(digits=20)

> (100*23)/40
[1] 57.5

> 100*(23/40)
[1] 57.499999999999992895

So the two operations give a slightly different result because the
fractional part of the division of 100*23 by 40 is 0.5.  So the first
operations gives, exactly, 57.5 while the second operation does not
because 23/40 has no exact representation.


But, change the example's divisor from 40 to 30 [the fractional part
from 1/2 to 2/3]:

> (100*23)/30
[1] 76.666666666666671404

> 100*(23/30)
[1] 76.666666666666671404

Now the two operations give the same answer to the full precision
available.  So, it isn't "generally true true in R that (100*x)/y is
more accurate than 100*(x/y), if x > y."

The key (in your example) is a property of the way that floating point
arithmetic is implemented.


---JRG



On 04/21/2017 08:19 AM, Paul Johnson wrote:
> We all agree it is a problem with digital computing, not unique to R. I
> don't think that is the right place to stop.
> 
> What to do? The round example arose in a real funded project where 2 R
> programs differed in results and cause was  that one person got 57 and
> another got 58. The explanation was found, but its less clear how to
> prevent similar in future. Guidelines, anyone?
> 
> So far, these are my guidelines.
> 
> 1. Insert L on numbers to signal that you really mean INTEGER. In R,
> forgetting the L in a single number will usually promote whole calculation
> to floats.
> 2. S3 variables are called 'numeric' if they are integer or double storage.
> So avoid "is.numeric" and prefer "is.double".
> 3. == is a total fail on floats
> 4. Run print with digits=20 so we can see the less rounded number. Perhaps
> start sessions with "options(digits=20)"
> 5. all.equal does what it promises, but one must be cautious.
> 
> Are there math habits we should follow?
> 
> For example, Is it generally true in R that (100*x)/y is more accurate than
> 100*(x/y), if x > y?   (If that is generally true, couldn't the R
> interpreter do it for the user?)
> 
> I've seen this problem before. In later editions of the game theory program
> Gambit, extraordinary effort was taken to keep values symbolically as
> integers as long as possible. Avoid division until the last steps. Same in
> Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
> Machine along those lines, showing accidents from trusting floats.
> 
> I wonder now if all uses of > or < with numeric variables are suspect.
> 
> Oh well. If everybody posts their advice, I will write a summary.
> 
> Paul Johnson
> University of Kansas
> 
> On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>>
>> The problem is that people using Excel or probably other such spreadsheets
>> do not encounter this behaviour as Excel silently rounds all your
>> calculations and makes approximate comparison without telling it does so.
>> Therefore most people usually do not have any knowledge of floating point
>> numbers representation.
>>
>>  Cheers
>> Petr
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
>> Johnson
>> Sent: Thursday, April 20, 2017 11:56 PM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] Interesting quirk with fractions and rounding
>>
>> Hello, R friends
>>
>> My student unearthed this quirk that might interest you.
>>
>> I wondered if this might be a bug in the R interpreter. If not a bug, it
>> certainly stands as a good example of the dangers of floating point numbers
>> in computing.
>>
>> What do you think?
>>
>>> 100*(23/40)
>> [1] 57.5
>>> (100*23)/40
>> [1] 57.5
>>> round(100*(23/40))
>> [1] 57
>>> round((100*23)/40)
>> [1] 58
>>
>> The result in the 2 rounds should be the same, I think.  Clearly some
>> digital number devil is at work. I *guess* that when you put in whole
>> numbers and group them like this (100*23), the interpreter does integer
>> math, but if you group (23/40), you force a fractional division and a
>> floating point number. The results from the first 2 calculations are not
>> actually 57.5, they just appear that way.
>>
>> Before you close the books, look at this:
>>
>>> aa <- 100*(23/40)
>>> bb <- (100*23)/40
>>> all.equal(aa,bb)
>> [1] TRUE
>>> round(aa)
>> [1] 57
>>> round(bb)
>> [1] 58
>>
>> I'm putting this one in my collection of "difficult to understand"
>> numerical calculations.
>>
>> If you have seen this before, I'm sorry to waste your time.
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From 814057409 at qq.com  Fri Apr 21 16:08:31 2017
From: 814057409 at qq.com (=?utf-8?B?6IuP5paH6b6Z?=)
Date: Fri, 21 Apr 2017 22:08:31 +0800
Subject: [R] =?utf-8?b?5Zue5aSN77yaUkU6ICBieSBmdW5jdGlvbiBlcnJvcg==?=
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A213DE@SRVEXCHCM301.precheza.cz>
References: <tencent_359C5A13002D902825AA36DB@qq.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A213DE@SRVEXCHCM301.precheza.cz>
Message-ID: <tencent_13E9022F6CFBAB4C4DBD2A85@qq.com>

I got it; thanks


------------------
BestRegards
  
 Su Wenlong
 Phone:13408010439


 




------------------ ???? ------------------
???: "PIKAL Petr";<petr.pikal at precheza.cz>;
????: 2017?4?21?(???) ??0:16
???: "???"<814057409 at qq.com>; "r-help"<r-help at r-project.org>; 

??: RE: [R] by function error



Hi

The problem is in your function, not in by.

> dstats(mtcars[,c('mpg', 'hp')])
Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'
In addition: Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
>

Your function expects vector but you give it data frame and it cannot handle data frames.

see

str(by(mtcars[,c('mpg', 'hp')], mtcars$am, I))
List of 2
 $ 0:Classes ?AsIs? and 'data.frame':   19 obs. of  2 variables:
  ..$ mpg: num [1:19] 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 ...
  ..$ hp : num [1:19] 110 175 105 245 62 95 123 123 180 180 ...
 $ 1:Classes ?AsIs? and 'data.frame':   13 obs. of  2 variables:
  ..$ mpg: num [1:13] 21 21 22.8 32.4 30.4 33.9 27.3 26 30.4 15.8 ...
  ..$ hp : num [1:13] 110 110 93 66 52 65 66 91 113 264 ...
 - attr(*, "dim")= int 2
 - attr(*, "dimnames")=List of 1
  ..$ mtcars$am: chr [1:2] "0" "1"
 - attr(*, "call")= language by.data.frame(data = mtcars[, c("mpg", "hp")], INDICES = mtcars$am, FUN = I)
 - attr(*, "class")= chr "by"

You maybe should consult ?aggregate.

Cheers.
Petr




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ???
Sent: Thursday, April 20, 2017 2:17 AM
To: r-help <r-help at r-project.org>
Subject: [R] by function error

hi, I practice R programing by the step in <<R In Action>>; when i test by function, i get error like these; call for help!


dstats <- function(x){c(mean=mean(x), sd=sd(x))}
> by(mtcars[,c('mpg', 'hp')], mtcars$am, dstats)
 Show Traceback

 Rerun with Debug
 Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'



------------------
BestRegards

 Su Wenlong
 Phone:13408010439
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
	[[alternative HTML version deleted]]


From bhaller at mac.com  Fri Apr 21 09:44:01 2017
From: bhaller at mac.com (Ben Haller)
Date: Fri, 21 Apr 2017 16:44:01 +0900
Subject: [R] Maximum length for a -e argument to Rscript?
Message-ID: <8D391176-D58F-402F-BA49-3DCAAAEB5014@mac.com>

  Hi!  I?m attempting to use Rscript to do some automated plotting.  It is working well, except that I seem to be running into a maximum line length issue, and I?m wondering if it is a bug on your end.  Here?s an example of the command I?m trying to run:

/usr/local/bin/Rscript -e '{x <- c(-1.31171, -0.686165, 1.62771, 0.320195, -0.322011, 1.66518, -0.271971, -0.665367, 0.516482, -0.716343, -0.317471, 0.068046, -0.100371, -1.15907, 0.263329, -0.936049, -0.852444, 0.358817, -0.233959, 0.209891, -0.831575, -0.952987, -0.0420206, -1.78527, -0.280584, -0.62353, 1.42597, 0.127994, 0.0751232, 0.896835, -0.319488, 0.897876, 0.18457, 0.779571, -0.0543194, 0.226722, -0.769983, -0.723463, 0.144386, -0.468544, -0.349417, 0.336786, 0.749212, -1.62397, 0.683075, -0.746449, 0.300921, -0.365468, 0.548271, 1.13169, -1.34042, -0.0740572, 1.34986, 0.531771, -0.147157, 0.824894, -1.05816, 1.58867, -0.885764, 1.11912, 0.361512, 1.77985, 0.585099, -1.205, 2.44134, -0.331372, -0.346322, 0.0535267, -1.75089, 0.0773243, -1.07846, -1.29632, 1.0622, 1.34867, 0.199777, 0.197516, 0.574185, 1.06555, -0.885166, -0.788576, -1.46061, -1.54026, 0.690576, -0.88821, 0.343747, -0.100751, -0.865596, -0.128504, 0.222334, -1.18932, -0.555258, -0.557368, 0.219272, 0.298858, 0.848022, 0.142608, 1.10082, -0.348039, 0.0566489, 0.662136, 0.50451, -0.909399, 1.02446, 1.40592, -0.114786, -1.10718, 2.02549, 0.0818607, -1.037, 1.18961, -0.204, 2.83165, -0.959653, -0.393082, -0.463351, 0.914054, 1.14472, -1.32927, 1.25416, 0.372267, 0.410832, 1.04187, 1.22288, 1.27131, 0.0949385, 0.194053, -0.226184, -0.502155, -1.36834, -0.000591861, -0.565903, 1.14099, 1.67811, 0.331709, -0.756879, 0.889596, 0.718098, 0.740242, -0.861818, 0.0332746, 1.01745, 0.584536, -1.14245, -0.444485, -1.34237, 0.660603, 1.16048, -0.898828, 0.965746, -1.16953, -2.33417, 0.591078, -0.364892, 0.0719267, -1.21676, 1.12646, 1.37534, 0.0712832, 1.22889, -0.0110024, 0.248213, -1.12013, -0.525197, -0.352156, -0.317182, -0.89552, 1.53422, -1.36777, 1.52099, 1.18789, -3.15251, 1.24008, -0.564289, -0.515629, -0.0920464, 2.94027, 0.895481, -0.157643, -0.347874, -0.290823, -0.771436, 1.29285, 0.216689, -1.86856, 2.24075, 0.888635, 0.430417, -0.585856, 1.13119, -0.243977, 0.544491, 0.921995, 0.815365, 1.2584, -1.29347, 0.0574579, 0.990557, -1.58657, -0.264373, 0.865893, 0.599298, -0.417531, 0.132897, 1.88597, 1.33112, -0.880904, 0.0762161, 0.0567852, 0.593295, -0.632135, 0.885625, 0.365863, -0.17885, 0.420185, -0.508275, 0.974357, 0.628085, 0.710578, 1.72447, 1.38488, 1.01301, 1.30015, 0.260501, 0.808981, 0.440228, 0.416344, -1.66273, -0.397224, -0.512086, -0.175854, -0.663143, 0.369712, -1.01654, 0.660465, 0.124851, -1.51101, -0.95725, 2.09893, 1.26819, 1.08086, 0.493204, 0.79073, 1.49191, 0.563689, 0.414473, 2.27361, 0.871923, 0.193703, -0.185039, -0.312859, -1.42267, -2.11561, 0.311996, -0.0906527, 1.19139, 1.57502, 1.10587, 0.416333, 2.35374, -1.0531, 0.0450512, 0.979958, 0.398269, 0.0897618, -0.855305, -1.59337, -0.084904, 0.245872, 1.27115, 1.3512, -0.166962, 1.01098, -1.19854, -2.05932, -0.98, 0.704973, 0.694688, 1.20408, -1.12553, 0.770056, 1.01602, 0.295223, -1.18801, 1.51707, 1.1418, -0.148787, 1.28886, 1.23981, 1.67984, 0.0185941, -0.877581, 0.495042, -0.368668, 1.59972, -2.20849, -1.36852, -0.972566, -1.01848, -0.366674, -2.60273, -0.540706, -0.475797, 0.227651, -1.11476, 1.73452, -0.212185, 3.04994, -0.251225, -0.0443482, -0.489125, 0.557936, -0.246389, -0.954287, 0.388668, 0.759049, -0.501683, -1.98722, 0.158712, -0.897082, -1.17644, 0.192465, -1.49901, -0.289129, -0.0460198, -0.520331, 0.432488, -0.471775, 1.21482, 0.998091, -0.794933, -0.36989, 0.937091, 1.27297, 1.06108, -0.784307, 0.70919, -0.309221, -0.516031, 0.479702, -0.669637, 1.60288, 0.657474, -0.666286, -1.01816, -0.452818, -0.283749, 1.05511, -1.2002, 0.112269, -1.37403, 1.00512, 0.664936, 0.600516, -1.08099, -0.705522, 0.103051, 0.0461179, 1.74404, 0.727475, 2.41175, 1.20414, 1.71095, 0.0957544, 0.610755, 0.545194, -0.936381, 0.190467, 0.485791, 0.0855697, 0.142676, 0.721754, -1.84506, 2.1227, -1.1271, -1.11228, -1.2807, 0.13385, 0.228727, -0.34391, 1.09837, -0.37053, 0.832574, 0.673463, 0.717732, -0.307687, 1.12486, 0.159803, -1.51251, 1.403, 2.0215, 0.010914, -0.543749, 0.137119, 0.200364, -0.104029, -0.930966, -1.56781, -0.526978, -0.537582, 1.11872, -0.99061, -0.501421, 1.21982, 0.813201, -0.539109, 0.433523, -0.0615188, 2.04298, 0.697692, 1.34515, 1.7298, 0.515137, 2.08119, 0.550985, 1.49876, 1.31187, 0.920405, 0.597678, 0.884353, -0.732892, -0.143545, -0.236836, -0.330872, 1.55577, -1.74473, -0.493322, 1.46375, 1.14347, 1.76164, 1.73099, -0.234701, -0.0546848, 0.346991, -0.393301, 1.34267, -1.58519, -0.381789, 0.622675, 1.34655, 2.84895, -0.371, -0.519666, -1.64944, 0.573592, 1.06484, -0.0239894, -0.604563, 0.0680641, -0.881325, 1.07265, 0.182585, 0.373288, 2.20228, -0.763593, -0.25659, 1.9397, -0.166943, -0.672522, -1.35983, 0.227406, 0.49471, -1.23535, -0.479552, 1.97798, 0.418181, 1.23454, -0.0767748, 0.828642, -0.0348468, -0.264499, 0.76699, -0.910363, -2.11408, -0.209169, 0.902191, -2.27096, 0.098513, -0.380699, -0.231276, -0.0296834, 0.834972, -0.658283, 0.616493, 0.198916, -1.89783, -1.30219, 0.51036, 0.195825, -1.68961, -1.27838, 0.879616, 0.566719, 1.21876, 0.270402, -1.38261, 0.365878, 1.54191, 1.25104, 1.23067, 1.87261);y <- c(0.986442, 2.65684, -1.79726, 1.79999, -2.43971, -1.68358, -1.84081, -2.27973, 2.96046, 2.61837, 1.48756, 1.63497, 1.46876, 2.09348, -0.925101, 3.6792, -2.03618, 1.33232, -0.0652269, 0.809911, -2.82019, -1.87691, 1.1284, 0.249619, -2.94777, 3.00423, -2.79901, -0.110801, -3.546, 1.67156, -3.10723, -3.24205, 3.16911, -3.24227, -1.29801, 0.271933, -2.83573, -0.79973, -2.34429, -0.905163, -0.197905, -3.05664, -0.694481, 1.89301, -2.70264, 2.94361, -2.32469, 1.9576, 1.73556, -3.29777, -1.54311, -2.03172, -0.871756, 0.77581, 3.7692, 1.54446, 3.92129, 0.160296, -3.45486, -1.56317, -2.72913, 0.695854, 3.15786, 1.1006, 3.25649, -1.57206, -3.15353, 0.242301, -1.95855, -0.256919, 3.04782, -0.505045, -2.35542, 2.11649, -1.73363, 2.65149, 3.66302, 0.457907, -2.2759, -2.36105, -2.49263, -2.9784, -3.53525, -0.699404, 3.17647, -1.52424, 2.72699, 3.82774, 0.100029, 3.42107, 1.74672, 3.1279, -0.793162, -0.025109, 1.07262, 2.4517, -2.00605, -3.6625, -2.57031, -2.43599, 2.56309, -1.31707, -2.10777, -3.75394, 0.954311, 0.496025, 3.82545, -3.74259, -1.96145, 0.366455, 3.97474, 3.26111, -3.69904, 2.07392, 0.591191, -3.34162, -0.926126, 1.03966, -2.68754, -2.69653, 0.651845, 2.82333, 2.25596, 3.26545, -2.57379, 2.69137, -3.08119, 2.99114, -3.86005, -1.30995, 1.80096, 1.39404, -2.6482, -2.12922, -3.28834, -1.06563, -1.6683, -2.023, 1.60516, -1.67431, 1.38595, 0.287423, 2.56888, -2.99169, 0.549401, 2.31817, -2.48251, 2.20152, 1.0531, -3.60478, 0.327999, 0.475523, -0.454324, -2.63147, -1.61249, -1.65507, 1.13203, 0.218, 2.87289, -0.279036, -0.316795, 3.22757, -2.25, -1.10923, 0.0949814, -2.60818, -0.181803, 3.65484, 2.86193, 0.940815, 3.5461, 1.23983, 2.01177, -0.428626, 3.5539, -2.63454, 1.63098, 3.69696, 0.404995, 0.480342, 3.22724, -3.57127, -2.38176, -1.23267, 0.738668, 1.64966, 1.37331, -2.60132, -1.60081, 2.57359, -3.58266, 1.32347, 3.24265, 3.81, 3.90706, -0.407994, 2.42083, 3.34477, 3.43151, -1.08974, -2.93732, 2.39014, -1.36511, -0.101514, -1.46445, 2.11849, -3.63955, -1.57038, 3.41777, -1.00185, -0.0702487, 2.01317, -3.38133, 3.64754, -0.740182, -3.64028, -3.77238, 2.45613, -3.11631, 3.82543, 2.15285, -0.790691, -1.22153, -0.943069, -3.37327, 1.19097, 1.48834, 0.502127, -2.90383, -3.4236, -0.676889, 3.41785, 2.54728, -2.60006, -3.25969, -1.85346, -2.8088, 3.3905, -1.34015, -1.3877, 2.38485, 3.16688, -3.26326, -1.94801, 0.0878641, 0.492529, 2.62313, -2.08994, -1.77721, 1.92357, 0.739532, 0.869021, -3.82981, 3.92422, -1.16293, 3.82139, -1.67119, 1.1145, -2.24382, -1.93777, -0.109559, -0.350947, 1.94832, -2.54192, 1.224, 0.797731, 0.767982, -2.93565, -2.72896, 1.2624, 1.91513, -3.96412, 3.43534, 0.358804, 3.05541, -0.213663, 0.38204, -0.539063, -0.897154, -2.91298, -0.198784, -0.0732228, 2.99983, 3.54078, 2.27245, 3.87904, 2.99445, -0.705307, 0.187173, 1.79102, 1.69581, 2.08613, 1.54021, 0.7471, -1.19008, 2.44732, -1.59312, 1.5387, -0.526756, 3.06958, -1.707, -2.46148, -0.523427, -0.675584, -3.02611, -2.22116, -3.4546, -2.94353, 2.1346, 3.51197, 1.85137, 1.7461, -0.875901, -2.13891, -2.1714, 1.6953, -0.159958, 1.77583, -0.808156, 2.04446, 3.58507, -1.27303, -0.0739294, 0.22885, -1.16883, -0.0437807, -1.30141, 2.71702, 2.85379, 3.74969, 3.5839, -0.159889, -0.236555, 2.78411, 2.15217, -0.945737, -1.90692, 0.536403, -1.08419, -3.75986, 2.65243, -2.29661, 3.8776, 1.23146, -2.26545, 2.79205, 2.34152, -3.62388, -3.51983, -0.152083, -0.77672, -0.0661756, -1.12531, 1.77691, -1.49266, -0.401453, -2.98782, 1.15182, 3.00211, -0.338523, 2.63385, -1.30166, -1.96304, -2.03665, -2.91373, 3.33512, 0.26508, -2.4008, -0.989122, -1.96516, 0.498154, -0.139963, 1.762, -0.36494, 2.42886, 1.26076, -0.344707, -2.2629, 3.01517, -0.192693, 1.72579, -3.09541, 0.898774, -3.33187, -2.09473, 2.13997, -1.20736, -1.78102, 0.661333, -2.15738, -2.82721, -0.34423, 0.945198, -1.3919, 2.24165, -1.72333, -3.61333, 0.177856, -0.499845, 1.08322, -0.57797, 1.32396, -0.580476, -0.990233, 3.13608, 0.2254, 2.44513, -1.43021, -2.20293, -0.0295935, 3.9359, 0.872028, 2.94495, 2.3334, -1.4539, -2.0155, 1.90474, -1.83284, -3.6983, -0.223583, -2.19197, 2.98892, 2.11877, -0.614374, 0.860207, 3.63726, -1.54793, 0.699044, -3.31199, -2.87789, 3.21311, -3.24507, -0.0689166, 0.225146, -2.84127, -3.67944, 0.763724, -3.93721, -3.81518, -1.06853, 0.726999, 0.562243, 3.79879, 3.75762, 2.1455, 2.00329, -0.400098, -1.80113, 3.49374, 3.26726, -1.24347, 2.0535, 2.55697, 0.670452, -2.79004, 1.39668, 2.32366, -2.27311, -0.352436, -2.71256, -2.31389, -2.11829, 0.111656, -1.67798, 2.97944, -3.7505, -1.88802, 3.50199, 1.31453, 3.32241, -1.04754, -3.03124, 1.60895, 1.15746, 2.29443, 3.31704, -0.172815, 2.81695, 0.253896, 0.298466, -3.90939, -2.39831, 3.46711, 2.41166, 2.03439, 0.387814, -3.40236, -3.71227, -1.68499, -3.81028, 2.97335, 3.32693, -3.88281, -2.61789, -3.31616, 2.71789, 3.05144, -0.579528, -0.672907, 2.75653);quartz(width=4, height=4, type="pdf", file="~/Desktop/testpdf.pdf");plot(x=x, y=y, xlim=c(-5, 5), ylim=c(-5, 5), pch=19, cex=0.5, main="2000");dev.off();}?

  If I execute the R code that is in the -e argument directly in R GUI (on OS X) it works fine.  And if I put that code in a file and run Rscript <file>, it works fine.  So the length limit is not intrinsic to R?s parser, it would seem.  But if I try to execute exactly the same code in an interactive R session in my Unix terminal's command line, I get a continuation prompt, +, and a little investigation indicates that the input line may have been truncated after 3843 characters (a strange number) and it is waiting for more input to follow that truncated input.  And ? what is most relevant for my situation ? if I try to run the full Rscript command as given above (inside /bin/sh), it prints out:

WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402

and then it hangs ? the full warning doesn?t complete printing, so it is not clear what it is trying to warn about.  That represents 844 characters of input script, but with the weird way that spaces have been replaced by ~+~ by somebody, it is 1013 characters ? suspiciously close to 1024.

  Note that if I simply make the R script shorter, by plotting 100 x/y values instead of 500, everything works fine.  So there is no issue with the way that I?m quoting strings or anything like that; the only issue seems to be the total length of the command line.

  Now of course I could break up the script into multiple chunks, passed via separate -e arguments, and perhaps that would work somewhat better.  But given that I want to set up a vector x with a single c() command containing all of the data for x, I will still hit a line length limit; the single line of code to set up x will already be over the maximum line length that Rscript allows for a -e argument, apparently.  Getting around that would obviously be possible too, but would be considerably more hassle.

  And incidentally, this seems to have nothing to do with the /bin/sh input line limit; that is much higher.  According to "getconf ARG_MAX?, it is 262144 characters on my machine, which is more than enough headroom for what I?m trying to do.

  So my questions are: (1) is this a bug, (2) if so, do you think you are likely to fix it any time soon :->, and (3) if the answer to that is no, are there any standard workarounds for this sort of situation that you would recommend?  I suppose I could write out the script to a file and then execute that file with Rscript, since that seems to work; but I was really hoping to avoid that extra complication and overhead.  Is there a better way?

  Thanks for any help you can provide!  :->

Cheers,
-B.

Benjamin C. Haller
Messer Lab
Cornell University


From thomas.mailund at gmail.com  Fri Apr 21 13:23:36 2017
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Fri, 21 Apr 2017 13:23:36 +0200
Subject: [R] Peformance question
In-Reply-To: <CAErODj8YX+urx=xz1+4KkMfAR_-_vvLa7CTG+tFFKVP6GUYS2g@mail.gmail.com>
References: <4c841014-fc27-4590-891a-9b8b1304f1cf@Spark>
 <CAErODj8YX+urx=xz1+4KkMfAR_-_vvLa7CTG+tFFKVP6GUYS2g@mail.gmail.com>
Message-ID: <170eef0c-3abd-45a7-9426-950ee942d252@Spark>

I did try to profile it but I'll throw some more experiments at it. Right now I suspect it is mostly a problem of wrapping the data in objects which I do more for the purely functional version than the other two, but I'll experiment some more

Cheers

Thomas

On 21 Apr 2017, 13.20 +0200, Paul Johnson <pauljohn32 at gmail.com>, wrote:
> I dont understand your code. But I do have suggestion. Run the functions in the profiler, maybe differences will point at the enemy.
>
> Know what I mean?
>
> Rprof('check.out')
> #run code
> Rprof(NULL)
> summaryRprof('check.out')
>
> Do that for each method. That may be uninformative.
>
> I wondered if you tried to compile your functions? In some cases it helps erase differences like this. Norman Matloff has examples like that in Art of R Programming.
>
> I keep a list of things that are slow, if we can put finger on problem, I will add to list. I suspect slow here is in runtime object lookup. The environment ones have info located more quickly by the runtime, I expect. Also, passing info back and forth from the R runtime system using [ is a common cause of slow. It is why everybody yells 'vectorize' and 'use lapply' all the time. Then again, I'm guessing because I dont understand your code:)
>
> Good luck,
> PJ
>
>
>
>
> On Apr 11, 2017 7:44 PM, "Thomas Mailund" <thomas.mailund at gmail.com (mailto:thomas.mailund at gmail.com)> wrote:
> > Hi y?all,
> >
> > I?m working on a book on how to implement functional data structures in R, and in particular on a chapter on implementing queues. You get get the current version here https://www.dropbox.com/s/9c2yk3a67p1ypmr/book.pdf?dl=0 and the relevant pages are 50-59. I?ve implemented three versions of the same idea, implementing a queue using two linked lists. One list contains the elements you add to the end of a list, the other contains the elements at the front of the list, and when you try to get an element from a list and the front-list is empty you move elements from the back-list to the front. The asymptotic analysis is explained in this figure https://www.dropbox.com/s/tzi84zmyq16hdx0/queue-amortized-linear-bound.png?dl=0 and all my implementations do get a linear time complexity when I evaluate them on a linear number of operations. However, the two implementations that uses environments seem to be almost twice as fast as the implementation that gives me a persistent data structure (see https://www.dropbox.com/s/i9dyab9ordkm0xj/queue-comparisons.png?dl=0), and I cannot figure out why.
> >
> > The code below contains the implementation of all three versions of the queue plus the code I use to measure their performances. I?m sorry it is a little long, but it is a minimal implementation of all three variants, the comments just make it look longer than it really is.
> >
> > Since the three implementations are doing basically the same things, I am a little stumped about why the performance is so consistently different.
> >
> > Can anyone shed some light on this, or help me figure out how to explore this further?
> >
> > Cheers
> >
> > Thomas
> >
> >
> >
> > ## Implementations of queues ##################
> >
> > #' Test if a data structure is empty
> > #' @param x The data structure
> > #' @return TRUE if x is empty.
> > #' @export
> > is_empty <- function(x) UseMethod("is_empty")
> >
> > #' Add an element to a queue
> > #' @param x A queue
> > #' @param elm An element
> > #' @return an updated queue where the element has been added
> > #' @export
> > enqueue <- function(x, elm) UseMethod("enqueue")
> >
> > #' Get the front element of a queue
> > #' @param x A queue
> > #' @return the front element of the queue
> > #' @export
> > front <- function(x) UseMethod("front")
> >
> > #' Remove the front element of a queue
> > #' @param x The queue
> > #' @return The updated queue
> > #' @export
> > dequeue <- function(x) UseMethod("dequeue")
> >
> > ## Linked lists #########################
> >
> > #' Add a head item to a linked list.
> > #' @param elem The item to put at the head of the list.
> > #' @param lst The list -- it will become the tail of the new list.
> > #' @return a new linked list.
> > #' @export
> > list_cons <- function(elem, lst)
> > structure(list(head = elem, tail = lst), class = "linked_list")
> >
> > list_nil <- list_cons(NA, NULL)
> >
> > #' @method is_empty linked_list
> > #' @export
> > is_empty.linked_list <- function(x) identical(x, list_nil)
> >
> > #' Create an empty linked list.
> > #' @return an empty linked list.
> > #' @export
> > empty_list <- function() list_nil
> >
> >
> > #' Get the item at the head of a linked list.
> > #' @param lst The list
> > #' @return The element at the head of the list.
> > #' @export
> > list_head <- function(lst) lst$head
> >
> > #' Get the tail of a linked list.
> > #' @param lst The list
> > #' @return The tail of the list
> > #' @export
> > list_tail <- function(lst) lst$tail
> >
> > #' Reverse a list
> > #' @param lst A list
> > #' @return the reverse of lst
> > #' @export
> > list_reverse <- function(lst) {
> > acc <- empty_list()
> > while (!is_empty(lst)) {
> > acc <- list_cons(list_head(lst), acc)
> > lst <- list_tail(lst)
> > }
> > acc
> > }
> >
> >
> > ## Environment queues #################################################
> >
> > queue_environment <- function(front, back) {
> > e <- new.env(parent = emptyenv())
> > e$front <- front
> > e$back <- back
> > class(e) <- c("env_queue", "environment")
> > e
> > }
> >
> > #' Construct an empty closure based queue
> > #' @return an empty queue
> > #' @export
> > empty_env_queue <- function()
> > queue_environment(empty_list(), empty_list())
> >
> > #' @method is_empty env_queue
> > #' @export
> > is_empty.env_queue <- function(x)
> > is_empty(x$front) && is_empty(x$back)
> >
> > #' @method enqueue env_queue
> > #' @export
> > enqueue.env_queue <- function(x, elm) {
> > x$back <- list_cons(elm, x$back)
> > x
> > }
> >
> > #' @method front env_queue
> > #' @export
> > front.env_queue <- function(x) {
> > if (is_empty(x$front)) {
> > x$front <- list_reverse(x$back)
> > x$back <- empty_list()
> > }
> > list_head(x$front)
> > }
> >
> > #' @method dequeue env_queue
> > #' @export
> > dequeue.env_queue <- function(x) {
> > if (is_empty(x$front)) {
> > x$front <- list_reverse(x$back)
> > x$back <- empty_list()
> > }
> > x$front <- list_tail(x$front)
> > x
> > }
> >
> >
> >
> > ## Closure queues #####################################################
> >
> > queue <- function(front, back)
> > list(front = front, back = back)
> >
> > queue_closure <- function() {
> > q <- queue(empty_list(), empty_list())
> >
> > get_queue <- function() q
> >
> > queue_is_empty <- function() is_empty(q$front) && is_empty(q$back)
> >
> > enqueue <- function(elm) {
> > q <<- queue(q$front, list_cons(elm, q$back))
> > }
> >
> > front <- function() {
> > if (queue_is_empty()) stop("Taking the front of an empty list")
> > if (is_empty(q$front)) {
> > q <<- queue(list_reverse(q$back), empty_list())
> > }
> > list_head(q$front)
> > }
> >
> > dequeue <- function() {
> > if (queue_is_empty()) stop("Taking the front of an empty list")
> > if (is_empty(q$front)) {
> > q <<- queue(list_tail(list_reverse(q$back)), empty_list())
> > } else {
> > q <<- queue(list_tail(q$front), q$back)
> > }
> > }
> >
> > structure(list(is_empty = queue_is_empty,
> > get_queue = get_queue,
> > enqueue = enqueue,
> > front = front,
> > dequeue = dequeue),
> > class = "closure_queue")
> > }
> >
> > #' Construct an empty closure based queue
> > #' @return an empty queue
> > #' @export
> > empty_closure_queue <- function() queue_closure()
> >
> > #' @method is_empty closure_queue
> > #' @export
> > is_empty.closure_queue <- function(x) x$is_empty()
> >
> > #' @method enqueue closure_queue
> > #' @export
> > enqueue.closure_queue <- function(x, elm) {
> > x$enqueue(elm)
> > x
> > }
> >
> > #' @method front closure_queue
> > #' @export
> > front.closure_queue <- function(x) x$front()
> >
> > #' @method dequeue closure_queue
> > #' @export
> > dequeue.closure_queue <- function(x) {
> > x$dequeue()
> > x
> > }
> >
> > ## Extended (purely functional) queues ################################
> > queue_extended <- function(x, front, back)
> > structure(list(x = x, front = front, back = back),
> > class = "extended_queue")
> >
> >
> > #' Construct an empty extended queue
> > #'
> > #' This is just a queue that doesn't use a closure to be able to update
> > #' the data structure when front is called.
> > #'
> > #' @return an empty queue
> > #' @export
> > empty_extended_queue <- function() queue_extended(NA, empty_list(), empty_list())
> >
> > #' @method is_empty extended_queue
> > #' @export
> > is_empty.extended_queue <- function(x)
> > is_empty(x$front) && is_empty(x$back)
> >
> > #' @method enqueue extended_queue
> > #' @export
> > enqueue.extended_queue <- function(x, elm)
> > queue_extended(ifelse(is_empty(x$back), elm, x$x),
> > x$front, list_cons(elm, x$back))
> >
> > #' @method front extended_queue
> > #' @export
> > front.extended_queue <- function(x) {
> > if (is_empty(x)) stop("Taking the front of an empty list")
> > if (is_empty(x$front)) x$x
> > else list_head(x$front)
> > }
> >
> > #' @method dequeue extended_queue
> > #' @export
> > dequeue.extended_queue <- function(x) {
> > if (is_empty(x)) stop("Taking the front of an empty list")
> > if (is_empty(x$front))
> > x <- queue_extended(NA, list_reverse(x$back), empty_list())
> > queue_extended(x$x, list_tail(x$front), x$back)
> > }
> >
> > ## Performance experiments ######################
> >
> > library(microbenchmark)
> > library(tibble)
> > library(ggplot2)
> >
> > get_performance_n <- function(
> > algo
> > , n
> > , setup
> > , evaluate
> > , times
> > , ...) {
> >
> > config <- setup(n)
> > benchmarks <- microbenchmark(evaluate(n, config), times = times)
> > tibble(algo = algo, n = n, time = benchmarks$time / 1e9) # time in sec
> > }
> >
> > get_performance <- function(
> > algo
> > , ns
> > , setup
> > , evaluate
> > , times = 10
> > , ...) {
> > f <- function(n)
> > get_performance_n(algo, n, setup, evaluate, times = times, ...)
> > results <- Map(f, ns)
> > do.call('rbind', results)
> > }
> >
> >
> > setup <- function(n) n
> > evaluate <- function(empty) function(n, x) {
> > elements <- 1:n
> > queue <- empty
> > for (elm in elements) {
> > queue <- enqueue(queue, elm)
> > }
> > for (i in seq_along(elements)) {
> > queue <- dequeue(queue)
> > }
> > }
> >
> > ns <- seq(5000, 10000, by = 1000)
> > performance <- rbind(get_performance("explicity environment", ns, setup, evaluate(empty_env_queue())),
> > get_performance("closure environment", ns, setup, evaluate(empty_closure_queue())),
> > get_performance("functional queue", ns, setup, evaluate(empty_extended_queue())))
> >
> > ggplot(performance, aes(x = as.factor(n), y = time / n, fill = algo)) +
> > geom_boxplot() +
> > scale_fill_grey("Data structure") +
> > xlab(quote(n)) + ylab(expression(Time / n)) + theme_minimal()
> >
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org (mailto:R-help at r-project.org) mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jacobkap at sas.upenn.edu  Fri Apr 21 15:34:36 2017
From: jacobkap at sas.upenn.edu (Jacob Kaplan)
Date: Fri, 21 Apr 2017 09:34:36 -0400
Subject: [R] [R-pkgs] New package: fastDummies
Message-ID: <CAPVd8gK5BAKqh7n1tyGVtru9kD3mYUHYQZdjqXG63E3Six40yA@mail.gmail.com>

Dear R users,

I am happy to announce that the package fastDummies is now on CRAN
(*https://cran.r-project.org/package=fastDummies
<https://cran.r-project.org/package=fastDummies>)*.

The fastDummies package lets you quickly and easily create dummy columns
from categorical variables in data.tables or data.frames. This package is
much faster than model.matrix() in handling data with greater than 1,000
rows.

Please submit all question or issues here (https://github.com/jacobkap/
fastDummies/issues)

Best,
Jacob

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From br at dmstat1.com  Fri Apr 21 19:14:29 2017
From: br at dmstat1.com (BR_email)
Date: Fri, 21 Apr 2017 13:14:29 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>

David:
Hate to bother you, but because you have seen my code perhaps
you can tell me what I am doing wrong.
I want to replicate my original Response data by 0 times, called 
ResponseX10.
All is good until the first calculation, cum_R.
Would you kindly, assist me?
Thanks.
Bruce
****
Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Response <- Response[order(Response$yhat,decreasing=TRUE),]

ResponseX10 <- do.call(rbind, replicate(10, Response, simplify=FALSE))

ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]

ResponseX10[[2]] <- NULL
ResponseX10

cum_R    <- cumsum(Response)
cum_R
*******

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

David L Carlson wrote:
> You can rename the columns with colnames() before passing it to xtable. This will let you use characters that data.frame would automatically convert.
>
> I don't see an easy way to center the columns when printing an html file. If you are not making too many of these, you could open the .html file into a WYSIWIG html editor such as BlueGriffon, make the changes and save the file. If you have Microsoft Excel and Word, another fallback solution is to read the .html file into Excel where you have a wide variety of styles.
>
> David C
>
> -----Original Message-----
> From: BR_email [mailto:br at dmstat1.com]
> Sent: Thursday, April 20, 2017 4:31 PM
> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
> Subject: Re: [R] Looking for a package to replace xtable
>
> David:
> All is perfect, almost - after I ran your corrections.
> Is there a way I can have more control of the column names, i.e.,
> not be restricted to abbreviations headings, and center-justify?
>
> Thanks a lot, nice.
> Bruce
>
>    
>
> David L Carlson wrote:
>> #1 You can remove the rownames by adding the argument include.rownames=FALSE to print.xtable():
>>
>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", include.rownames=FALSE)
>>
>> #2 Prevent data.frame from converting the first column to a factor and use NAs for the columns where you don't want totals:
>>
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>
>> total_line<-cbind(DECILE="Total",
>>     as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1)))
>>
>> Now the table should print without totals in the last three columns and no rownames.
>>
>> attach is discouraged since it can lead to confusion when a variable name exists in the environment and in a data frame (or multiple data frames). It is easy to forget which version of the variable you are using. More typing, but less subject to confusion would be to use with(), eg:
>>
>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>>
>> This way it is always clear where Cum_R and Cum_n are coming from. In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>>
>> Cum_RespRate          <- cum_R/cum_n)*100
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
>> Sent: Thursday, April 20, 2017 12:10 PM
>> To: r-help at r-project.org
>> Subject: [R] Looking for a package to replace xtable
>>
>> R-helper:
>> Below, code for generating a decile table.
>> I am using the xtable package, but it is not quite right for the output.
>> Issue #1. xtable inserts an unwanted column, before the first derived
>> column DECILE
>> Issue #2. In the last line "Total" I manually sum all columns, even
>> though I only want the sums for second and third columns.
>> If I calculate only second and third columns, the remaining columns
>> would have NAs.
>> Either scenario is not desired.
>>
>> Any suggestions, would be appreciated, for a package that addresses
>> issue #1,
>> and has an option for summing the desired two columns.
>>
>> Lastly, I read that one should rarely use "attach()", but if I don't the
>> program will not run.
>> An explanation of why I need attach() would also be appreciated.
>> Thanks.
>> Bruce
>>
>>     ****
>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>>
>> Response[[2]] <- NULL
>>
>> cum_R    <- cumsum(Response)
>> sam_size <- nrow(Response)
>>
>> cum_n    <- seq(1:1,sam_size)
>> wt       <- rep(c(1), times=sam_size)
>> cum_wt   <- cumsum(wt)
>>
>> dec      <- (cum_n/sam_size)
>> decc     <- floor((cum_n*10)/(sam_size+1))
>>
>> dec_mean <- aggregate(Response, by=list(decc), mean)
>>
>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>> dd  <- cbind(Response, dd_)
>> names(dd)[2] <- "cum_R"
>>
>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>>
>> wt         <- rep(c(1), times=sam_size)
>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>>
>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>> dec_mean_wt    <- dec_mean_wt[-3]
>>
>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>>
>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>        "No_Resp")
>>
>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>>
>> cum_n        <- dec_mean_wt_R[2]
>> cum_n        <- cumsum(cum_n)
>>
>> cum_R        <- dec_mean_wt_R[3]
>> cum_R        <- cumsum(cum_R)
>>
>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>>
>> colnames(dec_mean_wt_R_nR) <-
>>        c("Decile", "No_Inds", "No_Resp", "RespRate",
>>                    "Cum_n", "Cum_R")
>>
>> dec_mean_wt_R_nR
>>
>> attach(dec_mean_wt_R_nR)
>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>>
>> options(digits=4)
>> Decile_RespRate          <- (No_Resp/No_Inds)
>>
>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate)
>>
>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>>
>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>
>> total_line<-cbind(DECILE="Total",
>>     as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>>
>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>> decile_table <- dec_mean_wt_R_nRDLT
>> decile_table
>>
>> #Install the xtable package: install.packages("xtable")
>> #Load the xtable package:
>> library(xtable)
>>
>> DECILE_TABLE <-xtable(decile_table)
>> DECILE_TABLE
>>
>> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
>>
>> ****
>>
>> --
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
>


From bgunter.4567 at gmail.com  Fri Apr 21 19:42:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 21 Apr 2017 10:42:26 -0700
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
Message-ID: <CAGxFJbTT5HZ1dfBeXeoO=fd9q4AgqkrRFhBQgsGNfGm32kMFuQ@mail.gmail.com>

??
Works for me.

Perhaps show us the output of sessionInfo(). Mine is:

R version 3.3.3 (2017-03-06)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.20-34 backports_1.0.5

loaded via a namespace (and not attached):
[1] tools_3.3.3 grid_3.3.3

--Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 21, 2017 at 10:14 AM, BR_email <br at dmstat1.com> wrote:
> David:
> Hate to bother you, but because you have seen my code perhaps
> you can tell me what I am doing wrong.
> I want to replicate my original Response data by 0 times, called
> ResponseX10.
> All is good until the first calculation, cum_R.
> Would you kindly, assist me?
> Thanks.
> Bruce
> ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>
> ResponseX10 <- do.call(rbind, replicate(10, Response, simplify=FALSE))
>
> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>
> ResponseX10[[2]] <- NULL
> ResponseX10
>
> cum_R    <- cumsum(Response)
> cum_R
> *******
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
> David L Carlson wrote:
>>
>> You can rename the columns with colnames() before passing it to xtable.
>> This will let you use characters that data.frame would automatically
>> convert.
>>
>> I don't see an easy way to center the columns when printing an html file.
>> If you are not making too many of these, you could open the .html file into
>> a WYSIWIG html editor such as BlueGriffon, make the changes and save the
>> file. If you have Microsoft Excel and Word, another fallback solution is to
>> read the .html file into Excel where you have a wide variety of styles.
>>
>> David C
>>
>> -----Original Message-----
>> From: BR_email [mailto:br at dmstat1.com]
>> Sent: Thursday, April 20, 2017 4:31 PM
>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>>
>> David:
>> All is perfect, almost - after I ran your corrections.
>> Is there a way I can have more control of the column names, i.e.,
>> not be restricted to abbreviations headings, and center-justify?
>>
>> Thanks a lot, nice.
>> Bruce
>>
>>
>> David L Carlson wrote:
>>>
>>> #1 You can remove the rownames by adding the argument
>>> include.rownames=FALSE to print.xtable():
>>>
>>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html",
>>> include.rownames=FALSE)
>>>
>>> #2 Prevent data.frame from converting the first column to a factor and
>>> use NAs for the columns where you don't want totals:
>>>
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift,
>>> stringsAsFactors=FALSE)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>>     as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA,
>>> 3)),nrow=1)))
>>>
>>> Now the table should print without totals in the last three columns and
>>> no rownames.
>>>
>>> attach is discouraged since it can lead to confusion when a variable name
>>> exists in the environment and in a data frame (or multiple data frames). It
>>> is easy to forget which version of the variable you are using. More typing,
>>> but less subject to confusion would be to use with(), eg:
>>>
>>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>>>
>>> This way it is always clear where Cum_R and Cum_n are coming from. In
>>> your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>>>
>>> Cum_RespRate          <- cum_R/cum_n)*100
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
>>> Sent: Thursday, April 20, 2017 12:10 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Looking for a package to replace xtable
>>>
>>> R-helper:
>>> Below, code for generating a decile table.
>>> I am using the xtable package, but it is not quite right for the output.
>>> Issue #1. xtable inserts an unwanted column, before the first derived
>>> column DECILE
>>> Issue #2. In the last line "Total" I manually sum all columns, even
>>> though I only want the sums for second and third columns.
>>> If I calculate only second and third columns, the remaining columns
>>> would have NAs.
>>> Either scenario is not desired.
>>>
>>> Any suggestions, would be appreciated, for a package that addresses
>>> issue #1,
>>> and has an option for summing the desired two columns.
>>>
>>> Lastly, I read that one should rarely use "attach()", but if I don't the
>>> program will not run.
>>> An explanation of why I need attach() would also be appreciated.
>>> Thanks.
>>> Bruce
>>>
>>>     ****
>>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>>>
>>> Response[[2]] <- NULL
>>>
>>> cum_R    <- cumsum(Response)
>>> sam_size <- nrow(Response)
>>>
>>> cum_n    <- seq(1:1,sam_size)
>>> wt       <- rep(c(1), times=sam_size)
>>> cum_wt   <- cumsum(wt)
>>>
>>> dec      <- (cum_n/sam_size)
>>> decc     <- floor((cum_n*10)/(sam_size+1))
>>>
>>> dec_mean <- aggregate(Response, by=list(decc), mean)
>>>
>>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>>> dd  <- cbind(Response, dd_)
>>> names(dd)[2] <- "cum_R"
>>>
>>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>>>
>>> wt         <- rep(c(1), times=sam_size)
>>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>>>
>>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>>> dec_mean_wt    <- dec_mean_wt[-3]
>>>
>>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>>>
>>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>>        "No_Resp")
>>>
>>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>>>
>>> cum_n        <- dec_mean_wt_R[2]
>>> cum_n        <- cumsum(cum_n)
>>>
>>> cum_R        <- dec_mean_wt_R[3]
>>> cum_R        <- cumsum(cum_R)
>>>
>>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>>>
>>> colnames(dec_mean_wt_R_nR) <-
>>>        c("Decile", "No_Inds", "No_Resp", "RespRate",
>>>                    "Cum_n", "Cum_R")
>>>
>>> dec_mean_wt_R_nR
>>>
>>> attach(dec_mean_wt_R_nR)
>>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>>>
>>> options(digits=4)
>>> Decile_RespRate          <- (No_Resp/No_Inds)
>>>
>>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate,
>>> Decile_RespRate)
>>>
>>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>>>
>>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>>     as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>>>
>>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>>> decile_table <- dec_mean_wt_R_nRDLT
>>> decile_table
>>>
>>> #Install the xtable package: install.packages("xtable")
>>> #Load the xtable package:
>>> library(xtable)
>>>
>>> DECILE_TABLE <-xtable(decile_table)
>>> DECILE_TABLE
>>>
>>> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html")
>>>
>>> ****
>>>
>>> --
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Fri Apr 21 20:07:33 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 21 Apr 2017 14:07:33 -0400
Subject: [R] Maximum length for a -e argument to Rscript?
In-Reply-To: <8D391176-D58F-402F-BA49-3DCAAAEB5014@mac.com>
References: <8D391176-D58F-402F-BA49-3DCAAAEB5014@mac.com>
Message-ID: <E5624108-C367-4D36-85DC-BA81EA2CB21B@bigelow.org>

Hi,

I suspect you are over the 10kb limit for the expression.  See 

https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Invoking-R-from-the-command-line

Cheers,
Ben

> On Apr 21, 2017, at 3:44 AM, Ben Haller <bhaller at mac.com> wrote:
> 
>  Hi!  I?m attempting to use Rscript to do some automated plotting.  It is working well, except that I seem to be running into a maximum line length issue, and I?m wondering if it is a bug on your end.  Here?s an example of the command I?m trying to run:
> 
> /usr/local/bin/Rscript -e '{x <- c(-1.31171, -0.686165, 1.62771, 0.320195, -0.322011, 1.66518, -0.271971, -0.665367, 0.516482, -0.716343, -0.317471, 0.068046, -0.100371, -1.15907, 0.263329, -0.936049, -0.852444, 0.358817, -0.233959, 0.209891, -0.831575, -0.952987, -0.0420206, -1.78527, -0.280584, -0.62353, 1.42597, 0.127994, 0.0751232, 0.896835, -0.319488, 0.897876, 0.18457, 0.779571, -0.0543194, 0.226722, -0.769983, -0.723463, 0.144386, -0.468544, -0.349417, 0.336786, 0.749212, -1.62397, 0.683075, -0.746449, 0.300921, -0.365468, 0.548271, 1.13169, -1.34042, -0.0740572, 1.34986, 0.531771, -0.147157, 0.824894, -1.05816, 1.58867, -0.885764, 1.11912, 0.361512, 1.77985, 0.585099, -1.205, 2.44134, -0.331372, -0.346322, 0.0535267, -1.75089, 0.0773243, -1.07846, -1.29632, 1.0622, 1.34867, 0.199777, 0.197516, 0.574185, 1.06555, -0.885166, -0.788576, -1.46061, -1.54026, 0.690576, -0.88821, 0.343747, -0.100751, -0.865596, -0.128504, 0.222334, -1.18932, -0.555258, -0.557368, 0.219272, 0.298858, 0.848022, 0.142608, 1.10082, -0.348039, 0.0566489, 0.662136, 0.50451, -0.909399, 1.02446, 1.40592, -0.114786, -1.10718, 2.02549, 0.0818607, -1.037, 1.18961, -0.204, 2.83165, -0.959653, -0.393082, -0.463351, 0.914054, 1.14472, -1.32927, 1.25416, 0.372267, 0.410832, 1.04187, 1.22288, 1.27131, 0.0949385, 0.194053, -0.226184, -0.502155, -1.36834, -0.000591861, -0.565903, 1.14099, 1.67811, 0.331709, -0.756879, 0.889596, 0.718098, 0.740242, -0.861818, 0.0332746, 1.01745, 0.584536, -1.14245, -0.444485, -1.34237, 0.660603, 1.16048, -0.898828, 0.965746, -1.16953, -2.33417, 0.591078, -0.364892, 0.0719267, -1.21676, 1.12646, 1.37534, 0.0712832, 1.22889, -0.0110024, 0.248213, -1.12013, -0.525197, -0.352156, -0.317182, -0.89552, 1.53422, -1.36777, 1.52099, 1.18789, -3.15251, 1.24008, -0.564289, -0.515629, -0.0920464, 2.94027, 0.895481, -0.157643, -0.347874, -0.290823, -0.771436, 1.29285, 0.216689, -1.86856, 2.24075, 0.888635, 0.430417, -0.585856, 1.13119, -0.243977, 0.544491, 0.921995, 0.815365, 1.2584, -1.29347, 0.0574579, 0.990557, -1.58657, -0.264373, 0.865893, 0.599298, -0.417531, 0.132897, 1.88597, 1.33112, -0.880904, 0.0762161, 0.0567852, 0.593295, -0.632135, 0.885625, 0.365863, -0.17885, 0.420185, -0.508275, 0.974357, 0.628085, 0.710578, 1.72447, 1.38488, 1.01301, 1.30015, 0.260501, 0.808981, 0.440228, 0.416344, -1.66273, -0.397224, -0.512086, -0.175854, -0.663143, 0.369712, -1.01654, 0.660465, 0.124851, -1.51101, -0.95725, 2.09893, 1.26819, 1.08086, 0.493204, 0.79073, 1.49191, 0.563689, 0.414473, 2.27361, 0.871923, 0.193703, -0.185039, -0.312859, -1.42267, -2.11561, 0.311996, -0.0906527, 1.19139, 1.57502, 1.10587, 0.416333, 2.35374, -1.0531, 0.0450512, 0.979958, 0.398269, 0.0897618, -0.855305, -1.59337, -0.084904, 0.245872, 1.27115, 1.3512, -0.166962, 1.01098, -1.19854, -2.05932, -0.98, 0.704973, 0.694688, 1.20408, -1.12553, 0.770056, 1.01602, 0.295223, -1.18801, 1.51707, 1.1418, -0.148787, 1.28886, 1.23981, 1.67984, 0.0185941, -0.877581, 0.495042, -0.368668, 1.59972, -2.20849, -1.36852, -0.972566, -1.01848, -0.366674, -2.60273, -0.540706, -0.475797, 0.227651, -1.11476, 1.73452, -0.212185, 3.04994, -0.251225, -0.0443482, -0.489125, 0.557936, -0.246389, -0.954287, 0.388668, 0.759049, -0.501683, -1.98722, 0.158712, -0.897082, -1.17644, 0.192465, -1.49901, -0.289129, -0.0460198, -0.520331, 0.432488, -0.471775, 1.21482, 0.998091, -0.794933, -0.36989, 0.937091, 1.27297, 1.06108, -0.784307, 0.70919, -0.309221, -0.516031, 0.479702, -0.669637, 1.60288, 0.657474, -0.666286, -1.01816, -0.452818, -0.283749, 1.05511, -1.2002, 0.112269, -1.37403, 1.00512, 0.664936, 0.600516, -1.08099, -0.705522, 0.103051, 0.0461179, 1.74404, 0.727475, 2.41175, 1.20414, 1.71095, 0.0957544, 0.610755, 0.545194, -0.936381, 0.190467, 0.485791, 0.0855697, 0.142676, 0.721754, -1.84506, 2.1227, -1.1271, -1.11228, -1.2807, 0.13385, 0.228727, -0.34391, 1.09837, -0.37053, 0.832574, 0.673463, 0.717732, -0.307687, 1.12486, 0.159803, -1.51251, 1.403, 2.0215, 0.010914, -0.543749, 0.137119, 0.200364, -0.104029, -0.930966, -1.56781, -0.526978, -0.537582, 1.11872, -0.99061, -0.501421, 1.21982, 0.813201, -0.539109, 0.433523, -0.0615188, 2.04298, 0.697692, 1.34515, 1.7298, 0.515137, 2.08119, 0.550985, 1.49876, 1.31187, 0.920405, 0.597678, 0.884353, -0.732892, -0.143545, -0.236836, -0.330872, 1.55577, -1.74473, -0.493322, 1.46375, 1.14347, 1.76164, 1.73099, -0.234701, -0.0546848, 0.346991, -0.393301, 1.34267, -1.58519, -0.381789, 0.622675, 1.34655, 2.84895, -0.371, -0.519666, -1.64944, 0.573592, 1.06484, -0.0239894, -0.604563, 0.0680641, -0.881325, 1.07265, 0.182585, 0.373288, 2.20228, -0.763593, -0.25659, 1.9397, -0.166943, -0.672522, -1.35983, 0.227406, 0.49471, -1.23535, -0.479552, 1.97798, 0.418181, 1.23454, -0.0767748, 0.828642, -0.0348468, -0.264499, 0.76699, -0.910363, -2.11408, -0.209169, 0.902191, -2.27096, 0.098513, -0.380699, -0.231276, -0.0296834, 0.834972, -0.658283, 0.616493, 0.198916, -1.89783, -1.30219, 0.51036, 0.195825, -1.68961, -1.27838, 0.879616, 0.566719, 1.21876, 0.270402, -1.38261, 0.365878, 1.54191, 1.25104, 1.23067, 1.87261);y <- c(0.986442, 2.65684, -1.79726, 1.79999, -2.43971, -1.68358, -1.84081, -2.27973, 2.96046, 2.61837, 1.48756, 1.63497, 1.46876, 2.09348, -0.925101, 3.6792, -2.03618, 1.33232, -0.0652269, 0.809911, -2.82019, -1.87691, 1.1284, 0.249619, -2.94777, 3.00423, -2.79901, -0.110801, -3.546, 1.67156, -3.10723, -3.24205, 3.16911, -3.24227, -1.29801, 0.271933, -2.83573, -0.79973, -2.34429, -0.905163, -0.197905, -3.05664, -0.694481, 1.89301, -2.70264, 2.94361, -2.32469, 1.9576, 1.73556, -3.29777, -1.54311, -2.03172, -0.871756, 0.77581, 3.7692, 1.54446, 3.92129, 0.160296, -3.45486, -1.56317, -2.72913, 0.695854, 3.15786, 1.1006, 3.25649, -1.57206, -3.15353, 0.242301, -1.95855, -0.256919, 3.04782, -0.505045, -2.35542, 2.11649, -1.73363, 2.65149, 3.66302, 0.457907, -2.2759, -2.36105, -2.49263, -2.9784, -3.53525, -0.699404, 3.17647, -1.52424, 2.72699, 3.82774, 0.100029, 3.42107, 1.74672, 3.1279, -0.793162, -0.025109, 1.07262, 2.4517, -2.00605, -3.6625, -2.57031, -2.43599, 2.56309, -1.31707, -2.10777, -3.75394, 0.954311, 0.496025, 3.82545, -3.74259, -1.96145, 0.366455, 3.97474, 3.26111, -3.69904, 2.07392, 0.591191, -3.34162, -0.926126, 1.03966, -2.68754, -2.69653, 0.651845, 2.82333, 2.25596, 3.26545, -2.57379, 2.69137, -3.08119, 2.99114, -3.86005, -1.30995, 1.80096, 1.39404, -2.6482, -2.12922, -3.28834, -1.06563, -1.6683, -2.023, 1.60516, -1.67431, 1.38595, 0.287423, 2.56888, -2.99169, 0.549401, 2.31817, -2.48251, 2.20152, 1.0531, -3.60478, 0.327999, 0.475523, -0.454324, -2.63147, -1.61249, -1.65507, 1.13203, 0.218, 2.87289, -0.279036, -0.316795, 3.22757, -2.25, -1.10923, 0.0949814, -2.60818, -0.181803, 3.65484, 2.86193, 0.940815, 3.5461, 1.23983, 2.01177, -0.428626, 3.5539, -2.63454, 1.63098, 3.69696, 0.404995, 0.480342, 3.22724, -3.57127, -2.38176, -1.23267, 0.738668, 1.64966, 1.37331, -2.60132, -1.60081, 2.57359, -3.58266, 1.32347, 3.24265, 3.81, 3.90706, -0.407994, 2.42083, 3.34477, 3.43151, -1.08974, -2.93732, 2.39014, -1.36511, -0.101514, -1.46445, 2.11849, -3.63955, -1.57038, 3.41777, -1.00185, -0.0702487, 2.01317, -3.38133, 3.64754, -0.740182, -3.64028, -3.77238, 2.45613, -3.11631, 3.82543, 2.15285, -0.790691, -1.22153, -0.943069, -3.37327, 1.19097, 1.48834, 0.502127, -2.90383, -3.4236, -0.676889, 3.41785, 2.54728, -2.60006, -3.25969, -1.85346, -2.8088, 3.3905, -1.34015, -1.3877, 2.38485, 3.16688, -3.26326, -1.94801, 0.0878641, 0.492529, 2.62313, -2.08994, -1.77721, 1.92357, 0.739532, 0.869021, -3.82981, 3.92422, -1.16293, 3.82139, -1.67119, 1.1145, -2.24382, -1.93777, -0.109559, -0.350947, 1.94832, -2.54192, 1.224, 0.797731, 0.767982, -2.93565, -2.72896, 1.2624, 1.91513, -3.96412, 3.43534, 0.358804, 3.05541, -0.213663, 0.38204, -0.539063, -0.897154, -2.91298, -0.198784, -0.0732228, 2.99983, 3.54078, 2.27245, 3.87904, 2.99445, -0.705307, 0.187173, 1.79102, 1.69581, 2.08613, 1.54021, 0.7471, -1.19008, 2.44732, -1.59312, 1.5387, -0.526756, 3.06958, -1.707, -2.46148, -0.523427, -0.675584, -3.02611, -2.22116, -3.4546, -2.94353, 2.1346, 3.51197, 1.85137, 1.7461, -0.875901, -2.13891, -2.1714, 1.6953, -0.159958, 1.77583, -0.808156, 2.04446, 3.58507, -1.27303, -0.0739294, 0.22885, -1.16883, -0.0437807, -1.30141, 2.71702, 2.85379, 3.74969, 3.5839, -0.159889, -0.236555, 2.78411, 2.15217, -0.945737, -1.90692, 0.536403, -1.08419, -3.75986, 2.65243, -2.29661, 3.8776, 1.23146, -2.26545, 2.79205, 2.34152, -3.62388, -3.51983, -0.152083, -0.77672, -0.0661756, -1.12531, 1.77691, -1.49266, -0.401453, -2.98782, 1.15182, 3.00211, -0.338523, 2.63385, -1.30166, -1.96304, -2.03665, -2.91373, 3.33512, 0.26508, -2.4008, -0.989122, -1.96516, 0.498154, -0.139963, 1.762, -0.36494, 2.42886, 1.26076, -0.344707, -2.2629, 3.01517, -0.192693, 1.72579, -3.09541, 0.898774, -3.33187, -2.09473, 2.13997, -1.20736, -1.78102, 0.661333, -2.15738, -2.82721, -0.34423, 0.945198, -1.3919, 2.24165, -1.72333, -3.61333, 0.177856, -0.499845, 1.08322, -0.57797, 1.32396, -0.580476, -0.990233, 3.13608, 0.2254, 2.44513, -1.43021, -2.20293, -0.0295935, 3.9359, 0.872028, 2.94495, 2.3334, -1.4539, -2.0155, 1.90474, -1.83284, -3.6983, -0.223583, -2.19197, 2.98892, 2.11877, -0.614374, 0.860207, 3.63726, -1.54793, 0.699044, -3.31199, -2.87789, 3.21311, -3.24507, -0.0689166, 0.225146, -2.84127, -3.67944, 0.763724, -3.93721, -3.81518, -1.06853, 0.726999, 0.562243, 3.79879, 3.75762, 2.1455, 2.00329, -0.400098, -1.80113, 3.49374, 3.26726, -1.24347, 2.0535, 2.55697, 0.670452, -2.79004, 1.39668, 2.32366, -2.27311, -0.352436, -2.71256, -2.31389, -2.11829, 0.111656, -1.67798, 2.97944, -3.7505, -1.88802, 3.50199, 1.31453, 3.32241, -1.04754, -3.03124, 1.60895, 1.15746, 2.29443, 3.31704, -0.172815, 2.81695, 0.253896, 0.298466, -3.90939, -2.39831, 3.46711, 2.41166, 2.03439, 0.387814, -3.40236, -3.71227, -1.68499, -3.81028, 2.97335, 3.32693, -3.88281, -2.61789, -3.31616, 2.71789, 3.05144, -0.579528, -0.672907, 2.75653);quartz(width=4, height=4, type="pdf", file="~/Desktop/testpdf.pdf");plot(x=x, y=y, xlim=c(-5, 5), ylim=c(-5, 5), pch=19, cex=0.5, main="2000");dev.off();}?
> 
>  If I execute the R code that is in the -e argument directly in R GUI (on OS X) it works fine.  And if I put that code in a file and run Rscript <file>, it works fine.  So the length limit is not intrinsic to R?s parser, it would seem.  But if I try to execute exactly the same code in an interactive R session in my Unix terminal's command line, I get a continuation prompt, +, and a little investigation indicates that the input line may have been truncated after 3843 characters (a strange number) and it is waiting for more input to follow that truncated input.  And ? what is most relevant for my situation ? if I try to run the full Rscript command as given above (inside /bin/sh), it prints out:
> 
> WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402
> 
> and then it hangs ? the full warning doesn?t complete printing, so it is not clear what it is trying to warn about.  That represents 844 characters of input script, but with the weird way that spaces have been replaced by ~+~ by somebody, it is 1013 characters ? suspiciously close to 1024.
> 
>  Note that if I simply make the R script shorter, by plotting 100 x/y values instead of 500, everything works fine.  So there is no issue with the way that I?m quoting strings or anything like that; the only issue seems to be the total length of the command line.
> 
>  Now of course I could break up the script into multiple chunks, passed via separate -e arguments, and perhaps that would work somewhat better.  But given that I want to set up a vector x with a single c() command containing all of the data for x, I will still hit a line length limit; the single line of code to set up x will already be over the maximum line length that Rscript allows for a -e argument, apparently.  Getting around that would obviously be possible too, but would be considerably more hassle.
> 
>  And incidentally, this seems to have nothing to do with the /bin/sh input line limit; that is much higher.  According to "getconf ARG_MAX?, it is 262144 characters on my machine, which is more than enough headroom for what I?m trying to do.
> 
>  So my questions are: (1) is this a bug, (2) if so, do you think you are likely to fix it any time soon :->, and (3) if the answer to that is no, are there any standard workarounds for this sort of situation that you would recommend?  I suppose I could write out the script to a file and then execute that file with Rscript, since that seems to work; but I was really hoping to avoid that extra complication and overhead.  Is there a better way?
> 
>  Thanks for any help you can provide!  :->
> 
> Cheers,
> -B.
> 
> Benjamin C. Haller
> Messer Lab
> Cornell University
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From br at dmstat1.com  Fri Apr 21 20:22:24 2017
From: br at dmstat1.com (BR_email)
Date: Fri, 21 Apr 2017 14:22:24 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
Message-ID: <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>

David:
I tried somethings and got a little more working.
Now, I am struck at last line provided: "dec_mean    <- 
aggregate(Response ~ decc, dd, mean)"
Any help is appreciated.
Bruce

*****
Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Resp <- Resp[order(Response$yhat,decreasing=TRUE),]

ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
str(ResponseX10)

ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]

str(ResponseX10)
head(ResponseX10)

ResponseX10[[2]] <- NULL
ResponseX10 <- data.frame(ResponseX10)
str(ResponseX10)

cum_R    <- cumsum(Response)
cum_R

sam_size <- nrow(ResponseX10)
sam_size
cum_n    <- seq(1:1,sam_size)
cum_n
wt       <- rep(c(1), times=sam_size)
cum_wt   <- cumsum(wt)
cum_wt

dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))
str(decc)

dec_mean <- aggregate(Response, by=list(decc), mean)

dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
dd  <- cbind(Response, dd_)
names(dd)[2] <- "cum_R"

dec_mean    <- aggregate(Response ~ decc, dd, mean)
******

BR_email wrote:
> David:
> Hate to bother you, but because you have seen my code perhaps
> you can tell me what I am doing wrong.
> I want to replicate my original Response data by 0 times, called 
> ResponseX10.
> All is good until the first calculation, cum_R.
> Would you kindly, assist me?
> Thanks.
> Bruce
> ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>
> ResponseX10 <- do.call(rbind, replicate(10, Response, simplify=FALSE))
>
> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>
> ResponseX10[[2]] <- NULL
> ResponseX10
>
> cum_R    <- cumsum(Response)
> cum_R
> *******
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> David L Carlson wrote:
>> You can rename the columns with colnames() before passing it to 
>> xtable. This will let you use characters that data.frame would 
>> automatically convert.
>>
>> I don't see an easy way to center the columns when printing an html 
>> file. If you are not making too many of these, you could open the 
>> .html file into a WYSIWIG html editor such as BlueGriffon, make the 
>> changes and save the file. If you have Microsoft Excel and Word, 
>> another fallback solution is to read the .html file into Excel where 
>> you have a wide variety of styles.
>>
>> David C
>>
>> -----Original Message-----
>> From: BR_email [mailto:br at dmstat1.com]
>> Sent: Thursday, April 20, 2017 4:31 PM
>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>>
>> David:
>> All is perfect, almost - after I ran your corrections.
>> Is there a way I can have more control of the column names, i.e.,
>> not be restricted to abbreviations headings, and center-justify?
>>
>> Thanks a lot, nice.
>> Bruce
>>
>>
>> David L Carlson wrote:
>>> #1 You can remove the rownames by adding the argument 
>>> include.rownames=FALSE to print.xtable():
>>>
>>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", 
>>> include.rownames=FALSE)
>>>
>>> #2 Prevent data.frame from converting the first column to a factor 
>>> and use NAs for the columns where you don't want totals:
>>>
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
>>> stringsAsFactors=FALSE)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>>     as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), 
>>> rep(NA, 3)),nrow=1)))
>>>
>>> Now the table should print without totals in the last three columns 
>>> and no rownames.
>>>
>>> attach is discouraged since it can lead to confusion when a variable 
>>> name exists in the environment and in a data frame (or multiple data 
>>> frames). It is easy to forget which version of the variable you are 
>>> using. More typing, but less subject to confusion would be to use 
>>> with(), eg:
>>>
>>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>>>
>>> This way it is always clear where Cum_R and Cum_n are coming from. 
>>> In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>>>
>>> Cum_RespRate          <- cum_R/cum_n)*100
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>> BR_email
>>> Sent: Thursday, April 20, 2017 12:10 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Looking for a package to replace xtable
>>>
>>> R-helper:
>>> Below, code for generating a decile table.
>>> I am using the xtable package, but it is not quite right for the 
>>> output.
>>> Issue #1. xtable inserts an unwanted column, before the first derived
>>> column DECILE
>>> Issue #2. In the last line "Total" I manually sum all columns, even
>>> though I only want the sums for second and third columns.
>>> If I calculate only second and third columns, the remaining columns
>>> would have NAs.
>>> Either scenario is not desired.
>>>
>>> Any suggestions, would be appreciated, for a package that addresses
>>> issue #1,
>>> and has an option for summing the desired two columns.
>>>
>>> Lastly, I read that one should rarely use "attach()", but if I don't 
>>> the
>>> program will not run.
>>> An explanation of why I need attach() would also be appreciated.
>>> Thanks.
>>> Bruce
>>>
>>>     ****
>>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>>>
>>> Response[[2]] <- NULL
>>>
>>> cum_R    <- cumsum(Response)
>>> sam_size <- nrow(Response)
>>>
>>> cum_n    <- seq(1:1,sam_size)
>>> wt       <- rep(c(1), times=sam_size)
>>> cum_wt   <- cumsum(wt)
>>>
>>> dec      <- (cum_n/sam_size)
>>> decc     <- floor((cum_n*10)/(sam_size+1))
>>>
>>> dec_mean <- aggregate(Response, by=list(decc), mean)
>>>
>>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>>> dd  <- cbind(Response, dd_)
>>> names(dd)[2] <- "cum_R"
>>>
>>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>>>
>>> wt         <- rep(c(1), times=sam_size)
>>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>>>
>>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>>> dec_mean_wt    <- dec_mean_wt[-3]
>>>
>>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>>>
>>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>>        "No_Resp")
>>>
>>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>>>
>>> cum_n        <- dec_mean_wt_R[2]
>>> cum_n        <- cumsum(cum_n)
>>>
>>> cum_R        <- dec_mean_wt_R[3]
>>> cum_R        <- cumsum(cum_R)
>>>
>>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>>>
>>> colnames(dec_mean_wt_R_nR) <-
>>>        c("Decile", "No_Inds", "No_Resp", "RespRate",
>>>                    "Cum_n", "Cum_R")
>>>
>>> dec_mean_wt_R_nR
>>>
>>> attach(dec_mean_wt_R_nR)
>>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>>>
>>> options(digits=4)
>>> Decile_RespRate          <- (No_Resp/No_Inds)
>>>
>>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, 
>>> Decile_RespRate)
>>>
>>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>>>
>>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>> as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>>>
>>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>>> decile_table <- dec_mean_wt_R_nRDLT
>>> decile_table
>>>
>>> #Install the xtable package: install.packages("xtable")
>>> #Load the xtable package:
>>> library(xtable)
>>>
>>> DECILE_TABLE <-xtable(decile_table)
>>> DECILE_TABLE
>>>
>>> print.xtable(DECILE_TABLE, 
>>> type="html",file="C:/R_Data/DecileTable.html")
>>>
>>> ****
>>>
>>> -- 
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>
>>
>


From george.trojan at noaa.gov  Fri Apr 21 20:59:28 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Fri, 21 Apr 2017 18:59:28 +0000
Subject: [R] Wireframe plot inside a function
In-Reply-To: <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
 <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
Message-ID: <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>

Thanks. After changing the function to

cplot <- function(cop1, cop2) {
  x11()
  o <- plot(cop1, main = "cop1 function")
  print(o)
  x11()
  o <- plot(cop2, main = "cop2 function")
  print(o)
}

I see both plots. But, since "cop2 function" was plotted before, does
it mean it is plotted twice now? Looks as a strange design.

I did check the "Plain text mode" in Chrome, you should see only the text part.

George

On 21 April 2017 at 16:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> FAQ 7.22
> And don't send HTML email... you are the one making it difficult for us to read your question.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>>Consider the following example:
>>
>>library("kdecopula")
>>library("mvtnorm")
>>
>>pobs <- function(x) rank(x) / (length(x) + 1)
>>
>>n <- 1000
>>
>>sigma1 <- diag(x = 1, 2, 2)
>>x1 <- rmvnorm(n, sigma = sigma1)
>>xx1 <- apply(x1, 2, pobs)
>>cop1 <- kdecop(xx1)
>>
>>eps <- 0.8
>>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>>x2 <- rmvnorm(n, sigma = sigma2)
>>xx2 <- apply(x2, 2, pobs)
>>cop2 <- kdecop(xx2)
>>
>>x11()
>>plot(cop1, main = "cop1 main")
>>x11()
>>plot(cop2, main = "cop2 main")
>>
>>cplot <- function(cop1, cop2) {
>>  x11()
>>  plot(cop1, main = "cop1 function")
>>  x11()
>>  plot(cop2, main = "cop2 function")
>>}
>>
>>cplot(cop1, cop2)
>>
>>cat("Press <Enter> to quit")
>>readLines(file("stdin"), n
>>
>>=
>>
>>1)
>>quit()
>>
>>When I run it with Rscript all four x11 windows pop up, however the one
>>that should display "cop1 function" is blank, the wireframe is not
>>plotted.
>>This is R 3.3.1, on Fedora 20.
>>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code from
>>RStudio (the most recent one).
>>
>>George
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Apr 21 21:43:03 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 21 Apr 2017 19:43:03 +0000
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
Message-ID: <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>

You have an issue at the top with

Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Resp <- Resp[order(Response$yhat,decreasing=TRUE),]

Since Response$yhat has not been defined at this point. Presumably you want

Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]

The main issue is that you have a variable Response that is located in a data frame called ResponseX10. 

In creating cum_R you need

cum_R    <- with(ResponseX10, cumsum(Response))

then dec_mean

dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))

then dd

dd  <- with(ResponseX10, cbind(Response, dd_))


You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().

I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.

Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?


David C


-----Original Message-----
From: BR_email [mailto:br at dmstat1.com] 
Sent: Friday, April 21, 2017 1:22 PM
To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
Subject: Re: [R] Looking for a package to replace xtable

David:
I tried somethings and got a little more working.
Now, I am struck at last line provided: "dec_mean    <- 
aggregate(Response ~ decc, dd, mean)"
Any help is appreciated.
Bruce

*****
Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
Resp <- Resp[order(Response$yhat,decreasing=TRUE),]

ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
str(ResponseX10)

ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]

str(ResponseX10)
head(ResponseX10)

ResponseX10[[2]] <- NULL
ResponseX10 <- data.frame(ResponseX10)
str(ResponseX10)

cum_R    <- cumsum(Response)
cum_R

sam_size <- nrow(ResponseX10)
sam_size
cum_n    <- seq(1:1,sam_size)
cum_n
wt       <- rep(c(1), times=sam_size)
cum_wt   <- cumsum(wt)
cum_wt

dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))
str(decc)

dec_mean <- aggregate(Response, by=list(decc), mean)

dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
dd  <- cbind(Response, dd_)
names(dd)[2] <- "cum_R"

dec_mean    <- aggregate(Response ~ decc, dd, mean)
******

BR_email wrote:
> David:
> Hate to bother you, but because you have seen my code perhaps
> you can tell me what I am doing wrong.
> I want to replicate my original Response data by 0 times, called 
> ResponseX10.
> All is good until the first calculation, cum_R.
> Would you kindly, assist me?
> Thanks.
> Bruce
> ****
> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>
> ResponseX10 <- do.call(rbind, replicate(10, Response, simplify=FALSE))
>
> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>
> ResponseX10[[2]] <- NULL
> ResponseX10
>
> cum_R    <- cumsum(Response)
> cum_R
> *******
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> David L Carlson wrote:
>> You can rename the columns with colnames() before passing it to 
>> xtable. This will let you use characters that data.frame would 
>> automatically convert.
>>
>> I don't see an easy way to center the columns when printing an html 
>> file. If you are not making too many of these, you could open the 
>> .html file into a WYSIWIG html editor such as BlueGriffon, make the 
>> changes and save the file. If you have Microsoft Excel and Word, 
>> another fallback solution is to read the .html file into Excel where 
>> you have a wide variety of styles.
>>
>> David C
>>
>> -----Original Message-----
>> From: BR_email [mailto:br at dmstat1.com]
>> Sent: Thursday, April 20, 2017 4:31 PM
>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>>
>> David:
>> All is perfect, almost - after I ran your corrections.
>> Is there a way I can have more control of the column names, i.e.,
>> not be restricted to abbreviations headings, and center-justify?
>>
>> Thanks a lot, nice.
>> Bruce
>>
>>
>> David L Carlson wrote:
>>> #1 You can remove the rownames by adding the argument 
>>> include.rownames=FALSE to print.xtable():
>>>
>>> print.xtable(DECILE_TABLE, type="html",file="DecileTable.html", 
>>> include.rownames=FALSE)
>>>
>>> #2 Prevent data.frame from converting the first column to a factor 
>>> and use NAs for the columns where you don't want totals:
>>>
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
>>> stringsAsFactors=FALSE)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>>     as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), 
>>> rep(NA, 3)),nrow=1)))
>>>
>>> Now the table should print without totals in the last three columns 
>>> and no rownames.
>>>
>>> attach is discouraged since it can lead to confusion when a variable 
>>> name exists in the environment and in a data frame (or multiple data 
>>> frames). It is easy to forget which version of the variable you are 
>>> using. More typing, but less subject to confusion would be to use 
>>> with(), eg:
>>>
>>> Cum_RespRate          <- with(dec_mean_wt_R_nR, (Cum_R/Cum_n)*100)
>>>
>>> This way it is always clear where Cum_R and Cum_n are coming from. 
>>> In your code cum_R = Cum_R and cum_n = Cum_n so you could also use
>>>
>>> Cum_RespRate          <- cum_R/cum_n)*100
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>> BR_email
>>> Sent: Thursday, April 20, 2017 12:10 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Looking for a package to replace xtable
>>>
>>> R-helper:
>>> Below, code for generating a decile table.
>>> I am using the xtable package, but it is not quite right for the 
>>> output.
>>> Issue #1. xtable inserts an unwanted column, before the first derived
>>> column DECILE
>>> Issue #2. In the last line "Total" I manually sum all columns, even
>>> though I only want the sums for second and third columns.
>>> If I calculate only second and third columns, the remaining columns
>>> would have NAs.
>>> Either scenario is not desired.
>>>
>>> Any suggestions, would be appreciated, for a package that addresses
>>> issue #1,
>>> and has an option for summing the desired two columns.
>>>
>>> Lastly, I read that one should rarely use "attach()", but if I don't 
>>> the
>>> program will not run.
>>> An explanation of why I need attach() would also be appreciated.
>>> Thanks.
>>> Bruce
>>>
>>>     ****
>>> Response <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>> Response <- Response[order(Response$yhat,decreasing=TRUE),]
>>>
>>> Response[[2]] <- NULL
>>>
>>> cum_R    <- cumsum(Response)
>>> sam_size <- nrow(Response)
>>>
>>> cum_n    <- seq(1:1,sam_size)
>>> wt       <- rep(c(1), times=sam_size)
>>> cum_wt   <- cumsum(wt)
>>>
>>> dec      <- (cum_n/sam_size)
>>> decc     <- floor((cum_n*10)/(sam_size+1))
>>>
>>> dec_mean <- aggregate(Response, by=list(decc), mean)
>>>
>>> dd_        <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
>>> dd  <- cbind(Response, dd_)
>>> names(dd)[2] <- "cum_R"
>>>
>>> dec_mean    <- aggregate(Response ~ decc, dd, mean)
>>>
>>> wt         <- rep(c(1), times=sam_size)
>>> cum_wt     <- aggregate(wt        ~ decc, dd, sum)
>>> cum_R      <- aggregate(Response  ~ decc, dd, sum)
>>>
>>> dec_mean_wt    <- cbind(dec_mean, cum_wt)
>>> dec_mean_wt    <- dec_mean_wt[-3]
>>>
>>> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
>>> dec_mean_wt_R  <- dec_mean_wt_R[-4]
>>>
>>> colnames(dec_mean_wt_R) <- c("Decile", "Resp_Rate", "No_Inds",
>>>        "No_Resp")
>>>
>>> dec_mean_wt_R  <- dec_mean_wt_R[,c(1,3,4,2)]
>>>
>>> cum_n        <- dec_mean_wt_R[2]
>>> cum_n        <- cumsum(cum_n)
>>>
>>> cum_R        <- dec_mean_wt_R[3]
>>> cum_R        <- cumsum(cum_R)
>>>
>>> dec_mean_wt_R_nR  <- cbind(dec_mean_wt_R, cum_n, cum_R)
>>>
>>> colnames(dec_mean_wt_R_nR) <-
>>>        c("Decile", "No_Inds", "No_Resp", "RespRate",
>>>                    "Cum_n", "Cum_R")
>>>
>>> dec_mean_wt_R_nR
>>>
>>> attach(dec_mean_wt_R_nR)
>>> Cum_RespRate          <- (Cum_R/Cum_n)*100
>>>
>>> options(digits=4)
>>> Decile_RespRate          <- (No_Resp/No_Inds)
>>>
>>> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_RespRate, 
>>> Decile_RespRate)
>>>
>>> avg_RR             <- dec_mean_wt_R_nRD[10,7]
>>> Cum_Lift           <- (Cum_RespRate/avg_RR)*100
>>>
>>> DECILE             <- c("top","2","3","4","5","6","7","8","9","bot")
>>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift)
>>> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)]
>>>
>>> total_line<-cbind(DECILE="Total",
>>> as.data.frame(matrix(colSums(dec_mean_wt_R_nRDL[-1]),nrow=1)))
>>>
>>> names(total_line)<-names(dec_mean_wt_R_nRDL)
>>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line)
>>> decile_table <- dec_mean_wt_R_nRDLT
>>> decile_table
>>>
>>> #Install the xtable package: install.packages("xtable")
>>> #Load the xtable package:
>>> library(xtable)
>>>
>>> DECILE_TABLE <-xtable(decile_table)
>>> DECILE_TABLE
>>>
>>> print.xtable(DECILE_TABLE, 
>>> type="html",file="C:/R_Data/DecileTable.html")
>>>
>>> ****
>>>
>>> -- 
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>
>>
>


From br at dmstat1.com  Fri Apr 21 22:25:24 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 21 Apr 2017 16:25:24 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>

David:
Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
response variable. 
I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original. 
(I know this is viewed by some as unorthodox.)

Your point: I only need Response as a column vector. 
That said, what would you alter, please?
Thanks for your time.
Regards, 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> You have an issue at the top with
> 
> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
> 
> Since Response$yhat has not been defined at this point. Presumably you want
> 
> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
> 
> The main issue is that you have a variable Response that is located in a data frame called ResponseX10. 
> 
> In creating cum_R you need
> 
> cum_R    <- with(ResponseX10, cumsum(Response))
> 
> then dec_mean
> 
> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
> 
> then dd
> 
> dd  <- with(ResponseX10, cbind(Response, dd_))
> 
> 
> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
> 
> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
> 
> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
> 
> 
> David C
> 
> 
> -----Original Message-----
> From: BR_email [mailto:br at dmstat1.com] 
> Sent: Friday, April 21, 2017 1:22 PM
> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
> Subject: Re: [R] Looking for a package to replace xtable
> 
> David:
> I tried somethings and got a little more working.
> Now, I am struck at last line provided: "dec_mean    <- 
> aggregate(Response ~ decc, dd, mean)"
> Any help is appreciated.
> Bruce
> 
> *****
> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
> 
> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
> str(ResponseX10)
> 
> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
> 
> str(ResponseX10)
> head(ResponseX10)
> 
> ResponseX10[[2]] <- NULL
> ResponseX10 <- data.frame(ResponseX10)
> str(ResponseX10)
> 
> cum_R    <- cumsum(Response)
> cum_R
> 
> sam_size <- n


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 22:32:02 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 21 Apr 2017 13:32:02 -0700
Subject: [R] Wireframe plot inside a function
In-Reply-To: <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
 <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
 <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>
Message-ID: <E12CA3D1-4D55-482C-B744-0D604C783F95@dcn.davis.ca.us>

Your original function created the cop1 plot object but did nothing with it. It then created the cop2 plot and returned it from the function. Since you had invoked the cplot function from the interactive console, R printed that returned object automatically, which displayed the plot. 

FYI: when you want to start presenting multiple plots and/or tables together you will find that something like knitr and RMarkdown are very helpful. 
-- 
Sent from my phone. Please excuse my brevity.

On April 21, 2017 11:59:28 AM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>Thanks. After changing the function to
>
>cplot <- function(cop1, cop2) {
>  x11()
>  o <- plot(cop1, main = "cop1 function")
>  print(o)
>  x11()
>  o <- plot(cop2, main = "cop2 function")
>  print(o)
>}
>
>I see both plots. But, since "cop2 function" was plotted before, does
>it mean it is plotted twice now? Looks as a strange design.
>
>I did check the "Plain text mode" in Chrome, you should see only the
>text part.
>
>George
>
>On 21 April 2017 at 16:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> FAQ 7.22
>> And don't send HTML email... you are the one making it difficult for
>us to read your question.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal
><george.trojan at noaa.gov> wrote:
>>>Consider the following example:
>>>
>>>library("kdecopula")
>>>library("mvtnorm")
>>>
>>>pobs <- function(x) rank(x) / (length(x) + 1)
>>>
>>>n <- 1000
>>>
>>>sigma1 <- diag(x = 1, 2, 2)
>>>x1 <- rmvnorm(n, sigma = sigma1)
>>>xx1 <- apply(x1, 2, pobs)
>>>cop1 <- kdecop(xx1)
>>>
>>>eps <- 0.8
>>>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>>>x2 <- rmvnorm(n, sigma = sigma2)
>>>xx2 <- apply(x2, 2, pobs)
>>>cop2 <- kdecop(xx2)
>>>
>>>x11()
>>>plot(cop1, main = "cop1 main")
>>>x11()
>>>plot(cop2, main = "cop2 main")
>>>
>>>cplot <- function(cop1, cop2) {
>>>  x11()
>>>  plot(cop1, main = "cop1 function")
>>>  x11()
>>>  plot(cop2, main = "cop2 function")
>>>}
>>>
>>>cplot(cop1, cop2)
>>>
>>>cat("Press <Enter> to quit")
>>>readLines(file("stdin"), n
>>>
>>>=
>>>
>>>1)
>>>quit()
>>>
>>>When I run it with Rscript all four x11 windows pop up, however the
>one
>>>that should display "cop1 function" is blank, the wireframe is not
>>>plotted.
>>>This is R 3.3.1, on Fedora 20.
>>>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code
>from
>>>RStudio (the most recent one).
>>>
>>>George
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Fri Apr 21 22:45:42 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 21 Apr 2017 16:45:42 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
Message-ID: <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>

David:
Correction: I do need a data frame because from the order Response column I create a data frame as per all my calculated columns, yielding the five column decile table. 
I used your latest corrections but something buggy is a happenin'.

Bruce
______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> 
> David:
> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
> response variable. 
> I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original. 
> (I know this is viewed by some as unorthodox.)
> 
> Your point: I only need Response as a column vector. 
> That said, what would you alter, please?
> Thanks for your time.
> Regards, 
> Bruce
> 
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
> 
> 
> 
>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>> You have an issue at the top with
>> 
>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>> 
>> Since Response$yhat has not been defined at this point. Presumably you want
>> 
>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>> 
>> The main issue is that you have a variable Response that is located in a data frame called ResponseX10. 
>> 
>> In creating cum_R you need
>> 
>> cum_R    <- with(ResponseX10, cumsum(Response))
>> 
>> then dec_mean
>> 
>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
>> 
>> then dd
>> 
>> dd  <- with(ResponseX10, cbind(Response, dd_))
>> 
>> 
>> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
>> 
>> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
>> 
>> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
>> 
>> 
>> David C
>> 
>> 
>> -----Original Message-----
>> From: BR_email [mailto:br at dmstat1.com] 
>> Sent: Friday, April 21, 2017 1:22 PM
>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>> 
>> David:
>> I tried somethings and got a little more working.
>> Now, I am struck at last line provided: "dec_mean    <- 
>> aggregate(Response ~ decc, dd, mean)"
>> Any help is appreciated.
>> Bruce
>> 
>> *****
>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>> 
>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>> str(ResponseX10)
>> 
>> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>> 
>> str(ResponseX10)
>> head(ResponseX10)
>> 
>> ResponseX10[[2]] <- NULL
>> ResponseX10 <- data.frame(ResponseX10)
>> str(ResponseX10)
>> 
>> cum_R    <- cumsum(Response)
>> cum_R
>> 
>> sam_size <- n


From george.trojan at noaa.gov  Fri Apr 21 22:56:00 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Fri, 21 Apr 2017 20:56:00 +0000
Subject: [R] Wireframe plot inside a function
In-Reply-To: <E12CA3D1-4D55-482C-B744-0D604C783F95@dcn.davis.ca.us>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
 <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
 <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>
 <E12CA3D1-4D55-482C-B744-0D604C783F95@dcn.davis.ca.us>
Message-ID: <CABie7_qWjq9SF0D=ga=ycRREXkQcjqVyUDooiNtCw13R7uYBHg@mail.gmail.com>

I see. So, if I don't care about the plot object itself,  the proper
incantation is

plot(plot(cop1, main = "cop1 function"))

Thanks again.

On 21 April 2017 at 20:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Your original function created the cop1 plot object but did nothing with it. It then created the cop2 plot and returned it from the function. Since you had invoked the cplot function from the interactive console, R printed that returned object automatically, which displayed the plot.
>
> FYI: when you want to start presenting multiple plots and/or tables together you will find that something like knitr and RMarkdown are very helpful.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 21, 2017 11:59:28 AM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>>Thanks. After changing the function to
>>
>>cplot <- function(cop1, cop2) {
>>  x11()
>>  o <- plot(cop1, main = "cop1 function")
>>  print(o)
>>  x11()
>>  o <- plot(cop2, main = "cop2 function")
>>  print(o)
>>}
>>
>>I see both plots. But, since "cop2 function" was plotted before, does
>>it mean it is plotted twice now? Looks as a strange design.
>>
>>I did check the "Plain text mode" in Chrome, you should see only the
>>text part.
>>
>>George
>>
>>On 21 April 2017 at 16:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>wrote:
>>> FAQ 7.22
>>> And don't send HTML email... you are the one making it difficult for
>>us to read your question.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal
>><george.trojan at noaa.gov> wrote:
>>>>Consider the following example:
>>>>
>>>>library("kdecopula")
>>>>library("mvtnorm")
>>>>
>>>>pobs <- function(x) rank(x) / (length(x) + 1)
>>>>
>>>>n <- 1000
>>>>
>>>>sigma1 <- diag(x = 1, 2, 2)
>>>>x1 <- rmvnorm(n, sigma = sigma1)
>>>>xx1 <- apply(x1, 2, pobs)
>>>>cop1 <- kdecop(xx1)
>>>>
>>>>eps <- 0.8
>>>>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>>>>x2 <- rmvnorm(n, sigma = sigma2)
>>>>xx2 <- apply(x2, 2, pobs)
>>>>cop2 <- kdecop(xx2)
>>>>
>>>>x11()
>>>>plot(cop1, main = "cop1 main")
>>>>x11()
>>>>plot(cop2, main = "cop2 main")
>>>>
>>>>cplot <- function(cop1, cop2) {
>>>>  x11()
>>>>  plot(cop1, main = "cop1 function")
>>>>  x11()
>>>>  plot(cop2, main = "cop2 function")
>>>>}
>>>>
>>>>cplot(cop1, cop2)
>>>>
>>>>cat("Press <Enter> to quit")
>>>>readLines(file("stdin"), n
>>>>
>>>>=
>>>>
>>>>1)
>>>>quit()
>>>>
>>>>When I run it with Rscript all four x11 windows pop up, however the
>>one
>>>>that should display "cop1 function" is blank, the wireframe is not
>>>>plotted.
>>>>This is R 3.3.1, on Fedora 20.
>>>>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code
>>from
>>>>RStudio (the most recent one).
>>>>
>>>>George
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Apr 21 22:57:20 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 21 Apr 2017 20:57:20 +0000
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
Message-ID: <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>

I've attached a modification of your script file (called .txt so it doesn't get stripped). See if this does what you want.

David C

-----Original Message-----
From: Bruce Ratner PhD [mailto:br at dmstat1.com] 
Sent: Friday, April 21, 2017 3:46 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] Looking for a package to replace xtable

David:
Correction: I do need a data frame because from the order Response column I create a data frame as per all my calculated columns, yielding the five column decile table. 
I used your latest corrections but something buggy is a happenin'.

Bruce
______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> 
> David:
> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
> response variable. 
> I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original. 
> (I know this is viewed by some as unorthodox.)
> 
> Your point: I only need Response as a column vector. 
> That said, what would you alter, please?
> Thanks for your time.
> Regards, 
> Bruce
> 
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
> 
> 
> 
>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>> You have an issue at the top with
>> 
>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>> 
>> Since Response$yhat has not been defined at this point. Presumably you want
>> 
>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>> 
>> The main issue is that you have a variable Response that is located in a data frame called ResponseX10. 
>> 
>> In creating cum_R you need
>> 
>> cum_R    <- with(ResponseX10, cumsum(Response))
>> 
>> then dec_mean
>> 
>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
>> 
>> then dd
>> 
>> dd  <- with(ResponseX10, cbind(Response, dd_))
>> 
>> 
>> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
>> 
>> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
>> 
>> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
>> 
>> 
>> David C
>> 
>> 
>> -----Original Message-----
>> From: BR_email [mailto:br at dmstat1.com] 
>> Sent: Friday, April 21, 2017 1:22 PM
>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>> 
>> David:
>> I tried somethings and got a little more working.
>> Now, I am struck at last line provided: "dec_mean    <- 
>> aggregate(Response ~ decc, dd, mean)"
>> Any help is appreciated.
>> Bruce
>> 
>> *****
>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>> 
>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>> str(ResponseX10)
>> 
>> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>> 
>> str(ResponseX10)
>> head(ResponseX10)
>> 
>> ResponseX10[[2]] <- NULL
>> ResponseX10 <- data.frame(ResponseX10)
>> str(ResponseX10)
>> 
>> cum_R    <- cumsum(Response)
>> cum_R
>> 
>> sam_size <- n

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Bruce.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170421/46dd8991/attachment.txt>

From Ted.Harding at wlandres.net  Fri Apr 21 23:03:43 2017
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Fri, 21 Apr 2017 22:03:43 +0100 (BST)
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <1e9710c8-5293-acac-ea92-cd8d63841de2@fredhutch.org>
Message-ID: <XFMail.20170421220343.Ted.Harding@wlandres.net>

I've been following this thread with interest. A nice
collection of things to watch out for, if you don't
want the small arithmetic errors due to finite-length
digital representations of fractions to cause trouble!

However, as well as these small discrepancies, major
malfunctions can also result.

Back on Dec 22, 2013, I posted a Christmas Greetings
message to R-help:

  Season's Greetings (and great news ... )!

which starts:

  Greetings All!
  With the Festive Season fast approaching, I bring you joy
  with the news (which you will surely wish to celebrate)
  that R cannot do arithmetic!

  Usually, this is manifest in a trivial way when users report
  puzzlement that, for instance,

    sqrt(pi)^2 == pi
    # [1] FALSE

  which is the result of a (generally trivial) rounding or
  truncation error:

     sqrt(pi)^2 - pi
    # [1] -4.440892e-16

  But for some very simple calculations R goes off its head.

And the example given is:

  Consider a sequence generated by the recurrence relation

    x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
    x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1

  (for 0 <= x[n] <= 1).

  This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
  and at x[n] = 2/3:

    2/3 -> 2*(1 - 2/3) = 2/3

  It also has periodic points, e.g.

    2/5 -> 4/5 -> 2/5 (period 2)
    2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)

  The recurrence relation can be implemented as the R function

    nextx <- function(x){
      if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
    }

  Now have a look at what happens when we start at the equilibrium
  point x = 2/3:

    N <- 1 ; x <- 2/3
    while(x > 0){
      cat(sprintf("%i: %.9f\n",N,x))
      x <- nextx(x) ; N <- N+1
    }
    cat(sprintf("%i: %.9f\n",N,x))

For a while [run it and see!], this looks as though it's doing what
the arithmetic would lead us to expect: the first 24 results will all
be printed as 0.666666667, which looks fine as 2/3 to 9 places.

But then the "little errors" start to creep in:

  N=25: 0.666666666
  N=28: 0.666666672 
  N=46: 0.667968750
  N=47: 0.664062500
  N=48: 0.671875000
  N=49: 0.656250000
  N=50: 0.687500000
  N=51: 0.625000000
  N=52: 0.750000000
  N=53: 0.500000000
  N=54: 1.000000000
  N=55: 0.000000000

  What is happening is that, each time R multiplies by 2, the binary
  representation is shifted up by one and a zero bit is introduced
  at the bottom end.

At N=53, the first binary bit of 'x' is 1, and all the rest are 0,
so now 'x' is exactly 0.5 = 1/2, hence the final two are also exact
results; 53 is the Machine$double.digits = 53 binary places.

So this normally "almost" trivial feature can, for such a simple
calculation, lead to chaos or catastrophe (in the literal technical
sense).

For more detail, including an extension of the above, look at the
original posting in the R-help archives for Dec 22, 2013:

  From: (Ted Harding) <Ted.Harding at wlandres.net>
  Subject: [R] Season's Greetings (and great news ... )!
  Date: Sun, 22 Dec 2013 09:59:16 -0000 (GMT)

(Apologies, but I couldn't track down the URL for this posting
in the R-help archives; there were a few follow-ups).

I gave this as an example to show that the results of the "little"
arithmetic errors (such as have recently been discussed from many
aspects) can, in certain contexts, destroy a computation.

So be careful to consider what can happen in the particular
context you are working with.

There are ways to dodge the issue -- such as using the R interface
to the 'bc' calculator, which computes arithmetic expressions in
a way which is quite different from the fixed-finite-length binary
representation and algorithms used, not only by R, but also by many
other numerical computation software suites

Best wishes to all,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 21-Apr-2017  Time: 22:03:15
This message was sent by XFMail


From br at dmstat1.com  Fri Apr 21 23:11:23 2017
From: br at dmstat1.com (BR_email)
Date: Fri, 21 Apr 2017 17:11:23 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>

David:
Its' not going my way today.
I'll try to work with all that you provided.
It's late Friday and I cannot impose on you much more.
Thank you.
If I may, after I rework it, I'll contact you, okay?
Have great weekend. And thanks, again.
Bruce
FYI: Below are where the error messages start:

R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not 
found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR, Cum_RespRate, 
Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, Cum_RespRate, 
Decile_RespRate) : object 'Decile_RespRate' not found R> R> R> R> avg_RR 
<- dec_mean_wt_R_nRD[10,7] Error: object 'dec_mean_wt_R_nRD' not found 
R> Cum_Lift <- (Cum_RespRate/avg_RR)*100 Error: object 'avg_RR' not 
found R> R> DECILE <- c("top","2","3","4","5","6","7","8","9","bot") R> 
R> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, 
Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not 
found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] 
Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> 
total_line<-cbind(DECILE="Total", + 
as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 
3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL' 
not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: 
object 'dec_mean_wt_R_nRDL' not found R> 
dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in 
rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' not 
found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 
'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 
'decile_table' not found R> R> #Install the xtable package: 
install.packages("xtable") R> #Load the xtable package: R> 
library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in 
xtable(decile_table) : object 'decile_table' not found R> DECILE_TABLE 
Error: object 'DECILE_TABLE' not found R> R> R> 
print.xtable(DECILE_TABLE, 
type="html",file="C:/R_Data/DecileTable.html", include.rownames=FALSE) 
Error in print.xtable(DECILE_TABLE, type = "html", file = 
"C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' not found

R>


Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

David L Carlson wrote:
> I've attached a modification of your script file (called .txt so it doesn't get stripped). See if this does what you want.
>
> David C
>
> -----Original Message-----
> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
> Sent: Friday, April 21, 2017 3:46 PM
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Looking for a package to replace xtable
>
> David:
> Correction: I do need a data frame because from the order Response column I create a data frame as per all my calculated columns, yielding the five column decile table.
> I used your latest corrections but something buggy is a happenin'.
>
> Bruce
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>
>> David:
>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
>> response variable.
>> I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original.
>> (I know this is viewed by some as unorthodox.)
>>
>> Your point: I only need Response as a column vector.
>> That said, what would you alter, please?
>> Thanks for your time.
>> Regards,
>> Bruce
>>
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>>
>>
>>
>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>
>>> You have an issue at the top with
>>>
>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>
>>> Since Response$yhat has not been defined at this point. Presumably you want
>>>
>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>
>>> The main issue is that you have a variable Response that is located in a data frame called ResponseX10.
>>>
>>> In creating cum_R you need
>>>
>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>
>>> then dec_mean
>>>
>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
>>>
>>> then dd
>>>
>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>
>>>
>>> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
>>>
>>> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
>>>
>>> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
>>>
>>>
>>> David C
>>>
>>>
>>> -----Original Message-----
>>> From: BR_email [mailto:br at dmstat1.com]
>>> Sent: Friday, April 21, 2017 1:22 PM
>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>> Subject: Re: [R] Looking for a package to replace xtable
>>>
>>> David:
>>> I tried somethings and got a little more working.
>>> Now, I am struck at last line provided: "dec_mean    <-
>>> aggregate(Response ~ decc, dd, mean)"
>>> Any help is appreciated.
>>> Bruce
>>>
>>> *****
>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>
>>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>>> str(ResponseX10)
>>>
>>> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>
>>> str(ResponseX10)
>>> head(ResponseX10)
>>>
>>> ResponseX10[[2]] <- NULL
>>> ResponseX10 <- data.frame(ResponseX10)
>>> str(ResponseX10)
>>>
>>> cum_R    <- cumsum(Response)
>>> cum_R
>>>
>>> sam_size <- n


From jdnewmil at dcn.davis.ca.us  Fri Apr 21 23:58:46 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 21 Apr 2017 14:58:46 -0700
Subject: [R] Wireframe plot inside a function
In-Reply-To: <CABie7_qWjq9SF0D=ga=ycRREXkQcjqVyUDooiNtCw13R7uYBHg@mail.gmail.com>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
 <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
 <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>
 <E12CA3D1-4D55-482C-B744-0D604C783F95@dcn.davis.ca.us>
 <CABie7_qWjq9SF0D=ga=ycRREXkQcjqVyUDooiNtCw13R7uYBHg@mail.gmail.com>
Message-ID: <00B5B4E3-DB83-4E4D-B6C2-1DD59B6225C1@dcn.davis.ca.us>

No... it is

print(plot(cop1, main = "cop1 function"))

-- 
Sent from my phone. Please excuse my brevity.

On April 21, 2017 1:56:00 PM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>I see. So, if I don't care about the plot object itself,  the proper
>incantation is
>
>plot(plot(cop1, main = "cop1 function"))
>
>Thanks again.
>
>On 21 April 2017 at 20:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> Your original function created the cop1 plot object but did nothing
>with it. It then created the cop2 plot and returned it from the
>function. Since you had invoked the cplot function from the interactive
>console, R printed that returned object automatically, which displayed
>the plot.
>>
>> FYI: when you want to start presenting multiple plots and/or tables
>together you will find that something like knitr and RMarkdown are very
>helpful.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 21, 2017 11:59:28 AM PDT, George Trojan - NOAA Federal
><george.trojan at noaa.gov> wrote:
>>>Thanks. After changing the function to
>>>
>>>cplot <- function(cop1, cop2) {
>>>  x11()
>>>  o <- plot(cop1, main = "cop1 function")
>>>  print(o)
>>>  x11()
>>>  o <- plot(cop2, main = "cop2 function")
>>>  print(o)
>>>}
>>>
>>>I see both plots. But, since "cop2 function" was plotted before, does
>>>it mean it is plotted twice now? Looks as a strange design.
>>>
>>>I did check the "Plain text mode" in Chrome, you should see only the
>>>text part.
>>>
>>>George
>>>
>>>On 21 April 2017 at 16:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>wrote:
>>>> FAQ 7.22
>>>> And don't send HTML email... you are the one making it difficult
>for
>>>us to read your question.
>>>>
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal
>>><george.trojan at noaa.gov> wrote:
>>>>>Consider the following example:
>>>>>
>>>>>library("kdecopula")
>>>>>library("mvtnorm")
>>>>>
>>>>>pobs <- function(x) rank(x) / (length(x) + 1)
>>>>>
>>>>>n <- 1000
>>>>>
>>>>>sigma1 <- diag(x = 1, 2, 2)
>>>>>x1 <- rmvnorm(n, sigma = sigma1)
>>>>>xx1 <- apply(x1, 2, pobs)
>>>>>cop1 <- kdecop(xx1)
>>>>>
>>>>>eps <- 0.8
>>>>>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>>>>>x2 <- rmvnorm(n, sigma = sigma2)
>>>>>xx2 <- apply(x2, 2, pobs)
>>>>>cop2 <- kdecop(xx2)
>>>>>
>>>>>x11()
>>>>>plot(cop1, main = "cop1 main")
>>>>>x11()
>>>>>plot(cop2, main = "cop2 main")
>>>>>
>>>>>cplot <- function(cop1, cop2) {
>>>>>  x11()
>>>>>  plot(cop1, main = "cop1 function")
>>>>>  x11()
>>>>>  plot(cop2, main = "cop2 function")
>>>>>}
>>>>>
>>>>>cplot(cop1, cop2)
>>>>>
>>>>>cat("Press <Enter> to quit")
>>>>>readLines(file("stdin"), n
>>>>>
>>>>>=
>>>>>
>>>>>1)
>>>>>quit()
>>>>>
>>>>>When I run it with Rscript all four x11 windows pop up, however the
>>>one
>>>>>that should display "cop1 function" is blank, the wireframe is not
>>>>>plotted.
>>>>>This is R 3.3.1, on Fedora 20.
>>>>>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code
>>>from
>>>>>RStudio (the most recent one).
>>>>>
>>>>>George
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Fri Apr 21 23:59:58 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 21 Apr 2017 14:59:58 -0700
Subject: [R] Maximum length for a -e argument to Rscript?
In-Reply-To: <E5624108-C367-4D36-85DC-BA81EA2CB21B@bigelow.org>
References: <8D391176-D58F-402F-BA49-3DCAAAEB5014@mac.com>
 <E5624108-C367-4D36-85DC-BA81EA2CB21B@bigelow.org>
Message-ID: <CAFDcVCTSUcguJDHfLoE4tt3e-LFUCUTZL9ZjQAqOTEuXdhFZqw@mail.gmail.com>

That Rscript stalls sounds like a bug, but not sure it's R or the
terminal that needs to be fixed:

  Rscript -e "$long_expression"
WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402
^C^C
^C
^C^C^C^C^C^C
^\Quit (core dumped)

On my default Ubuntu 16.04 terminal, R 3.3.3 hangs and does not
respond to user interrupts (SIGINT), but it does respond to Ctrl-\
(SIGKILL).

A workaround is to pass the expression via standard input to R, e.g.

$ echo "$long_expression" | R --no-save

/Henrik

On Fri, Apr 21, 2017 at 11:07 AM, Ben Tupper <btupper at bigelow.org> wrote:
> Hi,
>
> I suspect you are over the 10kb limit for the expression.  See
>
> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Invoking-R-from-the-command-line
>
> Cheers,
> Ben
>
>> On Apr 21, 2017, at 3:44 AM, Ben Haller <bhaller at mac.com> wrote:
>>
>>  Hi!  I?m attempting to use Rscript to do some automated plotting.  It is working well, except that I seem to be running into a maximum line length issue, and I?m wondering if it is a bug on your end.  Here?s an example of the command I?m trying to run:
>>
>> /usr/local/bin/Rscript -e '{x <- c(-1.31171, -0.686165, 1.62771, 0.320195, -0.322011, 1.66518, -0.271971, -0.665367, 0.516482, -0.716343, -0.317471, 0.068046, -0.100371, -1.15907, 0.263329, -0.936049, -0.852444, 0.358817, -0.233959, 0.209891, -0.831575, -0.952987, -0.0420206, -1.78527, -0.280584, -0.62353, 1.42597, 0.127994, 0.0751232, 0.896835, -0.319488, 0.897876, 0.18457, 0.779571, -0.0543194, 0.226722, -0.769983, -0.723463, 0.144386, -0.468544, -0.349417, 0.336786, 0.749212, -1.62397, 0.683075, -0.746449, 0.300921, -0.365468, 0.548271, 1.13169, -1.34042, -0.0740572, 1.34986, 0.531771, -0.147157, 0.824894, -1.05816, 1.58867, -0.885764, 1.11912, 0.361512, 1.77985, 0.585099, -1.205, 2.44134, -0.331372, -0.346322, 0.0535267, -1.75089, 0.0773243, -1.07846, -1.29632, 1.0622, 1.34867, 0.199777, 0.197516, 0.574185, 1.06555, -0.885166, -0.788576, -1.46061, -1.54026, 0.690576, -0.88821, 0.343747, -0.100751, -0.865596, -0.128504, 0.222334, -1.18932, -0.555258, -0.557368, 0.219272, 0.298858, 0.848022, 0.142608, 1.10082, -0.348039, 0.0566489, 0.662136, 0.50451, -0.909399, 1.02446, 1.40592, -0.114786, -1.10718, 2.02549, 0.0818607, -1.037, 1.18961, -0.204, 2.83165, -0.959653, -0.393082, -0.463351, 0.914054, 1.14472, -1.32927, 1.25416, 0.372267, 0.410832, 1.04187, 1.22288, 1.27131, 0.0949385, 0.194053, -0.226184, -0.502155, -1.36834, -0.000591861, -0.565903, 1.14099, 1.67811, 0.331709, -0.756879, 0.889596, 0.718098, 0.740242, -0.861818, 0.0332746, 1.01745, 0.584536, -1.14245, -0.444485, -1.34237, 0.660603, 1.16048, -0.898828, 0.965746, -1.16953, -2.33417, 0.591078, -0.364892, 0.0719267, -1.21676, 1.12646, 1.37534, 0.0712832, 1.22889, -0.0110024, 0.248213, -1.12013, -0.525197, -0.352156, -0.317182, -0.89552, 1.53422, -1.36777, 1.52099, 1.18789, -3.15251, 1.24008, -0.564289, -0.515629, -0.0920464, 2.94027, 0.895481, -0.157643, -0.347874, -0.290823, -0.771436, 1.29285, 0.216689, -1.86856, 2.24075, 0.888635, 0.430417, -0.585856, 1.13119, -0.243977, 0.544491, 0.921995, 0.815365, 1.2584, -1.29347, 0.0574579, 0.990557, -1.58657, -0.264373, 0.865893, 0.599298, -0.417531, 0.132897, 1.88597, 1.33112, -0.880904, 0.0762161, 0.0567852, 0.593295, -0.632135, 0.885625, 0.365863, -0.17885, 0.420185, -0.508275, 0.974357, 0.628085, 0.710578, 1.72447, 1.38488, 1.01301, 1.30015, 0.260501, 0.808981, 0.440228, 0.416344, -1.66273, -0.397224, -0.512086, -0.175854, -0.663143, 0.369712, -1.01654, 0.660465, 0.124851, -1.51101, -0.95725, 2.09893, 1.26819, 1.08086, 0.493204, 0.79073, 1.49191, 0.563689, 0.414473, 2.27361, 0.871923, 0.193703, -0.185039, -0.312859, -1.42267, -2.11561, 0.311996, -0.0906527, 1.19139, 1.57502, 1.10587, 0.416333, 2.35374, -1.0531, 0.0450512, 0.979958, 0.398269, 0.0897618, -0.855305, -1.59337, -0.084904, 0.245872, 1.27115, 1.3512, -0.166962, 1.01098, -1.19854, -2.05932, -0.98, 0.704973, 0.694688, 1.20408, -1.12553, 0.770056, 1.01602, 0.295223, -1.18801, 1.51707, 1.1418, -0.148787, 1.28886, 1.23981, 1.67984, 0.0185941, -0.877581, 0.495042, -0.368668, 1.59972, -2.20849, -1.36852, -0.972566, -1.01848, -0.366674, -2.60273, -0.540706, -0.475797, 0.227651, -1.11476, 1.73452, -0.212185, 3.04994, -0.251225, -0.0443482, -0.489125, 0.557936, -0.246389, -0.954287, 0.388668, 0.759049, -0.501683, -1.98722, 0.158712, -0.897082, -1.17644, 0.192465, -1.49901, -0.289129, -0.0460198, -0.520331, 0.432488, -0.471775, 1.21482, 0.998091, -0.794933, -0.36989, 0.937091, 1.27297, 1.06108, -0.784307, 0.70919, -0.309221, -0.516031, 0.479702, -0.669637, 1.60288, 0.657474, -0.666286, -1.01816, -0.452818, -0.283749, 1.05511, -1.2002, 0.112269, -1.37403, 1.00512, 0.664936, 0.600516, -1.08099, -0.705522, 0.103051, 0.0461179, 1.74404, 0.727475, 2.41175, 1.20414, 1.71095, 0.0957544, 0.610755, 0.545194, -0.936381, 0.190467, 0.485791, 0.0855697, 0.142676, 0.721754, -1.84506, 2.1227, -1.1271, -1.11228, -1.2807, 0.13385, 0.228727, -0.34391, 1.09837, -0.37053, 0.832574, 0.673463, 0.717732, -0.307687, 1.12486, 0.159803, -1.51251, 1.403, 2.0215, 0.010914, -0.543749, 0.137119, 0.200364, -0.104029, -0.930966, -1.56781, -0.526978, -0.537582, 1.11872, -0.99061, -0.501421, 1.21982, 0.813201, -0.539109, 0.433523, -0.0615188, 2.04298, 0.697692, 1.34515, 1.7298, 0.515137, 2.08119, 0.550985, 1.49876, 1.31187, 0.920405, 0.597678, 0.884353, -0.732892, -0.143545, -0.236836, -0.330872, 1.55577, -1.74473, -0.493322, 1.46375, 1.14347, 1.76164, 1.73099, -0.234701, -0.0546848, 0.346991, -0.393301, 1.34267, -1.58519, -0.381789, 0.622675, 1.34655, 2.84895, -0.371, -0.519666, -1.64944, 0.573592, 1.06484, -0.0239894, -0.604563, 0.0680641, -0.881325, 1.07265, 0.182585, 0.373288, 2.20228, -0.763593, -0.25659, 1.9397, -0.166943, -0.672522, -1.35983, 0.227406, 0.49471, -1.23535, -0.479552, 1.97798, 0.418181, 1.23454, -0.0767748, 0.828642, -0.0348468, -0.264499, 0.76699, -0.910363, -2.11408, -0.209169, 0.902191, -2.27096, 0.098513, -0.380699, -0.231276, -0.0296834, 0.834972, -0.658283, 0.616493, 0.198916, -1.89783, -1.30219, 0.51036, 0.195825, -1.68961, -1.27838, 0.879616, 0.566719, 1.21876, 0.270402, -1.38261, 0.365878, 1.54191, 1.25104, 1.23067, 1.87261);y <- c(0.986442, 2.65684, -1.79726, 1.79999, -2.43971, -1.68358, -1.84081, -2.27973, 2.96046, 2.61837, 1.48756, 1.63497, 1.46876, 2.09348, -0.925101, 3.6792, -2.03618, 1.33232, -0.0652269, 0.809911, -2.82019, -1.87691, 1.1284, 0.249619, -2.94777, 3.00423, -2.79901, -0.110801, -3.546, 1.67156, -3.10723, -3.24205, 3.16911, -3.24227, -1.29801, 0.271933, -2.83573, -0.79973, -2.34429, -0.905163, -0.197905, -3.05664, -0.694481, 1.89301, -2.70264, 2.94361, -2.32469, 1.9576, 1.73556, -3.29777, -1.54311, -2.03172, -0.871756, 0.77581, 3.7692, 1.54446, 3.92129, 0.160296, -3.45486, -1.56317, -2.72913, 0.695854, 3.15786, 1.1006, 3.25649, -1.57206, -3.15353, 0.242301, -1.95855, -0.256919, 3.04782, -0.505045, -2.35542, 2.11649, -1.73363, 2.65149, 3.66302, 0.457907, -2.2759, -2.36105, -2.49263, -2.9784, -3.53525, -0.699404, 3.17647, -1.52424, 2.72699, 3.82774, 0.100029, 3.42107, 1.74672, 3.1279, -0.793162, -0.025109, 1.07262, 2.4517, -2.00605, -3.6625, -2.57031, -2.43599, 2.56309, -1.31707, -2.10777, -3.75394, 0.954311, 0.496025, 3.82545, -3.74259, -1.96145, 0.366455, 3.97474, 3.26111, -3.69904, 2.07392, 0.591191, -3.34162, -0.926126, 1.03966, -2.68754, -2.69653, 0.651845, 2.82333, 2.25596, 3.26545, -2.57379, 2.69137, -3.08119, 2.99114, -3.86005, -1.30995, 1.80096, 1.39404, -2.6482, -2.12922, -3.28834, -1.06563, -1.6683, -2.023, 1.60516, -1.67431, 1.38595, 0.287423, 2.56888, -2.99169, 0.549401, 2.31817, -2.48251, 2.20152, 1.0531, -3.60478, 0.327999, 0.475523, -0.454324, -2.63147, -1.61249, -1.65507, 1.13203, 0.218, 2.87289, -0.279036, -0.316795, 3.22757, -2.25, -1.10923, 0.0949814, -2.60818, -0.181803, 3.65484, 2.86193, 0.940815, 3.5461, 1.23983, 2.01177, -0.428626, 3.5539, -2.63454, 1.63098, 3.69696, 0.404995, 0.480342, 3.22724, -3.57127, -2.38176, -1.23267, 0.738668, 1.64966, 1.37331, -2.60132, -1.60081, 2.57359, -3.58266, 1.32347, 3.24265, 3.81, 3.90706, -0.407994, 2.42083, 3.34477, 3.43151, -1.08974, -2.93732, 2.39014, -1.36511, -0.101514, -1.46445, 2.11849, -3.63955, -1.57038, 3.41777, -1.00185, -0.0702487, 2.01317, -3.38133, 3.64754, -0.740182, -3.64028, -3.77238, 2.45613, -3.11631, 3.82543, 2.15285, -0.790691, -1.22153, -0.943069, -3.37327, 1.19097, 1.48834, 0.502127, -2.90383, -3.4236, -0.676889, 3.41785, 2.54728, -2.60006, -3.25969, -1.85346, -2.8088, 3.3905, -1.34015, -1.3877, 2.38485, 3.16688, -3.26326, -1.94801, 0.0878641, 0.492529, 2.62313, -2.08994, -1.77721, 1.92357, 0.739532, 0.869021, -3.82981, 3.92422, -1.16293, 3.82139, -1.67119, 1.1145, -2.24382, -1.93777, -0.109559, -0.350947, 1.94832, -2.54192, 1.224, 0.797731, 0.767982, -2.93565, -2.72896, 1.2624, 1.91513, -3.96412, 3.43534, 0.358804, 3.05541, -0.213663, 0.38204, -0.539063, -0.897154, -2.91298, -0.198784, -0.0732228, 2.99983, 3.54078, 2.27245, 3.87904, 2.99445, -0.705307, 0.187173, 1.79102, 1.69581, 2.08613, 1.54021, 0.7471, -1.19008, 2.44732, -1.59312, 1.5387, -0.526756, 3.06958, -1.707, -2.46148, -0.523427, -0.675584, -3.02611, -2.22116, -3.4546, -2.94353, 2.1346, 3.51197, 1.85137, 1.7461, -0.875901, -2.13891, -2.1714, 1.6953, -0.159958, 1.77583, -0.808156, 2.04446, 3.58507, -1.27303, -0.0739294, 0.22885, -1.16883, -0.0437807, -1.30141, 2.71702, 2.85379, 3.74969, 3.5839, -0.159889, -0.236555, 2.78411, 2.15217, -0.945737, -1.90692, 0.536403, -1.08419, -3.75986, 2.65243, -2.29661, 3.8776, 1.23146, -2.26545, 2.79205, 2.34152, -3.62388, -3.51983, -0.152083, -0.77672, -0.0661756, -1.12531, 1.77691, -1.49266, -0.401453, -2.98782, 1.15182, 3.00211, -0.338523, 2.63385, -1.30166, -1.96304, -2.03665, -2.91373, 3.33512, 0.26508, -2.4008, -0.989122, -1.96516, 0.498154, -0.139963, 1.762, -0.36494, 2.42886, 1.26076, -0.344707, -2.2629, 3.01517, -0.192693, 1.72579, -3.09541, 0.898774, -3.33187, -2.09473, 2.13997, -1.20736, -1.78102, 0.661333, -2.15738, -2.82721, -0.34423, 0.945198, -1.3919, 2.24165, -1.72333, -3.61333, 0.177856, -0.499845, 1.08322, -0.57797, 1.32396, -0.580476, -0.990233, 3.13608, 0.2254, 2.44513, -1.43021, -2.20293, -0.0295935, 3.9359, 0.872028, 2.94495, 2.3334, -1.4539, -2.0155, 1.90474, -1.83284, -3.6983, -0.223583, -2.19197, 2.98892, 2.11877, -0.614374, 0.860207, 3.63726, -1.54793, 0.699044, -3.31199, -2.87789, 3.21311, -3.24507, -0.0689166, 0.225146, -2.84127, -3.67944, 0.763724, -3.93721, -3.81518, -1.06853, 0.726999, 0.562243, 3.79879, 3.75762, 2.1455, 2.00329, -0.400098, -1.80113, 3.49374, 3.26726, -1.24347, 2.0535, 2.55697, 0.670452, -2.79004, 1.39668, 2.32366, -2.27311, -0.352436, -2.71256, -2.31389, -2.11829, 0.111656, -1.67798, 2.97944, -3.7505, -1.88802, 3.50199, 1.31453, 3.32241, -1.04754, -3.03124, 1.60895, 1.15746, 2.29443, 3.31704, -0.172815, 2.81695, 0.253896, 0.298466, -3.90939, -2.39831, 3.46711, 2.41166, 2.03439, 0.387814, -3.40236, -3.71227, -1.68499, -3.81028, 2.97335, 3.32693, -3.88281, -2.61789, -3.31616, 2.71789, 3.05144, -0.579528, -0.672907, 2.75653);quartz(width=4, height=4, type="pdf", file="~/Desktop/testpdf.pdf");plot(x=x, y=y, xlim=c(-5, 5), ylim=c(-5, 5), pch=19, cex=0.5, main="2000");dev.off();}?
>>
>>  If I execute the R code that is in the -e argument directly in R GUI (on OS X) it works fine.  And if I put that code in a file and run Rscript <file>, it works fine.  So the length limit is not intrinsic to R?s parser, it would seem.  But if I try to execute exactly the same code in an interactive R session in my Unix terminal's command line, I get a continuation prompt, +, and a little investigation indicates that the input line may have been truncated after 3843 characters (a strange number) and it is waiting for more input to follow that truncated input.  And ? what is most relevant for my situation ? if I try to run the full Rscript command as given above (inside /bin/sh), it prints out:
>>
>> WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402
>>
>> and then it hangs ? the full warning doesn?t complete printing, so it is not clear what it is trying to warn about.  That represents 844 characters of input script, but with the weird way that spaces have been replaced by ~+~ by somebody, it is 1013 characters ? suspiciously close to 1024.
>>
>>  Note that if I simply make the R script shorter, by plotting 100 x/y values instead of 500, everything works fine.  So there is no issue with the way that I?m quoting strings or anything like that; the only issue seems to be the total length of the command line.
>>
>>  Now of course I could break up the script into multiple chunks, passed via separate -e arguments, and perhaps that would work somewhat better.  But given that I want to set up a vector x with a single c() command containing all of the data for x, I will still hit a line length limit; the single line of code to set up x will already be over the maximum line length that Rscript allows for a -e argument, apparently.  Getting around that would obviously be possible too, but would be considerably more hassle.
>>
>>  And incidentally, this seems to have nothing to do with the /bin/sh input line limit; that is much higher.  According to "getconf ARG_MAX?, it is 262144 characters on my machine, which is more than enough headroom for what I?m trying to do.
>>
>>  So my questions are: (1) is this a bug, (2) if so, do you think you are likely to fix it any time soon :->, and (3) if the answer to that is no, are there any standard workarounds for this sort of situation that you would recommend?  I suppose I could write out the script to a file and then execute that file with Rscript, since that seems to work; but I was really hoping to avoid that extra complication and overhead.  Is there a better way?
>>
>>  Thanks for any help you can provide!  :->
>>
>> Cheers,
>> -B.
>>
>> Benjamin C. Haller
>> Messer Lab
>> Cornell University
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From george.trojan at noaa.gov  Sat Apr 22 00:45:54 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Fri, 21 Apr 2017 22:45:54 +0000
Subject: [R] Wireframe plot inside a function
In-Reply-To: <00B5B4E3-DB83-4E4D-B6C2-1DD59B6225C1@dcn.davis.ca.us>
References: <CABie7_qe4EU9L-LnrV-gJE-ig5ncOcO-jiPTjsSHAOX_35A21g@mail.gmail.com>
 <A57C3569-722F-4A5E-9CB0-00F9311FB4F0@dcn.davis.ca.us>
 <CABie7_pt4XC_6CvTM3Bqus=Vf2vWW4LOv9bYBR6qW+sRNMHKaA@mail.gmail.com>
 <E12CA3D1-4D55-482C-B744-0D604C783F95@dcn.davis.ca.us>
 <CABie7_qWjq9SF0D=ga=ycRREXkQcjqVyUDooiNtCw13R7uYBHg@mail.gmail.com>
 <00B5B4E3-DB83-4E4D-B6C2-1DD59B6225C1@dcn.davis.ca.us>
Message-ID: <CABie7_q1yEZPYuLCXhGbTKOhfK-xe7ygsCDNabMyC4M2W5RMkA@mail.gmail.com>

But it works ;-). According to print.trellis help, 'plot' is an alias
for 'print'.

IMO, this is an abuse of overloading: same method name does totally
different things.

On 21 April 2017 at 21:58, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> No... it is
>
> print(plot(cop1, main = "cop1 function"))
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 21, 2017 1:56:00 PM PDT, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
>>I see. So, if I don't care about the plot object itself,  the proper
>>incantation is
>>
>>plot(plot(cop1, main = "cop1 function"))
>>
>>Thanks again.
>>
>>On 21 April 2017 at 20:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>wrote:
>>> Your original function created the cop1 plot object but did nothing
>>with it. It then created the cop2 plot and returned it from the
>>function. Since you had invoked the cplot function from the interactive
>>console, R printed that returned object automatically, which displayed
>>the plot.
>>>
>>> FYI: when you want to start presenting multiple plots and/or tables
>>together you will find that something like knitr and RMarkdown are very
>>helpful.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 21, 2017 11:59:28 AM PDT, George Trojan - NOAA Federal
>><george.trojan at noaa.gov> wrote:
>>>>Thanks. After changing the function to
>>>>
>>>>cplot <- function(cop1, cop2) {
>>>>  x11()
>>>>  o <- plot(cop1, main = "cop1 function")
>>>>  print(o)
>>>>  x11()
>>>>  o <- plot(cop2, main = "cop2 function")
>>>>  print(o)
>>>>}
>>>>
>>>>I see both plots. But, since "cop2 function" was plotted before, does
>>>>it mean it is plotted twice now? Looks as a strange design.
>>>>
>>>>I did check the "Plain text mode" in Chrome, you should see only the
>>>>text part.
>>>>
>>>>George
>>>>
>>>>On 21 April 2017 at 16:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>wrote:
>>>>> FAQ 7.22
>>>>> And don't send HTML email... you are the one making it difficult
>>for
>>>>us to read your question.
>>>>>
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On April 21, 2017 8:27:20 AM PDT, George Trojan - NOAA Federal
>>>><george.trojan at noaa.gov> wrote:
>>>>>>Consider the following example:
>>>>>>
>>>>>>library("kdecopula")
>>>>>>library("mvtnorm")
>>>>>>
>>>>>>pobs <- function(x) rank(x) / (length(x) + 1)
>>>>>>
>>>>>>n <- 1000
>>>>>>
>>>>>>sigma1 <- diag(x = 1, 2, 2)
>>>>>>x1 <- rmvnorm(n, sigma = sigma1)
>>>>>>xx1 <- apply(x1, 2, pobs)
>>>>>>cop1 <- kdecop(xx1)
>>>>>>
>>>>>>eps <- 0.8
>>>>>>sigma2 <- matrix(c(1, eps, eps, 1), ncol = 2)
>>>>>>x2 <- rmvnorm(n, sigma = sigma2)
>>>>>>xx2 <- apply(x2, 2, pobs)
>>>>>>cop2 <- kdecop(xx2)
>>>>>>
>>>>>>x11()
>>>>>>plot(cop1, main = "cop1 main")
>>>>>>x11()
>>>>>>plot(cop2, main = "cop2 main")
>>>>>>
>>>>>>cplot <- function(cop1, cop2) {
>>>>>>  x11()
>>>>>>  plot(cop1, main = "cop1 function")
>>>>>>  x11()
>>>>>>  plot(cop2, main = "cop2 function")
>>>>>>}
>>>>>>
>>>>>>cplot(cop1, cop2)
>>>>>>
>>>>>>cat("Press <Enter> to quit")
>>>>>>readLines(file("stdin"), n
>>>>>>
>>>>>>=
>>>>>>
>>>>>>1)
>>>>>>quit()
>>>>>>
>>>>>>When I run it with Rscript all four x11 windows pop up, however the
>>>>one
>>>>>>that should display "cop1 function" is blank, the wireframe is not
>>>>>>plotted.
>>>>>>This is R 3.3.1, on Fedora 20.
>>>>>>I see similar behaviour on Fedora 24, R 3.3.3 when I run the code
>>>>from
>>>>>>RStudio (the most recent one).
>>>>>>
>>>>>>George
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>>______________________________________________
>>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>PLEASE do read the posting guide
>>>>>>http://www.R-project.org/posting-guide.html
>>>>>>and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Sat Apr 22 01:57:07 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 21 Apr 2017 16:57:07 -0700
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <XFMail.20170421220343.Ted.Harding@wlandres.net>
References: <XFMail.20170421220343.Ted.Harding@wlandres.net>
Message-ID: <7a4357af-c580-6a56-c086-d4532f442220@fredhutch.org>

On 04/21/2017 02:03 PM, (Ted Harding) wrote:
> I've been following this thread with interest. A nice
> collection of things to watch out for, if you don't
> want the small arithmetic errors due to finite-length
> digital representations of fractions to cause trouble!
>
> However, as well as these small discrepancies, major
> malfunctions can also result.
>
> Back on Dec 22, 2013, I posted a Christmas Greetings
> message to R-help:
>
>   Season's Greetings (and great news ... )!
>
> which starts:
>
>   Greetings All!
>   With the Festive Season fast approaching, I bring you joy
>   with the news (which you will surely wish to celebrate)
>   that R cannot do arithmetic!
>
>   Usually, this is manifest in a trivial way when users report
>   puzzlement that, for instance,
>
>     sqrt(pi)^2 == pi
>     # [1] FALSE
>
>   which is the result of a (generally trivial) rounding or
>   truncation error:
>
>      sqrt(pi)^2 - pi
>     # [1] -4.440892e-16
>
>   But for some very simple calculations R goes off its head.
>
> And the example given is:
>
>   Consider a sequence generated by the recurrence relation
>
>     x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
>     x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1
>
>   (for 0 <= x[n] <= 1).
>
>   This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
>   and at x[n] = 2/3:
>
>     2/3 -> 2*(1 - 2/3) = 2/3
>
>   It also has periodic points, e.g.
>
>     2/5 -> 4/5 -> 2/5 (period 2)
>     2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)
>
>   The recurrence relation can be implemented as the R function
>
>     nextx <- function(x){
>       if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
>     }
>
>   Now have a look at what happens when we start at the equilibrium
>   point x = 2/3:
>
>     N <- 1 ; x <- 2/3
>     while(x > 0){
>       cat(sprintf("%i: %.9f\n",N,x))
>       x <- nextx(x) ; N <- N+1
>     }
>     cat(sprintf("%i: %.9f\n",N,x))
>
> For a while [run it and see!], this looks as though it's doing what
> the arithmetic would lead us to expect: the first 24 results will all
> be printed as 0.666666667, which looks fine as 2/3 to 9 places.
>
> But then the "little errors" start to creep in:
>
>   N=25: 0.666666666
>   N=28: 0.666666672
>   N=46: 0.667968750
>   N=47: 0.664062500
>   N=48: 0.671875000
>   N=49: 0.656250000
>   N=50: 0.687500000
>   N=51: 0.625000000
>   N=52: 0.750000000
>   N=53: 0.500000000
>   N=54: 1.000000000
>   N=55: 0.000000000
>
>   What is happening is that, each time R multiplies by 2, the binary
>   representation is shifted up by one and a zero bit is introduced
>   at the bottom end.
>
> At N=53, the first binary bit of 'x' is 1, and all the rest are 0,
> so now 'x' is exactly 0.5 = 1/2, hence the final two are also exact
> results; 53 is the Machine$double.digits = 53 binary places.
>
> So this normally "almost" trivial feature can, for such a simple
> calculation, lead to chaos or catastrophe (in the literal technical
> sense).

The only surprise is to end up at the other equilibrium point (0),
not that the iterations didn't stabilize around or converge to
equilibrium point 2/3. That's because:

   1) You didn't start *exactly* at equilibrium point 2/3

   2) The iterating process is not supposed to converge but to diverge
      from the equilibrium point. It's its mathematical nature and has
      nothing to do with rounding errors.

So if you don't start exactly at 2/3, the iterations will take you
further apart, even on a hypothetical computer that uses exact
representation of any arbitrary real number (i.e. no rounding errors).
With such an instable algorithm, all bets are off: you can end up
to the other equilibrium point or not end up anywhere (chaos) or
hit a periodic point and go in cycles from there.

But hey, shouldn't people examine the mathematical properties of
their iterative numerical algorithms before implementing them? Like
convergence, stability etc...

H.

>
> For more detail, including an extension of the above, look at the
> original posting in the R-help archives for Dec 22, 2013:
>
>   From: (Ted Harding) <Ted.Harding at wlandres.net>
>   Subject: [R] Season's Greetings (and great news ... )!
>   Date: Sun, 22 Dec 2013 09:59:16 -0000 (GMT)
>
> (Apologies, but I couldn't track down the URL for this posting
> in the R-help archives; there were a few follow-ups).
>
> I gave this as an example to show that the results of the "little"
> arithmetic errors (such as have recently been discussed from many
> aspects) can, in certain contexts, destroy a computation.
>
> So be careful to consider what can happen in the particular
> context you are working with.
>
> There are ways to dodge the issue -- such as using the R interface
> to the 'bc' calculator, which computes arithmetic expressions in
> a way which is quite different from the fixed-finite-length binary
> representation and algorithms used, not only by R, but also by many
> other numerical computation software suites
>
> Best wishes to all,
> Ted.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 21-Apr-2017  Time: 22:03:15
> This message was sent by XFMail
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=ILkgA-W4NkL_PpalU1VtS9iO60moznxYVBGfU5QbyNw&s=puQK7QZvG7lZuOYvo9D6UANEgWylkApF-xIvpLMGVhQ&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=ILkgA-W4NkL_PpalU1VtS9iO60moznxYVBGfU5QbyNw&s=zohn8q-ufE7UhlQDQGc3KP-lsbM4O62SzwBXQ4S7I0g&e=
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From edwardsmolina at gmail.com  Fri Apr 21 20:57:46 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Fri, 21 Apr 2017 15:57:46 -0300
Subject: [R] GLMM for Combined experiments and overdispersed data
Message-ID: <CAF5W3aR8qvjUmJEFsnS3CMSTLsbbpukUKbZHc=ffRY7NarSvew@mail.gmail.com>

I am analyzing data from 3 field experiments (farms=3) for a citrus flower
disease: response variable is binomial because the flower can only be
diseased or healthy.

I have particular interest in comparing 5 fungicide spraying systems
(trt=5).

Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
which I assessed 100 flowers each one. This is a quick look of the data:

farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
<fctr> <int> <int>
iaras      cal      1      1     0    100
iaras      cal      1      2     1    100
iaras      cal      2      1     1    100
iaras      cal      2      2     3    100
iaras      cal      3      1     0    100
iaras      cal      3      2     5    100...

The model I considered was:

resp <- with(df, cbind(dis, tot-dis))

m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)

I tested the overdispersion with the overdisp_fun() from GLMM page
<http://glmm.wikidot.com/faq>

        chisq         ratio             p          logp
 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01

As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
considered to add the observation level random effect (link
<http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html>)
to deal with the overdispersion.

farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
<fctr> <fctr> <int> <int> <fctr>
iaras      cal      1      1     0    100    1
iaras      cal      1      2     1    100    2
iaras      cal      2      1     1    100    3...

so now was added a random effect for each row (tree_id) to the model, but I
am not sure of how to include it. This is my approach:

m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial, data=df)

I also wonder if farm should be a fixed effect, since it has only 3
levels...

m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
binomial, data=df)

I really appreciate your suggestions about my model specifications...




*Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
- ESALQ-USP/Brazil?*

	[[alternative HTML version deleted]]


From rbarnes at umn.edu  Fri Apr 21 21:41:25 2017
From: rbarnes at umn.edu (Richard Barnes)
Date: Fri, 21 Apr 2017 12:41:25 -0700
Subject: [R] CRAN and Github: Licensing Issues
Message-ID: <d48fa27d-228f-93b2-6f16-233d3b781fe9@umn.edu>

I have an R package who's code I'd like to keep on Github.

In accordance with R's requirements (see here for a note about template
licenses), I have in my DESCRIPTION file the line:
> License: MIT + file LICENCE
And my LICENCE file contains the MIT template, as required:
> YEAR: 2017
> COPYRIGHT HOLDER: Don Quixote
Github used to figure out licensing only by looking at the LICENSE file,
which allowed me to keep the MIT text in LICENSE so that Github would
detect it and the CRAN template in LICENCE so that CRAN would detect it.

But now, a darkness has fallen on the land: Github looks at both LICENSE
and LICENCE. Finding them different, it abandons its attempt to
determine the project's license.

Renaming my CRAN license template file from `LICENCE` to
`LICENCE.template` would fix the issue, but then CRAN complains about a
non-standard file.

As a result, it does not seem possible to use the MIT license in a way
which satisfies both CRAN and Github.

(I feel CRAN is at fault here by using a standardized file name
(LICENCE/LICENSE) for a non-standard purpose: templating.)

Is there a workaround (beyond relicensing to GPL, which is not a CRAN
template license)?

Thanks,
Richard


From bhaller at mac.com  Sat Apr 22 00:04:27 2017
From: bhaller at mac.com (Ben Haller)
Date: Sat, 22 Apr 2017 07:04:27 +0900
Subject: [R] Maximum length for a -e argument to Rscript?
In-Reply-To: <CAFDcVCTSUcguJDHfLoE4tt3e-LFUCUTZL9ZjQAqOTEuXdhFZqw@mail.gmail.com>
References: <8D391176-D58F-402F-BA49-3DCAAAEB5014@mac.com>
 <E5624108-C367-4D36-85DC-BA81EA2CB21B@bigelow.org>
 <CAFDcVCTSUcguJDHfLoE4tt3e-LFUCUTZL9ZjQAqOTEuXdhFZqw@mail.gmail.com>
Message-ID: <B90BEB0E-7D44-48C8-ADF1-E9AD00AA0459@mac.com>

  OK, thanks for the information Ben and Henrik.  It sounds like even if the Rscript stall were fixed, there would still be a 10k limit when using -e, as well as a 4K maximum line length limit when using -e or stdin, if I understand the section cited by Ben; so I need to switch to using a script file instead, to get past these various limits, I guess.  Thanks for your help.

Cheers,
-B.

Benjamin C. Haller
Messer Lab
Cornell University


> On Apr 22, 2017, at 6:59 AM, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> That Rscript stalls sounds like a bug, but not sure it's R or the
> terminal that needs to be fixed:
> 
>  Rscript -e "$long_expression"
> WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402
> ^C^C
> ^C
> ^C^C^C^C^C^C
> ^\Quit (core dumped)
> 
> On my default Ubuntu 16.04 terminal, R 3.3.3 hangs and does not
> respond to user interrupts (SIGINT), but it does respond to Ctrl-\
> (SIGKILL).
> 
> A workaround is to pass the expression via standard input to R, e.g.
> 
> $ echo "$long_expression" | R --no-save
> 
> /Henrik
> 
> On Fri, Apr 21, 2017 at 11:07 AM, Ben Tupper <btupper at bigelow.org> wrote:
>> Hi,
>> 
>> I suspect you are over the 10kb limit for the expression.  See
>> 
>> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Invoking-R-from-the-command-line
>> 
>> Cheers,
>> Ben
>> 
>>> On Apr 21, 2017, at 3:44 AM, Ben Haller <bhaller at mac.com> wrote:
>>> 
>>> Hi!  I?m attempting to use Rscript to do some automated plotting.  It is working well, except that I seem to be running into a maximum line length issue, and I?m wondering if it is a bug on your end.  Here?s an example of the command I?m trying to run:
>>> 
>>> /usr/local/bin/Rscript -e '{x <- c(-1.31171, -0.686165, 1.62771, 0.320195, -0.322011, 1.66518, -0.271971, -0.665367, 0.516482, -0.716343, -0.317471, 0.068046, -0.100371, -1.15907, 0.263329, -0.936049, -0.852444, 0.358817, -0.233959, 0.209891, -0.831575, -0.952987, -0.0420206, -1.78527, -0.280584, -0.62353, 1.42597, 0.127994, 0.0751232, 0.896835, -0.319488, 0.897876, 0.18457, 0.779571, -0.0543194, 0.226722, -0.769983, -0.723463, 0.144386, -0.468544, -0.349417, 0.336786, 0.749212, -1.62397, 0.683075, -0.746449, 0.300921, -0.365468, 0.548271, 1.13169, -1.34042, -0.0740572, 1.34986, 0.531771, -0.147157, 0.824894, -1.05816, 1.58867, -0.885764, 1.11912, 0.361512, 1.77985, 0.585099, -1.205, 2.44134, -0.331372, -0.346322, 0.0535267, -1.75089, 0.0773243, -1.07846, -1.29632, 1.0622, 1.34867, 0.199777, 0.197516, 0.574185, 1.06555, -0.885166, -0.788576, -1.46061, -1.54026, 0.690576, -0.88821, 0.343747, -0.100751, -0.865596, -0.128504, 0.222334, -1.18932, -0.555258, -0.557368, 0.219272, 0.298858, 0.848022, 0.142608, 1.10082, -0.348039, 0.0566489, 0.662136, 0.50451, -0.909399, 1.02446, 1.40592, -0.114786, -1.10718, 2.02549, 0.0818607, -1.037, 1.18961, -0.204, 2.83165, -0.959653, -0.393082, -0.463351, 0.914054, 1.14472, -1.32927, 1.25416, 0.372267, 0.410832, 1.04187, 1.22288, 1.27131, 0.0949385, 0.194053, -0.226184, -0.502155, -1.36834, -0.000591861, -0.565903, 1.14099, 1.67811, 0.331709, -0.756879, 0.889596, 0.718098, 0.740242, -0.861818, 0.0332746, 1.01745, 0.584536, -1.14245, -0.444485, -1.34237, 0.660603, 1.16048, -0.898828, 0.965746, -1.16953, -2.33417, 0.591078, -0.364892, 0.0719267, -1.21676, 1.12646, 1.37534, 0.0712832, 1.22889, -0.0110024, 0.248213, -1.12013, -0.525197, -0.352156, -0.317182, -0.89552, 1.53422, -1.36777, 1.52099, 1.18789, -3.15251, 1.24008, -0.564289, -0.515629, -0.0920464, 2.94027, 0.895481, -0.157643, -0.347874, -0.290823, -0.771436, 1.29285, 0.216689, -1.86856, 2.24075, 0.888635, 0.430417, -0.585856, 1.13119, -0.243977, 0.544491, 0.921995, 0.815365, 1.2584, -1.29347, 0.0574579, 0.990557, -1.58657, -0.264373, 0.865893, 0.599298, -0.417531, 0.132897, 1.88597, 1.33112, -0.880904, 0.0762161, 0.0567852, 0.593295, -0.632135, 0.885625, 0.365863, -0.17885, 0.420185, -0.508275, 0.974357, 0.628085, 0.710578, 1.72447, 1.38488, 1.01301, 1.30015, 0.260501, 0.808981, 0.440228, 0.416344, -1.66273, -0.397224, -0.512086, -0.175854, -0.663143, 0.369712, -1.01654, 0.660465, 0.124851, -1.51101, -0.95725, 2.09893, 1.26819, 1.08086, 0.493204, 0.79073, 1.49191, 0.563689, 0.414473, 2.27361, 0.871923, 0.193703, -0.185039, -0.312859, -1.42267, -2.11561, 0.311996, -0.0906527, 1.19139, 1.57502, 1.10587, 0.416333, 2.35374, -1.0531, 0.0450512, 0.979958, 0.398269, 0.0897618, -0.855305, -1.59337, -0.084904, 0.245872, 1.27115, 1.3512, -0.166962, 1.01098, -1.19854, -2.05932, -0.98, 0.704973, 0.694688, 1.20408, -1.12553, 0.770056, 1.01602, 0.295223, -1.18801, 1.51707, 1.1418, -0.148787, 1.28886, 1.23981, 1.67984, 0.0185941, -0.877581, 0.495042, -0.368668, 1.59972, -2.20849, -1.36852, -0.972566, -1.01848, -0.366674, -2.60273, -0.540706, -0.475797, 0.227651, -1.11476, 1.73452, -0.212185, 3.04994, -0.251225, -0.0443482, -0.489125, 0.557936, -0.246389, -0.954287, 0.388668, 0.759049, -0.501683, -1.98722, 0.158712, -0.897082, -1.17644, 0.192465, -1.49901, -0.289129, -0.0460198, -0.520331, 0.432488, -0.471775, 1.21482, 0.998091, -0.794933, -0.36989, 0.937091, 1.27297, 1.06108, -0.784307, 0.70919, -0.309221, -0.516031, 0.479702, -0.669637, 1.60288, 0.657474, -0.666286, -1.01816, -0.452818, -0.283749, 1.05511, -1.2002, 0.112269, -1.37403, 1.00512, 0.664936, 0.600516, -1.08099, -0.705522, 0.103051, 0.0461179, 1.74404, 0.727475, 2.41175, 1.20414, 1.71095, 0.0957544, 0.610755, 0.545194, -0.936381, 0.190467, 0.485791, 0.0855697, 0.142676, 0.721754, -1.84506, 2.1227, -1.1271, -1.11228, -1.2807, 0.13385, 0.228727, -0.34391, 1.09837, -0.37053, 0.832574, 0.673463, 0.717732, -0.307687, 1.12486, 0.159803, -1.51251, 1.403, 2.0215, 0.010914, -0.543749, 0.137119, 0.200364, -0.104029, -0.930966, -1.56781, -0.526978, -0.537582, 1.11872, -0.99061, -0.501421, 1.21982, 0.813201, -0.539109, 0.433523, -0.0615188, 2.04298, 0.697692, 1.34515, 1.7298, 0.515137, 2.08119, 0.550985, 1.49876, 1.31187, 0.920405, 0.597678, 0.884353, -0.732892, -0.143545, -0.236836, -0.330872, 1.55577, -1.74473, -0.493322, 1.46375, 1.14347, 1.76164, 1.73099, -0.234701, -0.0546848, 0.346991, -0.393301, 1.34267, -1.58519, -0.381789, 0.622675, 1.34655, 2.84895, -0.371, -0.519666, -1.64944, 0.573592, 1.06484, -0.0239894, -0.604563, 0.0680641, -0.881325, 1.07265, 0.182585, 0.373288, 2.20228, -0.763593, -0.25659, 1.9397, -0.166943, -0.672522, -1.35983, 0.227406, 0.49471, -1.23535, -0.479552, 1.97798, 0.418181, 1.23454, -0.0767748, 0.828642, -0.0348468, -0.264499, 0.76699, -0.910363, -2.11408, -0.209169, 0.902191, -2.27096, 0.098513, -0.380699, -0.231276, -0.0296834, 0.834972, -0.658283, 0.616493, 0.198916, -1.89783, -1.30219, 0.51036, 0.195825, -1.68961, -1.27838, 0.879616, 0.566719, 1.21876, 0.270402, -1.38261, 0.365878, 1.54191, 1.25104, 1.23067, 1.87261);y <- c(0.986442, 2.65684, -1.79726, 1.79999, -2.43971, -1.68358, -1.84081, -2.27973, 2.96046, 2.61837, 1.48756, 1.63497, 1.46876, 2.09348, -0.925101, 3.6792, -2.03618, 1.33232, -0.0652269, 0.809911, -2.82019, -1.87691, 1.1284, 0.249619, -2.94777, 3.00423, -2.79901, -0.110801, -3.546, 1.67156, -3.10723, -3.24205, 3.16911, -3.24227, -1.29801, 0.271933, -2.83573, -0.79973, -2.34429, -0.905163, -0.197905, -3.05664, -0.694481, 1.89301, -2.70264, 2.94361, -2.32469, 1.9576, 1.73556, -3.29777, -1.54311, -2.03172, -0.871756, 0.77581, 3.7692, 1.54446, 3.92129, 0.160296, -3.45486, -1.56317, -2.72913, 0.695854, 3.15786, 1.1006, 3.25649, -1.57206, -3.15353, 0.242301, -1.95855, -0.256919, 3.04782, -0.505045, -2.35542, 2.11649, -1.73363, 2.65149, 3.66302, 0.457907, -2.2759, -2.36105, -2.49263, -2.9784, -3.53525, -0.699404, 3.17647, -1.52424, 2.72699, 3.82774, 0.100029, 3.42107, 1.74672, 3.1279, -0.793162, -0.025109, 1.07262, 2.4517, -2.00605, -3.6625, -2.57031, -2.43599, 2.56309, -1.31707, -2.10777, -3.75394, 0.954311, 0.496025, 3.82545, -3.74259, -1.96145, 0.366455, 3.97474, 3.26111, -3.69904, 2.07392, 0.591191, -3.34162, -0.926126, 1.03966, -2.68754, -2.69653, 0.651845, 2.82333, 2.25596, 3.26545, -2.57379, 2.69137, -3.08119, 2.99114, -3.86005, -1.30995, 1.80096, 1.39404, -2.6482, -2.12922, -3.28834, -1.06563, -1.6683, -2.023, 1.60516, -1.67431, 1.38595, 0.287423, 2.56888, -2.99169, 0.549401, 2.31817, -2.48251, 2.20152, 1.0531, -3.60478, 0.327999, 0.475523, -0.454324, -2.63147, -1.61249, -1.65507, 1.13203, 0.218, 2.87289, -0.279036, -0.316795, 3.22757, -2.25, -1.10923, 0.0949814, -2.60818, -0.181803, 3.65484, 2.86193, 0.940815, 3.5461, 1.23983, 2.01177, -0.428626, 3.5539, -2.63454, 1.63098, 3.69696, 0.404995, 0.480342, 3.22724, -3.57127, -2.38176, -1.23267, 0.738668, 1.64966, 1.37331, -2.60132, -1.60081, 2.57359, -3.58266, 1.32347, 3.24265, 3.81, 3.90706, -0.407994, 2.42083, 3.34477, 3.43151, -1.08974, -2.93732, 2.39014, -1.36511, -0.101514, -1.46445, 2.11849, -3.63955, -1.57038, 3.41777, -1.00185, -0.0702487, 2.01317, -3.38133, 3.64754, -0.740182, -3.64028, -3.77238, 2.45613, -3.11631, 3.82543, 2.15285, -0.790691, -1.22153, -0.943069, -3.37327, 1.19097, 1.48834, 0.502127, -2.90383, -3.4236, -0.676889, 3.41785, 2.54728, -2.60006, -3.25969, -1.85346, -2.8088, 3.3905, -1.34015, -1.3877, 2.38485, 3.16688, -3.26326, -1.94801, 0.0878641, 0.492529, 2.62313, -2.08994, -1.77721, 1.92357, 0.739532, 0.869021, -3.82981, 3.92422, -1.16293, 3.82139, -1.67119, 1.1145, -2.24382, -1.93777, -0.109559, -0.350947, 1.94832, -2.54192, 1.224, 0.797731, 0.767982, -2.93565, -2.72896, 1.2624, 1.91513, -3.96412, 3.43534, 0.358804, 3.05541, -0.213663, 0.38204, -0.539063, -0.897154, -2.91298, -0.198784, -0.0732228, 2.99983, 3.54078, 2.27245, 3.87904, 2.99445, -0.705307, 0.187173, 1.79102, 1.69581, 2.08613, 1.54021, 0.7471, -1.19008, 2.44732, -1.59312, 1.5387, -0.526756, 3.06958, -1.707, -2.46148, -0.523427, -0.675584, -3.02611, -2.22116, -3.4546, -2.94353, 2.1346, 3.51197, 1.85137, 1.7461, -0.875901, -2.13891, -2.1714, 1.6953, -0.159958, 1.77583, -0.808156, 2.04446, 3.58507, -1.27303, -0.0739294, 0.22885, -1.16883, -0.0437807, -1.30141, 2.71702, 2.85379, 3.74969, 3.5839, -0.159889, -0.236555, 2.78411, 2.15217, -0.945737, -1.90692, 0.536403, -1.08419, -3.75986, 2.65243, -2.29661, 3.8776, 1.23146, -2.26545, 2.79205, 2.34152, -3.62388, -3.51983, -0.152083, -0.77672, -0.0661756, -1.12531, 1.77691, -1.49266, -0.401453, -2.98782, 1.15182, 3.00211, -0.338523, 2.63385, -1.30166, -1.96304, -2.03665, -2.91373, 3.33512, 0.26508, -2.4008, -0.989122, -1.96516, 0.498154, -0.139963, 1.762, -0.36494, 2.42886, 1.26076, -0.344707, -2.2629, 3.01517, -0.192693, 1.72579, -3.09541, 0.898774, -3.33187, -2.09473, 2.13997, -1.20736, -1.78102, 0.661333, -2.15738, -2.82721, -0.34423, 0.945198, -1.3919, 2.24165, -1.72333, -3.61333, 0.177856, -0.499845, 1.08322, -0.57797, 1.32396, -0.580476, -0.990233, 3.13608, 0.2254, 2.44513, -1.43021, -2.20293, -0.0295935, 3.9359, 0.872028, 2.94495, 2.3334, -1.4539, -2.0155, 1.90474, -1.83284, -3.6983, -0.223583, -2.19197, 2.98892, 2.11877, -0.614374, 0.860207, 3.63726, -1.54793, 0.699044, -3.31199, -2.87789, 3.21311, -3.24507, -0.0689166, 0.225146, -2.84127, -3.67944, 0.763724, -3.93721, -3.81518, -1.06853, 0.726999, 0.562243, 3.79879, 3.75762, 2.1455, 2.00329, -0.400098, -1.80113, 3.49374, 3.26726, -1.24347, 2.0535, 2.55697, 0.670452, -2.79004, 1.39668, 2.32366, -2.27311, -0.352436, -2.71256, -2.31389, -2.11829, 0.111656, -1.67798, 2.97944, -3.7505, -1.88802, 3.50199, 1.31453, 3.32241, -1.04754, -3.03124, 1.60895, 1.15746, 2.29443, 3.31704, -0.172815, 2.81695, 0.253896, 0.298466, -3.90939, -2.39831, 3.46711, 2.41166, 2.03439, 0.387814, -3.40236, -3.71227, -1.68499, -3.81028, 2.97335, 3.32693, -3.88281, -2.61789, -3.31616, 2.71789, 3.05144, -0.579528, -0.672907, 2.75653);quartz(width=4, height=4, type="pdf", file="~/Desktop/testpdf.pdf");plot(x=x, y=y, xlim=c(-5, 5), ylim=c(-5, 5), pch=19, cex=0.5, main="2000");dev.off();}?
>>> 
>>> If I execute the R code that is in the -e argument directly in R GUI (on OS X) it works fine.  And if I put that code in a file and run Rscript <file>, it works fine.  So the length limit is not intrinsic to R?s parser, it would seem.  But if I try to execute exactly the same code in an interactive R session in my Unix terminal's command line, I get a continuation prompt, +, and a little investigation indicates that the input line may have been truncated after 3843 characters (a strange number) and it is waiting for more input to follow that truncated input.  And ? what is most relevant for my situation ? if I try to run the full Rscript command as given above (inside /bin/sh), it prints out:
>>> 
>>> WARNING: '-e {x~+~<-~+~c(-1.31171,~+~-0.686165,~+~1.62771,~+~0.320195,~+~-0.322011,~+~1.66518,~+~-0.271971,~+~-0.665367,~+~0.516482,~+~-0.716343,~+~-0.317471,~+~0.068046,~+~-0.100371,~+~-1.15907,~+~0.263329,~+~-0.936049,~+~-0.852444,~+~0.358817,~+~-0.233959,~+~0.209891,~+~-0.831575,~+~-0.952987,~+~-0.0420206,~+~-1.78527,~+~-0.280584,~+~-0.62353,~+~1.42597,~+~0.127994,~+~0.0751232,~+~0.896835,~+~-0.319488,~+~0.897876,~+~0.18457,~+~0.779571,~+~-0.0543194,~+~0.226722,~+~-0.769983,~+~-0.723463,~+~0.144386,~+~-0.468544,~+~-0.349417,~+~0.336786,~+~0.749212,~+~-1.62397,~+~0.683075,~+~-0.746449,~+~0.300921,~+~-0.365468,~+~0.548271,~+~1.13169,~+~-1.34042,~+~-0.0740572,~+~1.34986,~+~0.531771,~+~-0.147157,~+~0.824894,~+~-1.05816,~+~1.58867,~+~-0.885764,~+~1.11912,~+~0.361512,~+~1.77985,~+~0.585099,~+~-1.205,~+~2.44134,~+~-0.331372,~+~-0.346322,~+~0.0535267,~+~-1.75089,~+~0.0773243,~+~-1.07846,~+~-1.29632,~+~1.0622,~+~1.34867,~+~0.199777,~+~0.197516,~+~0.574185,~+~1.06555,~+~-0.885166,~+~-0.788576,~+~-1.46061,~+~-1.5402
>>> 
>>> and then it hangs ? the full warning doesn?t complete printing, so it is not clear what it is trying to warn about.  That represents 844 characters of input script, but with the weird way that spaces have been replaced by ~+~ by somebody, it is 1013 characters ? suspiciously close to 1024.
>>> 
>>> Note that if I simply make the R script shorter, by plotting 100 x/y values instead of 500, everything works fine.  So there is no issue with the way that I?m quoting strings or anything like that; the only issue seems to be the total length of the command line.
>>> 
>>> Now of course I could break up the script into multiple chunks, passed via separate -e arguments, and perhaps that would work somewhat better.  But given that I want to set up a vector x with a single c() command containing all of the data for x, I will still hit a line length limit; the single line of code to set up x will already be over the maximum line length that Rscript allows for a -e argument, apparently.  Getting around that would obviously be possible too, but would be considerably more hassle.
>>> 
>>> And incidentally, this seems to have nothing to do with the /bin/sh input line limit; that is much higher.  According to "getconf ARG_MAX?, it is 262144 characters on my machine, which is more than enough headroom for what I?m trying to do.
>>> 
>>> So my questions are: (1) is this a bug, (2) if so, do you think you are likely to fix it any time soon :->, and (3) if the answer to that is no, are there any standard workarounds for this sort of situation that you would recommend?  I suppose I could write out the script to a file and then execute that file with Rscript, since that seems to work; but I was really hoping to avoid that extra complication and overhead.  Is there a better way?
>>> 
>>> Thanks for any help you can provide!  :->
>>> 
>>> Cheers,
>>> -B.
>>> 
>>> Benjamin C. Haller
>>> Messer Lab
>>> Cornell University
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr 22 13:47:44 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 22 Apr 2017 07:47:44 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
Message-ID: <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>

David:
This is my last query on this issue.
I thank you, again, for your patience,
without perhaps your not understanding what drives (bugs) me.

Is there a more efficient way of writing the code, below,
which is replicating the original dataset Response 5 times?

Response5x <- rbind(Response, Response, Response, Response, Response)

Regards,
Bruce

  

BR_email wrote:
> David:
> Its' not going my way today.
> I'll try to work with all that you provided.
> It's late Friday and I cannot impose on you much more.
> Thank you.
> If I may, after I rework it, I'll contact you, okay?
> Have great weekend. And thanks, again.
> Bruce
> FYI: Below are where the error messages start:
>
> R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not 
> found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR, Cum_RespRate, 
> Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, Cum_RespRate, 
> Decile_RespRate) : object 'Decile_RespRate' not found R> R> R> R> 
> avg_RR <- dec_mean_wt_R_nRD[10,7] Error: object 'dec_mean_wt_R_nRD' 
> not found R> Cum_Lift <- (Cum_RespRate/avg_RR)*100 Error: object 
> 'avg_RR' not found R> R> DECILE <- 
> c("top","2","3","4","5","6","7","8","9","bot") R> R> 
> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
> stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, 
> Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not 
> found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] 
> Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> 
> total_line<-cbind(DECILE="Total", + 
> as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 
> 3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL' 
> not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: 
> object 'dec_mean_wt_R_nRDL' not found R> 
> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in 
> rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' 
> not found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 
> 'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 
> 'decile_table' not found R> R> #Install the xtable package: 
> install.packages("xtable") R> #Load the xtable package: R> 
> library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in 
> xtable(decile_table) : object 'decile_table' not found R> DECILE_TABLE 
> Error: object 'DECILE_TABLE' not found R> R> R> 
> print.xtable(DECILE_TABLE, 
> type="html",file="C:/R_Data/DecileTable.html", include.rownames=FALSE) 
> Error in print.xtable(DECILE_TABLE, type = "html", file = 
> "C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' not found
>
> R>
>
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>
>
> David L Carlson wrote:
>> I've attached a modification of your script file (called .txt so it 
>> doesn't get stripped). See if this does what you want.
>>
>> David C
>>
>> -----Original Message-----
>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>> Sent: Friday, April 21, 2017 3:46 PM
>> To: David L Carlson <dcarlson at tamu.edu>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Looking for a package to replace xtable
>>
>> David:
>> Correction: I do need a data frame because from the order Response 
>> column I create a data frame as per all my calculated columns, 
>> yielding the five column decile table.
>> I used your latest corrections but something buggy is a happenin'.
>>
>> Bruce
>> ______________
>> Bruce Ratner PhD
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analytics -- www.DMSTAT1.com
>> Machine-Learning Data Mining -- www.GenIQ.net
>>
>>
>>
>>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>
>>> David:
>>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the 
>>> output of a say logistic model, where Response is actual 0-1 
>>> responses, and yhat is the predicted
>>> response variable.
>>> I usually resample the original data to get some noise out of the 
>>> data. I find it valuable if I can resample from a large sample than 
>>> the original.
>>> (I know this is viewed by some as unorthodox.)
>>>
>>> Your point: I only need Response as a column vector.
>>> That said, what would you alter, please?
>>> Thanks for your time.
>>> Regards,
>>> Bruce
>>>
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> 
>>>> wrote:
>>>>
>>>> You have an issue at the top with
>>>>
>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>
>>>> Since Response$yhat has not been defined at this point. Presumably 
>>>> you want
>>>>
>>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>>
>>>> The main issue is that you have a variable Response that is located 
>>>> in a data frame called ResponseX10.
>>>>
>>>> In creating cum_R you need
>>>>
>>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>>
>>>> then dec_mean
>>>>
>>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), 
>>>> mean))
>>>>
>>>> then dd
>>>>
>>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>>
>>>>
>>>> You might consider if Response really needs to be inside a data 
>>>> frame that consists of a single column (maybe you do if you need to 
>>>> keep track of the row numbers). If you just worked with the vector 
>>>> Response, you would not have to use with() or attach().
>>>>
>>>> I'm not sure what the first few lines of your code are intended to 
>>>> do. You choose random binomial values and uniform random values and 
>>>> then order the first by the second. But rbinom() is selecting 
>>>> random values so what is the purpose of randomizing random values? 
>>>> If the real data consist of a vector of 1's and 0's and those need 
>>>> to be randomized, sample(data) will do it for you.
>>>>
>>>> Then those numbers are replicated 10 times. Why not just select 500 
>>>> values using rbinom() initially?
>>>>
>>>>
>>>> David C
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: BR_email [mailto:br at dmstat1.com]
>>>> Sent: Friday, April 21, 2017 1:22 PM
>>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>
>>>> David:
>>>> I tried somethings and got a little more working.
>>>> Now, I am struck at last line provided: "dec_mean    <-
>>>> aggregate(Response ~ decc, dd, mean)"
>>>> Any help is appreciated.
>>>> Bruce
>>>>
>>>> *****
>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>
>>>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>>>> str(ResponseX10)
>>>>
>>>> ResponseX10    <- 
>>>> ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>>
>>>> str(ResponseX10)
>>>> head(ResponseX10)
>>>>
>>>> ResponseX10[[2]] <- NULL
>>>> ResponseX10 <- data.frame(ResponseX10)
>>>> str(ResponseX10)
>>>>
>>>> cum_R    <- cumsum(Response)
>>>> cum_R
>>>>
>>>> sam_size <- n
>


From spencer.graves at effectivedefense.org  Sat Apr 22 14:57:55 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 22 Apr 2017 07:57:55 -0500
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
 <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
Message-ID: <de3b2a7f-e1b4-08dc-07b4-e7e4fe30bb6b@effectivedefense.org>

Have you looked at library(sos)?  It includes the following that might 
help you find what you want:


       * "findFn" function that searches help pages for matches to your 
search term, then sorts the results by package.  The print method 
displays the results in a web browser.


       * "packageSum" to summarize the results by package.


       * "writeFinFn2xls" to write an Excel file with sheets for package 
summary and individual help pages found.


       * "installPackages" to automatically install the packages found 
most relevant, so "packageSum" and "writeFindFn2xls" can provide more 
information.


       * a vignette, also available at 
"https://journal.r-project.org/archive/2009/RJ-2009-017/RJ-2009-017.pdf".


       hope this helps
       Spencer Graves


On 2017-04-22 6:47 AM, BR_email wrote:
> David:
> This is my last query on this issue.
> I thank you, again, for your patience,
> without perhaps your not understanding what drives (bugs) me.
>
> Is there a more efficient way of writing the code, below,
> which is replicating the original dataset Response 5 times?
>
> Response5x <- rbind(Response, Response, Response, Response, Response)
>
> Regards,
> Bruce
>
>
>
> BR_email wrote:
>> David:
>> Its' not going my way today.
>> I'll try to work with all that you provided.
>> It's late Friday and I cannot impose on you much more.
>> Thank you.
>> If I may, after I rework it, I'll contact you, okay?
>> Have great weekend. And thanks, again.
>> Bruce
>> FYI: Below are where the error messages start:
>>
>> R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not 
>> found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR, 
>> Cum_RespRate, Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, 
>> Cum_RespRate, Decile_RespRate) : object 'Decile_RespRate' not found 
>> R> R> R> R> avg_RR <- dec_mean_wt_R_nRD[10,7] Error: object 
>> 'dec_mean_wt_R_nRD' not found R> Cum_Lift <- 
>> (Cum_RespRate/avg_RR)*100 Error: object 'avg_RR' not found R> R> 
>> DECILE <- c("top","2","3","4","5","6","7","8","9","bot") R> R> 
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
>> stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, 
>> Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not 
>> found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] 
>> Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> 
>> total_line<-cbind(DECILE="Total", + 
>> as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 
>> 3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL' 
>> not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: 
>> object 'dec_mean_wt_R_nRDL' not found R> 
>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in 
>> rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' 
>> not found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 
>> 'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 
>> 'decile_table' not found R> R> #Install the xtable package: 
>> install.packages("xtable") R> #Load the xtable package: R> 
>> library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in 
>> xtable(decile_table) : object 'decile_table' not found R> 
>> DECILE_TABLE Error: object 'DECILE_TABLE' not found R> R> R> 
>> print.xtable(DECILE_TABLE, 
>> type="html",file="C:/R_Data/DecileTable.html", 
>> include.rownames=FALSE) Error in print.xtable(DECILE_TABLE, type = 
>> "html", file = "C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' 
>> not found
>>
>> R>
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>>
>> David L Carlson wrote:
>>> I've attached a modification of your script file (called .txt so it 
>>> doesn't get stripped). See if this does what you want.
>>>
>>> David C
>>>
>>> -----Original Message-----
>>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>>> Sent: Friday, April 21, 2017 3:46 PM
>>> To: David L Carlson <dcarlson at tamu.edu>
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Looking for a package to replace xtable
>>>
>>> David:
>>> Correction: I do need a data frame because from the order Response 
>>> column I create a data frame as per all my calculated columns, 
>>> yielding the five column decile table.
>>> I used your latest corrections but something buggy is a happenin'.
>>>
>>> Bruce
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>>
>>>> David:
>>>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the 
>>>> output of a say logistic model, where Response is actual 0-1 
>>>> responses, and yhat is the predicted
>>>> response variable.
>>>> I usually resample the original data to get some noise out of the 
>>>> data. I find it valuable if I can resample from a large sample than 
>>>> the original.
>>>> (I know this is viewed by some as unorthodox.)
>>>>
>>>> Your point: I only need Response as a column vector.
>>>> That said, what would you alter, please?
>>>> Thanks for your time.
>>>> Regards,
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> 
>>>>> wrote:
>>>>>
>>>>> You have an issue at the top with
>>>>>
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>
>>>>> Since Response$yhat has not been defined at this point. Presumably 
>>>>> you want
>>>>>
>>>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>>>
>>>>> The main issue is that you have a variable Response that is 
>>>>> located in a data frame called ResponseX10.
>>>>>
>>>>> In creating cum_R you need
>>>>>
>>>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>>>
>>>>> then dec_mean
>>>>>
>>>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), 
>>>>> mean))
>>>>>
>>>>> then dd
>>>>>
>>>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>>>
>>>>>
>>>>> You might consider if Response really needs to be inside a data 
>>>>> frame that consists of a single column (maybe you do if you need 
>>>>> to keep track of the row numbers). If you just worked with the 
>>>>> vector Response, you would not have to use with() or attach().
>>>>>
>>>>> I'm not sure what the first few lines of your code are intended to 
>>>>> do. You choose random binomial values and uniform random values 
>>>>> and then order the first by the second. But rbinom() is selecting 
>>>>> random values so what is the purpose of randomizing random values? 
>>>>> If the real data consist of a vector of 1's and 0's and those need 
>>>>> to be randomized, sample(data) will do it for you.
>>>>>
>>>>> Then those numbers are replicated 10 times. Why not just select 
>>>>> 500 values using rbinom() initially?
>>>>>
>>>>>
>>>>> David C
>>>>>
>>>>>
>>>>> -----Original Message-----
>>>>> From: BR_email [mailto:br at dmstat1.com]
>>>>> Sent: Friday, April 21, 2017 1:22 PM
>>>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>>
>>>>> David:
>>>>> I tried somethings and got a little more working.
>>>>> Now, I am struck at last line provided: "dec_mean    <-
>>>>> aggregate(Response ~ decc, dd, mean)"
>>>>> Any help is appreciated.
>>>>> Bruce
>>>>>
>>>>> *****
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>
>>>>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>>>>> str(ResponseX10)
>>>>>
>>>>> ResponseX10    <- 
>>>>> ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>>>
>>>>> str(ResponseX10)
>>>>> head(ResponseX10)
>>>>>
>>>>> ResponseX10[[2]] <- NULL
>>>>> ResponseX10 <- data.frame(ResponseX10)
>>>>> str(ResponseX10)
>>>>>
>>>>> cum_R    <- cumsum(Response)
>>>>> cum_R
>>>>>
>>>>> sam_size <- n
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Apr 22 15:38:22 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 22 Apr 2017 15:38:22 +0200
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
 <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
Message-ID: <2C728C0D-87F1-4BFA-B1B2-3C4BBCDB22FC@gmail.com>


> On 22 Apr 2017, at 13:47 , BR_email <br at dmstat1.com> wrote:
> 
> David:
> This is my last query on this issue.
> I thank you, again, for your patience,
> without perhaps your not understanding what drives (bugs) me.
> 
> Is there a more efficient way of writing the code, below,
> which is replicating the original dataset Response 5 times?
> 
> Response5x <- rbind(Response, Response, Response, Response, Response)

Dunno about the efficiency, but there is

do.call(rbind, rep(list(Response), 5))

-pd

> 
> Regards,
> Bruce
> 
> 
> BR_email wrote:
>> David:
>> Its' not going my way today.
>> I'll try to work with all that you provided.
>> It's late Friday and I cannot impose on you much more.
>> Thank you.
>> If I may, after I rework it, I'll contact you, okay?
>> Have great weekend. And thanks, again.
>> Bruce
>> FYI: Below are where the error messages start:
>> 
>> R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate) : object 'Decile_RespRate' not found R> R> R> R> avg_RR <- dec_mean_wt_R_nRD[10,7] Error: object 'dec_mean_wt_R_nRD' not found R> Cum_Lift <- (Cum_RespRate/avg_RR)*100 Error: object 'avg_RR' not found R> R> DECILE <- c("top","2","3","4","5","6","7","8","9","bot") R> R> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> total_line<-cbind(DECILE="Total", + as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL' not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: object 'dec_mean_wt_R_nRDL' not found R> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' not found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 'decile_table' not found R> R> #Install the xtable package: install.packages("xtable") R> #Load the xtable package: R> library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in xtable(decile_table) : object 'decile_table' not found R> DECILE_TABLE Error: object 'DECILE_TABLE' not found R> R> R> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html", include.rownames=FALSE) Error in print.xtable(DECILE_TABLE, type = "html", file = "C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' not found
>> 
>> R>
>> 
>> 
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>> 
>> 
>> David L Carlson wrote:
>>> I've attached a modification of your script file (called .txt so it doesn't get stripped). See if this does what you want.
>>> 
>>> David C
>>> 
>>> -----Original Message-----
>>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>>> Sent: Friday, April 21, 2017 3:46 PM
>>> To: David L Carlson <dcarlson at tamu.edu>
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Looking for a package to replace xtable
>>> 
>>> David:
>>> Correction: I do need a data frame because from the order Response column I create a data frame as per all my calculated columns, yielding the five column decile table.
>>> I used your latest corrections but something buggy is a happenin'.
>>> 
>>> Bruce
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>> 
>>> 
>>> 
>>>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>> 
>>>> David:
>>>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
>>>> response variable.
>>>> I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original.
>>>> (I know this is viewed by some as unorthodox.)
>>>> 
>>>> Your point: I only need Response as a column vector.
>>>> That said, what would you alter, please?
>>>> Thanks for your time.
>>>> Regards,
>>>> Bruce
>>>> 
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>> 
>>>> 
>>>> 
>>>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>>> 
>>>>> You have an issue at the top with
>>>>> 
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>> 
>>>>> Since Response$yhat has not been defined at this point. Presumably you want
>>>>> 
>>>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>>> 
>>>>> The main issue is that you have a variable Response that is located in a data frame called ResponseX10.
>>>>> 
>>>>> In creating cum_R you need
>>>>> 
>>>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>>> 
>>>>> then dec_mean
>>>>> 
>>>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
>>>>> 
>>>>> then dd
>>>>> 
>>>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>>> 
>>>>> 
>>>>> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
>>>>> 
>>>>> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
>>>>> 
>>>>> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
>>>>> 
>>>>> 
>>>>> David C
>>>>> 
>>>>> 
>>>>> -----Original Message-----
>>>>> From: BR_email [mailto:br at dmstat1.com]
>>>>> Sent: Friday, April 21, 2017 1:22 PM
>>>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>> 
>>>>> David:
>>>>> I tried somethings and got a little more working.
>>>>> Now, I am struck at last line provided: "dec_mean    <-
>>>>> aggregate(Response ~ decc, dd, mean)"
>>>>> Any help is appreciated.
>>>>> Bruce
>>>>> 
>>>>> *****
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>> 
>>>>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>>>>> str(ResponseX10)
>>>>> 
>>>>> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>>> 
>>>>> str(ResponseX10)
>>>>> head(ResponseX10)
>>>>> 
>>>>> ResponseX10[[2]] <- NULL
>>>>> ResponseX10 <- data.frame(ResponseX10)
>>>>> str(ResponseX10)
>>>>> 
>>>>> cum_R    <- cumsum(Response)
>>>>> cum_R
>>>>> 
>>>>> sam_size <- n
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Sat Apr 22 15:50:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 22 Apr 2017 06:50:58 -0700
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
 <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
Message-ID: <CEC32F53-9F14-43D3-A907-7B401A89C5CE@dcn.davis.ca.us>

Response5x  <- Response[ rep ( seq_along( Response[[1]] ), 5 ), ]
-- 
Sent from my phone. Please excuse my brevity.

On April 22, 2017 4:47:44 AM PDT, BR_email <br at dmstat1.com> wrote:
>David:
>This is my last query on this issue.
>I thank you, again, for your patience,
>without perhaps your not understanding what drives (bugs) me.
>
>Is there a more efficient way of writing the code, below,
>which is replicating the original dataset Response 5 times?
>
>Response5x <- rbind(Response, Response, Response, Response, Response)
>
>Regards,
>Bruce
>
>  
>
>BR_email wrote:
>> David:
>> Its' not going my way today.
>> I'll try to work with all that you provided.
>> It's late Friday and I cannot impose on you much more.
>> Thank you.
>> If I may, after I rework it, I'll contact you, okay?
>> Have great weekend. And thanks, again.
>> Bruce
>> FYI: Below are where the error messages start:
>>
>> R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not 
>> found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR,
>Cum_RespRate, 
>> Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, Cum_RespRate, 
>> Decile_RespRate) : object 'Decile_RespRate' not found R> R> R> R> 
>> avg_RR <- dec_mean_wt_R_nRD[10,7] Error: object 'dec_mean_wt_R_nRD' 
>> not found R> Cum_Lift <- (Cum_RespRate/avg_RR)*100 Error: object 
>> 'avg_RR' not found R> R> DECILE <- 
>> c("top","2","3","4","5","6","7","8","9","bot") R> R> 
>> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, 
>> stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, 
>> Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not 
>> found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] 
>> Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> 
>> total_line<-cbind(DECILE="Total", + 
>> as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 
>> 3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL'
>
>> not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: 
>> object 'dec_mean_wt_R_nRDL' not found R> 
>> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in 
>> rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' 
>> not found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 
>> 'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 
>> 'decile_table' not found R> R> #Install the xtable package: 
>> install.packages("xtable") R> #Load the xtable package: R> 
>> library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in 
>> xtable(decile_table) : object 'decile_table' not found R>
>DECILE_TABLE 
>> Error: object 'DECILE_TABLE' not found R> R> R> 
>> print.xtable(DECILE_TABLE, 
>> type="html",file="C:/R_Data/DecileTable.html",
>include.rownames=FALSE) 
>> Error in print.xtable(DECILE_TABLE, type = "html", file = 
>> "C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' not found
>>
>> R>
>>
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>>
>> David L Carlson wrote:
>>> I've attached a modification of your script file (called .txt so it 
>>> doesn't get stripped). See if this does what you want.
>>>
>>> David C
>>>
>>> -----Original Message-----
>>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>>> Sent: Friday, April 21, 2017 3:46 PM
>>> To: David L Carlson <dcarlson at tamu.edu>
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Looking for a package to replace xtable
>>>
>>> David:
>>> Correction: I do need a data frame because from the order Response 
>>> column I create a data frame as per all my calculated columns, 
>>> yielding the five column decile table.
>>> I used your latest corrections but something buggy is a happenin'.
>>>
>>> Bruce
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>
>>>
>>>
>>>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com>
>wrote:
>>>>
>>>> David:
>>>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the 
>>>> output of a say logistic model, where Response is actual 0-1 
>>>> responses, and yhat is the predicted
>>>> response variable.
>>>> I usually resample the original data to get some noise out of the 
>>>> data. I find it valuable if I can resample from a large sample than
>
>>>> the original.
>>>> (I know this is viewed by some as unorthodox.)
>>>>
>>>> Your point: I only need Response as a column vector.
>>>> That said, what would you alter, please?
>>>> Thanks for your time.
>>>> Regards,
>>>> Bruce
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> 
>>>>> wrote:
>>>>>
>>>>> You have an issue at the top with
>>>>>
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>
>>>>> Since Response$yhat has not been defined at this point. Presumably
>
>>>>> you want
>>>>>
>>>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>>>
>>>>> The main issue is that you have a variable Response that is
>located 
>>>>> in a data frame called ResponseX10.
>>>>>
>>>>> In creating cum_R you need
>>>>>
>>>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>>>
>>>>> then dec_mean
>>>>>
>>>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), 
>>>>> mean))
>>>>>
>>>>> then dd
>>>>>
>>>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>>>
>>>>>
>>>>> You might consider if Response really needs to be inside a data 
>>>>> frame that consists of a single column (maybe you do if you need
>to 
>>>>> keep track of the row numbers). If you just worked with the vector
>
>>>>> Response, you would not have to use with() or attach().
>>>>>
>>>>> I'm not sure what the first few lines of your code are intended to
>
>>>>> do. You choose random binomial values and uniform random values
>and 
>>>>> then order the first by the second. But rbinom() is selecting 
>>>>> random values so what is the purpose of randomizing random values?
>
>>>>> If the real data consist of a vector of 1's and 0's and those need
>
>>>>> to be randomized, sample(data) will do it for you.
>>>>>
>>>>> Then those numbers are replicated 10 times. Why not just select
>500 
>>>>> values using rbinom() initially?
>>>>>
>>>>>
>>>>> David C
>>>>>
>>>>>
>>>>> -----Original Message-----
>>>>> From: BR_email [mailto:br at dmstat1.com]
>>>>> Sent: Friday, April 21, 2017 1:22 PM
>>>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>>
>>>>> David:
>>>>> I tried somethings and got a little more working.
>>>>> Now, I am struck at last line provided: "dec_mean    <-
>>>>> aggregate(Response ~ decc, dd, mean)"
>>>>> Any help is appreciated.
>>>>> Bruce
>>>>>
>>>>> *****
>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>
>>>>> ResponseX10    <- do.call(rbind, replicate(10, Resp,
>simplify=FALSE))
>>>>> str(ResponseX10)
>>>>>
>>>>> ResponseX10    <- 
>>>>> ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>>>
>>>>> str(ResponseX10)
>>>>> head(ResponseX10)
>>>>>
>>>>> ResponseX10[[2]] <- NULL
>>>>> ResponseX10 <- data.frame(ResponseX10)
>>>>> str(ResponseX10)
>>>>>
>>>>> cum_R    <- cumsum(Response)
>>>>> cum_R
>>>>>
>>>>> sam_size <- n
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr 22 16:16:09 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 22 Apr 2017 10:16:09 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <2C728C0D-87F1-4BFA-B1B2-3C4BBCDB22FC@gmail.com>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
 <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
 <2C728C0D-87F1-4BFA-B1B2-3C4BBCDB22FC@gmail.com>
Message-ID: <42b27132-32d2-d912-2f37-25f7094599e9@dmstat1.com>

Peter:
Nice, Thanks.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

peter dalgaard wrote:
>> On 22 Apr 2017, at 13:47 , BR_email <br at dmstat1.com> wrote:
>>
>> David:
>> This is my last query on this issue.
>> I thank you, again, for your patience,
>> without perhaps your not understanding what drives (bugs) me.
>>
>> Is there a more efficient way of writing the code, below,
>> which is replicating the original dataset Response 5 times?
>>
>> Response5x <- rbind(Response, Response, Response, Response, Response)
> Dunno about the efficiency, but there is
>
> do.call(rbind, rep(list(Response), 5))
>
> -pd
>
>> Regards,
>> Bruce
>>
>>
>> BR_email wrote:
>>> David:
>>> Its' not going my way today.
>>> I'll try to work with all that you provided.
>>> It's late Friday and I cannot impose on you much more.
>>> Thank you.
>>> If I may, after I rework it, I'll contact you, okay?
>>> Have great weekend. And thanks, again.
>>> Bruce
>>> FYI: Below are where the error messages start:
>>>
>>> R> Decile_RespRate <- (No_Resp/No_Inds) Error: object 'No_Resp' not found R> R> dec_mean_wt_R_nRD <- cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate) Error in cbind(dec_mean_wt_R_nR, Cum_RespRate, Decile_RespRate) : object 'Decile_RespRate' not found R> R> R> R> avg_RR <- dec_mean_wt_R_nRD[10,7] Error: object 'dec_mean_wt_R_nRD' not found R> Cum_Lift <- (Cum_RespRate/avg_RR)*100 Error: object 'avg_RR' not found R> R> DECILE <- c("top","2","3","4","5","6","7","8","9","bot") R> R> dec_mean_wt_R_nRDL <- cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors=FALSE) Error in cbind(DECILE, dec_mean_wt_R_nRD, Cum_Lift, stringsAsFactors = FALSE) : object 'dec_mean_wt_R_nRD' not found R> dec_mean_wt_R_nRDL <- dec_mean_wt_R_nRDL[,c(1,3,4,9,8,10)] Error: object 'dec_mean_wt_R_nRDL' not found R> R> R> total_line<-cbind(DECILE="Total", + as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 3)),nrow=1))) Error in is.data.frame(x) : object 'dec_mean_wt_R_nRDL' not found R> R> names(total_line)<-names(dec_mean_wt_R_nRDL) Error: object 'dec_mean_wt_R_nRDL' not found R> dec_mean_wt_R_nRDLT<-rbind(dec_mean_wt_R_nRDL,total_line) Error in rbind(dec_mean_wt_R_nRDL, total_line) : object 'dec_mean_wt_R_nRDL' not found R> decile_table <- dec_mean_wt_R_nRDLT Error: object 'dec_mean_wt_R_nRDLT' not found R> decile_table Error: object 'decile_table' not found R> R> #Install the xtable package: install.packages("xtable") R> #Load the xtable package: R> library(xtable) R> R> DECILE_TABLE <-xtable(decile_table) Error in xtable(decile_table) : object 'decile_table' not found R> DECILE_TABLE Error: object 'DECILE_TABLE' not found R> R> R> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html", include.rownames=FALSE) Error in print.xtable(DECILE_TABLE, type = "html", file = "C:/R_Data/DecileTable.html", : object 'DECILE_TABLE' not found
>>>
>>> R>
>>>
>>>
>>> Bruce Ratner, Ph.D.
>>> The Significant Statistician?
>>> (516) 791-3544
>>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>>
>>>
>>> David L Carlson wrote:
>>>> I've attached a modification of your script file (called .txt so it doesn't get stripped). See if this does what you want.
>>>>
>>>> David C
>>>>
>>>> -----Original Message-----
>>>> From: Bruce Ratner PhD [mailto:br at dmstat1.com]
>>>> Sent: Friday, April 21, 2017 3:46 PM
>>>> To: David L Carlson <dcarlson at tamu.edu>
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>
>>>> David:
>>>> Correction: I do need a data frame because from the order Response column I create a data frame as per all my calculated columns, yielding the five column decile table.
>>>> I used your latest corrections but something buggy is a happenin'.
>>>>
>>>> Bruce
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>> (516) 791-3544
>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>
>>>>
>>>>
>>>>> On Apr 21, 2017, at 4:25 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>>>
>>>>> David:
>>>>> Response=rbinom(50,1,0.2), and yhat=runif(50) are simulating the output of a say logistic model, where Response is actual 0-1 responses, and yhat is the predicted
>>>>> response variable.
>>>>> I usually resample the original data to get some noise out of the data. I find it valuable if I can resample from a large sample than the original.
>>>>> (I know this is viewed by some as unorthodox.)
>>>>>
>>>>> Your point: I only need Response as a column vector.
>>>>> That said, what would you alter, please?
>>>>> Thanks for your time.
>>>>> Regards,
>>>>> Bruce
>>>>>
>>>>> ______________
>>>>> Bruce Ratner PhD
>>>>> The Significant Statistician?
>>>>> (516) 791-3544
>>>>> Statistical Predictive Analytics -- www.DMSTAT1.com
>>>>> Machine-Learning Data Mining -- www.GenIQ.net
>>>>>
>>>>>
>>>>>
>>>>>> On Apr 21, 2017, at 3:43 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>>>>
>>>>>> You have an issue at the top with
>>>>>>
>>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>>
>>>>>> Since Response$yhat has not been defined at this point. Presumably you want
>>>>>>
>>>>>> Resp <- Resp[order(Resp$yhat,decreasing=TRUE),]
>>>>>>
>>>>>> The main issue is that you have a variable Response that is located in a data frame called ResponseX10.
>>>>>>
>>>>>> In creating cum_R you need
>>>>>>
>>>>>> cum_R    <- with(ResponseX10, cumsum(Response))
>>>>>>
>>>>>> then dec_mean
>>>>>>
>>>>>> dec_mean <- with(ResponseX10, aggregate(Response, by=list(decc), mean))
>>>>>>
>>>>>> then dd
>>>>>>
>>>>>> dd  <- with(ResponseX10, cbind(Response, dd_))
>>>>>>
>>>>>>
>>>>>> You might consider if Response really needs to be inside a data frame that consists of a single column (maybe you do if you need to keep track of the row numbers). If you just worked with the vector Response, you would not have to use with() or attach().
>>>>>>
>>>>>> I'm not sure what the first few lines of your code are intended to do. You choose random binomial values and uniform random values and then order the first by the second. But rbinom() is selecting random values so what is the purpose of randomizing random values? If the real data consist of a vector of 1's and 0's and those need to be randomized, sample(data) will do it for you.
>>>>>>
>>>>>> Then those numbers are replicated 10 times. Why not just select 500 values using rbinom() initially?
>>>>>>
>>>>>>
>>>>>> David C
>>>>>>
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: BR_email [mailto:br at dmstat1.com]
>>>>>> Sent: Friday, April 21, 2017 1:22 PM
>>>>>> To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
>>>>>> Subject: Re: [R] Looking for a package to replace xtable
>>>>>>
>>>>>> David:
>>>>>> I tried somethings and got a little more working.
>>>>>> Now, I am struck at last line provided: "dec_mean    <-
>>>>>> aggregate(Response ~ decc, dd, mean)"
>>>>>> Any help is appreciated.
>>>>>> Bruce
>>>>>>
>>>>>> *****
>>>>>> Resp <- data.frame(Response=rbinom(50,1,0.2), yhat=runif(50))
>>>>>> Resp <- Resp[order(Response$yhat,decreasing=TRUE),]
>>>>>>
>>>>>> ResponseX10    <- do.call(rbind, replicate(10, Resp, simplify=FALSE))
>>>>>> str(ResponseX10)
>>>>>>
>>>>>> ResponseX10    <- ResponseX10[order(ResponseX10$yhat,decreasing=TRUE),]
>>>>>>
>>>>>> str(ResponseX10)
>>>>>> head(ResponseX10)
>>>>>>
>>>>>> ResponseX10[[2]] <- NULL
>>>>>> ResponseX10 <- data.frame(ResponseX10)
>>>>>> str(ResponseX10)
>>>>>>
>>>>>> cum_R    <- cumsum(Response)
>>>>>> cum_R
>>>>>>
>>>>>> sam_size <- n
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sat Apr 22 16:16:50 2017
From: br at dmstat1.com (BR_email)
Date: Sat, 22 Apr 2017 10:16:50 -0400
Subject: [R] Looking for a package to replace xtable
In-Reply-To: <CEC32F53-9F14-43D3-A907-7B401A89C5CE@dcn.davis.ca.us>
References: <ae14fc9c-1a18-5847-af57-ab4e2fd253dc@dmstat1.com>
 <497e64d2f3b342dfadd83e61584a6d62@exch-2p-mbx-w2.ads.tamu.edu>
 <c070e99d-3dbb-9c0b-a1b6-4bbf25c118d9@dmstat1.com>
 <7b0d09522693460ba97dddfc9e5b7576@exch-2p-mbx-w2.ads.tamu.edu>
 <bec35e91-5deb-ef83-8066-125e981b2338@dmstat1.com>
 <82d3265f-da43-e3a8-13fe-03358010feb2@dmstat1.com>
 <79e98b5367684947b47702104621c9c8@exch-2p-mbx-w2.ads.tamu.edu>
 <63E4F498-66B0-4E71-BC19-8DF70767980A@dmstat1.com>
 <6AF30C2E-57FD-493C-A1BA-1E94ACDB65CE@dmstat1.com>
 <1a3edb18c2da47afadbb34058dc3fccb@exch-2p-mbx-w2.ads.tamu.edu>
 <dd764e5c-d887-565d-01f5-62c802bad831@dmstat1.com>
 <bc00fb5f-d731-194e-8d21-50c5011b466d@dmstat1.com>
 <CEC32F53-9F14-43D3-A907-7B401A89C5CE@dcn.davis.ca.us>
Message-ID: <fa538be7-4862-6c7b-7161-ff936270600f@dmstat1.com>

Jeff:
It does what I want.
Thanks.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Jeff Newmiller wrote:
> Response5x  <- Response[ rep ( seq_along( Response[[1]] ), 5 ), ]


From r.turner at auckland.ac.nz  Sat Apr 22 23:45:13 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 23 Apr 2017 09:45:13 +1200
Subject: [R] Bug in the triMat( ) function in the deldir package.
Message-ID: <7d28780a-52b5-dcd0-69c8-b48e5bb6784a@auckland.ac.nz>


Yesterday Jay Call drew to my attention the fact that the triMat() 
function was giving wrong answers in some instances.  Wrong answers 
occur if the union of three contiguous Delaunay triangles happens to 
constitute another triangle.  This latter triangle appeared in the list 
of triangles produced by triMat() but is *not* itself a Delaunay 
triangle (and hence should not appear in the list).

I have swatted this bug (at least I think/hope that I have!) and have 
uploaded a revised version of deldir (version 0.1-14) to CRAN.  The 
revision contains other amendments and innovations in addition to this 
bug fix.

If you have in the past used triMat(), you should check your results 
from that usage against those produced by the triMat() function from the 
revised version.

Sorry 'bout that.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From patzelt at g.harvard.edu  Sat Apr 22 20:40:09 2017
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Sat, 22 Apr 2017 14:40:09 -0400
Subject: [R] Modeling regressions with 2 DV's?
Message-ID: <CAB9UfhT+-VQ5=tJDU8u5CQkJ0Eve9cs00Ea5eH7=25oAJo_8SA@mail.gmail.com>

Hi R project,

I have a data set (see below) where I have 2 parameters estimated from a
computational model ("lowStakesW", "highStakesW") which represent 2
separate conditions in the experiment. I would like to find out the
relationship of the variable "compulsiveIntrusive" to each of these
conditions ("lowStakesW", "highStakesW").

Do I model an interaction in the DV:

lme((lowStakesW*highStakesW) ~ compulsiveIntrusive + (age + genderTotal +
IQ) , data = data, random = ~ 1 | subject, na.action = na.omit, method =
"ML")

or alternatively, reformat the data to a long format with 2 rows for each
subject and model the "stakes" as a factor? (when I do this it can't
estimate the coefficients)



structure(list(compulsiveIntrusive = c(2.18937963752221, 1.29096892796289,
2.51831554859146, 2.43060016848778, 1.57614819291028, 1.75121219866719,
2.99144667879001, 4.74399673935091, 1.03054126068731, 1.99784375854779,
1.35461253095473, 2.26360948518013, 1.62377445817051, 1.35932322358476,
2.04000412136899, 1.5900455870051, 3.06948431322046, 1.94661260373863,
2.2572276471116, 2.79743033120073), lowStakesW = c(0.733710338106936,
0, 1, 0.257321035855335, 0.780270122098848, 0, 0, 0.934177492567927,
1, 0.595435858091935, 0.838657946021969, 1, 0.891978169296885,
0.750837363915553, 0.797155118780438, 0, 0.648507902264236, 1,
0.856440481475081, 0.547093456389246), highStakesW = c(1, 0,
0.794942129347966, 0.375548142583892, 0.636201082644207, 1, 0,
0.45392263824212, 0.532547871760986, 1, 1, 0.708909875170169,
1, 0.863742838985097, 0.553236337037592, 1, 0.669248271910537,
1, 1, 0.655973113591005), genderTotal = structure(c(1L, 2L, 2L,
2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L), .Label = c("f", "m"), class = "factor"), IQ = c(103.89052,
99.7076935, 85.723885, 109.358215, 92.841325, 107.20297, 96.952615,
77.37235, 83.6863, 115.8529, 101.0889415, 96.952615, 92.63521,
74.7073, 95.476285, 81.3889, 113.988445, 113.975365, 105.61399,
98.03281), age = c(54, 29, 38, 21, 31, 47, 28, 35, 36, 57, 34,
29, 44, 34, 22, 26, 31, 27, 32, 42), subject = c("subject_1",
"subject_2", "subject_3", "subject_4", "subject_5", "subject_6",
"subject_7", "subject_8", "subject_9", "subject_10", "subject_11",
"subject_12", "subject_13", "subject_14", "subject_15", "subject_16",
"subject_17", "subject_18", "subject_19", "subject_20")), .Names =
c("compulsiveIntrusive",
"lowStakesW", "highStakesW", "genderTotal", "IQ", "age", "subject"
), row.names = c(NA, 20L), class = "data.frame")

-- 
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University
*Computational Cognitive Neuroscience Laboratory
<http://gershmanlab.webfactional.com/>*

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Sun Apr 23 06:52:36 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 22 Apr 2017 23:52:36 -0500
Subject: [R] Interesting quirk with fractions and rounding
In-Reply-To: <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
Message-ID: <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>

On Apr 21, 2017 12:01 PM, "JRG" <loesljrg at accucom.net> wrote:

A good part of the problem in the specific case you initially presented
is that some non-integer numbers have an exact representation in the
binary floating point arithmetic being used.  Basically, if the
fractional part is of the form 1/2^k for some integer k > 0, there is an
exact representation in the binary floating point scheme.

> options(digits=20)

> (100*23)/40
[1] 57.5

> 100*(23/40)
[1] 57.499999999999992895

So the two operations give a slightly different result because the
fractional part of the division of 100*23 by 40 is 0.5.  So the first
operations gives, exactly, 57.5 while the second operation does not
because 23/40 has no exact representation.

Thanks for answering.

This case seemed fun because it was not a contrived example.  We found this
one by comparing masses of report tables from 2 separate programs. It
happened 1 time in about 10,000 calculations.

Guidelines for R coders, though, would be welcome. So far, all I am sure of
is

1 Don't use == for floating point numbers.

Your 1/2^k point helps me understand why == does seem to work correctly
sometimes.

I wonder if we should be suspicious of >=. Imagine the horror if a= w/x >
b=y/z in fractions, but digitally a < b. Blech. Can that happen?


But, change the example's divisor from 40 to 30 [the fractional part
from 1/2 to 2/3]:

> (100*23)/30
[1] 76.666666666666671404

> 100*(23/30)
[1] 76.666666666666671404

Now the two operations give the same answer to the full precision
available.  So, it isn't "generally true true in R that (100*x)/y is
more accurate than 100*(x/y), if x > y."


The good news here is that round() gives same answer in both cases:)

I am looking for a case where the first method is less accurate than the
second. I expect that multiplying integers before dividing is never less
accurate. Sometimes it is more accurate.
`
Following your 1/2^k insight, you see why multiplying first is helpful in
some cases. Question is will situation get worse.

But Bert is right. I have to read more books.

I studied Golub and van Loan and came away with healthy fear of matrix
inversion. But when you look at user contributed regression packages, what
do you find? Matrix inversion and lots of X'X.


Paul Johnson
University of Kansask


The key (in your example) is a property of the way that floating point
arithmetic is implemented.


---JRG



On 04/21/2017 08:19 AM, Paul Johnson wrote:
> We all agree it is a problem with digital computing, not unique to R. I
> don't think that is the right place to stop.
>
> What to do? The round example arose in a real funded project where 2 R
> programs differed in results and cause was  that one person got 57 and
> another got 58. The explanation was found, but its less clear how to
> prevent similar in future. Guidelines, anyone?
>
> So far, these are my guidelines.
>
> 1. Insert L on numbers to signal that you really mean INTEGER. In R,
> forgetting the L in a single number will usually promote whole calculation
> to floats.
> 2. S3 variables are called 'numeric' if they are integer or double
storage.
> So avoid "is.numeric" and prefer "is.double".
> 3. == is a total fail on floats
> 4. Run print with digits=20 so we can see the less rounded number. Perhaps
> start sessions with "options(digits=20)"
> 5. all.equal does what it promises, but one must be cautious.
>
> Are there math habits we should follow?
>
> For example, Is it generally true in R that (100*x)/y is more accurate
than
> 100*(x/y), if x > y?   (If that is generally true, couldn't the R
> interpreter do it for the user?)
>
> I've seen this problem before. In later editions of the game theory
program
> Gambit, extraordinary effort was taken to keep values symbolically as
> integers as long as possible. Avoid division until the last steps. Same in
> Swarm simulations. Gary Polhill wrote an essay about the Ghost in the
> Machine along those lines, showing accidents from trusting floats.
>
> I wonder now if all uses of > or < with numeric variables are suspect.
>
> Oh well. If everybody posts their advice, I will write a summary.
>
> Paul Johnson
> University of Kansas
>
> On Apr 21, 2017 12:02 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> The problem is that people using Excel or probably other such
spreadsheets
>> do not encounter this behaviour as Excel silently rounds all your
>> calculations and makes approximate comparison without telling it does so.
>> Therefore most people usually do not have any knowledge of floating point
>> numbers representation.
>>
>>  Cheers
>> Petr
>>


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Sun Apr 23 14:49:59 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 23 Apr 2017 08:49:59 -0400
Subject: [R] Interesting quirk with fractions and rounding / using ==
 for floating point
In-Reply-To: <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
 <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
Message-ID: <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>

For over 4 decades I've had to put up with people changing my codes because
I use equalities of floating point numbers in tests for convergence. (Note that
tests of convergence are a subset of tests for termination -- I'll be happy to
explain that if requested.) Then I get "your program isn't working" and find
that is is NOT my program, but a crippled version thereof.

But I don't use equality tests (i.e., ==) blindly. My tests are of the form

   if ( (x_new + offset) == (x_old + offset) ) { # we cannot get more progress

Now it is possible to imagine some weird cases where this can fail, so an
additional test is needed on, say, maximum iterations to avoid trouble. But
I've not seen such cases (or perhaps never noticed one, though I run with
very large maximum counters). The test works by having offset as some
modest value. For single precision I use 10 or 16, for double around 100.

When x_new and x_old are near zero, the bit pattern is dominated by offset and
we get convergence. When x_new is big, then it dominates.

Why do I do this? The reason is that in the early 1970s there were many, many
different floating point arithmetics with all sorts of choices of radix and
length of mantissa. (Are "radix" and "mantissa" taught to computer science
students any more?). If my programs were ported between machines there was a
good chance any tolerances would be wrong. And users -- for some reason at the
time engineers in particular -- would say "I only need 2 digits, I'll use 1e-3
as my tolerance". And "my" program would then not work. Sigh. For some reason,
the nicely scaled offset did not attract the attention of the compulsive fiddlers.

So equality in floating point is not always "wrong", though it should be used
with some attention to what is going on.

Apologies to those (e.g., Peter D.) who have heard this all before. I suspect
there are many to whom it is new.

John Nash


On 2017-04-23 12:52 AM, Paul Johnson wrote:
>
> 1 Don't use == for floating point numbers.
>


From pdalgd at gmail.com  Sun Apr 23 15:37:09 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 23 Apr 2017 15:37:09 +0200
Subject: [R] Interesting quirk with fractions and rounding / using ==
 for floating point
In-Reply-To: <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
 <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
 <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>
Message-ID: <A579B35C-DE07-4089-A700-C99D2432F281@gmail.com>


> On 23 Apr 2017, at 14:49 , J C Nash <profjcnash at gmail.com> wrote:
> 
> 
> So equality in floating point is not always "wrong", though it should be used
> with some attention to what is going on.
> 
> Apologies to those (e.g., Peter D.) who have heard this all before. I suspect
> there are many to whom it is new.

Peter D. still insists on never trusting exact equality, though. There was at least one case in the R sources where age-old code got itself into a condition where a residual terme that provably should decrease on every iteration oscillated between two values of 1-2 ulp in magnitude without ever reaching 0. The main thing is that you cannot trust optimising compilers these days. There is, e.g.,  no guarantee that a compiler will not transform

(x_new + offset) == (x_old + offset)

to

(x_new + offset) - (x_old + offset) == 0

to

(x_new - x_old) + (offset - offset) == 0

to.... well, you get the point.

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From profjcnash at gmail.com  Sun Apr 23 16:06:00 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 23 Apr 2017 10:06:00 -0400
Subject: [R] Interesting quirk with fractions and rounding / using ==
 for floating point
In-Reply-To: <A579B35C-DE07-4089-A700-C99D2432F281@gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
 <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
 <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>
 <A579B35C-DE07-4089-A700-C99D2432F281@gmail.com>
Message-ID: <8f4aad05-f9b4-86e2-435c-e31581aefa8c@gmail.com>

Yes. I should have mentioned "optimizing" compilers, and I can agree with "never
trusting exact equality", though I consider conscious use of equality tests useful.
Optimizing compilers have bitten me once or twice. Unfortunately, a lot of
floating-point work requires attention to detail. In the situation of testing
for convergence, the alternatives to the test I propose require quite a lot of
code, with variants for different levels of precision e.g., single, double, quad.

There's no universal answer and we do have to look "under the hood". A particularly
nasty instance (now fortunately long gone) was the Tektronix 4051 graphics station,
where the comparisons automatically included a "fuzz". There was a FUZZ command to
set this. Sometimes the "good old days" weren't! Today's equivalent is when there
is an upstream change to an "optimization" that changes the manner of computation,
as in Peter's examples. If we specify x <- y * (a / b), then we should not get
x <- (y * a) / b.

A slightly related case concerns eigenvectors / singular vectors when there are
degenerate values (i.e., two or more equal eigenvalues). The vectors are then
determined only to lie in a (hyper)plane. A large computer contracting firm spent
two weeks of high-priced but non-numerical help trying to find the "error" in either
an IBM or Univac program because they gave very different eigenvectors.

And in my own field of function minimization / nonlinear least squares, it is quite
common to have multiple minima or a plateau.

Does anyone know if R has a test suite to check some of these situations? If not,
I'll be happy to participate in generating some. They would not need to be run
very often, and could be useful as a didactic tool as well as checking for
differences in platforms.

JN

On 2017-04-23 09:37 AM, peter dalgaard wrote:
>
>> On 23 Apr 2017, at 14:49 , J C Nash <profjcnash at gmail.com> wrote:
>>
>>
>> So equality in floating point is not always "wrong", though it should be used
>> with some attention to what is going on.
>>
>> Apologies to those (e.g., Peter D.) who have heard this all before. I suspect
>> there are many to whom it is new.
>
> Peter D. still insists on never trusting exact equality, though. There was at least one case in the R sources where age-old code got itself into a condition where a residual terme that provably should decrease on every iteration oscillated between two values of 1-2 ulp in magnitude without ever reaching 0. The main thing is that you cannot trust optimising compilers these days. There is, e.g.,  no guarantee that a compiler will not transform
>
> (x_new + offset) == (x_old + offset)
>
> to
>
> (x_new + offset) - (x_old + offset) == 0
>
> to
>
> (x_new - x_old) + (offset - offset) == 0
>
> to.... well, you get the point.
>
> -pd
>


From rmh at temple.edu  Sun Apr 23 17:42:16 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 23 Apr 2017 11:42:16 -0400
Subject: [R] Interesting quirk with fractions and rounding / using ==
 for floating point
In-Reply-To: <8f4aad05-f9b4-86e2-435c-e31581aefa8c@gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
 <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
 <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>
 <A579B35C-DE07-4089-A700-C99D2432F281@gmail.com>
 <8f4aad05-f9b4-86e2-435c-e31581aefa8c@gmail.com>
Message-ID: <CAGx1TMCFvBdSrtQOD77KWSvMJ6f+VW0ZrzkajZMkBJ1FGhE_Ng@mail.gmail.com>

John,

I would be happy to participate in designing the test suite you suggest.

About a year ago I revised FAQ 7.31, based on my talk at the Aalberg R
conference.  It now points, in addition to the Goldberg paper that has
been referenced there for a long time, to my appendix on precision.
Here is the link from the FAQ

      A discussion with many easily followed examples is in Appendix G
   "Computational Precision and Floating Point Arithmetic", pages 753-771
   of _Statistical Analysis and Data Display: An Intermediate Course with
   Examples in R_, Richard M. Heiberger and Burt Holland (Springer 2015,
   second edition).  This appendix is a free download from
   <http://link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf>.

The appendix is based on the paper I gave at the Aalberg R
Conference. It uses the Rmpfr package to illustrate exactly what
is happening at the level of the machine arithmetic.  The
investigation and discussion of the effect of optimization on
floating point arithmetic should use the Rmpfr tools.


Rich

On Sun, Apr 23, 2017 at 10:06 AM, J C Nash <profjcnash at gmail.com> wrote:
> Yes. I should have mentioned "optimizing" compilers, and I can agree with
> "never
> trusting exact equality", though I consider conscious use of equality tests
> useful.
> Optimizing compilers have bitten me once or twice. Unfortunately, a lot of
> floating-point work requires attention to detail. In the situation of
> testing
> for convergence, the alternatives to the test I propose require quite a lot
> of
> code, with variants for different levels of precision e.g., single, double,
> quad.
>
> There's no universal answer and we do have to look "under the hood". A
> particularly
> nasty instance (now fortunately long gone) was the Tektronix 4051 graphics
> station,
> where the comparisons automatically included a "fuzz". There was a FUZZ
> command to
> set this. Sometimes the "good old days" weren't! Today's equivalent is when
> there
> is an upstream change to an "optimization" that changes the manner of
> computation,
> as in Peter's examples. If we specify x <- y * (a / b), then we should not
> get
> x <- (y * a) / b.
>
> A slightly related case concerns eigenvectors / singular vectors when there
> are
> degenerate values (i.e., two or more equal eigenvalues). The vectors are
> then
> determined only to lie in a (hyper)plane. A large computer contracting firm
> spent
> two weeks of high-priced but non-numerical help trying to find the "error"
> in either
> an IBM or Univac program because they gave very different eigenvectors.
>
> And in my own field of function minimization / nonlinear least squares, it
> is quite
> common to have multiple minima or a plateau.
>
> Does anyone know if R has a test suite to check some of these situations? If
> not,
> I'll be happy to participate in generating some. They would not need to be
> run
> very often, and could be useful as a didactic tool as well as checking for
> differences in platforms.
>
> JN
>
> On 2017-04-23 09:37 AM, peter dalgaard wrote:
>>
>>
>>> On 23 Apr 2017, at 14:49 , J C Nash <profjcnash at gmail.com> wrote:
>>>
>>>
>>> So equality in floating point is not always "wrong", though it should be
>>> used
>>> with some attention to what is going on.
>>>
>>> Apologies to those (e.g., Peter D.) who have heard this all before. I
>>> suspect
>>> there are many to whom it is new.
>>
>>
>> Peter D. still insists on never trusting exact equality, though. There was
>> at least one case in the R sources where age-old code got itself into a
>> condition where a residual terme that provably should decrease on every
>> iteration oscillated between two values of 1-2 ulp in magnitude without ever
>> reaching 0. The main thing is that you cannot trust optimising compilers
>> these days. There is, e.g.,  no guarantee that a compiler will not transform
>>
>> (x_new + offset) == (x_old + offset)
>>
>> to
>>
>> (x_new + offset) - (x_old + offset) == 0
>>
>> to
>>
>> (x_new - x_old) + (offset - offset) == 0
>>
>> to.... well, you get the point.
>>
>> -pd
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Sun Apr 23 18:12:38 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 23 Apr 2017 12:12:38 -0400
Subject: [R] Interesting quirk with fractions and rounding / using ==
 for floating point
In-Reply-To: <CAGx1TMCFvBdSrtQOD77KWSvMJ6f+VW0ZrzkajZMkBJ1FGhE_Ng@mail.gmail.com>
References: <CAErODj9B18aRSjB5u2F=8Dx_eCXE57JPk6+PmTF1Hcdn22qVbA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A2157D@SRVEXCHCM301.precheza.cz>
 <CAErODj_Oct4oKZy53uMY8A7=+qUroqQ9DF6dD6zdC54+GoCAAw@mail.gmail.com>
 <e14310d7-17fb-b7f3-a887-05a641235979@accucom.net>
 <CAErODj-a0_5tLrdi0b75SOnG=JpFddADnw4ZkwfbRFPotc-9ZQ@mail.gmail.com>
 <66a5a6b8-fbf0-0f66-6316-5a197c3974f0@gmail.com>
 <A579B35C-DE07-4089-A700-C99D2432F281@gmail.com>
 <8f4aad05-f9b4-86e2-435c-e31581aefa8c@gmail.com>
 <CAGx1TMCFvBdSrtQOD77KWSvMJ6f+VW0ZrzkajZMkBJ1FGhE_Ng@mail.gmail.com>
Message-ID: <b7cb8b8d-49e1-275c-db04-012afe2bf5b4@gmail.com>

Thanks Richard.

I've some stuff too, but I need to look it up. A few years ago I built
a small test spreadsheet for Gnumeric when working with Jody Goldberg.
In the early 2000s, Jody contacted R (I think Duncan Murdoch) to ask if
it was OK for Gnumeric to use R's distribution function approximations (Yes).
Someone can correct me if wrong, but apparently a few weeks later Jody
sent some improvements, and I believe these were incorporated. Good
open-source improvements like that deserve to be recorded in a better way
than I have done here. But in any event, I can dig out that material, as
well as some of Kahan's PARANOIA materials.

Suggest taking the discussion off-line from here on unless we come up
with some important bugs or improvements or ...

Best, JN


On 2017-04-23 11:42 AM, Richard M. Heiberger wrote:
> John,
>
> I would be happy to participate in designing the test suite you suggest.
>
> About a year ago I revised FAQ 7.31, based on my talk at the Aalberg R
> conference.  It now points, in addition to the Goldberg paper that has
> been referenced there for a long time, to my appendix on precision.
> Here is the link from the FAQ
>
>       A discussion with many easily followed examples is in Appendix G
>    "Computational Precision and Floating Point Arithmetic", pages 753-771
>    of _Statistical Analysis and Data Display: An Intermediate Course with
>    Examples in R_, Richard M. Heiberger and Burt Holland (Springer 2015,
>    second edition).  This appendix is a free download from
>    <http://link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf>.
>
> The appendix is based on the paper I gave at the Aalberg R
> Conference. It uses the Rmpfr package to illustrate exactly what
> is happening at the level of the machine arithmetic.  The
> investigation and discussion of the effect of optimization on
> floating point arithmetic should use the Rmpfr tools.
>
>
> Rich
>
> On Sun, Apr 23, 2017 at 10:06 AM, J C Nash <profjcnash at gmail.com> wrote:
>> Yes. I should have mentioned "optimizing" compilers, and I can agree with
>> "never
>> trusting exact equality", though I consider conscious use of equality tests
>> useful.
>> Optimizing compilers have bitten me once or twice. Unfortunately, a lot of
>> floating-point work requires attention to detail. In the situation of
>> testing
>> for convergence, the alternatives to the test I propose require quite a lot
>> of
>> code, with variants for different levels of precision e.g., single, double,
>> quad.
>>
>> There's no universal answer and we do have to look "under the hood". A
>> particularly
>> nasty instance (now fortunately long gone) was the Tektronix 4051 graphics
>> station,
>> where the comparisons automatically included a "fuzz". There was a FUZZ
>> command to
>> set this. Sometimes the "good old days" weren't! Today's equivalent is when
>> there
>> is an upstream change to an "optimization" that changes the manner of
>> computation,
>> as in Peter's examples. If we specify x <- y * (a / b), then we should not
>> get
>> x <- (y * a) / b.
>>
>> A slightly related case concerns eigenvectors / singular vectors when there
>> are
>> degenerate values (i.e., two or more equal eigenvalues). The vectors are
>> then
>> determined only to lie in a (hyper)plane. A large computer contracting firm
>> spent
>> two weeks of high-priced but non-numerical help trying to find the "error"
>> in either
>> an IBM or Univac program because they gave very different eigenvectors.
>>
>> And in my own field of function minimization / nonlinear least squares, it
>> is quite
>> common to have multiple minima or a plateau.
>>
>> Does anyone know if R has a test suite to check some of these situations? If
>> not,
>> I'll be happy to participate in generating some. They would not need to be
>> run
>> very often, and could be useful as a didactic tool as well as checking for
>> differences in platforms.
>>
>> JN
>>
>> On 2017-04-23 09:37 AM, peter dalgaard wrote:
>>>
>>>
>>>> On 23 Apr 2017, at 14:49 , J C Nash <profjcnash at gmail.com> wrote:
>>>>
>>>>
>>>> So equality in floating point is not always "wrong", though it should be
>>>> used
>>>> with some attention to what is going on.
>>>>
>>>> Apologies to those (e.g., Peter D.) who have heard this all before. I
>>>> suspect
>>>> there are many to whom it is new.
>>>
>>>
>>> Peter D. still insists on never trusting exact equality, though. There was
>>> at least one case in the R sources where age-old code got itself into a
>>> condition where a residual terme that provably should decrease on every
>>> iteration oscillated between two values of 1-2 ulp in magnitude without ever
>>> reaching 0. The main thing is that you cannot trust optimising compilers
>>> these days. There is, e.g.,  no guarantee that a compiler will not transform
>>>
>>> (x_new + offset) == (x_old + offset)
>>>
>>> to
>>>
>>> (x_new + offset) - (x_old + offset) == 0
>>>
>>> to
>>>
>>> (x_new - x_old) + (offset - offset) == 0
>>>
>>> to.... well, you get the point.
>>>
>>> -pd
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From darth.pathos at gmail.com  Sun Apr 23 04:29:48 2017
From: darth.pathos at gmail.com (Chris Battiston)
Date: Sat, 22 Apr 2017 22:29:48 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
Message-ID: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>

Good evening,

I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.  

Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.

Thanks so much for your time and have a good evening
Chris


From uriblasbalg at gmail.com  Sun Apr 23 15:53:04 2017
From: uriblasbalg at gmail.com (Uri Blasbalg)
Date: Sun, 23 Apr 2017 16:53:04 +0300
Subject: [R] question: mediation results are not in line with compression of
 glmm consisted models
Message-ID: <CAMcDj2qa=8Rjj6=xUW3wBKKJR4nEAVaK6wo2-Re2HR1WVDeniQ@mail.gmail.com>

hi all,
I'll begin with my two question and all the related information
(description of the research and the data and full output) will follow.

1. When i execute model1 (glmm with random intercept only for subjects):
predictor (suppBin) and outcome (DtlsBinUp) and pre-intervention variables,
it results with significance . when I carry out model 2: add the mediator
(rlctDown) too as a predictor, the association shown in the model1 isn't
significant anymore (suppBin-DtlsBinup), and for the mediator and outcome
it is (rlctDown-dtlsBinup), with higher coefficient. that should imply for
full mediation, meaning there isn't direct effect between the predictor and
the outcome, only indirect. but when i the test mediation model (monte
carlo method), I gel significant effect for total effect, direct effect and
the indirect effect. how can it be that the monte carlo contradicts what
shown when substracting model1 from model2? what am i missing?

2.i am having trouble in interpreting the values of the effects estimations
in the monte carlo test. I understood the coefficients for the glmm
as log odds that after transforming using exponential function can be
understood as odds and may also be expressed as probabilities. but
the estimates in the monte carlo output are much lower than those in the
glmm output. so how should they be understood.

following are description and output,
thank you
uri.





********** predictor - outcome


Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: dtlsBinUp ~ suppBin * qu + ageS + gender + (1 | PD)
   Data: hypoTest
Control: glmerControl(tolPwrss = 0.001)

     AIC      BIC   logLik deviance df.resid
 15351.9  15406.1  -7669.0  15337.9    17111

Scaled residuals:
    Min      1Q  Median      3Q     Max
-0.6655 -0.5281 -0.5140 -0.1889  5.4472

Random effects:
 Groups Name        Variance Std.Dev.
 PD     (Intercept) 0        0
Number of obs: 17118, groups:  PD, 200

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.20574    0.14668 -21.856  < 2e-16 ***
suppBin      0.57468    0.15930   3.607 0.000309 ***
qu           2.02646    0.10902  18.588  < 2e-16 ***
ageS        -0.09564    0.09923  -0.964 0.335151
gender      -0.05598    0.04141  -1.352 0.176458
suppBin:qu  -0.15165    0.17283  -0.877 0.380250
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) suppBn qu     ageS   gender
suppBin    -0.495
qu         -0.718  0.655
ageS       -0.673  0.010  0.002
gender     -0.179  0.008  0.034  0.065
suppBin:qu  0.456 -0.922 -0.631 -0.004 -0.028



********** predictor, mediator - outcome


Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: dtlsBinUp ~ suppBin * qu + rlctDown + ageS + gender + (1 | PD)
   Data: hypoTest
Control: glmerControl(tolPwrss = 0.001)

     AIC      BIC   logLik deviance df.resid
 14114.1  14176.0  -7049.0  14098.1    17110

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.5239 -0.4638 -0.4552 -0.1487  6.8990

Random effects:
 Groups Name        Variance Std.Dev.
 PD     (Intercept) 0        0
Number of obs: 17118, groups:  PD, 200

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.69635    0.15247  -24.24   <2e-16 ***
suppBin      0.14896    0.16475    0.90    0.366
qu           2.26040    0.11289   20.02   <2e-16 ***
rlctDown     2.06709    0.05947   34.76   <2e-16 ***
ageS        -0.10680    0.10432   -1.02    0.306
gender      -0.02293    0.04360   -0.53    0.599
suppBin:qu   0.13720    0.17963    0.76    0.445
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) suppBn qu     rlctDw ageS   gender
suppBin    -0.462
qu         -0.708  0.629
rlctDown   -0.159 -0.088  0.143
ageS       -0.665  0.000 -0.018 -0.005
gender     -0.184  0.008  0.035  0.024  0.066
suppBin:qu  0.426 -0.916 -0.607  0.062  0.005 -0.029




********** predictor, mediator - outcome (function "mediate" from packege
"mediation"

** script (syntax):
med.out.8.1.2.1 <- mediate(model3.1, model8.1.2.med, treat = "suppBin",
mediator = "rlctDown",
                   sims = 1000)


Causal Mediation Analysis

Quasi-Bayesian Confidence Intervals

Mediator Groups: PD

Outcome Groups: PD

Output Based on Overall Averages Across Groups

                         Estimate 95% CI Lower 95% CI Upper p-value
ACME (control)             0.0401       0.0321       0.0481       0
ACME (treated)             0.0420       0.0338       0.0506       0
ADE (control)              0.0376       0.0178       0.0575       0
ADE (treated)              0.0395       0.0189       0.0595       0
Total Effect               0.0796       0.0580       0.1013       0
Prop. Mediated (control)   0.5015       0.3890       0.6852       0
Prop. Mediated (treated)   0.5276       0.4127       0.7081       0
ACME (average)             0.0410       0.0329       0.0492       0
ADE (average)              0.0385       0.0183       0.0584       0
Prop. Mediated (average)   0.5145       0.3999       0.6961       0

Sample Size Used: 17118


Simulations: 1000

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Apr 23 20:42:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 23 Apr 2017 11:42:52 -0700
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
Message-ID: <CAGxFJbRc3wcdOgF_m__9xygpPVsFtWiRPVN6OUYATWUYx96iag@mail.gmail.com>

"I cannot seem to get them to work as i need them to"  does not
provide sufficient information for anyone to help you. See -- and
follow -- the posting guide to get useful help.

My advice would be to forget it: you need to spend (far) more time
learning about the options and tools than you have. Be realistic.

(Of course, others may diagree and be able to rescue you).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 22, 2017 at 7:29 PM, Chris Battiston <darth.pathos at gmail.com> wrote:
> Good evening,
>
> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>
> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>
> Thanks so much for your time and have a good evening
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Apr 23 20:45:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 23 Apr 2017 11:45:18 -0700
Subject: [R] question: mediation results are not in line with
 compression of glmm consisted models
In-Reply-To: <CAMcDj2qa=8Rjj6=xUW3wBKKJR4nEAVaK6wo2-Re2HR1WVDeniQ@mail.gmail.com>
References: <CAMcDj2qa=8Rjj6=xUW3wBKKJR4nEAVaK6wo2-Re2HR1WVDeniQ@mail.gmail.com>
Message-ID: <CAGxFJbTzAUEKB8A6Dkxx8Qo6BSnt3vVmt1p=2XbUaDKCvChRPQ@mail.gmail.com>

This is not a statistical help site, and your questions appear to be
about statistics, not programming in R. I would suggest that you get
local statistical help, but you might try posting on a
stats.stackexchange.com for remote help.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 23, 2017 at 6:53 AM, Uri Blasbalg <uriblasbalg at gmail.com> wrote:
> hi all,
> I'll begin with my two question and all the related information
> (description of the research and the data and full output) will follow.
>
> 1. When i execute model1 (glmm with random intercept only for subjects):
> predictor (suppBin) and outcome (DtlsBinUp) and pre-intervention variables,
> it results with significance . when I carry out model 2: add the mediator
> (rlctDown) too as a predictor, the association shown in the model1 isn't
> significant anymore (suppBin-DtlsBinup), and for the mediator and outcome
> it is (rlctDown-dtlsBinup), with higher coefficient. that should imply for
> full mediation, meaning there isn't direct effect between the predictor and
> the outcome, only indirect. but when i the test mediation model (monte
> carlo method), I gel significant effect for total effect, direct effect and
> the indirect effect. how can it be that the monte carlo contradicts what
> shown when substracting model1 from model2? what am i missing?
>
> 2.i am having trouble in interpreting the values of the effects estimations
> in the monte carlo test. I understood the coefficients for the glmm
> as log odds that after transforming using exponential function can be
> understood as odds and may also be expressed as probabilities. but
> the estimates in the monte carlo output are much lower than those in the
> glmm output. so how should they be understood.
>
> following are description and output,
> thank you
> uri.
>
>
>
>
>
> ********** predictor - outcome
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: dtlsBinUp ~ suppBin * qu + ageS + gender + (1 | PD)
>    Data: hypoTest
> Control: glmerControl(tolPwrss = 0.001)
>
>      AIC      BIC   logLik deviance df.resid
>  15351.9  15406.1  -7669.0  15337.9    17111
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -0.6655 -0.5281 -0.5140 -0.1889  5.4472
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  PD     (Intercept) 0        0
> Number of obs: 17118, groups:  PD, 200
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -3.20574    0.14668 -21.856  < 2e-16 ***
> suppBin      0.57468    0.15930   3.607 0.000309 ***
> qu           2.02646    0.10902  18.588  < 2e-16 ***
> ageS        -0.09564    0.09923  -0.964 0.335151
> gender      -0.05598    0.04141  -1.352 0.176458
> suppBin:qu  -0.15165    0.17283  -0.877 0.380250
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>            (Intr) suppBn qu     ageS   gender
> suppBin    -0.495
> qu         -0.718  0.655
> ageS       -0.673  0.010  0.002
> gender     -0.179  0.008  0.034  0.065
> suppBin:qu  0.456 -0.922 -0.631 -0.004 -0.028
>
>
>
> ********** predictor, mediator - outcome
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: dtlsBinUp ~ suppBin * qu + rlctDown + ageS + gender + (1 | PD)
>    Data: hypoTest
> Control: glmerControl(tolPwrss = 0.001)
>
>      AIC      BIC   logLik deviance df.resid
>  14114.1  14176.0  -7049.0  14098.1    17110
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.5239 -0.4638 -0.4552 -0.1487  6.8990
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  PD     (Intercept) 0        0
> Number of obs: 17118, groups:  PD, 200
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -3.69635    0.15247  -24.24   <2e-16 ***
> suppBin      0.14896    0.16475    0.90    0.366
> qu           2.26040    0.11289   20.02   <2e-16 ***
> rlctDown     2.06709    0.05947   34.76   <2e-16 ***
> ageS        -0.10680    0.10432   -1.02    0.306
> gender      -0.02293    0.04360   -0.53    0.599
> suppBin:qu   0.13720    0.17963    0.76    0.445
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>            (Intr) suppBn qu     rlctDw ageS   gender
> suppBin    -0.462
> qu         -0.708  0.629
> rlctDown   -0.159 -0.088  0.143
> ageS       -0.665  0.000 -0.018 -0.005
> gender     -0.184  0.008  0.035  0.024  0.066
> suppBin:qu  0.426 -0.916 -0.607  0.062  0.005 -0.029
>
>
>
>
> ********** predictor, mediator - outcome (function "mediate" from packege
> "mediation"
>
> ** script (syntax):
> med.out.8.1.2.1 <- mediate(model3.1, model8.1.2.med, treat = "suppBin",
> mediator = "rlctDown",
>                    sims = 1000)
>
>
> Causal Mediation Analysis
>
> Quasi-Bayesian Confidence Intervals
>
> Mediator Groups: PD
>
> Outcome Groups: PD
>
> Output Based on Overall Averages Across Groups
>
>                          Estimate 95% CI Lower 95% CI Upper p-value
> ACME (control)             0.0401       0.0321       0.0481       0
> ACME (treated)             0.0420       0.0338       0.0506       0
> ADE (control)              0.0376       0.0178       0.0575       0
> ADE (treated)              0.0395       0.0189       0.0595       0
> Total Effect               0.0796       0.0580       0.1013       0
> Prop. Mediated (control)   0.5015       0.3890       0.6852       0
> Prop. Mediated (treated)   0.5276       0.4127       0.7081       0
> ACME (average)             0.0410       0.0329       0.0492       0
> ADE (average)              0.0385       0.0183       0.0584       0
> Prop. Mediated (average)   0.5145       0.3999       0.6961       0
>
> Sample Size Used: 17118
>
>
> Simulations: 1000
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sun Apr 23 21:07:19 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Sun, 23 Apr 2017 15:07:19 -0400
Subject: [R] "Copy-pastable" output of 1000 plus variables
Message-ID: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>

R-helpers:
I'm reading "Advanced R" (Wickham), which provides his way, quoted below, of keeping variables. This cherry-picking approach clearly is not practical with a large dataset. 

"If you know the columns you don?t want, use set operations to work out which colums to keep: df[setdiff(names(df), "z")]"

I'm looking for a way of producing an output of 1000 plus variables, such that I can get a clean listing of variables, not like from st(), that are easily copy-pastable for selecting the variables I want to keep. 

Any suggestion is appreciated.
Thanks. 
Bruce


From jdnewmil at dcn.davis.ca.us  Sun Apr 23 21:21:31 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 23 Apr 2017 12:21:31 -0700
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
Message-ID: <9E451B13-1208-45F5-BAF8-F172D2CDFDF6@dcn.davis.ca.us>

You have a lot of limitations... haven't left much room for success. Not sure how to help.

I am told that Microsoft provides a cloud solution in which R can be used, but I don't think you would get much useful help in setting that up on this free mailing list... generally you have to pay to play there. 
-- 
Sent from my phone. Please excuse my brevity.

On April 22, 2017 7:29:48 PM PDT, Chris Battiston <darth.pathos at gmail.com> wrote:
>Good evening,
>
>I?m relatively new to using R and am trying to find a way to create a
>series of interconnected graphs where I have a filter (either a drop
>down or series of checkboxes) where when an option is selected, all
>graphs are updated to show that group?s data.  I need to keep these
>graphs internal to our organization, so can?t use Shiny etc.; I am also
>unable to run R or other products on my server (company policy).  So,
>basically what I?m trying to do is create the dashboard on my desktop,
>export the HTML or whatever files, and post those to the Intranet.  I
>have tried ggvis, iplots, and a variety of other packages but I cannot
>seem to get them to work as i need them to.  
>
>Any suggestions?  I need to present my proposed plan to the directors
>on Wednesday and really don?t want to use Excel for the graphs - I want
>this to be intuitive for them, but ensuring that the report is easily
>maintained and more flexible than a Pivot Table.
>
>Thanks so much for your time and have a good evening
>Chris
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Apr 23 21:57:43 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Apr 2017 13:57:43 -0600
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
Message-ID: <CB1A5DBF-25D8-4F1C-97CA-CB52C3006801@comcast.net>

It would be best if you could demonstrate _with_ _code_ the sort of operation you propose.

David

Sent from my iPhone

> On Apr 23, 2017, at 1:07 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> 
> R-helpers:
> I'm reading "Advanced R" (Wickham), which provides his way, quoted below, of keeping variables. This cherry-picking approach clearly is not practical with a large dataset. 
> 
> "If you know the columns you don?t want, use set operations to work out which colums to keep: df[setdiff(names(df), "z")]"
> 
> I'm looking for a way of producing an output of 1000 plus variables, such that I can get a clean listing of variables, not like from st(), that are easily copy-pastable for selecting the variables I want to keep. 
> 
> Any suggestion is appreciated.
> Thanks. 
> Bruce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Apr 23 22:11:50 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 23 Apr 2017 16:11:50 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
Message-ID: <66ffd1c8-362b-0ca1-b44e-820a24efa0ce@gmail.com>

On 22/04/2017 10:29 PM, Chris Battiston wrote:
> Good evening,
>
> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>
> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>

Given that you can't run R on the server, you would basically need to 
produce all possible displays in advance, then have your web page select 
which one to show based on the controls on the page. (You might be able 
to show all data, then have the checkboxes set some points to be 
invisible, but that gets tricky.)

The rgl package does things like that but is aimed at 3D plots; getting 
it to do good looking 2D plots isn't easy.

On the other hand, this is pretty easy to do using Shiny or RStudio 
Connect (a paid service, see https://www.rstudio.com/products/connect/), 
which could run on your own server.  So I'd try to relax your constraints.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Sun Apr 23 22:38:53 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 23 Apr 2017 13:38:53 -0700
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
Message-ID: <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>

Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis. 

Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend. 

Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:

a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list. 

b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.

# typically easier to manage in an external data file, online for example only
colsets <- read.csv( text=
"Colname,set1,set2
key,TRUE,TRUE
value1,TRUE,FALSE
value2,TRUE,FALSE
factor1,FALSE,TRUE
",header=TRUE,as.is=TRUE)
dta[ , colsets$set1 ]

Also your criteria of "clean listing" and "copy-pasteable" are likely mutually exclusive, depending how you interpret them. You might be able to use dput to export a set of column names that can be re-imported accurately, but you might not regard it as "clean" if you are thinking "readable".
-- 
Sent from my phone. Please excuse my brevity.

On April 23, 2017 12:07:19 PM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>R-helpers:
>I'm reading "Advanced R" (Wickham), which provides his way, quoted
>below, of keeping variables. This cherry-picking approach clearly is
>not practical with a large dataset. 
>
>"If you know the columns you don?t want, use set operations to work out
>which colums to keep: df[setdiff(names(df), "z")]"
>
>I'm looking for a way of producing an output of 1000 plus variables,
>such that I can get a clean listing of variables, not like from st(),
>that are easily copy-pastable for selecting the variables I want to
>keep. 
>
>Any suggestion is appreciated.
>Thanks. 
>Bruce
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Sun Apr 23 22:43:07 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 23 Apr 2017 16:43:07 -0400
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <CB1A5DBF-25D8-4F1C-97CA-CB52C3006801@comcast.net>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <CB1A5DBF-25D8-4F1C-97CA-CB52C3006801@comcast.net>
Message-ID: <922ef5a0-7103-7665-571d-187ad0b985cf@dmstat1.com>

David:
I cannot demonstrate _with_ _code_ , otherwise I would not have a 
problem. However, I can illustrate:
In SAS, I can run Proc SQL for a dump, VARLIST_IS_HERE, showing on the 
computer screen the variables, e.g., ID, X1, X2, X3, ..., X1000,
  that I can copy and paste into the editor window (e.g., R Source 
window) to easily select which variables among the big data of today
I want keep.


  

David Winsemius wrote:
> It would be best if you could demonstrate _with_ _code_ the sort of operation you propose.
>
> David
>
> Sent from my iPhone
>
>> On Apr 23, 2017, at 1:07 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>
>> R-helpers:
>> I'm reading "Advanced R" (Wickham), which provides his way, quoted below, of keeping variables. This cherry-picking approach clearly is not practical with a large dataset.
>>
>> "If you know the columns you don?t want, use set operations to work out which colums to keep: df[setdiff(names(df), "z")]"
>>
>> I'm looking for a way of producing an output of 1000 plus variables, such that I can get a clean listing of variables, not like from st(), that are easily copy-pastable for selecting the variables I want to keep.
>>
>> Any suggestion is appreciated.
>> Thanks.
>> Bruce
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From br at dmstat1.com  Sun Apr 23 22:46:41 2017
From: br at dmstat1.com (BR_email)
Date: Sun, 23 Apr 2017 16:46:41 -0400
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
Message-ID: <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>

Jeff:
Thanks, Please see my reply to David.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Jeff Newmiller wrote:
> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis.
>
> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend.
>
> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
>
> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list.
>
> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
>
> # typically easier to manage in an external data file, online for example only
> colsets <- read.csv( text=
> "Colname,set1,set2
> key,TRUE,TRUE
> value1,TRUE,FALSE
> value2,TRUE,FALSE
> factor1,FALSE,TRUE
> ",header=TRUE,as.is=TRUE)
> dta[ , colsets$set1 ]
>
> Also your criteria of "clean listing" and "copy-pasteable" are likely mutually exclusive, depending how you interpret them. You might be able to use dput to export a set of column names that can be re-imported accurately, but you might not regard it as "clean" if you are thinking "readable".


From sarah.goslee at gmail.com  Sun Apr 23 23:26:32 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 23 Apr 2017 17:26:32 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
Message-ID: <CAM_vjukKehDgKfSdscaw3FLdqOdYcr2O5HJHhmjXBbtumy3Y7g@mail.gmail.com>

HI Chris,

You can use the R plotly library on your own computer to create the
interactive graph, then upload the code to the server.

I have a setup like that where real-time data is processed every hour,
a Rmarkdown file is rendered using the R plotly package to make the
graphs, and then the resulting html file is copied to the server.

It sounds like exactly what you need.

Sarah

On Sat, Apr 22, 2017 at 10:29 PM, Chris Battiston
<darth.pathos at gmail.com> wrote:
> Good evening,
>
> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>
> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>
> Thanks so much for your time and have a good evening
> Chris


Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Mon Apr 24 01:26:33 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 23 Apr 2017 23:26:33 +0000
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
 <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>
Message-ID: <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>

This might work for you:

cols <- LETTERS # actually this will be cols <- colnames(df) in your example
# Create a data frame to select columns
choose <- data.frame(cols, select=0, stringsAsFactors=FALSE)
# Run the editor and replace 0 with 1 in the select column 
# for each variable you wish to include
fix(choose)
# Your list of variables will be the vector mycols
mycols <- choose$cols[choose$select==1]


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
Sent: Sunday, April 23, 2017 3:47 PM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
Subject: Re: [R] "Copy-pastable" output of 1000 plus variables

Jeff:
Thanks, Please see my reply to David.
Bruce

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

Jeff Newmiller wrote:
> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis.
>
> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend.
>
> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
>
> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list.
>
> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
>
> # typically easier to manage in an external data file, online for example only
> colsets <- read.csv( text=
> "Colname,set1,set2
> key,TRUE,TRUE
> value1,TRUE,FALSE
> value2,TRUE,FALSE
> factor1,FALSE,TRUE
> ",header=TRUE,as.is=TRUE)
> dta[ , colsets$set1 ]
>
> Also your criteria of "clean listing" and "copy-pasteable" are likely mutually exclusive, depending how you interpret them. You might be able to use dput to export a set of column names that can be re-imported accurately, but you might not regard it as "clean" if you are thinking "readable".

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From darth.pathos at gmail.com  Sun Apr 23 20:59:14 2017
From: darth.pathos at gmail.com (Chris Battiston)
Date: Sun, 23 Apr 2017 14:59:14 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <CAGxFJbRc3wcdOgF_m__9xygpPVsFtWiRPVN6OUYATWUYx96iag@mail.gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
 <CAGxFJbRc3wcdOgF_m__9xygpPVsFtWiRPVN6OUYATWUYx96iag@mail.gmail.com>
Message-ID: <260E3BF0-938D-47BC-BAFB-CAAAE9F19891@gmail.com>

Thanks Bert - you?re absolutely right, although it?s my first post on the R Mailing list, I participate in a number of others and should?ve taken my own advice of ?not posting when frustrated?.  

More background - I have tried multiple graphics packages (including iPlots, ggvis, ggplot2, dplyr, etc) using the examples from the documentation.  Copying and pasting the basic examples usually works (I couldn?t get iplots to work, even though i was using JGR as per the documentation) but getting into the more complex examples, especially the ones with the drop downs to filter the data, I could not get to work.  I am running the most recent versions of R and R Studio (3.4 and 1.0.143 respectively) on a MacBook, Mac Desktop, and a Surface Pro with Windows 10 (I was hoping maybe the differences in OS had something to do with the issues, but apparently not).  

Maybe if I describe the goal in more detail, it would be easier.  I have 2 Excel files that I will be getting on a monthly data; one with support tickets and one with customer feedback.  I need to build a dashboard with 4 reports, 2 based on the tickets data and the other on the feedback.  I need to have the dashboard posted to our internal Sharepoint site, so the directors and VPs can go in and see their areas? data.  The ?interconnectedness and interactivity? i was referring to is there needs to be a drop down with all the groups, and when a user selects a department from the dropdown, all 4 graphs update automatically.  

I?m running R locally, so will need something I can export where the file(s) will be self-contained, and then upload them to the Sharepoint.  I know Shiny can do everything I need, but we don?t have any available servers, and the data is extremely sensitive so cannot leave our intranet (per company policy).  

Any thoughts would be appreciated, and apologies again for my previously vague message.

Chris

> On Apr 23, 2017, at 2:42 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> "I cannot seem to get them to work as i need them to"  does not
> provide sufficient information for anyone to help you. See -- and
> follow -- the posting guide to get useful help.
> 
> My advice would be to forget it: you need to spend (far) more time
> learning about the options and tools than you have. Be realistic.
> 
> (Of course, others may diagree and be able to rescue you).
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sat, Apr 22, 2017 at 7:29 PM, Chris Battiston <darth.pathos at gmail.com> wrote:
>> Good evening,
>> 
>> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>> 
>> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>> 
>> Thanks so much for your time and have a good evening
>> Chris
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From darth.pathos at gmail.com  Sun Apr 23 21:47:40 2017
From: darth.pathos at gmail.com (Chris Battiston)
Date: Sun, 23 Apr 2017 15:47:40 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <9E451B13-1208-45F5-BAF8-F172D2CDFDF6@dcn.davis.ca.us>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
 <9E451B13-1208-45F5-BAF8-F172D2CDFDF6@dcn.davis.ca.us>
Message-ID: <9C08D43A-7B90-4DDA-AA2D-6C0F6FD56C53@gmail.com>

Hi Jeff

Thanks for the reply.  Totally understand that my issue may not be resolvable; I was hoping that there was a graphics package I may have missed that I could try.  

Re: Microsoft product - we do actually have a full license to Power BI, but the director who is requesting the reports didn't like how it printed out.  I may just do what I need in an Access database - was hoping to provide a little more functionality but what can you do.

Thanks for your reply
Chris

Sent from my iPhone

> On Apr 23, 2017, at 15:21, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> You have a lot of limitations... haven't left much room for success. Not sure how to help.
> 
> I am told that Microsoft provides a cloud solution in which R can be used, but I don't think you would get much useful help in setting that up on this free mailing list... generally you have to pay to play there. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On April 22, 2017 7:29:48 PM PDT, Chris Battiston <darth.pathos at gmail.com> wrote:
>> Good evening,
>> 
>> I?m relatively new to using R and am trying to find a way to create a
>> series of interconnected graphs where I have a filter (either a drop
>> down or series of checkboxes) where when an option is selected, all
>> graphs are updated to show that group?s data.  I need to keep these
>> graphs internal to our organization, so can?t use Shiny etc.; I am also
>> unable to run R or other products on my server (company policy).  So,
>> basically what I?m trying to do is create the dashboard on my desktop,
>> export the HTML or whatever files, and post those to the Intranet.  I
>> have tried ggvis, iplots, and a variety of other packages but I cannot
>> seem to get them to work as i need them to.  
>> 
>> Any suggestions?  I need to present my proposed plan to the directors
>> on Wednesday and really don?t want to use Excel for the graphs - I want
>> this to be intuitive for them, but ensuring that the report is easily
>> maintained and more flexible than a Pivot Table.
>> 
>> Thanks so much for your time and have a good evening
>> Chris
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From darth.pathos at gmail.com  Sun Apr 23 22:28:16 2017
From: darth.pathos at gmail.com (Chris Battiston)
Date: Sun, 23 Apr 2017 16:28:16 -0400
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <66ffd1c8-362b-0ca1-b44e-820a24efa0ce@gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
 <66ffd1c8-362b-0ca1-b44e-820a24efa0ce@gmail.com>
Message-ID: <00BD0066-B743-4D6E-AEC7-DCFD9D6CC946@gmail.com>

Thanks Duncan - I have 16 groups so generating one output per should be fairly easy.  Unfortunately the constraints are not mine but those from the Senior VP team combined with company policy.  As I said to someone else I may go with an alternative software (Access database maybe) which will be able to do more of what I need.

Have a great day
Chris

Sent from my iPhone

> On Apr 23, 2017, at 16:11, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 22/04/2017 10:29 PM, Chris Battiston wrote:
>> Good evening,
>> 
>> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>> 
>> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>> 
> 
> Given that you can't run R on the server, you would basically need to produce all possible displays in advance, then have your web page select which one to show based on the controls on the page. (You might be able to show all data, then have the checkboxes set some points to be invisible, but that gets tricky.)
> 
> The rgl package does things like that but is aimed at 3D plots; getting it to do good looking 2D plots isn't easy.
> 
> On the other hand, this is pretty easy to do using Shiny or RStudio Connect (a paid service, see https://www.rstudio.com/products/connect/), which could run on your own server.  So I'd try to relax your constraints.
> 
> Duncan Murdoch


From dwinsemius at comcast.net  Mon Apr 24 05:13:09 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Apr 2017 21:13:09 -0600
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
 <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>
 <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <5A4C66B1-6466-476A-843D-2546B1C9B66D@comcast.net>

I don't have a lot of interest in trying to replicate operations in SAS. 

If you don't exhibit the willingness to show code in R then ... best of luck. But do read the Posting Guide to at least understand the local expectations.

Good luck;
David

Sent from my iPhone

> On Apr 23, 2017, at 5:26 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> This might work for you:
> 
> cols <- LETTERS # actually this will be cols <- colnames(df) in your example
> # Create a data frame to select columns
> choose <- data.frame(cols, select=0, stringsAsFactors=FALSE)
> # Run the editor and replace 0 with 1 in the select column 
> # for each variable you wish to include
> fix(choose)
> # Your list of variables will be the vector mycols
> mycols <- choose$cols[choose$select==1]
> 
> 
> David L. Carlson
> Department of Anthropology
> Texas A&M University
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Sunday, April 23, 2017 3:47 PM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
> Subject: Re: [R] "Copy-pastable" output of 1000 plus variables
> 
> Jeff:
> Thanks, Please see my reply to David.
> Bruce
> 
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
> 
> 
> Jeff Newmiller wrote:
>> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis.
>> 
>> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend.
>> 
>> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
>> 
>> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list.
>> 
>> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
>> 
>> # typically easier to manage in an external data f


From dwinsemius at comcast.net  Mon Apr 24 05:39:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Apr 2017 21:39:22 -0600
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
Message-ID: <7B2A3731-C006-460E-8100-9C321D0E3EE8@comcast.net>

In context.

Sent from my iPhone

> On Apr 23, 2017, at 2:38 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis. 
> 
> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend. 

That was not how my wetware interpreter read that code. I saw it as a single argument to "[".

Best;
David
> 
> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
> 
> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list. 
> 
> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
> 
> # typically easier to manage in an external data file, online for example only
> colsets <- read.csv( text=
> "Colname,set1,set2
> key,TRUE,TRUE
> value1,TRUE,FALSE
> value2,TRUE,FALSE
> factor1,FALSE,TRUE
> ",header=TRUE,as.is=TRUE)
> dta[ , colsets$set1 ]
> 
> Also your criteria of "clean listing" and "copy-pasteable" are likely mutually exclusive, depending how you interpret them. You might be able to use dput to export a set of column names that can be re-imported accurately, but you might not regard it as "clean" if you are thinking "readable".
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On April 23, 2017 12:07:19 PM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> R-helpers:
>> I'm reading "Advanced R" (Wickham), which provides his way, quoted
>> below, of keeping variables. This cherry-picking approach clearly is
>> not practical with a large dataset. 
>> 
>> "If you know the columns you don?t want, use set operations to work out
>> which colums to keep: df[setdiff(names(df), "z")]"
>> 
>> I'm looking for a way of producing an output of 1000 plus variables,
>> such that I can get a clean listing of variables, not like from st(),
>> that are easily copy-pastable for selecting the variables I want to
>> keep. 
>> 
>> Any suggestion is appreciated.
>> Thanks. 
>> Bruce
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Mon Apr 24 05:40:38 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Sun, 23 Apr 2017 20:40:38 -0700
Subject: [R] Creating interactive graphs and exporting to Intranet site
In-Reply-To: <CAM_vjukKehDgKfSdscaw3FLdqOdYcr2O5HJHhmjXBbtumy3Y7g@mail.gmail.com>
References: <BBB49E9A-BAFB-48D2-8653-F15F6A4EA8C9@gmail.com>
 <CAM_vjukKehDgKfSdscaw3FLdqOdYcr2O5HJHhmjXBbtumy3Y7g@mail.gmail.com>
Message-ID: <CAA99HCyHcazFz6bdG-0sQBbQ1sYD0biy-PbpKv_+qWQOLrptVA@mail.gmail.com>

Hi Chris (and Sarah),

Chris you've listed a lot of restrictions, but I just wanted to
mention Jeroen Ooms' work developing OpenCPU:

"The OpenCPU system exposes an http API for embedded scientific
computing with R. The server can run either as a single-user
development server within the interactive R session, or as a
multi-user linux stack based on rApache and NGINX."

https://www.opencpu.org
https://www.opencpu.org/apps.html
https://github.com/jeroen/opencpu

You may be able to figure out a way to work around (some of) your
restrictions using opencpu.js, the OpenCPU JavaScript client library.

HTH,

Bill

William Michels, Ph.D.


On Sun, Apr 23, 2017 at 2:26 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> HI Chris,
>
> You can use the R plotly library on your own computer to create the
> interactive graph, then upload the code to the server.
>
> I have a setup like that where real-time data is processed every hour,
> a Rmarkdown file is rendered using the R plotly package to make the
> graphs, and then the resulting html file is copied to the server.
>
> It sounds like exactly what you need.
>
> Sarah
>
> On Sat, Apr 22, 2017 at 10:29 PM, Chris Battiston
> <darth.pathos at gmail.com> wrote:
>> Good evening,
>>
>> I?m relatively new to using R and am trying to find a way to create a series of interconnected graphs where I have a filter (either a drop down or series of checkboxes) where when an option is selected, all graphs are updated to show that group?s data.  I need to keep these graphs internal to our organization, so can?t use Shiny etc.; I am also unable to run R or other products on my server (company policy).  So, basically what I?m trying to do is create the dashboard on my desktop, export the HTML or whatever files, and post those to the Intranet.  I have tried ggvis, iplots, and a variety of other packages but I cannot seem to get them to work as i need them to.
>>
>> Any suggestions?  I need to present my proposed plan to the directors on Wednesday and really don?t want to use Excel for the graphs - I want this to be intuitive for them, but ensuring that the report is easily maintained and more flexible than a Pivot Table.
>>
>> Thanks so much for your time and have a good evening
>> Chris
>
>
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Mon Apr 24 12:37:16 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 24 Apr 2017 06:37:16 -0400
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <5A4C66B1-6466-476A-843D-2546B1C9B66D@comcast.net>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
 <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>
 <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>
 <5A4C66B1-6466-476A-843D-2546B1C9B66D@comcast.net>
Message-ID: <5824e13e-4260-a5c9-2826-3543207c820c@dmstat1.com>

David:
Sorry, of course I will show you the code:
Copy-Pasteable
PROC CONTENTS data=IN
out = vars (keep = name type) noprint;
run;
PROC SQL noprint;
select name into :varlist_is_here separated by ? ? from vars;
quit;
%put _global_ ;

Bruce Ratner, Ph.D.
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analtyics -- www.DMSTAT1.com
Machine-Learning Data Mining and Modeling -- www.GenIQ.net
  

David Winsemius wrote:
> I don't have a lot of interest in trying to replicate operations in SAS.
>
> If you don't exhibit the willingness to show code in R then ... best of luck. But do read the Posting Guide to at least understand the local expectations.
>
> Good luck;
> David
>
> Sent from my iPhone
>
>> On Apr 23, 2017, at 5:26 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> This might work for you:
>>
>> cols <- LETTERS # actually this will be cols <- colnames(df) in your example
>> # Create a data frame to select columns
>> choose <- data.frame(cols, select=0, stringsAsFactors=FALSE)
>> # Run the editor and replace 0 with 1 in the select column
>> # for each variable you wish to include
>> fix(choose)
>> # Your list of variables will be the vector mycols
>> mycols <- choose$cols[choose$select==1]
>>
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
>> Sent: Sunday, April 23, 2017 3:47 PM
>> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
>> Subject: Re: [R] "Copy-pastable" output of 1000 plus variables
>>
>> Jeff:
>> Thanks, Please see my reply to David.
>> Bruce
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics -- www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>>
>>
>> Jeff Newmiller wrote:
>>> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis.
>>>
>>> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend.
>>>
>>> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
>>>
>>> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list.
>>>
>>> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
>>>
>>> # typically easier to manage in an external data f
>
>
>


From br at dmstat1.com  Mon Apr 24 12:51:56 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 24 Apr 2017 06:51:56 -0400
Subject: [R] "Copy-pastable" output of 1000 plus variables
In-Reply-To: <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>
References: <31B82D82-63A5-4EE4-9C39-3C93A449969E@dmstat1.com>
 <D587A5E7-F85E-4C99-8472-E57B03574C9E@dcn.davis.ca.us>
 <36986bd8-6490-e736-96e3-7fcd6100e31a@dmstat1.com>
 <3fd68e69739b439b9d2913daffa99cda@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <65494e5d-16c0-503b-1113-2e8a000c5a7b@dmstat1.com>

David:
Your code worked beautifully.
This little ditty should be high-profile for those who work big data,
which are virtually never accompanied with a data dictionary.
This code is the first step to grab the data at large to bring it down 
in size.
Excellent.
Thank you.
Bruce

  

David L Carlson wrote:
> This might work for you:
>
> cols <- LETTERS # actually this will be cols <- colnames(df) in your example
> # Create a data frame to select columns
> choose <- data.frame(cols, select=0, stringsAsFactors=FALSE)
> # Run the editor and replace 0 with 1 in the select column
> # for each variable you wish to include
> fix(choose)
> # Your list of variables will be the vector mycols
> mycols <- choose$cols[choose$select==1]
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BR_email
> Sent: Sunday, April 23, 2017 3:47 PM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
> Subject: Re: [R] "Copy-pastable" output of 1000 plus variables
>
> Jeff:
> Thanks, Please see my reply to David.
> Bruce
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics -- www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling -- www.GenIQ.net
>    
>
> Jeff Newmiller wrote:
>> Coming from an Excel background, copying and pasting seems attractive, but it does not create a reproducible record of what you did so it becomes quite tiring and frustrating after some time has passed and you return to your analysis.
>>
>> Nitpick: you put the setdiff function in the row selection position, an error I am sure Hadley did not recommend.
>>
>> Since R is programmable, there are far more ways to select columns than just setdiff. Since your description of desired features is vague, you are unlikely to get the answer you would really like from your email. Some possibilities to think about:
>>
>> a) use regular expressions and grep or grepl to select by similar character patterns. E.g. all columns including the the substring "value" or "key": grep( "key|value", names( dta ). Possible to specify very complex selection patterns, but there are whole books on regular expressions, so you can't expect to learn all about them on this R-specific mailing list.
>>
>> b) use a separate csv file with a column listing each column name, and then one column for each subset you want to define, using TRUE/FALSE values to include or not include the column name identified. E.g.
>>
>> # typically easier to manage in an external data file, online for example only
>> colsets <- read.csv( text=
>> "Colname,set1,set2
>> key,TRUE,TRUE
>> value1,TRUE,FALSE
>> value2,TRUE,FALSE
>> factor1,FALSE,TRUE
>> ",header=TRUE,as.is=TRUE)
>> dta[ , colsets$set1 ]
>>
>> Also your criteria of "clean listing" and "copy-pasteable" are likely mutually exclusive, depending how you interpret them. You might be able to use dput to export a set of column names that can be re-imported accurately, but you might not regard it as "clean" if you are thinking "readable".
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abo_dlsh at hotmail.com  Mon Apr 24 07:07:21 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Mon, 24 Apr 2017 05:07:21 +0000
Subject: [R] Frequency of Combinations
Message-ID: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>

Hi there

I have data set with 500,000 patients (rows) and the first column is Patient I'D Number, columns from 2 to 20 are Drug1,Drug 2,...,Drug 20 so each row starts with the patient ID and the remaining of cells in the row are codes for names of the treatments taken by the patient. Number of treatments differ between patients. For example, there are patients with 3 treatments only and patients with 20 drugs. The unique number of treatments in the entire data set is about 6700 drugs. However, I'm interested in studying only 128 drugs, these drugs are listed in a second sheet as code numbers associated with their meanings (names of drugs representing the code). I'm interested in identifying the most frequently used DRUG COMBINATIONS between only the 128 drugs among the 6700 drugs. The structure of the Excell file to be used in analysis is like this:

-Sheet 1( the entire data set):-
1   Patient ID    Drug1    Drug2 ....    Drug 20.
2  1125            45            46                55
3  1126              60           55                 45
.
.
500,000

-Sheet 2 (list of codes meanings for only the drugs of interest):

1    Drug code             meaning
2    45                            Simvastatin
3    55                            Aspirin
4    60                            Paracetamol
.
128

The desired output I'm looking for :

 Drug codes      Meaning          Frequency
45+55               Simvastatin              2
                         +Aspirin
60+55             Aspirin+                       1
                        Paracetamol
60+45             Simvastatin+                1
                        Paracetamol

Please note the the final output does not include any combination containing drug 46 as this is not in the list of drugs preferred to be studied which are mentioned in sheet 2.

Could you please help me which R codes and packages should be used to run this analyisis?

Regards
Mustafa

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 24 09:12:59 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Apr 2017 09:12:59 +0200
Subject: [R] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAF5W3aR8qvjUmJEFsnS3CMSTLsbbpukUKbZHc=ffRY7NarSvew@mail.gmail.com>
References: <CAF5W3aR8qvjUmJEFsnS3CMSTLsbbpukUKbZHc=ffRY7NarSvew@mail.gmail.com>
Message-ID: <CAJuCY5xDhORjH2+3C+Z_kXos1e3740yBqxTmkMK4GCv7mMuBoA@mail.gmail.com>

Please don't cross post. You've send the message to the mixed models
mailing list as well (which more appropriate).

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-21 20:57 GMT+02:00 Juan Pablo Edwards Molina <
edwardsmolina at gmail.com>:

> I am analyzing data from 3 field experiments (farms=3) for a citrus flower
> disease: response variable is binomial because the flower can only be
> diseased or healthy.
>
> I have particular interest in comparing 5 fungicide spraying systems
> (trt=5).
>
> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
> which I assessed 100 flowers each one. This is a quick look of the data:
>
> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
> <fctr> <int> <int>
> iaras      cal      1      1     0    100
> iaras      cal      1      2     1    100
> iaras      cal      2      1     1    100
> iaras      cal      2      2     3    100
> iaras      cal      3      1     0    100
> iaras      cal      3      2     5    100...
>
> The model I considered was:
>
> resp <- with(df, cbind(dis, tot-dis))
>
> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>
> I tested the overdispersion with the overdisp_fun() from GLMM page
> <http://glmm.wikidot.com/faq>
>
>         chisq         ratio             p          logp
>  4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>
> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
> considered to add the observation level random effect (link
> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html>)
> to deal with the overdispersion.
>
> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
> <fctr> <fctr> <int> <int> <fctr>
> iaras      cal      1      1     0    100    1
> iaras      cal      1      2     1    100    2
> iaras      cal      2      1     1    100    3...
>
> so now was added a random effect for each row (tree_id) to the model, but I
> am not sure of how to include it. This is my approach:
>
> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
> data=df)
>
> I also wonder if farm should be a fixed effect, since it has only 3
> levels...
>
> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
> binomial, data=df)
>
> I really appreciate your suggestions about my model specifications...
>
>
>
>
> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
> - ESALQ-USP/Brazil?*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Mon Apr 24 14:35:20 2017
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Mon, 24 Apr 2017 14:35:20 +0200
Subject: [R] Delayed evaluation / lazy expression evaluation
Message-ID: <6e77024e-5d51-4b5d-a68a-3d7796bb69c3@Spark>

Hi, I?m playing around with ways of implementing lazy evaluation of expressions. In R, function arguments are evaluated as promises but expressions are evaluated immediately, so I am trying to wrap expressions in thunks?functions with no arguments that evaluate an expression?to get something the resembles lazy evaluation of expressions.

As an example, consider this:

lazy <- function(value) {
? function() value
}

f <- lazy((1:100000)[1])

If we evaluate f we have to create the long vector and then get the first element. We delay the evaluation to f so the first time we call f we should see a slow operation and if we evaluate it again we should see faster evaluations. If you run this benchmark, you will see that this is indeed what we get:

library(microbenchmark)
microbenchmark(f(), times = 1)
microbenchmark(f(), times = 1)
microbenchmark(f(), times = 1)
microbenchmark(f(), times = 1)

Now, I want to use this to implement lazy linked lists. It is not particularly important why I want to do this, but if you are interested, it is because you can implement persistent queues with amortised constant time operations this way, which is what I am experimenting with.

I have this implementation of linked lists:

list_cons <- function(elem, lst)
? structure(list(head = elem, tail = lst), class = "linked_list")

list_nil <- list_cons(NA, NULL)
empty_list <- function() list_nil
is_empty.linked_list <- function(x) identical(x, list_nil)


You can implement it simpler using NULL as an empty list, but this particular implementation lets me use polymorphism to implement different versions of data structures ? the reasoning is explained in chapter 2 of a book I?m working on:?https://www.dropbox.com/s/qdnjc0bx4yivl8r/book.pdf?dl=0

Anyway, that list implementation doesn?t evaluate the lists lazily, so I am trying to wrap these lists in calls to lazy().

A simple implementation looks like this:


lazy_empty_list <- lazy(empty_list())
lazy_cons <- function(elm, lst) {
? lazy(list_cons(elm, lst()))
}

Now, this works fine for adding an element to an empty list:

lst <- lazy_cons(2, lazy_empty_list)
lst()

It also works fine if I add another element to an expression for constructing a list:

lst <- lazy_cons(1, lazy_cons(2, lazy_empty_list))
lst()

I can construct lists as long as I want, as long as I explicitly give the lazy_cons() function an expression for the list:

lst <- lazy_cons(1, lazy_cons(2, lazy_cons(3, lazy_empty_list)))
lst()


However, if I save intermediate lists in a variable, it breaks down. This code:

lst <- lazy_cons(2, lazy_empty_list)
lst <- lazy_cons(1, lst)
lst()

gives me this error:

?Error in lst() :
? promise already under evaluation: recursive default argument reference or earlier problems?

Now, I am particularly dense today, it being Monday and all, so there is likely to be something very obvious I am missing, but I would think that the ?lit? variable, when passed to lazy_cons(), would be interpreted as a promise to be evaluated in the parent environment, so I don?t see why it is considered a circular definition of it.

If I force the list to be evaluated, it all works, and the first evaluation is more expensive than the following:

lazy_cons <- function(elm, lst) {
? force(lst)
? lazy(list_cons(elm, lst()))
}
lst <- lazy_cons(1, lazy_empty_list)
lst <- lazy_cons(2, lst)
lst <- lazy_cons(3, lst)
microbenchmark(lst(), times = 1)
microbenchmark(lst(), times = 1)
microbenchmark(lst(), times = 1)

But if I do the exact same thing in a for-loop, it breaks again?this does not work and I get the same error as earlier:

lst <- lazy_empty_list()
for (e in 1:3) {
? lst <- lazy_cons(e, lst)
}
microbenchmark(lst(), times = 1)
microbenchmark(lst(), times = 1)
microbenchmark(lst(), times = 1)

I really can?t see what the difference is between the loop version and the explicitly unwrapping of the loop, but R certainly sees a difference?

I would really love to hear if any of you guys have any insights to what is going on here...


Cheers

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 24 16:43:06 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Apr 2017 16:43:06 +0200
Subject: [R] Frequency of Combinations
In-Reply-To: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAJuCY5x9camE16NDFnYKOp54q70j-kYDBGxLmCY=ND2LiL=3FA@mail.gmail.com>

Dear Mustafa,

I'd recommend the packages readxls to import the data, tidyr to transform
the data into long format and dplyr to select the data.

1. read the data into R with read_excel()
2. transform sheet 1 into a long format with gather(). The result is one
row for each patient / drug combination
3. select the relevant drugs in sheet 2 with filter()
4. join long sheet 1 and filtered sheet2 with inner_join()
5. summarise() the drug codes and names after group_by(patient_id)
6. count() the number of drug codes.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-24 7:07 GMT+02:00 abo dalash <abo_dlsh at hotmail.com>:

> Hi there
>
> I have data set with 500,000 patients (rows) and the first column is
> Patient I'D Number, columns from 2 to 20 are Drug1,Drug 2,...,Drug 20 so
> each row starts with the patient ID and the remaining of cells in the row
> are codes for names of the treatments taken by the patient. Number of
> treatments differ between patients. For example, there are patients with 3
> treatments only and patients with 20 drugs. The unique number of treatments
> in the entire data set is about 6700 drugs. However, I'm interested in
> studying only 128 drugs, these drugs are listed in a second sheet as code
> numbers associated with their meanings (names of drugs representing the
> code). I'm interested in identifying the most frequently used DRUG
> COMBINATIONS between only the 128 drugs among the 6700 drugs. The structure
> of the Excell file to be used in analysis is like this:
>
> -Sheet 1( the entire data set):-
> 1   Patient ID    Drug1    Drug2 ....    Drug 20.
> 2  1125            45            46                55
> 3  1126              60           55                 45
> .
> .
> 500,000
>
> -Sheet 2 (list of codes meanings for only the drugs of interest):
>
> 1    Drug code             meaning
> 2    45                            Simvastatin
> 3    55                            Aspirin
> 4    60                            Paracetamol
> .
> 128
>
> The desired output I'm looking for :
>
>  Drug codes      Meaning          Frequency
> 45+55               Simvastatin              2
>                          +Aspirin
> 60+55             Aspirin+                       1
>                         Paracetamol
> 60+45             Simvastatin+                1
>                         Paracetamol
>
> Please note the the final output does not include any combination
> containing drug 46 as this is not in the list of drugs preferred to be
> studied which are mentioned in sheet 2.
>
> Could you please help me which R codes and packages should be used to run
> this analyisis?
>
> Regards
> Mustafa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Apr 24 16:59:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 24 Apr 2017 07:59:57 -0700
Subject: [R] Delayed evaluation / lazy expression evaluation
In-Reply-To: <6e77024e-5d51-4b5d-a68a-3d7796bb69c3@Spark>
References: <6e77024e-5d51-4b5d-a68a-3d7796bb69c3@Spark>
Message-ID: <CAGxFJbREwDR00HZ_TC2DunSmVXgajgyT+qBUO4BSfu8AbjXaCA@mail.gmail.com>

There is no way that I have the tenacity to wade through your verbiage
(maybe other hardier souls will). However, it sounds like you are
trying to reinvent wheels. I think you want: ?substitute.

> f <- function(exp)substitute(exp)
> f(1:100)
1:100

see also ?delayedAssign for direct manipulation of promises. You may
also wish to check out Hadley Wickham's book on advanced R (available
over the web also, I think) or other resources (e.g. see the R
Language Reference that ships with R) for "computing on the language"
resources.

If all this misses your point, sorry. As I said, others may have
greater initiative with your missive.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 24, 2017 at 5:35 AM, Thomas Mailund
<thomas.mailund at gmail.com> wrote:
> Hi, I?m playing around with ways of implementing lazy evaluation of expressions. In R, function arguments are evaluated as promises but expressions are evaluated immediately, so I am trying to wrap expressions in thunks?functions with no arguments that evaluate an expression?to get something the resembles lazy evaluation of expressions.
>
> As an example, consider this:
>
> lazy <- function(value) {
>   function() value
> }
>
> f <- lazy((1:100000)[1])
>
> If we evaluate f we have to create the long vector and then get the first element. We delay the evaluation to f so the first time we call f we should see a slow operation and if we evaluate it again we should see faster evaluations. If you run this benchmark, you will see that this is indeed what we get:
>
> library(microbenchmark)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
>
> Now, I want to use this to implement lazy linked lists. It is not particularly important why I want to do this, but if you are interested, it is because you can implement persistent queues with amortised constant time operations this way, which is what I am experimenting with.
>
> I have this implementation of linked lists:
>
> list_cons <- function(elem, lst)
>   structure(list(head = elem, tail = lst), class = "linked_list")
>
> list_nil <- list_cons(NA, NULL)
> empty_list <- function() list_nil
> is_empty.linked_list <- function(x) identical(x, list_nil)
>
>
> You can implement it simpler using NULL as an empty list, but this particular implementation lets me use polymorphism to implement different versions of data structures ? the reasoning is explained in chapter 2 of a book I?m working on: https://www.dropbox.com/s/qdnjc0bx4yivl8r/book.pdf?dl=0
>
> Anyway, that list implementation doesn?t evaluate the lists lazily, so I am trying to wrap these lists in calls to lazy().
>
> A simple implementation looks like this:
>
>
> lazy_empty_list <- lazy(empty_list())
> lazy_cons <- function(elm, lst) {
>   lazy(list_cons(elm, lst()))
> }
>
> Now, this works fine for adding an element to an empty list:
>
> lst <- lazy_cons(2, lazy_empty_list)
> lst()
>
> It also works fine if I add another element to an expression for constructing a list:
>
> lst <- lazy_cons(1, lazy_cons(2, lazy_empty_list))
> lst()
>
> I can construct lists as long as I want, as long as I explicitly give the lazy_cons() function an expression for the list:
>
> lst <- lazy_cons(1, lazy_cons(2, lazy_cons(3, lazy_empty_list)))
> lst()
>
>
> However, if I save intermediate lists in a variable, it breaks down. This code:
>
> lst <- lazy_cons(2, lazy_empty_list)
> lst <- lazy_cons(1, lst)
> lst()
>
> gives me this error:
>
>  Error in lst() :
>   promise already under evaluation: recursive default argument reference or earlier problems?
>
> Now, I am particularly dense today, it being Monday and all, so there is likely to be something very obvious I am missing, but I would think that the ?lit? variable, when passed to lazy_cons(), would be interpreted as a promise to be evaluated in the parent environment, so I don?t see why it is considered a circular definition of it.
>
> If I force the list to be evaluated, it all works, and the first evaluation is more expensive than the following:
>
> lazy_cons <- function(elm, lst) {
>   force(lst)
>   lazy(list_cons(elm, lst()))
> }
> lst <- lazy_cons(1, lazy_empty_list)
> lst <- lazy_cons(2, lst)
> lst <- lazy_cons(3, lst)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
>
> But if I do the exact same thing in a for-loop, it breaks again?this does not work and I get the same error as earlier:
>
> lst <- lazy_empty_list()
> for (e in 1:3) {
>   lst <- lazy_cons(e, lst)
> }
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
>
> I really can?t see what the difference is between the loop version and the explicitly unwrapping of the loop, but R certainly sees a difference?
>
> I would really love to hear if any of you guys have any insights to what is going on here...
>
>
> Cheers
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Apr 24 18:47:34 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 24 Apr 2017 12:47:34 -0400
Subject: [R] Frequency of Combinations
In-Reply-To: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <FCA4D290-2FD3-409D-9E85-E86B248F602C@utoronto.ca>

This can be easily done in base R.

The solution below is pedestrian, transparent and explicit. Thus it's easy to
debug and validate(!) each step.

Prepare:
(1) Save your Excel spreadsheet as a text file with tab-separated values.
(2) Initialize a 128 * 128 matrix to hold your results. It should have
    your drug-codes as row names and as column names. 
(3) Create a vector of drug codes as character(!) (not as integers). Treating them
    as strings avoids being bitten by whatever unexpected stuff you'll find in your data.

Compile:
(4) read your data line by line. For each line:
       use strsplit() to get a vector of contents of your spreadsheet cells,
         drop the patient ID while you are doing this (IDs could overlap drug codes). 
       use match() to compare your drug codes with the vector of contents. match()
         returns a vector of positions. 
       if the length of this vector is > 1:
         use a nested loop to consider all combinations of matched drugs. For each
         combination of drug codes, increment the corresponding value in your matrix.
            
(5) Now all counts are in the matrix, but the same combination may appear
    in different order: add the value of each element below the diagonal
    of your matrix to the corresponding value above the diagonal.
    (The values _in_ the diagonal would correspond to drugs that have been
     entered more than once.)

(6) Finally, replace the matrix row- and column names with the actual drug names.

Analyze:
There are many ways. Myself, I would create a data frame with the counts in one column,
and the two drug names in the second and third column, then order() the rows
by count.

All in all, that's about 20 lines of code to prepare and compile, 10 more for the
result. Post again if this wasn't clear, or if you need help with the actual syntax.


Cheers,
B.    


> On Apr 24, 2017, at 1:07 AM, abo dalash <abo_dlsh at hotmail.com> wrote:
> 
> Hi there
> 
> I have data set with 500,000 patients (rows) and the first column is Patient I'D Number, columns from 2 to 20 are Drug1,Drug 2,...,Drug 20 so each row starts with the patient ID and the remaining of cells in the row are codes for names of the treatments taken by the patient. Number of treatments differ between patients. For example, there are patients with 3 treatments only and patients with 20 drugs. The unique number of treatments in the entire data set is about 6700 drugs. However, I'm interested in studying only 128 drugs, these drugs are listed in a second sheet as code numbers associated with their meanings (names of drugs representing the code). I'm interested in identifying the most frequently used DRUG COMBINATIONS between only the 128 drugs among the 6700 drugs. The structure of the Excell file to be used in analysis is like this:
> 
> -Sheet 1( the entire data set):-
> 1   Patient ID    Drug1    Drug2 ....    Drug 20.
> 2  1125            45            46                55
> 3  1126              60           55                 45
> .
> .
> 500,000
> 
> -Sheet 2 (list of codes meanings for only the drugs of interest):
> 
> 1    Drug code             meaning
> 2    45                            Simvastatin
> 3    55                            Aspirin
> 4    60                            Paracetamol
> .
> 128
> 
> The desired output I'm looking for :
> 
> Drug codes      Meaning          Frequency
> 45+55               Simvastatin              2
>                         +Aspirin
> 60+55             Aspirin+                       1
>                        Paracetamol
> 60+45             Simvastatin+                1
>                        Paracetamol
> 
> Please note the the final output does not include any combination containing drug 46 as this is not in the list of drugs preferred to be studied which are mentioned in sheet 2.
> 
> Could you please help me which R codes and packages should be used to run this analyisis?
> 
> Regards
> Mustafa
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From miah.mohammadsaifudd at mavs.uta.edu  Tue Apr 25 06:34:08 2017
From: miah.mohammadsaifudd at mavs.uta.edu (Saifuddin, Miah Mohammad)
Date: Tue, 25 Apr 2017 04:34:08 +0000
Subject: [R] asking for help
Message-ID: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>

I have a data frame having 163863 values. I want to subset it so that each set has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second. how can I do that, preferably in a loop.


TIA

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 25 07:16:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 24 Apr 2017 22:16:32 -0700
Subject: [R] asking for help
In-Reply-To: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
References: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
Message-ID: <CAGxFJbSYY-35GL_bWDvEKrCn7pEzWygAj4NJt4oQrhS-ykzWTw@mail.gmail.com>

By 163863 "values" do you mean rows in the data frame? If so, please
read about indexing in any online R tutorial or the Intro to R
tutorial that ships with R. This is an absolutely basic R operation,
and if you are unwilling or unable to put in the time to learn about
it, you should probably consider using other software.

If you mean something else, then please read and follow the posting
guide to help you post your question in a way that will make your
meaning clear and enable others to help you. And please post in *plain
text*, not HTML, which can get mangled by the mail software (though it
was fine this time).

Also, please note that "looping" in R is often unnecessary and inefficient.

Cheers,
Bert



-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 24, 2017 at 9:34 PM, Saifuddin, Miah Mohammad
<miah.mohammadsaifudd at mavs.uta.edu> wrote:
> I have a data frame having 163863 values. I want to subset it so that each set has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second. how can I do that, preferably in a loop.
>
>
> TIA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From catalinroibu at gmail.com  Tue Apr 25 08:21:29 2017
From: catalinroibu at gmail.com (catalin roibu)
Date: Tue, 25 Apr 2017 09:21:29 +0300
Subject: [R] R 3.4.0 problem installation
Message-ID: <CAEW+BDJ+4htKOZ_8=JQROs-ujpyObyczuSNyZS1gKs8AQeEkdg@mail.gmail.com>

Dear all,

I have a problem with the newest R version. I'm trying to install a
specific package dplR how need the gpm package and I have this error on my
macbook (OS Sierra):

> install.packages("dplR")
also installing the dependency ?gmp?

Packages which are only available in source form, and may
  need compilation of C/C++/Fortran: ?gmp? ?dplR?
Do you want to attempt to install these from sources?
y/n: y
installing the source packages ?gmp?, ?dplR?

trying URL 'https://cran.rstudio.com/src/contrib/gmp_0.5-13.1.tar.gz'
Content type 'application/x-gzip' length 131321 bytes (128 KB)
==================================================
downloaded 128 KB

trying URL 'https://cran.rstudio.com/src/contrib/dplR_1.6.5.tar.gz'
Content type 'application/x-gzip' length 1672999 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package ?gmp? ...
** package ?gmp? successfully unpacked and MD5 sums checked
creating cache ./config.cache
checking for __gmpz_ui_sub in -lgmp... no
configure: error: GNU MP not found, or not 4.1.4 or up, see
http://gmplib.org
ERROR: configuration failed for package ?gmp?
* removing
?/Library/Frameworks/R.framework/Versions/3.4/Resources/library/gmp?
Warning in install.packages :
  installation of package ?gmp? had non-zero exit status
ERROR: dependency ?gmp? is not available for package ?dplR?
* removing
?/Library/Frameworks/R.framework/Versions/3.4/Resources/library/dplR?
Warning in install.packages :
  installation of package ?dplR? had non-zero exit status

The downloaded source packages are in
?/private/var/folders/c5/6g4vbk5x55586m8ky2v_6pbc0000gn/T/RtmprYzSE8/downloaded_packages?


All the others packages work in good conditions.
Please help me to solve this annoying situation.

Best regards!

CR

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>



  <https://mailtrack.io/> Sent with Mailtrack
<https://mailtrack.io/install?source=signature&lang=en&referral=catalinroibu at gmail.com&idSignature=22>
<#>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Tue Apr 25 08:47:10 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 25 Apr 2017 08:47:10 +0200
Subject: [R] R 3.4.0 problem installation
In-Reply-To: <CAEW+BDJ+4htKOZ_8=JQROs-ujpyObyczuSNyZS1gKs8AQeEkdg@mail.gmail.com>
References: <CAEW+BDJ+4htKOZ_8=JQROs-ujpyObyczuSNyZS1gKs8AQeEkdg@mail.gmail.com>
Message-ID: <FB604610-0A82-4429-8D3E-5B263AA2F242@xs4all.nl>


> On 25 Apr 2017, at 08:21, catalin roibu <catalinroibu at gmail.com> wrote:
> 
> Dear all,
> 
> I have a problem with the newest R version. I'm trying to install a
> specific package dplR how need the gpm package and I have this error on my
> macbook (OS Sierra):
> 
>> install.packages("dplR")
> also installing the dependency ?gmp?
> 
> Packages which are only available in source form, and may
>  need compilation of C/C++/Fortran: ?gmp? ?dplR?
> Do you want to attempt to install these from sources?
> y/n: y
> installing the source packages ?gmp?, ?dplR?
> 
> trying URL 'https://cran.rstudio.com/src/contrib/gmp_0.5-13.1.tar.gz'
> Content type 'application/x-gzip' length 131321 bytes (128 KB)
> ==================================================
> downloaded 128 KB
> 
> trying URL 'https://cran.rstudio.com/src/contrib/dplR_1.6.5.tar.gz'
> Content type 'application/x-gzip' length 1672999 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
> 
> * installing *source* package ?gmp? ...
> ** package ?gmp? successfully unpacked and MD5 sums checked
> creating cache ./config.cache
> checking for __gmpz_ui_sub in -lgmp... no
> configure: error: GNU MP not found, or not 4.1.4 or up, see
> http://gmplib.org
> ERROR: configuration failed for package ?gmp?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.4/Resources/library/gmp?
> Warning in install.packages :
>  installation of package ?gmp? had non-zero exit status
> ERROR: dependency ?gmp? is not available for package ?dplR?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.4/Resources/library/dplR?
> Warning in install.packages :
>  installation of package ?dplR? had non-zero exit status
> 
> The downloaded source packages are in
> ?/private/var/folders/c5/6g4vbk5x55586m8ky2v_6pbc0000gn/T/RtmprYzSE8/downloaded_packages?
> 
> 
> All the others packages work in good conditions.
> Please help me to solve this annoying situation.
> 


This should have been sent to the R-SIG-Mac mailinglist.

If you look on CRAN for the packages Rmpfr and gmp you will see that both packages are not available in binary form for OS X El Capitan.  You'll have to wait or try to compile  gmp and mpfr relevant packages from source first before installing Rmpfr.
I don't know the reason for the non-availability.

Berend Hasselman

> Best regards!
> 
> CR
> 
> -- 
> 
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
> 
> 
> 
>  <https://mailtrack.io/> Sent with Mailtrack
> <https://mailtrack.io/install?source=signature&lang=en&referral=catalinroibu at gmail.com&idSignature=22>
> <#>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Tue Apr 25 10:22:48 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 25 Apr 2017 10:22:48 +0200
Subject: [R] R-3.4.0 and survival_2.41-3
Message-ID: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>

I installed R-3.4.0 and got problems with the survival package, for instance

------------
 > library(survival)
 > mort <- data.frame(exit = 1:4, event = rep(1, 4), x = c(0, 1, 0, 1))
 > fit <- coxph(Surv(exit, event) ~ x, data = mort)
Error in fitter(X, Y, strats, offset, init, control, weights = weights,  :
   object 'Ccoxmart' not found
-------------

No problems with R-3.3.3 and the same (latest) survival version, which 
makes me think that something is going on in my R installation rather 
than in the survival package.

Thanks for any hint,

G?ran

 > sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.2 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libblas.so.3
LAPACK: /usr/lib/libopenblasp-r0.2.18.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=sv_SE.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=sv_SE.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=sv_SE.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=sv_SE.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] survival_2.41-3

loaded via a namespace (and not attached):
[1] compiler_3.4.0  Matrix_1.2-8    splines_3.4.0   grid_3.4.0
[5] lattice_0.20-35


From ashimkapoor at gmail.com  Tue Apr 25 10:32:18 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Tue, 25 Apr 2017 14:02:18 +0530
Subject: [R] The effect of tolerance in all.equal()
Message-ID: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>

Dear all,

I am not able to understand the interplay of absolute vs relative and
tolerance in the use of all.equal

If I want to find out if absolute differences between 2 numbers/vectors are
bigger than a given tolerance I would do:

all.equal(1,1.1,scale=1,tol= .1)

If I want to find out if relative differences between 2 numbers/vectors are
bigger than a given tolerance I would do :

all.equal(1,1.1,tol=.1)

##################################################################################################################################

I can also do :

all.equal(1,3,tol=1)

to find out if the absolute difference is bigger than 1.But here I won't be
able to detect absolute differences smaller than 1 in this case,so I don't
think that this is a good way.

My query is: what is the reasoning behind all.equal returning the absolute
difference if the tolerance >= target and relative difference if tolerance
< target?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Apr 25 10:34:38 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Apr 2017 10:34:38 +0200
Subject: [R] R-3.4.0 and survival_2.41-3 ..
In-Reply-To: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
References: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
Message-ID: <22783.2590.76647.622491@stat.math.ethz.ch>

>>>>> G?ran Brostr?m <goran.brostrom at umu.se>
>>>>>     on Tue, 25 Apr 2017 10:22:48 +0200 writes:

    > I installed R-3.4.0 and got problems with the survival package, for instance
    > ------------
    >> library(survival)
    >> mort <- data.frame(exit = 1:4, event = rep(1, 4), x = c(0, 1, 0, 1))
    >> fit <- coxph(Surv(exit, event) ~ x, data = mort)
    > Error in fitter(X, Y, strats, offset, init, control, weights = weights,  :
    > object 'Ccoxmart' not found
    > -------------

    > No problems with R-3.3.3 and the same (latest) survival version, which 
    > makes me think that something is going on in my R installation rather 
    > than in the survival package.

    > Thanks for any hint,

    > G?ran

    >> sessionInfo()
    > R version 3.4.0 (2017-04-21)
    > Platform: x86_64-pc-linux-gnu (64-bit)
    > Running under: Ubuntu 16.04.2 LTS

    > Matrix products: default
    > BLAS: /usr/lib/openblas-base/libblas.so.3
    > LAPACK: /usr/lib/libopenblasp-r0.2.18.so

    > locale:
    > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
    > [3] LC_TIME=sv_SE.UTF-8        LC_COLLATE=en_US.UTF-8
    > [5] LC_MONETARY=sv_SE.UTF-8    LC_MESSAGES=en_US.UTF-8
    > [7] LC_PAPER=sv_SE.UTF-8       LC_NAME=C
    > [9] LC_ADDRESS=C               LC_TELEPHONE=C
    > [11] LC_MEASUREMENT=sv_SE.UTF-8 LC_IDENTIFICATION=C

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > other attached packages:
    > [1] survival_2.41-3

    > loaded via a namespace (and not attached):
    > [1] compiler_3.4.0  Matrix_1.2-8    splines_3.4.0   grid_3.4.0
    > [5] lattice_0.20-35

I'm 99.5% sure that you are using more than just the default
library of package (a very good thing - we have been doing the
same for years).

We have in NEWS for R 3.4.0

  > PACKAGE INSTALLATION:

  >   [...........]

  >   [...........]

  >   ? Packages which register native routines for .C or .Fortran need
  >     to be re-installed for this version (unless installed with
  >     R-devel SVN revision r72375 or later).

and Prof Brian Ripley did announce that nicely and early on R-devel.
==> https://hypatia.math.ethz.ch/pipermail/r-devel/2017-March/073940.html

==> You have to re-install quite a few packages for R 3.4.0,
     __if__ they use .C() or .Fortran() 

When we've e-talked about the issue within R-core, 
Uwe Ligges noted we should really ask everyone to run

   	  update.packages(checkBuilt=TRUE)

after an update to a new major (meaning "R-x.y.0") release of R
and **not** re-use packages {inside R-x.y.z}
that were installed with R-x.(y-1).z'  ..

and of course Uwe is right:
We should ask others to do it _and_ do it ourselves.

Anyway it _is_ considerably more important for the 3.4.0
release.

Martin Maechler
ETH Zurich (and R Core team)


From goran.brostrom at umu.se  Tue Apr 25 10:59:42 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 25 Apr 2017 10:59:42 +0200
Subject: [R] R-3.4.0 and survival_2.41-3 ..
In-Reply-To: <22783.2590.76647.622491@stat.math.ethz.ch>
References: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
 <22783.2590.76647.622491@stat.math.ethz.ch>
Message-ID: <9647d3da-53cd-5301-00e5-4c5492895c2b@umu.se>

Thanks Martin,

that helped!

G?ran

On 2017-04-25 10:34, Martin Maechler wrote:
>>>>>> G?ran Brostr?m <goran.brostrom at umu.se>
>>>>>>     on Tue, 25 Apr 2017 10:22:48 +0200 writes:
>
>     > I installed R-3.4.0 and got problems with the survival package, for instance
>     > ------------
>     >> library(survival)
>     >> mort <- data.frame(exit = 1:4, event = rep(1, 4), x = c(0, 1, 0, 1))
>     >> fit <- coxph(Surv(exit, event) ~ x, data = mort)
>     > Error in fitter(X, Y, strats, offset, init, control, weights = weights,  :
>     > object 'Ccoxmart' not found
>     > -------------
>
>     > No problems with R-3.3.3 and the same (latest) survival version, which
>     > makes me think that something is going on in my R installation rather
>     > than in the survival package.
>
>     > Thanks for any hint,
>
>     > G?ran
>
>     >> sessionInfo()
>     > R version 3.4.0 (2017-04-21)
>     > Platform: x86_64-pc-linux-gnu (64-bit)
>     > Running under: Ubuntu 16.04.2 LTS
>
>     > Matrix products: default
>     > BLAS: /usr/lib/openblas-base/libblas.so.3
>     > LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
>     > locale:
>     > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>     > [3] LC_TIME=sv_SE.UTF-8        LC_COLLATE=en_US.UTF-8
>     > [5] LC_MONETARY=sv_SE.UTF-8    LC_MESSAGES=en_US.UTF-8
>     > [7] LC_PAPER=sv_SE.UTF-8       LC_NAME=C
>     > [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     > [11] LC_MEASUREMENT=sv_SE.UTF-8 LC_IDENTIFICATION=C
>
>     > attached base packages:
>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>
>     > other attached packages:
>     > [1] survival_2.41-3
>
>     > loaded via a namespace (and not attached):
>     > [1] compiler_3.4.0  Matrix_1.2-8    splines_3.4.0   grid_3.4.0
>     > [5] lattice_0.20-35
>
> I'm 99.5% sure that you are using more than just the default
> library of package (a very good thing - we have been doing the
> same for years).
>
> We have in NEWS for R 3.4.0
>
>   > PACKAGE INSTALLATION:
>
>   >   [...........]
>
>   >   [...........]
>
>   >   ? Packages which register native routines for .C or .Fortran need
>   >     to be re-installed for this version (unless installed with
>   >     R-devel SVN revision r72375 or later).
>
> and Prof Brian Ripley did announce that nicely and early on R-devel.
> ==> https://hypatia.math.ethz.ch/pipermail/r-devel/2017-March/073940.html
>
> ==> You have to re-install quite a few packages for R 3.4.0,
>      __if__ they use .C() or .Fortran()
>
> When we've e-talked about the issue within R-core,
> Uwe Ligges noted we should really ask everyone to run
>
>    	  update.packages(checkBuilt=TRUE)
>
> after an update to a new major (meaning "R-x.y.0") release of R
> and **not** re-use packages {inside R-x.y.z}
> that were installed with R-x.(y-1).z'  ..
>
> and of course Uwe is right:
> We should ask others to do it _and_ do it ourselves.
>
> Anyway it _is_ considerably more important for the 3.4.0
> release.
>
> Martin Maechler
> ETH Zurich (and R Core team)
>
>


From mailund at birc.au.dk  Tue Apr 25 11:20:01 2017
From: mailund at birc.au.dk (Thomas Mailund)
Date: Tue, 25 Apr 2017 09:20:01 +0000
Subject: [R] asking for help
In-Reply-To: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
References: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
Message-ID: <4c4be595-4702-4f9d-a757-859eae12dd02@Spark>

If you write something like

indices <- rep(1:(163863/6069), each = 6069)

you can get the i?th block of rows with

table[indices == i,]

It looks like a little more work than a loop would be since you have to run through all rows for each block, but the implicit loop in this approach is likely to be faster than an explicit for-loop.

Cheers
?Thomas

On 25 Apr 2017, 07.01 +0200, Saifuddin, Miah Mohammad <miah.mohammadsaifudd at mavs.uta.edu>, wrote:
I have a data frame having 163863 values. I want to subset it so that each set has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second. how can I do that, preferably in a loop.


TIA

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Apr 25 11:44:06 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Apr 2017 11:44:06 +0200
Subject: [R] The effect of tolerance in all.equal()
In-Reply-To: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
References: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
Message-ID: <22783.6758.310171.440071@stat.math.ethz.ch>

>>>>> Ashim Kapoor <ashimkapoor at gmail.com>
>>>>>     on Tue, 25 Apr 2017 14:02:18 +0530 writes:

    > Dear all,
    > I am not able to understand the interplay of absolute vs relative and
    > tolerance in the use of all.equal

    > If I want to find out if absolute differences between 2 numbers/vectors are
    > bigger than a given tolerance I would do:

    > all.equal(1,1.1,scale=1,tol= .1)

    > If I want to find out if relative differences between 2 numbers/vectors are
    > bigger than a given tolerance I would do :

    > all.equal(1,1.1,tol=.1)

    > ##################################################################################################################################

    > I can also do :

    > all.equal(1,3,tol=1)

    > to find out if the absolute difference is bigger than 1.But here I won't be
    > able to detect absolute differences smaller than 1 in this case,so I don't
    > think that this is a good way.

    > My query is: what is the reasoning behind all.equal returning the absolute
    > difference if the tolerance >= target and relative difference if tolerance
    > < target?
(above, it is    tol  >/<=  |target|  ie. absolute value)


The following are desiderata / restrictions :

1) Relative tolerance is needed to keep things scale-invariant
   i.e.,  all.equal(x, y)  and  all.equal(1000 * x, 1000 * y)
   should typically be identical for (almost) all (x,y).

   ==> "the typical behavior should use relative error tolerance"

2) when x or y (and typically both!) are very close to zero it
   is typically undesirable to keep relative tolerances (in the
   boundary case, they _are_ zero exactly, and "relative error" is undefined).
   E.g., for most purposes, 3.45e-15 and 1.23e-17 should be counted as
   equal to zero and hence to themselves.

1) and 2) are typically reconciled by switching from relative to absolute
when the arguments are close to zero (*).

The exact cutoff at which to switch from relative to absolute
(or a combination of the two) is somewhat arbitrary(*2) and for
all.equal() has been made in the 1980's (or even slightly
earlier?) when all.equal() was introduced into the S language at
Bell labs AFAIK. Maybe John Chambers (or Rick Becker or ...,
but they may not read R-help) knows more.
*2) Then, the choice for all.equal() is in some way "least arbitrary", 
    using c = 1 in the more general   tolerance >= c*|target|  framework.

*) There have been alternatives in "the (applied numerical
 analysis / algorithm) literature" seen in published algorithms,
 but I don't have any example ready.
 Notably some of these alternatives are _symmetric_ in (x,y)
 where all.equal() was designed to be asymmetric using names
 'target' and 'current'.

The alternative idea is along the following thoughts:

Assume that for "equality" we want _both_ relative and
absolute (e := tolerance) "equality"
 
   |x - y| < e (|x|+|y|)/2  (where you could use |y| or |x| 
      	       		     instead of their mean; all.equal()
      	       		     uses |target|)
   |x - y| < e * e1	     (where e1 = 1, or e1 = 10^-7..)

If you add the two inequalities you get

   |x - y| < e (e1 + |x+y|/2)

as check which is a "mixture" of relative and absolute tolerance.

With a somewhat long history, my gut feeling would nowadays
actually prefer this (I think with a default of e1 = e) - which
does treat x and y symmetrically.

Note that convergence checks in good algorithms typically check
for _both_ relative and absolute difference (each with its
tolerance providable by the user), and the really good ones for
minimization do  check for (approximate) gradients also being
close to zero - as old timers among us should have learned from
Doug Bates ... but now I'm really diverging.

Last but not least some  R  code at the end,  showing that the *asymmetric*
nature of all.equal() may lead to somewhat astonishing (but very
logical and as documented!) behavior.

Martin

    > Best Regards,
    > Ashim


> ## The "data" to use:
> epsQ <- lapply(seq(12,18,by=1/2), function(P) bquote(10^-.(P))); names(epsQ) <- sapply(epsQ, deparse); str(epsQ)
List of 13
 $ 10^-12  : language 10^-12
 $ 10^-12.5: language 10^-12.5
 $ 10^-13  : language 10^-13
 $ 10^-13.5: language 10^-13.5
 $ 10^-14  : language 10^-14
 $ 10^-14.5: language 10^-14.5
 $ 10^-15  : language 10^-15
 $ 10^-15.5: language 10^-15.5
 $ 10^-16  : language 10^-16
 $ 10^-16.5: language 10^-16.5
 $ 10^-17  : language 10^-17
 $ 10^-17.5: language 10^-17.5
 $ 10^-18  : language 10^-18

> str(lapply(epsQ, function(tl) all.equal(3.45e-15, 1.23e-17, tol = eval(tl))))
List of 13
 $ 10^-12  : logi TRUE
 $ 10^-12.5: logi TRUE
 $ 10^-13  : logi TRUE
 $ 10^-13.5: logi TRUE
 $ 10^-14  : logi TRUE
 $ 10^-14.5: chr "Mean relative difference: 0.9964348"
 $ 10^-15  : chr "Mean relative difference: 0.9964348"
 $ 10^-15.5: chr "Mean relative difference: 0.9964348"
 $ 10^-16  : chr "Mean relative difference: 0.9964348"
 $ 10^-16.5: chr "Mean relative difference: 0.9964348"
 $ 10^-17  : chr "Mean relative difference: 0.9964348"
 $ 10^-17.5: chr "Mean relative difference: 0.9964348"
 $ 10^-18  : chr "Mean relative difference: 0.9964348"

> ## Now swap `target` and `current` :
> str(lapply(epsQ, function(tl) all.equal(1.23e-17, 3.45e-15, tol = eval(tl))))
List of 13
 $ 10^-12  : logi TRUE
 $ 10^-12.5: logi TRUE
 $ 10^-13  : logi TRUE
 $ 10^-13.5: logi TRUE
 $ 10^-14  : logi TRUE
 $ 10^-14.5: chr "Mean absolute difference: 3.4377e-15"
 $ 10^-15  : chr "Mean absolute difference: 3.4377e-15"
 $ 10^-15.5: chr "Mean absolute difference: 3.4377e-15"
 $ 10^-16  : chr "Mean absolute difference: 3.4377e-15"
 $ 10^-16.5: chr "Mean absolute difference: 3.4377e-15"
 $ 10^-17  : chr "Mean relative difference: 279.4878"
 $ 10^-17.5: chr "Mean relative difference: 279.4878"
 $ 10^-18  : chr "Mean relative difference: 279.4878"

>


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr 25 12:20:10 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Tue, 25 Apr 2017 10:20:10 +0000
Subject: [R] R-3.4.0 and survival_2.41-3 ..
In-Reply-To: <9647d3da-53cd-5301-00e5-4c5492895c2b@umu.se>
References: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
 <22783.2590.76647.622491@stat.math.ethz.ch>
 <9647d3da-53cd-5301-00e5-4c5492895c2b@umu.se>
Message-ID: <2266ebaa08e24910b0eaea067a9a3f63@UM-MAIL3216.unimaas.nl>

Sort of an obvious approach, but after every upgrade (regardless if it is major/minor), I just delete my entire personal library and reinstall everything from scratch. For this, I have a script that includes just a bunch of install.packages() calls. Like:

install.packages(c("lme4", "glmmML", "MCMCglmm"))
install.packages(c("psych", "GPArotation", "sem", "lavaan"))
[...]

I split things up a bit, based on the purpose/topic (along the lines of http://www.wvbauer.com/doku.php/rpackages) to keep things organized.

This may not be the most efficient method if you use hundreds of packages, but works for me.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of G?ran
>Brostr?m
>Sent: Tuesday, April 25, 2017 11:00
>To: Martin Maechler
>Cc: r-help at r-project.org
>Subject: Re: [R] R-3.4.0 and survival_2.41-3 ..
>
>Thanks Martin,
>
>that helped!
>
>G?ran
>
>On 2017-04-25 10:34, Martin Maechler wrote:
>>>>>>> G?ran Brostr?m <goran.brostrom at umu.se>
>>>>>>>     on Tue, 25 Apr 2017 10:22:48 +0200 writes:
>>
>>     > I installed R-3.4.0 and got problems with the survival package,
>for instance
>>     > ------------
>>     >> library(survival)
>>     >> mort <- data.frame(exit = 1:4, event = rep(1, 4), x = c(0, 1, 0,
>1))
>>     >> fit <- coxph(Surv(exit, event) ~ x, data = mort)
>>     > Error in fitter(X, Y, strats, offset, init, control, weights =
>weights,  :
>>     > object 'Ccoxmart' not found
>>     > -------------
>>
>>     > No problems with R-3.3.3 and the same (latest) survival version,
>which
>>     > makes me think that something is going on in my R installation
>rather
>>     > than in the survival package.
>>
>>     > Thanks for any hint,
>>
>>     > G?ran
>>
>>     >> sessionInfo()
>>     > R version 3.4.0 (2017-04-21)
>>     > Platform: x86_64-pc-linux-gnu (64-bit)
>>     > Running under: Ubuntu 16.04.2 LTS
>>
>>     > Matrix products: default
>>     > BLAS: /usr/lib/openblas-base/libblas.so.3
>>     > LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>>
>>     > locale:
>>     > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>     > [3] LC_TIME=sv_SE.UTF-8        LC_COLLATE=en_US.UTF-8
>>     > [5] LC_MONETARY=sv_SE.UTF-8    LC_MESSAGES=en_US.UTF-8
>>     > [7] LC_PAPER=sv_SE.UTF-8       LC_NAME=C
>>     > [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>     > [11] LC_MEASUREMENT=sv_SE.UTF-8 LC_IDENTIFICATION=C
>>
>>     > attached base packages:
>>     > [1] stats     graphics  grDevices utils     datasets  methods
>base
>>
>>     > other attached packages:
>>     > [1] survival_2.41-3
>>
>>     > loaded via a namespace (and not attached):
>>     > [1] compiler_3.4.0  Matrix_1.2-8    splines_3.4.0   grid_3.4.0
>>     > [5] lattice_0.20-35
>>
>> I'm 99.5% sure that you are using more than just the default
>> library of package (a very good thing - we have been doing the
>> same for years).
>>
>> We have in NEWS for R 3.4.0
>>
>>   > PACKAGE INSTALLATION:
>>
>>   >   [...........]
>>
>>   >   [...........]
>>
>>   >   ? Packages which register native routines for .C or .Fortran need
>>   >     to be re-installed for this version (unless installed with
>>   >     R-devel SVN revision r72375 or later).
>>
>> and Prof Brian Ripley did announce that nicely and early on R-devel.
>> ==> https://hypatia.math.ethz.ch/pipermail/r-devel/2017-
>March/073940.html
>>
>> ==> You have to re-install quite a few packages for R 3.4.0,
>>      __if__ they use .C() or .Fortran()
>>
>> When we've e-talked about the issue within R-core,
>> Uwe Ligges noted we should really ask everyone to run
>>
>>    	  update.packages(checkBuilt=TRUE)
>>
>> after an update to a new major (meaning "R-x.y.0") release of R
>> and **not** re-use packages {inside R-x.y.z}
>> that were installed with R-x.(y-1).z'  ..
>>
>> and of course Uwe is right:
>> We should ask others to do it _and_ do it ourselves.
>>
>> Anyway it _is_ considerably more important for the 3.4.0
>> release.
>>
>> Martin Maechler
>> ETH Zurich (and R Core team)

From thierry.onkelinx at inbo.be  Tue Apr 25 13:22:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 25 Apr 2017 13:22:58 +0200
Subject: [R] Frequency of Combinations
In-Reply-To: <CY4PR15MB130271D1E12DFF6403E7EC48EF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB13028839C4A5B55254CF047EEF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAJuCY5x9camE16NDFnYKOp54q70j-kYDBGxLmCY=ND2LiL=3FA@mail.gmail.com>
 <CY4PR15MB130271D1E12DFF6403E7EC48EF1F0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAJuCY5zDq_dKRYpgVdsHhzfYof-bBBws9VmpiTRKzbgrU=g96Q@mail.gmail.com>

Dear Mustafa,

Please keep the mailing list in cc.

Since you claim to have written the code, you can share the code so we can
review it. That makes more sense than having us to write code for you...

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-24 19:24 GMT+02:00 abo dalash <abo_dlsh at hotmail.com>:

> Dear Thierry
>
> Many thanks for your cooperation. I'm trying to apply the steps you have
> mentioned. If you don't mind, could you please type the entire codes after
> these functions so I can make sure that I have done everything correctly. I
> mean the details inside the ().
>
> Many thanks
>  Regards
>
>
>
> Sent from my Samsung device
>
>
> -------- Original message --------
> From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Date: 24/04/2017 3:43 p.m. (GMT+00:00)
> To: abo dalash <abo_dlsh at hotmail.com>
> Cc: "r-help at R-project.org" <r-help at r-project.org>
> Subject: Re: [R] Frequency of Combinations
>
> Dear Mustafa,
>
> I'd recommend the packages readxls to import the data, tidyr to transform
> the data into long format and dplyr to select the data.
>
> 1. read the data into R with read_excel()
> 2. transform sheet 1 into a long format with gather(). The result is one
> row for each patient / drug combination
> 3. select the relevant drugs in sheet 2 with filter()
> 4. join long sheet 1 and filtered sheet2 with inner_join()
> 5. summarise() the drug codes and names after group_by(patient_id)
> 6. count() the number of drug codes.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-24 7:07 GMT+02:00 abo dalash <abo_dlsh at hotmail.com>:
>
>> Hi there
>>
>> I have data set with 500,000 patients (rows) and the first column is
>> Patient I'D Number, columns from 2 to 20 are Drug1,Drug 2,...,Drug 20 so
>> each row starts with the patient ID and the remaining of cells in the row
>> are codes for names of the treatments taken by the patient. Number of
>> treatments differ between patients. For example, there are patients with 3
>> treatments only and patients with 20 drugs. The unique number of treatments
>> in the entire data set is about 6700 drugs. However, I'm interested in
>> studying only 128 drugs, these drugs are listed in a second sheet as code
>> numbers associated with their meanings (names of drugs representing the
>> code). I'm interested in identifying the most frequently used DRUG
>> COMBINATIONS between only the 128 drugs among the 6700 drugs. The structure
>> of the Excell file to be used in analysis is like this:
>>
>> -Sheet 1( the entire data set):-
>> 1   Patient ID    Drug1    Drug2 ....    Drug 20.
>> 2  1125            45            46                55
>> 3  1126              60           55                 45
>> .
>> .
>> 500,000
>>
>> -Sheet 2 (list of codes meanings for only the drugs of interest):
>>
>> 1    Drug code             meaning
>> 2    45                            Simvastatin
>> 3    55                            Aspirin
>> 4    60                            Paracetamol
>> .
>> 128
>>
>> The desired output I'm looking for :
>>
>>  Drug codes      Meaning          Frequency
>> 45+55               Simvastatin              2
>>                          +Aspirin
>> 60+55             Aspirin+                       1
>>                         Paracetamol
>> 60+45             Simvastatin+                1
>>                         Paracetamol
>>
>> Please note the the final output does not include any combination
>> containing drug 46 as this is not in the list of drugs preferred to be
>> studied which are mentioned in sheet 2.
>>
>> Could you please help me which R codes and packages should be used to run
>> this analyisis?
>>
>> Regards
>> Mustafa
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From goran.brostrom at umu.se  Tue Apr 25 13:33:30 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 25 Apr 2017 13:33:30 +0200
Subject: [R] R-3.4.0 and survival_2.41-3 ..
In-Reply-To: <2266ebaa08e24910b0eaea067a9a3f63@UM-MAIL3216.unimaas.nl>
References: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
 <22783.2590.76647.622491@stat.math.ethz.ch>
 <9647d3da-53cd-5301-00e5-4c5492895c2b@umu.se>
 <2266ebaa08e24910b0eaea067a9a3f63@UM-MAIL3216.unimaas.nl>
Message-ID: <1ff830bb-8c07-853b-d074-5cb7224beda7@umu.se>

Right, normally this is how it works for me when I install R from 
source. In this case, on this computer, I use the debian/ubuntu 
packaging, and then it is necessary to 'rebuild' packages, obviously.

Thanks, G?ran

On 2017-04-25 12:20, Viechtbauer Wolfgang (SP) wrote:
> Sort of an obvious approach, but after every upgrade (regardless if
> it is major/minor), I just delete my entire personal library and
> reinstall everything from scratch. For this, I have a script that
> includes just a bunch of install.packages() calls. Like:
>
> install.packages(c("lme4", "glmmML", "MCMCglmm"))
> install.packages(c("psych", "GPArotation", "sem", "lavaan")) [...]
>
> I split things up a bit, based on the purpose/topic (along the lines
> of http://www.wvbauer.com/doku.php/rpackages) to keep things
> organized.
>
> This may not be the most efficient method if you use hundreds of
> packages, but works for me.
>
> Best, Wolfgang
>


From petr.pikal at precheza.cz  Tue Apr 25 14:33:03 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 25 Apr 2017 12:33:03 +0000
Subject: [R] asking for help
In-Reply-To: <4c4be595-4702-4f9d-a757-859eae12dd02@Spark>
References: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
 <4c4be595-4702-4f9d-a757-859eae12dd02@Spark>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A22676@SRVEXCHCM301.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Mailund
> Sent: Tuesday, April 25, 2017 11:20 AM
> To: r-help at r-project.org; Saifuddin, Miah Mohammad
> <miah.mohammadsaifudd at mavs.uta.edu>
> Subject: Re: [R] asking for help
>
> If you write something like
>
> indices <- rep(1:(163863/6069), each = 6069)

You can get similar result by

indices2 <- 0:163862%/%6069

but starting with zero.

or the same with
indices2 <- (0:163862%/%6069)+1

Cheers
Petr

>
> you can get the i?th block of rows with
>
> table[indices == i,]
>
> It looks like a little more work than a loop would be since you have to run
> through all rows for each block, but the implicit loop in this approach is likely
> to be faster than an explicit for-loop.
>
> Cheers
> ?Thomas
>
> On 25 Apr 2017, 07.01 +0200, Saifuddin, Miah Mohammad
> <miah.mohammadsaifudd at mavs.uta.edu>, wrote:
> I have a data frame having 163863 values. I want to subset it so that each set
> has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second.
> how can I do that, preferably in a loop.
>
>
> TIA
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From goran.brostrom at umu.se  Tue Apr 25 14:31:33 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 25 Apr 2017 14:31:33 +0200
Subject: [R] R-3.4.0 and survival_2.41-3 ..
In-Reply-To: <22783.2590.76647.622491@stat.math.ethz.ch>
References: <5b2f9d13-97f6-6fb1-5d45-16eb134801c6@umu.se>
 <22783.2590.76647.622491@stat.math.ethz.ch>
Message-ID: <58279e8a-6573-70e9-24db-268ab10f01ad@umu.se>



On 2017-04-25 10:34, Martin Maechler wrote:
>>>>>> G?ran Brostr?m <goran.brostrom at umu.se>
>>>>>>     on Tue, 25 Apr 2017 10:22:48 +0200 writes:
>
>     > I installed R-3.4.0 and got problems with the survival package, for instance
>     > ------------
>     >> library(survival)
>     >> mort <- data.frame(exit = 1:4, event = rep(1, 4), x = c(0, 1, 0, 1))
>     >> fit <- coxph(Surv(exit, event) ~ x, data = mort)
>     > Error in fitter(X, Y, strats, offset, init, control, weights = weights,  :
>     > object 'Ccoxmart' not found
>     > -------------
>
>     > No problems with R-3.3.3 and the same (latest) survival version, which
>     > makes me think that something is going on in my R installation rather
>     > than in the survival package.
>
>     > Thanks for any hint,
>
>     > G?ran
>
>     >> sessionInfo()
>     > R version 3.4.0 (2017-04-21)
>     > Platform: x86_64-pc-linux-gnu (64-bit)
>     > Running under: Ubuntu 16.04.2 LTS
>
>     > Matrix products: default
>     > BLAS: /usr/lib/openblas-base/libblas.so.3
>     > LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
>     > locale:
>     > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>     > [3] LC_TIME=sv_SE.UTF-8        LC_COLLATE=en_US.UTF-8
>     > [5] LC_MONETARY=sv_SE.UTF-8    LC_MESSAGES=en_US.UTF-8
>     > [7] LC_PAPER=sv_SE.UTF-8       LC_NAME=C
>     > [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     > [11] LC_MEASUREMENT=sv_SE.UTF-8 LC_IDENTIFICATION=C
>
>     > attached base packages:
>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>
>     > other attached packages:
>     > [1] survival_2.41-3
>
>     > loaded via a namespace (and not attached):
>     > [1] compiler_3.4.0  Matrix_1.2-8    splines_3.4.0   grid_3.4.0
>     > [5] lattice_0.20-35
>
> I'm 99.5% sure that you are using more than just the default
> library of package (a very good thing - we have been doing the
> same for years).
>
> We have in NEWS for R 3.4.0
>
>   > PACKAGE INSTALLATION:
>
>   >   [...........]
>
>   >   [...........]
>
>   >   ? Packages which register native routines for .C or .Fortran need
>   >     to be re-installed for this version (unless installed with
>   >     R-devel SVN revision r72375 or later).
>
> and Prof Brian Ripley did announce that nicely and early on R-devel.
> ==> https://hypatia.math.ethz.ch/pipermail/r-devel/2017-March/073940.html
>
> ==> You have to re-install quite a few packages for R 3.4.0,
>      __if__ they use .C() or .Fortran()
>
> When we've e-talked about the issue within R-core,
> Uwe Ligges noted we should really ask everyone to run
>
>    	  update.packages(checkBuilt=TRUE)

A small nuisance with this is that I end up with two versions of the 
survival package (and other recommended packages), since I cannot write 
to /usr/lib/R/library. However, this is obviously a problem suitable to 
present on R-SIG-Debian. See you there.

G?ran

>
> after an update to a new major (meaning "R-x.y.0") release of R
> and **not** re-use packages {inside R-x.y.z}
> that were installed with R-x.(y-1).z'  ..
>
> and of course Uwe is right:
> We should ask others to do it _and_ do it ourselves.
>
> Anyway it _is_ considerably more important for the 3.4.0
> release.
>
> Martin Maechler
> ETH Zurich (and R Core team)
>
>


From peter.anthoni at kit.edu  Tue Apr 25 14:38:07 2017
From: peter.anthoni at kit.edu (Anthoni, Peter (IMK))
Date: Tue, 25 Apr 2017 12:38:07 +0000
Subject: [R] asking for help
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A22676@SRVEXCHCM301.precheza.cz>
References: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
 <4c4be595-4702-4f9d-a757-859eae12dd02@Spark>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A22676@SRVEXCHCM301.precheza.cz>
Message-ID: <EA993888-DB2E-4543-BDD8-6C2516840817@kit.edu>

Hi,

the cut function might be helpful.

vec=1: 163863
fcut=cut(vec,seq(1, 163863+1,by= 6069),include.lowest = T,right=F)
aggregate(vec,by=list(fcut),min)
aggregate(vec,by=list(fcut),max)

cheers
Peter



On 25. Apr 2017, at 14:33, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
Mailund
Sent: Tuesday, April 25, 2017 11:20 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>; Saifuddin, Miah Mohammad
<miah.mohammadsaifudd at mavs.uta.edu<mailto:miah.mohammadsaifudd at mavs.uta.edu>>
Subject: Re: [R] asking for help

If you write something like

indices <- rep(1:(163863/6069), each = 6069)

You can get similar result by

indices2 <- 0:163862%/%6069

but starting with zero.

or the same with
indices2 <- (0:163862%/%6069)+1

Cheers
Petr


you can get the i?th block of rows with

table[indices == i,]

It looks like a little more work than a loop would be since you have to run
through all rows for each block, but the implicit loop in this approach is likely
to be faster than an explicit for-loop.

Cheers
?Thomas

On 25 Apr 2017, 07.01 +0200, Saifuddin, Miah Mohammad
<miah.mohammadsaifudd at mavs.uta.edu<mailto:miah.mohammadsaifudd at mavs.uta.edu>>, wrote:
I have a data frame having 163863 values. I want to subset it so that each set
has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second.
how can I do that, preferably in a loop.


TIA

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
and provide commented, minimal, self-contained, reproducible code.

     [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue Apr 25 18:36:31 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 25 Apr 2017 18:36:31 +0200
Subject: [R] Multiple-Response Analysis: Cleaning of Duplicate Codes
Message-ID: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>

Hi All,

in my current project I am working with multiple-response questions 
(MRSets):

-- Coding --
100 Main Code 1
110 Sub Code 1.1
120 Sub Code 1.2
130 Sub Code 1.3

200 Main Code 2
210 Sub Code 2.1
220 Sub Code 2.2
230 Sub Code 2.3

300 Main Code 3
310 Sub Code 3.1
320 Sub Code 3.2

The coding for the variables is to detailed. Therefore I have recoded all 
sub codes to the respective main code, e.g. all 110, 120 and 130 to 100, 
all 210, 220 and 230 to 200 and all 310, 320 and 330 to 300.

Now it happens that some respondents get several times the same main code. 
If the coding was done for respondent 1 with 120 and 130 after recoding 
the values are 100 and 100. If I count this, it would mean that I weight 
the multiple values of this respondent by factor 2. This is not my aim. I 
would like to count the 100 for the respective respondent only once.

Here is my script so far:

# -- cut --

library(expss)

d_sample <-
  structure(
    list(
      c05_01 = c(
        110,
        110,
        130,
        110,
        110,
        110,
        110,
        110,
        110,
        110,
        110,
        999,
        110,
        495,
        160,
        110,
        410
      ),
      c05_02 = c(NA,
                 NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA, 
170,
                 NA, 130),
      c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
                 NA, NA, NA, NA, NA, NA, NA),
      c05_04 = c(
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_
      ),
      c05_05 = c(
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_
      )
    ),
    .Names = c("c05_01",
               "c05_02", "c05_03", "c05_04", "c05_05"),
    row.names = c(
      "1",
      "2",
      "3",
      "4",
      "5",
      "10",
      "11",
      "12",
      "13",
      "14",
      "15",
      "20",
      "21",
      "22",
      "23",
      "24",
      "25"
    ),
    class = "data.frame"
  )

c05_xx_r01 <- d_sample %>%
  select(starts_with("c05_")) %>%
  recode(c(
    110 %thru% 195 ~ 100,
    210 %thru% 295 ~ 200,
    310 %thru% 395 ~ 300,
    410 %thru% 495 ~ 400,
    510 %thru% 595 ~ 500,
    810 %thru% 895 ~ 800,
    910 %thru% 999 ~ 900))
names(c05_xx_r01) <- paste0("c05_0", 1:5, "_r01")
d_sample <- cbind(d_sample, c05_xx_r01)

# -- cut --

I would like to eliminate all duplicates codes, e. g. 100 and 100 for 
respondents in row 3, 6, 13, 14 and 15 to 100 only once:

# -- cut --
d_sample_1 <-
  structure(
    list(
      c05_01 = c(
        110,
        110,
        130,
        110,
        110,
        110,
        110,
        110,
        110,
        110,
        110,
        999,
        110,
        495,
        160,
        110,
        410
      ),
      c05_02 = c(NA,
                 NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA, 
170,
                 NA, 130),
      c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
                 NA, NA, NA, NA, NA, NA, NA),
      c05_04 = c(
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_
      ),
      c05_05 = c(
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_,
        NA_real_
      ),
      c05_01_r01 = c(
        100,
        100,
        100,
        100,
        100,
        100,
        100,
        100,
        100,
        100,
        100,
        900,
        100,
        400,
        100,
        100,
        400
      ),
      c05_02_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA,
                     NA, NA, NA, NA, NA, NA, NA, NA, 100),
      c05_03_r01 = c(NA, NA,
                     NA, NA, NA, NA, NA, NA, NA, 400, NA, NA, NA, NA, NA, 
NA, NA),
      c05_04_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
                     NA, NA, NA, NA, NA, NA),
      c05_05_r01 = c(NA, NA, NA, NA, NA,
                     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
    ),
    .Names = c(
      "c05_01",
      "c05_02",
      "c05_03",
      "c05_04",
      "c05_05",
      "c05_01_r01",
      "c05_02_r01",
      "c05_03_r01",
      "c05_04_r01",
      "c05_05_r01"
    ),
    row.names = c(
      "1",
      "2",
      "3",
      "4",
      "5",
      "10",
      "11",
      "12",
      "13",
      "14",
      "15",
      "20",
      "21",
      "22",
      "23",
      "24",
      "25"
    ),
    class = "data.frame"
  )

# -- cut --

How could I achieve this?

Kind regards

Georg


From thomas.mailund at gmail.com  Tue Apr 25 11:54:55 2017
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Tue, 25 Apr 2017 11:54:55 +0200
Subject: [R] Delayed evaluation / lazy expression evaluation
In-Reply-To: <6e77024e-5d51-4b5d-a68a-3d7796bb69c3@Spark>
References: <6e77024e-5d51-4b5d-a68a-3d7796bb69c3@Spark>
Message-ID: <c8feaeb5-4055-4fea-86c1-b5b00a1129b9@Spark>

If anyone are interested, I found a solution for lazy lists. A simplified version of their construction and access looks like this:

nil <- function() NULL
cons <- function(car, cdr) {
? force(car)
? force(cdr)
? function() list(car = car, cdr = cdr)
}

is_nil <- function(lst) is.null(lst())
car <- function(lst) lst()$car
cdr <- function(lst) lst()$cdr

An invariant is that a list is always a thunk that evaluates to either NULL or a list tha contains car and cdr where cdr is another list (i.e. a thunk).

Operations on lists can be made lazy by wrapping them in a thunk that returns an evaluated promise. The laziness comes from wrapping an expression in a promise and by evaluating this promise we make it behave like the un-wrapped list would do.

So we can, for example, implement lazy reversal and concatenation like this:

reverse <- function(lst) {
? do_reverse <- function(lst) {
? ? result <- nil
? ? while (!is_nil(lst)) {
? ? ? result <- cons(car(lst), result)
? ? ? lst <- cdr(lst)
? ? }
? ? result
? }

? force(lst)
? lazy_thunk <- function(lst) {
? ? function() lst()
? }
? lazy_thunk(do_reverse(lst))
}

cat <- function(l1, l2) {
? do_cat <- function(l1, l2) {
? ? rev_l1 <- nil
? ? while (!is_nil(l1)) {
? ? ? rev_l1 <- cons(car(l1), rev_l1)
? ? ? l1 <- cdr(l1)
? ? }
? ? result <- l2
? ? while (!is_nil(rev_l1)) {
? ? ? result <- cons(car(rev_l1), result)
? ? ? rev_l1 <- cdr(rev_l1)
? ? }
? ? result
? }

? force(l1)
? force(l2)
? lazy_thunk <- function(lst) {
? ? function() lst()
? }
? lazy_thunk(do_cat(l1, l2))
}


As an example of how this laziness works, we can test concatenation. Concatenating two lists is a fast operation, because we don?t actually evaluate the concatenation, but when we access the list afterward we pay for both the concatenation and the access.

vector_to_list <- function(v) {
? lst <- nil
? for (x in v) lst <- cons(x, lst)
? reverse(lst)
}

l1 <- vector_to_list(1:10000)
l2 <- vector_to_list(1:10000)

library(microbenchmark)
microbenchmark(lst <- cat(l1, l2), times = 1) # fast operation
microbenchmark(car(lst), times = 1) # slow operation
microbenchmark(car(lst), times = 1) # faster operation


Of course, such a lazy list implementation is just a slow way of implementing lists, but it makes it possible to exploit a combination of amortised analysis and persistent data structures to implement queues?http://www.westpoint.edu/eecs/SiteAssets/SitePages/Faculty%20Publication%20Documents/Okasaki/jfp95queue.pdf


Cheers

On 24 Apr 2017, 16.35 +0200, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> Hi, I?m playing around with ways of implementing lazy evaluation of expressions. In R, function arguments are evaluated as promises but expressions are evaluated immediately, so I am trying to wrap expressions in thunks?functions with no arguments that evaluate an expression?to get something the resembles lazy evaluation of expressions.
>
> As an example, consider this:
>
> lazy <- function(value) {
> ? function() value
> }
>
> f <- lazy((1:100000)[1])
>
> If we evaluate f we have to create the long vector and then get the first element. We delay the evaluation to f so the first time we call f we should see a slow operation and if we evaluate it again we should see faster evaluations. If you run this benchmark, you will see that this is indeed what we get:
>
> library(microbenchmark)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
> microbenchmark(f(), times = 1)
>
> Now, I want to use this to implement lazy linked lists. It is not particularly important why I want to do this, but if you are interested, it is because you can implement persistent queues with amortised constant time operations this way, which is what I am experimenting with.
>
> I have this implementation of linked lists:
>
> list_cons <- function(elem, lst)
> ? structure(list(head = elem, tail = lst), class = "linked_list")
>
> list_nil <- list_cons(NA, NULL)
> empty_list <- function() list_nil
> is_empty.linked_list <- function(x) identical(x, list_nil)
>
>
> You can implement it simpler using NULL as an empty list, but this particular implementation lets me use polymorphism to implement different versions of data structures ? the reasoning is explained in chapter 2 of a book I?m working on:?https://www.dropbox.com/s/qdnjc0bx4yivl8r/book.pdf?dl=0
>
> Anyway, that list implementation doesn?t evaluate the lists lazily, so I am trying to wrap these lists in calls to lazy().
>
> A simple implementation looks like this:
>
>
> lazy_empty_list <- lazy(empty_list())
> lazy_cons <- function(elm, lst) {
> ? lazy(list_cons(elm, lst()))
> }
>
> Now, this works fine for adding an element to an empty list:
>
> lst <- lazy_cons(2, lazy_empty_list)
> lst()
>
> It also works fine if I add another element to an expression for constructing a list:
>
> lst <- lazy_cons(1, lazy_cons(2, lazy_empty_list))
> lst()
>
> I can construct lists as long as I want, as long as I explicitly give the lazy_cons() function an expression for the list:
>
> lst <- lazy_cons(1, lazy_cons(2, lazy_cons(3, lazy_empty_list)))
> lst()
>
>
> However, if I save intermediate lists in a variable, it breaks down. This code:
>
> lst <- lazy_cons(2, lazy_empty_list)
> lst <- lazy_cons(1, lst)
> lst()
>
> gives me this error:
>
> ?Error in lst() :
> ? promise already under evaluation: recursive default argument reference or earlier problems?
>
> Now, I am particularly dense today, it being Monday and all, so there is likely to be something very obvious I am missing, but I would think that the ?lit? variable, when passed to lazy_cons(), would be interpreted as a promise to be evaluated in the parent environment, so I don?t see why it is considered a circular definition of it.
>
> If I force the list to be evaluated, it all works, and the first evaluation is more expensive than the following:
>
> lazy_cons <- function(elm, lst) {
> ? force(lst)
> ? lazy(list_cons(elm, lst()))
> }
> lst <- lazy_cons(1, lazy_empty_list)
> lst <- lazy_cons(2, lst)
> lst <- lazy_cons(3, lst)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
>
> But if I do the exact same thing in a for-loop, it breaks again?this does not work and I get the same error as earlier:
>
> lst <- lazy_empty_list()
> for (e in 1:3) {
> ? lst <- lazy_cons(e, lst)
> }
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
> microbenchmark(lst(), times = 1)
>
> I really can?t see what the difference is between the loop version and the explicitly unwrapping of the loop, but R certainly sees a difference?
>
> I would really love to hear if any of you guys have any insights to what is going on here...
>
>
> Cheers
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From empirical_bayesian at ieee.org  Tue Apr 25 15:39:40 2017
From: empirical_bayesian at ieee.org (Jan Galkowski)
Date: Tue, 25 Apr 2017 09:39:40 -0400
Subject: [R] R 3.4.0 on Windows 7 Home Premium installed apparently fine,
 but packages failing to load ...
Message-ID: <1493127580.452177.955580136.152AC059@webmail.messagingengine.com>

Hello!

I welcome the new *R* 3.4.0.  I installed it on my Windows 7 Home
Premium [Service Pack 1, updated to latest, running on an HP AMD(Phenom)
II 955 X4 Processor, 3.20 GHz, 16 GB RAM, 64-bit, with lots of free
storage on disk and a solid state disk for virtual cache]. It was
installed atop the previous *R* version.
I tried the usual *update.packages(ask=FALSE)* and found many instances
of packages, e.g., *ctmm*, *SweaveListingUtils*, *plotly*,
*scatterplot3d*, *startupmsg *which failed to install, apparently
because of an attempt to include an install of i386 instead of only x64.
I was using the Berkeley mirror via *https:*> 
> R version 3.4.0 (2017-04-21) -- "You Stupid Darkness" 
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)

I opted *not* to install from source those packages requiring
compilation, although Rtools was installed and when installing a package
before, FORTRAN compilations succeed. I also have an MSVC++ installed,
but I've not gotten that to work on Windows, unlike when I install on
Ubuntu machines.
Unfortunately, install at least for these packages fails:

Do you want to install from sources the packages which need compilation?y/n: n
Package which is only available in source form, and may need
compilation of  C/C++/Fortran: ?gpclib?
Do you want to attempt to install these from sources?
y/n: n
trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/crosstalk_1.0.0.zip'Content type 'application/zip' length 598840 bytes (584 KB)
downloaded 584 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/deldir_0.1-12.zip'Content type 'application/zip' length 173098 bytes (169 KB)
downloaded 169 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/distr_2.6.zip'Content type 'application/zip' length 2226722 bytes (2.1 MB)
downloaded 2.1 MB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/distrEx_2.6.zip'Content type 'application/zip' length 720392 bytes (703 KB)
downloaded 703 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/foreign_0.8-67.zip'Content type 'application/zip' length 309745 bytes (302 KB)
downloaded 302 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/gam_1.14-3.zip'Content type 'application/zip' length 319049 bytes (311 KB)
downloaded 311 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/lattice_0.20-34.zip'Content type 'application/zip' length 731408 bytes (714 KB)
downloaded 714 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/MASS_7.3-45.zip'Content type 'application/zip' length 1173817 bytes (1.1 MB)
downloaded 1.1 MB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/rpart_4.1-10.zip'Content type 'application/zip' length 950721 bytes (928 KB)
downloaded 928 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/sem_3.1-8.zip'Content type 'application/zip' length 1110127 bytes (1.1 MB)
downloaded 1.1 MB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/SparseM_1.76.zip'Content type 'application/zip' length 952285 bytes (929 KB)
downloaded 929 KB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/survival_2.41-2.zip'Content type 'application/zip' length 5426933 bytes (5.2 MB)
downloaded 5.2 MB

trying URL '
https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/VineCopula_2.1.1.zip'Content type 'application/zip' length 1106702 bytes (1.1 MB)
downloaded 1.1 MB

package ?crosstalk? successfully unpacked and MD5 sums checked
package ?deldir? successfully unpacked and MD5 sums checked
package ?distr? successfully unpacked and MD5 sums checked
package ?distrEx? successfully unpacked and MD5 sums checked
package ?foreign? successfully unpacked and MD5 sums checked
package ?gam? successfully unpacked and MD5 sums checked
package ?lattice? successfully unpacked and MD5 sums checked
package ?MASS? successfully unpacked and MD5 sums checked
package ?rpart? successfully unpacked and MD5 sums checked
package ?sem? successfully unpacked and MD5 sums checked
package ?SparseM? successfully unpacked and MD5 sums checked
package ?survival? successfully unpacked and MD5 sums checked
package ?VineCopula? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu\downloaded_packages
installing the source packages ?ctmm?, ?plotly?, ?scatterplot3d?,
?startupmsg?, ?SweaveListingUtils?
trying URL '
https://mirrors.nics.utk.edu/cran/src/contrib/ctmm_0.3.6.tar.gz'Content type 'application/x-gzip' length 731682 bytes (714 KB)
downloaded 714 KB

trying URL '
https://mirrors.nics.utk.edu/cran/src/contrib/plotly_4.6.0.tar.gz'Content type 'application/x-gzip' length 980458 bytes (957 KB)
downloaded 957 KB

trying URL '
https://mirrors.nics.utk.edu/cran/src/contrib/scatterplot3d_0.3-40.tar.gz'Content type 'application/x-gzip' length 453806 bytes (443 KB)
downloaded 443 KB

trying URL '
https://mirrors.nics.utk.edu/cran/src/contrib/startupmsg_0.9.4.tar.gz'Content type 'application/x-gzip' length 9496 bytes
downloaded 9496 bytes

trying URL '
https://mirrors.nics.utk.edu/cran/src/contrib/SweaveListingUtils_0.7.7.tar.gz'Content type 'application/x-gzip' length 579120 bytes (565 KB)
downloaded 565 KB


Welcome at Tue Apr 25 09:32:12 2017
* installing *source* package 'ctmm' ...
** package 'ctmm' successfully unpacked and MD5 sums checked
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
*** arch - i386
*** arch - x64

Welcome at Tue Apr 25 09:34:38 2017

Goodbye at  Tue Apr 25 09:34:42 2017
ERROR: loading failed for 'i386'
* removing 'C:/Program Files/R/R-2.13.1/library/ctmm'
* restoring previous 'C:/Program Files/R/R-2.13.1/library/ctmm'
Warning: running command '"C:/PROGRA~1/R/R-213~1.1/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-2.13.1\library" C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu/downloaded_packages/ctmm_0.3.6.tar.gz' had status 1Warning in install.packages(update[instlib == l, "Package"], l, repos
= repos,  :  installation of package ?ctmm? had non-zero exit status

Welcome at Tue Apr 25 09:34:43 2017
* installing *source* package 'plotly' ...
** package 'plotly' successfully unpacked and MD5 sums checked
** R
** data
*** moving datasets to lazyload DB
** demo
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64

Welcome at Tue Apr 25 09:35:03 2017

Goodbye at  Tue Apr 25 09:35:04 2017
ERROR: loading failed for 'i386'
* removing 'C:/Program Files/R/R-2.13.1/library/plotly'
* restoring previous 'C:/Program Files/R/R-2.13.1/library/plotly'
Warning: running command '"C:/PROGRA~1/R/R-213~1.1/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-2.13.1\library" C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu/downloaded_packages/plotly_4.6.0.tar.gz' had status 1Warning in install.packages(update[instlib == l, "Package"], l, repos
= repos,  :  installation of package ?plotly? had non-zero exit status

Welcome at Tue Apr 25 09:35:07 2017
* installing *source* package 'scatterplot3d' ...
** package 'scatterplot3d' successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
*** arch - i386
*** arch - x64

Welcome at Tue Apr 25 09:35:11 2017

Goodbye at  Tue Apr 25 09:35:11 2017
ERROR: loading failed for 'i386'
* removing 'C:/Program Files/R/R-2.13.1/library/scatterplot3d'
* restoring previous 'C:/Program Files/R/R-2.13.1/library/scatterplot3d'Warning: running command '"C:/PROGRA~1/R/R-213~1.1/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-2.13.1\library" C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu/downloaded_packages/scatterplot3d_0.3-40.tar.gz' had status 1Warning in install.packages(update[instlib == l, "Package"], l, repos
= repos,  :  installation of package ?scatterplot3d? had non-zero exit status

Welcome at Tue Apr 25 09:35:14 2017
* installing *source* package 'startupmsg' ...
** package 'startupmsg' successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64

Welcome at Tue Apr 25 09:35:17 2017

Goodbye at  Tue Apr 25 09:35:17 2017
ERROR: loading failed for 'i386'
* removing 'C:/Program Files/R/R-2.13.1/library/startupmsg'
* restoring previous 'C:/Program Files/R/R-2.13.1/library/startupmsg'
Warning: running command '"C:/PROGRA~1/R/R-213~1.1/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-2.13.1\library" C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu/downloaded_packages/startupmsg_0.9.4.tar.gz' had status 1Warning in install.packages(update[instlib == l, "Package"], l, repos
= repos,  :  installation of package ?startupmsg? had non-zero exit status

Welcome at Tue Apr 25 09:35:18 2017
* installing *source* package 'SweaveListingUtils' ...
** package 'SweaveListingUtils' successfully unpacked and MD5
sums checked** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
*** arch - i386
*** arch - x64

Welcome at Tue Apr 25 09:35:24 2017

Goodbye at  Tue Apr 25 09:35:24 2017
ERROR: loading failed for 'i386'
* removing 'C:/Program Files/R/R-2.13.1/library/SweaveListingUtils'
* restoring previous 'C:/Program Files/R/R-
  2.13.1/library/SweaveListingUtils'Warning: running command '"C:/PROGRA~1/R/R-213~1.1/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-2.13.1\library" C:\Users\Jan\AppData\Local\Temp\Rtmpyekpgu/downloaded_packages/SweaveListingUtils_0.7.7.tar.gz' had status 1Warning in install.packages(update[instlib == l, "Package"], l, repos
= repos,  :  installation of package ?SweaveListingUtils? had non-zero exit status
The important package *boot* was failing before as well, but I tried
again using Vanderbilt as the mirror, and that seemed to work fine.
Sorry for the length of the post, but I wanted to include all the
important information, and did not know where or how to write a
bug report about all this.  After all, this does not look,
strictly speaking, like an *R* or a package problem, but a
delivery system problem.
Thanks for all your great work!

--
Jan Galkowski (o?)




	[[alternative HTML version deleted]]


From miah.mohammadsaifudd at mavs.uta.edu  Tue Apr 25 16:36:02 2017
From: miah.mohammadsaifudd at mavs.uta.edu (Saifuddin, Miah Mohammad)
Date: Tue, 25 Apr 2017 14:36:02 +0000
Subject: [R] asking for help
In-Reply-To: <EA993888-DB2E-4543-BDD8-6C2516840817@kit.edu>
References: <CY1PR01MB185203514C2667550A04C93AA21E0@CY1PR01MB1852.prod.exchangelabs.com>
 <4c4be595-4702-4f9d-a757-859eae12dd02@Spark>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A22676@SRVEXCHCM301.precheza.cz>,
 <EA993888-DB2E-4543-BDD8-6C2516840817@kit.edu>
Message-ID: <CY1PR01MB1852D3DB716AB6E97B395436A21E0@CY1PR01MB1852.prod.exchangelabs.com>

Dear Altruist,


Thank you so much.


This does it.


I shall keep connected.


Regards,

Miah


________________________________
From: Anthoni, Peter (IMK) <peter.anthoni at kit.edu>
Sent: Tuesday, April 25, 2017 8:38 AM
To: Saifuddin, Miah Mohammad
Cc: Thomas Mailund; r-help at r-project.org; PIKAL Petr
Subject: Re: [R] asking for help

Hi,

the cut function might be helpful.

vec=1: 163863
fcut=cut(vec,seq(1, 163863+1,by= 6069),include.lowest = T,right=F)
aggregate(vec,by=list(fcut),min)
aggregate(vec,by=list(fcut),max)

cheers
Peter



On 25. Apr 2017, at 14:33, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
Mailund
Sent: Tuesday, April 25, 2017 11:20 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>; Saifuddin, Miah Mohammad
<miah.mohammadsaifudd at mavs.uta.edu<mailto:miah.mohammadsaifudd at mavs.uta.edu>>
Subject: Re: [R] asking for help

If you write something like

indices <- rep(1:(163863/6069), each = 6069)

You can get similar result by

indices2 <- 0:163862%/%6069

but starting with zero.

or the same with
indices2 <- (0:163862%/%6069)+1

Cheers
Petr


you can get the i?th block of rows with

table[indices == i,]

It looks like a little more work than a loop would be since you have to run
through all rows for each block, but the implicit loop in this approach is likely
to be faster than an explicit for-loop.

Cheers
?Thomas

On 25 Apr 2017, 07.01 +0200, Saifuddin, Miah Mohammad
<miah.mohammadsaifudd at mavs.uta.edu<mailto:miah.mohammadsaifudd at mavs.uta.edu>>, wrote:
I have a data frame having 163863 values. I want to subset it so that each set
has 6069 values in it. for example 1:6069 as first, 6070: 6070+6068 as second.
how can I do that, preferably in a loop.


TIA

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
and provide commented, minimal, self-contained, reproducible code.

     [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 25 19:10:53 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 25 Apr 2017 10:10:53 -0700
Subject: [R] Multiple-Response Analysis: Cleaning of Duplicate Codes
In-Reply-To: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>
References: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>
Message-ID: <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>

If I understand you correctly, one way is:

> z <- rep(LETTERS[1:3],4)
> z
 [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
> z[!duplicated(z)]
[1] "A" "B" "C"


?duplicated

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 25, 2017 at 9:36 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I am working with multiple-response questions
> (MRSets):
>
> -- Coding --
> 100 Main Code 1
> 110 Sub Code 1.1
> 120 Sub Code 1.2
> 130 Sub Code 1.3
>
> 200 Main Code 2
> 210 Sub Code 2.1
> 220 Sub Code 2.2
> 230 Sub Code 2.3
>
> 300 Main Code 3
> 310 Sub Code 3.1
> 320 Sub Code 3.2
>
> The coding for the variables is to detailed. Therefore I have recoded all
> sub codes to the respective main code, e.g. all 110, 120 and 130 to 100,
> all 210, 220 and 230 to 200 and all 310, 320 and 330 to 300.
>
> Now it happens that some respondents get several times the same main code.
> If the coding was done for respondent 1 with 120 and 130 after recoding
> the values are 100 and 100. If I count this, it would mean that I weight
> the multiple values of this respondent by factor 2. This is not my aim. I
> would like to count the 100 for the respective respondent only once.
>
> Here is my script so far:
>
> # -- cut --
>
> library(expss)
>
> d_sample <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       )
>     ),
>     .Names = c("c05_01",
>                "c05_02", "c05_03", "c05_04", "c05_05"),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> c05_xx_r01 <- d_sample %>%
>   select(starts_with("c05_")) %>%
>   recode(c(
>     110 %thru% 195 ~ 100,
>     210 %thru% 295 ~ 200,
>     310 %thru% 395 ~ 300,
>     410 %thru% 495 ~ 400,
>     510 %thru% 595 ~ 500,
>     810 %thru% 895 ~ 800,
>     910 %thru% 999 ~ 900))
> names(c05_xx_r01) <- paste0("c05_0", 1:5, "_r01")
> d_sample <- cbind(d_sample, c05_xx_r01)
>
> # -- cut --
>
> I would like to eliminate all duplicates codes, e. g. 100 and 100 for
> respondents in row 3, 6, 13, 14 and 15 to 100 only once:
>
> # -- cut --
> d_sample_1 <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_01_r01 = c(
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         900,
>         100,
>         400,
>         100,
>         100,
>         400
>       ),
>       c05_02_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, 100),
>       c05_03_r01 = c(NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, 400, NA, NA, NA, NA, NA,
> NA, NA),
>       c05_04_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA),
>       c05_05_r01 = c(NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
>     ),
>     .Names = c(
>       "c05_01",
>       "c05_02",
>       "c05_03",
>       "c05_04",
>       "c05_05",
>       "c05_01_r01",
>       "c05_02_r01",
>       "c05_03_r01",
>       "c05_04_r01",
>       "c05_05_r01"
>     ),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> # -- cut --
>
> How could I achieve this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Apr 25 19:28:35 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 25 Apr 2017 13:28:35 -0400
Subject: [R] Multiple-Response Analysis: Cleaning of Duplicate Codes
In-Reply-To: <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
References: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>
 <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
Message-ID: <E64AF588-0A6A-4771-9ED7-0CFEF8F553E1@utoronto.ca>

How about:

d_sample_1 <- floor(d_sample/100) * 100

for (i in 1:nrow(d_sample_1)) {
    d_sample_1[i, duplicated(unlist(d_sample_1[i, ]))] <- NA 
}


B.


> On Apr 25, 2017, at 1:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> If I understand you correctly, one way is:
> 
>> z <- rep(LETTERS[1:3],4)
>> z
> [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
>> z[!duplicated(z)]
> [1] "A" "B" "C"
> 
> 
> ?duplicated
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Apr 25, 2017 at 9:36 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>> 
>> in my current project I am working with multiple-response questions
>> (MRSets):
>> 
>> -- Coding --
>> 100 Main Code 1
>> 110 Sub Code 1.1
>> 120 Sub Code 1.2
>> 130 Sub Code 1.3
>> 
>> 200 Main Code 2
>> 210 Sub Code 2.1
>> 220 Sub Code 2.2
>> 230 Sub Code 2.3
>> 
>> 300 Main Code 3
>> 310 Sub Code 3.1
>> 320 Sub Code 3.2
>> 
>> The coding for the variables is to detailed. Therefore I have recoded all
>> sub codes to the respective main code, e.g. all 110, 120 and 130 to 100,
>> all 210, 220 and 230 to 200 and all 310, 320 and 330 to 300.
>> 
>> Now it happens that some respondents get several times the same main code.
>> If the coding was done for respondent 1 with 120 and 130 after recoding
>> the values are 100 and 100. If I count this, it would mean that I weight
>> the multiple values of this respondent by factor 2. This is not my aim. I
>> would like to count the 100 for the respective respondent only once.
>> 
>> Here is my script so far:
>> 
>> # -- cut --
>> 
>> library(expss)
>> 
>> d_sample <-
>>  structure(
>>    list(
>>      c05_01 = c(
>>        110,
>>        110,
>>        130,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        999,
>>        110,
>>        495,
>>        160,
>>        110,
>>        410
>>      ),
>>      c05_02 = c(NA,
>>                 NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
>> 170,
>>                 NA, 130),
>>      c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>>                 NA, NA, NA, NA, NA, NA, NA),
>>      c05_04 = c(
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_
>>      ),
>>      c05_05 = c(
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_
>>      )
>>    ),
>>    .Names = c("c05_01",
>>               "c05_02", "c05_03", "c05_04", "c05_05"),
>>    row.names = c(
>>      "1",
>>      "2",
>>      "3",
>>      "4",
>>      "5",
>>      "10",
>>      "11",
>>      "12",
>>      "13",
>>      "14",
>>      "15",
>>      "20",
>>      "21",
>>      "22",
>>      "23",
>>      "24",
>>      "25"
>>    ),
>>    class = "data.frame"
>>  )
>> 
>> c05_xx_r01 <- d_sample %>%
>>  select(starts_with("c05_")) %>%
>>  recode(c(
>>    110 %thru% 195 ~ 100,
>>    210 %thru% 295 ~ 200,
>>    310 %thru% 395 ~ 300,
>>    410 %thru% 495 ~ 400,
>>    510 %thru% 595 ~ 500,
>>    810 %thru% 895 ~ 800,
>>    910 %thru% 999 ~ 900))
>> names(c05_xx_r01) <- paste0("c05_0", 1:5, "_r01")
>> d_sample <- cbind(d_sample, c05_xx_r01)
>> 
>> # -- cut --
>> 
>> I would like to eliminate all duplicates codes, e. g. 100 and 100 for
>> respondents in row 3, 6, 13, 14 and 15 to 100 only once:
>> 
>> # -- cut --
>> d_sample_1 <-
>>  structure(
>>    list(
>>      c05_01 = c(
>>        110,
>>        110,
>>        130,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        110,
>>        999,
>>        110,
>>        495,
>>        160,
>>        110,
>>        410
>>      ),
>>      c05_02 = c(NA,
>>                 NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
>> 170,
>>                 NA, 130),
>>      c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>>                 NA, NA, NA, NA, NA, NA, NA),
>>      c05_04 = c(
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_
>>      ),
>>      c05_05 = c(
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_,
>>        NA_real_
>>      ),
>>      c05_01_r01 = c(
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        100,
>>        900,
>>        100,
>>        400,
>>        100,
>>        100,
>>        400
>>      ),
>>      c05_02_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA,
>>                     NA, NA, NA, NA, NA, NA, NA, NA, 100),
>>      c05_03_r01 = c(NA, NA,
>>                     NA, NA, NA, NA, NA, NA, NA, 400, NA, NA, NA, NA, NA,
>> NA, NA),
>>      c05_04_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>                     NA, NA, NA, NA, NA, NA),
>>      c05_05_r01 = c(NA, NA, NA, NA, NA,
>>                     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
>>    ),
>>    .Names = c(
>>      "c05_01",
>>      "c05_02",
>>      "c05_03",
>>      "c05_04",
>>      "c05_05",
>>      "c05_01_r01",
>>      "c05_02_r01",
>>      "c05_03_r01",
>>      "c05_04_r01",
>>      "c05_05_r01"
>>    ),
>>    row.names = c(
>>      "1",
>>      "2",
>>      "3",
>>      "4",
>>      "5",
>>      "10",
>>      "11",
>>      "12",
>>      "13",
>>      "14",
>>      "15",
>>      "20",
>>      "21",
>>      "22",
>>      "23",
>>      "24",
>>      "25"
>>    ),
>>    class = "data.frame"
>>  )
>> 
>> # -- cut --
>> 
>> How could I achieve this?
>> 
>> Kind regards
>> 
>> Georg
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reichmanj at sbcglobal.net  Tue Apr 25 23:04:48 2017
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Tue, 25 Apr 2017 16:04:48 -0500
Subject: [R] R Date Time
Message-ID: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>

R Users

 

Having problems converting the following DTG into an R recognized date/time
field

 

01-01-2016T14:02:23.325

 

Would I separate it into a date field and time filed then put it back
together???

 

Jeff


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 25 23:13:46 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Apr 2017 17:13:46 -0400
Subject: [R] R Date Time
In-Reply-To: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
References: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
Message-ID: <7d472994-d1df-74b8-da49-c590369d67f2@gmail.com>

On 25/04/2017 5:04 PM, Jeff Reichman wrote:
> R Users
>
>
>
> Having problems converting the following DTG into an R recognized date/time
> field
>
>
>
> 01-01-2016T14:02:23.325
>
>
>
> Would I separate it into a date field and time filed then put it back
> together???
>

This appears to work (though I'm not sure whether you are using MDY or 
DMY; I used DMY):

strptime("01-01-2016T14:02:23.325", format="%d-%m-%YT%H:%M:%OS")

Duncan Murdoch


From wdunlap at tibco.com  Tue Apr 25 23:21:00 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 25 Apr 2017 14:21:00 -0700
Subject: [R] R Date Time
In-Reply-To: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
References: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
Message-ID: <CAF8bMcaU8JqpUdTe6vr-jNjECCemLTrbRFs4B75cXsguQGvDeQ@mail.gmail.com>

> z <- as.POSIXct("01-01-2016T14:02:23.325", format="%d-%m-%YT%H:%M:%OS")
> dput(z)
structure(1451685743.325, class = c("POSIXct", "POSIXt"), tzone = "")
> z
[1] "2016-01-01 14:02:23 PST"
> format(z, "%H:%M:%OS3 on %b %d, %Y")
[1] "14:02:23.325 on Jan 01, 2016"

(Don't separate the date and time parts because some times don't exist on
some days.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 25, 2017 at 2:04 PM, Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R Users
>
>
>
> Having problems converting the following DTG into an R recognized date/time
> field
>
>
>
> 01-01-2016T14:02:23.325
>
>
>
> Would I separate it into a date field and time filed then put it back
> together???
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From edd at debian.org  Tue Apr 25 23:41:09 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 25 Apr 2017 16:41:09 -0500
Subject: [R] R Date Time
In-Reply-To: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
References: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
Message-ID: <22783.49781.313917.270753@max.eddelbuettel.com>


On 25 April 2017 at 16:04, Jeff Reichman wrote:
| R Users
| 
| Having problems converting the following DTG into an R recognized date/time
| field
| 
| 01-01-2016T14:02:23.325
| 
| Would I separate it into a date field and time filed then put it back
| together???

The anytime package (on CRAN) does this (and other date or datetime input
variants) without requiring a format:

  R> library(anytime)
  R> anytime("01-01-2016T14:02:23.325")
  [1] "2016-01-01 14:02:23.325 CST"
  R>

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Wed Apr 26 00:05:17 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Apr 2017 18:05:17 -0400
Subject: [R] R Date Time
In-Reply-To: <22783.49781.313917.270753@max.eddelbuettel.com>
References: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
 <22783.49781.313917.270753@max.eddelbuettel.com>
Message-ID: <b2292381-e900-e905-ac54-d7c5400e4246@gmail.com>

On 25/04/2017 5:41 PM, Dirk Eddelbuettel wrote:
>
> On 25 April 2017 at 16:04, Jeff Reichman wrote:
> | R Users
> |
> | Having problems converting the following DTG into an R recognized date/time
> | field
> |
> | 01-01-2016T14:02:23.325
> |
> | Would I separate it into a date field and time filed then put it back
> | together???
>
> The anytime package (on CRAN) does this (and other date or datetime input
> variants) without requiring a format:
>
>   R> library(anytime)
>   R> anytime("01-01-2016T14:02:23.325")
>   [1] "2016-01-01 14:02:23.325 CST"

How does it decide between MDY and DMY orderings in dates?  Doesn't 
matter for this example, but it would for "01-02-2016T14:02:23.325"

Duncan Murdoch


From edd at debian.org  Wed Apr 26 00:14:04 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 25 Apr 2017 17:14:04 -0500
Subject: [R] R Date Time
In-Reply-To: <b2292381-e900-e905-ac54-d7c5400e4246@gmail.com>
References: <000001d2be07$9521bb30$bf653190$@sbcglobal.net>
 <22783.49781.313917.270753@max.eddelbuettel.com>
 <b2292381-e900-e905-ac54-d7c5400e4246@gmail.com>
Message-ID: <22783.51756.501170.330768@max.eddelbuettel.com>


On 25 April 2017 at 18:05, Duncan Murdoch wrote:
| On 25/04/2017 5:41 PM, Dirk Eddelbuettel wrote:
| >
| > On 25 April 2017 at 16:04, Jeff Reichman wrote:
| > | R Users
| > |
| > | Having problems converting the following DTG into an R recognized date/time
| > | field
| > |
| > | 01-01-2016T14:02:23.325
| > |
| > | Would I separate it into a date field and time filed then put it back
| > | together???
| >
| > The anytime package (on CRAN) does this (and other date or datetime input
| > variants) without requiring a format:
| >
| >   R> library(anytime)
| >   R> anytime("01-01-2016T14:02:23.325")
| >   [1] "2016-01-01 14:02:23.325 CST"
| 
| How does it decide between MDY and DMY orderings in dates?  Doesn't 
| matter for this example, but it would for "01-02-2016T14:02:23.325"

See 

    http://dirk.eddelbuettel.com/code/anytime.html

    https://github.com/eddelbuettel/anytime

    https://github.com/eddelbuettel/anytime/blob/master/src/anytime.cpp#L43-L106

for overview(s), some comments, notes and in particular the set of formats.

It has a strong preference for sane (ie ISO formats) but in the case of
ambiguity it (grudingly) prefers the (silly) US way:

    R> anytime("01-02-2003")
    [1] "2003-01-02 CST"
    R>

But I try not to miss an opportunity that the format should really not be used.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dan.abner99 at gmail.com  Wed Apr 26 02:14:43 2017
From: dan.abner99 at gmail.com (Dan Abner)
Date: Tue, 25 Apr 2017 20:14:43 -0400
Subject: [R] Counting enumerated items in each element of a character vector
Message-ID: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>

Hi all,

I am looking for a streamlined way of counting the number of enumerated
items are each element of a character vector. For example:


text1<-c("This is an example.
List 1
1) Example 1
2) Example 2
10) Example 10
List 2
1) Example 1
2) Example 2
These have been examples.","This is another example.
List 1
1. Example 1
2. Example 2
10. Example 10
List 2
1. Example 1
2. Example 2
These have been examples.","This is a third example. List 1 1) Example 1.
2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
been examples."
,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
10. List 2 Example 1. 2. Example 2. These have been examples.")

text1

===

I would like the result to be c(5,5,5,5). Notice that sometimes there are
leading hard returns, other times not. Sometimes are there separate lists
and the same numbers are used in the enumerated items multiple times within
each character string. Sometimes the leading numbers for the enumerated
items exceed single digits. Notice that the delimiter may be ) or a period
(.). If the delimiter is a period and there are hard returns (example 2),
then I expect that will be easy enough to differentiate sentences ending
with a number from enumerated items. However, I imagine it would be much
more difficult to differentiate the two for example 4.

Any suggestions are appreciated.

Best,

Dan

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Apr 26 02:23:48 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 25 Apr 2017 20:23:48 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
Message-ID: <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>

How about:

unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1 } ))


Splitting your string on the five "Examples" in each gives six elements. length(x) - 1 is the number of
matches. You can use any regex instead of "example" if you need to tweak what you are looking for.


B.




> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
> 
> Hi all,
> 
> I am looking for a streamlined way of counting the number of enumerated
> items are each element of a character vector. For example:
> 
> 
> text1<-c("This is an example.
> List 1
> 1) Example 1
> 2) Example 2
> 10) Example 10
> List 2
> 1) Example 1
> 2) Example 2
> These have been examples.","This is another example.
> List 1
> 1. Example 1
> 2. Example 2
> 10. Example 10
> List 2
> 1. Example 1
> 2. Example 2
> These have been examples.","This is a third example. List 1 1) Example 1.
> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
> been examples."
> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
> 10. List 2 Example 1. 2. Example 2. These have been examples.")
> 
> text1
> 
> ===
> 
> I would like the result to be c(5,5,5,5). Notice that sometimes there are
> leading hard returns, other times not. Sometimes are there separate lists
> and the same numbers are used in the enumerated items multiple times within
> each character string. Sometimes the leading numbers for the enumerated
> items exceed single digits. Notice that the delimiter may be ) or a period
> (.). If the delimiter is a period and there are hard returns (example 2),
> then I expect that will be easy enough to differentiate sentences ending
> with a number from enumerated items. However, I imagine it would be much
> more difficult to differentiate the two for example 4.
> 
> Any suggestions are appreciated.
> 
> Best,
> 
> Dan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Apr 26 02:33:39 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 25 Apr 2017 20:33:39 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
Message-ID: <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>

I should add: there's a str_count() function in the stringr package.

library(stringr)
str_count(text1, "Example")
# [1] 5 5 5 5

I guess that would be the neater solution.

B.



> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> How about:
> 
> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1 } ))
> 
> 
> Splitting your string on the five "Examples" in each gives six elements. length(x) - 1 is the number of
> matches. You can use any regex instead of "example" if you need to tweak what you are looking for.
> 
> 
> B.
> 
> 
> 
> 
>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> 
>> Hi all,
>> 
>> I am looking for a streamlined way of counting the number of enumerated
>> items are each element of a character vector. For example:
>> 
>> 
>> text1<-c("This is an example.
>> List 1
>> 1) Example 1
>> 2) Example 2
>> 10) Example 10
>> List 2
>> 1) Example 1
>> 2) Example 2
>> These have been examples.","This is another example.
>> List 1
>> 1. Example 1
>> 2. Example 2
>> 10. Example 10
>> List 2
>> 1. Example 1
>> 2. Example 2
>> These have been examples.","This is a third example. List 1 1) Example 1.
>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
>> been examples."
>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
>> 
>> text1
>> 
>> ===
>> 
>> I would like the result to be c(5,5,5,5). Notice that sometimes there are
>> leading hard returns, other times not. Sometimes are there separate lists
>> and the same numbers are used in the enumerated items multiple times within
>> each character string. Sometimes the leading numbers for the enumerated
>> items exceed single digits. Notice that the delimiter may be ) or a period
>> (.). If the delimiter is a period and there are hard returns (example 2),
>> then I expect that will be easy enough to differentiate sentences ending
>> with a number from enumerated items. However, I imagine it would be much
>> more difficult to differentiate the two for example 4.
>> 
>> Any suggestions are appreciated.
>> 
>> Best,
>> 
>> Dan
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Wed Apr 26 05:40:34 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Tue, 25 Apr 2017 20:40:34 -0700
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
Message-ID: <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>

I like Boris's "Hadley" solution.  For the record, I've appended a
version that uses regular expressions, the only benefit of which is
that it could be generalized to find more-complicated patterns.

-- Mike

counts <- sapply(text1, function(next_string) {
    loc_example <- length(gregexpr("Example", next_string)[[1]])
    loc_example
}, USE.NAMES=FALSE)

> counts
[1] 5 5 5 5
>

On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> I should add: there's a str_count() function in the stringr package.
>
> library(stringr)
> str_count(text1, "Example")
> # [1] 5 5 5 5
>
> I guess that would be the neater solution.
>
> B.
>
>
>
>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>> How about:
>>
>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1 } ))
>>
>>
>> Splitting your string on the five "Examples" in each gives six elements. length(x) - 1 is the number of
>> matches. You can use any regex instead of "example" if you need to tweak what you are looking for.
>>
>>
>> B.
>>
>>
>>
>>
>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>>>
>>> Hi all,
>>>
>>> I am looking for a streamlined way of counting the number of enumerated
>>> items are each element of a character vector. For example:
>>>
>>>
>>> text1<-c("This is an example.
>>> List 1
>>> 1) Example 1
>>> 2) Example 2
>>> 10) Example 10
>>> List 2
>>> 1) Example 1
>>> 2) Example 2
>>> These have been examples.","This is another example.
>>> List 1
>>> 1. Example 1
>>> 2. Example 2
>>> 10. Example 10
>>> List 2
>>> 1. Example 1
>>> 2. Example 2
>>> These have been examples.","This is a third example. List 1 1) Example 1.
>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
>>> been examples."
>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
>>>
>>> text1
>>>
>>> ===
>>>
>>> I would like the result to be c(5,5,5,5). Notice that sometimes there are
>>> leading hard returns, other times not. Sometimes are there separate lists
>>> and the same numbers are used in the enumerated items multiple times within
>>> each character string. Sometimes the leading numbers for the enumerated
>>> items exceed single digits. Notice that the delimiter may be ) or a period
>>> (.). If the delimiter is a period and there are hard returns (example 2),
>>> then I expect that will be easy enough to differentiate sentences ending
>>> with a number from enumerated items. However, I imagine it would be much
>>> more difficult to differentiate the two for example 4.
>>>
>>> Any suggestions are appreciated.
>>>
>>> Best,
>>>
>>> Dan
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Apr 26 05:47:19 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 25 Apr 2017 23:47:19 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
 <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
Message-ID: <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>

stringr::str_count (and stringi::stri_count that it wraps) interpret
the pattern argument as a regular expression by default.

Best,
Ista

On Tue, Apr 25, 2017 at 11:40 PM, Michael Hannon
<jmhannon.ucdavis at gmail.com> wrote:
> I like Boris's "Hadley" solution.  For the record, I've appended a
> version that uses regular expressions, the only benefit of which is
> that it could be generalized to find more-complicated patterns.
>
> -- Mike
>
> counts <- sapply(text1, function(next_string) {
>     loc_example <- length(gregexpr("Example", next_string)[[1]])
>     loc_example
> }, USE.NAMES=FALSE)
>
>> counts
> [1] 5 5 5 5
>>
>
> On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> I should add: there's a str_count() function in the stringr package.
>>
>> library(stringr)
>> str_count(text1, "Example")
>> # [1] 5 5 5 5
>>
>> I guess that would be the neater solution.
>>
>> B.
>>
>>
>>
>>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>
>>> How about:
>>>
>>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1 } ))
>>>
>>>
>>> Splitting your string on the five "Examples" in each gives six elements. length(x) - 1 is the number of
>>> matches. You can use any regex instead of "example" if you need to tweak what you are looking for.
>>>
>>>
>>> B.
>>>
>>>
>>>
>>>
>>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>>>>
>>>> Hi all,
>>>>
>>>> I am looking for a streamlined way of counting the number of enumerated
>>>> items are each element of a character vector. For example:
>>>>
>>>>
>>>> text1<-c("This is an example.
>>>> List 1
>>>> 1) Example 1
>>>> 2) Example 2
>>>> 10) Example 10
>>>> List 2
>>>> 1) Example 1
>>>> 2) Example 2
>>>> These have been examples.","This is another example.
>>>> List 1
>>>> 1. Example 1
>>>> 2. Example 2
>>>> 10. Example 10
>>>> List 2
>>>> 1. Example 1
>>>> 2. Example 2
>>>> These have been examples.","This is a third example. List 1 1) Example 1.
>>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
>>>> been examples."
>>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
>>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
>>>>
>>>> text1
>>>>
>>>> ===
>>>>
>>>> I would like the result to be c(5,5,5,5). Notice that sometimes there are
>>>> leading hard returns, other times not. Sometimes are there separate lists
>>>> and the same numbers are used in the enumerated items multiple times within
>>>> each character string. Sometimes the leading numbers for the enumerated
>>>> items exceed single digits. Notice that the delimiter may be ) or a period
>>>> (.). If the delimiter is a period and there are hard returns (example 2),
>>>> then I expect that will be easy enough to differentiate sentences ending
>>>> with a number from enumerated items. However, I imagine it would be much
>>>> more difficult to differentiate the two for example 4.
>>>>
>>>> Any suggestions are appreciated.
>>>>
>>>> Best,
>>>>
>>>> Dan
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Wed Apr 26 06:52:41 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Tue, 25 Apr 2017 21:52:41 -0700
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
 <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
 <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>
Message-ID: <CACdH2ZbO9u=t_hK6P-f33Qk+T8HXf4N1ZDh_iVqN2DNqoVjxyg@mail.gmail.com>

Thanks, Ista.  I thought there might be a "tidy" way to do this, but I
hadn't use stringr.

-- Mike


On Tue, Apr 25, 2017 at 8:47 PM, Ista Zahn <istazahn at gmail.com> wrote:
> stringr::str_count (and stringi::stri_count that it wraps) interpret
> the pattern argument as a regular expression by default.
>
> Best,
> Ista
>
> On Tue, Apr 25, 2017 at 11:40 PM, Michael Hannon
> <jmhannon.ucdavis at gmail.com> wrote:
>> I like Boris's "Hadley" solution.  For the record, I've appended a
>> version that uses regular expressions, the only benefit of which is
>> that it could be generalized to find more-complicated patterns.
>>
>> -- Mike
>>
>> counts <- sapply(text1, function(next_string) {
>>     loc_example <- length(gregexpr("Example", next_string)[[1]])
>>     loc_example
>> }, USE.NAMES=FALSE)
>>
>>> counts
>> [1] 5 5 5 5
>>>
>>
>> On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> I should add: there's a str_count() function in the stringr package.
>>>
>>> library(stringr)
>>> str_count(text1, "Example")
>>> # [1] 5 5 5 5
>>>
>>> I guess that would be the neater solution.
>>>
>>> B.
>>>
>>>
>>>
>>>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>>
>>>> How about:
>>>>
>>>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1 } ))
>>>>
>>>>
>>>> Splitting your string on the five "Examples" in each gives six elements. length(x) - 1 is the number of
>>>> matches. You can use any regex instead of "example" if you need to tweak what you are looking for.
>>>>
>>>>
>>>> B.
>>>>
>>>>
>>>>
>>>>
>>>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I am looking for a streamlined way of counting the number of enumerated
>>>>> items are each element of a character vector. For example:
>>>>>
>>>>>
>>>>> text1<-c("This is an example.
>>>>> List 1
>>>>> 1) Example 1
>>>>> 2) Example 2
>>>>> 10) Example 10
>>>>> List 2
>>>>> 1) Example 1
>>>>> 2) Example 2
>>>>> These have been examples.","This is another example.
>>>>> List 1
>>>>> 1. Example 1
>>>>> 2. Example 2
>>>>> 10. Example 10
>>>>> List 2
>>>>> 1. Example 1
>>>>> 2. Example 2
>>>>> These have been examples.","This is a third example. List 1 1) Example 1.
>>>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2. These have
>>>>> been examples."
>>>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10. Example
>>>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
>>>>>
>>>>> text1
>>>>>
>>>>> ===
>>>>>
>>>>> I would like the result to be c(5,5,5,5). Notice that sometimes there are
>>>>> leading hard returns, other times not. Sometimes are there separate lists
>>>>> and the same numbers are used in the enumerated items multiple times within
>>>>> each character string. Sometimes the leading numbers for the enumerated
>>>>> items exceed single digits. Notice that the delimiter may be ) or a period
>>>>> (.). If the delimiter is a period and there are hard returns (example 2),
>>>>> then I expect that will be easy enough to differentiate sentences ending
>>>>> with a number from enumerated items. However, I imagine it would be much
>>>>> more difficult to differentiate the two for example 4.
>>>>>
>>>>> Any suggestions are appreciated.
>>>>>
>>>>> Best,
>>>>>
>>>>> Dan
>>>>>
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Wed Apr 26 11:57:08 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 26 Apr 2017 11:57:08 +0200
Subject: [R] Antwort: Re: Multiple-Response Analysis: Cleaning of Duplicate
	Codes (SOLVED)
In-Reply-To: <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
References: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>
 <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
Message-ID: <OF6A58E804.D589867B-ONC125810E.00306892-C125810E.0036ABBA@lotus.hawesko.de>

Hi Bert,

many thanks for your reply. I appreciate your help a lot.

I would like to do the operation (= finding the duplicates) row-wise.

During this night a solution showed up in my dreams :) Instead of using 
duplicates() to flag and filter the values I could use unique instead with 
the same result. I tested:

# -- cut --

apply(X = c05_xx_r01, MARGIN = 1, unique)

# -- cut --

This finds the unique values for each row. That is nice but lacks the 
requirement that I need a dataframe with a set of variables back that is 
as long as the total amount of unique values for the complete 
data.frame/matrix or the amount of variable of the original data.frame 
respectively.

The result of the above operation gives a list instead of a data.frame due 
to the fact that the amount of resulting values vary from 1 to 7. 
Therefore no data.frame but a list is returned.

I search the web for a solution and found:

http://stackoverflow.com/questions/15753091/convert-mixed-length-named-list-to-data-frame

The complete solution would then look like:

# -- cut --

library(stringi)
library(tidyverse)
my_list <- apply(c05_xx_r01, MARGIN = 1, unique)
my_tibble <- as_tibble(stringi::stri_list2matrix(my_list, byrow = TRUE)
# DONE !

# -- cut --

All-in-all thanks again for your help.

Kind regards

Georg

P.S: I had a look into ?unique. The statement "unique(c05_xx_r01, MARGIN = 
1) does not do the job, cause this looks for unique combinations of values 
on all columns. But that is not the desired outcome.




Von:    Bert Gunter <bgunter.4567 at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  R-help <r-help at r-project.org>
Datum:  25.04.2017 19:10
Betreff:        Re: [R] Multiple-Response Analysis: Cleaning of Duplicate 
Codes



If I understand you correctly, one way is:

> z <- rep(LETTERS[1:3],4)
> z
 [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
> z[!duplicated(z)]
[1] "A" "B" "C"


?duplicated

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 25, 2017 at 9:36 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I am working with multiple-response questions
> (MRSets):
>
> -- Coding --
> 100 Main Code 1
> 110 Sub Code 1.1
> 120 Sub Code 1.2
> 130 Sub Code 1.3
>
> 200 Main Code 2
> 210 Sub Code 2.1
> 220 Sub Code 2.2
> 230 Sub Code 2.3
>
> 300 Main Code 3
> 310 Sub Code 3.1
> 320 Sub Code 3.2
>
> The coding for the variables is to detailed. Therefore I have recoded 
all
> sub codes to the respective main code, e.g. all 110, 120 and 130 to 100,
> all 210, 220 and 230 to 200 and all 310, 320 and 330 to 300.
>
> Now it happens that some respondents get several times the same main 
code.
> If the coding was done for respondent 1 with 120 and 130 after recoding
> the values are 100 and 100. If I count this, it would mean that I weight
> the multiple values of this respondent by factor 2. This is not my aim. 
I
> would like to count the 100 for the respective respondent only once.
>
> Here is my script so far:
>
> # -- cut --
>
> library(expss)
>
> d_sample <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       )
>     ),
>     .Names = c("c05_01",
>                "c05_02", "c05_03", "c05_04", "c05_05"),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> c05_xx_r01 <- d_sample %>%
>   select(starts_with("c05_")) %>%
>   recode(c(
>     110 %thru% 195 ~ 100,
>     210 %thru% 295 ~ 200,
>     310 %thru% 395 ~ 300,
>     410 %thru% 495 ~ 400,
>     510 %thru% 595 ~ 500,
>     810 %thru% 895 ~ 800,
>     910 %thru% 999 ~ 900))
> names(c05_xx_r01) <- paste0("c05_0", 1:5, "_r01")
> d_sample <- cbind(d_sample, c05_xx_r01)
>
> # -- cut --
>
> I would like to eliminate all duplicates codes, e. g. 100 and 100 for
> respondents in row 3, 6, 13, 14 and 15 to 100 only once:
>
> # -- cut --
> d_sample_1 <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_01_r01 = c(
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         900,
>         100,
>         400,
>         100,
>         100,
>         400
>       ),
>       c05_02_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, 100),
>       c05_03_r01 = c(NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, 400, NA, NA, NA, NA, 
NA,
> NA, NA),
>       c05_04_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA),
>       c05_05_r01 = c(NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
>     ),
>     .Names = c(
>       "c05_01",
>       "c05_02",
>       "c05_03",
>       "c05_04",
>       "c05_05",
>       "c05_01_r01",
>       "c05_02_r01",
>       "c05_03_r01",
>       "c05_04_r01",
>       "c05_05_r01"
>     ),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> # -- cut --
>
> How could I achieve this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Apr 26 11:57:50 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 26 Apr 2017 11:57:50 +0200
Subject: [R] Antwort: Re: Multiple-Response Analysis: Cleaning of Duplicate
	Codes (SOLVED)
In-Reply-To: <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
References: <OF70873803.174FA154-ONC125810D.0059A574-C125810D.005B3C4A@lotus.hawesko.de>
 <CAGxFJbT1peajDOD0Gy4f93Uqi3jexoZ+_G3jqoZd_-j0Jo=Naw@mail.gmail.com>
Message-ID: <OF6A58E804.D589867B-ONC125810E.00306892-C125810E.0036BC53@lotus.hawesko.de>

Hi Bert,

many thanks for your reply. I appreciate your help a lot.

I would like to do the operation (= finding the duplicates) row-wise.

During this night a solution showed up in my dreams :) Instead of using 
duplicates() to flag and filter the values I could use unique instead with 
the same result. I tested:

# -- cut --

apply(X = c05_xx_r01, MARGIN = 1, unique)

# -- cut --

This finds the unique values for each row. That is nice but lacks the 
requirement that I need a dataframe with a set of variables back that is 
as long as the total amount of unique values for the complete 
data.frame/matrix or the amount of variable of the original data.frame 
respectively.

The result of the above operation gives a list instead of a data.frame due 
to the fact that the amount of resulting values vary from 1 to 7. 
Therefore no data.frame but a list is returned.

I search the web for a solution and found:

http://stackoverflow.com/questions/15753091/convert-mixed-length-named-list-to-data-frame

The complete solution would then look like:

# -- cut --

library(stringi)
library(tidyverse)
my_list <- apply(c05_xx_r01, MARGIN = 1, unique)
my_tibble <- as_tibble(stringi::stri_list2matrix(my_list, byrow = TRUE)
# DONE !

# -- cut --

All-in-all thanks again for your help.

Kind regards

Georg

P.S: I had a look into ?unique. The statement "unique(c05_xx_r01, MARGIN = 
1) does not do the job, cause this looks for unique combinations of values 
on all columns. But that is not the desired outcome.




Von:    Bert Gunter <bgunter.4567 at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  R-help <r-help at r-project.org>
Datum:  25.04.2017 19:10
Betreff:        Re: [R] Multiple-Response Analysis: Cleaning of Duplicate 
Codes



If I understand you correctly, one way is:

> z <- rep(LETTERS[1:3],4)
> z
 [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
> z[!duplicated(z)]
[1] "A" "B" "C"


?duplicated

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 25, 2017 at 9:36 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I am working with multiple-response questions
> (MRSets):
>
> -- Coding --
> 100 Main Code 1
> 110 Sub Code 1.1
> 120 Sub Code 1.2
> 130 Sub Code 1.3
>
> 200 Main Code 2
> 210 Sub Code 2.1
> 220 Sub Code 2.2
> 230 Sub Code 2.3
>
> 300 Main Code 3
> 310 Sub Code 3.1
> 320 Sub Code 3.2
>
> The coding for the variables is to detailed. Therefore I have recoded 
all
> sub codes to the respective main code, e.g. all 110, 120 and 130 to 100,
> all 210, 220 and 230 to 200 and all 310, 320 and 330 to 300.
>
> Now it happens that some respondents get several times the same main 
code.
> If the coding was done for respondent 1 with 120 and 130 after recoding
> the values are 100 and 100. If I count this, it would mean that I weight
> the multiple values of this respondent by factor 2. This is not my aim. 
I
> would like to count the 100 for the respective respondent only once.
>
> Here is my script so far:
>
> # -- cut --
>
> library(expss)
>
> d_sample <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       )
>     ),
>     .Names = c("c05_01",
>                "c05_02", "c05_03", "c05_04", "c05_05"),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> c05_xx_r01 <- d_sample %>%
>   select(starts_with("c05_")) %>%
>   recode(c(
>     110 %thru% 195 ~ 100,
>     210 %thru% 295 ~ 200,
>     310 %thru% 395 ~ 300,
>     410 %thru% 495 ~ 400,
>     510 %thru% 595 ~ 500,
>     810 %thru% 895 ~ 800,
>     910 %thru% 999 ~ 900))
> names(c05_xx_r01) <- paste0("c05_0", 1:5, "_r01")
> d_sample <- cbind(d_sample, c05_xx_r01)
>
> # -- cut --
>
> I would like to eliminate all duplicates codes, e. g. 100 and 100 for
> respondents in row 3, 6, 13, 14 and 15 to 100 only once:
>
> # -- cut --
> d_sample_1 <-
>   structure(
>     list(
>       c05_01 = c(
>         110,
>         110,
>         130,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         110,
>         999,
>         110,
>         495,
>         160,
>         110,
>         410
>       ),
>       c05_02 = c(NA,
>                  NA, 120, NA, NA, 150, NA, NA, 170, 160, NA, NA, NA, NA,
> 170,
>                  NA, 130),
>       c05_03 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 410,
>                  NA, NA, NA, NA, NA, NA, NA),
>       c05_04 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_05 = c(
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_,
>         NA_real_
>       ),
>       c05_01_r01 = c(
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         100,
>         900,
>         100,
>         400,
>         100,
>         100,
>         400
>       ),
>       c05_02_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, 100),
>       c05_03_r01 = c(NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, 400, NA, NA, NA, NA, 
NA,
> NA, NA),
>       c05_04_r01 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA),
>       c05_05_r01 = c(NA, NA, NA, NA, NA,
>                      NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
>     ),
>     .Names = c(
>       "c05_01",
>       "c05_02",
>       "c05_03",
>       "c05_04",
>       "c05_05",
>       "c05_01_r01",
>       "c05_02_r01",
>       "c05_03_r01",
>       "c05_04_r01",
>       "c05_05_r01"
>     ),
>     row.names = c(
>       "1",
>       "2",
>       "3",
>       "4",
>       "5",
>       "10",
>       "11",
>       "12",
>       "13",
>       "14",
>       "15",
>       "20",
>       "21",
>       "22",
>       "23",
>       "24",
>       "25"
>     ),
>     class = "data.frame"
>   )
>
> # -- cut --
>
> How could I achieve this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dan.abner99 at gmail.com  Wed Apr 26 14:33:05 2017
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 26 Apr 2017 08:33:05 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CACdH2ZbO9u=t_hK6P-f33Qk+T8HXf4N1ZDh_iVqN2DNqoVjxyg@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
 <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
 <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>
 <CACdH2ZbO9u=t_hK6P-f33Qk+T8HXf4N1ZDh_iVqN2DNqoVjxyg@mail.gmail.com>
Message-ID: <CAPRGo-nkxBQF0xZx9vs0PTKHw_JxEg21YpueP0vC=mcEi23LiA@mail.gmail.com>

Hi all,

I was not clearly enough in my example code. Please see below where "blah
blah blah" can be ANY text or numbers: No predictable pattern at all to
what may or may not be written in place of "blah blah blah".

text1<-c("blah blah blah.
blah blah blah
1) blah blah blah 1
2) blah blah blah
10) blah 10 blah blah
blah blah blah
1) blah blah blah
2) blah blah blah 2
blah blah blah.","blah blah blah.
blah blah blah
1. blah blah blah 1
2. blah blah blah
10.blah 10 blah blah
blah blah blah
1. blah blah blah 1
2. blah blah blah
blah blah blah.","blah blah blah. blah blah blah 1 1)blah blah blah 1. 2) blah
blah blah 10) blah 10 blah blah blah blah blah 1) blah blah blah 1. 2) blah
blah blah. blah blah blah."
,"blah blah blah. blah blah blah 1 1.blah blah blah 1. 2. blah blah blah.
 10. blah 10 blah blah. blah blah blah 1. blah blah blah 1. 2. blah blah
blah. blah blah blah.")

text1

Thank you in advance for your suggestions and/or guidance.

Best,

Dan


On Wed, Apr 26, 2017 at 12:52 AM, Michael Hannon <jmhannon.ucdavis at gmail.com
> wrote:

> Thanks, Ista.  I thought there might be a "tidy" way to do this, but I
> hadn't use stringr.
>
> -- Mike
>
>
> On Tue, Apr 25, 2017 at 8:47 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > stringr::str_count (and stringi::stri_count that it wraps) interpret
> > the pattern argument as a regular expression by default.
> >
> > Best,
> > Ista
> >
> > On Tue, Apr 25, 2017 at 11:40 PM, Michael Hannon
> > <jmhannon.ucdavis at gmail.com> wrote:
> >> I like Boris's "Hadley" solution.  For the record, I've appended a
> >> version that uses regular expressions, the only benefit of which is
> >> that it could be generalized to find more-complicated patterns.
> >>
> >> -- Mike
> >>
> >> counts <- sapply(text1, function(next_string) {
> >>     loc_example <- length(gregexpr("Example", next_string)[[1]])
> >>     loc_example
> >> }, USE.NAMES=FALSE)
> >>
> >>> counts
> >> [1] 5 5 5 5
> >>>
> >>
> >> On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >>> I should add: there's a str_count() function in the stringr package.
> >>>
> >>> library(stringr)
> >>> str_count(text1, "Example")
> >>> # [1] 5 5 5 5
> >>>
> >>> I guess that would be the neater solution.
> >>>
> >>> B.
> >>>
> >>>
> >>>
> >>>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >>>>
> >>>> How about:
> >>>>
> >>>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1
> } ))
> >>>>
> >>>>
> >>>> Splitting your string on the five "Examples" in each gives six
> elements. length(x) - 1 is the number of
> >>>> matches. You can use any regex instead of "example" if you need to
> tweak what you are looking for.
> >>>>
> >>>>
> >>>> B.
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com>
> wrote:
> >>>>>
> >>>>> Hi all,
> >>>>>
> >>>>> I am looking for a streamlined way of counting the number of
> enumerated
> >>>>> items are each element of a character vector. For example:
> >>>>>
> >>>>>
> >>>>> text1<-c("This is an example.
> >>>>> List 1
> >>>>> 1) Example 1
> >>>>> 2) Example 2
> >>>>> 10) Example 10
> >>>>> List 2
> >>>>> 1) Example 1
> >>>>> 2) Example 2
> >>>>> These have been examples.","This is another example.
> >>>>> List 1
> >>>>> 1. Example 1
> >>>>> 2. Example 2
> >>>>> 10. Example 10
> >>>>> List 2
> >>>>> 1. Example 1
> >>>>> 2. Example 2
> >>>>> These have been examples.","This is a third example. List 1 1)
> Example 1.
> >>>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2.
> These have
> >>>>> been examples."
> >>>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10.
> Example
> >>>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
> >>>>>
> >>>>> text1
> >>>>>
> >>>>> ===
> >>>>>
> >>>>> I would like the result to be c(5,5,5,5). Notice that sometimes
> there are
> >>>>> leading hard returns, other times not. Sometimes are there separate
> lists
> >>>>> and the same numbers are used in the enumerated items multiple times
> within
> >>>>> each character string. Sometimes the leading numbers for the
> enumerated
> >>>>> items exceed single digits. Notice that the delimiter may be ) or a
> period
> >>>>> (.). If the delimiter is a period and there are hard returns
> (example 2),
> >>>>> then I expect that will be easy enough to differentiate sentences
> ending
> >>>>> with a number from enumerated items. However, I imagine it would be
> much
> >>>>> more difficult to differentiate the two for example 4.
> >>>>>
> >>>>> Any suggestions are appreciated.
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Dan
> >>>>>
> >>>>>      [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Apr 26 14:35:23 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 26 Apr 2017 08:35:23 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CAPRGo-nkxBQF0xZx9vs0PTKHw_JxEg21YpueP0vC=mcEi23LiA@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
 <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
 <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>
 <CACdH2ZbO9u=t_hK6P-f33Qk+T8HXf4N1ZDh_iVqN2DNqoVjxyg@mail.gmail.com>
 <CAPRGo-nkxBQF0xZx9vs0PTKHw_JxEg21YpueP0vC=mcEi23LiA@mail.gmail.com>
Message-ID: <ABDB7DCF-07E1-4BEB-AC67-0B54F81BC1C7@utoronto.ca>

What's the expected output for this sample?

How do _you_ define what should be counted?





> On Apr 26, 2017, at 8:33 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> 
> Hi all,
> 
> I was not clearly enough in my example code. Please see below where "blah
> blah blah" can be ANY text or numbers: No predictable pattern at all to
> what may or may not be written in place of "blah blah blah".
> 
> text1<-c("blah blah blah.
> blah blah blah
> 1) blah blah blah 1
> 2) blah blah blah
> 10) blah 10 blah blah
> blah blah blah
> 1) blah blah blah
> 2) blah blah blah 2
> blah blah blah.","blah blah blah.
> blah blah blah
> 1. blah blah blah 1
> 2. blah blah blah
> 10.blah 10 blah blah
> blah blah blah
> 1. blah blah blah 1
> 2. blah blah blah
> blah blah blah.","blah blah blah. blah blah blah 1 1)blah blah blah 1. 2) blah
> blah blah 10) blah 10 blah blah blah blah blah 1) blah blah blah 1. 2) blah
> blah blah. blah blah blah."
> ,"blah blah blah. blah blah blah 1 1.blah blah blah 1. 2. blah blah blah.
> 10. blah 10 blah blah. blah blah blah 1. blah blah blah 1. 2. blah blah
> blah. blah blah blah.")
> 
> text1
> 
> Thank you in advance for your suggestions and/or guidance.
> 
> Best,
> 
> Dan
> 
> 
> On Wed, Apr 26, 2017 at 12:52 AM, Michael Hannon <jmhannon.ucdavis at gmail.com
>> wrote:
> 
>> Thanks, Ista.  I thought there might be a "tidy" way to do this, but I
>> hadn't use stringr.
>> 
>> -- Mike
>> 
>> 
>> On Tue, Apr 25, 2017 at 8:47 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>> stringr::str_count (and stringi::stri_count that it wraps) interpret
>>> the pattern argument as a regular expression by default.
>>> 
>>> Best,
>>> Ista
>>> 
>>> On Tue, Apr 25, 2017 at 11:40 PM, Michael Hannon
>>> <jmhannon.ucdavis at gmail.com> wrote:
>>>> I like Boris's "Hadley" solution.  For the record, I've appended a
>>>> version that uses regular expressions, the only benefit of which is
>>>> that it could be generalized to find more-complicated patterns.
>>>> 
>>>> -- Mike
>>>> 
>>>> counts <- sapply(text1, function(next_string) {
>>>>    loc_example <- length(gregexpr("Example", next_string)[[1]])
>>>>    loc_example
>>>> }, USE.NAMES=FALSE)
>>>> 
>>>>> counts
>>>> [1] 5 5 5 5
>>>>> 
>>>> 
>>>> On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>>>> I should add: there's a str_count() function in the stringr package.
>>>>> 
>>>>> library(stringr)
>>>>> str_count(text1, "Example")
>>>>> # [1] 5 5 5 5
>>>>> 
>>>>> I guess that would be the neater solution.
>>>>> 
>>>>> B.
>>>>> 
>>>>> 
>>>>> 
>>>>>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>>>>> 
>>>>>> How about:
>>>>>> 
>>>>>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1
>> } ))
>>>>>> 
>>>>>> 
>>>>>> Splitting your string on the five "Examples" in each gives six
>> elements. length(x) - 1 is the number of
>>>>>> matches. You can use any regex instead of "example" if you need to
>> tweak what you are looking for.
>>>>>> 
>>>>>> 
>>>>>> B.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com>
>> wrote:
>>>>>>> 
>>>>>>> Hi all,
>>>>>>> 
>>>>>>> I am looking for a streamlined way of counting the number of
>> enumerated
>>>>>>> items are each element of a character vector. For example:
>>>>>>> 
>>>>>>> 
>>>>>>> text1<-c("This is an example.
>>>>>>> List 1
>>>>>>> 1) Example 1
>>>>>>> 2) Example 2
>>>>>>> 10) Example 10
>>>>>>> List 2
>>>>>>> 1) Example 1
>>>>>>> 2) Example 2
>>>>>>> These have been examples.","This is another example.
>>>>>>> List 1
>>>>>>> 1. Example 1
>>>>>>> 2. Example 2
>>>>>>> 10. Example 10
>>>>>>> List 2
>>>>>>> 1. Example 1
>>>>>>> 2. Example 2
>>>>>>> These have been examples.","This is a third example. List 1 1)
>> Example 1.
>>>>>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2.
>> These have
>>>>>>> been examples."
>>>>>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10.
>> Example
>>>>>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
>>>>>>> 
>>>>>>> text1
>>>>>>> 
>>>>>>> ===
>>>>>>> 
>>>>>>> I would like the result to be c(5,5,5,5). Notice that sometimes
>> there are
>>>>>>> leading hard returns, other times not. Sometimes are there separate
>> lists
>>>>>>> and the same numbers are used in the enumerated items multiple times
>> within
>>>>>>> each character string. Sometimes the leading numbers for the
>> enumerated
>>>>>>> items exceed single digits. Notice that the delimiter may be ) or a
>> period
>>>>>>> (.). If the delimiter is a period and there are hard returns
>> (example 2),
>>>>>>> then I expect that will be easy enough to differentiate sentences
>> ending
>>>>>>> with a number from enumerated items. However, I imagine it would be
>> much
>>>>>>> more difficult to differentiate the two for example 4.
>>>>>>> 
>>>>>>> Any suggestions are appreciated.
>>>>>>> 
>>>>>>> Best,
>>>>>>> 
>>>>>>> Dan
>>>>>>> 
>>>>>>>     [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From swbueno at gmail.com  Wed Apr 26 14:38:16 2017
From: swbueno at gmail.com (Santiago Bueno)
Date: Wed, 26 Apr 2017 08:38:16 -0400
Subject: [R] Hiring experts
Message-ID: <CAGfmZu7ykDGnJLN+2SP+X-FtNpsBh85g62cjJjHkp7WD9DXF5A@mail.gmail.com>

I need to hire an R software expert to help me with nls, nlme and surface
prediction plots. Can I get suggestions?

Best,

Santiago Bueno

	[[alternative HTML version deleted]]


From jake at jakestone.net  Wed Apr 26 15:55:26 2017
From: jake at jakestone.net (Jake Stone)
Date: Wed, 26 Apr 2017 06:55:26 -0700
Subject: [R] Network Alternative to rJava/JRI?
Message-ID: <CAL964Uxa56OutBmYPNp3g2Geo_-e6CFNs0rNihjE9ZiSRV1L6w@mail.gmail.com>

I am a java programmer, quite new to R.

I am familiar with rJava/JRI, but would prefer a distributed networked
architecture for my systems.

TASK:

   - Java runs an NLP analysis of a text. It then sends an array (vector)
   of variables to R
   - R predicts the class of the input vector based on a pre-analyzed
   discriminant analysis of a full dataset in R.
   - R returns the class prediction to java.

IDEAL SOLUTION
R is an online webserver (perhaps shiny?) that "waits" for a request sent
via http. (This is similar to a jave servlet on a webserver)
Java program sends an http request with the array of variables
R responds with a response of the class prediction.

QUESTION
Is there an extant architecture that supports this. I expect shiny can do
this, but I am hesitant to spend two or three days learning shiny unless I
am confident the effort will pay off.

best

jake

	[[alternative HTML version deleted]]


From quickling at gmail.com  Wed Apr 26 01:40:16 2017
From: quickling at gmail.com (Alex Fun)
Date: Wed, 26 Apr 2017 09:40:16 +1000
Subject: [R] Implementations of bootstrap aggregation
Message-ID: <CACUMBrzpB+bgiKhzTectWb7afH_cVwkyH+y0faqs7eBGtNjnvg@mail.gmail.com>

I would like to do bootstrap aggregation of a model (currently fit
with glm()) so that:

1) Data observations are replicated as N bootstrap samples.
2) The specified model is fit to each sample.
3) Error is calculated on out of bag samples.
4) Have an easy way of making model predictions.
5) + all other sensible features that you can inherit from a random
forest implementation.

I can find plenty of packages (ipred, randomForest, etc) that bag
trees but none that will give the bootstrap aggregation features to a
general model. For a glm, the closest is probably the package
randomGLM, however this does not seem to let you fix the covariates in
the glm model. Does anyone know of neat/elegant implementations of the
general bagging procedure, or should I write something myself, like
this (horrible code):
http://stackoverflow.com/questions/21785699/bagging-logistic-regression-in-r

Thanks,

Alex


From r-packages at r-project.org  Wed Apr 26 12:14:17 2017
From: r-packages at r-project.org (Hong Ooi via R-packages)
Date: Wed, 26 Apr 2017 10:14:17 +0000
Subject: [R] [R-pkgs] Package glmnetUtils now on CRAN
Message-ID: <HK2P15301MB0083996D3D6C30B103FCF96DA6110@HK2P15301MB0083.APCP153.PROD.OUTLOOK.COM>

I'm pleased to announce that the glmnetUtils package is now available on CRAN. I wrote this after using the popular glmnet package to fit elastic net models for a few customer projects, and rewriting the same boilerplate code each time.

glmnetUtils provides some quality-of-life improvements for glmnet, specifically:

- a formula/data frame interface to glmnet and cv.glmnet. No more manual fiddling around with model.matrix/as.matrix/data.matrix, worrying about NA values, etc.
- a cva.glmnet function to choose both the alpha and lambda parameters via cross-validation, following the approach described in the help page for cv.glmnet. Optionally does the cross-validation in parallel.
- Methods for predict and coef for the above.

In addition, to facilitate analysis of very wide datasets, glmnetUtils by default takes a slightly different approach to generating model matrices. Rather than calling model.frame() and model.matrix() on the full dataset, it builds up the model.matrix term by term. This is because model.frame() creates a terms object, which can be excessively large for wide data. Building up the model matrix one term at a time avoids this problem.

CRAN link: https://cran.r-project.org/package=glmnetUtils

Github repo: https://github.com/hong-revo/glmnetUtils

Please feel free to contact me with suggestions, bug reports, criticisms, etc.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sanjeevkumargpt321 at gmail.com  Wed Apr 26 08:27:01 2017
From: sanjeevkumargpt321 at gmail.com (Sanjeev Kumar)
Date: Wed, 26 Apr 2017 11:57:01 +0530
Subject: [R] Reg. help for SWAT Calibration
Message-ID: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>

Sir/Mam
      I am a Research Scholar at Central University of Karnataka and I am
working on SWAT (Soil And Water Assessment tool) and I need 'R' for the
Calibration purpose but for 'R' I need a code. So if it is possible to send
that code pls send me.



https://www.youtube.com/watch?v=5NFn9paBR98&t=15s
This is the video link where i came to know about 'R'



Thanks

Yours Sincerely
Sanjeev Kumar
Research Associate
Central University of Karnataka
Karnataka India

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Apr 26 17:27:13 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 26 Apr 2017 11:27:13 -0400
Subject: [R] Network Alternative to rJava/JRI?
In-Reply-To: <CAL964Uxa56OutBmYPNp3g2Geo_-e6CFNs0rNihjE9ZiSRV1L6w@mail.gmail.com>
References: <CAL964Uxa56OutBmYPNp3g2Geo_-e6CFNs0rNihjE9ZiSRV1L6w@mail.gmail.com>
Message-ID: <CA+vqiLFVU3ptoyMOrP8qn-FShROLeJJGbWnUvx3Y6kZ9PGiCug@mail.gmail.com>

Shiny could probably work, but https://www.opencpu.org/ is probably a
better fit.

Best,
Ista

On Wed, Apr 26, 2017 at 9:55 AM, Jake Stone <jake at jakestone.net> wrote:
> I am a java programmer, quite new to R.
>
> I am familiar with rJava/JRI, but would prefer a distributed networked
> architecture for my systems.
>
> TASK:
>
>    - Java runs an NLP analysis of a text. It then sends an array (vector)
>    of variables to R
>    - R predicts the class of the input vector based on a pre-analyzed
>    discriminant analysis of a full dataset in R.
>    - R returns the class prediction to java.
>
> IDEAL SOLUTION
> R is an online webserver (perhaps shiny?) that "waits" for a request sent
> via http. (This is similar to a jave servlet on a webserver)
> Java program sends an http request with the array of variables
> R responds with a response of the class prediction.
>
> QUESTION
> Is there an extant architecture that supports this. I expect shiny can do
> this, but I am hesitant to spend two or three days learning shiny unless I
> am confident the effort will pay off.
>
> best
>
> jake
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Apr 26 18:04:42 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 26 Apr 2017 12:04:42 -0400
Subject: [R] Reg. help for SWAT Calibration
In-Reply-To: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
References: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
Message-ID: <12CFB8DB-CB97-4C18-8A3F-27DED5745279@utoronto.ca>

Your mental model of what R is and does appears to be misaligned with actuality. Quoting from Wikipedia:

   R is an open source programming language and software environment
   for statistical computing and graphics [...]. The R language is
   widely used among statisticians and data miners for developing
   statistical software and data analysis.

With that in mind, a web search for how this relates to solving your actual problems may become productive.

Good luck!
B.




> On Apr 26, 2017, at 2:27 AM, Sanjeev Kumar <sanjeevkumargpt321 at gmail.com> wrote:
> 
> Sir/Mam
>      I am a Research Scholar at Central University of Karnataka and I am
> working on SWAT (Soil And Water Assessment tool) and I need 'R' for the
> Calibration purpose but for 'R' I need a code. So if it is possible to send
> that code pls send me.
> 
> 
> 
> https://www.youtube.com/watch?v=5NFn9paBR98&t=15s
> This is the video link where i came to know about 'R'
> 
> 
> 
> Thanks
> 
> Yours Sincerely
> Sanjeev Kumar
> Research Associate
> Central University of Karnataka
> Karnataka India
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Apr 26 18:14:43 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 26 Apr 2017 09:14:43 -0700
Subject: [R] Reg. help for SWAT Calibration
In-Reply-To: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
References: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
Message-ID: <9EEC9FF3-356C-4E53-BBDA-938970AB19FF@dcn.davis.ca.us>

http://www.r-project.org/posting-guide.html

https://cran.r-project.org
-- 
Sent from my phone. Please excuse my brevity.

On April 25, 2017 11:27:01 PM PDT, Sanjeev Kumar <sanjeevkumargpt321 at gmail.com> wrote:
>Sir/Mam
>    I am a Research Scholar at Central University of Karnataka and I am
>working on SWAT (Soil And Water Assessment tool) and I need 'R' for the
>Calibration purpose but for 'R' I need a code. So if it is possible to
>send
>that code pls send me.
>
>
>
>https://www.youtube.com/watch?v=5NFn9paBR98&t=15s
>This is the video link where i came to know about 'R'
>
>
>
>Thanks
>
>Yours Sincerely
>Sanjeev Kumar
>Research Associate
>Central University of Karnataka
>Karnataka India
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From davidhughjones at gmail.com  Wed Apr 26 15:51:30 2017
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Wed, 26 Apr 2017 14:51:30 +0100
Subject: [R] [R-pkgs] Package huxtable 0.2.1 on CRAN
Message-ID: <CAARY7kgYxJaY-eO_ecdA+86yBMJ4eDhEeq+EkjJU0XV-dPY3AQ@mail.gmail.com>

Hi all,

I'm happy to announce that the huxtable package version 0.2.1 is on CRAN.

huxtable is an R package to create LaTeX and HTML tables, with a friendly,
modern interface. Features of 0.2.1 include:

- Export to LaTeX, HTML, Word and Markdown
- Easy integration with knitr and rmarkdown documents
- Multirow and multicolumn cells
- Fine-grained control over cell background, spacing, alignment, size and
borders
- Control over text font, style, size, colour, alignment, number format and
rotation
- Table manipulation using standard R subsetting, or dplyr functions like
filter and select
- Easy conditional formatting based on table contents
- Quick table themes
- Automatic creation of regression output tables with the huxreg function

The CRAN link is https://cran.r-project.org/package=huxtable , and there's
a website with documentation at http://hughjonesd.github.io/huxtable

Comments, suggestions and bug reports are welcome and can be filed at
http://www.github.com/hughjonesd/huxtable/issues

Cheers,
David

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From boris.steipe at utoronto.ca  Wed Apr 26 18:39:25 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 26 Apr 2017 12:39:25 -0400
Subject: [R] Counting enumerated items in each element of a character
	vector
In-Reply-To: <CAPRGo-nkE5HHGUc78UguGGAaLZeqbxT+bxfj-+ZbTvo40doiJw@mail.gmail.com>
References: <CAPRGo-=_rZTSh0p3u-5iR-mEAdR0cxf58f+V8qhEn-cunExGTg@mail.gmail.com>
 <6593C8C8-1FB7-4833-BD4E-637441E54FB7@utoronto.ca>
 <AC330799-CCF8-4F0A-87E1-773EED27AE7F@utoronto.ca>
 <CACdH2ZatU0PVi06Fh1THQ6N-+b6GibE_pe7mXHoqC_k=OTPsPQ@mail.gmail.com>
 <CA+vqiLH=kFMpHgsf7z5OJeQC2+xCge-79jkcfzPtY+tk6dZumQ@mail.gmail.com>
 <CACdH2ZbO9u=t_hK6P-f33Qk+T8HXf4N1ZDh_iVqN2DNqoVjxyg@mail.gmail.com>
 <CAPRGo-nkxBQF0xZx9vs0PTKHw_JxEg21YpueP0vC=mcEi23LiA@mail.gmail.com>
 <ABDB7DCF-07E1-4BEB-AC67-0B54F81BC1C7@utoronto.ca>
 <CAPRGo-nkE5HHGUc78UguGGAaLZeqbxT+bxfj-+ZbTvo40doiJw@mail.gmail.com>
Message-ID: <DD173F7A-82D2-4C62-9622-024715716410@utoronto.ca>

Let's be a bit careful.

You'll probably need a regular expression. But maybe a regex can't work in principle, so one can't just gloss over the details.

You said: "blah blah blah" can contain ANY text. If this is true, "blah blah blah" could contain the delimiters. If that is the case, a regex is not powerful enough in principle and you need a context-sensitive parser.

So let's have a list of valid demarcations. From what you write I can guess that ...

text2 <- c(
    "blah   1) blah blah blah 1",
    "blah   10. blah blah blah 1",
    "blah 1)  1) blah blah blah 1",
    "blah 1.  10) blah blah blah 1",
    "blah 1)  1. blah blah blah 1",
    "blah 10.  10. blah blah blah 1"
)
    
... captures the variation. But that's just my guess from staring at your examples. I can't be sure - that's your task to contribute.

On text2, the regular expression ...

"(\d+(\)|\.)\s*){1,2}"

... gives the expected result of
# [1] 1 1 1 1 1 1
... and ...
# [1] 5 5 5 5
... on your text1.

In code:

library(stringr)
str_count(text1, "(\\d+(\\)|\\.)\\s*){1,2}")






> On Apr 26, 2017, at 10:13 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> 
> Hi all,
> 
> I am looking for a streamlined way of counting the number of enumerated items are each element of a character vector. For example:
> 
> 
> text1<-c("blah blah blah.
> blah blah blah
> 1) blah blah blah 1
> 2) blah blah blah
> 10) blah 10 blah blah
> blah blah blah
> 1) blah blah blah
> 2) blah blah blah 2
> blah blah blah.","blah blah blah.
> blah blah blah
> 1. blah blah blah 1
> 2. blah blah blah
> 10.blah 10 blah blah
> blah blah blah
> 1. blah blah blah 1
> 2. blah blah blah
> blah blah blah.","blah blah blah. blah blah blah 1 1)blah blah blah 1. 2) blah blah blah 10) blah 10 blah blah blah blah blah 1) blah blah blah 1. 2) blah blah blah. blah blah blah."
> ,"blah blah blah. blah blah blah 1 1.blah blah blah 1. 2. blah blah blah. 10. blah 10 blah blah. blah blah blah 1. blah blah blah 1. 2. blah blah blah. blah blah blah.")
> 
> text1
> 
> ===
> 
> I would like the result to be c(5,5,5,5). Notice that sometimes there are leading hard returns, other times not. Sometimes are there separate lists and the same numbers are used in the enumerated items multiple times within each character string. Sometimes the leading numbers for the enumerated items exceed single digits. Notice that the delimiter may be ) or a period (.). If the delimiter is a period and there are hard returns (example 2), then I expect that will be easy enough to differentiate sentences ending with a number from enumerated items. However, I imagine it would be much more difficult to differentiate the two for example 4.
> 
> Any suggestions are appreciated.
> 
> Best,
> 
> Dan
> 
> On Wed, Apr 26, 2017 at 8:35 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> What's the expected output for this sample?
> 
> How do _you_ define what should be counted?
> 
> 
> 
> 
> 
> > On Apr 26, 2017, at 8:33 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> >
> > Hi all,
> >
> > I was not clearly enough in my example code. Please see below where "blah
> > blah blah" can be ANY text or numbers: No predictable pattern at all to
> > what may or may not be written in place of "blah blah blah".
> >
> > text1<-c("blah blah blah.
> > blah blah blah
> > 1) blah blah blah 1
> > 2) blah blah blah
> > 10) blah 10 blah blah
> > blah blah blah
> > 1) blah blah blah
> > 2) blah blah blah 2
> > blah blah blah.","blah blah blah.
> > blah blah blah
> > 1. blah blah blah 1
> > 2. blah blah blah
> > 10.blah 10 blah blah
> > blah blah blah
> > 1. blah blah blah 1
> > 2. blah blah blah
> > blah blah blah.","blah blah blah. blah blah blah 1 1)blah blah blah 1. 2) blah
> > blah blah 10) blah 10 blah blah blah blah blah 1) blah blah blah 1. 2) blah
> > blah blah. blah blah blah."
> > ,"blah blah blah. blah blah blah 1 1.blah blah blah 1. 2. blah blah blah.
> > 10. blah 10 blah blah. blah blah blah 1. blah blah blah 1. 2. blah blah
> > blah. blah blah blah.")
> >
> > text1
> >
> > Thank you in advance for your suggestions and/or guidance.
> >
> > Best,
> >
> > Dan
> >
> >
> > On Wed, Apr 26, 2017 at 12:52 AM, Michael Hannon <jmhannon.ucdavis at gmail.com
> >> wrote:
> >
> >> Thanks, Ista.  I thought there might be a "tidy" way to do this, but I
> >> hadn't use stringr.
> >>
> >> -- Mike
> >>
> >>
> >> On Tue, Apr 25, 2017 at 8:47 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >>> stringr::str_count (and stringi::stri_count that it wraps) interpret
> >>> the pattern argument as a regular expression by default.
> >>>
> >>> Best,
> >>> Ista
> >>>
> >>> On Tue, Apr 25, 2017 at 11:40 PM, Michael Hannon
> >>> <jmhannon.ucdavis at gmail.com> wrote:
> >>>> I like Boris's "Hadley" solution.  For the record, I've appended a
> >>>> version that uses regular expressions, the only benefit of which is
> >>>> that it could be generalized to find more-complicated patterns.
> >>>>
> >>>> -- Mike
> >>>>
> >>>> counts <- sapply(text1, function(next_string) {
> >>>>    loc_example <- length(gregexpr("Example", next_string)[[1]])
> >>>>    loc_example
> >>>> }, USE.NAMES=FALSE)
> >>>>
> >>>>> counts
> >>>> [1] 5 5 5 5
> >>>>>
> >>>>
> >>>> On Tue, Apr 25, 2017 at 5:33 PM, Boris Steipe <boris.steipe at utoronto.ca>
> >> wrote:
> >>>>> I should add: there's a str_count() function in the stringr package.
> >>>>>
> >>>>> library(stringr)
> >>>>> str_count(text1, "Example")
> >>>>> # [1] 5 5 5 5
> >>>>>
> >>>>> I guess that would be the neater solution.
> >>>>>
> >>>>> B.
> >>>>>
> >>>>>
> >>>>>
> >>>>>> On Apr 25, 2017, at 8:23 PM, Boris Steipe <boris.steipe at utoronto.ca>
> >> wrote:
> >>>>>>
> >>>>>> How about:
> >>>>>>
> >>>>>> unlist(lapply(strsplit(text1, "Example"), function(x) { length(x) - 1
> >> } ))
> >>>>>>
> >>>>>>
> >>>>>> Splitting your string on the five "Examples" in each gives six
> >> elements. length(x) - 1 is the number of
> >>>>>> matches. You can use any regex instead of "example" if you need to
> >> tweak what you are looking for.
> >>>>>>
> >>>>>>
> >>>>>> B.
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>> On Apr 25, 2017, at 8:14 PM, Dan Abner <dan.abner99 at gmail.com>
> >> wrote:
> >>>>>>>
> >>>>>>> Hi all,
> >>>>>>>
> >>>>>>> I am looking for a streamlined way of counting the number of
> >> enumerated
> >>>>>>> items are each element of a character vector. For example:
> >>>>>>>
> >>>>>>>
> >>>>>>> text1<-c("This is an example.
> >>>>>>> List 1
> >>>>>>> 1) Example 1
> >>>>>>> 2) Example 2
> >>>>>>> 10) Example 10
> >>>>>>> List 2
> >>>>>>> 1) Example 1
> >>>>>>> 2) Example 2
> >>>>>>> These have been examples.","This is another example.
> >>>>>>> List 1
> >>>>>>> 1. Example 1
> >>>>>>> 2. Example 2
> >>>>>>> 10. Example 10
> >>>>>>> List 2
> >>>>>>> 1. Example 1
> >>>>>>> 2. Example 2
> >>>>>>> These have been examples.","This is a third example. List 1 1)
> >> Example 1.
> >>>>>>> 2) Example 2. 10) Example 10. List 2 1) Example 1. 2) Example 2.
> >> These have
> >>>>>>> been examples."
> >>>>>>> ,"This is a fourth example. List 1 1. Example 1. 2. Example 2. 10.
> >> Example
> >>>>>>> 10. List 2 Example 1. 2. Example 2. These have been examples.")
> >>>>>>>
> >>>>>>> text1
> >>>>>>>
> >>>>>>> ===
> >>>>>>>
> >>>>>>> I would like the result to be c(5,5,5,5). Notice that sometimes
> >> there are
> >>>>>>> leading hard returns, other times not. Sometimes are there separate
> >> lists
> >>>>>>> and the same numbers are used in the enumerated items multiple times
> >> within
> >>>>>>> each character string. Sometimes the leading numbers for the
> >> enumerated
> >>>>>>> items exceed single digits. Notice that the delimiter may be ) or a
> >> period
> >>>>>>> (.). If the delimiter is a period and there are hard returns
> >> (example 2),
> >>>>>>> then I expect that will be easy enough to differentiate sentences
> >> ending
> >>>>>>> with a number from enumerated items. However, I imagine it would be
> >> much
> >>>>>>> more difficult to differentiate the two for example 4.
> >>>>>>>
> >>>>>>> Any suggestions are appreciated.
> >>>>>>>
> >>>>>>> Best,
> >>>>>>>
> >>>>>>> Dan
> >>>>>>>
> >>>>>>>     [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From therneau at mayo.edu  Wed Apr 26 20:51:10 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 26 Apr 2017 13:51:10 -0500
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <47cabe$6a6f5l@ironport10.mayo.edu>

A user contacted me directly about this, I answered with my best understanding of the 
recent R-help discussion of the issue, and their response to my response shows that I'm 
not quite right.

I am emphatically not an MS Windows user so am asking for help -- which I will cut/paste 
to this user and to the next dozen who will invariably contact me directly.

Thanks,
   Terry Therneau



-------- Forwarded Message --------
Subject: RE: survival package
Date: Wed, 26 Apr 2017 18:05:30 +0000
From: SeshanV at mskcc.org
To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>

Thank you for the quick response. The session info command for v3.4.0 does in fact report 
survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the same computer the 
library paths do not have any directory in common:

> .libPaths()
[1] "C:/Program Files/R/R-3.4.0/library"
>

and
> .libPaths()
[1] "C:/Program Files/R/R-3.3.1/library"
>


Thanks,
Venkat


-----Original Message-----
From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: Wednesday, April 26, 2017 
1:42 PM
To: Seshan, Venkatraman E./Epidemiology-Biostatistics
Subject: Re: survival package

This has been discussed in R-help by multiple people.  You have a pre-3.4 version of the 
survival package somewhere on your search path, and the method for resolving .C calls has 
changed.   The sessionInfo command should report survival version 2.41-3.

Terry T.


On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
> Dear Prof. Therneau,
>
> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>
> ----------------------------------------------------------------------
> -------------------------
>
> ***************************
> **  Works under R-3.3.1  **
> ***************************
>
>> source("coxfit6-issue.R")
> [1] -0.4838181
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
> (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] survival_2.39-4
>
> loaded via a namespace (and not attached):
> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>
> ----------------------------------------------------------------------
> -------------------------
>
> ***********************************
> **  Does not work under R-3.4.0  **
> ***********************************
>
>> library(survival)
>> source("coxfit6-issue.R")
> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>    "Ccoxfit6" not available for .Call() for package "survival"
>> sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
> (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] survival_2.41-3
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
> [5] lattice_0.20-35
>
> ----------------------------------------------------------------------
> -------------------------
>
> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>
> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>    object 'Ccoxfit6' not found
>
>
> I would greatly appreciate your help in resolving this.
>
> Thanks,
> Venkat Seshan
>


=====================================================================

      Please note that this e-mail and any files transmitted from
      Memorial Sloan Kettering Cancer Center may be privileged, confidential,
      and protected from disclosure under applicable law. If the reader of
      this message is not the intended recipient, or an employee or agent
      responsible for delivering this message to the intended recipient,
      you are hereby notified that any reading, dissemination, distribution,
      copying, or other use of this communication or any of its attachments
      is strictly prohibited.  If you have received this communication in
      error, please notify the sender immediately by replying to this message
      and deleting this message, any attachments, and all copies and backups
      from your computer.


From murdoch.duncan at gmail.com  Wed Apr 26 22:17:30 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Apr 2017 16:17:30 -0400
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <47cabe$6a6f5l@ironport10.mayo.edu>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
Message-ID: <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>

On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
> A user contacted me directly about this, I answered with my best understanding of the
> recent R-help discussion of the issue, and their response to my response shows that I'm
> not quite right.
>
> I am emphatically not an MS Windows user so am asking for help -- which I will cut/paste
> to this user and to the next dozen who will invariably contact me directly.
>
> Thanks,
>    Terry Therneau
>
>
>
> -------- Forwarded Message --------
> Subject: RE: survival package
> Date: Wed, 26 Apr 2017 18:05:30 +0000
> From: SeshanV at mskcc.org
> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>
> Thank you for the quick response. The session info command for v3.4.0 does in fact report
> survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the same computer the
> library paths do not have any directory in common:
>
>> .libPaths()
> [1] "C:/Program Files/R/R-3.4.0/library"
>>
>
> and
>> .libPaths()
> [1] "C:/Program Files/R/R-3.3.1/library"
>>
>
>
> Thanks,
> Venkat
>
>
> -----Original Message-----
> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: Wednesday, April 26, 2017
> 1:42 PM
> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
> Subject: Re: survival package
>
> This has been discussed in R-help by multiple people.  You have a pre-3.4 version of the
> survival package somewhere on your search path, and the method for resolving .C calls has
> changed.   The sessionInfo command should report survival version 2.41-3.
>
> Terry T.
>
>
> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>> Dear Prof. Therneau,
>>
>> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> ***************************
>> **  Works under R-3.3.1  **
>> ***************************
>>
>>> source("coxfit6-issue.R")
>> [1] -0.4838181
>>
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.39-4
>>
>> loaded via a namespace (and not attached):
>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> ***********************************
>> **  Does not work under R-3.4.0  **
>> ***********************************
>>
>>> library(survival)
>>> source("coxfit6-issue.R")
>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>>    "Ccoxfit6" not available for .Call() for package "survival"

As far as I can see, that line doesn't appear in the current survival 
source code, it's from some earlier version of the package.  The current 
one has

coxfit <- .Call(Ccoxfit6,
                      as.integer(maxiter),
                      stime,
                      sstat,
                      x[sorted,],
                      as.double(offset[sorted]),
                      weights,
                      newstrat,
                      as.integer(method=="efron"),
                      as.double(control$eps),
                      as.double(control$toler.chol),
                      as.vector(init),
                      as.integer(1))  # internally rescale

There are several differences, the one leading to the error being the 
change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That 
corresponds to the difference between a registered symbol and an 
unregistered one.

Without seeing the code that led to the error message I can't really say 
how the error came about.  There are a few ways:

- The user has a copy of the coxph.fit function from an older version of 
survival saved in their workspace, and are using that one instead of the 
current one.

- Some part of your code returns functions, and one of those is making 
this call based on an object produced in an earlier version of survival.

- There are really two versions of survival on the search path (or 
perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.

Duncan Murdoch

>>> sessionInfo()
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.41-3
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>> [5] lattice_0.20-35
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>>
>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>>    object 'Ccoxfit6' not found
>>
>>
>> I would greatly appreciate your help in resolving this.
>>
>> Thanks,
>> Venkat Seshan
>>
>
>
> =====================================================================
>
>       Please note that this e-mail and any files transmitted from
>       Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>       and protected from disclosure under applicable law. If the reader of
>       this message is not the intended recipient, or an employee or agent
>       responsible for delivering this message to the intended recipient,
>       you are hereby notified that any reading, dissemination, distribution,
>       copying, or other use of this communication or any of its attachments
>       is strictly prohibited.  If you have received this communication in
>       error, please notify the sender immediately by replying to this message
>       and deleting this message, any attachments, and all copies and backups
>       from your computer.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jake at jakestone.net  Thu Apr 27 00:05:05 2017
From: jake at jakestone.net (Jake Stone)
Date: Wed, 26 Apr 2017 15:05:05 -0700
Subject: [R] OpenCPU app development. Testing Source Code
Message-ID: <CAL964Uwqj=7zaV+ZO-wxEZuWFZ+Skw+KmY1fK4=LcZ67uMTZ4A@mail.gmail.com>

I'm brand new to opencpu.

Do I have to package my code before I can test on my opencpu single server?
It would be nice to just test from source.

-- 
*jake*

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 27 00:07:45 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 27 Apr 2017 08:07:45 +1000
Subject: [R] Reg. help for SWAT Calibration
In-Reply-To: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
References: <CAL7MW6e+AVuSoKEmT1MOmBT+oCwf=i+EnxirpXzegcMHyHb-xg@mail.gmail.com>
Message-ID: <CA+8X3fWNrPS=rpBF07H=oYtpNCadOr3ENinHu_7Bo9LcwwjLnw@mail.gmail.com>

Hi Sanjeev,
The video that you attached seems to contain the information that you
want. If you contact Kazi Rahman (the creator of the video) who seems
to be at the University of Geneva currently, you may be able to get
the information that you want.

Jim

On Wed, Apr 26, 2017 at 4:27 PM, Sanjeev Kumar
<sanjeevkumargpt321 at gmail.com> wrote:
> Sir/Mam
>       I am a Research Scholar at Central University of Karnataka and I am
> working on SWAT (Soil And Water Assessment tool) and I need 'R' for the
> Calibration purpose but for 'R' I need a code. So if it is possible to send
> that code pls send me.
>
>
>
> https://www.youtube.com/watch?v=5NFn9paBR98&t=15s
> This is the video link where i came to know about 'R'
>
>
>
> Thanks
>
> Yours Sincerely
> Sanjeev Kumar
> Research Associate
> Central University of Karnataka
> Karnataka India
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Apr 27 00:47:28 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 26 Apr 2017 15:47:28 -0700
Subject: [R] OpenCPU app development. Testing Source Code
In-Reply-To: <CAL964Uwqj=7zaV+ZO-wxEZuWFZ+Skw+KmY1fK4=LcZ67uMTZ4A@mail.gmail.com>
References: <CAL964Uwqj=7zaV+ZO-wxEZuWFZ+Skw+KmY1fK4=LcZ67uMTZ4A@mail.gmail.com>
Message-ID: <2824A645-2F10-4B6A-A876-6A5C73CB8BDF@dcn.davis.ca.us>

Not the right forum... try https://www.opencpu.org/help.html

I suggest you learn R interactively (not via OpenCPU), but packages are not that hard to build if you use RStudio.
-- 
Sent from my phone. Please excuse my brevity.

On April 26, 2017 3:05:05 PM PDT, Jake Stone <jake at jakestone.net> wrote:
>I'm brand new to opencpu.
>
>Do I have to package my code before I can test on my opencpu single
>server?
>It would be nice to just test from source.


From valkremk at gmail.com  Thu Apr 27 02:45:10 2017
From: valkremk at gmail.com (Val)
Date: Wed, 26 Apr 2017 19:45:10 -0500
Subject: [R] missing and replace
Message-ID: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>

HI all,

I have a data frame with three variables. Some of the variables do
have missing values and I want to replace those missing values
(1represented by NA) with the mean value of that variable. In this
sample data,  variable z and y do have missing values. The mean value
of y  and z are152. 25  and 359.5, respectively . I want replace those
missing values  by the respective mean value ( rounded to the nearest
whole number).

DF1 <- read.table(header=TRUE, text='ID1 x y z
1  25  122    352
2  30  135    376
3  40   NA    350
4  26  157    NA
5  60  195    360')
mean x= 36.2
mean y=152.25
mean z= 359.5

output
ID1  x  y  z
1   25 122   352
2   30 135   376
3   40 152   350
4   26 157   360
5   60 195   360


Thank you in advance


From murdoch.duncan at gmail.com  Thu Apr 27 03:06:22 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Apr 2017 21:06:22 -0400
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <CDC04FFA7FC22548ADD6AECFA993565DE5CBA141@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
 <CDC04FFA7FC22548ADD6AECFA993565DE5CBA141@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <c012f9dd-08fc-7627-03ac-ef7a63ac2317@gmail.com>

On 26/04/2017 5:20 PM, SeshanV at mskcc.org wrote:
> Attaching the code that generates the error. The function phcoefs in the attached was modeled after coxph.fit from which all the preprocessing has been stripped so that just coxfit6 (C code) can be called to estimate the coefficients.
>
>> library(survival)
>> source("coxfit6-issue.R")
> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>   "Ccoxfit6" not available for .Call() for package "survival"
>
> Same file with the quotes surrounding "Ccoxfit6" removed
>
>> source("coxfit6-issue.R")
> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>   object 'Ccoxfit6' not found
>>
>
> I can confirm that this error occurs in linux (Ubuntu 14.0.4.5) as well.

That's misuse of the package.  As far as I know, the Ccoxfit6 function 
has never been exported from the survival package.  Using unexported 
internals from a package is very dangerous and likely to lead to errors. 
  (As I pointed out, there were other changes to the call besides the 
use of "Ccoxfit6" versus Ccoxfit6.

Duncan Murdoch

>
> Thanks,
> Venkat
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Wednesday, April 26, 2017 4:18 PM
> To: Therneau, Terry M., Ph.D.; R-help
> Cc: Seshan, Venkatraman E./Epidemiology-Biostatistics
> Subject: Re: [R] survival package can't find Ccoxfit6
>
> On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
>> A user contacted me directly about this, I answered with my best
>> understanding of the recent R-help discussion of the issue, and their
>> response to my response shows that I'm not quite right.
>>
>> I am emphatically not an MS Windows user so am asking for help --
>> which I will cut/paste to this user and to the next dozen who will invariably contact me directly.
>>
>> Thanks,
>>    Terry Therneau
>>
>>
>>
>> -------- Forwarded Message --------
>> Subject: RE: survival package
>> Date: Wed, 26 Apr 2017 18:05:30 +0000
>> From: SeshanV at mskcc.org
>> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>>
>> Thank you for the quick response. The session info command for v3.4.0
>> does in fact report survival_2.41-3. Furthermore, while both v3.3.1
>> and v3.40 are on the same computer the library paths do not have any directory in common:
>>
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.4.0/library"
>>>
>>
>> and
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.3.1/library"
>>>
>>
>>
>> Thanks,
>> Venkat
>>
>>
>> -----Original Message-----
>> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent:
>> Wednesday, April 26, 2017
>> 1:42 PM
>> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
>> Subject: Re: survival package
>>
>> This has been discussed in R-help by multiple people.  You have a
>> pre-3.4 version of the survival package somewhere on your search path, and the method for resolving .C calls has
>> changed.   The sessionInfo command should report survival version 2.41-3.
>>
>> Terry T.
>>
>>
>> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>>> Dear Prof. Therneau,
>>>
>>> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>>>
>>> ---------------------------------------------------------------------
>>> -
>>> -------------------------
>>>
>>> ***************************
>>> **  Works under R-3.3.1  **
>>> ***************************
>>>
>>>> source("coxfit6-issue.R")
>>> [1] -0.4838181
>>>
>>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
>>> x64 (build 7601) Service Pack 1
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.39-4
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>>
>>> ---------------------------------------------------------------------
>>> -
>>> -------------------------
>>>
>>> ***********************************
>>> **  Does not work under R-3.4.0  **
>>> ***********************************
>>>
>>>> library(survival)
>>>> source("coxfit6-issue.R")
>>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>>>    "Ccoxfit6" not available for .Call() for package "survival"
>
> As far as I can see, that line doesn't appear in the current survival source code, it's from some earlier version of the package.  The current one has
>
> coxfit <- .Call(Ccoxfit6,
>                       as.integer(maxiter),
>                       stime,
>                       sstat,
>                       x[sorted,],
>                       as.double(offset[sorted]),
>                       weights,
>                       newstrat,
>                       as.integer(method=="efron"),
>                       as.double(control$eps),
>                       as.double(control$toler.chol),
>                       as.vector(init),
>                       as.integer(1))  # internally rescale
>
> There are several differences, the one leading to the error being the change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That corresponds to the difference between a registered symbol and an unregistered one.
>
> Without seeing the code that led to the error message I can't really say how the error came about.  There are a few ways:
>
> - The user has a copy of the coxph.fit function from an older version of survival saved in their workspace, and are using that one instead of the current one.
>
> - Some part of your code returns functions, and one of those is making this call based on an object produced in an earlier version of survival.
>
> - There are really two versions of survival on the search path (or perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.
>
> Duncan Murdoch
>
>>>> sessionInfo()
>>> R version 3.4.0 (2017-04-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
>>> x64 (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.41-3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>>> [5] lattice_0.20-35
>>>
>>> ---------------------------------------------------------------------
>>> -
>>> -------------------------
>>>
>>> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>>>
>>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>>>    object 'Ccoxfit6' not found
>>>
>>>
>>> I would greatly appreciate your help in resolving this.
>>>
>>> Thanks,
>>> Venkat Seshan
>>>
>>
>>
>> =====================================================================
>>
>>       Please note that this e-mail and any files transmitted from
>>       Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>>       and protected from disclosure under applicable law. If the reader of
>>       this message is not the intended recipient, or an employee or agent
>>       responsible for delivering this message to the intended recipient,
>>       you are hereby notified that any reading, dissemination, distribution,
>>       copying, or other use of this communication or any of its attachments
>>       is strictly prohibited.  If you have received this communication in
>>       error, please notify the sender immediately by replying to this message
>>       and deleting this message, any attachments, and all copies and backups
>>       from your computer.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> =====================================================================
>
>      Please note that this e-mail and any files transmitted from
>      Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>      and protected from disclosure under applicable law. If the reader of
>      this message is not the intended recipient, or an employee or agent
>      responsible for delivering this message to the intended recipient,
>      you are hereby notified that any reading, dissemination, distribution,
>      copying, or other use of this communication or any of its attachments
>      is strictly prohibited.  If you have received this communication in
>      error, please notify the sender immediately by replying to this message
>      and deleting this message, any attachments, and all copies and backups
>      from your computer.
>


From murdoch.duncan at gmail.com  Thu Apr 27 03:09:59 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Apr 2017 21:09:59 -0400
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <CDC04FFA7FC22548ADD6AECFA993565DE5CBA3C6@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
 <CDC04FFA7FC22548ADD6AECFA993565DE5CBA3C6@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <a4ffedad-4ece-2333-24ce-e2cfe41eb3ad@gmail.com>

On 26/04/2017 7:40 PM, SeshanV at mskcc.org wrote:
> Thanks to Henrik Bengtsson I found a work around which is to use environment(phcoefs) <- asNamespace("survival")
>
> It seems like the symbols that are accessed using .Call are not accessible from outside the package that defines it.

If it was intended for that function to be called by others, it would 
have been exported, and you could have called it.  It wasn't exported, 
so Dr. Therneau may decide to change its meaning tomorrow, and your code 
will break.  It will be your own fault.

If you don't like the way coxph.fit was written, you should copy all of 
it (including the Ccoxfit6 code), not just part.  Or better:  work with 
Dr. Therneau to improve it for everyone.

Duncan Murdoch

>
>> phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients, control)
> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>   object 'Ccoxfit6' not found
>> environment(phcoefs) <- asNamespace("survival")
>> phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients, control)
> [1] -0.4838181
>
> Venkat
>
>
> ________________________________________
> From: Duncan Murdoch [murdoch.duncan at gmail.com]
> Sent: Wednesday, April 26, 2017 4:17 PM
> To: Therneau, Terry M., Ph.D.; R-help
> Cc: Seshan, Venkatraman E./Epidemiology-Biostatistics
> Subject: Re: [R] survival package can't find Ccoxfit6
>
> On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
>> A user contacted me directly about this, I answered with my best understanding of the
>> recent R-help discussion of the issue, and their response to my response shows that I'm
>> not quite right.
>>
>> I am emphatically not an MS Windows user so am asking for help -- which I will cut/paste
>> to this user and to the next dozen who will invariably contact me directly.
>>
>> Thanks,
>>    Terry Therneau
>>
>>
>>
>> -------- Forwarded Message --------
>> Subject: RE: survival package
>> Date: Wed, 26 Apr 2017 18:05:30 +0000
>> From: SeshanV at mskcc.org
>> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>>
>> Thank you for the quick response. The session info command for v3.4.0 does in fact report
>> survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the same computer the
>> library paths do not have any directory in common:
>>
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.4.0/library"
>>>
>>
>> and
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.3.1/library"
>>>
>>
>>
>> Thanks,
>> Venkat
>>
>>
>> -----Original Message-----
>> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: Wednesday, April 26, 2017
>> 1:42 PM
>> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
>> Subject: Re: survival package
>>
>> This has been discussed in R-help by multiple people.  You have a pre-3.4 version of the
>> survival package somewhere on your search path, and the method for resolving .C calls has
>> changed.   The sessionInfo command should report survival version 2.41-3.
>>
>> Terry T.
>>
>>
>> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>>> Dear Prof. Therneau,
>>>
>>> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> ***************************
>>> **  Works under R-3.3.1  **
>>> ***************************
>>>
>>>> source("coxfit6-issue.R")
>>> [1] -0.4838181
>>>
>>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>> (build 7601) Service Pack 1
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.39-4
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> ***********************************
>>> **  Does not work under R-3.4.0  **
>>> ***********************************
>>>
>>>> library(survival)
>>>> source("coxfit6-issue.R")
>>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>>>    "Ccoxfit6" not available for .Call() for package "survival"
>
> As far as I can see, that line doesn't appear in the current survival
> source code, it's from some earlier version of the package.  The current
> one has
>
> coxfit <- .Call(Ccoxfit6,
>                       as.integer(maxiter),
>                       stime,
>                       sstat,
>                       x[sorted,],
>                       as.double(offset[sorted]),
>                       weights,
>                       newstrat,
>                       as.integer(method=="efron"),
>                       as.double(control$eps),
>                       as.double(control$toler.chol),
>                       as.vector(init),
>                       as.integer(1))  # internally rescale
>
> There are several differences, the one leading to the error being the
> change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That
> corresponds to the difference between a registered symbol and an
> unregistered one.
>
> Without seeing the code that led to the error message I can't really say
> how the error came about.  There are a few ways:
>
> - The user has a copy of the coxph.fit function from an older version of
> survival saved in their workspace, and are using that one instead of the
> current one.
>
> - Some part of your code returns functions, and one of those is making
> this call based on an object produced in an earlier version of survival.
>
> - There are really two versions of survival on the search path (or
> perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.
>
> Duncan Murdoch
>
>>>> sessionInfo()
>>> R version 3.4.0 (2017-04-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>> (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.41-3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>>> [5] lattice_0.20-35
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>>>
>>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>>>    object 'Ccoxfit6' not found
>>>
>>>
>>> I would greatly appreciate your help in resolving this.
>>>
>>> Thanks,
>>> Venkat Seshan
>>>
>>
>>
>> =====================================================================
>>
>>       Please note that this e-mail and any files transmitted from
>>       Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>>       and protected from disclosure under applicable law. If the reader of
>>       this message is not the intended recipient, or an employee or agent
>>       responsible for delivering this message to the intended recipient,
>>       you are hereby notified that any reading, dissemination, distribution,
>>       copying, or other use of this communication or any of its attachments
>>       is strictly prohibited.  If you have received this communication in
>>       error, please notify the sender immediately by replying to this message
>>       and deleting this message, any attachments, and all copies and backups
>>       from your computer.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> =====================================================================
>
>      Please note that this e-mail and any files transmitted from
>      Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>      and protected from disclosure under applicable law. If the reader of
>      this message is not the intended recipient, or an employee or agent
>      responsible for delivering this message to the intended recipient,
>      you are hereby notified that any reading, dissemination, distribution,
>      copying, or other use of this communication or any of its attachments
>      is strictly prohibited.  If you have received this communication in
>      error, please notify the sender immediately by replying to this message
>      and deleting this message, any attachments, and all copies and backups
>      from your computer.
>


From r.turner at auckland.ac.nz  Thu Apr 27 03:16:32 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 27 Apr 2017 13:16:32 +1200
Subject: [R] [FORGED]  missing and replace
In-Reply-To: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
References: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
Message-ID: <2022e01c-fc48-8ed8-07da-6425f94090d0@auckland.ac.nz>

On 27/04/17 12:45, Val wrote:
> HI all,
>
> I have a data frame with three variables. Some of the variables do
> have missing values and I want to replace those missing values
> (1represented by NA) with the mean value of that variable. In this
> sample data,  variable z and y do have missing values. The mean value
> of y  and z are152. 25  and 359.5, respectively . I want replace those
> missing values  by the respective mean value ( rounded to the nearest
> whole number).
>
> DF1 <- read.table(header=TRUE, text='ID1 x y z
> 1  25  122    352
> 2  30  135    376
> 3  40   NA    350
> 4  26  157    NA
> 5  60  195    360')
> mean x= 36.2
> mean y=152.25
> mean z= 359.5
>
> output
> ID1  x  y  z
> 1   25 122   352
> 2   30 135   376
> 3   40 152   350
> 4   26 157   360
> 5   60 195   360

This is pretty basic.  You really ought to learn a bit more about R if 
you are going to use R.  That being said, try:

newDF1 <- as.data.frame(lapply(DF1,function(x){
                         x[is.na(x)] <- mean(x,na.rm=TRUE)
                         x}))

There may be sexier ways of accomplishing your goal, but this should work.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ngbolin91 at gmail.com  Thu Apr 27 03:19:26 2017
From: ngbolin91 at gmail.com (Ng Bo Lin)
Date: Thu, 27 Apr 2017 09:19:26 +0800
Subject: [R] missing and replace
In-Reply-To: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
References: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
Message-ID: <DF6E686E-2B51-4241-B301-58CE102EDCFD@gmail.com>

Hi Val,

You could do this by nesting 2 for loops, and defining a function such that it returns the mean of the column when the value is ?NA?.

df1 <- data.frame(x = c(25, 30, 40, 26, 60), y = c(122, 135, NA, 157, 195), z = c(352, 376, 350, NA, 360)); df2 <- df1[0, ]

means <- sapply(df1, mean, na.rm = T); return_mean_if_NA <- function(x, y) { if (is.na(x)){ x <- y } else { return(x) } }

for (i in 1:ncol(df1)){
        for (j in 1:nrow(df1)){
                df2[j, i] <- return_mean_if_NA(df1[j, i], means[i])
        }
}


Hope this helps!

Regards,
Bo Lin

> On 27 Apr 2017, at 8:45 AM, Val <valkremk at gmail.com> wrote:
> 
> HI all,
> 
> I have a data frame with three variables. Some of the variables do
> have missing values and I want to replace those missing values
> (1represented by NA) with the mean value of that variable. In this
> sample data,  variable z and y do have missing values. The mean value
> of y  and z are152. 25  and 359.5, respectively . I want replace those
> missing values  by the respective mean value ( rounded to the nearest
> whole number).
> 
> DF1 <- read.table(header=TRUE, text='ID1 x y z
> 1  25  122    352
> 2  30  135    376
> 3  40   NA    350
> 4  26  157    NA
> 5  60  195    360')
> mean x= 36.2
> mean y=152.25
> mean z= 359.5
> 
> output
> ID1  x  y  z
> 1   25 122   352
> 2   30 135   376
> 3   40 152   350
> 4   26 157   360
> 5   60 195   360
> 
> 
> Thank you in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ngbolin91 at gmail.com  Thu Apr 27 03:21:31 2017
From: ngbolin91 at gmail.com (Ng Bo Lin)
Date: Thu, 27 Apr 2017 09:21:31 +0800
Subject: [R] missing and replace
In-Reply-To: <DF6E686E-2B51-4241-B301-58CE102EDCFD@gmail.com>
References: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
 <DF6E686E-2B51-4241-B301-58CE102EDCFD@gmail.com>
Message-ID: <2D165E0B-1E4E-4B4E-8C59-FBB20CC3A84F@gmail.com>

Apologies, I re-read the question and realised you hope to replace the missing values rounded to the nearest whole number.

Here?s the code in full.

df1 <- data.frame(x = c(25, 30, 40, 26, 60), y = c(122, 135, NA, 157, 195), z = c(352, 376, 350, NA, 360))

means <- sapply(df1, mean, na.rm = T); return_mean_if_NA <- function(x, y) { if (is.na(x)){ x <- y } else { return(x) } }

df2 <- df1[0, ]

for (i in 1:ncol(df1)){
        for (j in 1:nrow(df1)){
                df2[j, i] <- round(return_mean_if_NA(df1[j, i], means[i]), 0)
        }
}

HTH.

Regards,
Bo Lin

> On 27 Apr 2017, at 9:19 AM, Ng Bo Lin <ngbolin91 at gmail.com> wrote:
> 
> Hi Val,
> 
> You could do this by nesting 2 for loops, and defining a function such that it returns the mean of the column when the value is ?NA?.
> 
> df1 <- data.frame(x = c(25, 30, 40, 26, 60), y = c(122, 135, NA, 157, 195), z = c(352, 376, 350, NA, 360)); df2 <- df1[0, ]
> 
> means <- sapply(df1, mean, na.rm = T); return_mean_if_NA <- function(x, y) { if (is.na(x)){ x <- y } else { return(x) } }
> 
> for (i in 1:ncol(df1)){
>        for (j in 1:nrow(df1)){
>                df2[j, i] <- return_mean_if_NA(df1[j, i], means[i])
>        }
> }
> 
> 
> Hope this helps!
> 
> Regards,
> Bo Lin
> 
>> On 27 Apr 2017, at 8:45 AM, Val <valkremk at gmail.com> wrote:
>> 
>> HI all,
>> 
>> I have a data frame with three variables. Some of the variables do
>> have missing values and I want to replace those missing values
>> (1represented by NA) with the mean value of that variable. In this
>> sample data,  variable z and y do have missing values. The mean value
>> of y  and z are152. 25  and 359.5, respectively . I want replace those
>> missing values  by the respective mean value ( rounded to the nearest
>> whole number).
>> 
>> DF1 <- read.table(header=TRUE, text='ID1 x y z
>> 1  25  122    352
>> 2  30  135    376
>> 3  40   NA    350
>> 4  26  157    NA
>> 5  60  195    360')
>> mean x= 36.2
>> mean y=152.25
>> mean z= 359.5
>> 
>> output
>> ID1  x  y  z
>> 1   25 122   352
>> 2   30 135   376
>> 3   40 152   350
>> 4   26 157   360
>> 5   60 195   360
>> 
>> 
>> Thank you in advance
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From SeshanV at mskcc.org  Wed Apr 26 23:20:57 2017
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Wed, 26 Apr 2017 21:20:57 +0000
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
Message-ID: <CDC04FFA7FC22548ADD6AECFA993565DE5CBA141@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>

Attaching the code that generates the error. The function phcoefs in the attached was modeled after coxph.fit from which all the preprocessing has been stripped so that just coxfit6 (C code) can be called to estimate the coefficients.

> library(survival)
> source("coxfit6-issue.R")
Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  : 
  "Ccoxfit6" not available for .Call() for package "survival"

Same file with the quotes surrounding "Ccoxfit6" removed

> source("coxfit6-issue.R")
Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  : 
  object 'Ccoxfit6' not found
> 

I can confirm that this error occurs in linux (Ubuntu 14.0.4.5) as well.

Thanks,
Venkat

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, April 26, 2017 4:18 PM
To: Therneau, Terry M., Ph.D.; R-help
Cc: Seshan, Venkatraman E./Epidemiology-Biostatistics
Subject: Re: [R] survival package can't find Ccoxfit6

On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
> A user contacted me directly about this, I answered with my best 
> understanding of the recent R-help discussion of the issue, and their 
> response to my response shows that I'm not quite right.
>
> I am emphatically not an MS Windows user so am asking for help -- 
> which I will cut/paste to this user and to the next dozen who will invariably contact me directly.
>
> Thanks,
>    Terry Therneau
>
>
>
> -------- Forwarded Message --------
> Subject: RE: survival package
> Date: Wed, 26 Apr 2017 18:05:30 +0000
> From: SeshanV at mskcc.org
> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>
> Thank you for the quick response. The session info command for v3.4.0 
> does in fact report survival_2.41-3. Furthermore, while both v3.3.1 
> and v3.40 are on the same computer the library paths do not have any directory in common:
>
>> .libPaths()
> [1] "C:/Program Files/R/R-3.4.0/library"
>>
>
> and
>> .libPaths()
> [1] "C:/Program Files/R/R-3.3.1/library"
>>
>
>
> Thanks,
> Venkat
>
>
> -----Original Message-----
> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: 
> Wednesday, April 26, 2017
> 1:42 PM
> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
> Subject: Re: survival package
>
> This has been discussed in R-help by multiple people.  You have a 
> pre-3.4 version of the survival package somewhere on your search path, and the method for resolving .C calls has
> changed.   The sessionInfo command should report survival version 2.41-3.
>
> Terry T.
>
>
> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>> Dear Prof. Therneau,
>>
>> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>>
>> ---------------------------------------------------------------------
>> -
>> -------------------------
>>
>> ***************************
>> **  Works under R-3.3.1  **
>> ***************************
>>
>>> source("coxfit6-issue.R")
>> [1] -0.4838181
>>
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 
>> x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4] 
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.39-4
>>
>> loaded via a namespace (and not attached):
>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>
>> ---------------------------------------------------------------------
>> -
>> -------------------------
>>
>> ***********************************
>> **  Does not work under R-3.4.0  **
>> ***********************************
>>
>>> library(survival)
>>> source("coxfit6-issue.R")
>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>>    "Ccoxfit6" not available for .Call() for package "survival"

As far as I can see, that line doesn't appear in the current survival source code, it's from some earlier version of the package.  The current one has

coxfit <- .Call(Ccoxfit6,
                      as.integer(maxiter),
                      stime,
                      sstat,
                      x[sorted,],
                      as.double(offset[sorted]),
                      weights,
                      newstrat,
                      as.integer(method=="efron"),
                      as.double(control$eps),
                      as.double(control$toler.chol),
                      as.vector(init),
                      as.integer(1))  # internally rescale

There are several differences, the one leading to the error being the change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That corresponds to the difference between a registered symbol and an unregistered one.

Without seeing the code that led to the error message I can't really say how the error came about.  There are a few ways:

- The user has a copy of the coxph.fit function from an older version of survival saved in their workspace, and are using that one instead of the current one.

- Some part of your code returns functions, and one of those is making this call based on an object produced in an earlier version of survival.

- There are really two versions of survival on the search path (or perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.

Duncan Murdoch

>>> sessionInfo()
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 
>> x64 (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4] 
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.41-3
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>> [5] lattice_0.20-35
>>
>> ---------------------------------------------------------------------
>> -
>> -------------------------
>>
>> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>>
>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>>    object 'Ccoxfit6' not found
>>
>>
>> I would greatly appreciate your help in resolving this.
>>
>> Thanks,
>> Venkat Seshan
>>
>
>
> =====================================================================
>
>       Please note that this e-mail and any files transmitted from
>       Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>       and protected from disclosure under applicable law. If the reader of
>       this message is not the intended recipient, or an employee or agent
>       responsible for delivering this message to the intended recipient,
>       you are hereby notified that any reading, dissemination, distribution,
>       copying, or other use of this communication or any of its attachments
>       is strictly prohibited.  If you have received this communication in
>       error, please notify the sender immediately by replying to this message
>       and deleting this message, any attachments, and all copies and backups
>       from your computer.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


=====================================================================

     Please note that this e-mail and any files transmitted from
     Memorial Sloan Kettering Cancer Center may be privileged, confidential,
     and protected from disclosure under applicable law. If the reader of
     this message is not the intended recipient, or an employee or agent
     responsible for delivering this message to the intended recipient,
     you are hereby notified that any reading, dissemination, distribution,
     copying, or other use of this communication or any of its attachments
     is strictly prohibited.  If you have received this communication in
     error, please notify the sender immediately by replying to this message
     and deleting this message, any attachments, and all copies and backups
     from your computer.

From SeshanV at mskcc.org  Thu Apr 27 01:40:16 2017
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Wed, 26 Apr 2017 23:40:16 +0000
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>,
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
Message-ID: <CDC04FFA7FC22548ADD6AECFA993565DE5CBA3C6@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>

Thanks to Henrik Bengtsson I found a work around which is to use environment(phcoefs) <- asNamespace("survival")

It seems like the symbols that are accessed using .Call are not accessible from outside the package that defines it.

> phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients, control)
Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  : 
  object 'Ccoxfit6' not found
> environment(phcoefs) <- asNamespace("survival")
> phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients, control)
[1] -0.4838181

Venkat


________________________________________
From: Duncan Murdoch [murdoch.duncan at gmail.com]
Sent: Wednesday, April 26, 2017 4:17 PM
To: Therneau, Terry M., Ph.D.; R-help
Cc: Seshan, Venkatraman E./Epidemiology-Biostatistics
Subject: Re: [R] survival package can't find Ccoxfit6

On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
> A user contacted me directly about this, I answered with my best understanding of the
> recent R-help discussion of the issue, and their response to my response shows that I'm
> not quite right.
>
> I am emphatically not an MS Windows user so am asking for help -- which I will cut/paste
> to this user and to the next dozen who will invariably contact me directly.
>
> Thanks,
>    Terry Therneau
>
>
>
> -------- Forwarded Message --------
> Subject: RE: survival package
> Date: Wed, 26 Apr 2017 18:05:30 +0000
> From: SeshanV at mskcc.org
> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>
> Thank you for the quick response. The session info command for v3.4.0 does in fact report
> survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the same computer the
> library paths do not have any directory in common:
>
>> .libPaths()
> [1] "C:/Program Files/R/R-3.4.0/library"
>>
>
> and
>> .libPaths()
> [1] "C:/Program Files/R/R-3.3.1/library"
>>
>
>
> Thanks,
> Venkat
>
>
> -----Original Message-----
> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: Wednesday, April 26, 2017
> 1:42 PM
> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
> Subject: Re: survival package
>
> This has been discussed in R-help by multiple people.  You have a pre-3.4 version of the
> survival package somewhere on your search path, and the method for resolving .C calls has
> changed.   The sessionInfo command should report survival version 2.41-3.
>
> Terry T.
>
>
> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>> Dear Prof. Therneau,
>>
>> I am encountering an error message when I try to use the coxfit6 routine from the survival package under the 3.4.0 version of R. The minimal function and the script are in the attached file. This function worked under earlier versions of R.
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> ***************************
>> **  Works under R-3.3.1  **
>> ***************************
>>
>>> source("coxfit6-issue.R")
>> [1] -0.4838181
>>
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.39-4
>>
>> loaded via a namespace (and not attached):
>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> ***********************************
>> **  Does not work under R-3.4.0  **
>> ***********************************
>>
>>> library(survival)
>>> source("coxfit6-issue.R")
>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, as.integer(sstat),  :
>>    "Ccoxfit6" not available for .Call() for package "survival"

As far as I can see, that line doesn't appear in the current survival
source code, it's from some earlier version of the package.  The current
one has

coxfit <- .Call(Ccoxfit6,
                      as.integer(maxiter),
                      stime,
                      sstat,
                      x[sorted,],
                      as.double(offset[sorted]),
                      weights,
                      newstrat,
                      as.integer(method=="efron"),
                      as.double(control$eps),
                      as.double(control$toler.chol),
                      as.vector(init),
                      as.integer(1))  # internally rescale

There are several differences, the one leading to the error being the
change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That
corresponds to the difference between a registered symbol and an
unregistered one.

Without seeing the code that led to the error message I can't really say
how the error came about.  There are a few ways:

- The user has a copy of the coxph.fit function from an older version of
survival saved in their workspace, and are using that one instead of the
current one.

- Some part of your code returns functions, and one of those is making
this call based on an object produced in an earlier version of survival.

- There are really two versions of survival on the search path (or
perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.

Duncan Murdoch

>>> sessionInfo()
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] survival_2.41-3
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>> [5] lattice_0.20-35
>>
>> ----------------------------------------------------------------------
>> -------------------------
>>
>> When I remove the quotes surrounding Ccoxfit6 in the function both versions give the error:
>>
>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), oo$coefficients,  :
>>    object 'Ccoxfit6' not found
>>
>>
>> I would greatly appreciate your help in resolving this.
>>
>> Thanks,
>> Venkat Seshan
>>
>
>
> =====================================================================
>
>       Please note that this e-mail and any files transmitted from
>       Memorial Sloan Kettering Cancer Center may be privileged, confidential,
>       and protected from disclosure under applicable law. If the reader of
>       this message is not the intended recipient, or an employee or agent
>       responsible for delivering this message to the intended recipient,
>       you are hereby notified that any reading, dissemination, distribution,
>       copying, or other use of this communication or any of its attachments
>       is strictly prohibited.  If you have received this communication in
>       error, please notify the sender immediately by replying to this message
>       and deleting this message, any attachments, and all copies and backups
>       from your computer.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


=====================================================================

     Please note that this e-mail and any files transmitted from
     Memorial Sloan Kettering Cancer Center may be privileged, confidential,
     and protected from disclosure under applicable law. If the reader of
     this message is not the intended recipient, or an employee or agent
     responsible for delivering this message to the intended recipient,
     you are hereby notified that any reading, dissemination, distribution,
     copying, or other use of this communication or any of its attachments
     is strictly prohibited.  If you have received this communication in
     error, please notify the sender immediately by replying to this message
     and deleting this message, any attachments, and all copies and backups
     from your computer.


From petr.pikal at precheza.cz  Thu Apr 27 08:33:30 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Apr 2017 06:33:30 +0000
Subject: [R] [FORGED]  missing and replace
In-Reply-To: <2022e01c-fc48-8ed8-07da-6425f94090d0@auckland.ac.nz>
References: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
 <2022e01c-fc48-8ed8-07da-6425f94090d0@auckland.ac.nz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF99824E@SRVEXCHCM301.precheza.cz>

Hi

not sure if sexiest but zoo package has several functions for replacing missing values.

as.data.frame(lapply(DF1, function(x) na.aggregate(x, FUN=function(y) round(mean(y)))))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf
> Turner
> Sent: Thursday, April 27, 2017 3:17 AM
> To: Val <valkremk at gmail.com>
> Cc: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] [FORGED] missing and replace
>
> On 27/04/17 12:45, Val wrote:
> > HI all,
> >
> > I have a data frame with three variables. Some of the variables do
> > have missing values and I want to replace those missing values
> > (1represented by NA) with the mean value of that variable. In this
> > sample data,  variable z and y do have missing values. The mean value
> > of y  and z are152. 25  and 359.5, respectively . I want replace those
> > missing values  by the respective mean value ( rounded to the nearest
> > whole number).
> >
> > DF1 <- read.table(header=TRUE, text='ID1 x y z
> > 1  25  122    352
> > 2  30  135    376
> > 3  40   NA    350
> > 4  26  157    NA
> > 5  60  195    360')
> > mean x= 36.2
> > mean y=152.25
> > mean z= 359.5
> >
> > output
> > ID1  x  y  z
> > 1   25 122   352
> > 2   30 135   376
> > 3   40 152   350
> > 4   26 157   360
> > 5   60 195   360
>
> This is pretty basic.  You really ought to learn a bit more about R if you are
> going to use R.  That being said, try:
>
> newDF1 <- as.data.frame(lapply(DF1,function(x){
>                          x[is.na(x)] <- mean(x,na.rm=TRUE)
>                          x}))
>
> There may be sexier ways of accomplishing your goal, but this should work.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dhiv.shreya at gmail.com  Thu Apr 27 07:40:50 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Thu, 27 Apr 2017 11:10:50 +0530
Subject: [R] Problem in conversion of regulate time series and forecasting
 using Date Time [Timestamp values]:R
Message-ID: <CACmggQvChjGQmNjm8dROkVc3mEbcsfpV=FkwWVQ=_eG-RuuZYQ@mail.gmail.com>

Hi,
I have a data frame "gg", that looks like this:

> head(gg)

           timestamps      value
1 2017-04-25 16:52:00 -0.4120000
2 2017-04-25 16:53:00 -0.4526667
3 2017-04-25 16:54:00 -0.4586667
4 2017-04-25 16:55:00 -0.4606667
5 2017-04-25 16:56:00 -0.5053333
6 2017-04-25 16:57:00 -0.5066667

I need to plot this as a Time series data to do forecasting. The steps are
as follows:

1) gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d %H-%M-%S")
 #changing "Timestamps" column 'factor' to 'as.POSIXct'.

2) gg.ts <- xts(x=gg$value, order.by = gg$timestamps) #converting the
dataframe to time series (Non Regular Time series)

3) fitting <- auto.arima(gg.ts) #fitting the time series model using
auto.arima

4) fore <- forecast(fitting, h=30, level = c(80,95))  #Forecasting

5) I am using plotly to this forecast model (Inspired from here :
https://plot.ly/r/graphing-multiple-chart-types/#plotting-forecast-objects)

plot_ly() %>%
  add_lines(x = time(gg.ts), y = gg.ts,
            color = I("black"), name = "observed") %>%
  add_ribbons(x = time(fore$mean), ymin = fore$lower[, 2], ymax =
fore$upper[, 2],
              color = I("gray95"), name = "95% confidence") %>%
  add_ribbons(x = time(fore$mean), ymin = fore$lower[, 1], ymax =
fore$upper[, 1],
              color = I("gray80"), name = "80% confidence") %>%
  add_lines(x = time(fore$mean), y = fore$mean, color = I("blue"), name =
"prediction")


The plot comes out wrong: 1) x axis labels are wrong. It shows some
irrelevant values on axis. 2) the plot is not coming out.
Also I tried to convert "gg.ts" to a regulate time series which throws
error :

> gg.xts <- ts(gg.ts, frequency = '1', start = ('2017-04-25 16:52:00'))
Error in 1/frequency : non-numeric argument to binary operator

Please help me how to use Date Time values in converting to regulate time
series for forecasting.


Regards
> Dhivya

	[[alternative HTML version deleted]]


From dhiv.shreya at gmail.com  Thu Apr 27 08:51:37 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Thu, 27 Apr 2017 12:21:37 +0530
Subject: [R] Problem in conversion of regulate time series and forecasting
 using Date Time [Timestamp values]:R
Message-ID: <CACmggQucN25sGfqeGBg_6PvtQsnrqg4+sfab831PdosKWO1XbA@mail.gmail.com>

Hi,
I am new to R. Kindly help me with the plot that gives wrong x-axis
values.  I have a data frame "gg", that looks like this:

> head(gg)

           timestamps      value
1 2017-04-25 16:52:00 -0.4120000
2 2017-04-25 16:53:00 -0.4526667
3 2017-04-25 16:54:00 -0.4586667
4 2017-04-25 16:55:00 -0.4606667
5 2017-04-25 16:56:00 -0.5053333
6 2017-04-25 16:57:00 -0.5066667

I need to plot this as a Time series data to do forecasting. The steps are
as follows:

1) gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d %H-%M-%S")
 #changing "Timestamps" column 'factor' to 'as.POSIXct'.

2) gg.ts <- xts(x=gg$value, order.by = gg$timestamps) #converting the
dataframe to time series (Non Regular Time series)

3) fitting <- auto.arima(gg.ts) #fitting the time series model using
auto.arima

4) fore <- forecast(fitting, h=30, level = c(80,95))  #Forecasting

5) I am using plotly to this forecast model (Inspired from here :
https://plot.ly/r/graphing-multiple-chart-types/#plotting-forecast-objects)

plot_ly() %>%
  add_lines(x = time(gg.ts), y = gg.ts,
            color = I("black"), name = "observed") %>%
  add_ribbons(x = time(fore$mean), ymin = fore$lower[, 2], ymax =
fore$upper[, 2],
              color = I("gray95"), name = "95% confidence") %>%
  add_ribbons(x = time(fore$mean), ymin = fore$lower[, 1], ymax =
fore$upper[, 1],
              color = I("gray80"), name = "80% confidence") %>%
  add_lines(x = time(fore$mean), y = fore$mean, color = I("blue"), name =
"prediction")


The plot comes out wrong: 1) x axis labels are wrong. It shows some
irrelevant values on axis. 2) the plot is not coming out.
Also I tried to convert "gg.ts" to a regulate time series which throws
error :

> gg.xts <- ts(gg.ts, frequency = '1', start = ('2017-04-25 16:52:00'))
Error in 1/frequency : non-numeric argument to binary operator

Please help me how to use Date Time values in converting to regulate time
series for forecasting.


Regards
> Dhivya

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Thu Apr 27 12:08:39 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Thu, 27 Apr 2017 15:38:39 +0530
Subject: [R] Reading XML attriutes in R
Message-ID: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>

Hi All,

I have a XML file like :

<city id="2643743" name="London">
<coord lon="-0.13" lat="51.51"/>
<country>GB</country>
<sun rise="2017-01-30T07:40:36" set="2017-01-30T16:47:56"/>
</city>
<temperature value="280.15" min="278.15" max="281.15" unit="kelvin"/>
<humidity value="81" unit="%"/>
<pressure value="1012" unit="hPa"/>
<wind>
<speed value="4.6" name="Gentle Breeze"/>
<gusts/>
<direction value="90" code="E" name="East"/>
</wind>
<clouds value="90" name="overcast clouds"/>
<visibility value="10000"/>
<precipitation mode="no"/>
<weather number="701" value="mist" icon="50d"/>
<lastupdate value="2017-01-30T15:50:00"/>
</current>

I want to create a data frame out of this XML but
obviously xmlToDataFrame() is not working.

It has dynamic attributes like for node precipitation , it could have
attributes like value and mode both if there is ppt in some city.

My basic issue now id to read XML attributes of different nodes and convert
it into a data frame, I have scraped many forums but could not find any
help in this.

For starters, please suggest a solution to parse the value of city node and
corresponding id, name, lat, long etc.

I know I am asking a lot, thanks for reading and cheers! :)

-- 
Regards
Archit

	[[alternative HTML version deleted]]


From fneiman at monticello.org  Thu Apr 27 13:20:33 2017
From: fneiman at monticello.org (Fraser D. Neiman)
Date: Thu, 27 Apr 2017 11:20:33 +0000
Subject: [R] missing and replace
In-Reply-To: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
References: <CAJOiR6ZRGKe7+11PvK45zGwP6ETesrwhbzo_AFTK_3Ljn5B-PQ@mail.gmail.com>
Message-ID: <2176AD174D58CB4ABBDA99F3458C20174404F28A@GRANGER.monticello.org>

Dear All,

Replacing  missing values with means is generally not a good idea:

"Perhaps the easiest way to impute is to replace each missing
value with the mean of the observed values for that variable. Unfortunately, this
strategy can severely distort the distribution for this variable, leading to complications
with summary measures including, notably, underestimates of the standard
deviation. Moreover, mean imputation distorts relationships between variables by
?pulling? estimates of the correlation toward zero."

That's from Gelman and Hill -- more here : http://www.stat.columbia.edu/~gelman/arm/missing.pdf


best, Fraser

________________________________________
From: Val [valkremk at gmail.com]
Sent: Wednesday, April 26, 2017 8:45 PM
To: r-help at R-project.org (r-help at r-project.org)
Subject: [R] missing and replace

HI all,

I have a data frame with three variables. Some of the variables do
have missing values and I want to replace those missing values
(1represented by NA) with the mean value of that variable. In this
sample data,  variable z and y do have missing values. The mean value
of y  and z are152. 25  and 359.5, respectively . I want replace those
missing values  by the respective mean value ( rounded to the nearest
whole number).

DF1 <- read.table(header=TRUE, text='ID1 x y z
1  25  122    352
2  30  135    376
3  40   NA    350
4  26  157    NA
5  60  195    360')
mean x= 36.2
mean y=152.25
mean z= 359.5

output
ID1  x  y  z
1   25 122   352
2   30 135   376
3   40 152   350
4   26 157   360
5   60 195   360


Thank you in advance

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Thu Apr 27 14:29:31 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 27 Apr 2017 07:29:31 -0500
Subject: [R] survival package can't find Ccoxfit6
Message-ID: <47cabe$6aa946@ironport10.mayo.edu>

  Let me summarize rather than repeat the entire thread:

An error report from a user (seshan) stumped me, and I asked for help here.

Duncan Murdoch picked up on fine details of the error message, i.e., that the error did 
NOT come from within the survival package.  That changes the whole tenor of the discussion.

Indeed, the user has their own function "phcoefs" that directly calls one of my internal C 
routines.  As of R 3.4, this can only be done for routines that I explicitly export.   I 
don't export coxfit6.c.

Where to go from here?

1. I'm not against exporting a routine, but I'm not going to do it without a discussion.  
Doing so is more work for me: I'd need to write a test routine in order to ensure 
long-term reliability of the export, and it ties my hands wrt future changes.  In this 
partiuclar case, why not use coxph.fit?

2. One of the design goals for the survival package is to make it usable as a component 
for other's work.  For instance all of the return structures are easily inspected (no S4 
classes) and most are carefully documented e.g. help(coxph.object).  The core computations 
of coxph are split out into separate functions coxph.fit and agreg.fit, so that they can 
be called directly without the formula and argument checking overhead.  Ditto for survreg, 
survifit, survdiff and concordance.  Given the number of other packages that depend on 
survival I have been at least moderately successful at this aim.  (To be honest this is 
not entirely alturism on my part as it stops the near infinite requests to add one 'just 
one more thing' to the package.)  This also means I am open to modifying a routine or 
exporting a call -- if you can make a good argument.

3. I need a good way to document this for the survival package. Yet one more chapter in my 
1/2 written book. Someday...

4. Calling another package's C routines is dangerous, and one of the goals of the 3.4 
namespace changes was to stop this from happening willy-nilly.  The new error messages 
look like success.   Though it means that I'm getting multiple "not found" emails.

Terry T.


From btupper at bigelow.org  Thu Apr 27 14:57:10 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 27 Apr 2017 08:57:10 -0400
Subject: [R] Reading XML attriutes in R
In-Reply-To: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>
References: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>
Message-ID: <E1259022-E9F1-41D0-8953-A529E40D0514@bigelow.org>

Hi,

There might be an easy solution out there already, but I suspect that you will need to parse the XML yourself.  The example below uses package xml2 not XML but you could do this with either.  The example simply shows how to get values out of the XML hierarchy.  Once you have the attributes you want in hand you can assemble the elements into a data frame (or a tibble from package tibble.)
 
By the way, I had to prepend your example with '<current>'

Cheers,
Ben

### START

library(tidyverse)
library(xml2)

txt <- "<current><city id=\"2643743\" name=\"London\"><coord lon=\"-0.13\" lat=\"51.51\"/><country>GB</country><sun rise=\"2017-01-30T07:40:36\" set=\"2017-01-30T16:47:56\"/></city><temperature value=\"280.15\" min=\"278.15\" max=\"281.15\" unit=\"kelvin\"/><humidity value=\"81\" unit=\"%\"/><pressure value=\"1012\" unit=\"hPa\"/><wind><speed value=\"4.6\" name=\"Gentle Breeze\"/><gusts/><direction value=\"90\" code=\"E\" name=\"East\"/></wind><clouds value=\"90\" name=\"overcast clouds\"/><visibility value=\"10000\"/><precipitation mode=\"no\"/><weather number=\"701\" value=\"mist\" icon=\"50d\"/><lastupdate value=\"2017-01-30T15:50:00\"/></current>"

x <- read_xml(txt)

windspeed <- x %>% 
    xml_find_first("wind/speed") %>% 
    xml_attrs()
    
winddir <- x %>% 
    xml_find_first("wind/direction") %>% 
    xml_attrs()
    
windspeed
#          value            name 
#          "4.6" "Gentle Breeze" 

winddir
#  value   code   name 
#  "90"    "E" "East" 

### END



> On Apr 27, 2017, at 6:08 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> 
> Hi All,
> 
> I have a XML file like :
> 
> <city id="2643743" name="London">
> <coord lon="-0.13" lat="51.51"/>
> <country>GB</country>
> <sun rise="2017-01-30T07:40:36" set="2017-01-30T16:47:56"/>
> </city>
> <temperature value="280.15" min="278.15" max="281.15" unit="kelvin"/>
> <humidity value="81" unit="%"/>
> <pressure value="1012" unit="hPa"/>
> <wind>
> <speed value="4.6" name="Gentle Breeze"/>
> <gusts/>
> <direction value="90" code="E" name="East"/>
> </wind>
> <clouds value="90" name="overcast clouds"/>
> <visibility value="10000"/>
> <precipitation mode="no"/>
> <weather number="701" value="mist" icon="50d"/>
> <lastupdate value="2017-01-30T15:50:00"/>
> </current>
> 
> I want to create a data frame out of this XML but
> obviously xmlToDataFrame() is not working.
> 
> It has dynamic attributes like for node precipitation , it could have
> attributes like value and mode both if there is ppt in some city.
> 
> My basic issue now id to read XML attributes of different nodes and convert
> it into a data frame, I have scraped many forums but could not find any
> help in this.
> 
> For starters, please suggest a solution to parse the value of city node and
> corresponding id, name, lat, long etc.
> 
> I know I am asking a lot, thanks for reading and cheers! :)
> 
> -- 
> Regards
> Archit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From therneau at mayo.edu  Thu Apr 27 17:41:16 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 27 Apr 2017 10:41:16 -0500
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
References: <47cabe$6aa945@ironport10.mayo.edu>
 <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <47cabe$6adci1@ironport10.mayo.edu>



On 04/27/2017 09:53 AM, SeshanV at mskcc.org wrote:
> Thank you Drs. Therneau and Murdoch.
>
> "Why not use coxph.fit?" -- My use case scenario is that I needed the Cox model coefficients for resampled data. I was trying to reduce the computational overhead of coxph.fit (since it will repeated a large number of times) by stripping all the parts that I don't need such as sorting of the data prior to coxfit6.c call and Martingale residual and concordance computations after the parameters are estimated.

That is an interesting use case which I had not thought about.  The first question is just 
how much slower coxph.fit is than the stripped down version (I'd guess about 1/2 but that 
is just a guess), and whether that makes a real difference to your code.  If it is 
spending 10% of its time in the coxph calculation a change to 5% isn't that much, but 90% 
is something else.  The next is what is the main impediment (I'd guess concordance, but 
again just a guess.)   Perhaps I could add concordance= and/or resid= flags to the fitting 
routine.

>
> Under the R v3.4.0 model one cannot create any modified form of coxph.fit and expect it to work. Worse yet is the following where I copy "coxph.fit" to my workspace as "mycoxph.fit" (works initially because the environment is namespace:survival and fails when environment changed to R_GlobalEnv)
>

If you were under linux another solution would be to grab the source from github, add your 
routine to the R/ directory, then R CMD build followed by R CMD INSTALL.  Macintosh is 
essentially as easy, though you need to install Xcode for the compilers.  The compile 
toolchain for windows is outside my ken.

Let's keep talking.

Terry T.


From murdoch.duncan at gmail.com  Thu Apr 27 18:54:41 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Apr 2017 12:54:41 -0400
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
References: <47cabe$6aa945@ironport10.mayo.edu>
 <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <997ddcee-b606-3dca-22be-c00bf52c6716@gmail.com>

On 27/04/2017 10:53 AM, SeshanV at mskcc.org wrote:
> Thank you Drs. Therneau and Murdoch.
>
> "Why not use coxph.fit?" -- My use case scenario is that I needed the Cox model coefficients for resampled data. I was trying to reduce the computational overhead of coxph.fit (since it will repeated a large number of times) by stripping all the parts that I don't need such as sorting of the data prior to coxfit6.c call and Martingale residual and concordance computations after the parameters are estimated.
>
> Under the R v3.4.0 model one cannot create any modified form of coxph.fit and expect it to work. Worse yet is the following where I copy "coxph.fit" to my workspace as "mycoxph.fit" (works initially because the environment is namespace:survival and fails when environment changed to R_GlobalEnv)

Under the R 3.3.1 model the problems are the same.  When a change is 
made to the internals, your code will break.  That's why your code broke.

>
>> set.seed(12345)
>> x <- rep(0:1, c(20,20))
>> y <- cbind(c(-log(runif(20)), -2*log(runif(20))), rep(1,40))
>> mycoxph.fit <- coxph.fit
>> control <- coxph.control()
>> oo1 <- coxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
>> oo2 <- mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
>> all.equal(oo1, oo2)
> [1] TRUE
>> environment(mycoxph.fit)
> <environment: namespace:survival>
>> environment(mycoxph.fit) <- .GlobalEnv
>> environment(mycoxph.fit)
> <environment: R_GlobalEnv>
>> mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
> Error in mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control,  :
>   object 'Ccoxfit6' not found
>
> So the question is can a user create new functions modeled after existing functions os is the new model going to hinder it?

The new model actually helps in this.  It offers the possibility that 
the run-time code will detect internal changes that break your code, 
rather than segfaulting when the argument list is wrong.

Duncan Murdoch


From drjimlemon at gmail.com  Thu Apr 27 23:49:32 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 28 Apr 2017 07:49:32 +1000
Subject: [R] Problem in conversion of regulate time series and
 forecasting using Date Time [Timestamp values]:R
In-Reply-To: <CACmggQucN25sGfqeGBg_6PvtQsnrqg4+sfab831PdosKWO1XbA@mail.gmail.com>
References: <CACmggQucN25sGfqeGBg_6PvtQsnrqg4+sfab831PdosKWO1XbA@mail.gmail.com>
Message-ID: <CA+8X3fW4tb8-MCkh5ZApdgq0RTt3+mz1BBvMF3gqYY=Q7xq4jA@mail.gmail.com>

Hi Dhivya,
I'm not that familiar with the "gg.ts" function, but you are passing
character values to the "frequency" and "start" arguments. If there is
no automatic conversion to numeric values, that would cause the error.
Similarly, your "timestamps" variable may have been read in as a
factor, which often causes trouble with date conversions. Try
as.character(gg$timestamps) instead of just gg$timestamps.

Jim


On Thu, Apr 27, 2017 at 4:51 PM, Dhivya Narayanasamy
<dhiv.shreya at gmail.com> wrote:
> Hi,
> I am new to R. Kindly help me with the plot that gives wrong x-axis
> values.  I have a data frame "gg", that looks like this:
>
>> head(gg)
>
>            timestamps      value
> 1 2017-04-25 16:52:00 -0.4120000
> 2 2017-04-25 16:53:00 -0.4526667
> 3 2017-04-25 16:54:00 -0.4586667
> 4 2017-04-25 16:55:00 -0.4606667
> 5 2017-04-25 16:56:00 -0.5053333
> 6 2017-04-25 16:57:00 -0.5066667
>
> I need to plot this as a Time series data to do forecasting. The steps are
> as follows:
>
> 1) gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d %H-%M-%S")
>  #changing "Timestamps" column 'factor' to 'as.POSIXct'.
>
> 2) gg.ts <- xts(x=gg$value, order.by = gg$timestamps) #converting the
> dataframe to time series (Non Regular Time series)
>
> 3) fitting <- auto.arima(gg.ts) #fitting the time series model using
> auto.arima
>
> 4) fore <- forecast(fitting, h=30, level = c(80,95))  #Forecasting
>
> 5) I am using plotly to this forecast model (Inspired from here :
> https://plot.ly/r/graphing-multiple-chart-types/#plotting-forecast-objects)
>
> plot_ly() %>%
>   add_lines(x = time(gg.ts), y = gg.ts,
>             color = I("black"), name = "observed") %>%
>   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 2], ymax =
> fore$upper[, 2],
>               color = I("gray95"), name = "95% confidence") %>%
>   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 1], ymax =
> fore$upper[, 1],
>               color = I("gray80"), name = "80% confidence") %>%
>   add_lines(x = time(fore$mean), y = fore$mean, color = I("blue"), name =
> "prediction")
>
>
> The plot comes out wrong: 1) x axis labels are wrong. It shows some
> irrelevant values on axis. 2) the plot is not coming out.
> Also I tried to convert "gg.ts" to a regulate time series which throws
> error :
>
>> gg.xts <- ts(gg.ts, frequency = '1', start = ('2017-04-25 16:52:00'))
> Error in 1/frequency : non-numeric argument to binary operator
>
> Please help me how to use Date Time values in converting to regulate time
> series for forecasting.
>
>
> Regards
>> Dhivya
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From SeshanV at mskcc.org  Thu Apr 27 16:53:43 2017
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Thu, 27 Apr 2017 14:53:43 +0000
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <47cabe$6aa945@ironport10.mayo.edu>
References: <47cabe$6aa945@ironport10.mayo.edu>
Message-ID: <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>

Thank you Drs. Therneau and Murdoch.

"Why not use coxph.fit?" -- My use case scenario is that I needed the Cox model coefficients for resampled data. I was trying to reduce the computational overhead of coxph.fit (since it will repeated a large number of times) by stripping all the parts that I don't need such as sorting of the data prior to coxfit6.c call and Martingale residual and concordance computations after the parameters are estimated. 

Under the R v3.4.0 model one cannot create any modified form of coxph.fit and expect it to work. Worse yet is the following where I copy "coxph.fit" to my workspace as "mycoxph.fit" (works initially because the environment is namespace:survival and fails when environment changed to R_GlobalEnv)

> set.seed(12345)
> x <- rep(0:1, c(20,20))
> y <- cbind(c(-log(runif(20)), -2*log(runif(20))), rep(1,40))
> mycoxph.fit <- coxph.fit
> control <- coxph.control()
> oo1 <- coxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
> oo2 <- mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
> all.equal(oo1, oo2)
[1] TRUE
> environment(mycoxph.fit)
<environment: namespace:survival>
> environment(mycoxph.fit) <- .GlobalEnv
> environment(mycoxph.fit)
<environment: R_GlobalEnv>
> mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control, NULL, "efron", NULL)
Error in mycoxph.fit(as.matrix(as.double(x)), y, NULL, NULL, NULL, control,  : 
  object 'Ccoxfit6' not found

So the question is can a user create new functions modeled after existing functions os is the new model going to hinder it?

Thanks,
Venkat


-----Original Message-----
From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] 
Sent: Thursday, April 27, 2017 8:30 AM
To: R-help
Cc: Duncan Murdoch; Seshan, Venkatraman E./Epidemiology-Biostatistics
Subject: Re: survival package can't find Ccoxfit6

  Let me summarize rather than repeat the entire thread:

An error report from a user (seshan) stumped me, and I asked for help here.

Duncan Murdoch picked up on fine details of the error message, i.e., that the error did NOT come from within the survival package.  That changes the whole tenor of the discussion.

Indeed, the user has their own function "phcoefs" that directly calls one of my internal C 
routines.  As of R 3.4, this can only be done for routines that I explicitly export.   I 
don't export coxfit6.c.

Where to go from here?

1. I'm not against exporting a routine, but I'm not going to do it without a discussion.  
Doing so is more work for me: I'd need to write a test routine in order to ensure long-term reliability of the export, and it ties my hands wrt future changes.  In this partiuclar case, why not use coxph.fit?

2. One of the design goals for the survival package is to make it usable as a component for other's work.  For instance all of the return structures are easily inspected (no S4
classes) and most are carefully documented e.g. help(coxph.object).  The core computations of coxph are split out into separate functions coxph.fit and agreg.fit, so that they can be called directly without the formula and argument checking overhead.  Ditto for survreg, survifit, survdiff and concordance.  Given the number of other packages that depend on survival I have been at least moderately successful at this aim.  (To be honest this is not entirely alturism on my part as it stops the near infinite requests to add one 'just one more thing' to the package.)  This also means I am open to modifying a routine or exporting a call -- if you can make a good argument.

3. I need a good way to document this for the survival package. Yet one more chapter in my
1/2 written book. Someday...

4. Calling another package's C routines is dangerous, and one of the goals of the 3.4 namespace changes was to stop this from happening willy-nilly.  The new error messages 
look like success.   Though it means that I'm getting multiple "not found" emails.

Terry T.






=====================================================================

     Please note that this e-mail and any files transmitted from
     Memorial Sloan Kettering Cancer Center may be privileged, confidential,
     and protected from disclosure under applicable law. If the reader of
     this message is not the intended recipient, or an employee or agent
     responsible for delivering this message to the intended recipient,
     you are hereby notified that any reading, dissemination, distribution,
     copying, or other use of this communication or any of its attachments
     is strictly prohibited.  If you have received this communication in
     error, please notify the sender immediately by replying to this message
     and deleting this message, any attachments, and all copies and backups
     from your computer.

From SeshanV at mskcc.org  Thu Apr 27 18:04:08 2017
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Thu, 27 Apr 2017 16:04:08 +0000
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <47cabe$6adci0@ironport10.mayo.edu>
References: <47cabe$6aa945@ironport10.mayo.edu>
 <CDC04FFA7FC22548ADD6AECFA993565DE5CBADB1@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6adci0@ironport10.mayo.edu>
Message-ID: <CDC04FFA7FC22548ADD6AECFA993565DE5CBAF35@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>

Since my coding philosophy is "why compute something that is not needed" I don't have timing data comparing coxph.fit to the stripped down version. I will try to come up with a test suite.

I do work under Linux (the initial Windows output was because I had both 3.3.1 and 3.4.0 on that machine). So I can get the source code and build the necessary parts into my function/package, but doesn't it defeat the purpose of reusable code?

Thanks,
Venkat

-----Original Message-----
From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] 
Sent: Thursday, April 27, 2017 11:41 AM
To: Seshan, Venkatraman E./Epidemiology-Biostatistics; Therneau, Terry M., Ph.D.; r-help
Cc: murdoch.duncan at gmail.com
Subject: Re: survival package can't find Ccoxfit6



On 04/27/2017 09:53 AM, SeshanV at mskcc.org wrote:
> Thank you Drs. Therneau and Murdoch.
>
> "Why not use coxph.fit?" -- My use case scenario is that I needed the Cox model coefficients for resampled data. I was trying to reduce the computational overhead of coxph.fit (since it will repeated a large number of times) by stripping all the parts that I don't need such as sorting of the data prior to coxfit6.c call and Martingale residual and concordance computations after the parameters are estimated.

That is an interesting use case which I had not thought about.  The first question is just how much slower coxph.fit is than the stripped down version (I'd guess about 1/2 but that is just a guess), and whether that makes a real difference to your code.  If it is spending 10% of its time in the coxph calculation a change to 5% isn't that much, but 90% is something else.  The next is what is the main impediment (I'd guess concordance, but 
again just a guess.)   Perhaps I could add concordance= and/or resid= flags to the fitting 
routine.

>
> Under the R v3.4.0 model one cannot create any modified form of 
> coxph.fit and expect it to work. Worse yet is the following where I 
> copy "coxph.fit" to my workspace as "mycoxph.fit" (works initially 
> because the environment is namespace:survival and fails when 
> environment changed to R_GlobalEnv)
>

If you were under linux another solution would be to grab the source from github, add your routine to the R/ directory, then R CMD build followed by R CMD INSTALL.  Macintosh is essentially as easy, though you need to install Xcode for the compilers.  The compile toolchain for windows is outside my ken.

Let's keep talking.

Terry T.

=====================================================================

     Please note that this e-mail and any files transmitted from
     Memorial Sloan Kettering Cancer Center may be privileged, confidential,
     and protected from disclosure under applicable law. If the reader of
     this message is not the intended recipient, or an employee or agent
     responsible for delivering this message to the intended recipient,
     you are hereby notified that any reading, dissemination, distribution,
     copying, or other use of this communication or any of its attachments
     is strictly prohibited.  If you have received this communication in
     error, please notify the sender immediately by replying to this message
     and deleting this message, any attachments, and all copies and backups
     from your computer.

From arbautjc at gmail.com  Thu Apr 27 19:55:56 2017
From: arbautjc at gmail.com (Jean-Claude Arbaut)
Date: Thu, 27 Apr 2017 19:55:56 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
Message-ID: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>

Hello,

I am currently getting a strange error when I call installed.packages():

Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
  missing value where TRUE/FALSE needed
Calls: installed.packages


I am working with R 3.4.0 on Windows. I didn't get this error with R 3.3.3.
Apparently, file.mtime() is returning NA well applied to a directory, and
this causes the entire && expression to be NA, then the "if" fails because
it needs either T or F.
The source of "installed.packages" seems to be roughly the same as in R
3.3.3, so I wonder if there have been other changes in R, maybe the logical
operators, that would make this function fail.

Any idea?

Best regards,

Jean-Claude Arbaut

	[[alternative HTML version deleted]]


From bianca12_domi at hotmail.com  Thu Apr 27 21:10:04 2017
From: bianca12_domi at hotmail.com (Biank M)
Date: Thu, 27 Apr 2017 19:10:04 +0000
Subject: [R] gap.barplot with means and standard error bars
Message-ID: <CY4PR06MB301494149B7F4705D0622C0A9A100@CY4PR06MB3014.namprd06.prod.outlook.com>

Hi..


I've been trying to create a barplot with the following data:


SA<- c(0.06, 0.061, 0.06, 0.06, 0.06)
AA<- c(0.29, 0.275, 0.271, 0.274, 0.276)
CA<- c(266.783, 257.726, 276.331, 268.859, 265.042)


I want a bar for "SA", a bar for "AA", and a bar for "CA" (x- axis). The height of the bar must be represented by the mean of each vector data and include SE bars. Since there are very very large differences in numbers , I want to add a gap between 1 and 250 (y-axis).


I know that the gap.barplot function is used to produce the gap, but I don't know how to include the means and SE bars.

Can you help me creating this plot??


Thank you very much!!


Greetings,

Bianca

	[[alternative HTML version deleted]]


From dhiv.shreya at gmail.com  Fri Apr 28 06:32:44 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Fri, 28 Apr 2017 10:02:44 +0530
Subject: [R] Problem in conversion of regulate time series and
 forecasting using Date Time [Timestamp values]:R
In-Reply-To: <CA+8X3fW4tb8-MCkh5ZApdgq0RTt3+mz1BBvMF3gqYY=Q7xq4jA@mail.gmail.com>
References: <CACmggQucN25sGfqeGBg_6PvtQsnrqg4+sfab831PdosKWO1XbA@mail.gmail.com>
 <CA+8X3fW4tb8-MCkh5ZApdgq0RTt3+mz1BBvMF3gqYY=Q7xq4jA@mail.gmail.com>
Message-ID: <CACmggQu+MKFW-Ux3RwFVYsf65MG7KJO9oPkoiMAw=2HGTufhSQ@mail.gmail.com>

Hi Jim,

Thank you for the reply. 'gg.ts' is actually the object name of the time
series I am using here.  Also I have changed my timestamp class from factor
to POSIXct  (gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d
%H-%M-%S") . When i plot this time series on graph, the x axis scales shows
random value rather than showing timestamp value. Is there any way to
correct the graph to make it show the timestamp value on x axis?  I use
plotly function for plotting.

Regards| Mit freundlichen Gr??en,

Dhivya Narayanasamy

Contact No: +91-8438505020

On Fri, Apr 28, 2017 at 3:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Dhivya,
> I'm not that familiar with the "gg.ts" function, but you are passing
> character values to the "frequency" and "start" arguments. If there is
> no automatic conversion to numeric values, that would cause the error.
> Similarly, your "timestamps" variable may have been read in as a
> factor, which often causes trouble with date conversions. Try
> as.character(gg$timestamps) instead of just gg$timestamps.
>
> Jim
>
>
> On Thu, Apr 27, 2017 at 4:51 PM, Dhivya Narayanasamy
> <dhiv.shreya at gmail.com> wrote:
> > Hi,
> > I am new to R. Kindly help me with the plot that gives wrong x-axis
> > values.  I have a data frame "gg", that looks like this:
> >
> >> head(gg)
> >
> >            timestamps      value
> > 1 2017-04-25 16:52:00 -0.4120000
> > 2 2017-04-25 16:53:00 -0.4526667
> > 3 2017-04-25 16:54:00 -0.4586667
> > 4 2017-04-25 16:55:00 -0.4606667
> > 5 2017-04-25 16:56:00 -0.5053333
> > 6 2017-04-25 16:57:00 -0.5066667
> >
> > I need to plot this as a Time series data to do forecasting. The steps
> are
> > as follows:
> >
> > 1) gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d
> %H-%M-%S")
> >  #changing "Timestamps" column 'factor' to 'as.POSIXct'.
> >
> > 2) gg.ts <- xts(x=gg$value, order.by = gg$timestamps) #converting the
> > dataframe to time series (Non Regular Time series)
> >
> > 3) fitting <- auto.arima(gg.ts) #fitting the time series model using
> > auto.arima
> >
> > 4) fore <- forecast(fitting, h=30, level = c(80,95))  #Forecasting
> >
> > 5) I am using plotly to this forecast model (Inspired from here :
> > https://plot.ly/r/graphing-multiple-chart-types/#
> plotting-forecast-objects)
> >
> > plot_ly() %>%
> >   add_lines(x = time(gg.ts), y = gg.ts,
> >             color = I("black"), name = "observed") %>%
> >   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 2], ymax =
> > fore$upper[, 2],
> >               color = I("gray95"), name = "95% confidence") %>%
> >   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 1], ymax =
> > fore$upper[, 1],
> >               color = I("gray80"), name = "80% confidence") %>%
> >   add_lines(x = time(fore$mean), y = fore$mean, color = I("blue"), name =
> > "prediction")
> >
> >
> > The plot comes out wrong: 1) x axis labels are wrong. It shows some
> > irrelevant values on axis. 2) the plot is not coming out.
> > Also I tried to convert "gg.ts" to a regulate time series which throws
> > error :
> >
> >> gg.xts <- ts(gg.ts, frequency = '1', start = ('2017-04-25 16:52:00'))
> > Error in 1/frequency : non-numeric argument to binary operator
> >
> > Please help me how to use Date Time values in converting to regulate time
> > series for forecasting.
> >
> >
> > Regards
> >> Dhivya
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Apr 28 07:47:57 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 28 Apr 2017 07:47:57 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
Message-ID: <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>

We have several computers with the same problem.

Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com>:

Hello,

I am currently getting a strange error when I call installed.packages():

Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
  missing value where TRUE/FALSE needed
Calls: installed.packages


I am working with R 3.4.0 on Windows. I didn't get this error with R 3.3.3.
Apparently, file.mtime() is returning NA well applied to a directory, and
this causes the entire && expression to be NA, then the "if" fails because
it needs either T or F.
The source of "installed.packages" seems to be roughly the same as in R
3.3.3, so I wonder if there have been other changes in R, maybe the logical
operators, that would make this function fail.

Any idea?

Best regards,

Jean-Claude Arbaut

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Apr 28 07:48:09 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 27 Apr 2017 22:48:09 -0700
Subject: [R] Problem in conversion of regulate time series and
	forecasting using Date Time [Timestamp values]:R
In-Reply-To: <CACmggQu+MKFW-Ux3RwFVYsf65MG7KJO9oPkoiMAw=2HGTufhSQ@mail.gmail.com>
References: <CACmggQucN25sGfqeGBg_6PvtQsnrqg4+sfab831PdosKWO1XbA@mail.gmail.com>
 <CA+8X3fW4tb8-MCkh5ZApdgq0RTt3+mz1BBvMF3gqYY=Q7xq4jA@mail.gmail.com>
 <CACmggQu+MKFW-Ux3RwFVYsf65MG7KJO9oPkoiMAw=2HGTufhSQ@mail.gmail.com>
Message-ID: <A9275394-B99D-43DC-B519-82667353FB6A@dcn.davis.ca.us>

gg$timestamps <- as.POSIXct(as.character( gg$timestamps ) )

Factors are integers with the appearance of character data, so you are converting the integers to POSIXct. I usually try to avoid letting R automatically convert character data to factors, e.g. using stringsAsFactors=FALSE in read.csv so I don't have to convert them back from factors to manipulate them. 
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2017 9:32:44 PM PDT, Dhivya Narayanasamy <dhiv.shreya at gmail.com> wrote:
>Hi Jim,
>
>Thank you for the reply. 'gg.ts' is actually the object name of the
>time
>series I am using here.  Also I have changed my timestamp class from
>factor
>to POSIXct  (gg$timestamps <- as.POSIXct(gg$timestamps, format =
>"%Y-%m-%d
>%H-%M-%S") . When i plot this time series on graph, the x axis scales
>shows
>random value rather than showing timestamp value. Is there any way to
>correct the graph to make it show the timestamp value on x axis?  I use
>plotly function for plotting.
>
>Regards| Mit freundlichen Gr??en,
>
>Dhivya Narayanasamy
>
>Contact No: +91-8438505020
>
>On Fri, Apr 28, 2017 at 3:19 AM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>
>> Hi Dhivya,
>> I'm not that familiar with the "gg.ts" function, but you are passing
>> character values to the "frequency" and "start" arguments. If there
>is
>> no automatic conversion to numeric values, that would cause the
>error.
>> Similarly, your "timestamps" variable may have been read in as a
>> factor, which often causes trouble with date conversions. Try
>> as.character(gg$timestamps) instead of just gg$timestamps.
>>
>> Jim
>>
>>
>> On Thu, Apr 27, 2017 at 4:51 PM, Dhivya Narayanasamy
>> <dhiv.shreya at gmail.com> wrote:
>> > Hi,
>> > I am new to R. Kindly help me with the plot that gives wrong x-axis
>> > values.  I have a data frame "gg", that looks like this:
>> >
>> >> head(gg)
>> >
>> >            timestamps      value
>> > 1 2017-04-25 16:52:00 -0.4120000
>> > 2 2017-04-25 16:53:00 -0.4526667
>> > 3 2017-04-25 16:54:00 -0.4586667
>> > 4 2017-04-25 16:55:00 -0.4606667
>> > 5 2017-04-25 16:56:00 -0.5053333
>> > 6 2017-04-25 16:57:00 -0.5066667
>> >
>> > I need to plot this as a Time series data to do forecasting. The
>steps
>> are
>> > as follows:
>> >
>> > 1) gg$timestamps <- as.POSIXct(gg$timestamps, format = "%Y-%m-%d
>> %H-%M-%S")
>> >  #changing "Timestamps" column 'factor' to 'as.POSIXct'.
>> >
>> > 2) gg.ts <- xts(x=gg$value, order.by = gg$timestamps) #converting
>the
>> > dataframe to time series (Non Regular Time series)
>> >
>> > 3) fitting <- auto.arima(gg.ts) #fitting the time series model
>using
>> > auto.arima
>> >
>> > 4) fore <- forecast(fitting, h=30, level = c(80,95))  #Forecasting
>> >
>> > 5) I am using plotly to this forecast model (Inspired from here :
>> > https://plot.ly/r/graphing-multiple-chart-types/#
>> plotting-forecast-objects)
>> >
>> > plot_ly() %>%
>> >   add_lines(x = time(gg.ts), y = gg.ts,
>> >             color = I("black"), name = "observed") %>%
>> >   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 2], ymax =
>> > fore$upper[, 2],
>> >               color = I("gray95"), name = "95% confidence") %>%
>> >   add_ribbons(x = time(fore$mean), ymin = fore$lower[, 1], ymax =
>> > fore$upper[, 1],
>> >               color = I("gray80"), name = "80% confidence") %>%
>> >   add_lines(x = time(fore$mean), y = fore$mean, color = I("blue"),
>name =
>> > "prediction")
>> >
>> >
>> > The plot comes out wrong: 1) x axis labels are wrong. It shows some
>> > irrelevant values on axis. 2) the plot is not coming out.
>> > Also I tried to convert "gg.ts" to a regulate time series which
>throws
>> > error :
>> >
>> >> gg.xts <- ts(gg.ts, frequency = '1', start = ('2017-04-25
>16:52:00'))
>> > Error in 1/frequency : non-numeric argument to binary operator
>> >
>> > Please help me how to use Date Time values in converting to
>regulate time
>> > series for forecasting.
>> >
>> >
>> > Regards
>> >> Dhivya
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jake at jakestone.net  Fri Apr 28 07:54:00 2017
From: jake at jakestone.net (Jake Stone)
Date: Thu, 27 Apr 2017 22:54:00 -0700
Subject: [R] Root Dir for OpenCpu files
Message-ID: <CAL964UzqaV7gBqrLXy+=yCy6-5fmiSOuz+EMc=-fOaABXVXb=A@mail.gmail.com>

I have opencpu (single server) up and functioning. My first function will
open a dataset from a csv file stored on my hard drive.

Where should I deploy the csv file? (I tried my apps www directory, but it
doesn't work)

In sum: within an opencpu app, where do I deploy a file so that this line
of code will work?

indf <- read.csv(".\\nouns-categorical_R1.csv")

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Fri Apr 28 10:25:55 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Fri, 28 Apr 2017 13:55:55 +0530
Subject: [R] Reading XML attriutes in R
In-Reply-To: <E1259022-E9F1-41D0-8953-A529E40D0514@bigelow.org>
References: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>
 <E1259022-E9F1-41D0-8953-A529E40D0514@bigelow.org>
Message-ID: <CAJ7HxBws0OLPAyKN=TSq=tifHCCPULqFAmLa+0r3azafLB5G7Q@mail.gmail.com>

Thanks Ben, got it working, just want one more help on this,

If i have a node like: <precipitation mode="no"/> and in some other city it
came like:  <precipitation unit="3h" value="0.0925" type="rain"/>

How can i make my code to handle this dynamically? I am sorry to ask such
novice questions but it would be extremely helpful if you could help me
with this.

So, i would want my resulting data set from this code:- ppt <- (x %>%
xml_find_all("precipitation") %>% xml_attrs())
 if mode is no, then the three columns should come and values should be NA
and if values are populated then as is.

Unit     Value      Type
NA        NA         NA
3h        0.0925     rain

Thanks again and in advance !

Archit

On Thu, Apr 27, 2017 at 6:27 PM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> There might be an easy solution out there already, but I suspect that you
> will need to parse the XML yourself.  The example below uses package xml2
> not XML but you could do this with either.  The example simply shows how to
> get values out of the XML hierarchy.  Once you have the attributes you want
> in hand you can assemble the elements into a data frame (or a tibble from
> package tibble.)
>
> By the way, I had to prepend your example with '<current>'
>
> Cheers,
> Ben
>
> ### START
>
> library(tidyverse)
> library(xml2)
>
> txt <- "<current><city id=\"2643743\" name=\"London\"><coord lon=\"-0.13\"
> lat=\"51.51\"/><country>GB</country><sun rise=\"2017-01-30T07:40:36\"
> set=\"2017-01-30T16:47:56\"/></city><temperature value=\"280.15\"
> min=\"278.15\" max=\"281.15\" unit=\"kelvin\"/><humidity value=\"81\"
> unit=\"%\"/><pressure value=\"1012\" unit=\"hPa\"/><wind><speed
> value=\"4.6\" name=\"Gentle Breeze\"/><gusts/><direction value=\"90\"
> code=\"E\" name=\"East\"/></wind><clouds value=\"90\" name=\"overcast
> clouds\"/><visibility value=\"10000\"/><precipitation
> mode=\"no\"/><weather number=\"701\" value=\"mist\"
> icon=\"50d\"/><lastupdate value=\"2017-01-30T15:50:00\"/></current>"
>
> x <- read_xml(txt)
>
> windspeed <- x %>%
>     xml_find_first("wind/speed") %>%
>     xml_attrs()
>
> winddir <- x %>%
>     xml_find_first("wind/direction") %>%
>     xml_attrs()
>
> windspeed
> #          value            name
> #          "4.6" "Gentle Breeze"
>
> winddir
> #  value   code   name
> #  "90"    "E" "East"
>
> ### END
>
>
>
> > On Apr 27, 2017, at 6:08 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> >
> > Hi All,
> >
> > I have a XML file like :
> >
> > <city id="2643743" name="London">
> > <coord lon="-0.13" lat="51.51"/>
> > <country>GB</country>
> > <sun rise="2017-01-30T07:40:36" set="2017-01-30T16:47:56"/>
> > </city>
> > <temperature value="280.15" min="278.15" max="281.15" unit="kelvin"/>
> > <humidity value="81" unit="%"/>
> > <pressure value="1012" unit="hPa"/>
> > <wind>
> > <speed value="4.6" name="Gentle Breeze"/>
> > <gusts/>
> > <direction value="90" code="E" name="East"/>
> > </wind>
> > <clouds value="90" name="overcast clouds"/>
> > <visibility value="10000"/>
> > <precipitation mode="no"/>
> > <weather number="701" value="mist" icon="50d"/>
> > <lastupdate value="2017-01-30T15:50:00"/>
> > </current>
> >
> > I want to create a data frame out of this XML but
> > obviously xmlToDataFrame() is not working.
> >
> > It has dynamic attributes like for node precipitation , it could have
> > attributes like value and mode both if there is ppt in some city.
> >
> > My basic issue now id to read XML attributes of different nodes and
> convert
> > it into a data frame, I have scraped many forums but could not find any
> > help in this.
> >
> > For starters, please suggest a solution to parse the value of city node
> and
> > corresponding id, name, lat, long etc.
> >
> > I know I am asking a lot, thanks for reading and cheers! :)
> >
> > --
> > Regards
> > Archit
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr 28 10:36:56 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 28 Apr 2017 10:36:56 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
Message-ID: <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>

Yes, we noticed this in the last days of the code freeze before release and shied away from inserting a workaround, partly because we couldn't see what the root of the problem might be. 

For the purposes of installed.packages it is relatively harmless to treat the NA condition as FALSE, since it is just a matter of whether a cache is valid. I.e., it might cause an unnecessary cache rebuild. For other situations it might be more of an issue.

The workaround (NA -> FALSE, basically) is in place in R-patched and R-devel.

-pd

> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> We have several computers with the same problem.
> 
> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com>:
> 
> Hello,
> 
> I am currently getting a strange error when I call installed.packages():
> 
> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>  missing value where TRUE/FALSE needed
> Calls: installed.packages
> 
> 
> I am working with R 3.4.0 on Windows. I didn't get this error with R 3.3.3.
> Apparently, file.mtime() is returning NA well applied to a directory, and
> this causes the entire && expression to be NA, then the "if" fails because
> it needs either T or F.
> The source of "installed.packages" seems to be roughly the same as in R
> 3.3.3, so I wonder if there have been other changes in R, maybe the logical
> operators, that would make this function fail.
> 
> Any idea?
> 
> Best regards,
> 
> Jean-Claude Arbaut
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thierry.onkelinx at inbo.be  Fri Apr 28 10:45:16 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 28 Apr 2017 10:45:16 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
Message-ID: <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>

Dear Peter,

It actually breaks install.packages(). So it is not that innocent.

Best regards,

Thierry


Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard" <pdalgd at gmail.com>:

Yes, we noticed this in the last days of the code freeze before release and
shied away from inserting a workaround, partly because we couldn't see what
the root of the problem might be.

For the purposes of installed.packages it is relatively harmless to treat
the NA condition as FALSE, since it is just a matter of whether a cache is
valid. I.e., it might cause an unnecessary cache rebuild. For other
situations it might be more of an issue.

The workaround (NA -> FALSE, basically) is in place in R-patched and
R-devel.

-pd

> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:
>
> We have several computers with the same problem.
>
> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com
>:
>
> Hello,
>
> I am currently getting a strange error when I call installed.packages():
>
> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>  missing value where TRUE/FALSE needed
> Calls: installed.packages
>
>
> I am working with R 3.4.0 on Windows. I didn't get this error with R
3.3.3.
> Apparently, file.mtime() is returning NA well applied to a directory, and
> this causes the entire && expression to be NA, then the "if" fails because
> it needs either T or F.
> The source of "installed.packages" seems to be roughly the same as in R
> 3.3.3, so I wonder if there have been other changes in R, maybe the
logical
> operators, that would make this function fail.
>
> Any idea?
>
> Best regards,
>
> Jean-Claude Arbaut
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Fri Apr 28 11:21:18 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 28 Apr 2017 11:21:18 +0200
Subject: [R] Different output for "if else" and "ifelse" that I don't
	understand
Message-ID: <70de1526-5ed0-c9aa-58a1-4f606b46366e@yahoo.fr>

Dear list-members,

During the test phase of a function, I run it interactively (in Rstudio) 
and the ... produces an error. Then I use this to read it:

if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else 
p3p <- list(...)

It works fine; interactively I will get

 > if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() 
else p3p <- list(...)
 > p3p
list()

and within a function I will get a list with the ... value. Perfect.

I wanted to simplify the line by doing:

p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(), 
list(...))

In interactive mode, it works but within a function, I don't get the 
names of the parameters. I don't understand the logic behind this 
difference. Have you an idea ?

Thanks

Marc


 > Try1 <- function(...) {
+   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() 
else p3p <- list(...)
+   return(p3p)
+ }
 > Try1(k=100)
$k
[1] 100

 > Try1()
list()
 > Try2 <- function(...) {
+   p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", 
list(), list(...))
+   return(p3p)
+ }
 > Try2(k=100)
[[1]]
[1] 100

 > Try2()
[[1]]
NULL


From tr206 at kent.ac.uk  Fri Apr 28 13:07:40 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 28 Apr 2017 11:07:40 +0000
Subject: [R] Augmented Dickey Fuller test
Message-ID: <1493377701072.16786@kent.ac.uk>

Dear all,

I am trying to run an ADF test using the adf.test() function in the tseries package and the ur.df() function in the urca package. The results I get contrast sharply. Whilst the adf.test() indicates stationarity which is in line with the corresponding graph, the ur.df() indicates non-stationarity.



Why does this happen? Could anybody explain the adf.test() function in more detail? How does adf.test() select the number of lags is it AIC or BIC and how does it take an intercept and/or a trend into account?



Help is greatly appreciated.



Thanks in advance.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr 28 13:25:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 28 Apr 2017 21:25:58 +1000
Subject: [R] gap.barplot with means and standard error bars
In-Reply-To: <CY4PR06MB301494149B7F4705D0622C0A9A100@CY4PR06MB3014.namprd06.prod.outlook.com>
References: <CY4PR06MB301494149B7F4705D0622C0A9A100@CY4PR06MB3014.namprd06.prod.outlook.com>
Message-ID: <CA+8X3fUg=o2K1PxqRpZ51xxtcoYjmADeiJ9c+X4_GpU_--__Zg@mail.gmail.com>

Hi Bianca,
Try this:

gap.barplot(c(mean(SA),mean(AA),mean(CA)),
 gap=c(1,250),xlim=c(0.5,3.5),xaxlab=c("SA","AA","CA"),
 ytics=c(0,255,260,265),yaxlab=c(0,255,260,265))
barlabels(1:3,c(5,5,5),
 paste(c(mean(SA),mean(AA),mean(CA)),
 round(c(sd(SA),sd(AA),sd(CA)),3)))

It's a bit rough, but I don't have time for refinement tonight.

Jim

On Fri, Apr 28, 2017 at 5:10 AM, Biank M <bianca12_domi at hotmail.com> wrote:
> Hi..
>
>
> I've been trying to create a barplot with the following data:
>
>
> SA<- c(0.06, 0.061, 0.06, 0.06, 0.06)
> AA<- c(0.29, 0.275, 0.271, 0.274, 0.276)
> CA<- c(266.783, 257.726, 276.331, 268.859, 265.042)
>
>
> I want a bar for "SA", a bar for "AA", and a bar for "CA" (x- axis). The height of the bar must be represented by the mean of each vector data and include SE bars. Since there are very very large differences in numbers , I want to add a gap between 1 and 250 (y-axis).
>
>
> I know that the gap.barplot function is used to produce the gap, but I don't know how to include the means and SE bars.
>
> Can you help me creating this plot??
>
>
> Thank you very much!!
>
>
> Greetings,
>
> Bianca
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Fri Apr 28 13:58:43 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 28 Apr 2017 13:58:43 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
Message-ID: <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>



On 28.04.2017 10:45, Thierry Onkelinx wrote:
> Dear Peter,
>
> It actually breaks install.packages(). So it is not that innocent.

And hence, as Peter exoplained, it is already fixed inn R-patched, 
thanks to Tomas Kalibera.

Best,
Uwe Ligges





> Best regards,
>
> Thierry
>
>
> Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard" <pdalgd at gmail.com>:
>
> Yes, we noticed this in the last days of the code freeze before release and
> shied away from inserting a workaround, partly because we couldn't see what
> the root of the problem might be.
>
> For the purposes of installed.packages it is relatively harmless to treat
> the NA condition as FALSE, since it is just a matter of whether a cache is
> valid. I.e., it might cause an unnecessary cache rebuild. For other
> situations it might be more of an issue.
>
> The workaround (NA -> FALSE, basically) is in place in R-patched and
> R-devel.
>
> -pd
>
>> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>>
>> We have several computers with the same problem.
>>
>> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com
>> :
>>
>> Hello,
>>
>> I am currently getting a strange error when I call installed.packages():
>>
>> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>>  missing value where TRUE/FALSE needed
>> Calls: installed.packages
>>
>>
>> I am working with R 3.4.0 on Windows. I didn't get this error with R
> 3.3.3.
>> Apparently, file.mtime() is returning NA well applied to a directory, and
>> this causes the entire && expression to be NA, then the "if" fails because
>> it needs either T or F.
>> The source of "installed.packages" seems to be roughly the same as in R
>> 3.3.3, so I wonder if there have been other changes in R, maybe the
> logical
>> operators, that would make this function fail.
>>
>> Any idea?
>>
>> Best regards,
>>
>> Jean-Claude Arbaut
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Fri Apr 28 14:01:46 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 28 Apr 2017 14:01:46 +0200 (CEST)
Subject: [R] Augmented Dickey Fuller test
In-Reply-To: <1493377701072.16786@kent.ac.uk>
References: <1493377701072.16786@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1704281356470.4217@paninaro>

On Fri, 28 Apr 2017, T.Riedle wrote:

> Dear all,
>
> I am trying to run an ADF test using the adf.test() function in the 
> tseries package and the ur.df() function in the urca package. The 
> results I get contrast sharply. Whilst the adf.test() indicates 
> stationarity which is in line with the corresponding graph, the ur.df() 
> indicates non-stationarity.
>
> Why does this happen?

This is likely due to different setting for the deterministic part of the 
model and/or the number of lags tested. The defaults of ur.df() are often 
not suitable for many practical applications which might to spurious 
significant results.

> Could anybody explain the adf.test() function in more detail? How does 
> adf.test() select the number of lags is it AIC or BIC and how does it 
> take an intercept and/or a trend into account?

There is a deterministic trend and the default number of lags is selected 
by a heuristic.

At

https://stats.stackexchange.com/questions/168332/r-augmented-dickey-fuller-adf-test/168355#168355

I've summarized an overview that I had written for my students. It might 
also be helpful for you.

hth,
Z


From btupper at bigelow.org  Fri Apr 28 15:24:11 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 28 Apr 2017 09:24:11 -0400
Subject: [R] Reading XML attriutes in R
In-Reply-To: <CAJ7HxBws0OLPAyKN=TSq=tifHCCPULqFAmLa+0r3azafLB5G7Q@mail.gmail.com>
References: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>
 <E1259022-E9F1-41D0-8953-A529E40D0514@bigelow.org>
 <CAJ7HxBws0OLPAyKN=TSq=tifHCCPULqFAmLa+0r3azafLB5G7Q@mail.gmail.com>
Message-ID: <85AC688E-7FC0-44CA-9F7F-B05635394E41@bigelow.org>

Hi again,

It would be super easy if xml2::xml_attrs() accepted a list of attribute names and defaults values like xml2::xml_attr() does, but it doesn't.  Once you have a list of character vectors like that returned by your ...

ppt <- x %>% xml_find_all("precipitation") %>% xml_attrs()

..then you need only try to extract the fields you want.  Perhaps something like the following untested steps...

precip <-  tibble::as_tibble(do.call(rbind, lapply(ppt, '[', c('unit', 'value', 'type')) ))

colnames(precip) <- c('unit', 'value', 'type')

Bon chance!
Ben

P.S.  Don't forget to change your email client to send plain text messages to this list.  Typically rich text and html emails get turned into hash by the R-help list services.

> On Apr 28, 2017, at 4:25 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> 
> Thanks Ben, got it working, just want one more help on this,
> 
> If i have a node like: <precipitation mode="no"/> and in some other city it came like:  <precipitation unit="3h" value="0.0925" type="rain"/>
> 
> How can i make my code to handle this dynamically? I am sorry to ask such novice questions but it would be extremely helpful if you could help me with this.
> 
> So, i would want my resulting data set from this code:- ppt <- (x %>% xml_find_all("precipitation") %>% xml_attrs())
>  if mode is no, then the three columns should come and values should be NA and if values are populated then as is.
> 
> Unit     Value      Type
> NA        NA         NA
> 3h        0.0925     rain
> 
> Thanks again and in advance ! 
> 
> Archit
> 
> On Thu, Apr 27, 2017 at 6:27 PM, Ben Tupper <btupper at bigelow.org> wrote:
> Hi,
> 
> There might be an easy solution out there already, but I suspect that you will need to parse the XML yourself.  The example below uses package xml2 not XML but you could do this with either.  The example simply shows how to get values out of the XML hierarchy.  Once you have the attributes you want in hand you can assemble the elements into a data frame (or a tibble from package tibble.)
> 
> By the way, I had to prepend your example with '<current>'
> 
> Cheers,
> Ben
> 
> ### START
> 
> library(tidyverse)
> library(xml2)
> 
> txt <- "<current><city id=\"2643743\" name=\"London\"><coord lon=\"-0.13\" lat=\"51.51\"/><country>GB</country><sun rise=\"2017-01-30T07:40:36\" set=\"2017-01-30T16:47:56\"/></city><temperature value=\"280.15\" min=\"278.15\" max=\"281.15\" unit=\"kelvin\"/><humidity value=\"81\" unit=\"%\"/><pressure value=\"1012\" unit=\"hPa\"/><wind><speed value=\"4.6\" name=\"Gentle Breeze\"/><gusts/><direction value=\"90\" code=\"E\" name=\"East\"/></wind><clouds value=\"90\" name=\"overcast clouds\"/><visibility value=\"10000\"/><precipitation mode=\"no\"/><weather number=\"701\" value=\"mist\" icon=\"50d\"/><lastupdate value=\"2017-01-30T15:50:00\"/></current>"
> 
> x <- read_xml(txt)
> 
> windspeed <- x %>%
>     xml_find_first("wind/speed") %>%
>     xml_attrs()
> 
> winddir <- x %>%
>     xml_find_first("wind/direction") %>%
>     xml_attrs()
> 
> windspeed
> #          value            name
> #          "4.6" "Gentle Breeze"
> 
> winddir
> #  value   code   name
> #  "90"    "E" "East"
> 
> ### END
> 
> 
> 
> > On Apr 27, 2017, at 6:08 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> >
> > Hi All,
> >
> > I have a XML file like :
> >
> > <city id="2643743" name="London">
> > <coord lon="-0.13" lat="51.51"/>
> > <country>GB</country>
> > <sun rise="2017-01-30T07:40:36" set="2017-01-30T16:47:56"/>
> > </city>
> > <temperature value="280.15" min="278.15" max="281.15" unit="kelvin"/>
> > <humidity value="81" unit="%"/>
> > <pressure value="1012" unit="hPa"/>
> > <wind>
> > <speed value="4.6" name="Gentle Breeze"/>
> > <gusts/>
> > <direction value="90" code="E" name="East"/>
> > </wind>
> > <clouds value="90" name="overcast clouds"/>
> > <visibility value="10000"/>
> > <precipitation mode="no"/>
> > <weather number="701" value="mist" icon="50d"/>
> > <lastupdate value="2017-01-30T15:50:00"/>
> > </current>
> >
> > I want to create a data frame out of this XML but
> > obviously xmlToDataFrame() is not working.
> >
> > It has dynamic attributes like for node precipitation , it could have
> > attributes like value and mode both if there is ppt in some city.
> >
> > My basic issue now id to read XML attributes of different nodes and convert
> > it into a data frame, I have scraped many forums but could not find any
> > help in this.
> >
> > For starters, please suggest a solution to parse the value of city node and
> > corresponding id, name, lat, long etc.
> >
> > I know I am asking a lot, thanks for reading and cheers! :)
> >
> > --
> > Regards
> > Archit
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> 
> 
> 
> 
> 
> -- 
> Regards
> Archit

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From wdunlap at tibco.com  Fri Apr 28 17:34:57 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 28 Apr 2017 08:34:57 -0700
Subject: [R] Different output for "if else" and "ifelse" that I don't
	understand
In-Reply-To: <70de1526-5ed0-c9aa-58a1-4f606b46366e@yahoo.fr>
References: <70de1526-5ed0-c9aa-58a1-4f606b46366e@yahoo.fr>
Message-ID: <CAF8bMcbJ5MjR2xYJc=9tYS7T9=Q-_NhjF3yeWz4d1Nan5EM8fw@mail.gmail.com>

ifelse's vectorization messes this up.

You could replace your original
  if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
p3p <- list(...)
with
  p3p <- if (class(try(list(...), silent=TRUE))=="try-error") list() else
list(...)
instead of using ifelse, since the return value of 'if ... else ...' is the
value of whichever branch was taken.

Even better, use
  p3p <- try(list(...), error=function(e) list())


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 28, 2017 at 2:21 AM, Marc Girondot via R-help <
r-help at r-project.org> wrote:

> Dear list-members,
>
> During the test phase of a function, I run it interactively (in Rstudio)
> and the ... produces an error. Then I use this to read it:
>
> if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
> p3p <- list(...)
>
> It works fine; interactively I will get
>
> > if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
> p3p <- list(...)
> > p3p
> list()
>
> and within a function I will get a list with the ... value. Perfect.
>
> I wanted to simplify the line by doing:
>
> p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(),
> list(...))
>
> In interactive mode, it works but within a function, I don't get the names
> of the parameters. I don't understand the logic behind this difference.
> Have you an idea ?
>
> Thanks
>
> Marc
>
>
> > Try1 <- function(...) {
> +   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list()
> else p3p <- list(...)
> +   return(p3p)
> + }
> > Try1(k=100)
> $k
> [1] 100
>
> > Try1()
> list()
> > Try2 <- function(...) {
> +   p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(),
> list(...))
> +   return(p3p)
> + }
> > Try2(k=100)
> [[1]]
> [1] 100
>
> > Try2()
> [[1]]
> NULL
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Fri Apr 28 18:06:21 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Fri, 28 Apr 2017 11:06:21 -0500
Subject: [R] update.packages() error R 3.4.0
Message-ID: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>

Is there an easy work-around for the update.packages error I'm getting 
on Windows 10 with R 3.4.0?

 > update.packages()
--- Please select a CRAN mirror for use in this session ---
foreign :
  Version 0.8-67 installed in C:/Program Files/R/R-3.4.0/library
  Version 0.8-68 available at https://mirror.las.iastate.edu/CRAN
Update (y/N/c)?  y
Warning in install.packages(update[instlib == l, "Package"], l, repos = 
repos,  :
   'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
   missing value where TRUE/FALSE needed

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From dimitri.liakhovitski at gmail.com  Fri Apr 28 18:58:21 2017
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 28 Apr 2017 12:58:21 -0400
Subject: [R] update.packages() error R 3.4.0
In-Reply-To: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>
References: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>
Message-ID: <CAN2xGJa4-6uKb2_VR68W7hgvY9yQ7bWbia_RRgaghvy27zev2Q@mail.gmail.com>

I am having the same problem - just installed R 3.4.0 on my Windows
laptop. Same thing with packages - exactly the same error.

On Fri, Apr 28, 2017 at 12:06 PM, Robert Baer <rbaer at atsu.edu> wrote:
> Is there an easy work-around for the update.packages error I'm getting on
> Windows 10 with R 3.4.0?
>
>> update.packages()
> --- Please select a CRAN mirror for use in this session ---
> foreign :
>  Version 0.8-67 installed in C:/Program Files/R/R-3.4.0/library
>  Version 0.8-68 available at https://mirror.las.iastate.edu/CRAN
> Update (y/N/c)?  y
> Warning in install.packages(update[instlib == l, "Package"], l, repos =
> repos,  :
>   'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>   missing value where TRUE/FALSE needed
>
> --
>
>
> --
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> 660-626-2321 Department
> 660-626-2965 FAX
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From bgunter.4567 at gmail.com  Fri Apr 28 19:01:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 28 Apr 2017 10:01:11 -0700
Subject: [R] Different output for "if else" and "ifelse" that I don't
	understand
In-Reply-To: <CAF8bMcbJ5MjR2xYJc=9tYS7T9=Q-_NhjF3yeWz4d1Nan5EM8fw@mail.gmail.com>
References: <70de1526-5ed0-c9aa-58a1-4f606b46366e@yahoo.fr>
 <CAF8bMcbJ5MjR2xYJc=9tYS7T9=Q-_NhjF3yeWz4d1Nan5EM8fw@mail.gmail.com>
Message-ID: <CAGxFJbQ83eDKi+6u6EuX9hGAW5HK4crPH9=iUcZNNP8G2+2CDw@mail.gmail.com>

Typo: last line should be

Even better, use
  p3p <- tryCatch(list(...), error=function(e) list())


Cheers,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 28, 2017 at 8:34 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> ifelse's vectorization messes this up.
>
> You could replace your original
>   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
> p3p <- list(...)
> with
>   p3p <- if (class(try(list(...), silent=TRUE))=="try-error") list() else
> list(...)
> instead of using ifelse, since the return value of 'if ... else ...' is the
> value of whichever branch was taken.
>
> Even better, use
>   p3p <- try(list(...), error=function(e) list())
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Apr 28, 2017 at 2:21 AM, Marc Girondot via R-help <
> r-help at r-project.org> wrote:
>
>> Dear list-members,
>>
>> During the test phase of a function, I run it interactively (in Rstudio)
>> and the ... produces an error. Then I use this to read it:
>>
>> if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
>> p3p <- list(...)
>>
>> It works fine; interactively I will get
>>
>> > if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
>> p3p <- list(...)
>> > p3p
>> list()
>>
>> and within a function I will get a list with the ... value. Perfect.
>>
>> I wanted to simplify the line by doing:
>>
>> p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(),
>> list(...))
>>
>> In interactive mode, it works but within a function, I don't get the names
>> of the parameters. I don't understand the logic behind this difference.
>> Have you an idea ?
>>
>> Thanks
>>
>> Marc
>>
>>
>> > Try1 <- function(...) {
>> +   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list()
>> else p3p <- list(...)
>> +   return(p3p)
>> + }
>> > Try1(k=100)
>> $k
>> [1] 100
>>
>> > Try1()
>> list()
>> > Try2 <- function(...) {
>> +   p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(),
>> list(...))
>> +   return(p3p)
>> + }
>> > Try2(k=100)
>> [[1]]
>> [1] 100
>>
>> > Try2()
>> [[1]]
>> NULL
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Apr 28 19:02:13 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 28 Apr 2017 10:02:13 -0700
Subject: [R] update.packages() error R 3.4.0
In-Reply-To: <CAN2xGJa4-6uKb2_VR68W7hgvY9yQ7bWbia_RRgaghvy27zev2Q@mail.gmail.com>
References: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>
 <CAN2xGJa4-6uKb2_VR68W7hgvY9yQ7bWbia_RRgaghvy27zev2Q@mail.gmail.com>
Message-ID: <CAGxFJbQf1NU5pOdn9cMYPFW_985+h9ibNGPNG6RD399ScwgKww@mail.gmail.com>

Please see previous messages from today concerning this.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 28, 2017 at 9:58 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I am having the same problem - just installed R 3.4.0 on my Windows
> laptop. Same thing with packages - exactly the same error.
>
> On Fri, Apr 28, 2017 at 12:06 PM, Robert Baer <rbaer at atsu.edu> wrote:
>> Is there an easy work-around for the update.packages error I'm getting on
>> Windows 10 with R 3.4.0?
>>
>>> update.packages()
>> --- Please select a CRAN mirror for use in this session ---
>> foreign :
>>  Version 0.8-67 installed in C:/Program Files/R/R-3.4.0/library
>>  Version 0.8-68 available at https://mirror.las.iastate.edu/CRAN
>> Update (y/N/c)?  y
>> Warning in install.packages(update[instlib == l, "Package"], l, repos =
>> repos,  :
>>   'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
>> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>>   missing value where TRUE/FALSE needed
>>
>> --
>>
>>
>> --
>> Robert W. Baer, Ph.D.
>> Professor of Physiology
>> Kirksville College of Osteopathic Medicine
>> A T Still University of Health Sciences
>> 800 W. Jefferson St
>> Kirksville, MO 63501
>> 660-626-2321 Department
>> 660-626-2965 FAX
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Fri Apr 28 19:10:58 2017
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 28 Apr 2017 13:10:58 -0400
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>
Message-ID: <CAN2xGJYSsSwLSJjX1MVXfSxmySgc35zH_wgRYxY5auhz7tqGGQ@mail.gmail.com>

When I click on "r patched snapshot build" here
<https://cran.r-project.org/bin/windows/base/>, it take me here
<https://cran.r-project.org/bin/windows/base/rpatched.html> , it says: Download
R-3.3.3 Patched build for Windows
<https://cran.r-project.org/bin/windows/base/R-3.3.3patched-win.exe>
However, I am unclear how can one get to the patched 3.4.0 version?
Thank you!

On Fri, Apr 28, 2017 at 7:58 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 28.04.2017 10:45, Thierry Onkelinx wrote:
>
>> Dear Peter,
>>
>> It actually breaks install.packages(). So it is not that innocent.
>>
>
> And hence, as Peter exoplained, it is already fixed inn R-patched, thanks
> to Tomas Kalibera.
>
> Best,
> Uwe Ligges
>
>
>
>
>
>
> Best regards,
>>
>> Thierry
>>
>>
>> Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard" <pdalgd at gmail.com>:
>>
>> Yes, we noticed this in the last days of the code freeze before release
>> and
>> shied away from inserting a workaround, partly because we couldn't see
>> what
>> the root of the problem might be.
>>
>> For the purposes of installed.packages it is relatively harmless to treat
>> the NA condition as FALSE, since it is just a matter of whether a cache is
>> valid. I.e., it might cause an unnecessary cache rebuild. For other
>> situations it might be more of an issue.
>>
>> The workaround (NA -> FALSE, basically) is in place in R-patched and
>> R-devel.
>>
>> -pd
>>
>> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>
>> wrote:
>>
>>>
>>> We have several computers with the same problem.
>>>
>>> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <
>>> arbautjc at gmail.com
>>> :
>>>
>>> Hello,
>>>
>>> I am currently getting a strange error when I call installed.packages():
>>>
>>> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&
>>> :
>>>  missing value where TRUE/FALSE needed
>>> Calls: installed.packages
>>>
>>>
>>> I am working with R 3.4.0 on Windows. I didn't get this error with R
>>>
>> 3.3.3.
>>
>>> Apparently, file.mtime() is returning NA well applied to a directory, and
>>> this causes the entire && expression to be NA, then the "if" fails
>>> because
>>> it needs either T or F.
>>> The source of "installed.packages" seems to be roughly the same as in R
>>> 3.3.3, so I wonder if there have been other changes in R, maybe the
>>>
>> logical
>>
>>> operators, that would make this function fail.
>>>
>>> Any idea?
>>>
>>> Best regards,
>>>
>>> Jean-Claude Arbaut
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>>
>> posting-guide.html
>>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>>
>> posting-guide.html
>>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dimitri Liakhovitski

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Apr 28 19:19:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Apr 2017 10:19:01 -0700
Subject: [R] update.packages() error R 3.4.0
In-Reply-To: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>
References: <9f9366ae-d0da-5551-b5e7-81acdd9f0cab@atsu.edu>
Message-ID: <568E8500-5F45-42C3-9FE9-0DEB14A2AF66@dcn.davis.ca.us>

Ah, if you have been following along the thread..  use the patched version.
-- 
Sent from my phone. Please excuse my brevity.

On April 28, 2017 9:06:21 AM PDT, Robert Baer <rbaer at atsu.edu> wrote:
>Is there an easy work-around for the update.packages error I'm getting 
>on Windows 10 with R 3.4.0?
>
> > update.packages()
>--- Please select a CRAN mirror for use in this session ---
>foreign :
>  Version 0.8-67 installed in C:/Program Files/R/R-3.4.0/library
>  Version 0.8-68 available at https://mirror.las.iastate.edu/CRAN
>Update (y/N/c)?  y
>Warning in install.packages(update[instlib == l, "Package"], l, repos =
>
>repos,  :
>   'lib = "C:/Program Files/R/R-3.4.0/library"' is not writable
>Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&
> :
>   missing value where TRUE/FALSE needed


From wdunlap at tibco.com  Fri Apr 28 19:43:44 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 28 Apr 2017 10:43:44 -0700
Subject: [R] Different output for "if else" and "ifelse" that I don't
	understand
In-Reply-To: <CAGxFJbQ83eDKi+6u6EuX9hGAW5HK4crPH9=iUcZNNP8G2+2CDw@mail.gmail.com>
References: <70de1526-5ed0-c9aa-58a1-4f606b46366e@yahoo.fr>
 <CAF8bMcbJ5MjR2xYJc=9tYS7T9=Q-_NhjF3yeWz4d1Nan5EM8fw@mail.gmail.com>
 <CAGxFJbQ83eDKi+6u6EuX9hGAW5HK4crPH9=iUcZNNP8G2+2CDw@mail.gmail.com>
Message-ID: <CAF8bMcYh_j9S70Bctq8_obUn0s7f3+E1R0xqs+2JeJpPQ0zFYQ@mail.gmail.com>

Thank you - I did mean tryCatch.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 28, 2017 at 10:01 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Typo: last line should be
>
> Even better, use
>   p3p <- tryCatch(list(...), error=function(e) list())
>
>
> Cheers,
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 28, 2017 at 8:34 AM, William Dunlap via R-help
> <r-help at r-project.org> wrote:
> > ifelse's vectorization messes this up.
> >
> > You could replace your original
> >   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
> > p3p <- list(...)
> > with
> >   p3p <- if (class(try(list(...), silent=TRUE))=="try-error") list() else
> > list(...)
> > instead of using ifelse, since the return value of 'if ... else ...' is
> the
> > value of whichever branch was taken.
> >
> > Even better, use
> >   p3p <- try(list(...), error=function(e) list())
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Fri, Apr 28, 2017 at 2:21 AM, Marc Girondot via R-help <
> > r-help at r-project.org> wrote:
> >
> >> Dear list-members,
> >>
> >> During the test phase of a function, I run it interactively (in Rstudio)
> >> and the ... produces an error. Then I use this to read it:
> >>
> >> if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list() else
> >> p3p <- list(...)
> >>
> >> It works fine; interactively I will get
> >>
> >> > if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list()
> else
> >> p3p <- list(...)
> >> > p3p
> >> list()
> >>
> >> and within a function I will get a list with the ... value. Perfect.
> >>
> >> I wanted to simplify the line by doing:
> >>
> >> p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error", list(),
> >> list(...))
> >>
> >> In interactive mode, it works but within a function, I don't get the
> names
> >> of the parameters. I don't understand the logic behind this difference.
> >> Have you an idea ?
> >>
> >> Thanks
> >>
> >> Marc
> >>
> >>
> >> > Try1 <- function(...) {
> >> +   if (class(try(list(...), silent=TRUE))=="try-error") p3p <- list()
> >> else p3p <- list(...)
> >> +   return(p3p)
> >> + }
> >> > Try1(k=100)
> >> $k
> >> [1] 100
> >>
> >> > Try1()
> >> list()
> >> > Try2 <- function(...) {
> >> +   p3p <- ifelse(class(try(list(...), silent=TRUE))=="try-error",
> list(),
> >> list(...))
> >> +   return(p3p)
> >> + }
> >> > Try2(k=100)
> >> [[1]]
> >> [1] 100
> >>
> >> > Try2()
> >> [[1]]
> >> NULL
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.nh.gov  Fri Apr 28 20:51:17 2017
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Fri, 28 Apr 2017 18:51:17 +0000
Subject: [R] Overriding lack of i386 build for ROracle when updating packages
Message-ID: <40623df00b594bca9a34949c94bc2f71@dhhs.nh.gov>

Since I query my Oracle warehouse often, I load the ROracle package on startup. Whenever I update packages from RStudio (which actually runs the install.packages function) with ROracle loaded, I get the following error:

Error: package 'ROracle' is not installed for 'arch = i386'

Unloading the package doesn't help; I have to edit my startup script to not load ROracle, then restart R, update packages, and restore my original startup script. I don' t have any use for 32-bit ROracle and am not sure that it exists (the package archive doesn't contain a "libs/i386" folder. Does anyone know of a way to override the lack of an i386 build when installing other packages?

Thanks,
M.L.




	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Fri Apr 28 21:47:16 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Sat, 29 Apr 2017 01:17:16 +0530
Subject: [R] Reading XML attriutes in R
In-Reply-To: <85AC688E-7FC0-44CA-9F7F-B05635394E41@bigelow.org>
References: <CAJ7HxBwLaf9BQFir=fFn2TwijqwDQv3cyeFq5Gs-TRFXE-Gefg@mail.gmail.com>
 <E1259022-E9F1-41D0-8953-A529E40D0514@bigelow.org>
 <CAJ7HxBws0OLPAyKN=TSq=tifHCCPULqFAmLa+0r3azafLB5G7Q@mail.gmail.com>
 <85AC688E-7FC0-44CA-9F7F-B05635394E41@bigelow.org>
Message-ID: <CAJ7HxByvW7oP4ZN7vB=6o4DQCcrSd7Dfj00UAFufyBOMW9P-HA@mail.gmail.com>

Thanks Ben,  I'll give it a shot.. Thanks again :)

On Apr 28, 2017 18:54, "Ben Tupper" <btupper at bigelow.org> wrote:

> Hi again,
>
> It would be super easy if xml2::xml_attrs() accepted a list of attribute
> names and defaults values like xml2::xml_attr() does, but it doesn't.  Once
> you have a list of character vectors like that returned by your ...
>
> ppt <- x %>% xml_find_all("precipitation") %>% xml_attrs()
>
> ..then you need only try to extract the fields you want.  Perhaps
> something like the following untested steps...
>
> precip <-  tibble::as_tibble(do.call(rbind, lapply(ppt, '[', c('unit',
> 'value', 'type')) ))
>
> colnames(precip) <- c('unit', 'value', 'type')
>
> Bon chance!
> Ben
>
> P.S.  Don't forget to change your email client to send plain text messages
> to this list.  Typically rich text and html emails get turned into hash by
> the R-help list services.
>
> > On Apr 28, 2017, at 4:25 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> >
> > Thanks Ben, got it working, just want one more help on this,
> >
> > If i have a node like: <precipitation mode="no"/> and in some other city
> it came like:  <precipitation unit="3h" value="0.0925" type="rain"/>
> >
> > How can i make my code to handle this dynamically? I am sorry to ask
> such novice questions but it would be extremely helpful if you could help
> me with this.
> >
> > So, i would want my resulting data set from this code:- ppt <- (x %>%
> xml_find_all("precipitation") %>% xml_attrs())
> >  if mode is no, then the three columns should come and values should be
> NA and if values are populated then as is.
> >
> > Unit     Value      Type
> > NA        NA         NA
> > 3h        0.0925     rain
> >
> > Thanks again and in advance !
> >
> > Archit
> >
> > On Thu, Apr 27, 2017 at 6:27 PM, Ben Tupper <btupper at bigelow.org> wrote:
> > Hi,
> >
> > There might be an easy solution out there already, but I suspect that
> you will need to parse the XML yourself.  The example below uses package
> xml2 not XML but you could do this with either.  The example simply shows
> how to get values out of the XML hierarchy.  Once you have the attributes
> you want in hand you can assemble the elements into a data frame (or a
> tibble from package tibble.)
> >
> > By the way, I had to prepend your example with '<current>'
> >
> > Cheers,
> > Ben
> >
> > ### START
> >
> > library(tidyverse)
> > library(xml2)
> >
> > txt <- "<current><city id=\"2643743\" name=\"London\"><coord
> lon=\"-0.13\" lat=\"51.51\"/><country>GB</country><sun
> rise=\"2017-01-30T07:40:36\" set=\"2017-01-30T16:47:56\"/></city><temperature
> value=\"280.15\" min=\"278.15\" max=\"281.15\" unit=\"kelvin\"/><humidity
> value=\"81\" unit=\"%\"/><pressure value=\"1012\"
> unit=\"hPa\"/><wind><speed value=\"4.6\" name=\"Gentle
> Breeze\"/><gusts/><direction value=\"90\" code=\"E\"
> name=\"East\"/></wind><clouds value=\"90\" name=\"overcast
> clouds\"/><visibility value=\"10000\"/><precipitation
> mode=\"no\"/><weather number=\"701\" value=\"mist\"
> icon=\"50d\"/><lastupdate value=\"2017-01-30T15:50:00\"/></current>"
> >
> > x <- read_xml(txt)
> >
> > windspeed <- x %>%
> >     xml_find_first("wind/speed") %>%
> >     xml_attrs()
> >
> > winddir <- x %>%
> >     xml_find_first("wind/direction") %>%
> >     xml_attrs()
> >
> > windspeed
> > #          value            name
> > #          "4.6" "Gentle Breeze"
> >
> > winddir
> > #  value   code   name
> > #  "90"    "E" "East"
> >
> > ### END
> >
> >
> >
> > > On Apr 27, 2017, at 6:08 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> > >
> > > Hi All,
> > >
> > > I have a XML file like :
> > >
> > > <city id="2643743" name="London">
> > > <coord lon="-0.13" lat="51.51"/>
> > > <country>GB</country>
> > > <sun rise="2017-01-30T07:40:36" set="2017-01-30T16:47:56"/>
> > > </city>
> > > <temperature value="280.15" min="278.15" max="281.15" unit="kelvin"/>
> > > <humidity value="81" unit="%"/>
> > > <pressure value="1012" unit="hPa"/>
> > > <wind>
> > > <speed value="4.6" name="Gentle Breeze"/>
> > > <gusts/>
> > > <direction value="90" code="E" name="East"/>
> > > </wind>
> > > <clouds value="90" name="overcast clouds"/>
> > > <visibility value="10000"/>
> > > <precipitation mode="no"/>
> > > <weather number="701" value="mist" icon="50d"/>
> > > <lastupdate value="2017-01-30T15:50:00"/>
> > > </current>
> > >
> > > I want to create a data frame out of this XML but
> > > obviously xmlToDataFrame() is not working.
> > >
> > > It has dynamic attributes like for node precipitation , it could have
> > > attributes like value and mode both if there is ppt in some city.
> > >
> > > My basic issue now id to read XML attributes of different nodes and
> convert
> > > it into a data frame, I have scraped many forums but could not find any
> > > help in this.
> > >
> > > For starters, please suggest a solution to parse the value of city
> node and
> > > corresponding id, name, lat, long etc.
> > >
> > > I know I am asking a lot, thanks for reading and cheers! :)
> > >
> > > --
> > > Regards
> > > Archit
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > Ben Tupper
> > Bigelow Laboratory for Ocean Sciences
> > 60 Bigelow Drive, P.O. Box 380
> > East Boothbay, Maine 04544
> > http://www.bigelow.org
> >
> >
> >
> >
> >
> >
> > --
> > Regards
> > Archit
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>

	[[alternative HTML version deleted]]


From nilsson.henric at gmail.com  Fri Apr 28 23:37:47 2017
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 28 Apr 2017 23:37:47 +0200
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
Message-ID: <125664f5-f052-06d6-c774-582a8493daf7@gmail.com>

On 2017-04-26 22:17, Duncan Murdoch wrote:

> On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
>> A user contacted me directly about this, I answered with my best 
>> understanding of the
>> recent R-help discussion of the issue, and their response to my 
>> response shows that I'm
>> not quite right.
>>
>> I am emphatically not an MS Windows user so am asking for help -- 
>> which I will cut/paste
>> to this user and to the next dozen who will invariably contact me 
>> directly.
>>
>> Thanks,
>>    Terry Therneau
>>
>>
>>
>> -------- Forwarded Message --------
>> Subject: RE: survival package
>> Date: Wed, 26 Apr 2017 18:05:30 +0000
>> From: SeshanV at mskcc.org
>> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>>
>> Thank you for the quick response. The session info command for v3.4.0 
>> does in fact report
>> survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the 
>> same computer the
>> library paths do not have any directory in common:
>>
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.4.0/library"
>>>
>>
>> and
>>> .libPaths()
>> [1] "C:/Program Files/R/R-3.3.1/library"
>>>
>>
>>
>> Thanks,
>> Venkat
>>
>>
>> -----Original Message-----
>> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent: 
>> Wednesday, April 26, 2017
>> 1:42 PM
>> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
>> Subject: Re: survival package
>>
>> This has been discussed in R-help by multiple people.  You have a 
>> pre-3.4 version of the
>> survival package somewhere on your search path, and the method for 
>> resolving .C calls has
>> changed.   The sessionInfo command should report survival version 2.41-3.
>>
>> Terry T.
>>
>>
>> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>>> Dear Prof. Therneau,
>>>
>>> I am encountering an error message when I try to use the coxfit6 
>>> routine from the survival package under the 3.4.0 version of R. The 
>>> minimal function and the script are in the attached file. This 
>>> function worked under earlier versions of R.
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> ***************************
>>> **  Works under R-3.3.1  **
>>> ***************************
>>>
>>>> source("coxfit6-issue.R")
>>> [1] -0.4838181
>>>
>>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>> (build 7601) Service Pack 1
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.39-4
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> ***********************************
>>> **  Does not work under R-3.4.0  **
>>> ***********************************
>>>
>>>> library(survival)
>>>> source("coxfit6-issue.R")
>>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, 
>>> as.integer(sstat),  :
>>>    "Ccoxfit6" not available for .Call() for package "survival"
> 
> As far as I can see, that line doesn't appear in the current survival 
> source code, it's from some earlier version of the package.  The current 
> one has
> 
> coxfit <- .Call(Ccoxfit6,
>                       as.integer(maxiter),
>                       stime,
>                       sstat,
>                       x[sorted,],
>                       as.double(offset[sorted]),
>                       weights,
>                       newstrat,
>                       as.integer(method=="efron"),
>                       as.double(control$eps),
>                       as.double(control$toler.chol),
>                       as.vector(init),
>                       as.integer(1))  # internally rescale
> 
> There are several differences, the one leading to the error being the 
> change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That 
> corresponds to the difference between a registered symbol and an 
> unregistered one.

I think it's worthwhile to point out that non-exported symbols are 
available using ':::'.  See WRE Section 5.4.

So, after fixing the argument list, just use '.Call(survival:::Ccoxfit6, 
<args>)' instead of '.Call("Ccoxfit6", <args>, PACKAGE = "survival")'.


Henric Winell



> 
> Without seeing the code that led to the error message I can't really say 
> how the error came about.  There are a few ways:
> 
> - The user has a copy of the coxph.fit function from an older version of 
> survival saved in their workspace, and are using that one instead of the 
> current one.
> 
> - Some part of your code returns functions, and one of those is making 
> this call based on an object produced in an earlier version of survival.
> 
> - There are really two versions of survival on the search path (or 
> perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.
> 
> Duncan Murdoch
> 
>>>> sessionInfo()
>>> R version 3.4.0 (2017-04-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>> (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] survival_2.41-3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>>> [5] lattice_0.20-35
>>>
>>> ----------------------------------------------------------------------
>>> -------------------------
>>>
>>> When I remove the quotes surrounding Ccoxfit6 in the function both 
>>> versions give the error:
>>>
>>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), 
>>> oo$coefficients,  :
>>>    object 'Ccoxfit6' not found
>>>
>>>
>>> I would greatly appreciate your help in resolving this.
>>>
>>> Thanks,
>>> Venkat Seshan
>>>
>>
>>
>> =====================================================================
>>
>>       Please note that this e-mail and any files transmitted from
>>       Memorial Sloan Kettering Cancer Center may be privileged, 
>> confidential,
>>       and protected from disclosure under applicable law. If the 
>> reader of
>>       this message is not the intended recipient, or an employee or agent
>>       responsible for delivering this message to the intended recipient,
>>       you are hereby notified that any reading, dissemination, 
>> distribution,
>>       copying, or other use of this communication or any of its 
>> attachments
>>       is strictly prohibited.  If you have received this communication in
>>       error, please notify the sender immediately by replying to this 
>> message
>>       and deleting this message, any attachments, and all copies and 
>> backups
>>       from your computer.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From attenka at utu.fi  Fri Apr 28 11:18:53 2017
From: attenka at utu.fi (Atte Tenkanen)
Date: Fri, 28 Apr 2017 12:18:53 +0300
Subject: [R] Larger rgl-images?
Message-ID: <de5f3096-8d64-bb1c-67c4-69f2ed43f4a3@utu.fi>

Hi,

In package ?VecStatGraphs3D? is a DrawDensity3D-function in which the 
rgl-device size is defined as
r3dDefaults$windowRect=c(0,0, WSizeWidth, WSizeHeight).

To save, for instance, a png-snapshot, we can use rgl.snapshot()-function.

The size of the file is dependent on the window and thus your screen and 
video card.

Can we somehow produce  larger images virtually, for example, 4k-images 
(3840x2160)?

Atte Tenkanen


From murdoch.duncan at gmail.com  Fri Apr 28 12:08:05 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Apr 2017 06:08:05 -0400
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
Message-ID: <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>

On 28/04/2017 4:45 AM, Thierry Onkelinx wrote:
> Dear Peter,
>
> It actually breaks install.packages(). So it is not that innocent.

I don't think he meant that it is harmless, he meant that the fix is 
easy, and is in place in R-patched and R-devel.  You should use 
R-patched and you won't have the problem.

More generally, there's a lot more variety of systems in the wild than 
on our test machines, so we really do rely on people testing things in 
the alpha/beta/rc phase.  In this case we saw the error too late to fix 
it (as I recall, it was very late in rc).  If more people had tested, we 
might have found it earlier.

Duncan Murdoch

>
> Best regards,
>
> Thierry
>
>
> Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard" <pdalgd at gmail.com>:
>
> Yes, we noticed this in the last days of the code freeze before release and
> shied away from inserting a workaround, partly because we couldn't see what
> the root of the problem might be.
>
> For the purposes of installed.packages it is relatively harmless to treat
> the NA condition as FALSE, since it is just a matter of whether a cache is
> valid. I.e., it might cause an unnecessary cache rebuild. For other
> situations it might be more of an issue.
>
> The workaround (NA -> FALSE, basically) is in place in R-patched and
> R-devel.
>
> -pd
>
>> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>>
>> We have several computers with the same problem.
>>
>> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com
>> :
>>
>> Hello,
>>
>> I am currently getting a strange error when I call installed.packages():
>>
>> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>>  missing value where TRUE/FALSE needed
>> Calls: installed.packages
>>
>>
>> I am working with R 3.4.0 on Windows. I didn't get this error with R
> 3.3.3.
>> Apparently, file.mtime() is returning NA well applied to a directory, and
>> this causes the entire && expression to be NA, then the "if" fails because
>> it needs either T or F.
>> The source of "installed.packages" seems to be roughly the same as in R
>> 3.3.3, so I wonder if there have been other changes in R, maybe the
> logical
>> operators, that would make this function fail.
>>
>> Any idea?
>>
>> Best regards,
>>
>> Jean-Claude Arbaut
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From esawiek at gmail.com  Fri Apr 28 17:13:18 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Fri, 28 Apr 2017 11:13:18 -0400
Subject: [R] Data.table vs dplr handling multiple variables
Message-ID: <CA+ZkTxu1WexGQUOJt453zn-M_9Z3cNPLzB_UqtwLeqaaY0ga=Q@mail.gmail.com>

Hi All?

I am often working with large datasets with multiple variables (integer,
decimal, string, complex, date, and time) that require processing,
cleaning, etc. I am relatively new to R and I would like to get some input
on the following issue: I am trying to figure out which R-package(s) is
most suitable for my work. I looked into data.table and dplyr. Both are
very good but I found out that data.table does not handle time data well
(one has to use fast time package) and not sure whether dplyr does the same
or not. I am not sure about their handling of other variables listed above.
I like data.table.


The questions: (1) which package should I invest on learning and how to
deal with issue like time data and possibly other variables such complex
numbers, date, etc.? (2) What is the ?best? practical solution for such
issue?



Thanks in advance,


EKE

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr 28 19:04:22 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 28 Apr 2017 19:04:22 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
Message-ID: <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>


> On 28 Apr 2017, at 12:08 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 28/04/2017 4:45 AM, Thierry Onkelinx wrote:
>> Dear Peter,
>> 
>> It actually breaks install.packages(). So it is not that innocent.
> 
> I don't think he meant that it is harmless, he meant that the fix is easy, and is in place in R-patched and R-devel.  You should use R-patched and you won't have the problem.

Read more carefully: I said that the _fix_ is harmless for this case, but might not be so in general.

-pd

> 
> More generally, there's a lot more variety of systems in the wild than on our test machines, so we really do rely on people testing things in the alpha/beta/rc phase.  In this case we saw the error too late to fix it (as I recall, it was very late in rc).  If more people had tested, we might have found it earlier.
> 
> Duncan Murdoch
> 
>> 
>> Best regards,
>> 
>> Thierry
>> 
>> 
>> Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard" <pdalgd at gmail.com>:
>> 
>> Yes, we noticed this in the last days of the code freeze before release and
>> shied away from inserting a workaround, partly because we couldn't see what
>> the root of the problem might be.
>> 
>> For the purposes of installed.packages it is relatively harmless to treat
>> the NA condition as FALSE, since it is just a matter of whether a cache is
>> valid. I.e., it might cause an unnecessary cache rebuild. For other
>> situations it might be more of an issue.
>> 
>> The workaround (NA -> FALSE, basically) is in place in R-patched and
>> R-devel.
>> 
>> -pd
>> 
>>> On 28 Apr 2017, at 07:47 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>> 
>>> We have several computers with the same problem.
>>> 
>>> Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut" <arbautjc at gmail.com
>>> :
>>> 
>>> Hello,
>>> 
>>> I am currently getting a strange error when I call installed.packages():
>>> 
>>> Error in if (file.exists(dest) && file.mtime(dest) > file.mtime(lib) &&  :
>>> missing value where TRUE/FALSE needed
>>> Calls: installed.packages
>>> 
>>> 
>>> I am working with R 3.4.0 on Windows. I didn't get this error with R
>> 3.3.3.
>>> Apparently, file.mtime() is returning NA well applied to a directory, and
>>> this causes the entire && expression to be NA, then the "if" fails because
>>> it needs either T or F.
>>> The source of "installed.packages" seems to be roughly the same as in R
>>> 3.3.3, so I wonder if there have been other changes in R, maybe the
>> logical
>>> operators, that would make this function fail.
>>> 
>>> Any idea?
>>> 
>>> Best regards,
>>> 
>>> Jean-Claude Arbaut
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Fri Apr 28 23:58:30 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 28 Apr 2017 23:58:30 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <CAN2xGJYSsSwLSJjX1MVXfSxmySgc35zH_wgRYxY5auhz7tqGGQ@mail.gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>
 <CAN2xGJYSsSwLSJjX1MVXfSxmySgc35zH_wgRYxY5auhz7tqGGQ@mail.gmail.com>
Message-ID: <076e7118-a0ee-d6c4-4331-bf40f2f2171d@statistik.tu-dortmund.de>



On 28.04.2017 19:10, Dimitri Liakhovitski wrote:
> When I click on "r patched snapshot build" here
> <https://cran.r-project.org/bin/windows/base/>, it take me here
> <https://cran.r-project.org/bin/windows/base/rpatched.html> , it
> says: Download R-3.3.3 Patched build for Windows
> <https://cran.r-project.org/bin/windows/base/R-3.3.3patched-win.exe>
> However, I am unclear how can one get to the patched 3.4.0 version?

If you are on Windows, you did the roight things, but the page has to be 
updated.CCing Duncan who maintains these pages.

Best,
Uwe



> Thank you!
>
> On Fri, Apr 28, 2017 at 7:58 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>
>
>
>     On 28.04.2017 10:45, Thierry Onkelinx wrote:
>
>         Dear Peter,
>
>         It actually breaks install.packages(). So it is not that innocent.
>
>
>     And hence, as Peter exoplained, it is already fixed inn R-patched,
>     thanks to Tomas Kalibera.
>
>     Best,
>     Uwe Ligges
>
>
>
>
>
>
>         Best regards,
>
>         Thierry
>
>
>         Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard"
>         <pdalgd at gmail.com <mailto:pdalgd at gmail.com>>:
>
>         Yes, we noticed this in the last days of the code freeze before
>         release and
>         shied away from inserting a workaround, partly because we
>         couldn't see what
>         the root of the problem might be.
>
>         For the purposes of installed.packages it is relatively harmless
>         to treat
>         the NA condition as FALSE, since it is just a matter of whether
>         a cache is
>         valid. I.e., it might cause an unnecessary cache rebuild. For other
>         situations it might be more of an issue.
>
>         The workaround (NA -> FALSE, basically) is in place in R-patched and
>         R-devel.
>
>         -pd
>
>             On 28 Apr 2017, at 07:47 , Thierry Onkelinx
>             <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>
>         wrote:
>
>
>             We have several computers with the same problem.
>
>             Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut"
>             <arbautjc at gmail.com <mailto:arbautjc at gmail.com>
>             :
>
>             Hello,
>
>             I am currently getting a strange error when I call
>             installed.packages():
>
>             Error in if (file.exists(dest) && file.mtime(dest) >
>             file.mtime(lib) &&  :
>              missing value where TRUE/FALSE needed
>             Calls: installed.packages
>
>
>             I am working with R 3.4.0 on Windows. I didn't get this
>             error with R
>
>         3.3.3.
>
>             Apparently, file.mtime() is returning NA well applied to a
>             directory, and
>             this causes the entire && expression to be NA, then the "if"
>             fails because
>             it needs either T or F.
>             The source of "installed.packages" seems to be roughly the
>             same as in R
>             3.3.3, so I wonder if there have been other changes in R,
>             maybe the
>
>         logical
>
>             operators, that would make this function fail.
>
>             Any idea?
>
>             Best regards,
>
>             Jean-Claude Arbaut
>
>                    [[alternative HTML version deleted]]
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide http://www.R-project.org/
>
>         posting-guide.html
>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>                   [[alternative HTML version deleted]]
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide http://www.R-project.org/
>
>         posting-guide.html
>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>         --
>         Peter Dalgaard, Professor,
>         Center for Statistics, Copenhagen Business School
>         Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>         Phone: (+45)38153501 <tel:%28%2B45%2938153501>
>         Office: A 4.23
>         Email: pd.mes at cbs.dk <mailto:pd.mes at cbs.dk>  Priv:
>         PDalgd at gmail.com <mailto:PDalgd at gmail.com>
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Sat Apr 29 00:33:38 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Apr 2017 18:33:38 -0400
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <076e7118-a0ee-d6c4-4331-bf40f2f2171d@statistik.tu-dortmund.de>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>
 <CAN2xGJYSsSwLSJjX1MVXfSxmySgc35zH_wgRYxY5auhz7tqGGQ@mail.gmail.com>
 <076e7118-a0ee-d6c4-4331-bf40f2f2171d@statistik.tu-dortmund.de>
Message-ID: <978c9478-b7b1-52cb-e70d-31bff177aacf@gmail.com>

On 28/04/2017 5:58 PM, Uwe Ligges wrote:
>
>
> On 28.04.2017 19:10, Dimitri Liakhovitski wrote:
>> When I click on "r patched snapshot build" here
>> <https://cran.r-project.org/bin/windows/base/>, it take me here
>> <https://cran.r-project.org/bin/windows/base/rpatched.html> , it
>> says: Download R-3.3.3 Patched build for Windows
>> <https://cran.r-project.org/bin/windows/base/R-3.3.3patched-win.exe>
>> However, I am unclear how can one get to the patched 3.4.0 version?
>
> If you are on Windows, you did the roight things, but the page has to be
> updated.CCing Duncan who maintains these pages.

Thanks, I missed that update.  It is now building 3.4.0-patched, so that 
version should be available on the mirrors in a few hours.

Duncan Murdoch

>
> Best,
> Uwe
>
>
>
>> Thank you!
>>
>> On Fri, Apr 28, 2017 at 7:58 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de
>> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>>
>>
>>
>>     On 28.04.2017 10:45, Thierry Onkelinx wrote:
>>
>>         Dear Peter,
>>
>>         It actually breaks install.packages(). So it is not that innocent.
>>
>>
>>     And hence, as Peter exoplained, it is already fixed inn R-patched,
>>     thanks to Tomas Kalibera.
>>
>>     Best,
>>     Uwe Ligges
>>
>>
>>
>>
>>
>>
>>         Best regards,
>>
>>         Thierry
>>
>>
>>         Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard"
>>         <pdalgd at gmail.com <mailto:pdalgd at gmail.com>>:
>>
>>         Yes, we noticed this in the last days of the code freeze before
>>         release and
>>         shied away from inserting a workaround, partly because we
>>         couldn't see what
>>         the root of the problem might be.
>>
>>         For the purposes of installed.packages it is relatively harmless
>>         to treat
>>         the NA condition as FALSE, since it is just a matter of whether
>>         a cache is
>>         valid. I.e., it might cause an unnecessary cache rebuild. For other
>>         situations it might be more of an issue.
>>
>>         The workaround (NA -> FALSE, basically) is in place in R-patched and
>>         R-devel.
>>
>>         -pd
>>
>>             On 28 Apr 2017, at 07:47 , Thierry Onkelinx
>>             <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>>
>>         wrote:
>>
>>
>>             We have several computers with the same problem.
>>
>>             Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut"
>>             <arbautjc at gmail.com <mailto:arbautjc at gmail.com>
>>             :
>>
>>             Hello,
>>
>>             I am currently getting a strange error when I call
>>             installed.packages():
>>
>>             Error in if (file.exists(dest) && file.mtime(dest) >
>>             file.mtime(lib) &&  :
>>              missing value where TRUE/FALSE needed
>>             Calls: installed.packages
>>
>>
>>             I am working with R 3.4.0 on Windows. I didn't get this
>>             error with R
>>
>>         3.3.3.
>>
>>             Apparently, file.mtime() is returning NA well applied to a
>>             directory, and
>>             this causes the entire && expression to be NA, then the "if"
>>             fails because
>>             it needs either T or F.
>>             The source of "installed.packages" seems to be roughly the
>>             same as in R
>>             3.3.3, so I wonder if there have been other changes in R,
>>             maybe the
>>
>>         logical
>>
>>             operators, that would make this function fail.
>>
>>             Any idea?
>>
>>             Best regards,
>>
>>             Jean-Claude Arbaut
>>
>>                    [[alternative HTML version deleted]]
>>
>>             ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>             list -- To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             PLEASE do read the posting guide http://www.R-project.org/
>>
>>         posting-guide.html
>>
>>             and provide commented, minimal, self-contained, reproducible
>>             code.
>>
>>                   [[alternative HTML version deleted]]
>>
>>             ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>             list -- To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             PLEASE do read the posting guide http://www.R-project.org/
>>
>>         posting-guide.html
>>
>>             and provide commented, minimal, self-contained, reproducible
>>             code.
>>
>>
>>         --
>>         Peter Dalgaard, Professor,
>>         Center for Statistics, Copenhagen Business School
>>         Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>         Phone: (+45)38153501 <tel:%28%2B45%2938153501>
>>         Office: A 4.23
>>         Email: pd.mes at cbs.dk <mailto:pd.mes at cbs.dk>  Priv:
>>         PDalgd at gmail.com <mailto:PDalgd at gmail.com>
>>
>>                 [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>> --
>> Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Sat Apr 29 00:46:15 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Apr 2017 18:46:15 -0400
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <125664f5-f052-06d6-c774-582a8493daf7@gmail.com>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
 <125664f5-f052-06d6-c774-582a8493daf7@gmail.com>
Message-ID: <f9e0b9cd-03a1-cea7-80b9-4be008c95524@gmail.com>

On 28/04/2017 5:37 PM, Henric Winell wrote:
> On 2017-04-26 22:17, Duncan Murdoch wrote:
>
>> On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
>>> A user contacted me directly about this, I answered with my best
>>> understanding of the
>>> recent R-help discussion of the issue, and their response to my
>>> response shows that I'm
>>> not quite right.
>>>
>>> I am emphatically not an MS Windows user so am asking for help --
>>> which I will cut/paste
>>> to this user and to the next dozen who will invariably contact me
>>> directly.
>>>
>>> Thanks,
>>>    Terry Therneau
>>>
>>>
>>>
>>> -------- Forwarded Message --------
>>> Subject: RE: survival package
>>> Date: Wed, 26 Apr 2017 18:05:30 +0000
>>> From: SeshanV at mskcc.org
>>> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>>>
>>> Thank you for the quick response. The session info command for v3.4.0
>>> does in fact report
>>> survival_2.41-3. Furthermore, while both v3.3.1 and v3.40 are on the
>>> same computer the
>>> library paths do not have any directory in common:
>>>
>>>> .libPaths()
>>> [1] "C:/Program Files/R/R-3.4.0/library"
>>>>
>>>
>>> and
>>>> .libPaths()
>>> [1] "C:/Program Files/R/R-3.3.1/library"
>>>>
>>>
>>>
>>> Thanks,
>>> Venkat
>>>
>>>
>>> -----Original Message-----
>>> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent:
>>> Wednesday, April 26, 2017
>>> 1:42 PM
>>> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
>>> Subject: Re: survival package
>>>
>>> This has been discussed in R-help by multiple people.  You have a
>>> pre-3.4 version of the
>>> survival package somewhere on your search path, and the method for
>>> resolving .C calls has
>>> changed.   The sessionInfo command should report survival version 2.41-3.
>>>
>>> Terry T.
>>>
>>>
>>> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>>>> Dear Prof. Therneau,
>>>>
>>>> I am encountering an error message when I try to use the coxfit6
>>>> routine from the survival package under the 3.4.0 version of R. The
>>>> minimal function and the script are in the attached file. This
>>>> function worked under earlier versions of R.
>>>>
>>>> ----------------------------------------------------------------------
>>>> -------------------------
>>>>
>>>> ***************************
>>>> **  Works under R-3.3.1  **
>>>> ***************************
>>>>
>>>>> source("coxfit6-issue.R")
>>>> [1] -0.4838181
>>>>
>>>>> sessionInfo()
>>>> R version 3.3.1 (2016-06-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>>> (build 7601) Service Pack 1
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] survival_2.39-4
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>>>
>>>> ----------------------------------------------------------------------
>>>> -------------------------
>>>>
>>>> ***********************************
>>>> **  Does not work under R-3.4.0  **
>>>> ***********************************
>>>>
>>>>> library(survival)
>>>>> source("coxfit6-issue.R")
>>>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime,
>>>> as.integer(sstat),  :
>>>>    "Ccoxfit6" not available for .Call() for package "survival"
>>
>> As far as I can see, that line doesn't appear in the current survival
>> source code, it's from some earlier version of the package.  The current
>> one has
>>
>> coxfit <- .Call(Ccoxfit6,
>>                       as.integer(maxiter),
>>                       stime,
>>                       sstat,
>>                       x[sorted,],
>>                       as.double(offset[sorted]),
>>                       weights,
>>                       newstrat,
>>                       as.integer(method=="efron"),
>>                       as.double(control$eps),
>>                       as.double(control$toler.chol),
>>                       as.vector(init),
>>                       as.integer(1))  # internally rescale
>>
>> There are several differences, the one leading to the error being the
>> change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That
>> corresponds to the difference between a registered symbol and an
>> unregistered one.
>
> I think it's worthwhile to point out that non-exported symbols are
> available using ':::'.  See WRE Section 5.4.
>
> So, after fixing the argument list, just use '.Call(survival:::Ccoxfit6,
> <args>)' instead of '.Call("Ccoxfit6", <args>, PACKAGE = "survival")'.
>

Yes, and in another section it says "Using foo:::f instead of foo::f 
allows access to unexported objects. This is generally not recommended, 
as the semantics of unexported objects may be changed by the package 
author in routine maintenance."

Duncan Murdoch

>
> Henric Winell
>
>
>
>>
>> Without seeing the code that led to the error message I can't really say
>> how the error came about.  There are a few ways:
>>
>> - The user has a copy of the coxph.fit function from an older version of
>> survival saved in their workspace, and are using that one instead of the
>> current one.
>>
>> - Some part of your code returns functions, and one of those is making
>> this call based on an object produced in an earlier version of survival.
>>
>> - There are really two versions of survival on the search path (or
>> perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.
>>
>> Duncan Murdoch
>>
>>>>> sessionInfo()
>>>> R version 3.4.0 (2017-04-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>>>> (build 7601) Service Pack 1
>>>>
>>>> Matrix products: default
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United
>>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4]
>>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] survival_2.41-3
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>>>> [5] lattice_0.20-35
>>>>
>>>> ----------------------------------------------------------------------
>>>> -------------------------
>>>>
>>>> When I remove the quotes surrounding Ccoxfit6 in the function both
>>>> versions give the error:
>>>>
>>>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])),
>>>> oo$coefficients,  :
>>>>    object 'Ccoxfit6' not found
>>>>
>>>>
>>>> I would greatly appreciate your help in resolving this.
>>>>
>>>> Thanks,
>>>> Venkat Seshan
>>>>
>>>
>>>
>>> =====================================================================
>>>
>>>       Please note that this e-mail and any files transmitted from
>>>       Memorial Sloan Kettering Cancer Center may be privileged,
>>> confidential,
>>>       and protected from disclosure under applicable law. If the
>>> reader of
>>>       this message is not the intended recipient, or an employee or agent
>>>       responsible for delivering this message to the intended recipient,
>>>       you are hereby notified that any reading, dissemination,
>>> distribution,
>>>       copying, or other use of this communication or any of its
>>> attachments
>>>       is strictly prohibited.  If you have received this communication in
>>>       error, please notify the sender immediately by replying to this
>>> message
>>>       and deleting this message, any attachments, and all copies and
>>> backups
>>>       from your computer.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From murdoch.duncan at gmail.com  Sat Apr 29 00:49:24 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Apr 2017 18:49:24 -0400
Subject: [R] Larger rgl-images?
In-Reply-To: <de5f3096-8d64-bb1c-67c4-69f2ed43f4a3@utu.fi>
References: <de5f3096-8d64-bb1c-67c4-69f2ed43f4a3@utu.fi>
Message-ID: <80f9a09b-a875-ccd9-d839-1a123c2af3ba@gmail.com>

On 28/04/2017 5:18 AM, Atte Tenkanen wrote:
> Hi,
>
> In package ?VecStatGraphs3D? is a DrawDensity3D-function in which the
> rgl-device size is defined as
> r3dDefaults$windowRect=c(0,0, WSizeWidth, WSizeHeight).
>
> To save, for instance, a png-snapshot, we can use rgl.snapshot()-function.
>
> The size of the file is dependent on the window and thus your screen and
> video card.
>
> Can we somehow produce  larger images virtually, for example, 4k-images
> (3840x2160)?
>

I don't know of a way to do that.  If you can create a virtual screen of 
that size, and your system allows you to create a window on it, then it 
might work:  but I haven't come across a way to do that that also 
supports OpenGL in the virtual window.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Sat Apr 29 01:38:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Apr 2017 16:38:44 -0700
Subject: [R] Data.table vs dplr handling multiple variables
In-Reply-To: <CA+ZkTxu1WexGQUOJt453zn-M_9Z3cNPLzB_UqtwLeqaaY0ga=Q@mail.gmail.com>
References: <CA+ZkTxu1WexGQUOJt453zn-M_9Z3cNPLzB_UqtwLeqaaY0ga=Q@mail.gmail.com>
Message-ID: <846DEB5C-62BA-47F3-B215-A5EAC87FE959@dcn.davis.ca.us>

All approaches have strong points and weak points. Your question has no clear answer.

I happen to like dplyr for many things (including lots of timestamp values), but base R is always there to solve problems if the analysis framework-du-jour has troubles. So learn base R ways of doing things if nothing else. 

For next time: please read the Posting Guide. Give us a minimal example in R of what you are trying to accomplish along with your description and what you think the right answer will look like (consider using the reprex R package), and turn off HTML in your email program at least for your mails sent to this list because HTML gets damaged to varying degrees by the mailing list and then we are left puzzled about what you were asking. 
-- 
Sent from my phone. Please excuse my brevity.

On April 28, 2017 8:13:18 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
>Hi All?
>
>I am often working with large datasets with multiple variables
>(integer,
>decimal, string, complex, date, and time) that require processing,
>cleaning, etc. I am relatively new to R and I would like to get some
>input
>on the following issue: I am trying to figure out which R-package(s) is
>most suitable for my work. I looked into data.table and dplyr. Both are
>very good but I found out that data.table does not handle time data
>well
>(one has to use fast time package) and not sure whether dplyr does the
>same
>or not. I am not sure about their handling of other variables listed
>above.
>I like data.table.
>
>
>The questions: (1) which package should I invest on learning and how to
>deal with issue like time data and possibly other variables such
>complex
>numbers, date, etc.? (2) What is the ?best? practical solution for such
>issue?
>
>
>
>Thanks in advance,
>
>
>EKE
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jake at jakestone.net  Sat Apr 29 01:42:15 2017
From: jake at jakestone.net (Jake Stone)
Date: Fri, 28 Apr 2017 16:42:15 -0700
Subject: [R] Opencpu and caching
Message-ID: <CAL964Uz80aUrHo4dtvQcrwrPxO253uvj3Q04GASeNjj+s5PKTA@mail.gmail.com>

I am new to opencpu. My specialty is java. I use R for very specific
analyses.

*PROBLEM*
My understanding is that each API call to opencpu opens a new R session.
My function will classify the data input using the predict method of a
linear discriminant analysis (lda from MASS package).
The initial linear discriminant analysis on 100000+ cases and 150+ factor
levels takes time (over 30 seconds). This function returns a list.
The subsequent prediction function is quick and returns a simple vector.


*APPROACH*
I run one opencpu function to run the initial lda. This only needs to run
once.
I want my second function to ONLY run the predict function. This is
possible if the lda is held as a global variable.
My understanding is that global variables are not possible in opencpu. So I
will have to cache the lda on the file system.
In sum, I need to run the lda just once and hold the analysis (a list)
either in memory or on the file system. I then retrieve the lda analysis
when predict is called.

*QUESTION*
Which approach is best, and how to implement?
1. I could use an opencpu function that creates and returns the lda. Then
when I call a prediction, I could retrieve the lda object (a list) from the
file system. But how do I retrieve the list from the file system. How
does opencpu even know where it is?
2. I could use r.cache package. I haven't used this package before but the
docs suggest it is a solution. Will this work?

Any advice would be deeply appreciated.

best
jake

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr 29 02:23:19 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Apr 2017 17:23:19 -0700
Subject: [R] Opencpu and caching
In-Reply-To: <CAL964Uz80aUrHo4dtvQcrwrPxO253uvj3Q04GASeNjj+s5PKTA@mail.gmail.com>
References: <CAL964Uz80aUrHo4dtvQcrwrPxO253uvj3Q04GASeNjj+s5PKTA@mail.gmail.com>
Message-ID: <840C24CE-DF22-491E-8825-42416B6D1206@dcn.davis.ca.us>

You have already been told this is the wrong list for these questions. Go ask in the OpenCPU support areas.

My very limited understanding of OpenCPU is that what you are asking for is specifically not supported. You need to setup your own function that does everything before it returns.
-- 
Sent from my phone. Please excuse my brevity.

On April 28, 2017 4:42:15 PM PDT, Jake Stone <jake at jakestone.net> wrote:
>I am new to opencpu. My specialty is java. I use R for very specific
>analyses.
>
>*PROBLEM*
>My understanding is that each API call to opencpu opens a new R
>session.
>My function will classify the data input using the predict method of a
>linear discriminant analysis (lda from MASS package).
>The initial linear discriminant analysis on 100000+ cases and 150+
>factor
>levels takes time (over 30 seconds). This function returns a list.
>The subsequent prediction function is quick and returns a simple
>vector.
>
>
>*APPROACH*
>I run one opencpu function to run the initial lda. This only needs to
>run
>once.
>I want my second function to ONLY run the predict function. This is
>possible if the lda is held as a global variable.
>My understanding is that global variables are not possible in opencpu.
>So I
>will have to cache the lda on the file system.
>In sum, I need to run the lda just once and hold the analysis (a list)
>either in memory or on the file system. I then retrieve the lda
>analysis
>when predict is called.
>
>*QUESTION*
>Which approach is best, and how to implement?
>1. I could use an opencpu function that creates and returns the lda.
>Then
>when I call a prediction, I could retrieve the lda object (a list) from
>the
>file system. But how do I retrieve the list from the file system. How
>does opencpu even know where it is?
>2. I could use r.cache package. I haven't used this package before but
>the
>docs suggest it is a solution. Will this work?
>
>Any advice would be deeply appreciated.
>
>best
>jake
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Apr 29 02:57:03 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 28 Apr 2017 20:57:03 -0400
Subject: [R] How create columns for squared values from previous columns?
Message-ID: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>

Dear R list,

I am am a little unsure what is the best way to approach this. I suppose I
have

> dat <- matrix(rnorm(30), ncol = 5)
> dat <- data.frame(dat)
> dat
           X1          X2          X3         X4          X5
1 -1.13999917 -0.87868106 -0.33000492  1.5241765 -0.92483388
2 -0.56168006 -0.08837883  1.96237792 -0.5335615  0.02880586
3  0.82800071 -1.89965562 -0.05438815 -0.9162857 -0.57470053
4 -0.03218412 -0.23119263 -1.10671765 -0.2885518 -0.30953951
5  1.70525779 -0.93854817 -1.05932636 -0.2983139 -0.21980145
6  1.19047531  0.38301678 -0.20830015 -0.6668266  0.82578534

Suppose I want to add columns X6, X7, X8, where
X6 = X1^2
X7 = X2^2
X8 = X3^2

I am thinking of using apply(), but df asks for column names, what's a
quick way to generate names on the fly?

Thank you very much!

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Sat Apr 29 03:21:44 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 28 Apr 2017 21:21:44 -0400
Subject: [R] How create columns for squared values from previous columns?
In-Reply-To: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
Message-ID: <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>

I came up with this solution,

> cbind(dat, dat[, 1:3]^2)
           X1         X2         X3         X4          X5          X1
    X2        X3
1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379 0.529641625
1.28428102 3.9432044
2  0.05126592  0.2858707  0.9075806 1.27582713 -0.49438507 0.002628194
0.08172203 0.8237026
3 -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475 0.163459669
0.29780978 1.4218277
4  1.40746971 -1.2279416  0.3296075 0.84411774 -0.52371619 1.980970990
1.50784058 0.1086411
5 -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500 0.289886944
0.22563275 0.2213842
6  0.90691210  0.7247171  0.8244184 0.73328097 -1.05284737 0.822489552
0.52521494 0.6796657

But, you would NOT ONLY get undesired variable names, BUT ALSO duplicated
names. I suppose I can use paste() to solve that?

Any better ideas?


On Fri, Apr 28, 2017 at 8:57 PM, C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
>
> I am am a little unsure what is the best way to approach this. I suppose I
> have
>
> > dat <- matrix(rnorm(30), ncol = 5)
> > dat <- data.frame(dat)
> > dat
>            X1          X2          X3         X4          X5
> 1 -1.13999917 -0.87868106 -0.33000492  1.5241765 -0.92483388
> 2 -0.56168006 -0.08837883  1.96237792 -0.5335615  0.02880586
> 3  0.82800071 -1.89965562 -0.05438815 -0.9162857 -0.57470053
> 4 -0.03218412 -0.23119263 -1.10671765 -0.2885518 -0.30953951
> 5  1.70525779 -0.93854817 -1.05932636 -0.2983139 -0.21980145
> 6  1.19047531  0.38301678 -0.20830015 -0.6668266  0.82578534
>
> Suppose I want to add columns X6, X7, X8, where
> X6 = X1^2
> X7 = X2^2
> X8 = X3^2
>
> I am thinking of using apply(), but df asks for column names, what's a
> quick way to generate names on the fly?
>
> Thank you very much!
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr 29 03:58:24 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Apr 2017 18:58:24 -0700
Subject: [R] Opencpu and caching
In-Reply-To: <CAL964Ux_wCtmwTeZbW0XHAkxGXMGpiJ+z8mphfo2aZaRgVtq9g@mail.gmail.com>
References: <CAL964Uz80aUrHo4dtvQcrwrPxO253uvj3Q04GASeNjj+s5PKTA@mail.gmail.com>
 <840C24CE-DF22-491E-8825-42416B6D1206@dcn.davis.ca.us>
 <CAL964Ux_wCtmwTeZbW0XHAkxGXMGpiJ+z8mphfo2aZaRgVtq9g@mail.gmail.com>
Message-ID: <2ECFC594-9EEC-4577-A421-BEA5C04A8B3C@dcn.davis.ca.us>

A) The https://www.opencpu.org/help.html page recommends a Google Group and Stack Overflow. If you were "told" otherwise, it was probably because they thought you needed to learn R, which would be off topic for their support areas. 

B) The R mailing lists Posting Guide says that questions about contributed packages such as opencpu belong on their respective support areas. I can't even find any other mentions of opencpu in the archives other than "check it out".

C) If your question is purely about R, go ahead and ask on the appropriate R mailing list (quite possibly this one), but phrase it in terms of R and don't drag in Java or some server architecture that is off topic. To emphasize this we strongly recommend creating a minimal reproducible example ("reprex"). There are websites that describe what this means[1][2], and an R package (called reprex) to help you verify that other people will in fact be able to run your example at least to the point where it generates the error you are dealing with. 

So, if you need to learn enough R in order to ask your question coherently in the OpenCPU support areas, maybe you should start with some R documentation and learn the language?

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On April 28, 2017 5:34:37 PM PDT, Jake Stone <jake at jakestone.net> wrote:
>Opencpu website recommends this site.
>You might want to clarify with them.
>
>
>
>On Apr 28, 2017 5:23 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> You have already been told this is the wrong list for these
>questions. Go
>> ask in the OpenCPU support areas.
>>
>> My very limited understanding of OpenCPU is that what you are asking
>for
>> is specifically not supported. You need to setup your own function
>that
>> does everything before it returns.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 28, 2017 4:42:15 PM PDT, Jake Stone <jake at jakestone.net>
>wrote:
>> >I am new to opencpu. My specialty is java. I use R for very specific
>> >analyses.
>> >
>> >*PROBLEM*
>> >My understanding is that each API call to opencpu opens a new R
>> >session.
>> >My function will classify the data input using the predict method of
>a
>> >linear discriminant analysis (lda from MASS package).
>> >The initial linear discriminant analysis on 100000+ cases and 150+
>> >factor
>> >levels takes time (over 30 seconds). This function returns a list.
>> >The subsequent prediction function is quick and returns a simple
>> >vector.
>> >
>> >
>> >*APPROACH*
>> >I run one opencpu function to run the initial lda. This only needs
>to
>> >run
>> >once.
>> >I want my second function to ONLY run the predict function. This is
>> >possible if the lda is held as a global variable.
>> >My understanding is that global variables are not possible in
>opencpu.
>> >So I
>> >will have to cache the lda on the file system.
>> >In sum, I need to run the lda just once and hold the analysis (a
>list)
>> >either in memory or on the file system. I then retrieve the lda
>> >analysis
>> >when predict is called.
>> >
>> >*QUESTION*
>> >Which approach is best, and how to implement?
>> >1. I could use an opencpu function that creates and returns the lda.
>> >Then
>> >when I call a prediction, I could retrieve the lda object (a list)
>from
>> >the
>> >file system. But how do I retrieve the list from the file system.
>How
>> >does opencpu even know where it is?
>> >2. I could use r.cache package. I haven't used this package before
>but
>> >the
>> >docs suggest it is a solution. Will this work?
>> >
>> >Any advice would be deeply appreciated.
>> >
>> >best
>> >jake
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>


From jake at jakestone.net  Sat Apr 29 04:07:34 2017
From: jake at jakestone.net (Jake Stone)
Date: Fri, 28 Apr 2017 19:07:34 -0700
Subject: [R] Opencpu and caching
In-Reply-To: <2ECFC594-9EEC-4577-A421-BEA5C04A8B3C@dcn.davis.ca.us>
References: <CAL964Uz80aUrHo4dtvQcrwrPxO253uvj3Q04GASeNjj+s5PKTA@mail.gmail.com>
 <840C24CE-DF22-491E-8825-42416B6D1206@dcn.davis.ca.us>
 <CAL964Ux_wCtmwTeZbW0XHAkxGXMGpiJ+z8mphfo2aZaRgVtq9g@mail.gmail.com>
 <2ECFC594-9EEC-4577-A421-BEA5C04A8B3C@dcn.davis.ca.us>
Message-ID: <CAL964Uw=vu4gpKtq-ztOG83Ois12c8BfrJsLi59+aysG+=Jw2A@mail.gmail.com>

OK? thanks for the info
 I apologize. I must have misread or misremembered.

I have found the answer btw. R
Cache serves the said purpose perfectly.




On Apr 28, 2017 6:58 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

A) The https://www.opencpu.org/help.html page recommends a Google Group and
Stack Overflow. If you were "told" otherwise, it was probably because they
thought you needed to learn R, which would be off topic for their support
areas.

B) The R mailing lists Posting Guide says that questions about contributed
packages such as opencpu belong on their respective support areas. I can't
even find any other mentions of opencpu in the archives other than "check
it out".

C) If your question is purely about R, go ahead and ask on the appropriate
R mailing list (quite possibly this one), but phrase it in terms of R and
don't drag in Java or some server architecture that is off topic. To
emphasize this we strongly recommend creating a minimal reproducible
example ("reprex"). There are websites that describe what this means[1][2],
and an R package (called reprex) to help you verify that other people will
in fact be able to run your example at least to the point where it
generates the error you are dealing with.

So, if you need to learn enough R in order to ask your question coherently
in the OpenCPU support areas, maybe you should start with some R
documentation and learn the language?

[1] http://stackoverflow.com/questions/5963269/how-to-make-
a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
--
Sent from my phone. Please excuse my brevity.

On April 28, 2017 5:34:37 PM PDT, Jake Stone <jake at jakestone.net> wrote:
>Opencpu website recommends this site.
>You might want to clarify with them.
>
>
>
>On Apr 28, 2017 5:23 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> You have already been told this is the wrong list for these
>questions. Go
>> ask in the OpenCPU support areas.
>>
>> My very limited understanding of OpenCPU is that what you are asking
>for
>> is specifically not supported. You need to setup your own function
>that
>> does everything before it returns.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 28, 2017 4:42:15 PM PDT, Jake Stone <jake at jakestone.net>
>wrote:
>> >I am new to opencpu. My specialty is java. I use R for very specific
>> >analyses.
>> >
>> >*PROBLEM*
>> >My understanding is that each API call to opencpu opens a new R
>> >session.
>> >My function will classify the data input using the predict method of
>a
>> >linear discriminant analysis (lda from MASS package).
>> >The initial linear discriminant analysis on 100000+ cases and 150+
>> >factor
>> >levels takes time (over 30 seconds). This function returns a list.
>> >The subsequent prediction function is quick and returns a simple
>> >vector.
>> >
>> >
>> >*APPROACH*
>> >I run one opencpu function to run the initial lda. This only needs
>to
>> >run
>> >once.
>> >I want my second function to ONLY run the predict function. This is
>> >possible if the lda is held as a global variable.
>> >My understanding is that global variables are not possible in
>opencpu.
>> >So I
>> >will have to cache the lda on the file system.
>> >In sum, I need to run the lda just once and hold the analysis (a
>list)
>> >either in memory or on the file system. I then retrieve the lda
>> >analysis
>> >when predict is called.
>> >
>> >*QUESTION*
>> >Which approach is best, and how to implement?
>> >1. I could use an opencpu function that creates and returns the lda.
>> >Then
>> >when I call a prediction, I could retrieve the lda object (a list)
>from
>> >the
>> >file system. But how do I retrieve the list from the file system.
>How
>> >does opencpu even know where it is?
>> >2. I could use r.cache package. I haven't used this package before
>but
>> >the
>> >docs suggest it is a solution. Will this work?
>> >
>> >Any advice would be deeply appreciated.
>> >
>> >best
>> >jake
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Apr 29 04:48:42 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 29 Apr 2017 14:48:42 +1200
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
Message-ID: <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>

On 29/04/17 13:21, C W wrote:
> I came up with this solution,
>
>> cbind(dat, dat[, 1:3]^2)
>            X1         X2         X3         X4          X5          X1
>     X2        X3
> 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379 0.529641625
> 1.28428102 3.9432044
> 2  0.05126592  0.2858707  0.9075806 1.27582713 -0.49438507 0.002628194
> 0.08172203 0.8237026
> 3 -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475 0.163459669
> 0.29780978 1.4218277
> 4  1.40746971 -1.2279416  0.3296075 0.84411774 -0.52371619 1.980970990
> 1.50784058 0.1086411
> 5 -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500 0.289886944
> 0.22563275 0.2213842
> 6  0.90691210  0.7247171  0.8244184 0.73328097 -1.05284737 0.822489552
> 0.52521494 0.6796657
>
> But, you would NOT ONLY get undesired variable names, BUT ALSO duplicated
> names. I suppose I can use paste() to solve that?
>
> Any better ideas?

Well, if the names bizzo is your only worry, you could hit the result 
with data.frame() *after* cbinding on the squared terms:

dat <- matrix(rnorm(30),ncol=5)
dat <- cbind(dat,dat[,1:3]^2)
dat <- data.frame(dat)
names(dat)

And as you indicate, the names of a data frame are easily adjusted.

I wouldn't lose sleep over it.

cheers,

Rolf Turner

P.S. You could also do

     names(dat) <- make.unique(names(dat))

to your original idea, to get rid of the lack of uniqueness.  The result 
is probably "undesirable" but.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ragia11 at hotmail.com  Sat Apr 29 06:13:39 2017
From: ragia11 at hotmail.com (Ragia .)
Date: Sat, 29 Apr 2017 04:13:39 +0000
Subject: [R] read list of binary files and explore them
Message-ID: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>


Dear group,

I have  list of  4-byte float type files, the files are named f00, f01, f02 till f99....


kindly how can I read and explore them in R, merge the readings in a table or data frame

thanks in advance,


Ragia A. Ibrahim



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Apr 29 06:31:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 28 Apr 2017 21:31:58 -0700
Subject: [R] read list of binary files and explore them
In-Reply-To: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
References: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRTH_WjSs-G0+GR4ePwjM+aZxPqj_=v81RMUDLwyAC-yA@mail.gmail.com>

 ?readBin  (a search on "read binary files R" or similar would have found this).

and please spend some time with the R import/export manual + tutorials
to learn how to manipulate data in R. This list expects you to make an
effort to do your own work before posting. See the posting guide below
for details.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 28, 2017 at 9:13 PM, Ragia . <ragia11 at hotmail.com> wrote:
>
> Dear group,
>
> I have  list of  4-byte float type files, the files are named f00, f01, f02 till f99....
>
>
> kindly how can I read and explore them in R, merge the readings in a table or data frame
>
> thanks in advance,
>
>
> Ragia A. Ibrahim
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Apr 29 06:45:42 2017
From: tmrsg11 at gmail.com (Mike C)
Date: Sat, 29 Apr 2017 04:45:42 +0000
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>,
 <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
Message-ID: <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>

Thanks Rolf.
I was just a bit frustrated that R wouldn't generate dummy variable names on the fly.

Also, another question, if I want to put column 5 at column 3,

dat[, 3:5] <- dat[, c(5,3,4)]

It does not work, why?

________________________________
From: Rolf Turner <r.turner at auckland.ac.nz>
Sent: Friday, April 28, 2017 10:48:42 PM
To: C W
Cc: r-help
Subject: Re: [FORGED] Re: [R] How create columns for squared values from previous columns?

On 29/04/17 13:21, C W wrote:
> I came up with this solution,
>
>> cbind(dat, dat[, 1:3]^2)
>            X1         X2         X3         X4          X5          X1
>     X2        X3
> 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379 0.529641625
> 1.28428102 3.9432044
> 2  0.05126592  0.2858707  0.9075806 1.27582713 -0.49438507 0.002628194
> 0.08172203 0.8237026
> 3 -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475 0.163459669
> 0.29780978 1.4218277
> 4  1.40746971 -1.2279416  0.3296075 0.84411774 -0.52371619 1.980970990
> 1.50784058 0.1086411
> 5 -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500 0.289886944
> 0.22563275 0.2213842
> 6  0.90691210  0.7247171  0.8244184 0.73328097 -1.05284737 0.822489552
> 0.52521494 0.6796657
>
> But, you would NOT ONLY get undesired variable names, BUT ALSO duplicated
> names. I suppose I can use paste() to solve that?
>
> Any better ideas?

Well, if the names bizzo is your only worry, you could hit the result
with data.frame() *after* cbinding on the squared terms:

dat <- matrix(rnorm(30),ncol=5)
dat <- cbind(dat,dat[,1:3]^2)
dat <- data.frame(dat)
names(dat)

And as you indicate, the names of a data frame are easily adjusted.

I wouldn't lose sleep over it.

cheers,

Rolf Turner

P.S. You could also do

     names(dat) <- make.unique(names(dat))

to your original idea, to get rid of the lack of uniqueness.  The result
is probably "undesirable" but.

R. T.

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sat Apr 29 10:02:21 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 29 Apr 2017 13:32:21 +0530
Subject: [R] How to download the Shiny tutorial video
Message-ID: <CA+dpOJmv6vKJpAJLTPLOA5VcSth0wpBXtaYx27c0JR_4rDj_XA@mail.gmail.com>

Hi again,

I was trying to learn Shiny from Shiny tutorial "Teach yourself Shiny"
available in https://shiny.rstudio.com/tutorial/.

I intend to download this entire video for offline use, however could
not find any option available to doing so. I use slow internet
connection, therefore it is useful to me if I can download it onto my
hard disk.

I know it is a bot off topic for most of the Forum, however still
hopeful that I will get some pointer on how to download the video.

Thanks for your time


From goran.brostrom at umu.se  Sat Apr 29 10:06:45 2017
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 29 Apr 2017 10:06:45 +0200
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
 <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
 <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>
Message-ID: <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>



On 2017-04-29 06:45, Mike C wrote:
> Thanks Rolf. I was just a bit frustrated that R wouldn't generate
> dummy variable names on the fly.
>
> Also, another question, if I want to put column 5 at column 3,
>
> dat[, 3:5] <- dat[, c(5,3,4)]
>
> It does not work, why?

It "works", but you need to shuffle the names in the same way:

names(dat)[3:5] <- names(dat)[c(5,3,4)]

Better(?):

perm <- c(1,2,5,3,4)
dat <- dat[perm]

dat is a list.

G?ran

>
> ________________________________ From: Rolf Turner
> <r.turner at auckland.ac.nz> Sent: Friday, April 28, 2017 10:48:42 PM
> To: C W Cc: r-help Subject: Re: [FORGED] Re: [R] How create columns
> for squared values from previous columns?
>
> On 29/04/17 13:21, C W wrote:
>> I came up with this solution,
>>
>>> cbind(dat, dat[, 1:3]^2)
>> X1         X2         X3         X4          X5          X1 X2
>> X3 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379
>> 0.529641625 1.28428102 3.9432044 2  0.05126592  0.2858707
>> 0.9075806 1.27582713 -0.49438507 0.002628194 0.08172203 0.8237026 3
>> -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475
>> 0.163459669 0.29780978 1.4218277 4  1.40746971 -1.2279416
>> 0.3296075 0.84411774 -0.52371619 1.980970990 1.50784058 0.1086411 5
>> -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500
>> 0.289886944 0.22563275 0.2213842 6  0.90691210  0.7247171
>> 0.8244184 0.73328097 -1.05284737 0.822489552 0.52521494 0.6796657
>>
>> But, you would NOT ONLY get undesired variable names, BUT ALSO
>> duplicated names. I suppose I can use paste() to solve that?
>>
>> Any better ideas?
>
> Well, if the names bizzo is your only worry, you could hit the
> result with data.frame() *after* cbinding on the squared terms:
>
> dat <- matrix(rnorm(30),ncol=5) dat <- cbind(dat,dat[,1:3]^2) dat <-
> data.frame(dat) names(dat)
>
> And as you indicate, the names of a data frame are easily adjusted.
>
> I wouldn't lose sleep over it.
>
> cheers,
>
> Rolf Turner
>
> P.S. You could also do
>
> names(dat) <- make.unique(names(dat))
>
> to your original idea, to get rid of the lack of uniqueness.  The
> result is probably "undesirable" but.
>
> R. T.
>
> -- Technical Editor ANZJS Department of Statistics University of
> Auckland Phone: +64-9-373-7599 ext. 88276
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Sat Apr 29 16:40:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 29 Apr 2017 07:40:20 -0700
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
 <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
 <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>
 <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>
Message-ID: <CAGxFJbRXUrcM2=7duvjhz_=jC++=eSPjNJwUKdzsGXkbtrxbdA@mail.gmail.com>

Also:

"I was just a bit frustrated that R wouldn't generate dummy variable
names on the fly."

That is false. See ?lm  and ?model.matrix

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 29, 2017 at 1:06 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
>
>
> On 2017-04-29 06:45, Mike C wrote:
>>
>> Thanks Rolf. I was just a bit frustrated that R wouldn't generate
>> dummy variable names on the fly.
>>
>> Also, another question, if I want to put column 5 at column 3,
>>
>> dat[, 3:5] <- dat[, c(5,3,4)]
>>
>> It does not work, why?
>
>
> It "works", but you need to shuffle the names in the same way:
>
> names(dat)[3:5] <- names(dat)[c(5,3,4)]
>
> Better(?):
>
> perm <- c(1,2,5,3,4)
> dat <- dat[perm]
>
> dat is a list.
>
> G?ran
>
>
>>
>> ________________________________ From: Rolf Turner
>> <r.turner at auckland.ac.nz> Sent: Friday, April 28, 2017 10:48:42 PM
>> To: C W Cc: r-help Subject: Re: [FORGED] Re: [R] How create columns
>> for squared values from previous columns?
>>
>> On 29/04/17 13:21, C W wrote:
>>>
>>> I came up with this solution,
>>>
>>>> cbind(dat, dat[, 1:3]^2)
>>>
>>> X1         X2         X3         X4          X5          X1 X2
>>> X3 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379
>>> 0.529641625 1.28428102 3.9432044 2  0.05126592  0.2858707
>>> 0.9075806 1.27582713 -0.49438507 0.002628194 0.08172203 0.8237026 3
>>> -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475
>>> 0.163459669 0.29780978 1.4218277 4  1.40746971 -1.2279416
>>> 0.3296075 0.84411774 -0.52371619 1.980970990 1.50784058 0.1086411 5
>>> -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500
>>> 0.289886944 0.22563275 0.2213842 6  0.90691210  0.7247171
>>> 0.8244184 0.73328097 -1.05284737 0.822489552 0.52521494 0.6796657
>>>
>>> But, you would NOT ONLY get undesired variable names, BUT ALSO
>>> duplicated names. I suppose I can use paste() to solve that?
>>>
>>> Any better ideas?
>>
>>
>> Well, if the names bizzo is your only worry, you could hit the
>> result with data.frame() *after* cbinding on the squared terms:
>>
>> dat <- matrix(rnorm(30),ncol=5) dat <- cbind(dat,dat[,1:3]^2) dat <-
>> data.frame(dat) names(dat)
>>
>> And as you indicate, the names of a data frame are easily adjusted.
>>
>> I wouldn't lose sleep over it.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P.S. You could also do
>>
>> names(dat) <- make.unique(names(dat))
>>
>> to your original idea, to get rid of the lack of uniqueness.  The
>> result is probably "undesirable" but.
>>
>> R. T.
>>
>> -- Technical Editor ANZJS Department of Statistics University of
>> Auckland Phone: +64-9-373-7599 ext. 88276
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr 29 16:41:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 29 Apr 2017 07:41:40 -0700
Subject: [R] How to download the Shiny tutorial video
In-Reply-To: <CA+dpOJmv6vKJpAJLTPLOA5VcSth0wpBXtaYx27c0JR_4rDj_XA@mail.gmail.com>
References: <CA+dpOJmv6vKJpAJLTPLOA5VcSth0wpBXtaYx27c0JR_4rDj_XA@mail.gmail.com>
Message-ID: <CAGxFJbQGPAy7XOQwRgVTZsq7JkUQdEJKDKNdVBPnTHAqn51GSA@mail.gmail.com>

It is OT! Why not post on the RStudio forum?

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 29, 2017 at 1:02 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I was trying to learn Shiny from Shiny tutorial "Teach yourself Shiny"
> available in https://shiny.rstudio.com/tutorial/.
>
> I intend to download this entire video for offline use, however could
> not find any option available to doing so. I use slow internet
> connection, therefore it is useful to me if I can download it onto my
> hard disk.
>
> I know it is a bot off topic for most of the Forum, however still
> hopeful that I will get some pointer on how to download the video.
>
> Thanks for your time
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr 29 16:45:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 29 Apr 2017 07:45:29 -0700
Subject: [R] read list of binary files and explore them
In-Reply-To: <VI1PR10MB024045E0E414BFD5BFAEFCA9B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
References: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
 <CAGxFJbRTH_WjSs-G0+GR4ePwjM+aZxPqj_=v81RMUDLwyAC-yA@mail.gmail.com>
 <VI1PR10MB024045E0E414BFD5BFAEFCA9B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQbCeku7oWMdGi9G5d1EKdw6ynP8SW17Ew1AazOK95qMw@mail.gmail.com>

1. Unless your comment is OT or personal, always reply to the list.

2. What does your OS say about file size?

3. Beyond this, I cannot help.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Apr 29, 2017 at 6:38 AM, Ragia . <ragia11 at hotmail.com> wrote:

>
> lots  of thanks for answering, I guess I asked the question in wont way...
>
> I did that, but some times I got one single reading( number) from the
> file..other times two numbers, is there a way to be sure that I am reading
> it correctly? what I know is not more than its float content .
>
>
> Ribrahim
>
>
>
>
> ------------------------------
> *From:* Bert Gunter <bgunter.4567 at gmail.com>
> *Sent:* Saturday, April 29, 2017 6:31 AM
> *To:* Ragia .
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] read list of binary files and explore them
>
>
>  ?readBin  (a search on "read binary files R" or similar would have found
> this).
>
> and please spend some time with the R import/export manual + tutorials
> to learn how to manipulate data in R. This list expects you to make an
> effort to do your own work before posting. See the posting guide below
> for details.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 28, 2017 at 9:13 PM, Ragia . <ragia11 at hotmail.com> wrote:
> >
> > Dear group,
> >
> > I have  list of  4-byte float type files, the files are named f00, f01,
> f02 till f99....
> >
> >
> > kindly how can I read and explore them in R, merge the readings in a
> table or data frame
> >
> > thanks in advance,
> >
> >
> > Ragia A. Ibrahim
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> R-help -- Main R Mailing List: Primary help - Homepage - SfS
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and
> the availability of new code, questions and answers about problems and
> solutions using R ...
>
>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Sat Apr 29 17:34:33 2017
From: ragia11 at hotmail.com (Ragia .)
Date: Sat, 29 Apr 2017 15:34:33 +0000
Subject: [R] read list of binary files and explore them
In-Reply-To: <CAGxFJbQbCeku7oWMdGi9G5d1EKdw6ynP8SW17Ew1AazOK95qMw@mail.gmail.com>
References: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
 <CAGxFJbRTH_WjSs-G0+GR4ePwjM+aZxPqj_=v81RMUDLwyAC-yA@mail.gmail.com>
 <VI1PR10MB024045E0E414BFD5BFAEFCA9B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>,
 <CAGxFJbQbCeku7oWMdGi9G5d1EKdw6ynP8SW17Ew1AazOK95qMw@mail.gmail.com>
Message-ID: <VI1PR10MB0240E828357B13602CD173E8B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>


 files size is 7682 kb

sorry for multiple emails

Ragia




________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Saturday, April 29, 2017 4:45 PM
To: Ragia .; R-help
Subject: Re: [R] read list of binary files and explore them

1. Unless your comment is OT or personal, always reply to the list.

2. What does your OS say about file size?

3. Beyond this, I cannot help.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Apr 29, 2017 at 6:38 AM, Ragia . <ragia11 at hotmail.com<mailto:ragia11 at hotmail.com>> wrote:


lots  of thanks for answering, I guess I asked the question in wont way...

I did that, but some times I got one single reading( number) from the file..other times two numbers, is there a way to be sure that I am reading it correctly? what I know is not more than its float content .


Ribrahim




________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
Sent: Saturday, April 29, 2017 6:31 AM
To: Ragia .
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] read list of binary files and explore them


 ?readBin  (a search on "read binary files R" or similar would have found this).

and please spend some time with the R import/export manual + tutorials
to learn how to manipulate data in R. This list expects you to make an
effort to do your own work before posting. See the posting guide below
for details.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 28, 2017 at 9:13 PM, Ragia . <ragia11 at hotmail.com<mailto:ragia11 at hotmail.com>> wrote:
>
> Dear group,
>
> I have  list of  4-byte float type files, the files are named f00, f01, f02 till f99....
>
>
> kindly how can I read and explore them in R, merge the readings in a table or data frame
>
> thanks in advance,
>
>
> Ragia A. Ibrahim
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch<http://stat.ethz.ch>
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat Apr 29 17:51:50 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 29 Apr 2017 11:51:50 -0400
Subject: [R] read list of binary files and explore them
In-Reply-To: <VI1PR10MB0240E828357B13602CD173E8B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
References: <VI1PR10MB024047E17454700B06EBE325B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
 <CAGxFJbRTH_WjSs-G0+GR4ePwjM+aZxPqj_=v81RMUDLwyAC-yA@mail.gmail.com>
 <VI1PR10MB024045E0E414BFD5BFAEFCA9B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
 <CAGxFJbQbCeku7oWMdGi9G5d1EKdw6ynP8SW17Ew1AazOK95qMw@mail.gmail.com>
 <VI1PR10MB0240E828357B13602CD173E8B3120@VI1PR10MB0240.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <615B7668-8852-49D5-8A43-AC1FD8452873@utoronto.ca>

Given that, you can be certain that your file contains more than one or two numbers, thus your way of reading it must be wrong.

B.





> On Apr 29, 2017, at 11:34 AM, Ragia . <ragia11 at hotmail.com> wrote:
> 
> 
> files size is 7682 kb
> 
> sorry for multiple emails
> 
> Ragia
> 
> 
> 
> 
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Saturday, April 29, 2017 4:45 PM
> To: Ragia .; R-help
> Subject: Re: [R] read list of binary files and explore them
> 
> 1. Unless your comment is OT or personal, always reply to the list.
> 
> 2. What does your OS say about file size?
> 
> 3. Beyond this, I cannot help.
> 
> -- Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Sat, Apr 29, 2017 at 6:38 AM, Ragia . <ragia11 at hotmail.com<mailto:ragia11 at hotmail.com>> wrote:
> 
> 
> lots  of thanks for answering, I guess I asked the question in wont way...
> 
> I did that, but some times I got one single reading( number) from the file..other times two numbers, is there a way to be sure that I am reading it correctly? what I know is not more than its float content .
> 
> 
> Ribrahim
> 
> 
> 
> 
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> Sent: Saturday, April 29, 2017 6:31 AM
> To: Ragia .
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] read list of binary files and explore them
> 
> 
> ?readBin  (a search on "read binary files R" or similar would have found this).
> 
> and please spend some time with the R import/export manual + tutorials
> to learn how to manipulate data in R. This list expects you to make an
> effort to do your own work before posting. See the posting guide below
> for details.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Apr 28, 2017 at 9:13 PM, Ragia . <ragia11 at hotmail.com<mailto:ragia11 at hotmail.com>> wrote:
>> 
>> Dear group,
>> 
>> I have  list of  4-byte float type files, the files are named f00, f01, f02 till f99....
>> 
>> 
>> kindly how can I read and explore them in R, merge the readings in a table or data frame
>> 
>> thanks in advance,
>> 
>> 
>> Ragia A. Ibrahim
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
> 
> thz.ch/mailman/listinfo/r-help>
> stat.ethz.ch<http://stat.ethz.ch>
> The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...
> 
> 
> 
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr 29 18:53:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 29 Apr 2017 09:53:08 -0700
Subject: [R] Matrix-list table conversion+nrwos with specefic values.
In-Reply-To: <CY4PR15MB1302FCADFF1D33CB273A5386EF120@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302FCADFF1D33CB273A5386EF120@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAGxFJbQLZNF_HdVrQog4Y1yOMSBL7YPAL57k10_rO-VMc56KHw@mail.gmail.com>

I am not a private (or free!) consultant. Post to the r-help if your
question concerns R.

-- Bert

Bert Gunter



On Sat, Apr 29, 2017 at 8:51 AM, abo dalash <abo_dlsh at hotmail.com> wrote:
> Hi dear Bert
>
>
> I'm trying to identify number of rows containing 2 specific values.
>
> I tried : which(mydata == 566,235), but this returns logical values for all
> rows and any T in a certain row indicates the existence of one of these
> values but what I need to know is only number of rows in my data set with
> these 2 particular values considering these two values
>
> as one pair per row. For example :
>
>
> 1          123   566    235
>
> 2          443    54      566
>
> 3          566    44      235
>
>
> here number of rows with the values 566&235 is 2 which are
>
> rows 1 & 3. Row 2 has only 566 so it should not be included in
>
> our calculation.
>
>
> I also have a large matrix and wanted to convert it into a table so I can
>
> easily identify the combination with higher frequencies.
>
>
> The matrix looks like this:
>
>
>                     x      y      z
>
> x                  0      5       67
>
> y                  na    0      23
>
> z                   na   na      0
>
>
> and I would like to convert this into a table arranged with
>
> higher values first like this :
>
> x       z       67
>
> y       z       23
>
> x       y        5
>
> x       x        0
>
> y       y        0
>
> z        z        0
>
> y        x        na
>
> z        x        na
>
> z        y        na
>
>
> Is there a simple function to perform this conversion with some explanation
> about the Syntax if you don't mind?
>
>
> Regards


From arbautjc at gmail.com  Sat Apr 29 12:11:40 2017
From: arbautjc at gmail.com (Jean-Claude Arbaut)
Date: Sat, 29 Apr 2017 12:11:40 +0200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <978c9478-b7b1-52cb-e70d-31bff177aacf@gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <2f746635-6373-dbe4-66d7-afd4c47b8deb@statistik.tu-dortmund.de>
 <CAN2xGJYSsSwLSJjX1MVXfSxmySgc35zH_wgRYxY5auhz7tqGGQ@mail.gmail.com>
 <076e7118-a0ee-d6c4-4331-bf40f2f2171d@statistik.tu-dortmund.de>
 <978c9478-b7b1-52cb-e70d-31bff177aacf@gmail.com>
Message-ID: <CANufCk7Yzt+Yqxy0O+7tDrE34U8r46PCFLcfg2Z-F7swy4CULw@mail.gmail.com>

Thank you all for the help. I will try the patch.

Best regards,

Jean-Claude Arbaut

2017-04-29 0:33 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 28/04/2017 5:58 PM, Uwe Ligges wrote:
>
>>
>>
>> On 28.04.2017 19:10, Dimitri Liakhovitski wrote:
>>
>>> When I click on "r patched snapshot build" here
>>> <https://cran.r-project.org/bin/windows/base/>, it take me here
>>> <https://cran.r-project.org/bin/windows/base/rpatched.html> , it
>>> says: Download R-3.3.3 Patched build for Windows
>>> <https://cran.r-project.org/bin/windows/base/R-3.3.3patched-win.exe>
>>> However, I am unclear how can one get to the patched 3.4.0 version?
>>>
>>
>> If you are on Windows, you did the roight things, but the page has to be
>> updated.CCing Duncan who maintains these pages.
>>
>
> Thanks, I missed that update.  It is now building 3.4.0-patched, so that
> version should be available on the mirrors in a few hours.
>
> Duncan Murdoch
>
>
>> Best,
>> Uwe
>>
>>
>>
>> Thank you!
>>>
>>> On Fri, Apr 28, 2017 at 7:58 AM, Uwe Ligges
>>> <ligges at statistik.tu-dortmund.de
>>> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>>>
>>>
>>>
>>>     On 28.04.2017 10:45, Thierry Onkelinx wrote:
>>>
>>>         Dear Peter,
>>>
>>>         It actually breaks install.packages(). So it is not that
>>> innocent.
>>>
>>>
>>>     And hence, as Peter exoplained, it is already fixed inn R-patched,
>>>     thanks to Tomas Kalibera.
>>>
>>>     Best,
>>>     Uwe Ligges
>>>
>>>
>>>
>>>
>>>
>>>
>>>         Best regards,
>>>
>>>         Thierry
>>>
>>>
>>>         Op 28 apr. 2017 10:36 a.m. schreef "peter dalgaard"
>>>         <pdalgd at gmail.com <mailto:pdalgd at gmail.com>>:
>>>
>>>         Yes, we noticed this in the last days of the code freeze before
>>>         release and
>>>         shied away from inserting a workaround, partly because we
>>>         couldn't see what
>>>         the root of the problem might be.
>>>
>>>         For the purposes of installed.packages it is relatively harmless
>>>         to treat
>>>         the NA condition as FALSE, since it is just a matter of whether
>>>         a cache is
>>>         valid. I.e., it might cause an unnecessary cache rebuild. For
>>> other
>>>         situations it might be more of an issue.
>>>
>>>         The workaround (NA -> FALSE, basically) is in place in R-patched
>>> and
>>>         R-devel.
>>>
>>>         -pd
>>>
>>>             On 28 Apr 2017, at 07:47 , Thierry Onkelinx
>>>             <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>>>
>>>         wrote:
>>>
>>>
>>>             We have several computers with the same problem.
>>>
>>>             Op 28 apr. 2017 7:25 a.m. schreef "Jean-Claude Arbaut"
>>>             <arbautjc at gmail.com <mailto:arbautjc at gmail.com>
>>>             :
>>>
>>>             Hello,
>>>
>>>             I am currently getting a strange error when I call
>>>             installed.packages():
>>>
>>>             Error in if (file.exists(dest) && file.mtime(dest) >
>>>             file.mtime(lib) &&  :
>>>              missing value where TRUE/FALSE needed
>>>             Calls: installed.packages
>>>
>>>
>>>             I am working with R 3.4.0 on Windows. I didn't get this
>>>             error with R
>>>
>>>         3.3.3.
>>>
>>>             Apparently, file.mtime() is returning NA well applied to a
>>>             directory, and
>>>             this causes the entire && expression to be NA, then the "if"
>>>             fails because
>>>             it needs either T or F.
>>>             The source of "installed.packages" seems to be roughly the
>>>             same as in R
>>>             3.3.3, so I wonder if there have been other changes in R,
>>>             maybe the
>>>
>>>         logical
>>>
>>>             operators, that would make this function fail.
>>>
>>>             Any idea?
>>>
>>>             Best regards,
>>>
>>>             Jean-Claude Arbaut
>>>
>>>                    [[alternative HTML version deleted]]
>>>
>>>             ______________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>             list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide http://www.R-project.org/
>>>
>>>         posting-guide.html
>>>
>>>             and provide commented, minimal, self-contained, reproducible
>>>             code.
>>>
>>>                   [[alternative HTML version deleted]]
>>>
>>>             ______________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>             list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide http://www.R-project.org/
>>>
>>>         posting-guide.html
>>>
>>>             and provide commented, minimal, self-contained, reproducible
>>>             code.
>>>
>>>
>>>         --
>>>         Peter Dalgaard, Professor,
>>>         Center for Statistics, Copenhagen Business School
>>>         Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>         Phone: (+45)38153501 <tel:%28%2B45%2938153501>
>>>         Office: A 4.23
>>>         Email: pd.mes at cbs.dk <mailto:pd.mes at cbs.dk>  Priv:
>>>         PDalgd at gmail.com <mailto:PDalgd at gmail.com>
>>>
>>>                 [[alternative HTML version deleted]]
>>>
>>>         ______________________________________________
>>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>         -- To UNSUBSCRIBE and more, see
>>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>         PLEASE do read the posting guide
>>>         http://www.R-project.org/posting-guide.html
>>>         <http://www.R-project.org/posting-guide.html>
>>>         and provide commented, minimal, self-contained, reproducible
>>> code.
>>>
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>     To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>     PLEASE do read the posting guide
>>>     http://www.R-project.org/posting-guide.html
>>>     <http://www.R-project.org/posting-guide.html>
>>>     and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abo_dlsh at hotmail.com  Sat Apr 29 17:13:44 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Sat, 29 Apr 2017 15:13:44 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into a
	table
Message-ID: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1          123   566    235

2          443    54      566

3          566    44      235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


                    x      y      z

x                  0      5       67

y                  na    0      23

z                   na   na      0


and I would like to convert this into a table arranged with

higher values first like this :

x       z       67

y       z       23

x       y        5

x       x        0

y       y        0

z        z        0

y        x        na

z        x        na

z        y        na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr 29 21:11:08 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 29 Apr 2017 12:11:08 -0700
Subject: [R] Matrix-list table conversion+nrwos with specefic values.
In-Reply-To: <CAGxFJbQLZNF_HdVrQog4Y1yOMSBL7YPAL57k10_rO-VMc56KHw@mail.gmail.com>
References: <CY4PR15MB1302FCADFF1D33CB273A5386EF120@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAGxFJbQLZNF_HdVrQog4Y1yOMSBL7YPAL57k10_rO-VMc56KHw@mail.gmail.com>
Message-ID: <80B88966-B791-4083-AD3D-F1123BB8CD83@dcn.davis.ca.us>

Break it down. If you have a scalar value val and you want to know if it is in a vector vec, using val==vec gets you a logical vector as long as vec. You can use val %in% vec and you get a logical vector as long as val (e.g. 1). If val is a vector of, say, length 2, then you will get a length 2 logical vector. In your example, c(566,23) %in% c(123, 566, 235) would be c( TRUE, TRUE ). Since you want both of these elements to be TRUE,  you can use the all() function as in all( c(566,23) %in% c(123, 566, 235) ). So use the apply function to examine each row as a vector and you have it:

apply( mat, 1, function(v) { all( c( 566,235) %in% v ) } )

Note that this only works if your data are integers (see FAQ 7.31).

Re the matrix to table... use expand.grid and matrix indexing.

tbl <- expand.grid( r = seq.int( nrow( mat ) )
                  , c = seq.int( ncol( mat ) ) )
tbl$val <- mat[ as.matrix( tbl[ , c( "r","c" ) ] ) ]
tbl[ order( tbl$val, decreasing=TRUE), ]

-- 
Sent from my phone. Please excuse my brevity.

On April 29, 2017 9:53:08 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I am not a private (or free!) consultant. Post to the r-help if your
>question concerns R.
>
>-- Bert
>
>Bert Gunter
>
>
>
>On Sat, Apr 29, 2017 at 8:51 AM, abo dalash <abo_dlsh at hotmail.com>
>wrote:
>> Hi dear Bert
>>
>>
>> I'm trying to identify number of rows containing 2 specific values.
>>
>> I tried : which(mydata == 566,235), but this returns logical values
>for all
>> rows and any T in a certain row indicates the existence of one of
>these
>> values but what I need to know is only number of rows in my data set
>with
>> these 2 particular values considering these two values
>>
>> as one pair per row. For example :
>>
>>
>> 1          123   566    235
>>
>> 2          443    54      566
>>
>> 3          566    44      235
>>
>>
>> here number of rows with the values 566&235 is 2 which are
>>
>> rows 1 & 3. Row 2 has only 566 so it should not be included in
>>
>> our calculation.
>>
>>
>> I also have a large matrix and wanted to convert it into a table so I
>can
>>
>> easily identify the combination with higher frequencies.
>>
>>
>> The matrix looks like this:
>>
>>
>>                     x      y      z
>>
>> x                  0      5       67
>>
>> y                  na    0      23
>>
>> z                   na   na      0
>>
>>
>> and I would like to convert this into a table arranged with
>>
>> higher values first like this :
>>
>> x       z       67
>>
>> y       z       23
>>
>> x       y        5
>>
>> x       x        0
>>
>> y       y        0
>>
>> z        z        0
>>
>> y        x        na
>>
>> z        x        na
>>
>> z        y        na
>>
>>
>> Is there a simple function to perform this conversion with some
>explanation
>> about the Syntax if you don't mind?
>>
>>
>> Regards
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sat Apr 29 22:38:16 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 29 Apr 2017 20:38:16 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
	a	table
In-Reply-To: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>

First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L, 
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2", 
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
     row col
[1,]   3   1
[2,]   1   2
[3,]   2   3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which(). 

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235)) 
> Val235
[1]  TRUE FALSE  TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L, 
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
   x  y  z
x  0  5 67
y NA  0 23
z NA NA  0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
  Var1 Var2 Freq
7    x    z   67
8    y    z   23
4    x    y    5
1    x    x    0
5    y    y    0
9    z    z    0
2    y    x   NA
3    z    x   NA
6    z    y   NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1          123   566    235

2          443    54      566

3          566    44      235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


                    x      y      z

x                  0      5       67

y                  na    0      23

z                   na   na      0


and I would like to convert this into a table arranged with

higher values first like this :

x       z       67

y       z       23

x       y        5

x       x        0

y       y        0

z        z        0

y        x        na

z        x        na

z        y        na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Apr 30 00:15:09 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 29 Apr 2017 15:15:09 -0700
Subject: [R] Matrix-list table conversion+nrwos with specefic values.
In-Reply-To: <CY4PR15MB1302EA55A5423EA6F4FABE8AEF120@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302FCADFF1D33CB273A5386EF120@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAGxFJbQLZNF_HdVrQog4Y1yOMSBL7YPAL57k10_rO-VMc56KHw@mail.gmail.com>,
 <80B88966-B791-4083-AD3D-F1123BB8CD83@dcn.davis.ca.us>
 <CY4PR15MB1302EA55A5423EA6F4FABE8AEF120@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAE8D11E-A56F-43E1-99DF-905D36F4BC32@dcn.davis.ca.us>

Please use reply-all to make sure the mailing list is included so others can learn from the discussion. 

Yes, you can use row and column names. Have you tried it? 
-- 
Sent from my phone. Please excuse my brevity.

On April 29, 2017 2:44:06 PM PDT, abo dalash <abo_dlsh at hotmail.com> wrote:
>Many thanks Jeff for your rapid response.
>
>
>Reg. the first task, I will discuss this later with you as I have faced
>some issues.
>
>
>Your guidance reg. Matrix-Table conversion has produced the table I
>want.
>
>thank you so much. My matrix is of size 120*120 and the headers of the
>columns and rows contain the same list of drug names. The table I
>produced
>
>contains the number of rows and number of columns in the matrix under
>
>r and c columns in my produced table. Is it possible to have names of
>drugs
>
>in my table instead of the number of row or number of column of the
>matrix.
>
>Please let me know if this is not clear.
>
>
>Many thanks
>
>
>________________________________
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: 29 April 2017 10:11 PM
>To: r-help at r-project.org; Bert Gunter; abo dalash; R-help
>Subject: Re: [R] Matrix-list table conversion+nrwos with specefic
>values.
>
>Break it down. If you have a scalar value val and you want to know if
>it is in a vector vec, using val==vec gets you a logical vector as long
>as vec. You can use val %in% vec and you get a logical vector as long
>as val (e.g. 1). If val is a vector of, say, length 2, then you will
>get a length 2 logical vector. In your example, c(566,23) %in% c(123,
>566, 235) would be c( TRUE, TRUE ). Since you want both of these
>elements to be TRUE,  you can use the all() function as in all(
>c(566,23) %in% c(123, 566, 235) ). So use the apply function to examine
>each row as a vector and you have it:
>
>apply( mat, 1, function(v) { all( c( 566,235) %in% v ) } )
>
>Note that this only works if your data are integers (see FAQ 7.31).
>
>Re the matrix to table... use expand.grid and matrix indexing.
>
>tbl <- expand.grid( r = seq.int( nrow( mat ) )
>                  , c = seq.int( ncol( mat ) ) )
>tbl$val <- mat[ as.matrix( tbl[ , c( "r","c" ) ] ) ]
>tbl[ order( tbl$val, decreasing=TRUE), ]
>
>--
>Sent from my phone. Please excuse my brevity.
>
>On April 29, 2017 9:53:08 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>I am not a private (or free!) consultant. Post to the r-help if your
>>question concerns R.
>>
>>-- Bert
>>
>>Bert Gunter
>>
>>
>>
>>On Sat, Apr 29, 2017 at 8:51 AM, abo dalash <abo_dlsh at hotmail.com>
>>wrote:
>>> Hi dear Bert
>>>
>>>
>>> I'm trying to identify number of rows containing 2 specific values.
>>>
>>> I tried : which(mydata == 566,235), but this returns logical values
>>for all
>>> rows and any T in a certain row indicates the existence of one of
>>these
>>> values but what I need to know is only number of rows in my data set
>>with
>>> these 2 particular values considering these two values
>>>
>>> as one pair per row. For example :
>>>
>>>
>>> 1          123   566    235
>>>
>>> 2          443    54      566
>>>
>>> 3          566    44      235
>>>
>>>
>>> here number of rows with the values 566&235 is 2 which are
>>>
>>> rows 1 & 3. Row 2 has only 566 so it should not be included in
>>>
>>> our calculation.
>>>
>>>
>>> I also have a large matrix and wanted to convert it into a table so
>I
>>can
>>>
>>> easily identify the combination with higher frequencies.
>>>
>>>
>>> The matrix looks like this:
>>>
>>>
>>>                     x      y      z
>>>
>>> x                  0      5       67
>>>
>>> y                  na    0      23
>>>
>>> z                   na   na      0
>>>
>>>
>>> and I would like to convert this into a table arranged with
>>>
>>> higher values first like this :
>>>
>>> x       z       67
>>>
>>> y       z       23
>>>
>>> x       y        5
>>>
>>> x       x        0
>>>
>>> y       y        0
>>>
>>> z        z        0
>>>
>>> y        x        na
>>>
>>> z        x        na
>>>
>>> z        y        na
>>>
>>>
>>> Is there a simple function to perform this conversion with some
>>explanation
>>> about the Syntax if you don't mind?
>>>
>>>
>>> Regards
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>
>R-help -- Main R Mailing List: Primary help - Homepage -
>SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R ...
>
>
>
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sun Apr 30 01:03:07 2017
From: tmrsg11 at gmail.com (C W)
Date: Sat, 29 Apr 2017 19:03:07 -0400
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
 <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
 <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>
 <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>
Message-ID: <CAE2FW2krwG7Xz=3ZDK0w_9YL+kqPjsODkS43QpQr5YpnEACBdw@mail.gmail.com>

I thought it's just deleting and reassigning those specific columns.

I guess I don't know R as much as I think I do. :(

On Sat, Apr 29, 2017 at 4:06 AM, G?ran Brostr?m <goran.brostrom at umu.se>
wrote:

>
>
> On 2017-04-29 06:45, Mike C wrote:
>
>> Thanks Rolf. I was just a bit frustrated that R wouldn't generate
>> dummy variable names on the fly.
>>
>> Also, another question, if I want to put column 5 at column 3,
>>
>> dat[, 3:5] <- dat[, c(5,3,4)]
>>
>> It does not work, why?
>>
>
> It "works", but you need to shuffle the names in the same way:
>
> names(dat)[3:5] <- names(dat)[c(5,3,4)]
>
> Better(?):
>
> perm <- c(1,2,5,3,4)
> dat <- dat[perm]
>
> dat is a list.
>
> G?ran
>
>
>> ________________________________ From: Rolf Turner
>> <r.turner at auckland.ac.nz> Sent: Friday, April 28, 2017 10:48:42 PM
>> To: C W Cc: r-help Subject: Re: [FORGED] Re: [R] How create columns
>> for squared values from previous columns?
>>
>> On 29/04/17 13:21, C W wrote:
>>
>>> I came up with this solution,
>>>
>>> cbind(dat, dat[, 1:3]^2)
>>>>
>>> X1         X2         X3         X4          X5          X1 X2
>>> X3 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379
>>> 0.529641625 1.28428102 3.9432044 2  0.05126592  0.2858707
>>> 0.9075806 1.27582713 -0.49438507 0.002628194 0.08172203 0.8237026 3
>>> -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475
>>> 0.163459669 0.29780978 1.4218277 4  1.40746971 -1.2279416
>>> 0.3296075 0.84411774 -0.52371619 1.980970990 1.50784058 0.1086411 5
>>> -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500
>>> 0.289886944 0.22563275 0.2213842 6  0.90691210  0.7247171
>>> 0.8244184 0.73328097 -1.05284737 0.822489552 0.52521494 0.6796657
>>>
>>> But, you would NOT ONLY get undesired variable names, BUT ALSO
>>> duplicated names. I suppose I can use paste() to solve that?
>>>
>>> Any better ideas?
>>>
>>
>> Well, if the names bizzo is your only worry, you could hit the
>> result with data.frame() *after* cbinding on the squared terms:
>>
>> dat <- matrix(rnorm(30),ncol=5) dat <- cbind(dat,dat[,1:3]^2) dat <-
>> data.frame(dat) names(dat)
>>
>> And as you indicate, the names of a data frame are easily adjusted.
>>
>> I wouldn't lose sleep over it.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P.S. You could also do
>>
>> names(dat) <- make.unique(names(dat))
>>
>> to your original idea, to get rid of the lack of uniqueness.  The
>> result is probably "undesirable" but.
>>
>> R. T.
>>
>> -- Technical Editor ANZJS Department of Statistics University of
>> Auckland Phone: +64-9-373-7599 ext. 88276
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Sun Apr 30 01:05:38 2017
From: tmrsg11 at gmail.com (C W)
Date: Sat, 29 Apr 2017 19:05:38 -0400
Subject: [R] [FORGED] Re: How create columns for squared values from
 previous columns?
In-Reply-To: <CAGxFJbRXUrcM2=7duvjhz_=jC++=eSPjNJwUKdzsGXkbtrxbdA@mail.gmail.com>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
 <604f401a-f6eb-c8f7-4fc0-700bf3ee5c0e@auckland.ac.nz>
 <BN6PR13MB14908FC47AFEC4FC5B441291F5120@BN6PR13MB1490.namprd13.prod.outlook.com>
 <a45158f3-e229-b8ca-5039-01e0ba4ed8ab@umu.se>
 <CAGxFJbRXUrcM2=7duvjhz_=jC++=eSPjNJwUKdzsGXkbtrxbdA@mail.gmail.com>
Message-ID: <CAE2FW2=M-maptFPUQ8CAZ7t0rVB5PCwHYK1TvNkg6KZi6aHKDA@mail.gmail.com>

On Sat, Apr 29, 2017 at 10:40 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Also:
>
> "I was just a bit frustrated that R wouldn't generate dummy variable
> names on the fly."
>
> That is false. See ?lm  and ?model.matrix
>

I am not sure what you mean. I thought if there is a three level dummy
variable, then it would generate a dummy.1, dummy.2 in lm()


>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Apr 29, 2017 at 1:06 AM, G?ran Brostr?m <goran.brostrom at umu.se>
> wrote:
> >
> >
> > On 2017-04-29 06:45, Mike C wrote:
> >>
> >> Thanks Rolf. I was just a bit frustrated that R wouldn't generate
> >> dummy variable names on the fly.
> >>
> >> Also, another question, if I want to put column 5 at column 3,
> >>
> >> dat[, 3:5] <- dat[, c(5,3,4)]
> >>
> >> It does not work, why?
> >
> >
> > It "works", but you need to shuffle the names in the same way:
> >
> > names(dat)[3:5] <- names(dat)[c(5,3,4)]
> >
> > Better(?):
> >
> > perm <- c(1,2,5,3,4)
> > dat <- dat[perm]
> >
> > dat is a list.
> >
> > G?ran
> >
> >
> >>
> >> ________________________________ From: Rolf Turner
> >> <r.turner at auckland.ac.nz> Sent: Friday, April 28, 2017 10:48:42 PM
> >> To: C W Cc: r-help Subject: Re: [FORGED] Re: [R] How create columns
> >> for squared values from previous columns?
> >>
> >> On 29/04/17 13:21, C W wrote:
> >>>
> >>> I came up with this solution,
> >>>
> >>>> cbind(dat, dat[, 1:3]^2)
> >>>
> >>> X1         X2         X3         X4          X5          X1 X2
> >>> X3 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379
> >>> 0.529641625 1.28428102 3.9432044 2  0.05126592  0.2858707
> >>> 0.9075806 1.27582713 -0.49438507 0.002628194 0.08172203 0.8237026 3
> >>> -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475
> >>> 0.163459669 0.29780978 1.4218277 4  1.40746971 -1.2279416
> >>> 0.3296075 0.84411774 -0.52371619 1.980970990 1.50784058 0.1086411 5
> >>> -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500
> >>> 0.289886944 0.22563275 0.2213842 6  0.90691210  0.7247171
> >>> 0.8244184 0.73328097 -1.05284737 0.822489552 0.52521494 0.6796657
> >>>
> >>> But, you would NOT ONLY get undesired variable names, BUT ALSO
> >>> duplicated names. I suppose I can use paste() to solve that?
> >>>
> >>> Any better ideas?
> >>
> >>
> >> Well, if the names bizzo is your only worry, you could hit the
> >> result with data.frame() *after* cbinding on the squared terms:
> >>
> >> dat <- matrix(rnorm(30),ncol=5) dat <- cbind(dat,dat[,1:3]^2) dat <-
> >> data.frame(dat) names(dat)
> >>
> >> And as you indicate, the names of a data frame are easily adjusted.
> >>
> >> I wouldn't lose sleep over it.
> >>
> >> cheers,
> >>
> >> Rolf Turner
> >>
> >> P.S. You could also do
> >>
> >> names(dat) <- make.unique(names(dat))
> >>
> >> to your original idea, to get rid of the lack of uniqueness.  The
> >> result is probably "undesirable" but.
> >>
> >> R. T.
> >>
> >> -- Technical Editor ANZJS Department of Statistics University of
> >> Auckland Phone: +64-9-373-7599 ext. 88276
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> ______________________________________________ R-help at r-project.org
> >> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> >> posting guide http://www.R-project.org/posting-guide.html and provide
> >> commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Sun Apr 30 17:17:01 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sun, 30 Apr 2017 23:17:01 +0800
Subject: [R] how to assign a value to a specific position of a list
Message-ID: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>

Hi there,

I have a problem with assign(). Here is the demo code:

for (i in 1:10) {
    # create a list with variable name as list_1, list_2, ..., etc.
    assign(paste("list_", i, sep = ""), list())
    # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
    # list_1[[1]] <- 5 # works, however
    assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
}

How to do? Is there any alternatives? Many thanks!

Best,
Jinsong


From jszhao at yeah.net  Sun Apr 30 17:20:17 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sun, 30 Apr 2017 23:20:17 +0800
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
Message-ID: <06c9c58d-904b-eb6a-241d-16f6387a4343@yeah.net>

On 2017/4/30 23:17, Jinsong Zhao wrote:
> Hi there,
>
> I have a problem with assign(). Here is the demo code:
>
> for (i in 1:10) {
>    # create a list with variable name as list_1, list_2, ..., etc.
>    assign(paste("list_", i, sep = ""), list())
>    # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
>    # list_1[[1]] <- 5 # works, however
>    assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
      # wrong code in previous message, the correct on should be:
      assign(paste("list_", i, "[[1]]", sep = ""), 5) # does not work...
> }
>
> How to do? Is there any alternatives? Many thanks!
>
> Best,
> Jinsong


From dcarlson at tamu.edu  Sun Apr 30 17:47:49 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 30 Apr 2017 15:47:49 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
	a	table
In-Reply-To: <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>
Message-ID: <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>

You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this?more?.
I applied the function as.data.frame but this returned the same matrix 
without converting it into a list table. I'm not sure where is the problem
in my code :???mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L, 
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2", 
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
???? row col
[1,]?? 3?? 1
[2,]?? 1?? 2
[3,]?? 2?? 3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which(). 

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235)) 
> Val235
[1]? TRUE FALSE? TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L, 
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
?? x? y? z
x? 0? 5 67
y NA? 0 23
z NA NA? 0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
? Var1 Var2 Freq
7??? x??? z?? 67
8??? y??? z?? 23
4??? x??? y??? 5
1??? x??? x??? 0
5??? y??? y??? 0
9??? z??? z??? 0
2??? y??? x?? NA
3??? z??? x?? NA
6??? z??? y?? NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1????????? 123?? 566??? 235

2????????? 443??? 54????? 566

3????????? 566??? 44????? 235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


??????????????????? x????? y????? z

x????????????????? 0????? 5?????? 67

y????????????????? na??? 0????? 23

z?????????????????? na?? na????? 0


and I would like to convert this into a table arranged with

higher values first like this :

x?????? z?????? 67

y?????? z?????? 23

x?????? y??????? 5

x?????? x??????? 0

y?????? y??????? 0

z??????? z??????? 0

y??????? x??????? na

z??????? x??????? na

z??????? y??????? na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Apr 30 17:48:02 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 30 Apr 2017 17:48:02 +0200
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
Message-ID: <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>

assign(paste("list_", i, "[[1]]", sep = ""), 5) creates a new variable with a funny name. 

You'd have to parse() and eval() to make that work, something like

eval(parse(text=paste("list_",i,"[[1]]<-",5, sep="")))

However,
-------
> fortunes::fortune("parse")

If the answer is parse() you should usually rethink the question.
   -- Thomas Lumley
      R-help (February 2005)
-------

It is much easier to handle this using a data structure containing a list of lists:

l <- rep(list(list()), 10)
for ( i in 1:10 ) 
   l[[i]][[1]] <- 5
 
> On 30 Apr 2017, at 17:17 , Jinsong Zhao <jszhao at yeah.net> wrote:
> 
> Hi there,
> 
> I have a problem with assign(). Here is the demo code:
> 
> for (i in 1:10) {
>   # create a list with variable name as list_1, list_2, ..., etc.
>   assign(paste("list_", i, sep = ""), list())
>   # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
>   # list_1[[1]] <- 5 # works, however
>   assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
> }
> 
> How to do? Is there any alternatives? Many thanks!
> 
> Best,
> Jinsong
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Sun Apr 30 17:56:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 30 Apr 2017 08:56:48 -0700
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <06c9c58d-904b-eb6a-241d-16f6387a4343@yeah.net>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
 <06c9c58d-904b-eb6a-241d-16f6387a4343@yeah.net>
Message-ID: <E13306FA-000D-40DC-AC74-67729D1C47FB@dcn.davis.ca.us>

My reaction is... why do you think this is a good approach to pursue?

Avoid using assign!

library( fortunes )
fortune( 236 )

If you really need another level of containment, put your multiple lists into another list:

lst  <- lapply( 1:10, list )
lst[[1]][[1]] <- 5

-- 
Sent from my phone. Please excuse my brevity.

On April 30, 2017 8:20:17 AM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>On 2017/4/30 23:17, Jinsong Zhao wrote:
>> Hi there,
>>
>> I have a problem with assign(). Here is the demo code:
>>
>> for (i in 1:10) {
>>    # create a list with variable name as list_1, list_2, ..., etc.
>>    assign(paste("list_", i, sep = ""), list())
>>    # I hope to assign 5 to list_?[[1]], but I don't know how to code
>it.
>>    # list_1[[1]] <- 5 # works, however
>>    assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
>      # wrong code in previous message, the correct on should be:
>     assign(paste("list_", i, "[[1]]", sep = ""), 5) # does not work...
>> }
>>
>> How to do? Is there any alternatives? Many thanks!
>>
>> Best,
>> Jinsong
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Sun Apr 30 18:26:53 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 30 Apr 2017 21:56:53 +0530
Subject: [R] The effect of tolerance in all.equal()
In-Reply-To: <22783.6758.310171.440071@stat.math.ethz.ch>
References: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
 <22783.6758.310171.440071@stat.math.ethz.ch>
Message-ID: <CAC8=1erfHBFar4m5mNHxRf+BcTHoAUWcZXoNocDiGTwyOoMemA@mail.gmail.com>

Dear All,

This answer is very clear. Many thanks.

I am now confused about how str*ucture works. Where can I read more about
when does it  return language / logical / chr ? I would want to read that
so I can interpret the result of structure. I don't think ?str contains
this.To me, logical and chr make sense, what does language mean? I think I
need to read some more.

Many thanks,
Ashim

On Tue, Apr 25, 2017 at 3:14 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Ashim Kapoor <ashimkapoor at gmail.com>
> >>>>>     on Tue, 25 Apr 2017 14:02:18 +0530 writes:
>
>     > Dear all,
>     > I am not able to understand the interplay of absolute vs relative and
>     > tolerance in the use of all.equal
>
>     > If I want to find out if absolute differences between 2
> numbers/vectors are
>     > bigger than a given tolerance I would do:
>
>     > all.equal(1,1.1,scale=1,tol= .1)
>
>     > If I want to find out if relative differences between 2
> numbers/vectors are
>     > bigger than a given tolerance I would do :
>
>     > all.equal(1,1.1,tol=.1)
>
>     > ############################################################
> ######################################################################
>
>     > I can also do :
>
>     > all.equal(1,3,tol=1)
>
>     > to find out if the absolute difference is bigger than 1.But here I
> won't be
>     > able to detect absolute differences smaller than 1 in this case,so I
> don't
>     > think that this is a good way.
>
>     > My query is: what is the reasoning behind all.equal returning the
> absolute
>     > difference if the tolerance >= target and relative difference if
> tolerance
>     > < target?
> (above, it is    tol  >/<=  |target|  ie. absolute value)
>
>
> The following are desiderata / restrictions :
>
> 1) Relative tolerance is needed to keep things scale-invariant
>    i.e.,  all.equal(x, y)  and  all.equal(1000 * x, 1000 * y)
>    should typically be identical for (almost) all (x,y).
>
>    ==> "the typical behavior should use relative error tolerance"
>
> 2) when x or y (and typically both!) are very close to zero it
>    is typically undesirable to keep relative tolerances (in the
>    boundary case, they _are_ zero exactly, and "relative error" is
> undefined).
>    E.g., for most purposes, 3.45e-15 and 1.23e-17 should be counted as
>    equal to zero and hence to themselves.
>
> 1) and 2) are typically reconciled by switching from relative to absolute
> when the arguments are close to zero (*).
>
> The exact cutoff at which to switch from relative to absolute
> (or a combination of the two) is somewhat arbitrary(*2) and for
> all.equal() has been made in the 1980's (or even slightly
> earlier?) when all.equal() was introduced into the S language at
> Bell labs AFAIK. Maybe John Chambers (or Rick Becker or ...,
> but they may not read R-help) knows more.
> *2) Then, the choice for all.equal() is in some way "least arbitrary",
>     using c = 1 in the more general   tolerance >= c*|target|  framework.
>
> *) There have been alternatives in "the (applied numerical
>  analysis / algorithm) literature" seen in published algorithms,
>  but I don't have any example ready.
>  Notably some of these alternatives are _symmetric_ in (x,y)
>  where all.equal() was designed to be asymmetric using names
>  'target' and 'current'.
>
> The alternative idea is along the following thoughts:
>
> Assume that for "equality" we want _both_ relative and
> absolute (e := tolerance) "equality"
>
>    |x - y| < e (|x|+|y|)/2  (where you could use |y| or |x|
>                              instead of their mean; all.equal()
>                              uses |target|)
>    |x - y| < e * e1          (where e1 = 1, or e1 = 10^-7..)
>
> If you add the two inequalities you get
>
>    |x - y| < e (e1 + |x+y|/2)
>
> as check which is a "mixture" of relative and absolute tolerance.
>
> With a somewhat long history, my gut feeling would nowadays
> actually prefer this (I think with a default of e1 = e) - which
> does treat x and y symmetrically.
>
> Note that convergence checks in good algorithms typically check
> for _both_ relative and absolute difference (each with its
> tolerance providable by the user), and the really good ones for
> minimization do  check for (approximate) gradients also being
> close to zero - as old timers among us should have learned from
> Doug Bates ... but now I'm really diverging.
>
> Last but not least some  R  code at the end,  showing that the *asymmetric*
> nature of all.equal() may lead to somewhat astonishing (but very
> logical and as documented!) behavior.
>
> Martin
>
>     > Best Regards,
>     > Ashim
>
>
> > ## The "data" to use:
> > epsQ <- lapply(seq(12,18,by=1/2), function(P) bquote(10^-.(P)));
> names(epsQ) <- sapply(epsQ, deparse); str(epsQ)
> List of 13
>  $ 10^-12  : language 10^-12
>  $ 10^-12.5: language 10^-12.5
>  $ 10^-13  : language 10^-13
>  $ 10^-13.5: language 10^-13.5
>  $ 10^-14  : language 10^-14
>  $ 10^-14.5: language 10^-14.5
>  $ 10^-15  : language 10^-15
>  $ 10^-15.5: language 10^-15.5
>  $ 10^-16  : language 10^-16
>  $ 10^-16.5: language 10^-16.5
>  $ 10^-17  : language 10^-17
>  $ 10^-17.5: language 10^-17.5
>  $ 10^-18  : language 10^-18
>
> > str(lapply(epsQ, function(tl) all.equal(3.45e-15, 1.23e-17, tol =
> eval(tl))))
> List of 13
>  $ 10^-12  : logi TRUE
>  $ 10^-12.5: logi TRUE
>  $ 10^-13  : logi TRUE
>  $ 10^-13.5: logi TRUE
>  $ 10^-14  : logi TRUE
>  $ 10^-14.5: chr "Mean relative difference: 0.9964348"
>  $ 10^-15  : chr "Mean relative difference: 0.9964348"
>  $ 10^-15.5: chr "Mean relative difference: 0.9964348"
>  $ 10^-16  : chr "Mean relative difference: 0.9964348"
>  $ 10^-16.5: chr "Mean relative difference: 0.9964348"
>  $ 10^-17  : chr "Mean relative difference: 0.9964348"
>  $ 10^-17.5: chr "Mean relative difference: 0.9964348"
>  $ 10^-18  : chr "Mean relative difference: 0.9964348"
>
> > ## Now swap `target` and `current` :
> > str(lapply(epsQ, function(tl) all.equal(1.23e-17, 3.45e-15, tol =
> eval(tl))))
> List of 13
>  $ 10^-12  : logi TRUE
>  $ 10^-12.5: logi TRUE
>  $ 10^-13  : logi TRUE
>  $ 10^-13.5: logi TRUE
>  $ 10^-14  : logi TRUE
>  $ 10^-14.5: chr "Mean absolute difference: 3.4377e-15"
>  $ 10^-15  : chr "Mean absolute difference: 3.4377e-15"
>  $ 10^-15.5: chr "Mean absolute difference: 3.4377e-15"
>  $ 10^-16  : chr "Mean absolute difference: 3.4377e-15"
>  $ 10^-16.5: chr "Mean absolute difference: 3.4377e-15"
>  $ 10^-17  : chr "Mean relative difference: 279.4878"
>  $ 10^-17.5: chr "Mean relative difference: 279.4878"
>  $ 10^-18  : chr "Mean relative difference: 279.4878"
>
> >
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Sun Apr 30 18:33:34 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 30 Apr 2017 16:33:34 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
	a	table
In-Reply-To: <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>
Message-ID: <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>

Show us the code you used. Don't just tell us what you did. It is likely that something you did after creating the matrix converted it to a data frame. Copy and paste your code to your emails.

> str(mydf)
'data.frame':   3 obs. of  3 variables:
 $ x: int  0 NA NA
 $ y: int  5 0 NA
 $ z: int  67 23 0

> data.frame(as.table(as.matrix(mydf)))
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA

David C


From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 11:13 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

str(mymatrix)
The Structure shows that this is a 'data.frame'?? of 120 obs. and 120 variables 
of numeric type. R deals with my matrix as a data frame although I used 
the function matrix() to produce this matrix which is not clear to me why. As this is already a data.frame, this may explains why R returns me the same 
matrix. What do you recommend now?

Many thanks 


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 06:47 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this?more?.
I applied the function as.data.frame but this returned the same matrix 
without converting it into a list table. I'm not sure where is the problem
in my code :???mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L, 
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2", 
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
???? row col
[1,]?? 3?? 1
[2,]?? 1?? 2
[3,]?? 2?? 3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which(). 

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235)) 
> Val235
[1]? TRUE FALSE? TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L, 
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
?? x? y? z
x? 0? 5 67
y NA? 0 23
z NA NA? 0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
? Var1 Var2 Freq
7??? x??? z?? 67
8??? y??? z?? 23
4??? x??? y??? 5
1??? x??? x??? 0
5??? y??? y??? 0
9??? z??? z??? 0
2??? y??? x?? NA
3??? z??? x?? NA
6??? z??? y?? NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1????????? 123?? 566??? 235

2????????? 443??? 54????? 566

3????????? 566??? 44????? 235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


??????????????????? x????? y????? z

x????????????????? 0????? 5?????? 67

y????????????????? na??? 0????? 23

z?????????????????? na?? na????? 0


and I would like to convert this into a table arranged with

higher values first like this :

x?????? z?????? 67

y?????? z?????? 23

x?????? y??????? 5

x?????? x??????? 0

y?????? y??????? 0

z??????? z??????? 0

y??????? x??????? na

z??????? x??????? na

z??????? y??????? na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Apr 30 18:35:44 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Apr 2017 12:35:44 -0400
Subject: [R] The effect of tolerance in all.equal()
In-Reply-To: <CAC8=1erfHBFar4m5mNHxRf+BcTHoAUWcZXoNocDiGTwyOoMemA@mail.gmail.com>
References: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
 <22783.6758.310171.440071@stat.math.ethz.ch>
 <CAC8=1erfHBFar4m5mNHxRf+BcTHoAUWcZXoNocDiGTwyOoMemA@mail.gmail.com>
Message-ID: <d3ca18ce-d46a-d2fd-0db3-7173579c6a08@gmail.com>

On 30/04/2017 12:26 PM, Ashim Kapoor wrote:
> Dear All,
>
> This answer is very clear. Many thanks.
>
> I am now confused about how str*ucture works. Where can I read more about
> when does it  return language / logical / chr ? I would want to read that
> so I can interpret the result of structure. I don't think ?str contains
> this.To me, logical and chr make sense, what does language mean? I think I
> need to read some more.

I would read the R Language Definition manual, and then bits and pieces 
of R Internals, as necessary.  These are both included with R.  There 
are also books separate from R that talk about these things, but I don't 
know which to recommend.

Duncan Murdoch

>
> Many thanks,
> Ashim
>
> On Tue, Apr 25, 2017 at 3:14 PM, Martin Maechler <maechler at stat.math.ethz.ch
>> wrote:
>
>>>>>>> Ashim Kapoor <ashimkapoor at gmail.com>
>>>>>>>     on Tue, 25 Apr 2017 14:02:18 +0530 writes:
>>
>>     > Dear all,
>>     > I am not able to understand the interplay of absolute vs relative and
>>     > tolerance in the use of all.equal
>>
>>     > If I want to find out if absolute differences between 2
>> numbers/vectors are
>>     > bigger than a given tolerance I would do:
>>
>>     > all.equal(1,1.1,scale=1,tol= .1)
>>
>>     > If I want to find out if relative differences between 2
>> numbers/vectors are
>>     > bigger than a given tolerance I would do :
>>
>>     > all.equal(1,1.1,tol=.1)
>>
>>     > ############################################################
>> ######################################################################
>>
>>     > I can also do :
>>
>>     > all.equal(1,3,tol=1)
>>
>>     > to find out if the absolute difference is bigger than 1.But here I
>> won't be
>>     > able to detect absolute differences smaller than 1 in this case,so I
>> don't
>>     > think that this is a good way.
>>
>>     > My query is: what is the reasoning behind all.equal returning the
>> absolute
>>     > difference if the tolerance >= target and relative difference if
>> tolerance
>>     > < target?
>> (above, it is    tol  >/<=  |target|  ie. absolute value)
>>
>>
>> The following are desiderata / restrictions :
>>
>> 1) Relative tolerance is needed to keep things scale-invariant
>>    i.e.,  all.equal(x, y)  and  all.equal(1000 * x, 1000 * y)
>>    should typically be identical for (almost) all (x,y).
>>
>>    ==> "the typical behavior should use relative error tolerance"
>>
>> 2) when x or y (and typically both!) are very close to zero it
>>    is typically undesirable to keep relative tolerances (in the
>>    boundary case, they _are_ zero exactly, and "relative error" is
>> undefined).
>>    E.g., for most purposes, 3.45e-15 and 1.23e-17 should be counted as
>>    equal to zero and hence to themselves.
>>
>> 1) and 2) are typically reconciled by switching from relative to absolute
>> when the arguments are close to zero (*).
>>
>> The exact cutoff at which to switch from relative to absolute
>> (or a combination of the two) is somewhat arbitrary(*2) and for
>> all.equal() has been made in the 1980's (or even slightly
>> earlier?) when all.equal() was introduced into the S language at
>> Bell labs AFAIK. Maybe John Chambers (or Rick Becker or ...,
>> but they may not read R-help) knows more.
>> *2) Then, the choice for all.equal() is in some way "least arbitrary",
>>     using c = 1 in the more general   tolerance >= c*|target|  framework.
>>
>> *) There have been alternatives in "the (applied numerical
>>  analysis / algorithm) literature" seen in published algorithms,
>>  but I don't have any example ready.
>>  Notably some of these alternatives are _symmetric_ in (x,y)
>>  where all.equal() was designed to be asymmetric using names
>>  'target' and 'current'.
>>
>> The alternative idea is along the following thoughts:
>>
>> Assume that for "equality" we want _both_ relative and
>> absolute (e := tolerance) "equality"
>>
>>    |x - y| < e (|x|+|y|)/2  (where you could use |y| or |x|
>>                              instead of their mean; all.equal()
>>                              uses |target|)
>>    |x - y| < e * e1          (where e1 = 1, or e1 = 10^-7..)
>>
>> If you add the two inequalities you get
>>
>>    |x - y| < e (e1 + |x+y|/2)
>>
>> as check which is a "mixture" of relative and absolute tolerance.
>>
>> With a somewhat long history, my gut feeling would nowadays
>> actually prefer this (I think with a default of e1 = e) - which
>> does treat x and y symmetrically.
>>
>> Note that convergence checks in good algorithms typically check
>> for _both_ relative and absolute difference (each with its
>> tolerance providable by the user), and the really good ones for
>> minimization do  check for (approximate) gradients also being
>> close to zero - as old timers among us should have learned from
>> Doug Bates ... but now I'm really diverging.
>>
>> Last but not least some  R  code at the end,  showing that the *asymmetric*
>> nature of all.equal() may lead to somewhat astonishing (but very
>> logical and as documented!) behavior.
>>
>> Martin
>>
>>     > Best Regards,
>>     > Ashim
>>
>>
>>> ## The "data" to use:
>>> epsQ <- lapply(seq(12,18,by=1/2), function(P) bquote(10^-.(P)));
>> names(epsQ) <- sapply(epsQ, deparse); str(epsQ)
>> List of 13
>>  $ 10^-12  : language 10^-12
>>  $ 10^-12.5: language 10^-12.5
>>  $ 10^-13  : language 10^-13
>>  $ 10^-13.5: language 10^-13.5
>>  $ 10^-14  : language 10^-14
>>  $ 10^-14.5: language 10^-14.5
>>  $ 10^-15  : language 10^-15
>>  $ 10^-15.5: language 10^-15.5
>>  $ 10^-16  : language 10^-16
>>  $ 10^-16.5: language 10^-16.5
>>  $ 10^-17  : language 10^-17
>>  $ 10^-17.5: language 10^-17.5
>>  $ 10^-18  : language 10^-18
>>
>>> str(lapply(epsQ, function(tl) all.equal(3.45e-15, 1.23e-17, tol =
>> eval(tl))))
>> List of 13
>>  $ 10^-12  : logi TRUE
>>  $ 10^-12.5: logi TRUE
>>  $ 10^-13  : logi TRUE
>>  $ 10^-13.5: logi TRUE
>>  $ 10^-14  : logi TRUE
>>  $ 10^-14.5: chr "Mean relative difference: 0.9964348"
>>  $ 10^-15  : chr "Mean relative difference: 0.9964348"
>>  $ 10^-15.5: chr "Mean relative difference: 0.9964348"
>>  $ 10^-16  : chr "Mean relative difference: 0.9964348"
>>  $ 10^-16.5: chr "Mean relative difference: 0.9964348"
>>  $ 10^-17  : chr "Mean relative difference: 0.9964348"
>>  $ 10^-17.5: chr "Mean relative difference: 0.9964348"
>>  $ 10^-18  : chr "Mean relative difference: 0.9964348"
>>
>>> ## Now swap `target` and `current` :
>>> str(lapply(epsQ, function(tl) all.equal(1.23e-17, 3.45e-15, tol =
>> eval(tl))))
>> List of 13
>>  $ 10^-12  : logi TRUE
>>  $ 10^-12.5: logi TRUE
>>  $ 10^-13  : logi TRUE
>>  $ 10^-13.5: logi TRUE
>>  $ 10^-14  : logi TRUE
>>  $ 10^-14.5: chr "Mean absolute difference: 3.4377e-15"
>>  $ 10^-15  : chr "Mean absolute difference: 3.4377e-15"
>>  $ 10^-15.5: chr "Mean absolute difference: 3.4377e-15"
>>  $ 10^-16  : chr "Mean absolute difference: 3.4377e-15"
>>  $ 10^-16.5: chr "Mean absolute difference: 3.4377e-15"
>>  $ 10^-17  : chr "Mean relative difference: 279.4878"
>>  $ 10^-17.5: chr "Mean relative difference: 279.4878"
>>  $ 10^-18  : chr "Mean relative difference: 279.4878"
>>
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Sun Apr 30 19:14:23 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 30 Apr 2017 10:14:23 -0700
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
 <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>
Message-ID: <CAGxFJbR=My5fajkreoiccAPFFr7GmCtb9XOU9Op_dwr7qL+kGg@mail.gmail.com>

... and moreover, note that the assignment can even be shortened to:


> for ( i in 1:10 )  l[[c(i,1)]] <- 5

?"[["  contains details, but the relevant point is:

"[[ can be applied recursively to lists, so that if the single index i
is a vector of length p, alist[[i]] is equivalent to
alist[[i1]]...[[ip]] providing all but the final indexing results in a
list."

For a less terse version, see any good online R tutorial. Lists are
extremely useful in R, and indexing is fundamental. If you haven't
spent the time to learn about these constructs, you should now before
posting further. You'll save yourself a  lot of grief and perhaps even
some embarassment.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 30, 2017 at 8:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> assign(paste("list_", i, "[[1]]", sep = ""), 5) creates a new variable with a funny name.
>
> You'd have to parse() and eval() to make that work, something like
>
> eval(parse(text=paste("list_",i,"[[1]]<-",5, sep="")))
>
> However,
> -------
>> fortunes::fortune("parse")
>
> If the answer is parse() you should usually rethink the question.
>    -- Thomas Lumley
>       R-help (February 2005)
> -------
>
> It is much easier to handle this using a data structure containing a list of lists:
>
> l <- rep(list(list()), 10)
> for ( i in 1:10 )
>    l[[i]][[1]] <- 5
>
>> On 30 Apr 2017, at 17:17 , Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> Hi there,
>>
>> I have a problem with assign(). Here is the demo code:
>>
>> for (i in 1:10) {
>>   # create a list with variable name as list_1, list_2, ..., etc.
>>   assign(paste("list_", i, sep = ""), list())
>>   # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
>>   # list_1[[1]] <- 5 # works, however
>>   assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
>> }
>>
>> How to do? Is there any alternatives? Many thanks!
>>
>> Best,
>> Jinsong
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Apr 30 19:20:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 30 Apr 2017 10:20:56 -0700
Subject: [R] The effect of tolerance in all.equal()
In-Reply-To: <d3ca18ce-d46a-d2fd-0db3-7173579c6a08@gmail.com>
References: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
 <22783.6758.310171.440071@stat.math.ethz.ch>
 <CAC8=1erfHBFar4m5mNHxRf+BcTHoAUWcZXoNocDiGTwyOoMemA@mail.gmail.com>
 <d3ca18ce-d46a-d2fd-0db3-7173579c6a08@gmail.com>
Message-ID: <CAGxFJbTGK1aCdw2_t4wWdK=+Xy7goidLhnnNW5pe-q_+Wy-WCA@mail.gmail.com>

...

Some R tutorial recommendations can be found here:

https://www.rstudio.com/online-learning/#R

Hadley W.'s book might also be useful to you:  http://adv-r.had.co.nz/


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 30, 2017 at 9:35 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 30/04/2017 12:26 PM, Ashim Kapoor wrote:
>>
>> Dear All,
>>
>> This answer is very clear. Many thanks.
>>
>> I am now confused about how str*ucture works. Where can I read more about
>> when does it  return language / logical / chr ? I would want to read that
>> so I can interpret the result of structure. I don't think ?str contains
>> this.To me, logical and chr make sense, what does language mean? I think I
>> need to read some more.
>
>
> I would read the R Language Definition manual, and then bits and pieces of R
> Internals, as necessary.  These are both included with R.  There are also
> books separate from R that talk about these things, but I don't know which
> to recommend.
>
> Duncan Murdoch
>
>
>>
>> Many thanks,
>> Ashim
>>
>> On Tue, Apr 25, 2017 at 3:14 PM, Martin Maechler
>> <maechler at stat.math.ethz.ch
>>>
>>> wrote:
>>
>>
>>>>>>>> Ashim Kapoor <ashimkapoor at gmail.com>
>>>>>>>>     on Tue, 25 Apr 2017 14:02:18 +0530 writes:
>>>
>>>
>>>     > Dear all,
>>>     > I am not able to understand the interplay of absolute vs relative
>>> and
>>>     > tolerance in the use of all.equal
>>>
>>>     > If I want to find out if absolute differences between 2
>>> numbers/vectors are
>>>     > bigger than a given tolerance I would do:
>>>
>>>     > all.equal(1,1.1,scale=1,tol= .1)
>>>
>>>     > If I want to find out if relative differences between 2
>>> numbers/vectors are
>>>     > bigger than a given tolerance I would do :
>>>
>>>     > all.equal(1,1.1,tol=.1)
>>>
>>>     > ############################################################
>>> ######################################################################
>>>
>>>     > I can also do :
>>>
>>>     > all.equal(1,3,tol=1)
>>>
>>>     > to find out if the absolute difference is bigger than 1.But here I
>>> won't be
>>>     > able to detect absolute differences smaller than 1 in this case,so
>>> I
>>> don't
>>>     > think that this is a good way.
>>>
>>>     > My query is: what is the reasoning behind all.equal returning the
>>> absolute
>>>     > difference if the tolerance >= target and relative difference if
>>> tolerance
>>>     > < target?
>>> (above, it is    tol  >/<=  |target|  ie. absolute value)
>>>
>>>
>>> The following are desiderata / restrictions :
>>>
>>> 1) Relative tolerance is needed to keep things scale-invariant
>>>    i.e.,  all.equal(x, y)  and  all.equal(1000 * x, 1000 * y)
>>>    should typically be identical for (almost) all (x,y).
>>>
>>>    ==> "the typical behavior should use relative error tolerance"
>>>
>>> 2) when x or y (and typically both!) are very close to zero it
>>>    is typically undesirable to keep relative tolerances (in the
>>>    boundary case, they _are_ zero exactly, and "relative error" is
>>> undefined).
>>>    E.g., for most purposes, 3.45e-15 and 1.23e-17 should be counted as
>>>    equal to zero and hence to themselves.
>>>
>>> 1) and 2) are typically reconciled by switching from relative to absolute
>>> when the arguments are close to zero (*).
>>>
>>> The exact cutoff at which to switch from relative to absolute
>>> (or a combination of the two) is somewhat arbitrary(*2) and for
>>> all.equal() has been made in the 1980's (or even slightly
>>> earlier?) when all.equal() was introduced into the S language at
>>> Bell labs AFAIK. Maybe John Chambers (or Rick Becker or ...,
>>> but they may not read R-help) knows more.
>>> *2) Then, the choice for all.equal() is in some way "least arbitrary",
>>>     using c = 1 in the more general   tolerance >= c*|target|  framework.
>>>
>>> *) There have been alternatives in "the (applied numerical
>>>  analysis / algorithm) literature" seen in published algorithms,
>>>  but I don't have any example ready.
>>>  Notably some of these alternatives are _symmetric_ in (x,y)
>>>  where all.equal() was designed to be asymmetric using names
>>>  'target' and 'current'.
>>>
>>> The alternative idea is along the following thoughts:
>>>
>>> Assume that for "equality" we want _both_ relative and
>>> absolute (e := tolerance) "equality"
>>>
>>>    |x - y| < e (|x|+|y|)/2  (where you could use |y| or |x|
>>>                              instead of their mean; all.equal()
>>>                              uses |target|)
>>>    |x - y| < e * e1          (where e1 = 1, or e1 = 10^-7..)
>>>
>>> If you add the two inequalities you get
>>>
>>>    |x - y| < e (e1 + |x+y|/2)
>>>
>>> as check which is a "mixture" of relative and absolute tolerance.
>>>
>>> With a somewhat long history, my gut feeling would nowadays
>>> actually prefer this (I think with a default of e1 = e) - which
>>> does treat x and y symmetrically.
>>>
>>> Note that convergence checks in good algorithms typically check
>>> for _both_ relative and absolute difference (each with its
>>> tolerance providable by the user), and the really good ones for
>>> minimization do  check for (approximate) gradients also being
>>> close to zero - as old timers among us should have learned from
>>> Doug Bates ... but now I'm really diverging.
>>>
>>> Last but not least some  R  code at the end,  showing that the
>>> *asymmetric*
>>> nature of all.equal() may lead to somewhat astonishing (but very
>>> logical and as documented!) behavior.
>>>
>>> Martin
>>>
>>>     > Best Regards,
>>>     > Ashim
>>>
>>>
>>>> ## The "data" to use:
>>>> epsQ <- lapply(seq(12,18,by=1/2), function(P) bquote(10^-.(P)));
>>>
>>> names(epsQ) <- sapply(epsQ, deparse); str(epsQ)
>>> List of 13
>>>  $ 10^-12  : language 10^-12
>>>  $ 10^-12.5: language 10^-12.5
>>>  $ 10^-13  : language 10^-13
>>>  $ 10^-13.5: language 10^-13.5
>>>  $ 10^-14  : language 10^-14
>>>  $ 10^-14.5: language 10^-14.5
>>>  $ 10^-15  : language 10^-15
>>>  $ 10^-15.5: language 10^-15.5
>>>  $ 10^-16  : language 10^-16
>>>  $ 10^-16.5: language 10^-16.5
>>>  $ 10^-17  : language 10^-17
>>>  $ 10^-17.5: language 10^-17.5
>>>  $ 10^-18  : language 10^-18
>>>
>>>> str(lapply(epsQ, function(tl) all.equal(3.45e-15, 1.23e-17, tol =
>>>
>>> eval(tl))))
>>> List of 13
>>>  $ 10^-12  : logi TRUE
>>>  $ 10^-12.5: logi TRUE
>>>  $ 10^-13  : logi TRUE
>>>  $ 10^-13.5: logi TRUE
>>>  $ 10^-14  : logi TRUE
>>>  $ 10^-14.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-15  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-15.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-16  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-16.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-17  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-17.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-18  : chr "Mean relative difference: 0.9964348"
>>>
>>>> ## Now swap `target` and `current` :
>>>> str(lapply(epsQ, function(tl) all.equal(1.23e-17, 3.45e-15, tol =
>>>
>>> eval(tl))))
>>> List of 13
>>>  $ 10^-12  : logi TRUE
>>>  $ 10^-12.5: logi TRUE
>>>  $ 10^-13  : logi TRUE
>>>  $ 10^-13.5: logi TRUE
>>>  $ 10^-14  : logi TRUE
>>>  $ 10^-14.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-15  : chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-15.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-16  : chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-16.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-17  : chr "Mean relative difference: 279.4878"
>>>  $ 10^-17.5: chr "Mean relative difference: 279.4878"
>>>  $ 10^-18  : chr "Mean relative difference: 279.4878"
>>>
>>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abo_dlsh at hotmail.com  Sun Apr 30 17:09:15 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Sun, 30 Apr 2017 15:09:15 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
	a	table
In-Reply-To: <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>

Dear David ..,


Many thanks for this detailed answer.


Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.


Reg. the Matrix-table conversion, could you please clarify this more?.

I applied the function as.data.frame but this returned the same matrix

without converting it into a list table. I'm not sure where is the problem

in my code :   mymatrix <- as.data.frame(mymatrix).


Many thanks for your support


Regards



________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L,
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2",
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
     row col
[1,]   3   1
[2,]   1   2
[3,]   2   3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which().

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235))
> Val235
[1]  TRUE FALSE  TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L,
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
   x  y  z
x  0  5 67
y NA  0 23
z NA NA  0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
  Var1 Var2 Freq
7    x    z   67
8    y    z   23
4    x    y    5
1    x    x    0
5    y    y    0
9    z    z    0
2    y    x   NA
3    z    x   NA
6    z    y   NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1          123   566    235

2          443    54      566

3          566    44      235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


                    x      y      z

x                  0      5       67

y                  na    0      23

z                   na   na      0


and I would like to convert this into a table arranged with

higher values first like this :

x       z       67

y       z       23

x       y        5

x       x        0

y       y        0

z        z        0

y        x        na

z        x        na

z        y        na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From abo_dlsh at hotmail.com  Sun Apr 30 19:17:49 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Sun, 30 Apr 2017 17:17:49 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
	a	table
In-Reply-To: <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <DM5PR15MB1307DFBBDD6520E207711171EF150@DM5PR15MB1307.namprd15.prod.outlook.com>

Many thanks dear David, your teaching reg. the conversion of a matrix into a table has resolved my issue and I have now generated the desired table.


So many thanks for your support.


Regards


________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 07:33 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

Show us the code you used. Don't just tell us what you did. It is likely that something you did after creating the matrix converted it to a data frame. Copy and paste your code to your emails.

> str(mydf)
'data.frame':   3 obs. of  3 variables:
 $ x: int  0 NA NA
 $ y: int  5 0 NA
 $ z: int  67 23 0

> data.frame(as.table(as.matrix(mydf)))
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA

David C


From: abo dalash [mailto:abo_dlsh at hotmail.com]
Sent: Sunday, April 30, 2017 11:13 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

str(mymatrix)
The Structure shows that this is a 'data.frame'?  of 120 obs. and 120 variables
of numeric type. R deals with my matrix as a data frame although I used
the function matrix() to produce this matrix which is not clear to me why. As this is already a data.frame, this may explains why R returns me the same
matrix. What do you recommend now?

Many thanks


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 06:47 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com]
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this more?.
I applied the function as.data.frame but this returned the same matrix
without converting it into a list table. I'm not sure where is the problem
in my code :   mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L,
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2",
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
     row col
[1,]   3   1
[2,]   1   2
[3,]   2   3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which().

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235))
> Val235
[1]  TRUE FALSE  TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L,
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
   x  y  z
x  0  5 67
y NA  0 23
z NA NA  0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
  Var1 Var2 Freq
7    x    z   67
8    y    z   23
4    x    y    5
1    x    x    0
5    y    y    0
9    z    z    0
2    y    x   NA
3    z    x   NA
6    z    y   NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1          123   566    235

2          443    54      566

3          566    44      235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


                    x      y      z

x                  0      5       67

y                  na    0      23

z                   na   na      0


and I would like to convert this into a table arranged with

higher values first like this :

x       z       67

y       z       23

x       y        5

x       x        0

y       y        0

z        z        0

y        x        na

z        x        na

z        y        na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From abo_dlsh at hotmail.com  Sun Apr 30 21:35:33 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Sun, 30 Apr 2017 19:35:33 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
 a table
In-Reply-To: <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <DM5PR15MB130771F963A2AAC57FF686E7EF150@DM5PR15MB1307.namprd15.prod.outlook.com>

I'm trying to write the table I have created from the matrix using

write.table(mytable, file= "mytable.txt"). I have imported this txt. file into

an Excel sheet but  all data have been typed in one column (Var1,Var2,&Freq.)

and I want to see each vector in one column. Have I used the correct syntax?


Regards


________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 07:33 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

Show us the code you used. Don't just tell us what you did. It is likely that something you did after creating the matrix converted it to a data frame. Copy and paste your code to your emails.

> str(mydf)
'data.frame':   3 obs. of  3 variables:
 $ x: int  0 NA NA
 $ y: int  5 0 NA
 $ z: int  67 23 0

> data.frame(as.table(as.matrix(mydf)))
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA

David C


From: abo dalash [mailto:abo_dlsh at hotmail.com]
Sent: Sunday, April 30, 2017 11:13 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

str(mymatrix)
The Structure shows that this is a 'data.frame'?  of 120 obs. and 120 variables
of numeric type. R deals with my matrix as a data frame although I used
the function matrix() to produce this matrix which is not clear to me why. As this is already a data.frame, this may explains why R returns me the same
matrix. What do you recommend now?

Many thanks


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 06:47 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com]
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this more?.
I applied the function as.data.frame but this returned the same matrix
without converting it into a list table. I'm not sure where is the problem
in my code :   mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table

First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L,
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2",
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
     row col
[1,]   3   1
[2,]   1   2
[3,]   2   3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which().

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235))
> Val235
[1]  TRUE FALSE  TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L,
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
   x  y  z
x  0  5 67
y NA  0 23
z NA NA  0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
  Var1 Var2 Freq
1    x    x    0
2    y    x   NA
3    z    x   NA
4    x    y    5
5    y    y    0
6    z    y   NA
7    x    z   67
8    y    z   23
9    z    z    0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
  Var1 Var2 Freq
7    x    z   67
8    y    z   23
4    x    y    5
1    x    x    0
5    y    y    0
9    z    z    0
2    y    x   NA
3    z    x   NA
6    z    y   NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1          123   566    235

2          443    54      566

3          566    44      235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


                    x      y      z

x                  0      5       67

y                  na    0      23

z                   na   na      0


and I would like to convert this into a table arranged with

higher values first like this :

x       z       67

y       z       23

x       y        5

x       x        0

y       y        0

z        z        0

y        x        na

z        x        na

z        y        na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From adrian at trapletti.org  Sun Apr 30 10:55:04 2017
From: adrian at trapletti.org (Adrian Trapletti)
Date: Sun, 30 Apr 2017 10:55:04 +0200
Subject: [R] R-help Digest, Vol 170, Issue 29
In-Reply-To: <mailman.1.1493460002.64855.r-help@r-project.org>
References: <mailman.1.1493460002.64855.r-help@r-project.org>
Message-ID: <CAFmikf0hB4A4EfMTkvE5AiBueCz8XY-QqxT4E3E4_+PcSzj9Pg@mail.gmail.com>

> Message: 1
> Date: Fri, 28 Apr 2017 11:07:40 +0000
> From: T.Riedle <tr206 at kent.ac.uk>
> To: "R-help at r-project.org" <R-help at r-project.org>
> Subject: [R] Augmented Dickey Fuller test
> Message-ID: <1493377701072.16786 at kent.ac.uk>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear all,
>
> I am trying to run an ADF test using the adf.test() function in the tseries package and the ur.df() function in the urca package. The results I get contrast sharply. Whilst the adf.test() indicates stationarity which is in line with the corresponding graph, the ur.df() indicates non-stationarity.
>

In a simple example I can't reproduce your finding. The test statistic
of adf.test() and ur.df() are identical:

> library(urca)
> library(tseries)
>
> set.seed(1)
>
> x <- rnorm(1000)  # no unit-root
> adf.test(x)

Augmented Dickey-Fuller Test

data:  x
Dickey-Fuller = -9.9291, Lag order = 9, p-value = 0.01
alternative hypothesis: stationary

Warning message:
In adf.test(x) : p-value smaller than printed p-value
> ur.df(x, lags=trunc((length(x)-1)^(1/3)), type="trend")

###############################################################
# Augmented Dickey-Fuller Test Unit Root / Cointegration Test #
###############################################################

The value of the test statistic is: -9.9291 32.869 49.2953

>
> y <- diffinv(x)   # contains a unit-root
> adf.test(y)

Augmented Dickey-Fuller Test

data:  y
Dickey-Fuller = -2.5115, Lag order = 9, p-value = 0.3618
alternative hypothesis: stationary

> ur.df(y, lags=trunc((length(y)-1)^(1/3)),  type="trend")

###############################################################
# Augmented Dickey-Fuller Test Unit Root / Cointegration Test #
###############################################################

The value of the test statistic is: -2.5115 2.4203 3.5281

>
>
> Why does this happen? Could anybody explain the adf.test() function in more detail? How does adf.test() select the number of lags is it AIC or BIC and how does it take an intercept and/or a trend into account?

?adf.test

Details

The general regression equation which incorporates a constant and a
linear trend is used and the t-statistic for a first order
autoregressive coefficient equals one is computed. The number of lags
used in the regression is k. The default value of
trunc((length(x)-1)^(1/3)) corresponds to the suggested upper bound on
the rate at which the number of lags, k, should be made to grow with
the sample size for the general ARMA(p,q) setup.

References

A. Banerjee, J. J. Dolado, J. W. Galbraith, and D. F. Hendry (1993):
Cointegration, Error Correction, and the Econometric Analysis of
Non-Stationary Data, Oxford University Press, Oxford.
S. E. Said and D. A. Dickey (1984): Testing for Unit Roots in
Autoregressive-Moving Average Models of Unknown Order. Biometrika 71,
599?607.

>
>
>
> Help is greatly appreciated.
>
>
>
> Thanks in advance.
>
>         [[alternative HTML version deleted]]
>

Best regards

Adrian

--
Adrian Trapletti

Steinstrasse 9b, 8610 Uster, Switzerland
P +41 44 994 56 30  |  M +41 79 103 71 31
adrian at trapletti.org  |  www.trapletti.org


