From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Oct  1 01:52:18 2024
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 30 Sep 2024 16:52:18 -0700
Subject: [R] Problem with converting grib file to excel
In-Reply-To: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
References: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
Message-ID: <2DF4E95A-57B3-41FC-B082-7260C7E98F34@noaa.gov>

I have corresponded with Javad off-line,  posting this as a follow-up, to close the issue.  There are two separate questions here.  The first is why did the posted code below fail.  The second is there an easy way to read in the values, given the oddities of his file  (more on that), and yes it turns out "terra" performs much better than "raster".

First a little about GRIB files in general,  and this file in particular.  GRIB files were design to store grids in files with very small footprints,  usually from model output.  GRIB files have the characteristic that if I "cat" a bunch of  GRIB files,  I still have a valid GRIB file.  So a given GRIB file often contains multiple parameters,  and each of those through time.  To translate into terms used by R spatial packages,  each variable grid,  at each time period will be seen as a  "band" or a "layer" in the dataset.  Thus if I have 3 parameters,  say temperature,  dew point and cloud cover at  8670 time periods,  R spatial packages will see 3*8670 layers or bands.

However this GRIB file is clearly not a raw GRIB file made by a data provider,  but rather an extract made with some tool.  In this file there are 3 underlying time series. temperature,  dew point and cloud cover,  each of dimension (1, 1, 8670),  that is because it is defined at one spatial point only.

So why did the code below fail?  raster::stack()  read the file just fine,  and the layer_names are correct,  all 3*8670 of them.  The next steps:

>> # Extract layers based on layer names - adjust as necessary
>> t2m <- raster_data[[grep("t2m", layer_names)]]
>> d2m <- raster_data[[grep("d2m", layer_names)]]
>> tcc <- raster_data[[grep("tcc", layer_names)]]
>> valid_time <- raster_data[[grep("valid_time", layer_names)]]
>> t2m

which are aimed at subsetting the raster stack based on the variable name all fail because ""t2m" , "d2m" and "tcc" are not in the layer_names. So then of course everything else fails.

So the next question is how to read the file and get a data frame.  A first pass would be:

raster_stack <- raster::stack("Met.grib")
raster_data <- raster::getValues(raster_stack).

but you do not want to do that.  For whatever reason,  the raster_stack created above is enormous,  and the raster::getValues() takes forever,  I aborted after about an hour.  However,  if you use 'terra" instead:

raster_stack <-terra::rast("Met.grib")
raster_data <-terra::values(raster_stack).

it finishes in a flash.  raster_data is now one long array that needs to be reshaped:

raster_data <- array(raster_data, dim = c(3, 8670)

now raster_data[1, ] contains the temperature series,  raster_data[2, ] contains the dew point data,  and raster_data[3, ] contains the cloud cover data.

HTH,

-Roy

PS - GRIB files can be a bear.  The best GRIB readers in R are just front ends for either eccodes or wgrib2,    and  while they work very well,  installation for eccodes and wgrib2 can be non-trivial,  so I didn't want to use them as a solution.  Also for quick viewing of GRIB files there is NASA's Panoply (https://www.giss.nasa.gov/tools/panoply/) but that requires a Java installation.

> On Sep 23, 2024, at 11:31 PM, javad bayat <j.bayat194 at gmail.com> wrote:
> 
> Dear R users;
> I have downloaded a grib file format (Met.grib) and I want to export its
> data to excel file. Also I want to do some mathematic on some columns. But
> I got error. I would be more than happy if anyone can help me to do this. I
> have provided the codes and the Met.grib file in this email.
> Sincerely yours
> 
> # Load the necessary libraries
>> library(raster)      # For reading GRIB files
>> library(dplyr)       # For data manipulation
>> library(lubridate)   # For date manipulation
>> library(openxlsx)    # For writing Excel files
> 
> # Specify the file paths
>> grib_file_path <- "C:/Users/Omrab_Lab/Downloads/Met.grib"
>> excel_file_path <- "C:/Users/Omrab_Lab/Downloads/Met_updated.xlsx"
> 
> # Open the GRIB file
>> raster_data <- stack(grib_file_path)
> 
> # Check the names of the layers to identify which ones to extract
>> layer_names <- names(raster_data)
>> print(layer_names)  # Prints
> 
> 
>> # Extract layers based on layer names - adjust as necessary
>> t2m <- raster_data[[grep("t2m", layer_names)]]
>> d2m <- raster_data[[grep("d2m", layer_names)]]
>> tcc <- raster_data[[grep("tcc", layer_names)]]
>> valid_time <- raster_data[[grep("valid_time", layer_names)]]
>> t2m
> class      : RasterStack
> nlayers    : 0
> 
>> # Check if the raster layers are loaded correctly
>> if (is.null(t2m) || is.null(d2m) || is.null(tcc) || is.null(valid_time))
> {
> +     stop("One or more raster layers could not be loaded. Please check the
> layer names.")
> + }
> 
>> # Convert raster values to vectors
>> t2m_values <- values(t2m)
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
>> d2m_values <- values(d2m)
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
>> tcc_values <- values(tcc)
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
>> valid_time_values <- values(valid_time)
> Error in dimnames(x) <- dn :
>  length of 'dimnames' [2] not equal to array extent
> 
> # Check for NA values and dimensions
> if (any(is.na(t2m_values)) || any(is.na(d2m_values)) || any(is.na(tcc_values))
> || any(is.na(valid_time_values))) {
>  warning("One or more layers contain NA values. These will be removed.")
> }
> 
> # Create the data frame, ensuring no NA values are included
> df <- data.frame(
>  t2m = t2m_values,
>  d2m = d2m_values,
>  tcc = tcc_values,
>  valid_time = valid_time_values,
>  stringsAsFactors = FALSE
> )
> 
> # Remove rows with NA values
> df <- na.omit(df)
> 
> # Convert temperatures from Kelvin to Celsius
> df$t2m <- df$t2m - 273.15
> df$d2m <- df$d2m - 273.15
> 
> # Calculate relative humidity
> calculate_relative_humidity <- function(t2m, d2m) {
>  es <- 6.112 * exp((17.67 * t2m) / (t2m + 243.5))
>  e <- 6.112 * exp((17.67 * d2m) / (d2m + 243.5))
>  rh <- (e / es) * 100
>  return(rh)
> }
> df$RH <- calculate_relative_humidity(df$t2m, df$d2m)
> 
> # Convert valid_time from numeric to POSIXct assuming it's in seconds since
> the epoch
> df$valid_time <- as.POSIXct(df$valid_time, origin = "1970-01-01")
> 
> # Extract year, month, day, and hour from valid_time
> df$Year <- year(df$valid_time)
> df$Month <- month(df$valid_time)
> df$Day <- day(df$valid_time)
> df$Hour <- hour(df$valid_time)
> 
> # Select only the desired columns
> df_selected <- df %>% select(Year, Month, Day, Hour, tcc, t2m, RH)
> 
> # Save the updated DataFrame to an Excel file
> write.xlsx(df_selected, excel_file_path, row.names = FALSE)
> 
> 
> 
> 
> 
> 
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From e@ @end|ng |rom enr|co@chum@nn@net  Tue Oct  1 13:29:57 2024
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Tue, 01 Oct 2024 13:29:57 +0200
Subject: [R] How to install this package
In-Reply-To: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>
 (Christofer Bogaso's message of "Wed, 25 Sep 2024 18:53:02 +0530")
References: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>
Message-ID: <87frpgysay.fsf@enricoschumann.net>

On Wed, 25 Sep 2024, Christofer Bogaso writes:

> Hi,
>
> I would like to install an R library from
> https://cran.r-project.org/src/contrib/Archive/termstrc/
>
> I executed below code without success.
>
> Any help would be appreciated.
>
>> install.packages('/Users/termstrc_1.3.tar.gz', repos = NULL, type="source")
>
> * installing *source* package ?termstrc? ...
>
> ** using staged installation
>
> ** libs
>
> using C++ compiler: ?Apple clang version 16.0.0 (clang-1600.0.26.3)?
>
> using SDK: ?MacOSX15.0.sdk?
>
> clang++ -arch arm64 -std=gnu++17
> -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG
> -I'/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/Rcpp/include'
> -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2
> -c objfcts.cpp -o objfcts.o
>
> clang++ -arch arm64 -std=gnu++17 -dynamiclib
> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
> -L/Library/Frameworks/R.framework/Resources/lib -L/opt/R/arm64/lib -o
> termstrc.so objfcts.o -F/Library/Frameworks/R.framework/.. -framework
> R -Wl,-framework -Wl,CoreFoundation
>
> installing to /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/00LOCK-termstrc/00new/termstrc/libs
>
> ** R
>
> ** data
>
> ** demo
>
> ** byte-compile and prepare package for lazy loading
>
> Error in dyn.load(dynlib <- getDynlib(dir)) :
>
>   unable to load shared object
> '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so':
>
>   dlopen(/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so,
> 0x0006): Library not loaded: /opt/X11/lib/libGLU.1.dylib
>
>   Referenced from: <C90BFE0D-3008-3759-8DC8-B7FD5F3D934B>
> /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so
>
>   Reason: tried: '/opt/X11/lib/libGLU.1.dylib' (no such file),
> '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libGLU.1.dylib' (no
> such file), '/opt/X11/lib/libGLU.1.dylib' (no such file),
> '/Library/Frameworks/R.framework/Resources/lib/libGLU.1.dylib' (no
> such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libGLU.1.dylib'
> (no such file)
>
> ERROR: lazy loading failed for package ?termstrc?
>
> * removing ?/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/termstrc?
>
> Warning message:
>
> In install.packages("/Users/termstrc_1.3.tar.gz",  :
>
>   installation of package ?/Users/termstrc_1.3.tar.gz? had non-zero exit status
>

Is there a reason why you want version 1.3, when a (newer)
version 1.3.7 is available (in the sense of "archived on
CRAN") as well?  This "newer" version is still more than 10
years old.  But for what it is worth, I can install this
version on Ubuntu 24.04, with R 4.4.1.

In case you need only specific functionality from the
package, you might be able to extract those bits either from
the archived tarball, or from the source code at

  https://r-forge.r-project.org/scm/viewvc.php/pkg/?root=termstrc


good luck!

-- 
Enrico Schumann
Lucerne, Switzerland
https://enricoschumann.net


From |zm|r||g @end|ng |rom m@||@n|h@gov  Tue Oct  1 13:53:59 2024
From: |zm|r||g @end|ng |rom m@||@n|h@gov (Izmirlian, Grant (NIH/NCI) [E])
Date: Tue, 1 Oct 2024 11:53:59 +0000
Subject: [R] (no subject)
Message-ID: <w804sdrqrb0d6p4d40sagyxs.1727783543973@email.android.com>

I would go with unlist on x,single bracket subsetted on f


x <- list(`1` = c(7, 13, 1, 4, 10),
          `2` = c(2, 5,  14, 8, 11),
          `3` = c(6, 9, 15, 12, 3))
f <- factor(rep(1:3,5))

unlist(x[f])


Yes, unsplit() it is. I was messing around with ave() (which can be hammered into submission, sort of).

My overlooking unsplit() is somewhat impressive in view of "svn diff -c 18591"....

-pd

> On 27 Sep 2024, at 17:08 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>
>>>>>> Chris Evans via R-help
>>>>>>    on Fri, 27 Sep 2024 12:20:47 +0200 writes:
>
>> Oh glorious!  Thanks Duncan.
>> Fortune cookie nomination!
>
> I don't  disagree with the nomination -- thank you, Duncan!
>
> However, please note that I'm sure Rolf's was challenged /
> question was ment to work correctly for all  factors `f`  with
> levels "1", "2", "3".
>
> Almost all solution were simply assuming that the toy example
> `f` was the real `f`, but that's not realistic.
>
> Consequently, in my view, the only valid proposition and a very
> nice one, indeed, was  Deepayan's (well, he's "R core", ...)
>
>   unsplit(x, f)
>
> Martin
>
>> On 27/09/2024 11:13, Duncan Murdoch wrote:
>>> On 2024-09-26 11:55 p.m., Rolf Turner wrote:
>>>>
>>>> I have (toy example):
>>>>
>>>> x <- list(`1` = c(7, 13, 1, 4, 10),
>>>>            `2` = c(2, 5,  14, 8, 11),
>>>>            `3` = c(6, 9, 15, 12, 3))
>>>> and
>>>>
>>>> f <- factor(rep(1:3,5))
>>>>
>>>> I want to create a vector v of length 15 such that the entries of v,
>>>> corresponding to level l of f are the entries of x[[l]].  I.e. I want
>>>> v to equal
>>>>
>>>>      c(7, 2, 6, 13, 5, 9, 1, 14, 15, 4, 8, 12, 10, 11, 3)
>>>>
>>>> I can create v "easily enough", using say, a for-loop.  It seems to me,
>>>> though, that there should be sexier (single command) way of achieving
>>>> the desired result.  However I cannot devise one.
>>>>
>>>
>>> Don't you find a for loop's naked display of intention to be sexy?
>>>
>>> Duncan Murdoch
>>>
>> --
>> Chris Evans (he/him)
>> Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor,
>> University of Roehampton, London, UK.
>> CORE site: http://www.coresystemtrust.org.uk<http://www.coresystemtrust.org.uk/>
>> Other work web site: https://www.psyctc.org/psyctc/
>> Personal site: https://www.psyctc.org/pelerinage2016/
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html<https://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html<https://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes<http://pd.mes/>@cbs.dk  Priv: PDalgd at gmail.com


	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Tue Oct  1 22:23:11 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Tue, 1 Oct 2024 16:23:11 -0400
Subject: [R] (no subject)
In-Reply-To: <w804sdrqrb0d6p4d40sagyxs.1727783543973@email.android.com>
References: <w804sdrqrb0d6p4d40sagyxs.1727783543973@email.android.com>
Message-ID: <00e501db143f$bc88aad0$359a0070$@gmail.com>

Grant, I think,

Your NO SUBJECT message confused me as it seems a continuation of an earlier
discussion of a new and likely irrelevant metric of the worthiness of R
programs.

Did you make a mistake here? I tried your code as well and the results did
not look like what the OP asked for.

It took me a bit to figure out why we needed factors to do what was asked,
and I have concluded we did not but that a particular approach made use of
it as a way to get unsplit to gather the right values together as in:

  x <- list(`1` = c(7, 13, 1, 4, 10),
            `2` = c(2, 5,  14, 8, 11),
            `3` = c(6, 9, 15, 12, 3))
  f <- factor(rep(1:3,5))

  result <- unsplit(x, f)

By inspection, what the code is doing is treating the three list elements
like rows  stacked and then reading down the columns from left to right:

  > x
  $`1`
  [1]  7 13  1  4 10

  $`2`
  [1]  2  5 14  8 11

  $`3`
  [1]  6  9 15 12  3

  > unsplit(x, f)
   [1]  7  2  6 13  5  9  1 14 15  4  8 12 10 11  3

Your code offers, instead:

unlist(x[f])

I have no idea why that would work as it acts by taking indices (not really
factors even if in factor form as it end up being integers from 1 to 3
repeated 5 times) and thus simply repeats all of x five times and then
gathers all the results in a pile of numbers that does not resemble what is
wanted:

> f
 [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3
Levels: 1 2 3
> x[f]
$`1`
[1]  7 13  1  4 10

$`2`
[1]  2  5 14  8 11

$`3`
[1]  6  9 15 12  3

$`1`
[1]  7 13  1  4 10

<<<LOTS OMITTED

$`3`
[1]  6  9 15 12  3

> unlist(x[f])
11 12 13 14 15 21 22 23 24 25 31 32 33 34 35 11 12 13 14 15 21 22 23 24 25
31 32 33 34 35 11 12 13 14 15 
 7 13  1  4 10  2  5 14  8 11  6  9 15 12  3  7 13  1  4 10  2  5 14  8 11
6  9 15 12  3  7 13  1  4 10 
21 22 23 24 25 31 32 33 34 35 11 12 13 14 15 21 22 23 24 25 31 32 33 34 35
11 12 13 14 15 21 22 23 24 25 
 2  5 14  8 11  6  9 15 12  3  7 13  1  4 10  2  5 14  8 11  6  9 15 12  3
7 13  1  4 10  2  5 14  8 11 
31 32 33 34 35 
 6  9 15 12  3

I would like to hear if you meant something else or am I doing anything
wrong.

I was thinking of how to expand the request using the technique we now
consider the Rexiest.

If you declare x to be a list of Nrows vectors, all the same length, Mcols,
then a generalized version might be working on something like this, where,
names do not seem needed or even relevant as the various methods use have
tossed them.

x <- list(c(7, 13, 1, 4, 10, 12),
          c(2, 5,  14, 8, 11, 13),
          c(6, 9, 15, 12, 3, 14),
          c( 101, 102, 103, 104, 105, 15),
          c(-105, -104, -103, -102, -101, 16))

I added one number at the end of each from above and added two rows.

The number of items in the list is:

Nrows <- length(x)

In the above example, that happens to be five and in the original, 3.

Assuming all the parts are the same length, you can just check one of them
for a length as a vector:

Mcols <- length(x[[1]])

And you get 6 for the new version and 5 for the original.

So, using the same technique, generalized, should work as:

f <- factor(rep(1:Nrows,Mcols))

And the result is:

result <- unsplit(x, f)

Comparing the new test of x versus results shows

> x
[[1]]
[1]  7 13  1  4 10 12

[[2]]
[1]  2  5 14  8 11 13

[[3]]
[1]  6  9 15 12  3 14

[[4]]
[1] 101 102 103 104 105  15

[[5]]
[1] -105 -104 -103 -102 -101   16

> result
 [1]    7    2    6  101 -105   13    5    9  102 -104    1   14   15  103
-103    4    8   12  104 -102
[21]   10   11    3  105 -101   12   13   14   15   16

Of course, many of the other techniques we discussed here also scale up to
any size easily, if not as compactly.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Izmirlian, Grant
(NIH/NCI) [E] via R-help
Sent: Tuesday, October 1, 2024 7:54 AM
To: R-help at r-project.org
Subject: [R] (no subject)

I would go with unlist on x,single bracket subsetted on f


x <- list(`1` = c(7, 13, 1, 4, 10),
          `2` = c(2, 5,  14, 8, 11),
          `3` = c(6, 9, 15, 12, 3))
f <- factor(rep(1:3,5))

unlist(x[f])


Yes, unsplit() it is. I was messing around with ave() (which can be hammered
into submission, sort of).

My overlooking unsplit() is somewhat impressive in view of "svn diff -c
18591"....

-pd

> On 27 Sep 2024, at 17:08 , Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

>
>>>>>> Chris Evans via R-help
>>>>>>    on Fri, 27 Sep 2024 12:20:47 +0200 writes:
>
>> Oh glorious!  Thanks Duncan.
>> Fortune cookie nomination!
>
> I don't  disagree with the nomination -- thank you, Duncan!
>
> However, please note that I'm sure Rolf's was challenged /
> question was ment to work correctly for all  factors `f`  with
> levels "1", "2", "3".
>
> Almost all solution were simply assuming that the toy example
> `f` was the real `f`, but that's not realistic.
>
> Consequently, in my view, the only valid proposition and a very
> nice one, indeed, was  Deepayan's (well, he's "R core", ...)
>
>   unsplit(x, f)
>
> Martin
>
>> On 27/09/2024 11:13, Duncan Murdoch wrote:
>>> On 2024-09-26 11:55 p.m., Rolf Turner wrote:
>>>>
>>>> I have (toy example):
>>>>
>>>> x <- list(`1` = c(7, 13, 1, 4, 10),
>>>>            `2` = c(2, 5,  14, 8, 11),
>>>>            `3` = c(6, 9, 15, 12, 3))
>>>> and
>>>>
>>>> f <- factor(rep(1:3,5))
>>>>
>>>> I want to create a vector v of length 15 such that the entries of v,
>>>> corresponding to level l of f are the entries of x[[l]].  I.e. I want
>>>> v to equal
>>>>
>>>>      c(7, 2, 6, 13, 5, 9, 1, 14, 15, 4, 8, 12, 10, 11, 3)
>>>>
>>>> I can create v "easily enough", using say, a for-loop.  It seems to me,
>>>> though, that there should be sexier (single command) way of achieving
>>>> the desired result.  However I cannot devise one.
>>>>
>>>
>>> Don't you find a for loop's naked display of intention to be sexy?
>>>
>>> Duncan Murdoch
>>>
>> --
>> Chris Evans (he/him)
>> Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor,
>> University of Roehampton, London, UK.
>> CORE site:
http://www.coresystemtrust.org.uk<http://www.coresystemtrust.org.uk/>
>> Other work web site: https://www.psyctc.org/psyctc/
>> Personal site: https://www.psyctc.org/pelerinage2016/
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html<https://www.r-project.org/posti
ng-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html<https://www.r-project.org/posti
ng-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes<http://pd.mes/>@cbs.dk  Priv: PDalgd at gmail.com


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 03:57:21 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 09:57:21 +0800
Subject: [R] Change data frame to time series data
Message-ID: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>

Dear all, I have a data in data frame and would like to change to time
series data. Thank you for any help given.






> str(dt)'data.frame':	525600 obs. of  3 variables:
 $ time             : chr  "2014-01-01 00:00:00" "2014-01-01 00:01:00"
"2014-01-01 00:02:00" "2014-01-01 00:03:00" ...
 $ cnt_charge_events: int  0 0 0 0 0 0 0 0 0 0 ...
 $ count            : int  0 0 0 0 0 0 0 0 0 0 ...

> head(dt)                 time cnt_charge_events count
1 2014-01-01 00:00:00                 0     0
2 2014-01-01 00:01:00                 0     0
3 2014-01-01 00:02:00                 0     0
4 2014-01-01 00:03:00                 0     0
5 2014-01-01 00:04:00                 0     0
6 2014-01-01 00:05:00                 0     0


> dt_ts <- xts(dt$count, dt$time)Error in xts(dt$count, dt$time) :
  order.by requires an appropriate time-based object> head(dt_ts)Time Series:
Start = 1
End = 6
Frequency = 1
  dt_ts.date dt_ts.time dt[, 3]
1      16071          1       0
2      16071          2       0
3      16071          3       0
4      16071          4       0
5      16071          5       0
6      16071          6       0Dear


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Oct  2 09:01:58 2024
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 02 Oct 2024 09:01:58 +0200
Subject: [R] Change data frame to time series data
In-Reply-To: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 (roslinazairimah zakaria's message of "Wed, 2 Oct 2024 09:57:21
 +0800")
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
Message-ID: <874j5vm1i1.fsf@enricoschumann.net>

On Wed, 02 Oct 2024, roslinazairimah zakaria writes:

> Dear all, I have a data in data frame and would like to change to time
> series data. Thank you for any help given.
>
>> str(dt)'data.frame':	525600 obs. of  3 variables:
>  $ time             : chr  "2014-01-01 00:00:00" "2014-01-01 00:01:00"
> "2014-01-01 00:02:00" "2014-01-01 00:03:00" ...
>  $ cnt_charge_events: int  0 0 0 0 0 0 0 0 0 0 ...
>  $ count            : int  0 0 0 0 0 0 0 0 0 0 ...
>
>> head(dt)                 time cnt_charge_events count
> 1 2014-01-01 00:00:00                 0     0
> 2 2014-01-01 00:01:00                 0     0
> 3 2014-01-01 00:02:00                 0     0
> 4 2014-01-01 00:03:00                 0     0
> 5 2014-01-01 00:04:00                 0     0
> 6 2014-01-01 00:05:00                 0     0
>
>
>> dt_ts <- xts(dt$count, dt$time)Error in xts(dt$count, dt$time) :
>   order.by requires an appropriate time-based object> head(dt_ts)Time Series:
> Start = 1
> End = 6
> Frequency = 1
>   dt_ts.date dt_ts.time dt[, 3]
> 1      16071          1       0
> 2      16071          2       0
> 3      16071          3       0
> 4      16071          4       0
> 5      16071          5       0
> 6      16071          6       0Dear


Your "time" column consists of character strings, not
actual timestamps. 

  dt <- read.table(
  text ="
  time, cnt_charge_events, count
  2014-01-01 00:00:00, 1, 1 
  2014-01-01 00:01:00, 2, 2 
  2014-01-01 00:02:00, 3, 3 
  2014-01-01 00:03:00, 4, 4
  2014-01-01 00:04:00, 5, 5
  2014-01-01 00:05:00, 6, 6",
  header = TRUE, sep = ",")
  
  library("xts")
  xts(dt$count, dt$time)  ## won't work
  ## Error in xts(dt$count, dt$time) : 
  ##   order.by requires an appropriate time-based object
  
  dt$time <- as.POSIXct(dt$time)
  xts(dt$count, dt$time)
  ##                     [,1]
  ## 2014-01-01 00:00:00    1
  ## 2014-01-01 00:01:00    2
  ## 2014-01-01 00:02:00    3

But be sure to read about ?as.POSIXct; in particular,
the handling of timezones/daylight-saving time.


> [[alternative HTML version deleted]]

Please send plain-text messages to this list; otherwise,
the results become hard to read.

-- 
Enrico Schumann
Lucerne, Switzerland
https://enricoschumann.net


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 16:42:46 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 22:42:46 +0800
Subject: [R] How to install this package
In-Reply-To: <87frpgysay.fsf@enricoschumann.net>
References: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>
 <87frpgysay.fsf@enricoschumann.net>
Message-ID: <CANTvJZKK2j2pBa1=avpsE3s=d_w7xAb7MXpXMtaPkRtyMF3D5g@mail.gmail.com>

Hi Enrico, yes it works. I can also plot the graph.
Next question, how do I delete the date from 16 December until 31 December
2014?


Thank you very much.

> dt$time <- as.POSIXct(dt$time)> > dt_ts <- xts(dt$count, dt$time)> str(dt_ts)An xts object on 2014-01-01 / 2014-12-31 23:59:00 containing:
  Data:    integer [525600, 1]
  Index:   POSIXct,POSIXt [525600] (TZ: "")


plot(dt_ts)


On Tue, Oct 1, 2024 at 7:30?PM Enrico Schumann <es at enricoschumann.net>
wrote:

> On Wed, 25 Sep 2024, Christofer Bogaso writes:
>
> > Hi,
> >
> > I would like to install an R library from
> > https://cran.r-project.org/src/contrib/Archive/termstrc/
> >
> > I executed below code without success.
> >
> > Any help would be appreciated.
> >
> >> install.packages('/Users/termstrc_1.3.tar.gz', repos = NULL,
> type="source")
> >
> > * installing *source* package ?termstrc? ...
> >
> > ** using staged installation
> >
> > ** libs
> >
> > using C++ compiler: ?Apple clang version 16.0.0 (clang-1600.0.26.3)?
> >
> > using SDK: ?MacOSX15.0.sdk?
> >
> > clang++ -arch arm64 -std=gnu++17
> > -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG
> >
> -I'/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/Rcpp/include'
> > -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2
> > -c objfcts.cpp -o objfcts.o
> >
> > clang++ -arch arm64 -std=gnu++17 -dynamiclib
> > -Wl,-headerpad_max_install_names -undefined dynamic_lookup
> > -L/Library/Frameworks/R.framework/Resources/lib -L/opt/R/arm64/lib -o
> > termstrc.so objfcts.o -F/Library/Frameworks/R.framework/.. -framework
> > R -Wl,-framework -Wl,CoreFoundation
> >
> > installing to
> /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/00LOCK-termstrc/00new/termstrc/libs
> >
> > ** R
> >
> > ** data
> >
> > ** demo
> >
> > ** byte-compile and prepare package for lazy loading
> >
> > Error in dyn.load(dynlib <- getDynlib(dir)) :
> >
> >   unable to load shared object
> >
> '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so':
> >
> >
>  dlopen(/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so,
> > 0x0006): Library not loaded: /opt/X11/lib/libGLU.1.dylib
> >
> >   Referenced from: <C90BFE0D-3008-3759-8DC8-B7FD5F3D934B>
> >
> /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so
> >
> >   Reason: tried: '/opt/X11/lib/libGLU.1.dylib' (no such file),
> > '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libGLU.1.dylib' (no
> > such file), '/opt/X11/lib/libGLU.1.dylib' (no such file),
> > '/Library/Frameworks/R.framework/Resources/lib/libGLU.1.dylib' (no
> > such file),
> '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libGLU.1.dylib'
> > (no such file)
> >
> > ERROR: lazy loading failed for package ?termstrc?
> >
> > * removing
> ?/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/termstrc?
> >
> > Warning message:
> >
> > In install.packages("/Users/termstrc_1.3.tar.gz",  :
> >
> >   installation of package ?/Users/termstrc_1.3.tar.gz? had non-zero exit
> status
> >
>
> Is there a reason why you want version 1.3, when a (newer)
> version 1.3.7 is available (in the sense of "archived on
> CRAN") as well?  This "newer" version is still more than 10
> years old.  But for what it is worth, I can install this
> version on Ubuntu 24.04, with R 4.4.1.
>
> In case you need only specific functionality from the
> package, you might be able to extract those bits either from
> the archived tarball, or from the source code at
>
>   https://r-forge.r-project.org/scm/viewvc.php/pkg/?root=termstrc
>
>
> good luck!
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> https://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 16:45:02 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 22:45:02 +0800
Subject: [R] Change data frame to time series data
In-Reply-To: <874j5vm1i1.fsf@enricoschumann.net>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
Message-ID: <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>

Hi Enrico, yes it works. I can also plot the graph.
Next question, how do I delete the date from 16 December until 31 December
2014?


Thank you very much.

> dt$time <- as.POSIXct(dt$time)> > dt_ts <- xts(dt$count, dt$time)> str(dt_ts)An xts object on 2014-01-01 / 2014-12-31 23:59:00 containing:
  Data:    integer [525600, 1]
  Index:   POSIXct,POSIXt [525600] (TZ: "")


plot(dt_ts)


On Wed, Oct 2, 2024 at 3:01?PM Enrico Schumann <es at enricoschumann.net>
wrote:

> On Wed, 02 Oct 2024, roslinazairimah zakaria writes:
>
> > Dear all, I have a data in data frame and would like to change to time
> > series data. Thank you for any help given.
> >
> >> str(dt)'data.frame': 525600 obs. of  3 variables:
> >  $ time             : chr  "2014-01-01 00:00:00" "2014-01-01 00:01:00"
> > "2014-01-01 00:02:00" "2014-01-01 00:03:00" ...
> >  $ cnt_charge_events: int  0 0 0 0 0 0 0 0 0 0 ...
> >  $ count            : int  0 0 0 0 0 0 0 0 0 0 ...
> >
> >> head(dt)                 time cnt_charge_events count
> > 1 2014-01-01 00:00:00                 0     0
> > 2 2014-01-01 00:01:00                 0     0
> > 3 2014-01-01 00:02:00                 0     0
> > 4 2014-01-01 00:03:00                 0     0
> > 5 2014-01-01 00:04:00                 0     0
> > 6 2014-01-01 00:05:00                 0     0
> >
> >
> >> dt_ts <- xts(dt$count, dt$time)Error in xts(dt$count, dt$time) :
> >   order.by requires an appropriate time-based object> head(dt_ts)Time
> Series:
> > Start = 1
> > End = 6
> > Frequency = 1
> >   dt_ts.date dt_ts.time dt[, 3]
> > 1      16071          1       0
> > 2      16071          2       0
> > 3      16071          3       0
> > 4      16071          4       0
> > 5      16071          5       0
> > 6      16071          6       0Dear
>
>
> Your "time" column consists of character strings, not
> actual timestamps.
>
>   dt <- read.table(
>   text ="
>   time, cnt_charge_events, count
>   2014-01-01 00:00:00, 1, 1
>   2014-01-01 00:01:00, 2, 2
>   2014-01-01 00:02:00, 3, 3
>   2014-01-01 00:03:00, 4, 4
>   2014-01-01 00:04:00, 5, 5
>   2014-01-01 00:05:00, 6, 6",
>   header = TRUE, sep = ",")
>
>   library("xts")
>   xts(dt$count, dt$time)  ## won't work
>   ## Error in xts(dt$count, dt$time) :
>   ##   order.by requires an appropriate time-based object
>
>   dt$time <- as.POSIXct(dt$time)
>   xts(dt$count, dt$time)
>   ##                     [,1]
>   ## 2014-01-01 00:00:00    1
>   ## 2014-01-01 00:01:00    2
>   ## 2014-01-01 00:02:00    3
>
> But be sure to read about ?as.POSIXct; in particular,
> the handling of timezones/daylight-saving time.
>
>
> > [[alternative HTML version deleted]]
>
> Please send plain-text messages to this list; otherwise,
> the results become hard to read.
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> https://enricoschumann.net
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Wed Oct  2 16:58:19 2024
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Wed, 2 Oct 2024 07:58:19 -0700
Subject: [R] Change data frame to time series data
In-Reply-To: <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
Message-ID: <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>

On Wed, 2 Oct 2024 at 07:53, roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Next question, how do I delete the date from 16 December until 31 December
> 2014?
>

Something like:
myData <- xtsObj[myData$date <  "2014-12-16" & myData$date > "2024-12-31"]
-- H

-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 17:20:00 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 23:20:00 +0800
Subject: [R] Change data frame to time series data
In-Reply-To: <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
Message-ID: <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>

Let say, this is my data and I want to extract from 2014-01-01
00:00:00 to 2014-01-01
16:30:00

>dput(head(dt_ts,1000))

structure(c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), class = c("xts",
"zoo"), index = structure(c(1388505600, 1388505660, 1388505720,
1388505780, 1388505840, 1388505900, 1388505960, 1388506020, 1388506080,
1388506140, 1388506200, 1388506260, 1388506320, 1388506380, 1388506440,
1388506500, 1388506560, 1388506620, 1388506680, 1388506740, 1388506800,
1388506860, 1388506920, 1388506980, 1388507040, 1388507100, 1388507160,
1388507220, 1388507280, 1388507340, 1388507400, 1388507460, 1388507520,
1388507580, 1388507640, 1388507700, 1388507760, 1388507820, 1388507880,
1388507940, 1388508000, 1388508060, 1388508120, 1388508180, 1388508240,
1388508300, 1388508360, 1388508420, 1388508480, 1388508540, 1388508600,
1388508660, 1388508720, 1388508780, 1388508840, 1388508900, 1388508960,
1388509020, 1388509080, 1388509140, 1388509200, 1388509260, 1388509320,
1388509380, 1388509440, 1388509500, 1388509560, 1388509620, 1388509680,
1388509740, 1388509800, 1388509860, 1388509920, 1388509980, 1388510040,
1388510100, 1388510160, 1388510220, 1388510280, 1388510340, 1388510400,
1388510460, 1388510520, 1388510580, 1388510640, 1388510700, 1388510760,
1388510820, 1388510880, 1388510940, 1388511000, 1388511060, 1388511120,
1388511180, 1388511240, 1388511300, 1388511360, 1388511420, 1388511480,
1388511540, 1388511600, 1388511660, 1388511720, 1388511780, 1388511840,
1388511900, 1388511960, 1388512020, 1388512080, 1388512140, 1388512200,
1388512260, 1388512320, 1388512380, 1388512440, 1388512500, 1388512560,
1388512620, 1388512680, 1388512740, 1388512800, 1388512860, 1388512920,
1388512980, 1388513040, 1388513100, 1388513160, 1388513220, 1388513280,
1388513340, 1388513400, 1388513460, 1388513520, 1388513580, 1388513640,
1388513700, 1388513760, 1388513820, 1388513880, 1388513940, 1388514000,
1388514060, 1388514120, 1388514180, 1388514240, 1388514300, 1388514360,
1388514420, 1388514480, 1388514540, 1388514600, 1388514660, 1388514720,
1388514780, 1388514840, 1388514900, 1388514960, 1388515020, 1388515080,
1388515140, 1388515200, 1388515260, 1388515320, 1388515380, 1388515440,
1388515500, 1388515560, 1388515620, 1388515680, 1388515740, 1388515800,
1388515860, 1388515920, 1388515980, 1388516040, 1388516100, 1388516160,
1388516220, 1388516280, 1388516340, 1388516400, 1388516460, 1388516520,
1388516580, 1388516640, 1388516700, 1388516760, 1388516820, 1388516880,
1388516940, 1388517000, 1388517060, 1388517120, 1388517180, 1388517240,
1388517300, 1388517360, 1388517420, 1388517480, 1388517540, 1388517600,
1388517660, 1388517720, 1388517780, 1388517840, 1388517900, 1388517960,
1388518020, 1388518080, 1388518140, 1388518200, 1388518260, 1388518320,
1388518380, 1388518440, 1388518500, 1388518560, 1388518620, 1388518680,
1388518740, 1388518800, 1388518860, 1388518920, 1388518980, 1388519040,
1388519100, 1388519160, 1388519220, 1388519280, 1388519340, 1388519400,
1388519460, 1388519520, 1388519580, 1388519640, 1388519700, 1388519760,
1388519820, 1388519880, 1388519940, 1388520000, 1388520060, 1388520120,
1388520180, 1388520240, 1388520300, 1388520360, 1388520420, 1388520480,
1388520540, 1388520600, 1388520660, 1388520720, 1388520780, 1388520840,
1388520900, 1388520960, 1388521020, 1388521080, 1388521140, 1388521200,
1388521260, 1388521320, 1388521380, 1388521440, 1388521500, 1388521560,
1388521620, 1388521680, 1388521740, 1388521800, 1388521860, 1388521920,
1388521980, 1388522040, 1388522100, 1388522160, 1388522220, 1388522280,
1388522340, 1388522400, 1388522460, 1388522520, 1388522580, 1388522640,
1388522700, 1388522760, 1388522820, 1388522880, 1388522940, 1388523000,
1388523060, 1388523120, 1388523180, 1388523240, 1388523300, 1388523360,
1388523420, 1388523480, 1388523540, 1388523600, 1388523660, 1388523720,
1388523780, 1388523840, 1388523900, 1388523960, 1388524020, 1388524080,
1388524140, 1388524200, 1388524260, 1388524320, 1388524380, 1388524440,
1388524500, 1388524560, 1388524620, 1388524680, 1388524740, 1388524800,
1388524860, 1388524920, 1388524980, 1388525040, 1388525100, 1388525160,
1388525220, 1388525280, 1388525340, 1388525400, 1388525460, 1388525520,
1388525580, 1388525640, 1388525700, 1388525760, 1388525820, 1388525880,
1388525940, 1388526000, 1388526060, 1388526120, 1388526180, 1388526240,
1388526300, 1388526360, 1388526420, 1388526480, 1388526540, 1388526600,
1388526660, 1388526720, 1388526780, 1388526840, 1388526900, 1388526960,
1388527020, 1388527080, 1388527140, 1388527200, 1388527260, 1388527320,
1388527380, 1388527440, 1388527500, 1388527560, 1388527620, 1388527680,
1388527740, 1388527800, 1388527860, 1388527920, 1388527980, 1388528040,
1388528100, 1388528160, 1388528220, 1388528280, 1388528340, 1388528400,
1388528460, 1388528520, 1388528580, 1388528640, 1388528700, 1388528760,
1388528820, 1388528880, 1388528940, 1388529000, 1388529060, 1388529120,
1388529180, 1388529240, 1388529300, 1388529360, 1388529420, 1388529480,
1388529540, 1388529600, 1388529660, 1388529720, 1388529780, 1388529840,
1388529900, 1388529960, 1388530020, 1388530080, 1388530140, 1388530200,
1388530260, 1388530320, 1388530380, 1388530440, 1388530500, 1388530560,
1388530620, 1388530680, 1388530740, 1388530800, 1388530860, 1388530920,
1388530980, 1388531040, 1388531100, 1388531160, 1388531220, 1388531280,
1388531340, 1388531400, 1388531460, 1388531520, 1388531580, 1388531640,
1388531700, 1388531760, 1388531820, 1388531880, 1388531940, 1388532000,
1388532060, 1388532120, 1388532180, 1388532240, 1388532300, 1388532360,
1388532420, 1388532480, 1388532540, 1388532600, 1388532660, 1388532720,
1388532780, 1388532840, 1388532900, 1388532960, 1388533020, 1388533080,
1388533140, 1388533200, 1388533260, 1388533320, 1388533380, 1388533440,
1388533500, 1388533560, 1388533620, 1388533680, 1388533740, 1388533800,
1388533860, 1388533920, 1388533980, 1388534040, 1388534100, 1388534160,
1388534220, 1388534280, 1388534340, 1388534400, 1388534460, 1388534520,
1388534580, 1388534640, 1388534700, 1388534760, 1388534820, 1388534880,
1388534940, 1388535000, 1388535060, 1388535120, 1388535180, 1388535240,
1388535300, 1388535360, 1388535420, 1388535480, 1388535540, 1388535600,
1388535660, 1388535720, 1388535780, 1388535840, 1388535900, 1388535960,
1388536020, 1388536080, 1388536140, 1388536200, 1388536260, 1388536320,
1388536380, 1388536440, 1388536500, 1388536560, 1388536620, 1388536680,
1388536740, 1388536800, 1388536860, 1388536920, 1388536980, 1388537040,
1388537100, 1388537160, 1388537220, 1388537280, 1388537340, 1388537400,
1388537460, 1388537520, 1388537580, 1388537640, 1388537700, 1388537760,
1388537820, 1388537880, 1388537940, 1388538000, 1388538060, 1388538120,
1388538180, 1388538240, 1388538300, 1388538360, 1388538420, 1388538480,
1388538540, 1388538600, 1388538660, 1388538720, 1388538780, 1388538840,
1388538900, 1388538960, 1388539020, 1388539080, 1388539140, 1388539200,
1388539260, 1388539320, 1388539380, 1388539440, 1388539500, 1388539560,
1388539620, 1388539680, 1388539740, 1388539800, 1388539860, 1388539920,
1388539980, 1388540040, 1388540100, 1388540160, 1388540220, 1388540280,
1388540340, 1388540400, 1388540460, 1388540520, 1388540580, 1388540640,
1388540700, 1388540760, 1388540820, 1388540880, 1388540940, 1388541000,
1388541060, 1388541120, 1388541180, 1388541240, 1388541300, 1388541360,
1388541420, 1388541480, 1388541540, 1388541600, 1388541660, 1388541720,
1388541780, 1388541840, 1388541900, 1388541960, 1388542020, 1388542080,
1388542140, 1388542200, 1388542260, 1388542320, 1388542380, 1388542440,
1388542500, 1388542560, 1388542620, 1388542680, 1388542740, 1388542800,
1388542860, 1388542920, 1388542980, 1388543040, 1388543100, 1388543160,
1388543220, 1388543280, 1388543340, 1388543400, 1388543460, 1388543520,
1388543580, 1388543640, 1388543700, 1388543760, 1388543820, 1388543880,
1388543940, 1388544000, 1388544060, 1388544120, 1388544180, 1388544240,
1388544300, 1388544360, 1388544420, 1388544480, 1388544540, 1388544600,
1388544660, 1388544720, 1388544780, 1388544840, 1388544900, 1388544960,
1388545020, 1388545080, 1388545140, 1388545200, 1388545260, 1388545320,
1388545380, 1388545440, 1388545500, 1388545560, 1388545620, 1388545680,
1388545740, 1388545800, 1388545860, 1388545920, 1388545980, 1388546040,
1388546100, 1388546160, 1388546220, 1388546280, 1388546340, 1388546400,
1388546460, 1388546520, 1388546580, 1388546640, 1388546700, 1388546760,
1388546820, 1388546880, 1388546940, 1388547000, 1388547060, 1388547120,
1388547180, 1388547240, 1388547300, 1388547360, 1388547420, 1388547480,
1388547540, 1388547600, 1388547660, 1388547720, 1388547780, 1388547840,
1388547900, 1388547960, 1388548020, 1388548080, 1388548140, 1388548200,
1388548260, 1388548320, 1388548380, 1388548440, 1388548500, 1388548560,
1388548620, 1388548680, 1388548740, 1388548800, 1388548860, 1388548920,
1388548980, 1388549040, 1388549100, 1388549160, 1388549220, 1388549280,
1388549340, 1388549400, 1388549460, 1388549520, 1388549580, 1388549640,
1388549700, 1388549760, 1388549820, 1388549880, 1388549940, 1388550000,
1388550060, 1388550120, 1388550180, 1388550240, 1388550300, 1388550360,
1388550420, 1388550480, 1388550540, 1388550600, 1388550660, 1388550720,
1388550780, 1388550840, 1388550900, 1388550960, 1388551020, 1388551080,
1388551140, 1388551200, 1388551260, 1388551320, 1388551380, 1388551440,
1388551500, 1388551560, 1388551620, 1388551680, 1388551740, 1388551800,
1388551860, 1388551920, 1388551980, 1388552040, 1388552100, 1388552160,
1388552220, 1388552280, 1388552340, 1388552400, 1388552460, 1388552520,
1388552580, 1388552640, 1388552700, 1388552760, 1388552820, 1388552880,
1388552940, 1388553000, 1388553060, 1388553120, 1388553180, 1388553240,
1388553300, 1388553360, 1388553420, 1388553480, 1388553540, 1388553600,
1388553660, 1388553720, 1388553780, 1388553840, 1388553900, 1388553960,
1388554020, 1388554080, 1388554140, 1388554200, 1388554260, 1388554320,
1388554380, 1388554440, 1388554500, 1388554560, 1388554620, 1388554680,
1388554740, 1388554800, 1388554860, 1388554920, 1388554980, 1388555040,
1388555100, 1388555160, 1388555220, 1388555280, 1388555340, 1388555400,
1388555460, 1388555520, 1388555580, 1388555640, 1388555700, 1388555760,
1388555820, 1388555880, 1388555940, 1388556000, 1388556060, 1388556120,
1388556180, 1388556240, 1388556300, 1388556360, 1388556420, 1388556480,
1388556540, 1388556600, 1388556660, 1388556720, 1388556780, 1388556840,
1388556900, 1388556960, 1388557020, 1388557080, 1388557140, 1388557200,
1388557260, 1388557320, 1388557380, 1388557440, 1388557500, 1388557560,
1388557620, 1388557680, 1388557740, 1388557800, 1388557860, 1388557920,
1388557980, 1388558040, 1388558100, 1388558160, 1388558220, 1388558280,
1388558340, 1388558400, 1388558460, 1388558520, 1388558580, 1388558640,
1388558700, 1388558760, 1388558820, 1388558880, 1388558940, 1388559000,
1388559060, 1388559120, 1388559180, 1388559240, 1388559300, 1388559360,
1388559420, 1388559480, 1388559540, 1388559600, 1388559660, 1388559720,
1388559780, 1388559840, 1388559900, 1388559960, 1388560020, 1388560080,
1388560140, 1388560200, 1388560260, 1388560320, 1388560380, 1388560440,
1388560500, 1388560560, 1388560620, 1388560680, 1388560740, 1388560800,
1388560860, 1388560920, 1388560980, 1388561040, 1388561100, 1388561160,
1388561220, 1388561280, 1388561340, 1388561400, 1388561460, 1388561520,
1388561580, 1388561640, 1388561700, 1388561760, 1388561820, 1388561880,
1388561940, 1388562000, 1388562060, 1388562120, 1388562180, 1388562240,
1388562300, 1388562360, 1388562420, 1388562480, 1388562540, 1388562600,
1388562660, 1388562720, 1388562780, 1388562840, 1388562900, 1388562960,
1388563020, 1388563080, 1388563140, 1388563200, 1388563260, 1388563320,
1388563380, 1388563440, 1388563500, 1388563560, 1388563620, 1388563680,
1388563740, 1388563800, 1388563860, 1388563920, 1388563980, 1388564040,
1388564100, 1388564160, 1388564220, 1388564280, 1388564340, 1388564400,
1388564460, 1388564520, 1388564580, 1388564640, 1388564700, 1388564760,
1388564820, 1388564880, 1388564940, 1388565000, 1388565060, 1388565120,
1388565180, 1388565240, 1388565300, 1388565360, 1388565420, 1388565480,
1388565540), tzone = "", tclass = c("POSIXct", "POSIXt")), dim = c(1000L,
1L))


On Wed, Oct 2, 2024 at 11:03?PM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> On Wed, 2 Oct 2024 at 07:53, roslinazairimah zakaria <roslinaump at gmail.com
> >
> wrote:
>
> > Next question, how do I delete the date from 16 December until 31
> December
> > 2014?
> >
>
> Something like:
> myData <- xtsObj[myData$date <  "2014-12-16" & myData$date > "2024-12-31"]
> -- H
>
> --
> OpenPGP: https://hasan.d8u.us/openpgp.asc
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> from my mobile device
> Envoye de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Wed Oct  2 17:35:19 2024
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Wed, 2 Oct 2024 08:35:19 -0700
Subject: [R] Change data frame to time series data
In-Reply-To: <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
Message-ID: <CAP+bYWBJBJ1gTxxfyt6FVUH+1q2Rs54N-vgRthH9jjJH4p4mXQ@mail.gmail.com>

On Wed, 2 Oct 2024 at 08:20, roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Let say, this is my data and I want to extract from 2014-01-01 00:00:00
> to 2014-01-01 16:30:00
>
>
dt_ts['2014-01-01 00:00:00'::'2014-01-01 16:30:00']

Try that?



-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Oct  2 17:39:22 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 2 Oct 2024 16:39:22 +0100
Subject: [R] Change data frame to time series data
In-Reply-To: <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
Message-ID: <0df53d3b-1003-4922-9959-1c27621735f1@sapo.pt>

?s 16:20 de 02/10/2024, roslinazairimah zakaria escreveu:
> Let say, this is my data and I want to extract from 2014-01-01
> 00:00:00 to 2014-01-01
> 16:30:00
> 
>> dput(head(dt_ts,1000))
> 
> structure(c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), class = c("xts",
> "zoo"), index = structure(c(1388505600, 1388505660, 1388505720,
> 1388505780, 1388505840, 1388505900, 1388505960, 1388506020, 1388506080,
> 1388506140, 1388506200, 1388506260, 1388506320, 1388506380, 1388506440,
> 1388506500, 1388506560, 1388506620, 1388506680, 1388506740, 1388506800,
> 1388506860, 1388506920, 1388506980, 1388507040, 1388507100, 1388507160,
> 1388507220, 1388507280, 1388507340, 1388507400, 1388507460, 1388507520,
> 1388507580, 1388507640, 1388507700, 1388507760, 1388507820, 1388507880,
> 1388507940, 1388508000, 1388508060, 1388508120, 1388508180, 1388508240,
> 1388508300, 1388508360, 1388508420, 1388508480, 1388508540, 1388508600,
> 1388508660, 1388508720, 1388508780, 1388508840, 1388508900, 1388508960,
> 1388509020, 1388509080, 1388509140, 1388509200, 1388509260, 1388509320,
> 1388509380, 1388509440, 1388509500, 1388509560, 1388509620, 1388509680,
> 1388509740, 1388509800, 1388509860, 1388509920, 1388509980, 1388510040,
> 1388510100, 1388510160, 1388510220, 1388510280, 1388510340, 1388510400,
> 1388510460, 1388510520, 1388510580, 1388510640, 1388510700, 1388510760,
> 1388510820, 1388510880, 1388510940, 1388511000, 1388511060, 1388511120,
> 1388511180, 1388511240, 1388511300, 1388511360, 1388511420, 1388511480,
> 1388511540, 1388511600, 1388511660, 1388511720, 1388511780, 1388511840,
> 1388511900, 1388511960, 1388512020, 1388512080, 1388512140, 1388512200,
> 1388512260, 1388512320, 1388512380, 1388512440, 1388512500, 1388512560,
> 1388512620, 1388512680, 1388512740, 1388512800, 1388512860, 1388512920,
> 1388512980, 1388513040, 1388513100, 1388513160, 1388513220, 1388513280,
> 1388513340, 1388513400, 1388513460, 1388513520, 1388513580, 1388513640,
> 1388513700, 1388513760, 1388513820, 1388513880, 1388513940, 1388514000,
> 1388514060, 1388514120, 1388514180, 1388514240, 1388514300, 1388514360,
> 1388514420, 1388514480, 1388514540, 1388514600, 1388514660, 1388514720,
> 1388514780, 1388514840, 1388514900, 1388514960, 1388515020, 1388515080,
> 1388515140, 1388515200, 1388515260, 1388515320, 1388515380, 1388515440,
> 1388515500, 1388515560, 1388515620, 1388515680, 1388515740, 1388515800,
> 1388515860, 1388515920, 1388515980, 1388516040, 1388516100, 1388516160,
> 1388516220, 1388516280, 1388516340, 1388516400, 1388516460, 1388516520,
> 1388516580, 1388516640, 1388516700, 1388516760, 1388516820, 1388516880,
> 1388516940, 1388517000, 1388517060, 1388517120, 1388517180, 1388517240,
> 1388517300, 1388517360, 1388517420, 1388517480, 1388517540, 1388517600,
> 1388517660, 1388517720, 1388517780, 1388517840, 1388517900, 1388517960,
> 1388518020, 1388518080, 1388518140, 1388518200, 1388518260, 1388518320,
> 1388518380, 1388518440, 1388518500, 1388518560, 1388518620, 1388518680,
> 1388518740, 1388518800, 1388518860, 1388518920, 1388518980, 1388519040,
> 1388519100, 1388519160, 1388519220, 1388519280, 1388519340, 1388519400,
> 1388519460, 1388519520, 1388519580, 1388519640, 1388519700, 1388519760,
> 1388519820, 1388519880, 1388519940, 1388520000, 1388520060, 1388520120,
> 1388520180, 1388520240, 1388520300, 1388520360, 1388520420, 1388520480,
> 1388520540, 1388520600, 1388520660, 1388520720, 1388520780, 1388520840,
> 1388520900, 1388520960, 1388521020, 1388521080, 1388521140, 1388521200,
> 1388521260, 1388521320, 1388521380, 1388521440, 1388521500, 1388521560,
> 1388521620, 1388521680, 1388521740, 1388521800, 1388521860, 1388521920,
> 1388521980, 1388522040, 1388522100, 1388522160, 1388522220, 1388522280,
> 1388522340, 1388522400, 1388522460, 1388522520, 1388522580, 1388522640,
> 1388522700, 1388522760, 1388522820, 1388522880, 1388522940, 1388523000,
> 1388523060, 1388523120, 1388523180, 1388523240, 1388523300, 1388523360,
> 1388523420, 1388523480, 1388523540, 1388523600, 1388523660, 1388523720,
> 1388523780, 1388523840, 1388523900, 1388523960, 1388524020, 1388524080,
> 1388524140, 1388524200, 1388524260, 1388524320, 1388524380, 1388524440,
> 1388524500, 1388524560, 1388524620, 1388524680, 1388524740, 1388524800,
> 1388524860, 1388524920, 1388524980, 1388525040, 1388525100, 1388525160,
> 1388525220, 1388525280, 1388525340, 1388525400, 1388525460, 1388525520,
> 1388525580, 1388525640, 1388525700, 1388525760, 1388525820, 1388525880,
> 1388525940, 1388526000, 1388526060, 1388526120, 1388526180, 1388526240,
> 1388526300, 1388526360, 1388526420, 1388526480, 1388526540, 1388526600,
> 1388526660, 1388526720, 1388526780, 1388526840, 1388526900, 1388526960,
> 1388527020, 1388527080, 1388527140, 1388527200, 1388527260, 1388527320,
> 1388527380, 1388527440, 1388527500, 1388527560, 1388527620, 1388527680,
> 1388527740, 1388527800, 1388527860, 1388527920, 1388527980, 1388528040,
> 1388528100, 1388528160, 1388528220, 1388528280, 1388528340, 1388528400,
> 1388528460, 1388528520, 1388528580, 1388528640, 1388528700, 1388528760,
> 1388528820, 1388528880, 1388528940, 1388529000, 1388529060, 1388529120,
> 1388529180, 1388529240, 1388529300, 1388529360, 1388529420, 1388529480,
> 1388529540, 1388529600, 1388529660, 1388529720, 1388529780, 1388529840,
> 1388529900, 1388529960, 1388530020, 1388530080, 1388530140, 1388530200,
> 1388530260, 1388530320, 1388530380, 1388530440, 1388530500, 1388530560,
> 1388530620, 1388530680, 1388530740, 1388530800, 1388530860, 1388530920,
> 1388530980, 1388531040, 1388531100, 1388531160, 1388531220, 1388531280,
> 1388531340, 1388531400, 1388531460, 1388531520, 1388531580, 1388531640,
> 1388531700, 1388531760, 1388531820, 1388531880, 1388531940, 1388532000,
> 1388532060, 1388532120, 1388532180, 1388532240, 1388532300, 1388532360,
> 1388532420, 1388532480, 1388532540, 1388532600, 1388532660, 1388532720,
> 1388532780, 1388532840, 1388532900, 1388532960, 1388533020, 1388533080,
> 1388533140, 1388533200, 1388533260, 1388533320, 1388533380, 1388533440,
> 1388533500, 1388533560, 1388533620, 1388533680, 1388533740, 1388533800,
> 1388533860, 1388533920, 1388533980, 1388534040, 1388534100, 1388534160,
> 1388534220, 1388534280, 1388534340, 1388534400, 1388534460, 1388534520,
> 1388534580, 1388534640, 1388534700, 1388534760, 1388534820, 1388534880,
> 1388534940, 1388535000, 1388535060, 1388535120, 1388535180, 1388535240,
> 1388535300, 1388535360, 1388535420, 1388535480, 1388535540, 1388535600,
> 1388535660, 1388535720, 1388535780, 1388535840, 1388535900, 1388535960,
> 1388536020, 1388536080, 1388536140, 1388536200, 1388536260, 1388536320,
> 1388536380, 1388536440, 1388536500, 1388536560, 1388536620, 1388536680,
> 1388536740, 1388536800, 1388536860, 1388536920, 1388536980, 1388537040,
> 1388537100, 1388537160, 1388537220, 1388537280, 1388537340, 1388537400,
> 1388537460, 1388537520, 1388537580, 1388537640, 1388537700, 1388537760,
> 1388537820, 1388537880, 1388537940, 1388538000, 1388538060, 1388538120,
> 1388538180, 1388538240, 1388538300, 1388538360, 1388538420, 1388538480,
> 1388538540, 1388538600, 1388538660, 1388538720, 1388538780, 1388538840,
> 1388538900, 1388538960, 1388539020, 1388539080, 1388539140, 1388539200,
> 1388539260, 1388539320, 1388539380, 1388539440, 1388539500, 1388539560,
> 1388539620, 1388539680, 1388539740, 1388539800, 1388539860, 1388539920,
> 1388539980, 1388540040, 1388540100, 1388540160, 1388540220, 1388540280,
> 1388540340, 1388540400, 1388540460, 1388540520, 1388540580, 1388540640,
> 1388540700, 1388540760, 1388540820, 1388540880, 1388540940, 1388541000,
> 1388541060, 1388541120, 1388541180, 1388541240, 1388541300, 1388541360,
> 1388541420, 1388541480, 1388541540, 1388541600, 1388541660, 1388541720,
> 1388541780, 1388541840, 1388541900, 1388541960, 1388542020, 1388542080,
> 1388542140, 1388542200, 1388542260, 1388542320, 1388542380, 1388542440,
> 1388542500, 1388542560, 1388542620, 1388542680, 1388542740, 1388542800,
> 1388542860, 1388542920, 1388542980, 1388543040, 1388543100, 1388543160,
> 1388543220, 1388543280, 1388543340, 1388543400, 1388543460, 1388543520,
> 1388543580, 1388543640, 1388543700, 1388543760, 1388543820, 1388543880,
> 1388543940, 1388544000, 1388544060, 1388544120, 1388544180, 1388544240,
> 1388544300, 1388544360, 1388544420, 1388544480, 1388544540, 1388544600,
> 1388544660, 1388544720, 1388544780, 1388544840, 1388544900, 1388544960,
> 1388545020, 1388545080, 1388545140, 1388545200, 1388545260, 1388545320,
> 1388545380, 1388545440, 1388545500, 1388545560, 1388545620, 1388545680,
> 1388545740, 1388545800, 1388545860, 1388545920, 1388545980, 1388546040,
> 1388546100, 1388546160, 1388546220, 1388546280, 1388546340, 1388546400,
> 1388546460, 1388546520, 1388546580, 1388546640, 1388546700, 1388546760,
> 1388546820, 1388546880, 1388546940, 1388547000, 1388547060, 1388547120,
> 1388547180, 1388547240, 1388547300, 1388547360, 1388547420, 1388547480,
> 1388547540, 1388547600, 1388547660, 1388547720, 1388547780, 1388547840,
> 1388547900, 1388547960, 1388548020, 1388548080, 1388548140, 1388548200,
> 1388548260, 1388548320, 1388548380, 1388548440, 1388548500, 1388548560,
> 1388548620, 1388548680, 1388548740, 1388548800, 1388548860, 1388548920,
> 1388548980, 1388549040, 1388549100, 1388549160, 1388549220, 1388549280,
> 1388549340, 1388549400, 1388549460, 1388549520, 1388549580, 1388549640,
> 1388549700, 1388549760, 1388549820, 1388549880, 1388549940, 1388550000,
> 1388550060, 1388550120, 1388550180, 1388550240, 1388550300, 1388550360,
> 1388550420, 1388550480, 1388550540, 1388550600, 1388550660, 1388550720,
> 1388550780, 1388550840, 1388550900, 1388550960, 1388551020, 1388551080,
> 1388551140, 1388551200, 1388551260, 1388551320, 1388551380, 1388551440,
> 1388551500, 1388551560, 1388551620, 1388551680, 1388551740, 1388551800,
> 1388551860, 1388551920, 1388551980, 1388552040, 1388552100, 1388552160,
> 1388552220, 1388552280, 1388552340, 1388552400, 1388552460, 1388552520,
> 1388552580, 1388552640, 1388552700, 1388552760, 1388552820, 1388552880,
> 1388552940, 1388553000, 1388553060, 1388553120, 1388553180, 1388553240,
> 1388553300, 1388553360, 1388553420, 1388553480, 1388553540, 1388553600,
> 1388553660, 1388553720, 1388553780, 1388553840, 1388553900, 1388553960,
> 1388554020, 1388554080, 1388554140, 1388554200, 1388554260, 1388554320,
> 1388554380, 1388554440, 1388554500, 1388554560, 1388554620, 1388554680,
> 1388554740, 1388554800, 1388554860, 1388554920, 1388554980, 1388555040,
> 1388555100, 1388555160, 1388555220, 1388555280, 1388555340, 1388555400,
> 1388555460, 1388555520, 1388555580, 1388555640, 1388555700, 1388555760,
> 1388555820, 1388555880, 1388555940, 1388556000, 1388556060, 1388556120,
> 1388556180, 1388556240, 1388556300, 1388556360, 1388556420, 1388556480,
> 1388556540, 1388556600, 1388556660, 1388556720, 1388556780, 1388556840,
> 1388556900, 1388556960, 1388557020, 1388557080, 1388557140, 1388557200,
> 1388557260, 1388557320, 1388557380, 1388557440, 1388557500, 1388557560,
> 1388557620, 1388557680, 1388557740, 1388557800, 1388557860, 1388557920,
> 1388557980, 1388558040, 1388558100, 1388558160, 1388558220, 1388558280,
> 1388558340, 1388558400, 1388558460, 1388558520, 1388558580, 1388558640,
> 1388558700, 1388558760, 1388558820, 1388558880, 1388558940, 1388559000,
> 1388559060, 1388559120, 1388559180, 1388559240, 1388559300, 1388559360,
> 1388559420, 1388559480, 1388559540, 1388559600, 1388559660, 1388559720,
> 1388559780, 1388559840, 1388559900, 1388559960, 1388560020, 1388560080,
> 1388560140, 1388560200, 1388560260, 1388560320, 1388560380, 1388560440,
> 1388560500, 1388560560, 1388560620, 1388560680, 1388560740, 1388560800,
> 1388560860, 1388560920, 1388560980, 1388561040, 1388561100, 1388561160,
> 1388561220, 1388561280, 1388561340, 1388561400, 1388561460, 1388561520,
> 1388561580, 1388561640, 1388561700, 1388561760, 1388561820, 1388561880,
> 1388561940, 1388562000, 1388562060, 1388562120, 1388562180, 1388562240,
> 1388562300, 1388562360, 1388562420, 1388562480, 1388562540, 1388562600,
> 1388562660, 1388562720, 1388562780, 1388562840, 1388562900, 1388562960,
> 1388563020, 1388563080, 1388563140, 1388563200, 1388563260, 1388563320,
> 1388563380, 1388563440, 1388563500, 1388563560, 1388563620, 1388563680,
> 1388563740, 1388563800, 1388563860, 1388563920, 1388563980, 1388564040,
> 1388564100, 1388564160, 1388564220, 1388564280, 1388564340, 1388564400,
> 1388564460, 1388564520, 1388564580, 1388564640, 1388564700, 1388564760,
> 1388564820, 1388564880, 1388564940, 1388565000, 1388565060, 1388565120,
> 1388565180, 1388565240, 1388565300, 1388565360, 1388565420, 1388565480,
> 1388565540), tzone = "", tclass = c("POSIXct", "POSIXt")), dim = c(1000L,
> 1L))
> 
> 
> On Wed, Oct 2, 2024 at 11:03?PM Hasan Diwan <hasan.diwan at gmail.com> wrote:
> 
>> On Wed, 2 Oct 2024 at 07:53, roslinazairimah zakaria <roslinaump at gmail.com
>>>
>> wrote:
>>
>>> Next question, how do I delete the date from 16 December until 31
>> December
>>> 2014?
>>>
>>
>> Something like:
>> myData <- xtsObj[myData$date <  "2014-12-16" & myData$date > "2024-12-31"]
>> -- H
>>
>> --
>> OpenPGP: https://hasan.d8u.us/openpgp.asc
>> If you wish to request my time, please do so using
>> *bit.ly/hd1AppointmentRequest
>> <http://bit.ly/hd1AppointmentRequest>*.
>> Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
>> <http://bit.ly/hd1AppointmentRequest>*.
>>
>> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
>>> Sent
>> from my mobile device
>> Envoye de mon portable
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
Hello,

Use function index.


library(xts)

# extract from 2014-01-01 00:00:00
#           to 2014-01-01 16:30:00
from <- as.POSIXct("2014-01-01 00:00:00")
to <- as.POSIXct("2014-01-01 16:30:00")
i <- index(dt_ts) >= from & index(dt_ts) <= to
dt_ts[i]


Also, instead of copying&pasting the data, you can attach a file with 
extension .txt.

Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 17:49:06 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 23:49:06 +0800
Subject: [R] Change data frame to time series data
In-Reply-To: <CAP+bYWBJBJ1gTxxfyt6FVUH+1q2Rs54N-vgRthH9jjJH4p4mXQ@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
 <CAP+bYWBJBJ1gTxxfyt6FVUH+1q2Rs54N-vgRthH9jjJH4p4mXQ@mail.gmail.com>
Message-ID: <CANTvJZ+1X3GGgcV_v2c8KHe7n1mQgVH-OsCz3DWohWThKU01Zw@mail.gmail.com>

Hi Hasan,
Thank you so much for your help. But I got this error.

> dt_ts['2014-01-01 00:00:00'::'2014-12-15 23:59:00']Error in loadNamespace(x) :
  there is no package called ?2014-01-01 00:00:00?


On Wed, Oct 2, 2024 at 11:36?PM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> On Wed, 2 Oct 2024 at 08:20, roslinazairimah zakaria <roslinaump at gmail.com
> >
> wrote:
>
> > Let say, this is my data and I want to extract from 2014-01-01 00:00:00
> > to 2014-01-01 16:30:00
> >
> >
> dt_ts['2014-01-01 00:00:00'::'2014-01-01 16:30:00']
>
> Try that?
>
>
>
> --
> OpenPGP: https://hasan.d8u.us/openpgp.asc
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> from my mobile device
> Envoye de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 17:46:54 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Wed, 2 Oct 2024 23:46:54 +0800
Subject: [R] Change data frame to time series data
In-Reply-To: <0df53d3b-1003-4922-9959-1c27621735f1@sapo.pt>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
 <0df53d3b-1003-4922-9959-1c27621735f1@sapo.pt>
Message-ID: <CANTvJZK4raGk=Obbu2eNaOryqiQWP-fgAPB9CFs9mMq=xZrs-w@mail.gmail.com>

Thank you so much Rui, it is very helpful, simple yet works beautifully.

from <- as.POSIXct("2014-01-01 00:00:00")
to   <- as.POSIXct("2014-12-15 23:59:00")
i    <- index(dt_ts) >= from & index(dt_ts) <= to
dt_ts[i]

On Wed, Oct 2, 2024 at 11:39?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 16:20 de 02/10/2024, roslinazairimah zakaria escreveu:
> > Let say, this is my data and I want to extract from 2014-01-01
> > 00:00:00 to 2014-01-01
> > 16:30:00
> >
> >> dput(head(dt_ts,1000))
> >
> > structure(c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), class = c("xts",
> > "zoo"), index = structure(c(1388505600, 1388505660, 1388505720,
> > 1388505780, 1388505840, 1388505900, 1388505960, 1388506020, 1388506080,
> > 1388506140, 1388506200, 1388506260, 1388506320, 1388506380, 1388506440,
> > 1388506500, 1388506560, 1388506620, 1388506680, 1388506740, 1388506800,
> > 1388506860, 1388506920, 1388506980, 1388507040, 1388507100, 1388507160,
> > 1388507220, 1388507280, 1388507340, 1388507400, 1388507460, 1388507520,
> > 1388507580, 1388507640, 1388507700, 1388507760, 1388507820, 1388507880,
> > 1388507940, 1388508000, 1388508060, 1388508120, 1388508180, 1388508240,
> > 1388508300, 1388508360, 1388508420, 1388508480, 1388508540, 1388508600,
> > 1388508660, 1388508720, 1388508780, 1388508840, 1388508900, 1388508960,
> > 1388509020, 1388509080, 1388509140, 1388509200, 1388509260, 1388509320,
> > 1388509380, 1388509440, 1388509500, 1388509560, 1388509620, 1388509680,
> > 1388509740, 1388509800, 1388509860, 1388509920, 1388509980, 1388510040,
> > 1388510100, 1388510160, 1388510220, 1388510280, 1388510340, 1388510400,
> > 1388510460, 1388510520, 1388510580, 1388510640, 1388510700, 1388510760,
> > 1388510820, 1388510880, 1388510940, 1388511000, 1388511060, 1388511120,
> > 1388511180, 1388511240, 1388511300, 1388511360, 1388511420, 1388511480,
> > 1388511540, 1388511600, 1388511660, 1388511720, 1388511780, 1388511840,
> > 1388511900, 1388511960, 1388512020, 1388512080, 1388512140, 1388512200,
> > 1388512260, 1388512320, 1388512380, 1388512440, 1388512500, 1388512560,
> > 1388512620, 1388512680, 1388512740, 1388512800, 1388512860, 1388512920,
> > 1388512980, 1388513040, 1388513100, 1388513160, 1388513220, 1388513280,
> > 1388513340, 1388513400, 1388513460, 1388513520, 1388513580, 1388513640,
> > 1388513700, 1388513760, 1388513820, 1388513880, 1388513940, 1388514000,
> > 1388514060, 1388514120, 1388514180, 1388514240, 1388514300, 1388514360,
> > 1388514420, 1388514480, 1388514540, 1388514600, 1388514660, 1388514720,
> > 1388514780, 1388514840, 1388514900, 1388514960, 1388515020, 1388515080,
> > 1388515140, 1388515200, 1388515260, 1388515320, 1388515380, 1388515440,
> > 1388515500, 1388515560, 1388515620, 1388515680, 1388515740, 1388515800,
> > 1388515860, 1388515920, 1388515980, 1388516040, 1388516100, 1388516160,
> > 1388516220, 1388516280, 1388516340, 1388516400, 1388516460, 1388516520,
> > 1388516580, 1388516640, 1388516700, 1388516760, 1388516820, 1388516880,
> > 1388516940, 1388517000, 1388517060, 1388517120, 1388517180, 1388517240,
> > 1388517300, 1388517360, 1388517420, 1388517480, 1388517540, 1388517600,
> > 1388517660, 1388517720, 1388517780, 1388517840, 1388517900, 1388517960,
> > 1388518020, 1388518080, 1388518140, 1388518200, 1388518260, 1388518320,
> > 1388518380, 1388518440, 1388518500, 1388518560, 1388518620, 1388518680,
> > 1388518740, 1388518800, 1388518860, 1388518920, 1388518980, 1388519040,
> > 1388519100, 1388519160, 1388519220, 1388519280, 1388519340, 1388519400,
> > 1388519460, 1388519520, 1388519580, 1388519640, 1388519700, 1388519760,
> > 1388519820, 1388519880, 1388519940, 1388520000, 1388520060, 1388520120,
> > 1388520180, 1388520240, 1388520300, 1388520360, 1388520420, 1388520480,
> > 1388520540, 1388520600, 1388520660, 1388520720, 1388520780, 1388520840,
> > 1388520900, 1388520960, 1388521020, 1388521080, 1388521140, 1388521200,
> > 1388521260, 1388521320, 1388521380, 1388521440, 1388521500, 1388521560,
> > 1388521620, 1388521680, 1388521740, 1388521800, 1388521860, 1388521920,
> > 1388521980, 1388522040, 1388522100, 1388522160, 1388522220, 1388522280,
> > 1388522340, 1388522400, 1388522460, 1388522520, 1388522580, 1388522640,
> > 1388522700, 1388522760, 1388522820, 1388522880, 1388522940, 1388523000,
> > 1388523060, 1388523120, 1388523180, 1388523240, 1388523300, 1388523360,
> > 1388523420, 1388523480, 1388523540, 1388523600, 1388523660, 1388523720,
> > 1388523780, 1388523840, 1388523900, 1388523960, 1388524020, 1388524080,
> > 1388524140, 1388524200, 1388524260, 1388524320, 1388524380, 1388524440,
> > 1388524500, 1388524560, 1388524620, 1388524680, 1388524740, 1388524800,
> > 1388524860, 1388524920, 1388524980, 1388525040, 1388525100, 1388525160,
> > 1388525220, 1388525280, 1388525340, 1388525400, 1388525460, 1388525520,
> > 1388525580, 1388525640, 1388525700, 1388525760, 1388525820, 1388525880,
> > 1388525940, 1388526000, 1388526060, 1388526120, 1388526180, 1388526240,
> > 1388526300, 1388526360, 1388526420, 1388526480, 1388526540, 1388526600,
> > 1388526660, 1388526720, 1388526780, 1388526840, 1388526900, 1388526960,
> > 1388527020, 1388527080, 1388527140, 1388527200, 1388527260, 1388527320,
> > 1388527380, 1388527440, 1388527500, 1388527560, 1388527620, 1388527680,
> > 1388527740, 1388527800, 1388527860, 1388527920, 1388527980, 1388528040,
> > 1388528100, 1388528160, 1388528220, 1388528280, 1388528340, 1388528400,
> > 1388528460, 1388528520, 1388528580, 1388528640, 1388528700, 1388528760,
> > 1388528820, 1388528880, 1388528940, 1388529000, 1388529060, 1388529120,
> > 1388529180, 1388529240, 1388529300, 1388529360, 1388529420, 1388529480,
> > 1388529540, 1388529600, 1388529660, 1388529720, 1388529780, 1388529840,
> > 1388529900, 1388529960, 1388530020, 1388530080, 1388530140, 1388530200,
> > 1388530260, 1388530320, 1388530380, 1388530440, 1388530500, 1388530560,
> > 1388530620, 1388530680, 1388530740, 1388530800, 1388530860, 1388530920,
> > 1388530980, 1388531040, 1388531100, 1388531160, 1388531220, 1388531280,
> > 1388531340, 1388531400, 1388531460, 1388531520, 1388531580, 1388531640,
> > 1388531700, 1388531760, 1388531820, 1388531880, 1388531940, 1388532000,
> > 1388532060, 1388532120, 1388532180, 1388532240, 1388532300, 1388532360,
> > 1388532420, 1388532480, 1388532540, 1388532600, 1388532660, 1388532720,
> > 1388532780, 1388532840, 1388532900, 1388532960, 1388533020, 1388533080,
> > 1388533140, 1388533200, 1388533260, 1388533320, 1388533380, 1388533440,
> > 1388533500, 1388533560, 1388533620, 1388533680, 1388533740, 1388533800,
> > 1388533860, 1388533920, 1388533980, 1388534040, 1388534100, 1388534160,
> > 1388534220, 1388534280, 1388534340, 1388534400, 1388534460, 1388534520,
> > 1388534580, 1388534640, 1388534700, 1388534760, 1388534820, 1388534880,
> > 1388534940, 1388535000, 1388535060, 1388535120, 1388535180, 1388535240,
> > 1388535300, 1388535360, 1388535420, 1388535480, 1388535540, 1388535600,
> > 1388535660, 1388535720, 1388535780, 1388535840, 1388535900, 1388535960,
> > 1388536020, 1388536080, 1388536140, 1388536200, 1388536260, 1388536320,
> > 1388536380, 1388536440, 1388536500, 1388536560, 1388536620, 1388536680,
> > 1388536740, 1388536800, 1388536860, 1388536920, 1388536980, 1388537040,
> > 1388537100, 1388537160, 1388537220, 1388537280, 1388537340, 1388537400,
> > 1388537460, 1388537520, 1388537580, 1388537640, 1388537700, 1388537760,
> > 1388537820, 1388537880, 1388537940, 1388538000, 1388538060, 1388538120,
> > 1388538180, 1388538240, 1388538300, 1388538360, 1388538420, 1388538480,
> > 1388538540, 1388538600, 1388538660, 1388538720, 1388538780, 1388538840,
> > 1388538900, 1388538960, 1388539020, 1388539080, 1388539140, 1388539200,
> > 1388539260, 1388539320, 1388539380, 1388539440, 1388539500, 1388539560,
> > 1388539620, 1388539680, 1388539740, 1388539800, 1388539860, 1388539920,
> > 1388539980, 1388540040, 1388540100, 1388540160, 1388540220, 1388540280,
> > 1388540340, 1388540400, 1388540460, 1388540520, 1388540580, 1388540640,
> > 1388540700, 1388540760, 1388540820, 1388540880, 1388540940, 1388541000,
> > 1388541060, 1388541120, 1388541180, 1388541240, 1388541300, 1388541360,
> > 1388541420, 1388541480, 1388541540, 1388541600, 1388541660, 1388541720,
> > 1388541780, 1388541840, 1388541900, 1388541960, 1388542020, 1388542080,
> > 1388542140, 1388542200, 1388542260, 1388542320, 1388542380, 1388542440,
> > 1388542500, 1388542560, 1388542620, 1388542680, 1388542740, 1388542800,
> > 1388542860, 1388542920, 1388542980, 1388543040, 1388543100, 1388543160,
> > 1388543220, 1388543280, 1388543340, 1388543400, 1388543460, 1388543520,
> > 1388543580, 1388543640, 1388543700, 1388543760, 1388543820, 1388543880,
> > 1388543940, 1388544000, 1388544060, 1388544120, 1388544180, 1388544240,
> > 1388544300, 1388544360, 1388544420, 1388544480, 1388544540, 1388544600,
> > 1388544660, 1388544720, 1388544780, 1388544840, 1388544900, 1388544960,
> > 1388545020, 1388545080, 1388545140, 1388545200, 1388545260, 1388545320,
> > 1388545380, 1388545440, 1388545500, 1388545560, 1388545620, 1388545680,
> > 1388545740, 1388545800, 1388545860, 1388545920, 1388545980, 1388546040,
> > 1388546100, 1388546160, 1388546220, 1388546280, 1388546340, 1388546400,
> > 1388546460, 1388546520, 1388546580, 1388546640, 1388546700, 1388546760,
> > 1388546820, 1388546880, 1388546940, 1388547000, 1388547060, 1388547120,
> > 1388547180, 1388547240, 1388547300, 1388547360, 1388547420, 1388547480,
> > 1388547540, 1388547600, 1388547660, 1388547720, 1388547780, 1388547840,
> > 1388547900, 1388547960, 1388548020, 1388548080, 1388548140, 1388548200,
> > 1388548260, 1388548320, 1388548380, 1388548440, 1388548500, 1388548560,
> > 1388548620, 1388548680, 1388548740, 1388548800, 1388548860, 1388548920,
> > 1388548980, 1388549040, 1388549100, 1388549160, 1388549220, 1388549280,
> > 1388549340, 1388549400, 1388549460, 1388549520, 1388549580, 1388549640,
> > 1388549700, 1388549760, 1388549820, 1388549880, 1388549940, 1388550000,
> > 1388550060, 1388550120, 1388550180, 1388550240, 1388550300, 1388550360,
> > 1388550420, 1388550480, 1388550540, 1388550600, 1388550660, 1388550720,
> > 1388550780, 1388550840, 1388550900, 1388550960, 1388551020, 1388551080,
> > 1388551140, 1388551200, 1388551260, 1388551320, 1388551380, 1388551440,
> > 1388551500, 1388551560, 1388551620, 1388551680, 1388551740, 1388551800,
> > 1388551860, 1388551920, 1388551980, 1388552040, 1388552100, 1388552160,
> > 1388552220, 1388552280, 1388552340, 1388552400, 1388552460, 1388552520,
> > 1388552580, 1388552640, 1388552700, 1388552760, 1388552820, 1388552880,
> > 1388552940, 1388553000, 1388553060, 1388553120, 1388553180, 1388553240,
> > 1388553300, 1388553360, 1388553420, 1388553480, 1388553540, 1388553600,
> > 1388553660, 1388553720, 1388553780, 1388553840, 1388553900, 1388553960,
> > 1388554020, 1388554080, 1388554140, 1388554200, 1388554260, 1388554320,
> > 1388554380, 1388554440, 1388554500, 1388554560, 1388554620, 1388554680,
> > 1388554740, 1388554800, 1388554860, 1388554920, 1388554980, 1388555040,
> > 1388555100, 1388555160, 1388555220, 1388555280, 1388555340, 1388555400,
> > 1388555460, 1388555520, 1388555580, 1388555640, 1388555700, 1388555760,
> > 1388555820, 1388555880, 1388555940, 1388556000, 1388556060, 1388556120,
> > 1388556180, 1388556240, 1388556300, 1388556360, 1388556420, 1388556480,
> > 1388556540, 1388556600, 1388556660, 1388556720, 1388556780, 1388556840,
> > 1388556900, 1388556960, 1388557020, 1388557080, 1388557140, 1388557200,
> > 1388557260, 1388557320, 1388557380, 1388557440, 1388557500, 1388557560,
> > 1388557620, 1388557680, 1388557740, 1388557800, 1388557860, 1388557920,
> > 1388557980, 1388558040, 1388558100, 1388558160, 1388558220, 1388558280,
> > 1388558340, 1388558400, 1388558460, 1388558520, 1388558580, 1388558640,
> > 1388558700, 1388558760, 1388558820, 1388558880, 1388558940, 1388559000,
> > 1388559060, 1388559120, 1388559180, 1388559240, 1388559300, 1388559360,
> > 1388559420, 1388559480, 1388559540, 1388559600, 1388559660, 1388559720,
> > 1388559780, 1388559840, 1388559900, 1388559960, 1388560020, 1388560080,
> > 1388560140, 1388560200, 1388560260, 1388560320, 1388560380, 1388560440,
> > 1388560500, 1388560560, 1388560620, 1388560680, 1388560740, 1388560800,
> > 1388560860, 1388560920, 1388560980, 1388561040, 1388561100, 1388561160,
> > 1388561220, 1388561280, 1388561340, 1388561400, 1388561460, 1388561520,
> > 1388561580, 1388561640, 1388561700, 1388561760, 1388561820, 1388561880,
> > 1388561940, 1388562000, 1388562060, 1388562120, 1388562180, 1388562240,
> > 1388562300, 1388562360, 1388562420, 1388562480, 1388562540, 1388562600,
> > 1388562660, 1388562720, 1388562780, 1388562840, 1388562900, 1388562960,
> > 1388563020, 1388563080, 1388563140, 1388563200, 1388563260, 1388563320,
> > 1388563380, 1388563440, 1388563500, 1388563560, 1388563620, 1388563680,
> > 1388563740, 1388563800, 1388563860, 1388563920, 1388563980, 1388564040,
> > 1388564100, 1388564160, 1388564220, 1388564280, 1388564340, 1388564400,
> > 1388564460, 1388564520, 1388564580, 1388564640, 1388564700, 1388564760,
> > 1388564820, 1388564880, 1388564940, 1388565000, 1388565060, 1388565120,
> > 1388565180, 1388565240, 1388565300, 1388565360, 1388565420, 1388565480,
> > 1388565540), tzone = "", tclass = c("POSIXct", "POSIXt")), dim = c(1000L,
> > 1L))
> >
> >
> > On Wed, Oct 2, 2024 at 11:03?PM Hasan Diwan <hasan.diwan at gmail.com>
> wrote:
> >
> >> On Wed, 2 Oct 2024 at 07:53, roslinazairimah zakaria <
> roslinaump at gmail.com
> >>>
> >> wrote:
> >>
> >>> Next question, how do I delete the date from 16 December until 31
> >> December
> >>> 2014?
> >>>
> >>
> >> Something like:
> >> myData <- xtsObj[myData$date <  "2014-12-16" & myData$date >
> "2024-12-31"]
> >> -- H
> >>
> >> --
> >> OpenPGP: https://hasan.d8u.us/openpgp.asc
> >> If you wish to request my time, please do so using
> >> *bit.ly/hd1AppointmentRequest
> >> <http://bit.ly/hd1AppointmentRequest>*.
> >> Si vous voudriez faire connnaisance, allez a *
> bit.ly/hd1AppointmentRequest
> >> <http://bit.ly/hd1AppointmentRequest>*.
> >>
> >> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >>> Sent
> >> from my mobile device
> >> Envoye de mon portable
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> Hello,
>
> Use function index.
>
>
> library(xts)
>
> # extract from 2014-01-01 00:00:00
> #           to 2014-01-01 16:30:00
> from <- as.POSIXct("2014-01-01 00:00:00")
> to <- as.POSIXct("2014-01-01 16:30:00")
> i <- index(dt_ts) >= from & index(dt_ts) <= to
> dt_ts[i]
>
>
> Also, instead of copying&pasting the data, you can attach a file with
> extension .txt.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Wed Oct  2 17:54:54 2024
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Wed, 2 Oct 2024 08:54:54 -0700
Subject: [R] Change data frame to time series data
In-Reply-To: <CANTvJZ+1X3GGgcV_v2c8KHe7n1mQgVH-OsCz3DWohWThKU01Zw@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
 <CAP+bYWBJBJ1gTxxfyt6FVUH+1q2Rs54N-vgRthH9jjJH4p4mXQ@mail.gmail.com>
 <CANTvJZ+1X3GGgcV_v2c8KHe7n1mQgVH-OsCz3DWohWThKU01Zw@mail.gmail.com>
Message-ID: <CAP+bYWAewrih+hsKRzKJe+=yOJAdD+o8g2ysWFGCspECnQrdJA@mail.gmail.com>

> dt_ts['2014-01-01 00:00:00/2014-12-15 23:59:00']

Does that work? -- H

-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Wed Oct  2 18:02:03 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Thu, 3 Oct 2024 00:02:03 +0800
Subject: [R] Change data frame to time series data
In-Reply-To: <CAP+bYWAewrih+hsKRzKJe+=yOJAdD+o8g2ysWFGCspECnQrdJA@mail.gmail.com>
References: <CANTvJZJOOq4YZh0RzGXdK_o2Q=xoh0Y6wTGZ-_j7yO=B2uNvWg@mail.gmail.com>
 <874j5vm1i1.fsf@enricoschumann.net>
 <CANTvJZJJjvi6w1DsAKZpMzVcGoC4440j9cmMSFXcoG6c3dbekg@mail.gmail.com>
 <CAP+bYWB1nqedxzYxTpjm=-pg+RMtOaNWn-uxM0jJmpaPabhZng@mail.gmail.com>
 <CANTvJZKMbgm=pYG2pYF-unBm4MS23Y+EQK0r1sxJLCa_xa76cA@mail.gmail.com>
 <CAP+bYWBJBJ1gTxxfyt6FVUH+1q2Rs54N-vgRthH9jjJH4p4mXQ@mail.gmail.com>
 <CANTvJZ+1X3GGgcV_v2c8KHe7n1mQgVH-OsCz3DWohWThKU01Zw@mail.gmail.com>
 <CAP+bYWAewrih+hsKRzKJe+=yOJAdD+o8g2ysWFGCspECnQrdJA@mail.gmail.com>
Message-ID: <CANTvJZKnZYr8zBv_MbHDoC=_JjhnYX7AWW0-gN_z+bEAxo5OTg@mail.gmail.com>

Hi Hasan,

Yes, it works beautifully also. Thank you very much ..the simplest ya.

On Wed, Oct 2, 2024 at 11:56?PM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> > dt_ts['2014-01-01 00:00:00/2014-12-15 23:59:00']
>
> Does that work? -- H
>
> --
> OpenPGP: https://hasan.d8u.us/openpgp.asc
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> from my mobile device
> Envoye de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ro@||n@ump @end|ng |rom gm@||@com  Thu Oct  3 15:24:53 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Thu, 3 Oct 2024 21:24:53 +0800
Subject: [R] Time series data decomposition from by minute data
Message-ID: <CANTvJZKOYEO-9MgyyZjgZFEYfFWAtXJ4tXh_ntX_jFCixS=K9g@mail.gmail.com>

Dear all,

My data is by minutes and I can see it has seasonal trend by daily and
weekly. How do I decompose the minute data into daily and weekly

some data:

> dput(tail(dt_train,100))structure(c(11L, 11L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 11L, 11L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 9L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L), class = c("xts", "zoo"), index = structure(c(1412622480,
1412622540, 1412622600, 1412622660, 1412622720, 1412622780, 1412622840,
1412622900, 1412622960, 1412623020, 1412623080, 1412623140, 1412623200,
1412623260, 1412623320, 1412623380, 1412623440, 1412623500, 1412623560,
1412623620, 1412623680, 1412623740, 1412623800, 1412623860, 1412623920,
1412623980, 1412624040, 1412624100, 1412624160, 1412624220, 1412624280,
1412624340, 1412624400, 1412624460, 1412624520, 1412624580, 1412624640,
1412624700, 1412624760, 1412624820, 1412624880, 1412624940, 1412625000,
1412625060, 1412625120, 1412625180, 1412625240, 1412625300, 1412625360,
1412625420, 1412625480, 1412625540, 1412625600, 1412625660, 1412625720,
1412625780, 1412625840, 1412625900, 1412625960, 1412626020, 1412626080,
1412626140, 1412626200, 1412626260, 1412626320, 1412626380, 1412626440,
1412626500, 1412626560, 1412626620, 1412626680, 1412626740, 1412626800,
1412626860, 1412626920, 1412626980, 1412627040, 1412627100, 1412627160,
1412627220, 1412627280, 1412627340, 1412627400, 1412627460, 1412627520,
1412627580, 1412627640, 1412627700, 1412627760, 1412627820, 1412627880,
1412627940, 1412628000, 1412628060, 1412628120, 1412628180, 1412628240,
1412628300, 1412628360, 1412628420), tzone = "", tclass = c("POSIXct",
"POSIXt")), dim = c(100L, 1L))


I also attached the plot of training data.


I tried :

decompose(dt_train, type = "multiplicative", filter = NULL)Error in
decompose(dt_train, type = "multiplicative", filter = NULL) :
  time series has no or less than 2 periods


> stl(dt_train, s.window = "periodic")Error in stl(dt_train, s.window = "periodic") :
  series is not periodic or has less than two


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot_dt_train.pdf
Type: application/pdf
Size: 217119 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20241003/02f10b2a/attachment.pdf>

From ro@||n@ump @end|ng |rom gm@||@com  Fri Oct  4 06:02:33 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Fri, 4 Oct 2024 12:02:33 +0800
Subject: [R] Warning message: Removed 888 rows containing missing values or
 values outside the scale range (`geom_line()`)
Message-ID: <CANTvJZKvvOEtZgVMBR8RHbnaQ8tU17v3cod-5SQ9gpKv1CSJ7Q@mail.gmail.com>

Dear all,
I tried to rerun the examples given by Hyndman in otexts but keep on
getting errors and I have searched through google but no solution yet.

Thank you in advance for any help given.

library(fpp3)
library(lubridate)
library(xts)
library(fabletools)
library(ggplot2)
library(dplyr)
library(gridExtra)

> dput(head(new_us_retail_employment,100))structure(list(Month = structure(c(-11323, -11292, -11264, -11233,
-11203, -11172, -11142, -11111, -11080, -11050, -11019, -10989,
-10958, -10927, -10898, -10867, -10837, -10806, -10776, -10745,
-10714, -10684, -10653, -10623, -10592, -10561, -10533, -10502,
-10472, -10441, -10411, -10380, -10349, -10319, -10288, -10258,
-10227, -10196, -10168, -10137, -10107, -10076, -10046, -10015,
-9984, -9954, -9923, -9893, -9862, -9831, -9803, -9772, -9742,
-9711, -9681, -9650, -9619, -9589, -9558, -9528, -9497, -9466,
-9437, -9406, -9376, -9345, -9315, -9284, -9253, -9223, -9192,
-9162, -9131, -9100, -9072, -9041, -9011, -8980, -8950, -8919,
-8888, -8858, -8827, -8797, -8766, -8735, -8707, -8676, -8646,
-8615, -8585, -8554, -8523, -8493, -8462, -8432, -8401, -8370,
-8342, -8311), class = c("yearmonth", "vctrs_vctr")), Series_ID =
c("CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
"CEU0500000001", "CEU0500000001", "CEU0500000001"), Title = c("Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private", "Total Private",
"Total Private", "Total Private", "Total Private"), Employed = c(25338,
25447, 25833, 25801, 26113, 26485, 26481, 26848, 27468, 27830,
27740, 27886, 26847, 26902, 27205, 27255, 27535, 27765, 27789,
28332, 29007, 29399, 29619, 30221, 29402, 29671, 30079, 30610,
31379, 31999, 32545, 33014, 33417, 33457, 33367, 33552, 32660,
32739, 33240, 33764, 34203, 34624, 35065, 35460, 35771, 35852,
35867, 36209, 35494, 35627, 35955, 36212, 36202, 36608, 36637,
36628, 36584, 36658, 36810, 36815, 36018, 35973, 35948, 35833,
35768, 35949, 35861, 35828, 35652, 35555, 35597, 35850, 35229,
35290, 35411, 35161, 35024, 35065, 34769, 34490, 32760, 32833,
33354, 33755, 33656, 33092, 34240, 34997, 35409, 36074, 36474,
37139, 37532, 37637, 38045, 38351, 37510, 37495, 37720, 37686
)), class = c("tbl_ts", "tbl_df", "tbl", "data.frame"), row.names = c(NA,
-100L), key = structure(list(Series_ID = "CEU0500000001", .rows =
structure(list(
    1:100), ptype = integer(0), class = c("vctrs_list_of", "vctrs_vctr",
"list"))), class = c("tbl_df", "tbl", "data.frame"), row.names = c(NA,
-1L), .drop = TRUE), index = structure("Month", ordered = TRUE),
index2 = "Month", interval = structure(list(
    year = 0, quarter = 0, month = 1, week = 0, day = 0, hour = 0,
    minute = 0, second = 0, millisecond = 0, microsecond = 0,
    nanosecond = 0, unit = 0), .regular = TRUE, class = c("interval",
"vctrs_rcrd", "vctrs_vctr")))



# Decomposition
new_us_retail_employment <- na.omit(us_retail_employment) # data cleaning

new_us_retail_employment |>
  model(
    classical_decomposition(Employed, type = "additive")
  ) |>
  components() |>
  autoplot() +xlab("Year") +
  ggtitle("Classical additive decomposition of total
                  US retail employment")

> new_us_retail_employment |>+   model(+     classical_decomposition(Employed, type = "additive")+   ) |>+   components() |>+   autoplot() +xlab("Year") ++   ggtitle("Classical additive decomposition of total+                   US retail employment")Warning message:Removed 888 rows containing missing values or values outside the scale range (`geom_line()`)



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Fri Oct  4 06:09:46 2024
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Thu, 3 Oct 2024 21:09:46 -0700
Subject: [R] 
 Warning message: Removed 888 rows containing missing values or
 values outside the scale range (`geom_line()`)
In-Reply-To: <CANTvJZKvvOEtZgVMBR8RHbnaQ8tU17v3cod-5SQ9gpKv1CSJ7Q@mail.gmail.com>
References: <CANTvJZKvvOEtZgVMBR8RHbnaQ8tU17v3cod-5SQ9gpKv1CSJ7Q@mail.gmail.com>
Message-ID: <CAP+bYWBuJ6NDSMxjtH3LCOuty0KtOe19WrmR-ZHWkwo0C-dTKQ@mail.gmail.com>

These are warnings, not errors.

On Thu, 3 Oct 2024 at 21:02, roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Dear all,
> I tried to rerun the examples given by Hyndman in otexts but keep on
> getting errors and I have searched through google but no solution yet.
>
> Thank you in advance for any help given.
>
> library(fpp3)
> library(lubridate)
> library(xts)
> library(fabletools)
> library(ggplot2)
> library(dplyr)
> library(gridExtra)
>
> > dput(head(new_us_retail_employment,100))structure(list(Month =
> structure(c(-11323, -11292, -11264, -11233,
> -11203, -11172, -11142, -11111, -11080, -11050, -11019, -10989,
> -10958, -10927, -10898, -10867, -10837, -10806, -10776, -10745,
> -10714, -10684, -10653, -10623, -10592, -10561, -10533, -10502,
> -10472, -10441, -10411, -10380, -10349, -10319, -10288, -10258,
> -10227, -10196, -10168, -10137, -10107, -10076, -10046, -10015,
> -9984, -9954, -9923, -9893, -9862, -9831, -9803, -9772, -9742,
> -9711, -9681, -9650, -9619, -9589, -9558, -9528, -9497, -9466,
> -9437, -9406, -9376, -9345, -9315, -9284, -9253, -9223, -9192,
> -9162, -9131, -9100, -9072, -9041, -9011, -8980, -8950, -8919,
> -8888, -8858, -8827, -8797, -8766, -8735, -8707, -8676, -8646,
> -8615, -8585, -8554, -8523, -8493, -8462, -8432, -8401, -8370,
> -8342, -8311), class = c("yearmonth", "vctrs_vctr")), Series_ID =
> c("CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001", "CEU0500000001",
> "CEU0500000001", "CEU0500000001", "CEU0500000001"), Title = c("Total
> Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private", "Total Private",
> "Total Private", "Total Private", "Total Private"), Employed = c(25338,
> 25447, 25833, 25801, 26113, 26485, 26481, 26848, 27468, 27830,
> 27740, 27886, 26847, 26902, 27205, 27255, 27535, 27765, 27789,
> 28332, 29007, 29399, 29619, 30221, 29402, 29671, 30079, 30610,
> 31379, 31999, 32545, 33014, 33417, 33457, 33367, 33552, 32660,
> 32739, 33240, 33764, 34203, 34624, 35065, 35460, 35771, 35852,
> 35867, 36209, 35494, 35627, 35955, 36212, 36202, 36608, 36637,
> 36628, 36584, 36658, 36810, 36815, 36018, 35973, 35948, 35833,
> 35768, 35949, 35861, 35828, 35652, 35555, 35597, 35850, 35229,
> 35290, 35411, 35161, 35024, 35065, 34769, 34490, 32760, 32833,
> 33354, 33755, 33656, 33092, 34240, 34997, 35409, 36074, 36474,
> 37139, 37532, 37637, 38045, 38351, 37510, 37495, 37720, 37686
> )), class = c("tbl_ts", "tbl_df", "tbl", "data.frame"), row.names = c(NA,
> -100L), key = structure(list(Series_ID = "CEU0500000001", .rows =
> structure(list(
>     1:100), ptype = integer(0), class = c("vctrs_list_of", "vctrs_vctr",
> "list"))), class = c("tbl_df", "tbl", "data.frame"), row.names = c(NA,
> -1L), .drop = TRUE), index = structure("Month", ordered = TRUE),
> index2 = "Month", interval = structure(list(
>     year = 0, quarter = 0, month = 1, week = 0, day = 0, hour = 0,
>     minute = 0, second = 0, millisecond = 0, microsecond = 0,
>     nanosecond = 0, unit = 0), .regular = TRUE, class = c("interval",
> "vctrs_rcrd", "vctrs_vctr")))
>
>
>
> # Decomposition
> new_us_retail_employment <- na.omit(us_retail_employment) # data cleaning
>
> new_us_retail_employment |>
>   model(
>     classical_decomposition(Employed, type = "additive")
>   ) |>
>   components() |>
>   autoplot() +xlab("Year") +
>   ggtitle("Classical additive decomposition of total
>                   US retail employment")
>
> > new_us_retail_employment |>+   model(+
>  classical_decomposition(Employed, type = "additive")+   ) |>+
>  components() |>+   autoplot() +xlab("Year") ++   ggtitle("Classical
> additive decomposition of total+                   US retail
> employment")Warning message:Removed 888 rows containing missing values or
> values outside the scale range (`geom_line()`)
>
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Oct  4 06:17:06 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 3 Oct 2024 21:17:06 -0700
Subject: [R] How to install this package
In-Reply-To: <CANTvJZKK2j2pBa1=avpsE3s=d_w7xAb7MXpXMtaPkRtyMF3D5g@mail.gmail.com>
References: <CANTvJZKK2j2pBa1=avpsE3s=d_w7xAb7MXpXMtaPkRtyMF3D5g@mail.gmail.com>
Message-ID: <58542430-6255-43D2-99B0-483ED3F62FC3@comcast.net>

I?m 
Sent from my iPhone

> On Oct 2, 2024, at 7:43?AM, roslinazairimah zakaria <roslinaump at gmail.com> wrote:
> 
> ?Hi Enrico, yes it works. I can also plot the graph.
> Next question, how do I delete the date from 16 December until 31 December
> 2014?
> 
> 
> Thank you very much.
> 
>> dt$time <- as.POSIXct(dt$time)> > dt_ts <- xts(dt$count, dt$time)> str(dt_ts)An xts object on 2014-01-01 / 2014-12-31 23:59:00 containing:
>  Data:    integer [525600, 1]
>  Index:   POSIXct,POSIXt [525600] (TZ: "")
> 
> 
> plot(dt_ts)

I believe that xts objects store that sort of information in their attributes. Look at the results of 

attr(dt_ts)

In the future you should not ask unrelated questions without changing the subject line to reflect the new topic area. And you should stop posting in HTML. 

? 
David


> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
> 
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Fri Oct  4 10:32:06 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 4 Oct 2024 16:32:06 +0800
Subject: [R] apply
Message-ID: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>

The following line calculates standard deviations of a column vector:

se<-apply(dd,1,sd)

How can I calculate the covariance matrix using apply? Thanks.


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Oct  4 10:57:59 2024
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 4 Oct 2024 10:57:59 +0200
Subject: [R] apply
In-Reply-To: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
Message-ID: <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>

Homework questions are not answered on this list.

Best,
Uwe Ligges



On 04.10.2024 10:32, Steven Yen wrote:
> The following line calculates standard deviations of a column vector:
> 
> se<-apply(dd,1,sd)
> 
> How can I calculate the covariance matrix using apply? Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @tyen @end|ng |rom ntu@edu@tw  Fri Oct  4 11:15:39 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 4 Oct 2024 17:15:39 +0800
Subject: [R] apply
In-Reply-To: <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
Message-ID: <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>

On 10/4/2024 5:13 PM, Steven Yen wrote:

> Pardon me!!!
>
> What makes you think this is a homework question? You are not 
> obligated to respond if the question is not intelligent enough for you.
>
> I did the following: two ways to calculate a covariance matrix but 
> wonder how I might replicate the results with "apply". I am not too 
> comfortable with the online documentation of "apply".
>
> > set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115 
> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2] 
> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1] 
> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 
> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805 
> -0.00273267965 0.0151896601 >
> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>> Homework questions are not answered on this list.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 04.10.2024 10:32, Steven Yen wrote:
>>> The following line calculates standard deviations of a column vector:
>>>
>>> se<-apply(dd,1,sd)
>>>
>>> How can I calculate the covariance matrix using apply? Thanks.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Oct  4 11:16:02 2024
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 4 Oct 2024 11:16:02 +0200
Subject: [R] apply
In-Reply-To: <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
Message-ID: <979bb7e0-b0bd-44a4-91d4-0318e53da992@statistik.tu-dortmund.de>



On 04.10.2024 11:13, Steven Yen wrote:
> Pardon me!!!
> 
> What makes you think this is a homework question? You are not obligated 

Otherwise you called cov()

Best,
Uwe Ligges



> to respond if the question is not intelligent enough for you.
> 
> I did the following: two ways to calculate a covariance matrix but 
> wonder how I might replicate the results with "apply". I am not too 
> comfortable with the online do of apply.
> 
>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115 
> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2] [,3] 
> [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1] [,2] 
> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
> 0.0151896601 >
> 
> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>> Homework questions are not answered on this list.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 04.10.2024 10:32, Steven Yen wrote:
>>> The following line calculates standard deviations of a column vector:
>>>
>>> se<-apply(dd,1,sd)
>>>
>>> How can I calculate the covariance matrix using apply? Thanks.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct  4 12:35:54 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 4 Oct 2024 11:35:54 +0100
Subject: [R] apply
In-Reply-To: <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
Message-ID: <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>

Hello,

If you have a numeric matrix or data.frame, try something like

cov(mtcars)

Hope this helps,

Rui Barradas


?s 10:15 de 04/10/2024, Steven Yen escreveu:
> On 10/4/2024 5:13 PM, Steven Yen wrote:
> 
>> Pardon me!!!
>>
>> What makes you think this is a homework question? You are not
>> obligated to respond if the question is not intelligent enough for you.
>>
>> I did the following: two ways to calculate a covariance matrix but
>> wonder how I might replicate the results with "apply". I am not too
>> comfortable with the online documentation of "apply".
>>
>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115
>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>> -0.00273267965 0.0151896601 >
>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>> Homework questions are not answered on this list.
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>
>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>> The following line calculates standard deviations of a column vector:
>>>>
>>>> se<-apply(dd,1,sd)
>>>>
>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> https://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @tyen @end|ng |rom ntu@edu@tw  Fri Oct  4 13:14:30 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 4 Oct 2024 19:14:30 +0800
Subject: [R] apply
In-Reply-To: <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
Message-ID: <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>

Hello

I have a vector:

set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749 
1.55870831 I like to create a matrix with elements containing variances 
and covariances of x. That is var(x[1]) cov(x[1],x[2]) cov(x[1],x[3]) 
cov(x[2],x[1]) var(x[2]) cov(x[2],x[3]) cov(x[3],x[1]) cov(x[3],x[2]) 
var(x[3]) And I like to do it with "apply". Thanks.

On 10/4/2024 6:35 PM, Rui Barradas wrote:
> Hello,
>
> If you have a numeric matrix or data.frame, try something like
>
> cov(mtcars)
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>
>>> Pardon me!!!
>>>
>>> What makes you think this is a homework question? You are not
>>> obligated to respond if the question is not intelligent enough for you.
>>>
>>> I did the following: two ways to calculate a covariance matrix but
>>> wonder how I might replicate the results with "apply". I am not too
>>> comfortable with the online documentation of "apply".
>>>
>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115
>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>> -0.00273267965 0.0151896601 >
>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>> Homework questions are not answered on this list.
>>>>
>>>> Best,
>>>> Uwe Ligges
>>>>
>>>>
>>>>
>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>> The following line calculates standard deviations of a column vector:
>>>>>
>>>>> se<-apply(dd,1,sd)
>>>>>
>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> https://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Oct  4 13:28:29 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 4 Oct 2024 14:28:29 +0300
Subject: [R] apply
In-Reply-To: <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
Message-ID: <20241004142829.56c57670@arachnoid>

? Fri, 4 Oct 2024 19:14:30 +0800
Steven Yen <styen at ntu.edu.tw> ?????:

> I have a vector:

> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749
> 1.55870831

> var(x[1]) cov(x[1],x[2])

Are you sure you don't have a matrix? If you type var(x[1]) or
cov(x[1],x[2]) into R, you can see that all these are NA: an unbiased
estimate of variance or covariance requires dividing by (sample size -
1), which would be 0 for individual numbers.

Even if you did divide by (sample size), the answers would all be 0,
because a single number is always equal to the mean of the same one
number.

-- 
Best regards,
Ivan


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct  4 14:03:28 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 4 Oct 2024 13:03:28 +0100
Subject: [R] apply
In-Reply-To: <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
Message-ID: <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>

Hello,

This doesn't make sense, if you have only one vector you can estimate 
its variance with

var(x)


but there is no covariance, the joint variance of two rv's. "co" or 
joint with what if you have only x?
Note that the variance of x[1] or any other vector element is zero, it's 
only one value therefore it does not vary. A similar reasonong can be 
applied to cov(x[1], x[2]), etc.

Hope this helps,

Rui Barradas

?s 12:14 de 04/10/2024, Steven Yen escreveu:
> Hello
> 
> I have a vector:
> 
> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749 
> 1.55870831 I like to create a matrix with elements containing variances 
> and covariances of x. That is var(x[1]) cov(x[1],x[2]) cov(x[1],x[3]) 
> cov(x[2],x[1]) var(x[2]) cov(x[2],x[3]) cov(x[3],x[1]) cov(x[3],x[2]) 
> var(x[3]) And I like to do it with "apply". Thanks.
> 
> On 10/4/2024 6:35 PM, Rui Barradas wrote:
>> Hello,
>>
>> If you have a numeric matrix or data.frame, try something like
>>
>> cov(mtcars)
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>>
>>>> Pardon me!!!
>>>>
>>>> What makes you think this is a homework question? You are not
>>>> obligated to respond if the question is not intelligent enough for you.
>>>>
>>>> I did the following: two ways to calculate a covariance matrix but
>>>> wonder how I might replicate the results with "apply". I am not too
>>>> comfortable with the online documentation of "apply".
>>>>
>>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115
>>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>>>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>>> -0.00273267965 0.0151896601 >
>>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>>> Homework questions are not answered on this list.
>>>>>
>>>>> Best,
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>>> The following line calculates standard deviations of a column vector:
>>>>>>
>>>>>> se<-apply(dd,1,sd)
>>>>>>
>>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> https://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @tyen @end|ng |rom ntu@edu@tw  Fri Oct  4 14:28:01 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 4 Oct 2024 20:28:01 +0800
Subject: [R] apply
In-Reply-To: <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
Message-ID: <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>

OK. Thanks to all. Suppose I have two vectors, x and y. Is there a way 
to do the covariance matrix with ?apply?. The matrix I need really 
contains the deviation products divided by the degrees of freedom (n-1). 
That is, the elements

(1,1), (1,2),...,(1,n)

(2,1), (2,2),...., (2,n)

....

(n,1),(n,2),...,(n,n).

> Hello,
>
> This doesn't make sense, if you have only one vector you can estimate 
> its variance with
>
> var(x)
>
>
> but there is no covariance, the joint variance of two rv's. "co" or 
> joint with what if you have only x?
> Note that the variance of x[1] or any other vector element is zero, 
> it's only one value therefore it does not vary. A similar reasonong 
> can be applied to cov(x[1], x[2]), etc.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 12:14 de 04/10/2024, Steven Yen escreveu:
>> Hello
>>
>> I have a vector:
>>
>> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749 
>> 1.55870831 I like to create a matrix with elements containing 
>> variances and covariances of x. That is var(x[1]) cov(x[1],x[2]) 
>> cov(x[1],x[3]) cov(x[2],x[1]) var(x[2]) cov(x[2],x[3]) cov(x[3],x[1]) 
>> cov(x[3],x[2]) var(x[3]) And I like to do it with "apply". Thanks.
>>
>> On 10/4/2024 6:35 PM, Rui Barradas wrote:
>>> Hello,
>>>
>>> If you have a numeric matrix or data.frame, try something like
>>>
>>> cov(mtcars)
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>>>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>>>
>>>>> Pardon me!!!
>>>>>
>>>>> What makes you think this is a homework question? You are not
>>>>> obligated to respond if the question is not intelligent enough for 
>>>>> you.
>>>>>
>>>>> I did the following: two ways to calculate a covariance matrix but
>>>>> wonder how I might replicate the results with "apply". I am not too
>>>>> comfortable with the online documentation of "apply".
>>>>>
>>>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 
>>>>>> 0.80940115
>>>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>>>>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>>>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>>>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>>>> -0.00273267965 0.0151896601 >
>>>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>>>> Homework questions are not answered on this list.
>>>>>>
>>>>>> Best,
>>>>>> Uwe Ligges
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>>>> The following line calculates standard deviations of a column 
>>>>>>> vector:
>>>>>>>
>>>>>>> se<-apply(dd,1,sd)
>>>>>>>
>>>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> https://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ????[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From |kry|ov @end|ng |rom d|@root@org  Fri Oct  4 14:41:03 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 4 Oct 2024 15:41:03 +0300
Subject: [R] apply
In-Reply-To: <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
 <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
Message-ID: <20241004154103.3668dcb7@arachnoid>

? Fri, 4 Oct 2024 20:28:01 +0800
Steven Yen <styen at ntu.edu.tw> ?????:

> Suppose I have two vectors, x and y. Is there a way 
> to do the covariance matrix with ?apply?.

There is no covariance matrix for just two samples (vectors) 'x' and
'y'. You can only get one covariance value for these.

If you had a pair of vectors of _random variates_, the situation would
be different, but those are more abstract mathematical concepts. You
would need to sample every random variate, producing two matrices 'x'
and 'y' in order to calculate a covariance matrix for them.

-- 
Best regards,
Ivan


From bbo|ker @end|ng |rom gm@||@com  Fri Oct  4 14:44:37 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 4 Oct 2024 08:44:37 -0400
Subject: [R] apply
In-Reply-To: <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
 <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
Message-ID: <919089d7-c6ba-4855-872b-b488bdef6af8@gmail.com>

   It's still hard to figure out what you want.  If you have two vectors 
you can compute their (2x2) covariance matrix using cov(cbind(x,y)).

If you want to compute all pairwise squared differences between elements 
of x and y you could use outer(x, y, "-")^2.

  Can you explain a little bit more about (1) the context for your 
question and (2) why you want/need to use apply() ?

On 2024-10-04 8:28 a.m., Steven Yen wrote:
> OK. Thanks to all. Suppose I have two vectors, x and y. Is there a way 
> to do the covariance matrix with ?apply?. The matrix I need really 
> contains the deviation products divided by the degrees of freedom (n-1). 
> That is, the elements
> 
> (1,1), (1,2),...,(1,n)
> 
> (2,1), (2,2),...., (2,n)
> 
> ....
> 
> (n,1),(n,2),...,(n,n).
> 
>> Hello,
>>
>> This doesn't make sense, if you have only one vector you can estimate 
>> its variance with
>>
>> var(x)
>>
>>
>> but there is no covariance, the joint variance of two rv's. "co" or 
>> joint with what if you have only x?
>> Note that the variance of x[1] or any other vector element is zero, 
>> it's only one value therefore it does not vary. A similar reasonong 
>> can be applied to cov(x[1], x[2]), etc.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 12:14 de 04/10/2024, Steven Yen escreveu:
>>> Hello
>>>
>>> I have a vector:
>>>
>>> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749 
>>> 1.55870831 I like to create a matrix with elements containing 
>>> variances and covariances of x. That is var(x[1]) cov(x[1],x[2]) 
>>> cov(x[1],x[3]) cov(x[2],x[1]) var(x[2]) cov(x[2],x[3]) cov(x[3],x[1]) 
>>> cov(x[3],x[2]) var(x[3]) And I like to do it with "apply". Thanks.
>>>
>>> On 10/4/2024 6:35 PM, Rui Barradas wrote:
>>>> Hello,
>>>>
>>>> If you have a numeric matrix or data.frame, try something like
>>>>
>>>> cov(mtcars)
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>>>>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>>>>
>>>>>> Pardon me!!!
>>>>>>
>>>>>> What makes you think this is a homework question? You are not
>>>>>> obligated to respond if the question is not intelligent enough for 
>>>>>> you.
>>>>>>
>>>>>> I did the following: two ways to calculate a covariance matrix but
>>>>>> wonder how I might replicate the results with "apply". I am not too
>>>>>> comfortable with the online documentation of "apply".
>>>>>>
>>>>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 
>>>>>>> 0.80940115
>>>>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>>>>>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>>>>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>>>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>>>>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>>>>> -0.00273267965 0.0151896601 >
>>>>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>>>>> Homework questions are not answered on this list.
>>>>>>>
>>>>>>> Best,
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>>>>> The following line calculates standard deviations of a column 
>>>>>>>> vector:
>>>>>>>>
>>>>>>>> se<-apply(dd,1,sd)
>>>>>>>>
>>>>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> https://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> ????[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>>>>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From petr@p|k @end|ng |rom gm@||@com  Fri Oct  4 15:18:53 2024
From: petr@p|k @end|ng |rom gm@||@com (Petr Pikal)
Date: Fri, 4 Oct 2024 15:18:53 +0200
Subject: [R] Time series data decomposition from by minute data
In-Reply-To: <CANTvJZKOYEO-9MgyyZjgZFEYfFWAtXJ4tXh_ntX_jFCixS=K9g@mail.gmail.com>
References: <CANTvJZKOYEO-9MgyyZjgZFEYfFWAtXJ4tXh_ntX_jFCixS=K9g@mail.gmail.com>
Message-ID: <CAO8Egw8J+BFRL7C8e6itM9NMfEMAPOhO6NeVbMqSTdrCeK7WAA@mail.gmail.com>

Hallo

you can extract POSIX object

tv <- as.POSIXct(index(dt_train))

and use cut together with aggregate
cut(tv, "hour")

aggregate(dt_train, list(cut(tv, "hour")), mean)

2014-10-06 21:00:00 9.807692
2014-10-06 22:00:00 8.666667

Cheers.
Petr



?t 3. 10. 2024 v 17:25 odes?latel roslinazairimah zakaria <
roslinaump at gmail.com> napsal:

> Dear all,
>
> My data is by minutes and I can see it has seasonal trend by daily and
> weekly. How do I decompose the minute data into daily and weekly
>
> some data:
>
> > dput(tail(dt_train,100))structure(c(11L, 11L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L,
> 10L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 11L, 11L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 9L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L), class = c("xts", "zoo"), index = structure(c(1412622480,
> 1412622540, 1412622600, 1412622660, 1412622720, 1412622780, 1412622840,
> 1412622900, 1412622960, 1412623020, 1412623080, 1412623140, 1412623200,
> 1412623260, 1412623320, 1412623380, 1412623440, 1412623500, 1412623560,
> 1412623620, 1412623680, 1412623740, 1412623800, 1412623860, 1412623920,
> 1412623980, 1412624040, 1412624100, 1412624160, 1412624220, 1412624280,
> 1412624340, 1412624400, 1412624460, 1412624520, 1412624580, 1412624640,
> 1412624700, 1412624760, 1412624820, 1412624880, 1412624940, 1412625000,
> 1412625060, 1412625120, 1412625180, 1412625240, 1412625300, 1412625360,
> 1412625420, 1412625480, 1412625540, 1412625600, 1412625660, 1412625720,
> 1412625780, 1412625840, 1412625900, 1412625960, 1412626020, 1412626080,
> 1412626140, 1412626200, 1412626260, 1412626320, 1412626380, 1412626440,
> 1412626500, 1412626560, 1412626620, 1412626680, 1412626740, 1412626800,
> 1412626860, 1412626920, 1412626980, 1412627040, 1412627100, 1412627160,
> 1412627220, 1412627280, 1412627340, 1412627400, 1412627460, 1412627520,
> 1412627580, 1412627640, 1412627700, 1412627760, 1412627820, 1412627880,
> 1412627940, 1412628000, 1412628060, 1412628120, 1412628180, 1412628240,
> 1412628300, 1412628360, 1412628420), tzone = "", tclass = c("POSIXct",
> "POSIXt")), dim = c(100L, 1L))
>
>
> I also attached the plot of training data.
>
>
> I tried :
>
> decompose(dt_train, type = "multiplicative", filter = NULL)Error in
> decompose(dt_train, type = "multiplicative", filter = NULL) :
>   time series has no or less than 2 periods
>
>
> > stl(dt_train, s.window = "periodic")Error in stl(dt_train, s.window =
> "periodic") :
>   series is not periodic or has less than two
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Fri Oct  4 15:20:18 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 4 Oct 2024 13:20:18 +0000
Subject: [R] apply
In-Reply-To: <919089d7-c6ba-4855-872b-b488bdef6af8@gmail.com>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
 <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
 <919089d7-c6ba-4855-872b-b488bdef6af8@gmail.com>
Message-ID: <CH3PR22MB4514AA83E3BEC805469ED8CBCF722@CH3PR22MB4514.namprd22.prod.outlook.com>

Why must the answer use apply? It feels like there are elements of the problem that are not explained.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ben Bolker
Sent: Friday, October 4, 2024 8:45 AM
To: r-help at r-project.org
Subject: Re: [R] apply

[External Email]

   It's still hard to figure out what you want.  If you have two vectors you can compute their (2x2) covariance matrix using cov(cbind(x,y)).

If you want to compute all pairwise squared differences between elements of x and y you could use outer(x, y, "-")^2.

  Can you explain a little bit more about (1) the context for your question and (2) why you want/need to use apply() ?

On 2024-10-04 8:28 a.m., Steven Yen wrote:
> OK. Thanks to all. Suppose I have two vectors, x and y. Is there a way
> to do the covariance matrix with "apply". The matrix I need really
> contains the deviation products divided by the degrees of freedom (n-1).
> That is, the elements
>
> (1,1), (1,2),...,(1,n)
>
> (2,1), (2,2),...., (2,n)
>
> ....
>
> (n,1),(n,2),...,(n,n).
>
>> Hello,
>>
>> This doesn't make sense, if you have only one vector you can estimate
>> its variance with
>>
>> var(x)
>>
>>
>> but there is no covariance, the joint variance of two rv's. "co" or
>> joint with what if you have only x?
>> Note that the variance of x[1] or any other vector element is zero,
>> it's only one value therefore it does not vary. A similar reasonong
>> can be applied to cov(x[1], x[2]), etc.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 12:14 de 04/10/2024, Steven Yen escreveu:
>>> Hello
>>>
>>> I have a vector:
>>>
>>> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749
>>> 1.55870831 I like to create a matrix with elements containing
>>> variances and covariances of x. That is var(x[1]) cov(x[1],x[2])
>>> cov(x[1],x[3]) cov(x[2],x[1]) var(x[2]) cov(x[2],x[3])
>>> cov(x[3],x[1])
>>> cov(x[3],x[2]) var(x[3]) And I like to do it with "apply". Thanks.
>>>
>>> On 10/4/2024 6:35 PM, Rui Barradas wrote:
>>>> Hello,
>>>>
>>>> If you have a numeric matrix or data.frame, try something like
>>>>
>>>> cov(mtcars)
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>>>>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>>>>
>>>>>> Pardon me!!!
>>>>>>
>>>>>> What makes you think this is a homework question? You are not
>>>>>> obligated to respond if the question is not intelligent enough
>>>>>> for you.
>>>>>>
>>>>>> I did the following: two ways to calculate a covariance matrix
>>>>>> but wonder how I might replicate the results with "apply". I am
>>>>>> not too comfortable with the online documentation of "apply".
>>>>>>
>>>>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449
>>>>>>> 0.80940115
>>>>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1]
>>>>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>>>> 0.0022410598
>>>>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>>>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2
>>>>>> [,1] [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>>>>> -0.00273267965 0.0151896601 >
>>>>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>>>>> Homework questions are not answered on this list.
>>>>>>>
>>>>>>> Best,
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>>>>> The following line calculates standard deviations of a column
>>>>>>>> vector:
>>>>>>>>
>>>>>>>> se<-apply(dd,1,sd)
>>>>>>>>
>>>>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>>>> see
>>>>>>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F
>>>>>>>> %2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Cte
>>>>>>>> bert%40ufl.edu%7Cbd77351d05ca4ffd998308dce4728e54%7C0d4da0f84a3
>>>>>>>> 14d76ace60a62331e1b84%7C0%7C0%7C638636427922120864%7CUnknown%7C
>>>>>>>> TWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWw
>>>>>>>> iLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=9mHV2ck%2FlVQlaA457k3M8b7etH
>>>>>>>> %2BdlfHH1XXPvWcbaL4%3D&reserved=0 PLEASE do read the posting
>>>>>>>> guide
>>>>>>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F
>>>>>>>> %2Fwww.r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert
>>>>>>>> %40ufl.edu%7Cbd77351d05ca4ffd998308dce4728e54%7C0d4da0f84a314d7
>>>>>>>> 6ace60a62331e1b84%7C0%7C0%7C638636427922139431%7CUnknown%7CTWFp
>>>>>>>> bGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJ
>>>>>>>> XVCI6Mn0%3D%7C0%7C%7C%7C&sdata=TsIfyZl9gYLrlfoowyjLIz7jRZg65EXd
>>>>>>>> V4bIr34pBVA%3D&reserved=0 and provide commented, minimal,
>>>>>>>> self-contained, reproducible code.
>>>>>     [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2F
>>>>> stat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%4
>>>>> 0ufl.edu%7Cbd77351d05ca4ffd998308dce4728e54%7C0d4da0f84a314d76ace6
>>>>> 0a62331e1b84%7C0%7C0%7C638636427922154301%7CUnknown%7CTWFpbGZsb3d8
>>>>> eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D
>>>>> %7C0%7C%7C%7C&sdata=LcWqq5N8YO4tX7hPVTJOZl1nG6GC3Unq%2F46xSXspZjw%
>>>>> 3D&reserved=0 PLEASE do read the posting guide
>>>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2F
>>>>> http://www.r-project.org/%2Fposting-&data=05%7C02%7Ctebert%40ufl.edu%7Cbd7
>>>>> 7351d05ca4ffd998308dce4728e54%7C0d4da0f84a314d76ace60a62331e1b84%7
>>>>> C0%7C0%7C638636427922166033%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLj
>>>>> AwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&
>>>>> sdata=VJclmilR7Wpywl7b%2BN1KSoFP6nYDTYG9%2B77EFiShKLg%3D&reserved=
>>>>> 0
>>>>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cbd77351d05ca4ffd998308dce4728e54%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638636427922176572%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=
> RPev0nDdNEGZVUrut2P%2BSVtYWxbWX5MQ2H6rxiphsng%3D&reserved=0
> PLEASE do read the posting guide
> https://www/.
> r-project.org%2Fposting-&data=05%7C02%7Ctebert%40ufl.edu%7Cbd77351d05c
> a4ffd998308dce4728e54%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638
> 636427922187632%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2
> luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=idsohi4eloemUO
> oZ8uBXr5rujqgVN%2Fr4dQ2QIRaY4kQ%3D&reserved=0
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University Director, School of Computational Science and Engineering  > E-mail is sent at my convenience; I don't expect replies outside of working hours.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct  4 15:59:19 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 4 Oct 2024 14:59:19 +0100
Subject: [R] apply
In-Reply-To: <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
 <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
Message-ID: <78778048-74cc-4261-ba8d-cfd9aa175fe6@sapo.pt>

Hello,

You don't need apply, covariance calculations are so frequent that R or 
any other statistics package already has pre-programmed functions.
This time with two vectors x and y.



set.seed(123)
n <- 3
x <- rnorm(n)
y <- rnorm(n)

# the two main diagonal values
var(x)
#> [1] 1.300025
var(y)
#> [1] 0.8704518
# the secondary diagonal values
cov(x, y)
#> [1] 1.056885
# cov(x, y) == cov(y, x)
cov(y, x)
#> [1] 1.056885

# and the result you are after
# (the covariance matrix is symmetric)
cov(cbind(x, y))
#>          x         y
#> x 1.300025 1.0568845
#> y 1.056885 0.8704518



Hope this helps,

Rui Barradas


?s 13:28 de 04/10/2024, Steven Yen escreveu:
> OK. Thanks to all. Suppose I have two vectors, x and y. Is there a way 
> to do the covariance matrix with ?apply?. The matrix I need really 
> contains the deviation products divided by the degrees of freedom (n-1). 
> That is, the elements
> 
> (1,1), (1,2),...,(1,n)
> 
> (2,1), (2,2),...., (2,n)
> 
> ....
> 
> (n,1),(n,2),...,(n,n).
> 
>> Hello,
>>
>> This doesn't make sense, if you have only one vector you can estimate 
>> its variance with
>>
>> var(x)
>>
>>
>> but there is no covariance, the joint variance of two rv's. "co" or 
>> joint with what if you have only x?
>> Note that the variance of x[1] or any other vector element is zero, 
>> it's only one value therefore it does not vary. A similar reasonong 
>> can be applied to cov(x[1], x[2]), etc.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 12:14 de 04/10/2024, Steven Yen escreveu:
>>> Hello
>>>
>>> I have a vector:
>>>
>>> set.seed(123) > n<-3 > x<-rnorm(n); x [1] -0.56047565 -0.23017749 
>>> 1.55870831 I like to create a matrix with elements containing 
>>> variances and covariances of x. That is var(x[1]) cov(x[1],x[2]) 
>>> cov(x[1],x[3]) cov(x[2],x[1]) var(x[2]) cov(x[2],x[3]) cov(x[3],x[1]) 
>>> cov(x[3],x[2]) var(x[3]) And I like to do it with "apply". Thanks.
>>>
>>> On 10/4/2024 6:35 PM, Rui Barradas wrote:
>>>> Hello,
>>>>
>>>> If you have a numeric matrix or data.frame, try something like
>>>>
>>>> cov(mtcars)
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>> ?s 10:15 de 04/10/2024, Steven Yen escreveu:
>>>>> On 10/4/2024 5:13 PM, Steven Yen wrote:
>>>>>
>>>>>> Pardon me!!!
>>>>>>
>>>>>> What makes you think this is a homework question? You are not
>>>>>> obligated to respond if the question is not intelligent enough for 
>>>>>> you.
>>>>>>
>>>>>> I did the following: two ways to calculate a covariance matrix but
>>>>>> wonder how I might replicate the results with "apply". I am not too
>>>>>> comfortable with the online documentation of "apply".
>>>>>>
>>>>>>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 
>>>>>>> 0.80940115
>>>>>> 0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
>>>>>> [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598
>>>>>> 0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965
>>>>>> 0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
>>>>>> [,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
>>>>>> 0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
>>>>>> -0.00273267965 0.0151896601 >
>>>>>> On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>>>>>>> Homework questions are not answered on this list.
>>>>>>>
>>>>>>> Best,
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 04.10.2024 10:32, Steven Yen wrote:
>>>>>>>> The following line calculates standard deviations of a column 
>>>>>>>> vector:
>>>>>>>>
>>>>>>>> se<-apply(dd,1,sd)
>>>>>>>>
>>>>>>>> How can I calculate the covariance matrix using apply? Thanks.
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> https://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> ????[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>>>>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @yen04 @end|ng |rom gm@||@com  Fri Oct  4 11:13:26 2024
From: @yen04 @end|ng |rom gm@||@com (Steven Yen)
Date: Fri, 4 Oct 2024 17:13:26 +0800
Subject: [R] apply
In-Reply-To: <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
Message-ID: <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>

Pardon me!!!

What makes you think this is a homework question? You are not obligated 
to respond if the question is not intelligent enough for you.

I did the following: two ways to calculate a covariance matrix but 
wonder how I might replicate the results with "apply". I am not too 
comfortable with the online do of apply.

> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115 
0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2] [,3] 
[1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1] [,2] 
[,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
0.0151896601 >

On 10/4/2024 4:57 PM, Uwe Ligges wrote:
> Homework questions are not answered on this list.
>
> Best,
> Uwe Ligges
>
>
>
> On 04.10.2024 10:32, Steven Yen wrote:
>> The following line calculates standard deviations of a column vector:
>>
>> se<-apply(dd,1,sd)
>>
>> How can I calculate the covariance matrix using apply? Thanks.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Oct  4 20:16:45 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 04 Oct 2024 11:16:45 -0700
Subject: [R] apply
In-Reply-To: <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
Message-ID: <890C4A41-9D87-460B-B99E-9FD40163E2B9@dcn.davis.ca.us>

Even if this is not a homework question, it smells like one. If you read the Posting Guide it warns you that homework is off-topic, so when you impose an arbitrary constraint like "must use specific unrelated function" we feel like you are either cheating or wasting our time, and it is up to you to explain why we should follow you down this rabbit hole, keeping in mind that statistics theory per-se is also off-topic here. You have yet to explain why you want to do this the hard way.

On October 4, 2024 2:13:26 AM PDT, Steven Yen <syen04 at gmail.com> wrote:
>Pardon me!!!
>
>What makes you think this is a homework question? You are not obligated 
>to respond if the question is not intelligent enough for you.
>
>I did the following: two ways to calculate a covariance matrix but 
>wonder how I might replicate the results with "apply". I am not too 
>comfortable with the online do of apply.
>
>> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449 0.80940115 
>0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2] [,3] 
>[1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
>0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
>0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1] [,2] 
>[,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
>0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
>0.0151896601 >
>
>On 10/4/2024 4:57 PM, Uwe Ligges wrote:
>> Homework questions are not answered on this list.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 04.10.2024 10:32, Steven Yen wrote:
>>> The following line calculates standard deviations of a column vector:
>>>
>>> se<-apply(dd,1,sd)
>>>
>>> How can I calculate the covariance matrix using apply? Thanks.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ro||turner @end|ng |rom po@teo@net  Sat Oct  5 01:14:35 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Fri,  4 Oct 2024 23:14:35 +0000
Subject: [R] apply
In-Reply-To: <890C4A41-9D87-460B-B99E-9FD40163E2B9@dcn.davis.ca.us>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <890C4A41-9D87-460B-B99E-9FD40163E2B9@dcn.davis.ca.us>
Message-ID: <20241005121435.4a59ed5b@elderly-dell>

On Fri, 04 Oct 2024 11:16:45 -0700
Jeff Newmiller via R-help <r-help at r-project.org> wrote:

> Even if this is not a homework question, it smells like one. If you
> read the Posting Guide it warns you that homework is off-topic, so
> when you impose an arbitrary constraint like "must use specific
> unrelated function" we feel like you are either cheating or wasting
> our time, and it is up to you to explain why we should follow you
> down this rabbit hole, keeping in mind that statistics theory per-se
> is also off-topic here. You have yet to explain why you want to do
> this the hard way.

Well put, Jeff.

cheers,

Rolf

> On October 4, 2024 2:13:26 AM PDT, Steven Yen <syen04 at gmail.com>
> wrote:
> >Pardon me!!!
> >
> >What makes you think this is a homework question? You are not
> >obligated to respond if the question is not intelligent enough for
> >you.
> >
> >I did the following: two ways to calculate a covariance matrix but 
> >wonder how I might replicate the results with "apply". I am not too 
> >comfortable with the online do of apply.
> >
> >> set.seed(122345671) > n<-3 > x<-rnorm(n); x [1] 0.92098449
> >> 0.80940115 
> >0.60374785 > cov1<-outer(x-mean(x),x-mean(x))/(n-1); cov1 [,1] [,2]
> >[,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,] 0.0022410598 
> >0.00049161983 -0.0027326797 [3,] -0.0124569805 -0.00273267965 
> >0.0151896601 > cov2<-(x-mean(x))%*%t((x-mean(x)))/(n-1); cov2 [,1]
> >[,2] [,3] [1,] 0.0102159207 0.00224105983 -0.0124569805 [2,]
> >0.0022410598 0.00049161983 -0.0027326797 [3,] -0.0124569805
> >-0.00273267965 0.0151896601 >
> >
> >On 10/4/2024 4:57 PM, Uwe Ligges wrote:
> >> Homework questions are not answered on this list.
> >>
> >> Best,
> >> Uwe Ligges
> >>
> >>
> >>
> >> On 04.10.2024 10:32, Steven Yen wrote:
> >>> The following line calculates standard deviations of a column
> >>> vector:
> >>>
> >>> se<-apply(dd,1,sd)
> >>>
> >>> How can I calculate the covariance matrix using apply? Thanks.


From r@oknz @end|ng |rom gm@||@com  Sat Oct  5 02:03:22 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 5 Oct 2024 13:03:22 +1300
Subject: [R] apply
In-Reply-To: <20241004154103.3668dcb7@arachnoid>
References: <a2b0e838-6c7f-4248-977c-d4c8876a1c56@ntu.edu.tw>
 <5d7016d5-dba3-4d92-aa1d-94951de7dd44@statistik.tu-dortmund.de>
 <a6307aed-24bb-47d2-875a-abe441c88f18@gmail.com>
 <9c5bfb1d-e233-43d6-a9eb-994baf6dbac9@ntu.edu.tw>
 <3f7a76d1-b6c0-4e1c-9244-347c3c55a054@sapo.pt>
 <83a4f278-21dd-4b92-bc9d-9f6cec43ac52@ntu.edu.tw>
 <f88ecee8-0ee9-494e-97b6-e42e47912e02@sapo.pt>
 <a771c1cd-c8cf-4a14-881d-2e2746f19178@ntu.edu.tw>
 <20241004154103.3668dcb7@arachnoid>
Message-ID: <CABcYAdKENkVgZZCG-m3O=LjwZOz1GnZxCAy_GoQQvGcaMuMagA@mail.gmail.com>

> x <- runif(10)
> y <- runif(10)
> cov(cbind(x,y))
          x          y
x 0.1205034 0.02642830
y 0.0264283 0.09945432

I understand wanting to calculate covariance matrices.
What I DON'T understand is wanting to do it using apply().
(And that's what looked like a homework problem, it's so artificial.)


On Sat, 5 Oct 2024 at 01:41, Ivan Krylov via R-help
<r-help at r-project.org> wrote:
>
> ? Fri, 4 Oct 2024 20:28:01 +0800
> Steven Yen <styen at ntu.edu.tw> ?????:
>
> > Suppose I have two vectors, x and y. Is there a way
> > to do the covariance matrix with ?apply?.
>
> There is no covariance matrix for just two samples (vectors) 'x' and
> 'y'. You can only get one covariance value for these.
>
> If you had a pair of vectors of _random variates_, the situation would
> be different, but those are more abstract mathematical concepts. You
> would need to sample every random variate, producing two matrices 'x'
> and 'y' in order to calculate a covariance matrix for them.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ro@||n@ump @end|ng |rom gm@||@com  Mon Oct  7 00:47:45 2024
From: ro@||n@ump @end|ng |rom gm@||@com (roslinazairimah zakaria)
Date: Mon, 7 Oct 2024 06:47:45 +0800
Subject: [R] Time series data decomposition from by minute data
In-Reply-To: <CAO8Egw8J+BFRL7C8e6itM9NMfEMAPOhO6NeVbMqSTdrCeK7WAA@mail.gmail.com>
References: <CANTvJZKOYEO-9MgyyZjgZFEYfFWAtXJ4tXh_ntX_jFCixS=K9g@mail.gmail.com>
 <CAO8Egw8J+BFRL7C8e6itM9NMfEMAPOhO6NeVbMqSTdrCeK7WAA@mail.gmail.com>
Message-ID: <CANTvJZ+n=SzW59O=NkP27gzby8PQU2PgRArXRUtWpMoY_UCThg@mail.gmail.com>

Peter,

Thank you very much for your help.

On Fri, Oct 4, 2024 at 9:19?PM Petr Pikal <petr.pik at gmail.com> wrote:

> Hallo
>
> you can extract POSIX object
>
> tv <- as.POSIXct(index(dt_train))
>
> and use cut together with aggregate
> cut(tv, "hour")
>
> aggregate(dt_train, list(cut(tv, "hour")), mean)
>
> 2014-10-06 21:00:00 9.807692
> 2014-10-06 22:00:00 8.666667
>
> Cheers.
> Petr
>
>
>
> ?t 3. 10. 2024 v 17:25 odes?latel roslinazairimah zakaria <
> roslinaump at gmail.com> napsal:
>
>> Dear all,
>>
>> My data is by minutes and I can see it has seasonal trend by daily and
>> weekly. How do I decompose the minute data into daily and weekly
>>
>> some data:
>>
>> > dput(tail(dt_train,100))structure(c(11L, 11L, 10L, 10L, 10L, 10L, 10L,
>> 10L, 10L, 10L,
>> 10L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
>> 10L, 11L, 11L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
>> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 9L, 8L, 8L, 8L, 8L,
>> 8L, 8L, 8L, 8L, 8L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
>> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 9L, 9L, 9L), class = c("xts", "zoo"), index = structure(c(1412622480,
>> 1412622540, 1412622600, 1412622660, 1412622720, 1412622780, 1412622840,
>> 1412622900, 1412622960, 1412623020, 1412623080, 1412623140, 1412623200,
>> 1412623260, 1412623320, 1412623380, 1412623440, 1412623500, 1412623560,
>> 1412623620, 1412623680, 1412623740, 1412623800, 1412623860, 1412623920,
>> 1412623980, 1412624040, 1412624100, 1412624160, 1412624220, 1412624280,
>> 1412624340, 1412624400, 1412624460, 1412624520, 1412624580, 1412624640,
>> 1412624700, 1412624760, 1412624820, 1412624880, 1412624940, 1412625000,
>> 1412625060, 1412625120, 1412625180, 1412625240, 1412625300, 1412625360,
>> 1412625420, 1412625480, 1412625540, 1412625600, 1412625660, 1412625720,
>> 1412625780, 1412625840, 1412625900, 1412625960, 1412626020, 1412626080,
>> 1412626140, 1412626200, 1412626260, 1412626320, 1412626380, 1412626440,
>> 1412626500, 1412626560, 1412626620, 1412626680, 1412626740, 1412626800,
>> 1412626860, 1412626920, 1412626980, 1412627040, 1412627100, 1412627160,
>> 1412627220, 1412627280, 1412627340, 1412627400, 1412627460, 1412627520,
>> 1412627580, 1412627640, 1412627700, 1412627760, 1412627820, 1412627880,
>> 1412627940, 1412628000, 1412628060, 1412628120, 1412628180, 1412628240,
>> 1412628300, 1412628360, 1412628420), tzone = "", tclass = c("POSIXct",
>> "POSIXt")), dim = c(100L, 1L))
>>
>>
>> I also attached the plot of training data.
>>
>>
>> I tried :
>>
>> decompose(dt_train, type = "multiplicative", filter = NULL)Error in
>> decompose(dt_train, type = "multiplicative", filter = NULL) :
>>   time series has no or less than 2 periods
>>
>>
>> > stl(dt_train, s.window = "periodic")Error in stl(dt_train, s.window =
>> "periodic") :
>>   series is not periodic or has less than two
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Oct  7 01:53:20 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 6 Oct 2024 16:53:20 -0700
Subject: [R] Coda: On the efficiency of unsplit() for Rolf Turner's recent
 post
Message-ID: <CAGxFJbSKFYofbjqaVdWKfy9Hsq_L53nxvoZzim1itnO6aJnEqQ@mail.gmail.com>

(only of interest -- maybe! -- to those who followed this thread of a
couple of weeks ago)

Just for the heckuva it, I compared the timing of Deepayan's unsplit(x,f)
solution to my as.vector(do.call(rbind, x)) approach to the query for a
list of 3 vectors each of length 1000 (the original toy example was for a
list of 3 vectors of length 5). Unsurprisingly, I think, because the
unsplit() approach works for the general case whereas the do.call(rbind)
only works for the balanced structure of the toy example, do.call(rbind)
took about 1/10th the time of unsplit:

> microbenchmark(unsplit(x,f),times = 1000L)
Unit: microseconds
          expr    min     lq     mean median    uq      max neval
 unsplit(x, f) 63.058 64.042 70.44419 65.682 67.24 3893.155  1000
--------------
> microbenchmark(as.vector(do.call(rbind,x)),times = 1000L)
Unit: microseconds
                         expr   min    lq     mean median    uq    max neval
 as.vector(do.call(rbind, x)) 5.617 6.396 7.082299  6.765 7.216 79.335  1000

**Maybe** this suggests that adding a "regular" (or better-named) option to
unsplit() that would allow a simpler faster algorithm to be used for the
special but perhaps not uncommon case of Rolf's structured toy example
might be useful.

Please do not reply to this, as I am too ignorant to judge whether this is
foolish or not. I leave it to those more qualified to either dismiss or act
on this. I just wanted to present some limited but suggestive data.

Cheers to all,
Bert

	[[alternative HTML version deleted]]


From j@cob @end|ng |rom we@c|nc@com  Wed Oct  9 01:51:34 2024
From: j@cob @end|ng |rom we@c|nc@com (Jacob Williams)
Date: Tue, 8 Oct 2024 19:51:34 -0400
Subject: [R] R in Windows 11
Message-ID: <1F8D348D-4922-40F4-BA0D-D1155F0A4D4F@wescinc.com>

Hi,

What is the minimum version of R supported on Windows 11?

Thanks,
Jacob


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Oct  9 09:29:06 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 9 Oct 2024 08:29:06 +0100
Subject: [R] R in Windows 11
In-Reply-To: <1F8D348D-4922-40F4-BA0D-D1155F0A4D4F@wescinc.com>
References: <1F8D348D-4922-40F4-BA0D-D1155F0A4D4F@wescinc.com>
Message-ID: <9b54a0c2-637d-4471-a721-f84c817f7fde@sapo.pt>

?s 00:51 de 09/10/2024, Jacob Williams escreveu:
> Hi,
> 
> What is the minimum version of R supported on Windows 11?
> 
> Thanks,
> Jacob
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

The first version of R after the release of Windows 11 (2021-10-05) was 
R-4.1.2 (2021-11-01).
See [1]

[1] https://cran.r-project.org/src/base/R-4/

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @vi@e@gross m@iii@g oii gm@ii@com  Wed Oct  9 15:44:32 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Wed, 9 Oct 2024 09:44:32 -0400
Subject: [R] R in Windows 11
In-Reply-To: <1F8D348D-4922-40F4-BA0D-D1155F0A4D4F@wescinc.com>
References: <1F8D348D-4922-40F4-BA0D-D1155F0A4D4F@wescinc.com>
Message-ID: <004b01db1a51$5f61f510$1e25df30$@gmail.com>

Jacob,

I am curious about your request for a "minimum" and it makes me wonder what
aspects of switching to Windows 11 from earlier versions (no longer being
supported around now) have some impact on R.

Many people want to be running as recent a version of R as possible, albeit
there can be problems with having packages that have not been updated to run
on that version. For some purposes, you may want to freeze in everything
from an exact moment in time or have others replicate that configuration as
that is guaranteed to work for your purposes.

So, I was wondering about your request. I would think that pretty much all
versions of R going back years would work on Windows 11 with some possible
exceptions if you use some functionality that has changed.

Many people get R installed already compiled. Some can get the source code
and compile it locally. I wonder if there is a difference there. I suspect
you want the former and indeed there may not have been very old versions of
R set up for downloading on Windows 11.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jacob Williams
Sent: Tuesday, October 8, 2024 7:52 PM
To: r-help at r-project.org
Subject: [R] R in Windows 11

Hi,

What is the minimum version of R supported on Windows 11?

Thanks,
Jacob

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tgs77m m@iii@g oii y@hoo@com  Wed Oct  9 18:35:34 2024
From: tgs77m m@iii@g oii y@hoo@com (tgs77m m@iii@g oii y@hoo@com)
Date: Wed, 9 Oct 2024 09:35:34 -0700
Subject: [R] Discriminant of a cubic polynomial
References: <009a01db1a69$44ac9190$ce05b4b0$.ref@yahoo.com>
Message-ID: <009a01db1a69$44ac9190$ce05b4b0$@yahoo.com>

Colleagues

Given the coefficients of a cubic polynomial, a,b,c,d and
using

discriminant_cubic <- function(a, b, c, d) {
  D <- 18 * a * b * c * d - 4 * b^3 * d + b^2 * c^2 - 4 * a * c^2 - 27 * a^2
* d^2
  return(D)
}

I can find the discriminant of a cubic polynomial.
Is there an R package which can do this?

Thomas Subia


From |eo@m@d@ @end|ng |rom @yon|c@eu  Thu Oct 10 14:38:34 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Thu, 10 Oct 2024 12:38:34 +0000
Subject: [R] Discriminant of a cubic polynomial
Message-ID: <DBAP192MB09560B71DF1C16DCD5685AF684782@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Thomas,

Unfortunately, I do not know if any packages implement this functionality. Though, it is a topic that interests me.

Unlike the "classic discriminant", I prefer to work with the reduced polynomial. This "discriminant" is generalizable to a superset of Chebysev polynomials (which I called Cardano-polynomials).

x^3 - 3*c*x - 2*d = 0
x^5 - 5*c*x^3 + 5*c^2*x - 2*d = 0
x^7 - 7*c*x^5 + 14*c^2*x^3 - 7*c^3*x - 2*d = 0
discr = d^2 - c^n, where n = 3 for the degree 3 polynomial;

The beauty of this approach is that you can solve for all roots of these types of polynomials and the formula is much simpler. But you need to compute first the reduced polynomial. The order 3 polynomials always reduce to this type (which is not valid for higher orders).


By the way, the roots are as follows:
# intermediary quantities
p = (d + sqrt(discr))^(1/n);
q = (d - sqrt(discr))^(1/n);
# Roots:
p + q # Base-Root
m = cos(2*pi/n) + 1i * sin(2*pi/n); # root of unity
p * m^c(0, seq(n-1)) + q * m^c(0, rev(seq(n-1))); # All Roots

See on my GitHub page:
https://github.com/discoleo/R/blob/master/Math/Polynomials.CardanGeneralisation.R

Sincerely,

Leonard


	[[alternative HTML version deleted]]


From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Oct 10 15:46:19 2024
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 10 Oct 2024 15:46:19 +0200
Subject: [R] Time zones in POSIClt objects
Message-ID: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>


It is not completely clear to me how time zones work with POSIXlt 
objects. For POSIXct, I can understand what happens: time is always 
stored in GMT, the `tzone` attribute only affects how the times are 
displayed. All computations etc. are done in GMT.

POSIXlt objects have both a `tzone` attribute and a `zone` field. It 
seems that the `zone` field is largely ignored. It only seems to be used 
for displaying the times, but does not seem to play a role when doing 
arithmetic and conversions of the times.

For example below, we have the same times in two different time zones. 
The following seems to do what I expect: when we subtract the two times 
we get the difference in time between the two time zones:

t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
t1$zone
# [1] "GMT" "GMT"

t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
t2$zone
# [1] "CET" "CET"

t1 - t2
# Time differences in hours
# [1] 1 1


When I change the `tzone` attribute of t1 to that of t2:

attr(t1, "tzone") <- attr(t2, "tzone")
t1
#[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"

The times are still displayed as being in GMT, however when I take the 
difference:

t1 - t2
#Time differences in secs
#[1] 0 0

We get a difference of 0. So it seems that the difference is only based 
on the `tzone` attribute. The value of `zone` is completely ignored.

I am aware of the following remark in ?POSIXlt on arithmetic operations
| Be aware that ?"POSIXlt"? objects will be interpreted as being in
| the current time zone for these operations unless a time zone has
| been specified.

but this does not explain this, I think.

One of the reasons, I ask, is that I have (potentially) times in 
different time zones. Using POXIXlt objects seems like they could 
store/support this. But working with this seems unpractical as the 
`zone` field does not seem to do anything:

t1$zone <- c("CET", "GMT")
t1 - t2
#Time differences in secs
#[1] 0 0

Also the `gmtoff` field does not seem to do anything. For what/where is 
this field used?

t1$gmtoff <- c(3600, 0)
t1
#[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"

t1 - t2
#Time differences in secs
#[1] 0 0

as.POSIXct(t1)
#[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"

So, I am not sure what purpose the zone and gmtoff fields have. Do they 
have a purpose? Am I using them wrong? The reason I am asking, is that I 
have some times in potentially different time zones. The data I get is 
something like:

times <- list(
   year = c(2024L, 2024L),
   month = c(1L, 1L),
   day = c(1L, 1L),
   hour = c(12L, 12L),
   minutes = c(30L, 30L),
   seconds = c(0, 0),
   timezone = c("", "GMT")
)

I am looking for ways to convert this into a practical date format for 
working with in R. Possible time zones are only local time or UTC/GMT. I 
would be fine with either converting local time to GMT. What would be a 
good way to convert these to a format R can work with?

Thanks for the help.

Jan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Oct 10 16:13:56 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Oct 2024 07:13:56 -0700
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
Message-ID: <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>

POSIXt vectors do not support different time zones element-to-element.

If you want to keep track of timezones per element, you have to create a vector of timestamps (I would recommend POSIXct using UTC) and a parallel vector of timezone strings. How you manipulate these depends on your use cases, but from R's perspective you will have to manipulate them element-by-element.

I complained about this on this list a couple of decades ago, and was chastised for it. Evidently handling timezones per element was considered to be too impractically slow to be a standard feature.

On October 10, 2024 6:46:19 AM PDT, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>
>It is not completely clear to me how time zones work with POSIXlt objects. For POSIXct, I can understand what happens: time is always stored in GMT, the `tzone` attribute only affects how the times are displayed. All computations etc. are done in GMT.
>
>POSIXlt objects have both a `tzone` attribute and a `zone` field. It seems that the `zone` field is largely ignored. It only seems to be used for displaying the times, but does not seem to play a role when doing arithmetic and conversions of the times.
>
>For example below, we have the same times in two different time zones. The following seems to do what I expect: when we subtract the two times we get the difference in time between the two time zones:
>
>t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
>t1$zone
># [1] "GMT" "GMT"
>
>t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
>t2$zone
># [1] "CET" "CET"
>
>t1 - t2
># Time differences in hours
># [1] 1 1
>
>
>When I change the `tzone` attribute of t1 to that of t2:
>
>attr(t1, "tzone") <- attr(t2, "tzone")
>t1
>#[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"
>
>The times are still displayed as being in GMT, however when I take the difference:
>
>t1 - t2
>#Time differences in secs
>#[1] 0 0
>
>We get a difference of 0. So it seems that the difference is only based on the `tzone` attribute. The value of `zone` is completely ignored.
>
>I am aware of the following remark in ?POSIXlt on arithmetic operations
>| Be aware that ?"POSIXlt"? objects will be interpreted as being in
>| the current time zone for these operations unless a time zone has
>| been specified.
>
>but this does not explain this, I think.
>
>One of the reasons, I ask, is that I have (potentially) times in different time zones. Using POXIXlt objects seems like they could store/support this. But working with this seems unpractical as the `zone` field does not seem to do anything:
>
>t1$zone <- c("CET", "GMT")
>t1 - t2
>#Time differences in secs
>#[1] 0 0
>
>Also the `gmtoff` field does not seem to do anything. For what/where is this field used?
>
>t1$gmtoff <- c(3600, 0)
>t1
>#[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"
>
>t1 - t2
>#Time differences in secs
>#[1] 0 0
>
>as.POSIXct(t1)
>#[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"
>
>So, I am not sure what purpose the zone and gmtoff fields have. Do they have a purpose? Am I using them wrong? The reason I am asking, is that I have some times in potentially different time zones. The data I get is something like:
>
>times <- list(
>  year = c(2024L, 2024L),
>  month = c(1L, 1L),
>  day = c(1L, 1L),
>  hour = c(12L, 12L),
>  minutes = c(30L, 30L),
>  seconds = c(0, 0),
>  timezone = c("", "GMT")
>)
>
>I am looking for ways to convert this into a practical date format for working with in R. Possible time zones are only local time or UTC/GMT. I would be fine with either converting local time to GMT. What would be a good way to convert these to a format R can work with?
>
>Thanks for the help.
>
>Jan
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Oct 10 17:16:52 2024
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 10 Oct 2024 17:16:52 +0200
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
Message-ID: <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>

Thanks.

On 10/10/24 16:13, Jeff Newmiller wrote:
> POSIXt vectors do not support different time zones element-to-element.

 > I complained about this on this list a couple of decades ago, and was 
  chastised for it. Evidently handling timezones per element was 
considered to be too impractically slow to be a standard feature.


This is where it is unclear to me what the purpose is of the `zone` 
element of the POSIXlt object. It does allow for registering a time zone 
per element. It just seems to be ignored.

> 
> If you want to keep track of timezones per element, you have to create a vector of timestamps (I would recommend POSIXct using UTC) and a parallel vector of timezone strings. How you manipulate these depends on your use cases, but from R's perspective you will have to manipulate them element-by-element.

As I mentioned, fortunately, I only have local time and GMT and it would 
be fine to convert them to a single time zone if that is what it takes 
to work with them in R. So, I guess, I could split the vector in two, 
convert local time to GMT and combine them again (respecting the 
original order).

Jan




> On October 10, 2024 6:46:19 AM PDT, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>>
>> It is not completely clear to me how time zones work with POSIXlt objects. For POSIXct, I can understand what happens: time is always stored in GMT, the `tzone` attribute only affects how the times are displayed. All computations etc. are done in GMT.
>>
>> POSIXlt objects have both a `tzone` attribute and a `zone` field. It seems that the `zone` field is largely ignored. It only seems to be used for displaying the times, but does not seem to play a role when doing arithmetic and conversions of the times.
>>
>> For example below, we have the same times in two different time zones. The following seems to do what I expect: when we subtract the two times we get the difference in time between the two time zones:
>>
>> t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
>> t1$zone
>> # [1] "GMT" "GMT"
>>
>> t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
>> t2$zone
>> # [1] "CET" "CET"
>>
>> t1 - t2
>> # Time differences in hours
>> # [1] 1 1
>>
>>
>> When I change the `tzone` attribute of t1 to that of t2:
>>
>> attr(t1, "tzone") <- attr(t2, "tzone")
>> t1
>> #[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"
>>
>> The times are still displayed as being in GMT, however when I take the difference:
>>
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> We get a difference of 0. So it seems that the difference is only based on the `tzone` attribute. The value of `zone` is completely ignored.
>>
>> I am aware of the following remark in ?POSIXlt on arithmetic operations
>> | Be aware that ?"POSIXlt"? objects will be interpreted as being in
>> | the current time zone for these operations unless a time zone has
>> | been specified.
>>
>> but this does not explain this, I think.
>>
>> One of the reasons, I ask, is that I have (potentially) times in different time zones. Using POXIXlt objects seems like they could store/support this. But working with this seems unpractical as the `zone` field does not seem to do anything:
>>
>> t1$zone <- c("CET", "GMT")
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> Also the `gmtoff` field does not seem to do anything. For what/where is this field used?
>>
>> t1$gmtoff <- c(3600, 0)
>> t1
>> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"
>>
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> as.POSIXct(t1)
>> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"
>>
>> So, I am not sure what purpose the zone and gmtoff fields have. Do they have a purpose? Am I using them wrong? The reason I am asking, is that I have some times in potentially different time zones. The data I get is something like:
>>
>> times <- list(
>>   year = c(2024L, 2024L),
>>   month = c(1L, 1L),
>>   day = c(1L, 1L),
>>   hour = c(12L, 12L),
>>   minutes = c(30L, 30L),
>>   seconds = c(0, 0),
>>   timezone = c("", "GMT")
>> )
>>
>> I am looking for ways to convert this into a practical date format for working with in R. Possible time zones are only local time or UTC/GMT. I would be fine with either converting local time to GMT. What would be a good way to convert these to a format R can work with?
>>
>> Thanks for the help.
>>
>> Jan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothend|eck @end|ng |rom gm@||@com  Thu Oct 10 20:32:31 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 10 Oct 2024 14:32:31 -0400
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
 <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
Message-ID: <CAP01uR=EFCbEoKXUZv_FsFK8nF0AgjOkXsfen=32wLgh954kFQ@mail.gmail.com>

Sys.setenv(TZ = "GMT") will set the local time zone to GMT so there
would only be one time
zone regardless of whether local or GMT were used.

On Thu, Oct 10, 2024 at 11:17?AM Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>
> Thanks.
>
> On 10/10/24 16:13, Jeff Newmiller wrote:
> > POSIXt vectors do not support different time zones element-to-element.
>
>  > I complained about this on this list a couple of decades ago, and was
>   chastised for it. Evidently handling timezones per element was
> considered to be too impractically slow to be a standard feature.
>
>
> This is where it is unclear to me what the purpose is of the `zone`
> element of the POSIXlt object. It does allow for registering a time zone
> per element. It just seems to be ignored.
>
> >
> > If you want to keep track of timezones per element, you have to create a vector of timestamps (I would recommend POSIXct using UTC) and a parallel vector of timezone strings. How you manipulate these depends on your use cases, but from R's perspective you will have to manipulate them element-by-element.
>
> As I mentioned, fortunately, I only have local time and GMT and it would
> be fine to convert them to a single time zone if that is what it takes
> to work with them in R. So, I guess, I could split the vector in two,
> convert local time to GMT and combine them again (respecting the
> original order).
>
> Jan
>
>
>
>
> > On October 10, 2024 6:46:19 AM PDT, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
> >>
> >> It is not completely clear to me how time zones work with POSIXlt objects. For POSIXct, I can understand what happens: time is always stored in GMT, the `tzone` attribute only affects how the times are displayed. All computations etc. are done in GMT.
> >>
> >> POSIXlt objects have both a `tzone` attribute and a `zone` field. It seems that the `zone` field is largely ignored. It only seems to be used for displaying the times, but does not seem to play a role when doing arithmetic and conversions of the times.
> >>
> >> For example below, we have the same times in two different time zones. The following seems to do what I expect: when we subtract the two times we get the difference in time between the two time zones:
> >>
> >> t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
> >> t1$zone
> >> # [1] "GMT" "GMT"
> >>
> >> t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
> >> t2$zone
> >> # [1] "CET" "CET"
> >>
> >> t1 - t2
> >> # Time differences in hours
> >> # [1] 1 1
> >>
> >>
> >> When I change the `tzone` attribute of t1 to that of t2:
> >>
> >> attr(t1, "tzone") <- attr(t2, "tzone")
> >> t1
> >> #[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"
> >>
> >> The times are still displayed as being in GMT, however when I take the difference:
> >>
> >> t1 - t2
> >> #Time differences in secs
> >> #[1] 0 0
> >>
> >> We get a difference of 0. So it seems that the difference is only based on the `tzone` attribute. The value of `zone` is completely ignored.
> >>
> >> I am aware of the following remark in ?POSIXlt on arithmetic operations
> >> | Be aware that ?"POSIXlt"? objects will be interpreted as being in
> >> | the current time zone for these operations unless a time zone has
> >> | been specified.
> >>
> >> but this does not explain this, I think.
> >>
> >> One of the reasons, I ask, is that I have (potentially) times in different time zones. Using POXIXlt objects seems like they could store/support this. But working with this seems unpractical as the `zone` field does not seem to do anything:
> >>
> >> t1$zone <- c("CET", "GMT")
> >> t1 - t2
> >> #Time differences in secs
> >> #[1] 0 0
> >>
> >> Also the `gmtoff` field does not seem to do anything. For what/where is this field used?
> >>
> >> t1$gmtoff <- c(3600, 0)
> >> t1
> >> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"
> >>
> >> t1 - t2
> >> #Time differences in secs
> >> #[1] 0 0
> >>
> >> as.POSIXct(t1)
> >> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"
> >>
> >> So, I am not sure what purpose the zone and gmtoff fields have. Do they have a purpose? Am I using them wrong? The reason I am asking, is that I have some times in potentially different time zones. The data I get is something like:
> >>
> >> times <- list(
> >>   year = c(2024L, 2024L),
> >>   month = c(1L, 1L),
> >>   day = c(1L, 1L),
> >>   hour = c(12L, 12L),
> >>   minutes = c(30L, 30L),
> >>   seconds = c(0, 0),
> >>   timezone = c("", "GMT")
> >> )
> >>
> >> I am looking for ways to convert this into a practical date format for working with in R. Possible time zones are only local time or UTC/GMT. I would be fine with either converting local time to GMT. What would be a good way to convert these to a format R can work with?
> >>
> >> Thanks for the help.
> >>
> >> Jan
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Oct 11 02:30:51 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Oct 2024 17:30:51 -0700
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <CAP01uR=EFCbEoKXUZv_FsFK8nF0AgjOkXsfen=32wLgh954kFQ@mail.gmail.com>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
 <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
 <CAP01uR=EFCbEoKXUZv_FsFK8nF0AgjOkXsfen=32wLgh954kFQ@mail.gmail.com>
Message-ID: <88FF3DF7-E42C-4D99-B5D0-2FD806198402@dcn.davis.ca.us>

I am not sure what this has to do with timezones embedded in specific POSIXt vectors? Can you elaborate why this is relevant?

On October 10, 2024 11:32:31 AM PDT, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>Sys.setenv(TZ = "GMT") will set the local time zone to GMT so there
>would only be one time
>zone regardless of whether local or GMT were used.
>
>On Thu, Oct 10, 2024 at 11:17?AM Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>>
>> Thanks.
>>
>> On 10/10/24 16:13, Jeff Newmiller wrote:
>> > POSIXt vectors do not support different time zones element-to-element.
>>
>>  > I complained about this on this list a couple of decades ago, and was
>>   chastised for it. Evidently handling timezones per element was
>> considered to be too impractically slow to be a standard feature.
>>
>>
>> This is where it is unclear to me what the purpose is of the `zone`
>> element of the POSIXlt object. It does allow for registering a time zone
>> per element. It just seems to be ignored.
>>
>> >
>> > If you want to keep track of timezones per element, you have to create a vector of timestamps (I would recommend POSIXct using UTC) and a parallel vector of timezone strings. How you manipulate these depends on your use cases, but from R's perspective you will have to manipulate them element-by-element.
>>
>> As I mentioned, fortunately, I only have local time and GMT and it would
>> be fine to convert them to a single time zone if that is what it takes
>> to work with them in R. So, I guess, I could split the vector in two,
>> convert local time to GMT and combine them again (respecting the
>> original order).
>>
>> Jan
>>
>>
>>
>>
>> > On October 10, 2024 6:46:19 AM PDT, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>> >>
>> >> It is not completely clear to me how time zones work with POSIXlt objects. For POSIXct, I can understand what happens: time is always stored in GMT, the `tzone` attribute only affects how the times are displayed. All computations etc. are done in GMT.
>> >>
>> >> POSIXlt objects have both a `tzone` attribute and a `zone` field. It seems that the `zone` field is largely ignored. It only seems to be used for displaying the times, but does not seem to play a role when doing arithmetic and conversions of the times.
>> >>
>> >> For example below, we have the same times in two different time zones. The following seems to do what I expect: when we subtract the two times we get the difference in time between the two time zones:
>> >>
>> >> t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
>> >> t1$zone
>> >> # [1] "GMT" "GMT"
>> >>
>> >> t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
>> >> t2$zone
>> >> # [1] "CET" "CET"
>> >>
>> >> t1 - t2
>> >> # Time differences in hours
>> >> # [1] 1 1
>> >>
>> >>
>> >> When I change the `tzone` attribute of t1 to that of t2:
>> >>
>> >> attr(t1, "tzone") <- attr(t2, "tzone")
>> >> t1
>> >> #[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"
>> >>
>> >> The times are still displayed as being in GMT, however when I take the difference:
>> >>
>> >> t1 - t2
>> >> #Time differences in secs
>> >> #[1] 0 0
>> >>
>> >> We get a difference of 0. So it seems that the difference is only based on the `tzone` attribute. The value of `zone` is completely ignored.
>> >>
>> >> I am aware of the following remark in ?POSIXlt on arithmetic operations
>> >> | Be aware that ?"POSIXlt"? objects will be interpreted as being in
>> >> | the current time zone for these operations unless a time zone has
>> >> | been specified.
>> >>
>> >> but this does not explain this, I think.
>> >>
>> >> One of the reasons, I ask, is that I have (potentially) times in different time zones. Using POXIXlt objects seems like they could store/support this. But working with this seems unpractical as the `zone` field does not seem to do anything:
>> >>
>> >> t1$zone <- c("CET", "GMT")
>> >> t1 - t2
>> >> #Time differences in secs
>> >> #[1] 0 0
>> >>
>> >> Also the `gmtoff` field does not seem to do anything. For what/where is this field used?
>> >>
>> >> t1$gmtoff <- c(3600, 0)
>> >> t1
>> >> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"
>> >>
>> >> t1 - t2
>> >> #Time differences in secs
>> >> #[1] 0 0
>> >>
>> >> as.POSIXct(t1)
>> >> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"
>> >>
>> >> So, I am not sure what purpose the zone and gmtoff fields have. Do they have a purpose? Am I using them wrong? The reason I am asking, is that I have some times in potentially different time zones. The data I get is something like:
>> >>
>> >> times <- list(
>> >>   year = c(2024L, 2024L),
>> >>   month = c(1L, 1L),
>> >>   day = c(1L, 1L),
>> >>   hour = c(12L, 12L),
>> >>   minutes = c(30L, 30L),
>> >>   seconds = c(0, 0),
>> >>   timezone = c("", "GMT")
>> >> )
>> >>
>> >> I am looking for ways to convert this into a practical date format for working with in R. Possible time zones are only local time or UTC/GMT. I would be fine with either converting local time to GMT. What would be a good way to convert these to a format R can work with?
>> >>
>> >> Thanks for the help.
>> >>
>> >> Jan
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
Sent from my phone. Please excuse my brevity.


From |kry|ov @end|ng |rom d|@root@org  Fri Oct 11 09:10:41 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 11 Oct 2024 10:10:41 +0300
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
 <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
Message-ID: <20241011101041.1e54c933@Tarkus>

? Thu, 10 Oct 2024 17:16:52 +0200
Jan van der Laan <rhelp at eoos.dds.nl> ?????:

> This is where it is unclear to me what the purpose is of the `zone` 
> element of the POSIXlt object. It does allow for registering a time
> zone per element. It just seems to be ignored.

I think that since POSIXlt is an interface to what the C standard calls
the "broken-down" time (into parts, not in terms of functionality) and
both the C standard [1] and the POSIX mktime() [2] ignore the
tm_gmtoff/tm_zone fields (standard C because it's not defined there;
POSIX because it defers to standard C), these fields exist for
presentation purposes. They may be populated when constructing the time
object, but not used for later calculations.

Instead, the standard mktime() always uses the process-global timezone,
so when R processes POSIXlt values, it has to set the TZ environment
variable from the 'tzone' attribute, call tzset() to set global state in
the library, use mktime() to obtain seconds since epoch, and then reset
everything back.

> As I mentioned, fortunately, I only have local time and GMT and it
> would be fine to convert them to a single time zone if that is what
> it takes to work with them in R.

Since your data looks like the following:

times <- list(
   year = c(2024L, 2024L),
   month = c(1L, 1L),
   day = c(1L, 1L),
   hour = c(12L, 12L),
   minutes = c(30L, 30L),
   seconds = c(0, 0),
   timezone = c("", "GMT")
)

how about converting all the times into POSIXct?

do.call(mapply, c(
 \(year, month, day, hour, minutes, seconds, timezone)
  "%04d-%02d-%02d %02d:%02d:%02d" |>
   sprintf(year, month, day, hour, minutes, seconds) |>
   as.POSIXct(format = "%Y-%m-%d %H:%M:%S", tz = timezone),
 times
)) |> do.call(c, args=_)

Its 'tzone' attribute exists mostly for presentation purposes, so even
if you lose it, the exact point in UTC-relative time is still intact.

-- 
Best regards,
Ivan

[1]
https://en.cppreference.com/w/c/chrono/mktime

[2]
https://pubs.opengroup.org/onlinepubs/9799919799/functions/mktime.html


From pd@|gd @end|ng |rom gm@||@com  Fri Oct 11 10:50:32 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 11 Oct 2024 10:50:32 +0200
Subject: [R] [Rd] R 4.4.2 scheduled for October 31
Message-ID: <7D93F015-8D42-4847-BDF0-88B360816B08@gmail.com>

Full schedule is available on developer.r-project.org (pending update from SVN).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct 11 11:56:43 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 11 Oct 2024 10:56:43 +0100
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
Message-ID: <17ceb4e5-8e1d-443a-996c-008ea643962c@sapo.pt>

?s 15:13 de 10/10/2024, Jeff Newmiller via R-help escreveu:
> POSIXt vectors do not support different time zones element-to-element.
> 
> If you want to keep track of timezones per element, you have to create a vector of timestamps (I would recommend POSIXct using UTC) and a parallel vector of timezone strings. How you manipulate these depends on your use cases, but from R's perspective you will have to manipulate them element-by-element.
> 
> I complained about this on this list a couple of decades ago, and was chastised for it. Evidently handling timezones per element was considered to be too impractically slow to be a standard feature.
> 
> On October 10, 2024 6:46:19 AM PDT, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>>
>> It is not completely clear to me how time zones work with POSIXlt objects. For POSIXct, I can understand what happens: time is always stored in GMT, the `tzone` attribute only affects how the times are displayed. All computations etc. are done in GMT.
>>
>> POSIXlt objects have both a `tzone` attribute and a `zone` field. It seems that the `zone` field is largely ignored. It only seems to be used for displaying the times, but does not seem to play a role when doing arithmetic and conversions of the times.
>>
>> For example below, we have the same times in two different time zones. The following seems to do what I expect: when we subtract the two times we get the difference in time between the two time zones:
>>
>> t1 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"), tz = "GMT")
>> t1$zone
>> # [1] "GMT" "GMT"
>>
>> t2 <- as.POSIXlt(c("2024-01-01 12:30", "2024-01-01 12:30"))
>> t2$zone
>> # [1] "CET" "CET"
>>
>> t1 - t2
>> # Time differences in hours
>> # [1] 1 1
>>
>>
>> When I change the `tzone` attribute of t1 to that of t2:
>>
>> attr(t1, "tzone") <- attr(t2, "tzone")
>> t1
>> #[1] "2024-01-01 12:30:00 GMT" "2024-01-01 12:30:00 GMT"
>>
>> The times are still displayed as being in GMT, however when I take the difference:
>>
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> We get a difference of 0. So it seems that the difference is only based on the `tzone` attribute. The value of `zone` is completely ignored.
>>
>> I am aware of the following remark in ?POSIXlt on arithmetic operations
>> | Be aware that ?"POSIXlt"? objects will be interpreted as being in
>> | the current time zone for these operations unless a time zone has
>> | been specified.
>>
>> but this does not explain this, I think.
>>
>> One of the reasons, I ask, is that I have (potentially) times in different time zones. Using POXIXlt objects seems like they could store/support this. But working with this seems unpractical as the `zone` field does not seem to do anything:
>>
>> t1$zone <- c("CET", "GMT")
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> Also the `gmtoff` field does not seem to do anything. For what/where is this field used?
>>
>> t1$gmtoff <- c(3600, 0)
>> t1
>> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 GMT"
>>
>> t1 - t2
>> #Time differences in secs
>> #[1] 0 0
>>
>> as.POSIXct(t1)
>> #[1] "2024-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"
>>
>> So, I am not sure what purpose the zone and gmtoff fields have. Do they have a purpose? Am I using them wrong? The reason I am asking, is that I have some times in potentially different time zones. The data I get is something like:
>>
>> times <- list(
>>   year = c(2024L, 2024L),
>>   month = c(1L, 1L),
>>   day = c(1L, 1L),
>>   hour = c(12L, 12L),
>>   minutes = c(30L, 30L),
>>   seconds = c(0, 0),
>>   timezone = c("", "GMT")
>> )
>>
>> I am looking for ways to convert this into a practical date format for working with in R. Possible time zones are only local time or UTC/GMT. I would be fine with either converting local time to GMT. What would be a good way to convert these to a format R can work with?
>>
>> Thanks for the help.
>>
>> Jan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
Hello,

A way to have different time zones is to store t1 and t2 in list, which 
are vectors. Just not atomic vectors.
I think it complicates what should be simple, but here it is.



# create two lists
t1 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz = 
"GMT")
t2 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz = 
"CET")

# this works but is it a wanted way of making simple computations?
Map(`-`, t1, t2)
#> [[1]]
#> Time difference of 1 hours
#>
#> [[2]]
#> Time difference of 1 hours

# mapply default is to simplify the result, if possible
mapply(`-`, t1, t2)
#> [1] 1 1

t1 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz = 
"GMT")
t2 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz = 
"CET")

# as documented in ?mapply > sapply, all attributes are lost,
# after simplification the class attribute follows the hierarchy
# NULL < raw < logical < integer < double < complex < character < list < 
expression
mapply(`-`, t1, t2) |> str()
#>  num [1:2] 1 1


# now change only one member of the list t1
attr(t1[[2]], "tzone") <- attr(t2[[2]], "tzone")

# t1 has two different time zones and the Map/mapply loops
# above still give the expected results
Map(`-`, t1, t2)
#> [[1]]
#> Time difference of 1 hours
#>
#> [[2]]
#> Time difference of 0 secs

mapply(`-`, t1, t2)
#> [1] 1 0


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From rhe|p @end|ng |rom eoo@@dd@@n|  Fri Oct 11 13:12:11 2024
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Fri, 11 Oct 2024 13:12:11 +0200
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <20241011101041.1e54c933@Tarkus>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
 <2ebef1bf-60b3-4d8a-add6-2f89d36155cb@eoos.dds.nl>
 <20241011101041.1e54c933@Tarkus>
Message-ID: <fcf8b457-7dc0-4a16-ba28-3ff90d34a7b7@eoos.dds.nl>

Thanks,

On 10/11/24 09:10, Ivan Krylov wrote:
> ? Thu, 10 Oct 2024 17:16:52 +0200
> Jan van der Laan <rhelp at eoos.dds.nl> ?????:
>
>> This is where it is unclear to me what the purpose is of the `zone`
>> element of the POSIXlt object. It does allow for registering a time
>> zone per element. It just seems to be ignored.
> I think that since POSIXlt is an interface to what the C standard calls
> the "broken-down" time (into parts, not in terms of functionality) and
> both the C standard [1] and the POSIX mktime() [2] ignore the
> tm_gmtoff/tm_zone fields (standard C because it's not defined there;
> POSIX because it defers to standard C), these fields exist for
> presentation purposes. They may be populated when constructing the time
> object, but not used for later calculations.
>
> Instead, the standard mktime() always uses the process-global timezone,
> so when R processes POSIXlt values, it has to set the TZ environment
> variable from the 'tzone' attribute, call tzset() to set global state in
> the library, use mktime() to obtain seconds since epoch, and then reset
> everything back.

So that could then indeed be a performance issue. Still, a warning that 
this field is ignored might be nice.

And there are use-cases where it would be nice to have different time 
zones per record. For example, for a dataset with flights, departure and 
arrival times are often given in the local time zone of the airports and 
these local times might be relevant for some analyses. At the same time, 
to calculate, for example, flight durations these local time zones need 
to be handled correctly.

>> As I mentioned, fortunately, I only have local time and GMT and it
>> would be fine to convert them to a single time zone if that is what
>> it takes to work with them in R.
> Since your data looks like the following:
>
> times <- list(
>     year = c(2024L, 2024L),
>     month = c(1L, 1L),
>     day = c(1L, 1L),
>     hour = c(12L, 12L),
>     minutes = c(30L, 30L),
>     seconds = c(0, 0),
>     timezone = c("", "GMT")
> )
>
> how about converting all the times into POSIXct?
>
> do.call(mapply, c(
>   \(year, month, day, hour, minutes, seconds, timezone)
>    "%04d-%02d-%02d %02d:%02d:%02d" |>
>     sprintf(year, month, day, hour, minutes, seconds) |>
>     as.POSIXct(format = "%Y-%m-%d %H:%M:%S", tz = timezone),
>   times
> )) |> do.call(c, args=_)
>
> Its 'tzone' attribute exists mostly for presentation purposes, so even
> if you lose it, the exact point in UTC-relative time is still intact.

Thanks, I had already started to do something similar starting from 
POSIXlt: a funtion that converts to POSIXct using the zone information:

lttoct <- function(x) {
 ? tzone <- attr(x, "tzone")[1]
 ? result <- rep(as.POSIXct(0, tz = tzone), length(res))
 ? zones <- unique(x$zone)
 ? for (zone in zones) {
 ??? sel <- if (is.na(zone)) is.na(x$zone) else
 ????? x$zone == zone & !is.na(x$zone)
 ??? result[sel] <- as.POSIXct(x[sel], tz = zone)
 ? }
 ? result
}

t1 <- as.POSIXlt(c("2023-01-01 12:30", "2024-01-01 12:30"))
t1$zone <- c("", "GMT")

lttoct(t1)
# [1] "2023-01-01 12:30:00 CET" "2024-01-01 13:30:00 CET"
as.POSIXct(t1)
# [1] "2023-01-01 12:30:00 CET" "2024-01-01 12:30:00 CET"


From rhe|p @end|ng |rom eoo@@dd@@n|  Fri Oct 11 13:24:35 2024
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Fri, 11 Oct 2024 13:24:35 +0200
Subject: [R] Time zones in POSIClt objects
In-Reply-To: <17ceb4e5-8e1d-443a-996c-008ea643962c@sapo.pt>
References: <7c51d77b-4809-46fa-ab72-ad611a0e9e99@eoos.dds.nl>
 <FA1B0835-0DE8-43AA-9BAF-D431F19255E8@dcn.davis.ca.us>
 <17ceb4e5-8e1d-443a-996c-008ea643962c@sapo.pt>
Message-ID: <da3d0db0-5edf-4b96-ad99-c4421034c6ef@eoos.dds.nl>


On 10/11/24 11:56, Rui Barradas wrote:
> Hello,
>
> A way to have different time zones is to store t1 and t2 in list, 
> which are vectors. Just not atomic vectors.
> I think it complicates what should be simple, but here it is.
>
>
>
> # create two lists
> t1 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz 
> = "GMT")
> t2 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz 
> = "CET")
>
> # this works but is it a wanted way of making simple computations?
> Map(`-`, t1, t2)
> #> [[1]]
> #> Time difference of 1 hours
> #>
> #> [[2]]
> #> Time difference of 1 hours
>
> # mapply default is to simplify the result, if possible
> mapply(`-`, t1, t2)
> #> [1] 1 1
>
> t1 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz 
> = "GMT")
> t2 <- lapply(c("2024-01-01 12:30", "2024-01-01 12:30"), as.POSIXlt, tz 
> = "CET")
>
> # as documented in ?mapply > sapply, all attributes are lost,
> # after simplification the class attribute follows the hierarchy
> # NULL < raw < logical < integer < double < complex < character < list 
> < expression
> mapply(`-`, t1, t2) |> str()
> #>? num [1:2] 1 1
>
>
> # now change only one member of the list t1
> attr(t1[[2]], "tzone") <- attr(t2[[2]], "tzone")
>
> # t1 has two different time zones and the Map/mapply loops
> # above still give the expected results
> Map(`-`, t1, t2)
> #> [[1]]
> #> Time difference of 1 hours
> #>
> #> [[2]]
> #> Time difference of 0 secs
>
> mapply(`-`, t1, t2)
> #> [1] 1 0
>
>
> Hope this helps,
>
> Rui Barradas


Thanks. That would basically mean writing a separate class for date-time 
objects. If it was for a specific application where it is important to 
keep the time zones, this might be a good solution. However, the dates 
are output from a generic package and I would like to output something 
that is practical for users. Such a list of dates as you are proposing 
would not be supported by a lot of existing packages. Even something 
like plotting with the dates on the x-axis would not work. Perhaps a 
POSIXct object with an extra attribute containing the time zones would 
then be easier: by default everything would then be in, for example, UTC.

As I mentioned in the previous mail, I currently have a solution that 
converts everything to local time. But that means loosing the individual 
time zone information.

Best,

Jan


From @b|tbo| @end|ng |rom @ent@com  Sun Oct 13 12:45:36 2024
From: @b|tbo| @end|ng |rom @ent@com (Jean-Louis Abitbol)
Date: Sun, 13 Oct 2024 12:45:36 +0200
Subject: [R] Warning object has offset 0. PDF file
Message-ID: <48380494-81ec-43c7-a8a4-18097cd7ca5f@app.fastmail.com>

Good day to all

Using 
> library(pdftools)
Using poppler version 23.04.0

I get a number of warnings such as:

> pdf_subset(infile, pages = 156:157, output = outfile)
WARNING: /Users/jla/Library/CloudStorage/Dropbox/7cordas/Caio/record/90 NEW RODA SONG BOOK.pdf (object 7 0): object has offset 0
WARNING: /Users/jla/Library/CloudStorage/Dropbox/7cordas/Caio/record/90 NEW RODA SONG BOOK.pdf (object 175 0): object has offset 0
WARNING: /Users/jla/Library/CloudStorage/Dropbox/7cordas/Caio/record/90 NEW RODA SONG BOOK.pdf (object 254 0): object has offset 0

This does not prevent from getting the pages extracted properly and written to a pdf file which is readable. Aging is probably the cause of my irritation with such warnings.

 I assume there is a problem with the source pdf file which was assembled by music amateurs using various sources.

My question maybe out of the scope of this list is:

How can I detect and potentially correct using appropriate open source software what is wrong with the pdf file. 
I am on macos.

Thanks for any pointers and best wishes, Jean-Louis


From e|@@eg@rrenc @end|ng |rom gm@||@com  Sun Oct 13 13:19:09 2024
From: e|@@eg@rrenc @end|ng |rom gm@||@com (David Bars)
Date: Sun, 13 Oct 2024 13:19:09 +0200
Subject: [R] The RV coinertia coefficient to interpret multivariate analysis
 plots
Message-ID: <CABsq2cnD2_q+to4Hznnq8=ptEs3jhuLu0i7myNAnFH6JiC12gw@mail.gmail.com>

Dear all community,

My issue is related to the R package (made4) that permits me to calculate
the RV coefficient of co-inertia. However, it is a theoretical question.
And if I am not mistaken, the list Usenet groups sci.stat.consult is not
currently active.

Let me explain briefly:

Through different microbiota datasets, I have plotted PCoA, db-RDA and
sPLS-DA using 3 different types of normalization methods (Total sum of
squares, cumulative sum of squares and rarefaction). For each dataset and
multivariate analysis (PCoA, db-RDA or sPLS-DA) in order to easily
interpret if the different normalization strategies creates me different or
equivalent PCoA for example, I have calculated the Procrustes sum of
squares and the RV coefficient of co-inertia. However, for the RV
coefficient of co-inertia, I have obtained the value 1 (perfect
equivalence) for the PCoA comparisons amongst the 3 methods of
normalization, and also for the db-RDA. For the sPLS-DA I have not obtained
1 for all the comparisons.

Then, my concern, it is why the comparison of 3 normalization methods
within their PCoA plots and within db-RDA plots it is always 1, meaning
that the all PCoA plots between them (the 3 normalization methods compared)
are identical and the same for the db-RDA plots.. This scenario tells me
something at a theorically level?

Why could obtain 1 for PCoA and db-RDA and not for sPLS-DA?

Thanks on advance for your comments...

David

	[[alternative HTML version deleted]]


